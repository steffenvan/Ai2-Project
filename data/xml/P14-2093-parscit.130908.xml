<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010703">
<title confidence="0.98371">
Effective Selection of Translation Model Training Data
</title>
<author confidence="0.998734">
Le Liu Yu Hong* Hao Liu Xing Wang Jianmin Yao
</author>
<affiliation confidence="0.998296">
School of Computer Science &amp; Technology, Soochow University, China
</affiliation>
<email confidence="0.954993">
{20124227052, hongy, 20134227035, 20114227047, jyao}@suda.edu.cn
</email>
<sectionHeader confidence="0.992781" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999034136363636">
Data selection has been demonstrated to
be an effective approach to addressing
the lack of high-quality bitext for statisti-
cal machine translation in the domain of
interest. Most current data selection
methods solely use language models
trained on a small scale in-domain data to
select domain-relevant sentence pairs
from general-domain parallel corpus. By
contrast, we argue that the relevance be-
tween a sentence pair and target domain
can be better evaluated by the combina-
tion of language model and translation
model. In this paper, we study and exper-
iment with novel methods that apply
translation models into domain-relevant
data selection. The results show that our
methods outperform previous methods.
When the selected sentence pairs are
evaluated on an end-to-end MT task, our
methods can increase the translation per-
formance by 3 BLEU points.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999851588235294">
Statistical machine translation depends heavily
on large scale parallel corpora. The corpora are
necessary priori knowledge for training effective
translation model. However, domain-specific
machine translation has few parallel corpora for
translation model training in the domain of inter-
est. For this, an effective approach is to automat-
ically select and expand domain-specific sen-
tence pairs from large scale general-domain par-
allel corpus. The approach is named Data Selec-
tion. Current data selection methods mostly use
language models trained on small scale in-
domain data to measure domain relevance and
select domain-relevant parallel sentence pairs to
expand training corpora. Related work in litera-
ture has proven that the expanded corpora can
substantially improve the performance of ma-
</bodyText>
<note confidence="0.478782">
* Corresponding author
</note>
<bodyText confidence="0.9912788">
chine translation (Duh et al., 2010; Haddow and
Koehn, 2012).
However, the methods are still far from satis-
factory for real application for the following rea-
sons:
</bodyText>
<listItem confidence="0.866046384615385">
• There isn’t ready-made domain-specific
parallel bitext. So it’s necessary for data se-
lection to have significant capability in min-
ing parallel bitext in those assorted free texts.
But the existing methods seldom ensure
parallelism in the target domain while se-
lecting domain-relevant bitext.
• Available domain-relevant bitext needs keep
high domain-relevance at both the sides of
source and target language. But it’s difficult
for current method to maintain two-sided
domain-relevance when we aim at enhanc-
ing parallelism of bitext.
</listItem>
<bodyText confidence="0.998640230769231">
In a word, current data selection methods can’t
well maintain both parallelism and domain-
relevance of bitext. To overcome the problem,
we first propose the method combining transla-
tion model with language model in data selection.
The language model measures the domain-
specific generation probability of sentences, be-
ing used to select domain-relevant sentences at
both sides of source and target language. Mean-
while, the translation model measures the trans-
lation probability of sentence pair, being used to
verify the parallelism of the selected domain-
relevant bitext.
</bodyText>
<sectionHeader confidence="0.999767" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999207909090909">
The existing data selection methods are mostly
based on language model. Yasuda et al. (2008)
and Foster et al. (2010) ranked the sentence pairs
in the general-domain corpus according to the
perplexity scores of sentences, which are com-
puted with respect to in-domain language models.
Axelrod et al. (2011) improved the perplexity-
based approach and proposed bilingual cross-
entropy difference as a ranking function with in-
and general- domain language models. Duh et al.
(2013) employed the method of (Axelrod et al.,
</bodyText>
<page confidence="0.975933">
569
</page>
<bodyText confidence="0.925296222222222">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 569–573,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
2011) and further explored neural language mod-
el for data selection rather than the conventional
n-gram language model. Although previous
works in data selection (Duh et al., 2013; Koehn
and Haddow, 2012; Axelrod et al., 2011; Foster
et al., 2010; Yasuda et al., 2008) have gained
good performance, the methods which only
adopt language models to score the sentence
pairs are sub-optimal. The reason is that a sen-
tence pair contains a source language sentence
and a target language sentence, while the existing
methods are incapable of evaluating the mutual
translation probability of sentence pair in the tar-
get domain. Thus, we propose novel methods
which are based on translation model and lan-
guage model for data selection.
</bodyText>
<sectionHeader confidence="0.966819" genericHeader="method">
3 Training Data Selection Methods
</sectionHeader>
<bodyText confidence="0.999968428571429">
We present three data selection methods for
ranking and selecting domain-relevant sentence
pairs from general-domain corpus, with an eye
towards improving domain-specific translation
model performance. These methods are based on
language model and translation model, which are
trained on small in-domain parallel data.
</bodyText>
<subsectionHeader confidence="0.995779">
3.1 Data Selection with Translation Model
</subsectionHeader>
<bodyText confidence="0.9998598">
Translation model is a key component in statisti-
cal machine translation. It is commonly used to
translate the source language sentence into the
target language sentence. However, in this paper,
we adopt the translation model to evaluate the
translation probability of sentence pair and de-
velop a simple but effective variant of translation
model to rank the sentence pairs in the general-
domain corpus. The formulations are detailed as
below:
</bodyText>
<equation confidence="0.999748">
( ) ( ) ∏ ∑ ( ) (1)
√ ( ) (2)
</equation>
<bodyText confidence="0.9898516875">
Where ( ) is the translation model, which is
IBM Model 1 in this paper, it represents the
translation probability of target language sen-
tence conditioned on source language sentence
. and are the number of words in sentence
and respectively. ( ) is the translation
probability of word conditioned on word and
is estimated from the small in-domain parallel
data. The parameter is a constant and is as-
signed with the value of 1.0. is the length-
normalized IBM Model 1, which is used to score
general-domain sentence pairs. The sentence pair
with higher score is more likely to be generated
by in-domain translation model, thus, it is more
relevant to the in-domain corpus and will be re-
mained to expand the training data.
</bodyText>
<subsectionHeader confidence="0.8600325">
3.2 Data Selection by Combining Transla-
tion and Language model
</subsectionHeader>
<bodyText confidence="0.999974222222222">
As described in section 1, the existing data selec-
tion methods which only adopt language model
to score sentence pairs are unable to measure the
mutual translation probability of sentence pairs.
To solve the problem, we develop the second
data selection method, which is based on the
combination of translation model and language
model. Our method and ranking function are
formulated as follows:
</bodyText>
<equation confidence="0.999421666666667">
( ) ( ) ( ) (3)
√ ( )
√ ( ) (4)
</equation>
<bodyText confidence="0.987796222222222">
Where ( ) is a joint probability of sentence
and according to the translation model ( )
and language model ( ), whose parameters are
estimated from the small in-domain text. is the
improved ranking function and used to score the
sentence pairs with the length-normalized trans-
lation model ( )and language model ( ).
The sentence pair with higher score is more simi-
lar to in-domain corpus, and will be picked out.
</bodyText>
<subsectionHeader confidence="0.934728">
3.3 Data Selection by Bidirectionally
</subsectionHeader>
<bodyText confidence="0.9690834">
Combining Translation and Language
Models
As presented in subsection 3.2, the method com-
bines translation model and language model to
rank the sentence pairs in the general-domain
corpus. However, it does not evaluate the inverse
translation probability of sentence pair and the
probability of target language sentence. Thus, we
take bidirectional scores into account and simply
sum the scores in both directions.
</bodyText>
<equation confidence="0.98553275">
√ ( )
√ ( ) √ ( )
√ ( )
(5)
</equation>
<bodyText confidence="0.999778333333333">
Again, the sentence pairs with higher scores are
presumed to be better and will be selected to in-
corporate into the domain-specific training data.
This approach makes full use of two translation
models and two language models for sentence
pairs ranking.
</bodyText>
<page confidence="0.991136">
570
</page>
<sectionHeader confidence="0.998923" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.930866">
4.1 Corpora
</subsectionHeader>
<bodyText confidence="0.99839505">
We conduct our experiments on the Spoken Lan-
guage Translation English-to-Chinese task. Two
corpora are needed for the data selection. The in-
domain data is collected from CWMT09, which
consists of spoken dialogues in a travel setting,
containing approximately 50,000 parallel sen-
tence pairs in English and Chinese. Our general-
domain corpus mined from the Internet contains
16 million sentence pairs. Both the in- and gen-
eral- domain corpora are identically tokenized (in
English) and segmented (in Chinese)1. The de-
tails of corpora are listed in Table 1. Additionally,
we evaluate our work on the 2004 test set of
“863” Spoken Language Translation task (“863”
SLT), which consists of 400 English sentences
with 4 Chinese reference translations for each.
Meanwhile, the 2005 test set of “863” SLT task,
which contains 456 English sentences with 4 ref-
erences each, is used as the development set to
tune our systems.
</bodyText>
<table confidence="0.9998734">
Bilingual Cor- #sentence #token
pus
Eng Chn Eng Chn
In-domain 50K 50K 360K 310K
General-domain 16M 16M 3933M 3602M
</table>
<tableCaption confidence="0.999523">
Table 1. Data statics
</tableCaption>
<subsectionHeader confidence="0.975779">
4.2 System settings
</subsectionHeader>
<bodyText confidence="0.999985142857143">
We use the NiuTrans 2 toolkit which adopts
GIZA++ (Och and Ney, 2003) and MERT (Och,
2003) to train and tune the machine translation
system. As NiuTrans integrates the mainstream
translation engine, we select hierarchical phrase-
based engine (Chiang, 2007) to extract the trans-
lation rules and carry out our experiments.
Moreover, in the decoding process, we use the
NiuTrans decoder to produce the best outputs,
and score them with the widely used NIST mt-
eval131a3 tool. This tool scores the outputs in
several criterions, while the case-insensitive
BLEU-4 (Papineni et al., 2002) is used as the
evaluation for the machine translation system.
</bodyText>
<subsectionHeader confidence="0.979335">
4.3 Translation and Language models
</subsectionHeader>
<bodyText confidence="0.9995695">
Our work relies on the use of in-domain lan-
guage models and translation models to rank the
sentence pairs from the general-domain bilingual
training set. Here, we employ ngram language
</bodyText>
<footnote confidence="0.999902">
1http://www.nlplab.com/NiuPlan/NiuTrans.YourData.ch.html
2http://www.nlplab.com/NiuPlan/NiuTrans.ch.html#download
3 http://ww.itl.nist.gov/iad/mig/tools
</footnote>
<bodyText confidence="0.999787866666667">
model and IBM Model 1 for data selection. Thus,
we use the SRI Language Modeling Toolkit
(Stolcke, 2002) to train the in-domain 4-gram
language model with interpolated modified
Kneser-Ney discounting (Chen and Goodman,
1998). The language model is only used to score
the general-domain sentences. Meanwhile, we
use the language model training scripts integrat-
ed in the NiuTrans toolkit to train another 4-gram
language model, which is used in MT tuning and
decoding. Additionally, we adopt GIZA++ to get
the word alignment of in-domain parallel data
and form the word translation probability table.
This table will be used to compute the translation
probability of general-domain sentence pairs.
</bodyText>
<subsectionHeader confidence="0.993604">
4.4 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.995734785714286">
As described above, by using the NiuTrans
toolkit, we have built two baseline systems to
fulfill “863” SLT task in our experiments. The
In-domain baseline trained on spoken language
corpus has 1.05 million rules in its hierarchical-
phrase table. While, the General-domain baseline
trained on 16 million sentence pairs has a hierar-
chical phrase table containing 1.7 billion transla-
tion rules. These two baseline systems are
equipped with the same language model which is
trained on large-scale monolingual target lan-
guage corpus. The BLEU scores of the In-
domain and General-domain baseline system are
listed in Table 2.
</bodyText>
<table confidence="0.9946925">
Corpus Hierarchical Dev Test
phrase
In-domain 1.05M 15.01 21.99
General-domain 1747M 27.72 34.62
</table>
<tableCaption confidence="0.949441">
Table 2. Translation performances of In-domain and
General-domain baseline systems
</tableCaption>
<bodyText confidence="0.999923125">
The results show that General-domain system
trained on a larger amount of bilingual resources
outperforms the system trained on the in-domain
corpus by over 12 BLEU points. The reason is
that large scale parallel corpus maintains more
bilingual knowledge and language phenomenon,
while small in-domain corpus encounters data
sparse problem, which degrades the translation
performance. However, the performance of Gen-
eral-domain baseline can be improved further.
We use our three methods to refine the general-
domain corpus and improve the translation per-
formance in the domain of interest. Thus, we
build several contrasting systems trained on re-
fined training data selected by the following dif-
ferent methods.
</bodyText>
<page confidence="0.991393">
571
</page>
<listItem confidence="0.998675733333333">
• Igram: Data selection by 4-gram LMs with
Kneser-Ney smoothing. (Axelrod et al.,
2011)
• Ieural net: Data selection by Recurrent
Neural LM, with the RNNLM Tookit. (Duh
et al., 2013)
• Translation Model (TM): Data selection
with translation model: IBM Model 1.
• Translation model and Language Model
(TM+LM): Data selection by combining 4-
gram LMs with Kneser-Ney smoothing and
IBM model 1(equal weight).
• Bidirectional TM+LM: Data selection by
bidirectionally combining translation and
language models (equal weight).
</listItem>
<subsectionHeader confidence="0.975017">
4.5 Results of Training Data Selection
</subsectionHeader>
<bodyText confidence="0.999740307692308">
We adopt five methods for extracting domain-
relevant parallel data from general-domain cor-
pus. Using the scoring methods, we rank the sen-
tence pairs of the general-domain corpus and
select only the top N = {50k, 100k, 200k, 400k,
600k, 800k, 1000k} sentence pairs as refined
training data. New MT systems are then trained
on these small refined training data. Figure 1
shows the performances of systems trained on
selected corpora from the general-domain corpus.
The horizontal coordinate represents the number
of selected sentence pairs and vertical coordinate
is the BLEU scores of MT systems.
</bodyText>
<figure confidence="0.9720004">
Axelord et al.(2011) Duh et al.(2013)
TM TM+LM
Bidirectional TM+LM
40.00
38.00
36.00
34.00
32.00
30.00
28.00
26.00
24.00
22.00
20.00
0 200 400 600 800 1000
</figure>
<figureCaption confidence="0.9924935">
Figure 1. Results of the systems trained on only a sub-
set of the general-domain parallel corpus.
</figureCaption>
<bodyText confidence="0.999948829268293">
From Figure 1, we conclude that these five da-
ta selection methods are effective for domain-
specific translation. When top 600k sentence
pairs are picked out from general-domain corpus
to train machine translation systems, the systems
perform higher than the General-domain baseline
trained on 16 million parallel data. The results
indicate that more training data for translation
model is not always better. When the domain-
specific bilingual resources are deficient, the
domain-relevant sentence pairs will play an im-
portant role in improving the translation perfor-
mance.
Additionally, it turns out that our methods
(TM, TM+LM and Bidirectional TM+LM) are
indeed more effective in selecting domain-
relevant sentence pairs. In the end-to-end SMT
evaluation, TM selects top 600k sentence pairs
of general-domain corpus, but increases the
translation performance by 2.7 BLEU points.
Meanwhile, the TM+LM and Bidirectional
TM+LM have gained 3.66 and 3.56 BLEU point
improvements compared against the general-
domain baseline system. Compared with the
mainstream methods (Igram and Ieural net),
our methods increase translation performance by
nearly 3 BLEU points, when the top 600k sen-
tence pairs are picked out. Although, in the fig-
ure 1, our three methods are not performing bet-
ter than the existing methods in all cases, their
overall performances are relatively higher. We
therefore believe that combining in-domain
translation model and language model to score
the sentence pairs is well-suited for domain-
relevant sentence pair selection. Furthermore, we
observe that the overall performance of our
methods is gradually improved. This is because
our methods are combining more statistical char-
acteristics of in-domain data in ranking and se-
lecting sentence pairs. The results have proven
the effectiveness of our methods again.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999972090909091">
We present three novel methods for translation
model training data selection, which are based on
the translation model and language model. Com-
pared with the methods which only employ lan-
guage model for data selection, we observe that
our methods are able to select high-quality do-
main-relevant sentence pairs and improve the
translation performance by nearly 3 BLEU points.
In addition, our methods make full use of the
limited in-domain data and are easily implement-
ed. In the future, we are interested in applying
</bodyText>
<page confidence="0.990047">
572
</page>
<bodyText confidence="0.905697">
our methods into domain adaptation task of sta-
tistical machine translation in model level.
</bodyText>
<sectionHeader confidence="0.995476" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998145">
This research work has been sponsored by two
NSFC grants, No.61373097 and No.61272259,
and one National Science Foundation of Suzhou
(Grants No. SH201212).
</bodyText>
<sectionHeader confidence="0.989743" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999840697368421">
Amittai Axelrod, Xiaodong He, and Jianfeng Gao.
2011. Domain adaptation via pseudo in-domain da-
ta selection. In Proceedings of the 2011 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 355–362, Edinburgh, Scotland,
UK, July. Association for Computational Linguis-
tics.
Peter F.Brown, Vincent J. Della Pietra, Stephen A.
Della Pietra and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Computational linguistics,
1993, 19(2): 263-311.
Stanley Chen and Joshua Goodman. 1998. An Empir-
ical Study of Smoothing Techniques for Language
Modeling. Technical Report 10-98, Computer Sci-
ence Group, Harvard University.
Moore Robert C, Lewis William. 2010. Intelligent
selection of language model training data. In Pro-
ceedings of the ACL 2010 Conference Short Pa-
pers. Association for Computational Linguistics,
2010: 220-224.
Chiang David. A hierarchical phrase-based model for
statistical machine translation. 2005. In Proceed-
ings of the 43rd Annual Meeting on Association for
Computational Linguistics, pages: 263-270. Asso-
ciation for Computational Linguistics.
Kevin Duh, Graham Neubig, Katsuhito Sudoh and
Hajime Tsukada. Adaptation Data Selection using
Neural Language Models: Experiments in Machine
Translation. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 678-683, Sofia, Bulgaria, August 4-
9 2013.
Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada.
2010.Analysis of translation model adaptation for
statistical machine translation. In Proceedings of
the International Workshop on Spoken Language
Translation (IWSLT) - Technical Papers Track.
George Foster, Cyril Goutte, and Roland Kuhn. 2010.
Discriminative Instance Weighting for Domain
Adaptation in Statistical Machine Translation. Em-
pirical Methods in Natural Language Processing.
Barry Haddow and Philipp Koehn. 2012. Analysing
the effect of out-of-domain data on smt systems. In
Proceedings of the Seventh Workshop on Statistical
Machine Translation, pages 422–432, Montreal,
Canada, June. Association for Computational Lin-
guistics.
Och, Franz Josef, and Hermann Ney. A systematic
comparison of various statistical alignment models.
Computational linguistics 29.1 (2003): 19-51.
Och, Franz Josef. Minimum error rate training in sta-
tistical machine translation. Proceedings of the 41st
Annual Meeting on Association for Computational
Linguistics-Volume 1. Association for Computa-
tional Linguistics, 2003.
Philipp Koehn and Barry Haddow. 2012. Towards
effective use of training data in statistical machine
translation. In WMT.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: A method for auto-
matic evaluation of machine translation. In ACL.
Andreas Stolcke. 2002. SRILM - An extensible lan-
guage modeling toolkit. Spoken Language Pro-
cessing.
Tong Xiao, Jingbo Zhu, Hao Zhang and Qiang Li.
NiuTrans: an open source toolkit for phrase-based
and syntax-based machine translation. In Proceed-
ings of the ACL 2012 System Demonstrations. As-
sociation for Computational Linguistics, 2012: 19-
24.
Keiji Yasuda, Ruiqiang Zhang, Hirofumi Yamamoto,
and Eiichiro Sumita. 2008. Method of selecting
training data to build a compact and efficient trans-
lation model. International Joint Conference on
Natural Language Processing.
</reference>
<page confidence="0.998924">
573
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.684798">
<title confidence="0.998599">Effective Selection of Translation Model Training Data</title>
<author confidence="0.994025">Le_Liu Yu Hong Hao Liu Xing Wang Jianmin Yao</author>
<affiliation confidence="0.999994">School of Computer Science &amp; Technology, Soochow University,</affiliation>
<email confidence="0.749924">20124227052@suda.edu.cn</email>
<email confidence="0.749924">hongy@suda.edu.cn</email>
<email confidence="0.749924">20134227035@suda.edu.cn</email>
<email confidence="0.749924">20114227047@suda.edu.cn</email>
<email confidence="0.749924">jyao@suda.edu.cn</email>
<abstract confidence="0.996471347826087">Data selection has been demonstrated to be an effective approach to addressing the lack of high-quality bitext for statistical machine translation in the domain of interest. Most current data selection methods solely use language models trained on a small scale in-domain data to select domain-relevant sentence pairs from general-domain parallel corpus. By contrast, we argue that the relevance between a sentence pair and target domain can be better evaluated by the combination of language model and translation model. In this paper, we study and experiment with novel methods that apply translation models into domain-relevant data selection. The results show that our methods outperform previous methods. When the selected sentence pairs are evaluated on an end-to-end MT task, our methods can increase the translation performance by 3 BLEU points.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amittai Axelrod</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
</authors>
<title>Domain adaptation via pseudo in-domain data selection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>355--362</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK,</location>
<contexts>
<context position="3518" citStr="Axelrod et al. (2011)" startWordPosition="528" endWordPosition="531">pecific generation probability of sentences, being used to select domain-relevant sentences at both sides of source and target language. Meanwhile, the translation model measures the translation probability of sentence pair, being used to verify the parallelism of the selected domainrelevant bitext. 2 Related Work The existing data selection methods are mostly based on language model. Yasuda et al. (2008) and Foster et al. (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models. Axelrod et al. (2011) improved the perplexitybased approach and proposed bilingual crossentropy difference as a ranking function with inand general- domain language models. Duh et al. (2013) employed the method of (Axelrod et al., 569 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 569–573, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2011) and further explored neural language model for data selection rather than the conventional n-gram language model. Although previous works in data selection (Duh et al., </context>
<context position="12329" citStr="Axelrod et al., 2011" startWordPosition="1924" endWordPosition="1927">son is that large scale parallel corpus maintains more bilingual knowledge and language phenomenon, while small in-domain corpus encounters data sparse problem, which degrades the translation performance. However, the performance of General-domain baseline can be improved further. We use our three methods to refine the generaldomain corpus and improve the translation performance in the domain of interest. Thus, we build several contrasting systems trained on refined training data selected by the following different methods. 571 • Igram: Data selection by 4-gram LMs with Kneser-Ney smoothing. (Axelrod et al., 2011) • Ieural net: Data selection by Recurrent Neural LM, with the RNNLM Tookit. (Duh et al., 2013) • Translation Model (TM): Data selection with translation model: IBM Model 1. • Translation model and Language Model (TM+LM): Data selection by combining 4- gram LMs with Kneser-Ney smoothing and IBM model 1(equal weight). • Bidirectional TM+LM: Data selection by bidirectionally combining translation and language models (equal weight). 4.5 Results of Training Data Selection We adopt five methods for extracting domainrelevant parallel data from general-domain corpus. Using the scoring methods, we ran</context>
</contexts>
<marker>Axelrod, He, Gao, 2011</marker>
<rawString>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011. Domain adaptation via pseudo in-domain data selection. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 355–362, Edinburgh, Scotland, UK, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation. Computational linguistics,</title>
<date>1993</date>
<volume>19</volume>
<issue>2</issue>
<pages>263--311</pages>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F.Brown, Vincent J. Della Pietra, Stephen A. Della Pietra and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational linguistics, 1993, 19(2): 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling.</title>
<date>1998</date>
<tech>Technical Report 10-98,</tech>
<institution>Computer Science Group, Harvard University.</institution>
<contexts>
<context position="10237" citStr="Chen and Goodman, 1998" startWordPosition="1605" endWordPosition="1608">hine translation system. 4.3 Translation and Language models Our work relies on the use of in-domain language models and translation models to rank the sentence pairs from the general-domain bilingual training set. Here, we employ ngram language 1http://www.nlplab.com/NiuPlan/NiuTrans.YourData.ch.html 2http://www.nlplab.com/NiuPlan/NiuTrans.ch.html#download 3 http://ww.itl.nist.gov/iad/mig/tools model and IBM Model 1 for data selection. Thus, we use the SRI Language Modeling Toolkit (Stolcke, 2002) to train the in-domain 4-gram language model with interpolated modified Kneser-Ney discounting (Chen and Goodman, 1998). The language model is only used to score the general-domain sentences. Meanwhile, we use the language model training scripts integrated in the NiuTrans toolkit to train another 4-gram language model, which is used in MT tuning and decoding. Additionally, we adopt GIZA++ to get the word alignment of in-domain parallel data and form the word translation probability table. This table will be used to compute the translation probability of general-domain sentence pairs. 4.4 Baseline Systems As described above, by using the NiuTrans toolkit, we have built two baseline systems to fulfill “863” SLT </context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley Chen and Joshua Goodman. 1998. An Empirical Study of Smoothing Techniques for Language Modeling. Technical Report 10-98, Computer Science Group, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moore Robert C</author>
<author>Lewis William</author>
</authors>
<title>Intelligent selection of language model training data.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers. Association for Computational Linguistics,</booktitle>
<pages>220--224</pages>
<marker>C, William, 2010</marker>
<rawString>Moore Robert C, Lewis William. 2010. Intelligent selection of language model training data. In Proceedings of the ACL 2010 Conference Short Papers. Association for Computational Linguistics, 2010: 220-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiang David</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>David, 2005</marker>
<rawString>Chiang David. A hierarchical phrase-based model for statistical machine translation. 2005. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages: 263-270. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Graham Neubig</author>
</authors>
<title>Katsuhito Sudoh and Hajime Tsukada. Adaptation Data Selection using Neural Language Models: Experiments in Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>678--683</pages>
<location>Sofia, Bulgaria,</location>
<marker>Duh, Neubig, 2013</marker>
<rawString>Kevin Duh, Graham Neubig, Katsuhito Sudoh and Hajime Tsukada. Adaptation Data Selection using Neural Language Models: Experiments in Machine Translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 678-683, Sofia, Bulgaria, August 4-9 2013.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Duh</author>
</authors>
<title>Katsuhito Sudoh, and Hajime Tsukada. 2010.Analysis of translation model adaptation for statistical machine translation.</title>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT)</booktitle>
<tech>Technical Papers Track.</tech>
<marker>Duh, </marker>
<rawString>Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010.Analysis of translation model adaptation for statistical machine translation. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT) - Technical Papers Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Cyril Goutte</author>
<author>Roland Kuhn</author>
</authors>
<title>Discriminative Instance Weighting for Domain Adaptation</title>
<date>2010</date>
<booktitle>in Statistical Machine Translation. Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="3330" citStr="Foster et al. (2010)" startWordPosition="499" endWordPosition="502"> domainrelevance of bitext. To overcome the problem, we first propose the method combining translation model with language model in data selection. The language model measures the domainspecific generation probability of sentences, being used to select domain-relevant sentences at both sides of source and target language. Meanwhile, the translation model measures the translation probability of sentence pair, being used to verify the parallelism of the selected domainrelevant bitext. 2 Related Work The existing data selection methods are mostly based on language model. Yasuda et al. (2008) and Foster et al. (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models. Axelrod et al. (2011) improved the perplexitybased approach and proposed bilingual crossentropy difference as a ranking function with inand general- domain language models. Duh et al. (2013) employed the method of (Axelrod et al., 569 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 569–573, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational</context>
</contexts>
<marker>Foster, Goutte, Kuhn, 2010</marker>
<rawString>George Foster, Cyril Goutte, and Roland Kuhn. 2010. Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation. Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
</authors>
<title>Analysing the effect of out-of-domain data on smt systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>422--432</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montreal, Canada,</location>
<contexts>
<context position="1989" citStr="Haddow and Koehn, 2012" startWordPosition="292" endWordPosition="295">el training in the domain of interest. For this, an effective approach is to automatically select and expand domain-specific sentence pairs from large scale general-domain parallel corpus. The approach is named Data Selection. Current data selection methods mostly use language models trained on small scale indomain data to measure domain relevance and select domain-relevant parallel sentence pairs to expand training corpora. Related work in literature has proven that the expanded corpora can substantially improve the performance of ma* Corresponding author chine translation (Duh et al., 2010; Haddow and Koehn, 2012). However, the methods are still far from satisfactory for real application for the following reasons: • There isn’t ready-made domain-specific parallel bitext. So it’s necessary for data selection to have significant capability in mining parallel bitext in those assorted free texts. But the existing methods seldom ensure parallelism in the target domain while selecting domain-relevant bitext. • Available domain-relevant bitext needs keep high domain-relevance at both the sides of source and target language. But it’s difficult for current method to maintain two-sided domain-relevance when we a</context>
</contexts>
<marker>Haddow, Koehn, 2012</marker>
<rawString>Barry Haddow and Philipp Koehn. 2012. Analysing the effect of out-of-domain data on smt systems. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 422–432, Montreal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational linguistics</journal>
<volume>29</volume>
<contexts>
<context position="9065" citStr="Och and Ney, 2003" startWordPosition="1442" endWordPosition="1445"> corpora are listed in Table 1. Additionally, we evaluate our work on the 2004 test set of “863” Spoken Language Translation task (“863” SLT), which consists of 400 English sentences with 4 Chinese reference translations for each. Meanwhile, the 2005 test set of “863” SLT task, which contains 456 English sentences with 4 references each, is used as the development set to tune our systems. Bilingual Cor- #sentence #token pus Eng Chn Eng Chn In-domain 50K 50K 360K 310K General-domain 16M 16M 3933M 3602M Table 1. Data statics 4.2 System settings We use the NiuTrans 2 toolkit which adopts GIZA++ (Och and Ney, 2003) and MERT (Och, 2003) to train and tune the machine translation system. As NiuTrans integrates the mainstream translation engine, we select hierarchical phrasebased engine (Chiang, 2007) to extract the translation rules and carry out our experiments. Moreover, in the decoding process, we use the NiuTrans decoder to produce the best outputs, and score them with the widely used NIST mteval131a3 tool. This tool scores the outputs in several criterions, while the case-insensitive BLEU-4 (Papineni et al., 2002) is used as the evaluation for the machine translation system. 4.3 Translation and Langua</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef, and Hermann Ney. A systematic comparison of various statistical alignment models. Computational linguistics 29.1 (2003): 19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1. Association for Computational Linguistics,</booktitle>
<contexts>
<context position="9086" citStr="Och, 2003" startWordPosition="1448" endWordPosition="1449">1. Additionally, we evaluate our work on the 2004 test set of “863” Spoken Language Translation task (“863” SLT), which consists of 400 English sentences with 4 Chinese reference translations for each. Meanwhile, the 2005 test set of “863” SLT task, which contains 456 English sentences with 4 references each, is used as the development set to tune our systems. Bilingual Cor- #sentence #token pus Eng Chn Eng Chn In-domain 50K 50K 360K 310K General-domain 16M 16M 3933M 3602M Table 1. Data statics 4.2 System settings We use the NiuTrans 2 toolkit which adopts GIZA++ (Och and Ney, 2003) and MERT (Och, 2003) to train and tune the machine translation system. As NiuTrans integrates the mainstream translation engine, we select hierarchical phrasebased engine (Chiang, 2007) to extract the translation rules and carry out our experiments. Moreover, in the decoding process, we use the NiuTrans decoder to produce the best outputs, and score them with the widely used NIST mteval131a3 tool. This tool scores the outputs in several criterions, while the case-insensitive BLEU-4 (Papineni et al., 2002) is used as the evaluation for the machine translation system. 4.3 Translation and Language models Our work re</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, Franz Josef. Minimum error rate training in statistical machine translation. Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1. Association for Computational Linguistics, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Barry Haddow</author>
</authors>
<title>Towards effective use of training data in statistical machine translation.</title>
<date>2012</date>
<booktitle>In WMT.</booktitle>
<contexts>
<context position="4146" citStr="Koehn and Haddow, 2012" startWordPosition="621" endWordPosition="624">ved the perplexitybased approach and proposed bilingual crossentropy difference as a ranking function with inand general- domain language models. Duh et al. (2013) employed the method of (Axelrod et al., 569 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 569–573, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2011) and further explored neural language model for data selection rather than the conventional n-gram language model. Although previous works in data selection (Duh et al., 2013; Koehn and Haddow, 2012; Axelrod et al., 2011; Foster et al., 2010; Yasuda et al., 2008) have gained good performance, the methods which only adopt language models to score the sentence pairs are sub-optimal. The reason is that a sentence pair contains a source language sentence and a target language sentence, while the existing methods are incapable of evaluating the mutual translation probability of sentence pair in the target domain. Thus, we propose novel methods which are based on translation model and language model for data selection. 3 Training Data Selection Methods We present three data selection methods f</context>
</contexts>
<marker>Koehn, Haddow, 2012</marker>
<rawString>Philipp Koehn and Barry Haddow. 2012. Towards effective use of training data in statistical machine translation. In WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9576" citStr="Papineni et al., 2002" startWordPosition="1522" endWordPosition="1525">Table 1. Data statics 4.2 System settings We use the NiuTrans 2 toolkit which adopts GIZA++ (Och and Ney, 2003) and MERT (Och, 2003) to train and tune the machine translation system. As NiuTrans integrates the mainstream translation engine, we select hierarchical phrasebased engine (Chiang, 2007) to extract the translation rules and carry out our experiments. Moreover, in the decoding process, we use the NiuTrans decoder to produce the best outputs, and score them with the widely used NIST mteval131a3 tool. This tool scores the outputs in several criterions, while the case-insensitive BLEU-4 (Papineni et al., 2002) is used as the evaluation for the machine translation system. 4.3 Translation and Language models Our work relies on the use of in-domain language models and translation models to rank the sentence pairs from the general-domain bilingual training set. Here, we employ ngram language 1http://www.nlplab.com/NiuPlan/NiuTrans.YourData.ch.html 2http://www.nlplab.com/NiuPlan/NiuTrans.ch.html#download 3 http://ww.itl.nist.gov/iad/mig/tools model and IBM Model 1 for data selection. Thus, we use the SRI Language Modeling Toolkit (Stolcke, 2002) to train the in-domain 4-gram language model with interpol</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - An extensible language modeling toolkit. Spoken Language Processing.</title>
<date>2002</date>
<contexts>
<context position="10117" citStr="Stolcke, 2002" startWordPosition="1591" endWordPosition="1592">ral criterions, while the case-insensitive BLEU-4 (Papineni et al., 2002) is used as the evaluation for the machine translation system. 4.3 Translation and Language models Our work relies on the use of in-domain language models and translation models to rank the sentence pairs from the general-domain bilingual training set. Here, we employ ngram language 1http://www.nlplab.com/NiuPlan/NiuTrans.YourData.ch.html 2http://www.nlplab.com/NiuPlan/NiuTrans.ch.html#download 3 http://ww.itl.nist.gov/iad/mig/tools model and IBM Model 1 for data selection. Thus, we use the SRI Language Modeling Toolkit (Stolcke, 2002) to train the in-domain 4-gram language model with interpolated modified Kneser-Ney discounting (Chen and Goodman, 1998). The language model is only used to score the general-domain sentences. Meanwhile, we use the language model training scripts integrated in the NiuTrans toolkit to train another 4-gram language model, which is used in MT tuning and decoding. Additionally, we adopt GIZA++ to get the word alignment of in-domain parallel data and form the word translation probability table. This table will be used to compute the translation probability of general-domain sentence pairs. 4.4 Base</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - An extensible language modeling toolkit. Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Xiao</author>
<author>Jingbo Zhu</author>
</authors>
<title>Hao Zhang and Qiang Li. NiuTrans: an open source toolkit for phrase-based and syntax-based machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations. Association for Computational Linguistics,</booktitle>
<marker>Xiao, Zhu, 2012</marker>
<rawString>Tong Xiao, Jingbo Zhu, Hao Zhang and Qiang Li. NiuTrans: an open source toolkit for phrase-based and syntax-based machine translation. In Proceedings of the ACL 2012 System Demonstrations. Association for Computational Linguistics, 2012: 19-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keiji Yasuda</author>
<author>Ruiqiang Zhang</author>
<author>Hirofumi Yamamoto</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Method of selecting training data to build a compact and efficient translation model.</title>
<date>2008</date>
<booktitle>International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="3305" citStr="Yasuda et al. (2008)" startWordPosition="494" endWordPosition="497">tain both parallelism and domainrelevance of bitext. To overcome the problem, we first propose the method combining translation model with language model in data selection. The language model measures the domainspecific generation probability of sentences, being used to select domain-relevant sentences at both sides of source and target language. Meanwhile, the translation model measures the translation probability of sentence pair, being used to verify the parallelism of the selected domainrelevant bitext. 2 Related Work The existing data selection methods are mostly based on language model. Yasuda et al. (2008) and Foster et al. (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models. Axelrod et al. (2011) improved the perplexitybased approach and proposed bilingual crossentropy difference as a ranking function with inand general- domain language models. Duh et al. (2013) employed the method of (Axelrod et al., 569 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 569–573, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Asso</context>
</contexts>
<marker>Yasuda, Zhang, Yamamoto, Sumita, 2008</marker>
<rawString>Keiji Yasuda, Ruiqiang Zhang, Hirofumi Yamamoto, and Eiichiro Sumita. 2008. Method of selecting training data to build a compact and efficient translation model. International Joint Conference on Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>