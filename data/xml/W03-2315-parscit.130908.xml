<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991276">
Deriving the Communicative Structure in Applied NLG
</title>
<author confidence="0.998587">
Leo Wanner
</author>
<affiliation confidence="0.996495">
Intelligent Systems Institute
University of Stuttgart
</affiliation>
<email confidence="0.949454">
wanner@informatik.uni-stuttgart.de
</email>
<author confidence="0.984002">
Bernd Bohnet
</author>
<affiliation confidence="0.994521">
Intelligent Systems Institute
University of Stuttgart
</affiliation>
<email confidence="0.955805">
bohnet@informatik.uni-stuttgart.de
</email>
<author confidence="0.99106">
Mark Giereth
</author>
<affiliation confidence="0.995288">
Intelligent Systems Institute
University of Stuttgart
</affiliation>
<bodyText confidence="0.436005">
giereth @ i nformati k.un i - stuttgart. de
</bodyText>
<sectionHeader confidence="0.982418" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999808692307692">
Information structure is decisive for
constraining linguistic options during
sentence planning. Nonetheless, it is
only recently that it became a topic on
the agenda of the mainstream text gener-
ation research. We investigate how cer-
tain parameters of the information (or
communicative) structure developed in
Meaning-Text Linguistics can be derived
in applied text generation from the do-
main and discourse data, and how these
parameters guide the process of sen-
tence generation.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942666666667">
One of the notorious problems NLG faces since
its early days is the purposeful choice of one of
the linguistic options available to express a given
meaning. It is well known that a rich informa-
tion structure constraints sentence structures, and
thus, to a major extent, also the process of sen-
tence generation (Prince, 1978; Vallduvf, 1995;
Choi, 1996; Mel&apos; ouk, 2001). Existing propos-
als for the derivation of the information structure
in the context of NLG draw mainly on contex-
tual (extra-linguistic) information (Klabunde and
Jansche, 1998; Geldorf, 2000) or on the commu-
nicative intent of the speaker (Stone et al., 2001;
Creswell, 2002). Occasionally, recourse is made
to semantic coherence relations (Creswell, 2002).
We believe that a detailed information structure
can be sufficiently determined only when the fol-
lowing sources are taken into account: (i) domain-
specific communicative constraints (domain COM-
munication knowledge in (Rambow, 1990)), (ii) a
detailed discourse structure as provided, e.g., by
RST-based text planners, and (iii) the communica-
tive intent of the speaker.
In what follows, we describe the derivation of
the information structure in applied text genera-
tion from the above sources. As information struc-
ture, we use the Communicative Structure (hence-
forth CS) defined in the Meaning-Text Theory
(MTT), which has the advantage of being detailed
and rigorously defined; see (Mel&apos; euk, 2001). The
derivation of the CS and its processing is currently
being implemented in a text generator that is also
based on MTT (Mel&apos;euk, 1988). The application
domain under study is the ozone concentration do-
main in the province of Baden-Wurttemberg, Ger-
many. Note, however, that the proposed approach
is fully applicable to all data-oriented domains
(such as stock market, flood surveyance, weather
forecast, etc.).
</bodyText>
<sectionHeader confidence="0.917789" genericHeader="method">
2 Communicative Structure in MTT
</sectionHeader>
<bodyText confidence="0.999823833333333">
Hardly any other notion in linguistics received
such a heterogeneous presentation across the dif-
ferent theories as the information (= communica-
tive) structure. But it cannot be our goal to present
here a constrastive overview of the different inter-
pretations. Rather, we concentrate on a brief pre-
sentation of mTT&apos;s CS as described in (Mel&apos; &apos;auk,
2001).
MTT&apos;s CS is defined on a semantic structure
S„,, and consists of eight different dimensions or
tuples of contrastive information parameters. Six
of them call for consideration in NLG: I
</bodyText>
<listItem confidence="0.998576">
1. Thematicity (Rheme vs. Theme),
2. Giveness (Given vs. New),
3. Focalization (Focalized vs. Non-Focalized),
4. Perspective (Foregrounded vs. Backgrounded),
5. Presupposedness (Presupposed vs. Asserted),
6. Unitariness (Unitary vs. Articulated).
</listItem>
<footnote confidence="0.948326333333333">
1The seventh, Emphasis is immediately relevant to
speech generation, and the eighth, Locutionality to combined
gesture-language generation.
</footnote>
<page confidence="0.998059">
111
</page>
<bodyText confidence="0.995670227272727">
In what follows, we restrict their introduction
to short definitions and a minimal number of ex-
amples; the interested reader is asked to consult
(Mel&apos; &apos;auk, 2001). Note also that the definitions re-
flect the generative point of view, not the analytical
one. Therefore, they do not define the parameters
in terms of surface clues to be used to identify the
former in a sentence, but, rather, in terms of the
intentions of the Speaker.
Rheme vs. Theme. Rheme is that part of S„,,,
that the Speaker intends to present as being com-
municated. Theme is that part of S5n, that the
Speaker intends to present as something about
which Rheme is stated. (Theme is also some-
times referred to as topic, starting point, or old;
Rheme—as comment, focus, and new.)
Depending on its POS and the interrelation with
other parameters, a thematized element may be re-
alized as the Subject of a clause, be fronted or be
proleptized. The Rheme/Theme-dimension con-
straints thus lexicalization, syntactic choice and
word order. Cf. an example:
</bodyText>
<listItem confidence="0.98262275">
and (4) focality. Each of the degrees licenses pri-
marily the choice of specific anaphoric references:
(1) of the definite article, (2) of the deictic THAT,
(3) of the deictic THIS, and (4) of a personal pro-
noun (HE, SHE, ... ). That is, the Given/New
dimension constraints primarily morphosyntactic
options, but also lexical and syntactic ones. Cf.
(from Halliday, 1994):
</listItem>
<bodyText confidence="0.92919075">
a little guinea pig, New
being little, Given, was not big. New
Focalized vs. Non-Focalized. Focalized is that
part of Ssen, that the Speaker intends to present as
being focus of attention, i.e., logically prominent
for him
Focalization presents a configuration of entities
as excluding other logical options: &amp;quot;exactly X, and
not something else&amp;quot;. The linguistic means to ex-
press focalization (orfocus) include first of all dis-
location or detachment and various types of cleft-
ing; cf.:
</bodyText>
<listItem confidence="0.546100666666667">
1. To my daughter Fo, the uncle sent a doll, to his son
1. There was
2. which, Given
</listItem>
<bodyText confidence="0.7762118">
The typical function of an interrogative clause Th
is to ask a question Rh
he sent a toy car.
2. It was the uncle
Foe who sent my daughter that doll
</bodyText>
<listItem confidence="0.297068">
2. In a wh-interrogative, the Theme Th
consists of the wh-element. Rh
</listItem>
<bodyText confidence="0.98094253125">
Given vs. New. Given is the part of Ssen, that
the Speaker intends to present as being in the Ad-
dressee&apos;s current consciousness or easily accessi-
ble by the Addressee. New is that part of Ssen, that
the Speaker intends to present as being new to the
Addressee.
Since most often the Speaker assumes that
the information being stated is new to the Ad-
dressee, while the information about which it is
stated is present in the Addressee&apos;s consciousness,
Rheme/Theme and Given/New are often conflated
(this is why Theme/Rheme is sometimes called
old/new; see above). However, it does not need
to be the case that they coincide; consider, e.g.:
A farmer from Sommerset Th/New
has found a Roman chamberpot Rh/New•
Given elements are usually expressed by
anaphora. As suggested by Gundel (1988), MTT
distinguishes four degrees of giveness: (1) unique
identifiability, (2) familiarity, (3) activatedness,
Foregrounded vs. Backgrounded. Fore-
grounded is that part of Sse, that the Speaker
intends to present as being psychologically
prominent for him Backgrounded is that part
of Ssen, that the Speaker intends to present as
being psychologicall secondary for him Some
parts of Ssen, may be neither foregrounded nor
backgrounded.
The main linguistic means for the realization
of foregrounded elements is raising; for the real-
ization of backgrounded elements—parenthetical
constructions and downing; cf. (from the web):
</bodyText>
<listItem confidence="0.53413725">
1. I changed my girl&apos;s oil yesterday and washed the car
for her Forgr (in contrast to ... and washed her car,
which is neutral) (who was a skillful climber) Bachgr
2. The prisoner
</listItem>
<bodyText confidence="0.948137571428571">
climbed over the fence and escaped.
Presupposed vs. Asserted. Mel&apos; hik (2001) dis-
tinguishes between two types of presupposition:
&amp;quot;pragmatic&amp;quot; presupposition and &amp;quot;linguistic&amp;quot; pre-
supposition, focusing on the latter one.
Linguistically presupposed is that part of S„.„,
that the Speaker intends to present as taken for
</bodyText>
<page confidence="0.99734">
112
</page>
<bodyText confidence="0.961831714285714">
granted. (If the whole structure is negated or
questioned, the presupposed fragment remained
affirmed.) The part that is not presupposed is As-
serted.
Linguistically presupposed elements can be re-
alized only as attributive (modifying or appositive)
constructions; cf.:
</bodyText>
<listItem confidence="0.9004824">
1. The car, which was an old Renault Pres, broke down
2. Germ. Bei Ute pres liegt ein Toter unterm Sofa Pres
lit. &apos;At Ute&apos;s, lies a dead man under the couch&apos;. vs.
Unter Utes Sofa liegt em Toter &apos;Under Ute&apos;s couch lies
a dead man&apos;.2
</listItem>
<bodyText confidence="0.99709652631579">
In German, Presupposedness also constraints
word order (see below).
&amp;quot;Pragmatic&amp;quot; presupposition as used in genera-
tion, e.g., in (Stone et al., 2001), encloses all ele-
ments that are expected to be familiar to the reader
(either from his world knowledge, from the con-
text, or from the text). For generation, both types
of presupposition are needed.
Unitary vs. Articulated. Unitary is the part of
Ssen., that the Speaker intends to present as being
looked at as one (opaque) single entity. Articu-
lated is the part of Ssen, which the Speaker intends
to present as being a configuration of semantic en-
tities.
Fragments of Ssem that are marked as Unitary
are preferably expressed by single lexemes; those
that are marked as Articulated, are preferrably ex-
pressed such that each element in the semantic
structure receives an own lexical item; cf.:
</bodyText>
<listItem confidence="0.941981333333333">
1. The compiler unitary is very efficient.
2. The program for compiling user written code Artie.
is very efficient.
</listItem>
<bodyText confidence="0.99991725">
The unitary/articulated dimension is especially
important in German where regular compound
production allows for a unitary realization of a
broad range of configurations of semantic units.
</bodyText>
<sectionHeader confidence="0.910748" genericHeader="method">
3 The Starting Point
</sectionHeader>
<bodyText confidence="0.874403166666667">
In this section, we introduce the resources that
serve us as a basis for the derivation of the above
communicative dimensions, i.e., that we presup-
pose as being available.3
`Only the first variant implies (presupposes) that Ute&apos;s
couch is indeed at Ute&apos;s.
</bodyText>
<footnote confidence="0.6696955">
3This is not to say, of course, that we do not deal with
them at all. Rather, their processing is not our topic here.
</footnote>
<subsectionHeader confidence="0.99746">
3.1 Data and Discourse Structure
</subsectionHeader>
<bodyText confidence="0.9992645">
We presuppose that an applied text generator starts
from data stored, e.g., in a data base. In our appli-
cation, these data are measuring data that are ex-
ported from a DB into an XML-document.
An &amp;quot;expert system&amp;quot; module evaluates these
data, compiles a set of communicative goals that
are to be achieved, and chooses the data that are
relevant to these goals.
From the communicative goals, a text plan with
RST-like discourse relations (Mann and Thomp-
son, 1987) is derived. Besides RST-relations,
we use Halliday&apos;s (1994) expansion relations EN-
HANCEMENT and EXTENSION and their more
fine-grained variants. Our use of discourse rela-
tions differs from the use in traditional RST in two
respects:
</bodyText>
<listItem confidence="0.81900775">
(i) specifying a discourse relation between the dis-
course units D Ui and DU2, we also specify which
elements in DUi and DU2 are involved in the re-
lation; thus, the CONTRAST-relation between (a)
and (b) in
(a) It was John who sent my daughter the doll. (b) Mary never
sends her anything
the &amp;quot;hubs&amp;quot; of the nuclei are John and Mary, re-
spectively (not, e.g., doll and nothing)
(ii) several relations may hold between DUI. and
DU-2 (see also (Moore and Pollack, 1992) on the
need for multi-level analysis of RST-relations).
</listItem>
<bodyText confidence="0.997893">
As mentioned above, we presuppose that a text
plan has already been compiled when we start the
compilation of the CS.
</bodyText>
<subsectionHeader confidence="0.999608">
3.2 Domain Communication Data
</subsectionHeader>
<bodyText confidence="0.991408133333333">
Originally defined for the semantic level, mTT&apos;s
communicative dimensions can also be used at the
conceptual, i.e. &amp;quot;prelinguistic&amp;quot;, level. For some of
them, initial settings are already available before
generation starts. They are predetermined by the
domain, by the design of the interface via which
the reader communicates with the generator, and
by the actions the user takes during the session.
Data on Thematicity In applied generation, the
global theme of the discourse (i.e., the discourse
topic) is either known—if the generator is special-
ized on one text type—, or the reader determines it
by choosing a specific topic via the generator inter-
face. The theme and rheme of the first message in
soon after we left the town.
</bodyText>
<page confidence="0.964836">
113
</page>
<bodyText confidence="0.9997415">
the text are either directly related to the discourse
theme or can be derived from actions of the reader.
In our application, the discourse theme is deter-
mined by the goal-directed action of going to the
web page of the generator: Ozone in the province
of Baden-Wurttemberg, Germany. The initial dis-
course theme is thus &apos;ozone&apos;. The page contains
a map of Baden-Wiirttemberg with stations that
measure ozone being marked by a dot. By clicking
onto a station on the map, the user determines the
name of the station as the secondary theme. The
information on the current concentration at the sta-
tion in question constitutes the corresponding sec-
ondary rheme.
Note that on his first visit to the page, the reader
has no explicit information that the texts will be
about ozone CONCENTRATION. Therefore, dis-
course theme is &apos;ozone&apos; only. After the first text
has been generated, the discourse theme is ex-
tended to &apos;ozone concentration&apos; for all subsequent
messages.
Data on Giveness Some of the information units
can be considered as given to (or known by)
the reader before any text is generated or even
planned; some others as unknown or new. Cf.
Table 1 for the distribution of the given/new-
parameter in our domain for the most important
data:
</bodyText>
<tableCaption confidence="0.998154">
Table 1: Giveness of entities
</tableCaption>
<table confidence="0.9860662">
Entity given new
substance (ozone) x
values (concentrations) x
measuring unit (pg/m3) x
times (measured at) x
locations (measuring stations) x
names of applicable thresholds x
values of applicable thresholds x
Data on Focalization An entity e is a candidate
for focalization, e.g., if:
</table>
<listItem confidence="0.7940286">
– a specific (prominent) property or event can
be assigned to several entities, and it is as-
signed to e,
– e belongs to the global discourse rheme or to
a preceding local initial rheme.
</listItem>
<bodyText confidence="0.985673263157895">
Due to these conditions, in our domain, e.g.,
current ozone concentration (0) can be focal-
ized if it is either the highest or the lowest concen-
tration in the region; also, tref (= the time whose
concentration is contrasted to the current concen-
tration). Air quality experts suggest that it is not
adequate to focalize any information in the first
message of the text.
Data on Perspective In an informative dis-
course, data that are in one way or the other un-
usual or are supposed to somehow influence the
reader can be foregrounded, i.e., &amp;quot;marked as be-
ing psychologically primary&amp;quot;. Data or their eval-
uation that are &amp;quot;normal&amp;quot; from the perspective of
the reader may be backgrounded, i.e., &amp;quot;marked as
psychologically secondary&amp;quot;. Backgrounded may
be also data that are the premise of an evalua-
tion of data that is foregrounded (as, e.g., in Um
18 Uhr hat die Ozonkonzentration in Stuttgart mit
217 pg /m3 den hochsten Wert des Tages en-eicht
the mit-Konstruktion backgrounds the actual con-
centration).
In our domain, sentence constructions with
foregrounded elements have been judged &amp;quot;too dra-
matic&amp;quot;. Consider (b) in the following example:
(a) An der Messstation Esslingen wurde um 18 Uhr eine
Ozonkonzentration von 217 pg/m3 gemessen &apos;At the mea-
suring station Esslingen, at 18 o&apos;clock, an ozone concentra-
tion of 217 pg/m3 has been measured&apos; ... (b) Diese Konzen-
tration war zu der Zeit in der Region Mittlerer Neckar der
Hochstwert &apos;This concentration was at this time the highest-
value in the region Mittlerer Neckar.&apos;
The modifier hochste in hochste Konzentration
is raised to the sentential complement to build
the compound Hochstwert and thus focalized (re-
call that the main syntactic means to realize fore-
grounded elements is raising). A more appropriate
variant contains no foregrounded elements; cf.:
</bodyText>
<figure confidence="0.795369">
(a) ... (b) Dieser Wert war die hifichste zu dieser Zeit in der
</figure>
<subsubsectionHeader confidence="0.530479">
Region Mittlerer Neckar gemessene Konzentration. &apos;This
</subsubsectionHeader>
<bodyText confidence="0.938191636363636">
value was the highest concentration measured at this time in
the region Mittlerer Neckar&apos;.
Therefore, we use the &apos;background&apos; parameter
only.
Data on Presupposedness Certain elements of
the discourse that are very prominent in the
reader&apos;s mind can and should be omitted—either
from the start or after their first mention. That
is, they are pragmatically presupposed. In our do-
main, this is the name of the measuring station for
which the reader asked for information.
</bodyText>
<page confidence="0.994591">
114
</page>
<bodyText confidence="0.997804310344828">
In our domain, we can further identify some
linguistically presupposed elements before gener-
ation starts: with the user&apos;s action of clicking on a
measuring station, we can presuppose (i) the con-
cept of &apos;ozone concentration&apos;, the location (i.e.
measuring station), and the time at which the mea-
sure has taken place. The ozone concentration is
asserted.
Note that the presuposedness of time prevents
the shift of the time circumstantial to the final po-
sition in the clause (which is per se allowed in Ger-
man) :4
# An der Messstation Heilbronn lag die Ozonkonzentration
bei 182 pg /m3 urn 18 Uhr lit. &apos;At the measuring station
Heilbronn, the ozone concentration was at 182 lig /m3 at 18
o&apos; clock&apos; .
Data on Unitariness. Often, a domain pre-
scribes a unitary or an articulated realization of
specific information elements. Thus, articles on
a computer science issue written for professionals
would hardly use program for compiling user writ-
ten code to refer to a compiler, while in a paper for
laymen, it would make sense to introduce the term
&amp;quot;compiler&amp;quot; by an articulated lexicalization of the
concept.
In our domain, the following information units
are unitary by definition: (1) location + name, (2)
time + time instance, (3) substance + &apos;concentra-
tion&apos;.
</bodyText>
<sectionHeader confidence="0.992784" genericHeader="method">
4 Deriving the Communicative Structure
</sectionHeader>
<bodyText confidence="0.9999565625">
With the initial domain data, domain communica-
tion data, and the text plan at hand, the instantia-
tion of the communicative dimensions can be de-
rived for each message to be generated. In this
section, we illustrate how the parameters for the
first four dimensions from above can be dynami-
cally determined by a set of communicative rules.
The parameters of the other two dimensions are
determined analogously.
To facilitate the presentation, let us first in-
troduce some notations and conventions: (1) M
stands for &apos;message under construction&apos;, and M-,
for &apos;one of the preceding messages&apos; (an index
may be additionally given if more than one of the
preceding messages is considered). (2) DUA4-
and DUA4 stand for &apos;discourse unit containing
</bodyText>
<sectionHeader confidence="0.596977" genericHeader="method">
4 `7&apos;t marks communicatively inadequate utterances.
</sectionHeader>
<bodyText confidence="0.997481555555555">
message M or M, respectively&apos;. (3) Pairs of
the type &apos;ozone concentration-Y itg/m3&apos;, &apos;age-
4 months&apos;, &apos;time-5pm&apos;, etc. will be referred to as
&apos;token-value&apos; (t-v).
Theme/Rheme. To determine Theme and
Rheme of the message in question, we draw upon
all of the above types of data. Consider examples
for the use of each. The use of the domain
communication data is most obvious:
</bodyText>
<equation confidence="0.447660333333333">
If M is the first to be generated then
Thm := Thcascourse U Th init,secondary
Rhm := Rhi nit,secondary
</equation>
<figureCaption confidence="0.764767">
Discourse relations are often decisive when the
thematic structure of one of the subsequent mes-
sages is determined Consider:
</figureCaption>
<figure confidence="0.988987166666667">
(a) An der Station Stuttgart wurden um 18 Uhr 180 pg/m3
Ozon gemessen &apos;At the station Stuttgart at 18 o&apos;clock, 180
,ug/m3 have been measured&apos;. (b) Um 17 Uhr lag der Wert
noch bei 120 mg /m3 &apos;At 17 o&apos;clock, the value still was at
120 pg/m3&apos;.
(a) Sven Hannawald sprang in Bischofshofen 132.5m weit lit.
</figure>
<bodyText confidence="0.9215140625">
&apos;Sven Hannawald jumped in Bischofshofen 132.5m far.&apos; (b)
In Garmisch waren es nur noch 124m. lit. &apos;In Garmisch, they
were only just 124m&apos;.
In both examples, between (a) and (b) a CON-
TRAST relation holds; more precisely, between the
values of a token (in the first, the token is &apos;ozone
concentration&apos;, in the second, &apos;length&apos;) with re-
spect to a circumstantial (&apos;time&apos; in the first and
&apos;location&apos; in the second). In both (a)s, the token
belongs to Theme and value and the circumstan-
tial to Rheme. In both (b)s, the token and the cir-
cumstantial are Theme, and the value is Rheme.
This is a regular pattern. We can thus formulate
the following rule:
If between DUA,,_ and DUm a CONTRAST-relation
holds and
</bodyText>
<listItem confidence="0.574483333333333">
1. it contrasts the values v- E .A4- and v E .A4 of the
token t with respect to the circumstantial c,
2. t E Thm-, V- E Rhm-, C E Rhm—
</listItem>
<figure confidence="0.960055">
|XML |xmlLoc_5 xmlBold_no xmlItalic_no xmlFontSize_smaller xmlPic_no xmlTable_no xmlBullet_yes bi_xmlSFBIA_new bi_xmlPara_continue
Then, Thm &lt;— t; Thivt &lt;— c; Rhm v
Consider now
(a) Die Ozonkonzentration lag urn 18 Uhr bei 198 pg/m3
&apos;The ozone concentration was at 18h at 198 pg/m3&apos;. (b) Das
war der hochste Wert in der Region Mittlerer Neckar &apos;This
was the highest value in the region Mittlerer Neckar&apos;.
(a) Sven Hannawald sprang in Bischolshofen 132.5m weit
lit. &apos;Sven Hannawald jumped in Bischofshofen 132.5m far.&apos;
</figure>
<page confidence="0.89422">
115
</page>
<bodyText confidence="0.876789777777778">
(b) Das war der weiteste Sprung des Tages &apos;This was the
longest jump of the day&apos;.
Between the (a) and (b) the EVALUATION rela-
tion holds. Again, we can detect a stable theme
pattern: the value of a token introduced, i.e. rhe-
matized, in (a), is evaluated in (b) and is thus part
of theme in (b). Cf. the corresponding rule:
If between and DU.A4 an EVALUATION-
relation holds and
</bodyText>
<listItem confidence="0.967367333333333">
1. the value v- E .A4- of a token t E A4- is evaluated
by the entity e in A4,
2. t e Thm_ and v- E Rhm_
</listItem>
<bodyText confidence="0.961717555555555">
Then, ThA,t v-&apos;; Rhm e.
Other relations, such as ELABORATION, EN-
HANCEMENT, and JUSTIFICATION are equally
used for the derivation of thematic patterns.
The use of factual domain data along with dis-
course relations can be illustrated by the following
example:
(a) 217 pg/m3 ist relativ viel lit. &apos;217 pg/m3 is relatively
much&apos;, (b) wenn auch der Alarmschwellenwert von 240
pg/m3 noch nicht en-eicht 1st &apos;although the alarm threshold
of 240 pg/m3 has not yet been reached&apos;.
Here, between (a) and (b) a CONCESSION rela-
tion holds. In (a), 217 pg/m3 is the Theme, in (b)
der Alarmschwellenwert von 240 pg/m3. That is,
we have the general pattern &apos;Xis Y, but not yet Z&apos;.
This pattern is captured by the following rule:
If between DUm_ and DUm a CONCESSION-
relation holds and
</bodyText>
<listItem confidence="0.998073333333333">
1. A4- contains an attribute assignment &apos;v- is a&apos;,
2. A4 is a statement that v- &lt; threshold T,
3. v-e Thm and v- &gt; threshold a
</listItem>
<bodyText confidence="0.861785557692308">
Then, Thm T; Rhm &lt;— T &gt; V-
Given/New. The task of the Given/New-rules is
on the one hand to change the giveness status of
entities that have been mentioned in the current
message for the first time from &apos;New&apos; to &apos;Given&apos;
and, on the other hand, to assign a giveness degree
to &apos;Given&apos; entities.
To all entities that are marked as &apos;Given&apos; in the
initial given/new-table, we assign the giveness de-
gree 1.
The degree of giveness of an entity with respect
to .A4 (i.e. the message planned) depends on the
distance of this entity from .A4 (measured in num-
ber of words or messages). This is well-known
from the approaches to the generation of refer-
ring expressions (Dale and Reiter, 1995; Horacek,
1995). Which degree is assigned to the entities im-
mediately at .A4 and how quickly (or whether) the
degree is decremented with the increasing distance
depends on the domain and on the nature of each
individual entity. In our domain, only two degrees
are used: 1 and 4. The concept &apos;ozone concen-
tration&apos; is assigned the degree 4 at the point of its
mention; at message distance 2, the degree is set
to 1. All other given entities receive a constant de-
gree 1.
Degree 4 licenses the use of a personal pronoun
and the deictic pronoun DIEsE(R) &apos;this&apos;, and de-
gree 1 licenses the use of the definite article.
Focalized. Criteria for focalization tend to be
more idiosyncratic than the criteria for thematiza-
tion. Nonetheless, since focalization usually hap-
pens in context, focalization rules draw on both
discourse relations and ideational domain data.
A typical focalization is illustrated by the fol-
lowing discourses:
(a) An der Messstation Heilbronn wurden heute 86 pg/m3
gemessen lit. `At the measuring station Heilbronn, today 86
pg/m3 have been measured&apos; ... (b) 86 pg/m3, das war der
niedrigste Wert der Region Mittlerer Neckar &apos;86 pg / m3, this
was the lowest value of the Mittlerer Neckar region&apos;.
(a) Hannawald sprang heute 132m &apos;Hannawald jumped today
132m&apos; ... (b) 132m, das war der langste Sprung des Tages
&apos;132m, this was the longest jump of the day&apos;.
Between (a) and (b), which appear in the dis-
course at a certain distance from each other, an
EVALUATION-relation holds: (b) evaluates (a)&apos;s
rheme v . The evaluation in (b) consists of
the statement &apos;v- is highest/lowest in the given
range&apos;. The following rule captures this pattern:
If between DUm_ and DUm an EVALUATION-
relation holds and
</bodyText>
<listItem confidence="0.9849356">
1. the value 2)— E A4- of a token t E M— is evaluated
by the entity e in .A4,
2. v— E Rhivt_;
3. a states that v- is the highest/lowest in a given
range
</listItem>
<bodyText confidence="0.80775825">
Then, Focusm v–.
Similar rules can be defined for such cases as il-
lustrated by the following examples (focalized en-
tities are underlined):
</bodyText>
<footnote confidence="0.90582125">
(a) An der Messstation Heilbronn wurden um 17 Ulu- 47
pg/m3 gemessen &apos;At the measuring station Heilbronn, at 17
o&apos;clock, 47 pg/m3 have been measured&apos;. (b) Gegentiber
16 Uhr, als der Wert bei 20 pg/m3 lag, hat sich also die
</footnote>
<page confidence="0.99809">
116
</page>
<bodyText confidence="0.9711584">
Konzentration mehr als verdoppelt. lit. &apos;Compared to 16
o&apos;clock, when the value was about 20 pg/m3, the concen-
tration thus more than doubled&apos;.
where a CONTRAST relation holds between (a) and
(b).
</bodyText>
<figure confidence="0.659421666666667">
(a) ...(b) Was die anderen Messstationen der Region
Mittlerer Neckar betrifft, so lagen dort die Werte zwischen
51 pg/m3 in Esslingen und 67 pg /m3 in Plochingen &apos;As
</figure>
<bodyText confidence="0.995286666666667">
far as the other stations in the region Mittlerer Neckar are
concerned, the values there were between 51 pg/m3 in
Esslingen and 67 pg/m3 in Plochingen&apos;,
where an ENHANCEMENT-relation holds between
(a) and (b).
Backgrounded. As mentioned above, in accor-
dance with the characteristics of our domain, we
do not mark any information as Toregrounded&apos;
We background only in the case of the following
pattern:
If between DUm- and DUm an EVALUATION-
relation holds and
</bodyText>
<listItem confidence="0.9060112">
1. the value v- EM- of a token t EM- is evaluated
by the entity e in M,
2. v- is unusually high,
3. v- E Rhm-,
4. e states that v- is the highest in a given range
</listItem>
<subsectionHeader confidence="0.431662">
Then Background_ .
</subsectionHeader>
<bodyText confidence="0.9879592">
(compare the similarity with the focalization pat-
tern above).
The backgrounded element is &amp;quot;downed&amp;quot; such
that M- and M are realized in one clause; cf.:
An der Messstation Heilbronn wurde um 18 Uhr mit 198
pg/m3 der hochste Wert des Tages en-eicht lit. At the mea-
suring station Heilbronn, at 18 o&apos;clock with 198 pg/m3 the
highest value of the day has been reached.
(198 pg/m3 is downed by the use of a mit &apos;with&apos; -
PP).
</bodyText>
<sectionHeader confidence="0.968816" genericHeader="method">
5 Processing Comm. Structure
</sectionHeader>
<bodyText confidence="0.999922032258064">
MTT is a multistratal theory. The most abstract
stratum (or level) we use is the conceptual stra-
tum; the most concrete stratum that is relevant
for generation is the surface-morphological level,
which can be considered as a chain of inflected
wordforms. The representations at each level can,
somewhat simplified, be assumed as consisting of
two structures: the basic (propositional) structure
and the CS, which is defined on the basic struc-
ture and thus partitions the basic structure in terms
of communicative dimensions.
Generation in the sense of MTT consists of a se-
ries of mappings between representations of ad-
jacent levels, starting from the conceptual rep-
resentation that is annotated with communica-
tive dimensions and going up until the surface-
morphological representation is reached; for an
implementation, see (Bohnet and Wanner, 2001).
In Section 2, we have already indicated the lin-
guistic means by which the individual commu-
nicative parameters are realized. During the transi-
tion from level Ei to level Ei+i , a communicative
parameter is either realized by the appropriate lin-
guistic means available at Ei±i or is mapped onto
the CS of Ei+i , i.e., propagated to Ei+i in order
to be realized on one of the higher levels. Both
the realization and the propagation are specified in
terms of communicative rules, which make part of
the grammar rules. The communicative rules are
discussed at length in a longer version of this pa-
per.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999948346153846">
Among the first to apply the information struc-
ture to text generation were C. Matthiessen (1985),
K. McKeown (1985), and L. Iordanskaja (1992).
Especially Iordanskaja discusses in detail how
Thematization influences the order of the mes-
sages in a text plan, and, to a certain extent, also
aggregation.
More recently, Humphreys (1995) investigated
how the speaker&apos;s (communicative) intentions
guide the choice of such &amp;quot;non-canonical&amp;quot; sentence
patterns in English as clefting and dislocation
(which we considered as realizations of focalized
elements). As Humphreys, Stone et al. (2001) re-
late in the SPUD-system sentence planning options
to communicative intentions of the speaker, which
are in their case captured by Assertion, Presup-
position and Pragmatics (while Humphreys devel-
ops explicit speaker and hearer models). Note that
Assertion and Presupposition in SPUD are &amp;quot;prag-
matic notions&amp;quot; (see Section 2). Creswell (2002)
extends Stone et al.&apos;s approach by three types
of more fine-grained communicative goals: atten-
tion marking, discourse relation, and focus dis-
ambiguation. As examples of discourse relations
Creswell cites NARRATIVE and PARALLEL. How-
ever, it is not clear how many and which discourse
</bodyText>
<page confidence="0.992761">
117
</page>
<bodyText confidence="0.9977595">
relations are covered. But, obviously, Creswell&apos;s
proposal is similar to ours.
</bodyText>
<sectionHeader confidence="0.946672" genericHeader="conclusions">
7 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.99999696">
We presented how discourse structure relations
and domain communication data can be used to
compile a CS, which guides then sentence plan-
ning and realization. The described model is an
extension of the model underlying the AutoText
UIS generator, which has been developed in co-
operation with the Ministry of Environment and
Traffic, Baden-Wrirttemberg (Bohnet and et at.,
2001) and which is in action since summer 2001.
The extended model is currently under implemen-
tation. However, it still reveals several limitations.
Thus, we work so far with a subset of RST-like
relations in the air quality domain restricted to
ozone. It is planned to extend the generation to
other substances in this domain-which implies a
broader coverage of discourse relations, and thus,
also a broader coverage of the interrelation be-
tween discourse relations and communicative di-
mensions. However, the air quality domain alone
is certainly still too restricted for a full scale cov-
erage of the phenomena related to CS. There-
fore, we plan to examine two other application do-
mains: flood surveyance and weather forecast. In
parallel, we continue to work on the extension of
our sentence grammar module.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999715042253521">
B. Bohnet, L. Wanner et at. 2001. Autotext-UIS: Au-
tomatische Produktion von Ozonkurzberichten im
Umweltinformationssystem B aden-Wiirttemberg.
In Proceedings of the Workshop Hypermedia und
Umweltschutz, Ulm.
B. Bohnet and L. Wanner. 2001. On Using a Paral-
lel Graph Rewriting Grammar Formalism in Gener-
ation. In Proceedings of the 8th European Workshop
on NLG at the ACL, Toulouse, France.
H.-W. Choi. 1996. Optimizing Structure in Context:
Scrambling and Information Structure. Ph.D. thesis,
Stanford University, Stanford.
C. Creswell. 2002. Syntactic Form and Discourse
Function in NLG. In Proceedings of the 2nd Inter-
national Conference on NLG, Student Session.
R. Dale and E. Reiter. 1995. Computational Interpreta-
tion of the Gricean Maxims in the Generation of Re-
ferring Expressions. Cognitive Science, 19(2):233-
263.
S. Geldorf. 2000. From Context to Sentence Form. In
Proceedings of the 1st International Conference on
NLG, Student Session.
J.K. Gundel. 1988. &amp;quot;Universals of Topic-Comment
Structure&amp;quot;. In M. Hammond, E. Moraveik, and
J. Wirth, editors, Studies in Syntactic Typology,
pages 209-239. Benjamins, Amsterdam.
M.A.K. Halliday. 1994. An Introduction to Functional
Grammar. Edward Arnold, London.
H. Horacek. 1995. More on Generating Referring
Expressions. In Proceedings of the 5th European
Workshop on NLG, pages 43-58.
K. Humphreys. 1995. Formalising Pragmatic Infor-
mation for Natural Language Generation. Ph.D.
thesis, University of Edinburgh.
L. Iordanskaja. 1992. &amp;quot;Communicative Structure and
its Use during Text Generation&amp;quot;. Int. Forum on In-
formation and Documentation, 17(2):15-27.
R. Klabunde and M. Jansche. 1998. Abductive Rea-
soning for Syntactic Realization. In Proceedings
of the International Workshop NLG, Niagara-on-the-
Lake, ON, Canada.
W.C. Mann and S.A. Thompson. 1987. Rhetorical
Structure Theory: A theory of text organization.
In L. Polanyi, editor, The Structure of Discourse.
Ablex, Norwood, New Jersey.
C.M.I.M. Matthiessen. 1985. The Systemic Frame-
work in Text Generation: Nigel. In J.D. Benson and
W.S. Greaves, editors, Systemic Perspectives on Dis-
course, Volume 1. Ablex, Norwood, New Jersey.
K. McKeown. 1985. Text Generation: Using Dis-
course Strategies and Focus Constraints to Generate
Natural Language Text. CUP, Cambridge.
I.A. Mel&apos;euk. 1988. Dependency Syntax: Theory and
Practice. SUNY Press, Albany.
I. A. Mel&apos;euk. 2001. Communicative Organization
in Natural Language (The Semantic-Communicative
Structure of Sentences). Benj amins, Amsterdam.
J. Moore and M. Pollack. 1992. A problem for
RST: The Need for Multi-Level Discourse Analysis.
Computational Linguistics, 18(4):537-544.
E. Prince. 1978. A Comparison of WH-Clefts and IT-
Clefts in Discourse. Language, 54(4):883-906.
0. Rambow. 1990. Communication Domain Knowl-
edge. In Proceedings of the 5th. International Work-
shop on NLG., Dawson, PA.
M. Stone, C. Doran, B. Webber, T. Bleam, and
M. Palmer. 2001. Microplanning with Communica-
tive Intentions: The SPUD system. Rutgers.
E. Vallduvi. 1995. Information packaging: A survey.
Report, Center for Cognitive Science and HCRC,
University of Edinburgh.
</reference>
<page confidence="0.996223">
118
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.363844">
<title confidence="0.999766">Deriving the Communicative Structure in Applied NLG</title>
<author confidence="0.999961">Leo Wanner</author>
<affiliation confidence="0.999129">Intelligent Systems University of Stuttgart</affiliation>
<email confidence="0.94236">wanner@informatik.uni-stuttgart.de</email>
<author confidence="0.616012">Bernd</author>
<affiliation confidence="0.9968335">Intelligent Systems University of Stuttgart</affiliation>
<email confidence="0.984453">bohnet@informatik.uni-stuttgart.de</email>
<author confidence="0.991287">Mark</author>
<affiliation confidence="0.999049">Intelligent Systems University of Stuttgart</affiliation>
<email confidence="0.714322">giereth@informatik.unistuttgart.de</email>
<abstract confidence="0.992280285714286">Information structure is decisive for constraining linguistic options during sentence planning. Nonetheless, it is only recently that it became a topic on the agenda of the mainstream text generation research. We investigate how certain parameters of the information (or communicative) structure developed in Linguistics be derived in applied text generation from the domain and discourse data, and how these parameters guide the process of sentence generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>L Wanner et at</author>
</authors>
<title>Autotext-UIS: Automatische Produktion von Ozonkurzberichten im Umweltinformationssystem B aden-Wiirttemberg.</title>
<date>2001</date>
<booktitle>In Proceedings of the Workshop Hypermedia und Umweltschutz,</booktitle>
<location>Ulm.</location>
<marker>Bohnet, at, 2001</marker>
<rawString>B. Bohnet, L. Wanner et at. 2001. Autotext-UIS: Automatische Produktion von Ozonkurzberichten im Umweltinformationssystem B aden-Wiirttemberg. In Proceedings of the Workshop Hypermedia und Umweltschutz, Ulm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>L Wanner</author>
</authors>
<title>On Using a Parallel Graph Rewriting Grammar Formalism in Generation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th European Workshop on NLG at the ACL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="26967" citStr="Bohnet and Wanner, 2001" startWordPosition="4485" endWordPosition="4488"> chain of inflected wordforms. The representations at each level can, somewhat simplified, be assumed as consisting of two structures: the basic (propositional) structure and the CS, which is defined on the basic structure and thus partitions the basic structure in terms of communicative dimensions. Generation in the sense of MTT consists of a series of mappings between representations of adjacent levels, starting from the conceptual representation that is annotated with communicative dimensions and going up until the surfacemorphological representation is reached; for an implementation, see (Bohnet and Wanner, 2001). In Section 2, we have already indicated the linguistic means by which the individual communicative parameters are realized. During the transition from level Ei to level Ei+i , a communicative parameter is either realized by the appropriate linguistic means available at Ei±i or is mapped onto the CS of Ei+i , i.e., propagated to Ei+i in order to be realized on one of the higher levels. Both the realization and the propagation are specified in terms of communicative rules, which make part of the grammar rules. The communicative rules are discussed at length in a longer version of this paper. 6</context>
</contexts>
<marker>Bohnet, Wanner, 2001</marker>
<rawString>B. Bohnet and L. Wanner. 2001. On Using a Parallel Graph Rewriting Grammar Formalism in Generation. In Proceedings of the 8th European Workshop on NLG at the ACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-W Choi</author>
</authors>
<title>Optimizing Structure in Context: Scrambling and Information Structure.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University, Stanford.</institution>
<contexts>
<context position="1219" citStr="Choi, 1996" startWordPosition="174" endWordPosition="175">n parameters of the information (or communicative) structure developed in Meaning-Text Linguistics can be derived in applied text generation from the domain and discourse data, and how these parameters guide the process of sentence generation. 1 Introduction One of the notorious problems NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1</context>
</contexts>
<marker>Choi, 1996</marker>
<rawString>H.-W. Choi. 1996. Optimizing Structure in Context: Scrambling and Information Structure. Ph.D. thesis, Stanford University, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Creswell</author>
</authors>
<title>Syntactic Form and Discourse Function in NLG.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd International Conference on NLG, Student Session.</booktitle>
<contexts>
<context position="1510" citStr="Creswell, 2002" startWordPosition="220" endWordPosition="221">ms NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the information structure in applied text generation from the above sources. As information structure, </context>
<context position="28505" citStr="Creswell (2002)" startWordPosition="4732" endWordPosition="4733">cently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in their case captured by Assertion, Presupposition and Pragmatics (while Humphreys develops explicit speaker and hearer models). Note that Assertion and Presupposition in SPUD are &amp;quot;pragmatic notions&amp;quot; (see Section 2). Creswell (2002) extends Stone et al.&apos;s approach by three types of more fine-grained communicative goals: attention marking, discourse relation, and focus disambiguation. As examples of discourse relations Creswell cites NARRATIVE and PARALLEL. However, it is not clear how many and which discourse 117 relations are covered. But, obviously, Creswell&apos;s proposal is similar to ours. 7 Summary and Future Work We presented how discourse structure relations and domain communication data can be used to compile a CS, which guides then sentence planning and realization. The described model is an extension of the model </context>
</contexts>
<marker>Creswell, 2002</marker>
<rawString>C. Creswell. 2002. Syntactic Form and Discourse Function in NLG. In Proceedings of the 2nd International Conference on NLG, Student Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<date>1995</date>
<booktitle>Computational Interpretation of the Gricean Maxims in the Generation of Referring Expressions. Cognitive Science,</booktitle>
<pages>19--2</pages>
<contexts>
<context position="22442" citStr="Dale and Reiter, 1995" startWordPosition="3706" endWordPosition="3709">n/New-rules is on the one hand to change the giveness status of entities that have been mentioned in the current message for the first time from &apos;New&apos; to &apos;Given&apos; and, on the other hand, to assign a giveness degree to &apos;Given&apos; entities. To all entities that are marked as &apos;Given&apos; in the initial given/new-table, we assign the giveness degree 1. The degree of giveness of an entity with respect to .A4 (i.e. the message planned) depends on the distance of this entity from .A4 (measured in number of words or messages). This is well-known from the approaches to the generation of referring expressions (Dale and Reiter, 1995; Horacek, 1995). Which degree is assigned to the entities immediately at .A4 and how quickly (or whether) the degree is decremented with the increasing distance depends on the domain and on the nature of each individual entity. In our domain, only two degrees are used: 1 and 4. The concept &apos;ozone concentration&apos; is assigned the degree 4 at the point of its mention; at message distance 2, the degree is set to 1. All other given entities receive a constant degree 1. Degree 4 licenses the use of a personal pronoun and the deictic pronoun DIEsE(R) &apos;this&apos;, and degree 1 licenses the use of the defin</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>R. Dale and E. Reiter. 1995. Computational Interpretation of the Gricean Maxims in the Generation of Referring Expressions. Cognitive Science, 19(2):233-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Geldorf</author>
</authors>
<title>From Context to Sentence Form.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Conference on NLG, Student Session.</booktitle>
<contexts>
<context position="1427" citStr="Geldorf, 2000" startWordPosition="205" endWordPosition="206">ide the process of sentence generation. 1 Introduction One of the notorious problems NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the information stru</context>
</contexts>
<marker>Geldorf, 2000</marker>
<rawString>S. Geldorf. 2000. From Context to Sentence Form. In Proceedings of the 1st International Conference on NLG, Student Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K Gundel</author>
</authors>
<title>Universals of Topic-Comment Structure&amp;quot;.</title>
<date>1988</date>
<booktitle>Studies in Syntactic Typology,</booktitle>
<pages>209--239</pages>
<editor>In M. Hammond, E. Moraveik, and J. Wirth, editors,</editor>
<location>Benjamins, Amsterdam.</location>
<contexts>
<context position="6627" citStr="Gundel (1988)" startWordPosition="1045" endWordPosition="1046">is that part of Ssen, that the Speaker intends to present as being new to the Addressee. Since most often the Speaker assumes that the information being stated is new to the Addressee, while the information about which it is stated is present in the Addressee&apos;s consciousness, Rheme/Theme and Given/New are often conflated (this is why Theme/Rheme is sometimes called old/new; see above). However, it does not need to be the case that they coincide; consider, e.g.: A farmer from Sommerset Th/New has found a Roman chamberpot Rh/New• Given elements are usually expressed by anaphora. As suggested by Gundel (1988), MTT distinguishes four degrees of giveness: (1) unique identifiability, (2) familiarity, (3) activatedness, Foregrounded vs. Backgrounded. Foregrounded is that part of Sse, that the Speaker intends to present as being psychologically prominent for him Backgrounded is that part of Ssen, that the Speaker intends to present as being psychologicall secondary for him Some parts of Ssen, may be neither foregrounded nor backgrounded. The main linguistic means for the realization of foregrounded elements is raising; for the realization of backgrounded elements—parenthetical constructions and downing</context>
</contexts>
<marker>Gundel, 1988</marker>
<rawString>J.K. Gundel. 1988. &amp;quot;Universals of Topic-Comment Structure&amp;quot;. In M. Hammond, E. Moraveik, and J. Wirth, editors, Studies in Syntactic Typology, pages 209-239. Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>An Introduction to Functional Grammar. Edward</title>
<date>1994</date>
<location>Arnold, London.</location>
<contexts>
<context position="5053" citStr="Halliday, 1994" startWordPosition="774" endWordPosition="775"> the interrelation with other parameters, a thematized element may be realized as the Subject of a clause, be fronted or be proleptized. The Rheme/Theme-dimension constraints thus lexicalization, syntactic choice and word order. Cf. an example: and (4) focality. Each of the degrees licenses primarily the choice of specific anaphoric references: (1) of the definite article, (2) of the deictic THAT, (3) of the deictic THIS, and (4) of a personal pronoun (HE, SHE, ... ). That is, the Given/New dimension constraints primarily morphosyntactic options, but also lexical and syntactic ones. Cf. (from Halliday, 1994): a little guinea pig, New being little, Given, was not big. New Focalized vs. Non-Focalized. Focalized is that part of Ssen, that the Speaker intends to present as being focus of attention, i.e., logically prominent for him Focalization presents a configuration of entities as excluding other logical options: &amp;quot;exactly X, and not something else&amp;quot;. The linguistic means to express focalization (orfocus) include first of all dislocation or detachment and various types of clefting; cf.: 1. To my daughter Fo, the uncle sent a doll, to his son 1. There was 2. which, Given The typical function of an in</context>
</contexts>
<marker>Halliday, 1994</marker>
<rawString>M.A.K. Halliday. 1994. An Introduction to Functional Grammar. Edward Arnold, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>More on Generating Referring Expressions.</title>
<date>1995</date>
<booktitle>In Proceedings of the 5th European Workshop on NLG,</booktitle>
<pages>43--58</pages>
<contexts>
<context position="22458" citStr="Horacek, 1995" startWordPosition="3710" endWordPosition="3711">ne hand to change the giveness status of entities that have been mentioned in the current message for the first time from &apos;New&apos; to &apos;Given&apos; and, on the other hand, to assign a giveness degree to &apos;Given&apos; entities. To all entities that are marked as &apos;Given&apos; in the initial given/new-table, we assign the giveness degree 1. The degree of giveness of an entity with respect to .A4 (i.e. the message planned) depends on the distance of this entity from .A4 (measured in number of words or messages). This is well-known from the approaches to the generation of referring expressions (Dale and Reiter, 1995; Horacek, 1995). Which degree is assigned to the entities immediately at .A4 and how quickly (or whether) the degree is decremented with the increasing distance depends on the domain and on the nature of each individual entity. In our domain, only two degrees are used: 1 and 4. The concept &apos;ozone concentration&apos; is assigned the degree 4 at the point of its mention; at message distance 2, the degree is set to 1. All other given entities receive a constant degree 1. Degree 4 licenses the use of a personal pronoun and the deictic pronoun DIEsE(R) &apos;this&apos;, and degree 1 licenses the use of the definite article. Foc</context>
</contexts>
<marker>Horacek, 1995</marker>
<rawString>H. Horacek. 1995. More on Generating Referring Expressions. In Proceedings of the 5th European Workshop on NLG, pages 43-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Humphreys</author>
</authors>
<title>Formalising Pragmatic Information for Natural Language Generation.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="27914" citStr="Humphreys (1995)" startWordPosition="4647" endWordPosition="4648"> Ei+i in order to be realized on one of the higher levels. Both the realization and the propagation are specified in terms of communicative rules, which make part of the grammar rules. The communicative rules are discussed at length in a longer version of this paper. 6 Related Work Among the first to apply the information structure to text generation were C. Matthiessen (1985), K. McKeown (1985), and L. Iordanskaja (1992). Especially Iordanskaja discusses in detail how Thematization influences the order of the messages in a text plan, and, to a certain extent, also aggregation. More recently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in their case captured by Assertion, Presupposition and Pragmatics (while Humphreys develops explicit speaker and hearer models). Note that Assertion and Presupposition in SPUD are &amp;quot;pragmatic notions&amp;quot; (see Section 2). Creswell (2002) extends </context>
</contexts>
<marker>Humphreys, 1995</marker>
<rawString>K. Humphreys. 1995. Formalising Pragmatic Information for Natural Language Generation. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
</authors>
<title>Communicative Structure and its Use during Text Generation&amp;quot;.</title>
<date>1992</date>
<booktitle>Int. Forum on Information and Documentation,</booktitle>
<pages>17--2</pages>
<contexts>
<context position="27723" citStr="Iordanskaja (1992)" startWordPosition="4618" endWordPosition="4619">ransition from level Ei to level Ei+i , a communicative parameter is either realized by the appropriate linguistic means available at Ei±i or is mapped onto the CS of Ei+i , i.e., propagated to Ei+i in order to be realized on one of the higher levels. Both the realization and the propagation are specified in terms of communicative rules, which make part of the grammar rules. The communicative rules are discussed at length in a longer version of this paper. 6 Related Work Among the first to apply the information structure to text generation were C. Matthiessen (1985), K. McKeown (1985), and L. Iordanskaja (1992). Especially Iordanskaja discusses in detail how Thematization influences the order of the messages in a text plan, and, to a certain extent, also aggregation. More recently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in their case captured by Assertion, Presupposition</context>
</contexts>
<marker>Iordanskaja, 1992</marker>
<rawString>L. Iordanskaja. 1992. &amp;quot;Communicative Structure and its Use during Text Generation&amp;quot;. Int. Forum on Information and Documentation, 17(2):15-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Klabunde</author>
<author>M Jansche</author>
</authors>
<title>Abductive Reasoning for Syntactic Realization.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop NLG,</booktitle>
<location>Niagara-on-theLake, ON,</location>
<contexts>
<context position="1411" citStr="Klabunde and Jansche, 1998" startWordPosition="201" endWordPosition="204"> and how these parameters guide the process of sentence generation. 1 Introduction One of the notorious problems NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the </context>
</contexts>
<marker>Klabunde, Jansche, 1998</marker>
<rawString>R. Klabunde and M. Jansche. 1998. Abductive Reasoning for Syntactic Realization. In Proceedings of the International Workshop NLG, Niagara-on-theLake, ON, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: A theory of text organization.</title>
<date>1987</date>
<booktitle>The Structure of Discourse. Ablex,</booktitle>
<editor>In L. Polanyi, editor,</editor>
<location>Norwood, New Jersey.</location>
<contexts>
<context position="10281" citStr="Mann and Thompson, 1987" startWordPosition="1634" endWordPosition="1638">eed at Ute&apos;s. 3This is not to say, of course, that we do not deal with them at all. Rather, their processing is not our topic here. 3.1 Data and Discourse Structure We presuppose that an applied text generator starts from data stored, e.g., in a data base. In our application, these data are measuring data that are exported from a DB into an XML-document. An &amp;quot;expert system&amp;quot; module evaluates these data, compiles a set of communicative goals that are to be achieved, and chooses the data that are relevant to these goals. From the communicative goals, a text plan with RST-like discourse relations (Mann and Thompson, 1987) is derived. Besides RST-relations, we use Halliday&apos;s (1994) expansion relations ENHANCEMENT and EXTENSION and their more fine-grained variants. Our use of discourse relations differs from the use in traditional RST in two respects: (i) specifying a discourse relation between the discourse units D Ui and DU2, we also specify which elements in DUi and DU2 are involved in the relation; thus, the CONTRAST-relation between (a) and (b) in (a) It was John who sent my daughter the doll. (b) Mary never sends her anything the &amp;quot;hubs&amp;quot; of the nuclei are John and Mary, respectively (not, e.g., doll and not</context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>W.C. Mann and S.A. Thompson. 1987. Rhetorical Structure Theory: A theory of text organization. In L. Polanyi, editor, The Structure of Discourse. Ablex, Norwood, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M I M Matthiessen</author>
</authors>
<title>The Systemic Framework in Text Generation:</title>
<date>1985</date>
<booktitle>Systemic Perspectives on Discourse, Volume 1. Ablex,</booktitle>
<editor>Nigel. In J.D. Benson and W.S. Greaves, editors,</editor>
<location>Norwood, New Jersey.</location>
<contexts>
<context position="27677" citStr="Matthiessen (1985)" startWordPosition="4611" endWordPosition="4612">nicative parameters are realized. During the transition from level Ei to level Ei+i , a communicative parameter is either realized by the appropriate linguistic means available at Ei±i or is mapped onto the CS of Ei+i , i.e., propagated to Ei+i in order to be realized on one of the higher levels. Both the realization and the propagation are specified in terms of communicative rules, which make part of the grammar rules. The communicative rules are discussed at length in a longer version of this paper. 6 Related Work Among the first to apply the information structure to text generation were C. Matthiessen (1985), K. McKeown (1985), and L. Iordanskaja (1992). Especially Iordanskaja discusses in detail how Thematization influences the order of the messages in a text plan, and, to a certain extent, also aggregation. More recently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in th</context>
</contexts>
<marker>Matthiessen, 1985</marker>
<rawString>C.M.I.M. Matthiessen. 1985. The Systemic Framework in Text Generation: Nigel. In J.D. Benson and W.S. Greaves, editors, Systemic Perspectives on Discourse, Volume 1. Ablex, Norwood, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
</authors>
<title>Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text.</title>
<date>1985</date>
<publisher>CUP, Cambridge.</publisher>
<contexts>
<context position="27696" citStr="McKeown (1985)" startWordPosition="4614" endWordPosition="4615"> realized. During the transition from level Ei to level Ei+i , a communicative parameter is either realized by the appropriate linguistic means available at Ei±i or is mapped onto the CS of Ei+i , i.e., propagated to Ei+i in order to be realized on one of the higher levels. Both the realization and the propagation are specified in terms of communicative rules, which make part of the grammar rules. The communicative rules are discussed at length in a longer version of this paper. 6 Related Work Among the first to apply the information structure to text generation were C. Matthiessen (1985), K. McKeown (1985), and L. Iordanskaja (1992). Especially Iordanskaja discusses in detail how Thematization influences the order of the messages in a text plan, and, to a certain extent, also aggregation. More recently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in their case captured b</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>K. McKeown. 1985. Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. CUP, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel&apos;euk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>SUNY Press,</publisher>
<location>Albany.</location>
<contexts>
<context position="2427" citStr="Mel&apos;euk, 1988" startWordPosition="360" endWordPosition="361">bow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the information structure in applied text generation from the above sources. As information structure, we use the Communicative Structure (henceforth CS) defined in the Meaning-Text Theory (MTT), which has the advantage of being detailed and rigorously defined; see (Mel&apos; euk, 2001). The derivation of the CS and its processing is currently being implemented in a text generator that is also based on MTT (Mel&apos;euk, 1988). The application domain under study is the ozone concentration domain in the province of Baden-Wurttemberg, Germany. Note, however, that the proposed approach is fully applicable to all data-oriented domains (such as stock market, flood surveyance, weather forecast, etc.). 2 Communicative Structure in MTT Hardly any other notion in linguistics received such a heterogeneous presentation across the different theories as the information (= communicative) structure. But it cannot be our goal to present here a constrastive overview of the different interpretations. Rather, we concentrate on a brie</context>
</contexts>
<marker>Mel&apos;euk, 1988</marker>
<rawString>I.A. Mel&apos;euk. 1988. Dependency Syntax: Theory and Practice. SUNY Press, Albany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel&apos;euk</author>
</authors>
<title>Communicative Organization in Natural Language (The Semantic-Communicative Structure of Sentences). Benj amins,</title>
<date>2001</date>
<location>Amsterdam.</location>
<marker>Mel&apos;euk, 2001</marker>
<rawString>I. A. Mel&apos;euk. 2001. Communicative Organization in Natural Language (The Semantic-Communicative Structure of Sentences). Benj amins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Moore</author>
<author>M Pollack</author>
</authors>
<title>A problem for RST: The Need for Multi-Level Discourse Analysis.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--4</pages>
<contexts>
<context position="10976" citStr="Moore and Pollack, 1992" startWordPosition="1754" endWordPosition="1757">relations ENHANCEMENT and EXTENSION and their more fine-grained variants. Our use of discourse relations differs from the use in traditional RST in two respects: (i) specifying a discourse relation between the discourse units D Ui and DU2, we also specify which elements in DUi and DU2 are involved in the relation; thus, the CONTRAST-relation between (a) and (b) in (a) It was John who sent my daughter the doll. (b) Mary never sends her anything the &amp;quot;hubs&amp;quot; of the nuclei are John and Mary, respectively (not, e.g., doll and nothing) (ii) several relations may hold between DUI. and DU-2 (see also (Moore and Pollack, 1992) on the need for multi-level analysis of RST-relations). As mentioned above, we presuppose that a text plan has already been compiled when we start the compilation of the CS. 3.2 Domain Communication Data Originally defined for the semantic level, mTT&apos;s communicative dimensions can also be used at the conceptual, i.e. &amp;quot;prelinguistic&amp;quot;, level. For some of them, initial settings are already available before generation starts. They are predetermined by the domain, by the design of the interface via which the reader communicates with the generator, and by the actions the user takes during the sessi</context>
</contexts>
<marker>Moore, Pollack, 1992</marker>
<rawString>J. Moore and M. Pollack. 1992. A problem for RST: The Need for Multi-Level Discourse Analysis. Computational Linguistics, 18(4):537-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Prince</author>
</authors>
<title>A Comparison of WH-Clefts and ITClefts</title>
<date>1978</date>
<booktitle>in Discourse. Language,</booktitle>
<pages>54--4</pages>
<contexts>
<context position="1191" citStr="Prince, 1978" startWordPosition="170" endWordPosition="171">rch. We investigate how certain parameters of the information (or communicative) structure developed in Meaning-Text Linguistics can be derived in applied text generation from the domain and discourse data, and how these parameters guide the process of sentence generation. 1 Introduction One of the notorious problems NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunica</context>
</contexts>
<marker>Prince, 1978</marker>
<rawString>E. Prince. 1978. A Comparison of WH-Clefts and ITClefts in Discourse. Language, 54(4):883-906.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rambow</author>
</authors>
<title>Communication Domain Knowledge.</title>
<date>1990</date>
<booktitle>In Proceedings of the 5th. International Workshop on NLG.,</booktitle>
<location>Dawson, PA.</location>
<contexts>
<context position="1823" citStr="Rambow, 1990" startWordPosition="263" endWordPosition="264">hoi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the information structure in applied text generation from the above sources. As information structure, we use the Communicative Structure (henceforth CS) defined in the Meaning-Text Theory (MTT), which has the advantage of being detailed and rigorously defined; see (Mel&apos; euk, 2001). The derivation of the CS and its processing is currently being implemented in a text generator that is also based on MTT (Mel&apos;euk, 1</context>
</contexts>
<marker>Rambow, 1990</marker>
<rawString>0. Rambow. 1990. Communication Domain Knowledge. In Proceedings of the 5th. International Workshop on NLG., Dawson, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>C Doran</author>
<author>B Webber</author>
<author>T Bleam</author>
<author>M Palmer</author>
</authors>
<title>Microplanning with Communicative Intentions: The SPUD system.</title>
<date>2001</date>
<location>Rutgers.</location>
<contexts>
<context position="1493" citStr="Stone et al., 2001" startWordPosition="216" endWordPosition="219">the notorious problems NLG faces since its early days is the purposeful choice of one of the linguistic options available to express a given meaning. It is well known that a rich information structure constraints sentence structures, and thus, to a major extent, also the process of sentence generation (Prince, 1978; Vallduvf, 1995; Choi, 1996; Mel&apos; ouk, 2001). Existing proposals for the derivation of the information structure in the context of NLG draw mainly on contextual (extra-linguistic) information (Klabunde and Jansche, 1998; Geldorf, 2000) or on the communicative intent of the speaker (Stone et al., 2001; Creswell, 2002). Occasionally, recourse is made to semantic coherence relations (Creswell, 2002). We believe that a detailed information structure can be sufficiently determined only when the following sources are taken into account: (i) domainspecific communicative constraints (domain COMmunication knowledge in (Rambow, 1990)), (ii) a detailed discourse structure as provided, e.g., by RST-based text planners, and (iii) the communicative intent of the speaker. In what follows, we describe the derivation of the information structure in applied text generation from the above sources. As inform</context>
<context position="8395" citStr="Stone et al., 2001" startWordPosition="1319" endWordPosition="1322">ture is negated or questioned, the presupposed fragment remained affirmed.) The part that is not presupposed is Asserted. Linguistically presupposed elements can be realized only as attributive (modifying or appositive) constructions; cf.: 1. The car, which was an old Renault Pres, broke down 2. Germ. Bei Ute pres liegt ein Toter unterm Sofa Pres lit. &apos;At Ute&apos;s, lies a dead man under the couch&apos;. vs. Unter Utes Sofa liegt em Toter &apos;Under Ute&apos;s couch lies a dead man&apos;.2 In German, Presupposedness also constraints word order (see below). &amp;quot;Pragmatic&amp;quot; presupposition as used in generation, e.g., in (Stone et al., 2001), encloses all elements that are expected to be familiar to the reader (either from his world knowledge, from the context, or from the text). For generation, both types of presupposition are needed. Unitary vs. Articulated. Unitary is the part of Ssen., that the Speaker intends to present as being looked at as one (opaque) single entity. Articulated is the part of Ssen, which the Speaker intends to present as being a configuration of semantic entities. Fragments of Ssem that are marked as Unitary are preferably expressed by single lexemes; those that are marked as Articulated, are preferrably </context>
<context position="28165" citStr="Stone et al. (2001)" startWordPosition="4679" endWordPosition="4682">sion of this paper. 6 Related Work Among the first to apply the information structure to text generation were C. Matthiessen (1985), K. McKeown (1985), and L. Iordanskaja (1992). Especially Iordanskaja discusses in detail how Thematization influences the order of the messages in a text plan, and, to a certain extent, also aggregation. More recently, Humphreys (1995) investigated how the speaker&apos;s (communicative) intentions guide the choice of such &amp;quot;non-canonical&amp;quot; sentence patterns in English as clefting and dislocation (which we considered as realizations of focalized elements). As Humphreys, Stone et al. (2001) relate in the SPUD-system sentence planning options to communicative intentions of the speaker, which are in their case captured by Assertion, Presupposition and Pragmatics (while Humphreys develops explicit speaker and hearer models). Note that Assertion and Presupposition in SPUD are &amp;quot;pragmatic notions&amp;quot; (see Section 2). Creswell (2002) extends Stone et al.&apos;s approach by three types of more fine-grained communicative goals: attention marking, discourse relation, and focus disambiguation. As examples of discourse relations Creswell cites NARRATIVE and PARALLEL. However, it is not clear how ma</context>
</contexts>
<marker>Stone, Doran, Webber, Bleam, Palmer, 2001</marker>
<rawString>M. Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer. 2001. Microplanning with Communicative Intentions: The SPUD system. Rutgers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Vallduvi</author>
</authors>
<title>Information packaging: A survey.</title>
<date>1995</date>
<tech>Report,</tech>
<institution>Center for Cognitive Science and HCRC, University of Edinburgh.</institution>
<marker>Vallduvi, 1995</marker>
<rawString>E. Vallduvi. 1995. Information packaging: A survey. Report, Center for Cognitive Science and HCRC, University of Edinburgh.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>