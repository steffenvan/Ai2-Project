<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.901531">
NAACL HLT 2010
</note>
<title confidence="0.9689986">
Workshop on
Creating Speech and
Language Data with
Amazon’s Mechanical Turk
Proceedings of the Workshop
</title>
<author confidence="0.3988405">
June 6, 2010
Los Angeles, California
</author>
<figure confidence="0.709430111111111">
USB memory sticks produced by
Omnipress Inc.
2600 Anderson Street
Madison, WI 53707
USA
Generously Sponsored By:
and
c�2010 The Association for Computational Linguistics
Association for Computational Linguistics (ACL)
</figure>
<page confidence="0.410894">
209 N. Eighth Street
</page>
<note confidence="0.673774">
Stroudsburg, PA 18360
USA
Tel: +1-570-476-8006
Fax: +1-570-476-0860
</note>
<email confidence="0.731621">
acl@aclweb.org
</email>
<page confidence="0.625547">
ii
</page>
<note confidence="0.591615">
Preface
</note>
<bodyText confidence="0.997400625">
The NAACL-2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk
explores applications of crowdsourcing technologies for the creation and study of language data. Recent
work has evaluated the effectiveness of using crowdsourcing platforms, such as Amazon’s Mechanical
Turk, to create annotated data for natural language processing applications. This workshop further
explores this area and these proceedings contain 34 papers and an overview paper that each experiment
with applications of Mechanical Turk. The diversity of applications showcases the new possibilities for
annotating speech and text, and has the potential to dramatically change how we create data for human
language technologies.
Papers in the workshop also looked at best practices in creating data using Mechanical Turk.
Experiments evaluated how to design Human Intelligence Tasks (HITs), how to attract users to the task,
how to price annotation tasks, and how to ensure data quality. Applications include the creation of data
sets for standard NLP tasks, developing entirely new tasks, and investigating new ways of integrating
user feedback in the learning process.
The workshop featured an open-ended shared task in which 35 teams were awarded $100 of credit
on Amazon Mechanical Turk to spend on an annotation task of their choosing. Results of the shared
task are described in short papers and all collected data is publicly available. Shared task participants
focused on data collection questions, such as how to convey complex tasks to non-experts, how to
evaluate and ensure quality and annotation cost and speed.
The organizers thank the workshop participants who contributed to an incredibly strong workshop
program. We also thank the program committee for quickly reviewing the large number of submissions.
Special thanks go to Sharon Chiarella, vice president of Amazon Mechanical Turk, for funding the
shared task, Ted Sandler of Amazon for assistance in organizing the shared task, Stephanie Geerlings
and Lukas Biewald of CrowdFlower for making their service available to shared task participants, and
to Jonny Weese for editing and compiling the final proceedings.
</bodyText>
<page confidence="0.465861">
iii
</page>
<sectionHeader confidence="0.634715" genericHeader="abstract">
Organizers:
</sectionHeader>
<reference confidence="0.623562227272727">
Chris Callison-Burch, Johns Hopkins University
Mark Dredze, Johns Hopkins University
Program Committee:
Breck Baldwin, Alias-i, Inc.
Jordan Boyd-Graber, University of Maryland
Michael Bloodgood, Johns Hopkins University
Bob Carpenter, Alias-i, Inc.
David Chen, University of Texas, Austin
Maxine Eskenazi, Carnegie Mellon University
Nikesh Garera, Kosmix Corporation
Jim Glass, Massachusetts Institute of Technology
Alex Gruenstein, Google, Inc.
Janna Hamaker, Amazon.com, Inc.
Jon Hamaker, Microsoft Corporation
Samer Hassan, University of North Texas
Alexandre Klementiev, Johns Hopkins University
Benjamin Lambert, Carnegie Mellon University
Ben Leong, University of North Texas
Ian McGraw, Massachusetts Institute of Technology
Scott Novotney, Johns Hopkins University
Brendan O’Connor, Carnegie Mellon University
Gabriel Parent, Carnegie Mellon University
</reference>
<affiliation confidence="0.742886857142857">
Massimo Poesio, University of Essex
Joe Polifroni, Nokia Research Labs
Joseph Reisinger, University of Texas, Austin
Ted Sandler, Amazon.com, Inc.
Stephanie Seneff, Massachusetts Institute of Technology
Kevin Small, Tufts University
Rion Snow, Stanford University / Twitter, Inc.
</affiliation>
<page confidence="0.815365">
v
</page>
<tableCaption confidence="0.899635">
Table of Contents
</tableCaption>
<figure confidence="0.913248410526315">
Creating Speech and Language Data With Amazon’s Mechanical Turk
Chris Callison-Burch and Mark Dredze 1
Corpus Creation for New Genres: A Crowdsourced Approach to PP Attachment
Mukund Jha, Jacob Andreas, Kapil Thadani, Sara Rosenthal and Kathleen McKeown 13
Clustering dictionary definitions using Amazon Mechanical Turk
Gabriel Parent and Maxine Eskenazi 21
Semi-supervised Word Alignment with Mechanical Turk
Qin Gao and Stephan Vogel 30
Rating Computer-Generated Questions with Mechanical Turk
Michael Heilman and Noah A. Smith 35
Crowdsourced Accessibility: Elicitation of Wikipedia Articles
Scott Novotney and Chris Callison-Burch 41
Document Image Collection Using Amazon’s Mechanical Turk
Audrey Le, Jerome Ajot, Mark Przybocki and Stephanie Strassel 45
Using Amazon Mechanical Turk for Transcription of Non-Native Speech
Keelan Evanini, Derrick Higgins and Klaus Zechner 53
Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Col-
lected Using Amazon Mechanical Turk
Michael Denkowski and Alon Lavie 57
Can Crowds Build parallel corpora for Machine Translation Systems?
Vamshi Ambati and Stephan Vogel 62
Turker-Assisted Paraphrasing for English-Arabic Machine Translation
Michael Denkowski, Hassan Al-Haj and Alon Lavie 66
Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk
Nolan Lawson, Kevin Eustice, Mike Perkowitz and Meliha Yetisgen-Yildiz 71
Annotating Named Entities in Twitter Data with Crowdsourcing
Tim Finin, William Murnane, Anand Karandikar, Nicholas Keller, Justin Martineau and Mark
Dredze 80
MTurk Crowdsourcing: A Viable Method for Rapid Discovery of Arabic Nicknames?
Chiara Higgins, Elizabeth McGrath and Laila Moretto 89
An Enriched MT Grammar for Under $100
Omar F. Zaidan and Juri Ganitkevitch 93
vii
Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Sum-
marization
Matthew Marge, Satanjeev Banerjee and Alexander Rudnicky 99
Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages
Ann Irvine and Alexandre Klementiev 108
Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk
Bart Mellebeek, Francesc Benavent, Jens Grivolla, Joan Codina, Marta R. Costa-Juss`a and Rafael
Banchs 114
Crowdsourcing and language studies: the new generation of linguistic data
Robert Munro, Steven Bethard, Victor Kuperman, Vicky Tzuyin Lai, Robin Melnick, Christopher
Potts, Tyler Schnoebelen and Harry Tily 122
Not-So-Latent Dirichlet Allocation: Collapsed Gibbs Sampling Using Human Judgments
Jonathan Chang 131
Collecting Image Annotations Using Amazon’s Mechanical Turk
Cyrus Rashtchian, Peter Young, Micah Hodosh and Julia Hockenmaier 139
Non-Expert Evaluation of Summarization Systems is Risky
Dan Gillick and Yang Liu 148
Shedding (a Thousand Points of) Light on Biased Language
Tae Yano, Philip Resnik and Noah A. Smith 152
Evaluation of Commonsense Knowledge with Mechanical Turk
Jonathan Gordon, Benjamin Van Durme and Lenhart Schubert 159
Cheap Facts and Counter-Facts
Rui Wang and Chris Callison-Burch 163
The Wisdom of the Crowds Ear: Speech Accent Rating and Annotation with Amazon Mechanical Turk
Stephen Kunath and Steven Weinberger 168
Crowdsourcing Document Relevance Assessment with Mechanical Turk
Catherine Grady and Matthew Lease 172
Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named Entities
Meliha Yetisgen-Yildiz, Imre Solti, Fei Xia and Scott Halgrim 180
Tools for Collecting Speech Corpora via Mechanical-Turk
Ian Lane, Matthias Eck, Kay Rottmann and Alex Waibel 184
Measuring Transitivity Using Untrained Annotators
Nitin Madnani, Jordan Boyd-Graber and Philip Resnik 188
Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation
Cem Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea 195
viii
Non-Expert Correction of Automatically Generated Relation Annotations
Matthew R. Gormley, Adam Gerber, Mary Harper and Mark Dredze 204
Using Mechanical Turk to Build Machine Translation Evaluation Sets
Michael Bloodgood and Chris Callison-Burch 208
Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-
day Rush
Matteo Negri and Yashar Mehdad 212
Error Driven Paraphrase Annotation using Mechanical Turk
Olivia Buzek, Philip Resnik and Ben Bederson 217
ix
Workshop Program
Sunday, June 6, 2010
9:00 Morning Session
Creating Speech and Language Data With Amazon’s Mechanical Turk
Chris Callison-Burch and Mark Dredze
9:10 Invited Talk
10:10 Corpus Creation for New Genres: A Crowdsourced Approach to PP Attachment
Mukund Jha, Jacob Andreas, Kapil Thadani, Sara Rosenthal and Kathleen McKe-
own
10:30 Coffee Break
11:00 Poster Session 1
Clustering dictionary definitions using Amazon Mechanical Turk
Gabriel Parent and Maxine Eskenazi
Semi-supervised Word Alignment with Mechanical Turk
Qin Gao and Stephan Vogel
Rating Computer-Generated Questions with Mechanical Turk
</figure>
<reference confidence="0.529969">
Michael Heilman and Noah A. Smith
Crowdsourced Accessibility: Elicitation of Wikipedia Articles
Scott Novotney and Chris Callison-Burch
Document Image Collection Using Amazon’s Mechanical Turk
Audrey Le, Jerome Ajot, Mark Przybocki and Stephanie Strassel
Using Amazon Mechanical Turk for Transcription of Non-Native Speech
Keelan Evanini, Derrick Higgins and Klaus Zechner
Exploring Normalization Techniques for Human Judgments of Machine Translation
Adequacy Collected Using Amazon Mechanical Turk
Michael Denkowski and Alon Lavie
</reference>
<page confidence="0.499513">
xi
</page>
<note confidence="0.911715">
Sunday, June 6, 2010 (continued)
</note>
<reference confidence="0.791597034482759">
Can Crowds Build parallel corpora for Machine Translation Systems?
Vamshi Ambati and Stephan Vogel
Turker-Assisted Paraphrasing for English-Arabic Machine Translation
Michael Denkowski, Hassan Al-Haj and Alon Lavie
Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk
Nolan Lawson, Kevin Eustice, Mike Perkowitz and Meliha Yetisgen-Yildiz
Annotating Named Entities in Twitter Data with Crowdsourcing
Tim Finin, William Murnane, Anand Karandikar, Nicholas Keller, Justin Martineau and
Mark Dredze
MTurk Crowdsourcing: A Viable Method for Rapid Discovery of Arabic Nicknames?
Chiara Higgins, Elizabeth McGrath and Laila Moretto
An Enriched MT Grammar for Under $100
Omar F. Zaidan and Juri Ganitkevitch
12:30 Lunch
1:30 Afternoon Session 1
Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Ex-
tractive Summarization
Matthew Marge, Satanjeev Banerjee and Alexander Rudnicky
Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages
Ann Irvine and Alexandre Klementiev
Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Me-
chanical Turk
Bart Mellebeek, Francesc Benavent, Jens Grivolla, Joan Codina, Marta R. Costa-Juss`a and
Rafael Banchs
Crowdsourcing and language studies: the new generation of linguistic data
Robert Munro, Steven Bethard, Victor Kuperman, Vicky Tzuyin Lai, Robin Melnick,
Christopher Potts, Tyler Schnoebelen and Harry Tily
Not-So-Latent Dirichlet Allocation: Collapsed Gibbs Sampling Using Human Judgments
Jonathan Chang
</reference>
<page confidence="0.483864">
xii
</page>
<note confidence="0.67287">
Sunday, June 6, 2010 (continued)
</note>
<reference confidence="0.925828657894736">
3:10 Coffee Break
3:30 Afternoon Session 2
Collecting Image Annotations Using Amazon’s Mechanical Turk
Cyrus Rashtchian, Peter Young, Micah Hodosh and Julia Hockenmaier
Non-Expert Evaluation of Summarization Systems is Risky
Dan Gillick and Yang Liu
Shedding (a Thousand Points of) Light on Biased Language
Tae Yano, Philip Resnik and Noah A. Smith
4:30 Poster Session 2
Evaluation of Commonsense Knowledge with Mechanical Turk
Jonathan Gordon, Benjamin Van Durme and Lenhart Schubert
Cheap Facts and Counter-Facts
Rui Wang and Chris Callison-Burch
The Wisdom of the Crowds Ear: Speech Accent Rating and Annotation with Amazon Me-
chanical Turk
Stephen Kunath and Steven Weinberger
Crowdsourcing Document Relevance Assessment with Mechanical Turk
Catherine Grady and Matthew Lease
Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named
Entities
Meliha Yetisgen-Yildiz, Imre Solti, Fei Xia and Scott Halgrim
Tools for Collecting Speech Corpora via Mechanical-Turk
Ian Lane, Matthias Eck, Kay Rottmann and Alex Waibel
Measuring Transitivity Using Untrained Annotators
Nitin Madnani, Jordan Boyd-Graber and Philip Resnik
xiii
Sunday, June 6, 2010 (continued)
Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation
Cem Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea
Non-Expert Correction of Automatically Generated Relation Annotations
Matthew R. Gormley, Adam Gerber, Mary Harper and Mark Dredze
Using Mechanical Turk to Build Machine Translation Evaluation Sets
Michael Bloodgood and Chris Callison-Burch
Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk:
$100 for a 10-day Rush
Matteo Negri and Yashar Mehdad
Error Driven Paraphrase Annotation using Mechanical Turk
Olivia Buzek, Philip Resnik and Ben Bederson
</reference>
<page confidence="0.742794">
xiv
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.488299666666667">NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk Proceedings of the Workshop</note>
<date confidence="0.759995">June 6, 2010</date>
<note confidence="0.4712125">Los Angeles, California USB memory sticks produced by</note>
<affiliation confidence="0.946988">Omnipress Inc.</affiliation>
<address confidence="0.998648333333333">2600 Anderson Street Madison, WI 53707 USA</address>
<author confidence="0.816564">Generously Sponsored By</author>
<affiliation confidence="0.835059333333333">and The Association for Computational Linguistics Association for Computational Linguistics (ACL)</affiliation>
<address confidence="0.999392666666667">209 N. Eighth Street Stroudsburg, PA 18360 USA</address>
<phone confidence="0.9987815">Tel: +1-570-476-8006 Fax: +1-570-476-0860</phone>
<abstract confidence="0.931413482758621">acl@aclweb.org ii Preface The NAACL-2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk explores applications of crowdsourcing technologies for the creation and study of language data. Recent work has evaluated the effectiveness of using crowdsourcing platforms, such as Amazon’s Mechanical Turk, to create annotated data for natural language processing applications. This workshop further explores this area and these proceedings contain 34 papers and an overview paper that each experiment with applications of Mechanical Turk. The diversity of applications showcases the new possibilities for annotating speech and text, and has the potential to dramatically change how we create data for human language technologies. Papers in the workshop also looked at best practices in creating data using Mechanical Turk. Experiments evaluated how to design Human Intelligence Tasks (HITs), how to attract users to the task, how to price annotation tasks, and how to ensure data quality. Applications include the creation of data sets for standard NLP tasks, developing entirely new tasks, and investigating new ways of integrating user feedback in the learning process. The workshop featured an open-ended shared task in which 35 teams were awarded $100 of credit on Amazon Mechanical Turk to spend on an annotation task of their choosing. Results of the shared task are described in short papers and all collected data is publicly available. Shared task participants focused on data collection questions, such as how to convey complex tasks to non-experts, how to evaluate and ensure quality and annotation cost and speed. The organizers thank the workshop participants who contributed to an incredibly strong workshop program. We also thank the program committee for quickly reviewing the large number of submissions. Special thanks go to Sharon Chiarella, vice president of Amazon Mechanical Turk, for funding the shared task, Ted Sandler of Amazon for assistance in organizing the shared task, Stephanie Geerlings and Lukas Biewald of CrowdFlower for making their service available to shared task participants, and to Jonny Weese for editing and compiling the final proceedings. iii Organizers:</abstract>
<affiliation confidence="0.910420833333333">Chris Callison-Burch, Johns Hopkins University Mark Dredze, Johns Hopkins University Program Committee: Breck Baldwin, Alias-i, Inc. Jordan Boyd-Graber, University of Maryland Michael Bloodgood, Johns Hopkins University</affiliation>
<address confidence="0.538784">Bob Carpenter, Alias-i, Inc.</address>
<note confidence="0.506795">David Chen, University of Texas, Austin Maxine Eskenazi, Carnegie Mellon University Nikesh Garera, Kosmix Corporation Jim Glass, Massachusetts Institute of Technology Alex Gruenstein, Google, Inc. Janna Hamaker, Amazon.com, Inc. Jon Hamaker, Microsoft Corporation Samer Hassan, University of North Texas</note>
<affiliation confidence="0.806475">Alexandre Klementiev, Johns Hopkins University</affiliation>
<author confidence="0.78058">Benjamin Lambert</author>
<author confidence="0.78058">Carnegie Mellon University Ben Leong</author>
<author confidence="0.78058">University of North Texas</author>
<affiliation confidence="0.9302895">Ian McGraw, Massachusetts Institute of Technology Scott Novotney, Johns Hopkins University</affiliation>
<author confidence="0.763148666666667">Brendan O’Connor</author>
<author confidence="0.763148666666667">Carnegie Mellon University Gabriel Parent</author>
<author confidence="0.763148666666667">Carnegie Mellon University Massimo Poesio</author>
<author confidence="0.763148666666667">University of Essex</author>
<affiliation confidence="0.7650846">Joe Polifroni, Nokia Research Labs Joseph Reisinger, University of Texas, Austin Ted Sandler, Amazon.com, Inc. Stephanie Seneff, Massachusetts Institute of Technology Kevin Small, Tufts University</affiliation>
<address confidence="0.696857">Rion Snow, Stanford University / Twitter, Inc.</address>
<email confidence="0.92969">v</email>
<title confidence="0.5683475">Table of Contents Creating Speech and Language Data With Amazon’s Mechanical Turk Callison-Burch and Mark Dredze Corpus Creation for New Genres: A Crowdsourced Approach to PP Attachment Jha, Jacob Andreas, Kapil Thadani, Sara Rosenthal and Kathleen McKeown13 Clustering dictionary definitions using Amazon Mechanical Turk</title>
<author confidence="0.914058">Gabriel Parent</author>
<author confidence="0.914058">Maxine Eskenazi Semi-supervised Word Alignment with Mechanical Turk</author>
<note confidence="0.394401142857143">Gao and Stephan Vogel30 Rating Computer-Generated Questions with Mechanical Turk Heilman and Noah A. Smith35 Crowdsourced Accessibility: Elicitation of Wikipedia Articles Novotney and Chris Callison-Burch41 Document Image Collection Using Amazon’s Mechanical Turk Le, Jerome Ajot, Mark Przybocki and Stephanie Strassel45</note>
<title confidence="0.860205625">Using Amazon Mechanical Turk for Transcription of Non-Native Speech Keelan Evanini, Derrick Higgins and Klaus Zechner 53 Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected Using Amazon Mechanical Turk Michael Denkowski and Alon Lavie 57 Can Crowds Build parallel corpora for Machine Translation Systems? Ambati and Stephan Vogel62 Turker-Assisted Paraphrasing for English-Arabic Machine Translation</title>
<author confidence="0.6168655">Michael Denkowski</author>
<author confidence="0.6168655">Hassan Al-Haj</author>
<author confidence="0.6168655">Alon Lavie Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk</author>
<address confidence="0.422886">Lawson, Kevin Eustice, Mike Perkowitz and Meliha Yetisgen-Yildiz71</address>
<title confidence="0.991071">Annotating Named Entities in Twitter Data with Crowdsourcing</title>
<author confidence="0.904033">Tim Finin</author>
<author confidence="0.904033">William Murnane</author>
<author confidence="0.904033">Anand Karandikar</author>
<author confidence="0.904033">Nicholas Keller</author>
<author confidence="0.904033">Justin Martineau</author>
<author confidence="0.904033">Mark</author>
<note confidence="0.510292">Dredze 80 MTurk Crowdsourcing: A Viable Method for Rapid Discovery of Arabic Nicknames? Chiara Higgins, Elizabeth McGrath and Laila Moretto 89</note>
<title confidence="0.80353">Enriched MT Grammar for Under</title>
<author confidence="0.811143">Omar F Zaidan</author>
<author confidence="0.811143">Juri Ganitkevitch</author>
<email confidence="0.751345">vii</email>
<title confidence="0.9639665">Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Summarization</title>
<author confidence="0.76634">Matthew Marge</author>
<author confidence="0.76634">Satanjeev Banerjee</author>
<author confidence="0.76634">Alexander Rudnicky</author>
<title confidence="0.803624333333333">Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages Irvine and Alexandre Klementiev108 Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk</title>
<author confidence="0.798766">Bart Mellebeek</author>
<author confidence="0.798766">Francesc Benavent</author>
<author confidence="0.798766">Jens Grivolla</author>
<author confidence="0.798766">Joan Codina</author>
<author confidence="0.798766">Marta R Costa-Juss`a</author>
<author confidence="0.798766">Rafael</author>
<note confidence="0.468496">Banchs 114</note>
<title confidence="0.991724">Crowdsourcing and language studies: the new generation of linguistic data</title>
<author confidence="0.645358">Robert Munro</author>
<author confidence="0.645358">Steven Bethard</author>
<author confidence="0.645358">Victor Kuperman</author>
<author confidence="0.645358">Vicky Tzuyin Lai</author>
<author confidence="0.645358">Robin Melnick</author>
<author confidence="0.645358">Christopher Tyler Schnoebelen</author>
<author confidence="0.645358">Harry Tily Not-So-Latent Dirichlet Allocation Collapsed Gibbs Sampling Using Human Judgments</author>
<pubnum confidence="0.57425">Chang131</pubnum>
<title confidence="0.7647828">Collecting Image Annotations Using Amazon’s Mechanical Turk Rashtchian, Peter Young, Micah Hodosh and Julia Hockenmaier 139 Non-Expert Evaluation of Summarization Systems is Risky Gillick and Yang Liu148 Shedding (a Thousand Points of) Light on Biased Language</title>
<author confidence="0.902793">Philip Resnik Yano</author>
<author confidence="0.902793">Noah A Smith</author>
<affiliation confidence="0.904076">Evaluation of Commonsense Knowledge with Mechanical Turk</affiliation>
<address confidence="0.894671">Gordon, Benjamin Van Durme and Lenhart Schubert159</address>
<note confidence="0.665522">Cheap Facts and Counter-Facts Wang and Chris Callison-Burch163 The Wisdom of the Crowds Ear: Speech Accent Rating and Annotation with Amazon Mechanical Turk Kunath and Steven Weinberger168</note>
<title confidence="0.815035">Crowdsourcing Document Relevance Assessment with Mechanical Turk Grady and Matthew Lease 172 Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named Entities Yetisgen-Yildiz, Imre Solti, Fei Xia and Scott Halgrim 180 Tools for Collecting Speech Corpora via Mechanical-Turk Ian Lane, Matthias Eck, Kay Rottmann and Alex Waibel 184 Measuring Transitivity Using Untrained Annotators</title>
<author confidence="0.434367">Jordan Boyd-Graber Madnani</author>
<author confidence="0.434367">Philip Resnik</author>
<affiliation confidence="0.554965">Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation</affiliation>
<address confidence="0.694061">Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea 195</address>
<email confidence="0.678399">viii</email>
<title confidence="0.954443">Non-Expert Correction of Automatically Generated Relation Annotations</title>
<author confidence="0.767429">R Gormley</author>
<author confidence="0.767429">Adam Gerber</author>
<author confidence="0.767429">Mary Harper</author>
<author confidence="0.767429">Mark Dredze</author>
<title confidence="0.836469">Using Mechanical Turk to Build Machine Translation Evaluation Sets</title>
<note confidence="0.6430515">Bloodgood and Chris Callison-Burch208 a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: for a 10-</note>
<title confidence="0.554200666666667">day Rush Negri and Yashar Mehdad212 Error Driven Paraphrase Annotation using Mechanical Turk</title>
<author confidence="0.546855">Olivia Buzek</author>
<author confidence="0.546855">Philip Resnik</author>
<author confidence="0.546855">Ben Bederson</author>
<email confidence="0.886671">ix</email>
<note confidence="0.550669">Workshop Program Sunday, June 6, 2010</note>
<title confidence="0.9541135">Session Creating Speech and Language Data With Amazon’s Mechanical Turk</title>
<author confidence="0.995637">Chris Callison-Burch</author>
<author confidence="0.995637">Mark Dredze</author>
<address confidence="0.5185385">9:10 Invited Talk 10:10Corpus Creation for New Genres: A Crowdsourced Approach to PP Attachment</address>
<author confidence="0.774317">Mukund Jha</author>
<author confidence="0.774317">Jacob Andreas</author>
<author confidence="0.774317">Kapil Thadani</author>
<author confidence="0.774317">Sara Rosenthal</author>
<author confidence="0.774317">Kathleen McKe-</author>
<email confidence="0.745199">own</email>
<note confidence="0.874128">Break Session 1</note>
<title confidence="0.990305">Clustering dictionary definitions using Amazon Mechanical Turk</title>
<author confidence="0.86219">Gabriel Parent</author>
<author confidence="0.86219">Maxine Eskenazi Semi-supervised Word Alignment with Mechanical Turk Qin Gao</author>
<author confidence="0.86219">Stephan Vogel Rating Computer-Generated Questions with Mechanical Turk Michael Heilman</author>
<author confidence="0.86219">Noah A Smith</author>
<title confidence="0.602173">Crowdsourced Accessibility: Elicitation of Wikipedia Articles</title>
<author confidence="0.924083666666667">Scott Novotney</author>
<author confidence="0.924083666666667">Chris Callison-Burch Document Image Collection Using Amazon’s Mechanical Turk Audrey Le</author>
<author confidence="0.924083666666667">Jerome Ajot</author>
<author confidence="0.924083666666667">Mark Przybocki</author>
<author confidence="0.924083666666667">Stephanie Strassel</author>
<title confidence="0.86584025">Using Amazon Mechanical Turk for Transcription of Non-Native Speech Keelan Evanini, Derrick Higgins and Klaus Zechner Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected Using Amazon Mechanical Turk</title>
<author confidence="0.698442">Michael Denkowski</author>
<author confidence="0.698442">Alon Lavie xi</author>
<title confidence="0.6033045">Sunday, June 6, 2010 (continued) Can Crowds Build parallel corpora for Machine Translation Systems?</title>
<author confidence="0.644657">Vamshi Ambati</author>
<author confidence="0.644657">Stephan Vogel</author>
<title confidence="0.921052">Turker-Assisted Paraphrasing for English-Arabic Machine Translation</title>
<author confidence="0.804336">Michael Denkowski</author>
<author confidence="0.804336">Hassan Al-Haj</author>
<author confidence="0.804336">Alon Lavie</author>
<title confidence="0.753589333333333">Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk Nolan Lawson, Kevin Eustice, Mike Perkowitz and Meliha Yetisgen-Yildiz Annotating Named Entities in Twitter Data with Crowdsourcing</title>
<author confidence="0.970096">Tim Finin</author>
<author confidence="0.970096">William Murnane</author>
<author confidence="0.970096">Anand Karandikar</author>
<author confidence="0.970096">Nicholas Keller</author>
<author confidence="0.970096">Justin Martineau</author>
<author confidence="0.970096">Mark Dredze</author>
<title confidence="0.652656666666667">MTurk Crowdsourcing: A Viable Method for Rapid Discovery of Arabic Nicknames? Chiara Higgins, Elizabeth McGrath and Laila Moretto Enriched MT Grammar for Under</title>
<author confidence="0.975909">Omar F Zaidan</author>
<author confidence="0.975909">Juri Ganitkevitch</author>
<note confidence="0.909025">Session 1</note>
<title confidence="0.999564">Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Summarization</title>
<author confidence="0.979554">Matthew Marge</author>
<author confidence="0.979554">Satanjeev Banerjee</author>
<author confidence="0.979554">Alexander Rudnicky</author>
<title confidence="0.69000025">Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages Ann Irvine and Alexandre Klementiev Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk</title>
<author confidence="0.916436">Bart Mellebeek</author>
<author confidence="0.916436">Francesc Benavent</author>
<author confidence="0.916436">Jens Grivolla</author>
<author confidence="0.916436">Joan Codina</author>
<author confidence="0.916436">Marta R Costa-Juss`a</author>
<author confidence="0.916436">Rafael Banchs</author>
<title confidence="0.909102">Crowdsourcing and language studies: the new generation of linguistic data</title>
<author confidence="0.9827055">Robert Munro</author>
<author confidence="0.9827055">Steven Bethard</author>
<author confidence="0.9827055">Victor Kuperman</author>
<author confidence="0.9827055">Vicky Tzuyin Lai</author>
<author confidence="0.9827055">Robin Melnick</author>
<author confidence="0.9827055">Christopher Potts</author>
<author confidence="0.9827055">Tyler Schnoebelen</author>
<author confidence="0.9827055">Harry Tily</author>
<title confidence="0.751844">Not-So-Latent Dirichlet Allocation: Collapsed Gibbs Sampling Using Human Judgments</title>
<author confidence="0.999892">Jonathan Chang</author>
<email confidence="0.786177">xii</email>
<note confidence="0.575835">Sunday, June 6, 2010 (continued) Break Session 2</note>
<title confidence="0.996519">Collecting Image Annotations Using Amazon’s Mechanical Turk</title>
<author confidence="0.791532">Cyrus Rashtchian</author>
<author confidence="0.791532">Peter Young</author>
<author confidence="0.791532">Micah Hodosh</author>
<author confidence="0.791532">Julia Hockenmaier</author>
<title confidence="0.804723">Non-Expert Evaluation of Summarization Systems is Risky</title>
<author confidence="0.789672">Dan Gillick</author>
<author confidence="0.789672">Yang Liu</author>
<title confidence="0.856033">Shedding (a Thousand Points of) Light on Biased Language</title>
<author confidence="0.983154">Tae Yano</author>
<author confidence="0.983154">Philip Resnik</author>
<author confidence="0.983154">Noah A Smith</author>
<note confidence="0.36035">Session 2</note>
<title confidence="0.979048">Evaluation of Commonsense Knowledge with Mechanical Turk</title>
<author confidence="0.822362">Jonathan Gordon</author>
<author confidence="0.822362">Benjamin Van_Durme</author>
<author confidence="0.822362">Lenhart Schubert</author>
<title confidence="0.789471">Cheap Facts and Counter-Facts</title>
<author confidence="0.8293325">Rui Wang</author>
<author confidence="0.8293325">Chris Callison-Burch The Wisdom of the Crowds Ear Speech Accent Rating</author>
<author confidence="0.8293325">Annotation with Amazon Me-</author>
<title confidence="0.626551">chanical Turk</title>
<author confidence="0.963848">Stephen Kunath</author>
<author confidence="0.963848">Steven Weinberger Crowdsourcing Document Relevance Assessment with Mechanical Turk Catherine Grady</author>
<author confidence="0.963848">Matthew Lease</author>
<title confidence="0.81470825">Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named Entities Meliha Yetisgen-Yildiz, Imre Solti, Fei Xia and Scott Halgrim Tools for Collecting Speech Corpora via Mechanical-Turk</title>
<author confidence="0.946961">Ian Lane</author>
<author confidence="0.946961">Matthias Eck</author>
<author confidence="0.946961">Kay Rottmann</author>
<author confidence="0.946961">Alex Waibel</author>
<title confidence="0.991272">Measuring Transitivity Using Untrained Annotators</title>
<author confidence="0.990835">Nitin Madnani</author>
<author confidence="0.990835">Jordan Boyd-Graber</author>
<author confidence="0.990835">Philip Resnik</author>
<email confidence="0.806834">xiii</email>
<title confidence="0.81161">Sunday, June 6, 2010 (continued) Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation Cem Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea Non-Expert Correction of Automatically Generated Relation Annotations</title>
<author confidence="0.996974">Matthew R Gormley</author>
<author confidence="0.996974">Adam Gerber</author>
<author confidence="0.996974">Mary Harper</author>
<author confidence="0.996974">Mark Dredze</author>
<title confidence="0.981805">Using Mechanical Turk to Build Machine Translation Evaluation Sets</title>
<author confidence="0.916395">Michael Bloodgood</author>
<author confidence="0.916395">Chris Callison-Burch</author>
<title confidence="0.965326">Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: for a 10-day Rush</title>
<author confidence="0.910889666666667">Matteo Negri</author>
<author confidence="0.910889666666667">Yashar Mehdad Error Driven Paraphrase Annotation using Mechanical Turk Olivia Buzek</author>
<author confidence="0.910889666666667">Philip Resnik</author>
<author confidence="0.910889666666667">Ben Bederson</author>
<intro confidence="0.621028">xiv</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<institution>Johns Hopkins University Mark Dredze, Johns Hopkins University Program Committee: Breck Baldwin, Alias-i, Inc.</institution>
<marker>Callison-Burch, </marker>
<rawString>Chris Callison-Burch, Johns Hopkins University Mark Dredze, Johns Hopkins University Program Committee: Breck Baldwin, Alias-i, Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jordan Boyd-Graber</author>
</authors>
<publisher>Alias-i, Inc.</publisher>
<institution>University of Maryland Michael Bloodgood, Johns Hopkins University Bob Carpenter,</institution>
<marker>Boyd-Graber, </marker>
<rawString>Jordan Boyd-Graber, University of Maryland Michael Bloodgood, Johns Hopkins University Bob Carpenter, Alias-i, Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>David Chen</author>
</authors>
<institution>University of Texas, Austin Maxine Eskenazi, Carnegie Mellon University Nikesh Garera, Kosmix Corporation</institution>
<marker>Chen, </marker>
<rawString>David Chen, University of Texas, Austin Maxine Eskenazi, Carnegie Mellon University Nikesh Garera, Kosmix Corporation</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jim Glass</author>
</authors>
<institution>Massachusetts Institute of Technology Alex Gruenstein, Google, Inc.</institution>
<marker>Glass, </marker>
<rawString>Jim Glass, Massachusetts Institute of Technology Alex Gruenstein, Google, Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jon Hamaker</author>
</authors>
<institution>Microsoft Corporation Samer Hassan, University of North Texas Alexandre Klementiev, Johns Hopkins University</institution>
<marker>Hamaker, </marker>
<rawString>Janna Hamaker, Amazon.com, Inc. Jon Hamaker, Microsoft Corporation Samer Hassan, University of North Texas Alexandre Klementiev, Johns Hopkins University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Benjamin Lambert</author>
</authors>
<institution>Carnegie Mellon University Ben Leong, University of North Texas</institution>
<marker>Lambert, </marker>
<rawString>Benjamin Lambert, Carnegie Mellon University Ben Leong, University of North Texas</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ian McGraw</author>
</authors>
<institution>Massachusetts Institute of Technology Scott Novotney, Johns Hopkins University</institution>
<marker>McGraw, </marker>
<rawString>Ian McGraw, Massachusetts Institute of Technology Scott Novotney, Johns Hopkins University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brendan O’Connor</author>
</authors>
<institution>Carnegie Mellon University Gabriel Parent, Carnegie Mellon University</institution>
<marker>O’Connor, </marker>
<rawString>Brendan O’Connor, Carnegie Mellon University Gabriel Parent, Carnegie Mellon University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael Heilman</author>
<author>A Noah</author>
</authors>
<title>Smith Crowdsourced Accessibility: Elicitation of Wikipedia Articles Scott Novotney and Chris Callison-Burch</title>
<marker>Heilman, Noah, </marker>
<rawString>Michael Heilman and Noah A. Smith Crowdsourced Accessibility: Elicitation of Wikipedia Articles Scott Novotney and Chris Callison-Burch</rawString>
</citation>
<citation valid="false">
<title>Document Image Collection Using Amazon’s Mechanical Turk Audrey Le, Jerome Ajot, Mark Przybocki and Stephanie Strassel Using Amazon Mechanical Turk for Transcription of Non-Native Speech Keelan Evanini, Derrick Higgins and Klaus Zechner Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected Using Amazon Mechanical Turk Michael Denkowski and Alon Lavie</title>
<marker></marker>
<rawString>Document Image Collection Using Amazon’s Mechanical Turk Audrey Le, Jerome Ajot, Mark Przybocki and Stephanie Strassel Using Amazon Mechanical Turk for Transcription of Non-Native Speech Keelan Evanini, Derrick Higgins and Klaus Zechner Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected Using Amazon Mechanical Turk Michael Denkowski and Alon Lavie</rawString>
</citation>
<citation valid="false">
<authors>
<author>Can Crowds</author>
</authors>
<title>Build parallel corpora for Machine Translation Systems? Vamshi Ambati and Stephan Vogel Turker-Assisted Paraphrasing for English-Arabic Machine Translation Michael Denkowski, Hassan Al-Haj and Alon Lavie Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk</title>
<marker>Crowds, </marker>
<rawString>Can Crowds Build parallel corpora for Machine Translation Systems? Vamshi Ambati and Stephan Vogel Turker-Assisted Paraphrasing for English-Arabic Machine Translation Michael Denkowski, Hassan Al-Haj and Alon Lavie Annotating Large Email Datasets for Named Entity Recognition with Mechanical Turk</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nolan Lawson</author>
<author>Kevin Eustice</author>
</authors>
<title>Mike Perkowitz and Meliha Yetisgen-Yildiz Annotating Named Entities in Twitter Data with Crowdsourcing Tim Finin,</title>
<location>William Murnane, Anand Karandikar, Nicholas Keller, Justin</location>
<marker>Lawson, Eustice, </marker>
<rawString>Nolan Lawson, Kevin Eustice, Mike Perkowitz and Meliha Yetisgen-Yildiz Annotating Named Entities in Twitter Data with Crowdsourcing Tim Finin, William Murnane, Anand Karandikar, Nicholas Keller, Justin Martineau and Mark Dredze MTurk Crowdsourcing: A Viable Method for Rapid Discovery of Arabic Nicknames? Chiara Higgins, Elizabeth McGrath and Laila Moretto</rawString>
</citation>
<citation valid="false">
<title>An Enriched MT Grammar for Under $100 Omar F. Zaidan and</title>
<booktitle>Juri Ganitkevitch 12:30 Lunch 1:30 Afternoon Session 1 Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Summarization</booktitle>
<marker></marker>
<rawString>An Enriched MT Grammar for Under $100 Omar F. Zaidan and Juri Ganitkevitch 12:30 Lunch 1:30 Afternoon Session 1 Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Summarization</rawString>
</citation>
<citation valid="false">
<authors>
<author>Matthew Marge</author>
</authors>
<title>Satanjeev Banerjee and Alexander Rudnicky Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages Ann Irvine and Alexandre Klementiev Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk</title>
<marker>Marge, </marker>
<rawString>Matthew Marge, Satanjeev Banerjee and Alexander Rudnicky Using Mechanical Turk to Annotate Lexicons for Less Commonly Used Languages Ann Irvine and Alexandre Klementiev Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bart Mellebeek</author>
<author>Francesc Benavent</author>
<author>Jens Grivolla</author>
<author>Joan Codina</author>
<author>R Marta</author>
</authors>
<title>Costa-Juss`a and Rafael Banchs Crowdsourcing and language studies: the new generation of linguistic data</title>
<marker>Mellebeek, Benavent, Grivolla, Codina, Marta, </marker>
<rawString>Bart Mellebeek, Francesc Benavent, Jens Grivolla, Joan Codina, Marta R. Costa-Juss`a and Rafael Banchs Crowdsourcing and language studies: the new generation of linguistic data Robert Munro, Steven Bethard, Victor Kuperman, Vicky Tzuyin Lai, Robin Melnick, Christopher Potts, Tyler Schnoebelen and Harry Tily</rawString>
</citation>
<citation valid="false">
<authors>
<author>Not-So-Latent Dirichlet</author>
</authors>
<title>Allocation: Collapsed Gibbs Sampling Using Human Judgments Jonathan Chang</title>
<marker>Dirichlet, </marker>
<rawString>Not-So-Latent Dirichlet Allocation: Collapsed Gibbs Sampling Using Human Judgments Jonathan Chang</rawString>
</citation>
<citation valid="false">
<title>Break 3:30 Afternoon Session 2 Collecting Image Annotations Using Amazon’s Mechanical Turk Cyrus Rashtchian, Peter Young, Micah Hodosh and Julia Hockenmaier Non-Expert Evaluation of Summarization Systems is Risky Dan Gillick and Yang Liu</title>
<marker></marker>
<rawString>3:10 Coffee Break 3:30 Afternoon Session 2 Collecting Image Annotations Using Amazon’s Mechanical Turk Cyrus Rashtchian, Peter Young, Micah Hodosh and Julia Hockenmaier Non-Expert Evaluation of Summarization Systems is Risky Dan Gillick and Yang Liu</rawString>
</citation>
<citation valid="false">
<title>Shedding (a Thousand Points of) Light on Biased Language Tae Yano, Philip Resnik and Noah A. Smith Evaluation of Commonsense Knowledge with Mechanical Turk Jonathan Gordon, Benjamin Van Durme and Lenhart Schubert Cheap Facts and Counter-Facts</title>
<marker></marker>
<rawString>Shedding (a Thousand Points of) Light on Biased Language Tae Yano, Philip Resnik and Noah A. Smith Evaluation of Commonsense Knowledge with Mechanical Turk Jonathan Gordon, Benjamin Van Durme and Lenhart Schubert Cheap Facts and Counter-Facts</rawString>
</citation>
<citation valid="false">
<authors>
<author>Rui Wang</author>
<author>Chris</author>
</authors>
<title>Callison-Burch The Wisdom of the Crowds Ear: Speech Accent Rating and Annotation with Amazon Mechanical Turk</title>
<marker>Wang, Chris, </marker>
<rawString>Rui Wang and Chris Callison-Burch The Wisdom of the Crowds Ear: Speech Accent Rating and Annotation with Amazon Mechanical Turk</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stephen Kunath</author>
<author>Steven Weinberger</author>
</authors>
<title>Crowdsourcing Document Relevance Assessment with Mechanical Turk Catherine Grady and Matthew Lease</title>
<marker>Kunath, Weinberger, </marker>
<rawString>Stephen Kunath and Steven Weinberger Crowdsourcing Document Relevance Assessment with Mechanical Turk Catherine Grady and Matthew Lease</rawString>
</citation>
<citation valid="false">
<title>Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named Entities</title>
<marker></marker>
<rawString>Preliminary Experiments with Amazon’s Mechanical Turk for Annotating Medical Named Entities</rawString>
</citation>
<citation valid="false">
<authors>
<author>Meliha Yetisgen-Yildiz</author>
</authors>
<title>Imre Solti, Fei Xia and Scott Halgrim Tools for Collecting Speech Corpora via Mechanical-Turk Ian Lane, Matthias Eck, Kay Rottmann and Alex Waibel Measuring Transitivity Using Untrained Annotators Nitin Madnani, Jordan Boyd-Graber and Philip Resnik xiii</title>
<marker>Yetisgen-Yildiz, </marker>
<rawString>Meliha Yetisgen-Yildiz, Imre Solti, Fei Xia and Scott Halgrim Tools for Collecting Speech Corpora via Mechanical-Turk Ian Lane, Matthias Eck, Kay Rottmann and Alex Waibel Measuring Transitivity Using Untrained Annotators Nitin Madnani, Jordan Boyd-Graber and Philip Resnik xiii</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sunday</author>
</authors>
<title>(continued) Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation Cem Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea Non-Expert Correction of Automatically Generated Relation Annotations</title>
<date>2010</date>
<location>Rush</location>
<marker>Sunday, 2010</marker>
<rawString>Sunday, June 6, 2010 (continued) Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation Cem Akkaya, Alexander Conrad, Janyce Wiebe and Rada Mihalcea Non-Expert Correction of Automatically Generated Relation Annotations Matthew R. Gormley, Adam Gerber, Mary Harper and Mark Dredze Using Mechanical Turk to Build Machine Translation Evaluation Sets Michael Bloodgood and Chris Callison-Burch Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-day Rush</rawString>
</citation>
<citation valid="false">
<authors>
<author>Matteo Negri</author>
</authors>
<title>and Yashar Mehdad Error Driven Paraphrase Annotation using Mechanical Turk Olivia Buzek, Philip Resnik and Ben Bederson</title>
<marker>Negri, </marker>
<rawString>Matteo Negri and Yashar Mehdad Error Driven Paraphrase Annotation using Mechanical Turk Olivia Buzek, Philip Resnik and Ben Bederson</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>