<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.844982" genericHeader="method">
COMMONSENSE METAPHYSICS
AND LEXICAL SEMANTICS
</sectionHeader>
<author confidence="0.7243975">
Jerry R. Hobbs, William Croft, Todd Davies,
Douglas Edwards, and Kenneth Laws
</author>
<sectionHeader confidence="0.682772666666667" genericHeader="method">
Artificial Intelligence Center
SRI International
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956274509804">
In the TACITUS project for using commonsense knowl-
edge in the understanding of texts about mechanical de-
vices and their failures, we have been developing various
commonsense theories that are needed to mediate between
the way we talk about the behavior of such devices and
causal models of their operation. Of central importance in
this effort is the axiomatization of what might be called
&amp;quot;commonsense metaphysics&amp;quot;. This includes a number of
areas that figure in virtually every domain of discourse,
such as scalar notions, granularity, time, space, material,
physical objects, causality, functionality, force, and shape.
Our approach to lexical semantics is then to construct core
theories of each of these areas, and then to define, or at
least characterize, a large number of lexical items in terms
provided by the core theories. In the TACITUS system,
processes for solving pragmatics problems posed by a text
will use the knowledge base consisting of these theories in
conjunction with the logical forms of the sentences in the
text to produce an interpretation. In this paper we do
not stress these interpretation processes; this is another,
important aspect of the TACITUS project, and it will be
described in subsequent papers.
This work represents a convergence of research in lexical
semantics in linguistics and efforts in AI to encode com-
monsense knowledge. Lexical semanticists over the years
have developed formalisms of increasing adequacy for en-
coding word meaning, progressing from simple sets of fea-
tures (Katz and Fodor, 1963) to notations for predicate-
argument structure (Lakoff, 1972; Miller and Johnson-
Laird, 1976), but the early attempts still limited access
to world knowledge and assumed only very restricted sorts
of processing. Workers in computational linguistics intro-
duced inference (Rieger, 1974; Schank, 1975) and other
complex cognitive processes (Herskovits, 1982) into our
understanding of the role of word meaning. Recently, lin-
guists have given greater attention to the cognitive pro-
cesses that would operate on their representations (e.g.,
Talmy, 1983; Croft, 1986). Independently, in AI an ef-
fort arose to encode large amounts of commonsense knowl-
edge (Hayes, 1979; Hobbs and Moore, 1985; Hobbs et al.
1985). The research reported here represents a conver-
gence of these various developments. By developing core
theories of several fundamental phenomena and defining
lexical items within these theories, using the full power
of predicate calculus, we are able to cope with complex-
ities of word meaning that have hitherto escaped lexical
semanticists, within a framework that gives full scope to
the planning and reasoning processes that manipulate rep-
resentations of word meaning.
In constructing the core theories we are attempting to
adhere to several methodological principles.
</bodyText>
<listItem confidence="0.953137607142857">
1. One should aim for characterization of concepts,
rather than definition. One cannot generally expect to find
necessary and sufficient conditions for a concept. The most
we can hope for is to find a number of necessary condi-
tions and a number of sufficient conditions. This amounts
to saying that a great many predicates are primitive, but
primitives that are highly interrelated with the rest of the
knowledge base.
2. One should determine the minimal structure neces-
sary for a concept to make sense. In efforts to axiomatize
some area, there are two positions one may take, exem-
plified by set theory and by group theory. In axiomatiz-
ing set theory, one attempts to capture exactly some con-
cept one has strong intuitions about. If the axiomatization
turns out to have unexpected models, this exposes an in-
adequacy. In group theory, by contrast, one characterizes
an abstract class of structures. If there turn out to be
unexpected models, this is a serendipitous discovery of a
new phenomenon that we can reason about using an old
theory. The pervasive character of metaphor in natural
language discourse shows that our commonsense theories
of the world ought to be much more like group theory than
set theory. By seeking minimal structures in axiomatizing
concepts, we optimize the possibilities of using the theories
in metaphorical and analogical contexts. This principle
is illustrated below in the section on regions. One conse-
quence of this principle is that our approach will seem more
syntactic than semantic. We have concentrated more on
</listItem>
<page confidence="0.996633">
231
</page>
<bodyText confidence="0.999869">
specifying axioms than on constructing models. Our view
is that the chief role of models in our effort is for proving
the consistency and independence of sets of axioms, and for
showing their adequacy. As an example of the last point,
many of the spatial and temporal theories we construct
are intended at least to have Euclidean space or the real
numbers as one model, and a subclass of graph-theoretical
structures as other models.
</bodyText>
<listItem confidence="0.820528021276596">
3. A balance must be struck between attempting to
cover all cases and aiming only for the prototypical cases.
In general, we have tried to cover as many cases as pos-
sible with an elegant axiomatization, in line with the two
previous principles, but where the formalization begins to
look baroque, we assume that higher processes will suspend
some inferences in the marginal cases. We assume that in-
ferences will be drawn in a controlled fashion. Thus, every
outré, highly context-dependent counterexample need not
be accounted for, and to a certain extent, definitions can
be geared specifically for a prototype.
4. Where competing ontologies suggest themselves in a
domain, one should attempt to construct a theory that ac-
commodates both. Rather than commit oneself to adopt-
ing one set of primitives rather than another, one should
show how each set of primitives can be characterized in
terms of the other. Generally, each of the ontologies is
useful for different purposes, and it is convenient to be
able to appeal to both. Our treatment of time illustrates
this.
5. The theories one constructs should be richer in axioms
than in theorems. In mathematics, one expects to state
half a dozen axioms and prove dozens of theorems from
them. In encoding commonsense knowledge it seems to be
just the opposite. The theorems we seek to prove on the
basis of these axioms are theorems about specific situations
which are to be interpreted, in particular, theorems about
a text that the system is attempting to understand.
6. One should avoid falling into &amp;quot;black holes&amp;quot;. There
are a few &amp;quot;mysterious&amp;quot; concepts which crop up repeatedly
in the formalization of commonsense metaphysics. Among
these are &amp;quot;relevant&amp;quot; (that is, relevant to the task at hand)
and &amp;quot;normative&amp;quot; (or conforming to some norm or pattern).
To insist upon giving a satisfactory analysis of these before
using them in analyzing other concepts is to cross the event
horizon that separates lexical semantics from philosophy.
On the other hand, our experience suggests that to avoid
their use entirely is crippling; the lexical semantics of a
wide variety of other terms depends upon them. Instead,
we have decided to leave them minimally analyzed for the
moment and use them without scruple in the analysis of
other commonsense concepts. This approach will allow us
to accumulate many examples of the use of these mysteri-
ous concepts, and in the end, contribute to their success-
ful analysis. The use of these concepts appears below in
the discussions of the words &amp;quot;immediately&amp;quot;, &amp;quot;sample&amp;quot;, and
&amp;quot;operate&amp;quot;.
</listItem>
<bodyText confidence="0.99993580952381">
We chose as an initial target problem to encode the com-
monsense knowledge that underlies the concept of &amp;quot;wear&amp;quot;,
as in a part of a device wearing out. Our aim was to define
&amp;quot;wear&amp;quot; in terms of predicates characterized elsewhere in
the knowledge base and to infer consequences of wear. For
something to wear, we decided, is for it to lose impercepti-
ble bits of material from its surface due to abrasive action
over time. One goal,which we have not yet achieved, is to
be able to prove as a theorem that since the shape of a part
of a mechanical device is often functional and since loss of
material can result in a change of shape, wear of a part of
a device can result in the failure of the device as a whole.
In addition, as we have proceded, we have characterized a
number of words found in a set of target texts, as it has
become possible.
We are encoding the knowledge as axioms in what is
for the most part a first-order logic, described in Hobbs
(1985a), although quantification over predicates is some-
times convenient. In the formalism there is a nominaliza-
tion operator &amp;quot; &apos; &amp;quot; for reifying events and conditions, as
expressed in the following axiom schema:
</bodyText>
<equation confidence="0.974846">
(V x)p(x) (3 e)ps (e, z) A Exist(e)
</equation>
<bodyText confidence="0.924142142857143">
That is, p is true of x if and only if there is a condition e
of p being true of x and e exists in the real world.
In our implementation so far, we have been proving sim-
ple theorems from our axioms using the CG5 theorem-
prover developed by Mark Stickel (1982), but we are only
now beginning to use the knowledge base in text process-
ing.
</bodyText>
<sectionHeader confidence="0.8209565" genericHeader="method">
2 Requirements on Arguments of
Predicates
</sectionHeader>
<bodyText confidence="0.957387714285714">
There is a notational convention used below that deserves
some explanation. It has frequently been noted that re-
lational words in natural language can take only certain
types of words as their arguments. These are usually de-
scribed as selectional constraints. The same is true of pred-
icates in our knowledge base. They are expressed below by
rules of the form
</bodyText>
<equation confidence="0.876447">
p(x, y) : r(x , y)
</equation>
<bodyText confidence="0.9725405">
This means that for p even to make sense applied to x and
y, it must be the case that r is true of x and y. The logical
import of this rule is that wherever there is an axiom of
the form
</bodyText>
<equation confidence="0.895113333333333">
(V x, y)p(x, y) j q(x, y)
this is really to be read as
(V x, y)p(x, y) A r(x, y) j q(x, y)
</equation>
<page confidence="0.971465">
232
</page>
<bodyText confidence="0.986105166666667">
The checking of selectional constraints, therefore, falls out
as a by-product of other logical operations: the constraint
r(x, y) must be verified if anything else is to be proven from
P(x, y).
The simplest example of such an r(x, y) is a conjunction
of sort constraints r1(x) A r2(y). Our approach is a gener-
alization of this, because much more complex requirements
can be placed on the arguments. Consider, for example,
the verb &amp;quot;range&amp;quot;. If x ranges from y to z, there must be
a scale s that includes y and z, and x must be a set of en-
tities that are located at various places on the scale: This
can be represented as follows:
</bodyText>
<equation confidence="0.553009333333333">
range(x, y, z) : (3 s)scale(s) A yEs
AzEs A set(x)
A (V u)lu E x D (3 v)v E s A at(ti, v)]
</equation>
<sectionHeader confidence="0.998163" genericHeader="method">
3 The Knowledge Base
</sectionHeader>
<subsectionHeader confidence="0.99983">
3.1 Sets and Granularity
</subsectionHeader>
<bodyText confidence="0.9987165">
At the foundation of the knowledge base is an axiomatiza-
tion of set theory. It follows the standard Zermelo-Frankel
approach, except that there is no Axiom of Infinity.
Since so many concepts used in discourse are grain-
dependent, a theory of granularity is also fundamental (see
Hobbs 1985b). A grain is defined in terms of an indistin-
guishability relation, which is reflexive and symmetric, but
not necessarily transitive. One grain can be a refinement
of another with the obvious definition. The most refined
grain is the identity grain, i.e., the one in which every two
distinct elements are distinguishable. One possible rela-
tionship between two grains, one of which is a refinement
of the other, is what we call an &amp;quot;Archimedean relation&amp;quot;,
after the Archimedean property of real numbers. Intu-
itively, if enough events occur that are imperceptible at the
coarser grain g2 but perceptible at the finer grain g1, then
the aggregate will eventually be perceptible at the coarser
grain. This is an important property in phenomena sub-
ject to the Heap Paradox. Wear, for instance, eventually
has significant consequences.
</bodyText>
<subsectionHeader confidence="0.999641">
3.2 Scales
</subsectionHeader>
<bodyText confidence="0.9814625">
A great many of the most common words in English have
scales as their subject matter. This includes many preposi-
tions, the most common adverbs, comparatives, and many
abstract verbs. When spatial vocabulary is used metaphor-
ically, it is generally the scalar aspect of space that carries
over to the target domain. A scale is defined as a set of
elements, together with a partial ordering and a granular-
ity (or an indistinguishability relation). The partial or-
dering and the indistinguishability relation are consistent
with each other:
(Vx,y,z)x&lt;y A y,,,z Dx&lt;zvxz
It is useful to have an adjacency relation between points on
a scale, and there are a number of ways we could introduce
it. We could simply take it to be primitive; in a scale
having a distance function, we could define two points to
be adjacent when the distance between them is less than
some c; finally, we could define adjacency in terms of the
grain-size:
</bodyText>
<equation confidence="0.9937005">
(V x, y, s)adj(x,y, s)
(3 z)z,--xAz—yA—[x,—y],
</equation>
<bodyText confidence="0.997003">
Two important possible properties of scales are connect-
edness and denseness. We can say that two elements of a
scale are connected by a chain of adj relations:
</bodyText>
<equation confidence="0.988442">
(Vx, y, s)connected(x, y, s)
adj(z, y, s) V
(3 z)adj(x, z, s) A connected(z ,y, s)
</equation>
<bodyText confidence="0.999152428571429">
A scale is connected (sconnected) if all pairs of elements
are connected. A scale is dense if between any two points
there is a third point, until the two points are so close
together that the grain-size won&apos;t let us tell what the situ-
ation is. Cranking up the magnification could well resolve
the continuous space into a discrete set, as objects into
atoms.
</bodyText>
<equation confidence="0.9997435">
(V s)dense(s)
(Vz, y, &lt;)x Es A yEs A order(&lt;, s) A x y
D (3 z)(z&lt;zAz&lt;y)
V (3 z)(x.,,,z Az,,y)
</equation>
<bodyText confidence="0.99725825">
This captures the commonsense notion of continuity.
A subscale of a scale has as its elements a subset of the
elements of the scale and has as its partial ordering and its
grain the partial ordering and the grain of the scale.
</bodyText>
<equation confidence="0.950161333333333">
(V81, &lt;, .--)order(&lt;, Si) A grain(,,,, Si)
D 82)1sub8cale(s2, si)
8ubset(82, si) A order(&lt;, Si) A grain(, s2)]
An interval can be defined as a connected subscale:
(V Ointerval(i) (3 s)scale(s)
A sub8cale(i, s) A sconnected(i)
</equation>
<bodyText confidence="0.99992675">
The relations between time intervals that Allen and
Kautz (1985) have defined can be defined in a straight-
forward manner in the approach presented here, applied
to intervals in general.
A concept closely related to scales is that of a &amp;quot;cycle&amp;quot;.
This is a system which has a natural ordering locally but
contains a loop globally. Examples include the color wheel,
clock times, and geographical locations ordered by &amp;quot;east
of&amp;quot;. We have axiomatized cycles i:t terms of a ternary
between relation, whose axioms parallel the axioms for a
partial ordering.
The figure-ground relationship is of fundamental impor-
tance in language. We encode this with the primitive pred-
icate at. The minimal structure that seems to be necessary
for something to be a ground is that of a scale; hence, this
is a selectional constraint on the arguments of at.
</bodyText>
<page confidence="0.946313">
233
</page>
<equation confidence="0.751471">
at(r, y) : (3 s)y E s A scale(s)
</equation>
<bodyText confidence="0.996890333333333">
At this point, we are already in a position to define some
fairly complex words. As an illustration, we give the ex-
ample of &amp;quot;range&amp;quot; as in &amp;quot;x ranges from y to z&amp;quot;:
</bodyText>
<equation confidence="0.945251">
(Vz, y, z)range(x, y, z)
(3 s,si,ui, u2)scale(s) A subscale(si, s)
A bottom(y, si) A top(z, si)
A ul E x A at(ui, y)
A u2 E X A at(u2, z)
A (V u)[u E x j (3 v)v Esi A at(u, v)1
</equation>
<bodyText confidence="0.999636387096774">
A very important scale is the linearly ordered scale of
numbers. We do not plan to reason axiomatically about
numbers, but it is useful in natural language processing to
have encoded a few facts about numbers. For example, a
set has a cardinality which is an element of the number
scale.
Verticality is a concept that would be most properly an-
alyzed in the section on space, but it is a property that
many other scales have acquired metaphorically, for what-
ever reason. The number scale is one of these. Even in the
absence of an analysis of verticality, it is a useful property
to have as a primitive in lexical semantics.
The word &amp;quot;high&amp;quot; is a vague term that asserts an entity is
in the upper region of some scale. It requires that the scale
be a vertical one, such as the number scale. The vertical-
ity requirement distinguishes &amp;quot;high&amp;quot; from the more gen-
eral term &amp;quot;very&amp;quot;; we can say &amp;quot;very hard&amp;quot; but not &amp;quot;highly
hard&amp;quot;. The phrase &amp;quot;highly planar&amp;quot; sounds all right be-
cause the high register of &amp;quot;planar&amp;quot; suggests a quantifiable,
scientific accuracy, whereas the low register of &amp;quot;flat&amp;quot; makes
&amp;quot;highly flat&amp;quot; sound much worse.
The test of any definition is whether it allows one to draw
the appropriate inferences. In our target texts, the phrase
&amp;quot;high usage&amp;quot; occurs. Usage is a set of using events, and the
verticality requirement on &amp;quot;high&amp;quot; forces us to coerce the
phrase into &amp;quot;a high or large number of using events&amp;quot;. Com-
bining this with an axiom that says that the use of a me-
chanical device involves the likelihood of abrasive events,
as defined below, and with the definition of &amp;quot;wear&amp;quot; in terms
of abrasive events, we should be able to conclude the like-
lihood of wear.
</bodyText>
<subsectionHeader confidence="0.999322">
3.3 Time: Two Ontologies
</subsectionHeader>
<bodyText confidence="0.9999122">
There are two possible ontologies for time. In the first, the
one most acceptable to the mathematically minded, there
is a time line, which is a scale having some topological
structure. We can stipulate the time line to be linearly
ordered (although it is not in approaches that build ig-
norance of relative times into the representation of time
(e.g., Hobbs, 1974) nor in approaches using branching fu-
tures (e.g., McDermott, 1985)), and we can stipulate it to
be dense (although it is not in the situation calculus). We
take before to be the ordering on the time line:
</bodyText>
<equation confidence="0.997080333333333">
(V ti,t2)before(li tz)
(3 T, &lt;)Time-line(T) A order(&lt;, T)
A E T A 12 E T A 11 &lt;12
</equation>
<bodyText confidence="0.993457193548387">
We allow both instants and intervals of time. Most events
occur at some instant or during some interval. In this
approach, nearly every predicate takes a time argument.
In the second ontology, the one that seems to be more
deeply rooted in language, the world consists of a large
number of more or less independent processes, or histories,
or sequences of events. There is a primitive relation change
between conditions. Thus,
change(ei , e2) A pi (ei , x) A qqe2, x)
says that there is a change from the condition el of p being
true of x to the condition e2 of q being true of x.
The time line in this ontology is then an artificial con-
struct, a regular sequence of imagined abstract events—
think of them as ticks of a clock in the National Bureau
of Standards—to which other events can be related. The
change ontology seems to correspond to the way we ex-
perience the world. We recognize relations of causality,
change of state, and copresence among events and condi-
tions. When events are not related in these ways, judg-
ments of relative time must be mediated by copresence
relations between the events and events on a clock and
change of state relations on the clock.
The predicate change possesses a limited transitivity.
There has been a change from Reagan being an actor to
Reagan being President, even though he was governor in
between. But we probably do not want to say there has
been a change from Reagan being an actor to Margaret
Thatcher being Prime Minister, even though the second
comes after the first.
We can say that times, viewed in this ontology as events,
always have a change relation between them.
</bodyText>
<equation confidence="0.8412772">
(V ti,12)bef ore (1k, 12) D change(t , 12)
The predicate change is related to before by the axiom
(V e1, e2)change(e1, e2) D
(3 ti,12)at(ei, t)
A at(e2, t2) A be f ore(11, l2)
</equation>
<bodyText confidence="0.9812325">
This does not allow us to derive change of state from tem-
poral succession. For this, we need axioms of the form
</bodyText>
<equation confidence="0.795136333333333">
(V , e2, 11,12, x)p&apos; (ei, x) A at(ei , t)
A q&apos; (e2, x) A at(e2, 12) A be! ore(ti, 12)
D change(ci, ez)
</equation>
<bodyText confidence="0.7448444">
That is, if x is p at time ti and q at a later time 12, then
there has been a change of state from one to the other.
Time arguments in predications can be viewed as abbrevi-
ations:
x, t)p(x, t) (3 e)p&apos;(e, x) A at(e, t)
</bodyText>
<page confidence="0.986714">
234
</page>
<bodyText confidence="0.999275">
The word &amp;quot;move&amp;quot;, or the predicate move, (as in &amp;quot;x
moves from y to z&amp;quot;) can then be defined equivalently in
terms of change
</bodyText>
<equation confidence="0.971584333333333">
(V x, y, z)move(x, y, z)
(3 el, e2)change(ei, e2)
A at&apos;(e1x, y) A at&apos; (e2, x, z)
or in terms of the time line
(V x, y, z)move(x, y, z)
(3 t1, t2)at(x, y,11) A at(x , z,12) A be f ore(ti,t2)
</equation>
<bodyText confidence="0.989219678571429">
In English and apparently all other natural languages,
both ontologies are represented in the lexicon. The time
line ontology is found in clock and calendar terms, tense
systems of verbs, and in the deictic temporal locatives such
as &amp;quot;yesterday&amp;quot;, &amp;quot;today&amp;quot;, &amp;quot;tomorrow&amp;quot;, &amp;quot;last night&amp;quot;, and so
on. The change ontology is exhibited in most verbs, and
in temporal clausal connectives. The universal presence
of both classes of lexical items and grammatical mark-
ers in natural languages requires a theory which can ac-
commodate both ontologies, illustrating the importance of
methodological principle 4.
Among temporal connectives, the word &amp;quot;while&amp;quot; presents
interesting problems. In &amp;quot;e1 while e2&amp;quot;, e2 must be an event
occurring over a time interval; el must be an event and
may occur either at a point or over an interval. One&apos;s first
guess is that the point or interval for el must be included
in the interval for e2. However, there are cases, such as
It rained while I was in Philadelphia.
Or
The electricity should be off while the switch is
being repaired.
which suggest the reading &amp;quot;e2 is included in el&amp;quot;. We came
to the conclusion that one can infer no more than that
el and e2 overlap, and any tighter constraints result from
implicatures from background knowledge.
The word &amp;quot;immediately&amp;quot; also presents a number of prob-
lems. It requires its argument e to be an ordering relation
between two entities x and y on some scale s.
</bodyText>
<equation confidence="0.981663">
immediate(e) : (3 x, y, s)less-t han&apos; (e, x, y, s)
</equation>
<bodyText confidence="0.867689714285714">
It is not clear what the constraints on the scale are. Tem-
poral and spatial scales are okay, as in &amp;quot;immediately after
the alarm&amp;quot; and &amp;quot;immediately to the left&amp;quot;, but the size scale
isn&apos;t:
* John is immediately larger than Bill.
Etymologically, it means that there are no intermediate
entities between x and y on s. Thus,
</bodyText>
<construct confidence="0.6094045">
(Ye, x, y,$)immediate(e) A less-than&apos; (e, x, y, s)
z)less-than(x, z, s) A less-t han(z , y, s)
</construct>
<figureCaption confidence="0.999807">
Figure 1: The simplest space.
</figureCaption>
<bodyText confidence="0.998378428571429">
However, this will only work if we restrict z to be a relevant
entity. For example, in the sentence
We disengaged the compressor immediately after
the alarm.
the implication is that no event that could damage the
compressor occurred between the alarm and the disengage-
ment, since the text is about equipment failure.
</bodyText>
<subsectionHeader confidence="0.8877685">
3.4 Spaces and Dimension: The Minimal
Structure
</subsectionHeader>
<bodyText confidence="0.9998808">
The notion of dimension has been made precise in linear al-
gebra. Since the concept of a region is used metaphorically
as well as in the spatial sense, however, we were concerned
to determine the minimal structure that a system requires
for it to make sense to call it a space of more than one
dimension. For a two-dimensional space, tl-,Te must be a
scale, or partial ordering, for each dimension. Moreover,
the two scales must be independent, in that the order of
elements on one scale can not be determined from their
order on the other. Formally,
</bodyText>
<equation confidence="0.964098">
(V 813)812888(8p) -a:-
(3 81, 82, &lt;1, &lt;2)scalei(s 1, sp) A 8ca1e2(82, sp)
A order(&lt;1, si) A order(&lt;2, 82)
A (3 x)(3 Yi)(x &lt;1 Yi Ax &lt;2 Y1)
A (3 Y2)(x &lt;1 Y2 A 112&lt;2 x)
</equation>
<bodyText confidence="0.967778214285714">
Note that this does not allow &lt;2 to be simply the reverse of
&lt;1. An unsurprising consequence of this definition is that
the minimal example of a two-dimensional space consists
of three points (three points determine a plane), e.g., the
points A, B, and C, where
A &lt;1 B, A &lt;IC, C &lt;2 A, A &lt;2 B.
This is illustrated in Figure 1.
The dimensional scales are apparently found in all nat-
ural languages in relevant domains. The familiar three-
dimensional space of common sense is defined by the three
scale pairs &amp;quot;up-down&amp;quot;, &amp;quot;front-back&amp;quot;, and &amp;quot;left-right&amp;quot;; the
two-dimensional plane of the commonsense conception of
the earth&apos;s surface is represented by the two scale pairs
&amp;quot;north-south&amp;quot; and &amp;quot;east-west&amp;quot;.
</bodyText>
<page confidence="0.995651">
235
</page>
<bodyText confidence="0.986763">
The simplest, although not the only, way to define ad-
jacency in the space is as adjacency on both scales:
</bodyText>
<equation confidence="0.956700333333333">
(V x, y, sp)adj(x, y, sp)
(3 si, .92)scalei(si, sp) A sca/e2(82, sp)
A adj(x, y, Si) A adj(x, y, 82)
</equation>
<bodyText confidence="0.979957">
A region is a subset of a space. The surface and interior of
a region can be defined in terms of adjacency, in a manner
paralleling the definition of a boundary in point-set topol-
ogy. In the following, s is the boundary or surface of a two-
or three-dimensional region r embedded in a space sp.
</bodyText>
<equation confidence="0.995287">
(V s,r)surf ace(s, r, sp)
(V x)x E r J Ix ES
(Ey)(y E sp A -,(y e r) A adj(x, y, sp))1
</equation>
<bodyText confidence="0.993715">
Finally, we can define the notion of &amp;quot;contact&amp;quot; in terms of
points in different regions being adjacent.
</bodyText>
<equation confidence="0.998137">
(V r1, r2, sp)contact(ri , r2, sp)
disjoint (r1, r2) A
(Ex, y)(x E r A y E r2 A adj(x, y, sp))
</equation>
<bodyText confidence="0.999527428571429">
By picking the scales and defining adjacency right, we
can talk about points of contact between communicational
networks, systems of knowledge, and other metaphorical
domains. By picking the scales to be the real line and
defining adjacency in terms of (-neighborhoods, we get Eu-
clidean space and can talk about contact between physical
objects.
</bodyText>
<subsectionHeader confidence="0.703672">
3.5 Material
</subsectionHeader>
<bodyText confidence="0.99995675">
Physical objects and materials must be distinguished, just
as they are apparently distinguished in every natural lan-
guage, by means of the count noun - mass noun distinc-
tion. A physical object is not a bit of material, but rather
is comprised of a bit of material at any given time. Thus,
rivers and human bodies are physical objects, even though
their material constitution changes over time. This distinc-
tion also allows us to talk about an object losing material
through wear and still being the same object.
We will say that an entity b is a bit of material by means
of the expression material(b). Bits of material are char-
acterized by both extension and cohesion. The primitive
predication occupies(6, r, t) encodes extension, saying that
a bit of material b occupies a region r at time I. The topol-
ogy of a bit of material is then parasitic on the topology of
the region it occupies. A part bi of a bit of material b is a
bit of material whose occupied region is always a subregion
of the region occupied by b. Point-like particles (particle)
are defined in terms of points in the occupied region, dis-
joint bits (disjointbit) in terms of disjointness of regions,
and contact between bits in terms of contact between their
regions. We can then state as follows the Principle of Non-
Joint-Occupancy that two bits of material cannot occupy
the same place at the same time:
</bodyText>
<equation confidence="0.8466908">
(V bit, b2)(disjointbit(bi,b2)
x, y,b3,64)interior(b3,61)
A interior(b4,b2) A particl e(x, 63)
A particle(y, 64)
--,(Ez)(at(x, z) A at(y, z))
</equation>
<bodyText confidence="0.9949029">
At some future point in our work, this may emerge as a
consequence of a richer theory of cohesion and force.
The cohesion of materials is also a primitive property,
for we must distinguish between a bump on the surface of
an object and a chip merely lying on the surface. Cohesion
depends on a primitive relation bond between particles of
material, paralleling the role of adj in regions. The relation
attached is defined as the transitive closure of bond. A
topology of cohesion is built up in a manner analogous
to the topology of regions. In addition, we have encoded
the relation that bond bears to motion, i.e. that bonded
bits remain adjacent and that one moves when the other
does, and the relation of bond to force, i.e. that there is a
characteristic force that breaks a bond in a given material.
Different materials react in different ways to forces of
various strengths. Materials subjected to force exhibit or
fail to exhibit several invariance properties, proposed by
Hager (1985). lithe material is shape-invariant with re-
spect to a particular force, its shape remains the same.
If it is topologically invariant, particles that are adjacent
remain adjacent. Shape invariance implies topological in-
variance. Subject to forces of a certain strength or de-
gree d1, a material ceases being shape-invariant. At a
force of strength d2 &gt; d1, it ceases being topologically
invariant, and at a force of strength d3 &gt; d2, it sim-
ply breaks. Metals exhibit the full range of possibilities,
that is, 0 &lt; d1 &lt; d2 &lt; d3 &lt; co. For forces of strength
d &lt; d1, the material is &amp;quot;hard&amp;quot;; for forces of strength d
where d1 &lt; d &lt; d2, it is &amp;quot;flexible&amp;quot;; for forces of strength
d where d2 &lt; d &lt; d3, it is &amp;quot;malleable&amp;quot;. Words such as
&amp;quot;ductile&amp;quot; and &amp;quot;elastic&amp;quot; can be defined in terms of this vo-
cabulary, together with predicates about the geometry of
the bit of material. Words such as &amp;quot;brittle&amp;quot; (d1 = d2 = d3)
and &amp;quot;fluid&amp;quot; (d2 = 0, d3 = oo) can also be defined in these
terms. While we should not expect to be able to define
various material terms, like &amp;quot;metal&amp;quot; and &amp;quot;ceramic&amp;quot;, we
can certainly characterize many of their properties with
this vocabulary.
Because of its invariance properties, material interacts
with containment and motion. The word &amp;quot;clog&amp;quot; illustrates
this. The predicate clog is a three-place relation: x clogs
y against the flow of z. It is the obstruction by x of z&apos;s
motion through y, but with the selectional restriction that
z must be something that can flow, such as a liquid, gas,
or powder. If a rope is passing through a hole in a board,
and a knot in the rope prevents it from going through, we
do not say that the hole is clogged. On the other hand,
there do not seem to be any selectional constraints on x.
In particular, x can be identical with z: glue, sand, or
molasses can clog a passageway against its own flow. We
</bodyText>
<page confidence="0.995178">
236
</page>
<bodyText confidence="0.988928333333333">
can speak of clogging where the obstruction of flow is not
complete, but it must be thought of as &amp;quot;nearly&amp;quot; complete.
parts undergo normative state changes, thereby causing x
to undergo normative state changes, thereby causing x to
produce an effect with a normative function in the larger
system 8. The concept of &amp;quot;normative&amp;quot; is discussed below.
</bodyText>
<subsectionHeader confidence="0.68896">
3.6 Other Domains
3.6.1 Causal Connection
</subsectionHeader>
<bodyText confidence="0.9999618125">
Attachment within materials is one variety of causal con-
nection. In general, if two entities x and y are causally
connected with respect to some behavior p of x, then when-
ever p happens to x, there is some corresponding behavior
q that happens to y. In the case of attachment, p and q
are both move. A particularly common variety of causal
connection between two entities is one mediated by the mo-
tion of a third entity from one to the other. (This might
be called a &amp;quot;vector boson&amp;quot; connection.) Photons medi-
ating the connection between the sun and our eyes, rain
drops connecting a state of the clouds with the wetness of
our skin and clothes, a virus being transmitted from one
person to another, and utterances passing between peo-
ple are all examples of such causal connections. Barriers,
openings, and penetration are all with respect to paths of
causal connection.
</bodyText>
<subsectionHeader confidence="0.919169">
3.6.2 Force
</subsectionHeader>
<bodyText confidence="0.999991916666667">
The concept of &amp;quot;force&amp;quot; is axiomatized, in a way consistent
with Talmy&apos;s treatment (1985), in terms of the predica-
tions f orce(a, b, d1) and resist(b, a, d2)—a forces against b
with strength d1 and b resists a&apos;s action with strength d2.
We can infer motion from facts about relative strength.
This treatment can also be specialized to Newtonian force,
where we have not merely movement, but acceleration. In
addition, in spaces in which orientation is defined, forces
can have an orientation, and a version of the Parallelogram
of Forces Law can be encoded. Finally, force interacts with
shape in ways characterized by words like &amp;quot;stretch&amp;quot;, &amp;quot;com-
press&amp;quot;, &amp;quot;bend&amp;quot;, &amp;quot;twist&amp;quot;, and &amp;quot;shear&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.867467">
3.6.3 Systems and Functionality
</subsectionHeader>
<bodyText confidence="0.997140857142857">
An important concept is the notion of a &amp;quot;system&amp;quot;, which
is a set of entities, a set of their properties, and a set of
relations among them. A common kind of system is one
in which the entities are events and conditions and the
relations are causal and enabling relations. A mechanical
device can be described as such a system—in a sense, in
terms of the plan it executes in its operation. The function
of various parts and of conditions of those parts is then the
role they play in this system, or plan.
The intransitive sense of &amp;quot;operate&amp;quot;, as in
The diesel was operating.
involves systems and functionality. If an entity x oper-
ates, then there must be a larger system s of which x is
a part. The entity x itself is a system with parts. These
</bodyText>
<subsectionHeader confidence="0.91818">
3.6.4 Shape
</subsectionHeader>
<bodyText confidence="0.999993730769231">
We have been approaching the problem of characterizing
shape from a number of different angles. The classical
treatment of shape is via the notion of &amp;quot;similarity&amp;quot; in Eu-
clidean geometry, and in Hilbert&apos;s formal reconstruction of
Euclidean geometry (Hilbert, 1902) the key primitive con-
cept seems to be that of &amp;quot;congruent angles&amp;quot;. Therefore,
we first sought to develop a theory of &amp;quot;orientation&amp;quot;. The
shape of an object can then be characterized in terms of
changes in orientation of a tangent as one moves about on
the surface of the object, as is done in vision research (e.g.,
Zahn and Roskies, 1972). In all of this, since &amp;quot;shape&amp;quot; can
be used loosely and metaphorically, one question we are
asking is whether some minimal, abstract structure can be
found in which the notion of &amp;quot;shape&amp;quot; makes sense. Con-
sider, for instance, a graph in which one scale is discrete,
or even unordered. Accordingly, we have been examining
a number of examples, asking when it seems right to say
two structures have different shapes.
We have also examined the interactions of shape and
functionality (cf. Davis, 1989). What seems to be cru-
cial is how the shape of an obstacle constrains the motion
of a substance or of an object of a particular shape (cf.
Shoham, 1985). Thus, a funnel concentrates the flow of a
liquid, and similarly, a wedge concentrates force. A box
pushed against a ridge in the floor will topple, and a wheel
is a limiting case of continuous toppling.
</bodyText>
<subsectionHeader confidence="0.9937005">
3.7 Hitting, Abrasion, Wear, and Re-
lated Concepts
</subsectionHeader>
<bodyText confidence="0.999421166666667">
For x to hit y is for x to move into contact with y with
some force.
The basic scenario for an abrasive event is that there is
an impinging bit of material m which hits an object o and
by doing so removes a pointlike bit of material 60 from the
surface of o:
</bodyText>
<construct confidence="0.997742125">
abr-evene (e, m, o, bo) : material(m)
A topologically-invariant(o)
(V e, m, o, bo)abr-events (e, m, o, bo)
(3 t, b, s, 60, e1, e2, es)at(e, t)
A consists-of (o,b,t) A surf ace(8, b)
A particle(bo, s) A changeqe, e1, e2)
A attachedlei,bo,b) A notle2,
A cause(es, e) A hie(e3, rn, be)
</construct>
<bodyText confidence="0.9928365">
After the abrasive event, the pointlike bit 60 is no longer a
part of the object o:
</bodyText>
<page confidence="0.98996">
237
</page>
<figure confidence="0.2706966">
(Ye, m, o, bo, e1, e2, t2)abr-event1(e, m, 0, bo)
A change&apos; (e, el, e2) A attached&apos; (ei, 60, b)
A not&apos; (e2, ei) A at(e2, 12)
A consists-of (o, 62, t2)
-,part(bo, b2)
</figure>
<bodyText confidence="0.9891954">
It is necessary to state this explicitly since objects and bits
of material can be discontinuous.
An abrasion is a large number of abrasive events widely
distributed through some nonpointlike region on the sur-
face of an object:
</bodyText>
<figure confidence="0.858650142857143">
(Ye, rn, o)abrade (e, m, o)
(3 bs)RY E e D
(3 60)190 e bs A abr-event&apos; (ei,m, 0, bo)]
A (Yb, s, t)[at(e, t)
A consists-of (o, b, t) A surf ace(s, b)
D (3 r)subregion (r, 8)
A widely-distributed(bs, r)11
</figure>
<bodyText confidence="0.989796">
Wear can occur by means of a large collection of abrasive
events distributed over time as well as space (so that there
may be no time at which enough abrasive events occur to
count as an abrasion). Thus, the link between wear and
abrasion is via the common notion of abrasive events, not
via a definition of wear in terms of abrasion.
</bodyText>
<equation confidence="0.901868">
(Ye, m, o)wearle, x, o)
(3 bs)(V ei)lei E e
(3 bo)bo E bs) A abr-evene(ei , m, 0, bo)1
A (3 i)[interval(i) A widely-distributed(e, i))
</equation>
<bodyText confidence="0.98170856">
The concept &amp;quot;widely distributed&amp;quot; concerns systems. If
x is distributed in y, then y is a system and x is a set
of entities which are located at components of y. For the
distribution to be wide, most of the elements of a partition
of y determined independently of the distribution must
contain components which have elements of x at them.
The word &amp;quot;wear&amp;quot; is one of a large class of other events
involving cumulative, gradual loss of material - events de-
scribed by words like &amp;quot;chip&amp;quot;, &amp;quot;corrode&amp;quot;, &amp;quot;file&amp;quot;, &amp;quot;erode&amp;quot;,
&amp;quot;rub&amp;quot;, &amp;quot;sand&amp;quot;, &amp;quot;grind&amp;quot;, &amp;quot;weather&amp;quot;, &amp;quot;rust&amp;quot;, &amp;quot;tarnish&amp;quot;, &amp;quot;eat
away&amp;quot;, &amp;quot;rot&amp;quot;, and &amp;quot;decay&amp;quot;. All of these lexical items can
now be defined as variations on the definition of &amp;quot;wear&amp;quot;,
since we have built up the axiomatizations underlying
&amp;quot;wear&amp;quot;. We are now in a position to characterize the en-
tire class. We will illustrate this by defining two different
types of variants of &amp;quot;wear&amp;quot; - &amp;quot;chip&amp;quot; and &amp;quot;corrode&amp;quot;.
&amp;quot;Chip&amp;quot; differs from &amp;quot;wear&amp;quot; in three ways: the bit of
material removed in one abrasive event is larger (it need
not be point-like), it need not happen because of a mate-
rial hitting against the object, and &amp;quot;chip&amp;quot; does not require
(though it does permit) a large collection of such events:
one can say that some object is chipped if there is only
one chip in it. Thus, we slightly alter the definition of
abr-event to accommodate these changes:
(Ye, m, o, bo)chip&apos; (e, m, o, 60)
</bodyText>
<note confidence="0.402696">
(Be, b, 8,60, el, e2, e3)at(e, t)
</note>
<construct confidence="0.555387333333333">
A consists-of (o, b, t) A surf ace(s, b)
A part(bo, s) A change&apos; (e, , e2)
A attached&apos; (el, bo, b) A not&apos; (e2, ei)
&amp;quot;Corrode&amp;quot; differs from &amp;quot;wear&amp;quot; in that the bit of material
is chemically transformed as well as being detached by the
contact event; in fact, in some way the chemical transfor-
mation causes the detachment. This can be captured by
adding a condition to the abrasive event which renders it
a (single) corrode event:
corrode-event(m, o, 60) : f luid(m)
A contact(m, bo)
(Ye, m, o, bo)corrode-event&apos; (e, m, o, 60)
(3 t, b, s, 60, el, e2, es)at(e, t)
A consists-of (o, b, t) A surf ace(s, 6)
A partici e(bo, s) A change&apos; (e, el, e2)
A attached&apos; (e1,190, 6) A not&apos; (e2, ei)
A cause(es, e) A chemical-changes (e3, m, 60)
&amp;quot;Corrode&amp;quot; itself may be defined in a parallel fashion to
&amp;quot;wear&amp;quot;, substituting corrode-event for abr-event.
All of this suggests the generalization that abrasive
events, chipping and corrode events all detach the bit in
question, and that we may describe all of these as detach-
ing events. We can then generalize the above axiom about
abrasive events resulting in loss of material to the following
axiom about detaching:
(Ye, m, o, 60,62, e1, e2, t2)detach&apos; (e, in, o, 60)
A change&apos; (e, e1, e2) A attached&apos; (el, bo, b)
A notle2, el) A at(e2, t2)
A consists-of (o, b2, t2)
--+(part(bo, 62))
</construct>
<sectionHeader confidence="0.958049" genericHeader="evaluation">
4 Relevance and the Normative
</sectionHeader>
<bodyText confidence="0.998832833333333">
Many of the concepts we are investigating have driven us
inexorably to the problems of what is meant by &amp;quot;relevant&amp;quot;
and by &amp;quot;normative&amp;quot;. We do not pretend to have solved
these problems. But for each of these concepts we do have
the beginnings of an account that can play a role in anal-
ysis, if not yet in implementation.
Our view of relevance, briefly stated, is that something
is relevant to some goal if it is a part of a plan to achieve
that goal. IA formal treatment of a similar view is given in
Davies and Russell, 1986.) We can illustrate this with an
example involving the word &amp;quot;sample&amp;quot;. If a bit of material
is a sample of another bit of material y, then x is a part
of y, and moreover, there are relevant properties p and q
such that it is believed that if p is true of x then q is true
of y. That is, looking at the properties of the sample tells
us something important about the properties of the whole.
Frequently, p and q are the same property. In our target
texts, the following sentence occurs:
</bodyText>
<page confidence="0.990923">
238
</page>
<bodyText confidence="0.9998336">
We retained an oil sample for future inspection.
The oil in the sample is a part of the total lube oil in the
tube oil system, and it is believed that a property of the
sample, such as &amp;quot;contaminated with metal particles&amp;quot;, will
be true of all of the lube oil as well, and that this will
give information about possible wear on the bearings. It is
therefore relevant to the goal of maintaining the machinery
in good working order.
We have arrived at the following provisional account of
what it means to be &amp;quot;normative&amp;quot;. For an entity to exhibit
a normative condition or behavior, it must first of all be a
component of a larger system. This system has structure
in the form of relations among its components. A pat-
tern is a property of the system, namely, the property of
a subset of these stuctural relations holding. A norm is a
pattern which is established either by conventional stipula-
tion or by statistical regularity. An entity is behaving in a
normative fashion if it is a component of a system and in-
stantiates a norm within that system. The word &amp;quot;operate&amp;quot;
given above illustrates this. When we say that an engine
is operating, we have in mind a larger system, the device
the engine drives, to which the engine may bear various
possible relations. A subset of these relations is stipulated
to be the norm—the way it is supposed to work. We say
it is operating when it is instantiating this norm.
</bodyText>
<sectionHeader confidence="0.999113" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999986555555556">
The research we have been engaged in has forced us to ex-
plicate a complex set of commonsense concepts. Since we
have done it in as general a fashion as possible, we may
expect that it will be possible to axiomatize a large num-
ber of other areas, including areas unrelated to mechanical
devices, building on this foundation. The very fact that we
have been able to characterize words as diverse as &amp;quot;range&amp;quot;,
&amp;quot;immediately&amp;quot;, &amp;quot;brittle&amp;quot;, &amp;quot;operate&amp;quot; and &amp;quot;wear&amp;quot; shows the
promise of this approach.
</bodyText>
<sectionHeader confidence="0.996993" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.859251">
The research reported here was funded by the Defense Ad-
vanced Research Projects Agency under Office of Naval
Research contract N00014-85-C-0013. It builds on work
supported by NIH Grant LM03611 from the National Li-
brary of Medicine, by Grant IST-8209346 from the Na-
tional Science Foundation, and by a gift from the Systems
Development Foundation.
</bodyText>
<sectionHeader confidence="0.992251" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999941081632653">
[1] Allen, James F., and Henry A. Kautz. 1985. &amp;quot;A model
of naive temporal reasoning.&amp;quot; Formal Theories of the
Commonsense World, ed. by Jerry R. Hobbs and Robert
C. Moore, Ablex Publishing Corp., 251-268.
[2] Croft, William. 1986. Categories and Relations in Syn-
tax: The Clause-Level Organization of Information.
Ph.D. dissertation, Department of Linguistics, Stanford
University.
[3] Davies, Todd R., and Stuart J. Russell. 1986. &amp;quot;A logi-
cal approach to reasoning by analogy.&amp;quot; Submitted to the
AAAI-86 Fifth National Conference on Artificial Intel-
ligence, Philadelphia, Pennsylvania.
[4] Davis, Ernest. 1984. &amp;quot;Shape and Function of Solid Ob-
jects: Some Examples.&amp;quot; Computer Science Technical
Report 137, New York University. October 1984.
[5] Hager, Greg. 1985. &amp;quot;Naive physics of materials: A re-
con mission.&amp;quot; In Commonsense Summer: Final Report,
Report No. CSLI-85-35, Center for the Study of Lan-
guage and Information, Stanford University.
[6] Hayes, Patrick J. 1979. &amp;quot;Naive physics manifesto.&amp;quot; Ex-
pert Systems in the Micro-electronic Age, ed. by Donald
Michie, Edinburgh University Press, pp. 242-270.
[7] Herskovits, Annette. 1982. Space and the Prepositions
in English: Regularities and Irregularities in a Complex
Domain. Ph.D. dissertation, Department of Linguistics,
Stanford University.
[8] Hilbert, David. 1902. The Foundations of Geometry.
The Open Court Publishing Company.
[9] Hobbs, Jerry R. 1974. &amp;quot;A Model for Natural Language
Semantics, Part I: The Model.&amp;quot; Research Report #36,
Department of Computer Science, Yale University. Oc-
tober 1974.
[10] Hobbs, Jerry R. 1985a. &amp;quot;Ontological promiscuity.&amp;quot;
Proceedings, 23rd Annual Meeting of the Association for
Computational Linguistics, pp. 61-69.
[11] Hobbs, Jerry R. 1985b.&amp;quot;Granularity.&amp;quot; Proceedings of
the Ninth International Joint Conference on Artificial
Intelligence, Los Angeles, California, August 1985, 432-
435.
[12] Hobbs, Jerry R. and Robert C. Moore, eds. 1985. For-
mal Theories of the Commonsense World, Ablex Pub-
lishing Corp.
[13] Hobbs, Jerry R. et al. 1985. Commonsense Summer:
Final Report, Report No. CSLI-85-35, Center for the
Study of Language and Information, Stanford Univer-
sity.
[14] Katz, Jerrold J. and Jerry A. Fodor. 1963. &amp;quot;The stru-
ture of a semantic theory.&amp;quot; Language, Vol. 39 (April-
June 1963), 170-210.
</reference>
<page confidence="0.978032">
239
</page>
<reference confidence="0.999818305555556">
1151 Lakoff, G. 1972. &amp;quot;Linguistics and natural logic&amp;quot;. Se-
mantics of Natural Language, ed. by Donald Davidson
and Gilbert Harman, 545-665.
[16] McDermott, Drew. 1985. &amp;quot;Reasoning about plans.&amp;quot;
Formal Theories of the Commonsense World, ed. by
Jerry R. Hobbs and Robert C. Moore, Ablex Publishing
Corp., 269-318.
1171 Miller, George A. and Philip N. Johnson-Laird. 1976.
Language and Perception,Belknap Press.
[18] Rieger, Charles J. 1974. &amp;quot;Conceptual memory: A the-
ory and computer program for processing and meaning
content of natural language utterances.&amp;quot; Stanford AIM-
233, Department of Computer Science, Stanford Univer-
sity.
[19] Schank, Roger. 1975. Conceptual Information Pro-
cessing. Elsevier Publishing Company.
[20] Shoham, Yoav. 1985. &amp;quot;Naive kinematics: Two aspects
of shape.&amp;quot; In Commonsense Summer: Final Report, Re-
port No. CSLI-85-35, Center for the Study of Language
and Information, Stanford University.
[21] Stickel, M.E. 1982. &amp;quot;A nonclausal connection-graph
resolution theorem-proving program.&amp;quot; Proceedings of the
AAAI-82 National Conference on Artificial Intelligence,
Pittsburgh, Pennsylvania, 229-233.
[22] Talmy, Leonard. 1983. &amp;quot;How language structures
space.&amp;quot; Spatial Orientation: Theory, Research, and Ap-
plication, ed. by Herbert Pick and Linda Acredolo,
Plenum Press.
[23] Talmy, Leonard. 1985. &amp;quot;Force dynamics in lan-
guage and thought.&amp;quot; Proceedings from the Parasession
on Causatives and Agentivity, 21st Regional Meeting,
Chicago Linguistic Society, ed. by William H. Eilfort,
Paul D. Kroeber, and Karen L. Peterson.
[24] Zahn, C. T., and R. Z. Roskies. 1972. &amp;quot;Fourier de-
scriptors for plane closed curves.&amp;quot; IEEE Transactions
on Computers, Vol. C-21, No. 3, 269-281. March 1972.
</reference>
<page confidence="0.997029">
240
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.879334">
<title confidence="0.9902385">COMMONSENSE METAPHYSICS AND LEXICAL SEMANTICS</title>
<author confidence="0.954849">Jerry R Hobbs</author>
<author confidence="0.954849">William Croft</author>
<author confidence="0.954849">Todd Davies</author>
<author confidence="0.954849">Douglas Edwards</author>
<author confidence="0.954849">Kenneth Laws</author>
<affiliation confidence="0.992856">Artificial Intelligence Center SRI International</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Henry A Kautz</author>
</authors>
<title>A model of naive temporal reasoning.&amp;quot;</title>
<date>1985</date>
<booktitle>Formal Theories of the Commonsense World,</booktitle>
<pages>251--268</pages>
<editor>ed. by Jerry R. Hobbs and Robert C. Moore,</editor>
<publisher>Ablex Publishing Corp.,</publisher>
<marker>[1]</marker>
<rawString>Allen, James F., and Henry A. Kautz. 1985. &amp;quot;A model of naive temporal reasoning.&amp;quot; Formal Theories of the Commonsense World, ed. by Jerry R. Hobbs and Robert C. Moore, Ablex Publishing Corp., 251-268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Croft</author>
</authors>
<title>Categories and Relations in Syntax: The Clause-Level Organization of Information.</title>
<date>1986</date>
<institution>Department of Linguistics, Stanford University.</institution>
<note>Ph.D. dissertation,</note>
<marker>[2]</marker>
<rawString>Croft, William. 1986. Categories and Relations in Syntax: The Clause-Level Organization of Information. Ph.D. dissertation, Department of Linguistics, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Todd R Davies</author>
<author>Stuart J Russell</author>
</authors>
<title>A logical approach to reasoning by analogy.&amp;quot;</title>
<date>1986</date>
<booktitle>Submitted to the AAAI-86 Fifth National Conference on Artificial Intelligence,</booktitle>
<location>Philadelphia, Pennsylvania.</location>
<marker>[3]</marker>
<rawString>Davies, Todd R., and Stuart J. Russell. 1986. &amp;quot;A logical approach to reasoning by analogy.&amp;quot; Submitted to the AAAI-86 Fifth National Conference on Artificial Intelligence, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ernest Davis</author>
</authors>
<title>Shape and Function of Solid Objects: Some Examples.&amp;quot;</title>
<date>1984</date>
<journal>Computer Science</journal>
<tech>Technical Report 137,</tech>
<location>New York University.</location>
<marker>[4]</marker>
<rawString>Davis, Ernest. 1984. &amp;quot;Shape and Function of Solid Objects: Some Examples.&amp;quot; Computer Science Technical Report 137, New York University. October 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Hager</author>
</authors>
<title>Naive physics of materials: A recon mission.&amp;quot; In Commonsense Summer:</title>
<date>1985</date>
<tech>Final Report, Report No. CSLI-85-35,</tech>
<institution>Center for the Study of Language and Information, Stanford University.</institution>
<marker>[5]</marker>
<rawString>Hager, Greg. 1985. &amp;quot;Naive physics of materials: A recon mission.&amp;quot; In Commonsense Summer: Final Report, Report No. CSLI-85-35, Center for the Study of Language and Information, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick J Hayes</author>
</authors>
<title>Naive physics manifesto.&amp;quot;</title>
<date>1979</date>
<booktitle>Expert Systems in the Micro-electronic Age,</booktitle>
<pages>242--270</pages>
<editor>ed. by Donald Michie,</editor>
<publisher>Edinburgh University Press,</publisher>
<marker>[6]</marker>
<rawString>Hayes, Patrick J. 1979. &amp;quot;Naive physics manifesto.&amp;quot; Expert Systems in the Micro-electronic Age, ed. by Donald Michie, Edinburgh University Press, pp. 242-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annette Herskovits</author>
</authors>
<title>Space and the Prepositions in English: Regularities and Irregularities in a Complex Domain.</title>
<date>1982</date>
<institution>Department of Linguistics, Stanford University.</institution>
<note>Ph.D. dissertation,</note>
<marker>[7]</marker>
<rawString>Herskovits, Annette. 1982. Space and the Prepositions in English: Regularities and Irregularities in a Complex Domain. Ph.D. dissertation, Department of Linguistics, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hilbert</author>
</authors>
<title>The Foundations of Geometry.</title>
<date>1902</date>
<publisher>The Open Court Publishing Company.</publisher>
<marker>[8]</marker>
<rawString>Hilbert, David. 1902. The Foundations of Geometry. The Open Court Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>A Model for Natural Language Semantics, Part I: The Model.&amp;quot;</title>
<date>1974</date>
<tech>Research Report #36,</tech>
<institution>Department of Computer Science, Yale University.</institution>
<marker>[9]</marker>
<rawString>Hobbs, Jerry R. 1974. &amp;quot;A Model for Natural Language Semantics, Part I: The Model.&amp;quot; Research Report #36, Department of Computer Science, Yale University. October 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Ontological promiscuity.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>61--69</pages>
<marker>[10]</marker>
<rawString>Hobbs, Jerry R. 1985a. &amp;quot;Ontological promiscuity.&amp;quot; Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics, pp. 61-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<date>1985</date>
<booktitle>Proceedings of the Ninth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>432--435</pages>
<location>Los Angeles, California,</location>
<marker>[11]</marker>
<rawString>Hobbs, Jerry R. 1985b.&amp;quot;Granularity.&amp;quot; Proceedings of the Ninth International Joint Conference on Artificial Intelligence, Los Angeles, California, August 1985, 432-435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Robert C Moore</author>
<author>eds</author>
</authors>
<date>1985</date>
<booktitle>Formal Theories of the Commonsense World,</booktitle>
<publisher>Ablex Publishing Corp.</publisher>
<marker>[12]</marker>
<rawString>Hobbs, Jerry R. and Robert C. Moore, eds. 1985. Formal Theories of the Commonsense World, Ablex Publishing Corp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Commonsense Summer:</title>
<date>1985</date>
<tech>Final Report, Report No. CSLI-85-35,</tech>
<institution>Center for the Study of Language and Information, Stanford University.</institution>
<marker>[13]</marker>
<rawString>Hobbs, Jerry R. et al. 1985. Commonsense Summer: Final Report, Report No. CSLI-85-35, Center for the Study of Language and Information, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
<author>Jerry A Fodor</author>
</authors>
<title>The struture of a semantic theory.&amp;quot;</title>
<date>1963</date>
<journal>Language,</journal>
<booktitle>Lakoff, G.</booktitle>
<volume>39</volume>
<pages>170--210</pages>
<editor>ed. by Donald Davidson and Gilbert Harman,</editor>
<marker>[14]</marker>
<rawString>Katz, Jerrold J. and Jerry A. Fodor. 1963. &amp;quot;The struture of a semantic theory.&amp;quot; Language, Vol. 39 (AprilJune 1963), 170-210. 1151 Lakoff, G. 1972. &amp;quot;Linguistics and natural logic&amp;quot;. Semantics of Natural Language, ed. by Donald Davidson and Gilbert Harman, 545-665.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Drew McDermott</author>
</authors>
<title>Reasoning about plans.&amp;quot; Formal Theories of the Commonsense World,</title>
<date>1985</date>
<pages>269--318</pages>
<editor>ed. by Jerry R. Hobbs and Robert C. Moore,</editor>
<publisher>Ablex Publishing Corp.,</publisher>
<marker>[16]</marker>
<rawString>McDermott, Drew. 1985. &amp;quot;Reasoning about plans.&amp;quot; Formal Theories of the Commonsense World, ed. by Jerry R. Hobbs and Robert C. Moore, Ablex Publishing Corp., 269-318. 1171 Miller, George A. and Philip N. Johnson-Laird. 1976. Language and Perception,Belknap Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Rieger</author>
</authors>
<title>Conceptual memory: A theory and computer program for processing and meaning content of natural language utterances.&amp;quot;</title>
<date>1974</date>
<tech>Stanford AIM233,</tech>
<institution>Department of Computer Science, Stanford University.</institution>
<marker>[18]</marker>
<rawString>Rieger, Charles J. 1974. &amp;quot;Conceptual memory: A theory and computer program for processing and meaning content of natural language utterances.&amp;quot; Stanford AIM233, Department of Computer Science, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schank</author>
</authors>
<title>Conceptual Information Processing.</title>
<date>1975</date>
<publisher>Elsevier Publishing Company.</publisher>
<marker>[19]</marker>
<rawString>Schank, Roger. 1975. Conceptual Information Processing. Elsevier Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Shoham</author>
</authors>
<title>Naive kinematics: Two aspects of shape.&amp;quot; In Commonsense Summer:</title>
<date>1985</date>
<tech>Final Report, Report No. CSLI-85-35,</tech>
<institution>Center for the Study of Language and Information, Stanford University.</institution>
<marker>[20]</marker>
<rawString>Shoham, Yoav. 1985. &amp;quot;Naive kinematics: Two aspects of shape.&amp;quot; In Commonsense Summer: Final Report, Report No. CSLI-85-35, Center for the Study of Language and Information, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Stickel</author>
</authors>
<title>A nonclausal connection-graph resolution theorem-proving program.&amp;quot;</title>
<date>1982</date>
<booktitle>Proceedings of the AAAI-82 National Conference on Artificial Intelligence,</booktitle>
<pages>229--233</pages>
<location>Pittsburgh, Pennsylvania,</location>
<marker>[21]</marker>
<rawString>Stickel, M.E. 1982. &amp;quot;A nonclausal connection-graph resolution theorem-proving program.&amp;quot; Proceedings of the AAAI-82 National Conference on Artificial Intelligence, Pittsburgh, Pennsylvania, 229-233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>How language structures space.&amp;quot; Spatial Orientation: Theory, Research, and Application,</title>
<date>1983</date>
<editor>ed. by Herbert Pick and Linda Acredolo,</editor>
<publisher>Plenum Press.</publisher>
<marker>[22]</marker>
<rawString>Talmy, Leonard. 1983. &amp;quot;How language structures space.&amp;quot; Spatial Orientation: Theory, Research, and Application, ed. by Herbert Pick and Linda Acredolo, Plenum Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Force dynamics in language and thought.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings from the Parasession on Causatives and Agentivity, 21st Regional Meeting, Chicago Linguistic Society,</booktitle>
<editor>ed. by William H. Eilfort, Paul D. Kroeber, and Karen L. Peterson.</editor>
<marker>[23]</marker>
<rawString>Talmy, Leonard. 1985. &amp;quot;Force dynamics in language and thought.&amp;quot; Proceedings from the Parasession on Causatives and Agentivity, 21st Regional Meeting, Chicago Linguistic Society, ed. by William H. Eilfort, Paul D. Kroeber, and Karen L. Peterson.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C T Zahn</author>
<author>R Z Roskies</author>
</authors>
<title>Fourier descriptors for plane closed curves.&amp;quot;</title>
<date>1972</date>
<journal>IEEE Transactions on Computers,</journal>
<volume>21</volume>
<pages>269--281</pages>
<marker>[24]</marker>
<rawString>Zahn, C. T., and R. Z. Roskies. 1972. &amp;quot;Fourier descriptors for plane closed curves.&amp;quot; IEEE Transactions on Computers, Vol. C-21, No. 3, 269-281. March 1972.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>