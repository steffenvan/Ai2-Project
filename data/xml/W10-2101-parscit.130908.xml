<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000806">
<title confidence="0.985862">
Modeling and Encoding Traditional Wordlists for Machine Applications
</title>
<author confidence="0.993372">
Shakthi Poornima
</author>
<affiliation confidence="0.814051">
Department of Linguistics
University at Buffalo
</affiliation>
<address confidence="0.920713">
Buffalo, NY USA
</address>
<email confidence="0.998947">
poornima@buffalo.edu
</email>
<author confidence="0.997133">
Jeff Good
</author>
<affiliation confidence="0.815281">
Department of Linguistics
University at Buffalo
</affiliation>
<address confidence="0.921205">
Buffalo, NY USA
</address>
<email confidence="0.998925">
jcgood@buffalo.edu
</email>
<sectionHeader confidence="0.9939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999951230769231">
This paper describes work being done on
the modeling and encoding of a legacy re-
source, the traditional descriptive wordlist,
in ways that make its data accessible to
NLP applications. We describe an abstract
model for traditional wordlist entries and
then provide an instantiation of the model
in RDF/XML which makes clear the re-
lationship between our wordlist database
and interlingua approaches aimed towards
machine translation, and which also al-
lows for straightforward interoperation
with data from full lexicons.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960966666667">
When looking at the relationship between NLP
and linguistics, it is typical to focus on the dif-
ferent approaches taken with respect to issues
like parsing and generation of natural language
data—for example, to compare statistical NLP ap-
proaches to those involving grammar engineering.
Such comparison is undoubtedly important insofar
as it helps us understand how computational meth-
ods that are derived from these two lines of re-
search can complement each other. However, one
thing that the two areas of work have in common
is that they tend to focus on majority languages
and majority language resources. Even where this
is not the case (Bender et al., 2002; Alvarez et al.,
2006; Palmer et al., 2009), the resulting products
still cover relatively few languages from a world-
wide perspective. This is in part because such
work cannot easily make use of the extensive lan-
guage resources produced by descriptive linguists,
the group of researchers that are most actively in-
volved in documenting the world’s entire linguis-
tic diversity. In fact, one particular descriptive lin-
guistic product, the wordlist—which is the focus
of this paper—can be found for at least a quarter
of the world’s languages.
Clearly, descriptive linguistic resources can be
of potential value not just to traditional linguis-
tics, but also to computational linguistics. The
difficulty, however, is that the kinds of resources
produced in the course of linguistic description
are typically not easily exploitable in NLP appli-
cations. Nevertheless, in the last decade or so,
it has become widely recognized that the devel-
opment of new digital methods for encoding lan-
guage data can, in principle, not only help descrip-
tive linguists to work more effectively but also al-
low them, with relatively little extra effort, to pro-
duce resources which can be straightforwardly re-
purposed for, among other things, NLP (Simons et
al., 2004; Farrar and Lewis, 2007).
Despite this, it has proven difficult to create
significant electronic descriptive resources due to
the complex and specific problems inevitably as-
sociated with the conversion of legacy data. One
exception to this is found in the work done in
the context of the ODIN project (Xia and Lewis,
2009), a significant database of interlinear glossed
text (IGT), a standard descriptive linguistic data
format (Palmer et al., 2009), compiled by search-
ing the Web for legacy instances of IGT.
This paper describes another attempt to trans-
form an existing legacy dataset into a more read-
ily repurposable format. Our data consists of tra-
ditional descriptive wordlists originally collected
for comparative and historical linguistic research.&apos;
Wordlists have been widely employed as a first
step towards the creation of a dictionary or as a
means to quickly gather information about a lan-
guage for the purposes of language comparison
(especially in parts of the world where languages
</bodyText>
<footnote confidence="0.910875714285714">
&apos;These wordlists were collected by Timothy Usher and
Paul Whitehouse and represent an enormous effort without
which the work described here would not have been possible.
The RDF/XML implementations discussed in this paper will
be made available at http://lego.linguistlist.org
within the context of the Lexicon Enhancement via the
GOLD Ontology project.
</footnote>
<page confidence="0.515653">
1
</page>
<note confidence="0.9814975">
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 1–9,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999961333333333">
are poorly documented). Because of this, they
exist for many more languages than do full lexi-
cons. While the lexical information that wordlists
contain is quite sparse, they are relatively consis-
tent in their structure across resources. This al-
lows for the creation of a large-scale multilingual
database consisting of rough translational equiva-
lents which may lack precision but has coverage
well-beyond what would otherwise be available.
</bodyText>
<sectionHeader confidence="0.678925" genericHeader="introduction">
2 The Data and Project Background
</sectionHeader>
<bodyText confidence="0.999677961538462">
The data we are working with consists of 2,700
wordlists drawn from more than 1,500 languages
(some wordlists represent dialects) and close to
500,000 forms. This is almost certainly the largest
collection of wordlists in a standardized format.
The average size of the individual wordlists is
rather small, around 200 words, making them
comparable in size to the resources found in
a project like NEDO (Takenobu, 2006), though
smaller than in other related projects like those
discussed in section 4. While the work described
here was originally conceived to support descrip-
tive and comparative linguistics, our data model
and choice of encoding technologies has had the
additional effect of making these resources read-
ily exploitable in other domains, in particular NLP.
We have approached the data initially as tradi-
tional, not computational, linguists, and our first
goal has been to encode the available materials
not with any new information but rather to trans-
fer the information they originally contained in a
more exploitable way.
By way of introduction, the hypothetical exam-
ple in (1) illustrates a traditional presentation for-
mat of a wordlist, with English as the source lan-
guage and French as the target language.
</bodyText>
<listItem confidence="0.581583">
(1) MAN homme
WOMAN femme
</listItem>
<bodyText confidence="0.999569888888889">
As we will describe in more detail in section 5,
they key features of a wordlist entry are an index
to a concept assumed to be of general provenance
(e.g., MAN) and a form drawn from a specific lan-
guage (e.g. homme) determined to be the counter-
part for that concept within that language. Most
typically, the elements indexing the relevant con-
cepts are words drawn from languages of wider
communication (e.g., English or Spanish).
</bodyText>
<sectionHeader confidence="0.9358075" genericHeader="related work">
3 Related Work in Descriptive
Linguistics
</sectionHeader>
<bodyText confidence="0.997435878048781">
Recent years have seen a fair amount of attention
paid to the modeling of traditional linguistic data
types, including lexicons, glossed texts, and gram-
mars (Bell and Bird, 2000; Good, 2004; Palmer
and Erk, 2007; Nordhoff, 2008). The data type of
focus here, wordlists, has not seen serious treat-
ment. Superficially, wordlists resemble lexicons
and, of course, they can be considered a kind of
lexical resource. However, as will be shown in
section 5, there are important differences between
lexicons and wordlists which have implications for
how they should be modeled.
Most of the work on modeling descriptive lin-
guistic data types has proceeded without special
consideration for possible NLP applications for
the data being encoded. This is largely because the
work was initially a response to issues relating to
the longevity of digital descriptive data which was,
otherwise, quite often being encoded solely in (of-
ten proprietary) presentation formats (Bird and Si-
mons, 2003). However, the possibility for fruitful
interaction between computational linguistics and
descriptive linguistics is apparent and has been the
subject of some work (Palmer et al., 2009).
The work described here is also interested in
this possibility. In particular, we address the ques-
tion of how to model and encode a large-scale
dataset that was originally intended to be used for
descriptive purposes in ways that not only allow us
to faithfully represent the intention of the original
creator but also permit the data to be straightfor-
wardly exploitable for new uses, including NLP.
To the best of our knowledge, our work is innova-
tive both because of the data type being explored
and because the data modeling is being done par-
allel with the transformation of a legacy resource
with significant coverage of the world’s languages.
This stands in contrast to most other work (again,
with the exception of work done within ODIN
(Xia and Lewis, 2009)) whose data, while repre-
sentative, is not of the same scale.
</bodyText>
<sectionHeader confidence="0.985641" genericHeader="method">
4 Related Work on Lexicon
Interoperability in NLP
</sectionHeader>
<bodyText confidence="0.9996034">
The relevant related work in NLP is that focused
on interoperation among lexical resources. One
way to achieve this is to make use of language in-
dependent ontologies (or comparable objects) for
word meanings which can serve as pivots for mul-
</bodyText>
<page confidence="0.988285">
2
</page>
<bodyText confidence="0.999957628571429">
tilingual applications (Ide et al., 1998; Vossen,
2004; Nirenburg et al., 2004; Ronzano et al.,
2010). The word senses provided by WordNet, for
example, have been used for this purpose (O’Hara
et al., 1998).
A recognized data modeling standard for lexi-
cal interoperation is the Lexical Markup Frame-
work (LMF), which provides standardized frame-
work for the description and representation of lex-
icons (Francopoulo et al., 2009). Instantiations of
LMF have also been extended to represent Word-
Nets, e.g., Wordnet-LMF (Soria et al., 2009), in
ways which facilitate interoperation.
While we do not attempt to express the data
model we develop here in LMF, doing so should
be relatively straightforward. The key conceptual
observation is to recognize that the sets of mean-
ing labels found in wordlists (see section 2) can
be treated either as a shared language-neutral on-
tology or as a kind of interlingua, both of which
have already been the subject of LMF modeling
(Vossen, 2004). As such, they are also compa-
rable to language-independent ontologies of word
meaning, bringing them in line with the work on
multilingual NLP mentioned above.
These similarities should not be too surprising.
After all, one of the functions of wordlists has
been to facilitate language comparison, something
which is also at the heart of multilingual NLP.
An important development, however, is that new
data encoding technologies can allow us to en-
code word list data in ways that facilitate its re-
purposing for NLP applications much more easily
than would have been possible previously. We will
come back to this in section 6.
</bodyText>
<sectionHeader confidence="0.991413" genericHeader="method">
5 Modeling Wordlists
</sectionHeader>
<subsectionHeader confidence="0.999076">
5.1 Wordlist Entries as Defective Signs
</subsectionHeader>
<bodyText confidence="0.99954575">
A common linguistic conceptualization of a lexi-
cal item is to treat it as a sign triple: an association
of a form with meaning and grammar. Lexical
items in a lexicon generally contain information
on all three aspects of this triple. Wordlists do not,
and the information they encode is quite sparse.
In general, they give no indication of grammatical
information (e.g., part of speech), nor of language-
specific semantics.
In addition, from a descriptive standpoint, lex-
icons and wordlists differ in the direction of the
form-meaning mapping. As the example in (1)
suggests, in order to create or interpret a wordlist,
one begins with an abstract meaning, for example
MAN, and then tries to find the word in the tar-
get language which represents the best semantic
fit for that meaning. Lexicons, on the other hand,
prototypically map in the opposite direction from
form to meaning. Furthermore, as will be elab-
orated in section 5.3, the meanings employed in
wordlists are not intended to refer to meanings of
lexical items in specific languages. In this way,
they are quite distinct from bilingual dictionaries.
We can therefore view a wordlist as a set of de-
fective signs—containing information on the form
and meaning parts of the triple, but not the gram-
mar. The meaning information is not directly asso-
ciated with the specific form but, rather, is a kind
of “tag” indicating that the entire sign that a given
form is associated with is the best counterpart in
the language for a general concept.
Figure 1 compares the kind of information asso-
ciated with signs in a lexicon to those in a wordlist.
The box on the left gives a schematic form-
grammar-meaning triple for the Spanish word
perro ‘dog’, containing the sort of information that
might be found in a simple bilingual dictionary.
The box on the right schematizes the content of
a parallel French wordlist entry for chien ‘dog’.
Here, no grammatical or semantic information is
associated with the form, but there is an indication
that in French, this lexical item is the closest coun-
terpart to the general concept DOG. Of course, in
this case, the word chien is not only the counter-
part of DOG in French, but can be translated as
dog in English. The semantic connection between
a concept label and a lexical item may not always
be so straightforward, as we will see in section 5.2.
</bodyText>
<figureCaption confidence="0.994956">
Figure 1: Lexicon sign versus wordlist sign
</figureCaption>
<subsectionHeader confidence="0.999589">
5.2 Mapping between Form and Concept
</subsectionHeader>
<bodyText confidence="0.99986575">
A challenge in comparing lexical data among nu-
merous languages is that a complete match be-
tween a word’s meaning and a general concept
rarely occurs within a single language, let alone
</bodyText>
<figure confidence="0.7666276">
perro
noun
dog
chien
DOG
</figure>
<page confidence="0.982754">
3
</page>
<bodyText confidence="0.999985222222222">
across languages (Haspelmath and Tadmor, 2009).
Therefore, in order to describe the relationship be-
tween form and meaning in a wordlist, we use
the term counterpart, in the sense developed by
Haspelmath and Tadmor (2009). This is in con-
trast to related notions like definition or trans-
lation. While the meanings found in wordlists
could, in some cases, be interpreted as definitions
or translations, this is not how they are conceived
of in their core function. Rather, they are intended
to refer to language-independent concepts which
have been determined to be a useful way to begin
to explore the lexicon of a language.
A key property of the counterpart relationship
is that that even if one particular language (e.g.,
English or Spanish) is used to refer to a particular
concept (e.g., MAN), it is not the idiosyncratic se-
mantics of the word in that language that is used to
determine the relevant wordlist entry in the target
language. For instance, the meaning of the English
word MAN is ambiguous between human and male
human but the term in (1) only refers to human.
In using a language of wider communication, the
goal is to find the closest counterpart in the target
language for a general concept, not to translate.
We therefore distinguish between the meanings
associated with words in a given language from
the more general meanings found in wordlists by
using the term concept for the latter. Thus, a
wordlist entry can be schematized as in (2) where
a concept and a lexical item are related by the
hasCounterpart relation. In attested wordlist
entries, the concept is, as discussed, most typically
indexed via a language of wider communication
and a lexical item is indexed via a transcription
representing the lexical item’s form.
</bodyText>
<listItem confidence="0.548767">
(2) CONCEPT hasCounterpart lexicalItem
</listItem>
<bodyText confidence="0.999984684210526">
The counterpart relation is, by design, a rela-
tively imprecise one since a lack of precision fa-
cilitates the relatively rapid data collection that is
considered an important feature of wordlist cre-
ation. The meaning of a given counterpart could
be broader or narrower than that of the relevant
concept, for example (Haspelmath and Tadmor,
2009, p. 9). In principle, the counterpart relation
could be made more precise by specifying, for ex-
ample, that the relevant relation is sub-counterpart
for cases where a word in a target language refers
to a concept narrower than the one referred to in
the word list, as illustrated in (3) for English as
the target language. There are other logical kinds
of counterpart relationships as well (e.g., super-
counterpart), and the example is primarily for il-
lustrative purposes. In our database, we only em-
ploy the counterpart relation since that was the
level of precision found in the original data.
</bodyText>
<listItem confidence="0.9932305">
(3) PARENT’S SIBLING hasSubCounterpart
aunt, uncle
</listItem>
<bodyText confidence="0.999929615384615">
Though the canonical case for the counterpart
relation is that there will be one counterpart for
a given concept, this is often not the case in lan-
guages and in our data. To take an example from
a familiar language, the English counterpart for
MOVIE could reasonably be film or movie, and it
is quite easy to imagine a wordlist for English
containing both words. The entry in (4) from the
dataset we are working with gives an example of
this from a wordlist of North Asmat, a language
spoken in Indonesia. The concept GRANDFATHER
has two counterparts, whose relationship to each
other has not been specified in our source.
</bodyText>
<listItem confidence="0.863512">
(4) GRANDFATHER hasCounterpart -ak, afak
</listItem>
<bodyText confidence="0.9995611">
Data like that in (4) has led us to add an ad-
ditional layer in our model for the mapping be-
tween concept and form allowing for the possibil-
ity that the mapping may actually refer to a group
of forms. With more information, of course, one
may be able to avoid mapping to a group of forms
by, for example, determining that each member of
the group is a sub-counterpart of the relevant con-
cept. However, this information is not available to
us in our dataset.
</bodyText>
<subsectionHeader confidence="0.993079">
5.3 The Concepticon
</subsectionHeader>
<bodyText confidence="0.999239533333333">
The concepts found in wordlists have generally
been grouped into informally standardized lists.
Within our model, we treat these lists as an object
to be modeled in their own right and refer to them
as concepticons (i.e., “concept lexicon”). As will
be discussed in section 6, a concepticon is simi-
lar to an interlingua, though this connection has
rarely, if ever, been explicitly made.
As understood here, concepticons are simply
curated sets of concepts, minimally indexed via
one or more words from a language of wider com-
munication but, perhaps, also more elaborately
described using multiple languages (e.g., English
and Spanish) and illustrative example sentences.
Concepticons may include terms for concepts of
</bodyText>
<page confidence="0.987979">
4
</page>
<bodyText confidence="0.999629714285714">
such general provenance that counterpart words
would be expected to occur in almost all lan-
guages, such as TO EAT, as well as terms that may
occur commonly in only a certain region or lan-
guage family. For instance, Amazonian languages
do not have words for SNOWSHOE or MOSQUE,
and Siberian languages do not have a term for
TOUCAN (Haspelmath and Tadmor, 2009, p. 5–6).
The concepticon we are employing has been
based on three different concept lists. Of these,
the most precise and recently published list is the
Loanword Typology (LWT) concepticon (Haspel-
math and Tadmor, 2009), which consists of 1,460
entries and was developed from the Intercontinen-
tal Dictionary Series2 (IDS) concepticon (1,200
entries). The LWT concepticon often offers more
precision for the same concept than the IDS list.
For instance, the same concept in both LWT and
IDS is described in the LWT list by labeling an
English noun with the article the (5) in order to
clearly distinguish it from a homophonous verb.
</bodyText>
<listItem confidence="0.98775">
(5) LWT: THE DUST
IDS: DUST
</listItem>
<bodyText confidence="0.9969685">
In addition, certain concepts in the IDS concep-
ticon have been expanded in the LWT list to make
it clearer what kinds of words might be treatable
as counterparts.
</bodyText>
<listItem confidence="0.953966">
(6) IDS: THE LOUSE
</listItem>
<sectionHeader confidence="0.573903" genericHeader="method">
LWT: THE LOUSE, HEAD LOUSE, BODY
LOUSE
</sectionHeader>
<bodyText confidence="0.999865066666667">
The concepts in LWT and IDS concepticons re-
fer to a wide range of topics but, for historical
reasons, they are biased towards the geograph-
ical and cultural settings of Europe, southwest
Asia, and (native) South America (Haspelmath
and Tadmor, 2009, p. 6). The unpublished Usher-
Whitehouse concepticon (2,656 entries), used to
collect the bulk of the data used in the work de-
scribed here, includes LWT and IDS concepticons
but also adds new concepts, such as WILDEBEEST
or WATTLE, in order to facilitate the collection of
terms in languages from regions like Africa and
Papua New Guinea. Furthermore, certain concepts
in the LWT and IDS lists are subdivided in the
Usher-Whitehouse concepticon, as shown in (7).
</bodyText>
<footnote confidence="0.920955">
2http://lingweb.eva.mpg.de/ids/
</footnote>
<listItem confidence="0.992895333333333">
(7) 1. LWT: TO BREAK
2. IDS: BREAK, TR
3. Usher-Whitehouse:
</listItem>
<figure confidence="0.897704833333333">
(a) BREAK, INTO PIECES
(b) BREAK, BY IMPACT
(c) BREAK, BY MANIPULATION
(d) BREAK, STRINGS ETC.
(e) BREAK, LONG OBJECTS
(f) BREAK, BRITTLE SURFACES
</figure>
<bodyText confidence="0.998390666666667">
Our unified concepticon combines information
from the LWT, IDS, and Usher-Whitehouse lists.
This allow us to leverage the advantages of the dif-
ferent lists (e.g., the expanded term list in Usher-
Whitehouse against the more detailed concept de-
scriptions of LWT). No wordlist in our database
has entries corresponding to all of the concepts
in our concepticon. Nonetheless, we now have a
dataset with several thousand wordlists whose en-
tries, where present, are linked to the same con-
cepticon, thereby facilitating certain multilingual
and cross-lingual applications.
</bodyText>
<subsectionHeader confidence="0.972554">
5.4 The Overall Structure of a Wordlist
</subsectionHeader>
<bodyText confidence="0.999983090909091">
We schematize our abstract wordlist model in Fig-
ure 2. The oval on the left represents the language
being described, from which the word forms are
drawn (see section 5.1). On the right, the box
represents a concepticon (see section 5.3) where
the concepts are listed as a set of identifiers (e.g.,
1.PERSON) that are associated with labels and re-
lated to their best English counterpart. Of course,
the labels could be drawn from languages other
than English, and other indexing devices, such as
pictures, could also be used.
Counterparts from the language being described
for the relevant concepts are mapped to blocks of
defective signs (most typically containing just one
sign, but not always—see section 5.2) which are,
in turn, associated with a concept. The schema-
tization further illustrates a possibility not yet ex-
plicitly discussed that, due to the relatively impre-
cise nature of the counterpart relation, one group
of forms may be the counterpart for multiple con-
cepts. In short, the mapping between forms and
concepts is not necessarily particularly simple.
</bodyText>
<sectionHeader confidence="0.996824" genericHeader="method">
6 Implementing the Model
</sectionHeader>
<bodyText confidence="0.999864">
We have used the conceptual model for wordlists
developed in section 5 to create a wordlist
</bodyText>
<page confidence="0.880755">
5
</page>
<figure confidence="0.999776210526316">
Described
Variety
of a Language
3. WOMAN
1. PERSON
4. HORSE
2. MAN
5. EWE
Concepticon
inEnglish
&amp;quot;person&amp;quot;
&amp;quot;man&amp;quot;
&amp;quot;woman&amp;quot;
&amp;quot;horse&amp;quot;
inEnglish
&amp;quot;ewe&amp;quot;
.
.
.
</figure>
<figureCaption confidence="0.999765">
Figure 2: Wordlist modeled as a mapping between a language and a concepticon via blocks of signs
</figureCaption>
<bodyText confidence="0.999839903225807">
database using Semantic Web technologies, in par-
ticular RDF/XML, which we expect to have both
research and practical applications.
Each wordlist in our database consists of two
components: a set of metadata and a set of en-
tries. The metadata gives the various identifying
names and codes for the wordlist e.g., a unique
identifier, the ISO 639-3 code, the related Ethno-
logue language name3, alternate language names,
reference(s), the compilers of the wordlist, etc. All
forms in the wordlist are expressed as a sequence
of Unicode characters and annotated with appro-
priate contextual information. In cases where
there is more than one form attached to a concept,
we create multiple concept-form mappings. We do
not explicitly model form groups (see section 2) in
our RDF at present since the data we are working
with is not sufficiently detailed for us to need to
attach information to any particular form group.
Expressing the data encoded in our wordlist
database as RDF triples ensures Semantic Web
compatibility and allows our work to build on
more general work that facilitates sharing and in-
teroperating on linguistic data in a Semantic Web
context (Farrar and Lewis, 2007). An RDF frag-
ment describing the wordlist entry in (6) is given
in Figure 3 for illustrative purposes. In addition
to drawing on standard RDF constructs, we also
make use of descriptive linguistic concepts from
GOLD4 (General Ontology for Linguistic De-
scription), which is intended be a sharable OWL
</bodyText>
<footnote confidence="0.998442">
3http://ethnologue.com/
4http://linguistics-ontology.org/
</footnote>
<bodyText confidence="0.999900121212121">
ontology for language documentation and descrip-
tion (Farrar and Lewis, 2007). The key data en-
coded by our RDF representation is the counter-
part mapping between a particular wordlist con-
cept (lego:concept) drawn from our concep-
ticon and a form (gold:formUnit) found in a
given wordlist. (The “lego” prefix refers to our
internal project namespace.)
An important feature of our RDF encoding is
that the counterpart relation does not relate a con-
cept directly to a form but rather to a linguis-
tic sign (gold:LinguisticSign) whose form
feature contains the relevant specification. This
would allow for additional information about the
lexical element specified by the given form (e.g.,
part of speech, definition) to be added to the rep-
resentation without modification of the model.
Our RDF encoding, at present, is inspired by the
traditional understanding of wordlists, building di-
rectly on work done by linguists (Haspelmath and
Tadmor, 2009). While our use of RDF and an
OWL ontology brings the data into a format allow-
ing for much greater interoperability than would
otherwise be possible, in order to achieve maxi-
mal integration with current efforts in NLP more
could be done. For example, we could devise
an RDF expression of our model compatible with
LMF (Francopoulo et al., 2009) (see section 3).
The most difficult aspect of our model to en-
code in LMF would appear to be the counterpart
relation since core LMF assumes that meanings
will be expressed primarily as language-specific
senses. However, there is work in LMF encod-
</bodyText>
<page confidence="0.981725">
6
</page>
<figure confidence="0.998842307692308">
&lt;rdf:RDF xmlns:rdf=&amp;quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&amp;quot;
xmlns:lego=&amp;quot;http://purl.org/linguistics/lego/&amp;quot;
xmlns:gold=&amp;quot;http://purl.org/linguistics/gold/&amp;quot;&gt;
&lt;lego:concept rdf:about= &amp;quot;http://www.purl.org/linguistics/lego/concept/106&amp;quot;&gt;
&lt;lego:hasConceptID&gt;106&lt;/lego:hasConceptID&gt;
&lt;lego:hasConceptLabel&gt;the grandfather&lt;/lego:hasConceptLabel&gt;
&lt;lego:hasSource&gt;LEGO Project Unified Concepticon&lt;/lego:hasSource&gt;
&lt;lego:hasCounterpart&gt;
&lt;gold:LinguisticSign rdf:about=
&amp;quot;http://www.purl.org/linguistics/North Asmat Voorhoeve/12&amp;quot;&gt;
&lt;gold:inLanguage&gt;
&lt;gold:Language rdf:about=
&amp;quot;http://www.sil.org/ISO639-3/documentation.asp?id=nks&amp;quot;/&gt;
&lt;/gold:inLanguage&gt;
&lt;gold:hasForm&gt;
&lt;gold:formUnit&gt;
&lt;gold:stringRep&gt;-ak&lt;/gold:stringRep&gt;
&lt;/gold:formUnit&gt;
&lt;/gold:hasForm&gt;
&lt;lego:hasSource&gt;Voorhoeve 1980&lt;/lego:hasSource&gt;
&lt;/gold:LinguisticSign&gt;
&lt;/lego:hasCounterpart&gt;
&lt;lego:hasCounterpart&gt;
&lt;gold:LinguisticSign rdf:about=
&amp;quot;http://www.purl.org/linguistics/North Asmat Voorhoeve/13&amp;quot;&gt;
&lt;gold:inLanguage&gt;
&lt;gold:Language rdf:about=
&amp;quot;http://www.sil.org/ISO639-3/documentation.asp?id=nks&amp;quot;/&gt;
&lt;/gold:inLanguage&gt;
&lt;gold:hasForm&gt;
&lt;gold:formUnit&gt;
&lt;gold:stringRep&gt;afak&lt;/gold:stringRep&gt;
&lt;/gold:formUnit&gt;
&lt;/gold:hasForm&gt;
&lt;lego:hasSource&gt;Voorhoeve 1980&lt;/lego:hasSource&gt;
&lt;/gold:LinguisticSign&gt;
&lt;/lego:hasCounterpart&gt;
&lt;/lego:concept&gt;
&lt;/rdf:RDF&gt;
</figure>
<figureCaption confidence="0.999956">
Figure 3: Wordlist Entry RDF Fragment
</figureCaption>
<bodyText confidence="0.9956606">
ing something quite comparable to our notion of
counterpart, namely a SenseAxis, intended to sup-
port interlingual pivots for multilingual resources
(Soria et al., 2009).
As discussed in section 3, the concept labels
used in traditional wordlists can be understood as
a kind of interlingua. Therefore, it seems that
a promising approach for adapting our model to
an LMF model would involve making use of the
SenseAxes. Because of this we believe that it
would be relatively straightforward to adapt our
database in a way which would make it even more
accessible for NLP applications than it is in its
present form, though we leave this as a task for
future work.
</bodyText>
<sectionHeader confidence="0.992691" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<bodyText confidence="0.998457">
We have identified the following dimensions
across which it seems relevant to evaluate our
work against the state of the art: (i) the extent to
which it can be applied generally to wordlist data,
</bodyText>
<listItem confidence="0.968416">
(ii) how it compares to existing wordlist databases,
(iii) how it compares to other work which devel-
ops data models intended to serve as targets for
migration of legacy linguistic data, and (iv) the ex-
tent to which our model can create lexical data that
can straightforwardly interoperate with other lexi-
cal data. We discuss each of these dimensions of
evaluation in turn.
</listItem>
<bodyText confidence="0.501996">
(i) The RDF/XML model described here has
been successfully used to represent the entire core
</bodyText>
<page confidence="0.998048">
7
</page>
<bodyText confidence="0.999952222222222">
dataset being used for this project (see section 2).
This represents around 2,700 wordlists and half a
million forms, suggesting the model is reasonable,
at least as a first attempt. Further testing will re-
quire attempting to incorporate wordlist data from
other sources into our model.
(ii) Wordlists databases have been constructed
for comparative linguistic work for decades. How-
ever, there have not been extensive systematic at-
tempts to encode them in interoperable formats to
the best of our knowledge, and certainly not in-
volving a dataset of the size explored here. The
only comparable project is found in the World
Loanword Database (Haspelmath and Tadmor,
2010) (WOLD) which includes, as a possibility,
an RDF/XML export. This feature of the database
is not explicitly documented, making a direct com-
parison difficult. An examination of the data pro-
duced makes it appear largely similar to the model
proposed here. The database itself covers many
fewer languages (around 40) but has much more
data for each of its entries. In any event, we be-
lieve our project and WOLD are roughly simi-
lar regarding the extent to which the produced re-
sources can be used for multiple purposes, though
it is difficult to examine this in detail at this time
in the absence of better documentation of WOLD.
(iii) As discussed in section 3, most work on
designing data models to facilitate migration of
legacy descriptive data to more modern formats
has used representative data rather than producing
a substantial new resource in its own right. Fur-
thermore, while the data models have been gen-
eral in nature, the data encoding has often been in
parochial XML formats. By producing a substan-
tial resource in a Semantic Web encoding in paral-
lel with the data modeling, we believe our results
exceed most of the comparable work on legacy lin-
guistic data, with the exception of ODIN (Xia and
Lewis, 2009) which has also produced a substan-
tial resource.
(iv) Finally, by building our wordlist model
around the abstract notion of the linguistic sign,
and explicitly referring to the concept of sign
through an OWL ontology, we believe we have
produced a wordlist data model which can produce
data which can straightforwardly interoperate with
data from full lexicons since lexicon entries, too,
can be modeled as signs, as in Figure 1.
Therefore, while our work cannot be straight-
forwardly evaluated with quantitative metrics, we
believe that on a qualitative level it can be evalu-
ated at or above the state of the art across several
key dimensions.
</bodyText>
<sectionHeader confidence="0.994812" genericHeader="conclusions">
8 Applications
</sectionHeader>
<bodyText confidence="0.99998816">
Unlike typical research in NLP, our dataset cov-
ers thousands of minority languages that are oth-
erwise poorly represented. Therefore, while our
data is sparse in many ways, it has a coverage well-
beyond what is normally found.
Crucially, our data model makes visible the sim-
ilarities between a concepticon and an interlingua,
thus opening up a data type produced for descrip-
tive linguistics for use in NLP contexts. In partic-
ular, we have created a resource that we believe
could be exploited for NLP applications where
simple word-to-word mapping across languages is
useful, as in the PanImages5 search of the Pan-
Lex project, which facilitates cross-lingual image
searching. Such a database can also be readily
exploited for machine identification of cognates
and recurrent sound correspondences to test algo-
rithms for language family reconstruction (Kon-
drak et al., 2007; Nerbonne et al., 2007) or to assist
in the automatic identification of phonemic sys-
tems and, thereby, enhance relevant existing work
(Moran and Wright, 2009). We, therefore, think
it represents a useful example of using data mod-
eling and legacy data conversion to find common
ground between descriptive linguistics and NLP.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9993344">
Funding for the work described here was provided
by NSF grant BCS-0753321, and the work is being
done in the context of the larger Lexicon Enhance-
ment via the GOLD Ontology project, headed by
researchers at the Institute for Language Informa-
tion and Technology at Eastern Michigan Univer-
sity. Partial funding for the collection and cura-
tion of the wordlists was provided by the Rosetta
Project (NSF DUE-0333727), along with the Max
Planck Institute for Evolutionary Anthropology.
</bodyText>
<sectionHeader confidence="0.996093" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.768677666666667">
Alison Alvarez, Lori Levin, Robert Frederking, Simon
Fung, Donna Gates, and Jeff Good. 2006. The
MILE corpus for less commonly taught languages.
In NAACL ’06: Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Com-
panion Volume, pages 5–8. ACL.
</reference>
<footnote confidence="0.955058">
5http://www.panimages.org/
</footnote>
<page confidence="0.995403">
8
</page>
<reference confidence="0.998626783783784">
John Bell and Steven Bird. 2000. A preliminary study
of the structure of lexicon entries. In Proceedings
from the Workshop on Web-Based Language Docu-
mentation and Description. Philadelphia, December
12–15, 2000.
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2002. The Grammar Matrix: An open-source
starter-kit for the rapid development of cross-
linguistically consistent broad-coverage precision
grammars. In John Carroll, Nelleke Oostdijk, and
Richard Sutcliffe, editors, Proceedings of the Work-
shop on Grammar Engineering and Evaluation at
the 19th International Conference on Computational
Linguistics, pages 8–14, Taipei, Taiwan.
Steven Bird and Gary Simons. 2003. Seven dimen-
sions of portability for language documention and
description. Language, 79:557–582.
Scott Farrar and William D. Lewis. 2007. The GOLD
Community of Practice: An infrastructure for lin-
guistic data on the Web. Language Resources and
Evaluation, 41:45–60.
Gil Francopoulo, Nuria Bel, Monte George, Nicoletta
Calzolari, Monica Monachini, Mandy Pet, and Clau-
dia Soria. 2009. Multilingual resources for NLP
in the lexical markup framework (LMF). Language
Resources and Evaluation, 43:57–70.
Jeff Good. 2004. The descriptive grammar as a
(meta)database. In Proceedings of the E-MELD
Workshop on Linguistic Databases and Best Prac-
tice. Detroit, Michigan.
Martin Haspelmath and Uri Tadmor. 2009. The Loan-
word Typology Project and the World Loanword
Database. Loanwords in the world’s languages: A
comparative handbook, pages 1–33. Berlin: De
Gruyter.
Martina Haspelmath and Uri Tadmor, editors. 2010.
World Loanword Database. Munich: Max Planck
Digital Library. http://wold.livingsources.org.
Nancy Ide, Daniel Greenstein, and Piek Vossen. 1998.
Introduction to EuroWordNet. Computers and the
Humanities, 32:73–89.
Grzegorz Kondrak, David Beck, and Philip Dilts.
2007. Creating a comparative dictionary of
Totonac-Tepehua. In Proceedings of Ninth Meeting
of the ACL Special Interest Group in Computational
Morphology and Phonology, pages 134–141. ACL.
Steven Moran and Richard Wright. 2009. Pho-
netics Information Base and Lexicon (PHOIBLE).
http://phoible.org.
John Nerbonne, T. Mark Ellison, and Grzegorz Kon-
drak. 2007. Computing and historical phonology.
In Proceedings of Ninth Meeting of the ACL Special
Interest Group in Computational Morphology and
Phonology, pages 1–5. ACL.
Sergei Nirenburg, Marge McShane, and Steve Beale.
2004. The rationale for building resources expressly
for NLP. In 4th International Conference on Lan-
guage Resources and Evaluation, Lisbon, Portugal.
Sebastian Nordhoff. 2008. Electronic reference gram-
mars for typology: Challenges and solutions. Lan-
guage Documentation &amp; Conservation, 2:296–324.
Tom O’Hara, Kavi Mahesh, and Sergei Nirenburg.
1998. Lexical Acquisition with WordNet and the
Mikrokosmos Ontology. In Proceedings of the ACL
Workshop on the Use of WordNet in NLP, pages 94–
101.
Alexis Palmer and Katrin Erk. 2007. IGT-XML: An
XML format for interlinearized glossed text. In
Proceedings of the Linguistic Annotation Workshop,
pages 176–183. ACL.
Alexis Palmer, Taesun Moon, and Jason Baldridge.
2009. Evaluating automation strategies in language
documentation. In Proceedings of the NAACL HLT
2009 Workshop on Active Learning for Natural Lan-
guage Processing, pages 36–44. ACL.
Francesco Ronzano, Maurizio Tesconi, Salvatore Min-
utoli, Andrea Marchetti. 2010. Collaborative man-
agement of KYOTO Multilingual Knowledge Base:
The Wikyoto Knowledge Editor. In Proceedings
of the 5th International Conference of the Global
WordNet Association (GWC-2010). Mumbai, India.
Gary Simons, Brian Fitzsimons, Terence Langendoen,
William Lewis, Scott Farrar, Alexis Lanham, Ruby
Basham, and Hector Gonzalez. 2004. The descrip-
tive grammar as a (meta)database. In Proceedings
of the E-MELD Workshop on Linguistic Databases
and Best Practice. Detroit, Michigan.
Claudia Soria, Monica Monachini, and Piek Vossen.
2009. Wordnet-LMF: Fleshing out a Standard-
ized Format for Wordnet Interoperability. In Inter-
national Workshop on Intercultural Collaboration
(IWIC), pages 139–146. ACM.
Tokunaga Takenobu, Nicoletta Calzolari, Chu-Ren
Huang, Laurent Prevot, Virach Sornlertlamvanich,
Monica Monachini, Xia YingJu, Shirai Kiyoaki,
Thatsanee Charoenporn, Claudia Soria, and Hao,
Yu. 2006. Infrastructure for standardization of
Asian language resources In Proceedings of the
COLING/ACL Main Conference Poster Sessions,
pages 827–834. ACL.
Piek Vossen. 2004. EuroWordNet: A multilin-
gual database of autonomous and language-specific
wordnets connected via an Inter-Lingual-Index. In-
ternational Journal of Lexicography, 17:161–173.
Fei Xia and William D. Lewis. 2009. Applying NLP
technologies to the collection and enrichment of lan-
guage data on the Web to aid linguistic research. In
LaTeCH-SHELT&amp;R ’09: Proceedings of the EACL
2009 Workshop on Language Technology and Re-
sources for Cultural Heritage, Social Sciences, Hu-
manities, and Education, pages 51–59. ACL.
</reference>
<page confidence="0.997083">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.599330">
<title confidence="0.999988">Modeling and Encoding Traditional Wordlists for Machine Applications</title>
<author confidence="0.991956">Shakthi</author>
<affiliation confidence="0.986346">Department of University at</affiliation>
<address confidence="0.75963">Buffalo, NY</address>
<email confidence="0.996464">poornima@buffalo.edu</email>
<author confidence="0.99661">Jeff</author>
<affiliation confidence="0.989446">Department of University at</affiliation>
<address confidence="0.833259">Buffalo, NY</address>
<email confidence="0.999546">jcgood@buffalo.edu</email>
<abstract confidence="0.998163357142857">This paper describes work being done on the modeling and encoding of a legacy resource, the traditional descriptive wordlist, in ways that make its data accessible to NLP applications. We describe an abstract model for traditional wordlist entries and then provide an instantiation of the model in RDF/XML which makes clear the relationship between our wordlist database and interlingua approaches aimed towards machine translation, and which also allows for straightforward interoperation with data from full lexicons.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alison Alvarez</author>
<author>Lori Levin</author>
<author>Robert Frederking</author>
<author>Simon Fung</author>
<author>Donna Gates</author>
<author>Jeff Good</author>
</authors>
<title>The MILE corpus for less commonly taught languages.</title>
<date>2006</date>
<booktitle>In NAACL ’06: Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume,</booktitle>
<pages>5--8</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1489" citStr="Alvarez et al., 2006" startWordPosition="223" endWordPosition="226"> it is typical to focus on the different approaches taken with respect to issues like parsing and generation of natural language data—for example, to compare statistical NLP approaches to those involving grammar engineering. Such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other. However, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources. Even where this is not the case (Bender et al., 2002; Alvarez et al., 2006; Palmer et al., 2009), the resulting products still cover relatively few languages from a worldwide perspective. This is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists, the group of researchers that are most actively involved in documenting the world’s entire linguistic diversity. In fact, one particular descriptive linguistic product, the wordlist—which is the focus of this paper—can be found for at least a quarter of the world’s languages. Clearly, descriptive linguistic resources can be of potential value not just to t</context>
</contexts>
<marker>Alvarez, Levin, Frederking, Fung, Gates, Good, 2006</marker>
<rawString>Alison Alvarez, Lori Levin, Robert Frederking, Simon Fung, Donna Gates, and Jeff Good. 2006. The MILE corpus for less commonly taught languages. In NAACL ’06: Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 5–8. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Bell</author>
<author>Steven Bird</author>
</authors>
<title>A preliminary study of the structure of lexicon entries.</title>
<date>2000</date>
<booktitle>In Proceedings from the Workshop on Web-Based Language Documentation</booktitle>
<contexts>
<context position="6623" citStr="Bell and Bird, 2000" startWordPosition="1039" endWordPosition="1042">tail in section 5, they key features of a wordlist entry are an index to a concept assumed to be of general provenance (e.g., MAN) and a form drawn from a specific language (e.g. homme) determined to be the counterpart for that concept within that language. Most typically, the elements indexing the relevant concepts are words drawn from languages of wider communication (e.g., English or Spanish). 3 Related Work in Descriptive Linguistics Recent years have seen a fair amount of attention paid to the modeling of traditional linguistic data types, including lexicons, glossed texts, and grammars (Bell and Bird, 2000; Good, 2004; Palmer and Erk, 2007; Nordhoff, 2008). The data type of focus here, wordlists, has not seen serious treatment. Superficially, wordlists resemble lexicons and, of course, they can be considered a kind of lexical resource. However, as will be shown in section 5, there are important differences between lexicons and wordlists which have implications for how they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was init</context>
</contexts>
<marker>Bell, Bird, 2000</marker>
<rawString>John Bell and Steven Bird. 2000. A preliminary study of the structure of lexicon entries. In Proceedings from the Workshop on Web-Based Language Documentation and Description. Philadelphia, December 12–15, 2000.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>The Grammar Matrix: An open-source starter-kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars. In</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics,</booktitle>
<pages>8--14</pages>
<editor>John Carroll, Nelleke Oostdijk, and Richard Sutcliffe, editors,</editor>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="1467" citStr="Bender et al., 2002" startWordPosition="219" endWordPosition="222"> NLP and linguistics, it is typical to focus on the different approaches taken with respect to issues like parsing and generation of natural language data—for example, to compare statistical NLP approaches to those involving grammar engineering. Such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other. However, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources. Even where this is not the case (Bender et al., 2002; Alvarez et al., 2006; Palmer et al., 2009), the resulting products still cover relatively few languages from a worldwide perspective. This is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists, the group of researchers that are most actively involved in documenting the world’s entire linguistic diversity. In fact, one particular descriptive linguistic product, the wordlist—which is the focus of this paper—can be found for at least a quarter of the world’s languages. Clearly, descriptive linguistic resources can be of potenti</context>
</contexts>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>Emily M. Bender, Dan Flickinger, and Stephan Oepen. 2002. The Grammar Matrix: An open-source starter-kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars. In John Carroll, Nelleke Oostdijk, and Richard Sutcliffe, editors, Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics, pages 8–14, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Gary Simons</author>
</authors>
<title>Seven dimensions of portability for language documention and description.</title>
<date>2003</date>
<journal>Language,</journal>
<pages>79--557</pages>
<contexts>
<context position="7426" citStr="Bird and Simons, 2003" startWordPosition="1164" endWordPosition="1168">e, they can be considered a kind of lexical resource. However, as will be shown in section 5, there are important differences between lexicons and wordlists which have implications for how they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was initially a response to issues relating to the longevity of digital descriptive data which was, otherwise, quite often being encoded solely in (often proprietary) presentation formats (Bird and Simons, 2003). However, the possibility for fruitful interaction between computational linguistics and descriptive linguistics is apparent and has been the subject of some work (Palmer et al., 2009). The work described here is also interested in this possibility. In particular, we address the question of how to model and encode a large-scale dataset that was originally intended to be used for descriptive purposes in ways that not only allow us to faithfully represent the intention of the original creator but also permit the data to be straightforwardly exploitable for new uses, including NLP. To the best o</context>
</contexts>
<marker>Bird, Simons, 2003</marker>
<rawString>Steven Bird and Gary Simons. 2003. Seven dimensions of portability for language documention and description. Language, 79:557–582.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Farrar</author>
<author>William D Lewis</author>
</authors>
<title>The GOLD Community of Practice: An infrastructure for linguistic data on the Web. Language Resources and Evaluation,</title>
<date>2007</date>
<pages>41--45</pages>
<contexts>
<context position="2733" citStr="Farrar and Lewis, 2007" startWordPosition="422" endWordPosition="425">s, but also to computational linguistics. The difficulty, however, is that the kinds of resources produced in the course of linguistic description are typically not easily exploitable in NLP applications. Nevertheless, in the last decade or so, it has become widely recognized that the development of new digital methods for encoding language data can, in principle, not only help descriptive linguists to work more effectively but also allow them, with relatively little extra effort, to produce resources which can be straightforwardly repurposed for, among other things, NLP (Simons et al., 2004; Farrar and Lewis, 2007). Despite this, it has proven difficult to create significant electronic descriptive resources due to the complex and specific problems inevitably associated with the conversion of legacy data. One exception to this is found in the work done in the context of the ODIN project (Xia and Lewis, 2009), a significant database of interlinear glossed text (IGT), a standard descriptive linguistic data format (Palmer et al., 2009), compiled by searching the Web for legacy instances of IGT. This paper describes another attempt to transform an existing legacy dataset into a more readily repurposable form</context>
<context position="23073" citStr="Farrar and Lewis, 2007" startWordPosition="3775" endWordPosition="3778">with appropriate contextual information. In cases where there is more than one form attached to a concept, we create multiple concept-form mappings. We do not explicitly model form groups (see section 2) in our RDF at present since the data we are working with is not sufficiently detailed for us to need to attach information to any particular form group. Expressing the data encoded in our wordlist database as RDF triples ensures Semantic Web compatibility and allows our work to build on more general work that facilitates sharing and interoperating on linguistic data in a Semantic Web context (Farrar and Lewis, 2007). An RDF fragment describing the wordlist entry in (6) is given in Figure 3 for illustrative purposes. In addition to drawing on standard RDF constructs, we also make use of descriptive linguistic concepts from GOLD4 (General Ontology for Linguistic Description), which is intended be a sharable OWL 3http://ethnologue.com/ 4http://linguistics-ontology.org/ ontology for language documentation and description (Farrar and Lewis, 2007). The key data encoded by our RDF representation is the counterpart mapping between a particular wordlist concept (lego:concept) drawn from our concepticon and a form</context>
</contexts>
<marker>Farrar, Lewis, 2007</marker>
<rawString>Scott Farrar and William D. Lewis. 2007. The GOLD Community of Practice: An infrastructure for linguistic data on the Web. Language Resources and Evaluation, 41:45–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gil Francopoulo</author>
<author>Nuria Bel</author>
<author>Monte George</author>
<author>Nicoletta Calzolari</author>
<author>Monica Monachini</author>
<author>Mandy Pet</author>
<author>Claudia Soria</author>
</authors>
<date>2009</date>
<booktitle>Multilingual resources for NLP in the lexical markup framework (LMF). Language Resources and Evaluation,</booktitle>
<pages>43--57</pages>
<contexts>
<context position="9157" citStr="Francopoulo et al., 2009" startWordPosition="1450" endWordPosition="1453">cused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop here in LMF, doing so should be relatively straightforward. The key conceptual observation is to recognize that the sets of meaning labels found in wordlists (see section 2) can be treated either as a shared language-neutral ontology or as a kind of interlingua, both of which have already been the subject of LMF modeling (Vossen, 2004). As such, they are also comparable to language-in</context>
<context position="24716" citStr="Francopoulo et al., 2009" startWordPosition="4035" endWordPosition="4038">the given form (e.g., part of speech, definition) to be added to the representation without modification of the model. Our RDF encoding, at present, is inspired by the traditional understanding of wordlists, building directly on work done by linguists (Haspelmath and Tadmor, 2009). While our use of RDF and an OWL ontology brings the data into a format allowing for much greater interoperability than would otherwise be possible, in order to achieve maximal integration with current efforts in NLP more could be done. For example, we could devise an RDF expression of our model compatible with LMF (Francopoulo et al., 2009) (see section 3). The most difficult aspect of our model to encode in LMF would appear to be the counterpart relation since core LMF assumes that meanings will be expressed primarily as language-specific senses. However, there is work in LMF encod6 &lt;rdf:RDF xmlns:rdf=&amp;quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&amp;quot; xmlns:lego=&amp;quot;http://purl.org/linguistics/lego/&amp;quot; xmlns:gold=&amp;quot;http://purl.org/linguistics/gold/&amp;quot;&gt; &lt;lego:concept rdf:about= &amp;quot;http://www.purl.org/linguistics/lego/concept/106&amp;quot;&gt; &lt;lego:hasConceptID&gt;106&lt;/lego:hasConceptID&gt; &lt;lego:hasConceptLabel&gt;the grandfather&lt;/lego:hasConceptLabel&gt; &lt;lego:hasS</context>
</contexts>
<marker>Francopoulo, Bel, George, Calzolari, Monachini, Pet, Soria, 2009</marker>
<rawString>Gil Francopoulo, Nuria Bel, Monte George, Nicoletta Calzolari, Monica Monachini, Mandy Pet, and Claudia Soria. 2009. Multilingual resources for NLP in the lexical markup framework (LMF). Language Resources and Evaluation, 43:57–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Good</author>
</authors>
<title>The descriptive grammar as a (meta)database.</title>
<date>2004</date>
<booktitle>In Proceedings of the E-MELD Workshop on Linguistic Databases and Best Practice.</booktitle>
<location>Detroit, Michigan.</location>
<contexts>
<context position="6635" citStr="Good, 2004" startWordPosition="1043" endWordPosition="1044">ey key features of a wordlist entry are an index to a concept assumed to be of general provenance (e.g., MAN) and a form drawn from a specific language (e.g. homme) determined to be the counterpart for that concept within that language. Most typically, the elements indexing the relevant concepts are words drawn from languages of wider communication (e.g., English or Spanish). 3 Related Work in Descriptive Linguistics Recent years have seen a fair amount of attention paid to the modeling of traditional linguistic data types, including lexicons, glossed texts, and grammars (Bell and Bird, 2000; Good, 2004; Palmer and Erk, 2007; Nordhoff, 2008). The data type of focus here, wordlists, has not seen serious treatment. Superficially, wordlists resemble lexicons and, of course, they can be considered a kind of lexical resource. However, as will be shown in section 5, there are important differences between lexicons and wordlists which have implications for how they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was initially a resp</context>
</contexts>
<marker>Good, 2004</marker>
<rawString>Jeff Good. 2004. The descriptive grammar as a (meta)database. In Proceedings of the E-MELD Workshop on Linguistic Databases and Best Practice. Detroit, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
<author>Uri Tadmor</author>
</authors>
<title>The Loanword Typology Project and the World Loanword Database. Loanwords in the world’s languages: A comparative handbook,</title>
<date>2009</date>
<pages>1--33</pages>
<location>Berlin: De Gruyter.</location>
<contexts>
<context position="13075" citStr="Haspelmath and Tadmor, 2009" startWordPosition="2114" endWordPosition="2117"> the general concept DOG. Of course, in this case, the word chien is not only the counterpart of DOG in French, but can be translated as dog in English. The semantic connection between a concept label and a lexical item may not always be so straightforward, as we will see in section 5.2. Figure 1: Lexicon sign versus wordlist sign 5.2 Mapping between Form and Concept A challenge in comparing lexical data among numerous languages is that a complete match between a word’s meaning and a general concept rarely occurs within a single language, let alone perro noun dog chien DOG 3 across languages (Haspelmath and Tadmor, 2009). Therefore, in order to describe the relationship between form and meaning in a wordlist, we use the term counterpart, in the sense developed by Haspelmath and Tadmor (2009). This is in contrast to related notions like definition or translation. While the meanings found in wordlists could, in some cases, be interpreted as definitions or translations, this is not how they are conceived of in their core function. Rather, they are intended to refer to language-independent concepts which have been determined to be a useful way to begin to explore the lexicon of a language. A key property of the c</context>
<context position="15158" citStr="Haspelmath and Tadmor, 2009" startWordPosition="2461" endWordPosition="2464">ted by the hasCounterpart relation. In attested wordlist entries, the concept is, as discussed, most typically indexed via a language of wider communication and a lexical item is indexed via a transcription representing the lexical item’s form. (2) CONCEPT hasCounterpart lexicalItem The counterpart relation is, by design, a relatively imprecise one since a lack of precision facilitates the relatively rapid data collection that is considered an important feature of wordlist creation. The meaning of a given counterpart could be broader or narrower than that of the relevant concept, for example (Haspelmath and Tadmor, 2009, p. 9). In principle, the counterpart relation could be made more precise by specifying, for example, that the relevant relation is sub-counterpart for cases where a word in a target language refers to a concept narrower than the one referred to in the word list, as illustrated in (3) for English as the target language. There are other logical kinds of counterpart relationships as well (e.g., supercounterpart), and the example is primarily for illustrative purposes. In our database, we only employ the counterpart relation since that was the level of precision found in the original data. (3) P</context>
<context position="18023" citStr="Haspelmath and Tadmor, 2009" startWordPosition="2948" endWordPosition="2951">epts, minimally indexed via one or more words from a language of wider communication but, perhaps, also more elaborately described using multiple languages (e.g., English and Spanish) and illustrative example sentences. Concepticons may include terms for concepts of 4 such general provenance that counterpart words would be expected to occur in almost all languages, such as TO EAT, as well as terms that may occur commonly in only a certain region or language family. For instance, Amazonian languages do not have words for SNOWSHOE or MOSQUE, and Siberian languages do not have a term for TOUCAN (Haspelmath and Tadmor, 2009, p. 5–6). The concepticon we are employing has been based on three different concept lists. Of these, the most precise and recently published list is the Loanword Typology (LWT) concepticon (Haspelmath and Tadmor, 2009), which consists of 1,460 entries and was developed from the Intercontinental Dictionary Series2 (IDS) concepticon (1,200 entries). The LWT concepticon often offers more precision for the same concept than the IDS list. For instance, the same concept in both LWT and IDS is described in the LWT list by labeling an English noun with the article the (5) in order to clearly disting</context>
<context position="24372" citStr="Haspelmath and Tadmor, 2009" startWordPosition="3975" endWordPosition="3978">o our internal project namespace.) An important feature of our RDF encoding is that the counterpart relation does not relate a concept directly to a form but rather to a linguistic sign (gold:LinguisticSign) whose form feature contains the relevant specification. This would allow for additional information about the lexical element specified by the given form (e.g., part of speech, definition) to be added to the representation without modification of the model. Our RDF encoding, at present, is inspired by the traditional understanding of wordlists, building directly on work done by linguists (Haspelmath and Tadmor, 2009). While our use of RDF and an OWL ontology brings the data into a format allowing for much greater interoperability than would otherwise be possible, in order to achieve maximal integration with current efforts in NLP more could be done. For example, we could devise an RDF expression of our model compatible with LMF (Francopoulo et al., 2009) (see section 3). The most difficult aspect of our model to encode in LMF would appear to be the counterpart relation since core LMF assumes that meanings will be expressed primarily as language-specific senses. However, there is work in LMF encod6 &lt;rdf:RD</context>
</contexts>
<marker>Haspelmath, Tadmor, 2009</marker>
<rawString>Martin Haspelmath and Uri Tadmor. 2009. The Loanword Typology Project and the World Loanword Database. Loanwords in the world’s languages: A comparative handbook, pages 1–33. Berlin: De Gruyter.</rawString>
</citation>
<citation valid="true">
<date>2010</date>
<booktitle>World Loanword Database. Munich: Max Planck Digital Library. http://wold.livingsources.org.</booktitle>
<editor>Martina Haspelmath and Uri Tadmor, editors.</editor>
<marker>2010</marker>
<rawString>Martina Haspelmath and Uri Tadmor, editors. 2010. World Loanword Database. Munich: Max Planck Digital Library. http://wold.livingsources.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Daniel Greenstein</author>
<author>Piek Vossen</author>
</authors>
<date>1998</date>
<booktitle>Introduction to EuroWordNet. Computers and the Humanities,</booktitle>
<pages>32--73</pages>
<contexts>
<context position="8772" citStr="Ide et al., 1998" startWordPosition="1389" endWordPosition="1392">arallel with the transformation of a legacy resource with significant coverage of the world’s languages. This stands in contrast to most other work (again, with the exception of work done within ODIN (Xia and Lewis, 2009)) whose data, while representative, is not of the same scale. 4 Related Work on Lexicon Interoperability in NLP The relevant related work in NLP is that focused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop he</context>
</contexts>
<marker>Ide, Greenstein, Vossen, 1998</marker>
<rawString>Nancy Ide, Daniel Greenstein, and Piek Vossen. 1998. Introduction to EuroWordNet. Computers and the Humanities, 32:73–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
<author>David Beck</author>
<author>Philip Dilts</author>
</authors>
<title>Creating a comparative dictionary of Totonac-Tepehua.</title>
<date>2007</date>
<booktitle>In Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology,</booktitle>
<pages>134--141</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="31053" citStr="Kondrak et al., 2007" startWordPosition="4931" endWordPosition="4935"> makes visible the similarities between a concepticon and an interlingua, thus opening up a data type produced for descriptive linguistics for use in NLP contexts. In particular, we have created a resource that we believe could be exploited for NLP applications where simple word-to-word mapping across languages is useful, as in the PanImages5 search of the PanLex project, which facilitates cross-lingual image searching. Such a database can also be readily exploited for machine identification of cognates and recurrent sound correspondences to test algorithms for language family reconstruction (Kondrak et al., 2007; Nerbonne et al., 2007) or to assist in the automatic identification of phonemic systems and, thereby, enhance relevant existing work (Moran and Wright, 2009). We, therefore, think it represents a useful example of using data modeling and legacy data conversion to find common ground between descriptive linguistics and NLP. Acknowledgments Funding for the work described here was provided by NSF grant BCS-0753321, and the work is being done in the context of the larger Lexicon Enhancement via the GOLD Ontology project, headed by researchers at the Institute for Language Information and Technolo</context>
</contexts>
<marker>Kondrak, Beck, Dilts, 2007</marker>
<rawString>Grzegorz Kondrak, David Beck, and Philip Dilts. 2007. Creating a comparative dictionary of Totonac-Tepehua. In Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 134–141. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Moran</author>
<author>Richard Wright</author>
</authors>
<date>2009</date>
<booktitle>Phonetics Information Base and Lexicon (PHOIBLE). http://phoible.org.</booktitle>
<contexts>
<context position="31212" citStr="Moran and Wright, 2009" startWordPosition="4957" endWordPosition="4960">ntexts. In particular, we have created a resource that we believe could be exploited for NLP applications where simple word-to-word mapping across languages is useful, as in the PanImages5 search of the PanLex project, which facilitates cross-lingual image searching. Such a database can also be readily exploited for machine identification of cognates and recurrent sound correspondences to test algorithms for language family reconstruction (Kondrak et al., 2007; Nerbonne et al., 2007) or to assist in the automatic identification of phonemic systems and, thereby, enhance relevant existing work (Moran and Wright, 2009). We, therefore, think it represents a useful example of using data modeling and legacy data conversion to find common ground between descriptive linguistics and NLP. Acknowledgments Funding for the work described here was provided by NSF grant BCS-0753321, and the work is being done in the context of the larger Lexicon Enhancement via the GOLD Ontology project, headed by researchers at the Institute for Language Information and Technology at Eastern Michigan University. Partial funding for the collection and curation of the wordlists was provided by the Rosetta Project (NSF DUE-0333727), alon</context>
</contexts>
<marker>Moran, Wright, 2009</marker>
<rawString>Steven Moran and Richard Wright. 2009. Phonetics Information Base and Lexicon (PHOIBLE). http://phoible.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
<author>T Mark Ellison</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Computing and historical phonology.</title>
<date>2007</date>
<booktitle>In Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology,</booktitle>
<pages>1--5</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="31077" citStr="Nerbonne et al., 2007" startWordPosition="4936" endWordPosition="4939">ilarities between a concepticon and an interlingua, thus opening up a data type produced for descriptive linguistics for use in NLP contexts. In particular, we have created a resource that we believe could be exploited for NLP applications where simple word-to-word mapping across languages is useful, as in the PanImages5 search of the PanLex project, which facilitates cross-lingual image searching. Such a database can also be readily exploited for machine identification of cognates and recurrent sound correspondences to test algorithms for language family reconstruction (Kondrak et al., 2007; Nerbonne et al., 2007) or to assist in the automatic identification of phonemic systems and, thereby, enhance relevant existing work (Moran and Wright, 2009). We, therefore, think it represents a useful example of using data modeling and legacy data conversion to find common ground between descriptive linguistics and NLP. Acknowledgments Funding for the work described here was provided by NSF grant BCS-0753321, and the work is being done in the context of the larger Lexicon Enhancement via the GOLD Ontology project, headed by researchers at the Institute for Language Information and Technology at Eastern Michigan U</context>
</contexts>
<marker>Nerbonne, Ellison, Kondrak, 2007</marker>
<rawString>John Nerbonne, T. Mark Ellison, and Grzegorz Kondrak. 2007. Computing and historical phonology. In Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 1–5. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Marge McShane</author>
<author>Steve Beale</author>
</authors>
<title>The rationale for building resources expressly for NLP.</title>
<date>2004</date>
<booktitle>In 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="8810" citStr="Nirenburg et al., 2004" startWordPosition="1395" endWordPosition="1398">of a legacy resource with significant coverage of the world’s languages. This stands in contrast to most other work (again, with the exception of work done within ODIN (Xia and Lewis, 2009)) whose data, while representative, is not of the same scale. 4 Related Work on Lexicon Interoperability in NLP The relevant related work in NLP is that focused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop here in LMF, doing so should be relative</context>
</contexts>
<marker>Nirenburg, McShane, Beale, 2004</marker>
<rawString>Sergei Nirenburg, Marge McShane, and Steve Beale. 2004. The rationale for building resources expressly for NLP. In 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Nordhoff</author>
</authors>
<title>Electronic reference grammars for typology: Challenges and solutions.</title>
<date>2008</date>
<journal>Language Documentation &amp; Conservation,</journal>
<pages>2--296</pages>
<contexts>
<context position="6674" citStr="Nordhoff, 2008" startWordPosition="1049" endWordPosition="1050">y are an index to a concept assumed to be of general provenance (e.g., MAN) and a form drawn from a specific language (e.g. homme) determined to be the counterpart for that concept within that language. Most typically, the elements indexing the relevant concepts are words drawn from languages of wider communication (e.g., English or Spanish). 3 Related Work in Descriptive Linguistics Recent years have seen a fair amount of attention paid to the modeling of traditional linguistic data types, including lexicons, glossed texts, and grammars (Bell and Bird, 2000; Good, 2004; Palmer and Erk, 2007; Nordhoff, 2008). The data type of focus here, wordlists, has not seen serious treatment. Superficially, wordlists resemble lexicons and, of course, they can be considered a kind of lexical resource. However, as will be shown in section 5, there are important differences between lexicons and wordlists which have implications for how they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was initially a response to issues relating to the longevit</context>
</contexts>
<marker>Nordhoff, 2008</marker>
<rawString>Sebastian Nordhoff. 2008. Electronic reference grammars for typology: Challenges and solutions. Language Documentation &amp; Conservation, 2:296–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom O’Hara</author>
<author>Kavi Mahesh</author>
<author>Sergei Nirenburg</author>
</authors>
<title>Lexical Acquisition with WordNet and the Mikrokosmos Ontology.</title>
<date>1998</date>
<booktitle>In Proceedings of the ACL Workshop on the Use of WordNet in NLP,</booktitle>
<pages>94--101</pages>
<marker>O’Hara, Mahesh, Nirenburg, 1998</marker>
<rawString>Tom O’Hara, Kavi Mahesh, and Sergei Nirenburg. 1998. Lexical Acquisition with WordNet and the Mikrokosmos Ontology. In Proceedings of the ACL Workshop on the Use of WordNet in NLP, pages 94– 101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Palmer</author>
<author>Katrin Erk</author>
</authors>
<title>IGT-XML: An XML format for interlinearized glossed text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop,</booktitle>
<pages>176--183</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="6657" citStr="Palmer and Erk, 2007" startWordPosition="1045" endWordPosition="1048">res of a wordlist entry are an index to a concept assumed to be of general provenance (e.g., MAN) and a form drawn from a specific language (e.g. homme) determined to be the counterpart for that concept within that language. Most typically, the elements indexing the relevant concepts are words drawn from languages of wider communication (e.g., English or Spanish). 3 Related Work in Descriptive Linguistics Recent years have seen a fair amount of attention paid to the modeling of traditional linguistic data types, including lexicons, glossed texts, and grammars (Bell and Bird, 2000; Good, 2004; Palmer and Erk, 2007; Nordhoff, 2008). The data type of focus here, wordlists, has not seen serious treatment. Superficially, wordlists resemble lexicons and, of course, they can be considered a kind of lexical resource. However, as will be shown in section 5, there are important differences between lexicons and wordlists which have implications for how they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was initially a response to issues relatin</context>
</contexts>
<marker>Palmer, Erk, 2007</marker>
<rawString>Alexis Palmer and Katrin Erk. 2007. IGT-XML: An XML format for interlinearized glossed text. In Proceedings of the Linguistic Annotation Workshop, pages 176–183. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Palmer</author>
<author>Taesun Moon</author>
<author>Jason Baldridge</author>
</authors>
<title>Evaluating automation strategies in language documentation.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing,</booktitle>
<pages>36--44</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1511" citStr="Palmer et al., 2009" startWordPosition="227" endWordPosition="230">s on the different approaches taken with respect to issues like parsing and generation of natural language data—for example, to compare statistical NLP approaches to those involving grammar engineering. Such comparison is undoubtedly important insofar as it helps us understand how computational methods that are derived from these two lines of research can complement each other. However, one thing that the two areas of work have in common is that they tend to focus on majority languages and majority language resources. Even where this is not the case (Bender et al., 2002; Alvarez et al., 2006; Palmer et al., 2009), the resulting products still cover relatively few languages from a worldwide perspective. This is in part because such work cannot easily make use of the extensive language resources produced by descriptive linguists, the group of researchers that are most actively involved in documenting the world’s entire linguistic diversity. In fact, one particular descriptive linguistic product, the wordlist—which is the focus of this paper—can be found for at least a quarter of the world’s languages. Clearly, descriptive linguistic resources can be of potential value not just to traditional linguistics</context>
<context position="3158" citStr="Palmer et al., 2009" startWordPosition="489" endWordPosition="492">but also allow them, with relatively little extra effort, to produce resources which can be straightforwardly repurposed for, among other things, NLP (Simons et al., 2004; Farrar and Lewis, 2007). Despite this, it has proven difficult to create significant electronic descriptive resources due to the complex and specific problems inevitably associated with the conversion of legacy data. One exception to this is found in the work done in the context of the ODIN project (Xia and Lewis, 2009), a significant database of interlinear glossed text (IGT), a standard descriptive linguistic data format (Palmer et al., 2009), compiled by searching the Web for legacy instances of IGT. This paper describes another attempt to transform an existing legacy dataset into a more readily repurposable format. Our data consists of traditional descriptive wordlists originally collected for comparative and historical linguistic research.&apos; Wordlists have been widely employed as a first step towards the creation of a dictionary or as a means to quickly gather information about a language for the purposes of language comparison (especially in parts of the world where languages &apos;These wordlists were collected by Timothy Usher and</context>
<context position="7611" citStr="Palmer et al., 2009" startWordPosition="1191" endWordPosition="1194">w they should be modeled. Most of the work on modeling descriptive linguistic data types has proceeded without special consideration for possible NLP applications for the data being encoded. This is largely because the work was initially a response to issues relating to the longevity of digital descriptive data which was, otherwise, quite often being encoded solely in (often proprietary) presentation formats (Bird and Simons, 2003). However, the possibility for fruitful interaction between computational linguistics and descriptive linguistics is apparent and has been the subject of some work (Palmer et al., 2009). The work described here is also interested in this possibility. In particular, we address the question of how to model and encode a large-scale dataset that was originally intended to be used for descriptive purposes in ways that not only allow us to faithfully represent the intention of the original creator but also permit the data to be straightforwardly exploitable for new uses, including NLP. To the best of our knowledge, our work is innovative both because of the data type being explored and because the data modeling is being done parallel with the transformation of a legacy resource wi</context>
</contexts>
<marker>Palmer, Moon, Baldridge, 2009</marker>
<rawString>Alexis Palmer, Taesun Moon, and Jason Baldridge. 2009. Evaluating automation strategies in language documentation. In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing, pages 36–44. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesco Ronzano</author>
<author>Maurizio Tesconi</author>
<author>Salvatore Minutoli</author>
<author>Andrea Marchetti</author>
</authors>
<title>Collaborative management of KYOTO Multilingual Knowledge Base: The Wikyoto Knowledge Editor.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Conference of the Global WordNet Association (GWC-2010).</booktitle>
<location>Mumbai, India.</location>
<contexts>
<context position="8833" citStr="Ronzano et al., 2010" startWordPosition="1399" endWordPosition="1402">h significant coverage of the world’s languages. This stands in contrast to most other work (again, with the exception of work done within ODIN (Xia and Lewis, 2009)) whose data, while representative, is not of the same scale. 4 Related Work on Lexicon Interoperability in NLP The relevant related work in NLP is that focused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop here in LMF, doing so should be relatively straightforward. The</context>
</contexts>
<marker>Ronzano, Tesconi, Minutoli, Marchetti, 2010</marker>
<rawString>Francesco Ronzano, Maurizio Tesconi, Salvatore Minutoli, Andrea Marchetti. 2010. Collaborative management of KYOTO Multilingual Knowledge Base: The Wikyoto Knowledge Editor. In Proceedings of the 5th International Conference of the Global WordNet Association (GWC-2010). Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Simons</author>
<author>Brian Fitzsimons</author>
<author>Terence Langendoen</author>
<author>William Lewis</author>
<author>Scott Farrar</author>
<author>Alexis Lanham</author>
<author>Ruby Basham</author>
<author>Hector Gonzalez</author>
</authors>
<title>The descriptive grammar as a (meta)database.</title>
<date>2004</date>
<booktitle>In Proceedings of the E-MELD Workshop on Linguistic Databases and</booktitle>
<location>Detroit, Michigan.</location>
<contexts>
<context position="2708" citStr="Simons et al., 2004" startWordPosition="418" endWordPosition="421">raditional linguistics, but also to computational linguistics. The difficulty, however, is that the kinds of resources produced in the course of linguistic description are typically not easily exploitable in NLP applications. Nevertheless, in the last decade or so, it has become widely recognized that the development of new digital methods for encoding language data can, in principle, not only help descriptive linguists to work more effectively but also allow them, with relatively little extra effort, to produce resources which can be straightforwardly repurposed for, among other things, NLP (Simons et al., 2004; Farrar and Lewis, 2007). Despite this, it has proven difficult to create significant electronic descriptive resources due to the complex and specific problems inevitably associated with the conversion of legacy data. One exception to this is found in the work done in the context of the ODIN project (Xia and Lewis, 2009), a significant database of interlinear glossed text (IGT), a standard descriptive linguistic data format (Palmer et al., 2009), compiled by searching the Web for legacy instances of IGT. This paper describes another attempt to transform an existing legacy dataset into a more </context>
</contexts>
<marker>Simons, Fitzsimons, Langendoen, Lewis, Farrar, Lanham, Basham, Gonzalez, 2004</marker>
<rawString>Gary Simons, Brian Fitzsimons, Terence Langendoen, William Lewis, Scott Farrar, Alexis Lanham, Ruby Basham, and Hector Gonzalez. 2004. The descriptive grammar as a (meta)database. In Proceedings of the E-MELD Workshop on Linguistic Databases and Best Practice. Detroit, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Soria</author>
<author>Monica Monachini</author>
<author>Piek Vossen</author>
</authors>
<title>Wordnet-LMF: Fleshing out a Standardized Format for Wordnet Interoperability.</title>
<date>2009</date>
<booktitle>In International Workshop on Intercultural Collaboration (IWIC),</booktitle>
<pages>139--146</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9266" citStr="Soria et al., 2009" startWordPosition="1467" endWordPosition="1470">ologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop here in LMF, doing so should be relatively straightforward. The key conceptual observation is to recognize that the sets of meaning labels found in wordlists (see section 2) can be treated either as a shared language-neutral ontology or as a kind of interlingua, both of which have already been the subject of LMF modeling (Vossen, 2004). As such, they are also comparable to language-independent ontologies of word meaning, bringing them in line with the work on multilingual NLP mentioned above</context>
<context position="26464" citStr="Soria et al., 2009" startWordPosition="4165" endWordPosition="4168">df:about= &amp;quot;http://www.purl.org/linguistics/North Asmat Voorhoeve/13&amp;quot;&gt; &lt;gold:inLanguage&gt; &lt;gold:Language rdf:about= &amp;quot;http://www.sil.org/ISO639-3/documentation.asp?id=nks&amp;quot;/&gt; &lt;/gold:inLanguage&gt; &lt;gold:hasForm&gt; &lt;gold:formUnit&gt; &lt;gold:stringRep&gt;afak&lt;/gold:stringRep&gt; &lt;/gold:formUnit&gt; &lt;/gold:hasForm&gt; &lt;lego:hasSource&gt;Voorhoeve 1980&lt;/lego:hasSource&gt; &lt;/gold:LinguisticSign&gt; &lt;/lego:hasCounterpart&gt; &lt;/lego:concept&gt; &lt;/rdf:RDF&gt; Figure 3: Wordlist Entry RDF Fragment ing something quite comparable to our notion of counterpart, namely a SenseAxis, intended to support interlingual pivots for multilingual resources (Soria et al., 2009). As discussed in section 3, the concept labels used in traditional wordlists can be understood as a kind of interlingua. Therefore, it seems that a promising approach for adapting our model to an LMF model would involve making use of the SenseAxes. Because of this we believe that it would be relatively straightforward to adapt our database in a way which would make it even more accessible for NLP applications than it is in its present form, though we leave this as a task for future work. 7 Evaluation We have identified the following dimensions across which it seems relevant to evaluate our wo</context>
</contexts>
<marker>Soria, Monachini, Vossen, 2009</marker>
<rawString>Claudia Soria, Monica Monachini, and Piek Vossen. 2009. Wordnet-LMF: Fleshing out a Standardized Format for Wordnet Interoperability. In International Workshop on Intercultural Collaboration (IWIC), pages 139–146. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tokunaga Takenobu</author>
<author>Nicoletta Calzolari</author>
<author>Chu-Ren Huang</author>
<author>Laurent Prevot</author>
<author>Virach Sornlertlamvanich</author>
<author>Monica Monachini</author>
<author>Xia YingJu</author>
<author>Shirai Kiyoaki</author>
<author>Thatsanee Charoenporn</author>
<author>Claudia Soria</author>
<author>Yu Hao</author>
</authors>
<title>Infrastructure for standardization of Asian language resources</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL Main Conference Poster Sessions,</booktitle>
<pages>827--834</pages>
<publisher>ACL.</publisher>
<marker>Takenobu, Calzolari, Huang, Prevot, Sornlertlamvanich, Monachini, YingJu, Kiyoaki, Charoenporn, Soria, Hao, 2006</marker>
<rawString>Tokunaga Takenobu, Nicoletta Calzolari, Chu-Ren Huang, Laurent Prevot, Virach Sornlertlamvanich, Monica Monachini, Xia YingJu, Shirai Kiyoaki, Thatsanee Charoenporn, Claudia Soria, and Hao, Yu. 2006. Infrastructure for standardization of Asian language resources In Proceedings of the COLING/ACL Main Conference Poster Sessions, pages 827–834. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: A multilingual database of autonomous and language-specific wordnets connected via an Inter-Lingual-Index.</title>
<date>2004</date>
<journal>International Journal of Lexicography,</journal>
<pages>17--161</pages>
<contexts>
<context position="8786" citStr="Vossen, 2004" startWordPosition="1393" endWordPosition="1394">ransformation of a legacy resource with significant coverage of the world’s languages. This stands in contrast to most other work (again, with the exception of work done within ODIN (Xia and Lewis, 2009)) whose data, while representative, is not of the same scale. 4 Related Work on Lexicon Interoperability in NLP The relevant related work in NLP is that focused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard for lexical interoperation is the Lexical Markup Framework (LMF), which provides standardized framework for the description and representation of lexicons (Francopoulo et al., 2009). Instantiations of LMF have also been extended to represent WordNets, e.g., Wordnet-LMF (Soria et al., 2009), in ways which facilitate interoperation. While we do not attempt to express the data model we develop here in LMF, doi</context>
</contexts>
<marker>Vossen, 2004</marker>
<rawString>Piek Vossen. 2004. EuroWordNet: A multilingual database of autonomous and language-specific wordnets connected via an Inter-Lingual-Index. International Journal of Lexicography, 17:161–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William D Lewis</author>
</authors>
<title>Applying NLP technologies to the collection and enrichment of language data on the Web to aid linguistic research.</title>
<date>2009</date>
<booktitle>In LaTeCH-SHELT&amp;R ’09: Proceedings of the EACL 2009 Workshop on Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education,</booktitle>
<pages>51--59</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="3031" citStr="Xia and Lewis, 2009" startWordPosition="471" endWordPosition="474">new digital methods for encoding language data can, in principle, not only help descriptive linguists to work more effectively but also allow them, with relatively little extra effort, to produce resources which can be straightforwardly repurposed for, among other things, NLP (Simons et al., 2004; Farrar and Lewis, 2007). Despite this, it has proven difficult to create significant electronic descriptive resources due to the complex and specific problems inevitably associated with the conversion of legacy data. One exception to this is found in the work done in the context of the ODIN project (Xia and Lewis, 2009), a significant database of interlinear glossed text (IGT), a standard descriptive linguistic data format (Palmer et al., 2009), compiled by searching the Web for legacy instances of IGT. This paper describes another attempt to transform an existing legacy dataset into a more readily repurposable format. Our data consists of traditional descriptive wordlists originally collected for comparative and historical linguistic research.&apos; Wordlists have been widely employed as a first step towards the creation of a dictionary or as a means to quickly gather information about a language for the purpose</context>
<context position="8377" citStr="Xia and Lewis, 2009" startWordPosition="1322" endWordPosition="1325">dataset that was originally intended to be used for descriptive purposes in ways that not only allow us to faithfully represent the intention of the original creator but also permit the data to be straightforwardly exploitable for new uses, including NLP. To the best of our knowledge, our work is innovative both because of the data type being explored and because the data modeling is being done parallel with the transformation of a legacy resource with significant coverage of the world’s languages. This stands in contrast to most other work (again, with the exception of work done within ODIN (Xia and Lewis, 2009)) whose data, while representative, is not of the same scale. 4 Related Work on Lexicon Interoperability in NLP The relevant related work in NLP is that focused on interoperation among lexical resources. One way to achieve this is to make use of language independent ontologies (or comparable objects) for word meanings which can serve as pivots for mul2 tilingual applications (Ide et al., 1998; Vossen, 2004; Nirenburg et al., 2004; Ronzano et al., 2010). The word senses provided by WordNet, for example, have been used for this purpose (O’Hara et al., 1998). A recognized data modeling standard f</context>
<context position="29524" citStr="Xia and Lewis, 2009" startWordPosition="4685" endWordPosition="4688">ter documentation of WOLD. (iii) As discussed in section 3, most work on designing data models to facilitate migration of legacy descriptive data to more modern formats has used representative data rather than producing a substantial new resource in its own right. Furthermore, while the data models have been general in nature, the data encoding has often been in parochial XML formats. By producing a substantial resource in a Semantic Web encoding in parallel with the data modeling, we believe our results exceed most of the comparable work on legacy linguistic data, with the exception of ODIN (Xia and Lewis, 2009) which has also produced a substantial resource. (iv) Finally, by building our wordlist model around the abstract notion of the linguistic sign, and explicitly referring to the concept of sign through an OWL ontology, we believe we have produced a wordlist data model which can produce data which can straightforwardly interoperate with data from full lexicons since lexicon entries, too, can be modeled as signs, as in Figure 1. Therefore, while our work cannot be straightforwardly evaluated with quantitative metrics, we believe that on a qualitative level it can be evaluated at or above the stat</context>
</contexts>
<marker>Xia, Lewis, 2009</marker>
<rawString>Fei Xia and William D. Lewis. 2009. Applying NLP technologies to the collection and enrichment of language data on the Web to aid linguistic research. In LaTeCH-SHELT&amp;R ’09: Proceedings of the EACL 2009 Workshop on Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education, pages 51–59. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>