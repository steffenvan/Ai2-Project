<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.6541765">
Cross-language and Cross-encyclopedia Article Linking Using
Mixed-language Topic Model and Hypernym Translation
</title>
<author confidence="0.827387">
Chun-Kai Wu
</author>
<affiliation confidence="0.774015666666667">
Department of CSIE
National Tsinghua University
Hsinchu, Taiwan
</affiliation>
<email confidence="0.3820065">
s102065512@m102.
nthu.edu.tw
</email>
<author confidence="0.981645">
Yu-Chun Wang
</author>
<affiliation confidence="0.938701333333333">
Department of CSIE
National Taiwan University
Taipei, Taiwan
</affiliation>
<email confidence="0.988109">
d97023@csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.994565" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999728714285714">
Creating cross-language article links
among different online encyclopedias is
now an important task in the unification
of multilingual knowledge bases. In this
paper, we propose a cross-language article
linking method using a mixed-language
topic model and hypernym translation
features based on an SVM model to link
English Wikipedia and Chinese Baidu
Baike, the most widely used Wiki-like
encyclopedia in China. To evaluate our
approach, we compile a data set from the
top 500 Baidu Baike articles and their
corresponding English Wiki articles. The
evaluation results show that our approach
achieves 80.95% in MRR and 87.46%
in recall. Our method does not heavily
depend on linguistic characteristics and
can be easily extended to generate cross-
language article links among different
online encyclopedias in other languages.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.980612">
Online encyclopedias are among the most fre-
quently used Internet services today. One of
the largest and best known online encyclopedias
is Wikipedia. Wikipedia has many language ver-
sions, and articles in one language contain hyper-
links to corresponding pages in other languages.
However, the coverage of different language ver-
sions of Wikipedia is very inconsistent. Table 1
shows the statistics of inter-language link pages
in the English and Chinese editions in February
2014. The total number of Chinese articles is
about one-quarter of English ones, and only 2.3%
of English articles have inter-language links to
their Chinese versions.
</bodyText>
<note confidence="0.443652">
∗corresponding author
</note>
<author confidence="0.866962">
Richard Tzong-Han Tsai∗
</author>
<affiliation confidence="0.953242">
Department of CSIE
National Central University
Chungli, Taiwan
</affiliation>
<email confidence="0.88592">
thtsai@csie.ncu.edu.tw
</email>
<table confidence="0.982460333333333">
Articles Inter-language Links Ratio
zh 755,628 zh2en 486,086 64.3%
en 4,470,246 en2zh 106,729 2.3%
</table>
<tableCaption confidence="0.999555">
Table 1: Inter-Language Links in Wikipedia
</tableCaption>
<bodyText confidence="0.999982514285714">
However, there are alternatives to Wikipedia for
some languages. In China, for example Baidu
Baike and Hudong are the largest encyclopedia
sites, containing more than 6.2 and 7 million Chi-
nese articles respectively. Similarly, in Korea,
Naver Knowledge Encyclopedia has a large pres-
ence.
Since alternative encyclopedias like Baidu
Baike are larger (by article count) and growing
faster than the Chinese Wikipedia, it is worth-
while to investigate creating cross-language links
among different online encyclopedias. Several
works have focused on creating cross-language
links between Wikipedia language versions (Oh
et al., 2008; Sorg and Cimiano, 2008) or find-
ing a cross-language link for each entity mention
in a Wikipedia article, namely Cross-Language
Link Discovery (CLLD) (Tang et al., 2013; Mc-
Namee et al., 2011). These works were able to
exploit the link structure and metadata common
to all Wikipedia language versions. However,
when linking between different online encyclope-
dia platforms this is more difficult as many of these
structural features are different or not shared. To
date, little research has been done into linking be-
tween encyclopedias on different platforms.
Title translation is an effective and widely used
method of creating cross-language links between
encyclopedia articles. (Wang et al., 2012; Adafre
and de Rijke, 2005) However, title translation
alone is not always sufficient. In some cases, for
example, the titles of corresponding articles in dif-
ferent languages do not even match. Other meth-
ods must be used along with title translation to cre-
ate a more robust linking tool.
</bodyText>
<page confidence="0.977634">
586
</page>
<bodyText confidence="0.8701767">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 586–591,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
In this paper, we propose a method compris-
ing title and hypernym translation and mixed-
language topic model methods to select and link
related articles between the English Wikipedia and
Baidu Baike online encyclopedias. We also com-
pile a suitable dataset from the above two ency-
clopedias to evaluate the linking accuracy of our
method.
</bodyText>
<sectionHeader confidence="0.929127" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.9996930625">
Cross-language article linking between different
encyclopedias can be formulated as follows: For
each encyclopedia K, a collection of human-
written articles, can be defined as K = {ai}ni=1,
where ai is an article in K and n is the size of
K. Article linking can then be defined as fol-
lows: Given two encyclopedia K1 and K2, cross-
language article linking is the task of finding the
corresponding equivalent article aj from encyclo-
pedia K2 for each article ai from encyclopedia
K1. Equivalent articles are articles that describe
the same topic in different languages.
Our approach to cross-language article linking
comprises two stages: candidate selection, which
produces a list of candidate articles, and candidate
ranking, which ranks that list.
</bodyText>
<subsectionHeader confidence="0.997234">
2.1 Candidate Selection
</subsectionHeader>
<bodyText confidence="0.9999395">
Since knowledge bases (KB) may contain millions
of articles, comparison between all possible pairs
in two knowledge bases is time-consuming and
sometimes impractical. To avoid brute-force com-
parison, we first select plausible candidate articles
on which to focus our efforts. To extract possible
candidates, two similarity calculation methods are
carried out: title matching and title similarity.
</bodyText>
<subsectionHeader confidence="0.841837">
2.1.1 Title Matching
</subsectionHeader>
<bodyText confidence="0.99997837037037">
In our title matching method, we formulate can-
didate selection as an English-Chinese cross-
language information retrieval (CLIR) problem
(Sch¨onhofen et al., 2008), in which every English
article’s title is treated as a query and all the arti-
cles in the Chinese encyclopedia are treated as the
documents. We employ the two main CLIR meth-
ods: query translation and document translation.
In query translation, we translate the title of ev-
ery English article into Chinese and then use these
translated titles as queries to retrieve articles from
the Chinese encyclopedia. In document transla-
tion, we translate the contents of the entire Chinese
encyclopedia into English and then search them
using the original English titles. The top 100 re-
sults for the query-translation and the top 100 re-
sults for document-translation steps are unionized.
The resulting list contains our title-matching can-
didates.
For the query- and document-translation steps,
we use the Lucene search engine with similar-
ity scores calculated by the Okapi BM25 ranking
function (Beaulieu et al., 1997). We separate all
words in the translated and original English article
titles with the “OR” operator before submission to
the search engine. For all E-C and C-E translation
tasks, we use Google Translate.
</bodyText>
<subsectionHeader confidence="0.528969">
2.1.2 Title Similarity
</subsectionHeader>
<bodyText confidence="0.99946125">
In the title similarity method, every Chinese arti-
cle title is represented as a vector, and each dis-
tinct character in all these titles is a dimension of
all vectors. The title of each English article is
translated into Chinese and represented as a vec-
tor. Then, cosine similarity between this vector
and the vector of each Chinese title is measured as
title similarity.
</bodyText>
<subsectionHeader confidence="0.999685">
2.2 Candidate Ranking
</subsectionHeader>
<bodyText confidence="0.971285230769231">
The second stage of our approach is to score
each viable candidate using a supervised learning
method, and then sort all candidates in order of
score from high to low as final output.
Each article xi in KB K1 can be
represented by a feature vector xi =
(f1(xi), f2(xi), ... , fn(xi)). Also, we have
yj = (f1(yj), f2(yj), ... , fn(yj)) for a candidate
article yj in KB K2. Then, individual feature
functions Fk(xi, yj) are based on the feature
properties of both article ai and aj. The top pre-
dicted corresponding article yj in the knowledge
base K2 for an input article xi in K1 should
receive a higher score than any other entity in
K2, am E K2, m =� j. We use the support
vector machine (SVM) approach to determine the
probability of each pair (xi, yj) being equivalent.
Our SVM model’s features are described below.
Title Matching and Title Similarity Feature
(Baseline)
We use the results of title matching and title sim-
ilarity from the candidate selection stage as two
features for the candidate ranking stage. The sim-
ilarity values generated by title matching and title
similarity are used directly as real value features
in the SVM model.
</bodyText>
<page confidence="0.991915">
587
</page>
<sectionHeader confidence="0.695111" genericHeader="method">
Mixed-language Topic Model Feature (MTM)
</sectionHeader>
<bodyText confidence="0.999803171428571">
For a linked English-Chinese article pair, the dis-
tribution of words used in each usually shows
some convergence. The two semantically corre-
sponding articles often have many related terms,
which results in clusters of specific words. If two
articles do not describe the same topic, the distri-
bution of terms is often scattered. (Misra et al.,
2008) Thus, the distribution of terms is good mea-
surement of article similarity.
Because the number of all possible words is too
large, we adopt a topic model to gather the words
into some latent topics. For this feature, we use
the Latent Dirichlet Allocation (LDA) (Blei et al.,
2003). LDA can be seen as a typical probabilistic
approach to latent topic computation. Each topic
is represented by a distribution of words, and each
word has a probability score used to measure its
contribution to the topic. To train the LDA model,
the pair English and Chinese articles are concate-
nated into a single document. English and Chinese
terms are all regarded as terms of the same lan-
guage and the LDA topic model, namely mixed-
language topic model, generates both English and
Chinese terms for each latent topic. Then, for each
English article and Chinese candidate pair in test-
ing, the LDA model provides the distribution of
the latent topics. Next, we can use entropy to mea-
sure the distribution of topics. The entropy of the
estimated topic distribution of a related article is
expected to be lower than that of an unrelated ar-
ticle. We can calculate the entropy of the distribu-
tion as a value for SVM. The entropy is defined as
follows:
where T is the number of latent topics, Bdj is the
topic distribution of a given topic j.
</bodyText>
<subsectionHeader confidence="0.848723">
Hypernym Translation Feature (HT)
</subsectionHeader>
<bodyText confidence="0.998446025641026">
The first sentence of an encyclopedia article usu-
ally contains the title of the article. It may also
contain a hypernym that defines the category of
the article. For example, the first sentence of the
“iPad” article in the English Wikipedia begins,
“iPad is a line of tablet computers designed and
marketed by Apple Inc...” In this sentence, the
term “tablet computers” is the hypernym of iPad.
These extracted hypernyms can be treated as arti-
cle categories. Therefore, articles containing the
same hypernym are likely to belong to the same
category.
In this study, we only carry out title hypernym
extraction on the first sentences of English articles
due to the looser syntactic structure of Chinese. To
generate dependency parse trees for the sentences,
we adopt the Stanford Dependency Parser. Then,
we manually designed seven patterns to extract hy-
pernyms from the parse tree structures. To demon-
strate this idea, let us take the English article “The
Hunger Games” for example. The first sentence of
this article is “The Hunger Games is a 2008 young
adult novel by American writer Suzanne Collins.”
Since article titles may be named entities or com-
pound nouns, the dependency parser may mislabel
them and thus output an incorrect parse tree. To
avoid this problem, we first replace all instances of
an article’s title in the first sentence with pronouns.
For example, the previous sentence is rewritten as
“It is a 2008 young adult novel by American writer
Suzanne Collins.” Then, the dependency parser
generates the following parse tree:
novel
suzanne writer American
Next, we apply our predefined syntactic patterns
to extract the hypernym. (Hearst, 1992) If any pat-
tern matches the structure of the dependency parse
tree, the hypernym can be extracted. In the above
example, the following pattern is matched:
</bodyText>
<equation confidence="0.756666333333333">
[target]
nsubj cop nn
It is NN
</equation>
<bodyText confidence="0.999860444444444">
In this pattern, the rightmost leaf is the hyper-
nym target. Thus, we can extract the hypernym
“novel” from the previous example. The term
“novel” is the extracted hypernym of the English
article “The Hunger Games”.
After extracting the hypernym of the English ar-
ticle, the hypernym is translated into Chinese. The
value of this feature in the SVM model is calcu-
lated as follows:
</bodyText>
<equation confidence="0.979529">
Fhypernym(h) = log count(translated(h))
</equation>
<bodyText confidence="0.999853">
where h is the hypernym, translated(h) is the
Chinese translation of the term h.
</bodyText>
<subsectionHeader confidence="0.582891">
English Title Occurrence Feature (ETO)
</subsectionHeader>
<bodyText confidence="0.999702333333333">
In a Baidu Baike article, the first sentence may
contain a parenthetical translation of the main ti-
tle. For example, the first sentence of the Chinese
</bodyText>
<equation confidence="0.910495">
�Bdj
H = −
Bdj log
T
E
j=1
nsubj prep_by
</equation>
<bodyText confidence="0.79192525">
cop det num amod nn
It is a 2008 young adult collins
nn amod nn
NN
</bodyText>
<page confidence="0.992498">
588
</page>
<bodyText confidence="0.959415857142857">
article on San Francisco is “旧金山(San Fran-
cisco),又译‘圣弗朗西斯科’、‘三藩市’。”.
We regard the appearance of the English title in
the first sentence of a Baidu Baike article as a bi-
nary feature: If the English title appears in the first
sentence, the value of this feature is 1; otherwise,
the value is 0.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="method">
3 Evalutaion
</sectionHeader>
<subsectionHeader confidence="0.999576">
3.1 Evaluation Dataset
</subsectionHeader>
<bodyText confidence="0.999997742857143">
In order to evaluate the performance of cross-
language article linking between English Wikiep-
dia and Chinese Baidu Baike, we compile
an English-Chinese evaluation dataset from
Wikipedia and Baidu Baike online encyclopedias.
First, our spider crawls the entire contents of En-
glish Wikipedia and Chinese Baidu Baike. Since
the two encyclopedias’ article formats differ, we
copy the information in each article (title, content,
category, etc.) into a standardized XML structure.
In order to generate the gold standard evalua-
tion sets of correct English and Chinese article
pairs, we automatically collect English-Chinese
inter-language links from Wikipedia. For pairs
that have both English and Chinese articles, the
Chinese article title is regarded as the translation
of the English one. Next, we check if there is a
Chinese article in Baidu Baike with exactly the
same title as the one in Chinese Wikipedia. If
so, the corresponding English Wikipedia article
and the Baidu Baike article are paired in the gold
standard.
To evaluate the performance of our method on
linking different types of encyclopedia articles, we
compile a set containing the most popular articles.
We select the top 500 English-Chinese article pairs
with the highest page view counts in Baidu Baike.
This set represents the articles people in China are
most interested in.
Because our approach uses an SVM model, the
data set should be split into training and test sets.
For statistical generality, each data set is randomly
split 4:1 (training:test) 30 times. The final evalua-
tion results are calculated as the mean of the aver-
age of these 30 evaluation sets.
</bodyText>
<subsectionHeader confidence="0.996032">
3.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999978625">
To measure the quality of cross-language entity
linking, we use the following three metrics. For
each English article queries, ten output Baidu
Baike candidates are generated in a ranked list. To
define the metrics, we use following notations: N
is the number of English query; ri,j is j-th correct
Chinese article for i-th English query; ci,k is k-th
candiate the system output for i-th English query.
</bodyText>
<subsectionHeader confidence="0.941423">
Top-k Accuracy (ACC)
</subsectionHeader>
<bodyText confidence="0.999971">
ACC measures the correctness of the first candi-
date in the candidate list. ACC = 1 means that all
top candidates are correctly linked (i.e. they match
one of the references), and ACC = 0 means that
none of the top candidates is correct.
</bodyText>
<footnote confidence="0.6224795">
1 1 if ∃ri,j : ri,j = ci,k
0 otherwise
</footnote>
<subsectionHeader confidence="0.641762">
Mean Reciprocal Rank (MRR)
</subsectionHeader>
<bodyText confidence="0.998824">
Traditional MRR measures any correct answer
produced by the system from among the candi-
dates. 1/MRR approximates the average rank of
the correct transliteration. An MRR closer to 1 im-
plies that the correct answer usually appears close
to the top of the n-best lists.
</bodyText>
<equation confidence="0.927293857142857">
�
minj j 1if ∃ri,j, ci,k : ri,j = ci,k
RRi =
0 otherwise
1
MRR = N EN i=1 RRi
Recall
</equation>
<bodyText confidence="0.999773166666667">
Recall is the fraction of the retrieved articles that
are relevant to the given query. Recall is used to
measure the performance of the candidate selec-
tion method. If the candidate selection method can
actually select the correct Chinese candidate, the
recall will be high.
</bodyText>
<equation confidence="0.938056">
Recall = |relevant articles |∩ |retrieved articles|
|relevant articles|
</equation>
<subsectionHeader confidence="0.999306">
3.3 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999989857142857">
The overall results of our method achieves 80.95%
in MRR and 87.46% in recall. Figure 1 shows the
top-k ACC from the top 1 to 5. These results show
that our method is very effective in linking articles
in English Wikipedia to those in Baidu Baike.
In order to show the benefits of each feature
used in the SVM model, we conduct a experiment
to test the performance of different feature combi-
nations. Because title similarity of the articles is a
widely used method, we choose English and Chi-
nese title similarity as the baseline. Then, another
feature is added to each configuration until all the
features have been added. Table 2 shows the final
results of different feature combinations.
</bodyText>
<equation confidence="0.829552">
1
ACC = N
i=1
</equation>
<page confidence="0.981012">
589
</page>
<figureCaption confidence="0.999712">
Figure 1: Top-k Accuracy
</figureCaption>
<bodyText confidence="0.4236235">
Level Configuration MRR
0 Baseline (BL) 0.6559
</bodyText>
<equation confidence="0.948561142857143">
BL + MTM*1 0.69671
1 BL + HT*2 0.69751
BL + ETO*3 0.69811
BL + MTM + HT 0.77031
2 BL + MTM + ETO 0.75581
BL + HT + ETO 0.76821
3 BL + MTM + HT + ETO 0.80951
</equation>
<table confidence="0.9408326">
*1MTM: mix-language topic model
*2HT: hypernym translation
*3ETO: English title occurrence
† This config. outperforms the best config. in last level with
statistically significant difference.
</table>
<tableCaption confidence="0.999295">
Table 2: MRRs of Feature Combinations
</tableCaption>
<bodyText confidence="0.9999255">
In the results, we can observe that mix-language
topic model, hypernym, and English title oc-
curence features all noticeably improve the perfor-
mance. Combining two of these three feature has
more improvement and the combination of all the
features achieves the best.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="evaluation">
4 Discussion
</sectionHeader>
<bodyText confidence="0.99336835">
Although our method can effectively generate
cross-language links with high accuracy, some
correct candidates are not ranked number one. Af-
ter examining the results, we can divide errors into
several categories:
The first kind of error is due to large literal dif-
ferences between the English and Chinese titles.
For example, for the English article “Nero”, our
approach ranks the Chinese candidate “尼禄王”
(“King Nero”) as number one, instead of the cor-
rect answer “尼禄·克劳狄 乌斯·德鲁苏斯·日 If-
En P
f-PP V斯&amp;quot; (the number two candidate). The title
of the correct Chinese article is the full name of
the Roman Emperor Nero (Nero Claudius Drusus
Germanicus). The false positive “尼禄王” is a his-
torical novel about the life of the Emperor Nero.
Because of the large difference in title lengths, the
value of the title similarity feature between the En-
glish article “Nero” and the corresponding Chi-
nese article is low. Such length differences may
cause the SVM model to rank the correct answer
lower when the difference of other features are not
so significant because the contents of the Chinese
candidates are similar.
The second error type is caused by articles that
have duplicates in Baidu Baike. For example, for
the English article “Jensen Ackles”, our approach
generates a link to the Chinese article “Jensen”
in Baidu Baike. However, there is another Baidu
article “詹森·阿克斯” (“Jensen Ackles”). These
two articles both describe the actor Jensen Ackles.
In this case, our approach still generates a correct
link, although it is not the one in the gold standard.
The third error type is translation errors. For ex-
ample, the English article “Raccoon” is linked to
the Baidu article “狸” (raccoon dog), though the
correct one is “浣熊” (raccoon). The reason is that
Google Translate provides the translation “狸” in-
stead of “浣熊”.
</bodyText>
<sectionHeader confidence="0.998778" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999939625">
Cross-language article linking is the task of creat-
ing links between online encyclopedia articles in
different languages that describe the same content.
We propose a method based on article hypernym
and topic model to link English Wikipedia articles
to corresponding Chinese Baidu Baike articles.
Our method comprises two stages: candidate se-
lection and candidate ranking. We formulate can-
didate selection as a cross-language information
retrieval task based on the title similarity between
English and Chinese articles. In candidate rank-
ing, we employ several features of the articles in
our SVM model. To evaluate our method, we com-
pile a dataset from English Wikipedia and Baidu
Baike, containing the 500 most popular Baidu ar-
ticles. Evaluation results of our method show an
MRR of up to 80.95% and a recall of 87.46%. This
shows that our method is effective in generating
cross-language links between English Wikipedia
and Baidu Baike with high accuracy. Our method
does not heavily depend on linguistic characteris-
tics and can be easily extended to generate cross-
language article links among different encyclope-
dias in other languages.
</bodyText>
<figure confidence="0.9990391875">
0.88
1 2 3 4 5
0.869 0.87
0.858
0.839
0.76
TopK
0.86
0.84
0.82
0.8
0.78
0.76
0.74
0.72
0.7
</figure>
<page confidence="0.982573">
590
</page>
<sectionHeader confidence="0.991777" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998908490566038">
Sisay Fissaha Adafre and Maarten de Rijke. 2005.
Discovering missing links in wikipedia. In Proceed-
ings of the 3rd international workshop on Link dis-
covery (LinkKDD ’05).
M. Beaulieu, M. Gatford, X. Huang, S. Robertson,
S. Walker, and P. Williams. 1997. Okapi at TREC-
5. In Proceedings of the fifth Text REtrieval Confer-
ence (TREC-5), pages 143–166.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3(4-5):993–1022.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th conference on Computational linguistics,
volume 2.
Paul McNamee, James Mayfield, Dawn Lawrie, Dou-
glas W Oard, and David S Doermann. 2011. Cross-
language entity linking. In Proceedings of Interna-
tional Joint Con-ference on Natural Language Pro-
cessing (IJCNLP), pages 255–263.
Hemant Misra, Olivier Cappe, and Franc¸ois Yvon.
2008. Using lda to detect semantically incoherent
documents. In Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning
(CoNLL ’08).
Jong-Hoon Oh, Daisuke Kawahara, Kiyotaka Uchi-
moto, Jun’ichi Kazama, and Kentaro Torisawa.
2008. Enriching multilingual language re-
sources by discovering missing cross-language
links in wikipedia. In Proceedings of the 2008
IEEE/WIC/ACM International Conference on Web
Intelligence and Intelligent Agent Technology, vol-
ume 1, pages 322–328.
P`eter Sch¨onhofen, Andr`as Bencz`ur, Istv`an Bir`o, and
K`aroly Csalog`any. 2008. Cross-language retrieval
with wikipedia. Advances in Multilingual and
Multimodal Information Retrieval, Lecture Notes in
Computer Science, 5152:72–79.
Philipp Sorg and Philipp Cimiano. 2008. Enrich-
ing the crosslingual link structure of wikipedia-a
classification-based approach. In Proceedings of the
AAAI 2008 Workshop on Wikipedia and Artifical In-
telligence, pages 49–54.
Ling-Xiang Tang, In-Su Kang, Fuminori Kimura, Yi-
Hsun Lee, Andrew Trotman, Shlomo Geva, and Yue
Xu. 2013. Overview of the ntcir-10 cross-lingual
link discovery task. In Proceedings of the Tenth NT-
CIR Workshop Meeting.
Zhichun Wang, Juanzi Li, Zhigang Wang, and Jie Tang.
2012. Cross-lingual knowledge linking across wiki
knowledge bases. In Proceedings of the 21st in-
ternational conference on World Wide Web (WWW
’12).
</reference>
<page confidence="0.998091">
591
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.527949">
<title confidence="0.9985915">Cross-language and Cross-encyclopedia Article Linking Mixed-language Topic Model and Hypernym Translation</title>
<author confidence="0.96253">Chun-Kai</author>
<affiliation confidence="0.9968555">Department of National Tsinghua</affiliation>
<address confidence="0.838818">Hsinchu,</address>
<email confidence="0.987375">nthu.edu.tw</email>
<author confidence="0.802817">Yu-Chun</author>
<affiliation confidence="0.99703">Department of National Taiwan</affiliation>
<address confidence="0.859404">Taipei,</address>
<email confidence="0.978347">d97023@csie.ntu.edu.tw</email>
<abstract confidence="0.998993681818182">Creating cross-language article links among different online encyclopedias is now an important task in the unification of multilingual knowledge bases. In this paper, we propose a cross-language article linking method using a mixed-language topic model and hypernym translation features based on an SVM model to link English Wikipedia and Chinese Baidu Baike, the most widely used Wiki-like encyclopedia in China. To evaluate our approach, we compile a data set from the top 500 Baidu Baike articles and their corresponding English Wiki articles. The evaluation results show that our approach achieves 80.95% in MRR and 87.46% in recall. Our method does not heavily depend on linguistic characteristics and can be easily extended to generate crosslanguage article links among different online encyclopedias in other languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sisay Fissaha Adafre</author>
<author>Maarten de Rijke</author>
</authors>
<title>Discovering missing links in wikipedia.</title>
<date>2005</date>
<booktitle>In Proceedings of the 3rd international workshop on Link discovery (LinkKDD ’05).</booktitle>
<marker>Adafre, de Rijke, 2005</marker>
<rawString>Sisay Fissaha Adafre and Maarten de Rijke. 2005. Discovering missing links in wikipedia. In Proceedings of the 3rd international workshop on Link discovery (LinkKDD ’05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Beaulieu</author>
<author>M Gatford</author>
<author>X Huang</author>
<author>S Robertson</author>
<author>S Walker</author>
<author>P Williams</author>
</authors>
<title>Okapi at TREC5.</title>
<date>1997</date>
<booktitle>In Proceedings of the fifth Text REtrieval Conference (TREC-5),</booktitle>
<pages>143--166</pages>
<contexts>
<context position="6509" citStr="Beaulieu et al., 1997" startWordPosition="973" endWordPosition="976">article into Chinese and then use these translated titles as queries to retrieve articles from the Chinese encyclopedia. In document translation, we translate the contents of the entire Chinese encyclopedia into English and then search them using the original English titles. The top 100 results for the query-translation and the top 100 results for document-translation steps are unionized. The resulting list contains our title-matching candidates. For the query- and document-translation steps, we use the Lucene search engine with similarity scores calculated by the Okapi BM25 ranking function (Beaulieu et al., 1997). We separate all words in the translated and original English article titles with the “OR” operator before submission to the search engine. For all E-C and C-E translation tasks, we use Google Translate. 2.1.2 Title Similarity In the title similarity method, every Chinese article title is represented as a vector, and each distinct character in all these titles is a dimension of all vectors. The title of each English article is translated into Chinese and represented as a vector. Then, cosine similarity between this vector and the vector of each Chinese title is measured as title similarity. 2</context>
</contexts>
<marker>Beaulieu, Gatford, Huang, Robertson, Walker, Williams, 1997</marker>
<rawString>M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker, and P. Williams. 1997. Okapi at TREC5. In Proceedings of the fifth Text REtrieval Conference (TREC-5), pages 143–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--4</pages>
<contexts>
<context position="8950" citStr="Blei et al., 2003" startWordPosition="1392" endWordPosition="1395">d English-Chinese article pair, the distribution of words used in each usually shows some convergence. The two semantically corresponding articles often have many related terms, which results in clusters of specific words. If two articles do not describe the same topic, the distribution of terms is often scattered. (Misra et al., 2008) Thus, the distribution of terms is good measurement of article similarity. Because the number of all possible words is too large, we adopt a topic model to gather the words into some latent topics. For this feature, we use the Latent Dirichlet Allocation (LDA) (Blei et al., 2003). LDA can be seen as a typical probabilistic approach to latent topic computation. Each topic is represented by a distribution of words, and each word has a probability score used to measure its contribution to the topic. To train the LDA model, the pair English and Chinese articles are concatenated into a single document. English and Chinese terms are all regarded as terms of the same language and the LDA topic model, namely mixedlanguage topic model, generates both English and Chinese terms for each latent topic. Then, for each English article and Chinese candidate pair in testing, the LDA m</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3(4-5):993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguistics,</booktitle>
<volume>2</volume>
<contexts>
<context position="11685" citStr="Hearst, 1992" startWordPosition="1853" endWordPosition="1854">young adult novel by American writer Suzanne Collins.” Since article titles may be named entities or compound nouns, the dependency parser may mislabel them and thus output an incorrect parse tree. To avoid this problem, we first replace all instances of an article’s title in the first sentence with pronouns. For example, the previous sentence is rewritten as “It is a 2008 young adult novel by American writer Suzanne Collins.” Then, the dependency parser generates the following parse tree: novel suzanne writer American Next, we apply our predefined syntactic patterns to extract the hypernym. (Hearst, 1992) If any pattern matches the structure of the dependency parse tree, the hypernym can be extracted. In the above example, the following pattern is matched: [target] nsubj cop nn It is NN In this pattern, the rightmost leaf is the hypernym target. Thus, we can extract the hypernym “novel” from the previous example. The term “novel” is the extracted hypernym of the English article “The Hunger Games”. After extracting the hypernym of the English article, the hypernym is translated into Chinese. The value of this feature in the SVM model is calculated as follows: Fhypernym(h) = log count(translated</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th conference on Computational linguistics, volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
<author>Dawn Lawrie</author>
<author>Douglas W Oard</author>
<author>David S Doermann</author>
</authors>
<title>Crosslanguage entity linking.</title>
<date>2011</date>
<booktitle>In Proceedings of International Joint Con-ference on Natural Language Processing (IJCNLP),</booktitle>
<pages>255--263</pages>
<contexts>
<context position="2898" citStr="McNamee et al., 2011" startWordPosition="413" endWordPosition="417">cles respectively. Similarly, in Korea, Naver Knowledge Encyclopedia has a large presence. Since alternative encyclopedias like Baidu Baike are larger (by article count) and growing faster than the Chinese Wikipedia, it is worthwhile to investigate creating cross-language links among different online encyclopedias. Several works have focused on creating cross-language links between Wikipedia language versions (Oh et al., 2008; Sorg and Cimiano, 2008) or finding a cross-language link for each entity mention in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) (Tang et al., 2013; McNamee et al., 2011). These works were able to exploit the link structure and metadata common to all Wikipedia language versions. However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared. To date, little research has been done into linking between encyclopedias on different platforms. Title translation is an effective and widely used method of creating cross-language links between encyclopedia articles. (Wang et al., 2012; Adafre and de Rijke, 2005) However, title translation alone is not always sufficient. In som</context>
</contexts>
<marker>McNamee, Mayfield, Lawrie, Oard, Doermann, 2011</marker>
<rawString>Paul McNamee, James Mayfield, Dawn Lawrie, Douglas W Oard, and David S Doermann. 2011. Crosslanguage entity linking. In Proceedings of International Joint Con-ference on Natural Language Processing (IJCNLP), pages 255–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hemant Misra</author>
<author>Olivier Cappe</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Using lda to detect semantically incoherent documents.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL ’08).</booktitle>
<contexts>
<context position="8669" citStr="Misra et al., 2008" startWordPosition="1343" endWordPosition="1346"> similarity from the candidate selection stage as two features for the candidate ranking stage. The similarity values generated by title matching and title similarity are used directly as real value features in the SVM model. 587 Mixed-language Topic Model Feature (MTM) For a linked English-Chinese article pair, the distribution of words used in each usually shows some convergence. The two semantically corresponding articles often have many related terms, which results in clusters of specific words. If two articles do not describe the same topic, the distribution of terms is often scattered. (Misra et al., 2008) Thus, the distribution of terms is good measurement of article similarity. Because the number of all possible words is too large, we adopt a topic model to gather the words into some latent topics. For this feature, we use the Latent Dirichlet Allocation (LDA) (Blei et al., 2003). LDA can be seen as a typical probabilistic approach to latent topic computation. Each topic is represented by a distribution of words, and each word has a probability score used to measure its contribution to the topic. To train the LDA model, the pair English and Chinese articles are concatenated into a single docu</context>
</contexts>
<marker>Misra, Cappe, Yvon, 2008</marker>
<rawString>Hemant Misra, Olivier Cappe, and Franc¸ois Yvon. 2008. Using lda to detect semantically incoherent documents. In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL ’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Daisuke Kawahara</author>
<author>Kiyotaka Uchimoto</author>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Enriching multilingual language resources by discovering missing cross-language links in wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,</booktitle>
<volume>1</volume>
<pages>322--328</pages>
<contexts>
<context position="2706" citStr="Oh et al., 2008" startWordPosition="382" endWordPosition="385">ere are alternatives to Wikipedia for some languages. In China, for example Baidu Baike and Hudong are the largest encyclopedia sites, containing more than 6.2 and 7 million Chinese articles respectively. Similarly, in Korea, Naver Knowledge Encyclopedia has a large presence. Since alternative encyclopedias like Baidu Baike are larger (by article count) and growing faster than the Chinese Wikipedia, it is worthwhile to investigate creating cross-language links among different online encyclopedias. Several works have focused on creating cross-language links between Wikipedia language versions (Oh et al., 2008; Sorg and Cimiano, 2008) or finding a cross-language link for each entity mention in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) (Tang et al., 2013; McNamee et al., 2011). These works were able to exploit the link structure and metadata common to all Wikipedia language versions. However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared. To date, little research has been done into linking between encyclopedias on different platforms. Title translation is an effective and wid</context>
</contexts>
<marker>Oh, Kawahara, Uchimoto, Kazama, Torisawa, 2008</marker>
<rawString>Jong-Hoon Oh, Daisuke Kawahara, Kiyotaka Uchimoto, Jun’ichi Kazama, and Kentaro Torisawa. 2008. Enriching multilingual language resources by discovering missing cross-language links in wikipedia. In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 322–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P`eter Sch¨onhofen</author>
<author>Andr`as Bencz`ur</author>
<author>Istv`an Bir`o</author>
<author>K`aroly Csalog`any</author>
</authors>
<title>Cross-language retrieval with wikipedia.</title>
<date>2008</date>
<booktitle>Advances in Multilingual and Multimodal Information Retrieval, Lecture Notes in Computer Science,</booktitle>
<pages>5152--72</pages>
<marker>Sch¨onhofen, Bencz`ur, Bir`o, Csalog`any, 2008</marker>
<rawString>P`eter Sch¨onhofen, Andr`as Bencz`ur, Istv`an Bir`o, and K`aroly Csalog`any. 2008. Cross-language retrieval with wikipedia. Advances in Multilingual and Multimodal Information Retrieval, Lecture Notes in Computer Science, 5152:72–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Sorg</author>
<author>Philipp Cimiano</author>
</authors>
<title>Enriching the crosslingual link structure of wikipedia-a classification-based approach.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI 2008 Workshop on Wikipedia and Artifical Intelligence,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="2731" citStr="Sorg and Cimiano, 2008" startWordPosition="386" endWordPosition="389">ves to Wikipedia for some languages. In China, for example Baidu Baike and Hudong are the largest encyclopedia sites, containing more than 6.2 and 7 million Chinese articles respectively. Similarly, in Korea, Naver Knowledge Encyclopedia has a large presence. Since alternative encyclopedias like Baidu Baike are larger (by article count) and growing faster than the Chinese Wikipedia, it is worthwhile to investigate creating cross-language links among different online encyclopedias. Several works have focused on creating cross-language links between Wikipedia language versions (Oh et al., 2008; Sorg and Cimiano, 2008) or finding a cross-language link for each entity mention in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) (Tang et al., 2013; McNamee et al., 2011). These works were able to exploit the link structure and metadata common to all Wikipedia language versions. However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared. To date, little research has been done into linking between encyclopedias on different platforms. Title translation is an effective and widely used method of creati</context>
</contexts>
<marker>Sorg, Cimiano, 2008</marker>
<rawString>Philipp Sorg and Philipp Cimiano. 2008. Enriching the crosslingual link structure of wikipedia-a classification-based approach. In Proceedings of the AAAI 2008 Workshop on Wikipedia and Artifical Intelligence, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ling-Xiang Tang</author>
<author>In-Su Kang</author>
<author>Fuminori Kimura</author>
<author>YiHsun Lee</author>
<author>Andrew Trotman</author>
<author>Shlomo Geva</author>
<author>Yue Xu</author>
</authors>
<title>Overview of the ntcir-10 cross-lingual link discovery task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Tenth NTCIR Workshop Meeting.</booktitle>
<contexts>
<context position="2875" citStr="Tang et al., 2013" startWordPosition="409" endWordPosition="412">illion Chinese articles respectively. Similarly, in Korea, Naver Knowledge Encyclopedia has a large presence. Since alternative encyclopedias like Baidu Baike are larger (by article count) and growing faster than the Chinese Wikipedia, it is worthwhile to investigate creating cross-language links among different online encyclopedias. Several works have focused on creating cross-language links between Wikipedia language versions (Oh et al., 2008; Sorg and Cimiano, 2008) or finding a cross-language link for each entity mention in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) (Tang et al., 2013; McNamee et al., 2011). These works were able to exploit the link structure and metadata common to all Wikipedia language versions. However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared. To date, little research has been done into linking between encyclopedias on different platforms. Title translation is an effective and widely used method of creating cross-language links between encyclopedia articles. (Wang et al., 2012; Adafre and de Rijke, 2005) However, title translation alone is not al</context>
</contexts>
<marker>Tang, Kang, Kimura, Lee, Trotman, Geva, Xu, 2013</marker>
<rawString>Ling-Xiang Tang, In-Su Kang, Fuminori Kimura, YiHsun Lee, Andrew Trotman, Shlomo Geva, and Yue Xu. 2013. Overview of the ntcir-10 cross-lingual link discovery task. In Proceedings of the Tenth NTCIR Workshop Meeting.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhichun Wang</author>
<author>Juanzi Li</author>
<author>Zhigang Wang</author>
<author>Jie Tang</author>
</authors>
<title>Cross-lingual knowledge linking across wiki knowledge bases.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web (WWW ’12).</booktitle>
<contexts>
<context position="3404" citStr="Wang et al., 2012" startWordPosition="490" endWordPosition="493">n in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) (Tang et al., 2013; McNamee et al., 2011). These works were able to exploit the link structure and metadata common to all Wikipedia language versions. However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared. To date, little research has been done into linking between encyclopedias on different platforms. Title translation is an effective and widely used method of creating cross-language links between encyclopedia articles. (Wang et al., 2012; Adafre and de Rijke, 2005) However, title translation alone is not always sufficient. In some cases, for example, the titles of corresponding articles in different languages do not even match. Other methods must be used along with title translation to create a more robust linking tool. 586 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 586–591, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics In this paper, we propose a method comprising title and hypernym translation and mixedlanguage t</context>
</contexts>
<marker>Wang, Li, Wang, Tang, 2012</marker>
<rawString>Zhichun Wang, Juanzi Li, Zhigang Wang, and Jie Tang. 2012. Cross-lingual knowledge linking across wiki knowledge bases. In Proceedings of the 21st international conference on World Wide Web (WWW ’12).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>