<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000090">
<title confidence="0.993686">
Novel Reordering Approaches in Phrase-Based Statistical Machine
Translation
</title>
<author confidence="0.949639">
Stephan Kanthak, David Vilar, Evgeny Matusov, Richard Zens, and Hermann Ney
</author>
<affiliation confidence="0.7335005">
The authors are with the Lehrstuhl f¨ur Informatik VI,
Computer Science Department, RWTH Aachen University,
</affiliation>
<address confidence="0.579889">
D-52056 Aachen, Germany.
</address>
<email confidence="0.999724">
E-mail: {kanthak,vilar,matusov,zens,ney}@informatik.rwth-aachen.de.
</email>
<sectionHeader confidence="0.997401" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999801523809524">
This paper presents novel approaches to
reordering in phrase-based statistical ma-
chine translation. We perform consistent
reordering of source sentences in train-
ing and estimate a statistical translation
model. Using this model, we follow a
phrase-based monotonic machine transla-
tion approach, for which we develop an ef-
ficient and flexible reordering framework
that allows to easily introduce different re-
ordering constraints. In translation, we
apply source sentence reordering on word
level and use a reordering automaton as in-
put. We show how to compute reordering
automata on-demand using IBM or ITG
constraints, and also introduce two new
types of reordering constraints. We further
add weights to the reordering automata.
We present detailed experimental results
and show that reordering significantly im-
proves translation quality.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999933895833334">
Reordering is of crucial importance for machine
translation. Already (Knight et al., 1998) use full un-
weighted permutations on the level of source words
in their early weighted finite-state transducer ap-
proach which implemented single-word based trans-
lation using conditional probabilities. In a refine-
ment with additional phrase-based models, (Kumar
et al., 2003) define a probability distribution over
all possible permutations of source sentence phrases
and prune the resulting automaton to reduce com-
plexity.
A second category of finite-state translation ap-
proaches uses joint instead of conditional probabili-
ties. Many joint probability approaches originate in
speech-to-speech translation as they are the natural
choice in combination with speech recognition mod-
els. The automated transducer inference techniques
OMEGA (Vilar, 2000) and GIATI (Casacuberta et
al., 2004) work on phrase level, but ignore the re-
ordering problem from the view of the model. With-
out reordering both in training and during search,
sentences can only be translated properly into a lan-
guage with similar word order. In (Bangalore et al.,
2000) weighted reordering has been applied to tar-
get sentences since defining a permutation model on
the source side is impractical in combination with
speech recognition. In order to reduce the computa-
tional complexity, this approach considers only a set
of plausible reorderings seen on training data.
Most other phrase-based statistical approaches
like the Alignment Template system of Bender
et al. (2004) rely on (local) reorderings which are
implicitly memorized with each pair of source and
target phrases in training. Additional reorderings on
phrase level are fully integrated into the decoding
process, which increases the complexity of the sys-
tem and makes it hard to modify. Zens et al. (2003)
reviewed two types of reordering constraints for this
type of translation systems.
In our work we follow a phrase-based transla-
tion approach, applying source sentence reordering
on word level. We compute a reordering graph on-
demand and take it as input for monotonic trans-
lation. This approach is modular and allows easy
introduction of different reordering constraints and
probabilistic dependencies. We will show that it per-
forms at least as well as the best statistical machine
translation system at the IWSLT Evaluation.
</bodyText>
<page confidence="0.966249">
167
</page>
<note confidence="0.9930865">
Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 167–174,
Ann Arbor, June 2005. c�Association for Computational Linguistics, 2005
</note>
<bodyText confidence="0.999955615384616">
In the next section we briefly review the basic
theory of our translation system based on weighted
finite-state transducers (WFST). In Sec. 3 we in-
troduce new methods for reordering and alignment
monotonization in training. To compare differ-
ent reordering constraints used in the translation
search process we develop an on-demand com-
putable framework for permutation models in Sec. 4.
In the same section we also define and analyze un-
restricted and restricted permutations with some of
them being first published in this paper. We con-
clude the paper by presenting and discussing a rich
set of experimental results.
</bodyText>
<sectionHeader confidence="0.995345" genericHeader="method">
2 Machine Translation using WFSTs
</sectionHeader>
<bodyText confidence="0.999245">
Let fJ1 and ez be two sentences from a source and
target language. Assume that we have word level
alignments A of all sentence pairs from a bilingual
training corpus. We denote with ˜eJ1 the segmenta-
tion of a target sentence ei into J phrases such that
fJ1 and ˜eJ1 can be aligned to form bilingual tuples
(fj, ˜ej). If alignments are only functions of target
words A&apos; : 11, ... , I} —* 11, ... , J}, the bilingual
tuples (fj, ˜ej) can be inferred with e. g. the GIATI
method of (Casacuberta et al., 2004), or with our
novel monotonization technique (see Sec. 3). Each
source word will be mapped to a target phrase of one
or more words or an “empty” phrase E. In particular,
the source words which will remain non-aligned due
to the alignment functionality restriction are paired
with the empty phrase.
We can then formulate the problem of finding the
best translation ˆei of a source sentence fJ1 :
</bodyText>
<equation confidence="0.9761954">
ˆei = argmax Pr(fJ1 , ei)
eI 1
E= argmax Pr(fJ1 , ˜eJ1 , A)
�eJ1 AEA
Pr(A) · Pr(fJ1 , ˜eJ1 |A)
(fj, ˜ej). Mapping the bilingual language model to a
WFST T is canonical and it has been shown in (Kan-
thak et al., 2004) that the search problem can then be
rewritten using finite-state terminology:
eI1 = project-output(best(fJ1 oT)).
</equation>
<bodyText confidence="0.998073333333333">
This implementation of the problem as WFSTs may
be used to efficiently solve the search problem in
machine translation.
</bodyText>
<sectionHeader confidence="0.986084" genericHeader="method">
3 Reordering in Training
</sectionHeader>
<bodyText confidence="0.999947923076923">
When the alignment function A&apos; is not monotonic,
target language phrases e˜ can become very long.
For example in a completely non-monotonic align-
ment all target words are paired with the last aligned
source word, whereas all other source words form
tuples with the empty phrase. Therefore, for lan-
guage pairs with big differences in word order, prob-
ability estimates may be poor.
This problem can be solved by reordering either
source or target training sentences such that align-
ments become monotonic for all sentences. We
suggest the following consistent source sentence re-
ordering and alignment monotonization approach in
which we compute optimal, minimum-cost align-
ments.
First, we estimate a cost matrix C for each sen-
tence pair (fJ1 , ei). The elements of this matrix cij
are the local costs of aligning a source word fj to a
target word ei. Following (Matusov et al., 2004), we
compute these local costs by interpolating state oc-
cupation probabilities from the source-to-target and
target-to-source training of the HMM and IBM-4
models as trained by the GIZA++ toolkit (Och et al.,
2003). For a given alignment A C_ I x J, we define
the costs of this alignment c(A) as the sum of the
local costs of all aligned word pairs:
</bodyText>
<equation confidence="0.997715923076923">
c(A) = E cij (1)
(i,j)EA
�= argmax
eJ
1
max
AEA
r(fj, ˜ej|fj−1
1 , ˜ej−1
1 ,A)
�= argmax
eJ
1
</equation>
<bodyText confidence="0.9542875">
The goal is to find an alignment with the minimum
costs which fulfills certain constraints.
</bodyText>
<equation confidence="0.966936363636363">
�
max P
AEA
fj:j=1...J
= argmax
eJ 1
max
AEA
fj:j=1...J
( j−1 ˜j−1
plfj , ej  |fj−M,ej−M,A)
</equation>
<bodyText confidence="0.99977175">
In other words: if we assume a uniform distri-
bution for Pr(A), the translation problem can be
mapped to the problem of estimating an m-gram lan-
guage model over a learned set of bilingual tuples
</bodyText>
<subsectionHeader confidence="0.999513">
3.1 Source Sentence Reordering
</subsectionHeader>
<bodyText confidence="0.97849525">
To reorder a source sentence, we require the
alignment to be a function of source words A1:
11, . . . ,J} —* 11,..., I}, easily computed from the
cost matrix C as:
</bodyText>
<equation confidence="0.954514">
A1(j) = argmini cij (2)
</equation>
<page confidence="0.979872">
168
</page>
<bodyText confidence="0.999978666666667">
We do not allow for non-aligned source words. A1
naturally defines a new order of the source words fJ1
which we denote by fJ1 . By computing this permu-
tation for each pair of sentences in training and ap-
plying it to each source sentence, we create a corpus
of reordered sentences.
</bodyText>
<subsectionHeader confidence="0.999661">
3.2 Alignment Monotonization
</subsectionHeader>
<bodyText confidence="0.8378784">
In order to create a “sentence” of bilingual tuples
( fJ1 , EJ1 ) we required alignments between reordered
source and target words to be a function of target
words A2 : 11, ... , I} —* 11, ... , J}. This align-
ment can be computed in analogy to Eq. 2 as:
</bodyText>
<equation confidence="0.995387">
A2(i) = argminj czj (3)
</equation>
<bodyText confidence="0.99746875">
where czj are the elements of the new cost matrix
C� which corresponds to the reordered source sen-
tence. We can optionally re-estimate this matrix by
repeating EM training of state occupation probabili-
ties with GIZA++ using the reordered source corpus
and the original target corpus. Alternatively, we can
get the cost matrix C� by reordering the columns of
the cost matrix C according to the permutation given
by alignment A1.
In alignment A2 some target words that were pre-
viously unaligned in A1 (like “the” in Fig. 1) may
now still violate the alignment monotonicity. The
monotonicity of this alignment can not be guaran-
teed for all words if re-estimation of the cost matri-
ces had been performed using GIZA++.
The general GIATI technique (Casacuberta et al.,
2004) is applicable and can be used to monotonize
the alignment A2. However, in our experiments
the following method performs better. We make
use of the cost matrix representation and compute
a monotonic minimum-cost alignment with a dy-
namic programming algorithm similar to the Lev-
enshtein string edit distance algorithm. As costs of
each “edit” operation we consider the local align-
ment costs. The resulting alignment A3 represents
a minimum-cost monotonic “path” through the cost
matrix. To make A3 a function of target words we
do not consider the source words non-aligned in A2
and also forbid “deletions” (“many-to-one” source
word alignments) in the DP search.
An example of such consistent reordering and
monotonization is given in Fig. 1. Here, we re-
order the German source sentence based on the ini-
tial alignment A1, then compute the function of tar-
get words A2, and monotonize this alignment to A3
mir wUrde sehr gut Anfang Mai passen .
</bodyText>
<figure confidence="0.970119222222222">
A1
the very beginning of May would suit me .
sehr gut Anfang Mai wUrde passen mir .
A2
the very beginning of May would suit me .
sehr gut Anfang Mai wUrde passen mir .
the very beginning of May would suit me .
sehr|the_very gut|$ Anfang|beginning
Mai|of_May wUrde|would passen|suit mir|me .|.
</figure>
<figureCaption confidence="0.994471666666667">
Figure 1: Example of alignment, source sentence re-
ordering, monotonization, and construction of bilin-
gual tuples.
</figureCaption>
<bodyText confidence="0.9979405">
with the dynamic programming algorithm. Fig. 1
also shows the resulting bilingual tuples ( fj, ej).
</bodyText>
<sectionHeader confidence="0.966867" genericHeader="method">
4 Reordering in Search
</sectionHeader>
<bodyText confidence="0.999930333333333">
When searching the best translation eJ1 for a given
source sentence fJ1 , we permute the source sentence
as described in (Knight et al., 1998):
</bodyText>
<equation confidence="0.963444">
e1 = project-output(best(permute(fl) o T))
</equation>
<bodyText confidence="0.9998425">
Permuting an input sequence of J symbols re-
sults in J! possible permutations and representing
the permutations as a finite-state automaton requires
at least 2J states. Therefore, we opt for computing
the permutation automaton on-demand while apply-
ing beam pruning in the search.
</bodyText>
<subsectionHeader confidence="0.999052">
4.1 Lazy Permutation Automata
</subsectionHeader>
<bodyText confidence="0.999960333333333">
For on-demand computation of an automaton in the
flavor described in (Kanthak et al., 2004) it is suffi-
cient to specify a state description and an algorithm
that calculates all outgoing arcs of a state from the
state description. In our case, each state represents
a permutation of a subset of the source words fJ1 ,
which are already translated.
This can be described by a bit vector bJ1 (Zens
et al., 2002). Each bit of the state bit vector corre-
sponds to an arc of the linear input automaton and is
set to one if the arc has been used on any path from
the initial to the current state. The bit vectors of two
states connected by an arc differ only in a single bit.
Note that bit vectors elegantly solve the problem of
recombining paths in the automaton as states with
</bodyText>
<page confidence="0.8194885">
A3
169
</page>
<bodyText confidence="0.999906">
the same bit vectors can be merged. As a result, a
fully minimized permutation automaton has only a
single initial and final state.
Even with on-demand computation, complexity
using full permutations is unmanagable for long sen-
tences. We further reduce complexity by addition-
ally constraining permutations. Refer to Figure 2 for
visualizations of the permutation constraints which
we describe in the following.
</bodyText>
<subsectionHeader confidence="0.958708">
4.2 IBM Constraints
</subsectionHeader>
<bodyText confidence="0.999988090909091">
The IBM reordering constraints are well-known in
the field of machine translation and were first de-
scribed in (Berger et al., 1996). The idea behind
these constraints is to deviate from monotonic trans-
lation by postponing translations of a limited num-
ber of words. More specifically, at each state we
can translate any of the first l yet uncovered word
positions. The implementation using a bit vector is
straightforward. For consistency, we associate win-
dow size with the parameter l for all constraints pre-
sented here.
</bodyText>
<subsectionHeader confidence="0.989374">
4.3 Inverse IBM Constraints
</subsectionHeader>
<bodyText confidence="0.999944307692308">
The original IBM constraints are useful for a large
number of language pairs where the ability to skip
some words reflects the differences in word order
between the two languages. For some other pairs,
it is beneficial to translate some words at the end of
the sentence first and to translate the rest of the sen-
tence nearly monotonically. Following this idea we
can define the inverse IBM constraints. Let j be the
first uncovered position. We can choose any posi-
tion for translation, unless l − 1 words on positions
j&apos; &gt; j have been translated. If this is the case we
must translate the word in position j. The inverse
IBM constraints can also be expressed by
</bodyText>
<equation confidence="0.785836">
invIBM(x) = transpose(IBM(transpose(x))).
</equation>
<bodyText confidence="0.999885">
As the transpose operation can not be computed
on-demand, our specialized implementation uses bit
vectors b�1 similar to the IBM constraints.
</bodyText>
<subsectionHeader confidence="0.991226">
4.4 Local Constraints
</subsectionHeader>
<bodyText confidence="0.9052126875">
For some language pairs, e.g. Italian – English,
words are moved only a few words to the left or
right. The IBM constraints provide too many alter-
native permutations to chose from as each word can
be moved to the end of the sentence. A solution that
allows only for local permutations and therefore has
Figure 2: Permutations of a) positions j = 1, 2, 3, 4
of a source sentence f1f2f3f4 using a window size
of 2 for b) IBM constraints, c) inverse IBM con-
straints and d) local constraints.
very low complexity is given by the following per-
mutation rule: the next word for translation comes
from the window of l positions1 counting from the
first yet uncovered position. Note, that the local con-
straints define a true subset of the permutations de-
fined by the IBM constraints.
</bodyText>
<subsectionHeader confidence="0.850335">
4.5 ITG Constraints
</subsectionHeader>
<bodyText confidence="0.999979111111111">
Another type of reordering can be obtained using In-
version Transduction Grammars (ITG) (Wu, 1997).
These constraints are inspired by bilingual bracket-
ing. They proved to be quite useful for machine
translation, e.g. see (Bender et al., 2004). Here,
we interpret the input sentence as a sequence of seg-
ments. In the beginning, each word is a segment of
its own. Longer segments are constructed by recur-
sively combining two adjacent segments. At each
</bodyText>
<footnote confidence="0.882929">
1both covered and uncovered
</footnote>
<figure confidence="0.993764135135135">
1001
2
4
d)
1010
2
3
c)
4
a)
1 2 3 4
0000 1000 1100 1110 1111
b)
3
1
4
1011
1000
2
1010
2
2
3
1110
4
0000 2 1 1100
4
3
1111
0100
3
1
1101
1
0110
4 0111
0001
1
0000
2
1
1000
2
3
1100
4
3
2
1101
1110
3
4
1111
3
0100
1
1010
1
0010
1
1000
1110
4
2
3
0000
2
1
1100
4
3
1111
0100
1101
</figure>
<page confidence="0.974669">
170
</page>
<table confidence="0.9984445">
Chinese English Japanese English Italian English
train sentences 20 000 20 000 66107
words
singletons
vocabulary
182 904 160 523 209 012 160 427 410 275 427 402
3 525 2 948 4108 2 956 6 386 3 974
7 643 6 982 9 277 6 932 15 983 10 971
dev sentences 506 506 500
words
sentence length (avg/max)
3 515 3 595 4 374 3 595 3 155 3 253
6.95 / 24 7.01 / 29 8.64 / 30 7.01 / 29 5.79 / 24 6.51 / 25
test sentences 500 500 506
words
sentence length (avg/max)
3 794 7.16 – 4 370 7.16 – 2 931 3 595
7.59 / 62 / 71 8.74 / 75 / 71 6.31 / 27 6.84 / 28
</table>
<tableCaption confidence="0.999867">
Table 1: Statistics of the Basic Travel Expression (BTEC) corpora.
</tableCaption>
<bodyText confidence="0.999077666666667">
combination step, we either keep the two segments
in monotonic order or invert the order. This pro-
cess continues until only one segment for the whole
sentence remains. The on-demand computation is
implemented in spirit of Earley parsing.
We can modify the original ITG constraints to
further limit the number of reorderings by forbid-
ding segment inversions which violate IBM con-
straints with a certain window size. Thus, the re-
sulting reordering graph contains the intersection of
the reorderings with IBM and the original ITG con-
straints.
</bodyText>
<subsectionHeader confidence="0.981313">
4.6 Weighted Permutations
</subsectionHeader>
<bodyText confidence="0.999082909090909">
So far, we have discussed how to generate the per-
mutation graphs under different constraints, but per-
mutations were equally probable. Especially for the
case of nearly monotonic translation it is make sense
to restrict the degree of non-monotonicity that we
allow when translating a sentence. We propose a
simple approach which gives a higher probability
to the monotone transitions and penalizes the non-
monotonic ones.
A state description bi , for which the following
condition holds:
</bodyText>
<equation confidence="0.994197">
Mon(j) : bj, = S(j&apos; &lt; j) b 1 &lt; j&apos; &lt; J
</equation>
<bodyText confidence="0.999952">
represents the monotonic path up to the word fj. At
each state we assign the probability α to that out-
going arc where the target state description fullfills
Mon(j +1) and distribute the remaining probability
mass 1 − α uniformly among the remaining arcs. In
case there is no such arc, all outgoing arcs get the
same uniform probability. This weighting scheme
clearly depends on the state description and the out-
going arcs only and can be computed on-demand.
</bodyText>
<sectionHeader confidence="0.993926" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.990968">
5.1 Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.999973458333333">
The translation experiments were carried out on the
Basic Travel Expression Corpus (BTEC), a multilin-
gual speech corpus which contains tourism-related
sentences usually found in travel phrase books.
We tested our system on the so called Chinese-to-
English (CE) and Japanese-to-English (JE) Supplied
Tasks, the corpora which were provided during the
International Workshop on Spoken Language Trans-
lation (IWSLT 2004) (Akiba et al., 2004). In ad-
dition, we performed experiments on the Italian-to-
English (IE) task, for which a larger corpus was
kindly provided to us by ITC/IRST. The corpus
statistics for the three BTEC corpora are given in
Tab. 1. The development corpus for the Italian-to-
English translation had only one reference transla-
tion of each Italian sentence. A set of 506 source
sentences and 16 reference translations is used as
a development corpus for Chinese-to-English and
Japanese-to-English and as a test corpus for Italian-
to-English tasks. The 500 sentence Chinese and
Japanese test sets of the IWSLT 2004 evaluation
campaign were translated and automatically scored
against 16 reference translations after the end of the
campaign using the IWSLT evaluation server.
</bodyText>
<subsectionHeader confidence="0.995602">
5.2 Evaluation Criteria
</subsectionHeader>
<bodyText confidence="0.999542625">
For the automatic evaluation, we used the crite-
ria from the IWSLT evaluation campaign (Akiba et
al., 2004), namely word error rate (WER), position-
independent word error rate (PER), and the BLEU
and NIST scores (Papineni et al., 2002; Doddington,
2002). The two scores measure accuracy, i. e. larger
scores are better. The error rates and scores were
computed with respect to multiple reference transla-
</bodyText>
<page confidence="0.98976">
171
</page>
<figure confidence="0.990837833333333">
1 2 3 4 5 6 7 8 9
reordering constraints window size
1 2 3 4 5 6 7 8 9
reordering constraints window size
INV-IBM
IBM
ITG
LOCAL
INV-IBM
IBM
ITG
LOCAL
</figure>
<page confidence="0.885272238095238">
60
58
56
54
52
50
48
46
44
42
40
55
54
53
52
51
50
49
48
47
46
</page>
<figureCaption confidence="0.9964155">
Figure 3: Word error rate [%] as a function of the reordering window size for different reordering constraints:
Japanese-to-English (left) and Chinese-to-English (right) translation.
</figureCaption>
<bodyText confidence="0.9923346">
tions, when they were available. To indicate this, we
will label the error rate acronyms with an m. Both
training and evaluation were performed using cor-
pora and references in lowercase and without punc-
tuation marks.
</bodyText>
<subsectionHeader confidence="0.977201">
5.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999588888888889">
We used reordering and alignment monotonization
in training as described in Sec. 3. To estimate the
matrices of local alignment costs for the sentence
pairs in the training corpus we used the state occupa-
tion probabilities of GIZA++ IBM-4 model training
and interpolated the probabilities of source-to-target
and target-to-source training directions. After that
we estimated a smoothed 4-gram language model on
the level of bilingual tuples fj, ej and represented it
as a finite-state transducer.
When translating, we applied moderate beam
pruning to the search automaton only when using re-
ordering constraints with window sizes larger than 3.
For very large window sizes we also varied the prun-
ing thresholds depending on the length of the input
sentence. Pruning allowed for fast translations and
reasonable memory consumption without a signifi-
cant negative impact on performance.
In our first experiments, we tested the four re-
ordering constraints with various window sizes. We
aimed at improving the translation results on the de-
velopment corpora and compared the results with
two baselines: reordering only the source training
sentences and translation of the unreordered test sen-
tences; and the GIATI technique for creating bilin-
gual tuples (fj, ej) without reordering of the source
sentences, neither in training nor during translation.
</bodyText>
<subsubsectionHeader confidence="0.529859">
5.3.1 Highly Non-Monotonic Translation (JE)
</subsubsectionHeader>
<bodyText confidence="0.9997583125">
Fig. 3 (left) shows word error rate on the
Japanese-to-English task as a function of the win-
dow size for different reordering constraints. For
each of the constraints, good results are achieved
using a window size of 9 and larger. This can be
attributed to the Japanese word order which is very
different from English and often follows a subject-
object-verb structure. For small window sizes, ITG
or IBM constraints are better suited for this task, for
larger window sizes, inverse IBM constraints per-
form best. The local constraints perform worst and
require very large window sizes to capture the main
word order differences between Japanese and En-
glish. However, their computational complexity is
low; for instance, a system with local constraints
and window size of 9 is as fast (25 words per sec-
ond) as the same system with IBM constraints and
window size of 5. Using window sizes larger than
10 is computationally expensive and does not sig-
nificantly improve the translation quality under any
of the constraints.
Tab. 2 presents the overall improvements in trans-
lation quality when using the best setting: inverse
IBM constraints, window size 9. The baseline with-
out reordering in training and testing failed com-
pletely for this task, producing empty translations
for 37 % of the sentences2. Most of the original
alignments in training were non-monotonic which
resulted in mapping of almost all Japanese words to
E when using only the GIATI monotonization tech-
nique. Thus, the proposed reordering methods are of
crucial importance for this task.
</bodyText>
<footnote confidence="0.940729">
2Hence a NIST score of 0 due to the brevity penalty.
</footnote>
<page confidence="0.978713">
172
</page>
<table confidence="0.999478916666667">
Reordering: mWER mPER BLEU NIST
[%] [%] [%]
BTEC Japanese-to-English (JE) dev
none 59.7 58.8 13.0 0.00
in training 57.8 39.4 14.7 3.27
+ 9-inv-ibm 40.3 32.1 45.1 8.59
+ rescoring* 39.1 30.9 53.2 9.93
BTEC Chinese-to-English (CE) dev
none 55.2 52.1 24.9 1.34
in training 54.0 42.3 23.0 4.18
+ 7-inv-ibm 47.1 39.4 34.5 6.53
+ rescoring* 48.3 40.7 39.1 8.11
</table>
<tableCaption confidence="0.82375725">
Table 2: Translation results with optimal reorder-
ing constraints and window sizes for the BTEC
Japanese-to-English and Chinese-to-English devel-
opment corpora. *Optimized for the NIST score.
</tableCaption>
<table confidence="0.999660875">
mWER mPER BLEU NIST
[%] [%] [%]
BTEC Japanese-to-English (JE) test
AT 41.9 33.8 45.3 9.49
WFST 42.1 35.6 47.3 9.50
BTEC Chinese-to-English (CE) test
AT 45.6 39.0 40.9 8.55
WFST 46.4 38.8 40.8 8.73
</table>
<tableCaption confidence="0.998824">
Table 3: Comparison of the IWSLT-2004 automatic
</tableCaption>
<bodyText confidence="0.983371272727273">
evaluation results for the described system (WFST)
with those of the best submitted system (AT).
Further improvements were obtained with a
rescoring procedure. For rescoring, we produced
a k-best list of translation hypotheses and used the
word penalty and deletion model features, the IBM
Model 1 lexicon score, and target language n-gram
models of the order up to 9. The scaling factors for
all features were optimized on the development cor-
pus for the NIST score, as described in (Bender et
al., 2004).
</bodyText>
<subsectionHeader confidence="0.541725">
5.3.2 Moderately Non-Mon. Translation (CE)
</subsectionHeader>
<bodyText confidence="0.9999023">
Word order in Chinese and English is usually sim-
ilar. However, a few word reorderings over quite
large distances may be necessary. This is especially
true in case of questions, in which question words
like “where” and “when” are placed at the end of
a sentence in Chinese. The BTEC corpora contain
many sentences with questions.
The inverse IBM constraints are designed to per-
form this type of reordering (see Sec. 4.3). As shown
in Fig. 3, the system performs well under these con-
</bodyText>
<table confidence="0.998933666666667">
Reordering: mWER mPER BLEU NIST
[%] [%] [%]
none 25.6 22.0 62.1 10.46
in training 28.0 22.3 58.1 10.32
+ 4-local 26.3 20.3 62.2 10.81
+ weights 25.3 20.3 62.6 10.79
+ 3-ibm 27.2 20.5 61.4 10.76
+ weights 25.2 20.3 62.9 10.80
+ rescoring* 22.2 19.0 69.2 10.47
</table>
<tableCaption confidence="0.991699">
Table 4: Translation results with optimal reordering
</tableCaption>
<bodyText confidence="0.98606712">
constraints and window sizes for the test corpus of
the BTEC IE task. *Optimized for WER.
straints already with relatively small window sizes.
Increasing the window size beyond 4 for these con-
straints only marginally improves the translation er-
ror measures for both short (under 8 words) and long
sentences. Thus, a suitable language-pair-specific
choice of reordering constraints can avoid the huge
computational complexity required for permutations
of long sentences.
Tab. 2 includes error measures for the best setup
with inverse IBM constraints with window size of 7,
as well as additional improvements obtained by a k-
best list rescoring.
The best settings for reordering constraints and
model scaling factors on the development corpora
were then used to produce translations of the IWSLT
Japanese and Chinese test corpora. These trans-
lations were evaluated against multiple references
which were unknown to the authors. Our system
(denoted with WFST, see Tab. 3) produced results
competitive with the results of the best system at the
evaluation campaign (denoted with AT (Bender et
al., 2004)) and, according to some of the error mea-
sures, even outperformed this system.
</bodyText>
<subsectionHeader confidence="0.489525">
5.3.3 Almost Monotonic Translation (IE)
</subsectionHeader>
<bodyText confidence="0.99995875">
The word order in the Italian language does not
differ much from the English. Therefore, the abso-
lute translation error rates are quite low and translat-
ing without reordering in training and search already
results in a relatively good performance. This is re-
flected in Tab. 4. However, even for this language
pair it is possible to improve translation quality by
performing reordering both in training and during
translation. The best performance on the develop-
ment corpus is obtained when we constrain the re-
odering with relatively small window sizes of 3 to 4
and use either IBM or local reordering constraints.
</bodyText>
<page confidence="0.996659">
173
</page>
<bodyText confidence="0.999558">
On the test corpus, as shown in Tab. 4, all error mea-
sures can be improved with these settings.
Especially for languages with similar word order
it is important to use weighted reorderings (Sec. 4.6)
in order to prefer the original word order. Introduc-
tion of reordering weights for this task results in no-
table improvement of most error measures using ei-
ther the IBM or local constraints. The optimal prob-
ability α for the unreordered path was determined
on the development corpus as 0.5 for both of these
constraints. The results on the test corpus using this
setting are also given in Tab. 4.
</bodyText>
<sectionHeader confidence="0.999626" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999985176470588">
In this paper, we described a reordering framework
which performs source sentence reordering on word
level. We suggested to use optimal alignment func-
tions for monotonization and improvement of trans-
lation model training. This allowed us to translate
monotonically taking a reordering graph as input.
We then described known and novel reordering con-
straints and their efficient finite-state implementa-
tions in which the reordering graph is computed on-
demand. We also utilized weighted permutations.
We showed that our monotonic phrase-based trans-
lation approach effectively makes use of the reorder-
ing framework to produce quality translations even
from languages with significantly different word or-
der. On the Japanese-to-English and Chinese-to-
English IWSLT tasks, our system performed at least
as well as the best machine translation system.
</bodyText>
<sectionHeader confidence="0.983723" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999774166666667">
This work was partially funded by the Deutsche
Forschungsgemeinschaft (DFG) under the project
“Statistische Text¨ubersetzung” (Ne572/5) and by the
European Union under the integrated project TC-
STAR – Technology and Corpora for Speech to
Speech Translation (IST-2002-FP6-506738).
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999912615384615">
Y. Akiba, M. Federico, N. Kando, H. Nakaiwa, M. Paul,
and J. Tsujii. 2004. Overview of the IWSLT04 Evalu-
ation Campaign. Proc. Int. Workshop on Spoken Lan-
guage Translation, pp. 1–12, Kyoto, Japan.
S. Bangalore and G. Riccardi. 2000. Stochastic Finite-
State Models for Spoken Language Machine Transla-
tion. Proc. Workshop on Embedded Machine Transla-
tion Systems, pp. 52–59.
O. Bender, R. Zens, E. Matusov, and H. Ney. 2004.
Alignment Templates: the RWTH SMT System. Proc.
Int. Workshop on Spoken Language Translation, pp.
79–84, Kyoto, Japan.
A. L. Berger, P. F. Brown, S. A. Della Pietra, V. J. Della
Pietra, J. R. Gillett, A. S. Kehler, and R. L. Mercer.
1996. Language Translation Apparatus and Method
of Using Context-based Translation Models. United
States Patent 5510981.
F. Casacuberta and E. Vidal. 2004. Machine Transla-
tion with Inferred Stochastic Finite-State Transducers.
Computational Linguistics, vol. 30(2):205-225.
G. Doddington. 2002. Automatic Evaluation ofMachine
Translation Quality Using n-gram Co-Occurrence
Statistics. Proc. Human Language Technology Conf.,
San Diego, CA.
S. Kanthak and H. Ney. 2004. FSA: an Efficient and
Flexible C++ Toolkit for Finite State Automata using
On-demand Computation. Proc. 42nd Annual Meet-
ing of the Association for Computational Linguistics,
pp. 510–517, Barcelona, Spain.
K. Knight and Y. Al-Onaizan. 1998. Translation with
Finite-State Devices. Lecture Notes in Artificial Intel-
ligence, Springer-Verlag, vol. 1529, pp. 421–437.
S. Kumar and W. Byrne. 2003. A Weighted Finite State
Transducer Implementation of the Alignment Template
Model for Statistical Machine Translation. Proc. Hu-
man Language Technology Conf. NAACL, pp. 142–
149, Edmonton, Canada.
E. Matusov, R. Zens, and H. Ney. 2004. Symmetric Word
Alignments for Statistical Machine Translation. Proc.
20th Int. Conf. on Computational Linguistics, pp. 219–
225, Geneva, Switzerland.
F. J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, vol. 29, number 1, pp. 19–51.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
BLEU: a Methodfor Automatic Evaluation ofMachine
Translation. Proc. 40th Annual Meeting of the Associ-
ation for Computational Linguistics, Philadelphia, PA,
pp. 311–318.
J. M. Vilar, 2000. Improve the Learning of Sub-
sequential Transducers by Using Alignments and Dic-
tionaries. Lecture Notes in Artificial Intelligence,
Springer-Verlag, vol. 1891, pp. 298–312.
D. Wu. 1997. Stochastic Inversion Transduction
Grammars and Bilingual Parsing ofParallel Corpora.
Computational Linguistics, 23(3):377–403.
R. Zens, F. J. Och and H. Ney. 2002. Phrase-Based Sta-
tistical Machine Translation. In: M. Jarke, J. Koehler,
G. Lakemeyer (Eds.): KI - Conference on AI, KI 2002,
Vol. LNAI 2479, pp. 18-32, Springer Verlag.
R. Zens and H. Ney. 2003. A Comparative Study on
Reordering Constraints in Statistical Machine Trans-
lation. Proc. Annual Meeting of the Association
for Computational Linguistics, pp. 144–151, Sapporo,
Japan.
</reference>
<page confidence="0.998421">
174
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.836349">
<title confidence="0.9995195">Novel Reordering Approaches in Phrase-Based Statistical Machine Translation</title>
<author confidence="0.998523">Stephan Kanthak</author>
<author confidence="0.998523">David Vilar</author>
<author confidence="0.998523">Evgeny Matusov</author>
<author confidence="0.998523">Richard Zens</author>
<author confidence="0.998523">Hermann</author>
<affiliation confidence="0.9302595">The authors are with the Lehrstuhl f¨ur Informatik Computer Science Department, RWTH Aachen</affiliation>
<address confidence="0.990103">D-52056 Aachen,</address>
<abstract confidence="0.999022454545455">This paper presents novel approaches to reordering in phrase-based statistical machine translation. We perform consistent reordering of source sentences in training and estimate a statistical translation model. Using this model, we follow a phrase-based monotonic machine translation approach, for which we develop an efficient and flexible reordering framework that allows to easily introduce different reordering constraints. In translation, we apply source sentence reordering on word level and use a reordering automaton as input. We show how to compute reordering automata on-demand using IBM or ITG constraints, and also introduce two new types of reordering constraints. We further add weights to the reordering automata. We present detailed experimental results and show that reordering significantly improves translation quality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Akiba</author>
<author>M Federico</author>
<author>N Kando</author>
<author>H Nakaiwa</author>
<author>M Paul</author>
<author>J Tsujii</author>
</authors>
<date>2004</date>
<booktitle>Overview of the IWSLT04 Evaluation Campaign. Proc. Int. Workshop on Spoken Language Translation,</booktitle>
<pages>1--12</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="17813" citStr="Akiba et al., 2004" startWordPosition="3025" endWordPosition="3028">form probability. This weighting scheme clearly depends on the state description and the outgoing arcs only and can be computed on-demand. 5 Experimental Results 5.1 Corpus Statistics The translation experiments were carried out on the Basic Travel Expression Corpus (BTEC), a multilingual speech corpus which contains tourism-related sentences usually found in travel phrase books. We tested our system on the so called Chinese-toEnglish (CE) and Japanese-to-English (JE) Supplied Tasks, the corpora which were provided during the International Workshop on Spoken Language Translation (IWSLT 2004) (Akiba et al., 2004). In addition, we performed experiments on the Italian-toEnglish (IE) task, for which a larger corpus was kindly provided to us by ITC/IRST. The corpus statistics for the three BTEC corpora are given in Tab. 1. The development corpus for the Italian-toEnglish translation had only one reference translation of each Italian sentence. A set of 506 source sentences and 16 reference translations is used as a development corpus for Chinese-to-English and Japanese-to-English and as a test corpus for Italianto-English tasks. The 500 sentence Chinese and Japanese test sets of the IWSLT 2004 evaluation c</context>
</contexts>
<marker>Akiba, Federico, Kando, Nakaiwa, Paul, Tsujii, 2004</marker>
<rawString>Y. Akiba, M. Federico, N. Kando, H. Nakaiwa, M. Paul, and J. Tsujii. 2004. Overview of the IWSLT04 Evaluation Campaign. Proc. Int. Workshop on Spoken Language Translation, pp. 1–12, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Riccardi</author>
</authors>
<title>Stochastic FiniteState Models for Spoken Language Machine Translation.</title>
<date>2000</date>
<booktitle>Proc. Workshop on Embedded Machine Translation Systems,</booktitle>
<pages>52--59</pages>
<marker>Bangalore, Riccardi, 2000</marker>
<rawString>S. Bangalore and G. Riccardi. 2000. Stochastic FiniteState Models for Spoken Language Machine Translation. Proc. Workshop on Embedded Machine Translation Systems, pp. 52–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bender</author>
<author>R Zens</author>
<author>E Matusov</author>
<author>H Ney</author>
</authors>
<title>Alignment Templates: the RWTH SMT System.</title>
<date>2004</date>
<booktitle>Proc. Int. Workshop on Spoken Language Translation,</booktitle>
<pages>79--84</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="2745" citStr="Bender et al. (2004)" startWordPosition="390" endWordPosition="393">the reordering problem from the view of the model. Without reordering both in training and during search, sentences can only be translated properly into a language with similar word order. In (Bangalore et al., 2000) weighted reordering has been applied to target sentences since defining a permutation model on the source side is impractical in combination with speech recognition. In order to reduce the computational complexity, this approach considers only a set of plausible reorderings seen on training data. Most other phrase-based statistical approaches like the Alignment Template system of Bender et al. (2004) rely on (local) reorderings which are implicitly memorized with each pair of source and target phrases in training. Additional reorderings on phrase level are fully integrated into the decoding process, which increases the complexity of the system and makes it hard to modify. Zens et al. (2003) reviewed two types of reordering constraints for this type of translation systems. In our work we follow a phrase-based translation approach, applying source sentence reordering on word level. We compute a reordering graph ondemand and take it as input for monotonic translation. This approach is modula</context>
<context position="14664" citStr="Bender et al., 2004" startWordPosition="2433" endWordPosition="2436">b) IBM constraints, c) inverse IBM constraints and d) local constraints. very low complexity is given by the following permutation rule: the next word for translation comes from the window of l positions1 counting from the first yet uncovered position. Note, that the local constraints define a true subset of the permutations defined by the IBM constraints. 4.5 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997). These constraints are inspired by bilingual bracketing. They proved to be quite useful for machine translation, e.g. see (Bender et al., 2004). Here, we interpret the input sentence as a sequence of segments. In the beginning, each word is a segment of its own. Longer segments are constructed by recursively combining two adjacent segments. At each 1both covered and uncovered 1001 2 4 d) 1010 2 3 c) 4 a) 1 2 3 4 0000 1000 1100 1110 1111 b) 3 1 4 1011 1000 2 1010 2 2 3 1110 4 0000 2 1 1100 4 3 1111 0100 3 1 1101 1 0110 4 0111 0001 1 0000 2 1 1000 2 3 1100 4 3 2 1101 1110 3 4 1111 3 0100 1 1010 1 0010 1 1000 1110 4 2 3 0000 2 1 1100 4 3 1111 0100 1101 170 Chinese English Japanese English Italian English train sentences 20 000 20 000 66</context>
<context position="23909" citStr="Bender et al., 2004" startWordPosition="4020" endWordPosition="4023">o-English (CE) test AT 45.6 39.0 40.9 8.55 WFST 46.4 38.8 40.8 8.73 Table 3: Comparison of the IWSLT-2004 automatic evaluation results for the described system (WFST) with those of the best submitted system (AT). Further improvements were obtained with a rescoring procedure. For rescoring, we produced a k-best list of translation hypotheses and used the word penalty and deletion model features, the IBM Model 1 lexicon score, and target language n-gram models of the order up to 9. The scaling factors for all features were optimized on the development corpus for the NIST score, as described in (Bender et al., 2004). 5.3.2 Moderately Non-Mon. Translation (CE) Word order in Chinese and English is usually similar. However, a few word reorderings over quite large distances may be necessary. This is especially true in case of questions, in which question words like “where” and “when” are placed at the end of a sentence in Chinese. The BTEC corpora contain many sentences with questions. The inverse IBM constraints are designed to perform this type of reordering (see Sec. 4.3). As shown in Fig. 3, the system performs well under these conReordering: mWER mPER BLEU NIST [%] [%] [%] none 25.6 22.0 62.1 10.46 in t</context>
<context position="25845" citStr="Bender et al., 2004" startWordPosition="4336" endWordPosition="4339">ncludes error measures for the best setup with inverse IBM constraints with window size of 7, as well as additional improvements obtained by a kbest list rescoring. The best settings for reordering constraints and model scaling factors on the development corpora were then used to produce translations of the IWSLT Japanese and Chinese test corpora. These translations were evaluated against multiple references which were unknown to the authors. Our system (denoted with WFST, see Tab. 3) produced results competitive with the results of the best system at the evaluation campaign (denoted with AT (Bender et al., 2004)) and, according to some of the error measures, even outperformed this system. 5.3.3 Almost Monotonic Translation (IE) The word order in the Italian language does not differ much from the English. Therefore, the absolute translation error rates are quite low and translating without reordering in training and search already results in a relatively good performance. This is reflected in Tab. 4. However, even for this language pair it is possible to improve translation quality by performing reordering both in training and during translation. The best performance on the development corpus is obtai</context>
</contexts>
<marker>Bender, Zens, Matusov, Ney, 2004</marker>
<rawString>O. Bender, R. Zens, E. Matusov, and H. Ney. 2004. Alignment Templates: the RWTH SMT System. Proc. Int. Workshop on Spoken Language Translation, pp. 79–84, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>J R Gillett</author>
<author>A S Kehler</author>
<author>R L Mercer</author>
</authors>
<title>Language Translation Apparatus and Method of Using Context-based Translation Models. United States Patent 5510981.</title>
<date>1996</date>
<contexts>
<context position="12342" citStr="Berger et al., 1996" startWordPosition="2038" endWordPosition="2041"> recombining paths in the automaton as states with A3 169 the same bit vectors can be merged. As a result, a fully minimized permutation automaton has only a single initial and final state. Even with on-demand computation, complexity using full permutations is unmanagable for long sentences. We further reduce complexity by additionally constraining permutations. Refer to Figure 2 for visualizations of the permutation constraints which we describe in the following. 4.2 IBM Constraints The IBM reordering constraints are well-known in the field of machine translation and were first described in (Berger et al., 1996). The idea behind these constraints is to deviate from monotonic translation by postponing translations of a limited number of words. More specifically, at each state we can translate any of the first l yet uncovered word positions. The implementation using a bit vector is straightforward. For consistency, we associate window size with the parameter l for all constraints presented here. 4.3 Inverse IBM Constraints The original IBM constraints are useful for a large number of language pairs where the ability to skip some words reflects the differences in word order between the two languages. Fo</context>
</contexts>
<marker>Berger, Brown, Pietra, Pietra, Gillett, Kehler, Mercer, 1996</marker>
<rawString>A. L. Berger, P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, J. R. Gillett, A. S. Kehler, and R. L. Mercer. 1996. Language Translation Apparatus and Method of Using Context-based Translation Models. United States Patent 5510981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Casacuberta</author>
<author>E Vidal</author>
</authors>
<date>2004</date>
<booktitle>Machine Translation with Inferred Stochastic Finite-State Transducers. Computational Linguistics,</booktitle>
<volume>vol.</volume>
<pages>30--2</pages>
<marker>Casacuberta, Vidal, 2004</marker>
<rawString>F. Casacuberta and E. Vidal. 2004. Machine Translation with Inferred Stochastic Finite-State Transducers. Computational Linguistics, vol. 30(2):205-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic Evaluation ofMachine Translation Quality Using n-gram Co-Occurrence Statistics.</title>
<date>2002</date>
<booktitle>Proc. Human Language Technology Conf.,</booktitle>
<location>San Diego, CA.</location>
<contexts>
<context position="18836" citStr="Doddington, 2002" startWordPosition="3189" endWordPosition="3190">development corpus for Chinese-to-English and Japanese-to-English and as a test corpus for Italianto-English tasks. The 500 sentence Chinese and Japanese test sets of the IWSLT 2004 evaluation campaign were translated and automatically scored against 16 reference translations after the end of the campaign using the IWSLT evaluation server. 5.2 Evaluation Criteria For the automatic evaluation, we used the criteria from the IWSLT evaluation campaign (Akiba et al., 2004), namely word error rate (WER), positionindependent word error rate (PER), and the BLEU and NIST scores (Papineni et al., 2002; Doddington, 2002). The two scores measure accuracy, i. e. larger scores are better. The error rates and scores were computed with respect to multiple reference transla171 1 2 3 4 5 6 7 8 9 reordering constraints window size 1 2 3 4 5 6 7 8 9 reordering constraints window size INV-IBM IBM ITG LOCAL INV-IBM IBM ITG LOCAL 60 58 56 54 52 50 48 46 44 42 40 55 54 53 52 51 50 49 48 47 46 Figure 3: Word error rate [%] as a function of the reordering window size for different reordering constraints: Japanese-to-English (left) and Chinese-to-English (right) translation. tions, when they were available. To indicate this,</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>G. Doddington. 2002. Automatic Evaluation ofMachine Translation Quality Using n-gram Co-Occurrence Statistics. Proc. Human Language Technology Conf., San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanthak</author>
<author>H Ney</author>
</authors>
<title>FSA: an Efficient and Flexible C++ Toolkit for Finite State Automata using On-demand Computation.</title>
<date>2004</date>
<booktitle>Proc. 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>510--517</pages>
<location>Barcelona,</location>
<marker>Kanthak, Ney, 2004</marker>
<rawString>S. Kanthak and H. Ney. 2004. FSA: an Efficient and Flexible C++ Toolkit for Finite State Automata using On-demand Computation. Proc. 42nd Annual Meeting of the Association for Computational Linguistics, pp. 510–517, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>Y Al-Onaizan</author>
</authors>
<title>Translation with Finite-State Devices.</title>
<date>1998</date>
<journal>Lecture Notes in Artificial Intelligence, Springer-Verlag,</journal>
<volume>1529</volume>
<pages>421--437</pages>
<marker>Knight, Al-Onaizan, 1998</marker>
<rawString>K. Knight and Y. Al-Onaizan. 1998. Translation with Finite-State Devices. Lecture Notes in Artificial Intelligence, Springer-Verlag, vol. 1529, pp. 421–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>A Weighted Finite State Transducer Implementation of the Alignment Template Model for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>Proc. Human Language Technology Conf. NAACL,</booktitle>
<pages>142--149</pages>
<location>Edmonton, Canada.</location>
<marker>Kumar, Byrne, 2003</marker>
<rawString>S. Kumar and W. Byrne. 2003. A Weighted Finite State Transducer Implementation of the Alignment Template Model for Statistical Machine Translation. Proc. Human Language Technology Conf. NAACL, pp. 142– 149, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Symmetric Word Alignments for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>Proc. 20th Int. Conf. on Computational Linguistics,</booktitle>
<pages>219--225</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="6633" citStr="Matusov et al., 2004" startWordPosition="1044" endWordPosition="1047">h the empty phrase. Therefore, for language pairs with big differences in word order, probability estimates may be poor. This problem can be solved by reordering either source or target training sentences such that alignments become monotonic for all sentences. We suggest the following consistent source sentence reordering and alignment monotonization approach in which we compute optimal, minimum-cost alignments. First, we estimate a cost matrix C for each sentence pair (fJ1 , ei). The elements of this matrix cij are the local costs of aligning a source word fj to a target word ei. Following (Matusov et al., 2004), we compute these local costs by interpolating state occupation probabilities from the source-to-target and target-to-source training of the HMM and IBM-4 models as trained by the GIZA++ toolkit (Och et al., 2003). For a given alignment A C_ I x J, we define the costs of this alignment c(A) as the sum of the local costs of all aligned word pairs: c(A) = E cij (1) (i,j)EA �= argmax eJ 1 max AEA r(fj, ˜ej|fj−1 1 , ˜ej−1 1 ,A) �= argmax eJ 1 The goal is to find an alignment with the minimum costs which fulfills certain constraints. � max P AEA fj:j=1...J = argmax eJ 1 max AEA fj:j=1...J ( j−1 ˜j</context>
</contexts>
<marker>Matusov, Zens, Ney, 2004</marker>
<rawString>E. Matusov, R. Zens, and H. Ney. 2004. Symmetric Word Alignments for Statistical Machine Translation. Proc. 20th Int. Conf. on Computational Linguistics, pp. 219– 225, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<pages>pp.</pages>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, vol. 29, number 1, pp. 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a Methodfor Automatic Evaluation ofMachine Translation.</title>
<date>2002</date>
<booktitle>Proc. 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="18817" citStr="Papineni et al., 2002" startWordPosition="3185" endWordPosition="3188">nslations is used as a development corpus for Chinese-to-English and Japanese-to-English and as a test corpus for Italianto-English tasks. The 500 sentence Chinese and Japanese test sets of the IWSLT 2004 evaluation campaign were translated and automatically scored against 16 reference translations after the end of the campaign using the IWSLT evaluation server. 5.2 Evaluation Criteria For the automatic evaluation, we used the criteria from the IWSLT evaluation campaign (Akiba et al., 2004), namely word error rate (WER), positionindependent word error rate (PER), and the BLEU and NIST scores (Papineni et al., 2002; Doddington, 2002). The two scores measure accuracy, i. e. larger scores are better. The error rates and scores were computed with respect to multiple reference transla171 1 2 3 4 5 6 7 8 9 reordering constraints window size 1 2 3 4 5 6 7 8 9 reordering constraints window size INV-IBM IBM ITG LOCAL INV-IBM IBM ITG LOCAL 60 58 56 54 52 50 48 46 44 42 40 55 54 53 52 51 50 49 48 47 46 Figure 3: Word error rate [%] as a function of the reordering window size for different reordering constraints: Japanese-to-English (left) and Chinese-to-English (right) translation. tions, when they were available</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a Methodfor Automatic Evaluation ofMachine Translation. Proc. 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA, pp. 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Vilar</author>
</authors>
<title>Improve the Learning of Subsequential Transducers by Using Alignments and Dictionaries.</title>
<date>2000</date>
<journal>Lecture Notes in Artificial Intelligence, Springer-Verlag,</journal>
<volume>1891</volume>
<pages>298--312</pages>
<contexts>
<context position="2054" citStr="Vilar, 2000" startWordPosition="281" endWordPosition="282">d single-word based translation using conditional probabilities. In a refinement with additional phrase-based models, (Kumar et al., 2003) define a probability distribution over all possible permutations of source sentence phrases and prune the resulting automaton to reduce complexity. A second category of finite-state translation approaches uses joint instead of conditional probabilities. Many joint probability approaches originate in speech-to-speech translation as they are the natural choice in combination with speech recognition models. The automated transducer inference techniques OMEGA (Vilar, 2000) and GIATI (Casacuberta et al., 2004) work on phrase level, but ignore the reordering problem from the view of the model. Without reordering both in training and during search, sentences can only be translated properly into a language with similar word order. In (Bangalore et al., 2000) weighted reordering has been applied to target sentences since defining a permutation model on the source side is impractical in combination with speech recognition. In order to reduce the computational complexity, this approach considers only a set of plausible reorderings seen on training data. Most other phr</context>
</contexts>
<marker>Vilar, 2000</marker>
<rawString>J. M. Vilar, 2000. Improve the Learning of Subsequential Transducers by Using Alignments and Dictionaries. Lecture Notes in Artificial Intelligence, Springer-Verlag, vol. 1891, pp. 298–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<date>1997</date>
<booktitle>Stochastic Inversion Transduction Grammars and Bilingual Parsing ofParallel Corpora. Computational Linguistics,</booktitle>
<pages>23--3</pages>
<contexts>
<context position="14520" citStr="Wu, 1997" startWordPosition="2412" endWordPosition="2413">s and therefore has Figure 2: Permutations of a) positions j = 1, 2, 3, 4 of a source sentence f1f2f3f4 using a window size of 2 for b) IBM constraints, c) inverse IBM constraints and d) local constraints. very low complexity is given by the following permutation rule: the next word for translation comes from the window of l positions1 counting from the first yet uncovered position. Note, that the local constraints define a true subset of the permutations defined by the IBM constraints. 4.5 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997). These constraints are inspired by bilingual bracketing. They proved to be quite useful for machine translation, e.g. see (Bender et al., 2004). Here, we interpret the input sentence as a sequence of segments. In the beginning, each word is a segment of its own. Longer segments are constructed by recursively combining two adjacent segments. At each 1both covered and uncovered 1001 2 4 d) 1010 2 3 c) 4 a) 1 2 3 4 0000 1000 1100 1110 1111 b) 3 1 4 1011 1000 2 1010 2 2 3 1110 4 0000 2 1 1100 4 3 1111 0100 3 1 1101 1 0110 4 0111 0001 1 0000 2 1 1000 2 3 1100 4 3 2 1101 1110 3 4 1111 3 0100 1 1010</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing ofParallel Corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Phrase-Based Statistical Machine Translation. In:</title>
<date>2002</date>
<booktitle>Lakemeyer (Eds.): KI - Conference on AI, KI 2002, Vol. LNAI 2479,</booktitle>
<pages>18--32</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="11410" citStr="Zens et al., 2002" startWordPosition="1878" endWordPosition="1881">ermutations as a finite-state automaton requires at least 2J states. Therefore, we opt for computing the permutation automaton on-demand while applying beam pruning in the search. 4.1 Lazy Permutation Automata For on-demand computation of an automaton in the flavor described in (Kanthak et al., 2004) it is sufficient to specify a state description and an algorithm that calculates all outgoing arcs of a state from the state description. In our case, each state represents a permutation of a subset of the source words fJ1 , which are already translated. This can be described by a bit vector bJ1 (Zens et al., 2002). Each bit of the state bit vector corresponds to an arc of the linear input automaton and is set to one if the arc has been used on any path from the initial to the current state. The bit vectors of two states connected by an arc differ only in a single bit. Note that bit vectors elegantly solve the problem of recombining paths in the automaton as states with A3 169 the same bit vectors can be merged. As a result, a fully minimized permutation automaton has only a single initial and final state. Even with on-demand computation, complexity using full permutations is unmanagable for long senten</context>
</contexts>
<marker>Zens, Och, Ney, 2002</marker>
<rawString>R. Zens, F. J. Och and H. Ney. 2002. Phrase-Based Statistical Machine Translation. In: M. Jarke, J. Koehler, G. Lakemeyer (Eds.): KI - Conference on AI, KI 2002, Vol. LNAI 2479, pp. 18-32, Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>A Comparative Study on Reordering Constraints in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>Proc. Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>144--151</pages>
<location>Sapporo, Japan.</location>
<marker>Zens, Ney, 2003</marker>
<rawString>R. Zens and H. Ney. 2003. A Comparative Study on Reordering Constraints in Statistical Machine Translation. Proc. Annual Meeting of the Association for Computational Linguistics, pp. 144–151, Sapporo, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>