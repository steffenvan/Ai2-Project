<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008458">
<title confidence="0.9987165">
Improving alignment for SMT by reordering
and augmenting the training corpus
</title>
<author confidence="0.998763">
Maria Holmqvist, Sara Stymne, Jody Foo and Lars Ahrenberg
</author>
<affiliation confidence="0.9780275">
Department of Computer and Information Science
Linköping University, Sweden
</affiliation>
<email confidence="0.995206">
{marho,sarst,jodfo,lah}@ida.liu.se
</email>
<sectionHeader confidence="0.993832" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999830681818182">
We describe the LIU systems for English-
German and German-English translation
in the WMT09 shared task. We focus on
two methods to improve the word align-
ment: (i) by applying Giza++ in a sec-
ond phase to a reordered training cor-
pus, where reordering is based on the
alignments from the first phase, and (ii)
by adding lexical data obtained as high-
precision alignments from a different word
aligner. These methods were studied in
the context of a system that uses com-
pound processing, a morphological se-
quence model for German, and a part-
of-speech sequence model for English.
Both methods gave some improvements to
translation quality as measured by Bleu
and Meteor scores, though not consis-
tently. All systems used both out-of-
domain and in-domain data as the mixed
corpus had better scores in the baseline
configuration.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999677615384615">
It is an open question whether improved word
alignment actually improves statistical MT. Fraser
and Marcu (2007) found that improved alignments
as measured by AER will not necessarily improve
translation quality, whereas Ganchev et al. (2008)
did improve translation quality on several lan-
guage pairs by extending the alignment algorithm.
For this year’s shared task we therefore stud-
ied the effects of improving word alignment in the
context of our system for the WMT09 shared task.
Two methods were tried: (i) applying Giza++ in
a second phase to a reordered training corpus,
where reordering is based on the alignments from
the first phase, and (ii) adding lexical data ob-
tained as high-precision alignments from a differ-
ent word aligner. The submitted system includes
the first method in addition to the processing of
compounds and additional sequence models used
by Stymne et al. (2008). Heuristics were used
to generate true-cased versions of the translations
that were submitted, as reported in section 6.
In this paper we report case-insensitive Bleu
scores (Papineni et al., 2002), unless otherwise
stated, calculated with the NIST tool, and case-
insensitive Meteor-ranking scores, without Word-
Net (Agarwal and Lavie, 2008).
</bodyText>
<sectionHeader confidence="0.923858" genericHeader="introduction">
2 Baseline system
</sectionHeader>
<bodyText confidence="0.998428375">
Our baseline system uses compound split-
ting, compound merging and part-of-
speech/morphological sequence models (Stymne
et al., 2008). Except for these additions it is
similar to the baseline system of the workshop1.
The translation system is a factored phrase-
based translation system that uses the Moses
toolkit (Koehn et al., 2007) for decoding and train-
ing, GIZA++ for word alignment (Och and Ney,
2003), and SRILM (Stolcke, 2002) for language
models. Minimum error rate training was used to
tune the model feature weights (Och, 2003).
Tuning was performed on the news-dev2009a
set with 1025 sentences. All development test-
ing was performed on the news-dev2009b set with
1026 sentences.
</bodyText>
<subsectionHeader confidence="0.9826005">
2.1 Sequence model based on part-of-speech
and morphology
</subsectionHeader>
<bodyText confidence="0.9999665">
The translation models were factored with one ad-
ditional output factor. For English we used part-
of-speech tags obtained with TreeTagger (Schmid,
1994). For German we enriched the tags from
TreeTagger with morphological information, such
as case or tense, that we get from a commercial
</bodyText>
<footnote confidence="0.9984745">
1http://www.statmt.org/wmt09/baseline.
html
</footnote>
<note confidence="0.4977205">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 120–124,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.993562">
120
</page>
<bodyText confidence="0.9579062">
dependency parser2.
We used the extra factor in an additional se-
quence model which can improve agreement be-
tween words, and word order. For German this
factor was also used for compound merging.
</bodyText>
<subsectionHeader confidence="0.99983">
2.2 Compound processing
</subsectionHeader>
<bodyText confidence="0.999960407407408">
Prior to training and translation, compound pro-
cessing was performed using an empirical method
based on (Koehn and Knight, 2003; Stymne,
2008). Words were split if they could be split
into parts that occur in a monolingual corpus. We
chose the split with the highest arithmetic mean
of the corpus frequencies of compound parts. We
split nouns, adjectives and verbs into parts that
were content words or particles. A part had to
be at least 3 characters in length and a stop list
was used to avoid parts that often lead to errors,
such as arische (Aryan) in konsularische (con-
sular). Compound parts sometimes have special
compound suffixes, which could be additions or
truncations of letters, or combinations of these.
We used the top 10 suffixes from a corpus study
of Langer (1998), and we also treated hyphens as
suffixes of compound parts. Compound parts were
given a special part-of-speech tag that matched the
head word.
For translation into German, compound parts
were merged to form compounds, both during test
and tuning. The merging is based on the spe-
cial part-of-speech tag used for compound parts
(Stymne, 2009). A token with this POS-tag is
merged with the next token, either if the POS-tags
match, or if it results in a known word.
</bodyText>
<sectionHeader confidence="0.982415" genericHeader="method">
3 Domain adaptation
</sectionHeader>
<bodyText confidence="0.999850769230769">
This year three training corpora were available, a
small bilingual news commentary corpus, a rea-
sonably large Europarl corpus, and a very large
monolingual news corpus, see Table 1 for details.
The bilingual data was filtered to remove sen-
tences longer than 60 words. Because the German
news training corpus contained a number of En-
glish sentences, this corpus was cleaned by remov-
ing sentences containing a number of common En-
glish words.
Based on Koehn and Schroeder (2007) we
adapted our system from last year, which was fo-
cused on Europarl, to perform well on test data
</bodyText>
<footnote confidence="0.97404">
2Machinese syntax, from Connexor Oy http://www.
connexor.eu
</footnote>
<table confidence="0.76512325">
Corpus German English
news-commentary09 81,141
Europarl 1,331,262
news-train08 9,619,406 21,215,311
</table>
<tableCaption confidence="0.964403">
Table 1: Number of sentences in the corpora (after
filtering)
</tableCaption>
<table confidence="0.999689833333333">
Corpus En==�-De De==�En
Bleu Meteor Bleu Meteor
News com. 12.13 47.01 17.21 36.08
Europarl 12.92 47.27 18.53 37.65
Mixed 12.91 47.96 18.76 37.69
Mixed+ 14.62 49.48 19.92 38.18
</table>
<tableCaption confidence="0.999738">
Table 2: Results of domain adaptation
</tableCaption>
<bodyText confidence="0.9999815">
from the news domain. We used the possibility
to include several translation models in the Moses
decoder by using multiple alternative decoding
paths. We first trained systems on either bilingual
news data or Europarl. Then we trained a mixed
system, with two translation models one from each
corpus, a language model from the bilingual news
data, and a Europarl reordering model. The mixed
system was slightly better than the Europarl only
system. All sequence models used 5-grams for
surface form and 7-grams for part-of-speech. All
scores are shown in Table 2.
We wanted to train sequence models on the
large monolingual corpora, but due to limited
computer resources, we had to use a lower order
for this, than on the small corpus. Thus our se-
quence models on this data has lower order than
those trained on bilingual news or Europarl, with
4-grams for surface form and 6-grams for part-
of-speech. We also used the entropy-based prun-
ing included in the SRILM toolkit, with 10−8 as
a threshold. Using these sequence models in the
mixed model, called mixed+, improved the results
drastically, as shown in Table 2.
The other experiments reported in this paper are
based on the mixed+ system.
</bodyText>
<sectionHeader confidence="0.981425" genericHeader="method">
4 Improved alignment by reordering
</sectionHeader>
<bodyText confidence="0.999569571428572">
Word alignment with Giza++ has been shown to
improve from making the source and target lan-
guage more similar, e.g., in terms of segmentation
(Ma et al., 2007) or word order.
We used the following simple procedure to im-
prove alignment of the training corpus by reorder-
ing the words in one of the texts according to the
</bodyText>
<page confidence="0.977441">
121
</page>
<table confidence="0.998473">
Corpus En==&gt;.De De==&gt;.En
Bleu Meteor Bleu Meteor
Mixed+ 14.62 49.48 19.92 38.18
Re-Src 14.63 49.80 20.54 38.86
Re-Trg 14.51 48.62 20.48 38.73
</table>
<tableCaption confidence="0.999398">
Table 3: Results of reordering experiments
</tableCaption>
<listItem confidence="0.952681692307692">
word order in the other language:
1. Word align the corpus with Giza++.
2. Reorder the German words according to the
order of the English words they are aligned
to. (This is a common step in approaches that
extract reordering rules for translation. How-
ever, this is not what we use it for here.)
3. Word align the reordered German and origi-
nal English corpus with Giza++.
4. Put the reordered German words back into
their original position and adjust the align-
ments so that the improved alignment is pre-
served.
</listItem>
<bodyText confidence="0.984295431818182">
After this step we will have a possibly improved
alignment compared to the original Giza++ align-
ment. A phrase table was extracted from the align-
ment and training was performed as usual. The re-
ordering procedure was carried out on both source
(Re-Src) and target data (Re-Trg) and the results
of translating devtest data using these alignments
are shown in Table 3.
Compared with our baseline (mixed+), Bleu
and Meteor increased for the translation direction
German–English. Both source reordering and tar-
get reordering resulted in a 0.6 increase in Bleu.
For translation into German, source reordering
resulted in a somewhat higher Meteor score, but
overall did not seem to improve translation. Tar-
get reordering in this direction resulted in lower
scores.
It is not clear why reordering improved trans-
lation for German–English and not for English–
German. In all experiments, the heuristic sym-
metrization of directed Giza++ alignments was
performed in the intended translation direction 3.
3Our experiments show that symmetrization in the wrong
translation direction will result in lower translation quality
scores.
5 Augmenting the corpus with an
extracted dictionary
Previous research (Callison-Burch et al., 2004;
Fraser and Marcu, 2006) has shown that includ-
ing word aligned data during training can improve
translation results. In our case we included a dic-
tionary extracted from the news-commentary cor-
pus during the word alignment.
Using a method originally developed for term
extraction (Merkel and Foo, 2007), the news-
commentary09 corpus was grammatically anno-
tated and aligned using a heuristic word aligner.
Candidate dictionary entries were extracted from
the alignments. In order to optimize the qual-
ity of the dictionary, dictionary entry candidates
were ranked according to their Q-value, a metric
specifically designed for aligned data (Merkel and
Foo, 2007). The Q-value is based on the following
statistics:
</bodyText>
<listItem confidence="0.993464888888889">
• Type Pair Frequencies (TPF), i.e. the number
of times where the source and target types are
aligned.
• Target types per Source type (TpS), i.e. the
number of target types a specific source type
has been aligned to.
• Source types per Target type (SpT), i.e. the
number of source types a specific target type
has been aligned to.
</listItem>
<equation confidence="0.812611">
The Q-value is calculated as
Q−value= � � F
</equation>
<bodyText confidence="0.998220611111111">
� ������ . A high Q-value indi-
cates a dictionary candidate pair with a relatively
low number of translation variations. The candi-
dates were filtered using a Q-value threshold of
0.333, resulting in a dictionary containing 67287
entries.
For the experiments, the extracted dictionary
was inserted 200 times into the corpus used dur-
ing word alignment. The added dictionary entries
were removed before phrase extraction. Experi-
ments using the extracted dictionary as an addi-
tional phrase table were also run, but did not result
in any improvement of translation quality.
The results can be seen in Table 4. There was
no evident pattern how the inclusion of the dictio-
nary during alignment (DictAl) affected the trans-
lation quality. The inclusion of the dictionary pro-
duced both higher and lower Bleu scores than the
</bodyText>
<page confidence="0.993443">
122
</page>
<table confidence="0.99622">
Corpus En==&gt;.De De==&gt;.En
Bleu Meteor Bleu Meteor
Mixed+ 14.62 49.48 19.92 38.18
DictAl 14.73 49.39 18.93 37.71
</table>
<tableCaption confidence="0.996013">
Table 4: Results of domain adaptation
</tableCaption>
<table confidence="0.999457333333333">
Corpus En==&gt;.De De==&gt;.En
Mixed+ 13.31 17.47
with OOV 13.74 17.96
</table>
<tableCaption confidence="0.999033">
Table 5: Case-sensitive Bleu scores
</tableCaption>
<bodyText confidence="0.999429333333333">
baseline system depending on the translation di-
rection. Meteor scores were however consistently
lower than the baseline system.
</bodyText>
<sectionHeader confidence="0.981562" genericHeader="method">
6 Post processing of out-of-vocabulary
words
</sectionHeader>
<bodyText confidence="0.999961705882353">
In the standard systems all out-of-vocabulary
words are transferred as is from the translation in-
put to the translation output. Many of these words
are proper names, which do not get capitalized
properly, or numbers, which have different for-
matting in German and English. We used post-
processing to improve this.
For all unknown words we capitalized either the
first letter, or all letters, if they occur in that form
in the translation input. For unknown numbers
we switched between the German decimal comma
and the English decimal point for decimal num-
bers. For large numbers, English has a comma
to separate thousands, and German has a period.
These were also switched. This improved case-
sensitive Bleu scores in both translation directions,
see Table 5.
</bodyText>
<sectionHeader confidence="0.917271" genericHeader="method">
7 Submitted system
</sectionHeader>
<bodyText confidence="0.9984802">
For both translation directions De-En and En-De
we submitted a system with two translation mod-
els trained on bilingual news and Europarl. The
alignment was improved by using the reordering
techniques described in section 4. The systems
also use all features described in this paper except
for the lexical augmentation (section 5) which did
not result in significant improvement. The results
of the submitted systems on devtest data are bold-
faced in Table 3.
</bodyText>
<table confidence="0.98440425">
Corpus En==&gt;.De De==&gt;.En
All 14.63 20.54
En-De orig. 19.93 26.82
Other set 11.66 16.17
</table>
<tableCaption confidence="0.695825333333333">
Table 6: Bleu scores for the reordered systems on
two sections of development set news-dev2009b.
NIST scores show the same distribution.
</tableCaption>
<sectionHeader confidence="0.924966" genericHeader="evaluation">
8 Results on two sections of devtest data
</sectionHeader>
<bodyText confidence="0.9995054">
Comparisons of translation output with reference
translations on devtest data showed some surpris-
ing differences, which could be attributed to cor-
responding differences between source and refer-
ence data. The differences were not evenly dis-
tributed but especially frequent in those sections
where the original language was something other
than English or German. To check the homogene-
ity of the devtest data we divided it into two sec-
tions, one for documents of English or German
origin, and the other for the remainder. It turned
out that scores were dramatically different for the
two sections, as shown in Table 6.
The reason for the difference is likely to be that
only the En-De set contains source texts and trans-
lations, while the other section contains parallel
translations from the same source. This suggests
that it would be interesting to study the effects of
splitting the training corpus in the same way be-
fore training.
</bodyText>
<sectionHeader confidence="0.996767" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.9999861">
The results of augmenting the training corpus with
an extracted lexicon were inconclusive. How-
ever, the alignment reordering improved transla-
tion quality, especially in the De–En direction.
The result of these reordering experiments indi-
cates that better word alignment quality will im-
prove SMT. The reordering method described in
this paper also has the advantage of only requir-
ing two runs of Giza++, no additional resources or
training is necessary to get an improved alignment.
</bodyText>
<sectionHeader confidence="0.998854" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9918735">
Abhaya Agarwal and Alon Lavie. 2008. Meteor, M-
BLEU and M-TER: Evaluation metrics for high-
correlation with human rankings of machine trans-
lation output. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 115–118,
Columbus, Ohio.
</reference>
<page confidence="0.994514">
123
</page>
<reference confidence="0.997502761904762">
Chris Callison-Burch, David Talbot, and Miles Os-
borne. 2004. Statistical machine translation with
word- and sentence-aligned parallel corpora. In Pro-
ceedings of the 42nd Annual Meeting of ACL, pages
175–182, Barcelona, Spain.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting
of ACL, pages 769–776, Sydney, Australia.
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine trans-
lation. Computational Linguistics, 33(3):293–303.
Kuzman Ganchev, João de Almeida Varelas Graça, and
Ben Taskar. 2008. Better alignments = better trans-
lations? In Proceedings of the 46th Annual Meeting
of ACL, pages 986–993, Columbus, Ohio.
Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In Proceedings of
the tenth conference of EACL, pages 187–193, Bu-
dapest, Hungary.
Philipp Koehn and Josh Schroeder. 2007. Experi-
ments in domain adaptation for statistical machine
translation. In Proceedings of the Second Workshop
on Statistical Machine Translation, pages 224–227,
Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of
ACL, demonstration session, Prague, Czech Repub-
lic.
Stefan Langer. 1998. Zur Morphologie und Seman-
tik von Nominalkomposita. In Tagungsband der
4. Konferenz zur Verarbeitung natürlicher Sprache
(KONVENS), pages 83–97.
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007.
Boostrapping word alignment via word packing. In
Proceedings of the 45th Annual Meeting of ACL,
pages 304–311, Prague, Czech Republic.
Magnus Merkel and Jody Foo. 2007. Terminology
extraction and term ranking for standardizing term
banks. In Proceedings of the 16th Nordic Con-
ference of Computational Linguistics (NODALIDA-
2007), pages 349–354, Tartu, Estonia.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of ACL, pages 160–167, Sap-
poro, Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of ACL, pages 311–318,
Philadelphia, Pennsylvania.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In International Con-
ference on New Methods in Language Processing,
pages 44–49, Manchester, UK.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the Sev-
enth International Conference on Spoken Language
Processing (ICSLP), pages 901–904, Denver, Col-
orado.
Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.
2008. Effects of morphological analysis in transla-
tion between German and English. In Proceedings
of the Third Workshop on Statistical Machine Trans-
lation, pages 135–138, Columbus, Ohio.
Sara Stymne. 2008. German compounds in factored
statistical machine translation. In Aarne Ranta and
Bengt Nordström, editors, Proceedings of GoTAL,
6th International Conference on Natural Language
Processing, LNCS/LNAI Volume 5221, pages 464–
475.
Sara Stymne. 2009. A comparison of merging strate-
gies for translation of German compounds. In Pro-
ceedings of the EACL09 Student Research Work-
shop, Athens, Greece.
</reference>
<page confidence="0.998318">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.827696">
<title confidence="0.9747155">Improving alignment for SMT by and augmenting the training corpus</title>
<author confidence="0.995674">Maria Holmqvist</author>
<author confidence="0.995674">Sara Stymne</author>
<author confidence="0.995674">Jody Foo</author>
<author confidence="0.995674">Lars</author>
<affiliation confidence="0.9999235">Department of Computer and Information Linköping University,</affiliation>
<email confidence="0.980406">marho@ida.liu.se</email>
<email confidence="0.980406">sarst@ida.liu.se</email>
<email confidence="0.980406">jodfo@ida.liu.se</email>
<email confidence="0.980406">lah@ida.liu.se</email>
<abstract confidence="0.994854130434783">We describe the LIU systems for English- German and German-English translation in the WMT09 shared task. We focus on two methods to improve the word alignment: (i) by applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) by adding lexical data obtained as highprecision alignments from a different word aligner. These methods were studied in the context of a system that uses compound processing, a morphological sequence model for German, and a partof-speech sequence model for English. Both methods gave some improvements to translation quality as measured by Bleu and Meteor scores, though not consistently. All systems used both out-ofdomain and in-domain data as the mixed corpus had better scores in the baseline configuration.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abhaya Agarwal</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor, MBLEU and M-TER: Evaluation metrics for highcorrelation with human rankings of machine translation output.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>115--118</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="2320" citStr="Agarwal and Lavie, 2008" startWordPosition="360" endWordPosition="363">the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments from a different word aligner. The submitted system includes the first method in addition to the processing of compounds and additional sequence models used by Stymne et al. (2008). Heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6. In this paper we report case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a s</context>
</contexts>
<marker>Agarwal, Lavie, 2008</marker>
<rawString>Abhaya Agarwal and Alon Lavie. 2008. Meteor, MBLEU and M-TER: Evaluation metrics for highcorrelation with human rankings of machine translation output. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 115–118, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of ACL,</booktitle>
<pages>175--182</pages>
<location>Barcelona,</location>
<contexts>
<context position="9553" citStr="Callison-Burch et al., 2004" startWordPosition="1531" endWordPosition="1534">e reordering resulted in a somewhat higher Meteor score, but overall did not seem to improve translation. Target reordering in this direction resulted in lower scores. It is not clear why reordering improved translation for German–English and not for English– German. In all experiments, the heuristic symmetrization of directed Giza++ alignments was performed in the intended translation direction 3. 3Our experiments show that symmetrization in the wrong translation direction will result in lower translation quality scores. 5 Augmenting the corpus with an extracted dictionary Previous research (Callison-Burch et al., 2004; Fraser and Marcu, 2006) has shown that including word aligned data during training can improve translation results. In our case we included a dictionary extracted from the news-commentary corpus during the word alignment. Using a method originally developed for term extraction (Merkel and Foo, 2007), the newscommentary09 corpus was grammatically annotated and aligned using a heuristic word aligner. Candidate dictionary entries were extracted from the alignments. In order to optimize the quality of the dictionary, dictionary entry candidates were ranked according to their Q-value, a metric sp</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In Proceedings of the 42nd Annual Meeting of ACL, pages 175–182, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semisupervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of ACL,</booktitle>
<pages>769--776</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="9578" citStr="Fraser and Marcu, 2006" startWordPosition="1535" endWordPosition="1538">mewhat higher Meteor score, but overall did not seem to improve translation. Target reordering in this direction resulted in lower scores. It is not clear why reordering improved translation for German–English and not for English– German. In all experiments, the heuristic symmetrization of directed Giza++ alignments was performed in the intended translation direction 3. 3Our experiments show that symmetrization in the wrong translation direction will result in lower translation quality scores. 5 Augmenting the corpus with an extracted dictionary Previous research (Callison-Burch et al., 2004; Fraser and Marcu, 2006) has shown that including word aligned data during training can improve translation results. In our case we included a dictionary extracted from the news-commentary corpus during the word alignment. Using a method originally developed for term extraction (Merkel and Foo, 2007), the newscommentary09 corpus was grammatically annotated and aligned using a heuristic word aligner. Candidate dictionary entries were extracted from the alignments. In order to optimize the quality of the dictionary, dictionary entry candidates were ranked according to their Q-value, a metric specifically designed for a</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2006. Semisupervised training for statistical word alignment. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of ACL, pages 769–776, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="1201" citStr="Fraser and Marcu (2007)" startWordPosition="184" endWordPosition="187"> data obtained as highprecision alignments from a different word aligner. These methods were studied in the context of a system that uses compound processing, a morphological sequence model for German, and a partof-speech sequence model for English. Both methods gave some improvements to translation quality as measured by Bleu and Meteor scores, though not consistently. All systems used both out-ofdomain and in-domain data as the mixed corpus had better scores in the baseline configuration. 1 Introduction It is an open question whether improved word alignment actually improves statistical MT. Fraser and Marcu (2007) found that improved alignments as measured by AER will not necessarily improve translation quality, whereas Ganchev et al. (2008) did improve translation quality on several language pairs by extending the alignment algorithm. For this year’s shared task we therefore studied the effects of improving word alignment in the context of our system for the WMT09 shared task. Two methods were tried: (i) applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments f</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Computational Linguistics, 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>João de Almeida Varelas Graça</author>
<author>Ben Taskar</author>
</authors>
<title>Better alignments = better translations?</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of ACL,</booktitle>
<pages>986--993</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1331" citStr="Ganchev et al. (2008)" startWordPosition="203" endWordPosition="206"> uses compound processing, a morphological sequence model for German, and a partof-speech sequence model for English. Both methods gave some improvements to translation quality as measured by Bleu and Meteor scores, though not consistently. All systems used both out-ofdomain and in-domain data as the mixed corpus had better scores in the baseline configuration. 1 Introduction It is an open question whether improved word alignment actually improves statistical MT. Fraser and Marcu (2007) found that improved alignments as measured by AER will not necessarily improve translation quality, whereas Ganchev et al. (2008) did improve translation quality on several language pairs by extending the alignment algorithm. For this year’s shared task we therefore studied the effects of improving word alignment in the context of our system for the WMT09 shared task. Two methods were tried: (i) applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments from a different word aligner. The submitted system includes the first method in addition to the processing of compounds and additi</context>
</contexts>
<marker>Ganchev, Graça, Taskar, 2008</marker>
<rawString>Kuzman Ganchev, João de Almeida Varelas Graça, and Ben Taskar. 2008. Better alignments = better translations? In Proceedings of the 46th Annual Meeting of ACL, pages 986–993, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of the tenth conference of EACL,</booktitle>
<pages>187--193</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3942" citStr="Koehn and Knight, 2003" startWordPosition="607" endWordPosition="610">ch as case or tense, that we get from a commercial 1http://www.statmt.org/wmt09/baseline. html Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 120–124, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 120 dependency parser2. We used the extra factor in an additional sequence model which can improve agreement between words, and word order. For German this factor was also used for compound merging. 2.2 Compound processing Prior to training and translation, compound processing was performed using an empirical method based on (Koehn and Knight, 2003; Stymne, 2008). Words were split if they could be split into parts that occur in a monolingual corpus. We chose the split with the highest arithmetic mean of the corpus frequencies of compound parts. We split nouns, adjectives and verbs into parts that were content words or particles. A part had to be at least 3 characters in length and a stop list was used to avoid parts that often lead to errors, such as arische (Aryan) in konsularische (consular). Compound parts sometimes have special compound suffixes, which could be additions or truncations of letters, or combinations of these. We used t</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical methods for compound splitting. In Proceedings of the tenth conference of EACL, pages 187–193, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5556" citStr="Koehn and Schroeder (2007)" startWordPosition="881" endWordPosition="884">e, 2009). A token with this POS-tag is merged with the next token, either if the POS-tags match, or if it results in a known word. 3 Domain adaptation This year three training corpora were available, a small bilingual news commentary corpus, a reasonably large Europarl corpus, and a very large monolingual news corpus, see Table 1 for details. The bilingual data was filtered to remove sentences longer than 60 words. Because the German news training corpus contained a number of English sentences, this corpus was cleaned by removing sentences containing a number of common English words. Based on Koehn and Schroeder (2007) we adapted our system from last year, which was focused on Europarl, to perform well on test data 2Machinese syntax, from Connexor Oy http://www. connexor.eu Corpus German English news-commentary09 81,141 Europarl 1,331,262 news-train08 9,619,406 21,215,311 Table 1: Number of sentences in the corpora (after filtering) Corpus En==�-De De==�En Bleu Meteor Bleu Meteor News com. 12.13 47.01 17.21 36.08 Europarl 12.92 47.27 18.53 37.65 Mixed 12.91 47.96 18.76 37.69 Mixed+ 14.62 49.48 19.92 38.18 Table 2: Results of domain adaptation from the news domain. We used the possibility to include several </context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of ACL, demonstration session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="2671" citStr="Koehn et al., 2007" startWordPosition="414" endWordPosition="417">ns that were submitted, as reported in section 6. In this paper we report case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a set with 1025 sentences. All development testing was performed on the news-dev2009b set with 1026 sentences. 2.1 Sequence model based on part-of-speech and morphology The translation models were factored with one additional output factor. For English we used partof-speech tags obtained with TreeTagger (Schmid, 1994). For German we enriched the tags f</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of ACL, demonstration session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Langer</author>
</authors>
<title>Zur Morphologie und Semantik von Nominalkomposita.</title>
<date>1998</date>
<booktitle>In Tagungsband der 4. Konferenz zur Verarbeitung natürlicher Sprache (KONVENS),</booktitle>
<pages>83--97</pages>
<contexts>
<context position="4597" citStr="Langer (1998)" startWordPosition="722" endWordPosition="723">could be split into parts that occur in a monolingual corpus. We chose the split with the highest arithmetic mean of the corpus frequencies of compound parts. We split nouns, adjectives and verbs into parts that were content words or particles. A part had to be at least 3 characters in length and a stop list was used to avoid parts that often lead to errors, such as arische (Aryan) in konsularische (consular). Compound parts sometimes have special compound suffixes, which could be additions or truncations of letters, or combinations of these. We used the top 10 suffixes from a corpus study of Langer (1998), and we also treated hyphens as suffixes of compound parts. Compound parts were given a special part-of-speech tag that matched the head word. For translation into German, compound parts were merged to form compounds, both during test and tuning. The merging is based on the special part-of-speech tag used for compound parts (Stymne, 2009). A token with this POS-tag is merged with the next token, either if the POS-tags match, or if it results in a known word. 3 Domain adaptation This year three training corpora were available, a small bilingual news commentary corpus, a reasonably large Europa</context>
</contexts>
<marker>Langer, 1998</marker>
<rawString>Stefan Langer. 1998. Zur Morphologie und Semantik von Nominalkomposita. In Tagungsband der 4. Konferenz zur Verarbeitung natürlicher Sprache (KONVENS), pages 83–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanjun Ma</author>
<author>Nicolas Stroppa</author>
<author>Andy Way</author>
</authors>
<title>Boostrapping word alignment via word packing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of ACL,</booktitle>
<pages>304--311</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7476" citStr="Ma et al., 2007" startWordPosition="1194" endWordPosition="1197">data has lower order than those trained on bilingual news or Europarl, with 4-grams for surface form and 6-grams for partof-speech. We also used the entropy-based pruning included in the SRILM toolkit, with 10−8 as a threshold. Using these sequence models in the mixed model, called mixed+, improved the results drastically, as shown in Table 2. The other experiments reported in this paper are based on the mixed+ system. 4 Improved alignment by reordering Word alignment with Giza++ has been shown to improve from making the source and target language more similar, e.g., in terms of segmentation (Ma et al., 2007) or word order. We used the following simple procedure to improve alignment of the training corpus by reordering the words in one of the texts according to the 121 Corpus En==&gt;.De De==&gt;.En Bleu Meteor Bleu Meteor Mixed+ 14.62 49.48 19.92 38.18 Re-Src 14.63 49.80 20.54 38.86 Re-Trg 14.51 48.62 20.48 38.73 Table 3: Results of reordering experiments word order in the other language: 1. Word align the corpus with Giza++. 2. Reorder the German words according to the order of the English words they are aligned to. (This is a common step in approaches that extract reordering rules for translation. Ho</context>
</contexts>
<marker>Ma, Stroppa, Way, 2007</marker>
<rawString>Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. Boostrapping word alignment via word packing. In Proceedings of the 45th Annual Meeting of ACL, pages 304–311, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Merkel</author>
<author>Jody Foo</author>
</authors>
<title>Terminology extraction and term ranking for standardizing term banks.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA2007),</booktitle>
<pages>349--354</pages>
<location>Tartu, Estonia.</location>
<contexts>
<context position="9855" citStr="Merkel and Foo, 2007" startWordPosition="1579" endWordPosition="1582">rization of directed Giza++ alignments was performed in the intended translation direction 3. 3Our experiments show that symmetrization in the wrong translation direction will result in lower translation quality scores. 5 Augmenting the corpus with an extracted dictionary Previous research (Callison-Burch et al., 2004; Fraser and Marcu, 2006) has shown that including word aligned data during training can improve translation results. In our case we included a dictionary extracted from the news-commentary corpus during the word alignment. Using a method originally developed for term extraction (Merkel and Foo, 2007), the newscommentary09 corpus was grammatically annotated and aligned using a heuristic word aligner. Candidate dictionary entries were extracted from the alignments. In order to optimize the quality of the dictionary, dictionary entry candidates were ranked according to their Q-value, a metric specifically designed for aligned data (Merkel and Foo, 2007). The Q-value is based on the following statistics: • Type Pair Frequencies (TPF), i.e. the number of times where the source and target types are aligned. • Target types per Source type (TpS), i.e. the number of target types a specific source </context>
</contexts>
<marker>Merkel, Foo, 2007</marker>
<rawString>Magnus Merkel and Jody Foo. 2007. Terminology extraction and term ranking for standardizing term banks. In Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA2007), pages 349–354, Tartu, Estonia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2744" citStr="Och and Ney, 2003" startWordPosition="427" endWordPosition="430">case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a set with 1025 sentences. All development testing was performed on the news-dev2009b set with 1026 sentences. 2.1 Sequence model based on part-of-speech and morphology The translation models were factored with one additional output factor. For English we used partof-speech tags obtained with TreeTagger (Schmid, 1994). For German we enriched the tags from TreeTagger with morphological information, such as case or tense, tha</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of ACL,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2875" citStr="Och, 2003" startWordPosition="450" endWordPosition="451">nking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a set with 1025 sentences. All development testing was performed on the news-dev2009b set with 1026 sentences. 2.1 Sequence model based on part-of-speech and morphology The translation models were factored with one additional output factor. For English we used partof-speech tags obtained with TreeTagger (Schmid, 1994). For German we enriched the tags from TreeTagger with morphological information, such as case or tense, that we get from a commercial 1http://www.statmt.org/wmt09/baseline. html Proceedings of the Fourth Workshop on Statistical Machine Tr</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of ACL, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of ACL,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="2178" citStr="Papineni et al., 2002" startWordPosition="340" endWordPosition="343">T09 shared task. Two methods were tried: (i) applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments from a different word aligner. The submitted system includes the first method in addition to the processing of compounds and additional sequence models used by Stymne et al. (2008). Heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6. In this paper we report case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for la</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of ACL, pages 311–318, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="3236" citStr="Schmid, 1994" startWordPosition="504" endWordPosition="505">that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a set with 1025 sentences. All development testing was performed on the news-dev2009b set with 1026 sentences. 2.1 Sequence model based on part-of-speech and morphology The translation models were factored with one additional output factor. For English we used partof-speech tags obtained with TreeTagger (Schmid, 1994). For German we enriched the tags from TreeTagger with morphological information, such as case or tense, that we get from a commercial 1http://www.statmt.org/wmt09/baseline. html Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 120–124, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 120 dependency parser2. We used the extra factor in an additional sequence model which can improve agreement between words, and word order. For German this factor was also used for compound merging. 2.2 Compound processing Prior to training and</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the Seventh International Conference on Spoken Language Processing (ICSLP),</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado.</location>
<contexts>
<context position="2771" citStr="Stolcke, 2002" startWordPosition="433" endWordPosition="434">apineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models. Minimum error rate training was used to tune the model feature weights (Och, 2003). Tuning was performed on the news-dev2009a set with 1025 sentences. All development testing was performed on the news-dev2009b set with 1026 sentences. 2.1 Sequence model based on part-of-speech and morphology The translation models were factored with one additional output factor. For English we used partof-speech tags obtained with TreeTagger (Schmid, 1994). For German we enriched the tags from TreeTagger with morphological information, such as case or tense, that we get from a commercial </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the Seventh International Conference on Spoken Language Processing (ICSLP), pages 901–904, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>Maria Holmqvist</author>
<author>Lars Ahrenberg</author>
</authors>
<title>Effects of morphological analysis in translation between German and English.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>135--138</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1980" citStr="Stymne et al. (2008)" startWordPosition="310" endWordPosition="313">ity on several language pairs by extending the alignment algorithm. For this year’s shared task we therefore studied the effects of improving word alignment in the context of our system for the WMT09 shared task. Two methods were tried: (i) applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments from a different word aligner. The submitted system includes the first method in addition to the processing of compounds and additional sequence models used by Stymne et al. (2008). Heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6. In this paper we report case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008). 2 Baseline system Our baseline system uses compound splitting, compound merging and part-ofspeech/morphological sequence models (Stymne et al., 2008). Except for these additions it is similar to the baseline system of the workshop1. The translation system is</context>
</contexts>
<marker>Stymne, Holmqvist, Ahrenberg, 2008</marker>
<rawString>Sara Stymne, Maria Holmqvist, and Lars Ahrenberg. 2008. Effects of morphological analysis in translation between German and English. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 135–138, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>German compounds in factored statistical machine translation.</title>
<date>2008</date>
<booktitle>In Aarne Ranta and Bengt Nordström, editors, Proceedings of GoTAL, 6th International Conference on Natural Language Processing, LNCS/LNAI Volume 5221,</booktitle>
<pages>464--475</pages>
<contexts>
<context position="3957" citStr="Stymne, 2008" startWordPosition="611" endWordPosition="612">t we get from a commercial 1http://www.statmt.org/wmt09/baseline. html Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 120–124, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 120 dependency parser2. We used the extra factor in an additional sequence model which can improve agreement between words, and word order. For German this factor was also used for compound merging. 2.2 Compound processing Prior to training and translation, compound processing was performed using an empirical method based on (Koehn and Knight, 2003; Stymne, 2008). Words were split if they could be split into parts that occur in a monolingual corpus. We chose the split with the highest arithmetic mean of the corpus frequencies of compound parts. We split nouns, adjectives and verbs into parts that were content words or particles. A part had to be at least 3 characters in length and a stop list was used to avoid parts that often lead to errors, such as arische (Aryan) in konsularische (consular). Compound parts sometimes have special compound suffixes, which could be additions or truncations of letters, or combinations of these. We used the top 10 suffi</context>
</contexts>
<marker>Stymne, 2008</marker>
<rawString>Sara Stymne. 2008. German compounds in factored statistical machine translation. In Aarne Ranta and Bengt Nordström, editors, Proceedings of GoTAL, 6th International Conference on Natural Language Processing, LNCS/LNAI Volume 5221, pages 464– 475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>A comparison of merging strategies for translation of German compounds.</title>
<date>2009</date>
<booktitle>In Proceedings of the EACL09 Student Research Workshop,</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="4938" citStr="Stymne, 2009" startWordPosition="777" endWordPosition="778">ten lead to errors, such as arische (Aryan) in konsularische (consular). Compound parts sometimes have special compound suffixes, which could be additions or truncations of letters, or combinations of these. We used the top 10 suffixes from a corpus study of Langer (1998), and we also treated hyphens as suffixes of compound parts. Compound parts were given a special part-of-speech tag that matched the head word. For translation into German, compound parts were merged to form compounds, both during test and tuning. The merging is based on the special part-of-speech tag used for compound parts (Stymne, 2009). A token with this POS-tag is merged with the next token, either if the POS-tags match, or if it results in a known word. 3 Domain adaptation This year three training corpora were available, a small bilingual news commentary corpus, a reasonably large Europarl corpus, and a very large monolingual news corpus, see Table 1 for details. The bilingual data was filtered to remove sentences longer than 60 words. Because the German news training corpus contained a number of English sentences, this corpus was cleaned by removing sentences containing a number of common English words. Based on Koehn an</context>
</contexts>
<marker>Stymne, 2009</marker>
<rawString>Sara Stymne. 2009. A comparison of merging strategies for translation of German compounds. In Proceedings of the EACL09 Student Research Workshop, Athens, Greece.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>