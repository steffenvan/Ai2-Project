<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.308983">
<title confidence="0.988894">
Biomedical Event Extraction without Training Data
</title>
<author confidence="0.999049">
Andreas Vlachos, Paula Buttery, Diarmuid O´ S´eaghdha, Ted Briscoe
</author>
<affiliation confidence="0.9937665">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.652628">
Cambridge, UK
</address>
<email confidence="0.997424">
av308,pjb48,do242,ejb@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993854" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999556444444444">
We describe our system for the BioNLP 2009
event detection task. It is designed to be as
domain-independent and unsupervised as pos-
sible. Nevertheless, the precisions achieved
for single theme event classes range from 75%
to 92%, while maintaining reasonable recall.
The overall F-scores achieved were 36.44%
and 30.80% on the development and the test
sets respectively.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999675347826087">
In this paper we describe the system built for the
BioNLP 2009 event detection and characterization
task (Task 1). The approach is based on the output
of a syntactic parser and standard linguistic process-
ing, augmented by rules acquired from the develop-
ment data. The key idea is that a trigger connected
with an appropriate argument along a path through
the syntactic dependency graph forms an event.
The goal we set for our approach was to avoid
using training data explicitly annotated for the task
and to preserve domain independence. While we
acknowledge the utility of supervision (in the form
of annotated data) and domain knowledge, we be-
lieve it is valuable to explore an unsupervised ap-
proach. Firstly, manually annotated data is ex-
pensive to create and the annotation process itself
is difficult and unavoidably results in inconsisten-
cies, even in well-explored tasks such as named en-
tity recognition (NER). Secondly, unsupervised ap-
proaches, even if they fail to reach the performance
of supervised ones, are likely to be informative in
identifying useful features for the latter. Thirdly, ex-
ploring the potential of such a system may highlight
</bodyText>
<page confidence="0.990565">
37
</page>
<bodyText confidence="0.9999716875">
what domain knowledge is useful and its potential
contribution to performance. Finally, preserving do-
main independence allows us to develop and evalu-
ate a system that could be used for similar tasks with
minimal adaptation.
The overall architecture of the system is as fol-
lows. Initiallly, event triggers are identified and la-
belled with event types using seed terms. Based on
the dependency output of the parser the triggers are
connected with candidate arguments using patterns
identified in the development data. Anaphoric can-
didate arguments are then resolved. Finally, the trig-
gers connected with appropriate arguments are post-
processed to generate the final set of events. Each
of these stages are described in detail in subsequent
sections, followed by experiments and discussion.
</bodyText>
<sectionHeader confidence="0.945102" genericHeader="method">
2 Trigger identification
</sectionHeader>
<bodyText confidence="0.999783533333333">
We perform trigger identification using the assump-
tion that events are triggered in text either by verbal
or nominal prdicates (Cohen et al., 2008).
To build a dictionary of verbs and their associ-
ated event classes we use the triggers annotated in
the training data. We lemmatize and stem the trig-
gers with the morphology component of the RASP
toolkit (Briscoe et al., 2006)1 and the Porter stem-
mer2 respectively. We sort the trigger stem - event
class pairs found according to their frequency in
the training data and we keep only those pairs that
appear at least 10 times. The trigger stems are
then mapped to verbs. This excludes some rela-
tively common triggers, which will reduce recall,
but, given that we rely exclusively on the parser for
</bodyText>
<footnote confidence="0.9999865">
1http://www.cogs.susx.ac.uk/lab/nlp/rasp/
2http://www.tartarus.org/˜martin/PorterStemmer
</footnote>
<note confidence="0.8191935">
Proceedings of the Workshop on BioNLP: Shared Task, pages 37–40,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99984924137931">
argument extraction, such triggers would be difficult
to handle. For verbs with more than one event class
we keep only the most frequent one.
We consider the assumption that each verb de-
notes a single event class to be a reasonable one
given the restricted task domain. It hinders us from
dealing with triggers denoting multiple event classes
but it simplifies the task so that we do not need anno-
tated data. While we use the training data triggers to
obtain the list of verbs and their corresponding event
types, we believe that such lists could be obtained by
clustering (Korhonen et al., 2008) with editing and
labelling by domain experts. This is the only use of
the training data we make in our system.
During testing, using the tokenized text provided,
we attempt to match each token with one of the
verbs associated with an event type. We perform
this by relaxing the matching successively, using the
token lemma, then stem, and finally allowing a par-
tial match in order to deal with particles (so that e.g.
co-transfect matches transfect). This process returns
single-token candidate triggers which, while they do
not reproduce the trigger annotation, are likely to be
adequate for event extraction. We overgenerate trig-
gers, since not all occurrences denote an event, ei-
ther because they are not connected with appropriate
arguments or because they are found in a non-event
denoting context, but we expect to filter these at the
argument extraction stage.
</bodyText>
<sectionHeader confidence="0.977439" genericHeader="method">
3 Argument extraction
</sectionHeader>
<bodyText confidence="0.999965363636364">
Given a set of candidate triggers, we attempt to con-
nect them with appropriate arguments using the de-
pendency graph provided by a parser. In our ex-
periments we use the domain-independent unlexi-
calized RASP parser, which generates parses over
the part-of-speech (PoS) tags of the tokens generated
by an HMM-based tagger trained on balanced En-
glish text. While we expect that a parser adapted to
the biomedical domain may perform better, we want
to preserve the domain-independence of the system
and explore its potential.
The only adjustment we make is to change the
PoS tags of tokens that are part of a protein name
to proper names tags. We consider such an adjust-
ment domain-independent given that NER is avail-
able in many domains (Lewin, 2007). Following
Haghighi et al (2005), in order to ameliorate pars-
ing errors, we use the top-10 parses and return a
set of bilexical head-dependent grammatical rela-
tions (GRs) weighted according to the proportion
and probability of the top parses supporting that GR.
The GRs produced by the parser define directed
graphs between tokens in the sentence, and a partial
event is formed when a path that connects a trigger
with an appropriate argument is identified. GR paths
that are likely to generate events are selected using
the development data, which does not contradict the
goals of our approach because we do not require an-
notated training data. Development data is always
needed in order to build and test a system, and such
supervision could be provided by a human expert,
albeit not as easily as for the list of trigger verbs.
The set of GR paths identified follow:
</bodyText>
<table confidence="0.9390694">
VERB-TRIGGER –subject– ARG
NOUN-TRIGGER –iobj– PREP –dobj– ARG
NOUN-TRIGGER –modifier– ARG
TRIGGER –modifier– PREP –obj– ARG
TRIGGER –passive subject– ARG
</table>
<bodyText confidence="0.998682125">
The final system uses three sets of GR paths:
one for Regulation events; one for Binding events;
and one for all other events. The difference be-
tween these sets is in the lexicalization of the link-
ing prepositions. For example, in Binding events
the linking preposition required lexicalization since
binds x to/with y denotes a correct event but not
binds x by y. Binding events also required additional
GR paths to capture constructions such as binding of
x to y. For Regulation events, the path set was fur-
ther augmented to differentiate between theme and
cause. When the lexicalized GR pattern sets yielded
no events we backed-off to the unlexicalized pattern
set, which is identical for all event types. In all GR
path sets, the trigger was unlexicalized and only re-
stricted by PoS tag.
</bodyText>
<sectionHeader confidence="0.992993" genericHeader="method">
4 Anaphora resolution
</sectionHeader>
<bodyText confidence="0.999792428571429">
The events and arguments identified in the parsed
abstracts are post-processed in context to iden-
tify protein referents for event arguments that are
anaphoric (e.g., these proteins, its phosphorylation)
or too complex to be extracted directly from the
grammatical relations (phosphorylation of cellular
proteins, notably phospholipase C gamma 1). The
</bodyText>
<page confidence="0.998154">
38
</page>
<bodyText confidence="0.999862857142857">
anaphoric linking is performed by a set of heuris-
tic rules manually designed to capture a number of
common cases observed in the development dataset.
A further phenomenon dealt with by rules is coref-
erence between events, for example in The expres-
sion of LAL-mRNA is induced. This induction is de-
pendent on... where the Induction event described
by the first sentence is the same as the theme of the
Regulation event in the second and should be given
the same event index. The development of the post-
processing rules favoured precision over recall, but
the low frequency of each case considered means
that some overfitting to the development data may
have been unavoidable.
</bodyText>
<sectionHeader confidence="0.993604" genericHeader="method">
5 Event post-processing
</sectionHeader>
<bodyText confidence="0.999944428571428">
At the event post-processing stage, we form com-
plete events considering the trigger-argument pairs
produced at the argument extraction stage whose ar-
guments are resolved (possibly using anaphora res-
olution) either to a protein name or to a candidate
trigger. The latter are considered only for regula-
tion event triggers. Furthermore, regulation event
trigger-argument pairs are tagged either as theme or
cause at the argument extraction stage.
For each non-regulation trigger-argument pair, we
generate a single event with the argument marked as
theme. Given that we are dealing only with Task
1, this approach is expected to deal adequately with
all event types except Binding, which can have mul-
tiple themes. Regulation events are formed in the
following way. Given that the cause argument is
optional, we generate regulation events for trigger-
argument pairs whose argument is a protein name or
a trigger that has a formed event. Since regulation
events can have other regulation events as themes,
we repeat this process until no more events can be
formed. Occasionally, the use of multiple parses re-
sults in cycles between regulation triggers which are
resolved using the weighted GR scores. Then, we at-
tach any cause arguments that share the same trigger
with a formed regulation event.
In the analysis performed for trigger identification
in Section 2, we observed that certain verbs were
consistently annotated with two events (namely
overexpress and transfect), a non-regulation event
and a regulation event with the former event as its
theme. For candidate triggers that were recognized
due to such verbs, we treat them as non-regulation
events until the post-processing stage where we gen-
erate two events.
</bodyText>
<sectionHeader confidence="0.986952" genericHeader="method">
6 Experiments - Discussion
</sectionHeader>
<bodyText confidence="0.999980804878049">
We expected that our approach would achieve high
precision but relatively low recall. The evaluation
of our final submissions on the development and test
data (Table 1) confirmed this to a large extent. For
the non-regulation event classes excluding Binding,
the precisions achieved range from 75% to 92% in
both development and test data, with the exception
of Transcription in the test data. Our approach ex-
tracts Binding events with a single theme, more suit-
ably evaluated by the Event Decomposition evalua-
tion mode in which a similar high precision/low re-
call trend is observed, albeit with lower scores.
Of particular interest are the event classes for
which a single trigger verb was identified, namely
Transcription, Protein catabolism and Phosphoryla-
tion, which makes it easier to identify the strengths
and weaknesses of our approach. For the Phos-
phorylation class, almost all the triggers that were
annotated in the training data can be captured us-
ing the verb phosporylate and as a result, the per-
formances achieved by our system are 70.59% and
60.63% F-score on the development and test data re-
spectively. The precision was approximately 78% in
both datasets, while recall was lower due to parser
errors and unresolved anaphoric references. For the
Protein catabolism class, degrade was identified as
the only trigger verb, resulting in similar high preci-
sion but relatively lower recall due to the higher lex-
ical variation of the triggers for this class. For the
Transcription class we considered only transcribe
as a trigger verb, but while the performance on the
development data is reasonable (55%), the perfor-
mance on the test data is substantially lower (20%).
Inspecting the event triggers in the training data re-
veals that some very common triggers for this class
either cannot be mapped to a verb (e.g., mrna) or are
commonly used as triggers for other event classes.
A notable case of the latter type is the verb express,
which, while mostly a Gene Expressions trigger, is
also annotated as Transcription more than 100 times
in the training data. Assuming that this is desirable,
</bodyText>
<page confidence="0.996858">
39
</page>
<table confidence="0.9997788">
Development Test
Event Class recall precision fscore recall precision fscore
Localization 45.28 92.31 60.76 25.86 90.00 40.18
Binding 12.50 24.41 16.53 12.68 31.88 18.14
Gene expression 52.25 80.79 63.46 45.57 75.81 56.92
Transcription 42.68 77.78 55.12 12.41 56.67 20.36
Protein catabolism 42.86 81.82 56.25 35.71 83.33 50.00
Phosphorylation 63.83 78.95 70.59 49.63 77.91 60.63
Event Total 39.03 65.97 49.05 33.16 68.15 44.61
Regulation 20.12 50.75 28.81 9.28 36.49 14.79
Positive regulation 16.86 48.83 25.06 11.39 38.49 17.58
Negative regulation 11.22 36.67 17.19 6.86 36.11 11.53
Regulation Total 16.29 47.06 24.21 9.98 37.76 15.79
Total 26.55 58.09 36.44 21.12 56.90 30.80
Binding (decomposed) 26.92 66.14 38.27 18.84 54.35 27.99
</table>
<tableCaption confidence="0.999965">
Table 1: Performance analysis on development and test data using Approximate Span/Partial Recursive Matching.
</tableCaption>
<bodyText confidence="0.998287130434783">
a more appropriate solution would need to take con-
text into account.
Our performance on the regulation events is sub-
stantially lower in both recall and precision. This
is expected, as they rely on the extraction of non-
regulation events. The variety of lexical triggers is
not causing the drop in performance though, since
our system performed reasonably well in the Gene
Expression and Localization classes which have
similar lexical variation. Rather it is due to the com-
bination of the lexical variation with the requirement
to make the distinction between the theme and op-
tional cause argument, which cannot be handled ap-
propriately by the small set of GR paths employed.
The contribution of anaphora resolution to our
system is limited as it relies on the argument ex-
traction stage which, apart from introducing noise,
is geared towards maintaining high precision. Over-
all, it contributes 22 additional events on the de-
velopment set, of which 14 out of 16 are correct
non-regulation events. Of the remaining 6 regula-
tion events only 2 were correct. Similar trends were
observed on the test data.
</bodyText>
<sectionHeader confidence="0.999264" genericHeader="conclusions">
7 Conclusions - Future work
</sectionHeader>
<bodyText confidence="0.999941">
We described an almost unsupervised approach for
the BioNLP09 shared task on biomedical event ex-
traction which requires only a dictionary of verbs
and a set of argument extraction rules. Ignoring trig-
ger spans, the performance of the approach is parser-
dependent and while we used a domain-independent
parser in our experiments we also want to explore
the benefits of using an adapted one.
The main weakness of our approach is the han-
dling of events with multiple arguments and the dis-
tinctions between them, which are difficult to deal
with using simple unlexicalized rules. In our fu-
ture work we intend to explore semi-supervised ap-
proaches that allow us to acquire more complex
rules efficiently.
</bodyText>
<sectionHeader confidence="0.999199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988090235294118">
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the RASP system. In Proceed-
ings of the COLING/ACL Interactive presentation ses-
sions, pages 77–80.
Kevin B. Cohen, Martha Palmer, and Lawrence Hunter.
2008. Nominalization and alternations in biomedical
language. PLoS ONE, 3(9).
Aria Haghighi, Kristina Toutanova, and Chris Manning.
2005. A Joint Model for Semantic Role Labeling. In
Proceedings of CoNLL-2005: Shared Task.
Anna Korhonen, Yuval Krymolowski, and Nigel Collier.
2008. The choice of features for classification of verbs
in biomedical texts. In Proceedings of Coling.
Ian Lewin. 2007. BaseNPs that contain gene names:
domain specificity and genericity. In Proceedings of
the ACL workshop BioNLP: Biological, translational,
and clinical language processing, pages 163–170.
</reference>
<page confidence="0.998459">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.691728">
<title confidence="0.999743">Biomedical Event Extraction without Training Data</title>
<author confidence="0.994386">Andreas Vlachos</author>
<author confidence="0.994386">Paula Buttery</author>
<author confidence="0.994386">Diarmuid O´ S´eaghdha</author>
<author confidence="0.994386">Ted</author>
<affiliation confidence="0.9884475">Computer University of</affiliation>
<address confidence="0.721337">Cambridge,</address>
<email confidence="0.995286">av308,pjb48,do242,ejb@cl.cam.ac.uk</email>
<abstract confidence="0.9988619">We describe our system for the BioNLP 2009 event detection task. It is designed to be as domain-independent and unsupervised as possible. Nevertheless, the precisions achieved for single theme event classes range from 75% to 92%, while maintaining reasonable recall. The overall F-scores achieved were 36.44% and 30.80% on the development and the test sets respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL Interactive presentation sessions,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="2952" citStr="Briscoe et al., 2006" startWordPosition="458" endWordPosition="461">inally, the triggers connected with appropriate arguments are postprocessed to generate the final set of events. Each of these stages are described in detail in subsequent sections, followed by experiments and discussion. 2 Trigger identification We perform trigger identification using the assumption that events are triggered in text either by verbal or nominal prdicates (Cohen et al., 2008). To build a dictionary of verbs and their associated event classes we use the triggers annotated in the training data. We lemmatize and stem the triggers with the morphology component of the RASP toolkit (Briscoe et al., 2006)1 and the Porter stemmer2 respectively. We sort the trigger stem - event class pairs found according to their frequency in the training data and we keep only those pairs that appear at least 10 times. The trigger stems are then mapped to verbs. This excludes some relatively common triggers, which will reduce recall, but, given that we rely exclusively on the parser for 1http://www.cogs.susx.ac.uk/lab/nlp/rasp/ 2http://www.tartarus.org/˜martin/PorterStemmer Proceedings of the Workshop on BioNLP: Shared Task, pages 37–40, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguis</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString> Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the RASP system. In Proceedings of the COLING/ACL Interactive presentation sessions, pages 77–80. Kevin B. Cohen, Martha Palmer, and Lawrence Hunter.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kristina Toutanova Haghighi</author>
<author>Chris Manning</author>
</authors>
<title>Nominalization and alternations in biomedical language.</title>
<journal>PLoS ONE,</journal>
<volume>3</volume>
<issue>9</issue>
<marker>2008.</marker>
<rawString>Nominalization and alternations in biomedical language. PLoS ONE, 3(9). Aria Haghighi, Kristina Toutanova, and Chris Manning.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nigel Collier</author>
</authors>
<title>A Joint Model for Semantic Role Labeling.</title>
<booktitle>In Proceedings of CoNLL-2005: Shared Task. Anna Korhonen, Yuval Krymolowski, and</booktitle>
<contexts>
<context position="5823" citStr="(2005)" startWordPosition="928" endWordPosition="928">n-independent unlexicalized RASP parser, which generates parses over the part-of-speech (PoS) tags of the tokens generated by an HMM-based tagger trained on balanced English text. While we expect that a parser adapted to the biomedical domain may perform better, we want to preserve the domain-independence of the system and explore its potential. The only adjustment we make is to change the PoS tags of tokens that are part of a protein name to proper names tags. We consider such an adjustment domain-independent given that NER is available in many domains (Lewin, 2007). Following Haghighi et al (2005), in order to ameliorate parsing errors, we use the top-10 parses and return a set of bilexical head-dependent grammatical relations (GRs) weighted according to the proportion and probability of the top parses supporting that GR. The GRs produced by the parser define directed graphs between tokens in the sentence, and a partial event is formed when a path that connects a trigger with an appropriate argument is identified. GR paths that are likely to generate events are selected using the development data, which does not contradict the goals of our approach because we do not require annotated t</context>
</contexts>
<marker>2005.</marker>
<rawString>A Joint Model for Semantic Role Labeling. In Proceedings of CoNLL-2005: Shared Task. Anna Korhonen, Yuval Krymolowski, and Nigel Collier.</rawString>
</citation>
<citation valid="true">
<title>The choice of features for classification of verbs in biomedical texts.</title>
<date>2007</date>
<booktitle>In Proceedings of Coling. Ian Lewin.</booktitle>
<pages>163--170</pages>
<marker>2008.</marker>
<rawString>The choice of features for classification of verbs in biomedical texts. In Proceedings of Coling. Ian Lewin. 2007. BaseNPs that contain gene names: domain specificity and genericity. In Proceedings of the ACL workshop BioNLP: Biological, translational, and clinical language processing, pages 163–170.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>