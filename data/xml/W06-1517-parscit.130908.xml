<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000094">
<title confidence="0.819441">
Extended cross-serial dependencies in Tree Adjoining Grammars
</title>
<author confidence="0.85035">
Marco Kuhlmann and Mathias Möhl
</author>
<affiliation confidence="0.789202666666667">
Programming Systems Lab
Saarland University
Saarbrücken, Germany
</affiliation>
<email confidence="0.992403">
{kuhlmann|mmohl}@ps.uni-sb.de
</email>
<sectionHeader confidence="0.994683" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998355235294118">
The ability to represent cross-serial depen-
dencies is one of the central features of
Tree Adjoining Grammar (TAG). The class
of dependency structures representable by
lexicalized TAG derivations can be captured
by two graph-theoretic properties: a bound
on the gap degree of the structures, and a
constraint called well-nestedness. In this
paper, we compare formalisms from two
strands of extensions to TAG in the context
of the question, how they behave with re-
spect to these constraints. In particular, we
show that multi-component TAG does not
necessarily retain the well-nestedness con-
straint, while this constraint is inherent to
Coupled Context-Free Grammar (Hotz and
Pitsch, 1996).
</bodyText>
<sectionHeader confidence="0.99879" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999431096774194">
The ability to assign ‘limited cross-serial depen-
dencies’ to the words in a sentence is a hallmark
of mildly context-sensitive grammar formalisms
(Joshi, 1985). In the case of TAG, an exact def-
inition of this ability can be given in terms of
two graph-theoretic properties of the dependency
structures induced by TAG derivations: the gap de-
gree restriction and the well-nestedness constraint
(Bodirsky et al., 2005).
Gap degree and well-nestedness can be seen as
the formal correspondents of what Joshi (1985)
refers to as ‘a limited amount of cross-serial depen-
dencies’ and ‘the nesting properties as in the case
of context-free grammars.’ More specifically, the
gap degree of a dependency structure counts the
number of discontinuities in a dependency subtree,
while well-nestedness constrains the positions of
disjoint subtrees relative to one another. The depen-
dency structures that correspond to the derivations
in a lexicalized TAG are well-nested, and their gap
degree is at most 1.
In the present paper, we compare formalisms
from two strands of extensions to TAG in the con-
text of the question, what classes of dependency
structures they are able to induce.
We are particularly interested in formalisms that
induce only well-nested dependency structures.
This interest is motivated by two observations:
First, well-nestedness is interesting as a generaliza-
tion of projectivity (Marcus, 1967)—while more
than 23% of the 73 088 dependency structures in
the Prague Dependency Treebank of Czech (Ha-
jiˇc et al., 2001) are non-projective, only 0.11%
are not well-nested (Kuhlmann and Nivre, 2006).
Second, well-nestedness is interesting for process-
ing. Specifically, parsers for well-nested grammar
formalisms are not confronted with the ‘crossing
configurations’ that make the universal recogni-
tion problem of Linear Context-Free Rewriting Sys-
tems NP-complete (Satta, 1992). In summary, it
appears that well-nestedness can strike a successful
balance between empirical coverage and computa-
tional tractability. If this is true, then a formalism
that has the well-nestedness constraint hardwired
is preferable over one that has not.
The results of this paper can be summarized
as follows: Derivations in lexicalized multi-com-
ponent TAGs (Weir, 1988; Kallmeyer, 2005), in
which a single adjunction adds a set of elemen-
tary trees, either induce exactly the same depen-
dency structures as TAG, or induce all structures
of bounded gap degree, even non-well-nested ones.
This depends on the decision whether one takes
‘lexicalized’ to mean ‘one lexical anchor per tree’,
or ‘one lexical anchor per tree set’. In contrast,
multi-foot extensions of TAG (Abe, 1988; Hotz
and Pitsch, 1996), where a single elementary tree
may have more than one foot node, only induce
well-nested dependency structures of bounded gap
degree. Thus, from the dependency point of view,
they constitute the structurally more conservative
extension of TAG.
</bodyText>
<page confidence="0.973923">
121
</page>
<bodyText confidence="0.627269">
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</bodyText>
<figure confidence="0.987629833333333">
SO
a T D
B C
T O
a T D
B C
</figure>
<sectionHeader confidence="0.599309" genericHeader="method">
2 Dependency structures for TAG
</sectionHeader>
<bodyText confidence="0.9996376">
We start with a presentation of the dependency
view on TAG that constitutes the basis for our work,
and introduce the relevant terminology. The main
objective of this section is to provide intuitions; for
the formal details, see Bodirsky et al. (2005).
</bodyText>
<subsectionHeader confidence="0.997757">
2.1 The dependency view on TAG
</subsectionHeader>
<bodyText confidence="0.9989703">
Lets D w1 • • • wn be a sentence (a sequence of
tokens). By a dependency structure for s, we mean
a tuple (W, !, -&lt;), where W D fw1, ... , wng, and
! D f (wi, wj) 2 W x W j wj depends on wi g
~ D f(wi,wj) 2 W x W j i &lt; j g
To interpret a grammar formalism as a specifica-
tion for a set of dependency structures, we need to
assign meaning to the relation ‘depends’ in terms
of this formalism. For TAG, this can be done based
on the Fundamental Hypothesis that ‘every syntac-
tic dependency is expressed locally within a single
elementary tree’ (Frank, 2002). More specifically,
a derivation in a (strongly) lexicalized TAG can
be viewed as a dependency structure as follows:
The set W contains the (occurences of) lexical an-
chors involved in the derivation. For two anchors
wi, wj 2 W , wi ! wj if the elementary tree an-
chored at wj was substituted or adjoined into the
tree anchored at wi. We then have wi -&lt; wj if wi
precedes wj in the yield of the derived tree cor-
responding to the derivation. Notice that the rela-
tion ! in such a dependency structure is almost
exactly the derivation tree of the underlying TAG
derivation; the only difference is that elementary
trees have been replaced by their lexical anchors.
Figure 1 shows a TAG grammar together with a
dependency structure induced by a derivation of
this grammar. Tokens in the derived string are rep-
resented by labelled nodes; the solid arcs between
the nodes represent the dependencies.
</bodyText>
<subsectionHeader confidence="0.999509">
2.2 Gap degree and well-nestedness
</subsectionHeader>
<bodyText confidence="0.987752897435897">
An interesting feature of the dependency structure
shown in Figure 1 is that it violates a standard
constraint on dependency structures known as pro-
jectivity (Marcus, 1967). We introduce some termi-
nology for non-projective dependency structures:
A set T C W is convex, if for no two tokens
w1, w2 2 T , there exists a token w from W — T
such that w1 -&lt; w -&lt; w2. The cover of T , C(T ),
is the smallest convex set that contains T . For
w 2 W , we write #w for the set of tokens in the
b c d
subtree rooted at w (including w itself). A gap in
#w is a largest convex set in C(#w)—#w. The gap
degree of w, gd(w), is the number of gaps in #w.
The gaps in #w partition #w into gd(w)—1 largest
convex blocks; we write #iw to refer to the i-th
of these blocks, counted from left to right (with
respect to -&lt;). The gap degree of a dependency
structure is the maximum over the gap degrees of its
subtrees; we write Dg for the set of all dependency
structures with a gap degree of at most g.
The gap degree provides a quantitative measure
for the non-projectivity of dependency structures.
Well-nestedness is a qualitative property: it con-
strains the relative positions of disjoint subtrees.
Let w1, w2 2 W such that #w1 and #w2 are dis-
joint. Four tokens w11, w21 2 #w1, w12, w22 2 #w2
interleave, if w11 _&lt; w12 _&lt; w21 _&lt; w2 2. A depen-
dency structure is well-nested, if it does not contain
interleaving tokens. We write Dwn for the set of all
well-nested dependency structures.
For illustration, consider again the dependency
structure shown in Figure 1. It has gap degree 1:
a2 is the only token w for which #w is not convex;
the set fb1, c1g forms a gap in #a2. The structure
is also well-nested. In contrast, the structure shown
in the right half of Figure 2 is not well-nested; the
tokens b, c, d, e interleave. Bodirsky et al. (2005)
show that TAG induces precisely the set Dwn \ D1.
</bodyText>
<sectionHeader confidence="0.994683" genericHeader="method">
3 Multi-component extensions
</sectionHeader>
<bodyText confidence="0.999635">
Multi-component TAG (MCTAG) extends TAG with
the ability to adjoin a whole set of elementary trees
(components) simultaneously. To answer the ques-
tion, whether this extension also leads to an ex-
tended class of dependency structures, we first need
to decide how we want to transfer the Fundamental
Hypothesis (Frank, 2002) to MCTAGs.
</bodyText>
<figure confidence="0.5338">
.
a1 a2 b2 b1 c1 c2 d2 d1
</figure>
<figureCaption confidence="0.9884865">
Figure 1: TAG grammar for anbncndn, and a de-
pendency structure induced by this grammar
</figureCaption>
<figure confidence="0.995825322580645">
BO CO D0
122
D0
C0
2
C0
1
B0
2
E
D
d
c
9 8
&gt;&gt;ˆ
= &lt;ˆ
&gt; ˆ
;&gt;ˆ:
9
&gt;&gt;=
;&gt;&gt;
E0
e a b c d e
A0
a B1 C1 B2 C2
8
&lt;ˆ ˆ
ˆˆ:
B0
1
b
</figure>
<figureCaption confidence="0.975598">
Figure 2: An MCTAG and a not well-nested dependency structure derived by it.
</figureCaption>
<subsectionHeader confidence="0.997061">
3.1 One anchor per component
</subsectionHeader>
<bodyText confidence="0.9999508">
If we commit to the view that each component of
a tree set introduces a separate lexical anchor and
its syntactic dependencies, the dependency struc-
tures induced by MCTAG are exactly the structures
induced by TAG. In particular, each node in the
derivation tree, and therefore each token in the
dependency tree, corresponds to a single elemen-
tary tree. As Kallmeyer (2005) puts it, one can
then consider an MCTAG as a TAG G ‘where cer-
tain derivation trees in G are disallowed since they
do not satisfy certain constraints.’ The ability of
MCTAG to perform multiple adjunctions simultane-
ously allows one to induce more complex sets of
dependency structures—each individual structure
is limited as in the case of standard TAG.
</bodyText>
<subsectionHeader confidence="0.999366">
3.2 One anchor per tree set
</subsectionHeader>
<bodyText confidence="0.999019045454546">
If, on the other hand, we take a complete tree set
as the level on which syntactic dependencies are
specified, MCTAGs can induce a larger class of de-
pendency structures. Under this perspective, tokens
in the dependency structure correspond not to in-
dividual components, but to tree sets (Weir, 1988).
For each token w, �w then contains the lexical an-
chors of all the subderivations starting in the tree set
corresponding to w. As there can be a gap between
each two of these subderivations, the gap degree
of the induced dependency structures is bounded
only by the maximal number of components per
tree set. At the same time, even non-well-nested
structures can be induced; an example is shown in
Figure 2. Here, �b is distributed over the compo-
nents rooted at B1 and B2, and �c is distributed
over C1 and C2. The elementary tree rooted at A
arranges the substitution sites such that b, c, d, e in-
terleave. Note that the MCTAG used in this example
is heavily restricted: it is tree-local and does not
even use adjunction. This restricted form suffices
to induce non-well-nested dependency structures.
</bodyText>
<sectionHeader confidence="0.998608" genericHeader="method">
4 Multi-foot extensions
</sectionHeader>
<bodyText confidence="0.999744666666667">
A second way to extend TAG, orthogonal to the
multi-component approach, is to allow a single el-
ementary tree to have more than one foot node.
For this kind of extension, the Fundamental Hy-
pothesis does not need to be re-interpreted. Prob-
ably the most prominent multi-foot extension of
TAG is Ranked Node Rewriting Grammar (RNRG)
(Abe, 1988); however, the properties that we are
interested in here can be easier investigated in a
notational variant of RNRG, Coupled Context-Free
Grammar (Hotz and Pitsch, 1996).
Terminology Multi-foot formalisms require a
means to specify which foot node gets what ma-
terial in an adjunction. To do so, they use ranked
symbols. A ranked alphabet is a pair 17 = (E, p),
where E is an alphabet, and p E E --&gt; N is a total
function that assigns every symbol Q E E a (pos-
itive) rank. Define 17[r] := { Q E E I p(a) = r }.
The components of a, comp(a), are the elements
of the set { (a, i) I 1 &lt; i &lt; p(a) }. We write ai in-
stead of (a, i). Let comp(17) := SI2H comp(a).
</bodyText>
<subsectionHeader confidence="0.982235">
4.1 Coupled Context-Free Grammar
</subsectionHeader>
<bodyText confidence="0.9998024">
Coupled Context-Free Grammar (CCFG) is a gener-
alization of context-free grammar in which non-ter-
minals come from a ranked alphabet, and compo-
nents of a non-terminal can only be substituted si-
multaneously. The ‘TAG-ness’ of CCFG is reflected
in the requirement, that the RHS of productions
must be words from a bracket-like language, and
thus have the same hierarchical structure as ele-
mentary trees in a TAG. As an example, the second
elementary tree from Figure 1 can be linearized as
</bodyText>
<equation confidence="0.842916">
(T1aT1B1, C1T2D1T2) ,
</equation>
<bodyText confidence="0.9999166">
where each pair (T1, T2) of matching components
corresponds to an inner node in the tree, and the
boundary between the first and the second part of
the tuple marks the position of the foot node. The
required structure of the RHS can be formalized as
follows:
Definition 1 Let 17 be a ranked alphabet, and
let E be an unranked alphabet. The extended
semi-Dyck set over 17 and E, ESD(17, E), is the
smallest set that satisfies the following properties:
</bodyText>
<page confidence="0.992119">
123
</page>
<listItem confidence="0.59297725">
(a) ˙* C ESD.˘; ˙/; (b) ˘Œ1• C ESD.˘; ˙/;
(c) if s1; ::: ; sk E ESD.˘; ˙/ and 3r E ˘Œk + 1•,
then n1s1n2 . . . nksknk+1 E ESD.˘; ˙/; (d) if
s1; s2 E ESD.˘; ˙/, then s1s2 E ESD.˘; ˙/.
</listItem>
<bodyText confidence="0.998344333333333">
Definition 2 Let N be a ranked alphabet of non-
terminals, and let T be an (unranked) alphabet
of terminals. A ranked rewriting system over
ESD.N; T / is a finite, non-empty set of productions
of the form X --&gt; (˛1; ::: ; ˛r), where X E NŒr•,
and ˛ := ˛1 . . . ˛r E ESD.N; T /.
We write p.p/ to refer to the rank of the non-termi-
nal on the LHS of a production p.
RNRG and CCFG are notational variants because
each RNRG elementary tree with r — 1 foot nodes
can be linearized into the RHS of a production
X --&gt; (˛1; ::: ; ˛r) in a ranked rewriting system,
as indicated by the example above.
Definition 3 A coupled context-free grammar is a
tuple G = .N; T; P; S/ where: N is a ranked al-
phabet of non-terminal symbols; T is an unranked
alphabet of terminal symbols; P is a ranked rewrit-
ing system over ESD.N; T /; S E NŒ1• is a start
symbol.
We say that a CCFG G is an r-CCFG, if the maximal
rank among all non-terminals in G is r.
</bodyText>
<equation confidence="0.928780333333333">
Definition 4 Put V := comp.N/ U T , and let
l5 E V * = u1X1u2 ... urXrur+1
E V = u1˛1u2 ... ur˛rur+1
</equation>
<bodyText confidence="0.999903142857143">
such that u2;: : : ; ur E ESD.N; T /, and X E NŒr•.
We say that can be derived from q5 in one step,
and write =:�G , if G contains a production
X --&gt; (˛1; ::: ; ˛r). The string language of G is
the set L.G/ := {s E T * I S =:�*G s }.
Based on this definition, the notions of derivation
tree and derived tree are defined in the usual way.
In particular, the nodes of the derivation tree are
labelled with productions, while the nodes of the
corresponding derived tree are labelled with com-
ponents from comp.˘/ (inner nodes) and terminal
symbols (leaves). We write .T ]; T [/ to refer to a
derivation in CCFG: T ] stands for the derivation
tree, T [ for the corresponding derived tree.
</bodyText>
<subsectionHeader confidence="0.994344">
4.2 The dependency view on CCFG
</subsectionHeader>
<bodyText confidence="0.999926368421053">
A CCFG G is strongly lexicalized, if each produc-
tion p contains exactly one terminal symbol, writ-
ten as anchor.p/. Just as in the case of TAG, a
strongly lexicalized CCFG G can be interpreted as
a dependency grammar: Let .T ]; T [/ be a deriva-
tion in G. Since G is strongly lexicalized, there
is a one-to-one mapping between the nodes of the
derivation tree T ] (labelled with productions) and
the leaves of the derived tree T [ (labelled with ter-
minals); we refer to this mapping by the name fL.
Definition 5 A dependency structure D is induced
by a derivation .T ]; T [/, written .T ]; T [/ �- D, if
(a) anchor.p1/ --&gt; anchor.p2/ in D if and only
if p1 --&gt; p2 in T ]; (b) anchor.p1/ -&lt; anchor.p2/
in D if and only if fL.p1/ -&lt; fL.p2/ in T [.
We write D.G/ for the set of all dependency struc-
tures induced by derivations in G. Figure 3 shows
a sample CCFG G, a derivation in G, and the de-
pendency structure induced by this derivation.
</bodyText>
<subsectionHeader confidence="0.998323">
4.3 Projections
</subsectionHeader>
<bodyText confidence="0.999552">
To reason about the structural properties of the
dependency languages induced by CCFGs, we need
some additional definitions. In the following, we
use the notation .u : a/ to refer to a node u with
label a in some given labelled tree.
Let D E D.G/ be a dependency structure such
that .T ]; T [/ �- D, and let .u: p/ E T ] be a node.
Somewhere in the course of the derivation repre-
sented by T ], the p.p/ components of the non-ter-
minal on the LHS of the production p are simulta-
neously rewritten. Let fI .u/ be the p.p/-tuple of
nodes in T [ that correspond to these components.
Note that, while fL maps nodes in the derivation
tree T ] to leaves in the derived tree T [, fI takes
nodes in T ] to tuples of inner nodes in T [. Define
</bodyText>
<equation confidence="0.9984635">
down.u/ = { v I u --&gt;* v in T ] };
proj.u;i/ = {v I fI.u/i --&gt;* fL.v/ in T [ }:
</equation>
<bodyText confidence="0.999925">
The set down.u/ contains the lexical anchors in the
sub-derivation starting at u. The set proj.u; i/ iden-
tifies that part of this sub-derivation that is derived
from the i-th component of the non-terminal at the
LHS of the production corresponding to u. For the
derivation shown in Figure 3, we have
</bodyText>
<equation confidence="0.740714333333333">
fI.p2/ = (B1; B2; B3) ; proj.p2;1/ = {p2}:
Lemma 6 For all nodes u E T ],
down.u/ = U1&lt;i&lt;,.p/ proj.u;i/:
</equation>
<subsectionHeader confidence="0.585081">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.9937475">
In this section, we prove the main technical re-
sults of this paper: that all dependency structures
</bodyText>
<page confidence="0.982207">
124
</page>
<figure confidence="0.92829125">
Grammar G*: p1W A ! hai; p2W B ! hb; D1; D1i; p3W C ! hA1B1cA1B2A1B3i; p4W D ! hdi
P3
P1 P2 P1 P1
Pa Pa
(a) Derivation tree
C
A, B, c A, B2 A, B3
a b a D, a D,
d d
(b) Derived tree
(c) Induced dependency structure
a b c a d a d
</figure>
<figureCaption confidence="0.450614375">
Figure 3: A CCFG derivation and the dependency structure induced by it
induced by an r-CCFG have a gap degree that is
bounded by r; that they are all well-nested; and
that each well-nested structure with a gap degree
bounded by r can be induced by an r-CCFG. In the
following, let G be an r-CCFG, and write Gr for the
set of all r-CCFGs.
Lemma 7 D.G/ C Dr-1
</figureCaption>
<bodyText confidence="0.968279294117647">
Proof Let .T ]; T [/ ` D, and let .uW p/ 2 T ]. By
definition of proj, for each 1 &lt; i &lt; p.p/, the set
proj.u; i/ forms a contiguous region of the sen-
tence derived by T ]. Using Lemma 6, we then
see that down.u/ is distributed over at most p.u/
contiguous regions of that sentence. This means
that the dependency subtree rooted at anchor.p/
has at most p.p/ — 1 gaps.
Lemma 8 D.G/ c Dwn
Proof Choose a D 2 D.G/, and assume that D is
not well-nested. Then there is a governor u 2 D
with two distinct dependents v; w such that #v
contains tokens v1; v2, and #w contains tokens
w1; w2 such that v1 -&lt; w1 v2 -&lt; w2. For the
derivation .T ]; T [/ that induces D, this means that
there is a node .u W p/ with children .v W pv/ and
.w W pw/ in T ] such that
</bodyText>
<equation confidence="0.9879105">
9.v1; v2 2 down.v//W 9.w1; w2 2 down.w//W
fL.v1/ -&lt; fL.w1/ -&lt; fL.v2/ -&lt; fL.w2/ in T [ :
</equation>
<bodyText confidence="0.951094416666667">
Since down.v/ and down.w/ are disjoint; v1 and v2
must come from distinct convex blocks in down.v/,
and w1 and w2 must come from distinct convex
blocks in down.w/. Therefore,
v1 2 proj.v;i1/; v2 2 proj.v;i2/; i1 &lt; i2 and
w1 2 proj.w; j1/; w2 2 proj.w; j2/; j1 &lt; j2 :
By definition, proj.x; k/ (x 2 fv; wg) is the projec-
tion of a node fI .x/k in T [; the label of this node
is LHS.px/k. Assume now that the non-terminal
on the LHS of pv is V , and that the non-terminal
on the LHS of pw is W . Given that pv and pw are
used to rewrite p, RHS.p/ contains the substring
</bodyText>
<equation confidence="0.363683666666667">
Vi1 ... Wj1 . . � Vi2 • • • Wj2. This contradicts the fact
that RHS.p/ 2 ESD.N; T /.
Lemma 9 Dwn \ Dr-1 C SGE&apos;Vr D.G/
</equation>
<bodyText confidence="0.99143196">
Proof Let D D .W; !; -&lt;/ be a dependency struc-
ture from Dwn \ Dr-1. We construct an r-CCFG
G D .N; T; P; S/ that induces D. For the ranked
alphabet N of non-terminals, put
N D fNw j w 2 W g; p.Nw/ D gd.w/ C 1:
The set S of start symbols is fNTg, where &gt; is the
root of D. For the terminal alphabet, put T D W .
The set P consists of jW j productions of the form
Nw ! E˛, where w 2 W , and ˛E is a tuple with
arity gd.w/ C 1 that contains the terminal w and
non-terminal components for all children of w as
follows. Consider the following family of sets:
Cw D ffwgg[f #iv j w ! v; 1 &lt; i &lt; gd.v/C1g:
All sets in Cw are disjoint, and their union equals
the set #w. We define a function Œ•• that interprets
the elements of Cw as elements from N [ T as
follows: Œfwg• WD w, and Œ#iv• WD Niv. Now the
RHS of a rule Nw ! ˛E is fully specified by the
following equivalences, where C 2 Cw:
ŒC• occurs in ˛i iff C C #iw
ŒC1• precedes ŒC2• in ˛E iff C1 x C2 C -&lt;
Applied to the dependency structure of Figure 3c,
this constructs the given grammar G*. Note that,
due to the well-nestedness of D, the RHS of each
rule forms a valid extended semi-Dyck word.
</bodyText>
<page confidence="0.998104">
125
</page>
<sectionHeader confidence="0.997492" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.996851066666667">
Starting from the fact that TAG is able to derive
well-nested dependency structures with a gap de-
gree of at most 1, we have investigated how multi-
component and multi-foot extensions of TAG alter
this expressivity. Our results are as follows:
• For multi-component TAG, the notion of ‘in-
duced dependency structures’ depends on the
assumed notion of lexicalization. Therefore,
either the same structures as in TAG, or arbi-
trary gap-bounded dependency structures are
derivable. In the former case, MCTAG has the
same structural limits as standard TAG; in the
latter case, even non-well-nested dependency
structures are induced.
• The multi-foot extension CCFG (and its equiv-
alent RNRG) is restricted to well-nested de-
pendency structures, but in contrast to TAG, it
can induce structures with any bounded gap
degree. The rank of a grammar is an upper
bound on the gap degree of the dependency
structures it induces.
Since the extensions inherent to MCTAG and
CCFG are orthogonal, it is possible to combine
them: Multi-Component Multi-Foot TAG (MMTAG)
as described by Chiang (2001) allows to simulta-
neously adjoin sets of trees, where each tree may
have multiple foot nodes. The structural limita-
tions of the dependency structures inducible by
MCTAG and CCFG generalize to MMTAG as one
would expect. As in the case of MCTAG, there
are two different understandings of how a depen-
dency structure is induced by an MMTAG. Under
the ‘one anchor per component’ perspective, MM-
TAG, just like CCFG, derives well-nested structures
of bounded gap-degree. Under the ‘one anchor
per tree set’ perspective, just like MCTAG, it also
derives non-well-nested gap-bounded structures.
Acknowledgements We thank Jan Schwingham-
mer, Guido Tack, and Stefan Thater for fruitful dis-
cussions during the preparation of this paper, and
three anonymous reviewers for their detailed com-
ments on an earlier version. The work of Marco
Kuhlmann is funded by the Collaborative Research
Centre ‘Resource-Adaptive Cognitive Processes’
of the Deutsche Forschungsgemeinschaft.
</bodyText>
<sectionHeader confidence="0.99395" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998757428571428">
Naoki Abe. 1988. Feasible learnability of formal
grammars and the theory of natural language acqui-
sition. In 12th International Conference on Compu-
tational Linguistics, pages 1–6, Budapest, Hungary.
Manuel Bodirsky, Marco Kuhlmann, and Mathias
Möhl. 2005. Well-nested drawings as models of
syntactic structure. In Tenth Conference on For-
mal Grammar and Ninth Meeting on Mathematics
of Language (FG-MoL), Edinburgh, UK.
David Chiang. 2001. Constraints on strong gener-
ative power. In 39th Annual Meeting and Tenth
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 124–131,
Toulouse, France.
Robert Frank. 2002. Phrase Structure Composition
and Syntactic Dependencies. MIT Press.
Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevová,
Eva Hajiˇcová, Petr Sgall, and Petr Pajas. 2001.
Prague Dependency Treebank 1.0. LDC, 2001T10.
Günther Hotz and Gisela Pitsch. 1996. On parsing cou-
pled-context-free languages. Theoretical Computer
Science, 161:205–233.
Aravind K. Joshi. 1985. Tree adjoining grammars:
How much context-sensitivity is required to provide
reasonable structural descriptions? In David R.
Dowty, Lauri Karttunen, and Arnold M. Zwicky,
editors, Natural Language Parsing, pages 206–250.
Cambridge University Press, Cambridge, UK.
Laura Kallmeyer. 2005. A descriptive charac-
terization of multicomponent tree adjoining gram-
mars. In Traitement Automatique des Langues Na-
turelles (TALN), volume 1, pages 457–462, Dourdan,
France.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In 22nd In-
ternational Conference on Computational Linguis-
tics and 43rd Annual Meeting of the Association for
Computational Linguistics (COLING-ACL), Com-
panion Volume, Sydney, Australia.
Solomon Marcus. 1967. Algebraic Linguistics: An-
alytical Models, volume 29 of Mathematics in Sci-
ence and Engineering. Academic Press, New York.
Giorgio Satta. 1992. Recognition of linear context-
free rewriting systems. In 30th Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
89–95, Newark, Delaware, USA.
David J. Weir. 1988. Characterizing Mildly Context-
Sensitive Grammar Formalisms. Ph.D. thesis, Uni-
versity of Pennsylvania, Philadelphia, USA.
</reference>
<page confidence="0.998555">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208582">
<title confidence="0.914032">Extended cross-serial dependencies in Tree Adjoining Grammars</title>
<author confidence="0.547485">Kuhlmann</author>
<affiliation confidence="0.6184395">Programming Systems Saarland</affiliation>
<address confidence="0.937704">Saarbrücken,</address>
<email confidence="0.998815">{kuhlmann|mmohl}@ps.uni-sb.de</email>
<abstract confidence="0.9949729375">The ability to represent cross-serial dependencies is one of the central features of Adjoining Grammar The class of dependency structures representable by can be captured by two graph-theoretic properties: a bound the degree the structures, and a called In this paper, we compare formalisms from two of extensions to the context of the question, how they behave with respect to these constraints. In particular, we that multi-component not necessarily retain the well-nestedness constraint, while this constraint is inherent to</abstract>
<note confidence="0.8068875">Coupled Context-Free Grammar (Hotz and Pitsch, 1996).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Naoki Abe</author>
</authors>
<title>Feasible learnability of formal grammars and the theory of natural language acquisition.</title>
<date>1988</date>
<booktitle>In 12th International Conference on Computational Linguistics,</booktitle>
<pages>1--6</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3559" citStr="Abe, 1988" startWordPosition="533" endWordPosition="534">that has the well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones. This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’. In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree. Thus, from the dependency point of view, they constitute the structurally more conservative extension of TAG. 121 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126, Sydney, July 2006. c�2006 Association for Computational Linguistics SO a T D B C T O a T D B C 2 Dependency structures for TAG We start with a presentation of the dependency view on TAG that constitutes the basis fo</context>
<context position="10634" citStr="Abe, 1988" startWordPosition="1827" endWordPosition="1828">substitution sites such that b, c, d, e interleave. Note that the MCTAG used in this example is heavily restricted: it is tree-local and does not even use adjunction. This restricted form suffices to induce non-well-nested dependency structures. 4 Multi-foot extensions A second way to extend TAG, orthogonal to the multi-component approach, is to allow a single elementary tree to have more than one foot node. For this kind of extension, the Fundamental Hypothesis does not need to be re-interpreted. Probably the most prominent multi-foot extension of TAG is Ranked Node Rewriting Grammar (RNRG) (Abe, 1988); however, the properties that we are interested in here can be easier investigated in a notational variant of RNRG, Coupled Context-Free Grammar (Hotz and Pitsch, 1996). Terminology Multi-foot formalisms require a means to specify which foot node gets what material in an adjunction. To do so, they use ranked symbols. A ranked alphabet is a pair 17 = (E, p), where E is an alphabet, and p E E --&gt; N is a total function that assigns every symbol Q E E a (positive) rank. Define 17[r] := { Q E E I p(a) = r }. The components of a, comp(a), are the elements of the set { (a, i) I 1 &lt; i &lt; p(a) }. We wr</context>
</contexts>
<marker>Abe, 1988</marker>
<rawString>Naoki Abe. 1988. Feasible learnability of formal grammars and the theory of natural language acquisition. In 12th International Conference on Computational Linguistics, pages 1–6, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Bodirsky</author>
<author>Marco Kuhlmann</author>
<author>Mathias Möhl</author>
</authors>
<title>Well-nested drawings as models of syntactic structure.</title>
<date>2005</date>
<booktitle>In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language (FG-MoL),</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="1317" citStr="Bodirsky et al., 2005" startWordPosition="190" endWordPosition="193">icular, we show that multi-component TAG does not necessarily retain the well-nestedness constraint, while this constraint is inherent to Coupled Context-Free Grammar (Hotz and Pitsch, 1996). 1 Introduction The ability to assign ‘limited cross-serial dependencies’ to the words in a sentence is a hallmark of mildly context-sensitive grammar formalisms (Joshi, 1985). In the case of TAG, an exact definition of this ability can be given in terms of two graph-theoretic properties of the dependency structures induced by TAG derivations: the gap degree restriction and the well-nestedness constraint (Bodirsky et al., 2005). Gap degree and well-nestedness can be seen as the formal correspondents of what Joshi (1985) refers to as ‘a limited amount of cross-serial dependencies’ and ‘the nesting properties as in the case of context-free grammars.’ More specifically, the gap degree of a dependency structure counts the number of discontinuities in a dependency subtree, while well-nestedness constrains the positions of disjoint subtrees relative to one another. The dependency structures that correspond to the derivations in a lexicalized TAG are well-nested, and their gap degree is at most 1. In the present paper, we </context>
<context position="4322" citStr="Bodirsky et al. (2005)" startWordPosition="656" endWordPosition="659">ounded gap degree. Thus, from the dependency point of view, they constitute the structurally more conservative extension of TAG. 121 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126, Sydney, July 2006. c�2006 Association for Computational Linguistics SO a T D B C T O a T D B C 2 Dependency structures for TAG We start with a presentation of the dependency view on TAG that constitutes the basis for our work, and introduce the relevant terminology. The main objective of this section is to provide intuitions; for the formal details, see Bodirsky et al. (2005). 2.1 The dependency view on TAG Lets D w1 • • • wn be a sentence (a sequence of tokens). By a dependency structure for s, we mean a tuple (W, !, -&lt;), where W D fw1, ... , wng, and ! D f (wi, wj) 2 W x W j wj depends on wi g ~ D f(wi,wj) 2 W x W j i &lt; j g To interpret a grammar formalism as a specification for a set of dependency structures, we need to assign meaning to the relation ‘depends’ in terms of this formalism. For TAG, this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’ (Frank, 2002). More specifi</context>
<context position="7662" citStr="Bodirsky et al. (2005)" startWordPosition="1293" endWordPosition="1296"> #w1 and #w2 are disjoint. Four tokens w11, w21 2 #w1, w12, w22 2 #w2 interleave, if w11 _&lt; w12 _&lt; w21 _&lt; w2 2. A dependency structure is well-nested, if it does not contain interleaving tokens. We write Dwn for the set of all well-nested dependency structures. For illustration, consider again the dependency structure shown in Figure 1. It has gap degree 1: a2 is the only token w for which #w is not convex; the set fb1, c1g forms a gap in #a2. The structure is also well-nested. In contrast, the structure shown in the right half of Figure 2 is not well-nested; the tokens b, c, d, e interleave. Bodirsky et al. (2005) show that TAG induces precisely the set Dwn \ D1. 3 Multi-component extensions Multi-component TAG (MCTAG) extends TAG with the ability to adjoin a whole set of elementary trees (components) simultaneously. To answer the question, whether this extension also leads to an extended class of dependency structures, we first need to decide how we want to transfer the Fundamental Hypothesis (Frank, 2002) to MCTAGs. . a1 a2 b2 b1 c1 c2 d2 d1 Figure 1: TAG grammar for anbncndn, and a dependency structure induced by this grammar BO CO D0 122 D0 C0 2 C0 1 B0 2 E D d c 9 8 &gt;&gt;ˆ = &lt;ˆ &gt; ˆ ;&gt;ˆ: 9 &gt;&gt;= ;&gt;&gt; E0 </context>
</contexts>
<marker>Bodirsky, Kuhlmann, Möhl, 2005</marker>
<rawString>Manuel Bodirsky, Marco Kuhlmann, and Mathias Möhl. 2005. Well-nested drawings as models of syntactic structure. In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language (FG-MoL), Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Constraints on strong generative power.</title>
<date>2001</date>
<booktitle>In 39th Annual Meeting and Tenth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>124--131</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="20840" citStr="Chiang (2001)" startWordPosition="3875" endWordPosition="3876"> derivable. In the former case, MCTAG has the same structural limits as standard TAG; in the latter case, even non-well-nested dependency structures are induced. • The multi-foot extension CCFG (and its equivalent RNRG) is restricted to well-nested dependency structures, but in contrast to TAG, it can induce structures with any bounded gap degree. The rank of a grammar is an upper bound on the gap degree of the dependency structures it induces. Since the extensions inherent to MCTAG and CCFG are orthogonal, it is possible to combine them: Multi-Component Multi-Foot TAG (MMTAG) as described by Chiang (2001) allows to simultaneously adjoin sets of trees, where each tree may have multiple foot nodes. The structural limitations of the dependency structures inducible by MCTAG and CCFG generalize to MMTAG as one would expect. As in the case of MCTAG, there are two different understandings of how a dependency structure is induced by an MMTAG. Under the ‘one anchor per component’ perspective, MMTAG, just like CCFG, derives well-nested structures of bounded gap-degree. Under the ‘one anchor per tree set’ perspective, just like MCTAG, it also derives non-well-nested gap-bounded structures. Acknowledgemen</context>
</contexts>
<marker>Chiang, 2001</marker>
<rawString>David Chiang. 2001. Constraints on strong generative power. In 39th Annual Meeting and Tenth Conference of the European Chapter of the Association for Computational Linguistics, pages 124–131, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Frank</author>
</authors>
<title>Phrase Structure Composition and Syntactic Dependencies.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4908" citStr="Frank, 2002" startWordPosition="781" endWordPosition="782">see Bodirsky et al. (2005). 2.1 The dependency view on TAG Lets D w1 • • • wn be a sentence (a sequence of tokens). By a dependency structure for s, we mean a tuple (W, !, -&lt;), where W D fw1, ... , wng, and ! D f (wi, wj) 2 W x W j wj depends on wi g ~ D f(wi,wj) 2 W x W j i &lt; j g To interpret a grammar formalism as a specification for a set of dependency structures, we need to assign meaning to the relation ‘depends’ in terms of this formalism. For TAG, this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’ (Frank, 2002). More specifically, a derivation in a (strongly) lexicalized TAG can be viewed as a dependency structure as follows: The set W contains the (occurences of) lexical anchors involved in the derivation. For two anchors wi, wj 2 W , wi ! wj if the elementary tree anchored at wj was substituted or adjoined into the tree anchored at wi. We then have wi -&lt; wj if wi precedes wj in the yield of the derived tree corresponding to the derivation. Notice that the relation ! in such a dependency structure is almost exactly the derivation tree of the underlying TAG derivation; the only difference is that el</context>
<context position="8063" citStr="Frank, 2002" startWordPosition="1359" endWordPosition="1360">the set fb1, c1g forms a gap in #a2. The structure is also well-nested. In contrast, the structure shown in the right half of Figure 2 is not well-nested; the tokens b, c, d, e interleave. Bodirsky et al. (2005) show that TAG induces precisely the set Dwn \ D1. 3 Multi-component extensions Multi-component TAG (MCTAG) extends TAG with the ability to adjoin a whole set of elementary trees (components) simultaneously. To answer the question, whether this extension also leads to an extended class of dependency structures, we first need to decide how we want to transfer the Fundamental Hypothesis (Frank, 2002) to MCTAGs. . a1 a2 b2 b1 c1 c2 d2 d1 Figure 1: TAG grammar for anbncndn, and a dependency structure induced by this grammar BO CO D0 122 D0 C0 2 C0 1 B0 2 E D d c 9 8 &gt;&gt;ˆ = &lt;ˆ &gt; ˆ ;&gt;ˆ: 9 &gt;&gt;= ;&gt;&gt; E0 e a b c d e A0 a B1 C1 B2 C2 8 &lt;ˆ ˆ ˆˆ: B0 1 b Figure 2: An MCTAG and a not well-nested dependency structure derived by it. 3.1 One anchor per component If we commit to the view that each component of a tree set introduces a separate lexical anchor and its syntactic dependencies, the dependency structures induced by MCTAG are exactly the structures induced by TAG. In particular, each node in the de</context>
</contexts>
<marker>Frank, 2002</marker>
<rawString>Robert Frank. 2002. Phrase Structure Composition and Syntactic Dependencies. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Barbora Vidova Hladka, Jarmila Panevová, Eva Hajiˇcová, Petr Sgall, and Petr Pajas.</title>
<date>2001</date>
<marker>Hajiˇc, 2001</marker>
<rawString>Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevová, Eva Hajiˇcová, Petr Sgall, and Petr Pajas. 2001. Prague Dependency Treebank 1.0. LDC, 2001T10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Günther Hotz</author>
<author>Gisela Pitsch</author>
</authors>
<title>On parsing coupled-context-free languages.</title>
<date>1996</date>
<journal>Theoretical Computer Science,</journal>
<pages>161--205</pages>
<contexts>
<context position="885" citStr="Hotz and Pitsch, 1996" startWordPosition="122" endWordPosition="125">central features of Tree Adjoining Grammar (TAG). The class of dependency structures representable by lexicalized TAG derivations can be captured by two graph-theoretic properties: a bound on the gap degree of the structures, and a constraint called well-nestedness. In this paper, we compare formalisms from two strands of extensions to TAG in the context of the question, how they behave with respect to these constraints. In particular, we show that multi-component TAG does not necessarily retain the well-nestedness constraint, while this constraint is inherent to Coupled Context-Free Grammar (Hotz and Pitsch, 1996). 1 Introduction The ability to assign ‘limited cross-serial dependencies’ to the words in a sentence is a hallmark of mildly context-sensitive grammar formalisms (Joshi, 1985). In the case of TAG, an exact definition of this ability can be given in terms of two graph-theoretic properties of the dependency structures induced by TAG derivations: the gap degree restriction and the well-nestedness constraint (Bodirsky et al., 2005). Gap degree and well-nestedness can be seen as the formal correspondents of what Joshi (1985) refers to as ‘a limited amount of cross-serial dependencies’ and ‘the nes</context>
<context position="3583" citStr="Hotz and Pitsch, 1996" startWordPosition="535" endWordPosition="538">e well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones. This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’. In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree. Thus, from the dependency point of view, they constitute the structurally more conservative extension of TAG. 121 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126, Sydney, July 2006. c�2006 Association for Computational Linguistics SO a T D B C T O a T D B C 2 Dependency structures for TAG We start with a presentation of the dependency view on TAG that constitutes the basis for our work, and introduc</context>
<context position="10803" citStr="Hotz and Pitsch, 1996" startWordPosition="1851" endWordPosition="1854">junction. This restricted form suffices to induce non-well-nested dependency structures. 4 Multi-foot extensions A second way to extend TAG, orthogonal to the multi-component approach, is to allow a single elementary tree to have more than one foot node. For this kind of extension, the Fundamental Hypothesis does not need to be re-interpreted. Probably the most prominent multi-foot extension of TAG is Ranked Node Rewriting Grammar (RNRG) (Abe, 1988); however, the properties that we are interested in here can be easier investigated in a notational variant of RNRG, Coupled Context-Free Grammar (Hotz and Pitsch, 1996). Terminology Multi-foot formalisms require a means to specify which foot node gets what material in an adjunction. To do so, they use ranked symbols. A ranked alphabet is a pair 17 = (E, p), where E is an alphabet, and p E E --&gt; N is a total function that assigns every symbol Q E E a (positive) rank. Define 17[r] := { Q E E I p(a) = r }. The components of a, comp(a), are the elements of the set { (a, i) I 1 &lt; i &lt; p(a) }. We write ai instead of (a, i). Let comp(17) := SI2H comp(a). 4.1 Coupled Context-Free Grammar Coupled Context-Free Grammar (CCFG) is a generalization of context-free grammar </context>
</contexts>
<marker>Hotz, Pitsch, 1996</marker>
<rawString>Günther Hotz and Gisela Pitsch. 1996. On parsing coupled-context-free languages. Theoretical Computer Science, 161:205–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions? In</title>
<date>1985</date>
<booktitle>Natural Language Parsing,</booktitle>
<pages>206--250</pages>
<editor>David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="1061" citStr="Joshi, 1985" startWordPosition="150" endWordPosition="151">nd on the gap degree of the structures, and a constraint called well-nestedness. In this paper, we compare formalisms from two strands of extensions to TAG in the context of the question, how they behave with respect to these constraints. In particular, we show that multi-component TAG does not necessarily retain the well-nestedness constraint, while this constraint is inherent to Coupled Context-Free Grammar (Hotz and Pitsch, 1996). 1 Introduction The ability to assign ‘limited cross-serial dependencies’ to the words in a sentence is a hallmark of mildly context-sensitive grammar formalisms (Joshi, 1985). In the case of TAG, an exact definition of this ability can be given in terms of two graph-theoretic properties of the dependency structures induced by TAG derivations: the gap degree restriction and the well-nestedness constraint (Bodirsky et al., 2005). Gap degree and well-nestedness can be seen as the formal correspondents of what Joshi (1985) refers to as ‘a limited amount of cross-serial dependencies’ and ‘the nesting properties as in the case of context-free grammars.’ More specifically, the gap degree of a dependency structure counts the number of discontinuities in a dependency subtr</context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Aravind K. Joshi. 1985. Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions? In David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, editors, Natural Language Parsing, pages 206–250. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Kallmeyer</author>
</authors>
<title>A descriptive characterization of multicomponent tree adjoining grammars.</title>
<date>2005</date>
<booktitle>In Traitement Automatique des Langues Naturelles (TALN),</booktitle>
<volume>1</volume>
<pages>457--462</pages>
<location>Dourdan, France.</location>
<contexts>
<context position="3170" citStr="Kallmeyer, 2005" startWordPosition="469" endWordPosition="470">ng. Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992). In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability. If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones. This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’. In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree. Thus, from the dependency point of view, they const</context>
<context position="8787" citStr="Kallmeyer (2005)" startWordPosition="1511" endWordPosition="1512"> by this grammar BO CO D0 122 D0 C0 2 C0 1 B0 2 E D d c 9 8 &gt;&gt;ˆ = &lt;ˆ &gt; ˆ ;&gt;ˆ: 9 &gt;&gt;= ;&gt;&gt; E0 e a b c d e A0 a B1 C1 B2 C2 8 &lt;ˆ ˆ ˆˆ: B0 1 b Figure 2: An MCTAG and a not well-nested dependency structure derived by it. 3.1 One anchor per component If we commit to the view that each component of a tree set introduces a separate lexical anchor and its syntactic dependencies, the dependency structures induced by MCTAG are exactly the structures induced by TAG. In particular, each node in the derivation tree, and therefore each token in the dependency tree, corresponds to a single elementary tree. As Kallmeyer (2005) puts it, one can then consider an MCTAG as a TAG G ‘where certain derivation trees in G are disallowed since they do not satisfy certain constraints.’ The ability of MCTAG to perform multiple adjunctions simultaneously allows one to induce more complex sets of dependency structures—each individual structure is limited as in the case of standard TAG. 3.2 One anchor per tree set If, on the other hand, we take a complete tree set as the level on which syntactic dependencies are specified, MCTAGs can induce a larger class of dependency structures. Under this perspective, tokens in the dependency </context>
</contexts>
<marker>Kallmeyer, 2005</marker>
<rawString>Laura Kallmeyer. 2005. A descriptive characterization of multicomponent tree adjoining grammars. In Traitement Automatique des Langues Naturelles (TALN), volume 1, pages 457–462, Dourdan, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In 22nd International Conference on Computational Linguistics and 43rd Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Companion Volume,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2501" citStr="Kuhlmann and Nivre, 2006" startWordPosition="373" endWordPosition="376">e is at most 1. In the present paper, we compare formalisms from two strands of extensions to TAG in the context of the question, what classes of dependency structures they are able to induce. We are particularly interested in formalisms that induce only well-nested dependency structures. This interest is motivated by two observations: First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967)—while more than 23% of the 73 088 dependency structures in the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). Second, well-nestedness is interesting for processing. Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992). In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability. If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivati</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In 22nd International Conference on Computational Linguistics and 43rd Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Companion Volume, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Solomon Marcus</author>
</authors>
<title>Algebraic Linguistics: Analytical Models,</title>
<date>1967</date>
<booktitle>Mathematics in Science and Engineering.</booktitle>
<volume>29</volume>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="2302" citStr="Marcus, 1967" startWordPosition="343" endWordPosition="344">nstrains the positions of disjoint subtrees relative to one another. The dependency structures that correspond to the derivations in a lexicalized TAG are well-nested, and their gap degree is at most 1. In the present paper, we compare formalisms from two strands of extensions to TAG in the context of the question, what classes of dependency structures they are able to induce. We are particularly interested in formalisms that induce only well-nested dependency structures. This interest is motivated by two observations: First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967)—while more than 23% of the 73 088 dependency structures in the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). Second, well-nestedness is interesting for processing. Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992). In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational </context>
<context position="6007" citStr="Marcus, 1967" startWordPosition="970" endWordPosition="971">y structure is almost exactly the derivation tree of the underlying TAG derivation; the only difference is that elementary trees have been replaced by their lexical anchors. Figure 1 shows a TAG grammar together with a dependency structure induced by a derivation of this grammar. Tokens in the derived string are represented by labelled nodes; the solid arcs between the nodes represent the dependencies. 2.2 Gap degree and well-nestedness An interesting feature of the dependency structure shown in Figure 1 is that it violates a standard constraint on dependency structures known as projectivity (Marcus, 1967). We introduce some terminology for non-projective dependency structures: A set T C W is convex, if for no two tokens w1, w2 2 T , there exists a token w from W — T such that w1 -&lt; w -&lt; w2. The cover of T , C(T ), is the smallest convex set that contains T . For w 2 W , we write #w for the set of tokens in the b c d subtree rooted at w (including w itself). A gap in #w is a largest convex set in C(#w)—#w. The gap degree of w, gd(w), is the number of gaps in #w. The gaps in #w partition #w into gd(w)—1 largest convex blocks; we write #iw to refer to the i-th of these blocks, counted from left t</context>
</contexts>
<marker>Marcus, 1967</marker>
<rawString>Solomon Marcus. 1967. Algebraic Linguistics: Analytical Models, volume 29 of Mathematics in Science and Engineering. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Recognition of linear contextfree rewriting systems.</title>
<date>1992</date>
<booktitle>In 30th Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>89--95</pages>
<location>Newark, Delaware, USA.</location>
<contexts>
<context position="2779" citStr="Satta, 1992" startWordPosition="411" endWordPosition="412">his interest is motivated by two observations: First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967)—while more than 23% of the 73 088 dependency structures in the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006). Second, well-nestedness is interesting for processing. Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992). In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability. If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones. This depen</context>
</contexts>
<marker>Satta, 1992</marker>
<rawString>Giorgio Satta. 1992. Recognition of linear contextfree rewriting systems. In 30th Meeting of the Association for Computational Linguistics (ACL), pages 89–95, Newark, Delaware, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Weir</author>
</authors>
<title>Characterizing Mildly ContextSensitive Grammar Formalisms.</title>
<date>1988</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, USA.</location>
<contexts>
<context position="3152" citStr="Weir, 1988" startWordPosition="467" endWordPosition="468">for processing. Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992). In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability. If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not. The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones. This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’. In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree. Thus, from the dependency point o</context>
<context position="9467" citStr="Weir, 1988" startWordPosition="1626" endWordPosition="1627">rivation trees in G are disallowed since they do not satisfy certain constraints.’ The ability of MCTAG to perform multiple adjunctions simultaneously allows one to induce more complex sets of dependency structures—each individual structure is limited as in the case of standard TAG. 3.2 One anchor per tree set If, on the other hand, we take a complete tree set as the level on which syntactic dependencies are specified, MCTAGs can induce a larger class of dependency structures. Under this perspective, tokens in the dependency structure correspond not to individual components, but to tree sets (Weir, 1988). For each token w, �w then contains the lexical anchors of all the subderivations starting in the tree set corresponding to w. As there can be a gap between each two of these subderivations, the gap degree of the induced dependency structures is bounded only by the maximal number of components per tree set. At the same time, even non-well-nested structures can be induced; an example is shown in Figure 2. Here, �b is distributed over the components rooted at B1 and B2, and �c is distributed over C1 and C2. The elementary tree rooted at A arranges the substitution sites such that b, c, d, e int</context>
</contexts>
<marker>Weir, 1988</marker>
<rawString>David J. Weir. 1988. Characterizing Mildly ContextSensitive Grammar Formalisms. Ph.D. thesis, University of Pennsylvania, Philadelphia, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>