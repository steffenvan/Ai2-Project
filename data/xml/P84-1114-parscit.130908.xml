<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002880">
<note confidence="0.951105">
INTERPRETING SYNTACTICALLY ILL-FORMED SENTENCES
Leonardo LESMO and Pietro TORASSO
Dipartimento di Informatica - Universita&apos; di Torino
Corso Massimo D&apos;Azeglio 42 - 10125 Torino - ITALY
</note>
<sectionHeader confidence="0.598784" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999841">
The paper discusses three different kinds of
syntactic ill-formedness: ellipsis, conjunctions,
and actual syntactic errors. It is shown how a new
grammatical formalism, based on a two-level repre
sentation of the syntactic knowledge is used to cope
with ill-formed sentences. The basic control struc
ture of the parser is briefly sketched; the paper
shows that it can be applied without any substan
tial change both to correct and to ill-formed sen
tences. This is achieved by introducing a mechanism
for the hypothesization of syntactic structures,
which is largely independent of the rules defining
the well-formedness. On the contrary, the second
level of syntactic knowledge embodies those rules
and is used to validate the hypotheses emitted by
the first level. Alternative hypotheses are obtain
ed, when needed, by means of local reorganizations
of the parse tree. Sentence fragments are handled
by the same mechanism, but in this case the second
level rules are used to detect the absence of one
(or more) constituents.
</bodyText>
<sectionHeader confidence="0.990651" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.986857018181818">
In the last years we have been involved in
building a natural language (Italian) interface to
ward a relational database. Even if this research
required to consider issues relative to knowledge
representation (Lesmo et al 83) and query optimiza
tion (Lesmo at al, in press), our main concern was
to devise efficient parsing techniques (Lesmo et al
81, Lesmo &amp; Torasso 83).
The term &amp;quot;efficient&amp;quot;, when applied to language
processing, can take a number of different meanings,
ranging from pure processing speed to the ability
to analyze fragments of text, to the flexibility
that characterizes the behavior of the parser. We
believe that all facets of efficiency are worth be
ing pursued, but if the communication between the
man and the machine has to occur in a really natu
ral fashion, the robustness of the parser, i.e. its
ability to cope with unforeseen inputs must receive
the greatest attention. It is important to realize
that &amp;quot;unforeseen&amp;quot; is assumed her to refer to the
syntactic form of the input sentence: of course,
also inputs that are unexpected from a semantic
point of view should be handled properly, but,
since usually the syntactic knowledge acts as a fil
ter between the reception of the input and the sub
sequent stages of the analysis, the first problem
that must be faced is the following: how can the
parser be prevented from rejecting sentences that
are syntactically ill-formed, but could be interpre
ted correctly if they are passed to the other compo
nents of the system?
Alternatively, the problem can be stated as:
how to foresee every interpretable input? Marcus
(1982) envisages the following alternatives:
a) the use of special &amp;quot;un-grammatical&amp;quot; rules, which
explicitly encode facts about non-standard usage
b) the use of &amp;quot;meta-rules&amp;quot; to relax the constraints
imposed by classes of rules of the grammar
c) allowing flexible interaction between syntax and
semantics, so that semantics can directly ana
lyze substrings of syntactic fragments or indi
vidual words when full syntactic analysis fails.
Even if we agree in stating the importance of a
strong interaction between syntax and semantics,
our approach is quite different from c) (as
well as from the other ones). For this reason, and
in spite of the fact that a detailed description of
the parser&apos;s operating principles has been given
elsewhere (Lesmo &amp; Torasso 83), the next section is
devoted to an introduction to the basic ideas that
led to the design of the syntactic knowledge source.
The subsequent sections will cover some phenomena
which are related with ill-formedness of sentences,
namely: ellipsis, conjunctions, and some types of
actual syntactic errors.
</bodyText>
<sectionHeader confidence="0.985101" genericHeader="method">
GRAMMARS AND NATURAL LANGUAGE
</sectionHeader>
<bodyText confidence="0.9999803">
It is widely accepted (see Charniak 81) that
syntactic knowledge consitutes one of the founda
tions needed to build natural language interpreters.
Various kinds of grammatical formalisms have been
devised to represent in efficient, flexible and per
spicuous way the syntactic knowledge (Winograd 83).
Even if the formalisms are quite different, the
main characteristic shared by all grammars is that
they are prescriptive (or normative) in nature. A
grammar defines what a sentence is, that is it spec
</bodyText>
<page confidence="0.996653">
534
</page>
<bodyText confidence="0.982279443478261">
what sequences of words are acceptable. This is in
sharp contrast with the normal use of language,
which has, as its main purpose, the communication
of something. Of course all grammars can be (and
have been) augmented in order to build a representa
tion of the meaning of the sentences (i.e. some
thing that should be able to carry most of its corn
municative contents), but a meaning can only be ob
tamed for correct sentences.
Some efforts have recently been devoted to ex
tending the coverage of grammars, in order to deal
also with ill-formed sentences (Kwasny &amp; Sondheimer
81, Weischedel &amp; Sondheimer 82, Granger 82). This
is usually done by relaxing the constraints imposed
by some rules of the grammar, by adding new rules
to take care of some kinds of ill-formedness, or by
allowing the semantics to intervene when the syn
tax is not able to process the input. However, most
of these approaches present some problems: either
the perspicuousness and the readibility of the gram
mar is reduced or the control structure of the ana
lyser is made considerably more complex.
The sources of ill-formedness can be grouped
in three classes: ellipsis, conjunctions, and syn
tactic errors.
In the case of ellipsis, a fragment such as
&amp;quot;John&amp;quot; or &amp;quot;probably&amp;quot; can be understood by a human
listener without any particular difficulty, provi
ded that a particular context is given. On the 0th
er hand, it is apparent that those fragments are
not consistent with the rules defining the well-
formed sentences.
Similar problems arise in case the grammar at
tempts to cope with conjunctions. In general, ellip
sis is meaningful just in case a context external
to the expression to analyse is assumed to exist.
The situation with conjunctions is rather different:
in some sense, the context that must be used to in
terpret a conjunct is given by the previous con
junct(s), so that it is expressed inside the sen
tence that has to be analysed. The difficulty in
the analysis of conjunctions depends on the fact
that not only the second conjunct is often ill-
formed (if it is considered as a standing-alone sen
tence), but it is the particular form of ill-formed
ness that provides the analyzer with the piece of
information needed to decide what is the syntactic
role of that conjunct (or, if we assume that the re
sult of the syntactic analysis is represented in
form of a tree, to decide where the constituent ex
pressed by the conjunct has to be appended in the
syntactic tree). For this reason, in the following
sentences the second conjuncts have quite different
roles:
John loves Mary and Susy
John loves Mary and Susy Fred
John loves Mary and hates Violet
Thus, as in the case of ellipsis, a syntactic ana
lyser designed to handle conjunctions must be able
to operate on ill-formed fragments, but with the
additional difficulty of modifying the parse tree
on the basis of the type of ill-formedness.
The last source of ill-formedness that we will
consider are the syntactic errors. Differently
from the previous cases, it is almost impossible to
list all possible mistakes that a person could make
in writing a sentence. Probably, most of them can
not be considered as syntactic errors (e.g. misspel
ling of words or wrong markers for a given case of
a verb), but there are also errors that have purely
syntactic grounds. Some noticeable examples are
agreement errors, ordering errors and errors in
verb tenses. An examples of each of them is report
ed below:
John love Mary (4)
John is going probably to home (5)
Yesterday I have eaten a good cake (6)
Even if a more detailed discussion appears in the
fifth section of this paper, it is worth noting
here three points:
- most native English speakers will probably never
make such errors, but, firstly, they could easily
be made by non-native speakers and, secondly, at
least the error exemplified in (4) could result
from a typing error
- errors of that kind are more frequent in Italian,
since it is richly inflectional
- even if the first and third type of errors can be
(more or less) easily handled by means of relaxa
tion techniques (Kwasny &amp; Sondheimer 81), this is
not the case for ordering errors; this is due to
the fact that the agreement and tense constraints
are expressed &amp;quot;explicitly&amp;quot; in the grammar (e.g.
by an augmentation), whereas the order is specifi
ed implicitly (i.e. rigidly embodied in the gram
mar itself).
The analysis of the problems mentioned in this
section, together with some other considerations
that are not worth being discussed extensively here
(regarding, for instance, garden paths) led us to
the design of a formalism for representing the syn
tactic knowledge that splits it into two levels.
The first level contains a set of rules that, in
our intention, characterize the meaningful sen
tences. It can be questioned whether rules regard
ing meaning can be considered as syntactic rules.
Our opinion is that the syntactic categories asso
ciated with natural language words have a strong
semantic bias (see, for a thorough discussion of
this thesis (Lyons 77, Chapt.11)). For this reason,
we defined a set of node types that have to be used
in building the tree representing the syntactic
structure of the sentence. These node types (report
ed in table 1) are associated with the syntactic
categories and the topological constraints that gov
</bodyText>
<page confidence="0.996296">
535
</page>
<table confidence="0.9993108">
REL Relation Verbs, copulas
REF Referent Nouns, pronouns
CONN Connector Prepositions, conjunctions
DET Determiner Articles
demonstrative adjectives,
adjectival question words
MOD Adverbial Adverbs
Modifier
ADJ Adjectival Adjectives
Modifier
</table>
<tableCaption confidence="0.791365">
Table 1 - The node types: The first column contains
</tableCaption>
<bodyText confidence="0.999703317073171">
the name (actual and extended); the sec-
cond one contains the classical syntactic
categories associated with the node type
ern the attachment of nodes constitute the basic
filter which selects the &amp;quot;meaningful&amp;quot; fragments of
sentence. As an example of this kind of constraints,
it is unreasonable to assume that an ADJ node can
be attached elsewhere than a REF node (with the ex-
ception of verbs having a copulative function, e.g.
to be, to seem, to taste etc.). For this reason, in
dependently of its position in the sentence, we can
exclude some kinds of constructs (e.g. ADJ-ADJ at-
tachment) as meaningless.4 When a rule of the first
set is executed it (normally) involves the creation
of a new node (possibly more than one) and its at-
tachment to the syntactic tree which was built up
to that time.
Because of the limited knowledge used to hypo-
thesize the attachment point, it can often happen
that the parser made the wrong choice. Such an er-
ror can be detected by using two different knowledge
sources: higher-level syntactic constraints and se-
mantics. The first of them contains the rules that
define the well-formedness of sentences (in partic-
ular gender-number agreements rules and ordering
rules) whereas the second knowledge source tells
whether an attachment is semantically acceptable
(of course, even if a REF-ADJ attachment is consis
tent with the topological constraints, not all ad-
jectives can be used to qualify a given noun). The
semantic checks are done accessing a semantic net
organized in two levels: the first of them (exter-
nal) concerns the acceptable surface structures (e.
g. case frames for verbs), whilst the second one
(internal) is concerned with the actual semantics
of the domain (e.g. subsetting among classes).
it must be noted that the rules embodying these
constraints are expressed in procedural form.Even
if the lack of a declarative representation makes
more difficult the design and the maintenance of
the rules, they are made more efficient in terms
of execution time by taking into account the con
text where the word occurs (involving a limited
one word lookahead).
Because of the frequency of this kind of wrong hypo
thesization, an effective computational tool must
be used to restructure the tree: this tool consists
in what we called &amp;quot;natural changes&amp;quot;, which are sim-
ple pattern-action rules able to move around con-
stituents; their purpose is to provide the parser
with an alternative hypothesis when a given one has
failed. Whereas the natural changes are triggered
the same way both in case the inconsistency is syn-
tactic and semantic, different courses of action
take place if the changes cannot produce any accept
able alternative hypothesis: if the error is of syn
tactic type than the first hypothesis is maintained
but a warning message is sent to the user; if the
error is semantic, then the current interpretation
of the fragment is considered unacceptable and, in
case one or more choice points were previously met,
the parser backtracks, otherwise the analysis fails.
More details about the use of backup, as well as
about other topics related with the parsing strate-
gy, can be found in (Lesmo &amp; Torasso 83).
A problem which must be faced when a natural
change is stimulated is the choice of the best in-
terpretation. Let us suppose that an agreement be-
tween an adjective and a noun is violated. In this
case the natural change MOVE UP tries to attach the
adjective to a REF node which is at a higher level
with respect to the REF which the adjective is cur
rently attached to. The new attachment stimulates
the rules of the second set (that is the rules veri
fying the agreement and the word ordering) and the
semantic ones. It is possible that the semantic
rules signal that the new attachment is not admissi
ble from a semantic point of view. At this point,
if no alternative attachment is possible, the sys-
tem has to consider the first interpretation as the
best one since it violates only the &amp;quot;weak&amp;quot; syntac-
tic constraints.
</bodyText>
<sectionHeader confidence="0.55886" genericHeader="method">
ELLIPSIS
</sectionHeader>
<bodyText confidence="0.999732">
&amp;quot;Ellipsis&amp;quot; is a greek word (elleipsis) roughly
corresponding to &amp;quot;lack, omission&amp;quot;, that is used, to
take a dictionary definition, to stand for &amp;quot;omis-
sion of one or more words that can easily be sub-
sumed&amp;quot;. Even if all components of the definition
are fundamental, we want to stress the presence of
the adverb &amp;quot;easily&amp;quot;. It is consistent with the ob-
servation that, whereas other phenomena occurring
in natural language (e.g. garden path) require a
conscious effort in the listener, elliptical sen-
tences are understood without any difficulty. On
the other hand, most current grammatical formalisms
are not able to account for this ease in understand
ing ellipsis; it must be noted the importance that
is often laid on the ability to decide as soon as
possible what is the allowable form of a given cone
stituent (Buchenko et al. 83). This is due to the
necessityof triggering in advance a suitable re-
</bodyText>
<page confidence="0.996298">
536
</page>
<bodyText confidence="0.999966181818182">
stricted set of grammar rules, in our case this is
not required: the first-level rules will work the
same way independently of the global context where
a given word or constituent occurs (this is not
true for &amp;quot;local&amp;quot; contexts in the current version of
the system: see note 1); the consistency with the .
rules which govern the construction of well-formed
sentences will be tested afterwards. This is parti-
cularly useful for handling elliptical fragments.
Let&apos;s see through a pair of examples what is the be
haviour of the parser in such sistuations.
</bodyText>
<equation confidence="0.9673005">
Example (1) is reported below:
John (1)
</equation>
<bodyText confidence="0.9980824">
The rules associated with the category &amp;quot;noun&amp;quot; (note
that the first-level rules are grouped in packets
associated with syntactic categories), in case the
analysis is at the beginning of the sentence, cause
the building of the sentence reported below:
</bodyText>
<equation confidence="0.77960175">
REL
.11
CONN
JOHN IN
</equation>
<bodyText confidence="0.99880175">
When the end of the sentence in encountered, the
structure is recognized as being incomplete and a
pattern matching procedure applied to any preceding
question can reconstruct its actual meaning. What
must be noticed is that the first-level syntactic
rules used to analyze the fragment are exactly the
same that are used to analyze complete and correct
sentences.
</bodyText>
<sectionHeader confidence="0.894931" genericHeader="method">
CONJUNCTIONS
</sectionHeader>
<bodyText confidence="0.999990045454546">
The kind of processing that occurs in handling
conjunctions requires the introduction of rather
different constraints. The first interpretation pro
duced for sentences 3) and 4) after the fragment
&amp;quot;John loves Mary and Susy&amp;quot; has been analyzed is re-
ported in fig. la. This interpretation is confirmed
when the end of sentence 3) is encountered (so that
the final structure is the one shown in fig. la).
On the contrary, when the name &amp;quot;Fred&amp;quot; is scanned in
sentence 4), it cannot be attached to &amp;quot;Susy&amp;quot; (exclu
ding the possibility that &amp;quot;Fred&amp;quot; is her family name)
and the attempt to move it up to &amp;quot;loves&amp;quot; causes a
semantic error (three unmarked case for &amp;quot;love&amp;quot;). At
this point another &amp;quot;natural change&amp;quot; is triggered,
which handles conjunctions. It tries to move up the
&amp;quot;and&amp;quot; node, producing the structure of fig.lb which
is accepted as the correct one. Note, however, that
this kind of natural change is much more complex
than the standard ones. For example, in the report-
ed examples two new nodes have to be built: the emp
ty REL node (this is done easily since only two
nodes of the same type can be connected via &amp;quot;and&amp;quot;)
</bodyText>
<sectionHeader confidence="0.34926" genericHeader="method">
MOM
</sectionHeader>
<bodyText confidence="0.966820611111111">
Fig.1 - The parse trees for sentence 3) (fig.la)
and sentence 4 (fig.lb).
and the &amp;quot;UNMARKED&amp;quot; connection (for which an explic-
it request of creation and attachment must be is-
sued).
A final observation regards the fact that the
parser assumes that the first acceptable interpre-
tation is the right one. This implies that a sen-
tence of the form (see EX4 in Huang 83, pag.82)
&amp;quot;The man with the telescope and the woman with the
umbrella kicked the ball&amp;quot; would be interpreted as
&amp;quot;The man with the telescope and with the woman with
the umbrella kicked the ball&amp;quot;, that is not the most
natural interpretation for a human listener. How-
ever, Italian always expresses explicitly the num-
ber of the verb (i.e. plural in this case), so that
the Italian translation of the sentence would be
analyzed correctly.
</bodyText>
<sectionHeader confidence="0.71115" genericHeader="method">
SYNTACTIC ERRORS
</sectionHeader>
<bodyText confidence="0.9371615">
The system tolerates and possibly recovers the
following different kinds of errors:
- lexical errors
- agreement errors
- errors in the ordering of the constituents
- extra cases
(note that only the second and the third kind of
errors are actual syntactic errors).
As regards the errors at the lexical level,
they are detected when the morphological analyzer
tries to decompose a given word in &amp;quot;root + suffix&amp;quot;
form. When no decomposition is possible or none of
the obtained roots occurs in the dictionary, the
system asks the user about the possibility that the
input word is mispelled. In the affirmative case,
the user can retype the word, whereas in the oppo-
site case the system asks the user to provide it
with some pieces of information such as the syntac
tic category of the word, its normalized form (i.e.
its root), the gender, the number, etc.; moreover
the system asks what semantic object the word re-
fers to. In this way the analysis of the sentence
can go on and possibly an interpretation is con-
structed. However, it has to be pointed out that
the information provided by the user during the
AND
</bodyText>
<page confidence="0.959192">
537
</page>
<bodyText confidence="0.984073780701755">
analysis of the sentence is not always sufficient
for the system to complete the analysis. In fact,
the current version of the system has not the capa-
bility of restructuring the semantic net dynamical-
ly, so that the system can continue the analysis
only when the semantic object denoted by the un-
known word is already present in the net.
As regards &amp;quot;agreement errors&amp;quot; there is a large
variety of error types grouped under this label:
a) a first kind refers to the agreement in number
and gender between the noun and the determiner
and between the noun and the adjectives. It is
worth noticing that such kind of errors is un-
common in Italian, because the suffixes for male
and female and for singular and plural are in
many cases quite different.
b) A slightly more frequent error concerns the a-
greement in number, gender and person between
the subject and the verb. Since in Italian the
suffixes indicating the different persons of the
verb, its tense and mood are quite different,
people whose mother tongue is Italian usually do
not make this kind of mistake.
c) Another kind of agreement refers to the relation
ships existing between the moods and the tenses
of the verbs occurring in the main sentences and
its subordinates. The rules, which are quite corn
plex since they derive from the &amp;quot;consecutio tem-
porum&amp;quot; of Latin, are often violated so that this
kind of error must be tolerate by the system. In
this case the procedure which has the task of
verifying the agreement emits a warning message
when the rules are violated, but, contrarily to
cases a) and b), it does not try to restructure
the parse tree via &amp;quot;natural changes&amp;quot;, since in
most cases no alternative interpretation exists.
The framework we have provided is particularly
useful for treating errors in the ordering of the
constituents, in fact the order is checked only
when a given sentence (possibly a subordinate) has
been completed. This happens when the REL node that
heads the clause (main or subordinate) is closed,
that is a punctuation mark is encountered or a new
node is attached to a node which is (in the parse
tree) at a level higher than the REL currently ana-
lized. Before stimulating the ordering rules, the
system checks that the case frame of REL has been
correctly filled, that is all the cases attached to
REL are compatible with the head and among them.
Just in this case a set of rules is activated de-
pending on the sentence type (it is apparent that
the constituent order is different in a declarative,
interrogative or relative clause). Each rule repre-
sents a legitimate ordering of the constituents and
the rules are ordered in decreasing degree of ac-
ceptability. The rules are matched in turn against
the actual case frame of the verb acting as head of
the clause under examination; in case no rule
matches, a warning is issued to signal the user
that something has gone wrong in the ordering; any-
way the interpretation of the clause obtained by ac
cessing the semantic net is maintained and the ana-
lysis goes on if the entire sentence has not yet
been scanned. A similar (but simpler) processing oc
curs for a REF node with respect to the adjectives
attached to it.
There are also cases which are more difficult
to treat than the ones involving violations in the
word ordering. In fact, a sentence like &amp;quot;Il giorna-
le lo ha comprato Giovanni stamattina&amp;quot; (literally
&amp;quot;The newspaper it has bought John this morning&amp;quot;) in
volves not only word order violations (the syntac-
tic object occurs in the first position in the sen-
tence), but also there is a case denoted by &amp;quot;lo&amp;quot;
(&amp;quot;it&amp;quot;) which duplicates the object. Such sentences
are clearly incorrect from a syntactic point of
view as well as, in principle, from a semantic one
(wrong case frame), but they are perfectly under-
standable and quite frequent because they allow one
to identify as focus of the utterance the object
without passivizing the sentence.
The treatment of such kinds of errors requires
only relatively inexpensive modifications to the
way the semantic net is accessed. It is worth no-
ticing, in fact, that the syntactic object (&amp;quot;il
giornale&amp;quot;) is attached to a REL node which is empty
when this attachment is performed. The semantic and
agreement check procedures are stimulated but are
immediately suspended since the REL node is empty.
Similarly the pronoun &amp;quot;lo&amp;quot; is attached to the REL
and the corresponding check procedures are suspend-
ed. When the REL node has been filled with &amp;quot;compra-
to&amp;quot; the suspended checks are resumed. The semantic
procedure is able, by inspecting the semantic net,
to state that &amp;quot;giornale&amp;quot; may fill the &amp;quot;object&amp;quot; role
so that when the previously suspended semantic
check is executed, it concludes that &amp;quot;lo&amp;quot; (&amp;quot;it&amp;quot;)
cannot be attached to the REL filled with &amp;quot;comprare&amp;quot;
(&amp;quot;buy&amp;quot;) since the object role has already been fil-
led.
Instead of rejecting the current interpreta-
tion by stimulating the natural changes and possi-
bly the backup mechanism, a modification of the par
sing strategy consists in attaching a warning to
the REF node containing the pronoun &amp;quot;lo&amp;quot; and in go-
ing on with the sentence analysis. When the sen-
tence has been completely scanned and, consequently,
it is possible to perform a global check on the ac-
tual case frame of &amp;quot;comprare&amp;quot;, the semantic proce-
dure decides that &amp;quot;lo&amp;quot; is simply a repetition of
the object and therefore it may be disregarded. In
this way the interpretation of the sentence is pos-
sible, but the warning attached to the REF node con
taming &amp;quot;lo&amp;quot; is output to the user.
</bodyText>
<page confidence="0.996629">
538
</page>
<sectionHeader confidence="0.979306" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.99996597826087">
The paper presents a parsing strategy able to
cope with different kinds of syntactic ill-formed
ness: ellipsis, conjunctions, syntactic errors. Some
examples are reported to show that the adopted for
malism allows the parser to analyse ill-formed fra&amp;
ments without substantial changes to the rules used
to analyse correct sentences.
However, some problems still deserve further
attention. First of all, in case of ill-formed sen
tences it is often possible to assign more than one
interpretation to the sentence (e.g. in &amp;quot;The boy
love the girl&amp;quot; the subject can be considered plural
- missing &amp;quot;s&amp;quot; in &amp;quot;boy&amp;quot; - or singular - missing &amp;quot;s&amp;quot;
in &amp;quot;love&amp;quot;); this can also happen for correct sen
tences (see the last example in the section on
CONJUNCTIONS). The current version of the system
should be enhanced both by taking into account con
textual information (which could be useful in the
first case) and by weighing in some way the output
of the semantic component (which, today, is categor
ical: yes or no).
As regards the context, the experiments we made
on the parser refer to isolated sentences, so that
the &amp;quot;pattern matching&amp;quot; procedure we referred to in
the section on ELLIPSIS (see the example &amp;quot;John&amp;quot;) is
neither implemented nor designed. Our belief is that
the two components (pattern matcher and parser) are
quite independent each other, but we are planning
to address also issues connected with discourse
analysis.
Last but not least, some problems are more
strictly connected with the basic parser design.
Some English sentences break a locality principle
embodied in the first-level syntactic rules. An
example is given by &amp;quot;What architect do you know who
likes the balalaika&amp;quot; (see Winograd 83, pag.136). We
are currently studying this problem, whose solution
will involve a change in the final representation as
well as in the rule packets.
The current version of the parser, that runs
on a VAX-11/780 under the UNIX operating system and
is implemented in FRANZ LISP, includes the mecha
nisms for detecting and recovering the lexical,
agreement, and word ordering errors, whereas the
&amp;quot;extra cases&amp;quot;, in the sense explained above, are
currently being implemented.
</bodyText>
<sectionHeader confidence="0.992956" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999732125">
Bachenko J., Hindle D., Fitzpatrick: Constraining
a Deterministic Parser. Proc. AAAI-83 (1983)8-11.
Charniak E.:Six Topics in Search of a Parser: An
Overview of Al Language Research. Proc. 7th IJCAI
Vancouver B.C. (1981), 1074-1087.
Huang X.: Dealing with Conjunctions in a Machine
Translation Environment. Proc. let Conf. ACL-Eu
rope, Pisa (1983), 81-85.
Granger R.H.: Scruffy Text Understanding: Design
and Implementation of &amp;quot;Tolerant&amp;quot; Understanders.
Proc. 20th ACL, Toronto (1982), 157-160.
Kwasny S.C., Sondheimer N.K.: Relaxation Techniques
for Parsing Grammatically Ill-Formed Input in Nat
ural Language Understanding Systems. AJCL 7
(1981), 99-108.
Lesmo L., Magnani D., Torasso P.: A Deterministic
Analyzer for the Interpretation of Natural Lan-
guage Commands. Proc. 7th IJCAI, Vancouver B.C.
(1981), 440-442.
Lesmo L., Siklossy L., Torasso P.: A Two-Level Net
for Integrating Selectional Restrictions and Se-
mantic Knowledge. Proc. IEEE Int. Conf. on Sys-
tem, Man and Cybernetics, India (1983), 14-18.
Lesmo L., Torasso P.: A Flexible Natural Language
Parser based on a Two-Level Representation of
Syntax, Proc. 1st Conf. ACL-Europe, Pisa (1983).
114-121.
Lesmo L., Siklossy L;, Torasso P.: Semantic and
Pragmatic Processing in FIDO: A Flexible Inter-
face for Database Operations. Accepted for Publi
cation on Information Systems.
Lyons J.: Semantics. Cambridge Univ. Press (1977).
Marcus M.: Building Non-Normative Systems: The
Search for Robustness: An Overview. Proc. 20th
ACL, Toronto (1982), 152.
Weischedel R.M., Sondheimer N.K.: An Improved Heuri
stic for Ellipsis Processing. Proc. 20th ACL,
Toronto (1982), 85-88.
Winograd T.: Language as a Cognitive Process; Vol.1
Syntax. Addison Wesley (1983).
</reference>
<page confidence="0.998625">
539
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.958697">
<title confidence="0.997608">INTERPRETING SYNTACTICALLY ILL-FORMED SENTENCES</title>
<author confidence="0.999202">Leonardo LESMO</author>
<author confidence="0.999202">Pietro TORASSO</author>
<affiliation confidence="0.991832">Dipartimento di Informatica - Universita&apos; di Torino</affiliation>
<address confidence="0.993167">Corso Massimo D&apos;Azeglio 42 - 10125 Torino - ITALY</address>
<abstract confidence="0.998859272727273">The paper discusses three different kinds of syntactic ill-formedness: ellipsis, conjunctions, and actual syntactic errors. It is shown how a new grammatical formalism, based on a two-level repre sentation of the syntactic knowledge is used to cope with ill-formed sentences. The basic control struc ture of the parser is briefly sketched; the paper shows that it can be applied without any substan tial change both to correct and to ill-formed sen tences. This is achieved by introducing a mechanism for the hypothesization of syntactic structures, which is largely independent of the rules defining the well-formedness. On the contrary, the second level of syntactic knowledge embodies those rules and is used to validate the hypotheses emitted by the first level. Alternative hypotheses are obtain ed, when needed, by means of local reorganizations of the parse tree. Sentence fragments are handled by the same mechanism, but in this case the second level rules are used to detect the absence of one (or more) constituents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>J Bachenko</author>
<author>D Hindle</author>
</authors>
<title>Fitzpatrick: Constraining a Deterministic Parser.</title>
<booktitle>Proc. AAAI-83</booktitle>
<pages>1983--8</pages>
<marker>Bachenko, Hindle, </marker>
<rawString>Bachenko J., Hindle D., Fitzpatrick: Constraining a Deterministic Parser. Proc. AAAI-83 (1983)8-11.</rawString>
</citation>
<citation valid="true">
<title>Charniak E.:Six Topics in Search of a Parser: An Overview of Al Language Research.</title>
<date>1981</date>
<booktitle>Proc. 7th IJCAI Vancouver B.C.</booktitle>
<pages>1074--1087</pages>
<marker>1981</marker>
<rawString>Charniak E.:Six Topics in Search of a Parser: An Overview of Al Language Research. Proc. 7th IJCAI Vancouver B.C. (1981), 1074-1087.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
</authors>
<title>Dealing with Conjunctions in a Machine Translation Environment.</title>
<date>1983</date>
<booktitle>Proc. let Conf. ACL-Eu rope,</booktitle>
<pages>81--85</pages>
<location>Pisa</location>
<marker>Huang, 1983</marker>
<rawString>Huang X.: Dealing with Conjunctions in a Machine Translation Environment. Proc. let Conf. ACL-Eu rope, Pisa (1983), 81-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>Scruffy Text Understanding: Design and Implementation of &amp;quot;Tolerant&amp;quot; Understanders.</title>
<date>1982</date>
<booktitle>Proc. 20th ACL,</booktitle>
<pages>157--160</pages>
<location>Toronto</location>
<marker>Granger, 1982</marker>
<rawString>Granger R.H.: Scruffy Text Understanding: Design and Implementation of &amp;quot;Tolerant&amp;quot; Understanders. Proc. 20th ACL, Toronto (1982), 157-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
</authors>
<title>Sondheimer N.K.: Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Nat ural Language Understanding Systems.</title>
<date>1981</date>
<journal>AJCL</journal>
<volume>7</volume>
<pages>99--108</pages>
<marker>Kwasny, 1981</marker>
<rawString>Kwasny S.C., Sondheimer N.K.: Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Nat ural Language Understanding Systems. AJCL 7 (1981), 99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lesmo</author>
<author>D Magnani</author>
</authors>
<title>Torasso P.: A Deterministic Analyzer for the Interpretation of Natural Language Commands.</title>
<date>1981</date>
<booktitle>Proc. 7th IJCAI, Vancouver B.C.</booktitle>
<pages>440--442</pages>
<marker>Lesmo, Magnani, 1981</marker>
<rawString>Lesmo L., Magnani D., Torasso P.: A Deterministic Analyzer for the Interpretation of Natural Language Commands. Proc. 7th IJCAI, Vancouver B.C. (1981), 440-442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lesmo</author>
<author>L Siklossy</author>
</authors>
<title>Torasso P.: A Two-Level Net for Integrating Selectional Restrictions and Semantic Knowledge.</title>
<date>1983</date>
<booktitle>Proc. IEEE Int. Conf. on System, Man and Cybernetics,</booktitle>
<pages>14--18</pages>
<marker>Lesmo, Siklossy, 1983</marker>
<rawString>Lesmo L., Siklossy L., Torasso P.: A Two-Level Net for Integrating Selectional Restrictions and Semantic Knowledge. Proc. IEEE Int. Conf. on System, Man and Cybernetics, India (1983), 14-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lesmo</author>
</authors>
<title>Torasso P.: A Flexible Natural Language Parser based on a Two-Level Representation of Syntax,</title>
<date>1983</date>
<booktitle>Proc. 1st Conf. ACL-Europe,</booktitle>
<pages>114--121</pages>
<location>Pisa</location>
<marker>Lesmo, 1983</marker>
<rawString>Lesmo L., Torasso P.: A Flexible Natural Language Parser based on a Two-Level Representation of Syntax, Proc. 1st Conf. ACL-Europe, Pisa (1983). 114-121.</rawString>
</citation>
<citation valid="false">
<authors>
<author>L Lesmo</author>
<author>L Siklossy</author>
</authors>
<title>Semantic and Pragmatic Processing in FIDO: A Flexible Interface for Database Operations. Accepted for Publi cation on Information Systems.</title>
<marker>Lesmo, Siklossy, </marker>
<rawString>Lesmo L., Siklossy L;, Torasso P.: Semantic and Pragmatic Processing in FIDO: A Flexible Interface for Database Operations. Accepted for Publi cation on Information Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cambridge Univ</author>
</authors>
<title>Marcus M.: Building Non-Normative Systems: The Search for Robustness: An Overview.</title>
<date>1977</date>
<booktitle>Proc. 20th ACL,</booktitle>
<pages>152</pages>
<publisher>Press</publisher>
<location>Toronto</location>
<marker>Univ, 1977</marker>
<rawString>Lyons J.: Semantics. Cambridge Univ. Press (1977). Marcus M.: Building Non-Normative Systems: The Search for Robustness: An Overview. Proc. 20th ACL, Toronto (1982), 152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Weischedel</author>
</authors>
<title>Sondheimer N.K.: An Improved Heuri stic for Ellipsis Processing.</title>
<date>1982</date>
<booktitle>Proc. 20th ACL,</booktitle>
<pages>85--88</pages>
<location>Toronto</location>
<marker>Weischedel, 1982</marker>
<rawString>Weischedel R.M., Sondheimer N.K.: An Improved Heuri stic for Ellipsis Processing. Proc. 20th ACL, Toronto (1982), 85-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Language as a Cognitive Process; Vol.1 Syntax.</title>
<date>1983</date>
<publisher>Addison Wesley</publisher>
<marker>Winograd, 1983</marker>
<rawString>Winograd T.: Language as a Cognitive Process; Vol.1 Syntax. Addison Wesley (1983).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>