<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000126">
<title confidence="0.969446">
Alignment of Multiple Languages for Historical Comparison
</title>
<author confidence="0.915106">
Michael A. Covington
</author>
<affiliation confidence="0.949248">
Artificial Intelligence Center
The University of Georgia
</affiliation>
<address confidence="0.861894">
Athens, GA 30602-7415 U.S.A.
</address>
<email confidence="0.939512">
mcOuga.edu
</email>
<sectionHeader confidence="0.99188" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994">
An essential step in comparative reconstruction
is to align corresponding phonological segments
in the words being compared. To do this, one
must search among huge numbers of potential
alignments to find those that give a good pho-
netic fit. This is a hard computational prob-
lem, and it becomes exponentially more difficult
when more than two strings are being aligned.
In this paper I extend the guided-search align-
ment algorithm of Covington (Computational
Linguistics, 1996) to handle more than two
strings. The resulting algorithm has been im-
plemented in Prolog and gives reasonable results
when tested on data from several languages.
</bodyText>
<sectionHeader confidence="0.989899" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.9820395">
The Comparative Method for reconstructing
languages consists of at least the following steps:
</bodyText>
<listItem confidence="0.966589818181818">
1. Choose sets of words in the daughter lan-
guages that appear to be cognate;
2. Align the phonological segments that ap-
pear to correspond (e.g., skip the [1(] when
aligning German Pali] with English [niy]
&apos;knee&apos;) ;1
3. Find regular correspondence sets (proto-
allophones, Hoenigswald 1950);
4. Classify the proto-allophones into proto-
phonemes with phonological rules (sound
laws).
</listItem>
<bodyText confidence="0.998375555555556">
The results of each step can be used to refine
guesses made at previous steps. For example,
&apos;These phonetic transcriptions may nor may not be
phonemic. Because of the way the Comparative Method
works, synchronic allophony is, in general, factored out
along with diachronic allophony as the reconstruction
proceeds.
a regular correspondence, once discovered, can
be used to refine one&apos;s choice of alignments and
even putative cognates.
Parts of the Comparative Method have been
computerized by Frantz (1970), Hewson (1974),
Wimbish (1989), and Lowe and Mazaudon
(1994), but none of them have tackled the align-
ment step. Covington (1996) presents a work-
able alignment algorithm for comparing two lan-
guages. In this paper I extend that algorithm to
handle more than two languages at once.
</bodyText>
<sectionHeader confidence="0.986619" genericHeader="introduction">
2 Multiple-string alignment
</sectionHeader>
<bodyText confidence="0.97320508">
The alignment step is hard to automate be-
cause there are too many possible alignments
to choose from. For example, French le [la] and
Spanish el [el] can be lined up at least three
ways:
el el - -el
lo - la la-
Of these, the second is etymologically correct,
and the third would merit consideration if one
did not know the etymology.
The number of alignments rises exponentially
with the length of the strings and the number
of strings being aligned. Two ten-letter strings
have anywhere from 26,797 to 8,079,453 differ-
ent alignments depending on exactly what align-
ments are considered distinct (Covington 1996,
Covington and Canfield 1996). As for multiple
strings, if two strings have A alignments then
n strings have roughly An-1 alignments, assum-
ing the alignments are generated by aligning the
first two strings, then aligning the third string
against the second, and so forth. In fact, the
search space isn&apos;t quite that large because some
combinations are equivalent to others, but it is
clearly too large to search exhaustively.
</bodyText>
<page confidence="0.999576">
275
</page>
<tableCaption confidence="0.859989">
Table 1: Evaluation metric used by Covington
(1996).
</tableCaption>
<bodyText confidence="0.993046166666667">
Fortunately the comparative linguist is not
looking for all possible alignments, only the ones
that are likely to manifest regular sound corre-
spondences — that is, those with a reasonable
degree of phonetic similarity. Thus, phonetic
similarity can be used to constrain the search.
</bodyText>
<sectionHeader confidence="0.900884" genericHeader="method">
3 Applying an evaluation metric
</sectionHeader>
<bodyText confidence="0.99599325">
The phonetic similarity criterion used by Cov-
ington (1996) is shown in Table 1. It is obviously
just a stand-in for a more sophistiCated, per-
haps feature-based, system of phonology. The
algorithm computes a &amp;quot;badness&amp;quot; or &amp;quot;penalty&amp;quot; for
each step (column) in the alignment, summing
the values to judge the badness of the whole
alignment, thus:
</bodyText>
<table confidence="0.91398">
1
1 a
100 + 100 = 200
1
- 1 a
50 + 0 + 50 = 100
</table>
<bodyText confidence="0.9995486">
The alignment with the lowest total badness is
the one with the greatest phonetic similarity.
Note that two separate skips count exactly the
same as one complete mismatch; thus the align-
ments
</bodyText>
<equation confidence="0.803727">
-e
1 1 -
</equation>
<bodyText confidence="0.999900181818182">
are equally valued. In fact, a &amp;quot;no-alternating-
skips rule&amp;quot; prevents the second one from being
generated; deciding whether [e] and [1] corre-
spond is left for another, unstated, part of the
comparison process. I will explain below why
this is not satisfactory.
Naturally, the alignment with the best overall
phonetic similarity is not always the etymolog-
ically correct one, although it is usually close;
we are looking for a good phonetic fit, not nec-
essarily the best one.
</bodyText>
<sectionHeader confidence="0.880609" genericHeader="method">
4 Generalizing to three or more
languages
</sectionHeader>
<bodyText confidence="0.9944113">
When a guided search is involved, aligning
strings from three or more languages is not sim-
ply a matter of finding the best alignment of
the first two, then adding a third, and then a
fourth, and so on. Thus, an algorithm to align
two strings cannot be used iteratively to align
more than two.
The reason is that the best overall alignment
of three or more strings is not necessarily the
best alignment of any given pair in the set. Fox
(1995:68) gives a striking example, originally
from Haas (1969). The best alignment of the
Choctaw and Cree words for &apos;squirrel&apos; appears
to be:
Choctaw f an i
Cree -ilu
Here the correspondence [a]:[i] is problematic.
Add the Koasati word, though, and it becomes
clear that the correct alignment is actually:
Choctaw
Koasati
Cree
Any algorithm that started by finding the best
alignment of Choctaw against Cree would miss
this solution.
A much better strategy is to evaluate each col-
umn of the alignment (I&apos;ll call it a &amp;quot;step&amp;quot;) before
generating the next column. That is, evaluate
the first step,
and then the second step,
</bodyText>
<figure confidence="0.983848043478261">
Badness
Conditions
Exact match of consonants or glides
Exact match of vowels (nonzero so the
aligner will prefer to match consonants,
given a choice)
Match of 2 vowels that differ only in
length, or [4 and [y], or [u1 and [w]
Match of 2 dissimilar vowels
Match of 2 dissimilar consonants
Match of 2 unrelated segments
Skip preceded by another skip in the
same string
Skip not preceded by another skip in
the same string
0
5
10
30
60
100
40
50
</figure>
<page confidence="0.992751">
276
</page>
<bodyText confidence="0.983531666666667">
and so on. At each step, the total badness is
computed by comparing each segment to all of
the other segments. Thus the total badness of
</bodyText>
<equation confidence="0.825839">
a
is badness(a,b) + badness(b,c) + badness(a,c).
</equation>
<bodyText confidence="0.9825585">
That way, no string gets aligned against another
without considering the rest of the strings in the
set.
Another detail has to do with skips. Empiri-
cally, I found that the badness of
comes out too high if computed as
badness(f,p) + badness(p,-) + badness(f,-);
that is, the algorithm is too reluctant to take
skips. The reason, intuitively, is that in this
alignment step, there is really only one skip,
not two separate skips (one skipping VI and
one skipping [pp. This becomes even more
apparent when more than three strings are
being aligned.
Accordingly, when computing badness I count
each skip only once (assessing it 50 points),
then ignore skips when comparing the segments
against each other. I have not implemented the
rule from Covington (1996) that gives a reduced
penalty for adjacent skips in the same string to
reflect the fact that affixes tend to be contigu-
ous.
</bodyText>
<sectionHeader confidence="0.889653" genericHeader="method">
5 Searching the set of alignments
</sectionHeader>
<bodyText confidence="0.939020894736842">
The standard way to find the best alignment of
two strings is a matrix-based technique known
as dynamic programming (Ukkonen 1985, Wa-
terman 1995). However, dynamic program-
ming cannot accommodate rules that look ahead
along the string to recognize assimilation or
metathesis, a possibility that needs to be left
open when implementing comparative recon-
struction. Additionally, generalization of dy-
namic programming to multiple strings does not
entirely appear to be a solved problem (cf. Ke-
cecioglu 1993).
Accordingly, I follow Covington (1996) in re-
casting the problem as a tree search. Consider
the problem of aligning Eel] with Rai. Coving-
ton (1996) treats this as a process that steps
through both strings and, at each step, per-
forms either a &amp;quot;match&amp;quot; (accepting a character
from both strings), a &amp;quot;skip-1&amp;quot; (skipping a char-
acter in the first string), or a &amp;quot;skip-2&amp;quot; (skipping
a character in the second string). That results
in the search tree shown in Fig. 1 (ignoring Cov-
ington&apos;s &amp;quot;no-alternating-skips rule&amp;quot;).
The search tree can be generalized to multiple
strings by breaking up each step into a series
of operations, one on each string, as shown in
Fig. 2. Instead of three choices, match, skip-1,
and skip-2, there are really 2 x 2: accept or skip
on string 1 and then accept or skip on string
2. One of the four combinations is disallowed —
you can&apos;t have a step in which no characters are
accepted from any string.
Similarly, if there were three strings, there
would be three two-way decisions, leading to
eight (= 23) states, one of which would be dis-
allowed. Using search trees of this type, the de-
cisions necessary to align any number of strings
can be strung together in a satisfactory way.
</bodyText>
<sectionHeader confidence="0.941272" genericHeader="method">
6 Alternating skips
</sectionHeader>
<equation confidence="0.703574333333333">
Covington (1996) considers the alignments
-e
1 1 -
</equation>
<bodyText confidence="0.956253058823529">
equivalent and generates only the first of them,
leaving it to some later step in the comparison
process to decide whether [e] and [1] really cor-
respond. The rule is:
NO-ALTERNATING-SKIPS RULE: If there is
a skip in one string, there cannot be a skip
in the other string at the next step.
Although this tactic narrows the search space,
I do not think this is linguistically satisfactory;
after all, aligning [e] with [1] and skipping them
in tandem are quite different linguistic claims.
Consider for example the final segment of Span-
ish [dos] and Italian [due] `two&apos;; it is correct to
skip the [s] and the [e] in tandem because they
come from different Latin endings. It is not his-
torically correct to pair [s] with [e] in a corre-
spondence set.
</bodyText>
<page confidence="0.996165">
277
</page>
<figureCaption confidence="0.981045">
Figure 1: Part of a 3-way-branching search tree for generating potential alignments (Covington
1996, ignoring no-alternating-skips rule).
</figureCaption>
<subsubsectionHeader confidence="0.706961">
Processing Processing Processing Processing Processing
</subsubsectionHeader>
<bodyText confidence="0.935509">
string 1 string 2 string 1 string 2 string 1...
</bodyText>
<sectionHeader confidence="0.845814" genericHeader="method">
I I
</sectionHeader>
<bodyText confidence="0.517752">
Step 1 Step 2 Step 3...
</bodyText>
<figureCaption confidence="0.9992225">
Figure 2: Search tree factored into 2-way branchings with a disallowed state at each step. This tree
generalizes to handle more than 2 strings.
</figureCaption>
<figure confidence="0.998571">
Situations where only
Match [el all one move is possible
Skip on
string 2
[e -] Skip on [1 -]
e -1
1 0 string 2
[V] Skip on e I -
sting 1 [1-3
Start []
Match [
Skip on
string 1
Analogous
to above
Skip on
string 2
[e l
l al
fell ] [e -
1- Skip 1 -
Accept
Skip
Start H
Disallowed (each step must accept at least 1 character)
Accept
Skip
</figure>
<page confidence="0.992837">
278
</page>
<bodyText confidence="0.993088">
Also, the no-alternating-skips rule does not
generalize easily to multiple strings. I therefore
replace it with a different restriction:
</bodyText>
<figure confidence="0.287065888888889">
ORDERED-ALTERNATING-SKIPS RULE: A
skip can be taken in strings i and j in suc-
cessive steps only if i &lt; j.
That lets us generate
- e (String 1)
1 - (String 2)
but not
e -
-1
</figure>
<listItem confidence="0.8219094">
which is undeniably equivalent. It also ensures
that there is only one way of skipping several
consecutive segments; we get
- - - a b c
de f- - -
</listItem>
<tableCaption confidence="0.9369595">
Table 2: Some alignments found by the proto-
type program.
</tableCaption>
<equation confidence="0.955920384615385">
Spanish/It alian/French &apos;three&apos;:
tr-es
t r - e -
t rwa-
Spanish/Italian/French &apos;four&apos;:
kwa- t ro
kwat t ro
k- a- tr -
Spanish/Italian/French &apos;five&apos;:
Oink- o
c i nkwe
s - k - -
Koasati/Cree/Choctaw &apos;squirrel&apos;:
</equation>
<bodyText confidence="0.935857875">
ip- lu
i - - 1 u
- f an i
but not
-a-b-c a b c - - English three,2 the algorithm finds its &amp;quot;best&amp;quot;
d-e-f- ---def alignment,
or numerous other equivalent combinations of
skips.
</bodyText>
<sectionHeader confidence="0.802302" genericHeader="method">
7 Pruning the search
</sectionHeader>
<bodyText confidence="0.999906586206897">
The goal of the algorithm is, of course, to gen-
erate not the whole search tree, but only the
parts of it likely to contain the best alignments,
thereby narrowing the intractably large search
space into something manageable.
Following Covington (1996), I implemented
a very simple pruning strategy. The program
keeps track of the badness of the best complete
alignment found so far. Every branch in the
search tree is abandoned as soon as its total bad-
ness exceeds that value. Thus, bad alignments
are abandoned when they have only partly been
generated.
A second part of the strategy is that the com-
puter always tries matches before it tries skips.
As a result, if not much material needs to be
skipped, a good alignment is found very quickly.
For example, three four-character strings have
10,536 alignments (generated my way), but
when comparing Spanish tres, French trois, and
tr-es
t r w a -
Or- iy
after completing only ten other alignments, al-
though it also pursues several hundred branches
of the tree part of the way. (Here the match of [s]
with [y1 is problematic, but the computer can&apos;t
know that; it also finds a number of alternative
alignments.)
</bodyText>
<sectionHeader confidence="0.997324" genericHeader="conclusions">
8 Results and evaluation
</sectionHeader>
<bodyText confidence="0.996189333333333">
The algorithm has been prototyped in LPA Pro-
log, and Table 2 shows some of the alignments
it found. None of these took more than five sec-
onds on a 133-MHz Pentium, and the Prolog
program was written for versatility, not speed.
As comparative linguists know, the alignment
that gives the best phonetic fit (by any crite-
rion) is not always the etymologically correct
one. This is evident with my algorithm. For
</bodyText>
<footnote confidence="0.888726333333333">
2Admittedly an odd set to compare because of the
different depth of branching, but they are cognates and
each has four segments.
</footnote>
<page confidence="0.997013">
279
</page>
<bodyText confidence="0.990161772727273">
instance, comparing the Sanskrit, Greek, and
Latin words for &apos;field,&apos; the algorithm finds the
correct alignment,
ager - -
ag- ros
aj-ras (badness = 365)
but then discards it in favor of a seemingly bet-
ter alignment:
ager- -
ag- ros
a- jras (badness = 345)
It doesn&apos;t know, of course, that [gl:[j] is a pho-
netically probable correspondence.
Worse, occasionally the present algorithm
doesn&apos;t consider the etymologically correct
alignment at all because something that looks
better has already been found. For example,
taking the Avestan, Greek, and Latin words for
&apos;100&apos;, the algorithm settles on
- -sat am
hekat on
ken- tum (badness 610)
without ever considering the etymologically cor-
rect alignment:
--sa- tam
heka- ton
- -kent um (badness 690)
The penalties for skips may still be too high
here, but the real problem is, of course, that the
algorithm is looking for the one best alignment,
and that&apos;s not what comparative reconstruction
needs. Instead, the computer should prune the
search tree less eagerly, pursuing any alignment
whose badness is, say, no more than 120% of
the lowest found so far, and delivering all solu-
tions that are reasonably close to the best one
found during the entire procedure. Indeed, the
availability of multiple potential alignments is
the keystone of Kay&apos;s (1964) proposal to imple-
ment the Comparative Method, which could not
be implemented at the time Kay proposed it be-
cause of the lack of an efficient search algorithm.
The requisite modification is easily made and I
plan to pursue it in subsequent work.
</bodyText>
<sectionHeader confidence="0.996448" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9991559375">
Covington, Michael A. (1996) An algorithm to
align words for historical comparison. Com-
putational linguistics 22:481-496.
Covington, Michael A., and Canfield, E. Rodney
(1996) The number of distinct alignments of
two strings. Unpublished manuscript, Univer-
sity of Georgia.
Fox, Anthony (1995) Linguistic reconstruction:
an introduction to theory and method. Oxford:
Oxford University Press.
Frantz, Donald G. (1970) A PL/1 program to
assist the comparative linguist. Communica-
tions of the ACM 13:353-356.
Haas, Mary R. (1969) The prehistory of lan-
guages. The Hague: Mouton.
Hewson, John (1974) Comparative reconstruc-
tion on the computer. John M. Anderson and
Charles Jones, eds., Historical linguistics I:
syntax, morphology, internal and comparative
reconstruction, 191-197. Amsterdam: North
Holland.
Hoenigswald, Henry (1950) The principal step
in comparative grammar. Language 26:357-
364. Reprinted in Martin Joos, ed., Readings
in Linguistics I, 4th ed., 298-302. Chicago:
University of Chicago Press, 1966.
Kay, Martin (1964) The logic of cognate rcog-
nition in historical linguistics. (Memorandum
RM-4224-PR.) Santa Monica: The RAND
Corporation.
Kececioglu, John (1993) The maximum weight
trace problem in multiple sequence alignment.
Combinatorial pattern matching: 4th annual
symposium, ed. A. Apostolico et al., 106-119.
Berlin: Springer.
Lowe, John B., and Mazaudon, Martine (1994)
The Reconstruction Engine: a computer im-
plementation of the comparative method.
Computational Linguistics 20:381-417.
Ukkonen, Esko (1985) Algorithms for approxi-
mate string matching. Information and Con-
trol 64:100-118.
Waterman, Michael S. (1995) Introduction to
computational biology: maps, sequences and
genomes. London: Chapman &amp; Hall.
Wimbish, John S. (1989) WORDSURV: a pro-
gram for analyzing language survey word lists.
Dallas: Summer Institute of Linguistics.
</reference>
<page confidence="0.997172">
280
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000654">
<title confidence="0.99513">Alignment of Multiple Languages for Historical Comparison</title>
<author confidence="0.999813">Michael A Covington</author>
<affiliation confidence="0.999753">Artificial Intelligence Center The University of Georgia</affiliation>
<address confidence="0.880198">Athens, GA 30602-7415 U.S.A.</address>
<email confidence="0.999796">mcOuga.edu</email>
<abstract confidence="0.966624378947369">An essential step in comparative reconstruction is to align corresponding phonological segments in the words being compared. To do this, one must search among huge numbers of potential alignments to find those that give a good phonetic fit. This is a hard computational problem, and it becomes exponentially more difficult when more than two strings are being aligned. In this paper I extend the guided-search alignalgorithm of Covington to handle more than two strings. The resulting algorithm has been implemented in Prolog and gives reasonable results when tested on data from several languages. 1 Background The Comparative Method for reconstructing languages consists of at least the following steps: 1. Choose sets of words in the daughter languages that appear to be cognate; 2. Align the phonological segments that appear to correspond (e.g., skip the [1(] when aligning German Pali] with English [niy] &apos;knee&apos;) ;1 3. Find regular correspondence sets (protoallophones, Hoenigswald 1950); 4. Classify the proto-allophones into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. alignment The alignment step is hard to automate because there are too many possible alignments choose from. For example, French and can be lined up at least three ways: el el - -el la la- Of these, the second is etymologically correct, and the third would merit consideration if one did not know the etymology. The number of alignments rises exponentially with the length of the strings and the number of strings being aligned. Two ten-letter strings have anywhere from 26,797 to 8,079,453 different alignments depending on exactly what alignments are considered distinct (Covington 1996, Covington and Canfield 1996). As for multiple strings, if two strings have A alignments then strings have roughly alignments, assuming the alignments are generated by aligning the first two strings, then aligning the third string against the second, and so forth. In fact, the search space isn&apos;t quite that large because some combinations are equivalent to others, but it is clearly too large to search exhaustively. 275 Table 1: Evaluation metric used by Covington (1996). Fortunately the comparative linguist is not looking for all possible alignments, only the ones that are likely to manifest regular sound correspondences — that is, those with a reasonable degree of phonetic similarity. Thus, phonetic similarity can be used to constrain the search. 3 Applying an evaluation metric The phonetic similarity criterion used by Covington (1996) is shown in Table 1. It is obviously a stand-in for a sophistiCated, perhaps feature-based, system of phonology. The algorithm computes a &amp;quot;badness&amp;quot; or &amp;quot;penalty&amp;quot; for each step (column) in the alignment, summing the values to judge the badness of the whole alignment, thus: 1 1 a 100 + 100 = 200 1 - 1 a 50 + 0 + 50 = 100 The alignment with the lowest total badness is the one with the greatest phonetic similarity. Note that two separate skips count exactly the same as one complete mismatch; thus the alignments -e 1 1 are equally valued. In fact, a &amp;quot;no-alternatingskips rule&amp;quot; prevents the second one from being generated; deciding whether [e] and [1] correspond is left for another, unstated, part of the comparison process. I will explain below why this is not satisfactory. Naturally, the alignment with the best overall phonetic similarity is not always the etymologically correct one, although it is usually close; are looking for a fit, not necthe 4 Generalizing to three or more languages When a guided search is involved, aligning strings from three or more languages is not simply a matter of finding the best alignment of the first two, then adding a third, and then a fourth, and so on. Thus, an algorithm to align two strings cannot be used iteratively to align more than two. The reason is that the best overall alignment of three or more strings is not necessarily the best alignment of any given pair in the set. Fox (1995:68) gives a striking example, originally from Haas (1969). The best alignment of the Choctaw and Cree words for &apos;squirrel&apos; appears to be: Choctaw f an i Cree -ilu Here the correspondence [a]:[i] is problematic. Add the Koasati word, though, and it becomes clear that the correct alignment is actually: Choctaw Koasati Cree Any algorithm that started by finding the best alignment of Choctaw against Cree would miss this solution. A much better strategy is to evaluate each column of the alignment (I&apos;ll call it a &amp;quot;step&amp;quot;) before generating the next column. That is, evaluate the first step, and then the second step, Badness Conditions Exact match of consonants or glides Exact match of vowels (nonzero so the aligner will prefer to match consonants, given a choice) Match of 2 vowels that differ only in length, or [4 and [y], or [u1 and [w] Match of 2 dissimilar vowels Match of 2 dissimilar consonants Match of 2 unrelated segments Skip preceded by another skip in the same string Skip not preceded by another skip in the same string 0 5 10 30 60 100 40 50 276 and so on. At each step, the total badness is computed by comparing each segment to all of the other segments. Thus the total badness of a + badness(a,c). That way, no string gets aligned against another without considering the rest of the strings in the set. Another detail has to do with skips. Empirically, I found that the badness of comes out too high if computed as badness(f,p) + badness(p,-) + badness(f,-); that is, the algorithm is too reluctant to take skips. The reason, intuitively, is that in this step, there is really only not two separate skips (one skipping VI and one skipping [pp. This becomes even more apparent when more than three strings are being aligned. Accordingly, when computing badness I count each skip only once (assessing it 50 points), then ignore skips when comparing the segments against each other. I have not implemented the rule from Covington (1996) that gives a reduced penalty for adjacent skips in the same string to reflect the fact that affixes tend to be contiguous. 5 Searching the set of alignments The standard way to find the best alignment of two strings is a matrix-based technique known as dynamic programming (Ukkonen 1985, Waterman 1995). However, dynamic programming cannot accommodate rules that look ahead along the string to recognize assimilation or metathesis, a possibility that needs to be left open when implementing comparative reconstruction. Additionally, generalization of dynamic programming to multiple strings does not entirely appear to be a solved problem (cf. Kececioglu 1993). Accordingly, I follow Covington (1996) in recasting the problem as a tree search. Consider the problem of aligning Eel] with Rai. Covington (1996) treats this as a process that steps through both strings and, at each step, performs either a &amp;quot;match&amp;quot; (accepting a character from both strings), a &amp;quot;skip-1&amp;quot; (skipping a character in the first string), or a &amp;quot;skip-2&amp;quot; (skipping a character in the second string). That results in the search tree shown in Fig. 1 (ignoring Covington&apos;s &amp;quot;no-alternating-skips rule&amp;quot;). The search tree can be generalized to multiple strings by breaking up each step into a series of operations, one on each string, as shown in Fig. 2. Instead of three choices, match, skip-1, and skip-2, there are really 2 x 2: accept or skip on string 1 and then accept or skip on string 2. One of the four combinations is disallowed — you can&apos;t have a step in which no characters are accepted from any string. Similarly, if there were three strings, there would be three two-way decisions, leading to (= states, one of which would be disallowed. Using search trees of this type, the decisions necessary to align any number of strings can be strung together in a satisfactory way. 6 Alternating skips Covington (1996) considers the alignments -e 1 1 equivalent and generates only the first of them, leaving it to some later step in the comparison process to decide whether [e] and [1] really correspond. The rule is: RULE: there is a skip in one string, there cannot be a skip in the other string at the next step. Although this tactic narrows the search space, I do not think this is linguistically satisfactory; after all, aligning [e] with [1] and skipping them in tandem are quite different linguistic claims. Consider for example the final segment of Spanish [dos] and Italian [due] `two&apos;; it is correct to skip the [s] and the [e] in tandem because they come from different Latin endings. It is not historically correct to pair [s] with [e] in a correspondence set. 277 Figure 1: Part of a 3-way-branching search tree for generating potential alignments (Covington 1996, ignoring no-alternating-skips rule). Processing Processing Processing Processing Processing string 1 string 2 string 1 string 2 string 1... I I Step 1 Step 2 Step 3... Figure 2: Search tree factored into 2-way branchings with a disallowed state at each step. This tree generalizes to handle more than 2 strings. Situations where only [el move is possible Skip on string 2 -] Skip on [1 -] e -1 1 0 string 2 Skip on e I - 1 Start [] Skip on string 1 Analogous to above Skip on string 2 l l al ] - 1- Skip 1 -</abstract>
<note confidence="0.727798285714286">Accept Skip Start H Disallowed (each step must accept at least 1 character) Accept Skip 278</note>
<abstract confidence="0.9983487890625">Also, the no-alternating-skips rule does not generalize easily to multiple strings. I therefore replace it with a different restriction: ORDERED-ALTERNATING-SKIPS RULE: A can be taken in strings i and successive steps only if i &lt; j. That lets us generate e (String 1) 1 - (String 2) but not e - -1 which is undeniably equivalent. It also ensures that there is only one way of skipping several consecutive segments; we get - - a b c de f- - - Table 2: Some alignments found by the prototype program. Spanish/It alian/French &apos;three&apos;: tr-es t r e rwa- Spanish/Italian/French &apos;four&apos;: kwat ro kwat t ro katr - Spanish/Italian/French &apos;five&apos;: Oinko c i nkwe s k - - Koasati/Cree/Choctaw &apos;squirrel&apos;: iplu i - - 1 u f an i but not a b c - - English the algorithm finds its &amp;quot;best&amp;quot; alignment, or numerous other equivalent combinations of skips. 7 Pruning the search The goal of the algorithm is, of course, to generate not the whole search tree, but only the parts of it likely to contain the best alignments, thereby narrowing the intractably large search space into something manageable. Following Covington (1996), I implemented a very simple pruning strategy. The program keeps track of the badness of the best complete alignment found so far. Every branch in the search tree is abandoned as soon as its total badness exceeds that value. Thus, bad alignments are abandoned when they have only partly been generated. A second part of the strategy is that the computer always tries matches before it tries skips. As a result, if not much material needs to be skipped, a good alignment is found very quickly. For example, three four-character strings have 10,536 alignments (generated my way), but comparing Spanish tres, French tr-es t r w a - Oriy after completing only ten other alignments, although it also pursues several hundred branches of the tree part of the way. (Here the match of [s] with [y1 is problematic, but the computer can&apos;t know that; it also finds a number of alternative alignments.) 8 Results and evaluation The algorithm has been prototyped in LPA Prolog, and Table 2 shows some of the alignments found. None of these took more than seca 133-MHz Pentium, and the Prolog program was written for versatility, not speed. As comparative linguists know, the alignment that gives the best phonetic fit (by any criterion) is not always the etymologically correct one. This is evident with my algorithm. For an odd set to compare because of the different depth of branching, but they are cognates and each has four segments. 279 instance, comparing the Sanskrit, Greek, and Latin words for &apos;field,&apos; the algorithm finds the correct alignment, ager - agros aj-ras (badness = 365) but then discards it in favor of a seemingly better alignment: ager- agros ajras (badness = 345) It doesn&apos;t know, of course, that [gl:[j] is a phonetically probable correspondence. Worse, occasionally the present algorithm doesn&apos;t consider the etymologically correct alignment at all because something that looks better has already been found. For example, taking the Avestan, Greek, and Latin words for &apos;100&apos;, the algorithm settles on - -sat am hekat on kentum (badness 610) without ever considering the etymologically correct alignment: --satam hekaton - -kent um (badness 690) The penalties for skips may still be too high here, but the real problem is, of course, that the is looking for the alignment, and that&apos;s not what comparative reconstruction needs. Instead, the computer should prune the search tree less eagerly, pursuing any alignment whose badness is, say, no more than 120% of the lowest found so far, and delivering all solutions that are reasonably close to the best one found during the entire procedure. Indeed, the availability of multiple potential alignments is the keystone of Kay&apos;s (1964) proposal to implement the Comparative Method, which could not be implemented at the time Kay proposed it because of the lack of an efficient search algorithm. The requisite modification is easily made and I plan to pursue it in subsequent work.</abstract>
<note confidence="0.430925222222222">References Covington, Michael A. (1996) An algorithm to words for historical comparison. Comlinguistics Covington, Michael A., and Canfield, E. Rodney (1996) The number of distinct alignments of two strings. Unpublished manuscript, University of Georgia. Anthony (1995) reconstruction:</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>An algorithm to align words for historical comparison.</title>
<date>1996</date>
<journal>Computational linguistics</journal>
<pages>22--481</pages>
<contexts>
<context position="1944" citStr="Covington (1996)" startWordPosition="295" endWordPosition="296"> step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. 2 Multiple-string alignment The alignment step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit consideration if one did not know the etymology. The number of alignments rises exponentially with the length of the strings and the numbe</context>
<context position="3212" citStr="Covington (1996)" startWordPosition="507" endWordPosition="508">ave anywhere from 26,797 to 8,079,453 different alignments depending on exactly what alignments are considered distinct (Covington 1996, Covington and Canfield 1996). As for multiple strings, if two strings have A alignments then n strings have roughly An-1 alignments, assuming the alignments are generated by aligning the first two strings, then aligning the third string against the second, and so forth. In fact, the search space isn&apos;t quite that large because some combinations are equivalent to others, but it is clearly too large to search exhaustively. 275 Table 1: Evaluation metric used by Covington (1996). Fortunately the comparative linguist is not looking for all possible alignments, only the ones that are likely to manifest regular sound correspondences — that is, those with a reasonable degree of phonetic similarity. Thus, phonetic similarity can be used to constrain the search. 3 Applying an evaluation metric The phonetic similarity criterion used by Covington (1996) is shown in Table 1. It is obviously just a stand-in for a more sophistiCated, perhaps feature-based, system of phonology. The algorithm computes a &amp;quot;badness&amp;quot; or &amp;quot;penalty&amp;quot; for each step (column) in the alignment, summing the v</context>
<context position="7077" citStr="Covington (1996)" startWordPosition="1182" endWordPosition="1183">s. Empirically, I found that the badness of comes out too high if computed as badness(f,p) + badness(p,-) + badness(f,-); that is, the algorithm is too reluctant to take skips. The reason, intuitively, is that in this alignment step, there is really only one skip, not two separate skips (one skipping VI and one skipping [pp. This becomes even more apparent when more than three strings are being aligned. Accordingly, when computing badness I count each skip only once (assessing it 50 points), then ignore skips when comparing the segments against each other. I have not implemented the rule from Covington (1996) that gives a reduced penalty for adjacent skips in the same string to reflect the fact that affixes tend to be contiguous. 5 Searching the set of alignments The standard way to find the best alignment of two strings is a matrix-based technique known as dynamic programming (Ukkonen 1985, Waterman 1995). However, dynamic programming cannot accommodate rules that look ahead along the string to recognize assimilation or metathesis, a possibility that needs to be left open when implementing comparative reconstruction. Additionally, generalization of dynamic programming to multiple strings does not</context>
<context position="8972" citStr="Covington (1996)" startWordPosition="1505" endWordPosition="1506">ne on each string, as shown in Fig. 2. Instead of three choices, match, skip-1, and skip-2, there are really 2 x 2: accept or skip on string 1 and then accept or skip on string 2. One of the four combinations is disallowed — you can&apos;t have a step in which no characters are accepted from any string. Similarly, if there were three strings, there would be three two-way decisions, leading to eight (= 23) states, one of which would be disallowed. Using search trees of this type, the decisions necessary to align any number of strings can be strung together in a satisfactory way. 6 Alternating skips Covington (1996) considers the alignments -e 1 1 - equivalent and generates only the first of them, leaving it to some later step in the comparison process to decide whether [e] and [1] really correspond. The rule is: NO-ALTERNATING-SKIPS RULE: If there is a skip in one string, there cannot be a skip in the other string at the next step. Although this tactic narrows the search space, I do not think this is linguistically satisfactory; after all, aligning [e] with [1] and skipping them in tandem are quite different linguistic claims. Consider for example the final segment of Spanish [dos] and Italian [due] `tw</context>
<context position="11675" citStr="Covington (1996)" startWordPosition="2003" endWordPosition="2004">s t r - e - t rwaSpanish/Italian/French &apos;four&apos;: kwa- t ro kwat t ro k- a- tr - Spanish/Italian/French &apos;five&apos;: Oink- o c i nkwe s - k - - Koasati/Cree/Choctaw &apos;squirrel&apos;: ip- lu i - - 1 u - f an i but not -a-b-c a b c - - English three,2 the algorithm finds its &amp;quot;best&amp;quot; d-e-f- ---def alignment, or numerous other equivalent combinations of skips. 7 Pruning the search The goal of the algorithm is, of course, to generate not the whole search tree, but only the parts of it likely to contain the best alignments, thereby narrowing the intractably large search space into something manageable. Following Covington (1996), I implemented a very simple pruning strategy. The program keeps track of the badness of the best complete alignment found so far. Every branch in the search tree is abandoned as soon as its total badness exceeds that value. Thus, bad alignments are abandoned when they have only partly been generated. A second part of the strategy is that the computer always tries matches before it tries skips. As a result, if not much material needs to be skipped, a good alignment is found very quickly. For example, three four-character strings have 10,536 alignments (generated my way), but when comparing Sp</context>
</contexts>
<marker>Covington, 1996</marker>
<rawString>Covington, Michael A. (1996) An algorithm to align words for historical comparison. Computational linguistics 22:481-496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
<author>E Rodney Canfield</author>
</authors>
<title>The number of distinct alignments of two strings.</title>
<date>1996</date>
<institution>University of Georgia.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="2761" citStr="Covington and Canfield 1996" startWordPosition="431" endWordPosition="434">ent step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit consideration if one did not know the etymology. The number of alignments rises exponentially with the length of the strings and the number of strings being aligned. Two ten-letter strings have anywhere from 26,797 to 8,079,453 different alignments depending on exactly what alignments are considered distinct (Covington 1996, Covington and Canfield 1996). As for multiple strings, if two strings have A alignments then n strings have roughly An-1 alignments, assuming the alignments are generated by aligning the first two strings, then aligning the third string against the second, and so forth. In fact, the search space isn&apos;t quite that large because some combinations are equivalent to others, but it is clearly too large to search exhaustively. 275 Table 1: Evaluation metric used by Covington (1996). Fortunately the comparative linguist is not looking for all possible alignments, only the ones that are likely to manifest regular sound correspond</context>
</contexts>
<marker>Covington, Canfield, 1996</marker>
<rawString>Covington, Michael A., and Canfield, E. Rodney (1996) The number of distinct alignments of two strings. Unpublished manuscript, University of Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fox</author>
</authors>
<title>Linguistic reconstruction: an introduction to theory and method.</title>
<date>1995</date>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<contexts>
<context position="5072" citStr="Fox (1995" startWordPosition="835" endWordPosition="836">ymologically correct one, although it is usually close; we are looking for a good phonetic fit, not necessarily the best one. 4 Generalizing to three or more languages When a guided search is involved, aligning strings from three or more languages is not simply a matter of finding the best alignment of the first two, then adding a third, and then a fourth, and so on. Thus, an algorithm to align two strings cannot be used iteratively to align more than two. The reason is that the best overall alignment of three or more strings is not necessarily the best alignment of any given pair in the set. Fox (1995:68) gives a striking example, originally from Haas (1969). The best alignment of the Choctaw and Cree words for &apos;squirrel&apos; appears to be: Choctaw f an i Cree -ilu Here the correspondence [a]:[i] is problematic. Add the Koasati word, though, and it becomes clear that the correct alignment is actually: Choctaw Koasati Cree Any algorithm that started by finding the best alignment of Choctaw against Cree would miss this solution. A much better strategy is to evaluate each column of the alignment (I&apos;ll call it a &amp;quot;step&amp;quot;) before generating the next column. That is, evaluate the first step, and then </context>
</contexts>
<marker>Fox, 1995</marker>
<rawString>Fox, Anthony (1995) Linguistic reconstruction: an introduction to theory and method. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald G Frantz</author>
</authors>
<title>A PL/1 program to assist the comparative linguist.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<pages>13--353</pages>
<contexts>
<context position="1815" citStr="Frantz (1970)" startWordPosition="274" endWordPosition="275">enigswald 1950); 4. Classify the proto-allophones into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. 2 Multiple-string alignment The alignment step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit considera</context>
</contexts>
<marker>Frantz, 1970</marker>
<rawString>Frantz, Donald G. (1970) A PL/1 program to assist the comparative linguist. Communications of the ACM 13:353-356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary R Haas</author>
</authors>
<title>The prehistory of languages.</title>
<date>1969</date>
<publisher>The Hague: Mouton.</publisher>
<contexts>
<context position="5130" citStr="Haas (1969)" startWordPosition="843" endWordPosition="844">we are looking for a good phonetic fit, not necessarily the best one. 4 Generalizing to three or more languages When a guided search is involved, aligning strings from three or more languages is not simply a matter of finding the best alignment of the first two, then adding a third, and then a fourth, and so on. Thus, an algorithm to align two strings cannot be used iteratively to align more than two. The reason is that the best overall alignment of three or more strings is not necessarily the best alignment of any given pair in the set. Fox (1995:68) gives a striking example, originally from Haas (1969). The best alignment of the Choctaw and Cree words for &apos;squirrel&apos; appears to be: Choctaw f an i Cree -ilu Here the correspondence [a]:[i] is problematic. Add the Koasati word, though, and it becomes clear that the correct alignment is actually: Choctaw Koasati Cree Any algorithm that started by finding the best alignment of Choctaw against Cree would miss this solution. A much better strategy is to evaluate each column of the alignment (I&apos;ll call it a &amp;quot;step&amp;quot;) before generating the next column. That is, evaluate the first step, and then the second step, Badness Conditions Exact match of consona</context>
</contexts>
<marker>Haas, 1969</marker>
<rawString>Haas, Mary R. (1969) The prehistory of languages. The Hague: Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hewson</author>
</authors>
<title>Comparative reconstruction on the computer.</title>
<date>1974</date>
<booktitle>Historical linguistics I: syntax, morphology, internal and comparative reconstruction,</booktitle>
<pages>191--197</pages>
<editor>John M. Anderson and Charles Jones, eds.,</editor>
<publisher>North Holland.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="1830" citStr="Hewson (1974)" startWordPosition="276" endWordPosition="277">; 4. Classify the proto-allophones into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. 2 Multiple-string alignment The alignment step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit consideration if one did</context>
</contexts>
<marker>Hewson, 1974</marker>
<rawString>Hewson, John (1974) Comparative reconstruction on the computer. John M. Anderson and Charles Jones, eds., Historical linguistics I: syntax, morphology, internal and comparative reconstruction, 191-197. Amsterdam: North Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Hoenigswald</author>
</authors>
<title>The principal step in comparative grammar. Language 26:357-364. Reprinted in</title>
<date>1950</date>
<booktitle>Readings in Linguistics I, 4th ed.,</booktitle>
<pages>298--302</pages>
<editor>Martin Joos, ed.,</editor>
<publisher>University of Chicago Press,</publisher>
<location>Chicago:</location>
<contexts>
<context position="1217" citStr="Hoenigswald 1950" startWordPosition="184" endWordPosition="185">ment algorithm of Covington (Computational Linguistics, 1996) to handle more than two strings. The resulting algorithm has been implemented in Prolog and gives reasonable results when tested on data from several languages. 1 Background The Comparative Method for reconstructing languages consists of at least the following steps: 1. Choose sets of words in the daughter languages that appear to be cognate; 2. Align the phonological segments that appear to correspond (e.g., skip the [1(] when aligning German Pali] with English [niy] &apos;knee&apos;) ;1 3. Find regular correspondence sets (protoallophones, Hoenigswald 1950); 4. Classify the proto-allophones into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), </context>
</contexts>
<marker>Hoenigswald, 1950</marker>
<rawString>Hoenigswald, Henry (1950) The principal step in comparative grammar. Language 26:357-364. Reprinted in Martin Joos, ed., Readings in Linguistics I, 4th ed., 298-302. Chicago: University of Chicago Press, 1966.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>The logic of cognate rcognition in historical linguistics. (Memorandum RM-4224-PR.)</title>
<date>1964</date>
<publisher>The RAND Corporation.</publisher>
<location>Santa Monica:</location>
<marker>Kay, 1964</marker>
<rawString>Kay, Martin (1964) The logic of cognate rcognition in historical linguistics. (Memorandum RM-4224-PR.) Santa Monica: The RAND Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kececioglu</author>
</authors>
<title>The maximum weight trace problem in multiple sequence alignment.</title>
<date>1993</date>
<booktitle>Combinatorial pattern matching: 4th annual symposium,</booktitle>
<pages>106--119</pages>
<editor>ed. A. Apostolico et al.,</editor>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<contexts>
<context position="7738" citStr="Kececioglu 1993" startWordPosition="1287" endWordPosition="1289">ips in the same string to reflect the fact that affixes tend to be contiguous. 5 Searching the set of alignments The standard way to find the best alignment of two strings is a matrix-based technique known as dynamic programming (Ukkonen 1985, Waterman 1995). However, dynamic programming cannot accommodate rules that look ahead along the string to recognize assimilation or metathesis, a possibility that needs to be left open when implementing comparative reconstruction. Additionally, generalization of dynamic programming to multiple strings does not entirely appear to be a solved problem (cf. Kececioglu 1993). Accordingly, I follow Covington (1996) in recasting the problem as a tree search. Consider the problem of aligning Eel] with Rai. Covington (1996) treats this as a process that steps through both strings and, at each step, performs either a &amp;quot;match&amp;quot; (accepting a character from both strings), a &amp;quot;skip-1&amp;quot; (skipping a character in the first string), or a &amp;quot;skip-2&amp;quot; (skipping a character in the second string). That results in the search tree shown in Fig. 1 (ignoring Covington&apos;s &amp;quot;no-alternating-skips rule&amp;quot;). The search tree can be generalized to multiple strings by breaking up each step into a serie</context>
</contexts>
<marker>Kececioglu, 1993</marker>
<rawString>Kececioglu, John (1993) The maximum weight trace problem in multiple sequence alignment. Combinatorial pattern matching: 4th annual symposium, ed. A. Apostolico et al., 106-119. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John B Lowe</author>
<author>Martine Mazaudon</author>
</authors>
<title>The Reconstruction Engine: a computer implementation of the comparative method.</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<pages>20--381</pages>
<contexts>
<context position="1876" citStr="Lowe and Mazaudon (1994)" startWordPosition="281" endWordPosition="284">into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. 2 Multiple-string alignment The alignment step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit consideration if one did not know the etymology. The number of alignme</context>
</contexts>
<marker>Lowe, Mazaudon, 1994</marker>
<rawString>Lowe, John B., and Mazaudon, Martine (1994) The Reconstruction Engine: a computer implementation of the comparative method. Computational Linguistics 20:381-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esko Ukkonen</author>
</authors>
<title>Algorithms for approximate string matching.</title>
<date>1985</date>
<journal>Information and Control</journal>
<pages>64--100</pages>
<contexts>
<context position="7364" citStr="Ukkonen 1985" startWordPosition="1232" endWordPosition="1233">e skipping VI and one skipping [pp. This becomes even more apparent when more than three strings are being aligned. Accordingly, when computing badness I count each skip only once (assessing it 50 points), then ignore skips when comparing the segments against each other. I have not implemented the rule from Covington (1996) that gives a reduced penalty for adjacent skips in the same string to reflect the fact that affixes tend to be contiguous. 5 Searching the set of alignments The standard way to find the best alignment of two strings is a matrix-based technique known as dynamic programming (Ukkonen 1985, Waterman 1995). However, dynamic programming cannot accommodate rules that look ahead along the string to recognize assimilation or metathesis, a possibility that needs to be left open when implementing comparative reconstruction. Additionally, generalization of dynamic programming to multiple strings does not entirely appear to be a solved problem (cf. Kececioglu 1993). Accordingly, I follow Covington (1996) in recasting the problem as a tree search. Consider the problem of aligning Eel] with Rai. Covington (1996) treats this as a process that steps through both strings and, at each step, p</context>
</contexts>
<marker>Ukkonen, 1985</marker>
<rawString>Ukkonen, Esko (1985) Algorithms for approximate string matching. Information and Control 64:100-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael S Waterman</author>
</authors>
<title>Introduction to computational biology: maps, sequences and genomes.</title>
<date>1995</date>
<publisher>Chapman &amp; Hall.</publisher>
<location>London:</location>
<contexts>
<context position="7380" citStr="Waterman 1995" startWordPosition="1234" endWordPosition="1236">and one skipping [pp. This becomes even more apparent when more than three strings are being aligned. Accordingly, when computing badness I count each skip only once (assessing it 50 points), then ignore skips when comparing the segments against each other. I have not implemented the rule from Covington (1996) that gives a reduced penalty for adjacent skips in the same string to reflect the fact that affixes tend to be contiguous. 5 Searching the set of alignments The standard way to find the best alignment of two strings is a matrix-based technique known as dynamic programming (Ukkonen 1985, Waterman 1995). However, dynamic programming cannot accommodate rules that look ahead along the string to recognize assimilation or metathesis, a possibility that needs to be left open when implementing comparative reconstruction. Additionally, generalization of dynamic programming to multiple strings does not entirely appear to be a solved problem (cf. Kececioglu 1993). Accordingly, I follow Covington (1996) in recasting the problem as a tree search. Consider the problem of aligning Eel] with Rai. Covington (1996) treats this as a process that steps through both strings and, at each step, performs either a</context>
</contexts>
<marker>Waterman, 1995</marker>
<rawString>Waterman, Michael S. (1995) Introduction to computational biology: maps, sequences and genomes. London: Chapman &amp; Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Wimbish</author>
</authors>
<title>WORDSURV: a program for analyzing language survey word lists. Dallas: Summer Institute of Linguistics.</title>
<date>1989</date>
<contexts>
<context position="1846" citStr="Wimbish (1989)" startWordPosition="278" endWordPosition="279">he proto-allophones into protophonemes with phonological rules (sound laws). The results of each step can be used to refine guesses made at previous steps. For example, &apos;These phonetic transcriptions may nor may not be phonemic. Because of the way the Comparative Method works, synchronic allophony is, in general, factored out along with diachronic allophony as the reconstruction proceeds. a regular correspondence, once discovered, can be used to refine one&apos;s choice of alignments and even putative cognates. Parts of the Comparative Method have been computerized by Frantz (1970), Hewson (1974), Wimbish (1989), and Lowe and Mazaudon (1994), but none of them have tackled the alignment step. Covington (1996) presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once. 2 Multiple-string alignment The alignment step is hard to automate because there are too many possible alignments to choose from. For example, French le [la] and Spanish el [el] can be lined up at least three ways: el el - -el lo - la laOf these, the second is etymologically correct, and the third would merit consideration if one did not know the et</context>
</contexts>
<marker>Wimbish, 1989</marker>
<rawString>Wimbish, John S. (1989) WORDSURV: a program for analyzing language survey word lists. Dallas: Summer Institute of Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>