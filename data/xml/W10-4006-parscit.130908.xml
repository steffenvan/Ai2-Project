<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.950959">
Multi-Word Expression-Sensitive Word Alignment
</title>
<author confidence="0.872158">
Tsuyoshi Okita1, Alfredo Maldonado Guerra2, Yvette Graham3, Andy Way1
</author>
<note confidence="0.5657655">
{CNGL1, NCLT3} / School of Computing / Dublin City University,
CNGL / School of Computer Science and Statistics / Trinity College Dublin2
</note>
<email confidence="0.994125">
{tokita,ygraham,away}@computing.dcu.ie, maldonaa@scss.tcd.ie
</email>
<sectionHeader confidence="0.997339" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957633333333">
This paper presents a new word align-
ment method which incorporates knowl-
edge about Bilingual Multi-Word Expres-
sions (BMWEs). Our method of word
alignment first extracts such BMWEs in
a bidirectional way for a given corpus and
then starts conventional word alignment,
considering the properties of BMWEs in
their grouping as well as their alignment
links. We give partial annotation of align-
ment links as prior knowledge to the word
alignment process; by replacing the max-
imum likelihood estimate in the M-step
of the IBM Models with the Maximum A
Posteriori (MAP) estimate, prior knowl-
edge about BMWEs is embedded in the
prior in this MAP estimate. In our exper-
iments, we saw an improvement of 0.77
Bleu points absolute in JP–EN. Except
for one case, our method gave better re-
sults than the method using only BMWEs
grouping. Even though this paper does
not directly address the issues in Cross-
Lingual Information Retrieval (CLIR), it
discusses an approach of direct relevance
to the field. This approach could be
viewed as the opposite of current trends
in CLIR on semantic space that incorpo-
rate a notion of order in the bag-of-words
model (e.g. co-occurences).
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998966473684211">
Word alignment (Brown et al., 1993; Vogel et
al., 1996; Och and Ney, 2003a; Graca et al.,
2007) remains key to providing high-quality trans-
lations as all subsequent training stages rely on its
performance. It alone does not effectively cap-
ture many-to-many word correspondences, but in-
stead relies on the ability of subsequent heuristic
phrase extraction algorithms, such as grow-diag-
final (Koehn et al., 2003), to resolve them.
Some aligned corpora include implicit partial
alignment annotation, while for other corpora a
partial alignment can be extracted by state-of-
the-art techniques. For example, implicit tags
such as reference number within the patent cor-
pus of Fujii et al. (2010) provide (often many-to-
many) correspondences between source and tar-
get words, while statistical methods for extract-
ing a partial annotation, like Kupiec et al. (1993),
extract terminology pairs using linguistically pre-
defined POS patterns. Gale and Church (1991)
extract pairs of anchor words, such as num-
bers, proper nouns (organization, person, title),
dates, and monetary information. Resnik and
Melamed (1997) automatically extract domain-
specific lexica. Moore (2003) extracts named-
entities. In Machine Translation, Lambert and
Banchs (2006) extract BMWEs from a phrase ta-
ble, which is an outcome of word alignment fol-
lowed by phrase extraction; this method does not
alter the word alignment process.
This paper introduces a new method of incorpo-
rating previously known many-to-many word cor-
respondences into word alignment. A well-known
method of incorporating such prior knowledge
in Machine Learning is to replace the likelihood
maximization in the M-step of the EM algorithm
with either the MAP estimate or the Maximum
Penalized Likelihood (MPL) estimate (McLach-
</bodyText>
<page confidence="0.962406">
26
</page>
<note confidence="0.557662">
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 26–34,
Beijing, August 2010
</note>
<bodyText confidence="0.999758409090909">
lan and Krishnan, 1997; Bishop, 2006). Then, the
MAP estimate allows us to incorporate the prior,
a probability used to reflect the degree of prior be-
lief about the occurrences of the events.
A small number of studies have been carried
out that use partial alignment annotation for word
alignment. Firstly, Graca et al. (2007) introduce
a posterior regularization to employ the prior that
cannot be easily expressed over model parameters
such as stochastic constraints and agreement con-
straints. These constraints are set in the E-step to
discard intractable alignments contradicting these
constraints. This mechanism in the E-step is in a
similar spirit to that in GIZA++ for IBM Model
3 and 4 which only searches around neighbour-
ing alignments around the Viterbi alignment. For
this reason, this algorithm is not intended to be
used combined with IBM Models 3 and 4. Al-
though theoretically it is possible to incorporate
partial annotation with a small change in its code,
Graca et al. do not mention it. Secondly, Tal-
bot (2005) introduces a constrained EM method
which constrains the E-step to incorporate par-
tial alignment into word alignment,1 which is in
a similar manner to Graca et al. (2007). He con-
ducted experiments using partial alignment anno-
tation based on cognate relations, a bilingual dic-
tionary, domain-specific bilingual semantic anno-
tation, and numerical pattern matching. He did
not incorporate BMWEs. Thirdly, Callison-Burch
et al. (2004) replace the likelihood maximization
in the M-step with mixed likelihood maximiza-
tion, which is a convex combination of negative
log likelihood of known links and unknown links.
The remainder of this paper is organized as fol-
lows: in Section 2 we define the anchor word
alignment problem. In Section 3 we include
a review of the EM algorithm with IBM Mod-
els 1-5, and the HMM Model. Section 4 de-
scribes our own algorithm based on the combina-
tion of BMWE extraction and the modified word
alignment which incorporates the groupings of
BMWEs and enforces their alignment links; we
explain the EM algorithm with MAP estimation
</bodyText>
<footnote confidence="0.9684222">
1Although the code may be similar in practice to our Prior
Model I, his explanation to modify the E-step will not be
applied to IBM Models 3 and 4. Our view is to modify the
M-step due to the same reason above, i.e. GIZA++ searches
only over the alignment space around the Viterbi alignment.
</footnote>
<table confidence="0.999235181818182">
pair GIZA++(no prior) Ours(with prior)
EN-FR fin ini prior fin ini prior
is NULL 1 .25 0 0 .25 .25
rosy en 1 .5 0 0 .5 .2
that . 1 .25 0 0 .25 .25
life la 1 .25 0 0 .25 0
. c‘ 1 .25 0 0 .25 .25
that c‘ 0 .25 0 1 .25 .25
is est 0 .25 0 1 .25 .25
life vie 0 .5 0 1 .5 1
rosy rose 0 .25 0 1 .25 .2
</table>
<tableCaption confidence="0.9256615">
Table 1: The benefit of prior knowledge of anchor
words.
</tableCaption>
<bodyText confidence="0.993233666666667">
with three kinds of priors. In Section 5 our exper-
imental results are presented, and we conclude in
Section 6.
</bodyText>
<sectionHeader confidence="0.995454" genericHeader="method">
2 Anchor Word Alignment Problem
</sectionHeader>
<bodyText confidence="0.998737703703704">
The input to standard methods of word alignment
is simply the sentence-aligned corpus, whereas
our alignment method takes in additionally a par-
tial alignment. We assume, therefore, the avail-
ability of a partial alignment, for example via a
MWE extraction tool. Let e˘ denote an English
sentence, and e denote an English word, through-
out this paper. The anchor word alignment prob-
lem is defined as follows:
Definition 1 (Anchor Word Alignment Problem)
Let (˘e, ˘f) _ {(˘e1, ˘f1),... ,(˘en, ˘fn)} be aparallel
corpus. By prior knowledge we additionally
have knowledge of anchor words (ˆe, ˆf) _
{(senti, tel, tf1, poser, posf1, lengthe, lengthf),
..., (sentk, ten, tfn, posen, posfn, lengthe,
lengthf)} where senti denotes sentence ID,
posei denotes the position of tei in a sentence ˘ei,
and lengthe (and lengthf) denotes the sentence
length of the original sentence which includes
ei. Under a given (˘e, ˘f) and (ˆe, ˆf), our objective
is to obtain word alignments. It is noted that an
anchor word may include a phrase pair which
forms n-to-m mapping objects.
Table 1 shows two example phrase pairs for
French to English c’est la vie and that is life, and
la vie en rose and rosy life with the initial value
for the EM algorithm, the prior value and the fi-
</bodyText>
<page confidence="0.99751">
27
</page>
<table confidence="0.999841833333333">
Statistical MWE extraction method
97 groupe socialiste socialist group 26 26
101 monsieur poettering mr poettering 1 4
103 monsieur poettering mr poettering 1 11
110 monsieur poettering mr poettering 1 9
117 explication de vote explanation of vote 28 26
Heuristic-based MWE extraction method
28 the wheel 2 •W 2  25  5
28 the primary-side fixed armature 13 1 A fq
Z 1W -f� 1 3  13  9
28 the secondary-side rotary magnet 7 2 A fq 0
� —77-�,&amp;quot;,)h 7  15  11
</table>
<tableCaption confidence="0.990215">
Table 2: Example of MWE pairs in Europarl cor-
</tableCaption>
<bodyText confidence="0.992499615384616">
pus (FR-EN) and NTCIR patent corpus (JP-EN).
There are 5 columns for each term: sentence num-
ber, source term, target term, source position, and
target position. The number appended to each
term from the patent corpus (lower half) is a ref-
erence number. In this corpus, all the important
technical terms have been identified and annotated
with reference numbers.
nal lexical translation probability for Giza++ IBM
Model 4 and that of our modified Giza++. Our
modified Giza++ achieves the correct result when
anchor words ‘life’ and ‘vie’ are used to assign a
value to the prior in our model.
</bodyText>
<sectionHeader confidence="0.990139" genericHeader="method">
3 Word Alignment
</sectionHeader>
<bodyText confidence="0.999858909090909">
We review two models which address the prob-
lem of word alignment. The aim of word align-
ment is to obtain the model parameter t among
English and French words, ei and fj respectively.
We search for this model parameter under some
model M where M is chosen by IBM Models 1-
5 and the HMM model. We introduce the latent
variable a, which is an alignment function with
the hypothesis that each e and f correspond to this
latent variable. (e, f, a) is a complete data set, and
(e, f) is an incomplete data set.
</bodyText>
<subsectionHeader confidence="0.996766">
3.1 EM Algorithm
</subsectionHeader>
<bodyText confidence="0.996197555555555">
We follow the description of the EM algorithm for
IBM Models of Brown et al. (1993) but introduce
the parameter t explicitly. In this model, the pa-
rameter t represents the lexical translation proba-
bilities t(ei|fj). It is noted that we use e|f rather
than f|e following the notation of Koehn (2010).
One important remark is that the Viterbi align-
ment of the sentence pair (˘e, ˘f) = (eJ1 , fI1 ), which
is obtained as in (1):
</bodyText>
<equation confidence="0.994218">
Eviterbi : aJˆ1 = argmaxpˆθ(f,a|e) (1)
ai
I
</equation>
<bodyText confidence="0.998563928571429">
provides the best alignment for a given log-
likelihood distribution pˆθ(f, a|e). Instead of sum-
ming, this step simplifies the E-step. However, un-
der our modification of maximum likelihood esti-
mate with MAP estimate, this simplification is not
a correct approximation of the summation since
our surface in the E-step is greatly perturbed by
the prior. There is no guarantee that the Viterbi
alignment is within the proximity of the target
alignment (cf. Table 1).
Let z be the latent variable, t be the parameters,
and x be the observations. The EM algorithm is
an iterative procedure repeating the E-step and the
M-step as in (2):
</bodyText>
<equation confidence="0.992822333333333">
EEXH : q(z; x) =p(z|x; θ) (2)
MMLE : t′ = argmaxQ(t,told)
t
= arg max
t � q(z|x) log p(x, z; t)
x,z
</equation>
<bodyText confidence="0.999884473684211">
In the E-step, our knowledge of the values of the
latent variables in a is given only by the poste-
rior distribution p(a|e, f, t). Hence, the (negative
log)-likelihood of complete data (e, f, a), which
we denote by −log p(t|e, f, a), is obtained over
all possible alignments a. We use the current pa-
rameter values told to find the posterior distribu-
tion of the latent variables given by p(a|e, f, told).
We then use this posterior distribution to find the
expectation of the complete data log-likelihood
evaluated for parameter value t. This expectation
is given by Ea p(a|e, f, told) log p(e, f, a|t).
In the M-step, we use a maximal likelihood es-
timation to minimize negative log-likelihood in
order to determine the parameter t; note that t is
a lexical translation probability. Instead of using
the log-likelihood log p(a, e, f|t), we use the ex-
pected complete data log-likelihood over all the
possible alignments a that we obtained in the E-
</bodyText>
<page confidence="0.977916">
28
</page>
<bodyText confidence="0.789984">
step, as in (3):
</bodyText>
<equation confidence="0.9509965">
MMLE : t′ = arg max Q(t, told) (3)
t
c(f|e; f, e)
= P e c(f|e; f, e)
</equation>
<bodyText confidence="0.997617">
where an auxiliary function c(e|f; e, f) for IBM
Model 1 introduced by Brown et al. is defined as
</bodyText>
<equation confidence="0.634111">
c(f|e; f, e) = X p(a|e, f) Xm δ(f, fj)δ(e, ea;)
a j=1
</equation>
<bodyText confidence="0.985819">
and where the Kronecker-Delta function δ(x, y) is
1 if x = y and 0 otherwise. This auxiliary func-
tion is convenient since the normalization factor of
this count is also required. We note that if we use
the MAP estimate, the E-step remains the same as
in the maximum likelihood case, whereas in the
M-step the quantity to be minimized is given by
Q(t, told) + log p(t). Hence, we search for the
value of t which maximizes the following equa-
tion:
</bodyText>
<equation confidence="0.9942325">
MMAP : t′ = arg max Q(t, told) + log p(t)
t
</equation>
<subsectionHeader confidence="0.981095">
3.2 BMM
</subsectionHeader>
<bodyText confidence="0.99994775">
A first-order Hidden Markov Model (Vogel et al.,
1996) uses the sentence length probability p(J|I),
the mixture alignment probability p(i|j, I), and
the translation probability, as in (4):
</bodyText>
<equation confidence="0.987166333333333">
J
p(f|e) = p(J|I) Y p(fj|ei) (4)
j=1
</equation>
<bodyText confidence="0.99880875">
Suppose we have a training set of R observation
sequences Xr, where r = 1, · · · , R, each of which
is labelled according to its class m, where m =
1,···,M, as in (5):
</bodyText>
<equation confidence="0.95790775">
p(i
I
r(i−jJ) |j, I) = (5)
PIif=1r(i′ − j JI)
</equation>
<bodyText confidence="0.9604195">
The HMM alignment probabilities p(i|i′, I) de-
pend only on the jump width (i − i′). Using a set
of non-negative parameters s(i − i′), we have (6):
s(i − i′)
</bodyText>
<equation confidence="0.9947395">
p(i|i′, I) = PI (6)
l=1 s(l − i′)
</equation>
<sectionHeader confidence="0.973268" genericHeader="method">
4 Our Approach
</sectionHeader>
<bodyText confidence="0.887536">
Algorithm 1 Overall Algorithm
Given: a parallel corpus,
</bodyText>
<listItem confidence="0.998820833333333">
1. Extract MWEs by Algorithm 2.
2. Based on the results of Step 1, specify a set
of anchor word alignment links in the format of
anchor word alignment problem (cf. Definition
1 and Table 2).
3. Group MWEs in source and target text.
4. Calculate the prior in order to embed knowl-
edge about anchor words.
5. Calculate lexical translation probabilities
with the prior.
6. Obtain alignment probabilities.
7. Ungroup of MWEs in source and target text.
</listItem>
<bodyText confidence="0.999262181818182">
Algorithm 1 consists of seven steps. We use the
Model I prior for the case where our prior knowl-
edge is sparse and evenly distributed throughout
the corpus, whereas we use the Model II prior
when our prior knowledge is dense in a partial
corpus. A typical example of the former case
is when we use partial alignment annotation ex-
tracted throughout a corpus for bilingual terminol-
ogy. A typical example of the latter case is when a
sample of only a few hundred lines from the cor-
pus have been hand-annotated.
</bodyText>
<subsectionHeader confidence="0.977541">
4.1 MWE Extraction
</subsectionHeader>
<bodyText confidence="0.998473272727273">
Our algorithm of extracting MWEs is a statisti-
cal method which is a bidirectional version of Ku-
piec (1993). Firstly, Kupiec presents a method to
extract bilingual MWE pairs in a unidirectional
manner based on the knowledge about typical
POS patterns of noun phrases, which is language-
dependent but can be written down with some ease
by a linguistic expert. For example in French they
are N N, N prep N, and N Adj. Secondly, we take
the intersection (or union) of extracted bilingual
MWE pairs.2
</bodyText>
<footnote confidence="0.956521">
2In word alignment, bidirectional word alignment by tak-
ing the intersection or union is a standard method which
improves its quality compared to unidirectional word align-
ment.
</footnote>
<page confidence="0.995667">
29
</page>
<bodyText confidence="0.572619333333333">
Algorithm 2 MWE Extraction Algorithm
Given: a parallel corpus and a set of anchor
word alignment links:
</bodyText>
<listItem confidence="0.997499666666667">
1. We use a POS tagger (Part-Of-Speech Tag-
ger) to tag a sentence on the SL side.
2. Based on the typical POS patterns for the SL,
extract noun phrases on the SL side.
3. Count n-gram statistics (typically n =
1, · · · , 5 are used) on the TL side which jointly
occur with each source noun phrase extracted
in Step 2.
4. Obtain the maximum likelihood counts of
joint phrases, i.e. noun phrases on the SL side
and n-gram phrases on the TL side.
5. Repeat the same procedure from Step 1 to 4
reversing the SL and TL.
6. Intersect (or union) the results in both direc-
tions.
</listItem>
<bodyText confidence="0.999265666666667">
Let SL be the source language side and TL be
the target language side. The procedure is shown
in Algorithm 2. We informally evaluated the
MWE extraction tool following Kupiec (1993) by
manually inspecting the mapping of the 100 most
frequent terms. For example, we found that 93 of
the 100 most frequent English terms in the patent
corpus were correctly mapped to their Japanese
translation.
Depending on the corpus, we can use more
prior knowledge about implicit alignment links.
For example in some categories of patent and
technical documents corpora,3 we can use heuris-
tics to extract the “noun phrase” + “reference
number” from both sides. This is due to the fact
that terminology is often labelled with a unique
reference number, which is labelled on both the
SL and TL sides.
</bodyText>
<subsectionHeader confidence="0.533847">
4.2 Prior Model I
</subsectionHeader>
<bodyText confidence="0.979098333333333">
Prior for Exhaustive Alignment Space IBM
Models 1 and 2 implement a prior for all possible
3Unlike other language pairs, the availability of
Japanese–English parallel corpora is quite limited: the NT-
CIR patent corpus (Fujii et al., 2010) of 3 million sentence
pairs (the latest NTCIR-8 version) for the patent domain and
JENAAD corpus (Utiyama and Isahara, 2003) of 150k sen-
tence pairs for the news domain. In this regard, the patent
domain is particularly important for this particular language
pair.
Algorithm 3 Prior Model I for IBM Model 1
Given: parallel corpus ˘e, ˘f,
anchor words biTerm
initialize t(e|f) uniformly
do until convergence
set count(e|f) to 0 for all e,f
set total(f) to 0 for all f
for all sentence pairs (˘es, ˘fs)
</bodyText>
<equation confidence="0.9529014">
prior(e|f)3 = getPriorModelI(˘e, ˘f, biTerm)
for all words e in ˘es
totals(e) = 0
for all words f in ˘fs
totals(e) += t(e|f)
</equation>
<bodyText confidence="0.7879595">
for all words e in ˘es
for all words f in ˘fs
</bodyText>
<equation confidence="0.9069876">
count(e|f)+=t(e|f)/total3(e)× prior(e|f)3
total(f) += t(e|f)/total3(e) × prior(e|f)3
for all f
for all e
t(e|f) = count(e|f)/total(f)
</equation>
<bodyText confidence="0.998815428571429">
alignments exhaustively. Such a prior requires the
following two conditions. Firstly, partial knowl-
edge about the prior that we use in our context is
defined as follows. Let us denote a bilingual term
list T = {(si, ti), ... , (sm, tm)}. For example
with IBM Model 1: Let us define the following
prior p(e|f, e, f; T) from Equation (4):
</bodyText>
<equation confidence="0.980981">
p(e|f,e,f;T) = { 1 (ei = si, fj = tj)
uniform (ei =6 si, fj =6 tj)
0 (ei = si, fj =6 tj)
0 (ei =6 si, fj = tj)
</equation>
<bodyText confidence="0.990115714285714">
Secondly, this prior should be proper for the ex-
haustive case and non-proper for the sampled
alignment space where by proper we mean that the
probability is normalized to 1. Algorithm 3 shows
the pseudo-code for Prior Model I. Note that if
the prior is uniform in the MAP estimation, this is
equivalent to maximum likelihood estimation.
Prior for Sampled Alignment (Function) Space
Due to the exponential costs introduced by fertil-
ity, null token insertion, and distortion probability,
IBM Models 3 and 4 do not consider all (I + 1)J
alignments exhaustively, but rather a small subset
in the E-step. Each iteration only uses the sub-
set of all the alignment functions: this sampling
</bodyText>
<page confidence="0.996129">
30
</page>
<bodyText confidence="0.9990318125">
is not uniform, as it only includes the best possi-
ble alignment with all its neighbouring alignments
which differ from the best alignment by one word
(this can be corrected by a move operation) or two
words (this can be corrected by a swap operation).
If we consider the neighbouring alignment via
a move or a swap operation, two issues arise.
Firstly, the fact that these two neighbouring align-
ments are drawn from different underlying distri-
butions needs to be taken into account, and sec-
ondly, that the application of a move and a swap
operation alters a row or column of a prior ma-
trix (or indices of the prior) since either operation
involves the manipulation of links.
Algorithm 4 Pseudo-code for Prior Model II Ex-
haustive Alignment Space
</bodyText>
<equation confidence="0.967411941176471">
def getPriorModelII(˘e, ˘f,biTerm):
for i in sentence:
for e in ˘ei:
allWordsi = length of sentence e˘
for f in ˘fi:
if (e, f) in biTerm:
n= num of anchor words in i
uni(e|f)i = allWordsi−n
allWordsi
expSum(e|f) += uni(e|f)i × n
else:
countSum(e|f)i += n
countSum(e|f) += count(e|f)i
for e in alle:
for f in allf:
prior(e|f) = expSum(e|f) + countSum(e|f)
return prior(e|f)
</equation>
<bodyText confidence="0.999610777777778">
Prior for Jump Width i′ One implementation
of HMM is to use the forward-backward algo-
rithm. A prior should be embedded within the
forward-backward algorithm. From Equation (6),
there are three cases which depend on whether
ai and its neighbouring alignment ai−1 are deter-
mined by our prior knowledge about anchor words
or not. When both ai and aj are determined, this
probability is expressed as in (7):
</bodyText>
<equation confidence="0.9590893">
p(i − i′; I) = { 0 (else) (7)
1 (ei = si, fj = tj for ai) and
(e′i = s′i, f′j = t′j for aj)
When either ai or aj is determined, this probabil-
ity is expressed as in (8):4
0 (condition 1) (8)
1 (condition 2)
(m−#eai−···−#eai+m) (else)
1
(uniform distribution)
</equation>
<bodyText confidence="0.7875105">
When neither ai nor aj is determined, this proba-
bility is expressed as in (9): 5
</bodyText>
<equation confidence="0.843797166666667">
0 (condition 3) (9)
(m−#e1 (condition 4)
ai−···−#eai+m)2 (else)
m−i′
(Pascal’s triangle distribution)
4.3 Prior Model II
</equation>
<bodyText confidence="0.987966692307692">
Prior Model II assumes that we have prior knowl-
edge only in some part of the training corpus. A
typical example is when a small part of the corpus
has a hand-crafted ‘gold standard’ annotation.
Prior for Exhaustive Alignment Space Prior
Model II is used to obtain the prior probability
p(e|f) over all possible combinations of e and f.
In contrast to Prior Model I, which computes the
prior probability p(e|f) for each sentence, Prior
Model II computes the prior probability globally
for all sentences in the corpus. Algorithm 4 shows
the pseudo-code for Prior Model II Exhaustive
Alignment Space.
</bodyText>
<equation confidence="0.995106421052631">
4condition 1 is as follows:
((ei =� si, fj =� tj for ai) and (e′i = s′i, f′j = t′&apos;. for aj)) or
((ei # si, fj # tj for ai) and (e′i = s′i, f′j = t� for aj)) or
((ei = si, fj = tj for ai) and (e′i # s′i7 f′j # ti. for aj)) or
((ei = si, fj = tj for ai) and (e′i # s′i: f′j # tj for aj))
‘condition 2’ is as follows:
((ei = si, fj =� tj for ai) and (e′i = s′i, f′j = t′j for aj)) or
((ei =� si, fj = tj for ai) and (e′i = s′i, f′j = t′&apos;. for aj)) or
((ei = si, fj = tj for ai) and (e′i # s′i, f′j = t� for aj)) or
((ei = si, fj = tj for ai) and (e′i = s′i, f′j # tj for aj))
5‘condition 3’ is as follows:
((ei =� si, fj =� tj for ai) and (e′i =� s′i, f′j =� t′j for aj))
‘condition 4’ is as follows:
((ei =� si, fj =� tj for ai) and (e′i =� s′i, f′j = t′&apos;. for aj)) or
((ei # si, fj # tj for ai) and (e′i = s′i, f′j # t� for aj)) or
((ei # si, fj = tj for ai) and (e′i # s′i , f′j 54 tj for aj)) or
((ei = si, fj =� tj for ai) and (e′i =� s′i, f′j =� t′j for aj))
p(i − i′; I) = {
p(i − i′; I) = {
</equation>
<page confidence="0.99935">
31
</page>
<bodyText confidence="0.966825444444445">
Prior for Sampled Alignment (Function) Space
This is identical to that of the Prior Model II ex-
haustive alignment space with only a difference in
the normalization process.
Prior for Jump Width i′ This categorization of
Prior Model II is the same as that of Prior Model I
for for Jump Width i′ (see Section 4.2). Note that
Prior Model II requires more memory compared
to the Prior Model I.6
</bodyText>
<sectionHeader confidence="0.990352" genericHeader="method">
5 Experimental Settings
</sectionHeader>
<bodyText confidence="0.999828318181818">
The baseline in our experiments is a standard
log-linear phrase-based MT system based on
Moses. The GIZA++ implementation (Och and
Ney, 2003a) of IBM Model 4 is used as the base-
line for word alignment, which we compare to
our modified GIZA++. Model 4 is incrementally
trained by performing 5 iterations of Model 1, 5
iterations of HMM, 5 iterations of Model 3, and
5 iterations of Model 4. For phrase extraction the
grow-diag-final heuristics are used to derive the
refined alignment from bidirectional alignments.
We then perform MERT while a 5-gram language
model is trained with SRILM. Our implementa-
tion is based on a modified version of GIZA++
(Och and Ney, 2003a). This modification is on the
function that reads a bilingual terminology file,
the function that calculates priors, the M-step in
IBM Models 1-5, and the forward-backward algo-
rithm in the HMM Model. Other related software
tools are written in Python and Perl: terminol-
ogy concatenation, terminology numbering, and
so forth.
</bodyText>
<sectionHeader confidence="0.989284" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.999802666666667">
We conduct an experimental evaluation on the
NTCIR-8 corpus (Fujii et al., 2010) and on Eu-
roparl (Koehn, 2005). Firstly, MWEs are ex-
tracted from both corpora, as shown in Table 3.
In the second step, we apply our modified version
of GIZA++ in which we incorporate the results of
</bodyText>
<footnote confidence="0.993429875">
6This is because it needs to maintain potentially an ℓ × m
matrix, where ℓ denotes the number of English tokens in the
corpus and m denotes the number of foreign tokens, even if
the matrix is sparse. Prior Model I only requires an ℓˆ × mˆ
matrix where ℓˆ is the number of English tokens in a sentence
and mˆ is the number of foreign tokens in a sentence, which
is only needed until this information is incorporated in a pos-
terior probability during the iterative process.
</footnote>
<table confidence="0.998548875">
corpus language size #unique #all
MWEs MWEs
statistical method
NTCIR EN-JP 200k 1,121 120,070
europarl EN-FR 200k 312 22,001
europarl EN-ES 200k 406 16,350
heuristic method
NTCIR EN-JP 200k 50,613 114,373
</table>
<tableCaption confidence="0.6833225">
Table 3: Statistics of our MWE extraction method.
The numbers of MWEs are from 0.08 to 0.6 MWE
/ sentence pair in our statistical MWE extraction
methods.
</tableCaption>
<bodyText confidence="0.998919151515151">
MWE extraction. Secondly, in order to incorpo-
rate the extracted MWEs, they are reformatted as
shown in Table 2. Thirdly, we convert all MWEs
into a single token, i.e. we concatenate them with
an underscore character. We then run the modi-
fied version of GIZA++ and obtain a phrase and
reordering table. In the fourth step, we split the
concatenated MWEs embedded in the third step.
Finally, in the fifth step, we run MERT, and pro-
ceed with decoding before automatically evaluat-
ing the translations.
Table 4 shows the results where ‘baseline’ in-
dicates no BMWE grouping nor prior, and ‘base-
line2’ represents a BMWE grouping but without
the prior. Although ‘baseline2’ (BMWE group-
ing) shows a drop in performance in the JP–EN
/ EN–JP 50k sentence pair setting, Prior Model I
results in an increase in performance in the same
setting. Except for EN–ES 200k, our Prior Model
I was better than ‘baseline2’. For EN–JP NT-
CIR using 200k sentence pairs, we obtained an
absolute improvement of 0.77 Bleu points com-
pared to the ‘baseline’; for EN–JP using 50k sen-
tence pairs, 0.75 Bleu points; and for ES–EN Eu-
roparl corpus using 200k sentence pairs, 0.63 Bleu
points. In contrast, Prior Model II did not work
well. The possible reason for this is the misspec-
ification, i.e. the modelling by IBM Model 4 was
wrong in terms of the given data. One piece of ev-
idence for this is that most of the enforced align-
ments were found correct in a manual inspection.
For EN–JP NTCIR using the same corpus of
200k, although the number of unique MWEs ex-
</bodyText>
<page confidence="0.995233">
32
</page>
<table confidence="0.999942703703704">
size EN-JP Bleu JP-EN Bleu
50k baseline 16.33 baseline 22.01
50k baseline2 16.10 baseline2 21.71
50k prior I 17.08 prior I 22.11
50k prior II 16.02 prior II 20.02
200k baseline 23.42 baseline 21.68
200k baseline2 24.10 baseline2 22.32
200k prior I 24.22 prior I 22.45
200k prior II 23.22 prior II 21.00
size FR-EN Bleu EN-FR Bleu
50k baseline 17.68 baseline 17.80
50k baseline2 17.76 baseline2 18.00
50k prior I 17.81 prior I 18.02
50k prior II 17.01 prior II 17.30
200k baseline 18.40 baseline 18.20
200k baseline2 18.80 baseline2 18.50
200k prior I 18.99 prior I 18.60
200k prior II 18.20 prior II 17.50
size ES-EN Bleu EN-ES Bleu
50k baseline 16.21 baseline 15.17
50k baseline2 16.61 baseline2 15.60
50k prior I 16.91 prior I 15.87
50k prior II 16.15 prior II 14.60
200k baseline 16.87 baseline 17.62
200k baseline2 17.40 baseline2 18.21
200k prior I 17.50 prior I 18.20
200k prior II 16.50 prior II 17.10
</table>
<tableCaption confidence="0.991961">
Table 4: Results. Baseline is plain GIZA++ /
</tableCaption>
<bodyText confidence="0.9351942">
Moses (without BMWE grouping / prior), base-
line2 is with BMWE grouping, prior I / II are with
BMWE grouping and prior.
tracted by the statistical method and the heuris-
tic method varies significantly, the total number
of MWEs by each method becomes comparable.
The resulting Bleu score for the heuristic method
(24.24 / 22.48 Blue points for 200k EN–JP / JP–
EN) is slightly better than that of the statistical
method. The possible reason for this is related
to the way the heuristic method groups terms in-
cluding reference numbers, while the statistical
method does not. As a result, the complexity of
the alignment model simplifies slightly in the case
of the heuristic method.
</bodyText>
<sectionHeader confidence="0.99844" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99995036">
This paper presents a new method of incorporat-
ing BMWEs into word alignment. We first de-
tect BMWEs in a bidirectional way and then use
this information to do groupings and to enforce
already known alignment links. For the latter pro-
cess, we replace the maximum likelihood estimate
in the M-step of the EM algorithm with the MAP
estimate; this replacement allows the incorpora-
tion of the prior in the M-step of the EM algo-
rithm. We include an experimental investigation
into incorporating extracted BMWEs into a word
aligner. Although there is some work which incor-
porates BMWEs in groupings, they do not enforce
alignment links.
There are several ways in which this work can
be extended. Firstly, although we assume that our
a priori partial annotation is reliable, if we extract
such MWEs automatically, we cannot avoid erro-
neous pairs. Secondly, we assume that the rea-
son why our Prior Model II did not work was due
to the misspecification (or wrong modelling). We
would like to check this by discriminative mod-
elling. Thirdly, although here we extract BMWEs,
we can extend this to extract paraphrases and non-
literal expressions.
</bodyText>
<sectionHeader confidence="0.999006" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999744428571429">
This research is supported by the Science Foun-
dation Ireland (Grant 07/CE/I1142) as part of
the Centre for Next Generation Localisation
(http://www.cngl.ie) at Dublin City Uni-
versity and Trinity College Dublin. We would also
like to thank the Irish Centre for High-End Com-
puting.
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999938">
Bishop, Christopher M. 2006. Pattern Recognition
and Machine Learning. Springer. Cambridge, UK
Brown, Peter F., Vincent .J.D Pietra, Stephen
A.D.Pietra, Robert L. Mercer. 1993. The Mathe-
matics of Statistical Machine Translation: Param-
eter Estimation. Computational Linguistics. 19(2),
pp. 263–311.
Callison-Burch, Chris, David Talbot and Miles Os-
borne. 2004. Statistical Machine Translation with
</reference>
<page confidence="0.985545">
33
</page>
<reference confidence="0.999706568181818">
Word- and Sentence-Aligned Parallel Corpora. Pro-
ceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics (ACL’04),
Main Volume. Barcelona, Spain, pp. 175–182.
Fujii, Atsushi, Masao Utiyama, Mikio Yamamoto,
Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-
ya, Sayori Shimohata. 2010. Overview of the
Patent Translation Task at the NTCIR-8 Workshop.
Proceedings of the 8th NTCIR Workshop Meet-
ing on Evaluation of Information Access Technolo-
gies: Information Retrieval, Question Answering
and Cross-lingual Information Access, pp. 293–302.
Graca, Joao de Almeida Varelas, Kuzman Ganchev,
Ben Taskar. 2007. Expectation Maximization
and Posterior Constraints. In Neural Information
Processing Systems Conference (NIPS), Vancouver,
BC, Canada, pp. 569–576.
Gale, William, and Ken Church. 1991. A Program for
Aligning Sentences in Bilingual Corpora. In Pro-
ceedings of the 29th Annual Meeting of the Associ-
ation for Computational Linguistics. Berkeley CA,
pp. 177–184.
Koehn, Philipp, Franz Och, Daniel Marcu. 2003. Sta-
tistical Phrase-Based Translation. In Proceedings
of the 2003 Human Language Technology Confer-
ence of the North American Chapter of the Asso-
ciation for Computational Linguistics. Edmonton,
Canada. pp. 115–124.
Koehn, Philipp. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Conference
Proceedings: the tenth Machine Translation Sum-
mit. Phuket, Thailand, pp.79-86.
Koehn, Philipp, H. Hoang, A. Birch, C. Callison-
Burch, M. Federico, N. Bertoldi, B. Cowan,
W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar,
A. Constantin, and E. Herbst, 2007. Moses: Open
source toolkit for Statistical Machine Translation.
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Ses-
sions, Prague, Czech Republic, pp. 177–180.
Koehn, Philipp. 2010. Statistical Machine Transla-
tion. Cambridge University Press. Cambridge, UK.
Kupiec, Julian. 1993. An Algorithm for finding Noun
Phrase Correspondences in Bilingual Corpora. In
Proceedings of the 31st Annual Meeting of Associa-
tion for Computational Linguistics. Columbus. OH.
pp. 17–22.
Lambert, Patrik and Rafael Banchs. 2006. Group-
ing Multi-word Expressions According to Part-Of-
Speech in Statistical Machine Translation. In Pro-
ceedings of the EACL Workshop on Multi-Word-
Expressions in a Multilingual Context. Trento, Italy,
pp. 9–16.
McLachlan, Geoffrey J. and Thriyambakam Krishnan,
1997. The EM Algorithm and Extensions. Wiley
Series in probability and statistics. New York, NY.
Moore, Robert C.. 2003. Learning Translations of
Named-Entity Phrases from Parallel Corpora. In
Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Lin-
guistics. Budapest, Hungary. pp. 259–266.
Moore, Robert C.. 2004. On Log-Likelihood-Ratios
and the Significance ofRare Events. In Proceedings
of the 2004 Conference on Empirical Methods in
Natural Language Processing (EMNLP). Barcelona,
Spain, pp. 333–340.
Och, Franz and Herman Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics. 29(1), pp. 19–51.
Resnik, Philip and I. Dan Melamed, 1997. Semi-
Automatic Acquisition of Domain-Specific Transla-
tion Lexicons. Proceedings of the 5th Applied Nat-
ural Language Processing Conference. Washington,
DC., pp. 340–347.
Talbot, David. 2005. Constrained EMfor parallel text
alignment, Natural Language Engineering, 11(3):
pp. 263–277.
Utiyama, Masao and Hitoshi Isahara. 2003. Reliable
Measures for Aligning Japanese-English News Arti-
cles and Sentences, In Proceedings of the 41st An-
nual Meeting of the Association for Computational
Linguistics. Sapporo, Japan, pp. 72–79.
Vogel, Stephan, Hermann Ney, Christoph Tillmann
1996. HMM-Based Word Alignment in Statisti-
cal Translation. In Proceedings of the 16th Inter-
national Conference on Computational Linguistics.
Copenhagen, Denmark, pp. 836–841.
</reference>
<page confidence="0.999323">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888672">
<title confidence="0.999888">Multi-Word Expression-Sensitive Word Alignment</title>
<author confidence="0.999838">Alfredo Maldonado Yvette Andy</author>
<affiliation confidence="0.985397">School of Computing / Dublin City / School of Computer Science and Statistics / Trinity College</affiliation>
<abstract confidence="0.997163193548387">This paper presents a new word alignment method which incorporates knowledge about Bilingual Multi-Word Expressions (BMWEs). Our method of word alignment first extracts such BMWEs in a bidirectional way for a given corpus and then starts conventional word alignment, considering the properties of BMWEs in their grouping as well as their alignment links. We give partial annotation of alignment links as prior knowledge to the word alignment process; by replacing the maximum likelihood estimate in the M-step of the IBM Models with the Maximum A Posteriori (MAP) estimate, prior knowledge about BMWEs is embedded in the prior in this MAP estimate. In our experiments, we saw an improvement of 0.77 Bleu points absolute in JP–EN. Except for one case, our method gave better results than the method using only BMWEs grouping. Even though this paper does not directly address the issues in Cross- Lingual Information Retrieval (CLIR), it discusses an approach of direct relevance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<date>2006</date>
<booktitle>Pattern Recognition and Machine Learning.</booktitle>
<publisher>Springer.</publisher>
<location>Cambridge, UK</location>
<contexts>
<context position="3433" citStr="Bishop, 2006" startWordPosition="526" endWordPosition="527">y phrase extraction; this method does not alter the word alignment process. This paper introduces a new method of incorporating previously known many-to-many word correspondences into word alignment. A well-known method of incorporating such prior knowledge in Machine Learning is to replace the likelihood maximization in the M-step of the EM algorithm with either the MAP estimate or the Maximum Penalized Likelihood (MPL) estimate (McLach26 Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 26–34, Beijing, August 2010 lan and Krishnan, 1997; Bishop, 2006). Then, the MAP estimate allows us to incorporate the prior, a probability used to reflect the degree of prior belief about the occurrences of the events. A small number of studies have been carried out that use partial alignment annotation for word alignment. Firstly, Graca et al. (2007) introduce a posterior regularization to employ the prior that cannot be easily expressed over model parameters such as stochastic constraints and agreement constraints. These constraints are set in the E-step to discard intractable alignments contradicting these constraints. This mechanism in the E-step is in</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Bishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer. Cambridge, UK</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J D Pietra</author>
<author>Stephen A D Pietra</author>
<author>Robert L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics.</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263--311</pages>
<contexts>
<context position="1537" citStr="Brown et al., 1993" startWordPosition="236" endWordPosition="239">t BMWEs is embedded in the prior in this MAP estimate. In our experiments, we saw an improvement of 0.77 Bleu points absolute in JP–EN. Except for one case, our method gave better results than the method using only BMWEs grouping. Even though this paper does not directly address the issues in CrossLingual Information Retrieval (CLIR), it discusses an approach of direct relevance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences). 1 Introduction Word alignment (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2003a; Graca et al., 2007) remains key to providing high-quality translations as all subsequent training stages rely on its performance. It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference </context>
<context position="9230" citStr="Brown et al. (1993)" startWordPosition="1557" endWordPosition="1560">rd Alignment We review two models which address the problem of word alignment. The aim of word alignment is to obtain the model parameter t among English and French words, ei and fj respectively. We search for this model parameter under some model M where M is chosen by IBM Models 1- 5 and the HMM model. We introduce the latent variable a, which is an alignment function with the hypothesis that each e and f correspond to this latent variable. (e, f, a) is a complete data set, and (e, f) is an incomplete data set. 3.1 EM Algorithm We follow the description of the EM algorithm for IBM Models of Brown et al. (1993) but introduce the parameter t explicitly. In this model, the parameter t represents the lexical translation probabilities t(ei|fj). It is noted that we use e|f rather than f|e following the notation of Koehn (2010). One important remark is that the Viterbi alignment of the sentence pair (˘e, ˘f) = (eJ1 , fI1 ), which is obtained as in (1): Eviterbi : aJˆ1 = argmaxpˆθ(f,a|e) (1) ai I provides the best alignment for a given loglikelihood distribution pˆθ(f, a|e). Instead of summing, this step simplifies the E-step. However, under our modification of maximum likelihood estimate with MAP estimate</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, Peter F., Vincent .J.D Pietra, Stephen A.D.Pietra, Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics. 19(2), pp. 263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical Machine Translation with Word- and Sentence-Aligned Parallel Corpora.</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL’04), Main Volume.</booktitle>
<pages>175--182</pages>
<location>Barcelona,</location>
<contexts>
<context position="4855" citStr="Callison-Burch et al. (2004)" startWordPosition="752" endWordPosition="755">sed combined with IBM Models 3 and 4. Although theoretically it is possible to incorporate partial annotation with a small change in its code, Graca et al. do not mention it. Secondly, Talbot (2005) introduces a constrained EM method which constrains the E-step to incorporate partial alignment into word alignment,1 which is in a similar manner to Graca et al. (2007). He conducted experiments using partial alignment annotation based on cognate relations, a bilingual dictionary, domain-specific bilingual semantic annotation, and numerical pattern matching. He did not incorporate BMWEs. Thirdly, Callison-Burch et al. (2004) replace the likelihood maximization in the M-step with mixed likelihood maximization, which is a convex combination of negative log likelihood of known links and unknown links. The remainder of this paper is organized as follows: in Section 2 we define the anchor word alignment problem. In Section 3 we include a review of the EM algorithm with IBM Models 1-5, and the HMM Model. Section 4 describes our own algorithm based on the combination of BMWE extraction and the modified word alignment which incorporates the groupings of BMWEs and enforces their alignment links; we explain the EM algorith</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Callison-Burch, Chris, David Talbot and Miles Osborne. 2004. Statistical Machine Translation with Word- and Sentence-Aligned Parallel Corpora. Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL’04), Main Volume. Barcelona, Spain, pp. 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Masao Utiyama</author>
<author>Mikio Yamamoto</author>
</authors>
<title>Takehito Utsuro, Terumasa Ehara, Hiroshi Echizenya, Sayori Shimohata.</title>
<date>2010</date>
<booktitle>Overview of the Patent Translation Task at the NTCIR-8 Workshop. Proceedings of the 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering and Cross-lingual Information Access,</booktitle>
<pages>293--302</pages>
<contexts>
<context position="2191" citStr="Fujii et al. (2010)" startWordPosition="338" endWordPosition="341">2003a; Graca et al., 2007) remains key to providing high-quality translations as all subsequent training stages rely on its performance. It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, and monetary information. Resnik and Melamed (1997) automatically extract domainspecific lexica. Moore (2003) extracts namedentities. In Machine Translation, Lambert and Banchs (2006) extract BMWEs from a phrase table, which is an outcome</context>
<context position="16090" citStr="Fujii et al., 2010" startWordPosition="2801" endWordPosition="2804"> can use more prior knowledge about implicit alignment links. For example in some categories of patent and technical documents corpora,3 we can use heuristics to extract the “noun phrase” + “reference number” from both sides. This is due to the fact that terminology is often labelled with a unique reference number, which is labelled on both the SL and TL sides. 4.2 Prior Model I Prior for Exhaustive Alignment Space IBM Models 1 and 2 implement a prior for all possible 3Unlike other language pairs, the availability of Japanese–English parallel corpora is quite limited: the NTCIR patent corpus (Fujii et al., 2010) of 3 million sentence pairs (the latest NTCIR-8 version) for the patent domain and JENAAD corpus (Utiyama and Isahara, 2003) of 150k sentence pairs for the news domain. In this regard, the patent domain is particularly important for this particular language pair. Algorithm 3 Prior Model I for IBM Model 1 Given: parallel corpus ˘e, ˘f, anchor words biTerm initialize t(e|f) uniformly do until convergence set count(e|f) to 0 for all e,f set total(f) to 0 for all f for all sentence pairs (˘es, ˘fs) prior(e|f)3 = getPriorModelI(˘e, ˘f, biTerm) for all words e in ˘es totals(e) = 0 for all words f i</context>
<context position="23120" citStr="Fujii et al., 2010" startWordPosition="4110" endWordPosition="4113">nment from bidirectional alignments. We then perform MERT while a 5-gram language model is trained with SRILM. Our implementation is based on a modified version of GIZA++ (Och and Ney, 2003a). This modification is on the function that reads a bilingual terminology file, the function that calculates priors, the M-step in IBM Models 1-5, and the forward-backward algorithm in the HMM Model. Other related software tools are written in Python and Perl: terminology concatenation, terminology numbering, and so forth. 6 Experimental Results We conduct an experimental evaluation on the NTCIR-8 corpus (Fujii et al., 2010) and on Europarl (Koehn, 2005). Firstly, MWEs are extracted from both corpora, as shown in Table 3. In the second step, we apply our modified version of GIZA++ in which we incorporate the results of 6This is because it needs to maintain potentially an ℓ × m matrix, where ℓ denotes the number of English tokens in the corpus and m denotes the number of foreign tokens, even if the matrix is sparse. Prior Model I only requires an ℓˆ × mˆ matrix where ℓˆ is the number of English tokens in a sentence and mˆ is the number of foreign tokens in a sentence, which is only needed until this information is</context>
</contexts>
<marker>Fujii, Utiyama, Yamamoto, 2010</marker>
<rawString>Fujii, Atsushi, Masao Utiyama, Mikio Yamamoto, Takehito Utsuro, Terumasa Ehara, Hiroshi Echizenya, Sayori Shimohata. 2010. Overview of the Patent Translation Task at the NTCIR-8 Workshop. Proceedings of the 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering and Cross-lingual Information Access, pp. 293–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao de Almeida Varelas Graca</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation Maximization and Posterior Constraints.</title>
<date>2007</date>
<booktitle>In Neural Information Processing Systems Conference (NIPS),</booktitle>
<pages>569--576</pages>
<location>Vancouver, BC,</location>
<contexts>
<context position="1598" citStr="Graca et al., 2007" startWordPosition="248" endWordPosition="251">r experiments, we saw an improvement of 0.77 Bleu points absolute in JP–EN. Except for one case, our method gave better results than the method using only BMWEs grouping. Even though this paper does not directly address the issues in CrossLingual Information Retrieval (CLIR), it discusses an approach of direct relevance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences). 1 Introduction Word alignment (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2003a; Graca et al., 2007) remains key to providing high-quality translations as all subsequent training stages rely on its performance. It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provid</context>
<context position="3722" citStr="Graca et al. (2007)" startWordPosition="573" endWordPosition="576"> replace the likelihood maximization in the M-step of the EM algorithm with either the MAP estimate or the Maximum Penalized Likelihood (MPL) estimate (McLach26 Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 26–34, Beijing, August 2010 lan and Krishnan, 1997; Bishop, 2006). Then, the MAP estimate allows us to incorporate the prior, a probability used to reflect the degree of prior belief about the occurrences of the events. A small number of studies have been carried out that use partial alignment annotation for word alignment. Firstly, Graca et al. (2007) introduce a posterior regularization to employ the prior that cannot be easily expressed over model parameters such as stochastic constraints and agreement constraints. These constraints are set in the E-step to discard intractable alignments contradicting these constraints. This mechanism in the E-step is in a similar spirit to that in GIZA++ for IBM Model 3 and 4 which only searches around neighbouring alignments around the Viterbi alignment. For this reason, this algorithm is not intended to be used combined with IBM Models 3 and 4. Although theoretically it is possible to incorporate part</context>
</contexts>
<marker>Graca, Ganchev, Taskar, 2007</marker>
<rawString>Graca, Joao de Almeida Varelas, Kuzman Ganchev, Ben Taskar. 2007. Expectation Maximization and Posterior Constraints. In Neural Information Processing Systems Conference (NIPS), Vancouver, BC, Canada, pp. 569–576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Gale</author>
<author>Ken Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>177--184</pages>
<location>Berkeley CA,</location>
<contexts>
<context position="2453" citStr="Gale and Church (1991)" startWordPosition="376" endWordPosition="379">euristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, and monetary information. Resnik and Melamed (1997) automatically extract domainspecific lexica. Moore (2003) extracts namedentities. In Machine Translation, Lambert and Banchs (2006) extract BMWEs from a phrase table, which is an outcome of word alignment followed by phrase extraction; this method does not alter the word alignment process. This paper introduces a new method of incorporating previously known many-to-many word correspondences into word alignment. A well-known method of incorporat</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William, and Ken Church. 1991. A Program for Aligning Sentences in Bilingual Corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics. Berkeley CA, pp. 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<pages>115--124</pages>
<location>Edmonton,</location>
<contexts>
<context position="1913" citStr="Koehn et al., 2003" startWordPosition="295" endWordPosition="298">evance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences). 1 Introduction Word alignment (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2003a; Graca et al., 2007) remains key to providing high-quality translations as all subsequent training stages rely on its performance. It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper noun</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Och, Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Edmonton, Canada. pp. 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Conference Proceedings: the tenth Machine Translation Summit.</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand,</location>
<contexts>
<context position="23150" citStr="Koehn, 2005" startWordPosition="4118" endWordPosition="4119">We then perform MERT while a 5-gram language model is trained with SRILM. Our implementation is based on a modified version of GIZA++ (Och and Ney, 2003a). This modification is on the function that reads a bilingual terminology file, the function that calculates priors, the M-step in IBM Models 1-5, and the forward-backward algorithm in the HMM Model. Other related software tools are written in Python and Perl: terminology concatenation, terminology numbering, and so forth. 6 Experimental Results We conduct an experimental evaluation on the NTCIR-8 corpus (Fujii et al., 2010) and on Europarl (Koehn, 2005). Firstly, MWEs are extracted from both corpora, as shown in Table 3. In the second step, we apply our modified version of GIZA++ in which we incorporate the results of 6This is because it needs to maintain potentially an ℓ × m matrix, where ℓ denotes the number of English tokens in the corpus and m denotes the number of foreign tokens, even if the matrix is sparse. Prior Model I only requires an ℓˆ × mˆ matrix where ℓˆ is the number of English tokens in a sentence and mˆ is the number of foreign tokens in a sentence, which is only needed until this information is incorporated in a posterior p</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, Philipp. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Conference Proceedings: the tenth Machine Translation Summit. Phuket, Thailand, pp.79-86.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C CallisonBurch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic,</location>
<marker>Koehn, Hoang, Birch, CallisonBurch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Koehn, Philipp, H. Hoang, A. Birch, C. CallisonBurch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst, 2007. Moses: Open source toolkit for Statistical Machine Translation. Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, Prague, Czech Republic, pp. 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press. Cambridge, UK.</publisher>
<contexts>
<context position="9445" citStr="Koehn (2010)" startWordPosition="1595" endWordPosition="1596">arameter under some model M where M is chosen by IBM Models 1- 5 and the HMM model. We introduce the latent variable a, which is an alignment function with the hypothesis that each e and f correspond to this latent variable. (e, f, a) is a complete data set, and (e, f) is an incomplete data set. 3.1 EM Algorithm We follow the description of the EM algorithm for IBM Models of Brown et al. (1993) but introduce the parameter t explicitly. In this model, the parameter t represents the lexical translation probabilities t(ei|fj). It is noted that we use e|f rather than f|e following the notation of Koehn (2010). One important remark is that the Viterbi alignment of the sentence pair (˘e, ˘f) = (eJ1 , fI1 ), which is obtained as in (1): Eviterbi : aJˆ1 = argmaxpˆθ(f,a|e) (1) ai I provides the best alignment for a given loglikelihood distribution pˆθ(f, a|e). Instead of summing, this step simplifies the E-step. However, under our modification of maximum likelihood estimate with MAP estimate, this simplification is not a correct approximation of the summation since our surface in the E-step is greatly perturbed by the prior. There is no guarantee that the Viterbi alignment is within the proximity of th</context>
</contexts>
<marker>Koehn, 2010</marker>
<rawString>Koehn, Philipp. 2010. Statistical Machine Translation. Cambridge University Press. Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>An Algorithm for finding Noun Phrase Correspondences in Bilingual Corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of Association for Computational Linguistics.</booktitle>
<pages>17--22</pages>
<location>Columbus. OH.</location>
<contexts>
<context position="13810" citStr="Kupiec (1993)" startWordPosition="2402" endWordPosition="2404"> of seven steps. We use the Model I prior for the case where our prior knowledge is sparse and evenly distributed throughout the corpus, whereas we use the Model II prior when our prior knowledge is dense in a partial corpus. A typical example of the former case is when we use partial alignment annotation extracted throughout a corpus for bilingual terminology. A typical example of the latter case is when a sample of only a few hundred lines from the corpus have been hand-annotated. 4.1 MWE Extraction Our algorithm of extracting MWEs is a statistical method which is a bidirectional version of Kupiec (1993). Firstly, Kupiec presents a method to extract bilingual MWE pairs in a unidirectional manner based on the knowledge about typical POS patterns of noun phrases, which is languagedependent but can be written down with some ease by a linguistic expert. For example in French they are N N, N prep N, and N Adj. Secondly, we take the intersection (or union) of extracted bilingual MWE pairs.2 2In word alignment, bidirectional word alignment by taking the intersection or union is a standard method which improves its quality compared to unidirectional word alignment. 29 Algorithm 2 MWE Extraction Algor</context>
<context position="15233" citStr="Kupiec (1993)" startWordPosition="2659" endWordPosition="2660">noun phrases on the SL side. 3. Count n-gram statistics (typically n = 1, · · · , 5 are used) on the TL side which jointly occur with each source noun phrase extracted in Step 2. 4. Obtain the maximum likelihood counts of joint phrases, i.e. noun phrases on the SL side and n-gram phrases on the TL side. 5. Repeat the same procedure from Step 1 to 4 reversing the SL and TL. 6. Intersect (or union) the results in both directions. Let SL be the source language side and TL be the target language side. The procedure is shown in Algorithm 2. We informally evaluated the MWE extraction tool following Kupiec (1993) by manually inspecting the mapping of the 100 most frequent terms. For example, we found that 93 of the 100 most frequent English terms in the patent corpus were correctly mapped to their Japanese translation. Depending on the corpus, we can use more prior knowledge about implicit alignment links. For example in some categories of patent and technical documents corpora,3 we can use heuristics to extract the “noun phrase” + “reference number” from both sides. This is due to the fact that terminology is often labelled with a unique reference number, which is labelled on both the SL and TL sides</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Kupiec, Julian. 1993. An Algorithm for finding Noun Phrase Correspondences in Bilingual Corpora. In Proceedings of the 31st Annual Meeting of Association for Computational Linguistics. Columbus. OH. pp. 17–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrik Lambert</author>
<author>Rafael Banchs</author>
</authors>
<title>Grouping Multi-word Expressions According to Part-OfSpeech in Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL Workshop on Multi-WordExpressions in a Multilingual Context.</booktitle>
<pages>9--16</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="2736" citStr="Lambert and Banchs (2006)" startWordPosition="415" endWordPosition="418">it tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, and monetary information. Resnik and Melamed (1997) automatically extract domainspecific lexica. Moore (2003) extracts namedentities. In Machine Translation, Lambert and Banchs (2006) extract BMWEs from a phrase table, which is an outcome of word alignment followed by phrase extraction; this method does not alter the word alignment process. This paper introduces a new method of incorporating previously known many-to-many word correspondences into word alignment. A well-known method of incorporating such prior knowledge in Machine Learning is to replace the likelihood maximization in the M-step of the EM algorithm with either the MAP estimate or the Maximum Penalized Likelihood (MPL) estimate (McLach26 Proceedings of the 4th International Workshop on Cross Lingual Informati</context>
</contexts>
<marker>Lambert, Banchs, 2006</marker>
<rawString>Lambert, Patrik and Rafael Banchs. 2006. Grouping Multi-word Expressions According to Part-OfSpeech in Statistical Machine Translation. In Proceedings of the EACL Workshop on Multi-WordExpressions in a Multilingual Context. Trento, Italy, pp. 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey J McLachlan</author>
<author>Thriyambakam Krishnan</author>
</authors>
<title>The EM Algorithm and Extensions. Wiley Series in probability and statistics.</title>
<date>1997</date>
<location>New York, NY.</location>
<marker>McLachlan, Krishnan, 1997</marker>
<rawString>McLachlan, Geoffrey J. and Thriyambakam Krishnan, 1997. The EM Algorithm and Extensions. Wiley Series in probability and statistics. New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Learning Translations of Named-Entity Phrases from Parallel Corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<pages>259--266</pages>
<location>Budapest,</location>
<contexts>
<context position="2662" citStr="Moore (2003)" startWordPosition="407" endWordPosition="408"> extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, and monetary information. Resnik and Melamed (1997) automatically extract domainspecific lexica. Moore (2003) extracts namedentities. In Machine Translation, Lambert and Banchs (2006) extract BMWEs from a phrase table, which is an outcome of word alignment followed by phrase extraction; this method does not alter the word alignment process. This paper introduces a new method of incorporating previously known many-to-many word correspondences into word alignment. A well-known method of incorporating such prior knowledge in Machine Learning is to replace the likelihood maximization in the M-step of the EM algorithm with either the MAP estimate or the Maximum Penalized Likelihood (MPL) estimate (McLach2</context>
</contexts>
<marker>Moore, 2003</marker>
<rawString>Moore, Robert C.. 2003. Learning Translations of Named-Entity Phrases from Parallel Corpora. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics. Budapest, Hungary. pp. 259–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>On Log-Likelihood-Ratios and the Significance ofRare Events.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<pages>333--340</pages>
<location>Barcelona,</location>
<marker>Moore, 2004</marker>
<rawString>Moore, Robert C.. 2004. On Log-Likelihood-Ratios and the Significance ofRare Events. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP). Barcelona, Spain, pp. 333–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Herman Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics.</journal>
<volume>29</volume>
<issue>1</issue>
<pages>pp.</pages>
<contexts>
<context position="1576" citStr="Och and Ney, 2003" startWordPosition="244" endWordPosition="247"> MAP estimate. In our experiments, we saw an improvement of 0.77 Bleu points absolute in JP–EN. Except for one case, our method gave better results than the method using only BMWEs grouping. Even though this paper does not directly address the issues in CrossLingual Information Retrieval (CLIR), it discusses an approach of direct relevance to the field. This approach could be viewed as the opposite of current trends in CLIR on semantic space that incorporate a notion of order in the bag-of-words model (e.g. co-occurences). 1 Introduction Word alignment (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2003a; Graca et al., 2007) remains key to providing high-quality translations as all subsequent training stages rely on its performance. It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them. Some aligned corpora include implicit partial alignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fuji</context>
<context position="22163" citStr="Och and Ney, 2003" startWordPosition="3953" endWordPosition="3956">s′i, f′j =� t′j for aj)) p(i − i′; I) = { p(i − i′; I) = { 31 Prior for Sampled Alignment (Function) Space This is identical to that of the Prior Model II exhaustive alignment space with only a difference in the normalization process. Prior for Jump Width i′ This categorization of Prior Model II is the same as that of Prior Model I for for Jump Width i′ (see Section 4.2). Note that Prior Model II requires more memory compared to the Prior Model I.6 5 Experimental Settings The baseline in our experiments is a standard log-linear phrase-based MT system based on Moses. The GIZA++ implementation (Och and Ney, 2003a) of IBM Model 4 is used as the baseline for word alignment, which we compare to our modified GIZA++. Model 4 is incrementally trained by performing 5 iterations of Model 1, 5 iterations of HMM, 5 iterations of Model 3, and 5 iterations of Model 4. For phrase extraction the grow-diag-final heuristics are used to derive the refined alignment from bidirectional alignments. We then perform MERT while a 5-gram language model is trained with SRILM. Our implementation is based on a modified version of GIZA++ (Och and Ney, 2003a). This modification is on the function that reads a bilingual terminolo</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz and Herman Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics. 29(1), pp. 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>I Dan Melamed</author>
</authors>
<title>SemiAutomatic Acquisition of Domain-Specific Translation Lexicons.</title>
<date>1997</date>
<booktitle>Proceedings of the 5th Applied Natural Language Processing Conference.</booktitle>
<pages>340--347</pages>
<location>Washington, DC.,</location>
<contexts>
<context position="2604" citStr="Resnik and Melamed (1997)" startWordPosition="398" endWordPosition="401">lignment annotation, while for other corpora a partial alignment can be extracted by state-ofthe-art techniques. For example, implicit tags such as reference number within the patent corpus of Fujii et al. (2010) provide (often many-tomany) correspondences between source and target words, while statistical methods for extracting a partial annotation, like Kupiec et al. (1993), extract terminology pairs using linguistically predefined POS patterns. Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, and monetary information. Resnik and Melamed (1997) automatically extract domainspecific lexica. Moore (2003) extracts namedentities. In Machine Translation, Lambert and Banchs (2006) extract BMWEs from a phrase table, which is an outcome of word alignment followed by phrase extraction; this method does not alter the word alignment process. This paper introduces a new method of incorporating previously known many-to-many word correspondences into word alignment. A well-known method of incorporating such prior knowledge in Machine Learning is to replace the likelihood maximization in the M-step of the EM algorithm with either the MAP estimate o</context>
</contexts>
<marker>Resnik, Melamed, 1997</marker>
<rawString>Resnik, Philip and I. Dan Melamed, 1997. SemiAutomatic Acquisition of Domain-Specific Translation Lexicons. Proceedings of the 5th Applied Natural Language Processing Conference. Washington, DC., pp. 340–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
</authors>
<title>Constrained EMfor parallel text alignment,</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>3</issue>
<pages>263--277</pages>
<contexts>
<context position="4425" citStr="Talbot (2005)" startWordPosition="689" endWordPosition="691">over model parameters such as stochastic constraints and agreement constraints. These constraints are set in the E-step to discard intractable alignments contradicting these constraints. This mechanism in the E-step is in a similar spirit to that in GIZA++ for IBM Model 3 and 4 which only searches around neighbouring alignments around the Viterbi alignment. For this reason, this algorithm is not intended to be used combined with IBM Models 3 and 4. Although theoretically it is possible to incorporate partial annotation with a small change in its code, Graca et al. do not mention it. Secondly, Talbot (2005) introduces a constrained EM method which constrains the E-step to incorporate partial alignment into word alignment,1 which is in a similar manner to Graca et al. (2007). He conducted experiments using partial alignment annotation based on cognate relations, a bilingual dictionary, domain-specific bilingual semantic annotation, and numerical pattern matching. He did not incorporate BMWEs. Thirdly, Callison-Burch et al. (2004) replace the likelihood maximization in the M-step with mixed likelihood maximization, which is a convex combination of negative log likelihood of known links and unknown</context>
</contexts>
<marker>Talbot, 2005</marker>
<rawString>Talbot, David. 2005. Constrained EMfor parallel text alignment, Natural Language Engineering, 11(3): pp. 263–277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Reliable Measures for Aligning Japanese-English News Articles and Sentences,</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>72--79</pages>
<location>Sapporo,</location>
<contexts>
<context position="16215" citStr="Utiyama and Isahara, 2003" startWordPosition="2821" endWordPosition="2824">ocuments corpora,3 we can use heuristics to extract the “noun phrase” + “reference number” from both sides. This is due to the fact that terminology is often labelled with a unique reference number, which is labelled on both the SL and TL sides. 4.2 Prior Model I Prior for Exhaustive Alignment Space IBM Models 1 and 2 implement a prior for all possible 3Unlike other language pairs, the availability of Japanese–English parallel corpora is quite limited: the NTCIR patent corpus (Fujii et al., 2010) of 3 million sentence pairs (the latest NTCIR-8 version) for the patent domain and JENAAD corpus (Utiyama and Isahara, 2003) of 150k sentence pairs for the news domain. In this regard, the patent domain is particularly important for this particular language pair. Algorithm 3 Prior Model I for IBM Model 1 Given: parallel corpus ˘e, ˘f, anchor words biTerm initialize t(e|f) uniformly do until convergence set count(e|f) to 0 for all e,f set total(f) to 0 for all f for all sentence pairs (˘es, ˘fs) prior(e|f)3 = getPriorModelI(˘e, ˘f, biTerm) for all words e in ˘es totals(e) = 0 for all words f in ˘fs totals(e) += t(e|f) for all words e in ˘es for all words f in ˘fs count(e|f)+=t(e|f)/total3(e)× prior(e|f)3 total(f) +=</context>
</contexts>
<marker>Utiyama, Isahara, 2003</marker>
<rawString>Utiyama, Masao and Hitoshi Isahara. 2003. Reliable Measures for Aligning Japanese-English News Articles and Sentences, In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics. Sapporo, Japan, pp. 72–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
</authors>
<title>Christoph Tillmann</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics.</booktitle>
<pages>836--841</pages>
<location>Copenhagen,</location>
<marker>Vogel, Ney, 1996</marker>
<rawString>Vogel, Stephan, Hermann Ney, Christoph Tillmann 1996. HMM-Based Word Alignment in Statistical Translation. In Proceedings of the 16th International Conference on Computational Linguistics. Copenhagen, Denmark, pp. 836–841.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>