<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000202">
<title confidence="0.997179">
Information Classification and Navigation
Based on 5W1H of the Target Information
</title>
<author confidence="0.872319">
Takahiro Ikeda and Akitoshi Okumura and Kazunori Muraki
</author>
<affiliation confidence="0.865369">
C&amp;C Media Research Laboratories, NEC Corporation
</affiliation>
<address confidence="0.71103">
4-1-1 Miyazaki, Miyamae-ku, Kawasaki, Kanagawa 216
</address>
<sectionHeader confidence="0.975157" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971727272727">
This paper proposes a method by which 5W1H (who,
when, where, what, why, how, and predicate) infor-
mation is used to classify and navigate Japanese-
language texts. 5W1H information, extracted from
text data, has an access platform with three func-
tions: episodic retrieval, multi-dimensional classi-
fication, and overall classification. In a six-month
trial, the platform was used by 50 people to access
6400 newspaper articles. The three functions proved
to be effective for office documentation work and the
precision of extraction was approximately 82%.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939794117647">
In recent years, we have seen an explosive growth
in the volume of information available through on-
line networks and from large capacity storage de-
vices. High-speed and large-scale retrieval tech-
niques have made it possible to receive information
through information services such as news clipping
and keyword-based retrieval. However, information
retrieval is not a purpose in itself, but a means in
most cases. In office work, users use retrieval ser-
vices to create various documents such as proposals
and reports.
Conventional retrieval services do not provide
users with a good access platform to help them
achieve their practical purposes (Sakamoto, 1997;
Lesk et al., 1997). They have to repeat retrieval
operations and classify the data for themselves.
To overcome this difficulty, this paper proposes
a method by which 5W1H (who, when, where,
what, why, how, and predicate) information can
be used to classify and navigate Japanese-language
texts. 5W1H information provides users with easy-
to-understand classification axes and retrieval keys
because it has a set of fundamental elements needed
to describe events.
In this paper, we discuss common information
retrieval requirements for office work and describe
the three functions that our access platform us-
ing 5W1H information provides: episodic retrieval,
multi-dimensional classification, and overall classifi-
cation. We then discuss 5W1H extraction methods,
and, finally, we report on the results of a six-month
trial in which 50 people, linked to a company in-
tranet, used the platform to access newspaper arti-
cles.
</bodyText>
<sectionHeader confidence="0.9949685" genericHeader="introduction">
2 Retrieval Requirements In an
Office
</sectionHeader>
<bodyText confidence="0.999663875">
Information retrieval is an extremely important part
of office work, and particularly crucial in the creation
of office documents. The retrieval requirements in
office work can be classified into three types.
Episodic viewpoint: We are often required to
make an episode, temporal transition data on a cer-
tain event. For example, &amp;quot;Company X succeeded
in developing a two-gigabyte memory&amp;quot; makes the
user want to investigate what kind of events were
announced about Company X&apos;s memory before this
event. The user has to collect the related events
and then arrange them in temporal order to make
an episode.
Comparative viewpoint: The comparative view-
point is familiar to office workers. For example,
when the user fills out a purchase request form to
buy a product, he has to collect comparative infor-
mation on price, performance and so on, from several
companies. Here, the retrieval is done by changing
retrieval viewpoints.
Overall viewpoint: An overall viewpoint is neces-
sary when there is a large amount of classification
data. When a user produces a technical analysis re-
port after collecting electronics-related articles from
a newspaper over one year, the amount of data is
too large to allow global tendencies to be interpreted
such as when the events occurred, what kind of com-
panies were involved, and what type of action was
required. Here, users have to repeat retrieval and
classification by choosing appropriate keywords to
condense classification so that it is not too broad-
ranging to understand.
</bodyText>
<page confidence="0.99307">
571
</page>
<figure confidence="0.943486">
Overall classification
Information
</figure>
<figureCaption confidence="0.999762">
Figure 1: 5W1H classification and navigation
</figureCaption>
<sectionHeader confidence="0.9781185" genericHeader="method">
3 5W1H Classification and
Navigation
</sectionHeader>
<bodyText confidence="0.999816909090909">
Conventional keyword-based retrieval does not con-
sider logical relationships between keywords. For ex-
ample, the condition, &amp;quot;NEC &amp; semiconductor &amp; pro-
duce&amp;quot; retrieves an article containing &amp;quot;NEC formed
a technical alliance with B company, and B com-
pany produced semiconductor X.&amp;quot; Mine et al. and
Satoh et al. reported that this problem leads to re-
trieval noise and unnecessary results (Mine et al.,
1997; Satoh and Murald, 1993). This problem makes
it difficult to meet the requirements of an office be-
cause it produces retrieval noise in these three types
of operations.
5W1H information is who, when, where, what,
why, how, and predicate information extracted from
text data through the 5W1H extraction module us-
ing language dictionary and sentence analysis tech-
niques. 5W1H extraction modules assign 5W1H in-
dexes to the text data. The indexes are stored in list
form of predicates and arguments (when, who, what,
why, where, how) (Lesk et al., 1997). The 5W1H
index can suppress retrieval noise because the in-
dex considers the logical relationships between key-
words. For example, the 5W1H index makes it pos-
sible to retrieve texts using the retrieval condition
&amp;quot;who: NEC &amp; what: semiconductor &amp; predicate:
produce.&amp;quot; It can filter out the article containing
&amp;quot;NEC formed a technical alliance with B company,
and B company produced semiconductor X.&amp;quot;
Based on 5W1H information, we propose a 5W1H
classification and navigation model which can meet
office retrieval requirements. The model has three
functions: episodic retrieval, multi-dimensional clas-
sification, and overall classification (Figure 1).
</bodyText>
<subsectionHeader confidence="0.997174">
3.1 Episodic Retrieval
</subsectionHeader>
<bodyText confidence="0.99852">
The 5W1H index can easily do episodic retrieval
by choosing a set of related events and arranging
</bodyText>
<figure confidence="0.768041555555556">
96.10 NEC adjusts semiconductor production downward.
96.12 NEC postpones semiconductor production plant
construction.
97.1 NEC shifts semiconductor production to 64 Megabit next
generation DRAMs.
97.4 NEC invests V 40 billion for next generation
semiconductor production.
97.5 NEC semiconductor production 18% more than
expected.
</figure>
<figureCaption confidence="0.9230805">
Figure 2: Episodic retrieval example
X Corp. ... ...
:
Figure 3: Multi-dimensional classification example
</figureCaption>
<bodyText confidence="0.99970025">
the events in temporal order. The results are read-
able by users as a kind of episode. For example,
an NEC semiconductor production episode is made
by retrieving texts containing &amp;quot;who: NEC &amp; what:
semiconductor St predicate: product&amp;quot; indexes and
sorting the retrieved texts in temporal order (Figure
2).
The 5W1H index can suppress retrieval noise by
conventional keyword-based retrieval such as &amp;quot;NEC
&amp; semiconductor &amp; produce.&amp;quot; Also, the result is an
easily readable series of events which is able to meet
episodic viewpoint requirements in office retrieval.
</bodyText>
<subsectionHeader confidence="0.994919">
3.2 Multi-dimensional Classification
</subsectionHeader>
<bodyText confidence="0.999353555555556">
The 5W1H index has seven-dimensional axes for
classification. Texts are classified into categories on
the basis of whether they contain a certain combi-
nation of 5W1H elements or not. Though 5W1H
elements create seven-dimensional space, users are
provided with a two-dimensional matrix because this
makes it easier for them to understand text distri-
bution. Users can choose a fundamental viewpoint
from 5W1H elements to be the vertical axis. The
other elements are arranged on the horizontal axis
as the left matrix of Figure 3 shows. Classification
makes it possible to access data from a user&apos;s com-
parative viewpoints by combining 5W1H elements.
For example, the cell specified by NEC and PC
shows the number of articles containing NEC as a
&amp;quot;who&amp;quot; element and PC as a &amp;quot;what&amp;quot; element.
Users can easily obtain comparable data by
switching their fundamental viewpoint from the
</bodyText>
<figure confidence="0.991789619047619">
Episodic
retrieval
Multi-dimensional
classification
sell
produce
PC
HD
572
Who
NEC opens a new internet service.
A Corp. develops a new computer.
..
B Inc. puts a portable terminal on the market.
C Telecommunication starts a virtual market.
&lt;
Electric
Company
Communi-
cation
D Telephone sells a communication adapter.
</figure>
<figureCaption confidence="0.999949">
Figure 4: Overall classification example
</figureCaption>
<bodyText confidence="0.99965575">
&amp;quot;who&amp;quot; viewpoint to the &amp;quot;what&amp;quot; viewpoint, for ex-
ample, as the right matrix of Figure 3 shows. This
meets comparative viewpoint requirements in office
retrieval.
</bodyText>
<subsectionHeader confidence="0.999535">
3.3 Overall Classification
</subsectionHeader>
<bodyText confidence="0.9999727">
When there are a large number of 5W1H elements,
the classification matrix can be packed by using a
thesaurus. As 5W1H elements are represented by
upper concepts in the thesaurus, the matrix can be
condensed. Figure 4 has an example with six &amp;quot;who&amp;quot;
elements which are represented by two categories.
The matrix provides users with overall classification
as well as detailed sub-classification through the se-
lection of appropriate hierarchical levels. This meets
overall classification requirements in office retrieval.
</bodyText>
<sectionHeader confidence="0.991646" genericHeader="method">
4 5W1H Information Extraction
</sectionHeader>
<bodyText confidence="0.977398306451613">
5W1H extraction was done by a case-based shal-
low parsing (CBSP) model based on the algorithm
used in the VENIEX, Japanese information extrac-
tion system (Muraki et al., 1993). CBSP is a robust
and effective method of analysis which uses lexical
information, expression patterns and case-markers
in sentences. Figure 5 shows the detail on the algo-
rithm for CBSP.
In this algorithm, input sentences are first seg-
mented into words by Japanese morphological anal-
ysis (Japanese sentences have no blanks between
words.) Lexical information is linked to each word
such as the part-of-speech, root forms and semantic
categories.
Next, 5W1H elements are extracted by proper
noun extraction, pattern expression matching and
case-maker matching.
In the proper noun extraction phase, a 60 000-
word proper noun dictionary made it possible to
indicate people&apos;s names and organization names as
&amp;quot;who&amp;quot; elements and place names as &amp;quot;where&amp;quot; ele-
ments. For example, NEC and China are respec-
tively extracted as a &amp;quot;who&amp;quot; element and a &amp;quot;where&amp;quot;
procedure CBSP;
begin
Apply morphological analysis to the sentence;
foreach word in the sentence do begin
if the word is a people&apos;s name or
an organization name then
Mark the word as a &amp;quot;who&amp;quot; element and
push it to the stack;
else if the word is a place name then
Mark the word as a &amp;quot;where&amp;quot; element and
push it to the stack;
else if the word matches an organization
name pattern then
Mark the word as a &amp;quot;who&amp;quot; element and
push it to the stack;
else if the word matches a date pattern then
Mark the word as a &amp;quot;when&amp;quot; element and
push it to the stack;
else if the word is a noun then
if the next word is or it then
Mark the word and the kept unspecified
elements as &amp;quot;who&amp;quot; elements and
push them to the stack;
if the next word is or r. then
Mark the word and the kept unspecified
elements as &amp;quot;what&amp;quot; elements and
push them to the stack;
else
Keep the word as an unspecified element;
else if the word is a verb then begin
Fix the word as the predicate element of
a 5W1H set;
repeat
Pop one marked word from the stack;
if the 5W1H element
corresponding to the mark
of the word is not fixed then
Fix the word as the 5W1H element
corresponding to its mark;
</bodyText>
<figure confidence="0.653006833333333">
else
break repeat;
until stack is empty;
end
end
end
</figure>
<figureCaption confidence="0.99951">
Figure 5: The algorithm for CBSP
</figureCaption>
<bodyText confidence="0.9548524">
element from the sentence, &amp;quot;NEC tlii:1111-C *4*
t go (NEC produces semiconductors in China.)&amp;quot;
In the pattern expression matching phase, the sys-
tem extracts words matching predefined patterns as
&amp;quot;who&amp;quot; and &amp;quot;when&amp;quot; elements. There are several typ-
</bodyText>
<page confidence="0.998958">
573
</page>
<tableCaption confidence="0.977776">
Table 1: The results of evaluation for &amp;quot;who,&amp;quot; &amp;quot;what,&amp;quot; and &amp;quot;predicate&amp;quot; elements and overall extracted
information.
</tableCaption>
<table confidence="0.999845166666667">
&amp;quot;Who&amp;quot; elements &amp;quot;What&amp;quot; elements &amp;quot;Predicate&amp;quot; elements Overall
Present Absent Total Present Absent Total Present Absent Total
Correct 5423 71 5494 5653 50 5703 6042 5 6047 5270
Error 414 490 904 681 14 695 55 296 351 1128
Total 5837 561 6398 6334 64 6398 6097 301 6398 6396
Precision 92.9% 12.7% 85.9% 89.2% 78.1% 89.1% 99.1% 1.7% 94.5% 82.4%
</table>
<bodyText confidence="0.998309653846154">
ical patterns for organization names and people&apos;s
names, dates, and places (Murald et al., 1993). For
example, nouns followed by --1± (Co., Inc. Ltd.) and
(Univ.) mean they are organizations and &amp;quot;who&amp;quot;
elements. For example, 1998 4 18 El (April 18,
1998) can be identified as a date. &amp;quot;When&amp;quot; elements
can be recognized by focusing on the pattern for
(year), (month), and El (day).
For words which are not extracted as 5W1H el-
ements in previous phases, the system decides its
5W1H index by case marker matching. The system
checks the relationships between Japanese particles
(case markers) and verbs and assigns a 5W1H in-
dex to each word according to rules such as tt is a
marker of a &amp;quot;who&amp;quot; element and is a marker of a
&amp;quot;what&amp;quot; element. In the example &amp;quot;A littRA X
R-Pc (Company A sells product X.),&amp;quot; company A is
identified as a &amp;quot;who&amp;quot; element according to the case
marker 41 if it is not specified as a &amp;quot;who&amp;quot; element
by proper noun extraction and pattern expression
matching.
5W1H elements followed by a verb (predicate) are
fixed as a 5W1H set so that a 5W1H set does not
include two elements for the same 5W1H index. A
5W1H element belongs to the same 5W1H set as the
nearest predicate after it.
</bodyText>
<sectionHeader confidence="0.999309" genericHeader="method">
5 Information Access Platform
</sectionHeader>
<bodyText confidence="0.998340785714286">
5W1H information classification and navigation
works in the information access platform. The plat-
form disseminates users with newspaper information
through the company intranet. The platform struc-
ture is shown in Figure 6.
Web robots collect newspaper articles from spec-
ified URLs every day. The data is stored in the
database, and a 5W1H index data is made for the
data. Currently, 6398 news articles are stored in the
databases. Some articles are disseminated to users
according to their profiles. Users can browse all the
data through WWW browsers and use 5W1H classi-
fication and navigation functions by typing sentences
or specifying regions in the browsing texts.
</bodyText>
<table confidence="0.570031789473684">
WWW
robots
Dissemination
User
5W1H
extraction
Multi-
dimensional
classification
WWW
browser
ts.
5W1H
INDEX
Information Episodic
Database retrieval
...
1/4 Overall
classification
</table>
<figureCaption confidence="0.999563">
Figure 6: Information access interface structure
</figureCaption>
<bodyText confidence="0.9357586">
5W1H elements are automatically extracted from
the typed sentences and specified regions. The ex-
tracted 5W1H elements are used as retrieval keys for
episodic retrieval, and as axes for multi-dimensional
classification and overall classification.
</bodyText>
<subsectionHeader confidence="0.934524">
5.1 5W1H Information Extraction
</subsectionHeader>
<bodyText confidence="0.999988684210526">
&amp;quot;When,&amp;quot; &amp;quot;who,&amp;quot; &amp;quot;what,&amp;quot; and &amp;quot;predicate&amp;quot; informa-
tion has been extracted from 6398 electronics in-
dustry news articles since August, 1996. We have
evaluated extracted information for 6398 news head-
lines. The headline average length is approximately
12 words. Table 1 shows the result of evaluating
&amp;quot;who,&amp;quot; &amp;quot;what,&amp;quot; and &amp;quot;predicate&amp;quot; information and
overall extracted information.
In this table, the results are classified with re-
gard to the presence of corresponding elements in the
news headlines. More than 90% of &amp;quot;who,&amp;quot; &amp;quot;what,&amp;quot;
and &amp;quot;predicate&amp;quot; elements can correctly be extracted
with our extraction algorithm from headlines having
such elements. On the other hand, the algorithm
is not highly precise when there is no correspond-
ing element in the article. The errors are caused
by picking up other elements despite the absence
of the element to be extracted. However, the er-
rors hardly affect applications such as episodic re-
</bodyText>
<page confidence="0.994094">
574
</page>
<figure confidence="0.989363470588235">
)rri.6 Ma, abi263 rA,-X80 X1,0a, re.r.61. rto
&amp;quot;row pow aow rpm ror-w sr.:a verge .101,740 %MD
4-1-11kd eaF,1s1a1dtj,e.1
z Awl
[NEC t-mrgtisr1o)5Leniva•m1t.L5rav mum,
Ninon]] rieltitiallIE_T:.-111,1 el
E moj &lt;iv= c 2±irs.7.4441, tOTAPNVEL TOR M
DT/1/1 att..nektrIlt6414-41:1F.A.a.c.c.:7h- -NEC g
or/I/21] ‹..e rtffl&apos;ZY-41VAIL g
fr /5/11146..TC).4r56.e)-qi%.skfiratiulizewsaliAtzoxpiliPi[:
NEC. Militt_tmItt-F7311.1
ZCZ6VidaTignrgrairannelara
•-•
It, .
orlinagr:,=+if Mints?.c131P39$41,. . AM/WM
2■A .ste:
S.
</figure>
<figureCaption confidence="0.999933">
Figure 7: Episodic retrieval example (2)
</figureCaption>
<bodyText confidence="0.9994025">
trieval and multi-dimensional classification because
they only add unnecessary information and do not
remove necessary information.
The precision independent of the presence of the
element is from 85% to 95% for each, and the overall
precision is 82.4%.
</bodyText>
<subsubsectionHeader confidence="0.870823">
5.1.1 Episodic Retrieval
</subsubsectionHeader>
<figureCaption confidence="0.853688">
Figure 7 is an actual screen of Figure 2, which shows
</figureCaption>
<bodyText confidence="0.978236904761905">
an example of episodic retrieval based on headline
news saying, &amp;quot;NECtl*:41$0Dt.g -*.&amp;quot; 1 P) 18%1
(NEC produces 18% more semiconductors than ex-
pected)&amp;quot; The user specifies the region, &amp;quot;NEC tl
*-4&apos;*a) tg (NEC produces semiconductors)&amp;quot; on
the headline for episodic retrieval. A &amp;quot;who&amp;quot; element
NEC, a &amp;quot;what&amp;quot; element *44 (semiconductor), and
a &amp;quot;predicate&amp;quot; element tg (produce) are episodic re-
trieval keys. The extracted results are NEC&apos;s semi-
conductor production story.
The upper frame of the window lists a set of head-
lines arranged in temporal order. In each article,
NEC is a &amp;quot;who&amp;quot; element, the semiconductor is a
&amp;quot;what&amp;quot; element and production is a &amp;quot;predicate&amp;quot; el-
ement. By tracing episodic headlines, the user can
find that the semiconductor market was not good at
the end of 1996 but that it began turning around
in 1997. The lower frame shows an article corre-
sponding to the headline in the upper frame. When
the user clicks the 96/10/21 headline, the complete
article is displayed in the lower frame.
</bodyText>
<subsubsectionHeader confidence="0.873268">
5.1.2 Multi-dimensional Classification
</subsubsectionHeader>
<bodyText confidence="0.75687575">
Figures 8 and 9 show multi-dimensional classifica-
tion results based on the headline, &amp;quot;NEC • A 1±•
B op El Via* (NEC, A
Co., and B Co. are developing encoded data recov-
</bodyText>
<figure confidence="0.931600444444444">
93
NEc. $.1.1311 414FTLF—MMXIMUN---
IMINI 1114.1
1&amp;quot;&amp;quot; Wit 4•- iffir awl
InaZT 21—a-
Eittkila 211 zEt MA DA
7nE7 Uf— 2t7 11. Et Ulf
[97/62/02) NE..7-0±,1341 1-614t —iirDErittirMtN31^-
[96/1 6/021 NEC PENABISOAP-4-mtc,tv-71-tron
</figure>
<figureCaption confidence="0.994212">
Figure 8: Multi-dimensional classification example
</figureCaption>
<figure confidence="0.65963">
7,4610 rei.69 6v/stp )11r,Aw 4,1”c? wdelva
</figure>
<figureCaption confidence="0.999183">
Figure 9: Multi-dimensional classification example
</figureCaption>
<bodyText confidence="0.997551769230769">
ery techniques.).&amp;quot; &amp;quot;Who&amp;quot; elements are &amp;quot;NEC, A
Co., and B Co.&amp;quot; listed on the vertical axis which is
the fundamental axis in the upper frame of Figure
8. &amp;quot;What&amp;quot; elements are &amp;quot;Hig-A (encode), -/-* — 3&apos;
(data), El l (recovery), and #59R (technique).&amp;quot; A
&amp;quot;predicate&amp;quot; element is a &amp;quot;MR (develop).&amp;quot; &amp;quot;What&amp;quot;
and &amp;quot;predicate&amp;quot; elements are both arranged on the
horizontal axis in the upper frame of Figure 8. When
clicking a cell for &amp;quot;who&amp;quot;: NEC and &amp;quot;what&amp;quot;: *1+1t
(encode), users can see the headlines of articles con-
taining the above two keywords in the lower frame
of Figure 8.
When clicking on the &amp;quot;What&amp;quot; cell in the upper
</bodyText>
<figure confidence="0.905737352941177">
Unkl:1
NE.c•An.Ell 10414L-7-&apos;-00MME
INN&amp;quot;-
What
REd AR.
iff.Ja
214&apos; di di-
mit .04 igt talossl
r?/4/7J Citiztr,,,F-PAliffillraP/Mtv4Pit I^
Iv /own] NEc•Ali• s MK. IL F 9COERVATEOCA
mn 6/021 NEC rEmilltiffiCARTY 111-0KV-7FVNIR
tognal att 4-7.034-- Lt-timR--
N6,08 ham Vc.4 aim I-ft...71414R &apos;f
[worm] nr± 1141;:_5(8V11.1rc*6:-,f-24414R
Dvivzol 4:4 — *.D+ ttATECIAR
195m/131E1i secAmagtentrmaitillakcnimommt st.
Jam MCI 117. Grt ,
</figure>
<page confidence="0.996719">
575
</page>
<bodyText confidence="0.9740725">
frame of Figure 8, the user can switch the funda-
mental axis from &amp;quot;who&amp;quot; to &amp;quot;what&amp;quot; (Figure 9, up-
per frame). By switching the fundamental axis, the
user can easily see classification from different view-
points. On clicking the cell for &amp;quot;what&amp;quot;: 1*-11L (en-
code) and &amp;quot;predicate&amp;quot;: onm. (develop), the user finds
eight headlines (Figure 9, lower frame). The user
can then see different company activities such as the
97/04/07 headline; &amp;quot;C ± tz9-&amp;quot;&apos;— ACM
(C Company has developed data
transmission encoding technology using a satellite),&amp;quot;
shown in the lower frame of Figure 9.
In this way, a user can classify article headlines by
switching 5W1H viewpoints.
</bodyText>
<subsubsectionHeader confidence="0.741297">
5.1.3 Overall Classification
</subsubsectionHeader>
<bodyText confidence="0.999969961538461">
Overall classification is condensed by using an orga-
nization and a technical thesaurus. The organization
thesaurus has three layers and 2800 items, and the
technical thesaurus has two layers and 1000 techni-
cal terms. &amp;quot;Who&amp;quot; and &amp;quot;what&amp;quot; elements are respec-
tively represented by the upper classes of the orga-
nization thesaurus and the technical thesaurus. The
upper classes are vertical and horizontal elements in
the multi-dimensional classification matrix. &amp;quot;Pred-
icate&amp;quot; elements are categorized by several frequent
predicates based on the user&apos;s priorities.
Figure 10 shows the results of overall classifica-
tion for 250 articles disseminated in April, 1997.
Here, &amp;quot;who&amp;quot; elements on the vertical axis are rep-
resented by industry categories instead of company
names, and &amp;quot;what&amp;quot; elements on the horizontal axis
are represented by technical fields instead of tech-
nical terms. On clicking the second cell from the
top of the &amp;quot;who&amp;quot; elements, X%1114A (electrical and
mechanical) in Figure 10, the user can view subcat-
egorized classification on electrical and mechanical
industries as indicated in Figure 11. Here, 1%4*
(electrical and mechanical) is expanded to the sub-
categories;tt&apos;f,l&apos;aia (general electric) II (power
electric), IZAIff (home electric), itiEVA (commu-
nication), and so on.
</bodyText>
<sectionHeader confidence="0.987015" genericHeader="method">
6 Current Status
</sectionHeader>
<bodyText confidence="0.9839054">
The information access platform was exploited dur-
ing the MIIDAS (Multiple Indexed Information Dis-
semination and Acquisition Service) project which
NEC used internally (Okumura et al., 1997). The
DEC Alpha workstation (300 MHz) is a server ma-
chine providing 5W1H classification and navigation
functions for 50 users through WWW browsers.
User interaction occurs through CGI and JAVA pro-
grams.
After a six-month trial by 50 users, four areas for
improvement become evident.
1) 5W1H extraction: 5W1H extraction precision was
approximately 82% for newspaper headlines. The
extraction algorithm should be improved so that it
can deal with embedded sentences and compound
sentences.
Also, dictionaries should be improved in order to be
able to deal with different domains such as patent
data and academic papers.
2) Episodic retrieval: The interface should be im-
proved so that the user can switch retrieval from
episodic to normal retrieval in order to compare re-
trieval data.
Episodic retrieval is based on the temporal sorting
of a set of related events. At present, geographic ar-
rangement is expected to become a branch function
for episodic retrieval. It is possible to arrange each
event on a map by using 5W1H index data. This
would enable users to trace moving events such as
the onset of a typhoon or the escape of a criminal.
</bodyText>
<listItem confidence="0.9163835">
3) Multi-dimensional classification: Some users need
to edit the matrix for themselves on the screen.
</listItem>
<figureCaption confidence="0.997045">
Figure 10: Overall classification for 97/4 news
Figure 11: Overall sub-classification for 97/4 news
</figureCaption>
<page confidence="0.991745">
576
</page>
<bodyText confidence="0.98764875">
Moreover, it is necessary to insert new keywords and
delete unnecessary keywords.
also plan to improve the 5W1H extraction algorithm,
dictionaries and the user interface.
</bodyText>
<sectionHeader confidence="0.999934" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.998761914285715">
SOM (Self-Organization Map) is an effective auto-
matic classification method for any data represented
by vectors (Kohonen, 1990). However, the meaning
of each cluster is difficult to understand intuitively.
The clusters have no logical meaning because they
depend on a keyword set based on the frequency that
keywords occur.
Scatter/Gather is clustering information based on
user interaction (Hearst and Pederson, 1995; Hearst
et al., 1995). Initial cluster sets are based on key-
word frequencies.
GALOIS/ULYSSES is a lattice-based classifica-
tion system and the user can browse information on
the lattice produced by the existence of keywords
(Carpineto and Romano, 1995).
5W1H classification and navigation is unique in
that it is based on keyword functions, not on the
existence of keywords.
Lifestream manages e-mail by focusing on tempo-
ral viewpoints (Freeman and Fertig, 1995). In this
sense, this idea is similar to our episodic retrieval
though the purpose and target are different.
Mine et al. and Hyodo and Ikeda reported on the
effectiveness of using dependency relations between
keywords for retrieval (Mine et al., 1997; Hyodo and
Ikeda, 1994).
As the 5W1H index is more informative than sim-
ple word dependency, it is possible to create more
functions. More informative indexing such as se-
mantic indexing and conceptual indexing can the-
oretically provide more sophisticated classification.
However, this indexing is not always successful for
practical use because of semantic analysis difficul-
ties. Consequently 5W1H is the most appropriate
indexing method from the practical viewpoint.
</bodyText>
<sectionHeader confidence="0.999168" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999985214285714">
This paper proposed a method by which 5W1H
(who, when, where, what, why, how, and predi-
cate) information is used to classify and navigate
Japanese-language texts. 5W1H information, ex-
tracted from text data, provides an access plat-
form with three functions: episodic retrieval, multi-
dimensional classification, and overall classification.
In a six-month trial, the platform was used by 50
people to access 6400 newspaper articles.
The three functions proved to be effective for of-
fice documentation work and the extraction preci-
sion was approximately 82%.
We intend to make a more quantitative evaluation
by surveying more users about the functions. We
</bodyText>
<sectionHeader confidence="0.966186" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999887666666667">
We would like to thank Dr. Satoshi Goto and Dr.
Takao Watanabe for their encouragement and con-
tinued support throughout this work.
We also appreciate the contribution of Mr.
Kenji Satoh, Mr. Takayoshi Ochiai, Mr. Satoshi
Shimokawara, and Mr. Masahito Abe to this work.
</bodyText>
<sectionHeader confidence="0.999426" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999804571428572">
C. Carpineto and G. Romano. 1995. A system for
conceptual structuring and hybrid navigation of text
database. In AAAI Fall Symposium on AI Application
in Knowledge Navigation and Retrieval, pages 20-25.
E. Freeman and S. Fertig. 1995. Lifestreams: Organiz-
ing your electric life. In AAAI Fall Symposium on Al
Application in Knowledge Navigation and Retrieval,
pages 38-44.
M. A. Hearst and J. 0. Pederson. 1995. Revealing col-
lection structure through information access interface.
In Proceedings of IJCAP95, pages 2047-2048.
M. A. Hearst, D. R. Karger, and J. 0. Pederson. 1995.
Scatter/gather as a tool for navigation of retrieval re-
sults. In AAAI Fall Symposium on Al Application in
Knowledge Navigation and Retrieval, pages 65-71.
Y. Hyodo and T. Ikeda. 1994. Text retrieval system used
on structure matching. The Transactions of The Insti-
tute of Electronics, Information and Communication
Engineers, J77-D-II(5):1028-1030.
T. Kohonen. 1990. The self-organizing map. In Proceed-
ings of IEEE, volume 78, pages 1059-1063.
M. Lesk, D. Cutting, J. Pedersen, T. Noreault, and
M. Koll. 1997. Real life information retrieval: com-
mercial search engines. In Proceedings of SIGIR&apos;97,
page 333, July.
T. Mine, K. Aso, and M. Amamiya. 1997. Japanese
document retrieval system on www using depen-
dency relations between words. In Proceedings of PA-
CL INC &apos;97, pages 290-215, September.
K. Muraki, S. Doi, and S. Ando. 1993. Description of
the veniex system as used for muc-r. In Proceedings
of MUC5, pages 147-159, August.
A. Okumura, T. Ikeda, and K. Muraki. 1997. Selec-
tive dissemination of information based on a multiple-
ontology. In Proceedings of IJCAI&apos;97 Ontology Work-
shop, pages 138-145, August.
H. Sakamoto. 1997. Natural language processing tech-
nology for information. In JEIDA NLP Workshop,
July.
K. Satoh and K. Muraki. 1993. Penstation for idea pro-
cessing. In Proceedings of NLPRS&apos;93, pages 153-158,
December.
</reference>
<page confidence="0.997279">
577
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.541304">
<title confidence="0.997633">Information Classification and Navigation Based on 5W1H of the Target Information</title>
<author confidence="0.999309">Ikeda Okumura Muraki</author>
<affiliation confidence="0.999831">C&amp;C Media Research Laboratories, NEC Corporation</affiliation>
<address confidence="0.951915">4-1-1 Miyazaki, Miyamae-ku, Kawasaki, Kanagawa 216</address>
<abstract confidence="0.957234">This paper proposes a method by which 5W1H (who, when, where, what, why, how, and predicate) information is used to classify and navigate Japaneselanguage texts. 5W1H information, extracted from text data, has an access platform with three functions: episodic retrieval, multi-dimensional classification, and overall classification. In a six-month trial, the platform was used by 50 people to access 6400 newspaper articles. The three functions proved to be effective for office documentation work and the of extraction was approximately</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Carpineto</author>
<author>G Romano</author>
</authors>
<title>A system for conceptual structuring and hybrid navigation of text database.</title>
<date>1995</date>
<booktitle>In AAAI Fall Symposium on AI Application in Knowledge Navigation and Retrieval,</booktitle>
<pages>20--25</pages>
<contexts>
<context position="22908" citStr="Carpineto and Romano, 1995" startWordPosition="3610" endWordPosition="3613">e automatic classification method for any data represented by vectors (Kohonen, 1990). However, the meaning of each cluster is difficult to understand intuitively. The clusters have no logical meaning because they depend on a keyword set based on the frequency that keywords occur. Scatter/Gather is clustering information based on user interaction (Hearst and Pederson, 1995; Hearst et al., 1995). Initial cluster sets are based on keyword frequencies. GALOIS/ULYSSES is a lattice-based classification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it is based on keyword functions, not on the existence of keywords. Lifestream manages e-mail by focusing on temporal viewpoints (Freeman and Fertig, 1995). In this sense, this idea is similar to our episodic retrieval though the purpose and target are different. Mine et al. and Hyodo and Ikeda reported on the effectiveness of using dependency relations between keywords for retrieval (Mine et al., 1997; Hyodo and Ikeda, 1994). As the 5W1H index is more informative than simple word dependency, it is possible to create more functions. More i</context>
</contexts>
<marker>Carpineto, Romano, 1995</marker>
<rawString>C. Carpineto and G. Romano. 1995. A system for conceptual structuring and hybrid navigation of text database. In AAAI Fall Symposium on AI Application in Knowledge Navigation and Retrieval, pages 20-25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Freeman</author>
<author>S Fertig</author>
</authors>
<title>Lifestreams: Organizing your electric life.</title>
<date>1995</date>
<booktitle>In AAAI Fall Symposium on Al Application in Knowledge Navigation and Retrieval,</booktitle>
<pages>38--44</pages>
<contexts>
<context position="23118" citStr="Freeman and Fertig, 1995" startWordPosition="3643" endWordPosition="3646">y depend on a keyword set based on the frequency that keywords occur. Scatter/Gather is clustering information based on user interaction (Hearst and Pederson, 1995; Hearst et al., 1995). Initial cluster sets are based on keyword frequencies. GALOIS/ULYSSES is a lattice-based classification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it is based on keyword functions, not on the existence of keywords. Lifestream manages e-mail by focusing on temporal viewpoints (Freeman and Fertig, 1995). In this sense, this idea is similar to our episodic retrieval though the purpose and target are different. Mine et al. and Hyodo and Ikeda reported on the effectiveness of using dependency relations between keywords for retrieval (Mine et al., 1997; Hyodo and Ikeda, 1994). As the 5W1H index is more informative than simple word dependency, it is possible to create more functions. More informative indexing such as semantic indexing and conceptual indexing can theoretically provide more sophisticated classification. However, this indexing is not always successful for practical use because of se</context>
</contexts>
<marker>Freeman, Fertig, 1995</marker>
<rawString>E. Freeman and S. Fertig. 1995. Lifestreams: Organizing your electric life. In AAAI Fall Symposium on Al Application in Knowledge Navigation and Retrieval, pages 38-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
<author>J</author>
</authors>
<title>Revealing collection structure through information access interface.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAP95,</booktitle>
<pages>2047--2048</pages>
<marker>Hearst, J, 1995</marker>
<rawString>M. A. Hearst and J. 0. Pederson. 1995. Revealing collection structure through information access interface. In Proceedings of IJCAP95, pages 2047-2048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
<author>D R Karger</author>
<author>J</author>
</authors>
<title>Scatter/gather as a tool for navigation of retrieval results.</title>
<date>1995</date>
<booktitle>In AAAI Fall Symposium on Al Application in Knowledge Navigation and Retrieval,</booktitle>
<pages>65--71</pages>
<contexts>
<context position="22678" citStr="Hearst et al., 1995" startWordPosition="3575" endWordPosition="3578">ver, it is necessary to insert new keywords and delete unnecessary keywords. also plan to improve the 5W1H extraction algorithm, dictionaries and the user interface. 7 Related Work SOM (Self-Organization Map) is an effective automatic classification method for any data represented by vectors (Kohonen, 1990). However, the meaning of each cluster is difficult to understand intuitively. The clusters have no logical meaning because they depend on a keyword set based on the frequency that keywords occur. Scatter/Gather is clustering information based on user interaction (Hearst and Pederson, 1995; Hearst et al., 1995). Initial cluster sets are based on keyword frequencies. GALOIS/ULYSSES is a lattice-based classification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it is based on keyword functions, not on the existence of keywords. Lifestream manages e-mail by focusing on temporal viewpoints (Freeman and Fertig, 1995). In this sense, this idea is similar to our episodic retrieval though the purpose and target are different. Mine et al. and Hyodo and Ikeda reported on the eff</context>
</contexts>
<marker>Hearst, Karger, J, 1995</marker>
<rawString>M. A. Hearst, D. R. Karger, and J. 0. Pederson. 1995. Scatter/gather as a tool for navigation of retrieval results. In AAAI Fall Symposium on Al Application in Knowledge Navigation and Retrieval, pages 65-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hyodo</author>
<author>T Ikeda</author>
</authors>
<title>Text retrieval system used on structure matching.</title>
<date>1994</date>
<journal>The Transactions of The Institute of Electronics, Information and Communication Engineers,</journal>
<pages>77--5</pages>
<contexts>
<context position="23392" citStr="Hyodo and Ikeda, 1994" startWordPosition="3688" endWordPosition="3691">lassification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it is based on keyword functions, not on the existence of keywords. Lifestream manages e-mail by focusing on temporal viewpoints (Freeman and Fertig, 1995). In this sense, this idea is similar to our episodic retrieval though the purpose and target are different. Mine et al. and Hyodo and Ikeda reported on the effectiveness of using dependency relations between keywords for retrieval (Mine et al., 1997; Hyodo and Ikeda, 1994). As the 5W1H index is more informative than simple word dependency, it is possible to create more functions. More informative indexing such as semantic indexing and conceptual indexing can theoretically provide more sophisticated classification. However, this indexing is not always successful for practical use because of semantic analysis difficulties. Consequently 5W1H is the most appropriate indexing method from the practical viewpoint. 8 Conclusion This paper proposed a method by which 5W1H (who, when, where, what, why, how, and predicate) information is used to classify and navigate Japan</context>
</contexts>
<marker>Hyodo, Ikeda, 1994</marker>
<rawString>Y. Hyodo and T. Ikeda. 1994. Text retrieval system used on structure matching. The Transactions of The Institute of Electronics, Information and Communication Engineers, J77-D-II(5):1028-1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kohonen</author>
</authors>
<title>The self-organizing map.</title>
<date>1990</date>
<booktitle>In Proceedings of IEEE,</booktitle>
<volume>78</volume>
<pages>1059--1063</pages>
<contexts>
<context position="22366" citStr="Kohonen, 1990" startWordPosition="3530" endWordPosition="3531">nable users to trace moving events such as the onset of a typhoon or the escape of a criminal. 3) Multi-dimensional classification: Some users need to edit the matrix for themselves on the screen. Figure 10: Overall classification for 97/4 news Figure 11: Overall sub-classification for 97/4 news 576 Moreover, it is necessary to insert new keywords and delete unnecessary keywords. also plan to improve the 5W1H extraction algorithm, dictionaries and the user interface. 7 Related Work SOM (Self-Organization Map) is an effective automatic classification method for any data represented by vectors (Kohonen, 1990). However, the meaning of each cluster is difficult to understand intuitively. The clusters have no logical meaning because they depend on a keyword set based on the frequency that keywords occur. Scatter/Gather is clustering information based on user interaction (Hearst and Pederson, 1995; Hearst et al., 1995). Initial cluster sets are based on keyword frequencies. GALOIS/ULYSSES is a lattice-based classification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it </context>
</contexts>
<marker>Kohonen, 1990</marker>
<rawString>T. Kohonen. 1990. The self-organizing map. In Proceedings of IEEE, volume 78, pages 1059-1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lesk</author>
<author>D Cutting</author>
<author>J Pedersen</author>
<author>T Noreault</author>
<author>M Koll</author>
</authors>
<title>Real life information retrieval: commercial search engines.</title>
<date>1997</date>
<booktitle>In Proceedings of SIGIR&apos;97,</booktitle>
<pages>333</pages>
<contexts>
<context position="1494" citStr="Lesk et al., 1997" startWordPosition="220" endWordPosition="223">me of information available through online networks and from large capacity storage devices. High-speed and large-scale retrieval techniques have made it possible to receive information through information services such as news clipping and keyword-based retrieval. However, information retrieval is not a purpose in itself, but a means in most cases. In office work, users use retrieval services to create various documents such as proposals and reports. Conventional retrieval services do not provide users with a good access platform to help them achieve their practical purposes (Sakamoto, 1997; Lesk et al., 1997). They have to repeat retrieval operations and classify the data for themselves. To overcome this difficulty, this paper proposes a method by which 5W1H (who, when, where, what, why, how, and predicate) information can be used to classify and navigate Japanese-language texts. 5W1H information provides users with easyto-understand classification axes and retrieval keys because it has a set of fundamental elements needed to describe events. In this paper, we discuss common information retrieval requirements for office work and describe the three functions that our access platform using 5W1H info</context>
<context position="5011" citStr="Lesk et al., 1997" startWordPosition="773" endWordPosition="776">m leads to retrieval noise and unnecessary results (Mine et al., 1997; Satoh and Murald, 1993). This problem makes it difficult to meet the requirements of an office because it produces retrieval noise in these three types of operations. 5W1H information is who, when, where, what, why, how, and predicate information extracted from text data through the 5W1H extraction module using language dictionary and sentence analysis techniques. 5W1H extraction modules assign 5W1H indexes to the text data. The indexes are stored in list form of predicates and arguments (when, who, what, why, where, how) (Lesk et al., 1997). The 5W1H index can suppress retrieval noise because the index considers the logical relationships between keywords. For example, the 5W1H index makes it possible to retrieve texts using the retrieval condition &amp;quot;who: NEC &amp; what: semiconductor &amp; predicate: produce.&amp;quot; It can filter out the article containing &amp;quot;NEC formed a technical alliance with B company, and B company produced semiconductor X.&amp;quot; Based on 5W1H information, we propose a 5W1H classification and navigation model which can meet office retrieval requirements. The model has three functions: episodic retrieval, multi-dimensional classi</context>
</contexts>
<marker>Lesk, Cutting, Pedersen, Noreault, Koll, 1997</marker>
<rawString>M. Lesk, D. Cutting, J. Pedersen, T. Noreault, and M. Koll. 1997. Real life information retrieval: commercial search engines. In Proceedings of SIGIR&apos;97, page 333, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mine</author>
<author>K Aso</author>
<author>M Amamiya</author>
</authors>
<title>Japanese document retrieval system on www using dependency relations between words.</title>
<date>1997</date>
<booktitle>In Proceedings of PACL INC &apos;97,</booktitle>
<pages>290--215</pages>
<contexts>
<context position="4462" citStr="Mine et al., 1997" startWordPosition="683" endWordPosition="686">propriate keywords to condense classification so that it is not too broadranging to understand. 571 Overall classification Information Figure 1: 5W1H classification and navigation 3 5W1H Classification and Navigation Conventional keyword-based retrieval does not consider logical relationships between keywords. For example, the condition, &amp;quot;NEC &amp; semiconductor &amp; produce&amp;quot; retrieves an article containing &amp;quot;NEC formed a technical alliance with B company, and B company produced semiconductor X.&amp;quot; Mine et al. and Satoh et al. reported that this problem leads to retrieval noise and unnecessary results (Mine et al., 1997; Satoh and Murald, 1993). This problem makes it difficult to meet the requirements of an office because it produces retrieval noise in these three types of operations. 5W1H information is who, when, where, what, why, how, and predicate information extracted from text data through the 5W1H extraction module using language dictionary and sentence analysis techniques. 5W1H extraction modules assign 5W1H indexes to the text data. The indexes are stored in list form of predicates and arguments (when, who, what, why, where, how) (Lesk et al., 1997). The 5W1H index can suppress retrieval noise becau</context>
<context position="23368" citStr="Mine et al., 1997" startWordPosition="3684" endWordPosition="3687">s a lattice-based classification system and the user can browse information on the lattice produced by the existence of keywords (Carpineto and Romano, 1995). 5W1H classification and navigation is unique in that it is based on keyword functions, not on the existence of keywords. Lifestream manages e-mail by focusing on temporal viewpoints (Freeman and Fertig, 1995). In this sense, this idea is similar to our episodic retrieval though the purpose and target are different. Mine et al. and Hyodo and Ikeda reported on the effectiveness of using dependency relations between keywords for retrieval (Mine et al., 1997; Hyodo and Ikeda, 1994). As the 5W1H index is more informative than simple word dependency, it is possible to create more functions. More informative indexing such as semantic indexing and conceptual indexing can theoretically provide more sophisticated classification. However, this indexing is not always successful for practical use because of semantic analysis difficulties. Consequently 5W1H is the most appropriate indexing method from the practical viewpoint. 8 Conclusion This paper proposed a method by which 5W1H (who, when, where, what, why, how, and predicate) information is used to cla</context>
</contexts>
<marker>Mine, Aso, Amamiya, 1997</marker>
<rawString>T. Mine, K. Aso, and M. Amamiya. 1997. Japanese document retrieval system on www using dependency relations between words. In Proceedings of PACL INC &apos;97, pages 290-215, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Muraki</author>
<author>S Doi</author>
<author>S Ando</author>
</authors>
<title>Description of the veniex system as used for muc-r.</title>
<date>1993</date>
<booktitle>In Proceedings of MUC5,</booktitle>
<pages>147--159</pages>
<contexts>
<context position="8951" citStr="Muraki et al., 1993" startWordPosition="1372" endWordPosition="1375">thesaurus. As 5W1H elements are represented by upper concepts in the thesaurus, the matrix can be condensed. Figure 4 has an example with six &amp;quot;who&amp;quot; elements which are represented by two categories. The matrix provides users with overall classification as well as detailed sub-classification through the selection of appropriate hierarchical levels. This meets overall classification requirements in office retrieval. 4 5W1H Information Extraction 5W1H extraction was done by a case-based shallow parsing (CBSP) model based on the algorithm used in the VENIEX, Japanese information extraction system (Muraki et al., 1993). CBSP is a robust and effective method of analysis which uses lexical information, expression patterns and case-markers in sentences. Figure 5 shows the detail on the algorithm for CBSP. In this algorithm, input sentences are first segmented into words by Japanese morphological analysis (Japanese sentences have no blanks between words.) Lexical information is linked to each word such as the part-of-speech, root forms and semantic categories. Next, 5W1H elements are extracted by proper noun extraction, pattern expression matching and case-maker matching. In the proper noun extraction phase, a </context>
</contexts>
<marker>Muraki, Doi, Ando, 1993</marker>
<rawString>K. Muraki, S. Doi, and S. Ando. 1993. Description of the veniex system as used for muc-r. In Proceedings of MUC5, pages 147-159, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Okumura</author>
<author>T Ikeda</author>
<author>K Muraki</author>
</authors>
<title>Selective dissemination of information based on a multipleontology.</title>
<date>1997</date>
<booktitle>In Proceedings of IJCAI&apos;97 Ontology Workshop,</booktitle>
<pages>138--145</pages>
<contexts>
<context position="20707" citStr="Okumura et al., 1997" startWordPosition="3263" endWordPosition="3266">ms. On clicking the second cell from the top of the &amp;quot;who&amp;quot; elements, X%1114A (electrical and mechanical) in Figure 10, the user can view subcategorized classification on electrical and mechanical industries as indicated in Figure 11. Here, 1%4* (electrical and mechanical) is expanded to the subcategories;tt&apos;f,l&apos;aia (general electric) II (power electric), IZAIff (home electric), itiEVA (communication), and so on. 6 Current Status The information access platform was exploited during the MIIDAS (Multiple Indexed Information Dissemination and Acquisition Service) project which NEC used internally (Okumura et al., 1997). The DEC Alpha workstation (300 MHz) is a server machine providing 5W1H classification and navigation functions for 50 users through WWW browsers. User interaction occurs through CGI and JAVA programs. After a six-month trial by 50 users, four areas for improvement become evident. 1) 5W1H extraction: 5W1H extraction precision was approximately 82% for newspaper headlines. The extraction algorithm should be improved so that it can deal with embedded sentences and compound sentences. Also, dictionaries should be improved in order to be able to deal with different domains such as patent data and</context>
</contexts>
<marker>Okumura, Ikeda, Muraki, 1997</marker>
<rawString>A. Okumura, T. Ikeda, and K. Muraki. 1997. Selective dissemination of information based on a multipleontology. In Proceedings of IJCAI&apos;97 Ontology Workshop, pages 138-145, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sakamoto</author>
</authors>
<title>Natural language processing technology for information.</title>
<date>1997</date>
<booktitle>In JEIDA NLP Workshop,</booktitle>
<contexts>
<context position="1474" citStr="Sakamoto, 1997" startWordPosition="218" endWordPosition="219">owth in the volume of information available through online networks and from large capacity storage devices. High-speed and large-scale retrieval techniques have made it possible to receive information through information services such as news clipping and keyword-based retrieval. However, information retrieval is not a purpose in itself, but a means in most cases. In office work, users use retrieval services to create various documents such as proposals and reports. Conventional retrieval services do not provide users with a good access platform to help them achieve their practical purposes (Sakamoto, 1997; Lesk et al., 1997). They have to repeat retrieval operations and classify the data for themselves. To overcome this difficulty, this paper proposes a method by which 5W1H (who, when, where, what, why, how, and predicate) information can be used to classify and navigate Japanese-language texts. 5W1H information provides users with easyto-understand classification axes and retrieval keys because it has a set of fundamental elements needed to describe events. In this paper, we discuss common information retrieval requirements for office work and describe the three functions that our access plat</context>
</contexts>
<marker>Sakamoto, 1997</marker>
<rawString>H. Sakamoto. 1997. Natural language processing technology for information. In JEIDA NLP Workshop, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Satoh</author>
<author>K Muraki</author>
</authors>
<title>Penstation for idea processing.</title>
<date>1993</date>
<booktitle>In Proceedings of NLPRS&apos;93,</booktitle>
<pages>153--158</pages>
<marker>Satoh, Muraki, 1993</marker>
<rawString>K. Satoh and K. Muraki. 1993. Penstation for idea processing. In Proceedings of NLPRS&apos;93, pages 153-158, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>