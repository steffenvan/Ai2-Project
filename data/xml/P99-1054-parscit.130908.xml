<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001525">
<title confidence="0.820883">
Efficient probabilistic top-down and left-corner parsingt
</title>
<author confidence="0.506162">
Brian Roark and Mark Johnson
</author>
<affiliation confidence="0.325152">
Cognitive and Linguistic Sciences
</affiliation>
<address confidence="0.4547985">
Box 1978, Brown University
Providence, RI 02912, USA
</address>
<email confidence="0.998436">
brian-roark@brown.edu mj@cs.brown.edu
</email>
<sectionHeader confidence="0.994779" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999949214285714">
This paper examines efficient predictive broad-
coverage parsing without dynamic program-
ming. In contrast to bottom-up methods,
depth-first top-down parsing produces partial
parses that are fully connected trees spanning
the entire left context, from which any kind of
non-local dependency or partial semantic inter-
pretation can in principle be read. We con-
trast two predictive parsing approaches, top-
down and left-corner parsing, and find both to
be viable. In addition, we find that enhance-
ment with non-local information not only im-
proves parser accuracy, but also substantially
improves the search efficiency.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999823736842105">
Strong empirical evidence has been presented
over the past 15 years indicating that the hu-
man sentence processing mechanism makes on-
line use of contextual information in the preced-
ing discourse (Crain and Steedman, 1985; Alt-
mann and Steedman, 1988; Britt, 1994) and in
the visual environment (Tanenhaus et al., 1995).
These results lend support to Mark Steedman&apos;s
(1989) &amp;quot;intuition&amp;quot; that sentence interpretation
takes place incrementally, and that partial in-
terpretations are being built while the sentence
is being perceived. This is a very commonly
held view among psycholinguists today.
Many possible models of human sentence pro-
cessing can be made consistent with the above
view, but the general assumption that must un-
derlie them all is that explicit relationships be-
tween lexical items in the sentence must be spec-
ified incrementally. Such a processing mecha-
</bodyText>
<footnote confidence="0.932841666666667">
tThis material is based on work supported by the
National Science Foundation under Grant No. SBR-
9720368.
</footnote>
<bodyText confidence="0.999872926829268">
nism stands in marked contrast to dynamic pro-
gramming parsers, which delay construction of a
constituent until all of its sub-constituents have
been completed, and whose partial parses thus
consist of disconnected tree fragments. For ex-
ample, such parsers do not integrate a main verb
into the same tree structure as its subject NP
until the VP has been completely parsed, and
in many cases this is the final step of the entire
parsing process. Without explicit on-line inte-
gration, it would be difficult (though not impos-
sible) to produce partial interpretations on-line.
Similarly, it may be difficult to use non-local
statistical dependencies (e.g. between subject
and main verb) to actively guide such parsers.
,
Our predictive parser does not use dynamic
programming, but rather maintains fully con-
nected trees spanning the entire left context,
which make explicit the relationships between
constituents required for partial interpretation.
The parser uses probabilistic best-first pars-
ing methods to pursue the most likely analy-
ses first, and a beam-search to avoid the non-
termination problems typical of non-statistical
top-down predictive parsers.
There are two main results. First, this ap-
proach works and, with appropriate attention
to specific algorithmic details, is surprisingly
efficient. Second, not just accuracy but also
efficiency improves as the language model is
made more accurate. This bodes well for fu-
ture research into the use of other non-local (e.g.
lexical and semantic) information to guide the
parser.
In addition, we show that the improvement
in accuracy associated with left-corner parsing
over top-down is attributable to the non-local
information supplied by the strategy, and can
thus be obtained through other methods that
utilize that same information.
</bodyText>
<page confidence="0.99724">
421
</page>
<sectionHeader confidence="0.80933" genericHeader="method">
2 Parser architecture
</sectionHeader>
<bodyText confidence="0.999964833333333">
The parser proceeds incrementally from left to
right, with one item of look-ahead. Nodes are
expanded in a standard top-down, left-to-right
fashion. The parser utilizes: (i) a probabilis-
tic context-free grammar (PCFG), induced via
standard relative frequency estimation from a
corpus of parse trees; and (ii) look-ahead prob-
abilities as described below. Multiple compet-
ing partial parses (or analyses) are held on a
priority queue, which we will call the pending
heap. They are ranked by a figure of merit
(FOM), which will be discussed below. Each
analysis has its own stack of nodes to be ex-
panded, as well as a history, probability, and
FOM. The highest ranked analysis is popped
from the pending heap, and the category at the
top of its stack is expanded. A category is ex-
panded using every rule which could eventually
reach the look-ahead terminal. For every such
rule expansion, a new analysis is create&amp; and
pushed back onto the pending heap.
The FOM for an analysis is the product of the
probabilities of all PCFG rules used in its deriva-
tion and what we call its look-ahead probabil-
ity (LAP). The LAP approximates the product
of the probabilities of the rules that will be re-
quired to link the analysis in its current state
with the look-ahead termina12. That is, for a
grammar G, a stack state [C1 ... Crd and a look-
ahead terminal item w:
</bodyText>
<equation confidence="0.896689">
(1) LAP = PG([Ci. • .. Cn] 4 wa)
</equation>
<bodyText confidence="0.9999246">
We recursively estimate this with two empir-
ically observed conditional probabilities for ev-
ery non-terminal Ci on the stack: ,P(C, 4 co)
and P(Ci 4 e). The LAP approximation for a
given stack state and look-ahead terminal is:
</bodyText>
<listItem confidence="0.891064">
(2) PG([Ci . Cn] 4 wa) P(Ci 4 w) +
</listItem>
<bodyText confidence="0.90286675">
P(ci 4 e)*PG([ci+i cid 4 wa)
When the topmost stack category of an analy-
sis matches the look-ahead terminal, the termi-
nal is popped from the stack and the analysis
</bodyText>
<footnote confidence="0.7717796">
&apos;We count each of these as a parser state (or rule
expansion) considered, which can be used as a measure
of efficiency.
2Since this is a non-lexicalized grammar, we are tak-
ing pre-terminal POS markers as our terminal items.
</footnote>
<bodyText confidence="0.999950254901961">
is pushed onto a second priority queue, which
we will call the success heap. Once there are
&amp;quot;enough&amp;quot; analyses on the success heap, all those
remaining on the pending heap are discarded.
The success heap then becomes the pending
heap, and the look-ahead is moved forward to
the next item in the input string. When the end
of the input string is reached, the analysis with
the highest probability and an empty stack is
returned as the parse. If no such parse is found,
an error is returned.
The specifics of the beam-search dictate how
many analyses on the success heap constitute
&amp;quot;enough&amp;quot;. One approach is to set a constant
beam width, e.g. 10,000 analyses on the suc-
cess heap, at which point the parser moves to
the next item in the input. A problem with
this approach is that parses towards the bottom
of the success heap may be so unlikely relative
to those at the top that they have little or no
chance of becoming the most likely parse at the
end of the day, causing wasted effort. An al-
ternative approach is to dynamically vary the
beam width by stipulating a factor, say 10-5,
and proceed until the best analysis on the pend-
ing heap has an FOM less than 10-5 times the
probability of the best analysis on the success
heap. Sometimes, however, the number of anal-
yses that fall within such a range can be enor-
mous, creating nearly as large of a processing
burden as the first approach. As a compromise
between these two approaches, we stipulated a
base beam factor a (usually 10-4), and the ac-
tual beam factor used was a *13, where 0 is the
number of analyses on the success heap. Thus,
when 13 is small, the beam stays relatively wide,
to include as many analyses as possible; but as
f3 grows, the beam narrows. We found this to
be a simple and successful compromise
Of course, with a left recursive grammar, such
a top-down parser may never terminate. If
no analysis ever makes it to the success heap,
then, however one defines the beam-search, a
top-down depth-first search with a left-recursive
grammar will never terminate. To avoid this,
one must place an upper bound on the number
of analyses allowed to be pushed onto the pend-
ing heap. If that bound is exceeded, the parse
fails. With a left-corner strategy, which is not
prey to left recursion, no such upper bound is
necessary.
</bodyText>
<page confidence="0.991559">
422
</page>
<figure confidence="0.9967994">
(a) (b) (c) (d)
NP NP NP NP
DT+JJ+JJ NN DT NP-DT DT NP-DT DT NP-DT
I
DT+JJ JJ cat the JJ NP-DT-JJ the
JJ NP-DT-JJ the JJ NP-DT-JJ
I
DT JJ happy fat JJ NN fat JJ NP-DT-JJ-JJ fat JJ NP-DT-JJ-JJ
the fat happy cat happy NN happy NN NP-DT-JJ-JJ-NN
cat cat
</figure>
<figureCaption confidence="0.9974335">
Figure 1: Binarized trees: (a) left binarized (LB); (b) right binarized to binary (RB2); (c) right
binarized to unary (RB1); (d) right binarized to nullary (RBO)
</figureCaption>
<sectionHeader confidence="0.980634" genericHeader="method">
3 Grammar transforms
</sectionHeader>
<bodyText confidence="0.999965529411765">
Nijholt (1980) characterized parsing strategies
in terms of announce points: the point at which
a parent category is announced (identified) rel-
ative to its children, and the point at which the
rule expanding the parent is identified. In pure
top-down parsing, a parent category and the
rule expanding it are announced before any of
its children. In pure bottom-up parsing, they
are identified after all of the children. Gram-
mar transforms are one method for changing
the announce points. In top-down parsing with
an appropriately binarized grammar, the par-
ent is identified before, but the rule expanding
the parent after, all of the children. Left-corner
parsers announce a parent category and its ex-
panding rule after its leftmost child has been
completed, but before any of the other children.
</bodyText>
<subsectionHeader confidence="0.967071">
3.1 Delaying rule identification through
binarization
</subsectionHeader>
<bodyText confidence="0.99292578">
Suppose that the category on the top of the
stack is an NP and there is a determiner (DT)
in the look-ahead. In such a situation, there is
no information to distinguish between the rules
NP —&gt; DT JJ NN and NP DT JJ NNS.
If the decision can be delayed, however, until
such a time as the relevant pre-terminal is in
the look-ahead, the parser can make a more in-
formed decision. Grammar binarization is one
way to do this, by allowing the parser to use
a rule like NP —&gt; DT NP-DT, where the new
non-terminal NP-DT can expand into anything
that follows a DT in an NP. The expansion of
NP-DT occurs only after the next pre-terminal
is in the look-ahead. Such a delay is essential
for an efficient implementation of the kind of
incremental parser that we are proposing.
There are actually several ways to make a
grammar binary, some of which are better than
others for our parser. The first distinction that
can be drawn is between what we will call left
binarization (LB) versus right binarization (RB,
see figure 1). In the former, the leftmost items
on the righthand-side of each rule are grouped
together; in the latter, the rightmost items on
the righthand-side of the rule are grouped to-
gether. Notice that, for a top-down, left-to-right
parser, RB is the appropriate transform, be-
cause it underspecifies the right siblings. With
LB, a top-down parser must identify all of the
siblings before reaching the leftmost item, which
does not aid our purposes.
Within RB transforms, however, there is some
variation, with respect to how long rule under-
specification is maintained. One method is to
have the final underspecified category rewrite as
a binary rule (hereafter RB2, see figure lb). An-
other is to have the final underspecified category
rewrite as a unary rule (RB1, figure 1c). The
last is to have the final underspecified category
rewrite as a nullary rule (RBO, figure 1d). No-
tice that the original motivation for RB, to delay
specification until the relevant items are present
in the look-ahead, is not served by RB2, because
the second child must be specified without being
present in the look-ahead. RBO pushes the look-
ahead out to the first item in the string after the
constituent being expanded, which can be use-
ful in deciding between rules of unequal length,
e.g. NP —&gt; DT NN and NP—* DT NN NN.
</bodyText>
<tableCaption confidence="0.91852">
Table 1 summarizes some trials demonstrat-
</tableCaption>
<page confidence="0.93701">
423
</page>
<table confidence="0.9945635">
Binarization Rules in Percent of Avg. States Avg. Labelled Avg. MLP Ratio of Avg.
Grammar Sentences Considered Precision and Labelled Prob to Avg.
Parsed* Recant Prec/Rect MLP Probt
None 14962 34.16 19270 .65521 .76427 .001721
LB 37955 33.99 96813 .65539 .76095 .001440
RB1 29851 91.27 10140 .71616 .72712 .340858
RBO 41084 97.37 13868 .73207 .72327 .443705
Beam Factor = 10- *Length &lt; 40 (2245 sentences in F23 - Avg. length = 21.68) Of those sentences parsed
</table>
<tableCaption confidence="0.999953">
Table 1: The effect of different approaches to binarization
</tableCaption>
<bodyText confidence="0.999769736842105">
ing the effect of different binarization ap-
proaches on parser performance. The gram-
mars were induced from sections 2-21 of the
Penn Wall St. Journal Treebank (Marcus et
al., 1993), and tested on section 23. For each
transform tested, every tree in the training cor-
pus was transformed before grammar induc-
tion, resulting in a transformed PCFG and look-
ahead probabilities estimated in the standard
way. Each parse returned by the parser was de-
transformed for evaluation3. The parser used
in each trial was identical, with a base beam
factor a 10-4. The performance is evaluated
using these measures: (i) the percentage of can-
didate sentences for which a parse was found
(coverage); (ii) the average number of states
(i.e. rule expansions) considered per candidate
sentence (efficiency); and (iii) the average la-
belled precision and recall of those sentences for
which a parse was found (accuracy). We also
used the same grammars with an exhaustive,
bottom-up CKY parser, to ascertain both the
accuracy and probability of the maximum like-
lihood parse (MLP). We can then additionally
compare the parser&apos;s performance to the MLP&apos;s
on those same sentences.
As expected, left binarization conferred no
benefit to our parser. Right binarization, in con-
trast, improved performance across the board.
RBO provided a substantial improvement in cov-
erage and accuracy over RB1, with something
of a decrease in efficiency. This efficiency hit
is partly attributable to the fact that the same
tree has more nodes with RBO. Indeed, the effi-
ciency improvement with right binarization over
the standard grammar is even more interesting
in light of the great increase in the size of the
grammars.
</bodyText>
<footnote confidence="0.724725">
3See Johnson (1998) for details of the transform/de-
transform paradigm.
</footnote>
<bodyText confidence="0.9984568">
It is worth noting at this point that, with the
RBO grammar, this parser is now a viable broad-
coverage statistical parser, with good coverage,
accuracy, and efficiency4. Next we considered
the left-corner parsing strategy.
</bodyText>
<subsectionHeader confidence="0.996636">
3.2 Left-corner parsing
</subsectionHeader>
<bodyText confidence="0.950743142857143">
Left-corner (LC) parsing (Rosenkrantz and
Lewis II, 1970) is a well-known strategy that
uses both bottom-up evidence (from the left
corner of a rule) and top-down prediction (of
the rest of the rule). Rosenkrantz and Lewis
showed how to transform a context-free gram-
mar into a grammar that, when used by a top-
down parser, follows the same search path as an
LC parser. These LC grammars allow us to use
exactly the same predictive parser to evaluate
top-down versus LC parsing. Naturally, an LC
grammar performs best with our parser when
right binarized, for the same reasons outlined
above. We use transform composition to apply
first one transform, then another to the output
of the first. We denote this A o B where (A o
B)(t) B (A (t)). After applying the left-corner
transform, we then binarize the resulting gram-
mar5, i.e. LC o RB.
Another probabilistic LC parser investigated
(Manning and Carpenter, 1997), which uti-
lized an LC parsing architecture (not a trans-
formed grammar), also got a performance boost
4The very efficient bottom-up statistical parser de-
tailed in Charniak et al. (1998) measured efficiency in
terms of total edges popped. An edge (or, in our case, a
parser state) is considered when a probability is calcu-
lated for it, and we felt that this was a better efficiency
measure than simply those popped. As a baseline, their
parser considered an average of 2216 edges per sentence
in section 22 of the WSJ corpus (p.c.).
5Given that the LC transform involves nullary pro-
ductions, the use of RBO is not needed, i.e. nullary pro-
ductions need only be introduced from one source. Thus
binarization with left corner is always to unary (RB1).
</bodyText>
<page confidence="0.997043">
424
</page>
<table confidence="0.995059">
Transform Rules in Pct. of Avg. States Avg Labelled Avg. MLP Ratio of Avg.
Grammar Sentences Considered Precision and Labelled Prob to Avg.
Parsed* Recall t Prec/Rect MLP Probt
Left Corner (LC) 21797 91.75 9000 .76399 .78156 .175928
LB o LC 53026 96.75 7865 .77815 .78056 .359828
LC o RB 53494 96.7 8125 .77830 .78066 .359439
LC o RB o ANN 55094 96.21 7945 .77854 .78094 .346778
RB o LC 86007 93.38 4675 .76120 .80529 .267330
Beam Factor = 10-4 *Length &lt; 40 (2245 sentences in F23 - Avg. length = 21.68) tOf those sentences parsed
</table>
<tableCaption confidence="0.997103">
Table 2: Left Corner Results
</tableCaption>
<bodyText confidence="0.970431833333333">
through right binarization. This, however, is
equivalent to RB o LC, which is a very differ-
ent grammar from LC o RB. Given our two bi-
narization orientations (LB and RB), there are
four possible compositions of binarization and
LC transforms:
</bodyText>
<equation confidence="0.571411">
(a) LB o LC (b) RB o LC (c) LC o LB (d) LC o RB
</equation>
<bodyText confidence="0.999356846153846">
Table 2 shows left-corner results over various
conditions6. Interestingly, options (a) and (d)
encode the same information, leading to nearly
identical performance7. As stated before, right
binarization moves the rule announce point
from before to after all of the children. The
LC transform is such that LC o RB also delays
parent identification until after all of the chil-
dren. The transform LC o RB o ANN moves the
parent announce point back to the left corner by
introducing unary rules at the left corner that
simply identify the parent of the binarized rule.
This allows us to test the effect of the position of
the parent announce point on the performance
of the parser. As we can see, however, the ef-
fect is slight, with similar performance on all
measures.
RB o LC performs with higher accuracy than
the others when used with an exhaustive parser,
but seems to require a massive beam in order to
even approach performance at the MLP level.
Manning and Carpenter (1997) used a beam
width of 40,000 parses on the success heap at
each input item, which must have resulted in an
order of magnitude more rule expansions than
what we have been considering up to now, and
</bodyText>
<footnote confidence="0.9952982">
6Option (c) is not the appropriate kind of binarization
for our parser, as argued in the previous section, and so
is omitted.
7The difference is due to the introduction of vacuous
unary rules with RB.
</footnote>
<bodyText confidence="0.991363833333333">
yet their average labelled precision and recall
(.7875) still fell well below what we found to be
the MLP accuracy (.7987) for the grammar. We
are still investigating why this grammar func-
tions so poorly when used by an incremental
parser.
</bodyText>
<subsectionHeader confidence="0.996799">
3.3 Non-local annotation
</subsectionHeader>
<bodyText confidence="0.9999795">
Johnson (1998) discusses the improvement of
PCFG models via the annotation of non-local in-
formation onto non-terminal nodes in the trees
of the training corpus. One simple example
is to copy the parent node onto every non-
terminal, e.g. the rule S NP VP becomes
S —&gt; NPS VPIS. The idea here is that the
distribution of rules of expansion of a particular
non-terminal may differ depending on the non-
terminal&apos;s parent. Indeed, it was shown that
this additional information improves the MLP
accuracy dramatically.
We looked at two kinds of non-local infor-
mation annotation: parent (PA) and left-corner
(LCA). Left-corner parsing gives improved accu-
racy over top-down or bottom-up parsing with
the same grammar. Why? One reason may be
that the ancestor category exerts the same kind
of non-local influence upon the parser that the
parent category does in parent annotation. To
test this, we annotated the left-corner ancestor
category onto every leftmost non-terminal cat-
egory. The results of our annotation trials are
shown in table 3.
There are two important points to notice from
these results. First, with PA we get not only the
previously reported improvement in accuracy,
but additionally a fairly dramatic decrease in
the number of parser states that must be vis-
ited to find a parse. That is, the non-local in-
formation not only improves the final product of
the parse, but it guides the parser more quickly
</bodyText>
<page confidence="0.997168">
425
</page>
<table confidence="0.995828888888889">
Transform Rules in Pct. of Avg. States Avg Labelled Avg. MLP Ratio of Avg.
Grammar Sentences Considered Precision and Labelled Prob to Avg.
Parsed* Recant Prec/Rect MLP Probt
RBO 41084 97.37 13868 .73207 .72327 .443705
PA 0 RBO 63467 95.19 8596 .79188 .79759 .486995
LC 0 RB 53494 96.7 8125 .77830 .78066 .359439
LCA 0 RBO 58669 96.48 11158 .77476 .78058 .495912
PA 0 LC o RB 80245 93.52 4455 .81144 .81833 .484428
Beam Factor = 10-4 *Length &lt; 40 (2245 sentences in F23 - Avg. length = 21.68) t Of those sentences parsed
</table>
<tableCaption confidence="0.999205">
Table 3: Non-local annotation results
</tableCaption>
<bodyText confidence="0.999878944444445">
to the final product. The annotated grammar
has 1.5 times as many rules, and would slow
a bottom-up CKY parser proportionally. Yet
our parser actually considers far fewer states en
route to the more accurate parse.
Second, LC-annotation gives nearly all of the
accuracy gain of left-corner parsing/3, in support
of the hypothesis that the ancestor information
was responsible for the observed accuracy im-
provement. This result suggests that if we can
determine the information that is being anno-
tated by the troublesome RB o LC transform,
we may be able to get the accuracy improve-
ment with a relatively narrow beam. Parent-
annotation before the LC transform gave us the
best performance of all, with very few states
considered on average, and excellent accuracy
for a non-lexicalized grammar.
</bodyText>
<sectionHeader confidence="0.998647" genericHeader="method">
4 Accuracy/Efficiency tradeoff
</sectionHeader>
<bodyText confidence="0.999506764705882">
One point that deserves to be made is that there
is something of an accuracy/efficiency tradeoff
with regards to the base beam factor. The re-
sults given so far were at 10-4, which func-
tions pretty well for the transforms we have
investigated. Figures 2 and 3 show four per-
formance measures for four of our transforms
at base beam factors of 10-3, 10-4, 10-5, and
10-6. There is a dramatically increasing effi-
ciency burden as the beam widens, with vary-
ing degrees of payoff. With the top-down trans-
forms (RBO and PA o RBO), the ratio of the av-
erage probability to the MLP probability does
improve substantially as the beam grows, yet
with only marginal improvements in coverage
and accuracy. Increasing the beam seems to do
less with the left-corner transforms.
</bodyText>
<footnote confidence="0.941105">
8The rest could very well be within noise.
</footnote>
<sectionHeader confidence="0.993217" genericHeader="conclusions">
5 Conclusions and Future Research
</sectionHeader>
<bodyText confidence="0.999902285714286">
We have examined several probabilistic predic-
tive parser variations, and have shown the ap-
proach in general to be a viable one, both in
terms of the quality of the parses, and the ef-
ficiency with which they are found. We have
shown that the improvement of the grammars
with non-local information not only results in
better parses, but guides the parser to them
much more efficiently, in contrast to dynamic
programming methods. Finally, we have shown
that the accuracy improvement that has been
demonstrated with left-corner approaches can
be attributed to the non-local information uti-
lized by the method.
This is relevant to the study of the human
sentence processing mechanism insofar as it
demonstrates that it is possible to have a model
which makes explicit the syntactic relationships
between items in the input incrementally, while
still scaling up to broad-coverage.
Future research will include:
</bodyText>
<listItem confidence="0.933706333333333">
• lexicalization of the parser
• utilization of fully connected trees for ad-
ditional syntactic and semantic processing
• the use of syntactic predictions in the beam
for language modeling
• an examination of predictive parsing with
</listItem>
<bodyText confidence="0.992695666666667">
a left-branching language (e.g. German)
In addition, it may be of interest to the psy-
cholinguistic community if we introduce a time
variable into our model, and use it to compare
such competing sentence processing models as
race-based and competition-based parsing.
</bodyText>
<sectionHeader confidence="0.997476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.863703">
G. Altmann and M. Steedman. 1988. Interac-
tion with context during human sentence pro-
cessing. Cognition, 30:198-238.
</reference>
<page confidence="0.998203">
426
</page>
<figure confidence="0.987090388888889">
x 104 Average States Considered per Sentence
14
12
10
8
6
4
2
10-4 Base Beam Factor 10-5 10-6
Percentage of Sentences Parsed
RBO
LC o RB
PA o RBO
PA o LC o RB
88
10-3
10-4 Base Beam Factor 10-6
to-6
</figure>
<figureCaption confidence="0.996753">
Figure 2: Changes in performance with beam factor variation
</figureCaption>
<reference confidence="0.99355045">
M. Britt. 1994. The interaction of referential
ambiguity and argument structure. Journal
of Memory and Language, 33:251-283.
E. Charniak, S. Goldwater, and M. Johnson.
1998. Edge-based best-first chart parsing. In
Proceedings of the Sixth Workshop on Very
Large Corpora, pages 127-133.
S. Crain and M. Steedman. 1985. On not be-
ing led up the garden path: The use of con-
text by the psychological parser. In D. Dowty,
L. Karttunen, and A. Zwicky, editors, Natu-
ral Language Parsing. Cambridge University
Press, Cambridge, UK.
M. Johnson. 1998. PCFG models of linguistic
tree representations. Computational Linguis-
tics, 24:617-636.
C. Manning and B. Carpenter. 1997. Prob-
abilistic parsing using left corner language
models. In Proceedings of the Fifth Interna-
tional Workshop on Parsing Technologies.
</reference>
<page confidence="0.995068">
427
</page>
<figure confidence="0.988431130434782">
Average Labelled Precision and Recall
10-4 Base Beam Factor 10-5
Average Ratio of Parse Probability to Maximum Likelihood Probability
76 0.45
cc
0.4
0.35
75
74
73
72
10-3
0.65
82
81
80
79
78
I77
o.
76
-4 to-6
10 Base Beam Factor
</figure>
<figureCaption confidence="0.997727">
Figure 3: Changes in performance with beam factor variation
</figureCaption>
<reference confidence="0.991261636363636">
M.P. Marcus, B. Santorini, and M.A.
Marcinkiewicz. 1993. Building a large
annotated corpus of English: The Penn
Treebank. Computational Linguistics,
19(2):313-330.
A. Nijholt. 1980. Context-free Grammars: Cov-
ers, Normal Forms, and Parsing. Springer
Verlag, Berlin.
S.J. Rosenkrantz and P.M. Lewis II. 1970. De-
terministic left corner parsing. In IEEE Con-
ference Record of the 11th Annual Symposium
on Switching and Automata, pages 139-152.
M. Steedman. 1989. Grammar, interpreta-
tion, and processing from the lexicon. In
W. Marslen-Wilson, editor, Lexical represen-
tation and process. MIT Press, Cambridge,
MA.
M. Tanenhaus, M. Spivey-Knowlton, K. Eber-
hard, and J. Sedivy. 1995. Integration of vi-
sual and linguistic information during spoken
language comprehension. Science, 268:1632-
1634.
</reference>
<page confidence="0.998323">
428
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.911497">
<title confidence="0.999678">Efficient probabilistic top-down and left-corner parsingt</title>
<author confidence="0.999942">Brian Roark</author>
<author confidence="0.999942">Mark Johnson</author>
<affiliation confidence="0.961357">Cognitive and Linguistic Sciences</affiliation>
<address confidence="0.976556">Box 1978, Brown University Providence, RI 02912, USA</address>
<email confidence="0.999819">mj@cs.brown.edu</email>
<abstract confidence="0.999687733333333">This paper examines efficient predictive broadcoverage parsing without dynamic programming. In contrast to bottom-up methods, depth-first top-down parsing produces partial parses that are fully connected trees spanning the entire left context, from which any kind of non-local dependency or partial semantic interpretation can in principle be read. We contrast two predictive parsing approaches, topdown and left-corner parsing, and find both to be viable. In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Altmann</author>
<author>M Steedman</author>
</authors>
<title>Interaction with context during human sentence processing.</title>
<date>1988</date>
<journal>Cognition,</journal>
<pages>30--198</pages>
<contexts>
<context position="1095" citStr="Altmann and Steedman, 1988" startWordPosition="154" endWordPosition="158"> which any kind of non-local dependency or partial semantic interpretation can in principle be read. We contrast two predictive parsing approaches, topdown and left-corner parsing, and find both to be viable. In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency. 1 Introduction Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995). These results lend support to Mark Steedman&apos;s (1989) &amp;quot;intuition&amp;quot; that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. This is a very commonly held view among psycholinguists today. Many possible models of human sentence processing can be made consistent with the above view, but the general assumption that must underlie them all is that explicit relationships between lexical items in the sentence must be specified incrementally. Such a</context>
</contexts>
<marker>Altmann, Steedman, 1988</marker>
<rawString>G. Altmann and M. Steedman. 1988. Interaction with context during human sentence processing. Cognition, 30:198-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Britt</author>
</authors>
<title>The interaction of referential ambiguity and argument structure.</title>
<date>1994</date>
<journal>Journal of Memory and Language,</journal>
<pages>33--251</pages>
<contexts>
<context position="1109" citStr="Britt, 1994" startWordPosition="159" endWordPosition="160"> dependency or partial semantic interpretation can in principle be read. We contrast two predictive parsing approaches, topdown and left-corner parsing, and find both to be viable. In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency. 1 Introduction Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995). These results lend support to Mark Steedman&apos;s (1989) &amp;quot;intuition&amp;quot; that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. This is a very commonly held view among psycholinguists today. Many possible models of human sentence processing can be made consistent with the above view, but the general assumption that must underlie them all is that explicit relationships between lexical items in the sentence must be specified incrementally. Such a processing me</context>
</contexts>
<marker>Britt, 1994</marker>
<rawString>M. Britt. 1994. The interaction of referential ambiguity and argument structure. Journal of Memory and Language, 33:251-283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>S Goldwater</author>
<author>M Johnson</author>
</authors>
<title>Edge-based best-first chart parsing.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="15211" citStr="Charniak et al. (1998)" startWordPosition="2543" endWordPosition="2546">g. Naturally, an LC grammar performs best with our parser when right binarized, for the same reasons outlined above. We use transform composition to apply first one transform, then another to the output of the first. We denote this A o B where (A o B)(t) B (A (t)). After applying the left-corner transform, we then binarize the resulting grammar5, i.e. LC o RB. Another probabilistic LC parser investigated (Manning and Carpenter, 1997), which utilized an LC parsing architecture (not a transformed grammar), also got a performance boost 4The very efficient bottom-up statistical parser detailed in Charniak et al. (1998) measured efficiency in terms of total edges popped. An edge (or, in our case, a parser state) is considered when a probability is calculated for it, and we felt that this was a better efficiency measure than simply those popped. As a baseline, their parser considered an average of 2216 edges per sentence in section 22 of the WSJ corpus (p.c.). 5Given that the LC transform involves nullary productions, the use of RBO is not needed, i.e. nullary productions need only be introduced from one source. Thus binarization with left corner is always to unary (RB1). 424 Transform Rules in Pct. of Avg. S</context>
</contexts>
<marker>Charniak, Goldwater, Johnson, 1998</marker>
<rawString>E. Charniak, S. Goldwater, and M. Johnson. 1998. Edge-based best-first chart parsing. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 127-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>M Steedman</author>
</authors>
<title>On not being led up the garden path: The use of context by the psychological parser. In</title>
<date>1985</date>
<editor>D. Dowty, L. Karttunen, and A. Zwicky, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="1067" citStr="Crain and Steedman, 1985" startWordPosition="150" endWordPosition="153"> entire left context, from which any kind of non-local dependency or partial semantic interpretation can in principle be read. We contrast two predictive parsing approaches, topdown and left-corner parsing, and find both to be viable. In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency. 1 Introduction Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995). These results lend support to Mark Steedman&apos;s (1989) &amp;quot;intuition&amp;quot; that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. This is a very commonly held view among psycholinguists today. Many possible models of human sentence processing can be made consistent with the above view, but the general assumption that must underlie them all is that explicit relationships between lexical items in the sentence must be spe</context>
</contexts>
<marker>Crain, Steedman, 1985</marker>
<rawString>S. Crain and M. Steedman. 1985. On not being led up the garden path: The use of context by the psychological parser. In D. Dowty, L. Karttunen, and A. Zwicky, editors, Natural Language Parsing. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>PCFG models of linguistic tree representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--617</pages>
<contexts>
<context position="13816" citStr="Johnson (1998)" startWordPosition="2315" endWordPosition="2316">mpare the parser&apos;s performance to the MLP&apos;s on those same sentences. As expected, left binarization conferred no benefit to our parser. Right binarization, in contrast, improved performance across the board. RBO provided a substantial improvement in coverage and accuracy over RB1, with something of a decrease in efficiency. This efficiency hit is partly attributable to the fact that the same tree has more nodes with RBO. Indeed, the efficiency improvement with right binarization over the standard grammar is even more interesting in light of the great increase in the size of the grammars. 3See Johnson (1998) for details of the transform/detransform paradigm. It is worth noting at this point that, with the RBO grammar, this parser is now a viable broadcoverage statistical parser, with good coverage, accuracy, and efficiency4. Next we considered the left-corner parsing strategy. 3.2 Left-corner parsing Left-corner (LC) parsing (Rosenkrantz and Lewis II, 1970) is a well-known strategy that uses both bottom-up evidence (from the left corner of a rule) and top-down prediction (of the rest of the rule). Rosenkrantz and Lewis showed how to transform a context-free grammar into a grammar that, when used </context>
<context position="18282" citStr="Johnson (1998)" startWordPosition="3089" endWordPosition="3090"> input item, which must have resulted in an order of magnitude more rule expansions than what we have been considering up to now, and 6Option (c) is not the appropriate kind of binarization for our parser, as argued in the previous section, and so is omitted. 7The difference is due to the introduction of vacuous unary rules with RB. yet their average labelled precision and recall (.7875) still fell well below what we found to be the MLP accuracy (.7987) for the grammar. We are still investigating why this grammar functions so poorly when used by an incremental parser. 3.3 Non-local annotation Johnson (1998) discusses the improvement of PCFG models via the annotation of non-local information onto non-terminal nodes in the trees of the training corpus. One simple example is to copy the parent node onto every nonterminal, e.g. the rule S NP VP becomes S —&gt; NPS VPIS. The idea here is that the distribution of rules of expansion of a particular non-terminal may differ depending on the nonterminal&apos;s parent. Indeed, it was shown that this additional information improves the MLP accuracy dramatically. We looked at two kinds of non-local information annotation: parent (PA) and left-corner (LCA). Left-corn</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>M. Johnson. 1998. PCFG models of linguistic tree representations. Computational Linguistics, 24:617-636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>B Carpenter</author>
</authors>
<title>Probabilistic parsing using left corner language models.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth International Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="15026" citStr="Manning and Carpenter, 1997" startWordPosition="2513" endWordPosition="2516">r that, when used by a topdown parser, follows the same search path as an LC parser. These LC grammars allow us to use exactly the same predictive parser to evaluate top-down versus LC parsing. Naturally, an LC grammar performs best with our parser when right binarized, for the same reasons outlined above. We use transform composition to apply first one transform, then another to the output of the first. We denote this A o B where (A o B)(t) B (A (t)). After applying the left-corner transform, we then binarize the resulting grammar5, i.e. LC o RB. Another probabilistic LC parser investigated (Manning and Carpenter, 1997), which utilized an LC parsing architecture (not a transformed grammar), also got a performance boost 4The very efficient bottom-up statistical parser detailed in Charniak et al. (1998) measured efficiency in terms of total edges popped. An edge (or, in our case, a parser state) is considered when a probability is calculated for it, and we felt that this was a better efficiency measure than simply those popped. As a baseline, their parser considered an average of 2216 edges per sentence in section 22 of the WSJ corpus (p.c.). 5Given that the LC transform involves nullary productions, the use o</context>
<context position="17605" citStr="Manning and Carpenter (1997)" startWordPosition="2969" endWordPosition="2972">til after all of the children. The transform LC o RB o ANN moves the parent announce point back to the left corner by introducing unary rules at the left corner that simply identify the parent of the binarized rule. This allows us to test the effect of the position of the parent announce point on the performance of the parser. As we can see, however, the effect is slight, with similar performance on all measures. RB o LC performs with higher accuracy than the others when used with an exhaustive parser, but seems to require a massive beam in order to even approach performance at the MLP level. Manning and Carpenter (1997) used a beam width of 40,000 parses on the success heap at each input item, which must have resulted in an order of magnitude more rule expansions than what we have been considering up to now, and 6Option (c) is not the appropriate kind of binarization for our parser, as argued in the previous section, and so is omitted. 7The difference is due to the introduction of vacuous unary rules with RB. yet their average labelled precision and recall (.7875) still fell well below what we found to be the MLP accuracy (.7987) for the grammar. We are still investigating why this grammar functions so poorl</context>
</contexts>
<marker>Manning, Carpenter, 1997</marker>
<rawString>C. Manning and B. Carpenter. 1997. Probabilistic parsing using left corner language models. In Proceedings of the Fifth International Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<pages>19--2</pages>
<contexts>
<context position="12299" citStr="Marcus et al., 1993" startWordPosition="2068" endWordPosition="2071">. Grammar Sentences Considered Precision and Labelled Prob to Avg. Parsed* Recant Prec/Rect MLP Probt None 14962 34.16 19270 .65521 .76427 .001721 LB 37955 33.99 96813 .65539 .76095 .001440 RB1 29851 91.27 10140 .71616 .72712 .340858 RBO 41084 97.37 13868 .73207 .72327 .443705 Beam Factor = 10- *Length &lt; 40 (2245 sentences in F23 - Avg. length = 21.68) Of those sentences parsed Table 1: The effect of different approaches to binarization ing the effect of different binarization approaches on parser performance. The grammars were induced from sections 2-21 of the Penn Wall St. Journal Treebank (Marcus et al., 1993), and tested on section 23. For each transform tested, every tree in the training corpus was transformed before grammar induction, resulting in a transformed PCFG and lookahead probabilities estimated in the standard way. Each parse returned by the parser was detransformed for evaluation3. The parser used in each trial was identical, with a base beam factor a 10-4. The performance is evaluated using these measures: (i) the percentage of candidate sentences for which a parse was found (coverage); (ii) the average number of states (i.e. rule expansions) considered per candidate sentence (efficie</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nijholt</author>
</authors>
<title>Context-free Grammars: Covers, Normal Forms, and Parsing.</title>
<date>1980</date>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="8408" citStr="Nijholt (1980)" startWordPosition="1408" endWordPosition="1409">the pending heap. If that bound is exceeded, the parse fails. With a left-corner strategy, which is not prey to left recursion, no such upper bound is necessary. 422 (a) (b) (c) (d) NP NP NP NP DT+JJ+JJ NN DT NP-DT DT NP-DT DT NP-DT I DT+JJ JJ cat the JJ NP-DT-JJ the JJ NP-DT-JJ the JJ NP-DT-JJ I DT JJ happy fat JJ NN fat JJ NP-DT-JJ-JJ fat JJ NP-DT-JJ-JJ the fat happy cat happy NN happy NN NP-DT-JJ-JJ-NN cat cat Figure 1: Binarized trees: (a) left binarized (LB); (b) right binarized to binary (RB2); (c) right binarized to unary (RB1); (d) right binarized to nullary (RBO) 3 Grammar transforms Nijholt (1980) characterized parsing strategies in terms of announce points: the point at which a parent category is announced (identified) relative to its children, and the point at which the rule expanding the parent is identified. In pure top-down parsing, a parent category and the rule expanding it are announced before any of its children. In pure bottom-up parsing, they are identified after all of the children. Grammar transforms are one method for changing the announce points. In top-down parsing with an appropriately binarized grammar, the parent is identified before, but the rule expanding the paren</context>
</contexts>
<marker>Nijholt, 1980</marker>
<rawString>A. Nijholt. 1980. Context-free Grammars: Covers, Normal Forms, and Parsing. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Rosenkrantz</author>
<author>P M Lewis</author>
</authors>
<title>Deterministic left corner parsing.</title>
<date>1970</date>
<booktitle>In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata,</booktitle>
<pages>139--152</pages>
<marker>Rosenkrantz, Lewis, 1970</marker>
<rawString>S.J. Rosenkrantz and P.M. Lewis II. 1970. Deterministic left corner parsing. In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata, pages 139-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Grammar, interpretation, and processing from the lexicon. In</title>
<date>1989</date>
<editor>W. Marslen-Wilson, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Steedman, 1989</marker>
<rawString>M. Steedman. 1989. Grammar, interpretation, and processing from the lexicon. In W. Marslen-Wilson, editor, Lexical representation and process. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tanenhaus</author>
<author>M Spivey-Knowlton</author>
<author>K Eberhard</author>
<author>J Sedivy</author>
</authors>
<title>Integration of visual and linguistic information during spoken language comprehension.</title>
<date>1995</date>
<journal>Science,</journal>
<pages>268--1632</pages>
<contexts>
<context position="1164" citStr="Tanenhaus et al., 1995" startWordPosition="166" endWordPosition="169">on can in principle be read. We contrast two predictive parsing approaches, topdown and left-corner parsing, and find both to be viable. In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency. 1 Introduction Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse (Crain and Steedman, 1985; Altmann and Steedman, 1988; Britt, 1994) and in the visual environment (Tanenhaus et al., 1995). These results lend support to Mark Steedman&apos;s (1989) &amp;quot;intuition&amp;quot; that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived. This is a very commonly held view among psycholinguists today. Many possible models of human sentence processing can be made consistent with the above view, but the general assumption that must underlie them all is that explicit relationships between lexical items in the sentence must be specified incrementally. Such a processing mechatThis material is based on work supported by the Nat</context>
</contexts>
<marker>Tanenhaus, Spivey-Knowlton, Eberhard, Sedivy, 1995</marker>
<rawString>M. Tanenhaus, M. Spivey-Knowlton, K. Eberhard, and J. Sedivy. 1995. Integration of visual and linguistic information during spoken language comprehension. Science, 268:1632-1634.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>