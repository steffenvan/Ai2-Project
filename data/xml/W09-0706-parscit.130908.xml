<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000312">
<title confidence="0.9985325">
Part-of-Speech tagging of Northern Sotho:
Disambiguating polysemous function words
</title>
<author confidence="0.940108">
Gertrud Faaßtt Ulrich Heidt Elsab´e Taljardt Danie Prinsloot
</author>
<affiliation confidence="0.803595">
t Institut f¨ur Maschinelle Sprachverarbeitung t University of Pretoria
</affiliation>
<address confidence="0.4577675">
Universit¨at Stuttgart South Africa
Germany
</address>
<email confidence="0.9722965">
faaszgd@ims.uni-stuttgart.de elsabe.taljard@up.ac.za
heid@ims.uni-stuttgart.de danie.prinsloo@up.ac.za
</email>
<sectionHeader confidence="0.993238" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999793666666667">
A major obstacle to part-of-speech
(=POS) tagging of Northern Sotho
(Bantu, S 32) are ambiguous function
words. Many are highly polysemous and
very frequent in texts, and their local
context is not always distinctive.
With certain taggers, this issue leads to
comparatively poor results (between 88
and 92 % accuracy), especially when
sizeable tagsets (over 100 tags) are used.
We use the RF-tagger (Schmid and Laws,
2008), which is particularly designed for
the annotation of fine-grained tagsets (e.g.
including agreement information), and
we restructure the 141 tags of the tagset
proposed by Taljard et al. (2008) in a way
to fit the RF tagger. This leads to over
94 % accuracy. Error analysis in addition
shows which types of phenomena cause
trouble in the POS-tagging of Northern
Sotho.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979818181818">
In this paper, we discuss issues of the part-of-
speech (POS) tagging of Northern Sotho, one of
the eleven official languages of South Africa, spo-
ken in the North-east of the country. Northern
Sotho is a Bantu language belonging to the Sotho
family (Guthrie, 1967: S32). It is written disjunc-
tively (contrary to e.g. Zulu), i.e. certain mor-
phemes appear as character strings separated by
blank spaces. It makes use of 18 noun classes (1,
1a, 2, 2b, 3 to 10, 14, 15, and the locative classes
16, 17, 18, N-, which may be summarized as LOC
for their identical syntactic features). A concor-
dial system helps to verify agreement or resolve
ambiguities.
We address questions of the ambiguity of func-
tion words, in the framework of an attempt to use
“standard” European-style statistical POS taggers
on Northern Sotho texts.
In the remainder of this section, we briefly dis-
cuss our objectives (section 1.1) and situate our
work within the state of the art (section 1.2). Sec-
tion 2 deals with the main issues at stake, the han-
dling of unknown open class words, and the pol-
ysemy of Northern Sotho function words. In sec-
tion 3, we discuss our methodology, summarizing
the tagset and the tagging technique used, and re-
porting results from other taggers. Section 4 is
devoted to details of our own results, the effects
of the size of training material (4.2), the effects
of polysemy and reading frequency (4.3), and it
includes a discussion of proposals for quality im-
provement (Spoustov´a et al., 2007). We conclude
in section 5.
</bodyText>
<subsectionHeader confidence="0.94768">
1.1 Objectives
</subsectionHeader>
<bodyText confidence="0.999980272727273">
The long term perspective of our work is to sup-
port information extraction, lexicography, as well
as grammar development of Northern Sotho with
POS-tagged and possibly parsed corpus data. We
currently use the 5.5 million word University of
Pretoria Sepedi Corpus (PSC, cf. de Schryver
and Prinsloo (2000)), as well as a 45,000 words
training corpus. We aim at high accuracy in the
POS-tagging, and at minimizing the amount of un-
known word forms in arbitrary unseen corpora, by
using guessers for the open word classes.
</bodyText>
<sectionHeader confidence="0.617232" genericHeader="introduction">
1.2 Recent work
</sectionHeader>
<bodyText confidence="0.999725">
A few publications, so far, deal with POS-tagging
of Northern Sotho; most prominently, de Schryver
and de Pauw (2007) have presented the MaxTag
method, a tagger based on Maximum Entropy
</bodyText>
<note confidence="0.9495525">
Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 38–45,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998089">
38
</page>
<bodyText confidence="0.99792756">
Learning (Berger et al., 1996) as implemented in
the machine learning package Maxent (Le, 2004).
When trained on manually annotated text, it ex-
tracts features such as the first and last letter of
each word, or the first two and last two letters or
the first three and last three letters of each word;
it takes the word and the tag preceding and fol-
lowing the item to be tagged, etc., to decide about
word/tag probabilities. De Schryver and de Pauw
report an accuracy of 93.5 % on unseen data, using
a small training corpus of only ca. 10,000 word
forms.
Other work is only partly engaged in POS-
tagging, e.g. Kotz´e’s (2008) finite state analysis of
the verb complex of Northern Sotho. This study
does not cover all parts of speech and can thus not
be directly compared with our work. Taljard et al.
(2008) and Van Rooy and Pretorius (2003) present
tagsets for Northern Sotho and the closely related
language Setswana, but they focus on the defini-
tion of the tagsets without discussing their auto-
matic application in detail. In (Prinsloo and Heid,
2005), POS-tagging is mentioned as a step in a
corpus processing pipeline for Northern Sotho, but
no experimental results are reported.
</bodyText>
<sectionHeader confidence="0.583934" genericHeader="method">
2 Challenges in tagging Northern Sotho
</sectionHeader>
<bodyText confidence="0.999693777777778">
POS-tagging of Northern Sotho and of any dis-
junctively written Bantu language has to deal es-
pecially with two major issues which are con-
sequences of their morphology and their syntax.
One is the presence, in any unseen text, of a num-
ber of lexical items which are not covered by the
lexicon of the tagger (“unknown words”), and the
other is an extraordinarily high number of ambigu-
ous function words.
</bodyText>
<subsectionHeader confidence="0.98212">
2.1 Unknown words
</subsectionHeader>
<bodyText confidence="0.999986155555556">
In Northern Sotho, nouns, verbs and adverbs are
open class items; all other categories are closed
word classes: their items can be listed. The open
classes are characterized in particular by a rich
morphology: nouns can form derivations to ex-
press diminutives and augmentatives, as well as
locative forms, to name just a few. Adding the
suffix -ng to toropo ‘town’, for example, forms
toropong, ‘in/at/to town’. For verbs, tense, voice,
mood and many other dimensions, as well as nom-
inalization, lead to an even larger number of de-
rived items. Prinsloo (1994) distinguishes 18 clus-
ters of verbal suffixes which give rise to over 260
individual derivation types per verb. Only a few
of these derivations are highly frequent in corpus
text; however, due to productivity, a large number
of verbal derivation types can potentially appear in
any unseen text.
For tagging, noun and verb derivations show up
as unknown items, and an attempt to cover them
within a large lexicon will partly fail due to pro-
ductivity and recursive applicability of certain af-
fixes. The impact of the unknown material on
tagging quality is evident: de Schryver and de
Pauw (2007) report 95.1 % accuracy on known
items, but only 78.9 % on unknowns; this leads
to a total accuracy of 93.5 % on their test corpus.
We have carried out experiments with a version
of the memory-based tagger, MBT (Daelemans et
al., 2007), which arrives at 90.67 % for the known
items of our own test corpus (see section 3.2), as
opposed to only 59.68 % for unknowns.
To counterbalance the effect of unknown items,
we use rule-based and partly heuristic guessers for
noun and verb forms (cf. Prinsloo et al. (2008) and
(Heid et al., 2008)) and add their results to the tag-
ger lexicon before applying the statistical tagger:
the possible annotations for all words contained in
the text are thus part of the knowledge available to
the tagger.
Adverbs are also an open word class in North-
ern Sotho; so far, we have no tools for identifying
them. In high quality tagging, the suggestions of
our guessers are examined manually, before they
are added to the tagger lexicon.
</bodyText>
<subsectionHeader confidence="0.943916">
2.2 Polysemous function words and
ambiguity
</subsectionHeader>
<bodyText confidence="0.9696765">
Function words of Northern Sotho are highly am-
biguous, and because of the disjunctive writing
system of the language, a number of bound mor-
phemes are written separately from other words.
A single form can have several functions. For
example, the token -a- is nine-ways ambiguous:
it can be a subject concord of noun class 1 or 6,
an object concord of class 6, a possessive concord
of class 6, a demonstrative of class 6, a hortative
or a question particle or a verbal morpheme in-
dicating present tense or past tense (Appendix A
illustrates the ambiguity of -a- with example sen-
tences). Furthermore, the most polysemous func-
tion words are also the most frequent word types in
corpora. The highly ambiguous item go1 alone ac-
111 different functions of go may be distinguished: object
</bodyText>
<page confidence="0.997623">
39
</page>
<bodyText confidence="0.999991">
counts for over 5 % of all occurrences in our train-
ing corpus, where 88 types of function words, with
an average frequency of well over 200, make up
for about 40 % of all occurrences.
The different readings of the function words are
not evenly distributed: some are highly frequent,
others are rare. Furthermore, many ambiguous
function words appear in the context of other func-
tion words; thus the local context does not nec-
essarily disambiguate individual function words.
This issue is particularly significant with ambigu-
ities between concords which can have the same
function (e.g. object) in different noun classes. As
mentioned, -a- can be a subject concord of either
noun class 1 or 6: though there are some clearcut
cases, like the appearance of a noun of class 6 (in-
dicating class 6), or an auxiliary or the conjunction
ge in the left context (both rather indicating class
1) there still remain a number of occurrences of -a-
in the corpora only where a broader context, some-
times even information from preceding sentences,
may help to disambiguate this item.
Consequently, comparing tagging performance
across different tagsets does not give very clear re-
sults: if a tagset, like the one used by de Schryver
and de Pauw (2007), does not distinguish noun
classes, obviously a large number of difficult dis-
ambiguation cases does not appear at all (their
tagset distinguishes, for example, subject and ob-
ject concord, but gives no information on noun
class numbers). For the lexicographic applica-
tion we are interested in, and more generally as a
preparatory step to chunking or parsing of North-
ern Sotho texts, an annotation providing informa-
tion on noun classes is however highly desirable.
</bodyText>
<sectionHeader confidence="0.996344" genericHeader="method">
3 Methodology
</sectionHeader>
<subsectionHeader confidence="0.990474">
3.1 Tagset
</subsectionHeader>
<bodyText confidence="0.999964717391305">
There are several proposals for tagsets to be used
for Northern Sotho and related languages. Van
Rooy and Pretorius (2003) propose a detailed
tagset for Setswana, which is fully in line with
the guidelines stated by the EAGLES project, cf.
Leech and Wilson (1999). This tagset encodes a
considerable number of semantic distinctions in
its nominal and verbal tags. In Kotz´e’s work on
concord of class 15, object concord of the locative classes,
object concord of the 2nd person singular, subject concord
of class 15, indefinite subject concord, subject concord of
the locative classes, class prefix of class 15, locative particle,
copulative indicating either an indefinite subject, or a subject
of class 15 or a locative subject.
the Northern Sotho verb complex, (Kotz´e, 2008),
a number of POS tags are utilized to distinguish
the elements of the verb, however, due to Kotz´e’s
objectives, her classification does not cover other
items. De Schryver and de Pauw (2007) use a
tagset of only 56 different tags, whereas the pro-
posal by Van Rooy and Pretorius leads to over 100
tags. Finally, Taljard et al. (2008) propose a rather
detailed tagset: contrary to the other authors men-
tioned, they do encode noun classes in all relevant
tags, which leads to a total of 141 tags. Further-
more, they encode a number of additional mor-
phosyntactic distinctions on a second level of their
tagset, which leads to a total of 262 different clas-
sifications of Northern Sotho morphemes.
Our current tagset is inspired by Taljard et al.
(2008). However, we disregard some of their sec-
ond level information for the moment (which in
many cases encodes lexical properties of the items,
e.g. the subdivision of particles: hortative, ques-
tion, instrumental, locative, connective, etc.). We
use the RF-tagger (Schmid and Laws, 2008) (cf.
section 3.3), which is geared towards the annota-
tion of structured tagsets, by separating informa-
tion which partitions the inventory of forms (e.g.
broad word classes) from feature-like information
possibly shared by several classes, such as the
Sotho noun classes. With this method, we are able
to account for Taljard et al.’s (2008) 141 tags by
means of only 25 toplevel tags, plus a number of
feature-like labels of lower levels. We summarize
the properties of the tagsets considered in table 1.
</bodyText>
<subsectionHeader confidence="0.999204">
3.2 Training corpus
</subsectionHeader>
<bodyText confidence="0.999971533333333">
Our training corpus consists of ca. 45.000 manu-
ally annotated word forms, from two text types.
Over 20.000 word forms come from a novel of
the South African author Oliver K. Matsepe (Mat-
sepe, 1974); over 10.000 forms come from a Ph.D.
dissertation by Raphehli M. Thobakgale (Thobak-
gale, 2005), and another 10.000 from a second
Ph.D. dissertation, by Ramalau R. Maila (Maila,
2006). Obviously, this is not a balanced corpus; it
was indeed chosen because of its easy accessibil-
ity. We use this corpus to train our taggers and to
test them; in a ten-fold cross validation, we split
the text into ten slices of roughly equal size, train
on 9 of them and test on the tenth. In this article,
we give figures for the median of these results.
</bodyText>
<page confidence="0.991622">
40
</page>
<table confidence="0.679419833333333">
Authors No. of tags ± noun class tool?
(van Rooy and Pretorius, 2003) 106 - noun class no
(De Schryver and De Pauw, 2007) 56 - noun class yes
(Kotz´e, 2008) partial N.R. yes
(Taljard et al., 2008) 141/262 + noun class no
This paper 25/141 + noun class yes
</table>
<tableCaption confidence="0.995426">
Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools
</tableCaption>
<subsectionHeader confidence="0.995485">
3.3 Tagging techniques: the RF-tagger
</subsectionHeader>
<bodyText confidence="0.999896674418605">
We opt for the RF-tagger (Schmid and Laws,
2008), because it is a Hidden-Markov-Model
(HMM) tagger which was developed especially
for POS tagsets with a large number of (fine-
grained) tags. Tests with our training corpus have
shown that this tagger outperforms the Tree-tagger
((Schmid, 1994) and (Schmid, 1995)), as shown in
figure 1. An additional external lexicon may serve
as input, too. The development of the RF-tagger
was based on the widely shared opinion that for
languages like German or Czech, agreement in-
formation (e.g. case, number or person) should
preferably appear as part of all appropriate part
of speech tags. However, as tagsets increase im-
mensely in size when such information is part of
the tags, the data are decomposed, i.e. split into
several levels of processing. The probability of
each level is then calculated separately (the joint
probability of all levels is afterwards calculated as
their product). With such methodology, a tag of
the German determiner das may contain five levels
of information, e.g. ART.Def.Nom.Sg.Neut to de-
fine a definite, nominative singular, neutral deter-
miner (article) that appears in the nominative case.
This approach makes sense for the Bantu-
languages as well, since information on noun class
numbers should be part of the noun tags, too, as in
Taljard et al’s (2008) tagset. A noun here is not
only tagged “N”, but Nclass, e.g. mohumagadi
‘(married) woman’ as N01. All concords, pro-
nouns or other types that concordially agree with
nouns are also labelled with a class number, e.g.
o, the subject concord of class 1, is labelled CS01.
This approach makes sense, especially in the view
of chunking/parsing and reference resolution, be-
cause any of those elements can acquire a pronom-
inal function when the noun that they refer to is
deleted (Louwrens, 1991).
To utilize the RF-tagger, we split all tags con-
taining noun class numbers into several levels (e.g.
the tag N01 becomes N.01). Emphatic and posses-
sive pronouns are represented on three levels (e.g.
PROPOSSPERS becomes PRO.POSS.PERS)2.
</bodyText>
<sectionHeader confidence="0.999957" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.999956666666666">
In a preliminary experiment, we compared several
taggers3 on our manually annotated data. Apart
from the RF-tagger (Schmid and Laws, 2008),
we also used the Tree-Tagger (Schmid, 1994), the
TnT tagger (Brants, 2000) and MBT (Daelemans
et al., 2007).
</bodyText>
<subsectionHeader confidence="0.996619">
4.1 Comparing taggers
</subsectionHeader>
<bodyText confidence="0.97859544">
The results give a relatively homogenous picture,
with the RF-tagger achieving a median of 94.16 %
when utilising a lexicon containing several thou-
sand nouns and verbs. It leads to 91 % accuracy
without this lexicon (to simulate similar condi-
tions as for TnT or MBT where no external lex-
icon was offered). TnT achieves 91.01 %, and
MBT 87.68 %. Data from the Tree-Tagger were
not comparable for they had been obtained at an
earlier stage using the lexicon (92.46 %).
4.2 Effects of the size of the training corpus
on the tagging results
All probabilistic taggers are in need of training
data the size of which depends on the size of the
tagset and on the frequencies of occurrence of
each context. De Schryver and de Pauw (2007)
demonstrated that when utilizing a tagset that con-
tains only about a third of the tags (56) contained
in Taljard et al.’s (2008) tagset (141), their Max-
Tag POS-tagger reaches a 93.5 % accuracy with a
training corpus of only about 10,000 tokens.
Figure 1 depicts the effects of the size of the
training corpus on the accuracy figures of the Tree-
tagger and the RF-tagger. Tests with training cor-
pora of the sizes 15,000, 30,000 and 45,000 tokens
</bodyText>
<footnote confidence="0.9817904">
2Tests have shown that the quantitative pronouns should
be treated separately, their tags are thus only split into two
levels.
3Check the References section for the availability of these
taggers.
</footnote>
<page confidence="0.999181">
41
</page>
<figureCaption confidence="0.9593115">
Figure 1: Effects of the size of the training corpus
on tagger results.
</figureCaption>
<bodyText confidence="0.999199">
showed that the results might not improve much if
more data is added. The RF-tagger already reaches
more than 94 % correctness when utilizing the cur-
rent 45,000 token training corpus.
</bodyText>
<subsectionHeader confidence="0.9531755">
4.3 Effects of the highly polysemous function
words of Northern Sotho
</subsectionHeader>
<bodyText confidence="0.998464666666667">
The less frequently a token-label pair appears in
the corpus, the lower is its probability (leading to
the sparse data problem, when probability guesses
become unreliable because of low numbers of oc-
currences). This issue poses a problem for North-
ern Sotho function words: if they occur very fre-
quently with a certain label, the chances of them
being detected with another label are fairly low.
This effect is demonstrated in table 2, which de-
scribes the detection of the parts of speech of the
highly ambiguous function word -a-. The word -
a- as PART(icle) occurs only 45 times while -a-
as CS.01 occurs 1,182 times. More than 50% of
the particle occurrences (23) are wrongly labelled
CS.01 by the tagger. In table 2, we list the cor-
rect tags of all occurrences of -a-, as well as the
assigned tags to each of them by our tagger. Each
block of table 2 is ordered by decreasing numbers
of occurrence of each tag in the output of the RF-
tagger. For easier reference, the correct tags as-
signed by the RF-tagger are printed in bold. Table
2 also clearly shows the effect of ambiguous local
context on the tagging result: the accuracy of the
CS.06-annotation (subject concord of class 6) is
considerably lower than that of the more frequent
CS.01 (96.45 % vs. 63.08 %), and CS.01 is the
most frequent error in the CS.06 assignment pro-
</bodyText>
<table confidence="0.995647487179487">
a as freq RF-tagger sums %
CS.01 1182 CS.01 1140 96.4
CS.06 19 1.6
MORPH 14 1.2
CDEM.06 3 0.3
PART 2 0.2
CPOSS.06 2 0.2
CO.06 2 0.2
CS.06 176 CS.06 111 63.1
CS.01 43 24.4
CPOSS.06 10 5.7
CDEM.06 5 2.8
MORPH 3 1.7
PART 3 1.7
CO.06 1 0.6
CO.06 18 MORPH 7 38.9
CS.01 6 33.3
CO.06 3 16.7
CS.06 2 11.11
PART 45 CS.01 23 51.1
MORPH 11 24.4
CDEM.06 5 11.1
PART 5 11.1
CPOSS.06 1 2.2
CDEM.06 97 CDEM.06 89 91.8
CPOSS.06 4 4.1
CS.06 2 2.1
CS.01 1 1.0
PART 1 1.0
CPOSS.06 209 CPOSS.06 186 89.0
CDEM.06 12 5.7
CS.06 6 2.9
PART 4 1.9
CS.01 1 0.5
MORPH 89 MORPH 44 49.4
CO.06 26 29.2
CS.01 15 16.9
CPOSS.06 4 4.5
sums 1816 1816
</table>
<tableCaption confidence="0.995055">
Table 2: RF-tagger results for -a-
</tableCaption>
<bodyText confidence="0.816145">
cess.
</bodyText>
<subsectionHeader confidence="0.9135095">
4.4 Suggestions for increasing correctness
percentages
</subsectionHeader>
<bodyText confidence="0.9999382">
Spoustov´a et al. (2007) describe a significant in-
crease of accuracy in statistical tagging when uti-
lizing rule-based macros as a preprocessing, for
Czech. We have contemplated, in an earlier stage
of our work (Prinsloo and Heid, 2005) to adopt a
</bodyText>
<page confidence="0.997926">
42
</page>
<bodyText confidence="0.999958285714286">
similar strategy, i.e. to design rule-based macros
for the (partial) disambiguation of high-frequency
function words. However, the fact that the local
context of many function words is similar (i.e. the
ambiguity of this local context (see above)), is a
major obstacle to a disambiguation of single func-
tion words by means of rules. Rules would interact
in many ways, be dependent on the application or-
der, or disambiguate only partially (i.e. leave sev-
eral tag options). An alternative would be to de-
sign rules for the disambiguation of word or mor-
pheme sequences. This would however amount to
partial parsing. The status of such rules within a
tagging architecture would then be unclear.
</bodyText>
<subsectionHeader confidence="0.997857">
4.5 Effects of tagset size and structure
</subsectionHeader>
<bodyText confidence="0.999994130434783">
While a preprocessing with rule-based disam-
biguation does not seem to be promising, there
are other methods of improving accuracy, such as,
e.g., the adaptation of the tagset. Obviously, types
appearing in different contexts should have differ-
ent labels. For example, in the tagset of Taljard et
al. (2008), auxiliary verbs are a sub-class of verbs
(V aux). In typical Northern Sotho contexts, how-
ever, auxiliaries are surrounded by subject con-
cords, while verbs are only preceded by them.
When ’promoting’ the auxiliaries to the first level
by labelling them VAUX, the RF-tagger result in-
creases by 0.13 % to 94.16 % accuracy. We still
see room for further improvement here. For exam-
ple, ga as PART (either locative particle PART loc
or hortative particle PART hort) is identified cor-
rectly in only 29.2 % of all cases at the moment.
The hortative particle usually appears at the be-
ginning of a verbal segment, while the locative in
most cases follows the segment. Results may in-
crease to an even higher accuracy when ‘promot-
ing’ these second level annotations, hort(ative) and
loc(ative) to the first annotation level.
</bodyText>
<sectionHeader confidence="0.97228" genericHeader="method">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999976852459016">
This article gives an overview of work on POS-
tagging for Northern Sotho. Depending on the
place of tagging in an overall NLP chain for this
language, different choices with respect to the
tagset and to the tagging technology may prove
adequate.
In our work, which is part of a detailed lin-
guistic annotation of Northern Sotho corpora for
linguistic exploration with a view to lexicons and
grammars, it is vital to provide a solid basis for
chunking and/or parsing, by including informa-
tion on noun class numbers in the annotation.
We found that the RF-tagger (Schmid and Laws,
2008) performs well on this task, partly because
it allows us to structure the tagset into layers, and
to deal with noun class information in the same
way as with agreement features for European lan-
guages. We reach over 94% correctness, which
indicates that at least a first attempt at covering the
PSC corpus may now be in order.
Our error analysis, however, also highlights a
few more general aspects of the POS annotation
of Northern Sotho and related languages: obvi-
ously, frequent items and items in distinctive lo-
cal contexts are tagged quite well. When noun
class information is part of the distinctions under-
lying the tagset, function words usable for more
than one noun class tend however, to appear in
non-distinctive local contexts and thus to lead to
a considerable error rate. Furthermore, we found a
few cases of uses of, e.g., subject concords that are
anaphoric, with antecedents far away and thus not
accessible to tagging procedures based on the lo-
cal context. These facts raise the question whether,
to achieve the highest quality of lexical classifica-
tion of the words and morphemes of a text, chunk-
ing/parsing might be required altogether, rather
than tagging.
Our experiments also showed that several pa-
rameters are involved in fine-tuning a Sotho tag-
ger. The size and structure of the tagset is one
such a prominent parameter. Tendencies towards
simpler and smaller tagsets obviously conflict with
the needs of advanced processing of the texts and
of linguistically demanding applications. It seems
that tagset design and tool development go hand in
hand.
We intend to apply the current version of the
RF-tagger to the PSC corpus and to evaluate the
results carefully. We expect a substantial gain
from the use of the guessers for nouns and verbs,
cf. (Prinsloo et. al, 2008) and (Heid et al., 2008).
Detailed error analysis should allow us to also
design specific rules to correct the output of the
tagger. Instead of preprocessing (as proposed by
Spoustov´a et al. (2007)), a partial postprocess-
ing may contribute to further improving the overall
quality. Rules would then probably have to be ap-
plied to particular sequences of words and/or mor-
phemes which cause difficulties in the statistical
process.
</bodyText>
<page confidence="0.99971">
43
</page>
<sectionHeader confidence="0.990093" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.997530009433962">
Adam L. Berger, Stephen Della Peitra, and Vincent
J. Della Pietra. 1996. A Maximum Entropy Ap-
proach to Natural Language Processing. Computa-
tional Linguistics 22(1): pp. 39 – 71.
Thorsten Brants. 2000. TnT - A Statistical Part-of-
Speech Tagger. In Proceedings of the Sixth Applied
Natural Language Processing Conference ANLP-
2000, Seattle, WA.
Walter Daelemans, Jakub Zavrel, Antal van den Bosch.
2007. MBT: Memory-Base Tagger, version 3.1. Ref-
erence Guide. ILK Technical Report Series 07–08
[online]. Available : http://ilk.uvt.nl/
mbt (10th Jan, 2009).
Gilles-Maurice de Schryver and Guy de Pauw. 2007.
Dictionary Writing System (DWS) + Corpus Query
Package (CQP): The Case of TshwaneLex. Lexikos
17 AFRILEX-reeks/series 17:2007: pp. 226 –
246. [Online tagger:] http://aflat.org/?q=
node/177. (10th Feb, 2009)
Gilles-Maurice de Schryver and Daan J. Prinsloo.
2000. The compilation of electronic corpora with
special reference to the African languages. South-
ern African Linguistics and Applied Language Stud-
ies 18(1-4): pp. 89 – 106.
Malcolm Guthrie. 1971. Comparative Bantu: an in-
troduction to the comparative linguistics and prehis-
tory of the Bantu languages, vol 2, Farnborough:
Gregg International.
Ulrich Heid, Daan J. Prinsloo, Gertrud Faaß, and
Elsab´e Taljard. 2008 Designing a noun guesser for
part of speech tagging in Northern Sotho (33 pp).
ms: University of Pretoria.
Petronella M. Kotz´e. 2008. Northern Sotho grammat-
ical descriptions: the design of a tokeniser for the
verbal segment. Southern African Linguistics and
Applied Language Studies 26(2): pp. 197 – 208.
Zhang Le. 2004. Maximum Entropy Modeling Toolkit
for Python and C++ (Technical Report) [online].
Available: http://homepages.inf.ed.
ac.uk/s0450736/maxent_toolkit.html
(10th Jan, 2009).
Geoffrey Leech, Andrew Wilson. 1999. Standards for
Tagsets. in van Halteren (Ed.) Syntactic world-class
tagging: pp. 55 – 80 Dordrecht/Boston/London:
Kluwer Academic Publishers.
Louis J. Louwrens. 1991. Aspects of the Northern
Sotho Grammar p. 154. Pretoria:Via Afrika.
Ramalau A. Maila. 2006. Kgolo ya tiragatso ya Se-
pedi. [=“Development of the Sepedi Drama”]. Doc-
toral thesis. University of Pretoria, South Africa.
Oliver K. Matsepe. 1974. T˘sa Ka Mafuri. [=“From the
homestead”]. Pretoria: Van Schaik.
Daan J. Prinsloo. 1994. Lemmatization of verbs in
Northern Sotho. SA Journal of African Languages
14(2): pp. 93 – 102.
Daan J. Prinsloo and Ulrich Heid. 2005. Creating
word class tagged corpora for Northern Sotho by lin-
guistically informed bootstrapping. in: Isabella Ties
(Ed.): LULCL, Lesser used languages and compu-
tational linguistics, 27/28-10-2005, Bozen/Bolzano,
(Bozen: Eurac) 2006: pp. 97 – 113.
Daan J. Prinsloo, Gertrud Faaß, Elsab´e Taljard, and
Ulrich Heid. 2008. Designing a verb guesser for
part of speech tagging in Northern Sotho. Southern
African Linguistics and Applied Languages Studies
(SALALS) 26(2).
Helmut Schmid and Florian Laws. 2008. Es-
timation of Conditional Probabilities with
Decision Trees and an Application to Fine-
Grained POS Tagging [online]. COLING
2008. Manchester, Great Britain. Available:
http://www.ims.uni-stuttgart.de/
projekte/corplex/RFTagger/ (10th Jan,
2009).
Helmut Schmid. September 1994. Probabilistic
Part-of-Speech Tagging Using Decision Trees. Pro-
ceedings of the International Conference on New
Methods in Language Processing[online]. Avail-
able: http://www.ims.uni-stuttgart.
de/projekte/corplex/TreeTagger/
(10th Jan, 2009).
Helmut Schmid. March 1995. Improvements in Part-
of-Speech Tagging with an Application to German.
Proceedings of the ACL SIGDAT-Workshop.
Drahomira “johanka” Spoustov´a, Jan Haji˘c, Jan
Votrubec, Pavel Krbec, and Pavel Kv˘eto˘n. Jun
29, 2007. The best of two worlds: Coop-
eration of Statistical and Rule-based Taggers
for Czech. Balto-Slavonic Natural Language
Processing: pp. 67 – 74 [online]. Available:
http://langtech.jrc.it/BSNLP2007/
m/BSNLP-2007-proceedings.pdf (10th
Jan, 2009).
Elsab´e Taljard, Gertrud Faaß, Ulrich Heid and Daan J.
Prinsloo. 2008. On the development of a tagset for
Northern Sotho with special reference to standardi-
sation. Literator 29(1) 2008. Potchefstroom, South
Africa.
Raphehli M. Thobakgale. Khuet˘so ya OK Matsepe go
bangwadi ba Sepedi [=“Influence of OK Matsepe
on the writers of Sepedi”]. Doctoral thesis. Univer-
sity of Pretoria, South Africa.
Bertus van Rooy and Rigardt Pretorius. 2003. A word-
class tagset for Setswana. Southern African Linguis-
tics and Applied Language Studies 21(4): pp. 203 –
222.
</reference>
<page confidence="0.999248">
44
</page>
<sectionHeader confidence="0.731035" genericHeader="method">
Appendix A. The polysemy of -a-
Description Example
</sectionHeader>
<reference confidence="0.899995538461538">
1 Subject ge monna afihla
concord of conjunctive + noun cl. 1 + subject concord cl. 1 + verb stem
if/when + man + subj-cl1 + arrive
”when the man arrives”
2 Subject masogana a thu˘sa basadi
concord of noun cl. 6 + subject concord cl. 6 + verb stem + noun cl.2
nominal cl. 6 young men + subj-cl6 + help women
”the young men help the women”
3 Possessive maoto agagwe
concord of noun cl. 6 + possessive concord cl. 6 + possessive pronoun cl. 1
nominal cl. 6 feet + of + his
”his feet”
4 Present tense moruti˘si o a bit˘sa
</reference>
<bodyText confidence="0.77393825">
morpheme noun cl. 1 + subject concord cl.1 + present tense marker + verb stem
teacher + subj-cl1 + pres + call
”the teacher is calling”
5 Past tense moruti˘si ga o a bit˘sa masogana
morpheme noun cl. 1 + negation morpheme + subject concord cl.1 +
past tense marker + verb stem + noun cl. 6
teacher + neg + subj-cl1 + past + call + young men
”the teacher did not call the young men”
</bodyText>
<sectionHeader confidence="0.844998" genericHeader="method">
6 Demonstrative ba nyaka masogana a
</sectionHeader>
<bodyText confidence="0.924104090909091">
concord of subject concord cl. 2 + verb stem + noun cl. 6 + demonstrative concord
nominal cl. 6 they + look for + young men + these
”they are looking for these young men”
7 Hortative a ba tsene
particle hortative particle + subject concord cl. 2 + verb stem
let + subj-cl2 + come in
”let them come in”
8 Interrogative a o tseba Sepedi
particle interrogative particle + subject concord 2nd pers sg. + verb stem + noun cl. 7
ques + subj-2nd-pers-sg + know + Sepedi
”do you know Sepedi”
</bodyText>
<listItem confidence="0.547325">
9 Object moruti o a bidit˘se
</listItem>
<bodyText confidence="0.830550333333333">
concord of noun cl. 1 + subject concord cl. 1 + object concord cl. 6 + verb stem
teacher + subj-cl1 + obj-cl6 + called
”the teacher called them”
</bodyText>
<page confidence="0.999006">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.090891">
<title confidence="0.8051525">Part-of-Speech tagging of Northern Disambiguating polysemous function words</title>
<affiliation confidence="0.785106">f¨ur Maschinelle Sprachverarbeitung of Pretoria Universit¨at Stuttgart South</affiliation>
<address confidence="0.775096">Germany</address>
<email confidence="0.437782">faaszgd@ims.uni-stuttgart.deelsabe.taljard@up.ac.zaheid@ims.uni-stuttgart.dedanie.prinsloo@up.ac.za</email>
<abstract confidence="0.997821">A major obstacle to part-of-speech (=POS) tagging of Northern Sotho (Bantu, S 32) are ambiguous function words. Many are highly polysemous and very frequent in texts, and their local context is not always distinctive. With certain taggers, this issue leads to comparatively poor results (between 88 and 92 % accuracy), especially when sizeable tagsets (over 100 tags) are used. We use the RF-tagger (Schmid and Laws, 2008), which is particularly designed for the annotation of fine-grained tagsets (e.g. including agreement information), and we restructure the 141 tags of the tagset proposed by Taljard et al. (2008) in a way to fit the RF tagger. This leads to over 94 % accuracy. Error analysis in addition shows which types of phenomena cause trouble in the POS-tagging of Northern</abstract>
<intro confidence="0.647468">Sotho.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen Della Peitra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<volume>22</volume>
<issue>1</issue>
<pages>39--71</pages>
<contexts>
<context position="3659" citStr="Berger et al., 1996" startWordPosition="579" endWordPosition="582"> words training corpus. We aim at high accuracy in the POS-tagging, and at minimizing the amount of unknown word forms in arbitrary unseen corpora, by using guessers for the open word classes. 1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw (2007) have presented the MaxTag method, a tagger based on Maximum Entropy Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 38–45, Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics 38 Learning (Berger et al., 1996) as implemented in the machine learning package Maxent (Le, 2004). When trained on manually annotated text, it extracts features such as the first and last letter of each word, or the first two and last two letters or the first three and last three letters of each word; it takes the word and the tag preceding and following the item to be tagged, etc., to decide about word/tag probabilities. De Schryver and de Pauw report an accuracy of 93.5 % on unseen data, using a small training corpus of only ca. 10,000 word forms. Other work is only partly engaged in POStagging, e.g. Kotz´e’s (2008) finite</context>
</contexts>
<marker>Berger, Peitra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen Della Peitra, and Vincent J. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics 22(1): pp. 39 – 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT - A Statistical Part-ofSpeech Tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP2000,</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="15684" citStr="Brants, 2000" startWordPosition="2614" endWordPosition="2615">g and reference resolution, because any of those elements can acquire a pronominal function when the noun that they refer to is deleted (Louwrens, 1991). To utilize the RF-tagger, we split all tags containing noun class numbers into several levels (e.g. the tag N01 becomes N.01). Emphatic and possessive pronouns are represented on three levels (e.g. PROPOSSPERS becomes PRO.POSS.PERS)2. 4 Results In a preliminary experiment, we compared several taggers3 on our manually annotated data. Apart from the RF-tagger (Schmid and Laws, 2008), we also used the Tree-Tagger (Schmid, 1994), the TnT tagger (Brants, 2000) and MBT (Daelemans et al., 2007). 4.1 Comparing taggers The results give a relatively homogenous picture, with the RF-tagger achieving a median of 94.16 % when utilising a lexicon containing several thousand nouns and verbs. It leads to 91 % accuracy without this lexicon (to simulate similar conditions as for TnT or MBT where no external lexicon was offered). TnT achieves 91.01 %, and MBT 87.68 %. Data from the Tree-Tagger were not comparable for they had been obtained at an earlier stage using the lexicon (92.46 %). 4.2 Effects of the size of the training corpus on the tagging results All pr</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT - A Statistical Part-ofSpeech Tagger. In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP2000, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Antal van den Bosch</author>
</authors>
<title>MBT: Memory-Base Tagger, version 3.1. Reference Guide.</title>
<date>2007</date>
<booktitle>ILK Technical Report Series 07–08 [online]. Available : http://ilk.uvt.nl/ mbt (10th</booktitle>
<marker>Daelemans, Zavrel, van den Bosch, 2007</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Antal van den Bosch. 2007. MBT: Memory-Base Tagger, version 3.1. Reference Guide. ILK Technical Report Series 07–08 [online]. Available : http://ilk.uvt.nl/ mbt (10th Jan, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles-Maurice de Schryver</author>
<author>Guy de Pauw</author>
</authors>
<title>Dictionary Writing System (DWS) + Corpus Query Package (CQP): The Case of TshwaneLex.</title>
<date>2007</date>
<journal>Lexikos</journal>
<volume>17</volume>
<pages>226--246</pages>
<note>[Online tagger:] http://aflat.org/?q= node/177. (10th</note>
<marker>de Schryver, de Pauw, 2007</marker>
<rawString>Gilles-Maurice de Schryver and Guy de Pauw. 2007. Dictionary Writing System (DWS) + Corpus Query Package (CQP): The Case of TshwaneLex. Lexikos 17 AFRILEX-reeks/series 17:2007: pp. 226 – 246. [Online tagger:] http://aflat.org/?q= node/177. (10th Feb, 2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles-Maurice de Schryver</author>
<author>Daan J Prinsloo</author>
</authors>
<title>The compilation of electronic corpora with special reference to the African languages.</title>
<date>2000</date>
<journal>Southern African Linguistics and Applied Language Studies</journal>
<volume>18</volume>
<issue>1</issue>
<pages>89--106</pages>
<marker>de Schryver, Prinsloo, 2000</marker>
<rawString>Gilles-Maurice de Schryver and Daan J. Prinsloo. 2000. The compilation of electronic corpora with special reference to the African languages. Southern African Linguistics and Applied Language Studies 18(1-4): pp. 89 – 106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malcolm Guthrie</author>
</authors>
<title>Comparative Bantu: an introduction to the comparative linguistics and prehistory of the Bantu languages, vol 2,</title>
<date>1971</date>
<publisher>Gregg International.</publisher>
<location>Farnborough:</location>
<marker>Guthrie, 1971</marker>
<rawString>Malcolm Guthrie. 1971. Comparative Bantu: an introduction to the comparative linguistics and prehistory of the Bantu languages, vol 2, Farnborough: Gregg International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Heid</author>
<author>Daan J Prinsloo</author>
<author>Gertrud Faaß</author>
<author>Elsab´e Taljard</author>
</authors>
<title>Designing a noun guesser for part of speech tagging in Northern Sotho (33 pp). ms:</title>
<date>2008</date>
<institution>University of Pretoria.</institution>
<contexts>
<context position="6957" citStr="Heid et al., 2008" startWordPosition="1150" endWordPosition="1153"> the unknown material on tagging quality is evident: de Schryver and de Pauw (2007) report 95.1 % accuracy on known items, but only 78.9 % on unknowns; this leads to a total accuracy of 93.5 % on their test corpus. We have carried out experiments with a version of the memory-based tagger, MBT (Daelemans et al., 2007), which arrives at 90.67 % for the known items of our own test corpus (see section 3.2), as opposed to only 59.68 % for unknowns. To counterbalance the effect of unknown items, we use rule-based and partly heuristic guessers for noun and verb forms (cf. Prinsloo et al. (2008) and (Heid et al., 2008)) and add their results to the tagger lexicon before applying the statistical tagger: the possible annotations for all words contained in the text are thus part of the knowledge available to the tagger. Adverbs are also an open word class in Northern Sotho; so far, we have no tools for identifying them. In high quality tagging, the suggestions of our guessers are examined manually, before they are added to the tagger lexicon. 2.2 Polysemous function words and ambiguity Function words of Northern Sotho are highly ambiguous, and because of the disjunctive writing system of the language, a number</context>
</contexts>
<marker>Heid, Prinsloo, Faaß, Taljard, 2008</marker>
<rawString>Ulrich Heid, Daan J. Prinsloo, Gertrud Faaß, and Elsab´e Taljard. 2008 Designing a noun guesser for part of speech tagging in Northern Sotho (33 pp). ms: University of Pretoria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petronella M Kotz´e</author>
</authors>
<title>Northern Sotho grammatical descriptions: the design of a tokeniser for the verbal segment.</title>
<date>2008</date>
<journal>Southern African Linguistics and Applied Language Studies</journal>
<volume>26</volume>
<issue>2</issue>
<pages>197--208</pages>
<marker>Kotz´e, 2008</marker>
<rawString>Petronella M. Kotz´e. 2008. Northern Sotho grammatical descriptions: the design of a tokeniser for the verbal segment. Southern African Linguistics and Applied Language Studies 26(2): pp. 197 – 208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhang Le</author>
</authors>
<date>2004</date>
<booktitle>Maximum Entropy Modeling Toolkit for Python and C++ (Technical Report) [online]. Available: http://homepages.inf.ed. ac.uk/s0450736/maxent_toolkit.html (10th</booktitle>
<contexts>
<context position="3724" citStr="Le, 2004" startWordPosition="591" endWordPosition="592">inimizing the amount of unknown word forms in arbitrary unseen corpora, by using guessers for the open word classes. 1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw (2007) have presented the MaxTag method, a tagger based on Maximum Entropy Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 38–45, Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics 38 Learning (Berger et al., 1996) as implemented in the machine learning package Maxent (Le, 2004). When trained on manually annotated text, it extracts features such as the first and last letter of each word, or the first two and last two letters or the first three and last three letters of each word; it takes the word and the tag preceding and following the item to be tagged, etc., to decide about word/tag probabilities. De Schryver and de Pauw report an accuracy of 93.5 % on unseen data, using a small training corpus of only ca. 10,000 word forms. Other work is only partly engaged in POStagging, e.g. Kotz´e’s (2008) finite state analysis of the verb complex of Northern Sotho. This study</context>
</contexts>
<marker>Le, 2004</marker>
<rawString>Zhang Le. 2004. Maximum Entropy Modeling Toolkit for Python and C++ (Technical Report) [online]. Available: http://homepages.inf.ed. ac.uk/s0450736/maxent_toolkit.html (10th Jan, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
<author>Andrew Wilson</author>
</authors>
<title>Standards for Tagsets. in van Halteren (Ed.) Syntactic world-class tagging:</title>
<date>1999</date>
<pages>55</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<note>80 Dordrecht/Boston/London:</note>
<contexts>
<context position="10201" citStr="Leech and Wilson (1999)" startWordPosition="1698" endWordPosition="1701">set distinguishes, for example, subject and object concord, but gives no information on noun class numbers). For the lexicographic application we are interested in, and more generally as a preparatory step to chunking or parsing of Northern Sotho texts, an annotation providing information on noun classes is however highly desirable. 3 Methodology 3.1 Tagset There are several proposals for tagsets to be used for Northern Sotho and related languages. Van Rooy and Pretorius (2003) propose a detailed tagset for Setswana, which is fully in line with the guidelines stated by the EAGLES project, cf. Leech and Wilson (1999). This tagset encodes a considerable number of semantic distinctions in its nominal and verbal tags. In Kotz´e’s work on concord of class 15, object concord of the locative classes, object concord of the 2nd person singular, subject concord of class 15, indefinite subject concord, subject concord of the locative classes, class prefix of class 15, locative particle, copulative indicating either an indefinite subject, or a subject of class 15 or a locative subject. the Northern Sotho verb complex, (Kotz´e, 2008), a number of POS tags are utilized to distinguish the elements of the verb, however,</context>
</contexts>
<marker>Leech, Wilson, 1999</marker>
<rawString>Geoffrey Leech, Andrew Wilson. 1999. Standards for Tagsets. in van Halteren (Ed.) Syntactic world-class tagging: pp. 55 – 80 Dordrecht/Boston/London: Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louis J Louwrens</author>
</authors>
<title>Aspects of the Northern Sotho Grammar p. 154. Pretoria:Via Afrika.</title>
<date>1991</date>
<contexts>
<context position="15223" citStr="Louwrens, 1991" startWordPosition="2543" endWordPosition="2544">ulanguages as well, since information on noun class numbers should be part of the noun tags, too, as in Taljard et al’s (2008) tagset. A noun here is not only tagged “N”, but Nclass, e.g. mohumagadi ‘(married) woman’ as N01. All concords, pronouns or other types that concordially agree with nouns are also labelled with a class number, e.g. o, the subject concord of class 1, is labelled CS01. This approach makes sense, especially in the view of chunking/parsing and reference resolution, because any of those elements can acquire a pronominal function when the noun that they refer to is deleted (Louwrens, 1991). To utilize the RF-tagger, we split all tags containing noun class numbers into several levels (e.g. the tag N01 becomes N.01). Emphatic and possessive pronouns are represented on three levels (e.g. PROPOSSPERS becomes PRO.POSS.PERS)2. 4 Results In a preliminary experiment, we compared several taggers3 on our manually annotated data. Apart from the RF-tagger (Schmid and Laws, 2008), we also used the Tree-Tagger (Schmid, 1994), the TnT tagger (Brants, 2000) and MBT (Daelemans et al., 2007). 4.1 Comparing taggers The results give a relatively homogenous picture, with the RF-tagger achieving a m</context>
</contexts>
<marker>Louwrens, 1991</marker>
<rawString>Louis J. Louwrens. 1991. Aspects of the Northern Sotho Grammar p. 154. Pretoria:Via Afrika.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramalau A Maila</author>
</authors>
<title>Kgolo ya tiragatso ya Sepedi. [=“Development of the Sepedi Drama”]. Doctoral thesis.</title>
<date>2006</date>
<institution>University of Pretoria, South Africa.</institution>
<contexts>
<context position="12651" citStr="Maila, 2006" startWordPosition="2103" endWordPosition="2104">are able to account for Taljard et al.’s (2008) 141 tags by means of only 25 toplevel tags, plus a number of feature-like labels of lower levels. We summarize the properties of the tagsets considered in table 1. 3.2 Training corpus Our training corpus consists of ca. 45.000 manually annotated word forms, from two text types. Over 20.000 word forms come from a novel of the South African author Oliver K. Matsepe (Matsepe, 1974); over 10.000 forms come from a Ph.D. dissertation by Raphehli M. Thobakgale (Thobakgale, 2005), and another 10.000 from a second Ph.D. dissertation, by Ramalau R. Maila (Maila, 2006). Obviously, this is not a balanced corpus; it was indeed chosen because of its easy accessibility. We use this corpus to train our taggers and to test them; in a ten-fold cross validation, we split the text into ten slices of roughly equal size, train on 9 of them and test on the tenth. In this article, we give figures for the median of these results. 40 Authors No. of tags ± noun class tool? (van Rooy and Pretorius, 2003) 106 - noun class no (De Schryver and De Pauw, 2007) 56 - noun class yes (Kotz´e, 2008) partial N.R. yes (Taljard et al., 2008) 141/262 + noun class no This paper 25/141 + n</context>
</contexts>
<marker>Maila, 2006</marker>
<rawString>Ramalau A. Maila. 2006. Kgolo ya tiragatso ya Sepedi. [=“Development of the Sepedi Drama”]. Doctoral thesis. University of Pretoria, South Africa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver K Matsepe</author>
</authors>
<title>T˘sa Ka Mafuri. [=“From the homestead”].</title>
<date>1974</date>
<location>Pretoria: Van Schaik.</location>
<contexts>
<context position="12468" citStr="Matsepe, 1974" startWordPosition="2073" endWordPosition="2075">which partitions the inventory of forms (e.g. broad word classes) from feature-like information possibly shared by several classes, such as the Sotho noun classes. With this method, we are able to account for Taljard et al.’s (2008) 141 tags by means of only 25 toplevel tags, plus a number of feature-like labels of lower levels. We summarize the properties of the tagsets considered in table 1. 3.2 Training corpus Our training corpus consists of ca. 45.000 manually annotated word forms, from two text types. Over 20.000 word forms come from a novel of the South African author Oliver K. Matsepe (Matsepe, 1974); over 10.000 forms come from a Ph.D. dissertation by Raphehli M. Thobakgale (Thobakgale, 2005), and another 10.000 from a second Ph.D. dissertation, by Ramalau R. Maila (Maila, 2006). Obviously, this is not a balanced corpus; it was indeed chosen because of its easy accessibility. We use this corpus to train our taggers and to test them; in a ten-fold cross validation, we split the text into ten slices of roughly equal size, train on 9 of them and test on the tenth. In this article, we give figures for the median of these results. 40 Authors No. of tags ± noun class tool? (van Rooy and Pretor</context>
</contexts>
<marker>Matsepe, 1974</marker>
<rawString>Oliver K. Matsepe. 1974. T˘sa Ka Mafuri. [=“From the homestead”]. Pretoria: Van Schaik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daan J Prinsloo</author>
</authors>
<title>Lemmatization of verbs in Northern Sotho.</title>
<date>1994</date>
<journal>SA Journal of African Languages</journal>
<volume>14</volume>
<issue>2</issue>
<pages>93--102</pages>
<contexts>
<context position="5829" citStr="Prinsloo (1994)" startWordPosition="955" endWordPosition="956">h number of ambiguous function words. 2.1 Unknown words In Northern Sotho, nouns, verbs and adverbs are open class items; all other categories are closed word classes: their items can be listed. The open classes are characterized in particular by a rich morphology: nouns can form derivations to express diminutives and augmentatives, as well as locative forms, to name just a few. Adding the suffix -ng to toropo ‘town’, for example, forms toropong, ‘in/at/to town’. For verbs, tense, voice, mood and many other dimensions, as well as nominalization, lead to an even larger number of derived items. Prinsloo (1994) distinguishes 18 clusters of verbal suffixes which give rise to over 260 individual derivation types per verb. Only a few of these derivations are highly frequent in corpus text; however, due to productivity, a large number of verbal derivation types can potentially appear in any unseen text. For tagging, noun and verb derivations show up as unknown items, and an attempt to cover them within a large lexicon will partly fail due to productivity and recursive applicability of certain affixes. The impact of the unknown material on tagging quality is evident: de Schryver and de Pauw (2007) report</context>
</contexts>
<marker>Prinsloo, 1994</marker>
<rawString>Daan J. Prinsloo. 1994. Lemmatization of verbs in Northern Sotho. SA Journal of African Languages 14(2): pp. 93 – 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daan J Prinsloo</author>
<author>Ulrich Heid</author>
</authors>
<title>Creating word class tagged corpora for Northern Sotho by linguistically informed bootstrapping. in:</title>
<date>2005</date>
<booktitle>Isabella Ties (Ed.): LULCL, Lesser used languages and computational linguistics,</booktitle>
<pages>27--28</pages>
<location>Bozen/Bolzano, (Bozen: Eurac)</location>
<contexts>
<context position="4681" citStr="Prinsloo and Heid, 2005" startWordPosition="760" endWordPosition="763">chryver and de Pauw report an accuracy of 93.5 % on unseen data, using a small training corpus of only ca. 10,000 word forms. Other work is only partly engaged in POStagging, e.g. Kotz´e’s (2008) finite state analysis of the verb complex of Northern Sotho. This study does not cover all parts of speech and can thus not be directly compared with our work. Taljard et al. (2008) and Van Rooy and Pretorius (2003) present tagsets for Northern Sotho and the closely related language Setswana, but they focus on the definition of the tagsets without discussing their automatic application in detail. In (Prinsloo and Heid, 2005), POS-tagging is mentioned as a step in a corpus processing pipeline for Northern Sotho, but no experimental results are reported. 2 Challenges in tagging Northern Sotho POS-tagging of Northern Sotho and of any disjunctively written Bantu language has to deal especially with two major issues which are consequences of their morphology and their syntax. One is the presence, in any unseen text, of a number of lexical items which are not covered by the lexicon of the tagger (“unknown words”), and the other is an extraordinarily high number of ambiguous function words. 2.1 Unknown words In Northern</context>
<context position="19711" citStr="Prinsloo and Heid, 2005" startWordPosition="3339" endWordPosition="3342">MORPH 11 24.4 CDEM.06 5 11.1 PART 5 11.1 CPOSS.06 1 2.2 CDEM.06 97 CDEM.06 89 91.8 CPOSS.06 4 4.1 CS.06 2 2.1 CS.01 1 1.0 PART 1 1.0 CPOSS.06 209 CPOSS.06 186 89.0 CDEM.06 12 5.7 CS.06 6 2.9 PART 4 1.9 CS.01 1 0.5 MORPH 89 MORPH 44 49.4 CO.06 26 29.2 CS.01 15 16.9 CPOSS.06 4 4.5 sums 1816 1816 Table 2: RF-tagger results for -acess. 4.4 Suggestions for increasing correctness percentages Spoustov´a et al. (2007) describe a significant increase of accuracy in statistical tagging when utilizing rule-based macros as a preprocessing, for Czech. We have contemplated, in an earlier stage of our work (Prinsloo and Heid, 2005) to adopt a 42 similar strategy, i.e. to design rule-based macros for the (partial) disambiguation of high-frequency function words. However, the fact that the local context of many function words is similar (i.e. the ambiguity of this local context (see above)), is a major obstacle to a disambiguation of single function words by means of rules. Rules would interact in many ways, be dependent on the application order, or disambiguate only partially (i.e. leave several tag options). An alternative would be to design rules for the disambiguation of word or morpheme sequences. This would however </context>
</contexts>
<marker>Prinsloo, Heid, 2005</marker>
<rawString>Daan J. Prinsloo and Ulrich Heid. 2005. Creating word class tagged corpora for Northern Sotho by linguistically informed bootstrapping. in: Isabella Ties (Ed.): LULCL, Lesser used languages and computational linguistics, 27/28-10-2005, Bozen/Bolzano, (Bozen: Eurac) 2006: pp. 97 – 113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daan J Prinsloo</author>
<author>Gertrud Faaß</author>
<author>Elsab´e Taljard</author>
<author>Ulrich Heid</author>
</authors>
<title>Designing a verb guesser for part of speech tagging</title>
<date>2008</date>
<booktitle>in Northern Sotho. Southern African Linguistics and Applied Languages Studies (SALALS)</booktitle>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="6933" citStr="Prinsloo et al. (2008)" startWordPosition="1145" endWordPosition="1148">rtain affixes. The impact of the unknown material on tagging quality is evident: de Schryver and de Pauw (2007) report 95.1 % accuracy on known items, but only 78.9 % on unknowns; this leads to a total accuracy of 93.5 % on their test corpus. We have carried out experiments with a version of the memory-based tagger, MBT (Daelemans et al., 2007), which arrives at 90.67 % for the known items of our own test corpus (see section 3.2), as opposed to only 59.68 % for unknowns. To counterbalance the effect of unknown items, we use rule-based and partly heuristic guessers for noun and verb forms (cf. Prinsloo et al. (2008) and (Heid et al., 2008)) and add their results to the tagger lexicon before applying the statistical tagger: the possible annotations for all words contained in the text are thus part of the knowledge available to the tagger. Adverbs are also an open word class in Northern Sotho; so far, we have no tools for identifying them. In high quality tagging, the suggestions of our guessers are examined manually, before they are added to the tagger lexicon. 2.2 Polysemous function words and ambiguity Function words of Northern Sotho are highly ambiguous, and because of the disjunctive writing system o</context>
</contexts>
<marker>Prinsloo, Faaß, Taljard, Heid, 2008</marker>
<rawString>Daan J. Prinsloo, Gertrud Faaß, Elsab´e Taljard, and Ulrich Heid. 2008. Designing a verb guesser for part of speech tagging in Northern Sotho. Southern African Linguistics and Applied Languages Studies (SALALS) 26(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Florian Laws</author>
</authors>
<title>Estimation of Conditional Probabilities with Decision Trees and an Application to FineGrained POS Tagging [online].</title>
<date>2008</date>
<booktitle>COLING 2008. Manchester, Great Britain. Available: http://www.ims.uni-stuttgart.de/ projekte/corplex/RFTagger/ (10th</booktitle>
<contexts>
<context position="794" citStr="Schmid and Laws, 2008" startWordPosition="99" endWordPosition="102">Sprachverarbeitung t University of Pretoria Universit¨at Stuttgart South Africa Germany faaszgd@ims.uni-stuttgart.de elsabe.taljard@up.ac.za heid@ims.uni-stuttgart.de danie.prinsloo@up.ac.za Abstract A major obstacle to part-of-speech (=POS) tagging of Northern Sotho (Bantu, S 32) are ambiguous function words. Many are highly polysemous and very frequent in texts, and their local context is not always distinctive. With certain taggers, this issue leads to comparatively poor results (between 88 and 92 % accuracy), especially when sizeable tagsets (over 100 tags) are used. We use the RF-tagger (Schmid and Laws, 2008), which is particularly designed for the annotation of fine-grained tagsets (e.g. including agreement information), and we restructure the 141 tags of the tagset proposed by Taljard et al. (2008) in a way to fit the RF tagger. This leads to over 94 % accuracy. Error analysis in addition shows which types of phenomena cause trouble in the POS-tagging of Northern Sotho. 1 Introduction In this paper, we discuss issues of the part-ofspeech (POS) tagging of Northern Sotho, one of the eleven official languages of South Africa, spoken in the North-east of the country. Northern Sotho is a Bantu langua</context>
<context position="11746" citStr="Schmid and Laws, 2008" startWordPosition="1951" endWordPosition="1954"> they do encode noun classes in all relevant tags, which leads to a total of 141 tags. Furthermore, they encode a number of additional morphosyntactic distinctions on a second level of their tagset, which leads to a total of 262 different classifications of Northern Sotho morphemes. Our current tagset is inspired by Taljard et al. (2008). However, we disregard some of their second level information for the moment (which in many cases encodes lexical properties of the items, e.g. the subdivision of particles: hortative, question, instrumental, locative, connective, etc.). We use the RF-tagger (Schmid and Laws, 2008) (cf. section 3.3), which is geared towards the annotation of structured tagsets, by separating information which partitions the inventory of forms (e.g. broad word classes) from feature-like information possibly shared by several classes, such as the Sotho noun classes. With this method, we are able to account for Taljard et al.’s (2008) 141 tags by means of only 25 toplevel tags, plus a number of feature-like labels of lower levels. We summarize the properties of the tagsets considered in table 1. 3.2 Training corpus Our training corpus consists of ca. 45.000 manually annotated word forms, f</context>
<context position="13455" citStr="Schmid and Laws, 2008" startWordPosition="2252" endWordPosition="2255">dation, we split the text into ten slices of roughly equal size, train on 9 of them and test on the tenth. In this article, we give figures for the median of these results. 40 Authors No. of tags ± noun class tool? (van Rooy and Pretorius, 2003) 106 - noun class no (De Schryver and De Pauw, 2007) 56 - noun class yes (Kotz´e, 2008) partial N.R. yes (Taljard et al., 2008) 141/262 + noun class no This paper 25/141 + noun class yes Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools 3.3 Tagging techniques: the RF-tagger We opt for the RF-tagger (Schmid and Laws, 2008), because it is a Hidden-Markov-Model (HMM) tagger which was developed especially for POS tagsets with a large number of (finegrained) tags. Tests with our training corpus have shown that this tagger outperforms the Tree-tagger ((Schmid, 1994) and (Schmid, 1995)), as shown in figure 1. An additional external lexicon may serve as input, too. The development of the RF-tagger was based on the widely shared opinion that for languages like German or Czech, agreement information (e.g. case, number or person) should preferably appear as part of all appropriate part of speech tags. However, as tagsets</context>
<context position="15608" citStr="Schmid and Laws, 2008" startWordPosition="2600" endWordPosition="2603">s labelled CS01. This approach makes sense, especially in the view of chunking/parsing and reference resolution, because any of those elements can acquire a pronominal function when the noun that they refer to is deleted (Louwrens, 1991). To utilize the RF-tagger, we split all tags containing noun class numbers into several levels (e.g. the tag N01 becomes N.01). Emphatic and possessive pronouns are represented on three levels (e.g. PROPOSSPERS becomes PRO.POSS.PERS)2. 4 Results In a preliminary experiment, we compared several taggers3 on our manually annotated data. Apart from the RF-tagger (Schmid and Laws, 2008), we also used the Tree-Tagger (Schmid, 1994), the TnT tagger (Brants, 2000) and MBT (Daelemans et al., 2007). 4.1 Comparing taggers The results give a relatively homogenous picture, with the RF-tagger achieving a median of 94.16 % when utilising a lexicon containing several thousand nouns and verbs. It leads to 91 % accuracy without this lexicon (to simulate similar conditions as for TnT or MBT where no external lexicon was offered). TnT achieves 91.01 %, and MBT 87.68 %. Data from the Tree-Tagger were not comparable for they had been obtained at an earlier stage using the lexicon (92.46 %). </context>
<context position="22190" citStr="Schmid and Laws, 2008" startWordPosition="3755" endWordPosition="3758">on level. 5 Conclusions and future work This article gives an overview of work on POStagging for Northern Sotho. Depending on the place of tagging in an overall NLP chain for this language, different choices with respect to the tagset and to the tagging technology may prove adequate. In our work, which is part of a detailed linguistic annotation of Northern Sotho corpora for linguistic exploration with a view to lexicons and grammars, it is vital to provide a solid basis for chunking and/or parsing, by including information on noun class numbers in the annotation. We found that the RF-tagger (Schmid and Laws, 2008) performs well on this task, partly because it allows us to structure the tagset into layers, and to deal with noun class information in the same way as with agreement features for European languages. We reach over 94% correctness, which indicates that at least a first attempt at covering the PSC corpus may now be in order. Our error analysis, however, also highlights a few more general aspects of the POS annotation of Northern Sotho and related languages: obviously, frequent items and items in distinctive local contexts are tagged quite well. When noun class information is part of the distinc</context>
</contexts>
<marker>Schmid, Laws, 2008</marker>
<rawString>Helmut Schmid and Florian Laws. 2008. Estimation of Conditional Probabilities with Decision Trees and an Application to FineGrained POS Tagging [online]. COLING 2008. Manchester, Great Britain. Available: http://www.ims.uni-stuttgart.de/ projekte/corplex/RFTagger/ (10th Jan, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>Proceedings of the International Conference on New Methods in Language Processing[online]. Available: http://www.ims.uni-stuttgart. de/projekte/corplex/TreeTagger/ (10th</booktitle>
<contexts>
<context position="13698" citStr="Schmid, 1994" startWordPosition="2291" endWordPosition="2292">noun class no (De Schryver and De Pauw, 2007) 56 - noun class yes (Kotz´e, 2008) partial N.R. yes (Taljard et al., 2008) 141/262 + noun class no This paper 25/141 + noun class yes Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools 3.3 Tagging techniques: the RF-tagger We opt for the RF-tagger (Schmid and Laws, 2008), because it is a Hidden-Markov-Model (HMM) tagger which was developed especially for POS tagsets with a large number of (finegrained) tags. Tests with our training corpus have shown that this tagger outperforms the Tree-tagger ((Schmid, 1994) and (Schmid, 1995)), as shown in figure 1. An additional external lexicon may serve as input, too. The development of the RF-tagger was based on the widely shared opinion that for languages like German or Czech, agreement information (e.g. case, number or person) should preferably appear as part of all appropriate part of speech tags. However, as tagsets increase immensely in size when such information is part of the tags, the data are decomposed, i.e. split into several levels of processing. The probability of each level is then calculated separately (the joint probability of all levels is a</context>
<context position="15653" citStr="Schmid, 1994" startWordPosition="2609" endWordPosition="2610"> in the view of chunking/parsing and reference resolution, because any of those elements can acquire a pronominal function when the noun that they refer to is deleted (Louwrens, 1991). To utilize the RF-tagger, we split all tags containing noun class numbers into several levels (e.g. the tag N01 becomes N.01). Emphatic and possessive pronouns are represented on three levels (e.g. PROPOSSPERS becomes PRO.POSS.PERS)2. 4 Results In a preliminary experiment, we compared several taggers3 on our manually annotated data. Apart from the RF-tagger (Schmid and Laws, 2008), we also used the Tree-Tagger (Schmid, 1994), the TnT tagger (Brants, 2000) and MBT (Daelemans et al., 2007). 4.1 Comparing taggers The results give a relatively homogenous picture, with the RF-tagger achieving a median of 94.16 % when utilising a lexicon containing several thousand nouns and verbs. It leads to 91 % accuracy without this lexicon (to simulate similar conditions as for TnT or MBT where no external lexicon was offered). TnT achieves 91.01 %, and MBT 87.68 %. Data from the Tree-Tagger were not comparable for they had been obtained at an earlier stage using the lexicon (92.46 %). 4.2 Effects of the size of the training corpu</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. September 1994. Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of the International Conference on New Methods in Language Processing[online]. Available: http://www.ims.uni-stuttgart. de/projekte/corplex/TreeTagger/ (10th Jan, 2009).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Improvements in Partof-Speech Tagging with an Application to German.</title>
<date>1995</date>
<booktitle>Proceedings of the ACL SIGDAT-Workshop. Drahomira “johanka” Spoustov´a,</booktitle>
<contexts>
<context position="13717" citStr="Schmid, 1995" startWordPosition="2294" endWordPosition="2295">chryver and De Pauw, 2007) 56 - noun class yes (Kotz´e, 2008) partial N.R. yes (Taljard et al., 2008) 141/262 + noun class no This paper 25/141 + noun class yes Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools 3.3 Tagging techniques: the RF-tagger We opt for the RF-tagger (Schmid and Laws, 2008), because it is a Hidden-Markov-Model (HMM) tagger which was developed especially for POS tagsets with a large number of (finegrained) tags. Tests with our training corpus have shown that this tagger outperforms the Tree-tagger ((Schmid, 1994) and (Schmid, 1995)), as shown in figure 1. An additional external lexicon may serve as input, too. The development of the RF-tagger was based on the widely shared opinion that for languages like German or Czech, agreement information (e.g. case, number or person) should preferably appear as part of all appropriate part of speech tags. However, as tagsets increase immensely in size when such information is part of the tags, the data are decomposed, i.e. split into several levels of processing. The probability of each level is then calculated separately (the joint probability of all levels is afterwards calculate</context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>Helmut Schmid. March 1995. Improvements in Partof-Speech Tagging with an Application to German. Proceedings of the ACL SIGDAT-Workshop. Drahomira “johanka” Spoustov´a, Jan Haji˘c, Jan Votrubec, Pavel Krbec, and Pavel Kv˘eto˘n. Jun 29, 2007. The best of two worlds: Cooperation of Statistical and Rule-based Taggers for Czech. Balto-Slavonic Natural Language Processing: pp. 67 – 74 [online]. Available: http://langtech.jrc.it/BSNLP2007/ m/BSNLP-2007-proceedings.pdf (10th Jan, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elsab´e Taljard</author>
<author>Gertrud Faaß</author>
<author>Ulrich Heid</author>
<author>Daan J Prinsloo</author>
</authors>
<title>On the development of a tagset for Northern Sotho with special reference to standardisation.</title>
<date>2008</date>
<journal>Literator</journal>
<volume>29</volume>
<issue>1</issue>
<location>Potchefstroom, South Africa.</location>
<contexts>
<context position="989" citStr="Taljard et al. (2008)" startWordPosition="128" endWordPosition="131">act A major obstacle to part-of-speech (=POS) tagging of Northern Sotho (Bantu, S 32) are ambiguous function words. Many are highly polysemous and very frequent in texts, and their local context is not always distinctive. With certain taggers, this issue leads to comparatively poor results (between 88 and 92 % accuracy), especially when sizeable tagsets (over 100 tags) are used. We use the RF-tagger (Schmid and Laws, 2008), which is particularly designed for the annotation of fine-grained tagsets (e.g. including agreement information), and we restructure the 141 tags of the tagset proposed by Taljard et al. (2008) in a way to fit the RF tagger. This leads to over 94 % accuracy. Error analysis in addition shows which types of phenomena cause trouble in the POS-tagging of Northern Sotho. 1 Introduction In this paper, we discuss issues of the part-ofspeech (POS) tagging of Northern Sotho, one of the eleven official languages of South Africa, spoken in the North-east of the country. Northern Sotho is a Bantu language belonging to the Sotho family (Guthrie, 1967: S32). It is written disjunctively (contrary to e.g. Zulu), i.e. certain morphemes appear as character strings separated by blank spaces. It makes </context>
<context position="4434" citStr="Taljard et al. (2008)" startWordPosition="720" endWordPosition="723">t letter of each word, or the first two and last two letters or the first three and last three letters of each word; it takes the word and the tag preceding and following the item to be tagged, etc., to decide about word/tag probabilities. De Schryver and de Pauw report an accuracy of 93.5 % on unseen data, using a small training corpus of only ca. 10,000 word forms. Other work is only partly engaged in POStagging, e.g. Kotz´e’s (2008) finite state analysis of the verb complex of Northern Sotho. This study does not cover all parts of speech and can thus not be directly compared with our work. Taljard et al. (2008) and Van Rooy and Pretorius (2003) present tagsets for Northern Sotho and the closely related language Setswana, but they focus on the definition of the tagsets without discussing their automatic application in detail. In (Prinsloo and Heid, 2005), POS-tagging is mentioned as a step in a corpus processing pipeline for Northern Sotho, but no experimental results are reported. 2 Challenges in tagging Northern Sotho POS-tagging of Northern Sotho and of any disjunctively written Bantu language has to deal especially with two major issues which are consequences of their morphology and their syntax.</context>
<context position="11049" citStr="Taljard et al. (2008)" startWordPosition="1837" endWordPosition="1840">bject concord of class 15, indefinite subject concord, subject concord of the locative classes, class prefix of class 15, locative particle, copulative indicating either an indefinite subject, or a subject of class 15 or a locative subject. the Northern Sotho verb complex, (Kotz´e, 2008), a number of POS tags are utilized to distinguish the elements of the verb, however, due to Kotz´e’s objectives, her classification does not cover other items. De Schryver and de Pauw (2007) use a tagset of only 56 different tags, whereas the proposal by Van Rooy and Pretorius leads to over 100 tags. Finally, Taljard et al. (2008) propose a rather detailed tagset: contrary to the other authors mentioned, they do encode noun classes in all relevant tags, which leads to a total of 141 tags. Furthermore, they encode a number of additional morphosyntactic distinctions on a second level of their tagset, which leads to a total of 262 different classifications of Northern Sotho morphemes. Our current tagset is inspired by Taljard et al. (2008). However, we disregard some of their second level information for the moment (which in many cases encodes lexical properties of the items, e.g. the subdivision of particles: hortative, </context>
<context position="13205" citStr="Taljard et al., 2008" startWordPosition="2207" endWordPosition="2210">from a second Ph.D. dissertation, by Ramalau R. Maila (Maila, 2006). Obviously, this is not a balanced corpus; it was indeed chosen because of its easy accessibility. We use this corpus to train our taggers and to test them; in a ten-fold cross validation, we split the text into ten slices of roughly equal size, train on 9 of them and test on the tenth. In this article, we give figures for the median of these results. 40 Authors No. of tags ± noun class tool? (van Rooy and Pretorius, 2003) 106 - noun class no (De Schryver and De Pauw, 2007) 56 - noun class yes (Kotz´e, 2008) partial N.R. yes (Taljard et al., 2008) 141/262 + noun class no This paper 25/141 + noun class yes Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools 3.3 Tagging techniques: the RF-tagger We opt for the RF-tagger (Schmid and Laws, 2008), because it is a Hidden-Markov-Model (HMM) tagger which was developed especially for POS tagsets with a large number of (finegrained) tags. Tests with our training corpus have shown that this tagger outperforms the Tree-tagger ((Schmid, 1994) and (Schmid, 1995)), as shown in figure 1. An additional external lexicon may serve as input, too. The dev</context>
<context position="20763" citStr="Taljard et al. (2008)" startWordPosition="3512" endWordPosition="3515">iguate only partially (i.e. leave several tag options). An alternative would be to design rules for the disambiguation of word or morpheme sequences. This would however amount to partial parsing. The status of such rules within a tagging architecture would then be unclear. 4.5 Effects of tagset size and structure While a preprocessing with rule-based disambiguation does not seem to be promising, there are other methods of improving accuracy, such as, e.g., the adaptation of the tagset. Obviously, types appearing in different contexts should have different labels. For example, in the tagset of Taljard et al. (2008), auxiliary verbs are a sub-class of verbs (V aux). In typical Northern Sotho contexts, however, auxiliaries are surrounded by subject concords, while verbs are only preceded by them. When ’promoting’ the auxiliaries to the first level by labelling them VAUX, the RF-tagger result increases by 0.13 % to 94.16 % accuracy. We still see room for further improvement here. For example, ga as PART (either locative particle PART loc or hortative particle PART hort) is identified correctly in only 29.2 % of all cases at the moment. The hortative particle usually appears at the beginning of a verbal seg</context>
</contexts>
<marker>Taljard, Faaß, Heid, Prinsloo, 2008</marker>
<rawString>Elsab´e Taljard, Gertrud Faaß, Ulrich Heid and Daan J. Prinsloo. 2008. On the development of a tagset for Northern Sotho with special reference to standardisation. Literator 29(1) 2008. Potchefstroom, South Africa.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Raphehli M Thobakgale</author>
</authors>
<title>Khuet˘so ya OK Matsepe go bangwadi ba Sepedi [=“Influence of OK Matsepe on the writers of Sepedi”]. Doctoral thesis.</title>
<institution>University of Pretoria, South Africa.</institution>
<marker>Thobakgale, </marker>
<rawString>Raphehli M. Thobakgale. Khuet˘so ya OK Matsepe go bangwadi ba Sepedi [=“Influence of OK Matsepe on the writers of Sepedi”]. Doctoral thesis. University of Pretoria, South Africa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bertus van Rooy</author>
<author>Rigardt Pretorius</author>
</authors>
<title>A wordclass tagset for Setswana.</title>
<date>2003</date>
<journal>Southern African Linguistics and Applied Language Studies</journal>
<volume>21</volume>
<issue>4</issue>
<pages>203--222</pages>
<marker>van Rooy, Pretorius, 2003</marker>
<rawString>Bertus van Rooy and Rigardt Pretorius. 2003. A wordclass tagset for Setswana. Southern African Linguistics and Applied Language Studies 21(4): pp. 203 – 222.</rawString>
</citation>
<citation valid="false">
<title>1 Subject ge monna afihla concord of conjunctive + noun cl. 1 + subject concord cl. 1 + verb stem if/when + man + subj-cl1 + arrive ”when the man arrives” 2 Subject masogana a thu˘sa basadi concord of noun cl. 6 + subject concord cl.</title>
<booktitle>6 + verb stem + noun cl.2 nominal cl. 6 young men + subj-cl6 + help</booktitle>
<marker></marker>
<rawString>1 Subject ge monna afihla concord of conjunctive + noun cl. 1 + subject concord cl. 1 + verb stem if/when + man + subj-cl1 + arrive ”when the man arrives” 2 Subject masogana a thu˘sa basadi concord of noun cl. 6 + subject concord cl. 6 + verb stem + noun cl.2 nominal cl. 6 young men + subj-cl6 + help women ”the young men help the women” 3 Possessive maoto agagwe concord of noun cl. 6 + possessive concord cl. 6 + possessive pronoun cl. 1 nominal cl. 6 feet + of + his ”his feet” 4 Present tense moruti˘si o a bit˘sa</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>