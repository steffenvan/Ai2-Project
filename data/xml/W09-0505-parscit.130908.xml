<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.9966725">
Annotating Spoken Dialogs: from Speech Segments to Dialog Acts and
Frame Semantics
</title>
<author confidence="0.998786">
Marco Dinarelli, Silvia Quarteroni, Sara Tonelli, Alessandro Moschitti, Giuseppe Riccardi*
</author>
<affiliation confidence="0.999087">
University of Trento
</affiliation>
<address confidence="0.839357">
38050 Povo - Trento, Italy
</address>
<email confidence="0.99849">
{dinarelli,silviaq,moschitti,riccardi}@disi.unitn.it, satonelli@fbk.eu
</email>
<sectionHeader confidence="0.993902" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998475">
We are interested in extracting semantic
structures from spoken utterances gener-
ated within conversational systems. Cur-
rent Spoken Language Understanding sys-
tems rely either on hand-written seman-
tic grammars or on flat attribute-value se-
quence labeling. While the former ap-
proach is known to be limited in coverage
and robustness, the latter lacks detailed re-
lations amongst attribute-value pairs. In
this paper, we describe and analyze the hu-
man annotation process of rich semantic
structures in order to train semantic statis-
tical parsers. We have annotated spoken
conversations from both a human-machine
and a human-human spoken dialog cor-
pus. Given a sentence of the transcribed
corpora, domain concepts and other lin-
guistic features are annotated, ranging
from e.g. part-of-speech tagging and con-
stituent chunking, to more advanced anno-
tations, such as syntactic, dialog act and
predicate argument structure. In particu-
lar, the two latter annotation layers appear
to be promising for the design of complex
dialog systems. Statistics and mutual in-
formation estimates amongst such features
are reported and compared across corpora.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9978421">
Spoken language understanding (SLU) addresses
the problem of extracting and annotating the
meaning structure from spoken utterances in the
context of human dialogs (De Mori et al., 2008).
In spoken dialog systems (SDS) most used models
of SLU are based on the identification of slots (en-
Phis work was partially funded by the European Com-
mission projects LUNA (contract 33549) and ADAMACH
(contract 022593).
tities) within one or more frames (frame-slot se-
mantics) that is defined by the application. While
this model is simple and clearly insufficient to
cope with interpretation and reasoning, it has sup-
ported the first generation of spoken dialog sys-
tems. Such dialog systems are thus limited by the
ability to parse semantic features such as predi-
cates and to perform logical computation in the
context of a specific dialog act (Bechet et al.,
2004). This limitation is reflected in the type of
human-machine interactions which are mostly di-
rected at querying the user for specific slots (e.g.
“What is the departure city?”) or implementing
simple dialog acts (e.g. confirmation). We believe
that an important step in overcoming such limita-
tion relies on the study of models of human-human
dialogs at different levels of representation: lexi-
cal, syntactic, semantic and discourse.
In this paper, we present our results in address-
ing the above issues in the context of the LUNA
research project for next-generation spoken dialog
interfaces (De Mori et al., 2008). We propose
models for different levels of annotation of the
LUNA spoken dialog corpus, including attribute-
value, predicate argument structures and dialog
acts. We describe the tools and the adaptation of
off-the-shelf resources to carry out annotation of
the predicate argument structures (PAS) of spoken
utterances. We present a quantitative analysis of
such semantic structures for both human-machine
and human-human conversations.
To the best of our knowledge this is the first
(human-machine and human-human) SDS corpus
denoting a multilayer approach to the annotation
of lexical, semantic and dialog features, which al-
lows us to investigate statistical relations between
the layers such as shallow semantic and discourse
features used by humans or machines. In the fol-
lowing sections we describe the corpus, as well as
a quantitative analysis and statistical correlations
between annotation layers.
</bodyText>
<note confidence="0.8962075">
Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 34–41,
Athens, Greece, 30 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.996301">
34
</page>
<sectionHeader confidence="0.979759" genericHeader="method">
2 Annotation model
</sectionHeader>
<bodyText confidence="0.999968133333333">
Our corpus is planned to contain 1000 equally
partitioned Human-Human (HH) and Human-
Machine (HM) dialogs. These are recorded by
the customer care and technical support center of
an Italian company. While HH dialogs refer to
real conversations of users engaged in a problem
solving task in the domain of software/hardware
troubleshooting, HM dialogs are acquired with a
Wizard of Oz approach (WOZ). The human agent
(wizard) reacts to user’s spontaneous spoken re-
quests following one of ten possible dialog scenar-
ios inspired by the services provided by the com-
pany.
The above data is organized in transcrip-
tions and annotations of speech based on a new
multi-level protocol studied specifically within the
project, i.e. the annotation levels of words, turns1,
attribute-value pairs, dialog acts, predicate argu-
ment structures. The annotation at word level
is made with part-of-speech and morphosyntac-
tic information following the recommendations of
EAGLES corpora annotation (Leech and Wilson,
2006). The attribute-value annotation uses a pre-
defined domain ontology to specify concepts and
their relations. Dialog acts are used to annotate in-
tention in an utterance and can be useful to find
relations between different utterances as the next
section will show. For predicate structure annota-
tion, we followed the FrameNet model (Baker et
al., 1998) (see Section 2.2).
</bodyText>
<subsectionHeader confidence="0.996548">
2.1 Dialog Act annotation
</subsectionHeader>
<bodyText confidence="0.993274076923077">
Dialog act annotation is the task of identifying
the function or goal of a given utterance (Sinclair
and Coulthard, 1975): thus, it provides a comple-
mentary information to the identification of do-
main concepts in the utterance, and a domain-
independent dialog act scheme can be applied.
For our corpus, we used a dialog act taxonomy
which follows initiatives such as DAMSL (Core
and Allen, 1997), TRAINS (Traum, 1996) and
DIT++ (Bunt, 2005). Although the level of granu-
larity and coverage varies across such taxonomies,
a careful analysis leads to identifying three main
groups of dialog acts:
</bodyText>
<listItem confidence="0.660801">
1. Core acts, which represent the fundamen-
tal actions performed in the dialog, e.g. re-
</listItem>
<footnote confidence="0.968722">
1A turn is defined as the interval when a speaker is active,
between two pauses in his/her speech flow.
</footnote>
<bodyText confidence="0.68454">
questing and providing information, or exe-
cuting a task. These include initiatives (often
called forward-looking acts) and responses
(backward-looking acts);
</bodyText>
<listItem confidence="0.984849857142857">
2. Conventional/Discourse management acts,
which maintain dialog cohesion and delimit
specific phases, such as opening, continua-
tion, closing, and apologizing;
3. Feedback/Grounding acts,used to elicit and
provide feedback in order to establish or re-
store a common ground in the conversation.
</listItem>
<bodyText confidence="0.9240175">
Our taxonomy, following the same three-fold
partition, is summarized in Table 1.
</bodyText>
<tableCaption confidence="0.995949">
Table 1: Dialog act taxonomy
</tableCaption>
<figure confidence="0.920855523809524">
Core dialog acts
Info-request Speaker wants information from ad-
dressee
Action-request Speaker wants addressee to perform
an action
Yes-answer Affirmative answer
No-answer Negative answer
Answer Other kinds of answer
Offer Speaker offers or commits to perform
an action
ReportOnAction Speaker notifies an action is being/has
been performed
Inform Speaker provides addressee with in-
formation not explicitly required (via
an Info-request)
Conventional dialog acts
Greet Conversation opening
Quit Conversation closing
Apology Apology
Thank Thanking (and down-playing)
Feedback/turn management dialog acts
</figure>
<subsectionHeader confidence="0.746638">
Clarif-request Speaker asks addressee for confirma-
</subsectionHeader>
<bodyText confidence="0.901975">
tion/repetition of previous utterance
for clarification.
</bodyText>
<subsectionHeader confidence="0.770397">
Ack Speaker expresses agreement with
</subsectionHeader>
<bodyText confidence="0.988522">
previous utterance, or provides feed-
back to signal understanding of what
the addressee said
</bodyText>
<subsectionHeader confidence="0.787003">
Filler Utterance whose main goal is to man-
</subsectionHeader>
<bodyText confidence="0.9960005">
age conversational time (i.e. dpeaker
taking time while keeping the turn)
</bodyText>
<subsectionHeader confidence="0.609788">
Non-interpretable/non-classifiable dialog acts
</subsectionHeader>
<bodyText confidence="0.948555125">
Other Default tag for non-interpretable and
non-classifiable utterances
It can be noted that we have decided to retain
only the most frequent dialog act types from the
schemes that inspired our work. Rather than as-
piring to the full discriminative power of possible
conversational situations, we have opted for a sim-
ple taxonomy that would cover the vast majority
</bodyText>
<page confidence="0.995943">
35
</page>
<bodyText confidence="0.99968052173913">
of utterances and at the same time would be able
to generalize them. Its small number of classes is
meant to allow a supervised classification method
to achieve reasonable performance with limited
data. The taxonomy is currently used by the sta-
tistical Dialogue Manager in the ADAMACH EU
project (Varges et al., 2008); the limited number
of classes allows to reduce the number of hypoth-
esized current dialogue acts, thus reducing the di-
alogue state space.
Dialog act annotation was performed manually
by a linguist on speech transcriptions previously
segmented into turns as mentioned above. The an-
notation unit for dialog acts, is the utterance; how-
ever, utterances are complex semantic entities that
do not necessarily correspond to turns. Hence, a
segmentation of the dialog transcription into ut-
terances was performed by the annotator before
dialog act labeling. Both utterance segmentation
and dialog act labeling were performed through
the MMAX tool (M¨uller and Strube, 2003).
The annotator proceeded according to the fol-
lowing guidelines:
</bodyText>
<listItem confidence="0.995900777777778">
1. by default, a turn is also an utterance;
2. if more than one tag is applicable to an ut-
terance, choose the tag corresponding to its
main function;
3. in case of doubt among several tags, give pri-
ority to tags in core dialog acts group;
4. when needed, split the turn into several utter-
ances or merge several turns into one utter-
ance.
</listItem>
<bodyText confidence="0.9970532">
Utterance segmentation provides the basis not
only for dialog act labeling but also for the other
semantic annotations. See Fig. 1 for a dialog sam-
ple where each line represents an utterance anno-
tated according to the three levels.
</bodyText>
<subsectionHeader confidence="0.999125">
2.2 Predicate Argument annotation
</subsectionHeader>
<bodyText confidence="0.9999001">
We carried out predicate argument structure an-
notation applying the FrameNet paradigm as de-
scribed in (Baker et al., 1998). This model
comprises a set of prototypical situations called
frames, the frame-evoking words or expressions
called lexical units and the roles or participants in-
volved in these situations, called frame elements.
The latter are typically the syntactic dependents of
the lexical units. All lexical units belonging to
the same frame have similar semantics and show
</bodyText>
<figure confidence="0.99263305">
PERSON-NAME
Info: Buongiorno, sono Paola.
GREETING B._NAMED Name
Good morning, this is Paola.
Info-req: Come la posso aiutare?
Benefitted_party ASSISTANCE
How may I help you?
CONCEPT HARDWARE-COMPONENT
Info: Buongiorno. Ho un problema con la stampante.
GREETING PR._DESCRIPTION Affected_device
Good morning. I have a problem with the printer.
PART-OF-DAY NEGAT. ACTION ACTION
Info: Da stamattina non riesco più a stampare
Problem
Since this morning I can’t print.
Info-req: Mi pu˜ dire nome e cognome per favore?
Addressee TELLING Message
Can you tell me your name and surname, please?
PERSON-NAME PERSON-SURNAME
Answer: Mi chiamo Alessandro Manzoni.
</figure>
<figureCaption confidence="0.999685">
Figure 1: Annotated dialog extract. Each utterance
</figureCaption>
<bodyText confidence="0.9958868">
is preceded by dialog act annotation. Attribute-
value annotation appears above the text, PAS an-
notation below the text.
the same valence. A particular feature of the
FrameNet project both for English and for other
languages is its corpus-based nature, i.e. every el-
ement described in the resource has to be instanti-
ated in a corpus. To annotate our SDS corpus, we
adopted where possible the already existing frame
and frame element descriptions defined for the En-
glish FrameNet project, and introduced new def-
initions only in case of missing elements in the
original model.
Figure 1 shows a dialog sample with PAS an-
notation reported below the utterance. All lexi-
cal units are underlined and the frame is written in
capitals, while the other labels refer to frame el-
ements. In particular, ASSISTANCE is evoked by
the lexical unit aiutare and has one attested frame
element (Benefitted party), GREETING has no
frame element, and PROBLEM DESCRIPTION
and TELLING have two frame elements each.
Figure 2 gives a comprehensive view of the an-
notation process, from audio file transcription to
the annotation of three semantic layers. Whereas
</bodyText>
<table confidence="0.286897">
Entity B._NAMED Name
My name is Alessandro Manzoni.
</table>
<page confidence="0.810836">
36
</page>
<figureCaption confidence="0.983438">
Figure 2: The annotation process
</figureCaption>
<table confidence="0.7162965">
Audio file
Turn segmentation &amp;
Transcription
Utterance segmentation
POS tagging Dialog Act
annotation
Domain attribute
annotation
Syntactic parsing
PAS annotation
</table>
<bodyText confidence="0.999718074074074">
in terms of dialog acts is considerably higher in
the HH corpus than in the HM one. This can be ex-
plained by the fact that the WOZ follows a unique,
previously defined task-solving strategy that does
not allow for digressions. Utterance segmentation
was also performed differently on the two corpora.
In HH we performed 167 turn mergings and 225
turn splittings; in HM dialogs, only turn splittings
(158) but no turn mergings were performed.
Tables 2 and 3 report the dialog acts occurring
in the HM and HH corpora, respectively, ranked
by their frequencies.
attribute-value and DA annotation are carried
out on the segmented dialogs at utterance level,
PAS annotation requires POS-tagging and syntac-
tic parsing (via Bikel’s parser trained for Italian
(Corazza et al., 2007)). Finally, a shallow manual
correction is carried out to make sure that the tree
nodes that may carry semantic information have
correct constituent boundaries. For the annotation
of frame information, we used the Salto tool (Bur-
chardt et al., 2006), that stores the dialog file in
TIGER-XML format and allows to easily intro-
duce word tags and frame flags. Frame informa-
tion is recorded on top of parse trees, with target
information pointing to terminal words and frame
elements pointing to tree nodes.
</bodyText>
<sectionHeader confidence="0.996611" genericHeader="method">
3 Quantitative comparison of the
Annotation
</sectionHeader>
<bodyText confidence="0.999986333333333">
We evaluated the outcome of dialog act and
PAS annotation levels on both the human-human
(henceforth HH) and human-machine (HM) cor-
pora by not only analyzing frequencies and occur-
rences in the separate levels, but also their interac-
tion, as discussed in the following sections.
</bodyText>
<subsectionHeader confidence="0.998572">
3.1 Dialog Act annotation
</subsectionHeader>
<bodyText confidence="0.993899">
Analyzing the annotation of 50 HM and 50 HH
dialogs at the dialog act level, we note that an
HH dialog is composed in average by 48.9±17.4
(standard deviation) dialog acts, whereas a HM
dialog is composed of 18.9±4.4. The difference
between average lengths shows how HH sponta-
neous speech can be redundant, while HM dialogs
are more limited to an exchange of essential infor-
mation. The standard deviation of a conversation
</bodyText>
<tableCaption confidence="0.7503825">
Table 2: Dialog acts ranked by frequency in the
human-machine (HM) corpus
</tableCaption>
<table confidence="0.998802333333334">
human-machine (HM)
DA count rel. freq.
Info-request 249 26.3%
Answer 171 18.1%
Inform 163 17.2%
Yes-answer 70 7.4%
Quit 60 6.3%
Thank 56 5.9%
Greet 50 5.3%
Offer 49 5.2%
Clarification-request 26 2.7%
Action-request 25 2.6%
Ack 12 1.3%
Filler 6 0.6%
No-answer 5 0.5%
Other, ReportOnAction 2 0.2%
Apology 1 0.1%
TOTAL 947
</table>
<bodyText confidence="0.744384">
From a comparative analysis, we note that:
</bodyText>
<listItem confidence="0.996439875">
1. info-request is by far the most common dia-
log act in HM, whereas in HH ack and info
share the top ranking position;
2. the most frequently occurring dialog act in
HH, i.e. ack, is only ranked 11th in HM;
3. the relative frequency of clarification-request
(4,7%) is considerably higher in HH than in
HM.
</listItem>
<bodyText confidence="0.998754">
We also analyzed the ranking of the most fre-
quent dialog act bigrams in the two corpora. We
can summarize our comparative analysis, reported
in Table 4, to the following: in both corpora,
most bigram types contain info and info-request,
</bodyText>
<page confidence="0.999791">
37
</page>
<tableCaption confidence="0.882199">
Table 3: Dialog acts ranked by frequency in the
human-human (HH) corpus
</tableCaption>
<table confidence="0.996286055555556">
human-human (HH)
DA count rel. freq.
Ack 582 23.8%
Inform 562 23.0%
Info-request 303 12.4%
Answer 192 7.8%
Clarification-request 116 4.7%
Offer 114 4.7%
Yes-answer 112 4.6%
Quit 101 4.1%
ReportOnAction 91 3.7%
Other 70 2.9%
Action-request 69 2.8%
Filler 61 2.5%
Thank 33 1.3%
No-answer 26 1.1%
Greet, Apology 7 0.3%
TOTAL 2446
</table>
<bodyText confidence="0.999740461538462">
as expected in a troubleshooting system. How-
ever, the bigram info-request answer, which we
expected to form the core of a task-solving dia-
log, is only ranked 5th in the HH corpus, while 5
out of the top 10 bigram types contain ack. We
believe that this is because HH dialogs primarily
contain spontaneous information-providing turns
(e.g. several info info by the same speaker) and
acknowledgements for the purpose of backchan-
nel. Instead, HM dialogs, structured as sequences
of info-request answers pairs, are more minimal
and brittle, showing how users tend to avoid re-
dundancy when addressing a machine.
</bodyText>
<tableCaption confidence="0.646567">
Table 4: The 10 most frequent dialog act bigrams
</tableCaption>
<bodyText confidence="0.983747272727273">
human-machine (HM) human-human (HH)
info-req answer ack info
answer info-req info ack
info info-req info info
info-req y-answer ack ack
sentence beginning greet info-req answer
greet info info info-req
info quit info-req y-answer
offer info ack info-req
thank info answer ack
y-answer thank quit sentence end
</bodyText>
<subsectionHeader confidence="0.999067">
3.2 Predicate Argument annotation
</subsectionHeader>
<bodyText confidence="0.9999872">
We annotated 50 HM and 50 HH dialogs with
frame information. Differently from the English
FrameNet database, we didn’t annotate one frame
per sentence. On the contrary, we identified all
lexical units corresponding to “semantically rele-
vant” verbs, nouns and adjectives with a syntac-
tic subcategorization pattern, eventually skipping
the utterances with empty semantics (e.g. dis-
fluencies). In particular, we annotated all lexical
units that imply an action, introduce the speaker’s
opinion or describe the office environment. We
introduced 20 new frames out of the 174 iden-
tified in the corpus because the original defini-
tion of frames related to hardware/software, data-
handling and customer assistance was sometimes
too coarse-grained. Few new frame elements were
introduced as well, mostly expressing syntactic re-
alizations that are typical of spoken Italian.
Table 5 shows some statistics about the cor-
pus dimension and the results of our annotation.
The human-human dialogs contain less frame in-
stances in average than the human-machine group,
meaning that speech disfluencies, not present in
turns uttered by the WOZ, negatively affect the se-
mantic density of a turn. For the same reason, the
percentage of turns in HH dialogs that were manu-
ally corrected in the pre-processing step (see Sec-
tion 2.2) is lower than for HM turns, since HH di-
alogs have more turns that are semantically empty
and that were skipped in the correction phase. Be-
sides, HH dialogs show a higher frame variabil-
ity than HM, which can be explained by the fact
that spontaneous conversation may concern mi-
nor topics, whereas HM dialogs follow a previ-
ously defined structure, designed to solve soft-
ware/hardware problems.
Tables 6 and 7 report the 10 most frequent
frames occurring in the human-machine resp.
human-human dialogs. The relative frame fre-
quency in HH dialogs is more sparse than in HM
dialogs, meaning that the task-solving strategy fol-
lowed by the WOZ limits the number of digres-
sions, whereas the semantics of HH dialogs is
richer and more variable.
As mentioned above, we had to introduce and
define new frames which were not present in the
original FrameNet database for English in order to
capture all relevant situations described in the di-
alogs. A number of these frames appear in both
tables, suggesting that the latter are indeed rel-
</bodyText>
<page confidence="0.999255">
38
</page>
<tableCaption confidence="0.77573175">
Table 5: Dialog turn and frame statistics for the
human-machine (HM) resp. human-human (HH)
corpus
Table 6: The 10 most frequent frames in the HM
</tableCaption>
<table confidence="0.983976826086957">
corpus (* =newly introduced)
HM corpus
Frame count freq-%
HM HH
Total number of turns 662 1,997
Mean dialog length (turns) 13.2 39.9
Mean turn length (tokens) 11.4 10.8
Corrected turns (%) 50 39
Total number of annotations 923 1951
Mean number of frame annota- 18.5 39.0
tions per dialog
Mean number of frame elements 1.6 1.7
per frame annotation
Greeting* 146 15.8
Telling 134 14.5
Recording 83 8.9
Being named 74 8.0
Contacting 52 5.6
Usefulness 50 5.4
Being operational 28 3.0
Problem description* 24 2.6
Inspecting 24 2.6
Perception experience 21 2.3
</table>
<bodyText confidence="0.998899742857143">
evant to model the general semantics of the di-
alogs we are approaching. The most frequent
frame group comprises frames relating to infor-
mation exchange that is typical of the help-desk
activity, including Telling, Greeting, Contacting,
Statement, Recording, Communication. Another
relevant group encompasses frames related to the
operational state of a device, for example Be-
ing operational, Change operational state, Oper-
ational testing, Being in operation.
The two groups also show high variability of
lexical units. Telling, Change operational state
and Greeting have the richest lexical unit set,
with 11 verbs/nouns/adjectives each. Arriving
and Awareness are expressed by 10 different lexi-
cal units, while Statement, Being operational, Re-
moving and Undergo change of operational state
have 9 different lexical units each. The informal
nature of the spoken dialogs influences the com-
position of the lexical unit sets. In fact, they are
rich in verbs and multiwords used only in collo-
quial contexts, for which there are generally few
attestations in the English FrameNet database.
Similarly to the dialog act statistics, we also
analyzed the most frequent frame bigrams and
trigrams in HM and HH dialogs. Results are
reported in Tables 8 and 9. Both HH bigrams
and trigrams show a more sparse distribution and
lower relative frequency than HM ones, implying
that HH dialogs follow a more flexible structure
with a richer set of topics, thus the sequence of
themes is less predictable. In particular, 79%
of HH bigrams and 97% of HH trigrams occur
only once (vs. 68% HM bigrams and 82% HM
trigrams). On the contrary, HM dialogs deal with
</bodyText>
<tableCaption confidence="0.943314">
Table 7: The 10 most frequent frames in the HH
corpus (* =newly introduced)
</tableCaption>
<table confidence="0.986770916666667">
HH corpus
Frame count freq-%
Telling 143 7.3
Greeting* 124 6.3
Awareness 74 3.8
Contacting 63 3.2
Giving 62 3.2
Navigation* 61 3.1
Change operational state 51 2.6
Perception experience 46 2.3
Insert data* 46 2.3
Come to sight* 38 1.9
</table>
<bodyText confidence="0.9795815">
a fix sequence of topics driven by the turns uttered
by the WOZ. For instance, the most frequent
HM bigram and trigram both correspond to the
opening utterance of the WOZ:
Help desk buongiornoGREETING, sonoBEING NAMED
Paola, in cosa posso esserti utileUSEFULNESS?
(Good morning, help-desk service, Paola speaking, how can
I help you?)
</bodyText>
<subsectionHeader confidence="0.8261445">
3.3 Mutual information between PAS and
dialog acts
</subsectionHeader>
<bodyText confidence="0.999194285714286">
A unique feature of our corpus is the availabil-
ity of both a semantic and a dialog act annota-
tion level: it is intuitive to seek relationships in
the purpose of improving the recognition and un-
derstanding of each level by using features from
the other. We considered a subset of 20 HH and
50 HM dialogs and computed an initial analysis
</bodyText>
<page confidence="0.999531">
39
</page>
<tableCaption confidence="0.999648">
Table 8: The 5 most frequent frame bigrams
</tableCaption>
<table confidence="0.999972416666667">
human-machine (HM) freq-%
Greeting Being named 17.1
Being named Usefulness 15.3
Telling Recording 12.9
Recording Contacting 10.9
Contacting Greeting 10.6
human-human (HH) freq-%
Greeting Greeting 4.7
Navigation Navigation 1.2
Telling Telling 1.0
Change op. state Change op. state 0.9
Telling Problem description 0.8
</table>
<tableCaption confidence="0.998992">
Table 9: The 5 most frequent frame trigrams
</tableCaption>
<table confidence="0.999730916666667">
human-machine (HM) freq-%
Greeting Being named Usefulness 9.5
Recording Contacting Greeting 5.7
Being named Usefulness Greeting 3.7
Telling Recording Contacting 3.5
Telling Recording Recording 2.2
human-human (HH) freq-%
Greeting Greeting Greeting 1.6
Greeting Being named Greeting 0.5
Contacting Greeting Greeting 0.3
Navigation Navigation Navigation 0.2
Working on Greeting Greeting 0.2
</table>
<bodyText confidence="0.999853777777778">
of the co-occurrences of dialog acts and PAS. We
noted that each PAS tended to co-occur only with a
limited subset of the available dialog act tags, and
moreover in most cases the co-occurrence hap-
pened with only one dialog act. For a more thor-
ough analysis, we computed the weighted condi-
tional entropy between PAS and dialog acts, which
yields a direct estimate of the mutual information
between the two levels of annotation2.
</bodyText>
<footnote confidence="0.72174">
2Let H(yj|xi) be the weighted conditional entropy of ob-
servation yj of variable Y given observation xi of variable
</footnote>
<equation confidence="0.819746666666667">
X:
H(yj|xi) = −p(xi; yj)logp(xi; yj)
p(xi) ,
</equation>
<bodyText confidence="0.9999106">
where p(xi; yj) is the probability of co-occurrence of xi and
yj, and p(xi) and p(yj) are the marginal probabilities of oc-
currence of xi resp. yj in the corpus. There is an obvious re-
lation with the weighted mutual information between xi and
yj, defined following e.g. (Bechet et al., 2004) as:
</bodyText>
<figure confidence="0.6618105">
wMI(xi; yj) = p(xi; yj)log p(xi; yj)
p(xi)p(yj).
(a) human-machine dialogs (filtering co-occurrences below 3)
(b) human-human dialogs (filtering co-occurrences below 5)
</figure>
<figureCaption confidence="0.81522975">
Figure 3: Weighted conditional entropy between
PAS and dialog acts in the HM (a) and HH corpus
(b). To lower entropies correspond higher values
of mutual information (darker color in the scale)
</figureCaption>
<bodyText confidence="0.999628444444445">
Our results are illustrated in Figure 3. In the
HM corpus (Fig. 3(a)), we noted some interesting
associations between dialog acts and PAS. First,
info-req has the maximal MI with PAS like Be-
ing in operation and Being attached, as requests
are typically used by the operator to get informa-
tion about the status of device. Several PAS de-
note a high MI with the info dialog act, includ-
ing Activity resume, Information, Being named,
Contacting, and Resolve problem. Contacting
refers to the description of the situation and of the
speaker’s point of view (usually the caller). Be-
ing named is primarily employed when the caller
introduces himself, while Activity resume usually
refers to the operator’s description of the sched-
Indeed, the higher is H(yj|xi), the lower is wMI(xi; yj).
We approximate all probabilities using frequency of occur-
rence.
</bodyText>
<page confidence="0.994397">
40
</page>
<bodyText confidence="0.99943675">
uled interventions.
As for the remaining acts, clarif has the high-
est MI with Perception experience and Statement,
used to warn the addressee about understanding
problems and asking him to repeat/rephrase an ut-
terance, respectively. The two strategies can be
combined in the same utterance, as in the utter-
ance: Non ho sentito bene: per favore ripeti cer-
cando di parlare pi`u forte. (I haven’t quite heard
that, please repeat trying to speak up.).
The answer tag is highly informative with Suc-
cessful action, Change operational state, Becom-
ing nonfunctional, Being detached, Read data.
These PAS refer to the exchange of infor-
mation (Read data) or to actions performed
by the user after a suggestion of the system
(Change operational state). Action requests (act-
req) seem to be correlated to Replacing as it usu-
ally occurs when the operator requests the caller
to carry out an action to solve a problem, typically
to replace a component with another. Another fre-
quent request may refer to some device that the
operator has to test.
In the HH corpus (Fig. 3(b)), most of the PAS
are highly mutually informative with info: in-
deed, as shown in Table 3, this is the most fre-
quently occurring act in HH except for ack, which
rarely contain verbs that can be annotated by a
frame. As for the remaining acts, there is an easily
explainable high MI between quit and Greeting;
moreover, info-req denote its highest MI with
Giving, as in requests to give information, while
rep-action denotes a strong co-occurrence with
Inchoative attaching: indeed, interlocutors often
report on the action of connecting a device.
These results corroborate our initial observation
that for most PAS, the mutual information tends
to be very high in correspondence of one dialog
act type: this suggests the beneficial effect of in-
cluding shallow semantic information as features
for dialog act classification. The converse is less
clear as the same dialog act can relate to a span
of words covered by multiple PAS and generally,
several PAS co-occur with the same dialog act.
</bodyText>
<sectionHeader confidence="0.999843" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999595285714286">
In this paper we have proposed an approach to
the annotation of spoken dialogs using seman-
tic and discourse features. Such effort is crucial
to investigate the complex dependencies between
the layers of semantic processing. We have de-
signed the annotation model to incorporate fea-
tures and models developed both in the speech
and language research community and bridging
the gap between the two communities. Our multi-
layer annotation corpus allows the investigation
of cross-layer dependencies and across human-
machine and human-human dialogs as well as
training of semantic models which accounts for
predicate interpretation.
</bodyText>
<sectionHeader confidence="0.999193" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999217">
C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998.
The Berkeley FrameNet Project. In Proceedings of
ACL/Coling’98, pages 86–90.
F. Bechet, G. Riccardi, and D. Hakkani-Tur. 2004.
Mining spoken dialogue corpora for system evalu-
ation and modeling. In Proceedings of EMNLP’04,
pages 134–141.
H. Bunt. 2005. A framework for dialogue act specica-
tion. In Proceedings of SIGSEM WG on Represen-
tation of Multimodal Semantic Information.
A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pad´o,
and M. Pinkal. 2006. Salto - a versatile multi-
level annotation tool. In Proceedings of LREC 2006,
pages 517–520, Genoa, Italy.
A. Corazza, A. Lavelli, and G. Satta. 2007. Anal-
isi sintattica-statistica basata su costituenti. Intelli-
genza Artificiale, 4(2):38–39.
M. G. Core and J. F. Allen. 1997. Coding dialogs
with the DAMSL annotation scheme. In Proceed-
ings of the AAAI Fall Symposium on Communicative
Actions in Humans and Machines.
R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear,
G. Riccardi, and G. Tur. 2008. Spoken language
understanding: A survey. IEEE Signal Processing
magazine, 25(3):50–58.
G. Leech and A. Wilson. 2006. EAGLES recommen-
dations for the morphosyntactic annotation of cor-
pora. Technical report, ILC-CNR.
C. M¨uller and M. Strube. 2003. Multi-level annotation
in MMAX. In Proceedings of SIGDIAL’03.
J. M. Sinclair and R. M. Coulthard. 1975. Towards an
Analysis of Discourse: The English Used by Teach-
ers and Pupils. Oxford University Press, Oxford.
D. Traum. 1996. Conversational agency: The
TRAINS-93 dialogue manager. In Proceedings of
TWLT 11: Dialogue Management in Natural Lan-
guage Systems, pages 1–11, June.
S. Varges, G. Riccardi, and S. Quarteroni. 2008. Per-
sistent information state in a data-centric architec-
ture. In Proceedings of SIGDIAL’08.
</reference>
<page confidence="0.999447">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.726366">
<title confidence="0.918991">Annotating Spoken Dialogs: from Speech Segments to Dialog Acts Frame Semantics</title>
<author confidence="0.781671">Silvia Quarteroni Dinarelli</author>
<author confidence="0.781671">Sara Tonelli</author>
<author confidence="0.781671">Alessandro Moschitti</author>
<author confidence="0.781671">Giuseppe</author>
<affiliation confidence="0.999869">University of Trento</affiliation>
<address confidence="0.999772">38050 Povo - Trento, Italy</address>
<email confidence="0.998353">satonelli@fbk.eu</email>
<abstract confidence="0.999593275862069">We are interested in extracting semantic structures from spoken utterances generated within conversational systems. Current Spoken Language Understanding systems rely either on hand-written semantic grammars or on flat attribute-value sequence labeling. While the former approach is known to be limited in coverage and robustness, the latter lacks detailed relations amongst attribute-value pairs. In this paper, we describe and analyze the human annotation process of rich semantic structures in order to train semantic statistical parsers. We have annotated spoken conversations from both a human-machine and a human-human spoken dialog corpus. Given a sentence of the transcribed corpora, domain concepts and other linguistic features are annotated, ranging from e.g. part-of-speech tagging and constituent chunking, to more advanced annotations, such as syntactic, dialog act and predicate argument structure. In particular, the two latter annotation layers appear to be promising for the design of complex dialog systems. Statistics and mutual information estimates amongst such features are reported and compared across corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C F Baker</author>
<author>C J Fillmore</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL/Coling’98,</booktitle>
<pages>86--90</pages>
<contexts>
<context position="5379" citStr="Baker et al., 1998" startWordPosition="811" endWordPosition="814">tion levels of words, turns1, attribute-value pairs, dialog acts, predicate argument structures. The annotation at word level is made with part-of-speech and morphosyntactic information following the recommendations of EAGLES corpora annotation (Leech and Wilson, 2006). The attribute-value annotation uses a predefined domain ontology to specify concepts and their relations. Dialog acts are used to annotate intention in an utterance and can be useful to find relations between different utterances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain concepts in the utterance, and a domainindependent dialog act scheme can be applied. For our corpus, we used a dialog act taxonomy which follows initiatives such as DAMSL (Core and Allen, 1997), TRAINS (Traum, 1996) and DIT++ (Bunt, 2005). Although the level of granularity and coverage varies across such taxonomies, a careful analysis leads to identif</context>
<context position="9908" citStr="Baker et al., 1998" startWordPosition="1511" endWordPosition="1514">the tag corresponding to its main function; 3. in case of doubt among several tags, give priority to tags in core dialog acts group; 4. when needed, split the turn into several utterances or merge several turns into one utterance. Utterance segmentation provides the basis not only for dialog act labeling but also for the other semantic annotations. See Fig. 1 for a dialog sample where each line represents an utterance annotated according to the three levels. 2.2 Predicate Argument annotation We carried out predicate argument structure annotation applying the FrameNet paradigm as described in (Baker et al., 1998). This model comprises a set of prototypical situations called frames, the frame-evoking words or expressions called lexical units and the roles or participants involved in these situations, called frame elements. The latter are typically the syntactic dependents of the lexical units. All lexical units belonging to the same frame have similar semantics and show PERSON-NAME Info: Buongiorno, sono Paola. GREETING B._NAMED Name Good morning, this is Paola. Info-req: Come la posso aiutare? Benefitted_party ASSISTANCE How may I help you? CONCEPT HARDWARE-COMPONENT Info: Buongiorno. Ho un problema c</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of ACL/Coling’98, pages 86–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bechet</author>
<author>G Riccardi</author>
<author>D Hakkani-Tur</author>
</authors>
<title>Mining spoken dialogue corpora for system evaluation and modeling.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP’04,</booktitle>
<pages>134--141</pages>
<contexts>
<context position="2305" citStr="Bechet et al., 2004" startWordPosition="342" endWordPosition="345">ls of SLU are based on the identification of slots (enPhis work was partially funded by the European Commission projects LUNA (contract 33549) and ADAMACH (contract 022593). tities) within one or more frames (frame-slot semantics) that is defined by the application. While this model is simple and clearly insufficient to cope with interpretation and reasoning, it has supported the first generation of spoken dialog systems. Such dialog systems are thus limited by the ability to parse semantic features such as predicates and to perform logical computation in the context of a specific dialog act (Bechet et al., 2004). This limitation is reflected in the type of human-machine interactions which are mostly directed at querying the user for specific slots (e.g. “What is the departure city?”) or implementing simple dialog acts (e.g. confirmation). We believe that an important step in overcoming such limitation relies on the study of models of human-human dialogs at different levels of representation: lexical, syntactic, semantic and discourse. In this paper, we present our results in addressing the above issues in the context of the LUNA research project for next-generation spoken dialog interfaces (De Mori e</context>
<context position="24173" citStr="Bechet et al., 2004" startWordPosition="3822" endWordPosition="3825">we computed the weighted conditional entropy between PAS and dialog acts, which yields a direct estimate of the mutual information between the two levels of annotation2. 2Let H(yj|xi) be the weighted conditional entropy of observation yj of variable Y given observation xi of variable X: H(yj|xi) = −p(xi; yj)logp(xi; yj) p(xi) , where p(xi; yj) is the probability of co-occurrence of xi and yj, and p(xi) and p(yj) are the marginal probabilities of occurrence of xi resp. yj in the corpus. There is an obvious relation with the weighted mutual information between xi and yj, defined following e.g. (Bechet et al., 2004) as: wMI(xi; yj) = p(xi; yj)log p(xi; yj) p(xi)p(yj). (a) human-machine dialogs (filtering co-occurrences below 3) (b) human-human dialogs (filtering co-occurrences below 5) Figure 3: Weighted conditional entropy between PAS and dialog acts in the HM (a) and HH corpus (b). To lower entropies correspond higher values of mutual information (darker color in the scale) Our results are illustrated in Figure 3. In the HM corpus (Fig. 3(a)), we noted some interesting associations between dialog acts and PAS. First, info-req has the maximal MI with PAS like Being in operation and Being attached, as re</context>
</contexts>
<marker>Bechet, Riccardi, Hakkani-Tur, 2004</marker>
<rawString>F. Bechet, G. Riccardi, and D. Hakkani-Tur. 2004. Mining spoken dialogue corpora for system evaluation and modeling. In Proceedings of EMNLP’04, pages 134–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>A framework for dialogue act specication.</title>
<date>2005</date>
<booktitle>In Proceedings of SIGSEM WG on Representation of Multimodal Semantic Information.</booktitle>
<contexts>
<context position="5864" citStr="Bunt, 2005" startWordPosition="893" endWordPosition="894">erances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain concepts in the utterance, and a domainindependent dialog act scheme can be applied. For our corpus, we used a dialog act taxonomy which follows initiatives such as DAMSL (Core and Allen, 1997), TRAINS (Traum, 1996) and DIT++ (Bunt, 2005). Although the level of granularity and coverage varies across such taxonomies, a careful analysis leads to identifying three main groups of dialog acts: 1. Core acts, which represent the fundamental actions performed in the dialog, e.g. re1A turn is defined as the interval when a speaker is active, between two pauses in his/her speech flow. questing and providing information, or executing a task. These include initiatives (often called forward-looking acts) and responses (backward-looking acts); 2. Conventional/Discourse management acts, which maintain dialog cohesion and delimit specific pha</context>
</contexts>
<marker>Bunt, 2005</marker>
<rawString>H. Bunt. 2005. A framework for dialogue act specication. In Proceedings of SIGSEM WG on Representation of Multimodal Semantic Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Burchardt</author>
<author>K Erk</author>
<author>A Frank</author>
<author>A Kowalski</author>
<author>S Pad´o</author>
<author>M Pinkal</author>
</authors>
<title>Salto - a versatile multilevel annotation tool.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<pages>517--520</pages>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pad´o, and M. Pinkal. 2006. Salto - a versatile multilevel annotation tool. In Proceedings of LREC 2006, pages 517–520, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Corazza</author>
<author>A Lavelli</author>
<author>G Satta</author>
</authors>
<title>Analisi sintattica-statistica basata su costituenti.</title>
<date>2007</date>
<journal>Intelligenza Artificiale,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="13133" citStr="Corazza et al., 2007" startWordPosition="2015" endWordPosition="2018">iously defined task-solving strategy that does not allow for digressions. Utterance segmentation was also performed differently on the two corpora. In HH we performed 167 turn mergings and 225 turn splittings; in HM dialogs, only turn splittings (158) but no turn mergings were performed. Tables 2 and 3 report the dialog acts occurring in the HM and HH corpora, respectively, ranked by their frequencies. attribute-value and DA annotation are carried out on the segmented dialogs at utterance level, PAS annotation requires POS-tagging and syntactic parsing (via Bikel’s parser trained for Italian (Corazza et al., 2007)). Finally, a shallow manual correction is carried out to make sure that the tree nodes that may carry semantic information have correct constituent boundaries. For the annotation of frame information, we used the Salto tool (Burchardt et al., 2006), that stores the dialog file in TIGER-XML format and allows to easily introduce word tags and frame flags. Frame information is recorded on top of parse trees, with target information pointing to terminal words and frame elements pointing to tree nodes. 3 Quantitative comparison of the Annotation We evaluated the outcome of dialog act and PAS annot</context>
</contexts>
<marker>Corazza, Lavelli, Satta, 2007</marker>
<rawString>A. Corazza, A. Lavelli, and G. Satta. 2007. Analisi sintattica-statistica basata su costituenti. Intelligenza Artificiale, 4(2):38–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Core</author>
<author>J F Allen</author>
</authors>
<title>Coding dialogs with the DAMSL annotation scheme.</title>
<date>1997</date>
<booktitle>In Proceedings of the AAAI Fall Symposium on Communicative Actions in Humans and Machines.</booktitle>
<contexts>
<context position="5819" citStr="Core and Allen, 1997" startWordPosition="884" endWordPosition="887">d can be useful to find relations between different utterances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain concepts in the utterance, and a domainindependent dialog act scheme can be applied. For our corpus, we used a dialog act taxonomy which follows initiatives such as DAMSL (Core and Allen, 1997), TRAINS (Traum, 1996) and DIT++ (Bunt, 2005). Although the level of granularity and coverage varies across such taxonomies, a careful analysis leads to identifying three main groups of dialog acts: 1. Core acts, which represent the fundamental actions performed in the dialog, e.g. re1A turn is defined as the interval when a speaker is active, between two pauses in his/her speech flow. questing and providing information, or executing a task. These include initiatives (often called forward-looking acts) and responses (backward-looking acts); 2. Conventional/Discourse management acts, which main</context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>M. G. Core and J. F. Allen. 1997. Coding dialogs with the DAMSL annotation scheme. In Proceedings of the AAAI Fall Symposium on Communicative Actions in Humans and Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R De Mori</author>
<author>F Bechet</author>
<author>D Hakkani-Tur</author>
<author>M McTear</author>
<author>G Riccardi</author>
<author>G Tur</author>
</authors>
<title>Spoken language understanding: A survey.</title>
<date>2008</date>
<booktitle>IEEE Signal Processing magazine,</booktitle>
<pages>25--3</pages>
<marker>De Mori, Bechet, Hakkani-Tur, McTear, Riccardi, Tur, 2008</marker>
<rawString>R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear, G. Riccardi, and G. Tur. 2008. Spoken language understanding: A survey. IEEE Signal Processing magazine, 25(3):50–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
<author>A Wilson</author>
</authors>
<title>EAGLES recommendations for the morphosyntactic annotation of corpora.</title>
<date>2006</date>
<tech>Technical report, ILC-CNR.</tech>
<contexts>
<context position="5029" citStr="Leech and Wilson, 2006" startWordPosition="755" endWordPosition="758"> of Oz approach (WOZ). The human agent (wizard) reacts to user’s spontaneous spoken requests following one of ten possible dialog scenarios inspired by the services provided by the company. The above data is organized in transcriptions and annotations of speech based on a new multi-level protocol studied specifically within the project, i.e. the annotation levels of words, turns1, attribute-value pairs, dialog acts, predicate argument structures. The annotation at word level is made with part-of-speech and morphosyntactic information following the recommendations of EAGLES corpora annotation (Leech and Wilson, 2006). The attribute-value annotation uses a predefined domain ontology to specify concepts and their relations. Dialog acts are used to annotate intention in an utterance and can be useful to find relations between different utterances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain con</context>
</contexts>
<marker>Leech, Wilson, 2006</marker>
<rawString>G. Leech and A. Wilson. 2006. EAGLES recommendations for the morphosyntactic annotation of corpora. Technical report, ILC-CNR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M¨uller</author>
<author>M Strube</author>
</authors>
<title>Multi-level annotation in MMAX.</title>
<date>2003</date>
<booktitle>In Proceedings of SIGDIAL’03.</booktitle>
<marker>M¨uller, Strube, 2003</marker>
<rawString>C. M¨uller and M. Strube. 2003. Multi-level annotation in MMAX. In Proceedings of SIGDIAL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Sinclair</author>
<author>R M Coulthard</author>
</authors>
<title>Towards an Analysis of Discourse: The English Used by Teachers and Pupils.</title>
<date>1975</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="5546" citStr="Sinclair and Coulthard, 1975" startWordPosition="838" endWordPosition="841"> morphosyntactic information following the recommendations of EAGLES corpora annotation (Leech and Wilson, 2006). The attribute-value annotation uses a predefined domain ontology to specify concepts and their relations. Dialog acts are used to annotate intention in an utterance and can be useful to find relations between different utterances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain concepts in the utterance, and a domainindependent dialog act scheme can be applied. For our corpus, we used a dialog act taxonomy which follows initiatives such as DAMSL (Core and Allen, 1997), TRAINS (Traum, 1996) and DIT++ (Bunt, 2005). Although the level of granularity and coverage varies across such taxonomies, a careful analysis leads to identifying three main groups of dialog acts: 1. Core acts, which represent the fundamental actions performed in the dialog, e.g. re1A turn is defined as the interval when a </context>
</contexts>
<marker>Sinclair, Coulthard, 1975</marker>
<rawString>J. M. Sinclair and R. M. Coulthard. 1975. Towards an Analysis of Discourse: The English Used by Teachers and Pupils. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Conversational agency: The TRAINS-93 dialogue manager.</title>
<date>1996</date>
<booktitle>In Proceedings of TWLT 11: Dialogue Management in Natural Language Systems,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="5841" citStr="Traum, 1996" startWordPosition="889" endWordPosition="890">ns between different utterances as the next section will show. For predicate structure annotation, we followed the FrameNet model (Baker et al., 1998) (see Section 2.2). 2.1 Dialog Act annotation Dialog act annotation is the task of identifying the function or goal of a given utterance (Sinclair and Coulthard, 1975): thus, it provides a complementary information to the identification of domain concepts in the utterance, and a domainindependent dialog act scheme can be applied. For our corpus, we used a dialog act taxonomy which follows initiatives such as DAMSL (Core and Allen, 1997), TRAINS (Traum, 1996) and DIT++ (Bunt, 2005). Although the level of granularity and coverage varies across such taxonomies, a careful analysis leads to identifying three main groups of dialog acts: 1. Core acts, which represent the fundamental actions performed in the dialog, e.g. re1A turn is defined as the interval when a speaker is active, between two pauses in his/her speech flow. questing and providing information, or executing a task. These include initiatives (often called forward-looking acts) and responses (backward-looking acts); 2. Conventional/Discourse management acts, which maintain dialog cohesion a</context>
</contexts>
<marker>Traum, 1996</marker>
<rawString>D. Traum. 1996. Conversational agency: The TRAINS-93 dialogue manager. In Proceedings of TWLT 11: Dialogue Management in Natural Language Systems, pages 1–11, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Varges</author>
<author>G Riccardi</author>
<author>S Quarteroni</author>
</authors>
<title>Persistent information state in a data-centric architecture.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGDIAL’08.</booktitle>
<contexts>
<context position="8453" citStr="Varges et al., 2008" startWordPosition="1272" endWordPosition="1275">erances It can be noted that we have decided to retain only the most frequent dialog act types from the schemes that inspired our work. Rather than aspiring to the full discriminative power of possible conversational situations, we have opted for a simple taxonomy that would cover the vast majority 35 of utterances and at the same time would be able to generalize them. Its small number of classes is meant to allow a supervised classification method to achieve reasonable performance with limited data. The taxonomy is currently used by the statistical Dialogue Manager in the ADAMACH EU project (Varges et al., 2008); the limited number of classes allows to reduce the number of hypothesized current dialogue acts, thus reducing the dialogue state space. Dialog act annotation was performed manually by a linguist on speech transcriptions previously segmented into turns as mentioned above. The annotation unit for dialog acts, is the utterance; however, utterances are complex semantic entities that do not necessarily correspond to turns. Hence, a segmentation of the dialog transcription into utterances was performed by the annotator before dialog act labeling. Both utterance segmentation and dialog act labelin</context>
</contexts>
<marker>Varges, Riccardi, Quarteroni, 2008</marker>
<rawString>S. Varges, G. Riccardi, and S. Quarteroni. 2008. Persistent information state in a data-centric architecture. In Proceedings of SIGDIAL’08.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>