<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002027">
<title confidence="0.98427">
Cryptic Crossword Clues: Generating Text with a Hidden Meaning
</title>
<author confidence="0.995345">
David Hardcastle
</author>
<affiliation confidence="0.993501">
Open University, Milton Keynes, MK7 6AA
Birkbeck, University of London, London, WC1E 7HX
</affiliation>
<email confidence="0.9935085">
d.w.hardcastle@open.ac.uk
ahard04@dcs.bbk.ac.uk
</email>
<sectionHeader confidence="0.993792" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989545454546">
This paper discusses the generation of
cryptic crossword clues: a task that in-
volves generating texts that have both a
surface reading, based on a natural lan-
guage interpretation of the words, and a
hidden meaning in which the strings that
form the text can be interpreted as a puzzle.
The process of clue generation realizes a
representation of the hidden, puzzle mean-
ing of the clue through the aggregation of
chunks of text. As these chunks are com-
bined, syntactic and semantic selectional
constraints are explored, and through this
language understanding task a meaningful
surface reading is recovered. This hybrid
language generation/language understand-
ing process transforms a representation of
the clue as a word puzzle into a representa-
tion of some meaningful assertion in the
domain of the real world, mediated through
the generated multi-layered text; a text
which has two separate readings.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982708333334">
This paper discusses a system called ENIGMA
which generates cryptic crossword clues: frag-
ments of text that also have a hidden meaning,
quite different from the surface reading. This
raises an interesting research question: how to gen-
erate text that has multiple layers of meaning based
on different syntactic rules and different semantic
interpretations. The input to the realizer is a pro-
duction of a high-level cryptic clue grammar
whose terminals are the strings that participate in
the puzzle presented by the clue. These conceptu-
alizations of possible crossword clues contain no
implicit syntactic or semantic information, and so a
mechanism is required to ensure that the resulting
surface text is syntactically correct and semanti-
cally appropriate while the meaning of the text,
derived directly from the input, is not disturbed
during lexicalization. As with computational hu-
mour and poetry generation the process of genera-
tion is unusual in that the content is not specified in
the input (Ritchie, 2001; Manurung, 2000), and
this leads to tractability problems when consider-
ing the wide range of lexicalization options (see
also Ritchie, 2005: 4) requiring a bespoke solution.
</bodyText>
<subsectionHeader confidence="0.998655">
1.1 Cryptic Crossword Clues
</subsectionHeader>
<bodyText confidence="0.999013772727273">
The cryptic crossword clues generated by ENIGMA
consist of two separate indications of the solution
word, one of which is a definition, the other a puz-
zle based on its orthography. Consider, for exam-
ple, the following simple clue for noiseless:
Still wild lionesses (9)
Here noiseless is represented both by the synonym
still (the definition) and a wordplay puzzle (an
anagram of lionesses) indicated by the convention
keyword wild. All of the clues generated by the
system conform to Ximenean conventions
(Macnutt, 1966), a set of guidelines that impose
restrictions on inflection and word order to ensure
that clues are ‘fair’ and also encourage the use of
homographs and convention vocabulary to make
them cryptic in nature.
It is important to note here that there are two
separate readings of this clue: a surface reading in
which the clue is also a fragment of English text,
and the puzzle reading required to solve the clue.
In the surface reading the word still is an adverb
qualifying the adjective wild, while in the puzzle
</bodyText>
<page confidence="0.997207">
147
</page>
<bodyText confidence="0.999312846153846">
reading it is an adjective that is a synonym for
noiseless.
There are many different types of crossword
clue wordplay, including anagrams, homophones,
writing words backwards, appending words to-
gether, and more besides. ENIGMA generates clues
using seven of the eight main types listed in
(Macnutt, 1966) and can also generate complex
clues with subsidiary puzzles. This coverage com-
bined with the richness of lexical choice in cryptic
crossword convention vocabulary means that it is
not uncommon for ENIGMA to generate several
hundred valid clues for a single input word.
</bodyText>
<subsectionHeader confidence="0.605574">
1.2 Requirements for Generation
</subsectionHeader>
<bodyText confidence="0.999914052631579">
Given a particular solution word, such as noiseless,
the first step for the system is to determine the dif-
ferent ways in which the letters of the solution
could be presented as a puzzle. For example, the
basis of the clue could be that noiseless is an ana-
gram of lionesses, or that it can be formed by run-
ning noise and less together, or that it is composed
of a river (Oise) followed by the letter l all placed
inside the word ness. In its present form ENIGMA
locates 154 such formulations for the input word
noiseless. Each of these formulations can be repre-
sented as a clue tree under ENIGMA’s domain
grammar for cryptic crosswords in which the ter-
minal elements are the strings used to compose the
solution word. The sample clue tree in Figure 1
represents the fact that noiseless can be formed by
running noise and less together, a puzzle type
known as a Charade (Macnutt, 1966; Manley,
2001).
</bodyText>
<figureCaption confidence="0.524485">
Figure 1. A clue tree that represents appending
noise and less to form noiseless.
</figureCaption>
<bodyText confidence="0.999978857142857">
These clue trees contain no linguistic information -
the terminals should be thought of as strings not as
words. To lexicalize this data the system must con-
struct a fragment of natural language that can be
reinterpreted - through the resolution of homo-
graphs and a knowledge of special conventions - as
a valid cryptic clue puzzle based on this non-
linguistic structure. Along the way the syntax and
semantics of the puzzle reading must not be dis-
turbed or the clue will lose its hidden meaning. At
the same time, the natural language syntactic and
semantic information that is missing from the input
data must be imposed on the clue so that a valid
surface reading is achieved.
</bodyText>
<sectionHeader confidence="0.536553" genericHeader="method">
2 Chunk by Chunk Generation
</sectionHeader>
<bodyText confidence="0.999966238095238">
A complete clue does not need to be a sentence, or
even a clause, it can be any valid fragment of text,
and ENIGMA takes advantage of this fact to sim-
plify the generation algorithm. The clue tree shown
in Figure 1 is realized through a process of compo-
sition. First the symbol labeled A is realized. Next
B1 and B2 are realized individually and then com-
bined to form B. Now, A and B can themselves be
combined to form the clue. Each realization is a
fragment of text, and I refer to each of these frag-
ments as a chunk, although I note that they are
rather different from chunks based on major heads
(Abney, 1989), for the reasons set out below. To
implement this process the system needs to be able
to do two things: create chunks for each terminal in
the clue tree, and merge chunks into successively
larger ones until the root of the tree is reached.
This recursive process enables ENIGMA to con-
struct complex clues with subsidiary puzzles using
the same implementation it uses for simple puz-
zles.
</bodyText>
<subsectionHeader confidence="0.995961">
2.1 Word Order
</subsectionHeader>
<bodyText confidence="0.9999685">
When chunks are combined together they cannot
interleave or nest. The reason for this is that each
chunk represents a part of the hidden meaning of
the clue, and word order is central to its interpreta-
tion. This is why ENIGMA uses a flat structure
rather than a tree structure to build up the clue.
</bodyText>
<sectionHeader confidence="0.999116" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.998557333333333">
Each chunk can attach to another chunk to its left,
to its right, or via an intermediary word or phrase,
such as a conjunction, something I call ‘upward
</bodyText>
<page confidence="0.99283">
148
</page>
<bodyText confidence="0.99644">
attachment’. The grammar that underpins these
attachments is encoded as a set of three extension
points1 to each chunk: one specifying the relation-
ships that can occur to the left, another those that
can occur to the right, and the third specifying up-
ward attachments. For example the chunk wild li-
onesses has, amongst many others, an extension
point to the left indicating that it can attach as di-
rect object to a verb, one to the right indicating that
it can attach to a verb as subject and an upward
attachment through which it can attach via a coor-
dinating conjunction to another noun.
In addition to specifying the relationship and
target type each extension point also specifies an
erasure2 for the chunk to which it belongs - this
erasure indicates a word in the chunk that can
stand in for the chunk as a whole when determin-
ing attachment. It is important to note that the era-
sure is not equivalent to the syntactic head and that
different extension points on the same chunk may
have different erasures. For example, in addition to
looking for a verb to the left, the chunk wild lion-
esses also has an extension point looking for an
adverb to the left, since an adverb could qualify the
adjective wild. Therefore, the extension point look-
ing for a verb erases wild lionesses to lionesses, so
that a verb chunk looking for a noun to its right as
direct object will accept it, whereas the extension
point looking for an adverb erases this same chunk
to wild, so that an adverb looking to its right for an
adjective to qualify could also accept it. In this way
the concept of erasure makes it possible for a wider
variety of syntactic dependencies to be encoded in
the same way on a single chunk, enabling poly-
morphic behaviour.
In some respects the extension points and asso-
ciated erasures encoded onto each chunk act like
the categories on functors in Combinatory Cate-
gorial Grammar (Clark et al, 2002), or edges on the
agenda used in chart generation (Kay, 1996) as
they specify the type and directionality of the ar-
guments available and the type of the result. How-
1 The term extension point is more commonly used to
define the interfaces to plug-in components in extensi-
ble computer systems.
2 In Object-Oriented Programming an erasure is a sim-
plification or genericisation of a type through some in-
terface, see for example (Bracha et al, 2001).
ever, in addition to this syntactic information the
grammar also provides the mechanism through
which semantic selectional constraints are en-
forced. The erasures do not just specify a type
(such as noun or adjective) but also a member of
the chunk: wild or lionesses in this case. This en-
ables the erasures to be used to determine which
semantic checks are required to validate the at-
tachment, adding to ENIGMA’s implementation of
chunks the semantic constraints that Abney notes
as missing from his formulation (1989: 15). For
example, if the chunk wild lionesses attaches to a
chunk to its left that erases to a verb and is looking
for a direct object then the extension point govern-
ing this attachment enforces syntactic correctness,
but this is not enough. Since the clue tree only con-
tains information about crossword conventions a
separate semantic check is now required to ensure
that it makes sense for the verb to take the noun
lionesses as its direct object, and this semantic
check will be performed using the relation and the
erasures as arguments.
So, for example, when the chunk still is com-
bined to the left of wild lionesses the system per-
forms a semantic check to ensure that still can
qualify wild. If the verb calm (an alternative
homograph of a synonym for noiseless) is attached
to the left then the system checks that lionesses can
be the direct object of calm, and so on.
</bodyText>
<sectionHeader confidence="0.925773" genericHeader="method">
4 Sample output
</sectionHeader>
<bodyText confidence="0.9922528">
Figure 2 depicts system output from ENIGMA rep-
resenting the sample clue given in the introduction.
Since so many clues are generated the system also
generates a list of justifications which it uses to
determine a score and rank the clues. The output
shown in Figure 2 only includes information that
relates to this paper; the full listing also contains
information about the structure of the clue and the
difficulty of the clue as a word puzzle. All of the
explanatory text is generated using templates.
</bodyText>
<footnote confidence="0.531540555555556">
Clue for [noiseless]
Clue [Still wild lionesses (9)]
POS [still/AV0 wild/AJ0 lionesses/NN2]
Homograph pun: to solve the clue &apos;still&apos;
must be read as Adjective but has surface
reading Adverb
Sense: dependency fit &apos;wild lionesses&apos; of
type Adjective Modifier characterized as
&apos;inferred&apos;
</footnote>
<page confidence="0.988683">
149
</page>
<table confidence="0.970306111111111">
Attachment: &apos;wild lionesses&apos; attached via
type Attributive Adjective Modifier
Sense: &apos;still wild&apos; sense-checked for In-
tensifying Adverb attachment using the
lexicon
Attachment: &apos;still wild&apos; attached via
type Adverbial Qualifier (of Adjective)
Thematic Fit: &apos;wild&apos; and &apos;lionesses&apos;
share common thematic content.
</table>
<figureCaption confidence="0.99197">
Figure 2. Sample output from ENIGMA.
</figureCaption>
<sectionHeader confidence="0.999077" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9998905">
ENIGMA constructs clues using their hidden mean-
ing as the starting point. Lexical choice is very un-
restricted, while word order is quite tightly con-
strained. This leads to combinatorial explosion in
lexical choice, but of the intractably large number
of possible productions for each clue very few also
function as viable fragments of natural language.
ENIGMA’s approach is to work through the struc-
ture of the hidden clue and determine constraints
on the surface reading on the fly. The composi-
tional process reins in the combinatorial explosion
by pushing language constraints down to the most
local level at which they can operate.
ENIGMA uses various generic language under-
standing resources built specifically for the appli-
cation during the generation process to ensure that
the syntactic relationships behind the clue’s surface
reading are semantically supported.
</bodyText>
<listItem confidence="0.541043">
• A Collocational Semantic Lexicon mined
from British National Corpus and augmented
using WordNet determines if a proposed de-
</listItem>
<bodyText confidence="0.9591034">
pendency relation between two words is se-
mantically probable (Hardcastle 2007). This
lexicon is used to impose selectional con-
straints on syntactic dependency relations,
such as between a verb and its direct object.
</bodyText>
<listItem confidence="0.9669814">
• A Word Association Measure based on a dis-
tributional analysis of data in the British Na-
tional Corpus is used to evaluate the thematic
coherence of the clue (Hardcastle 2005).
• A Phrase Dictionary derived from the Moby
</listItem>
<bodyText confidence="0.91723725">
Compound word list3 is used to identify aggre-
gations that result in the creation of multi-word
units such as compound nouns or phrasal
verbs.
</bodyText>
<page confidence="0.51061">
3 http://www.dcs.shef.ac.uk/research/ilash/Moby/.
</page>
<bodyText confidence="0.9999646">
The resulting clue texts are syntactically and
semantically valid under the symbolic language
grammar of the domain, and at the same time are
plausible fragments of natural language. I plan to
perform a mix of qualitative and quantitative
evaluations on a set of generated clues, a reference
set of clues published in newspapers and a set of
control clues generated with no syntactic or seman-
tic constraints, grouped into subsets that share the
same solution word.
</bodyText>
<sectionHeader confidence="0.999185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999776405405405">
S. Abney. (1989). Parsing by Chunks. In The MIT Pars-
ing Volume, edited by C. Tenny. The MIT Press.
G. Bracha, N. Cohen, C. Kemper, S. Mark, M. Odersky,
S.-E. Panitz, D. Stoutamire, K. Thorup, and P.
Wadler. (2001). Adding generics to the Java pro-
gramming language: Participant draft specification.
Technical Report, Sun Microsystems.
S. Clark, J. Hockenmaier, and M. Steedman. (2002).
Building deep dependency structures with a wide-
coverage CCG parser. In Proceedings of the 40th
Meeting of the ACL, pages 327–334.
D. Hardcastle. (2007). Building a Collocational Seman-
tic Lexicon. Technical Report BBKCS-07-02. Birk-
beck, London.
D. Hardcastle. (2005). An examination of word associa-
tion scoring using distributional analysis in the Brit-
ish National Corpus: what is an interesting score and
what is a useful system? In Proceedings of Corpus
Linguistics, Birmingham.
M. Kay. (1996). Chart Generation. In Proceedings of
the 34th Meeting of the ACL, pages 200-204.
D. S. Macnutt. (1966). On the Art of the Crossword.
Swallowtail Books.
D. Manley. (2001). Chambers Crossword Manual.
Chambers.
H. Manurung, G. Ritchie and H. Thompson. (2000).
Towards a Computational Model of Poetry Genera-
tion. In Proceedings of AISB Symposium on Creative
and Cultural Aspects and Applications of AI and
Cognitive Science, pages 79-86.
G. Ritchie. (2001). Current Directions in Computational
Humour. In Artifical Intelligence Review 16(2),
pages 119-135.
G. Ritchie. (2005). Computational Mechanisms for Pun
Generation. In Proceedings of the 10th European
Natural Language Generation Workshop, pages 125-
132.
</reference>
<page confidence="0.998307">
150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.461704">
<title confidence="0.999848">Cryptic Crossword Clues: Generating Text with a Hidden Meaning</title>
<author confidence="0.999639">David Hardcastle</author>
<affiliation confidence="0.6988705">Open University, Milton Keynes, MK7 Birkbeck, University of London, London, WC1E 7HX</affiliation>
<email confidence="0.964565">ahard04@dcs.bbk.ac.uk</email>
<abstract confidence="0.99989047826087">This paper discusses the generation of cryptic crossword clues: a task that involves generating texts that have both a based on a natural language interpretation of the words, and a meaning which the strings that form the text can be interpreted as a puzzle. The process of clue generation realizes a representation of the hidden, puzzle meaning of the clue through the aggregation of chunks of text. As these chunks are combined, syntactic and semantic selectional constraints are explored, and through this language understanding task a meaningful surface reading is recovered. This hybrid language generation/language understanding process transforms a representation of the clue as a word puzzle into a representation of some meaningful assertion in the domain of the real world, mediated through the generated multi-layered text; a text which has two separate readings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Parsing by Chunks. In The MIT Parsing Volume, edited by</title>
<date>1989</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="6300" citStr="Abney, 1989" startWordPosition="1050" endWordPosition="1051">A complete clue does not need to be a sentence, or even a clause, it can be any valid fragment of text, and ENIGMA takes advantage of this fact to simplify the generation algorithm. The clue tree shown in Figure 1 is realized through a process of composition. First the symbol labeled A is realized. Next B1 and B2 are realized individually and then combined to form B. Now, A and B can themselves be combined to form the clue. Each realization is a fragment of text, and I refer to each of these fragments as a chunk, although I note that they are rather different from chunks based on major heads (Abney, 1989), for the reasons set out below. To implement this process the system needs to be able to do two things: create chunks for each terminal in the clue tree, and merge chunks into successively larger ones until the root of the tree is reached. This recursive process enables ENIGMA to construct complex clues with subsidiary puzzles using the same implementation it uses for simple puzzles. 2.1 Word Order When chunks are combined together they cannot interleave or nest. The reason for this is that each chunk represents a part of the hidden meaning of the clue, and word order is central to its interp</context>
</contexts>
<marker>Abney, 1989</marker>
<rawString>S. Abney. (1989). Parsing by Chunks. In The MIT Parsing Volume, edited by C. Tenny. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bracha</author>
<author>N Cohen</author>
<author>C Kemper</author>
<author>S Mark</author>
<author>M Odersky</author>
<author>S-E Panitz</author>
<author>D Stoutamire</author>
<author>K Thorup</author>
<author>P Wadler</author>
</authors>
<title>Adding generics to the Java programming language: Participant draft specification.</title>
<date>2001</date>
<tech>Technical Report,</tech>
<institution>Sun Microsystems.</institution>
<contexts>
<context position="9528" citStr="Bracha et al, 2001" startWordPosition="1622" endWordPosition="1625">In some respects the extension points and associated erasures encoded onto each chunk act like the categories on functors in Combinatory Categorial Grammar (Clark et al, 2002), or edges on the agenda used in chart generation (Kay, 1996) as they specify the type and directionality of the arguments available and the type of the result. How1 The term extension point is more commonly used to define the interfaces to plug-in components in extensible computer systems. 2 In Object-Oriented Programming an erasure is a simplification or genericisation of a type through some interface, see for example (Bracha et al, 2001). ever, in addition to this syntactic information the grammar also provides the mechanism through which semantic selectional constraints are enforced. The erasures do not just specify a type (such as noun or adjective) but also a member of the chunk: wild or lionesses in this case. This enables the erasures to be used to determine which semantic checks are required to validate the attachment, adding to ENIGMA’s implementation of chunks the semantic constraints that Abney notes as missing from his formulation (1989: 15). For example, if the chunk wild lionesses attaches to a chunk to its left t</context>
</contexts>
<marker>Bracha, Cohen, Kemper, Mark, Odersky, Panitz, Stoutamire, Thorup, Wadler, 2001</marker>
<rawString>G. Bracha, N. Cohen, C. Kemper, S. Mark, M. Odersky, S.-E. Panitz, D. Stoutamire, K. Thorup, and P. Wadler. (2001). Adding generics to the Java programming language: Participant draft specification. Technical Report, Sun Microsystems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J Hockenmaier</author>
<author>M Steedman</author>
</authors>
<title>Building deep dependency structures with a widecoverage CCG parser.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Meeting of the ACL,</booktitle>
<pages>327--334</pages>
<contexts>
<context position="9084" citStr="Clark et al, 2002" startWordPosition="1545" endWordPosition="1548">sses, so that a verb chunk looking for a noun to its right as direct object will accept it, whereas the extension point looking for an adverb erases this same chunk to wild, so that an adverb looking to its right for an adjective to qualify could also accept it. In this way the concept of erasure makes it possible for a wider variety of syntactic dependencies to be encoded in the same way on a single chunk, enabling polymorphic behaviour. In some respects the extension points and associated erasures encoded onto each chunk act like the categories on functors in Combinatory Categorial Grammar (Clark et al, 2002), or edges on the agenda used in chart generation (Kay, 1996) as they specify the type and directionality of the arguments available and the type of the result. How1 The term extension point is more commonly used to define the interfaces to plug-in components in extensible computer systems. 2 In Object-Oriented Programming an erasure is a simplification or genericisation of a type through some interface, see for example (Bracha et al, 2001). ever, in addition to this syntactic information the grammar also provides the mechanism through which semantic selectional constraints are enforced. The e</context>
</contexts>
<marker>Clark, Hockenmaier, Steedman, 2002</marker>
<rawString>S. Clark, J. Hockenmaier, and M. Steedman. (2002). Building deep dependency structures with a widecoverage CCG parser. In Proceedings of the 40th Meeting of the ACL, pages 327–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hardcastle</author>
</authors>
<title>Building a Collocational Semantic Lexicon.</title>
<date>2007</date>
<tech>Technical Report BBKCS-07-02.</tech>
<location>Birkbeck, London.</location>
<contexts>
<context position="13167" citStr="Hardcastle 2007" startWordPosition="2210" endWordPosition="2211">urface reading on the fly. The compositional process reins in the combinatorial explosion by pushing language constraints down to the most local level at which they can operate. ENIGMA uses various generic language understanding resources built specifically for the application during the generation process to ensure that the syntactic relationships behind the clue’s surface reading are semantically supported. • A Collocational Semantic Lexicon mined from British National Corpus and augmented using WordNet determines if a proposed dependency relation between two words is semantically probable (Hardcastle 2007). This lexicon is used to impose selectional constraints on syntactic dependency relations, such as between a verb and its direct object. • A Word Association Measure based on a distributional analysis of data in the British National Corpus is used to evaluate the thematic coherence of the clue (Hardcastle 2005). • A Phrase Dictionary derived from the Moby Compound word list3 is used to identify aggregations that result in the creation of multi-word units such as compound nouns or phrasal verbs. 3 http://www.dcs.shef.ac.uk/research/ilash/Moby/. The resulting clue texts are syntactically and se</context>
</contexts>
<marker>Hardcastle, 2007</marker>
<rawString>D. Hardcastle. (2007). Building a Collocational Semantic Lexicon. Technical Report BBKCS-07-02. Birkbeck, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hardcastle</author>
</authors>
<title>An examination of word association scoring using distributional analysis in the British National Corpus: what is an interesting score and what is a useful system?</title>
<date>2005</date>
<booktitle>In Proceedings of Corpus Linguistics,</booktitle>
<location>Birmingham.</location>
<contexts>
<context position="13480" citStr="Hardcastle 2005" startWordPosition="2263" endWordPosition="2264">sure that the syntactic relationships behind the clue’s surface reading are semantically supported. • A Collocational Semantic Lexicon mined from British National Corpus and augmented using WordNet determines if a proposed dependency relation between two words is semantically probable (Hardcastle 2007). This lexicon is used to impose selectional constraints on syntactic dependency relations, such as between a verb and its direct object. • A Word Association Measure based on a distributional analysis of data in the British National Corpus is used to evaluate the thematic coherence of the clue (Hardcastle 2005). • A Phrase Dictionary derived from the Moby Compound word list3 is used to identify aggregations that result in the creation of multi-word units such as compound nouns or phrasal verbs. 3 http://www.dcs.shef.ac.uk/research/ilash/Moby/. The resulting clue texts are syntactically and semantically valid under the symbolic language grammar of the domain, and at the same time are plausible fragments of natural language. I plan to perform a mix of qualitative and quantitative evaluations on a set of generated clues, a reference set of clues published in newspapers and a set of control clues genera</context>
</contexts>
<marker>Hardcastle, 2005</marker>
<rawString>D. Hardcastle. (2005). An examination of word association scoring using distributional analysis in the British National Corpus: what is an interesting score and what is a useful system? In Proceedings of Corpus Linguistics, Birmingham.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Chart Generation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Meeting of the ACL,</booktitle>
<pages>200--204</pages>
<contexts>
<context position="9145" citStr="Kay, 1996" startWordPosition="1558" endWordPosition="1559">object will accept it, whereas the extension point looking for an adverb erases this same chunk to wild, so that an adverb looking to its right for an adjective to qualify could also accept it. In this way the concept of erasure makes it possible for a wider variety of syntactic dependencies to be encoded in the same way on a single chunk, enabling polymorphic behaviour. In some respects the extension points and associated erasures encoded onto each chunk act like the categories on functors in Combinatory Categorial Grammar (Clark et al, 2002), or edges on the agenda used in chart generation (Kay, 1996) as they specify the type and directionality of the arguments available and the type of the result. How1 The term extension point is more commonly used to define the interfaces to plug-in components in extensible computer systems. 2 In Object-Oriented Programming an erasure is a simplification or genericisation of a type through some interface, see for example (Bracha et al, 2001). ever, in addition to this syntactic information the grammar also provides the mechanism through which semantic selectional constraints are enforced. The erasures do not just specify a type (such as noun or adjective</context>
</contexts>
<marker>Kay, 1996</marker>
<rawString>M. Kay. (1996). Chart Generation. In Proceedings of the 34th Meeting of the ACL, pages 200-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Macnutt</author>
</authors>
<title>On the Art of the Crossword.</title>
<date>1966</date>
<publisher>Swallowtail Books.</publisher>
<contexts>
<context position="2879" citStr="Macnutt, 1966" startWordPosition="445" endWordPosition="446">ptions (see also Ritchie, 2005: 4) requiring a bespoke solution. 1.1 Cryptic Crossword Clues The cryptic crossword clues generated by ENIGMA consist of two separate indications of the solution word, one of which is a definition, the other a puzzle based on its orthography. Consider, for example, the following simple clue for noiseless: Still wild lionesses (9) Here noiseless is represented both by the synonym still (the definition) and a wordplay puzzle (an anagram of lionesses) indicated by the convention keyword wild. All of the clues generated by the system conform to Ximenean conventions (Macnutt, 1966), a set of guidelines that impose restrictions on inflection and word order to ensure that clues are ‘fair’ and also encourage the use of homographs and convention vocabulary to make them cryptic in nature. It is important to note here that there are two separate readings of this clue: a surface reading in which the clue is also a fragment of English text, and the puzzle reading required to solve the clue. In the surface reading the word still is an adverb qualifying the adjective wild, while in the puzzle 147 reading it is an adjective that is a synonym for noiseless. There are many different</context>
<context position="4883" citStr="Macnutt, 1966" startWordPosition="792" endWordPosition="793">ses, or that it can be formed by running noise and less together, or that it is composed of a river (Oise) followed by the letter l all placed inside the word ness. In its present form ENIGMA locates 154 such formulations for the input word noiseless. Each of these formulations can be represented as a clue tree under ENIGMA’s domain grammar for cryptic crosswords in which the terminal elements are the strings used to compose the solution word. The sample clue tree in Figure 1 represents the fact that noiseless can be formed by running noise and less together, a puzzle type known as a Charade (Macnutt, 1966; Manley, 2001). Figure 1. A clue tree that represents appending noise and less to form noiseless. These clue trees contain no linguistic information - the terminals should be thought of as strings not as words. To lexicalize this data the system must construct a fragment of natural language that can be reinterpreted - through the resolution of homographs and a knowledge of special conventions - as a valid cryptic clue puzzle based on this nonlinguistic structure. Along the way the syntax and semantics of the puzzle reading must not be disturbed or the clue will lose its hidden meaning. At the</context>
</contexts>
<marker>Macnutt, 1966</marker>
<rawString>D. S. Macnutt. (1966). On the Art of the Crossword. Swallowtail Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Manley</author>
</authors>
<date>2001</date>
<journal>Chambers Crossword Manual. Chambers.</journal>
<contexts>
<context position="4898" citStr="Manley, 2001" startWordPosition="794" endWordPosition="795"> can be formed by running noise and less together, or that it is composed of a river (Oise) followed by the letter l all placed inside the word ness. In its present form ENIGMA locates 154 such formulations for the input word noiseless. Each of these formulations can be represented as a clue tree under ENIGMA’s domain grammar for cryptic crosswords in which the terminal elements are the strings used to compose the solution word. The sample clue tree in Figure 1 represents the fact that noiseless can be formed by running noise and less together, a puzzle type known as a Charade (Macnutt, 1966; Manley, 2001). Figure 1. A clue tree that represents appending noise and less to form noiseless. These clue trees contain no linguistic information - the terminals should be thought of as strings not as words. To lexicalize this data the system must construct a fragment of natural language that can be reinterpreted - through the resolution of homographs and a knowledge of special conventions - as a valid cryptic clue puzzle based on this nonlinguistic structure. Along the way the syntax and semantics of the puzzle reading must not be disturbed or the clue will lose its hidden meaning. At the same time, the</context>
</contexts>
<marker>Manley, 2001</marker>
<rawString>D. Manley. (2001). Chambers Crossword Manual. Chambers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Manurung</author>
<author>G Ritchie</author>
<author>H Thompson</author>
</authors>
<title>Towards a Computational Model of Poetry Generation.</title>
<date>2000</date>
<booktitle>In Proceedings of AISB Symposium on Creative and Cultural Aspects and Applications of AI and Cognitive Science,</booktitle>
<pages>79--86</pages>
<marker>Manurung, Ritchie, Thompson, 2000</marker>
<rawString>H. Manurung, G. Ritchie and H. Thompson. (2000). Towards a Computational Model of Poetry Generation. In Proceedings of AISB Symposium on Creative and Cultural Aspects and Applications of AI and Cognitive Science, pages 79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
</authors>
<title>Current Directions in Computational Humour.</title>
<date>2001</date>
<journal>In Artifical Intelligence Review</journal>
<volume>16</volume>
<issue>2</issue>
<pages>119--135</pages>
<contexts>
<context position="2155" citStr="Ritchie, 2001" startWordPosition="331" endWordPosition="332">f a high-level cryptic clue grammar whose terminals are the strings that participate in the puzzle presented by the clue. These conceptualizations of possible crossword clues contain no implicit syntactic or semantic information, and so a mechanism is required to ensure that the resulting surface text is syntactically correct and semantically appropriate while the meaning of the text, derived directly from the input, is not disturbed during lexicalization. As with computational humour and poetry generation the process of generation is unusual in that the content is not specified in the input (Ritchie, 2001; Manurung, 2000), and this leads to tractability problems when considering the wide range of lexicalization options (see also Ritchie, 2005: 4) requiring a bespoke solution. 1.1 Cryptic Crossword Clues The cryptic crossword clues generated by ENIGMA consist of two separate indications of the solution word, one of which is a definition, the other a puzzle based on its orthography. Consider, for example, the following simple clue for noiseless: Still wild lionesses (9) Here noiseless is represented both by the synonym still (the definition) and a wordplay puzzle (an anagram of lionesses) indica</context>
</contexts>
<marker>Ritchie, 2001</marker>
<rawString>G. Ritchie. (2001). Current Directions in Computational Humour. In Artifical Intelligence Review 16(2), pages 119-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
</authors>
<title>Computational Mechanisms for Pun Generation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th European Natural Language Generation Workshop,</booktitle>
<pages>125--132</pages>
<contexts>
<context position="2295" citStr="Ritchie, 2005" startWordPosition="352" endWordPosition="353">ations of possible crossword clues contain no implicit syntactic or semantic information, and so a mechanism is required to ensure that the resulting surface text is syntactically correct and semantically appropriate while the meaning of the text, derived directly from the input, is not disturbed during lexicalization. As with computational humour and poetry generation the process of generation is unusual in that the content is not specified in the input (Ritchie, 2001; Manurung, 2000), and this leads to tractability problems when considering the wide range of lexicalization options (see also Ritchie, 2005: 4) requiring a bespoke solution. 1.1 Cryptic Crossword Clues The cryptic crossword clues generated by ENIGMA consist of two separate indications of the solution word, one of which is a definition, the other a puzzle based on its orthography. Consider, for example, the following simple clue for noiseless: Still wild lionesses (9) Here noiseless is represented both by the synonym still (the definition) and a wordplay puzzle (an anagram of lionesses) indicated by the convention keyword wild. All of the clues generated by the system conform to Ximenean conventions (Macnutt, 1966), a set of guide</context>
</contexts>
<marker>Ritchie, 2005</marker>
<rawString>G. Ritchie. (2005). Computational Mechanisms for Pun Generation. In Proceedings of the 10th European Natural Language Generation Workshop, pages 125-132.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>