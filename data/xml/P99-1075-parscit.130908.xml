<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000380">
<title confidence="0.997809">
Packing of Feature Structures for
Efficient Unification of Disjunctive Feature Structures
</title>
<author confidence="0.997659">
Yusuke Miyao
</author>
<affiliation confidence="0.999541">
Department of Information Science, University of Tokyo
</affiliation>
<address confidence="0.948139">
7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033 Japan
</address>
<email confidence="0.990637">
E-mail: yusukais .s .u-tokyo .ac. jp
</email>
<sectionHeader confidence="0.997218" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999275">
This paper proposes a method for packing fea-
ture structures, which automatically collapses
equivalent parts of lexical/phrasal feature struc-
tures of HPSG into a single packed feature struc-
ture. This method avoids redundant repetition
of unification of those parts. Preliminary exper-
iments show that this method can significantly
improve a unification speed in parsing.
</bodyText>
<sectionHeader confidence="0.999389" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999036692307692">
Efficient treatment of syntactic/semantic ambi-
guity is a key to making efficient parsers for
wide-coverage grammars. In feature-structure-
based grammarsl, such as HPSG (Pollard and
Sag, 1994), ambiguity is expressed not only
by manually-tailored disjunctive feature struc-
tures, but also by enumerating non-disjunctive
feature structures. In addition, there is ambigu-
ity caused by non-determinism when applying
lexical/grammar rules. As a result, a large num-
ber of lexical/phrasal feature structures are re-
quired to express ambiguous syntactic/semantic
structures. Without efficient processing of these
feature structures, a sufficient parsing speed is
unattainable.
This paper proposes a method for packing
feature structures, which is an automatic op-
timization method for parsers based on feature
structure unification. This method automati-
cally extracts equivalent parts of feature struc-
tures and collapses them into a single packed
feature structure. A packed feature structure
can be processed more efficiently because we can
avoid redundant repetition of unification of the
equivalent parts of original feature structures.
There have been many studies on efficient
</bodyText>
<footnote confidence="0.8385535">
11n this paper we consider typed feature structures
described in (Carpenter, 1992).
</footnote>
<bodyText confidence="0.999973878787879">
unification of disjunctive feature structures
(Kasper and Rounds, 1986; Hasida, 1986; Dorre
and Eisele, 1990; Nakano, 1991; Blache, 1997;
Blache, 1998). All of them suppose that dis-
junctive feature structures should be given by
grammar writers or lexicographers. However,
it is not practical to specify all ambiguity us-
ing only manually-tailored disjunctive feature
structures in grammar development. Where dis-
junctive feature structures cannot be given ex-
plicitly those algorithms lose their advantages.
Hence, an automatic conversion method, such
as the packing method described hereafter, is re-
quired for further optimization of those systems.
In addition, this packing method converts gen-
eral feature structures to a suitable form for a
simple and efficient unification algorithm which
is also described in this paper.
Griffith (Griffith, 1995; Griffith, 1996) points
out the same problem and proposes a compila-
tion method for feature structures called mod-
ularization. However, modularization is very
time-consuming, and is not suitable for opti-
mizing feature structures produced during pars-
ing. An earlier paper of myself (Miyao et al.,
1998) also discusses the same problem and pro-
poses another packing method. However, that
method can pack only pre-specified parts of
input feature structures, and this characteris-
tic limits the overall efficient gain. The new
method in this paper can pack any kind of fea-
ture structures as far as possible, and is more
general than the previous method.
</bodyText>
<sectionHeader confidence="0.772578" genericHeader="method">
2 Data Structure and Algorithms
</sectionHeader>
<bodyText confidence="0.999875">
This section describes the data structure of
packed feature structures, and the algorithms
for packing and unification of packed feature
structures. Through of this section, I will refer
to examples from the XHPSG system (Tateisi
</bodyText>
<page confidence="0.997182">
579
</page>
<bodyText confidence="0.9981925">
et al., 1998), an HPSG-based grammar for En-
glish.
</bodyText>
<subsectionHeader confidence="0.99547">
2.1 Packed Feature Structure
</subsectionHeader>
<bodyText confidence="0.99932">
Figure 1 shows 4 out of 37 lexical entries which
the XHPSG system assigns to the word &amp;quot;cred-
ited&amp;quot;. These lexical entries have various equiva-
lent parts in their respective feature structures.
In Figure 1, equivalent parts are shaded with
the same pattern.
Figure 2 shows a packed feature structure for
the lexical entries shown in Figure 1. Note that
the equivalent parts of the original feature struc-
tures are collapsed into a feature structure seg-
ment, which is denoted by Si in Figure 2. So is
a special segment called the root segment, which
</bodyText>
<figure confidence="0.8272975">
-weed
PHEW eauddecf
</figure>
<figureCaption confidence="0.94692325">
Figure 2: A packed feature structure expressing
the same information as the set of feature structures
in Figure 1. Shaded parts correspond to the parts
with the same pattern in Figure 1.
</figureCaption>
<bodyText confidence="0.999818535714286">
describes the root nodes of all original feature
structures. Each segment can have disjunctive
nodes, which are denoted by Ai. For example,
53 has two disjunctive nodes, 6.5 and A6. A de-
pendency function, denoted by Di, is a mapping
from a disjunctive node to a segment, and each
Di corresponds to one original feature structure.
We can obtain each original feature structure by
replacing each disjunctive node with the output
of the respective dependency function.
For applying the unification algorithm de-
scribed in Section 2.3, we introduce a con-
dition on segments: a segment cannot have
inter- or intra-segment shared nodes. For ex-
ample, the disjunctive node Ai in Figure 2
must be introduced for satisfying this con-
dition, even though the value of this node
is the same in all the original feature struc-
tures. This is because this path is structure-
shared with another path (SYNSEMILOCALICONT1
ARG1 and SYNSEMILOCALICONTIARG2). Structure-
sharing in original feature structures is instead
expressed by letting the dependency function
return the same value for different inputs. For
example, result values of applying D1 to Ai and
A7 are both Si.
The reason why we introduce this condition
is to guarantee that a disjunctive node in the
</bodyText>
<figure confidence="0.992838928571429">
CAT
LOCAL
word
PHON ecrediefa
—HEAD verb
[sum ,{CAT IT H1 nagenod,
VAI. SPR &lt;
VHS EM
- word
PHota e aloof •,
Icrcdth,12
ARG1 II
ARG2 Fl
_NONUX INHERI SLASH &apos;(
</figure>
<figureCaption confidence="0.993226">
Figure 1: 4 out of 37 lexical entries which the
XHPSG system assigns to the word &amp;quot;credited&amp;quot;.
Parts shaded with the same pattern are equivalent.
</figureCaption>
<figure confidence="0.997811138888889">
HEAD tr.&amp;
sow [CAT&apos; HEAD 29/910/
LOCAL VAL
CM LCONT
COMPS A2
SPR &lt; &gt;
CON
_Nom_ocj INH ER I SLASH A.
S ° [AcrReGrAdi 7]
▪ &lt;&gt;
S&apos;t: 1-CA1IFIEAD
LOCH! A.
S o :
SYNSEM
52
$
S9: by
Si. Wffl_01#
$ 7 non. _oh&apos;
I S I
2-* Sn
• S.
17
5-* S
S
S
• S
2
09 =
cofrIcred fedi 1
ARGI J
NONLOC I INHERISLASH
580
Si: John
82: Yusuke
131=C S13 D2= C At-4&apos;S 23
</figure>
<figureCaption confidence="0.89601075">
Figure 3: A sample packed feature structure. If it is
unified with the top feature structure in Figure 1, a
new disjunctive node must be introduced to SYNSEMI
LOCALICATIVALISUBJIFIRSTICONT.
</figureCaption>
<bodyText confidence="0.9999446875">
result of unification will appear only at a path
where a disjunctive node appears in either of the
input feature structures at the same path. For
example, suppose we unify the top feature struc-
ture in Figure 1 with the packed feature struc-
ture in Figure 3. In the result of unification, a
new disjunctive node must appear at SYNSEMI
LOCALICATIVALISUBJIFIRSTICONT, while no dis-
junctive nodes appear in either of the input fea-
ture structures at this path. By introducing
such a disjunctive node in advance, we can sim-
plify the algorithm for unification described in
Section 2.3.
Below I first describe the algorithm for pack-
ing feature structures, and then the algorithm
for unification of packed feature structures.
</bodyText>
<subsectionHeader confidence="0.991872">
2.2 Algorithm for Packing
</subsectionHeader>
<bodyText confidence="0.999911105263158">
The procedure pack_f eature_structures in
Figure 4 describes the algorithm for packing two
packed feature structures, denoted by (8&apos;, D&apos;)
and (8&amp;quot; ,D&apos;&apos;). S&apos; and 8&amp;quot; denote sets of seg-
ments, and D&apos; and D&amp;quot; denote sets of depen-
dency functions. We start from comparing the
types of the root nodes of both feature struc-
tures. If either of the nodes is a disjunctive node
(Case 1), we compare the type of the other fea-
ture structure with the type of each disjunct,
and recursively pack nodes with the same type
if they exist (Case 1.1). Otherwise, we just
add the other feature structure to the disjunc-
tive node as a new disjunct (Case 1.2). If the
types of the nodes are equivalent (Case 2), we
collapse them into one node, and apply packing
recursively to all of their subnodes. If they are
not equivalent (Case 3), we create a new dis-
junctive node at this node, and let each original
</bodyText>
<figureCaption confidence="0.960722">
Figure 4: Algorithm for packing two packed feature
structures (8&apos;,V) and (8&amp;quot;,D&amp;quot;).
</figureCaption>
<bodyText confidence="0.998674166666667">
feature structure from this node become a new
segment.
For simplicity, Figure 4 omits the algorithm
for introducing disjunctive nodes into shared
nodes. We can easily create disjunctive nodes
in such places by preprocessing input feature
structures in the following way. First each input
feature structure is converted to a packed fea-
ture structure in advance by converting shared
nodes to disjunctive nodes. Then the above
algorithm can be applied to these converted
packed feature structures.
</bodyText>
<subsectionHeader confidence="0.983276">
2.3 Algorithm for Unification
</subsectionHeader>
<bodyText confidence="0.971644166666667">
Below I describe the algorithm for unification of
packed feature structures, referring to the exam-
ple in Figure 2. Suppose that we are unifying
this packed feature structure with the feature
structure in Figure 5. This example consid-
ers unification of a non-packed feature structure
with a packed feature structure, although this
algorithm is capable of unifying two packed fea-
ture structures.
The process itself is described by the pro-
cedure unify_packed_feature_structures in
Figure 6. It is quite similar to a normal uni-
</bodyText>
<figure confidence="0.805031166666666">
[HEAD verb
[CAT
VAL I SUBJ &lt; DONT contena j _
CONT
[
c
r
e
d
i
te
d
]1
ARG1
So:
-word
PHON ecredfted&gt;
SYNSEM I LOCAL
procedure pack_feature_structuros((Si, V1), (5&amp;quot; ,7,&amp;quot;))
begin
S 4,
ES&apos;. Sg E s&amp;quot;
pack(Sfo. sg)
U El&amp;quot;
</figure>
<table confidence="0.962714357142857">
return (5, V)
and
procedure pack(FI , F&amp;quot;) • • • Case /
begin ... Case 1.1
if F&apos; (or F&amp;quot;) is disjunction then • .. Case 1.2
if 3G(G E disjuncts(P1). Case 2
G and F&amp;quot; have equivalent types) than Case 3
S := SUdisjuncts(P)
pack(G, F&amp;quot;)
D&amp;quot; := {DID&amp;quot; E D&amp;quot; , D = D&amp;quot; F&amp;quot;))
else
S := SUdisjuncts(P )1.1{ F&amp;quot;
Du := {DID&amp;quot; E D&amp;quot; D = D&amp;quot; u (F&apos; F&amp;quot;))
endif
aloe if F&apos; and F&amp;quot; have equivalent types then
F&apos; := F&amp;quot;
Corinth f in features(F&apos;)
pack(f. ollow(f F&apos;), tones( f F&amp;quot;))
Glee
S := S u {F&apos;, F&amp;quot;}
F disjunctive_uode
:= (DID&apos; ED&apos;, D = U (F F&apos;))
D&amp;quot; := {DID&apos; E D&amp;quot; , D = D&amp;quot; U (F -• F&amp;quot;))
*edit
and
disjuncts: return a set of disjuncts of the disjunctive node
features: return a set of features
folios: return a substructure reached by the specified feature
</table>
<page confidence="0.822486">
581
</page>
<figure confidence="0.999246645833333">
word
PHON &lt; credited&gt;
HEAD verb
CAT [
VAL COMPS IE
SUBJ &lt; ECONT al ] &gt;
SPR &lt; &gt; &lt; &gt;
CONT I ARG1 lal
_NONLOC I INNER I SLASH list
So:
SYNSEM LOCAL
word
PHON ecreditecr&gt;
SYNSEM
LOCAL
CAT
_
HEAD verb
[sow &lt;FCATI HEAD nounI
VAL
[CONT zs,
COMPS A2
SPR &lt;&gt;
CONT
_NONLOC I INNER I SLASH A4
SI
S2
S3
nom_obj
&lt;&gt;
rcATIHEAD
[CONT A, J&gt;
So: ARG1
[ Aj
ARG2
credited2
So: &lt;&gt;
s FCATI HEAD nounl
[CONT A10 j&gt;
IA2 So
IAaSs
D2=
5-* S
11-&apos;&apos;S 6
8`÷ Si
9-&gt; St,
• [ARG1
Ss &apos; creditedl
</figure>
<figureCaption confidence="0.99930025">
Figure 5: A sample feature structure to be unified
with the packed feature structure in Figure 2.
Figure 6: Algorithm for unifying two packed fea-
ture structures (S&apos;,21 and (S&amp;quot;,731&amp;quot;).
</figureCaption>
<bodyText confidence="0.988354">
fication algorithm. The only difference is the
part that handles disjunctive nodes. When we
reach a disjunctive node, we put it onto a stack
(segment _st ack), and postpone further unifi-
cation from this node ((5) in Figure 6). In this
example, we put Ai, A2, A3, and A4 onto the
stack. At the end of the entire unification, we
</bodyText>
<equation confidence="0.630309333333333">
03=...D4 =
aegmenteatack = ( A2 A3 A4 )
D .G60-&gt; S
</equation>
<figureCaption confidence="0.728503833333333">
Figure 7: Intermediate data structure after unify-
ing Ai with D Disjunction is expressed by non-
determinism when applying the dependency func-
tions. When we unify a feature structure segment
for A2, we unify S2 if we are applying D1, or S3 if
D2
</figureCaption>
<bodyText confidence="0.999859913043478">
apply a dependency function to each member
of the stack, and unify every resulting segment
with a corresponding part of the other feature
structure ((1) in Figure 6). In this example,
we apply Di to Ai, which returns segment Si.
We therefore unify Si with the feature structure
tagged as a in Figure 5.
Disjunction is expressed by non-determinism
when applying the dependency functions. Fig-
ure 7 shows the intermediate data structure af-
ter unifying Ai with a. We are now focusing
on the disjunctive node A2 which is now on the
top of segment_stack. When we are applying
we unify 52 with the corresponding feature
structure b . Should we instead apply D2, 53
would be unified.
A benefit of this unification algorithm is that
we can skip unification of feature structure seg-
ments whose unification is already computed
((2) in Figure 6). For example, we unify seg-
ment So with the other feature structure only
once. We can also skip unification of Si and Sio
for D2 because the result is already computed
</bodyText>
<figure confidence="0.982391346938776">
procedure unify_packedJeature_structures((Si, D&apos;), (S&amp;quot;, V&amp;quot;))
begin
S := 56, V:=
foreach E D&apos; and D&amp;quot; E D0
11322:
begin
push_segroent.stack (St E . S&apos;c; E S&amp;quot;)
do until segment_stack-is-empty
begin
pop_segment_otack(Si .S&amp;quot;)
if S&apos; is disjunction then S&apos; := D&apos;(S1)
if S&amp;quot; is disjunction then Su
SEOBEIT_Ull SPY :
if already_unitied(S1,S&amp;quot;) then
S :=restore..unity_result ( 51,S&amp;quot;
:= S. S&amp;quot; := S
else
it S:= unity(S1 .S&amp;quot; ) fails than
goon NEXT
else
S := S U {SI
set_unification-result(S, S&amp;quot;)
:= S, S&amp;quot; := S
omit!&apos;
audit
and
:= U {D&apos; U D&amp;quot;}
end
return (S , D)
end
procedure unify (F&apos; .F&amp;quot;)
begin
it 14 or F&amp;quot; is disjunction than
F disjunctive_node
push_segment_stack(F/ , F&amp;quot;)
also
F := unify_type(Fi F&amp;quot;)
foreath f in feature (F)
follow(&apos; .F):= unity(follet(f ) dollen(&apos; .F&amp;quot;))
*edit
return F
end
alroady_unified: true when unification is already computed
restore_unity_result: restore the result of unification from
the table
set_unity-rosult : store the result of unification into the table
unify_type return the unification of both types
• • • (4)
S4
So
S6
S7:
noun
by
nom_obj
nom_obj
582
-word
PHON ecrediterf&gt;
LOCAL
SYNSEM COMPS 62
sPR &lt;&gt;
CONT
_NONLOC I INNER I SLASH 6,
• : no- m_obj S nom_obj
S2 &lt;&gt; So: &lt;3
S3 : [credited] [CATI HEAD noun]
ARG1 6 S7 &lt;
• [ZReteX.1 CONT
LARG2 6, j
So:
HEAD verb
suBj &lt;1-CATI HEAD nounl &gt;
CAT LCONT 6, j
VAL
CAT- HEAD verb
[VAL [sua &lt;FCATI HEAD noun-I
COMPS Q.
SPR &lt; &gt;1-(x)NT noun]
CONT
_NONLOCI INHER I SLASH A,
[
So: credited]
ARG1
sio: &lt;&gt;
So:
SYNSEM
S1 : notn_obi
S2 &lt;&gt;
LOCAL
-word
PHON eoredited&gt;
segment_stack = ( &amp;) al=12-*S2
Si 3-&gt;S4
2 S2 4-* S7
-*i 6-&gt; Si
S 7-*S6
SI 13-&gt;S5,
</figure>
<figureCaption confidence="0.9920448">
Figure 8: Intermediate data structure after the uni-
fication of A4 . Because the result of applying Di. to
A 7 is already overwritten by the result of unifying
S1 with a we unify this resulting feature structure
with
</figureCaption>
<bodyText confidence="0.999698176470588">
for D1. This operation preserves the validity of
unification because each segment does not have
inter- or intra-segment shared nodes, because of
the condition we previously introduced.
Note that this method can correctly unify fea-
ture structures with reentrancies. For example,
Figure 8 shows the intermediate data structure
after unifying L4, and the process currently
reached A 7 and B. The result of the appli-
cation of D1 to A7 is the result of unifying Si
with a , because Si is overwritten with the re-
sult of this previous unification ((3) and (4) in
Figure 6). Hence, we unify la with this result.
Above unification algorithm is applied to ev-
ery combination of dependency functions. The
result of the entire unification is shown in Fig-
ure 9.
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9958301">
I implemented the algorithms for packing and
unification in LiLFeS (Makin° et al., 1998).
LiLFeS is one of the fastest inference engines
for processing feature structure logic, and effi-
cient parsers have already been realized using
this system. For performance evaluation I mea-
sure the execution time for a part of application
of grammar rules (i.e. schemata) of XHP SG.
Table 1 shows the execution time for uni-
fying the resulting feature structure of apply-
</bodyText>
<figureCaption confidence="0.994124">
Figure 9: The resulting packed feature structure
of unifying the packed feature structure of Figure 2
with the feature structure of Figure 5.
</figureCaption>
<bodyText confidence="0.999935375">
ing schemata to lexical entries of &amp;quot;Mary&amp;quot; as
a left daughter, with lexical entries of &amp;quot;cred-
ited&amp;quot;/&amp;quot;walked&amp;quot; as right daughters. Unification
of packed feature structures achieved a speed-
up by a factor of 6.4 to 8.4, compared to the
naive approach. Table 2 shows the number of
unification routine calls. NODE_UNIFY shows the
number of nodes for which unification of types
is computed. As can be seen, it is significantly
reduced. On the other hand, SEGMENT_UNIFY
shows the number of check operations whether
unification is already computed. It shows that
the number of node unification operations is sig-
nificantly reduced by the packing method, and
segment unification operations account for most
of the time taken by the unification.
These results indicate that a unification speed
can be improved furthermore by reducing the
number of the segment unification. The data
structure of dependency functions has to be
improved, and dependency functions can be
packed. I observed that at least a quarter of
the segment unification operations can be sup-
pressed. This is one of the future works.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999913">
The packing method I described in this paper
automatically extracts equivalent parts from
feature structures and collapses them into a sin-
gle packed feature structure. It reduces redun-
dant repetition of unification operations on the
</bodyText>
<page confidence="0.999543">
583
</page>
<tableCaption confidence="0.995675">
Table 1: Execution time for unification. Test data shows the word used for the experiment. # of LEs
</tableCaption>
<bodyText confidence="0.679394">
shows the number of lexical entries assigned to the word. Naive shows the time for unification with a naive
method. PFS shows the time for unification of packed feature structures (PFS). Improvement shows the
ratio (Naive)/(PFS).
</bodyText>
<table confidence="0.867182333333333">
Test data # of LEs Naive (msec.) PFS (msec.) Improvement (factor)
credited 37 36.5 5.7 6.4
walked 79 77.2 9.2 8.4
</table>
<tableCaption confidence="0.736672666666667">
Table 2: The number of calling each part of the unification routines. Naive shows the number of node
unification operations in the naive unification algorithm (corresponds to NODE_UNIFY of my algorithm).
NODE_UNIFY and SEGMENT_UNIFY are specified in Figure 6.
</tableCaption>
<bodyText confidence="0.980425875">
Test data Naive NODE_UNIFY SEGMENT_UNIFY
credited 30929 256 5095
walked 65709 265 10603
equivalent parts. I implemented this method in
LiLFeS, and achieved a speed-up of the unifica-
tion process by a factor of 6.4 to 8.4. For realiz-
ing efficient NLP systems, I am currently build-
ing an efficient parser by integrating the packing
method with the compilation method for HPSG
(Torisawa and Tsujii, 1996). While the compi-
lation method reduces the number of unification
operations during parsing, it cannot prevent in-
efficiency caused by ambiguity. The packing
method will overcome this problem, and will
hopefully enable us to realize practical and effi-
cient NLP systems.
</bodyText>
<sectionHeader confidence="0.999101" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998750857142857">
Philippe Blache. 1997. Disambiguating with
controlled disjunctions. In Proc. Interna-
tional Workshop on Parsing Technologies.
Philippe Blache. 1998. Parsing ambigu-
ous structures using controlled disjunctions
and unary quasi-trees. In Proc. COLING-
ACL&apos;98, pages 124-130.
Bob Carpenter. 1992. The Logic of Typed Fea-
ture Structures. Cambridge University Press.
Jochen Dorm and Andreas Eisele. 1990. Fea-
ture logic with disjunctive unification. In
Proc. 13th COLING, volume 2, pages 100-
105.
John Griffith. 1995. Optimizing feature struc-
ture unification with dependent disjunctions.
In Proc. Workshop on Grammar Formalism
for NLP at ESSLLI-94, pages 37-59.
John Griffith. 1996. Modularizing contexted
constraints. In Proc. COLING&apos;96, pages 448-
453.
Kohl Hasida. 1986. Conditioned unification for
natural language processing. In Proc. 11th
COLING, pages 85-87.
Robert T. Kasper and William C. Rounds.
1986. A logical semantics for feature struc-
tures. In Proc. 24th ACL, pages 257-266.
Takaki Makino, Minoru Yoshida, Kentaro Tori-
sawa, and Jun&apos;ichi Tsujii. 1998. LiLFeS -
towards a practical HPSG parser. In Proc.
COLING-ACL &apos;98, pages 807-811.
Yusuke Miyao, Kentaro Torisawa, Yuka Tateisi,
and Jun&apos;ichi Tsujii. 1998. Packing of fea-
ture structures for optimizing the HPSG-
style grammar translated from TAG. In Proc.
TAG+4 Workshop, pages 104-107.
Mikio Nakano. 1991. Constraint projection: An
efficient treatment of disjunctive feature de-
scriptions. In Proc. 29th ACL, pages 307-314.
C. Pollard and I. A. Sag. 1994. Head-Driven
Phrase Structure Grammar. University of
Chicago Press.
Yuka Tateisi, Kentaro Torisawa, Yusuke Miyao,
and Jun&apos;ichi Tsujii. 1998. Translating the
XTAG English grammar to HPSG. In Proc.
TAG+4 Workshop, pages 172-175.
Kentaro Torisawa and Jun&apos;ichi Tsujii. 1996.
Computing phrasal-signs in HPSG prior to
parsing. In Proc. 16th COLING, pages 949-
955.
</reference>
<page confidence="0.998595">
584
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.681247">
<title confidence="0.9997735">Packing of Feature Structures for Efficient Unification of Disjunctive Feature Structures</title>
<author confidence="0.998987">Yusuke Miyao</author>
<affiliation confidence="0.999888">Department of Information Science, University of Tokyo</affiliation>
<address confidence="0.951472">7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033 Japan</address>
<email confidence="0.70183">.s.ac.jp</email>
<abstract confidence="0.999391666666667">This paper proposes a method for packing feature structures, which automatically collapses equivalent parts of lexical/phrasal feature strucof HPSG into a single feature strucmethod avoids redundant repetition of unification of those parts. Preliminary experiments show that this method can significantly improve a unification speed in parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Philippe Blache</author>
</authors>
<title>Disambiguating with controlled disjunctions.</title>
<date>1997</date>
<booktitle>In Proc. International Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="2022" citStr="Blache, 1997" startWordPosition="283" endWordPosition="284">rs based on feature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a suitable form f</context>
</contexts>
<marker>Blache, 1997</marker>
<rawString>Philippe Blache. 1997. Disambiguating with controlled disjunctions. In Proc. International Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Blache</author>
</authors>
<title>Parsing ambiguous structures using controlled disjunctions and unary quasi-trees.</title>
<date>1998</date>
<booktitle>In Proc. COLINGACL&apos;98,</booktitle>
<pages>124--130</pages>
<contexts>
<context position="2037" citStr="Blache, 1998" startWordPosition="285" endWordPosition="286">ature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a suitable form for a simple and</context>
</contexts>
<marker>Blache, 1998</marker>
<rawString>Philippe Blache. 1998. Parsing ambiguous structures using controlled disjunctions and unary quasi-trees. In Proc. COLINGACL&apos;98, pages 124-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures.</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1884" citStr="Carpenter, 1992" startWordPosition="264" endWordPosition="265">arsing speed is unattainable. This paper proposes a method for packing feature structures, which is an automatic optimization method for parsers based on feature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is req</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. The Logic of Typed Feature Structures. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Dorm</author>
<author>Andreas Eisele</author>
</authors>
<title>Feature logic with disjunctive unification.</title>
<date>1990</date>
<booktitle>In Proc. 13th COLING,</booktitle>
<volume>2</volume>
<pages>100--105</pages>
<marker>Dorm, Eisele, 1990</marker>
<rawString>Jochen Dorm and Andreas Eisele. 1990. Feature logic with disjunctive unification. In Proc. 13th COLING, volume 2, pages 100-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Griffith</author>
</authors>
<title>Optimizing feature structure unification with dependent disjunctions.</title>
<date>1995</date>
<booktitle>In Proc. Workshop on Grammar Formalism for NLP at ESSLLI-94,</booktitle>
<pages>37--59</pages>
<contexts>
<context position="2733" citStr="Griffith, 1995" startWordPosition="388" endWordPosition="389">ar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a suitable form for a simple and efficient unification algorithm which is also described in this paper. Griffith (Griffith, 1995; Griffith, 1996) points out the same problem and proposes a compilation method for feature structures called modularization. However, modularization is very time-consuming, and is not suitable for optimizing feature structures produced during parsing. An earlier paper of myself (Miyao et al., 1998) also discusses the same problem and proposes another packing method. However, that method can pack only pre-specified parts of input feature structures, and this characteristic limits the overall efficient gain. The new method in this paper can pack any kind of feature structures as far as possible</context>
</contexts>
<marker>Griffith, 1995</marker>
<rawString>John Griffith. 1995. Optimizing feature structure unification with dependent disjunctions. In Proc. Workshop on Grammar Formalism for NLP at ESSLLI-94, pages 37-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Griffith</author>
</authors>
<title>Modularizing contexted constraints.</title>
<date>1996</date>
<booktitle>In Proc. COLING&apos;96,</booktitle>
<pages>448--453</pages>
<contexts>
<context position="2750" citStr="Griffith, 1996" startWordPosition="390" endWordPosition="391">xicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a suitable form for a simple and efficient unification algorithm which is also described in this paper. Griffith (Griffith, 1995; Griffith, 1996) points out the same problem and proposes a compilation method for feature structures called modularization. However, modularization is very time-consuming, and is not suitable for optimizing feature structures produced during parsing. An earlier paper of myself (Miyao et al., 1998) also discusses the same problem and proposes another packing method. However, that method can pack only pre-specified parts of input feature structures, and this characteristic limits the overall efficient gain. The new method in this paper can pack any kind of feature structures as far as possible, and is more gen</context>
</contexts>
<marker>Griffith, 1996</marker>
<rawString>John Griffith. 1996. Modularizing contexted constraints. In Proc. COLING&apos;96, pages 448-453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kohl Hasida</author>
</authors>
<title>Conditioned unification for natural language processing.</title>
<date>1986</date>
<booktitle>In Proc. 11th COLING,</booktitle>
<pages>85--87</pages>
<contexts>
<context position="1970" citStr="Hasida, 1986" startWordPosition="275" endWordPosition="276"> which is an automatic optimization method for parsers based on feature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method conv</context>
</contexts>
<marker>Hasida, 1986</marker>
<rawString>Kohl Hasida. 1986. Conditioned unification for natural language processing. In Proc. 11th COLING, pages 85-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
<author>William C Rounds</author>
</authors>
<title>A logical semantics for feature structures.</title>
<date>1986</date>
<booktitle>In Proc. 24th ACL,</booktitle>
<pages>257--266</pages>
<contexts>
<context position="1956" citStr="Kasper and Rounds, 1986" startWordPosition="271" endWordPosition="274">cking feature structures, which is an automatic optimization method for parsers based on feature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packi</context>
</contexts>
<marker>Kasper, Rounds, 1986</marker>
<rawString>Robert T. Kasper and William C. Rounds. 1986. A logical semantics for feature structures. In Proc. 24th ACL, pages 257-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaki Makino</author>
<author>Minoru Yoshida</author>
<author>Kentaro Torisawa</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>LiLFeS -towards a practical HPSG parser.</title>
<date>1998</date>
<booktitle>In Proc. COLING-ACL &apos;98,</booktitle>
<pages>807--811</pages>
<marker>Makino, Yoshida, Torisawa, Tsujii, 1998</marker>
<rawString>Takaki Makino, Minoru Yoshida, Kentaro Torisawa, and Jun&apos;ichi Tsujii. 1998. LiLFeS -towards a practical HPSG parser. In Proc. COLING-ACL &apos;98, pages 807-811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Kentaro Torisawa</author>
<author>Yuka Tateisi</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Packing of feature structures for optimizing the HPSGstyle grammar translated from TAG.</title>
<date>1998</date>
<booktitle>In Proc. TAG+4 Workshop,</booktitle>
<pages>104--107</pages>
<contexts>
<context position="3033" citStr="Miyao et al., 1998" startWordPosition="432" endWordPosition="435">version method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a suitable form for a simple and efficient unification algorithm which is also described in this paper. Griffith (Griffith, 1995; Griffith, 1996) points out the same problem and proposes a compilation method for feature structures called modularization. However, modularization is very time-consuming, and is not suitable for optimizing feature structures produced during parsing. An earlier paper of myself (Miyao et al., 1998) also discusses the same problem and proposes another packing method. However, that method can pack only pre-specified parts of input feature structures, and this characteristic limits the overall efficient gain. The new method in this paper can pack any kind of feature structures as far as possible, and is more general than the previous method. 2 Data Structure and Algorithms This section describes the data structure of packed feature structures, and the algorithms for packing and unification of packed feature structures. Through of this section, I will refer to examples from the XHPSG system</context>
</contexts>
<marker>Miyao, Torisawa, Tateisi, Tsujii, 1998</marker>
<rawString>Yusuke Miyao, Kentaro Torisawa, Yuka Tateisi, and Jun&apos;ichi Tsujii. 1998. Packing of feature structures for optimizing the HPSGstyle grammar translated from TAG. In Proc. TAG+4 Workshop, pages 104-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikio Nakano</author>
</authors>
<title>Constraint projection: An efficient treatment of disjunctive feature descriptions.</title>
<date>1991</date>
<booktitle>In Proc. 29th ACL,</booktitle>
<pages>307--314</pages>
<contexts>
<context position="2008" citStr="Nakano, 1991" startWordPosition="281" endWordPosition="282">thod for parsers based on feature structure unification. This method automatically extracts equivalent parts of feature structures and collapses them into a single packed feature structure. A packed feature structure can be processed more efficiently because we can avoid redundant repetition of unification of the equivalent parts of original feature structures. There have been many studies on efficient 11n this paper we consider typed feature structures described in (Carpenter, 1992). unification of disjunctive feature structures (Kasper and Rounds, 1986; Hasida, 1986; Dorre and Eisele, 1990; Nakano, 1991; Blache, 1997; Blache, 1998). All of them suppose that disjunctive feature structures should be given by grammar writers or lexicographers. However, it is not practical to specify all ambiguity using only manually-tailored disjunctive feature structures in grammar development. Where disjunctive feature structures cannot be given explicitly those algorithms lose their advantages. Hence, an automatic conversion method, such as the packing method described hereafter, is required for further optimization of those systems. In addition, this packing method converts general feature structures to a s</context>
</contexts>
<marker>Nakano, 1991</marker>
<rawString>Mikio Nakano. 1991. Constraint projection: An efficient treatment of disjunctive feature descriptions. In Proc. 29th ACL, pages 307-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="823" citStr="Pollard and Sag, 1994" startWordPosition="112" endWordPosition="115">n E-mail: yusukais .s .u-tokyo .ac. jp Abstract This paper proposes a method for packing feature structures, which automatically collapses equivalent parts of lexical/phrasal feature structures of HPSG into a single packed feature structure. This method avoids redundant repetition of unification of those parts. Preliminary experiments show that this method can significantly improve a unification speed in parsing. 1 Introduction Efficient treatment of syntactic/semantic ambiguity is a key to making efficient parsers for wide-coverage grammars. In feature-structurebased grammarsl, such as HPSG (Pollard and Sag, 1994), ambiguity is expressed not only by manually-tailored disjunctive feature structures, but also by enumerating non-disjunctive feature structures. In addition, there is ambiguity caused by non-determinism when applying lexical/grammar rules. As a result, a large number of lexical/phrasal feature structures are required to express ambiguous syntactic/semantic structures. Without efficient processing of these feature structures, a sufficient parsing speed is unattainable. This paper proposes a method for packing feature structures, which is an automatic optimization method for parsers based on f</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Kentaro Torisawa</author>
<author>Yusuke Miyao</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Translating the XTAG English grammar to HPSG.</title>
<date>1998</date>
<booktitle>In Proc. TAG+4 Workshop,</booktitle>
<pages>172--175</pages>
<marker>Tateisi, Torisawa, Miyao, Tsujii, 1998</marker>
<rawString>Yuka Tateisi, Kentaro Torisawa, Yusuke Miyao, and Jun&apos;ichi Tsujii. 1998. Translating the XTAG English grammar to HPSG. In Proc. TAG+4 Workshop, pages 172-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Computing phrasal-signs in HPSG prior to parsing.</title>
<date>1996</date>
<booktitle>In Proc. 16th COLING,</booktitle>
<pages>949--955</pages>
<marker>Torisawa, Tsujii, 1996</marker>
<rawString>Kentaro Torisawa and Jun&apos;ichi Tsujii. 1996. Computing phrasal-signs in HPSG prior to parsing. In Proc. 16th COLING, pages 949-955.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>