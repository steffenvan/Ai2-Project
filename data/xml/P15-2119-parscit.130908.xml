<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047993">
<title confidence="0.9932395">
How Well Do Distributional Models Capture
Different Types of Semantic Knowledge?
</title>
<author confidence="0.999161">
Dana Rubinstein Effi Levi Roy Schwartz Ari Rappoport
</author>
<affiliation confidence="0.999497">
Institute of Computer Science, The Hebrew University
</affiliation>
<email confidence="0.991624">
{drubin80,efle,roys02,arir}@cs.huji.ac.il
</email>
<sectionHeader confidence="0.997303" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957666666667">
In recent years, distributional models
(DMs) have shown great success in repre-
senting lexical semantics. In this work we
show that the extent to which DMs rep-
resent semantic knowledge is highly de-
pendent on the type of knowledge. We
pose the task of predicting properties of
concrete nouns in a supervised setting,
and compare between learning taxonomic
properties (e.g., animacy) and attributive
properties (e.g., size, color). We employ
four state-of-the-art DMs as sources of
feature representation for this task, and
show that they all yield poor results when
tested on attributive properties, achieving
no more than an average F-score of 0.37 in
the binary property prediction task, com-
pared to 0.73 on taxonomic properties.
Our results suggest that the distributional
hypothesis may not be equally applicable
to all types of semantic information.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999815068965517">
The Distributional Hypothesis states that the
meaning of words can be inferred from their lin-
guistic environment (Harris, 1954). This hypothe-
sis lies at the heart of distributional models (DMs),
which approximate the meaning of words by con-
sidering the statistics of their co-occurrence with
other words in the lexicon.
DMs have shown impressive results in many
semantic tasks, such as predicting the similarity
of two words, grouping words into semantic cat-
egories, and solving analogy questions (see Ba-
roni et al. (2014) for a recent survey). They are
also used as a source of semantic information by
many downstream applications, including syntac-
tic parsing (Socher et al., 2013), image annotation
(Klein et al., 2014), and semantic frame identifica-
tion (Hermann et al., 2014).
However, the empirical success of DMs may
not be uniform across the full range of semantic
knowledge. It has been argued that DMs can never
grasp the full meaning of words, as many aspects
of meaning are grounded in the physical world
(Andrews et al., 2009). This claim relies chiefly on
cognitive theory (Louwerse, 2011), and is some-
what supported in empirical findings (Baroni and
Lenci, 2008; Andrews et al., 2009). Moreover, a
recent study by (Hill et al., 2014) has shown that
DMs may not model word similarity as well as
previously believed.
In this work, we seek to further study the capa-
bilities of DMs in capturing semantic information.
For our purposes, we assume that the meaning of
a word referring to a concrete object (henceforth
concept) is comprised of a list of properties (Ba-
roni and Lenci, 2008). For example, the mean-
ing of the concept an apple is comprised of such
properties as red, round, edible, a fruit, etc. We
distinguish between taxonomic properties (Wu and
Barsalou, 2001; McRae et al., 2005), which de-
fine the conceptual category that a concept belongs
to (e.g. an apple is a fruit), and all other types
of properties (henceforth referred to as attributive
properties). In this paper we employ DMs in the
task of learning properties of concepts, and show
a very large discrepancy in performance between
learning taxonomic and attributive properties.
Several previous works addressed semantic
property learning, but mostly in terms of automati-
cally extracting salient properties of concepts from
raw text (Almuhareb and Poesio, 2005; Barbu,
2008; Baroni and Lenci, 2008; Devereux et al.,
2009; Baroni et al., 2010; Kelly, 2013). Baroni
and Lenci (2008) is the only work we are aware
of that addressed different property types, while
utilizing a DM for property extraction. However,
their approach is simple, and includes defining the
properties of a concept to be the 10 neighboring
words of that concept in the DM space.
</bodyText>
<page confidence="0.926137">
726
</page>
<bodyText confidence="0.961623470588235">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
In order to determine to what extent proper-
ties of concepts are captured by DMs, we define
the following task. The goal is to predict, for a
given concept, whether it holds a specific prop-
erty or not (e.g., whether or not the concept ele-
phant is considered large) . We model this task as
a learning problem, in which concepts have a fea-
ture representation based on a state-of-the-art DM.
A property-predictor is then trained to predict, for
any given concept, whether the property applies
to it or not (in a binary classification setup), or the
strength of affiliation between the property and the
concept (in a regression setup). By evaluating the
performance of these predictors, we assess the de-
gree to which the property is captured by the DM.
We experiment with four state-of-the-art DMs
(Baroni and Lenci, 2010; Mikolov et al., 2013;
Levy and Goldberg, 2014; Pennington et al.,
2014). Our results show that all DMs, quite suc-
cessful in many semantic tasks, fail when it comes
to predicting attributive properties of concepts.
For example, in the classification task, the best
performing DM achieves an averaged F-score of
only 0.37, contrasted with an average F-score of
0.73 achieved by the same model for taxonomic
properties. This result, which may be attributed
to an essential difference between taxonomic and
attributive properties, demonstrates possible limi-
tations of the distributional hypothesis, at least in
terms of the information captured by current state-
of-the-art DMs.
</bodyText>
<sectionHeader confidence="0.922543" genericHeader="method">
2 Learning Semantic Properties of
Concepts
</sectionHeader>
<bodyText confidence="0.999960571428571">
The goal of this paper is to gain better understand-
ing of the type of information DMs encode. We
do so by evaluating the performance of a predictor
trained on a DM-based representation to learn a
semantic property. In this section, we describe the
proposed learning task, the dataset and the DMs
which serve as feature representations.
</bodyText>
<subsectionHeader confidence="0.983837">
2.1 Task Description
</subsectionHeader>
<bodyText confidence="0.999992125">
We model the problem of learning a single seman-
tic property both as a binary classification problem
and as a regression problem. The binary setup is
simpler, however it may be argued that a regres-
sion setup is more appropriate, since the nature of
the affiliation between a concept and its properties
is not necessarily binary.
Binary Classification. For each property p, we
take concepts for which p applies to be positive
instances, and concepts for which it does not as
negative instances. For example, the property is
loud is positive for a trumpet but negative for a
mouse. Let X denote the domain of concepts,
and Yp = {±1} denote the binary label space.
Then for each property p we learn a predictor
hp : 0(X) → Yp, where 0(X) ⊆ Rn is a map-
ping from the concept domain to some DM space.
Regression. Here we consider the saliency of
a property for a concept and regard it as a real-
valued measure. For example, white is a salient
property of swan, a less salient property of house,
and not a property at all of hammer. The formal
definitions are the same as in the binary classifica-
tion setup, except that here Yp = R.
</bodyText>
<subsectionHeader confidence="0.99845">
2.2 The Data
</subsectionHeader>
<bodyText confidence="0.999983428571428">
We use the McRae Feature Norms dataset (McRae
et al., 2005). This data was collected in a set of ex-
periments, where participants were presented with
concepts (concrete nouns only) and were asked to
write down properties that describe them. This re-
sulted in a matrix of 541 concepts and 2,526 prop-
erties, where each (concept, property) entry holds
the number of participants who elicited the prop-
erty for the concept. This dataset has been widely
used in the past as a proxy to the human percep-
tual representation of concrete objects (Baroni and
Lenci, 2008; Barbu, 2008; Devereux et al., 2009;
Johns and Jones, 2012).
In the binary classification setting, for each
property, we take all concepts for which this prop-
erty was elicited (by any number of participants)1
to be positive, and all other concepts to be nega-
tive. In the regression setting, we take the [0,1]-
scaled number of participants who elicited each
property for a concept to be the real-valued mea-
sure of its saliency for that concept.
</bodyText>
<subsectionHeader confidence="0.969291">
2.3 Distributional Models
</subsectionHeader>
<bodyText confidence="0.9998422">
We experiment with four state-of-the-art DMs as
feature representations for the concept domain.
The models differ with respect to their method
of generation (neural network or transformed co-
occurrence counts) and their consideration of lin-
</bodyText>
<footnote confidence="0.929479333333333">
1Due to a pre-defined threshold applied by McRae et al.
(2005), only properties mentioned by at least 5 participants
are considered positive.
</footnote>
<page confidence="0.990983">
727
</page>
<bodyText confidence="0.9987675">
guistic information (using plain text only, mor-
phology, syntax or pattern information).
word2vec. word2vec (w2v, Mikolov et al.
(2013)) is a neural network model which imple-
ments a language model objective. It has reached
state-of-the-art results for word similarity, catego-
rization and analogy tasks (Baroni et al., 2014).
We use the off-the-shelf 300-dimensional version
trained on a corpus of 100B tokens.2
GloVe. GloVe (gv, Pennington et al. (2014)) is a
log bilinear regression model. The authors report
state-of-the-art results in word similarity, seman-
tic analogies and NER tasks. We use the off-the-
shelf 300-dimensional version trained on a corpus
of 840B tokens.3
Distributional Memory. The Distributional
Memory model (dm, Baroni and Lenci (2010)) is a
co-occurrence based DM, which admits morpho-
logical, structural and pattern information. The
authors have shown that it is highly competitive
with state-of-the-art co-occurrence models in a
range of semantic tasks. We use the off-the-shelf
5K-dimensional version trained on 3B tokens.4
Dependency word2vec. The dependency
word2vec model (dep, Levy and Goldberg (2014))
is a variation of the word2vec model, which
takes into account the dependency links between
words. The authors have shown that it accurately
models word similarity. We use the off-the-shelf
300-dimensional version trained on Wikipedia.5
</bodyText>
<subsectionHeader confidence="0.953787">
2.4 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999385">
In our experiments, we consider properties which
have at least 25 positive instances in the dataset.
We then discard attributive properties that clearly
correspond to a taxonomic property. For exam-
ple, the property has feathers is no different from
the bird category, or the property lives in water is
identical to the fish category. The final list consists
of 7 taxonomic and 13 attributive properties.6
For each property, we learn both a linear SVM
classifier in the binary setup, and a linear SVM re-
gressor in the regression setup. For both setups we
</bodyText>
<footnote confidence="0.963224571428571">
2code.google.com/p/word2vec/
3nlp.stanford.edu/projects/glove/
4clic.cimec.unitn.it/dm/
5levyomer.wordpress.com/2014/04/25/
dependency-based-word-embeddings/
6The average number of positive instances per property is
42 for taxonomic properties and 61 for attributive properties.
</footnote>
<bodyText confidence="0.999830714285714">
use the lib-svm package (Chang and Lin, 2011)7
and follow a 5-fold cross-validation protocol.
In the binary setup, we report F-scores only, as
accuracy measures tend to be misleading due to
an unbalanced label distribution. In the regression
setup, we report Pearson’s correlation scores be-
tween predicted values and gold standard values.
</bodyText>
<sectionHeader confidence="0.660983" genericHeader="evaluation">
2.5 Results
</sectionHeader>
<bodyText confidence="0.999954958333333">
Table 1 shows our results in the binary setup (left
side) and in the regression setup (right side) for all
models. We display average scores separately for
taxonomic and attributive properties.
The results for the binary setup show a rather
low performance on learning attributive proper-
ties, attaining an average F-score of no more than
0.37 (dep model). This is emphasized when com-
pared to the average performance on taxonomic
properties, which is 0.73 for dep, and can be as
high as 0.78 (w2v). The regression setup shows a
similar trend; the average correlation for attribu-
tive properties is at most 0.28 (dep), compared to
0.59 for taxonomic properties.
While linear Support Vectors are a well-
established method for classification and regres-
sion, we have attempted the same experiments
with several other methods, including K-Nearest-
Neighbors and Decision Trees for classification,
and simple Least Squares for regression. In all
cases, the results were found to be inferior to the
ones obtained by the Support Vectors, while main-
taining the discrepancy in performance between
taxonomic and attributive property learning.
</bodyText>
<sectionHeader confidence="0.999717" genericHeader="conclusions">
3 Discussion
</sectionHeader>
<bodyText confidence="0.999886466666667">
Our results show that there is a great difference
between the performance of DMs when used to
predict taxonomic and attributive properties. Con-
cretely, four state-of-the-art DMs fail to predict at-
tributive properties, implying that even if the prop-
erty information is indicated in text, it is signaled
very weakly, at least by means of linguistic regu-
larities captured by current, state-of-the-art DMs.
Our findings are in line with previous work,
such as (Baroni and Lenci, 2008), who demon-
strated that taxonomic properties are more dom-
inant in text compared to attributive properties.
This suggests that the distributional hypothesis
may not be equally applicable to all types of se-
mantic information, and in particular, it may be
</bodyText>
<footnote confidence="0.970878">
7www.csie.ntu.edu.tw/˜cjlin/libsvm
</footnote>
<page confidence="0.988062">
728
</page>
<table confidence="0.999136125">
Property Binary Classification Regression
w2v gv dm dep w2v gv dm dep
Attributive Taxonomic a bird 0.83 0.86 0.78 0.71 0.63 0.63 0.39 0.57
a fruit 0.86 0.8 0.72 0.6 0.66 0.69 0.57 0.55
a mammal 0.71 0.69 0.65 0.73 0.47 0.44 0.46 0.41
a vegetable 0.74 0.81 0.75 0.7 0.65 0.69 0.54 0.56
a weapon 0.72 0.64 0.67 0.77 0.61 0.58 0.48 0.58
an animal 0.8 0.77 0.74 0.82 0.79 0.73 0.51 0.78
clothing 0.81 0.84 0.64 0.81 0.63 0.69 0.36 0.67
Average 0.78 0.77 0.71 0.73 0.63 0.64 0.47 0.59
of different colors 0.44 0.41 0.33 0.46 0.36 0.32 0.22 0.38
is black 0.24 0.2 0.17 0.22 0.09 0.17 0.13 0.15
is brown 0.28 0.23 0.29 0.33 0.25 0.25 0.16 0.27
is green 0.4 0.4 0.45 0.44 0.28 0.24 0.28 0.39
is white 0.19 0.22 0.11 0.2 0.06 0.1 0.06 0.15
is yellow 0.21 0.14 0.15 0.21 0.12 0.15 0.12 0.23
is large 0.4 0.41 0.42 0.44 0.39 0.34 0.38 0.33
is small 0.43 0.4 0.43 0.48 0.29 0.21 0.25 0.31
is long 0.31 0.24 0.31 0.36 0.24 0.03 0.14 0.27
is round 0.29 0.3 0.29 0.43 0.22 0.15 0.24 0.28
is loud 0.35 0.27 0.3 0.36 0.33 0.25 0.15 0.23
is dangerous 0.45 0.47 0.49 0.5 0.32 0.3 0.25 0.41
is fast 0.41 0.34 0.29 0.35 0.33 0.32 0.19 0.26
Average 0.34 0.31 0.31 0.37 0.25 0.22 0.2 0.28
</table>
<tableCaption confidence="0.995627">
Table 1: Results for the Property Learning Task. On the left: F-scores for the binary classification task.
</tableCaption>
<bodyText confidence="0.985227404255319">
On the right: Pearson correlation scores for the regression task.
limited with respect to attributive properties.
An interesting observation is found in the rela-
tive success of DMs in predicting taxonomic prop-
erties. This result, in line with past research,
e.g. (Schwartz et al., 2014), may be explained
by considering taxonomic properties as a rich ag-
gregate of attributive properties (Baroni and Lenci,
2010). For example, animals usually have legs and
mouths, they make sounds, they can be killed, etc.
This is contrasted with attributive properties such
as is white, whose members do not have much in
common, other than the property itself. We there-
fore hypothesize that although attributive proper-
ties may be signaled very weakly in text, as our
results indicate, their accumulation is sufficient to
distinguish concepts that share most of them from
concepts that do not.
To demonstrate this, we turned back to the
McRae dataset. For each property, we observed
the vector of its values across all concepts in the
dataset. We then found its 5 nearest neighbors
in terms of correlation, and computed the average
correlation with these neighbors, denoted c. Next,
we compared the averaged c value for taxonomic
properties with that of attributive properties. Taxo-
nomic properties show an average c value of 0.62,
compared to 0.32 only for attributive properties.
This supports our hypothesis that members of tax-
onomic properties are similar to each other in var-
ious aspects, while members of attributive proper-
ties are much less so. This finding may provide
a partial explanation as to why taxonomic proper-
ties are more easily learned compared to attribu-
tive properties, as demonstrated in this paper.
To conclude, we have shown that in the con-
text of learning semantic properties, state-of-the-
art distributional models perform differently with
respect to the type of property learned. Our results
serve as a basis for establishing the limitations to
the distributional hypothesis. As future work we
propose to further investigate the nature of the dis-
tributional hypothesis in its manifestation as DMs,
possibly by considering a more fine grained dis-
tinction between property types. For example, we
intend to compare the performance between prop-
erties grounded in the physical world, like colors
</bodyText>
<page confidence="0.993481">
729
</page>
<bodyText confidence="0.665755666666667">
or size, and more abstract properties such as dan-
gerous or cute.
Karl Moritz Hermann, Dipanjan Das, Jason Weston,
and Kuzman Ganchev. 2014. Semantic frame iden-
tification with distributed word representations. In
Proceedings ofACL.
</bodyText>
<sectionHeader confidence="0.959116" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999357">
We would like to thank Roi Reichart for his care-
ful reading and helpful comments. This research
was funded (in part) by the Intel Collaborative
Research Institute for Computational Intelligence
(ICRI-CI).
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999574738636364">
Abdulrahman Almuhareb and Massimo Poesio. 2005.
Concept learning and categorization from the web.
In Proc. of CogSci.
Mark Andrews, Gabriella Vigliocco, and David Vin-
son. 2009. Integrating experiential and distribu-
tional data to learn semantic representations. Psy-
chological review, 116(3):463.
Eduard Barbu. 2008. Combining methods to learn
feature-norm-like concept descriptions. In Proceed-
ings of the ESSLLI Workshop on Distributional Lex-
ical Semantics, pages 9–16.
Marco Baroni and Alessandro Lenci. 2008. Concepts
and properties in word spaces. Italian Journal of
Linguistics, 20(1):55–88.
Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional memory: A general framework for
corpus-based semantics. Computational Linguis-
tics, 36(4):673–721.
Marco Baroni, Brian Murphy, Eduard Barbu, and Mas-
simo Poesio. 2010. Strudel: A corpus-based seman-
tic model based on properties and types. Cognitive
Science, 34(2):222–254.
Marco Baroni, Georgiana Dinu, and Germ´an
Kruszewski. 2014. Dont count, predict! a
systematic comparison of context-counting vs.
context-predicting semantic vectors. In Proceedings
of the 52nd Annual Meeting of the Association
for Computational Linguistics, volume 1, pages
238–247.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technol-
ogy, 2:27:1–27:27. Software available at http://
www.csie.ntu.edu.tw/˜cjlin/libsvm.
Barry Devereux, Nicholas Pilkington, Thierry Poibeau,
and Anna Korhonen. 2009. Towards unrestricted,
large-scale acquisition of feature-based conceptual
representations from corpus data. Research on Lan-
guage and Computation, 7(2-4):137–170.
Felix Hill, Roi Reichart, and Anna Korhonen. 2014.
Simlex-999: Evaluating semantic models with
(genuine) similarity estimation. arXiv preprint
arXiv:1408.3456.
Brendan T Johns and Michael N Jones. 2012. Per-
ceptual inference through global lexical similarity.
Topics in Cognitive Science, 4(1):103–120.
Colin Kelly. 2013. Automatic extraction of property
norm-like data from large text corpora.
Benjamin Klein, Guy Lev, Gil Sadeh, and Lior Wolf.
2014. Fisher vectors derived from hybrid gaussian-
laplacian mixture models for image annotation.
arXiv preprint arXiv:1411.7399.
Omer Levy and Yoav Goldberg. 2014. Dependen-
cybased word embeddings. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics, volume 2, pages 302–308.
Max M Louwerse. 2011. Symbol interdependency in
symbolic and embodied cognition. Topics in Cogni-
tive Science, 3(2):273–302.
Ken McRae, George S Cree, Mark S Seidenberg, and
Chris McNorgan. 2005. Semantic feature produc-
tion norms for a large set of living and nonliving
things. Behavior research methods, 37(4):547–559.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.
Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Proc. of EMNLP.
Roy Schwartz, Roi Reichart, and Ari Rappoport. 2014.
Minimally supervised classification to semantic cat-
egories using automatically acquired symmetric pat-
terns. In Proceedings of COLING 2014, the 25th In-
ternational Conference on Computational Linguis-
tics: Technical Papers, pages 1612–1623, Dublin,
Ireland, August. Dublin City University and Associ-
ation for Computational Linguistics.
Richard Socher, John Bauer, Christopher D Manning,
and Andrew Y Ng. 2013. Parsing with composi-
tional vector grammars. In In Proceedings of the
ACL conference. Citeseer.
Ling-Ling Wu and Lawrence W Barsalou. 2001.
Grounding concepts in perceptual simulation: I: Ev-
idence from property generation. Under review
http://userwww. service. emory. edu/˜ barsalou.
Zellig S Harris. 1954. Distributional structure. Word.
</reference>
<page confidence="0.997216">
730
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.887575">
<title confidence="0.99647">How Well Do Distributional Models Different Types of Semantic Knowledge?</title>
<author confidence="0.999328">Dana Rubinstein Effi Levi Roy Schwartz Ari Rappoport</author>
<affiliation confidence="0.912716">Institute of Computer Science, The Hebrew</affiliation>
<abstract confidence="0.999034727272727">In recent years, distributional models (DMs) have shown great success in representing lexical semantics. In this work we show that the extent to which DMs represent semantic knowledge is highly dependent on the type of knowledge. We pose the task of predicting properties of concrete nouns in a supervised setting, and compare between learning taxonomic (e.g., and attributive (e.g., We employ four state-of-the-art DMs as sources of feature representation for this task, and show that they all yield poor results when tested on attributive properties, achieving no more than an average F-score of 0.37 in the binary property prediction task, compared to 0.73 on taxonomic properties. Our results suggest that the distributional hypothesis may not be equally applicable to all types of semantic information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abdulrahman Almuhareb</author>
<author>Massimo Poesio</author>
</authors>
<title>Concept learning and categorization from the web.</title>
<date>2005</date>
<booktitle>In Proc. of CogSci.</booktitle>
<contexts>
<context position="3448" citStr="Almuhareb and Poesio, 2005" startWordPosition="542" endWordPosition="545">e distinguish between taxonomic properties (Wu and Barsalou, 2001; McRae et al., 2005), which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, Chin</context>
</contexts>
<marker>Almuhareb, Poesio, 2005</marker>
<rawString>Abdulrahman Almuhareb and Massimo Poesio. 2005. Concept learning and categorization from the web. In Proc. of CogSci.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Andrews</author>
<author>Gabriella Vigliocco</author>
<author>David Vinson</author>
</authors>
<title>Integrating experiential and distributional data to learn semantic representations. Psychological review,</title>
<date>2009</date>
<pages>116--3</pages>
<contexts>
<context position="2144" citStr="Andrews et al., 2009" startWordPosition="329" endWordPosition="332">o words, grouping words into semantic categories, and solving analogy questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept a</context>
</contexts>
<marker>Andrews, Vigliocco, Vinson, 2009</marker>
<rawString>Mark Andrews, Gabriella Vigliocco, and David Vinson. 2009. Integrating experiential and distributional data to learn semantic representations. Psychological review, 116(3):463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Barbu</author>
</authors>
<title>Combining methods to learn feature-norm-like concept descriptions.</title>
<date>2008</date>
<booktitle>In Proceedings of the ESSLLI Workshop on Distributional Lexical Semantics,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="3461" citStr="Barbu, 2008" startWordPosition="546" endWordPosition="547">mic properties (Wu and Barsalou, 2001; McRae et al., 2005), which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, China, July 26-31</context>
<context position="7715" citStr="Barbu, 2008" startWordPosition="1265" endWordPosition="1266">up, except that here Yp = R. 2.2 The Data We use the McRae Feature Norms dataset (McRae et al., 2005). This data was collected in a set of experiments, where participants were presented with concepts (concrete nouns only) and were asked to write down properties that describe them. This resulted in a matrix of 541 concepts and 2,526 properties, where each (concept, property) entry holds the number of participants who elicited the property for the concept. This dataset has been widely used in the past as a proxy to the human perceptual representation of concrete objects (Baroni and Lenci, 2008; Barbu, 2008; Devereux et al., 2009; Johns and Jones, 2012). In the binary classification setting, for each property, we take all concepts for which this property was elicited (by any number of participants)1 to be positive, and all other concepts to be negative. In the regression setting, we take the [0,1]- scaled number of participants who elicited each property for a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect to their metho</context>
</contexts>
<marker>Barbu, 2008</marker>
<rawString>Eduard Barbu. 2008. Combining methods to learn feature-norm-like concept descriptions. In Proceedings of the ESSLLI Workshop on Distributional Lexical Semantics, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>Concepts and properties in word spaces.</title>
<date>2008</date>
<journal>Italian Journal of Linguistics,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="2281" citStr="Baroni and Lenci, 2008" startWordPosition="350" endWordPosition="353"> also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a fruit, etc. We distinguish between taxonomic properties (Wu and Barsalou</context>
<context position="3568" citStr="Baroni and Lenci (2008)" startWordPosition="562" endWordPosition="565">y that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics In order to determine to what extent properties of</context>
<context position="7702" citStr="Baroni and Lenci, 2008" startWordPosition="1261" endWordPosition="1264">inary classification setup, except that here Yp = R. 2.2 The Data We use the McRae Feature Norms dataset (McRae et al., 2005). This data was collected in a set of experiments, where participants were presented with concepts (concrete nouns only) and were asked to write down properties that describe them. This resulted in a matrix of 541 concepts and 2,526 properties, where each (concept, property) entry holds the number of participants who elicited the property for the concept. This dataset has been widely used in the past as a proxy to the human perceptual representation of concrete objects (Baroni and Lenci, 2008; Barbu, 2008; Devereux et al., 2009; Johns and Jones, 2012). In the binary classification setting, for each property, we take all concepts for which this property was elicited (by any number of participants)1 to be positive, and all other concepts to be negative. In the regression setting, we take the [0,1]- scaled number of participants who elicited each property for a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect t</context>
<context position="12754" citStr="Baroni and Lenci, 2008" startWordPosition="2029" endWordPosition="2032">ned by the Support Vectors, while maintaining the discrepancy in performance between taxonomic and attributive property learning. 3 Discussion Our results show that there is a great difference between the performance of DMs when used to predict taxonomic and attributive properties. Concretely, four state-of-the-art DMs fail to predict attributive properties, implying that even if the property information is indicated in text, it is signaled very weakly, at least by means of linguistic regularities captured by current, state-of-the-art DMs. Our findings are in line with previous work, such as (Baroni and Lenci, 2008), who demonstrated that taxonomic properties are more dominant in text compared to attributive properties. This suggests that the distributional hypothesis may not be equally applicable to all types of semantic information, and in particular, it may be 7www.csie.ntu.edu.tw/˜cjlin/libsvm 728 Property Binary Classification Regression w2v gv dm dep w2v gv dm dep Attributive Taxonomic a bird 0.83 0.86 0.78 0.71 0.63 0.63 0.39 0.57 a fruit 0.86 0.8 0.72 0.6 0.66 0.69 0.57 0.55 a mammal 0.71 0.69 0.65 0.73 0.47 0.44 0.46 0.41 a vegetable 0.74 0.81 0.75 0.7 0.65 0.69 0.54 0.56 a weapon 0.72 0.64 0.67</context>
</contexts>
<marker>Baroni, Lenci, 2008</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2008. Concepts and properties in word spaces. Italian Journal of Linguistics, 20(1):55–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>Distributional memory: A general framework for corpus-based semantics.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<contexts>
<context position="4934" citStr="Baroni and Lenci, 2010" startWordPosition="786" endWordPosition="789">r not (e.g., whether or not the concept elephant is considered large) . We model this task as a learning problem, in which concepts have a feature representation based on a state-of-the-art DM. A property-predictor is then trained to predict, for any given concept, whether the property applies to it or not (in a binary classification setup), or the strength of affiliation between the property and the concept (in a regression setup). By evaluating the performance of these predictors, we assess the degree to which the property is captured by the DM. We experiment with four state-of-the-art DMs (Baroni and Lenci, 2010; Mikolov et al., 2013; Levy and Goldberg, 2014; Pennington et al., 2014). Our results show that all DMs, quite successful in many semantic tasks, fail when it comes to predicting attributive properties of concepts. For example, in the classification task, the best performing DM achieves an averaged F-score of only 0.37, contrasted with an average F-score of 0.73 achieved by the same model for taxonomic properties. This result, which may be attributed to an essential difference between taxonomic and attributive properties, demonstrates possible limitations of the distributional hypothesis, at </context>
<context position="9315" citStr="Baroni and Lenci (2010)" startWordPosition="1511" endWordPosition="1514">)) is a neural network model which implements a language model objective. It has reached state-of-the-art results for word similarity, categorization and analogy tasks (Baroni et al., 2014). We use the off-the-shelf 300-dimensional version trained on a corpus of 100B tokens.2 GloVe. GloVe (gv, Pennington et al. (2014)) is a log bilinear regression model. The authors report state-of-the-art results in word similarity, semantic analogies and NER tasks. We use the off-theshelf 300-dimensional version trained on a corpus of 840B tokens.3 Distributional Memory. The Distributional Memory model (dm, Baroni and Lenci (2010)) is a co-occurrence based DM, which admits morphological, structural and pattern information. The authors have shown that it is highly competitive with state-of-the-art co-occurrence models in a range of semantic tasks. We use the off-the-shelf 5K-dimensional version trained on 3B tokens.4 Dependency word2vec. The dependency word2vec model (dep, Levy and Goldberg (2014)) is a variation of the word2vec model, which takes into account the dependency links between words. The authors have shown that it accurately models word similarity. We use the off-the-shelf 300-dimensional version trained on </context>
<context position="14730" citStr="Baroni and Lenci, 2010" startWordPosition="2384" endWordPosition="2387">0.25 0.41 is fast 0.41 0.34 0.29 0.35 0.33 0.32 0.19 0.26 Average 0.34 0.31 0.31 0.37 0.25 0.22 0.2 0.28 Table 1: Results for the Property Learning Task. On the left: F-scores for the binary classification task. On the right: Pearson correlation scores for the regression task. limited with respect to attributive properties. An interesting observation is found in the relative success of DMs in predicting taxonomic properties. This result, in line with past research, e.g. (Schwartz et al., 2014), may be explained by considering taxonomic properties as a rich aggregate of attributive properties (Baroni and Lenci, 2010). For example, animals usually have legs and mouths, they make sounds, they can be killed, etc. This is contrasted with attributive properties such as is white, whose members do not have much in common, other than the property itself. We therefore hypothesize that although attributive properties may be signaled very weakly in text, as our results indicate, their accumulation is sufficient to distinguish concepts that share most of them from concepts that do not. To demonstrate this, we turned back to the McRae dataset. For each property, we observed the vector of its values across all concepts</context>
</contexts>
<marker>Baroni, Lenci, 2010</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2010. Distributional memory: A general framework for corpus-based semantics. Computational Linguistics, 36(4):673–721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Brian Murphy</author>
<author>Eduard Barbu</author>
<author>Massimo Poesio</author>
</authors>
<title>Strudel: A corpus-based semantic model based on properties and types.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="3529" citStr="Baroni et al., 2010" startWordPosition="556" endWordPosition="559">which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics In order to</context>
</contexts>
<marker>Baroni, Murphy, Barbu, Poesio, 2010</marker>
<rawString>Marco Baroni, Brian Murphy, Eduard Barbu, and Massimo Poesio. 2010. Strudel: A corpus-based semantic model based on properties and types. Cognitive Science, 34(2):222–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Georgiana Dinu</author>
<author>Germ´an Kruszewski</author>
</authors>
<title>Dont count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>238--247</pages>
<contexts>
<context position="1628" citStr="Baroni et al. (2014)" startWordPosition="241" endWordPosition="245">nal hypothesis may not be equally applicable to all types of semantic information. 1 Introduction The Distributional Hypothesis states that the meaning of words can be inferred from their linguistic environment (Harris, 1954). This hypothesis lies at the heart of distributional models (DMs), which approximate the meaning of words by considering the statistics of their co-occurrence with other words in the lexicon. DMs have shown impressive results in many semantic tasks, such as predicting the similarity of two words, grouping words into semantic categories, and solving analogy questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat su</context>
<context position="8881" citStr="Baroni et al., 2014" startWordPosition="1446" endWordPosition="1449"> domain. The models differ with respect to their method of generation (neural network or transformed cooccurrence counts) and their consideration of lin1Due to a pre-defined threshold applied by McRae et al. (2005), only properties mentioned by at least 5 participants are considered positive. 727 guistic information (using plain text only, morphology, syntax or pattern information). word2vec. word2vec (w2v, Mikolov et al. (2013)) is a neural network model which implements a language model objective. It has reached state-of-the-art results for word similarity, categorization and analogy tasks (Baroni et al., 2014). We use the off-the-shelf 300-dimensional version trained on a corpus of 100B tokens.2 GloVe. GloVe (gv, Pennington et al. (2014)) is a log bilinear regression model. The authors report state-of-the-art results in word similarity, semantic analogies and NER tasks. We use the off-theshelf 300-dimensional version trained on a corpus of 840B tokens.3 Distributional Memory. The Distributional Memory model (dm, Baroni and Lenci (2010)) is a co-occurrence based DM, which admits morphological, structural and pattern information. The authors have shown that it is highly competitive with state-of-the-</context>
</contexts>
<marker>Baroni, Dinu, Kruszewski, 2014</marker>
<rawString>Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski. 2014. Dont count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 1, pages 238–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<note>Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="10828" citStr="Chang and Lin, 2011" startWordPosition="1726" endWordPosition="1729">category, or the property lives in water is identical to the fish category. The final list consists of 7 taxonomic and 13 attributive properties.6 For each property, we learn both a linear SVM classifier in the binary setup, and a linear SVM regressor in the regression setup. For both setups we 2code.google.com/p/word2vec/ 3nlp.stanford.edu/projects/glove/ 4clic.cimec.unitn.it/dm/ 5levyomer.wordpress.com/2014/04/25/ dependency-based-word-embeddings/ 6The average number of positive instances per property is 42 for taxonomic properties and 61 for attributive properties. use the lib-svm package (Chang and Lin, 2011)7 and follow a 5-fold cross-validation protocol. In the binary setup, we report F-scores only, as accuracy measures tend to be misleading due to an unbalanced label distribution. In the regression setup, we report Pearson’s correlation scores between predicted values and gold standard values. 2.5 Results Table 1 shows our results in the binary setup (left side) and in the regression setup (right side) for all models. We display average scores separately for taxonomic and attributive properties. The results for the binary setup show a rather low performance on learning attributive properties, a</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Devereux</author>
<author>Nicholas Pilkington</author>
<author>Thierry Poibeau</author>
<author>Anna Korhonen</author>
</authors>
<title>Towards unrestricted, large-scale acquisition of feature-based conceptual representations from corpus data.</title>
<date>2009</date>
<journal>Research on Language and Computation,</journal>
<pages>7--2</pages>
<contexts>
<context position="3508" citStr="Devereux et al., 2009" startWordPosition="552" endWordPosition="555">; McRae et al., 2005), which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Li</context>
<context position="7738" citStr="Devereux et al., 2009" startWordPosition="1267" endWordPosition="1270">at here Yp = R. 2.2 The Data We use the McRae Feature Norms dataset (McRae et al., 2005). This data was collected in a set of experiments, where participants were presented with concepts (concrete nouns only) and were asked to write down properties that describe them. This resulted in a matrix of 541 concepts and 2,526 properties, where each (concept, property) entry holds the number of participants who elicited the property for the concept. This dataset has been widely used in the past as a proxy to the human perceptual representation of concrete objects (Baroni and Lenci, 2008; Barbu, 2008; Devereux et al., 2009; Johns and Jones, 2012). In the binary classification setting, for each property, we take all concepts for which this property was elicited (by any number of participants)1 to be positive, and all other concepts to be negative. In the regression setting, we take the [0,1]- scaled number of participants who elicited each property for a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect to their method of generation (neural</context>
</contexts>
<marker>Devereux, Pilkington, Poibeau, Korhonen, 2009</marker>
<rawString>Barry Devereux, Nicholas Pilkington, Thierry Poibeau, and Anna Korhonen. 2009. Towards unrestricted, large-scale acquisition of feature-based conceptual representations from corpus data. Research on Language and Computation, 7(2-4):137–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Felix Hill</author>
<author>Roi Reichart</author>
<author>Anna Korhonen</author>
</authors>
<title>Simlex-999: Evaluating semantic models with (genuine) similarity estimation. arXiv preprint arXiv:1408.3456.</title>
<date>2014</date>
<contexts>
<context position="2353" citStr="Hill et al., 2014" startWordPosition="363" endWordPosition="366">ns, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a fruit, etc. We distinguish between taxonomic properties (Wu and Barsalou, 2001; McRae et al., 2005), which define the conceptual category that a</context>
</contexts>
<marker>Hill, Reichart, Korhonen, 2014</marker>
<rawString>Felix Hill, Roi Reichart, and Anna Korhonen. 2014. Simlex-999: Evaluating semantic models with (genuine) similarity estimation. arXiv preprint arXiv:1408.3456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan T Johns</author>
<author>Michael N Jones</author>
</authors>
<title>Perceptual inference through global lexical similarity.</title>
<date>2012</date>
<journal>Topics in Cognitive Science,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="7762" citStr="Johns and Jones, 2012" startWordPosition="1271" endWordPosition="1274"> Data We use the McRae Feature Norms dataset (McRae et al., 2005). This data was collected in a set of experiments, where participants were presented with concepts (concrete nouns only) and were asked to write down properties that describe them. This resulted in a matrix of 541 concepts and 2,526 properties, where each (concept, property) entry holds the number of participants who elicited the property for the concept. This dataset has been widely used in the past as a proxy to the human perceptual representation of concrete objects (Baroni and Lenci, 2008; Barbu, 2008; Devereux et al., 2009; Johns and Jones, 2012). In the binary classification setting, for each property, we take all concepts for which this property was elicited (by any number of participants)1 to be positive, and all other concepts to be negative. In the regression setting, we take the [0,1]- scaled number of participants who elicited each property for a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect to their method of generation (neural network or transformed </context>
</contexts>
<marker>Johns, Jones, 2012</marker>
<rawString>Brendan T Johns and Michael N Jones. 2012. Perceptual inference through global lexical similarity. Topics in Cognitive Science, 4(1):103–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Kelly</author>
</authors>
<title>Automatic extraction of property norm-like data from large text corpora.</title>
<date>2013</date>
<contexts>
<context position="3543" citStr="Kelly, 2013" startWordPosition="560" endWordPosition="561">eptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009; Baroni et al., 2010; Kelly, 2013). Baroni and Lenci (2008) is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction. However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space. 726 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 726–730, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics In order to determine to </context>
</contexts>
<marker>Kelly, 2013</marker>
<rawString>Colin Kelly. 2013. Automatic extraction of property norm-like data from large text corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Klein</author>
<author>Guy Lev</author>
<author>Gil Sadeh</author>
<author>Lior Wolf</author>
</authors>
<title>Fisher vectors derived from hybrid gaussianlaplacian mixture models for image annotation. arXiv preprint arXiv:1411.7399.</title>
<date>2014</date>
<contexts>
<context position="1827" citStr="Klein et al., 2014" startWordPosition="274" endWordPosition="277">nvironment (Harris, 1954). This hypothesis lies at the heart of distributional models (DMs), which approximate the meaning of words by considering the statistics of their co-occurrence with other words in the lexicon. DMs have shown impressive results in many semantic tasks, such as predicting the similarity of two words, grouping words into semantic categories, and solving analogy questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously be</context>
</contexts>
<marker>Klein, Lev, Sadeh, Wolf, 2014</marker>
<rawString>Benjamin Klein, Guy Lev, Gil Sadeh, and Lior Wolf. 2014. Fisher vectors derived from hybrid gaussianlaplacian mixture models for image annotation. arXiv preprint arXiv:1411.7399.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omer Levy</author>
<author>Yoav Goldberg</author>
</authors>
<title>Dependencybased word embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>302--308</pages>
<contexts>
<context position="4981" citStr="Levy and Goldberg, 2014" startWordPosition="794" endWordPosition="797">nt is considered large) . We model this task as a learning problem, in which concepts have a feature representation based on a state-of-the-art DM. A property-predictor is then trained to predict, for any given concept, whether the property applies to it or not (in a binary classification setup), or the strength of affiliation between the property and the concept (in a regression setup). By evaluating the performance of these predictors, we assess the degree to which the property is captured by the DM. We experiment with four state-of-the-art DMs (Baroni and Lenci, 2010; Mikolov et al., 2013; Levy and Goldberg, 2014; Pennington et al., 2014). Our results show that all DMs, quite successful in many semantic tasks, fail when it comes to predicting attributive properties of concepts. For example, in the classification task, the best performing DM achieves an averaged F-score of only 0.37, contrasted with an average F-score of 0.73 achieved by the same model for taxonomic properties. This result, which may be attributed to an essential difference between taxonomic and attributive properties, demonstrates possible limitations of the distributional hypothesis, at least in terms of the information captured by c</context>
<context position="9688" citStr="Levy and Goldberg (2014)" startWordPosition="1564" endWordPosition="1567">ort state-of-the-art results in word similarity, semantic analogies and NER tasks. We use the off-theshelf 300-dimensional version trained on a corpus of 840B tokens.3 Distributional Memory. The Distributional Memory model (dm, Baroni and Lenci (2010)) is a co-occurrence based DM, which admits morphological, structural and pattern information. The authors have shown that it is highly competitive with state-of-the-art co-occurrence models in a range of semantic tasks. We use the off-the-shelf 5K-dimensional version trained on 3B tokens.4 Dependency word2vec. The dependency word2vec model (dep, Levy and Goldberg (2014)) is a variation of the word2vec model, which takes into account the dependency links between words. The authors have shown that it accurately models word similarity. We use the off-the-shelf 300-dimensional version trained on Wikipedia.5 2.4 Experimental Setup In our experiments, we consider properties which have at least 25 positive instances in the dataset. We then discard attributive properties that clearly correspond to a taxonomic property. For example, the property has feathers is no different from the bird category, or the property lives in water is identical to the fish category. The </context>
</contexts>
<marker>Levy, Goldberg, 2014</marker>
<rawString>Omer Levy and Yoav Goldberg. 2014. Dependencybased word embeddings. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 2, pages 302–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max M Louwerse</author>
</authors>
<title>Symbol interdependency in symbolic and embodied cognition.</title>
<date>2011</date>
<journal>Topics in Cognitive Science,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="2208" citStr="Louwerse, 2011" startWordPosition="340" endWordPosition="341">questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a</context>
</contexts>
<marker>Louwerse, 2011</marker>
<rawString>Max M Louwerse. 2011. Symbol interdependency in symbolic and embodied cognition. Topics in Cognitive Science, 3(2):273–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken McRae</author>
<author>George S Cree</author>
<author>Mark S Seidenberg</author>
<author>Chris McNorgan</author>
</authors>
<title>Semantic feature production norms for a large set of living and nonliving things. Behavior research methods,</title>
<date>2005</date>
<pages>37--4</pages>
<contexts>
<context position="2908" citStr="McRae et al., 2005" startWordPosition="459" endWordPosition="462">s et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a fruit, etc. We distinguish between taxonomic properties (Wu and Barsalou, 2001; McRae et al., 2005), which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; Devereux et al., 2009</context>
<context position="7205" citStr="McRae et al., 2005" startWordPosition="1176" endWordPosition="1179">. Let X denote the domain of concepts, and Yp = {±1} denote the binary label space. Then for each property p we learn a predictor hp : 0(X) → Yp, where 0(X) ⊆ Rn is a mapping from the concept domain to some DM space. Regression. Here we consider the saliency of a property for a concept and regard it as a realvalued measure. For example, white is a salient property of swan, a less salient property of house, and not a property at all of hammer. The formal definitions are the same as in the binary classification setup, except that here Yp = R. 2.2 The Data We use the McRae Feature Norms dataset (McRae et al., 2005). This data was collected in a set of experiments, where participants were presented with concepts (concrete nouns only) and were asked to write down properties that describe them. This resulted in a matrix of 541 concepts and 2,526 properties, where each (concept, property) entry holds the number of participants who elicited the property for the concept. This dataset has been widely used in the past as a proxy to the human perceptual representation of concrete objects (Baroni and Lenci, 2008; Barbu, 2008; Devereux et al., 2009; Johns and Jones, 2012). In the binary classification setting, for</context>
<context position="8475" citStr="McRae et al. (2005)" startWordPosition="1386" endWordPosition="1389"> property was elicited (by any number of participants)1 to be positive, and all other concepts to be negative. In the regression setting, we take the [0,1]- scaled number of participants who elicited each property for a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect to their method of generation (neural network or transformed cooccurrence counts) and their consideration of lin1Due to a pre-defined threshold applied by McRae et al. (2005), only properties mentioned by at least 5 participants are considered positive. 727 guistic information (using plain text only, morphology, syntax or pattern information). word2vec. word2vec (w2v, Mikolov et al. (2013)) is a neural network model which implements a language model objective. It has reached state-of-the-art results for word similarity, categorization and analogy tasks (Baroni et al., 2014). We use the off-the-shelf 300-dimensional version trained on a corpus of 100B tokens.2 GloVe. GloVe (gv, Pennington et al. (2014)) is a log bilinear regression model. The authors report state-o</context>
</contexts>
<marker>McRae, Cree, Seidenberg, McNorgan, 2005</marker>
<rawString>Ken McRae, George S Cree, Mark S Seidenberg, and Chris McNorgan. 2005. Semantic feature production norms for a large set of living and nonliving things. Behavior research methods, 37(4):547–559.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="4956" citStr="Mikolov et al., 2013" startWordPosition="790" endWordPosition="793">not the concept elephant is considered large) . We model this task as a learning problem, in which concepts have a feature representation based on a state-of-the-art DM. A property-predictor is then trained to predict, for any given concept, whether the property applies to it or not (in a binary classification setup), or the strength of affiliation between the property and the concept (in a regression setup). By evaluating the performance of these predictors, we assess the degree to which the property is captured by the DM. We experiment with four state-of-the-art DMs (Baroni and Lenci, 2010; Mikolov et al., 2013; Levy and Goldberg, 2014; Pennington et al., 2014). Our results show that all DMs, quite successful in many semantic tasks, fail when it comes to predicting attributive properties of concepts. For example, in the classification task, the best performing DM achieves an averaged F-score of only 0.37, contrasted with an average F-score of 0.73 achieved by the same model for taxonomic properties. This result, which may be attributed to an essential difference between taxonomic and attributive properties, demonstrates possible limitations of the distributional hypothesis, at least in terms of the </context>
<context position="8693" citStr="Mikolov et al. (2013)" startWordPosition="1417" endWordPosition="1420">r a concept to be the real-valued measure of its saliency for that concept. 2.3 Distributional Models We experiment with four state-of-the-art DMs as feature representations for the concept domain. The models differ with respect to their method of generation (neural network or transformed cooccurrence counts) and their consideration of lin1Due to a pre-defined threshold applied by McRae et al. (2005), only properties mentioned by at least 5 participants are considered positive. 727 guistic information (using plain text only, morphology, syntax or pattern information). word2vec. word2vec (w2v, Mikolov et al. (2013)) is a neural network model which implements a language model objective. It has reached state-of-the-art results for word similarity, categorization and analogy tasks (Baroni et al., 2014). We use the off-the-shelf 300-dimensional version trained on a corpus of 100B tokens.2 GloVe. GloVe (gv, Pennington et al. (2014)) is a log bilinear regression model. The authors report state-of-the-art results in word similarity, semantic analogies and NER tasks. We use the off-theshelf 300-dimensional version trained on a corpus of 840B tokens.3 Distributional Memory. The Distributional Memory model (dm, B</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Glove: Global vectors for word representation.</title>
<date>2014</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="5007" citStr="Pennington et al., 2014" startWordPosition="798" endWordPosition="801"> We model this task as a learning problem, in which concepts have a feature representation based on a state-of-the-art DM. A property-predictor is then trained to predict, for any given concept, whether the property applies to it or not (in a binary classification setup), or the strength of affiliation between the property and the concept (in a regression setup). By evaluating the performance of these predictors, we assess the degree to which the property is captured by the DM. We experiment with four state-of-the-art DMs (Baroni and Lenci, 2010; Mikolov et al., 2013; Levy and Goldberg, 2014; Pennington et al., 2014). Our results show that all DMs, quite successful in many semantic tasks, fail when it comes to predicting attributive properties of concepts. For example, in the classification task, the best performing DM achieves an averaged F-score of only 0.37, contrasted with an average F-score of 0.73 achieved by the same model for taxonomic properties. This result, which may be attributed to an essential difference between taxonomic and attributive properties, demonstrates possible limitations of the distributional hypothesis, at least in terms of the information captured by current stateof-the-art DMs</context>
<context position="9011" citStr="Pennington et al. (2014)" startWordPosition="1466" endWordPosition="1469">their consideration of lin1Due to a pre-defined threshold applied by McRae et al. (2005), only properties mentioned by at least 5 participants are considered positive. 727 guistic information (using plain text only, morphology, syntax or pattern information). word2vec. word2vec (w2v, Mikolov et al. (2013)) is a neural network model which implements a language model objective. It has reached state-of-the-art results for word similarity, categorization and analogy tasks (Baroni et al., 2014). We use the off-the-shelf 300-dimensional version trained on a corpus of 100B tokens.2 GloVe. GloVe (gv, Pennington et al. (2014)) is a log bilinear regression model. The authors report state-of-the-art results in word similarity, semantic analogies and NER tasks. We use the off-theshelf 300-dimensional version trained on a corpus of 840B tokens.3 Distributional Memory. The Distributional Memory model (dm, Baroni and Lenci (2010)) is a co-occurrence based DM, which admits morphological, structural and pattern information. The authors have shown that it is highly competitive with state-of-the-art co-occurrence models in a range of semantic tasks. We use the off-the-shelf 5K-dimensional version trained on 3B tokens.4 Depe</context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Schwartz</author>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>Minimally supervised classification to semantic categories using automatically acquired symmetric patterns.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>1612--1623</pages>
<institution>Dublin City University and Association for Computational Linguistics.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="14605" citStr="Schwartz et al., 2014" startWordPosition="2365" endWordPosition="2368">9 0.3 0.29 0.43 0.22 0.15 0.24 0.28 is loud 0.35 0.27 0.3 0.36 0.33 0.25 0.15 0.23 is dangerous 0.45 0.47 0.49 0.5 0.32 0.3 0.25 0.41 is fast 0.41 0.34 0.29 0.35 0.33 0.32 0.19 0.26 Average 0.34 0.31 0.31 0.37 0.25 0.22 0.2 0.28 Table 1: Results for the Property Learning Task. On the left: F-scores for the binary classification task. On the right: Pearson correlation scores for the regression task. limited with respect to attributive properties. An interesting observation is found in the relative success of DMs in predicting taxonomic properties. This result, in line with past research, e.g. (Schwartz et al., 2014), may be explained by considering taxonomic properties as a rich aggregate of attributive properties (Baroni and Lenci, 2010). For example, animals usually have legs and mouths, they make sounds, they can be killed, etc. This is contrasted with attributive properties such as is white, whose members do not have much in common, other than the property itself. We therefore hypothesize that although attributive properties may be signaled very weakly in text, as our results indicate, their accumulation is sufficient to distinguish concepts that share most of them from concepts that do not. To demon</context>
</contexts>
<marker>Schwartz, Reichart, Rappoport, 2014</marker>
<rawString>Roy Schwartz, Roi Reichart, and Ari Rappoport. 2014. Minimally supervised classification to semantic categories using automatically acquired symmetric patterns. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1612–1623, Dublin, Ireland, August. Dublin City University and Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Parsing with compositional vector grammars. In</title>
<date>2013</date>
<booktitle>In Proceedings of the ACL conference. Citeseer.</booktitle>
<contexts>
<context position="1788" citStr="Socher et al., 2013" startWordPosition="268" endWordPosition="271"> can be inferred from their linguistic environment (Harris, 1954). This hypothesis lies at the heart of distributional models (DMs), which approximate the meaning of words by considering the statistics of their co-occurrence with other words in the lexicon. DMs have shown impressive results in many semantic tasks, such as predicting the similarity of two words, grouping words into semantic categories, and solving analogy questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and semantic frame identification (Hermann et al., 2014). However, the empirical success of DMs may not be uniform across the full range of semantic knowledge. It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world (Andrews et al., 2009). This claim relies chiefly on cognitive theory (Louwerse, 2011), and is somewhat supported in empirical findings (Baroni and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model w</context>
</contexts>
<marker>Socher, Bauer, Manning, Ng, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D Manning, and Andrew Y Ng. 2013. Parsing with compositional vector grammars. In In Proceedings of the ACL conference. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ling-Ling Wu</author>
<author>Lawrence W Barsalou</author>
</authors>
<title>Grounding concepts in perceptual simulation: I: Evidence from property generation. Under review http://userwww.</title>
<date>2001</date>
<note>service. emory. edu/˜ barsalou.</note>
<contexts>
<context position="2887" citStr="Wu and Barsalou, 2001" startWordPosition="455" endWordPosition="458">and Lenci, 2008; Andrews et al., 2009). Moreover, a recent study by (Hill et al., 2014) has shown that DMs may not model word similarity as well as previously believed. In this work, we seek to further study the capabilities of DMs in capturing semantic information. For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and Lenci, 2008). For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a fruit, etc. We distinguish between taxonomic properties (Wu and Barsalou, 2001; McRae et al., 2005), which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties). In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties. Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text (Almuhareb and Poesio, 2005; Barbu, 2008; Baroni and Lenci, 2008; </context>
</contexts>
<marker>Wu, Barsalou, 2001</marker>
<rawString>Ling-Ling Wu and Lawrence W Barsalou. 2001. Grounding concepts in perceptual simulation: I: Evidence from property generation. Under review http://userwww. service. emory. edu/˜ barsalou.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig S Harris</author>
</authors>
<date>1954</date>
<note>Distributional structure. Word.</note>
<contexts>
<context position="1233" citStr="Harris, 1954" startWordPosition="180" endWordPosition="181">nd attributive properties (e.g., size, color). We employ four state-of-the-art DMs as sources of feature representation for this task, and show that they all yield poor results when tested on attributive properties, achieving no more than an average F-score of 0.37 in the binary property prediction task, compared to 0.73 on taxonomic properties. Our results suggest that the distributional hypothesis may not be equally applicable to all types of semantic information. 1 Introduction The Distributional Hypothesis states that the meaning of words can be inferred from their linguistic environment (Harris, 1954). This hypothesis lies at the heart of distributional models (DMs), which approximate the meaning of words by considering the statistics of their co-occurrence with other words in the lexicon. DMs have shown impressive results in many semantic tasks, such as predicting the similarity of two words, grouping words into semantic categories, and solving analogy questions (see Baroni et al. (2014) for a recent survey). They are also used as a source of semantic information by many downstream applications, including syntactic parsing (Socher et al., 2013), image annotation (Klein et al., 2014), and </context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig S Harris. 1954. Distributional structure. Word.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>