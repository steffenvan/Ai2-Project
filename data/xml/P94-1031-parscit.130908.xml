<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997455">
Tricolor DAGs for Machine Translation
</title>
<author confidence="0.996171">
Koichi Takeda
</author>
<affiliation confidence="0.997681">
Tokyo Research Laboratory, IBM Research
</affiliation>
<address confidence="0.8883055">
1623-14 Shimotsuruma, Yamato, Kanagawa 242, Japan
Phone: 81-462-73-4569, 81-462-73-7413 (FAX)
</address>
<email confidence="0.878625">
takedaOtrl.vnet.ibm.com
</email>
<sectionHeader confidence="0.991088" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999597818181818">
Machine translation (MT) has recently been for-
mulated in terms of constraint-based knowledge
representation and unification theories, but it is
becoming more and more evident that it is not
possible to design a practical MT system without
an adequate method of handling mismatches be-
tween semantic representations in the source and
target languages. In this paper, we introduce the
idea of &amp;quot;information-based&amp;quot; MT, which is consid-
erably more flexible than interlingual MT or the
conventional transfer-based MT.
</bodyText>
<sectionHeader confidence="0.958201" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.991590666666667">
With the intensive exploration of contemporary
theories on unification grammars[6, 15, 13] and
feature structures[7, 19] in the last decade, the
old image of machine translation (MT) as a bru-
tal form of natural language processing has given
way to that of a process based on a uniform and
reversible architecture[16, 1, 27].
The developers of MT systems based on the
constraint-based formalism found a serious prob-
lem in &amp;quot;language mismatching,&amp;quot; namely, the dif-
ference between semantic representations in the
source and target languages.&apos; Attempts to de-
sign a. pure interlingual MT system were therefore
abandoned,2 and the notion of &amp;quot;semantic trans-
fer&amp;quot;[24, 22] came into focus as a practical so-
lution to the problem of handling the language
mismatching. The constraint-based formalism[2]
seemed promising as a formal definition of trans-
fer, but pure constraints are too rigid to be pre-
cisely imposed on target-language sentences.
Some researchers(e.g., Russell[14]) introduced
</bodyText>
<footnote confidence="0.800586142857143">
&apos;For example, Yasuhara[26] reported there was an
overlap of only 10% between his group&apos;s English and
Japanese concept dictionaries, which covered 0.2 mil-
lion concepts.
&apos;Even an MT system with a controlled input
language[12] does not claim to be a pure interlingual
system.
</footnote>
<bodyText confidence="0.9994745">
the concept of defeasible reasoning in order to for-
malize what is missing from a pure constraint-
based approach, and control mechanisms for such
reasoning have also been proposed[5, 3]. With
this additional mechanism, we can formulate the
&amp;quot;transfer&amp;quot; process as a mapping from a set of con-
straints into another set of mandatory and defea-
sible constraints. This idea leads us further to the
concept of &amp;quot;information-based&amp;quot; MT, which means
that, with an appropriate representation scheme,
a source sentence can be represented by a set of
constraints that it implies and that, given a target
sentence, the set C, of constraints can be divided
into three disjoint subsets:
</bodyText>
<listItem confidence="0.892693333333333">
• The subset Co of constraints that is also implied
by the target sentence
• The subset af. of constraints that is not im-
plied by, but is consistent with, the translated
sentence
• The subset C_ of constraints that is violated by
the target sentence
The target sentence may also imply another set
• of constraints, none of which is in C,. That
</listItem>
<bodyText confidence="0.999023333333333">
is, the set Ct of constraints implied by the tar-
get sentences is a union of Co and Cnew, while
C, = Co UC+ UC_. When C, = Co = Ct, we have
a fully interlingual translation of the source sen-
tence. If C+ C_ =41, and Cnew = 4), the tar-
get sentence is said to be under-generated, while it
is said to be over-generated when C+ = =
and Cn„,, 0 0.3 In either case, C_ must be empty
if a consistent translation is required. Thus, the
goal of machine translation is to find an optimal
pair of source and target sentences that minimizes
C+, C—, and Cnew. Intuitively, Co corresponds
to essential information, and C+ and Ca,,,, can
be viewed as language-dependent supportive in-
formation. C_ might be the inconsistency be-
</bodyText>
<note confidence="0.810206333333333">
&apos;The notions of completeness and coherence in
LFG[6] have been employed by Wedekind[25] to avoid
over- and under-generation.
</note>
<page confidence="0.998091">
226
</page>
<bodyText confidence="0.979139592592593">
tween the assumptions of the source- and target-
language speakers.
In this paper, we introduce tricolor DAGs
to represent the above constraints, and discuss
how tricolor DAGs are used for practical MT sys-
tems. In particular, we give a generation algo-
rithm that incorporates the notion of semantic
transfer by gradually approaching the optimal tar-
get sentence through the use of tricolor DAGs,
when a fully interlingual translation fails. Tricolor
DAGs give a graph-algorithmic interpretation of
the constraints, and the distinctions between the
types of constraint mentioned above allow us to
adjust the margin between the current and opti-
mal solution effectively.
Tricolor DAGs
A tricolor DAG (TDAG, for short) is a rooted,
directed, acyclic4 gr,aph with a set of three colors
(red, yellow, and ireen) for nodes and directed
arcs. It is used to represent a feature structure of
a source or target sentence. Each node represents
either an atomic value or a root of a DAG, and
each arc is labeled with a feature name. The only
difference between the familiar usage of DAGs in
unification grammars and that of TDAGs is that
the color of a node or .arc represents its degree of
importance:
</bodyText>
<listItem confidence="0.885184789473684">
1. Red shows that a node (arc) is essential.
2. Yellow shows that a node (arc) may be ignored,
but must not be violated.
3. Green shows that a node (arc) may be violated.
For practical reasons, the above distinctions are
interpreted as follows:
1. Red shows that a node (arc) is derived from
lexicons and grammatical constraints.
2. Yellow shows that a node (arc) may be inferred
from a source or a target sentence by using do-
main knowledge, common sense, and so on.
3. Green shows that a node (arc) is defeasibly in-
ferred, specified as a default, or heuristically
specified.
When all the nodes and arcs of TDAGs are red,
TDAGs are basically the same as the feature struc-
tures&apos; of grammar-based translation[25, 17). A
TDAG is well-formed if the following conditions
are satisfied:
</listItem>
<footnote confidence="0.993568428571429">
4Acyclicity is not crucial to the results in this pa-
per, but it significantly simplifies the definition of the
tricolor DAGs and semantic transfer.
5We will only consider the semantic portion of the
feature structure although the theory of tricolor DAGS
for representing entire feature structures is an interest-
ing topic.
</footnote>
<listItem confidence="0.995534818181818">
1. The root is a red node.
2. Each red arc connects two red nodes.
3. Each red node is reachable from the root
through the red arcs and red nodes.
4. Each yellow node is reachable from the root
through the arcs and nodes that are red and/or
yellow.
5. Each yellow arc connects red and/or yellow
nodes.
6. No two arcs start from the same node, and have
the same feature name.
</listItem>
<bodyText confidence="0.995527583333333">
Conditions 1 to 3 require that all the red nodes
and red arcs between them make a single, con-
nected DAG. Condition 4 and 5 state that a de-
feasible constraint must not be used to derive an
imposed constraint. In the rest of this paper, we
will consider only well-formed TDAGs. Further-
more, since only the semantic portions of TDAGs
are used for machine translation, we will not dis-
cuss syntactic features.
The subsumption relationship among the
TDAGs is defined as the usual subsumption over
DAGs, with the following extensions.
</bodyText>
<listItem confidence="0.997997666666667">
• A red node (arc) subsumes only a red node
(arc).
• A yellow node (arc) subsumes a red node (arc)
and a yellow node (arc).
• A green node (arc) subsumes a node (arc) with
any color.
</listItem>
<bodyText confidence="0.977619333333333">
The unification of TDAGs is similarly defined.
The colors of unified nodes and arcs are specified
as follows:
</bodyText>
<listItem confidence="0.996844333333333">
• Unification of a red node (arc) with another
node (arc) makes a red node (arc).
• Unification of a yellow node (arc) with a yellow
or green node (arc) makes a yellow node (arc).
• Unification of two green nodes (arcs) makes a
green node (arc).
</listItem>
<bodyText confidence="0.984656888888889">
Since the green nodes and arcs represent defeasible
constraints, unification of a green node (either a
root of a TDAG or an atomic node) with a red
or yellow node always succeeds, and results in a
red or yellow node. When two conflicting green
nodes are to be unified, the result is indefinite, or
a single non-atomic green node!&apos;
Now, the problem is that a red node/arc in a
source TDAG (the TDAG for a source sentence)
</bodyText>
<footnote confidence="0.998986">
6An alternative definition is that one green node
has precedence over the other[14]. Practically, such
a conflicting unification should be postponed until no
other possibility is found.
</footnote>
<page confidence="0.995726">
227
</page>
<figureCaption confidence="0.99984">
Figure 1: Sample TDAGs
</figureCaption>
<bodyText confidence="0.991163069767442">
may not always be a red node/arc in the target
TDAG (the TDAG for a target sentence). For
example, the functional control of the verb &amp;quot;wish&amp;quot;
in the English sentence
John wished to walk
may produce the TDAG1 in Figure 1, but the
red arc corresponding to the agent of the *WALK
predicate may not be preserved in a target
TDAG2.7 This means that the target sentence
alone cannot convey the information that it is
John who wished to walk, even if this information
can be understood from the context. Hence the
red arc is relaxed into a yellow one, and any tar-
get TDAG must have an agent of *WALK that is
consistent with *JOHN. This relaxation will help
the sentence generator in two ways. First, it can
prevent generation failure (or non-termination in
the worst case). Second, it retains important in-
formation for a choosing correct translation of the
verb &amp;quot;walk&amp;quot;.8
&apos;For example, the Japanese counterpart &amp;quot;Ws&amp;quot; for
the verb &amp;quot;wish&amp;quot; only takes a sentential complement,
and no functional control is observed.
&apos;Whether or not the subject of the verb is human
is often crucial information for making an appropriate
choice between the verb&apos;s two Japanese counterparts
&amp;quot;&lt;&amp;quot; and &amp;quot;V1-71-Z&amp;quot;.
Another example is the problem of iden-
tifying number and determiner in Japanese-to-
English translation. This type of information is
rarely available from a syntactic representation
of a Japanese noun phrase, and a set of heuris-
tic rules[11] is the only known basis for making
a reasonable guess. Even if such contextual pro-
cessing could be integrated into a logical inference
system, the obtained information should be defea-
sible, and hence should be represented by green
nodes and arcs in the TDAGs. Pronoun resolu-
tion can be similarly represented by using green
nodes and arcs.
It is worth looking at the source and tar-
get TDAGs in the opposite direction. From the
Japanese sentence,
</bodyText>
<equation confidence="0.818463">
lt &lt; tzf 0
John +subj walk +nom +obj wished
</equation>
<bodyText confidence="0.9996962">
we get the source TDAG3 in Figure 1, where func-
tional control and number information are miss-
ing. With the help of contextual processing, we
get the target TDAG4, which can be used to gen-
erate the English sentence &amp;quot;John wished to walk.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.811775">
Semantic Transfer
</subsectionHeader>
<bodyText confidence="0.999959741935484">
As illustrated in the previous section, it is often
the case that we have to solve mismatches between
source and target TDAGs in order to obtain suc-
cessful translations. Syntactic/semantic transfer
has been formulated by several researchers[18, 27]
as a means of handling situations in which fully
interlingual translation does not work. It is not
enough, however, to capture only the equivalent
relationship between source and target semantic
representations: this is merely a mapping among
red nodes and arcs in TDAGs. What is missing in
the existing formulation is the provision of some
margin between what is said and what is trans-
lated. The semantic transfer in our framework is
defined as a set of successive operations on TDAGs
for creating a sequence of TDAGs to, t1, tk
such that to is a source TDAG and tk is a target
TDAG that is a successful input to the sentence
generator.
A powerful contextual processing and a do-
main knowledge base can be used to infer addi-
tional facts and constraints, which correspond to
the addition of yellow nodes and arcs. Default in-
heritance, proposed by Russell et al.[14], provides
an efficient way of obtaining further information
necessary for translation, which corresponds to the
addition of green nodes and arcs. A set of well-
known heuristic rules, which we will describe later
in the &amp;quot;Implementation&amp;quot; Section, can also be used
to add green nodes and arcs. To complete the
model of semantic transfer, we have to introduce
</bodyText>
<figure confidence="0.999465636363636">
&apos;WALK
Source T-DAG1
Target T-DAG2
theme
&apos;WALK
&apos;JOHN
&apos;WALK
•
•
red node
yellow node
green node
red arc
• iw yellow arc
green arc
AO
num num *
&apos;WISH 414*
&apos;JOHN *JOHN
agent
agent agent
•
sg
num
&apos;JOHN
A
agent
*WALK
Target T-DAG4
&apos;WISH
&apos;WISH
&apos;WISH
Source T-DAG3
</figure>
<page confidence="0.981744">
228
</page>
<bodyText confidence="0.996583357142857">
a &amp;quot;painter.&amp;quot; A painter maps a red node to ei-
ther a yellow or a green node, a yellow node to
a green node, and so on. It is used to loosen the
constraints imposed by the TDAGs. Every appli-
cation of the painter monotonically loses some in-
formation in a TDAG, and only a finite number of
applications of the painter are possible before the
TDAG consists entirely of green nodes and arcs
except for a red root node. Note that the painter
never, removes a node or an arc from a TDAG,
it simply weakens the constraints imposed by the
nodes and arcs.
Formally, semantic transfer is defined as a se-
quence of the following operations on TDAGs:
</bodyText>
<listItem confidence="0.9936045">
• Addition of a yellow node (and a yellow arc) to
a given TDAG. The node must be connected to
a node in the TDAG by a yellow arc.
• Addition of a yellow arc to a given TDAG. The
arc must connect two red or yellow nodes in the
TDAG.
• Addition of a green node (and a green arc) to a
given TDAG. The node must be connected to a
node in the TDAG by the green arc.
• Addition of a green arc to a given TDAG. The
arc can connect two nodes of any color in the
TDAG.
• Replacement of a red node (arc) with a yellow
one, as long as the well-formedness is preserved.
• Replacement of a yellow node (arc) with a green
one, as long as the well-formedness is preserved.
</listItem>
<bodyText confidence="0.999970025">
The first two operations define the logical impli-
cations (possibly with common sense or domain
knowledge) of a given TDAG. The next two op-
erations define the defeasible (or heuristic) infer-
ence from a given TDAG. The last two operations
define the painter. The definition of the painter
specifies that it can only gradually relax the con-
straints. That is, when a red or yellow node (or
arc) X has other red or yellow nodes that are only
connected through X, X cannot be &amp;quot;painted&amp;quot; un-
til each of the connected red and yellow nodes is
painted yellow or green to maintain the reachabil-
ity through X.
In the sentence analysis phase, the first four
operations can be applied for obtaining a source
TDAG as a reasonable semantic interpretation of
a sentence. The application of these operations
can be controlled by &amp;quot;weighted abduction&amp;quot; [5], de-
fault inheritance, and so on. These operations can
also be applied at semantic transfer for augment-
ing the TDAG with a common sense knowledge of
the target language. On the other hand, these op-
erations are not applied to a TDAG in the gener-
ation phase, as we will explain in the next section.
This is because the lexicon and grammatical con-
straints are only applied to determine whether red
nodes and arcs are exactly derived. If they are not
exactly derived, we will end up with either over- or
under-generation beyond the permissible margin.
Semantic transfer is applied to a source TDAG as
many times9 as necessary until a successful gen-
eration is made. Recall the sample sentence in
Figure 1, where two painter calls were made to
change two red arcs in TDAG, into yellow ones
in TDAG2. These are examples of the first sub-
stitution operation shown above. An addition of
a green node and a green arc, followed by an ad-
dition of a green arc, was applied to TDAG3 to
obtain TDAG4. These additions are examples of
the third and fourth addition operations.
</bodyText>
<subsectionHeader confidence="0.572676">
Sentence Generation Algorithm
</subsectionHeader>
<bodyText confidence="0.999941">
Before describing the generation algorithm, let us
look at the representation of lexicons and gram-
mars for machine translation. A lexical rule is
represented by a set of equations, which intro-
duce red nodes and arcs into a source TDAG.1° A
phrasal rule is similarly defined by a set of equa-
tions, which also introduce red nodes and arcs for
describing a syntactic head and its complements.
For example, if we use Shieber&apos;s PATR-II[15]
notation, the lexical rule for &amp;quot;wished&amp;quot; can be rep-
resented as follows:
</bodyText>
<equation confidence="0.8919533">
V wished
(V cat) = v
(V form) = past
(V subj cat) = np
(V obj cat) = v
(V obj form) = infinitival
(V pred) = *WISH
(V pred agent) = (V subj pred)
(V pred theme) = (V obj pred)
(V pred theme agent) = (V subj pred)
</equation>
<bodyText confidence="0.902103388888889">
The last four equations are semantic equa-
tions. Its TDAG representation is shown in Fig-
ure 2. It would be more practical to further as-
sume that such a lexical rule is obtained from
a type inference system,&amp;quot; which makes use of a
syntactic class hierarchy so that each lexical class
can inherit general properties of its superclasses.
Similarly, semantic concepts such as *WISH and
*WALK should be separately defined in an onto-
logical hierarchy together with necessary domain
knowledge (e.g., selectional constraints on case
&apos;The iteration is bounded by the number of nodes
and arcs in the TDAG, although the number of possi-
ble sequences of operations could be exponential.
&apos;For simplicity, we will only consider semantic
equations to form the TDAGs.
&amp;quot;as in Shieber[15], Pollard and Sag[13], and Russell
et al114]
</bodyText>
<page confidence="0.996643">
229
</page>
<figureCaption confidence="0.9973668">
Figure 2: TDAG representation of the verb
&amp;quot;wished&amp;quot; (embedded in the entire feature struc-
ture)
Figure 3: Source TDAG for the sentence &amp;quot;The
Boston Office called.&amp;quot;
</figureCaption>
<bodyText confidence="0.981290333333333">
fillers and part-of relationships. See KBMT-89[8].)
A unification grammar is used for both analysis
and generation. Let us assume that we have two
unification grammars for English and Japanese.
Analyzing a sentence yields a source TDAG with
red nodes and arcs. Semantic interpretation re-
solves possible ambiguity and the resulting TDAG
may include all kinds of nodes and arcs. For ex-
ample, the sentence12
</bodyText>
<subsectionHeader confidence="0.666094">
The Boston office called
</subsectionHeader>
<bodyText confidence="0.946131133333333">
would give the source TDAG in Figure 3. By
utilizing the domain knowledge, the node labeled
*PERSON is introduced into the TDAG as a real
caller of the action &apos;CALL, and two arcs repre-
senting *PERSON work-for *OFFICE and *OF-
FICE in *BOSTON are abductively inferred.
Our generation algorithm is based on
Wedekind&apos;s DAG traversal algorithm[25) for
LFG.13 The algorithm runs with an input TDAG
by traversing the nodesand arcs that were derived
from the lexicon and grammar rules. The termi-
nation conditions are as follows:
&amp;quot;in Hobbs et al.[5]
&amp;quot;It would be identical to Wedekind&apos;s algorithm if
an input TDAG consisted of only red nodes and arcs.
</bodyText>
<figureCaption confidence="0.977707">
Figure 4: Target TDAG for the sentence &amp;quot;The
Boston Office called.&amp;quot;
</figureCaption>
<listItem confidence="0.9703294">
• Every red node and arc in the TDAG was de-
rived.
• No new red node (arc) is to be introduced into
the TDAG if there is no corresponding node
(arc) of any color in the TDAG. That is, the
generator can change the color of a node (arc)
to red, but cannot add a new node (arc).
• For each set of red paths (i.e., the sequence of
red arcs) that connects the same pair of nodes,
the reentrancy was also derived.
</listItem>
<bodyText confidence="0.803485428571429">
These conditions are identical to those of
Wedekind except that yellow (or green) nodes and
arcs may or may not be derived. For example, the
sentence &amp;quot;The Boston Office called&amp;quot; in Figure 3
can be translated into Japanese by the following
sequence of semantic transfer and sentence gener-
ation.
</bodyText>
<listItem confidence="0.980447">
1. Apply the painter to change the yellow of the
definite node and the def arc to green.
2. Apply the painter to change the yellow of the
singular node and the num arc to green. The
resulting TDAG is shown in Figure 4.
3. Run the sentence generator with an input fea-
ture structure, which has a root and an arc pred
connecting to the given TDAG. (See the node
marked &amp;quot;1&amp;quot; in Figure 4.)
4. The generator applies a phrasal rule, say S
NP VP, which derives the subj arc connecting
to the subject NP (marked &amp;quot;2&amp;quot;), and the agent
arc.
5. The generator applies a phrasal rule, say NP
MOD NP,14 which derives the npnaod arc to the
</listItem>
<figure confidence="0.785922333333333">
agent
def
definite
</figure>
<footnote confidence="0.699796428571428">
14There are several phrasal rules for deriving this
LHS NP in Japanese: (1) A noun-noun compound, (2)
a noun, copula, and a noun, and (3) a noun, postposi-
tional particle, and a noun. These three rules roughly
correspond to the forms (1) Boston Office, (2) office
of Boston, and (3) office in Boston. Inference of the
&amp;quot;OFFICE in *BOSTON&amp;quot; relation is easiest if rule (3)
</footnote>
<figure confidence="0.994779692307692">
&apos;WISH
cat
pred
theme agent
pred
cat
CT) v
C.)
past
*PERSON
caller I work-for
&amp;quot;OFFICE&amp;quot;n
0 &apos;CALL
&apos;BOSTON
pred
definite singular
0
T. *PERSON
•. work-for
caller • -..
*CALL.
OFFICE
mod
num
singular
.1\ in BOSTON
</figure>
<page confidence="0.986746">
230
</page>
<bodyText confidence="0.935208">
modifier of the NP (marked &amp;quot;3&amp;quot;) and the mod
arc.
</bodyText>
<listItem confidence="0.631315666666667">
6. Lexical rules are applied and all the semantic
nodes, *CALL, *OFFICE, and *BOSTON are
derived.
</listItem>
<bodyText confidence="0.999983166666667">
The annotated sample run of the sentence gen-
erator is shown in Figure 5. The input TDAG in
the sample run is embedded in the input feature
structure as a set of PRED values, but the seman-
tic arcs are not shown in the figure. The input
feature structure has syntactic features that were
specified in the lexical rules. The feature value
*UNDEFINED* is used to show that the node has
been traversed by the generator.
The basic property of the generation algo-
rithm is as follows:
Let t be a given TDAG, trnin be the connected
subgraph including all the red nodes and arcs
in t, and tmar be the connected subgraph of
t obtained by changing all the colors of the
nodes and arcs to red. Then, any successful
generation with the derived TDAG ty, satisfies
the condition that tmin subsumes tg, and tg
subsumes t,,,as•
The proof is immediately obtained from the defini-
tion of successful generation and the fact that the
generator never introduces a new node or a new
arc into an input TDAG. The TDAGs can also
be employed by the semantic head-driven genera-
tion algorithm[17] while retaining the above prop-
erty. Semantic monotonicity always holds for a
TDAG, since red nodes must be connected. It has
been shown by Takeda[21] that semantically non-
monotonic representations can also be handled by
introducing a functional semantic class.
</bodyText>
<sectionHeader confidence="0.602131" genericHeader="method">
Implementation
</sectionHeader>
<bodyText confidence="0.999930583333333">
We have been developing a prototype English-
to-Japanese MT system, called Shalt2[22], with
a lexicon for a computer-manual domain includ-
ing about 24,000 lexemes each for English and
Japanese, and a general lexicon including about
50,000 English words and their translations. A
sample set of 736 sentences was collected from
the &amp;quot;IBM AS/400 Getting Started&amp;quot; manual, and
was tested with the above semantic transfer and
generation algorithm.&amp;quot; The result of the syntac-
tic analysis by the English parser is mapped to
a TDAG using a set of semantic equations&amp;quot; ob-
</bodyText>
<footnote confidence="0.867100285714286">
is used, but the noun-noun compound is probably the
best translation. /
&amp;quot;We used McCord&apos;s English parser based on his
English Slot Grammar[10], which covered more than
93% of the sentences.
16We call such a set of semantic equations mapping
rides (see Shalt2[20] or KBMT-89[8]).
</footnote>
<table confidence="0.9875934">
; ; run the generator with input f-structure
0&gt; *J-GG-START called with
((PRED &amp;quot;*X&amp;quot;) (CAT V) (VTYPE V-6DAN-B)
(SUBCAT TRANS) (ASP-TYPE SHUNKAN)
(:MOOD ((PRED &amp;quot;Cdec&amp;quot;)))
(AUX ((PRED &apos;aux&apos;) (:TIME ((PRED &amp;quot;Opast&amp;quot;)))
(:PASSIVE ((PRED &amp;quot;Cminus&amp;quot;)))))
(SUBJ ((CAT N) (PRED
(XADJUNCT ((XCOP &amp;quot;-CO&amp;quot;) (CAT N)
(PRED &apos;.c l.&amp;quot;))))))
3&gt; *J-GG-S called ;;&lt;start&gt; -&gt;...-&gt; &lt;S&gt;
4&gt; *J-GG-XP called with ;;subj-filler
((CASE (*OB.* &amp;quot;ii&amp;quot; &amp;quot;h1&amp;quot;)) (CAT N)
(NEG *UNDEFINED*) (PRED -4KIM&amp;quot;)
(XADJUNCT ((COP -) (CAT N)
</table>
<figure confidence="0.547266285714286">
(PRED &amp;quot;%NA :/&amp;quot;))))
5&gt; *J-GG-NP called ;;head NP of subj
10&lt; *GG-N-ROOT returns ;;np mod
;;&amp;quot;Hoston&amp;quot;
9&gt; *J-GG-N called ;;head op
10&lt; *GG-N-ROOT returns
&amp;quot;VW&amp;quot; ;;&amp;quot;office&amp;quot;
7&lt; *9 (&lt;SS&gt; &lt;NP&gt;) returns ;;mod+NP
&amp;quot;4Ai&apos;s./TV4SK&amp;quot;
5&lt; *1 (&lt;NP&gt; &lt;P&gt;) returns ;;NP+case-marker
&amp;quot;W A l• :/&amp;quot;CGDWOlifill&amp;quot;
4&lt; *J-GG-XP returns &amp;quot;4:-.A :/-co-Aun
4&gt; *J-GG-S called with ;;VP part
5&gt; *J-GG-VP called ;;stem +
6&gt; *J-GG-V called ;;function word chains
((SUBJ *UNDEFINED*)
(ADVADJUNCT *UNDEFINED*)
(PPADJUNCT *UNDEFINED*)
(:MOOD *UNDEFINED*)
(AUX ((:TINE ((PRED &amp;quot;Cpast&amp;quot;)))
(:PASSIVE
((PRED (*OR* *UNDEFINED* &amp;quot;Cminus&amp;quot;))))
(PRED &amp;quot;Caux&amp;quot;)))
(CAT V) (TYPE FINAL) (ASP-TYPE SHUNKAN)
(VTYPE V-5DAN-B) (SUBCAT TRANS)
(PRED &amp;quot;V?..g&amp;quot;))
7&gt; *J-GG-RENTAI-PAST called ;;past-form
14&lt; *GG-V-ROOT returns &amp;quot;Of&amp;quot; ;;stem
6&lt; *J-GG-V returns &amp;quot;112RYI Lt.:&amp;quot;
5&lt; *J-GG-VP returns &amp;quot;11:nri Lt.:&amp;quot;
4&lt; *J-GG-S returns &amp;quot;aril Lt.&amp;quot;
3&lt; *3-00-5 returns
&amp;quot;WAi&apos;:/TVASTRUITWILt.:.&amp;quot;
0&lt; *J-GG-START returns
&amp;quot;WAj. U Ltz. &amp;quot;
</figure>
<figureCaption confidence="0.9891245">
Figure 5: Sentence generation from the TDAG for
&amp;quot;The Boston Office called.&amp;quot;
</figureCaption>
<page confidence="0.991639">
231
</page>
<bodyText confidence="0.999396733333333">
tamed from the lexicons. We have a very shal-
low knowledge base for the computer domain,
and no logical inference system was used to de-
rive further constraints from the given source sen-
tences. The Japanese grammar is similar to the
one used in KBMT-89, which is written in pseudo-
unification[23) equations, but we have added sev-
eral new types of equation for handling coordi-
nated structures. The Japanese grammar can gen-
erate sentences from all the successful TDAGs for
the sample English sentences.
It turned out that there were a few collections
of semantic transfer sequences which contributed
very strongly to the successful generation. These
sequences include
</bodyText>
<listItem confidence="0.9998284">
• Painting the functional control arcs in yellow.
• Painting the gaps of relative clauses in yellow.
• Painting the number and definiteness features
in yellow.
• Painting the passivization feature in green.17
</listItem>
<bodyText confidence="0.892541333333333">
Other kinds of semantic transfer are rather id-
iosyncratic, and are usually triggered by a par-
ticular lexical rule. Some of the sample sentences
used for the translations are as follows:18
Make sure you are using the proper edition
for the level of the product.
</bodyText>
<figure confidence="0.87544685">
it Mg 1.,.‘•)1. AvJ
user +subj product +pos level +f or proper
45VER lOZ
edition +obj use +prog +nom +obj
4414 &lt; 0
confirm +imp
Publications are not stocked at the address
Fol.ven below.
RV- -cs
publication +subj following +loc provide
A
address +loc stock +passive +neg
This publication could contain technical
inaccuracies or typographical errors.
AA- it to:}14itzT14.
this publication +subj technical inaccuracy
PR!)±.0) —
or typographical error +obj
L 47.
contain +ability +past
</figure>
<footnote confidence="0.377685333333333">
17We decided to include the passivization feature in
the semantic representation in order to determine the
proper word ordering in Japanese.
&apos;Japanese translation reflects the errors made in
English analysis. For example, the auxiliary verb
&amp;quot;could&amp;quot; is misinterpreted in the last sample sentence.
</footnote>
<bodyText confidence="0.999871272727273">
The overall accuracy of the translated sen-
tences was about 63%. The main reason for trans-
lation errors was the occurrence of errors in lexi-
cal and structural disambiguation by the syntac-
tic/semantic analyzer. We found that the accu-
racy of semantic transfer and sentence generation
was practically acceptable.
Though there were few serious errors, some
occurred when a source TDAG had to be com-
pletely &amp;quot;paraphrased&amp;quot; into a different TDAG. For
example, the sentence •
</bodyText>
<subsectionHeader confidence="0.783651">
Let&apos;s get started.
</subsectionHeader>
<bodyText confidence="0.999966307692308">
was very hard to translate into a natural Japanese
sentence. Therefore, a TDAG had to be para-
phrased into a totally different TDAG, which is an-
other important role of semantic transfer. Other
serious errors were related to the ordering of con-
stituents in the TDAG. It might be generally ac-
ceptable to assume that the ordering of nodes in a
DAG is immaterial. However, the different order-
ing of adjuncts sometimes resulted in a misleading
translation, as did the ordering of members in a
coordinated structure. These subtle issues have to
be taken into account in the framework of seman-
tic transfer and sentence generation.
</bodyText>
<sectionHeader confidence="0.578193" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999905846153846">
In this paper, we have introduced tricolor DAGs
to represent various degrees of constraint, and de-
fined the notions of semantic transfer and sen-
tence generation as operations on TDAGs. This
approach proved to be so practical that nearly
all of the source sentences that were correctly
parsed were translated into readily acceptable sen-
tences. Without semantic transfer, the translated
sentences would include greater numbers of incor-
rectly selected words, or in some cases the gener-
ator would simply fail19
Extension of TDAGs for disjunctive informa-
tion and a set of feature structures must be fully
incorporated into the framework. Currently only
a limited range of the cases are implemented. Op-
timal control of semantic transfer is still unknown.
Integration of the constraint-based formalism, de-
feasible reasoning, and practical heuristic rules are
also important for achieving high-quality transla-
tion. The ability to process and represent various
levels of knowledge in TDAGs by using a uniform
architecture is desirable, but there appears to be
some efficient procedural knowledge that is very
hard to represent declaratively. For example, the
negative determiner &amp;quot;no&amp;quot; modifying a noun phrase
in English has to be procedurally transferred into
</bodyText>
<footnote confidence="0.556687666666667">
&amp;quot;The Essential Arguments Algorithm[9) might be
an alternative method for finding a successful genera-
tion path.
</footnote>
<page confidence="0.984473">
232
</page>
<bodyText confidence="0.999083">
the negation of the verb governing the noun phrase
in Japanese. Translation of &amp;quot;any&amp;quot;, &amp;quot;yet&amp;quot;, &amp;quot;only&amp;quot;,
and so on involves similar problems.
While TDAGs reflect three discrete types of
constraints, it is possible to generalize the types
into continuous, numeric values such as potential
energy[4]. This approach will provide a consider-
ably more flexible margin that defines a set of per-
missible translations, but it is not clear whether
we can successfully define a numeric value for each
lexical rule in order to obtain acceptable transla-
tions.
</bodyText>
<sectionHeader confidence="0.996576" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99789525">
The idea of the tricolor DAGs grew from discus-
sions with Shiho Ogino on the design and im-
plementation of the sentence generator. I would
also like to thank the members of the NL group
— Naohiko Uramoto, Tetsuya Nasukawa, Hiroshi
Maruyama, Hiroshi Nomiyama, Hideo Watanabe,
Masayuki Morohashi, and Taijiro Tsutsumi — for
stimulating comments and discussions that di-
rectly and indirectly contributed to shaping the
paper. Michael McDonald, who has always been
the person I turn to for proofreading, helped me
write the final version.
</bodyText>
<reference confidence="0.999641388888889">
[10] M. McCord. &amp;quot;Slot Grammar: A System for Simpler
Construction of Practical Natural Language Grammars
(Ed:Studer,R.)&amp;quot;, pages 118-145. Springer-Verlag, 1990.
[11] M. Murata and M. Nagao. &amp;quot;Determination of Referential
Property and Number of Nouns in Japanese Sentences for
Machine Translation into English&amp;quot;. In Proc. of the 5th
International Conference on Theoretical and Method-
ological Issues in Machine Translation, pages 218-225,
Kyoto, Japan, July 1993.
[12] E. H. Nyberg, 3rd and T. Mitamura. &amp;quot;The KANT Sys-
tem: Fast, Accurate, High-Quality Translation in Prac-
tical Domains&amp;quot;. In Proc, of the 14th International Con-
ference on Computational Linguistics, pages 1069-1073,
July 1992.
[13] C. Pollard and I. A. Sag. &amp;quot;An Information-Based Syn-
tax and Semantics, Vol.1 Fundamentals&amp;quot;, CSLI Lecture
Notes, Number 13,1987.
[14] G. Russell, A. Ballim, J. Carroll, and S. Warwick-
Armstrong. &amp;quot;A Practical Approach to Multiple Default
Inheritance for Unification-Based Lexicons&amp;quot;. Computa-
tional Linguistics, 18(3):311-337, Sept. 1992.
[15] S. M. Shieber. &amp;quot;An Introduction to Unification-Based
Approaches to Grammar&amp;quot;. CSLI Lecture Notes, Number
4, Stanford, CA, 1986.
[16] S. M. Shieber. &amp;quot;A Uniform Architecture for Parsing and
Generation&amp;quot;. In Proc. of the 12th International Con-
ference on Computational Linguistics, pages 614-619,
August 1988.
[17] S. M. Shieber, F. C. N. Pereira, G. van Noord, and R. C.
Moore. &amp;quot;Semantic-Head-Driven Generation&amp;quot;. Computa-
tional Linguistics, 16(1):30-42, March 1990.
[18] S. M. Shieber and Y. Schabes. &amp;quot;Synchronous Tree-
Adjoining Grammars&amp;quot;. In Proc. of the 13th Interna-
tional Conference on Computational Linguistics, pages
253-258, August 1990.
[19] G. Smolka. &amp;quot;A Feature Logic with Subsorts&amp;quot;. Technical
Report LILOG-REPORT 33, IBM Deutschland GmbH,
Stuttgart, West Germany, May 1988.
[20] K. Takeda. &amp;quot;An Object-Oriented Implementation of Ma-
chine Translation Systems&amp;quot;. In Proc. of the 5th Inter-
national Conference on Theoretical and Methodologi-
cal Issues in Machine Translation, pages 154-167, July
1993.
[21] K. Takeda. &amp;quot;Sentence Generation from Partially Con-
strained Feature Structures&amp;quot;. In Proc. of the Natural
Language Processing Pacific Rim Symposium, pages 7-
16, Dec. 1993.
[22] K. Takeda, N. Uramoto, T. Nasukawa, and T. Tsutsumi.
&amp;quot;Shalt2- A Symmetric Machine Translation System with
Conceptual Transfer&amp;quot;. In Proc. of the 14th International
Conference on Computational Linguistics, pages 1034-
1038, July 1992.
[23] M. Tomita and K. Knight. &amp;quot;Pseudo Unification and Full
Unification&amp;quot;. Technical Report CMU-CMT-88-MEMO,
Center for Machine Translation, Carnegie Mellon Uni-
versity, November 1987.
[24] H. Uchida. &amp;quot;ATLAS II: A Machine Translation System
Using Conceptual Structure as an Interlingua&amp;quot;. In Proc.
of 2nd Intl. Conf. on Theoretical and Methodological
Issues in Machine Translation of Natural Languages,
pages 150-160, June 1988.
[25] J. Wedekind. &amp;quot;Generation as Structure Driven Deriva-
tion&amp;quot;. In Proc. of the 12th International Conference on
Computational Liguistics, pages 732-737, August 1988.
[26] H. Yasuhara. &amp;quot;Conceptual Transfer in an Interlingua.
Method and Example Based MT&amp;quot;. In Proc. of the Nat-
ural Language Processing Pacific Rim Symposium &apos;93,
pages 376-379, Fukuoka, Japan, Dec. 1993.
[27] R. Zajac. &amp;quot;A Uniform Architecture for Parsing, Gen-
eration and Transfer&amp;quot;. In Proc. of a Workshop on
Reversible Grammar in Natural Language Processing,
pages 71-80, June 1991.
</reference>
<figure confidence="0.639959">
References
</figure>
<figureCaption confidence="0.843922461538462">
M. Dymetman. &amp;quot;Inherently Reversible Grammars, Logic
Programming and Computability&amp;quot;. In Proc. of ACL
Workshop on Reversible Grammar in Natural Lan-
guage Processing, pages 20-30, Berkeley, California,
June 1991.
[2] M. Emele, U. Heid, S. Momma, and R. Zajac. &amp;quot;Inter-
actions between Linguistic Constraints: Procedural vs.
Declarative Approaches&amp;quot;. Machine Translation, 7(1-
2):61-98,1992.
K. Hasida. &amp;quot;Common Heuristics for Parsing, Genera-
tion, and Whatever,...&amp;quot;. In Proc. of a Workshop on
Reversible Grammar in Natural Language Processing,
pages 81-90, June 1991.
</figureCaption>
<bodyText confidence="0.939102260869565">
[4] K. Hasida. &amp;quot;Dynamics of Symbol Systems - An Inte-
grated Architecture of Cognition -&amp;quot;. In Proc. of Interna-
tional Conference on Fifth Generation Computer Sys-
tems 1992, pages 1141-1148, June 1992.
J. R. Hobbs, M. E. Stickel, D. E. Appelt, and P. Martin.
&amp;quot;Interpretation as abduction&amp;quot;. Artificial Intelligence,
63:69-142,1993.
[6] R. Kaplan and J. Bresnan. &amp;quot;Lexical-Functional Gram-
mar: A Formal System for Generalized Grammatical
Representation&amp;quot;. In J. Bresnan, editor, &amp;quot;Mental Rep-
resentation of Grammatical Relations&amp;quot;, pages 173-281.
MIT Press, Cambridge, Mass., 1982.
R. Kasper and W. C. Rounds. &amp;quot;A Logical Semantics for
Feature Structures&amp;quot;. In Proc. of the 24th Annual Meet-
ing of the Association for Computational Linguistics,
Columbia University, New York, NY, June 1986.
[8] KBMT89. &amp;quot;Special Issue on Knowlege-based Machine
Translation I and II&amp;quot;. Machine Translation, 4(2-3),
March-June 1989.
M. Martinovic and T. Strzalkowski. &amp;quot;Comparing Two
Grammar-Based Generation Algorithms: A Case Study&amp;quot;.
In Proc. of the .90th Annual Meeting of ACL, pages 81-
88, June 1992.
</bodyText>
<figure confidence="0.931412">
[3]
[5]
(71
</figure>
<page confidence="0.974368">
191
233
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.964587">
<title confidence="0.999727">Tricolor DAGs for Machine Translation</title>
<author confidence="0.998471">Koichi Takeda</author>
<affiliation confidence="0.999456">Tokyo Research Laboratory, IBM Research</affiliation>
<address confidence="0.996768">1623-14 Shimotsuruma, Yamato, Kanagawa 242, Japan</address>
<phone confidence="0.992489">81-462-73-4569, 81-462-73-7413 (FAX)</phone>
<email confidence="0.999749">takedaOtrl.vnet.ibm.com</email>
<abstract confidence="0.997803416666667">Machine translation (MT) has recently been formulated in terms of constraint-based knowledge representation and unification theories, but it is becoming more and more evident that it is not possible to design a practical MT system without an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M McCord</author>
</authors>
<title>Slot Grammar: A System for Simpler Construction of Practical Natural Language Grammars (Ed:Studer,R.)&amp;quot;,</title>
<date>1990</date>
<pages>118--145</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="22254" citStr="[10]" startWordPosition="3861" endWordPosition="3861">exicon for a computer-manual domain including about 24,000 lexemes each for English and Japanese, and a general lexicon including about 50,000 English words and their translations. A sample set of 736 sentences was collected from the &amp;quot;IBM AS/400 Getting Started&amp;quot; manual, and was tested with the above semantic transfer and generation algorithm.&amp;quot; The result of the syntactic analysis by the English parser is mapped to a TDAG using a set of semantic equations&amp;quot; obis used, but the noun-noun compound is probably the best translation. / &amp;quot;We used McCord&apos;s English parser based on his English Slot Grammar[10], which covered more than 93% of the sentences. 16We call such a set of semantic equations mapping rides (see Shalt2[20] or KBMT-89[8]). ; ; run the generator with input f-structure 0&gt; *J-GG-START called with ((PRED &amp;quot;*X&amp;quot;) (CAT V) (VTYPE V-6DAN-B) (SUBCAT TRANS) (ASP-TYPE SHUNKAN) (:MOOD ((PRED &amp;quot;Cdec&amp;quot;))) (AUX ((PRED &apos;aux&apos;) (:TIME ((PRED &amp;quot;Opast&amp;quot;))) (:PASSIVE ((PRED &amp;quot;Cminus&amp;quot;))))) (SUBJ ((CAT N) (PRED (XADJUNCT ((XCOP &amp;quot;-CO&amp;quot;) (CAT N) (PRED &apos;.c l.&amp;quot;)))))) 3&gt; *J-GG-S called ;;&lt;start&gt; -&gt;...-&gt; &lt;S&gt; 4&gt; *J-GG-XP called with ;;subj-filler ((CASE (*OB.* &amp;quot;ii&amp;quot; &amp;quot;h1&amp;quot;)) (CAT N) (NEG *UNDEFINED*) (PRED -4KIM&amp;quot;) (XA</context>
</contexts>
<marker>[10]</marker>
<rawString>M. McCord. &amp;quot;Slot Grammar: A System for Simpler Construction of Practical Natural Language Grammars (Ed:Studer,R.)&amp;quot;, pages 118-145. Springer-Verlag, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Murata</author>
<author>M Nagao</author>
</authors>
<title>Determination of Referential Property and Number of Nouns in Japanese Sentences for Machine Translation into English&amp;quot;.</title>
<date>1993</date>
<booktitle>In Proc. of the 5th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>218--225</pages>
<location>Kyoto, Japan,</location>
<contexts>
<context position="9621" citStr="[11]" startWordPosition="1622" endWordPosition="1622"> choosing correct translation of the verb &amp;quot;walk&amp;quot;.8 &apos;For example, the Japanese counterpart &amp;quot;Ws&amp;quot; for the verb &amp;quot;wish&amp;quot; only takes a sentential complement, and no functional control is observed. &apos;Whether or not the subject of the verb is human is often crucial information for making an appropriate choice between the verb&apos;s two Japanese counterparts &amp;quot;&lt;&amp;quot; and &amp;quot;V1-71-Z&amp;quot;. Another example is the problem of identifying number and determiner in Japanese-toEnglish translation. This type of information is rarely available from a syntactic representation of a Japanese noun phrase, and a set of heuristic rules[11] is the only known basis for making a reasonable guess. Even if such contextual processing could be integrated into a logical inference system, the obtained information should be defeasible, and hence should be represented by green nodes and arcs in the TDAGs. Pronoun resolution can be similarly represented by using green nodes and arcs. It is worth looking at the source and target TDAGs in the opposite direction. From the Japanese sentence, lt &lt; tzf 0 John +subj walk +nom +obj wished we get the source TDAG3 in Figure 1, where functional control and number information are missing. With the hel</context>
</contexts>
<marker>[11]</marker>
<rawString>M. Murata and M. Nagao. &amp;quot;Determination of Referential Property and Number of Nouns in Japanese Sentences for Machine Translation into English&amp;quot;. In Proc. of the 5th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 218-225, Kyoto, Japan, July 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Nyberg</author>
<author>3rd</author>
<author>T Mitamura</author>
</authors>
<title>The KANT System: Fast, Accurate, High-Quality Translation in Practical Domains&amp;quot;.</title>
<date>1992</date>
<booktitle>In Proc, of the 14th International Conference on Computational Linguistics,</booktitle>
<pages>1069--1073</pages>
<contexts>
<context position="1942" citStr="[12]" startWordPosition="285" endWordPosition="285">refore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sentences. Some researchers(e.g., Russell[14]) introduced &apos;For example, Yasuhara[26] reported there was an overlap of only 10% between his group&apos;s English and Japanese concept dictionaries, which covered 0.2 million concepts. &apos;Even an MT system with a controlled input language[12] does not claim to be a pure interlingual system. the concept of defeasible reasoning in order to formalize what is missing from a pure constraintbased approach, and control mechanisms for such reasoning have also been proposed[5, 3]. With this additional mechanism, we can formulate the &amp;quot;transfer&amp;quot; process as a mapping from a set of constraints into another set of mandatory and defeasible constraints. This idea leads us further to the concept of &amp;quot;information-based&amp;quot; MT, which means that, with an appropriate representation scheme, a source sentence can be represented by a set of constraints that </context>
</contexts>
<marker>[12]</marker>
<rawString>E. H. Nyberg, 3rd and T. Mitamura. &amp;quot;The KANT System: Fast, Accurate, High-Quality Translation in Practical Domains&amp;quot;. In Proc, of the 14th International Conference on Computational Linguistics, pages 1069-1073, July 1992.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>An Information-Based Syntax and Semantics, Vol.1 Fundamentals&amp;quot;,</title>
<journal>CSLI Lecture Notes, Number</journal>
<pages>13--1987</pages>
<contexts>
<context position="832" citStr="[6, 15, 13]" startWordPosition="111" endWordPosition="113">chine translation (MT) has recently been formulated in terms of constraint-based knowledge representation and unification theories, but it is becoming more and more evident that it is not possible to design a practical MT system without an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT. Introduction With the intensive exploration of contemporary theories on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practica</context>
<context position="16818" citStr="[13]" startWordPosition="2910" endWordPosition="2910">ype inference system,&amp;quot; which makes use of a syntactic class hierarchy so that each lexical class can inherit general properties of its superclasses. Similarly, semantic concepts such as *WISH and *WALK should be separately defined in an ontological hierarchy together with necessary domain knowledge (e.g., selectional constraints on case &apos;The iteration is bounded by the number of nodes and arcs in the TDAG, although the number of possible sequences of operations could be exponential. &apos;For simplicity, we will only consider semantic equations to form the TDAGs. &amp;quot;as in Shieber[15], Pollard and Sag[13], and Russell et al114] 229 Figure 2: TDAG representation of the verb &amp;quot;wished&amp;quot; (embedded in the entire feature structure) Figure 3: Source TDAG for the sentence &amp;quot;The Boston Office called.&amp;quot; fillers and part-of relationships. See KBMT-89[8].) A unification grammar is used for both analysis and generation. Let us assume that we have two unification grammars for English and Japanese. Analyzing a sentence yields a source TDAG with red nodes and arcs. Semantic interpretation resolves possible ambiguity and the resulting TDAG may include all kinds of nodes and arcs. For example, the sentence12 The Bo</context>
</contexts>
<marker>[13]</marker>
<rawString>C. Pollard and I. A. Sag. &amp;quot;An Information-Based Syntax and Semantics, Vol.1 Fundamentals&amp;quot;, CSLI Lecture Notes, Number 13,1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Russell</author>
<author>A Ballim</author>
<author>J Carroll</author>
<author>S WarwickArmstrong</author>
</authors>
<title>A Practical Approach to Multiple Default Inheritance for Unification-Based Lexicons&amp;quot;.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--3</pages>
<contexts>
<context position="1706" citStr="[14]" startWordPosition="250" endWordPosition="250">on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sentences. Some researchers(e.g., Russell[14]) introduced &apos;For example, Yasuhara[26] reported there was an overlap of only 10% between his group&apos;s English and Japanese concept dictionaries, which covered 0.2 million concepts. &apos;Even an MT system with a controlled input language[12] does not claim to be a pure interlingual system. the concept of defeasible reasoning in order to formalize what is missing from a pure constraintbased approach, and control mechanisms for such reasoning have also been proposed[5, 3]. With this additional mechanism, we can formulate the &amp;quot;transfer&amp;quot; process as a mapping from a set of constraints into another set o</context>
<context position="8075" citStr="[14]" startWordPosition="1363" endWordPosition="1363"> (arc) makes a yellow node (arc). • Unification of two green nodes (arcs) makes a green node (arc). Since the green nodes and arcs represent defeasible constraints, unification of a green node (either a root of a TDAG or an atomic node) with a red or yellow node always succeeds, and results in a red or yellow node. When two conflicting green nodes are to be unified, the result is indefinite, or a single non-atomic green node!&apos; Now, the problem is that a red node/arc in a source TDAG (the TDAG for a source sentence) 6An alternative definition is that one green node has precedence over the other[14]. Practically, such a conflicting unification should be postponed until no other possibility is found. 227 Figure 1: Sample TDAGs may not always be a red node/arc in the target TDAG (the TDAG for a target sentence). For example, the functional control of the verb &amp;quot;wish&amp;quot; in the English sentence John wished to walk may produce the TDAG1 in Figure 1, but the red arc corresponding to the agent of the *WALK predicate may not be preserved in a target TDAG2.7 This means that the target sentence alone cannot convey the information that it is John who wished to walk, even if this information can be und</context>
<context position="11479" citStr="[14]" startWordPosition="1941" endWordPosition="1941">s in TDAGs. What is missing in the existing formulation is the provision of some margin between what is said and what is translated. The semantic transfer in our framework is defined as a set of successive operations on TDAGs for creating a sequence of TDAGs to, t1, tk such that to is a source TDAG and tk is a target TDAG that is a successful input to the sentence generator. A powerful contextual processing and a domain knowledge base can be used to infer additional facts and constraints, which correspond to the addition of yellow nodes and arcs. Default inheritance, proposed by Russell et al.[14], provides an efficient way of obtaining further information necessary for translation, which corresponds to the addition of green nodes and arcs. A set of wellknown heuristic rules, which we will describe later in the &amp;quot;Implementation&amp;quot; Section, can also be used to add green nodes and arcs. To complete the model of semantic transfer, we have to introduce &apos;WALK Source T-DAG1 Target T-DAG2 theme &apos;WALK &apos;JOHN &apos;WALK • • red node yellow node green node red arc • iw yellow arc green arc AO num num * &apos;WISH 414* &apos;JOHN *JOHN agent agent agent • sg num &apos;JOHN A agent *WALK Target T-DAG4 &apos;WISH &apos;WISH &apos;WISH S</context>
</contexts>
<marker>[14]</marker>
<rawString>G. Russell, A. Ballim, J. Carroll, and S. WarwickArmstrong. &amp;quot;A Practical Approach to Multiple Default Inheritance for Unification-Based Lexicons&amp;quot;. Computational Linguistics, 18(3):311-337, Sept. 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar&amp;quot;.</title>
<date>1986</date>
<journal>CSLI Lecture Notes, Number</journal>
<volume>4</volume>
<location>Stanford, CA,</location>
<contexts>
<context position="832" citStr="[6, 15, 13]" startWordPosition="111" endWordPosition="113">chine translation (MT) has recently been formulated in terms of constraint-based knowledge representation and unification theories, but it is becoming more and more evident that it is not possible to design a practical MT system without an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT. Introduction With the intensive exploration of contemporary theories on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practica</context>
<context position="15745" citStr="[15]" startWordPosition="2718" endWordPosition="2718">an addition of a green arc, was applied to TDAG3 to obtain TDAG4. These additions are examples of the third and fourth addition operations. Sentence Generation Algorithm Before describing the generation algorithm, let us look at the representation of lexicons and grammars for machine translation. A lexical rule is represented by a set of equations, which introduce red nodes and arcs into a source TDAG.1° A phrasal rule is similarly defined by a set of equations, which also introduce red nodes and arcs for describing a syntactic head and its complements. For example, if we use Shieber&apos;s PATR-II[15] notation, the lexical rule for &amp;quot;wished&amp;quot; can be represented as follows: V wished (V cat) = v (V form) = past (V subj cat) = np (V obj cat) = v (V obj form) = infinitival (V pred) = *WISH (V pred agent) = (V subj pred) (V pred theme) = (V obj pred) (V pred theme agent) = (V subj pred) The last four equations are semantic equations. Its TDAG representation is shown in Figure 2. It would be more practical to further assume that such a lexical rule is obtained from a type inference system,&amp;quot; which makes use of a syntactic class hierarchy so that each lexical class can inherit general properties of </context>
</contexts>
<marker>[15]</marker>
<rawString>S. M. Shieber. &amp;quot;An Introduction to Unification-Based Approaches to Grammar&amp;quot;. CSLI Lecture Notes, Number 4, Stanford, CA, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>A Uniform Architecture for Parsing and Generation&amp;quot;.</title>
<date>1988</date>
<booktitle>In Proc. of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>614--619</pages>
<contexts>
<context position="1065" citStr="[16, 1, 27]" startWordPosition="152" endWordPosition="154">out an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT. Introduction With the intensive exploration of contemporary theories on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sent</context>
</contexts>
<marker>[16]</marker>
<rawString>S. M. Shieber. &amp;quot;A Uniform Architecture for Parsing and Generation&amp;quot;. In Proc. of the 12th International Conference on Computational Linguistics, pages 614-619, August 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
<author>F C N Pereira</author>
<author>G van Noord</author>
<author>R C Moore</author>
</authors>
<title>Semantic-Head-Driven Generation&amp;quot;.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="21280" citStr="[17]" startWordPosition="3707" endWordPosition="3707"> is as follows: Let t be a given TDAG, trnin be the connected subgraph including all the red nodes and arcs in t, and tmar be the connected subgraph of t obtained by changing all the colors of the nodes and arcs to red. Then, any successful generation with the derived TDAG ty, satisfies the condition that tmin subsumes tg, and tg subsumes t,,,as• The proof is immediately obtained from the definition of successful generation and the fact that the generator never introduces a new node or a new arc into an input TDAG. The TDAGs can also be employed by the semantic head-driven generation algorithm[17] while retaining the above property. Semantic monotonicity always holds for a TDAG, since red nodes must be connected. It has been shown by Takeda[21] that semantically nonmonotonic representations can also be handled by introducing a functional semantic class. Implementation We have been developing a prototype Englishto-Japanese MT system, called Shalt2[22], with a lexicon for a computer-manual domain including about 24,000 lexemes each for English and Japanese, and a general lexicon including about 50,000 English words and their translations. A sample set of 736 sentences was collected from </context>
</contexts>
<marker>[17]</marker>
<rawString>S. M. Shieber, F. C. N. Pereira, G. van Noord, and R. C. Moore. &amp;quot;Semantic-Head-Driven Generation&amp;quot;. Computational Linguistics, 16(1):30-42, March 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
<author>Y Schabes</author>
</authors>
<title>Synchronous TreeAdjoining Grammars&amp;quot;.</title>
<date>1990</date>
<booktitle>In Proc. of the 13th International Conference on Computational Linguistics,</booktitle>
<pages>253--258</pages>
<contexts>
<context position="10614" citStr="[18, 27]" startWordPosition="1790" endWordPosition="1791">TDAGs in the opposite direction. From the Japanese sentence, lt &lt; tzf 0 John +subj walk +nom +obj wished we get the source TDAG3 in Figure 1, where functional control and number information are missing. With the help of contextual processing, we get the target TDAG4, which can be used to generate the English sentence &amp;quot;John wished to walk.&amp;quot; Semantic Transfer As illustrated in the previous section, it is often the case that we have to solve mismatches between source and target TDAGs in order to obtain successful translations. Syntactic/semantic transfer has been formulated by several researchers[18, 27] as a means of handling situations in which fully interlingual translation does not work. It is not enough, however, to capture only the equivalent relationship between source and target semantic representations: this is merely a mapping among red nodes and arcs in TDAGs. What is missing in the existing formulation is the provision of some margin between what is said and what is translated. The semantic transfer in our framework is defined as a set of successive operations on TDAGs for creating a sequence of TDAGs to, t1, tk such that to is a source TDAG and tk is a target TDAG that is a succe</context>
</contexts>
<marker>[18]</marker>
<rawString>S. M. Shieber and Y. Schabes. &amp;quot;Synchronous TreeAdjoining Grammars&amp;quot;. In Proc. of the 13th International Conference on Computational Linguistics, pages 253-258, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Smolka</author>
</authors>
<title>A Feature Logic with Subsorts&amp;quot;.</title>
<date>1988</date>
<tech>Technical Report LILOG-REPORT 33,</tech>
<institution>IBM Deutschland GmbH,</institution>
<location>Stuttgart, West Germany,</location>
<contexts>
<context position="862" citStr="[7, 19]" startWordPosition="116" endWordPosition="117">y been formulated in terms of constraint-based knowledge representation and unification theories, but it is becoming more and more evident that it is not possible to design a practical MT system without an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT. Introduction With the intensive exploration of contemporary theories on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of h</context>
</contexts>
<marker>[19]</marker>
<rawString>G. Smolka. &amp;quot;A Feature Logic with Subsorts&amp;quot;. Technical Report LILOG-REPORT 33, IBM Deutschland GmbH, Stuttgart, West Germany, May 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
</authors>
<title>An Object-Oriented Implementation of Machine Translation Systems&amp;quot;.</title>
<date>1993</date>
<booktitle>In Proc. of the 5th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>154--167</pages>
<contexts>
<context position="22374" citStr="[20]" startWordPosition="3881" endWordPosition="3881">including about 50,000 English words and their translations. A sample set of 736 sentences was collected from the &amp;quot;IBM AS/400 Getting Started&amp;quot; manual, and was tested with the above semantic transfer and generation algorithm.&amp;quot; The result of the syntactic analysis by the English parser is mapped to a TDAG using a set of semantic equations&amp;quot; obis used, but the noun-noun compound is probably the best translation. / &amp;quot;We used McCord&apos;s English parser based on his English Slot Grammar[10], which covered more than 93% of the sentences. 16We call such a set of semantic equations mapping rides (see Shalt2[20] or KBMT-89[8]). ; ; run the generator with input f-structure 0&gt; *J-GG-START called with ((PRED &amp;quot;*X&amp;quot;) (CAT V) (VTYPE V-6DAN-B) (SUBCAT TRANS) (ASP-TYPE SHUNKAN) (:MOOD ((PRED &amp;quot;Cdec&amp;quot;))) (AUX ((PRED &apos;aux&apos;) (:TIME ((PRED &amp;quot;Opast&amp;quot;))) (:PASSIVE ((PRED &amp;quot;Cminus&amp;quot;))))) (SUBJ ((CAT N) (PRED (XADJUNCT ((XCOP &amp;quot;-CO&amp;quot;) (CAT N) (PRED &apos;.c l.&amp;quot;)))))) 3&gt; *J-GG-S called ;;&lt;start&gt; -&gt;...-&gt; &lt;S&gt; 4&gt; *J-GG-XP called with ;;subj-filler ((CASE (*OB.* &amp;quot;ii&amp;quot; &amp;quot;h1&amp;quot;)) (CAT N) (NEG *UNDEFINED*) (PRED -4KIM&amp;quot;) (XADJUNCT ((COP -) (CAT N) (PRED &amp;quot;%NA :/&amp;quot;)))) 5&gt; *J-GG-NP called ;;head NP of subj 10&lt; *GG-N-ROOT returns ;;np mod ;;&amp;quot;Hosto</context>
</contexts>
<marker>[20]</marker>
<rawString>K. Takeda. &amp;quot;An Object-Oriented Implementation of Machine Translation Systems&amp;quot;. In Proc. of the 5th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 154-167, July 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
</authors>
<title>Sentence Generation from Partially Constrained Feature Structures&amp;quot;.</title>
<date>1993</date>
<booktitle>In Proc. of the Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>7--16</pages>
<contexts>
<context position="21430" citStr="[21]" startWordPosition="3732" endWordPosition="3732">f t obtained by changing all the colors of the nodes and arcs to red. Then, any successful generation with the derived TDAG ty, satisfies the condition that tmin subsumes tg, and tg subsumes t,,,as• The proof is immediately obtained from the definition of successful generation and the fact that the generator never introduces a new node or a new arc into an input TDAG. The TDAGs can also be employed by the semantic head-driven generation algorithm[17] while retaining the above property. Semantic monotonicity always holds for a TDAG, since red nodes must be connected. It has been shown by Takeda[21] that semantically nonmonotonic representations can also be handled by introducing a functional semantic class. Implementation We have been developing a prototype Englishto-Japanese MT system, called Shalt2[22], with a lexicon for a computer-manual domain including about 24,000 lexemes each for English and Japanese, and a general lexicon including about 50,000 English words and their translations. A sample set of 736 sentences was collected from the &amp;quot;IBM AS/400 Getting Started&amp;quot; manual, and was tested with the above semantic transfer and generation algorithm.&amp;quot; The result of the syntactic analys</context>
</contexts>
<marker>[21]</marker>
<rawString>K. Takeda. &amp;quot;Sentence Generation from Partially Constrained Feature Structures&amp;quot;. In Proc. of the Natural Language Processing Pacific Rim Symposium, pages 7-16, Dec. 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
<author>N Uramoto</author>
<author>T Nasukawa</author>
<author>T Tsutsumi</author>
</authors>
<title>Shalt2- A Symmetric Machine Translation System with Conceptual Transfer&amp;quot;.</title>
<date>1992</date>
<booktitle>In Proc. of the 14th International Conference on Computational Linguistics,</booktitle>
<pages>1034--1038</pages>
<contexts>
<context position="1402" citStr="[24, 22]" startWordPosition="203" endWordPosition="205">ies on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sentences. Some researchers(e.g., Russell[14]) introduced &apos;For example, Yasuhara[26] reported there was an overlap of only 10% between his group&apos;s English and Japanese concept dictionaries, which covered 0.2 million concepts. &apos;Even an MT system with a controlled input language[12] does not claim to be a pure interlingual system. the concep</context>
<context position="21640" citStr="[22]" startWordPosition="3760" endWordPosition="3760">s immediately obtained from the definition of successful generation and the fact that the generator never introduces a new node or a new arc into an input TDAG. The TDAGs can also be employed by the semantic head-driven generation algorithm[17] while retaining the above property. Semantic monotonicity always holds for a TDAG, since red nodes must be connected. It has been shown by Takeda[21] that semantically nonmonotonic representations can also be handled by introducing a functional semantic class. Implementation We have been developing a prototype Englishto-Japanese MT system, called Shalt2[22], with a lexicon for a computer-manual domain including about 24,000 lexemes each for English and Japanese, and a general lexicon including about 50,000 English words and their translations. A sample set of 736 sentences was collected from the &amp;quot;IBM AS/400 Getting Started&amp;quot; manual, and was tested with the above semantic transfer and generation algorithm.&amp;quot; The result of the syntactic analysis by the English parser is mapped to a TDAG using a set of semantic equations&amp;quot; obis used, but the noun-noun compound is probably the best translation. / &amp;quot;We used McCord&apos;s English parser based on his English Sl</context>
</contexts>
<marker>[22]</marker>
<rawString>K. Takeda, N. Uramoto, T. Nasukawa, and T. Tsutsumi. &amp;quot;Shalt2- A Symmetric Machine Translation System with Conceptual Transfer&amp;quot;. In Proc. of the 14th International Conference on Computational Linguistics, pages 1034-1038, July 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
<author>K Knight</author>
</authors>
<title>Pseudo Unification and Full Unification&amp;quot;.</title>
<date>1987</date>
<tech>Technical Report CMU-CMT-88-MEMO,</tech>
<institution>Center for Machine Translation, Carnegie Mellon University,</institution>
<marker>[23]</marker>
<rawString>M. Tomita and K. Knight. &amp;quot;Pseudo Unification and Full Unification&amp;quot;. Technical Report CMU-CMT-88-MEMO, Center for Machine Translation, Carnegie Mellon University, November 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Uchida</author>
</authors>
<title>ATLAS II: A Machine Translation System Using Conceptual Structure as an Interlingua&amp;quot;.</title>
<date>1988</date>
<booktitle>In Proc. of 2nd Intl. Conf. on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<pages>150--160</pages>
<contexts>
<context position="1402" citStr="[24, 22]" startWordPosition="203" endWordPosition="205">ies on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sentences. Some researchers(e.g., Russell[14]) introduced &apos;For example, Yasuhara[26] reported there was an overlap of only 10% between his group&apos;s English and Japanese concept dictionaries, which covered 0.2 million concepts. &apos;Even an MT system with a controlled input language[12] does not claim to be a pure interlingual system. the concep</context>
</contexts>
<marker>[24]</marker>
<rawString>H. Uchida. &amp;quot;ATLAS II: A Machine Translation System Using Conceptual Structure as an Interlingua&amp;quot;. In Proc. of 2nd Intl. Conf. on Theoretical and Methodological Issues in Machine Translation of Natural Languages, pages 150-160, June 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wedekind</author>
</authors>
<title>Generation as Structure Driven Derivation&amp;quot;.</title>
<date>1988</date>
<booktitle>In Proc. of the 12th International Conference on Computational Liguistics,</booktitle>
<pages>732--737</pages>
<contexts>
<context position="3798" citStr="[25]" startWordPosition="614" endWordPosition="614">ce. If C+ C_ =41, and Cnew = 4), the target sentence is said to be under-generated, while it is said to be over-generated when C+ = = and Cn„,, 0 0.3 In either case, C_ must be empty if a consistent translation is required. Thus, the goal of machine translation is to find an optimal pair of source and target sentences that minimizes C+, C—, and Cnew. Intuitively, Co corresponds to essential information, and C+ and Ca,,,, can be viewed as language-dependent supportive information. C_ might be the inconsistency be&apos;The notions of completeness and coherence in LFG[6] have been employed by Wedekind[25] to avoid over- and under-generation. 226 tween the assumptions of the source- and targetlanguage speakers. In this paper, we introduce tricolor DAGs to represent the above constraints, and discuss how tricolor DAGs are used for practical MT systems. In particular, we give a generation algorithm that incorporates the notion of semantic transfer by gradually approaching the optimal target sentence through the use of tricolor DAGs, when a fully interlingual translation fails. Tricolor DAGs give a graph-algorithmic interpretation of the constraints, and the distinctions between the types of const</context>
</contexts>
<marker>[25]</marker>
<rawString>J. Wedekind. &amp;quot;Generation as Structure Driven Derivation&amp;quot;. In Proc. of the 12th International Conference on Computational Liguistics, pages 732-737, August 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yasuhara</author>
</authors>
<title>Conceptual Transfer in an Interlingua. Method and Example Based MT&amp;quot;.</title>
<date>1993</date>
<booktitle>In Proc. of the Natural Language Processing Pacific Rim Symposium &apos;93,</booktitle>
<pages>376--379</pages>
<location>Fukuoka, Japan,</location>
<contexts>
<context position="1745" citStr="[26]" startWordPosition="254" endWordPosition="254"> a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sentences. Some researchers(e.g., Russell[14]) introduced &apos;For example, Yasuhara[26] reported there was an overlap of only 10% between his group&apos;s English and Japanese concept dictionaries, which covered 0.2 million concepts. &apos;Even an MT system with a controlled input language[12] does not claim to be a pure interlingual system. the concept of defeasible reasoning in order to formalize what is missing from a pure constraintbased approach, and control mechanisms for such reasoning have also been proposed[5, 3]. With this additional mechanism, we can formulate the &amp;quot;transfer&amp;quot; process as a mapping from a set of constraints into another set of mandatory and defeasible constraints.</context>
</contexts>
<marker>[26]</marker>
<rawString>H. Yasuhara. &amp;quot;Conceptual Transfer in an Interlingua. Method and Example Based MT&amp;quot;. In Proc. of the Natural Language Processing Pacific Rim Symposium &apos;93, pages 376-379, Fukuoka, Japan, Dec. 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zajac</author>
</authors>
<title>A Uniform Architecture for Parsing, Generation and Transfer&amp;quot;.</title>
<date>1991</date>
<booktitle>In Proc. of a Workshop on Reversible Grammar in Natural Language Processing,</booktitle>
<pages>71--80</pages>
<contexts>
<context position="1065" citStr="[16, 1, 27]" startWordPosition="152" endWordPosition="154">out an adequate method of handling mismatches between semantic representations in the source and target languages. In this paper, we introduce the idea of &amp;quot;information-based&amp;quot; MT, which is considerably more flexible than interlingual MT or the conventional transfer-based MT. Introduction With the intensive exploration of contemporary theories on unification grammars[6, 15, 13] and feature structures[7, 19] in the last decade, the old image of machine translation (MT) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture[16, 1, 27]. The developers of MT systems based on the constraint-based formalism found a serious problem in &amp;quot;language mismatching,&amp;quot; namely, the difference between semantic representations in the source and target languages.&apos; Attempts to design a. pure interlingual MT system were therefore abandoned,2 and the notion of &amp;quot;semantic transfer&amp;quot;[24, 22] came into focus as a practical solution to the problem of handling the language mismatching. The constraint-based formalism[2] seemed promising as a formal definition of transfer, but pure constraints are too rigid to be precisely imposed on target-language sent</context>
<context position="10614" citStr="[18, 27]" startWordPosition="1790" endWordPosition="1791">TDAGs in the opposite direction. From the Japanese sentence, lt &lt; tzf 0 John +subj walk +nom +obj wished we get the source TDAG3 in Figure 1, where functional control and number information are missing. With the help of contextual processing, we get the target TDAG4, which can be used to generate the English sentence &amp;quot;John wished to walk.&amp;quot; Semantic Transfer As illustrated in the previous section, it is often the case that we have to solve mismatches between source and target TDAGs in order to obtain successful translations. Syntactic/semantic transfer has been formulated by several researchers[18, 27] as a means of handling situations in which fully interlingual translation does not work. It is not enough, however, to capture only the equivalent relationship between source and target semantic representations: this is merely a mapping among red nodes and arcs in TDAGs. What is missing in the existing formulation is the provision of some margin between what is said and what is translated. The semantic transfer in our framework is defined as a set of successive operations on TDAGs for creating a sequence of TDAGs to, t1, tk such that to is a source TDAG and tk is a target TDAG that is a succe</context>
</contexts>
<marker>[27]</marker>
<rawString>R. Zajac. &amp;quot;A Uniform Architecture for Parsing, Generation and Transfer&amp;quot;. In Proc. of a Workshop on Reversible Grammar in Natural Language Processing, pages 71-80, June 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>