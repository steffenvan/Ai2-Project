<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000134">
<title confidence="0.9941915">
Detection of Topic and its Extrinsic Evaluation Through Multi-Document
Summarization
</title>
<author confidence="0.992326">
Yoshimi Suzuki
</author>
<affiliation confidence="0.948465333333333">
Interdisciplinary Graduate School of
Medicine and Engineering
University of Yamanashi
</affiliation>
<address confidence="0.740855">
Kofu, 400-8511, JAPAN
</address>
<email confidence="0.997994">
ysuzuki@yamanashi.ac.jp
</email>
<sectionHeader confidence="0.993888" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988210526316">
This paper presents a method for detect-
ing words related to a topic (we call them
topic words) over time in the stream of
documents. Topic words are widely dis-
tributed in the stream of documents, and
sometimes they frequently appear in the
documents, and sometimes not. We pro-
pose a method to reinforce topic words
with low frequencies by collecting docu-
ments from the corpus, and applied Latent
Dirichlet Allocation (Blei et al., 2003) to
these documents. For the results of LDA,
we identified topic words by using Mov-
ing Average Convergence Divergence. In
order to evaluate the method, we applied
the results of topic detection to extractive
multi-document summarization. The re-
sults showed that the method was effective
for sentence selection in summarization.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972105263158">
As the volume of online documents has drastically
increased, the analysis of topic bursts, topic drift
or detection of topic is a practical problem attract-
ing more and more attention (Allan et al., 1998;
Swan and Allan, 2000; Allan, 2003; Klinken-
berg, 2004; Lazarescu et al., 2004; Folino et al.,
2007). The earliest known approach is the work
of Klinkenberg and Joachims (Klinkenberg and
Joachims, 2000). They have attempted to han-
dle concept changes by focusing a window with
documents sufficiently close to the target concept.
Mane et. al. proposed a method to generate
maps that support the identification of major re-
search topics and trends (Mane and Borner, 2004).
The method used Kleinberg’s burst detection al-
gorithm, co-occurrences of words, and graph lay-
out technique. Scholz et. al. have attempted to
use different ensembles obtained by training sev-
eral data streams to detect concept drift (Scholz,
</bodyText>
<note confidence="0.7423732">
Fumiyo Fukumoto
Interdisciplinary Graduate School of
Medicine and Engineering
University of Yamanashi
Kofu, 400-8511, JAPAN
</note>
<email confidence="0.962175">
fukumoto@yamanashi.ac.jp
</email>
<bodyText confidence="0.999928658536585">
2007). However the ensemble method itself re-
mains a problem that how to manage several clas-
sifiers effectively. He and Parket attempted to find
bursts, periods of elevated occurrence of events as
a dynamic phenomenon instead of focusing on ar-
rival rates (He and Parker, 2010). However, the
fact that topics are widely distributed in the stream
of documents, and sometimes they frequently ap-
pear in the documents, and sometimes not often
hamper such attempts.
This paper proposes a method for detecting
topic over time in series of documents. We rein-
forced words related to a topic with low frequen-
cies by collecting documents from the corpus, and
applied Latent Dirichlet Allocation (LDA) (Blei
et al., 2003) to these documents in order to ex-
tract topic candidates. For the results of LDA, we
applied Moving Average Convergence Divergence
(MACD) to find topic words while He et. al., ap-
plied it to find bursts. The MACD is a technique
to analyze stock market trends (Murphy, 1999). It
shows the relationship between two moving av-
erages of prices modeling bursts as intervals of
topic dynamics, i.e., positive acceleration. Fuku-
moto et. al also applied MACD to find topics.
However, they applied it only to the words with
high frequencies in the documents (Fukumoto et
al., 2013). In contrast, we applied it to the topic
candidates obtained by LDA.
We examined our method by extrinsic evalua-
tion, i.e., we applied the results of topic detection
to extractive multi-document summarization. We
assume that a salient sentence includes words re-
lated to the target topic, and an event of each doc-
uments. Here, an event is something that occurs
at a specific place and time associated with some
specific actions(Allan et al., 1998). We identified
event words by using the traditional tf∗idf method
applied to the results of named entities. Each sen-
tence in documents is represented using a vector
of frequency weighted words that can be event
</bodyText>
<page confidence="0.967335">
241
</page>
<bodyText confidence="0.372505428571429">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 241–246,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
or topic words. We used Markov Random Walk
(MRW) to compute the rank scores for the sen-
tences (Page et al., 1998). Finally, we selected a
certain number of sentences according to the rank
score into a summary.
</bodyText>
<sectionHeader confidence="0.966868" genericHeader="method">
2 Topic Detection
</sectionHeader>
<subsectionHeader confidence="0.999899">
2.1 Extraction of Topic Candidates
</subsectionHeader>
<bodyText confidence="0.999315666666667">
LDA presented by (Blei et al., 2003) models
each document as a mixture of topics (we call
it lda topic to discriminate our topic candidates),
and generates a discrete probability distribution
over words for each lda topic. The generative pro-
cess for LDA can be described as follows:
</bodyText>
<listItem confidence="0.9886806">
1. For each topic k = 1, · · · , K, generate φk,
multinomial distribution of words specific to
the topic k from a Dirichlet distribution with
parameter Q;
2. For each document d = 1, · · · , D, generate Bd,
multinomial distribution of topics specific to
the document d from a Dirichlet distribution
with parameter α;
3. For each word n = 1, · · · , Nd in document d;
(a) Generate a topic zdn of the nth word
in the document d from the multinomial
distribution Bd
(b) Generate a word wdn, the word associ-
ated with the nth word in document d
from multinomial φzdn
</listItem>
<bodyText confidence="0.980464666666667">
Like much previous work on LDA, we used Gibbs
sampling to estimate φ and B. The sampling prob-
ability for topic zi in document d is given by:
</bodyText>
<equation confidence="0.999296">
(nv \i,j + β)(nd \i,j +α)
P(zi  |z\i, W) = (n·\i,j + Wβ)(nd\i,· + Tα). (1)
</equation>
<bodyText confidence="0.9985604">
z\i refers to a topic set Z, not including the cur-
rent assignment zi. nv\i,j is the count of word v
in topic j that does not include the current assign-
ment zi, and n·\i,j indicates a summation over that
dimension. W refers to a set of documents, and T
denotes the total number of unique topics. After
a sufficient number of sampling iterations, the ap-
proximated posterior can be used to estimate φ and
B by examining the counts of word assignments to
topics and topic occurrences in documents. The
</bodyText>
<figureCaption confidence="0.997527">
Figure 1: Lda topic cluster and task cluster
</figureCaption>
<bodyText confidence="0.994353607142857">
approximated probability of topic k in the docu-
ment d, Bkˆd, and the assignments word w to topic
k, ˆφwk are given by:
We used documents prepared by summarization
tasks, NTCIR and DUC data as each task consists
of series of documents with the same topic. We
applied LDA to the set consisting of all documents
in the summarization tasks and documents from
the corpus. We need to estimate the appropriate
number of lda topic.
Let k′ be the number of lda topics and d′ be
the number of topmost d′ documents assigned to
each lda topic. We note that the result obtained
by LDA can be regarded as the two types of clus-
tering result shown in Figure 1: (i) each cluster
corresponds to each lda topic (topic id0, topic id1
· · · in Figure 1), and each element of the clusters
is the document in the summarization tasks (task1,
task2, · · · in Figure 1) or from the corpus (doc in
Figure 1), and (ii) each cluster corresponds to the
summarization task and each element of the clus-
ters is the document in the summarization tasks
or the document from the corpus assigned topic
id. For example, DUC2005 consists of 50 tasks.
Therefore the number of different clusters is 50.
We call the former lda topic cluster and the latter
task cluster. We estimated k′ and d′ by using En-
tropy measure given by:
</bodyText>
<figure confidence="0.942784344827586">
E l1 N-
o l E N3 P(Ai, Cj) log P(Ai, Cj).(4)
g j i
(i) Lda_topic clusters
cluster
(ii) Task clusters
topic id1
topic id0
task1 task2
topic id0
...
topic id2
topic id1
topic id2
...
....
cluster
....
task2
task1
doc
task1
task3
task2
task1
doc
....
....
topic id0 topic id1
</figure>
<equation confidence="0.9337286">
θk ˆ d = Ndk + α Nd + αK .(2)
ˆφw k = Nkw + β
N
k + βV .
(3)
</equation>
<page confidence="0.972981">
242
</page>
<bodyText confidence="0.999947615384615">
l refers to the number of clusters. P(Ai, Cj) is a
probability that the elements of the cluster Cj as-
signed to the correct class Ai. N denotes the total
number of elements and Nj shows the total num-
ber of elements assigned to the cluster Cj. The
value of E ranges from 0 to 1, and the smaller
value of E indicates better result. Let Et,,pic and
Etask are entropy value of lda topic cluster and
task cluster, respectively. We chose the parame-
ters k′ and d′ whose value of the summation of
Et,,pic and Etask is smallest. For each lda topic,
we extracted words whose probabilities are larger
than zero, and regarded these as topic candidates.
</bodyText>
<subsectionHeader confidence="0.995907">
2.2 Topic Detection by MACD
</subsectionHeader>
<bodyText confidence="0.999327">
The proposed method does not simply use MACD
to find bursts, but instead determines topic words
in series of documents. Unlike Dynamic Topic
Models (Blei and Lafferty, 2006), it does not as-
sume Gaussian distribution so that it is a natural
way to analyze bursts which depend on the data.
We applied it to extract topic words in series of
documents. MACD histogram defined by Eq. (6)
shows a difference between the MACD and its
moving average. MACD of a variable xt is defined
by the difference of n1-day and n2-day moving
averages, MACD(n1,n2) = EMA(n1) - EMA(n2).
Here, EMA(ni) refers to ni-day Exponential Mov-
ing Average (EMA). For a variable x = x(t) which
has a corresponding discrete time series x = {xt  |t
= 0,1,· · · }, the n-day EMA is defined by Eq. (5).
</bodyText>
<equation confidence="0.8014497">
EMA(n)[x]t = αxt + (1 − α)EMA(n − 1)[x]t_1
n
= E α(1 − α)kxt_k. (5)
k=0
α refers to a smoothing factor and it is often taken
to be 2
(n+1). MACD histogram shows a difference
between the MACD and its moving average1.
hist(n1, n2, n3) = MACD(n1, n2) −
EMA(n3)[MACD(n1, n2)]. (6)
</equation>
<bodyText confidence="0.999174857142857">
The procedure for topic detection with MACD
is illustrated in Figure 2. Let A be a series of doc-
uments and w be one of the topic candidates ob-
tained by LDA. Each document in A is sorted in
chronological order. We set A to the documents
from the summarization task. Whether or not a
word w is a topic word is judged as follows:
</bodyText>
<footnote confidence="0.992465">
1In the experiment, we set n1, n2, and n3 to 4, 8 and 5,
respectively (He and Parker, 2010).
</footnote>
<figureCaption confidence="0.994131">
Figure 2: Topic detection with MACD
</figureCaption>
<listItem confidence="0.9110796">
1. Create document-based MACD histogram
where X-axis refers to T, i.e., a period of time
(numbered from day 1 to 365). Y-axis is the
document count in A per day. Hereafter, re-
ferred to as correct histogram.
2. Create term-based MACD histogram where
X-axis refers to T, and Y-axis denotes bursts
of word w in A. Hereafter, referred to as
bursts histogram.
3. We assume that if a term w is informative
</listItem>
<bodyText confidence="0.9262324">
for summarizing a particular documents in
a collection, its burstiness approximates the
burstiness of documents in the collection.
Because w is a representative word of each
document in the task. Based on this assump-
tion, we computed similarity between correct
and word histograms by using KL-distance2.
Let P and Q be a normalized distance of
correct histogram, and bursts histogram, re-
spectively. KL-distance is defined by D(P ||
</bodyText>
<equation confidence="0.793544">
Q) = Ei=1 P(xi) log P (xi)
</equation>
<bodyText confidence="0.982606">
Q(xi) where xi refers
bursts in time i. If the value of D(P  ||Q)
is smaller than a certain threshold value, w is
regarded as a topic word.
</bodyText>
<sectionHeader confidence="0.996103" genericHeader="method">
3 Extrinsic Evaluation to Summarization
</sectionHeader>
<subsectionHeader confidence="0.990603">
3.1 Event detection
</subsectionHeader>
<bodyText confidence="0.916066875">
An event word is something that occurs at a spe-
cific place and time associated with some spe-
cific actions (Allan, 2003; Allan et al., 1998). It
refers to notions of who(person), where(place),
2We tested KL-distance, histogram intersection and Bhat-
tacharyya distance to obtain similarities. We reported only
the result obtained by KL-distance as it was the best results
among them.
</bodyText>
<figure confidence="0.991313333333333">
Correct histogram Bursts histogram
bursts bursts
T
bursts Histogram similarity
T
T
</figure>
<page confidence="0.996197">
243
</page>
<bodyText confidence="0.999974666666667">
when(time) including what, why and how in a doc-
ument. Therefore, we can assume that named en-
tities(NE) are linguistic features for event detec-
tion. An event word refers to the theme of the
document itself, and frequently appears in the doc-
ument but not frequently appear in other docu-
ments. Therefore, we first applied NE recogni-
tion to the target documents to be summarized, and
then calculated tf*idf to the results of NE recogni-
tion. We extracted words whose tf*idf values are
larger than a certain threshold value, and regarded
these as event words.
</bodyText>
<subsectionHeader confidence="0.99962">
3.2 Sentence extraction
</subsectionHeader>
<bodyText confidence="0.999934045454546">
We recall that our hypothesis about key sentences
in multiple documents is that they include topic
and event words. Each sentence in the docu-
ments is represented using a vector of frequency
weighted words that can be event or topic words.
Like much previous work on extractive sum-
marization (Erkan and Radev, 2004; Mihalcea
and Tarau, 2005; Wan and Yang, 2008), we used
Markov Random Walk (MRW) model to compute
the rank scores for the sentences. Given a set
of documents to be summarized, G = (5, E) is
a graph reflecting the relationships between two
sentences. 5 is a set of vertices, and each vertex
si in 5 is a sentence. E is a set of edges, and each
edge eij in E is associated with an affinity weight
f(i —* j) between sentences si and sj (i =� j). The
affinity weight is computed using cosine measure
between the two sentences, si and sj. Two ver-
tices are connected if their affinity weight is larger
than 0 and we let f(i —* i)= 0 to avoid self tran-
sition. The transition probability from si to sj is
then defined as follows:
</bodyText>
<equation confidence="0.997063333333333">
, if Ef =6 0
p(i → j) =
0 , otherwise.
</equation>
<bodyText confidence="0.999956">
We used the row-normalized matrix Uij =
(Uij)|S|×|S |to describe G with each entry corre-
sponding to the transition probability, where Uij =
p(i —* j). To make U a stochastic matrix, the rows
with all zero elements are replaced by a smoothing
vector with all elements set to 1
|S|. The final transi-
tion matrix is given by formula (8), and each score
of the sentence is obtained by the principal eigen-
vector of the matrix M.
</bodyText>
<equation confidence="0.9995895">
M = µUT + (1 − µ)
 |S  |�e�eT . (8)
</equation>
<bodyText confidence="0.999848">
We selected a certain number of sentences accord-
ing to rank score into the summary.
</bodyText>
<sectionHeader confidence="0.999699" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998514">
4.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.9999795">
We applied the results of topic detection to ex-
tractive multi-document summarization task, and
examined how the results of topic detection af-
fect the overall performance of the salient sen-
tence selection. We used two tasks, Japanese and
English summarization tasks, NTCIR-33 SUMM
Japanese and DUC4 English data. The baselines
are (i) MRW model (MRV): The method ap-
plies the MRW model only to the sentences con-
sisted of noun words, (ii) Event detection (Event):
The method applies the MRW model to the result
of event detection, (iii) Topic Detection by LDA
(LDA): MRW is applied to the result of topic can-
didates detection by LDA and (iv) Topic Detec-
tion by LDA and MACD (LDA &amp; MACD): MRW
is applied to the result of topic detection by LDA
and MACD only, i.e., the method does not include
event detection.
</bodyText>
<subsectionHeader confidence="0.972">
4.2 NTCIR data
</subsectionHeader>
<bodyText confidence="0.998721434782609">
The data used in the NTCIR-3 multi-document
summarization task is selected from 1998 to 1999
of Mainichi Japanese Newspaper documents. The
gold standard data provided to human judges con-
sists of FBFREE DryRun and FormalRun. Each
data consists of 30 tasks. There are two types of
correct summary according to the character length,
“long” and “short”, All series of documents were
tagged by CaboCha (Kudo and Matsumoto, 2003).
We used person name, organization, place and
proper name extracted from NE recognition (Kudo
and Matsumoto, 2003) for event detection, and
noun words including named entities for topic de-
tection. FBFREE DryRun data is used to tuning
parameters, i.e., the number of extracted words ac-
cording to the tf*idf value, and the threshold value
of KL-distance. The size that optimized the aver-
age Rouge-1(R-1) score across 30 tasks was cho-
sen. As a result, we set tf*idf and KL-distance to
100 and 0.104, respectively.
We used FormalRun as a test data, and another
set consisted of 218,724 documents from 1998 to
1999 of Mainichi newspaper as a corpus used in
</bodyText>
<footnote confidence="0.999266">
3http://research.nii.ac.jp/ntcir/
4http://duc.nist.gov/pubs.html
</footnote>
<equation confidence="0.761367444444444">
�
��� �
����
f(i→j)
|S|
L
k=1
f(i→k)
(7)
</equation>
<page confidence="0.924383">
244
</page>
<figure confidence="0.514093">
Number of documents
</figure>
<figureCaption confidence="0.941508">
Figure 3: Entropy against the # of topics and doc-
uments
</figureCaption>
<table confidence="0.599031571428571">
Short Long
R-1 R-1
.369 .454
.625 .724
.525 .712
.630 .742
.678 .744
</table>
<tableCaption confidence="0.99233">
Table 1: Sentence Extraction (NTCIR-3 test data)
</tableCaption>
<bodyText confidence="0.999121458333333">
LDA and MACD. We estimated the number of k′
and d′ in LDA, i.e., we searched k′ and d′ in steps
of 100 from 200 to 900. Figure 3 illustrates en-
tropy value against the number of topics k′ and
documents d′ using 30 tasks of FormalRun data.
Each plot shows that at least one of the docu-
ments for each summarization task is included in
the cluster. We can see from Figure 3 that the
value of entropy depends on the number of doc-
uments rather than the number of topics. From
the result shown in Figure 3, the minimum entropy
value was 0.025 and the number of topics and doc-
uments were 400 and 300, respectively. We used
them in the experiment. The summarization re-
sults are shown in Table 1.
Table 1 shows that our approach, “Event &amp;
Topic” outperforms other baselines, regardless of
the summary type (long/short). Topic candidates
include surplus words that are not related to the
topic because the results obtained by “LDA” were
worse than those obtained by “LDA &amp; MACD”,
and even worse than “Event” in both short and
long summary. This shows that integration of
LDA and MACD is effective for topic detection.
</bodyText>
<subsectionHeader confidence="0.998405">
4.3 DUC data
</subsectionHeader>
<bodyText confidence="0.999165333333333">
We used DUC2005 consisted of 50 tasks for train-
ing, and 50 tasks of DUC2006 data for testing in
order to estimate parameters. We set tf∗idf and
</bodyText>
<table confidence="0.999480333333333">
Method R-1 Method R-1
MRW .381 Event .407
LDA .402 LDA &amp; MACD .428
Event &amp; Topic .438
PYTHY .426 HybHSum .456
hPAM .412 TTM .447
</table>
<tableCaption confidence="0.998283">
Table 2: Comparative results (DUC2007 test data)
</tableCaption>
<bodyText confidence="0.99966784375">
KL-distance to 80 and 0.9. The minimum en-
tropy value was 0.050 and the number of topics
and documents were 500 and 600, respectively.
45 tasks from DUC2007 were used to evaluate
the performance of the method. All documents
were tagged by Tree Tagger (Schmid, 1995) and
Stanford Named Entity Tagger 5 (Finkel et al.,
2005). We used person name, organization and lo-
cation for event detection, and noun words includ-
ing named entities for topic detection. AQUAINT
corpus6 which consists of 1,033,461 documents
are used as a corpus in LDA and MACD. Table
2 shows Rouge-1 against unigrams.
We can see from Table 2 that Rouge-1 obtained
by our approach was also the best compared to the
baselines. Table 2 also shows the performance of
other research sites reported by (Celikylmaz and
Hakkani-Tur, 2010). The top site was “HybH-
Sum” by (Celikylmaz and Hakkani-Tur, 2010).
However, the method is a semi-supervised tech-
nique that needs a tagged training data. Our ap-
proach achieves performance approaching the top-
performing unsupervised method, “TTM” (Ce-
likylmaz and Hakkani-Tur, 2011), and is compet-
itive to “PYTHY” (Toutanoval et al., 2007) and
“hPAM” (Li and McCallum, 2006). Prior work
including “TTM” has demonstrated the usefulness
of semantic concepts for extracting salient sen-
tences. For future work, we should be able to
obtain further advantages in efficacy in our topic
detection and summarization approach by disam-
biguating topic senses.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9998066">
The research described in this paper explores a
method for detecting topic words over time in se-
ries of documents. The results of extrinsic evalu-
ation showed that integration of LDA and MACD
is effective for topic detection.
</bodyText>
<footnote confidence="0.9957535">
5http://nlp.stanford.edu/software/CRF-NER.shtml
6http://catalog.ldc.upenn.edu/LDC2002T31
</footnote>
<figure confidence="0.998599157894737">
Entropy
㻞㻜㻜 㻟㻜㻜 㻠㻜㻜 㻡㻜㻜 㻢㻜㻜 㻣㻜㻜 㻤㻜㻜 㻥㻜㻜
㻜㻚㻝㻞
㻜㻚㻝㻜
㻜㻚㻜㻤
㻜㻚㻜㻢
㻜㻚㻜㻠
㻜㻚㻜㻞
㻜㻚㻜㻜
㻞㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕 㻟㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕
㻠㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕 㻡㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕
㻢㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕 㻣㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕
㻤㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕 㻥㻜㻜 㻔㼠㼛㼜㼕㼏㼟㻕
Method
MRW
Event
LDA
LDA &amp; MACD
Event &amp; Topic
</figure>
<page confidence="0.995282">
245
</page>
<sectionHeader confidence="0.988949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999741594059406">
J. Allan, J. Carbonell, G. Doddington, J. Yamron, and
Y. Yang. 1998. Topic Detection and Tracking Pilot
Study Final Report. In Proc. of the DARPA Broad-
cast News Transcription and Understanding Work-
shop.
J. Allan, editor. 2003. Topic Detection and Tracking.
Kluwer Academic Publishers.
D. M. Blei and J. D. Lafferty. 2006. Dynamic Topic
Models. In Proc. of the 23rd International Confer-
ence on Machine Learning, pages 113–120.
D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. La-
tent Dirichlet Allocation. In The Journal ofMachine
Learning Research, volume 3, pages 993–1022.
A. Celikylmaz and D. Hakkani-Tur. 2010. A Hy-
bird Hierarchical Model for Multi-Document Sum-
marization. In Proc. of the 48th Annual Meeting
of the Association for Computational Linguistics,
pages 815–824.
A. Celikylmaz and D. Hakkani-Tur. 2011. Discovery
of Topically Coherent Sentences for Extractive Sum-
marization. In Proc. of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 491–499.
G. Erkan and D. Radev. 2004. LexPageRank: Prestige
in Multi-Document Text Summarization. In Proc. of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, pages 365–371.
J. R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating Non-local Information into Information
Extraction Systems by Gibbs Sampling. In Proc.
of the 43rd Annual Meeting of the Association for
Computational Linguistics, pages 363–370.
G. Folino, C. Pizzuti, and G. Spezzano. 2007. An
Adaptive Distributed Ensemble Approach to Mine
Concept-Drifting Data Streams. In Proc. of the 19th
IEEE International Conference on Tools with Artifi-
cial Intelligence, pages 183–188.
F. Fukumoto, Y. Suzuki, A. Takasu, and S. Matsuyoshi.
2013. Multi-document summarization based on
event and topic detection. In Proc. of the 6th Lan-
guage and Technology Conference: Human Lan-
guage Technologies as a Challenge for Computer
Science and Linguistics, pages 117–121.
D. He and D. S. Parker. 2010. Topic Dynamics: An
Alternative Model of Bursts in Streams of Topics.
In Proc. of the 16th ACM Special Interest Group on
Knowledge Discovery and Data Mining, pages 443–
452.
R. Klinkenberg and T. Joachims. 2000. Detecting
Concept Drift with Support Vector Machines. In
Proc. of the 17th International Conference on Ma-
chine Learning, pages 487–494.
R. Klinkenberg. 2004. Learning Drifting Concepts:
Example Selection vs. Example Weighting. Intel-
leginet Data Analysis, 8(3):281–300.
T. Kudo and Y. Matsumoto. 2003. Fast methods for
kernel-based text analysis. In Proc. of 41st Annual
Meeting of the Association for Computational Lin-
guistics, pages 24–31.
M. M. Lazarescu, S. Venkatesh, and H. H. Bui. 2004.
Using Multiple Windows to Track Concept Drift.
Intelligent Data Analysis, 8(1):29–59.
W. Li and A. McCallum. 2006. Pachinko Alloca-
tion: Dag-Structure Mixture Model of Topic Cor-
relations. In Proc. of the 23rd International Confer-
ence on Machine Learning, pages 577–584.
K. Mane and K. Borner. 2004. Mapping Topics
and Topic Bursts in PNAS. Proc. of the National
Academy of Sciences of the United States of Amer-
ica, 101:5287–5290.
R. Mihalcea and P. Tarau. 2005. Language Indepen-
dent Extractive Summarization. In In Proc. of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics, pages 49–52.
J. Murphy. 1999. Technical Analysis of the Financial
Markets. Prentice Hall.
L. Page, S. Brin, R. Motwani, and T. Winograd. 1998.
The Pagerank Citation Ranking: Bringing Order to
the Web. In Technical report, Stanford Digital Li-
braries.
H. Schmid. 1995. Improvements in Part-of-Speech
Tagging with an Application to German. In Proc. of
the European chapter of the Association for Compu-
tational Linguistics SIGDAT Workshop.
M. Scholz. 2007. Boosting Classifiers for Drifting
Concepts. Intelligent Data Analysis, 11(1):3–28.
R. Swan and J. Allan. 2000. Automatic Generation
of Overview Timelines. In Proc. of the 23rd An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
pages 38–45.
K. Toutanoval, C. Brockett, M. Gammon, J. Jagarla-
mudi, H. Suzuki, and L. Vanderwende. 2007. The
Phthy Summarization System: Microsoft Research
at DUC. In Proc. ofDocument Understanding Con-
ference 2007.
X. Wan and J. Yang. 2008. Multi-Document Summa-
rization using Cluster-based Link Analysis. In Proc.
of the 31st Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, pages 299–306.
</reference>
<page confidence="0.99872">
246
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.361515">
<title confidence="0.990785">Detection of Topic and its Extrinsic Evaluation Through Multi-Document Summarization</title>
<author confidence="0.564837">Yoshimi</author>
<affiliation confidence="0.758441">Interdisciplinary Graduate School Medicine and University of</affiliation>
<address confidence="0.966656">Kofu, 400-8511,</address>
<email confidence="0.986591">ysuzuki@yamanashi.ac.jp</email>
<abstract confidence="0.99927455">This paper presents a method for detecting words related to a topic (we call them topic words) over time in the stream of documents. Topic words are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not. We propose a method to reinforce topic words with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (Blei et al., 2003) to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allan</author>
<author>J Carbonell</author>
<author>G Doddington</author>
<author>J Yamron</author>
<author>Y Yang</author>
</authors>
<title>Topic Detection and Tracking Pilot Study Final Report.</title>
<date>1998</date>
<booktitle>In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop.</booktitle>
<contexts>
<context position="1222" citStr="Allan et al., 1998" startWordPosition="184" endWordPosition="187">m the corpus, and applied Latent Dirichlet Allocation (Blei et al., 2003) to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have att</context>
<context position="3804" citStr="Allan et al., 1998" startWordPosition="601" endWordPosition="604">ive acceleration. Fukumoto et. al also applied MACD to find topics. However, they applied it only to the words with high frequencies in the documents (Fukumoto et al., 2013). In contrast, we applied it to the topic candidates obtained by LDA. We examined our method by extrinsic evaluation, i.e., we applied the results of topic detection to extractive multi-document summarization. We assume that a salient sentence includes words related to the target topic, and an event of each documents. Here, an event is something that occurs at a specific place and time associated with some specific actions(Allan et al., 1998). We identified event words by using the traditional tf∗idf method applied to the results of named entities. Each sentence in documents is represented using a vector of frequency weighted words that can be event 241 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 241–246, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics or topic words. We used Markov Random Walk (MRW) to compute the rank scores for the sentences (Page et al., 1998). Finally, we selected a certain number of sentences accordi</context>
<context position="11081" citStr="Allan et al., 1998" startWordPosition="1944" endWordPosition="1947">ment in the task. Based on this assumption, we computed similarity between correct and word histograms by using KL-distance2. Let P and Q be a normalized distance of correct histogram, and bursts histogram, respectively. KL-distance is defined by D(P || Q) = Ei=1 P(xi) log P (xi) Q(xi) where xi refers bursts in time i. If the value of D(P ||Q) is smaller than a certain threshold value, w is regarded as a topic word. 3 Extrinsic Evaluation to Summarization 3.1 Event detection An event word is something that occurs at a specific place and time associated with some specific actions (Allan, 2003; Allan et al., 1998). It refers to notions of who(person), where(place), 2We tested KL-distance, histogram intersection and Bhattacharyya distance to obtain similarities. We reported only the result obtained by KL-distance as it was the best results among them. Correct histogram Bursts histogram bursts bursts T bursts Histogram similarity T T 243 when(time) including what, why and how in a document. Therefore, we can assume that named entities(NE) are linguistic features for event detection. An event word refers to the theme of the document itself, and frequently appears in the document but not frequently appear </context>
</contexts>
<marker>Allan, Carbonell, Doddington, Yamron, Yang, 1998</marker>
<rawString>J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. 1998. Topic Detection and Tracking Pilot Study Final Report. In Proc. of the DARPA Broadcast News Transcription and Understanding Workshop.</rawString>
</citation>
<citation valid="true">
<title>Topic Detection and Tracking.</title>
<date>2003</date>
<editor>J. Allan, editor.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>2003</marker>
<rawString>J. Allan, editor. 2003. Topic Detection and Tracking. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>J D Lafferty</author>
</authors>
<title>Dynamic Topic Models.</title>
<date>2006</date>
<booktitle>In Proc. of the 23rd International Conference on Machine Learning,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="8560" citStr="Blei and Lafferty, 2006" startWordPosition="1481" endWordPosition="1484">igned to the cluster Cj. The value of E ranges from 0 to 1, and the smaller value of E indicates better result. Let Et,,pic and Etask are entropy value of lda topic cluster and task cluster, respectively. We chose the parameters k′ and d′ whose value of the summation of Et,,pic and Etask is smallest. For each lda topic, we extracted words whose probabilities are larger than zero, and regarded these as topic candidates. 2.2 Topic Detection by MACD The proposed method does not simply use MACD to find bursts, but instead determines topic words in series of documents. Unlike Dynamic Topic Models (Blei and Lafferty, 2006), it does not assume Gaussian distribution so that it is a natural way to analyze bursts which depend on the data. We applied it to extract topic words in series of documents. MACD histogram defined by Eq. (6) shows a difference between the MACD and its moving average. MACD of a variable xt is defined by the difference of n1-day and n2-day moving averages, MACD(n1,n2) = EMA(n1) - EMA(n2). Here, EMA(ni) refers to ni-day Exponential Moving Average (EMA). For a variable x = x(t) which has a corresponding discrete time series x = {xt |t = 0,1,· · · }, the n-day EMA is defined by Eq. (5). EMA(n)[x]</context>
</contexts>
<marker>Blei, Lafferty, 2006</marker>
<rawString>D. M. Blei and J. D. Lafferty. 2006. Dynamic Topic Models. In Proc. of the 23rd International Conference on Machine Learning, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>A Y Ng</author>
<author>M I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<booktitle>In The Journal ofMachine Learning Research,</booktitle>
<volume>3</volume>
<pages>993--1022</pages>
<contexts>
<context position="677" citStr="Blei et al., 2003" startWordPosition="98" endWordPosition="101">ti-Document Summarization Yoshimi Suzuki Interdisciplinary Graduate School of Medicine and Engineering University of Yamanashi Kofu, 400-8511, JAPAN ysuzuki@yamanashi.ac.jp Abstract This paper presents a method for detecting words related to a topic (we call them topic words) over time in the stream of documents. Topic words are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not. We propose a method to reinforce topic words with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (Blei et al., 2003) to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004;</context>
<context position="2788" citStr="Blei et al., 2003" startWordPosition="430" endWordPosition="433">ssifiers effectively. He and Parket attempted to find bursts, periods of elevated occurrence of events as a dynamic phenomenon instead of focusing on arrival rates (He and Parker, 2010). However, the fact that topics are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not often hamper such attempts. This paper proposes a method for detecting topic over time in series of documents. We reinforced words related to a topic with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to these documents in order to extract topic candidates. For the results of LDA, we applied Moving Average Convergence Divergence (MACD) to find topic words while He et. al., applied it to find bursts. The MACD is a technique to analyze stock market trends (Murphy, 1999). It shows the relationship between two moving averages of prices modeling bursts as intervals of topic dynamics, i.e., positive acceleration. Fukumoto et. al also applied MACD to find topics. However, they applied it only to the words with high frequencies in the documents (Fukumoto et al., 2013). In contrast, we applied it t</context>
<context position="4530" citStr="Blei et al., 2003" startWordPosition="717" endWordPosition="720"> Each sentence in documents is represented using a vector of frequency weighted words that can be event 241 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 241–246, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics or topic words. We used Markov Random Walk (MRW) to compute the rank scores for the sentences (Page et al., 1998). Finally, we selected a certain number of sentences according to the rank score into a summary. 2 Topic Detection 2.1 Extraction of Topic Candidates LDA presented by (Blei et al., 2003) models each document as a mixture of topics (we call it lda topic to discriminate our topic candidates), and generates a discrete probability distribution over words for each lda topic. The generative process for LDA can be described as follows: 1. For each topic k = 1, · · · , K, generate φk, multinomial distribution of words specific to the topic k from a Dirichlet distribution with parameter Q; 2. For each document d = 1, · · · , D, generate Bd, multinomial distribution of topics specific to the document d from a Dirichlet distribution with parameter α; 3. For each word n = 1, · · · , Nd i</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent Dirichlet Allocation. In The Journal ofMachine Learning Research, volume 3, pages 993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Celikylmaz</author>
<author>D Hakkani-Tur</author>
</authors>
<title>A Hybird Hierarchical Model for Multi-Document Summarization.</title>
<date>2010</date>
<booktitle>In Proc. of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>815--824</pages>
<contexts>
<context position="18083" citStr="Celikylmaz and Hakkani-Tur, 2010" startWordPosition="3173" endWordPosition="3176">ed to evaluate the performance of the method. All documents were tagged by Tree Tagger (Schmid, 1995) and Stanford Named Entity Tagger 5 (Finkel et al., 2005). We used person name, organization and location for event detection, and noun words including named entities for topic detection. AQUAINT corpus6 which consists of 1,033,461 documents are used as a corpus in LDA and MACD. Table 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). However, the method is a semi-supervised technique that needs a tagged training data. Our approach achieves performance approaching the topperforming unsupervised method, “TTM” (Celikylmaz and Hakkani-Tur, 2011), and is competitive to “PYTHY” (Toutanoval et al., 2007) and “hPAM” (Li and McCallum, 2006). Prior work including “TTM” has demonstrated the usefulness of semantic concepts for extracting salient sentences. For future work, we should be able to obtain further advantages in efficacy in our topic detection and summarizat</context>
</contexts>
<marker>Celikylmaz, Hakkani-Tur, 2010</marker>
<rawString>A. Celikylmaz and D. Hakkani-Tur. 2010. A Hybird Hierarchical Model for Multi-Document Summarization. In Proc. of the 48th Annual Meeting of the Association for Computational Linguistics, pages 815–824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Celikylmaz</author>
<author>D Hakkani-Tur</author>
</authors>
<title>Discovery of Topically Coherent Sentences for Extractive Summarization.</title>
<date>2011</date>
<booktitle>In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>491--499</pages>
<contexts>
<context position="18362" citStr="Celikylmaz and Hakkani-Tur, 2011" startWordPosition="3214" endWordPosition="3218">etection. AQUAINT corpus6 which consists of 1,033,461 documents are used as a corpus in LDA and MACD. Table 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). However, the method is a semi-supervised technique that needs a tagged training data. Our approach achieves performance approaching the topperforming unsupervised method, “TTM” (Celikylmaz and Hakkani-Tur, 2011), and is competitive to “PYTHY” (Toutanoval et al., 2007) and “hPAM” (Li and McCallum, 2006). Prior work including “TTM” has demonstrated the usefulness of semantic concepts for extracting salient sentences. For future work, we should be able to obtain further advantages in efficacy in our topic detection and summarization approach by disambiguating topic senses. 5 Conclusion The research described in this paper explores a method for detecting topic words over time in series of documents. The results of extrinsic evaluation showed that integration of LDA and MACD is effective for topic detecti</context>
</contexts>
<marker>Celikylmaz, Hakkani-Tur, 2011</marker>
<rawString>A. Celikylmaz and D. Hakkani-Tur. 2011. Discovery of Topically Coherent Sentences for Extractive Summarization. In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 491–499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erkan</author>
<author>D Radev</author>
</authors>
<title>LexPageRank: Prestige in Multi-Document Text Summarization.</title>
<date>2004</date>
<booktitle>In Proc. of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>365--371</pages>
<contexts>
<context position="12301" citStr="Erkan and Radev, 2004" startWordPosition="2143" endWordPosition="2146"> in other documents. Therefore, we first applied NE recognition to the target documents to be summarized, and then calculated tf*idf to the results of NE recognition. We extracted words whose tf*idf values are larger than a certain threshold value, and regarded these as event words. 3.2 Sentence extraction We recall that our hypothesis about key sentences in multiple documents is that they include topic and event words. Each sentence in the documents is represented using a vector of frequency weighted words that can be event or topic words. Like much previous work on extractive summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005; Wan and Yang, 2008), we used Markov Random Walk (MRW) model to compute the rank scores for the sentences. Given a set of documents to be summarized, G = (5, E) is a graph reflecting the relationships between two sentences. 5 is a set of vertices, and each vertex si in 5 is a sentence. E is a set of edges, and each edge eij in E is associated with an affinity weight f(i —* j) between sentences si and sj (i =� j). The affinity weight is computed using cosine measure between the two sentences, si and sj. Two vertices are connected if their affinity weight is larger tha</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G. Erkan and D. Radev. 2004. LexPageRank: Prestige in Multi-Document Text Summarization. In Proc. of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 365–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="17608" citStr="Finkel et al., 2005" startWordPosition="3094" endWordPosition="3097">ed of 50 tasks for training, and 50 tasks of DUC2006 data for testing in order to estimate parameters. We set tf∗idf and Method R-1 Method R-1 MRW .381 Event .407 LDA .402 LDA &amp; MACD .428 Event &amp; Topic .438 PYTHY .426 HybHSum .456 hPAM .412 TTM .447 Table 2: Comparative results (DUC2007 test data) KL-distance to 80 and 0.9. The minimum entropy value was 0.050 and the number of topics and documents were 500 and 600, respectively. 45 tasks from DUC2007 were used to evaluate the performance of the method. All documents were tagged by Tree Tagger (Schmid, 1995) and Stanford Named Entity Tagger 5 (Finkel et al., 2005). We used person name, organization and location for event detection, and noun words including named entities for topic detection. AQUAINT corpus6 which consists of 1,033,461 documents are used as a corpus in LDA and MACD. Table 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). However, the method is a semi-supervised technique that n</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>J. R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Folino</author>
<author>C Pizzuti</author>
<author>G Spezzano</author>
</authors>
<title>An Adaptive Distributed Ensemble Approach to Mine Concept-Drifting Data Streams.</title>
<date>2007</date>
<booktitle>In Proc. of the 19th IEEE International Conference on Tools with Artificial Intelligence,</booktitle>
<pages>183--188</pages>
<contexts>
<context position="1322" citStr="Folino et al., 2007" startWordPosition="201" endWordPosition="204">the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training several data streams to detect concept drift </context>
</contexts>
<marker>Folino, Pizzuti, Spezzano, 2007</marker>
<rawString>G. Folino, C. Pizzuti, and G. Spezzano. 2007. An Adaptive Distributed Ensemble Approach to Mine Concept-Drifting Data Streams. In Proc. of the 19th IEEE International Conference on Tools with Artificial Intelligence, pages 183–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Fukumoto</author>
<author>Y Suzuki</author>
<author>A Takasu</author>
<author>S Matsuyoshi</author>
</authors>
<title>Multi-document summarization based on event and topic detection.</title>
<date>2013</date>
<booktitle>In Proc. of the 6th Language and Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics,</booktitle>
<pages>117--121</pages>
<contexts>
<context position="3358" citStr="Fukumoto et al., 2013" startWordPosition="527" endWordPosition="530">atent Dirichlet Allocation (LDA) (Blei et al., 2003) to these documents in order to extract topic candidates. For the results of LDA, we applied Moving Average Convergence Divergence (MACD) to find topic words while He et. al., applied it to find bursts. The MACD is a technique to analyze stock market trends (Murphy, 1999). It shows the relationship between two moving averages of prices modeling bursts as intervals of topic dynamics, i.e., positive acceleration. Fukumoto et. al also applied MACD to find topics. However, they applied it only to the words with high frequencies in the documents (Fukumoto et al., 2013). In contrast, we applied it to the topic candidates obtained by LDA. We examined our method by extrinsic evaluation, i.e., we applied the results of topic detection to extractive multi-document summarization. We assume that a salient sentence includes words related to the target topic, and an event of each documents. Here, an event is something that occurs at a specific place and time associated with some specific actions(Allan et al., 1998). We identified event words by using the traditional tf∗idf method applied to the results of named entities. Each sentence in documents is represented usi</context>
</contexts>
<marker>Fukumoto, Suzuki, Takasu, Matsuyoshi, 2013</marker>
<rawString>F. Fukumoto, Y. Suzuki, A. Takasu, and S. Matsuyoshi. 2013. Multi-document summarization based on event and topic detection. In Proc. of the 6th Language and Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, pages 117–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D He</author>
<author>D S Parker</author>
</authors>
<title>Topic Dynamics: An Alternative Model of Bursts in Streams of Topics.</title>
<date>2010</date>
<booktitle>In Proc. of the 16th ACM Special Interest Group on Knowledge Discovery and Data Mining,</booktitle>
<pages>443--452</pages>
<contexts>
<context position="2355" citStr="He and Parker, 2010" startWordPosition="359" endWordPosition="362">algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training several data streams to detect concept drift (Scholz, Fumiyo Fukumoto Interdisciplinary Graduate School of Medicine and Engineering University of Yamanashi Kofu, 400-8511, JAPAN fukumoto@yamanashi.ac.jp 2007). However the ensemble method itself remains a problem that how to manage several classifiers effectively. He and Parket attempted to find bursts, periods of elevated occurrence of events as a dynamic phenomenon instead of focusing on arrival rates (He and Parker, 2010). However, the fact that topics are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not often hamper such attempts. This paper proposes a method for detecting topic over time in series of documents. We reinforced words related to a topic with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to these documents in order to extract topic candidates. For the results of LDA, we applied Moving Average Convergence Divergence (MACD) to find topic words while He </context>
<context position="9846" citStr="He and Parker, 2010" startWordPosition="1729" endWordPosition="1732">efers to a smoothing factor and it is often taken to be 2 (n+1). MACD histogram shows a difference between the MACD and its moving average1. hist(n1, n2, n3) = MACD(n1, n2) − EMA(n3)[MACD(n1, n2)]. (6) The procedure for topic detection with MACD is illustrated in Figure 2. Let A be a series of documents and w be one of the topic candidates obtained by LDA. Each document in A is sorted in chronological order. We set A to the documents from the summarization task. Whether or not a word w is a topic word is judged as follows: 1In the experiment, we set n1, n2, and n3 to 4, 8 and 5, respectively (He and Parker, 2010). Figure 2: Topic detection with MACD 1. Create document-based MACD histogram where X-axis refers to T, i.e., a period of time (numbered from day 1 to 365). Y-axis is the document count in A per day. Hereafter, referred to as correct histogram. 2. Create term-based MACD histogram where X-axis refers to T, and Y-axis denotes bursts of word w in A. Hereafter, referred to as bursts histogram. 3. We assume that if a term w is informative for summarizing a particular documents in a collection, its burstiness approximates the burstiness of documents in the collection. Because w is a representative w</context>
</contexts>
<marker>He, Parker, 2010</marker>
<rawString>D. He and D. S. Parker. 2010. Topic Dynamics: An Alternative Model of Bursts in Streams of Topics. In Proc. of the 16th ACM Special Interest Group on Knowledge Discovery and Data Mining, pages 443– 452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Klinkenberg</author>
<author>T Joachims</author>
</authors>
<title>Detecting Concept Drift with Support Vector Machines.</title>
<date>2000</date>
<booktitle>In Proc. of the 17th International Conference on Machine Learning,</booktitle>
<pages>487--494</pages>
<contexts>
<context position="1424" citStr="Klinkenberg and Joachims, 2000" startWordPosition="216" endWordPosition="219">e. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training several data streams to detect concept drift (Scholz, Fumiyo Fukumoto Interdisciplinary Graduate School of Medicine and Engineering University of Y</context>
</contexts>
<marker>Klinkenberg, Joachims, 2000</marker>
<rawString>R. Klinkenberg and T. Joachims. 2000. Detecting Concept Drift with Support Vector Machines. In Proc. of the 17th International Conference on Machine Learning, pages 487–494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Klinkenberg</author>
</authors>
<title>Learning Drifting Concepts: Example Selection vs. Example Weighting. Intelleginet Data Analysis,</title>
<date>2004</date>
<contexts>
<context position="1276" citStr="Klinkenberg, 2004" startWordPosition="194" endWordPosition="196">Blei et al., 2003) to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training</context>
</contexts>
<marker>Klinkenberg, 2004</marker>
<rawString>R. Klinkenberg. 2004. Learning Drifting Concepts: Example Selection vs. Example Weighting. Intelleginet Data Analysis, 8(3):281–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proc. of 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="14888" citStr="Kudo and Matsumoto, 2003" startWordPosition="2615" endWordPosition="2618">ion by LDA and (iv) Topic Detection by LDA and MACD (LDA &amp; MACD): MRW is applied to the result of topic detection by LDA and MACD only, i.e., the method does not include event detection. 4.2 NTCIR data The data used in the NTCIR-3 multi-document summarization task is selected from 1998 to 1999 of Mainichi Japanese Newspaper documents. The gold standard data provided to human judges consists of FBFREE DryRun and FormalRun. Each data consists of 30 tasks. There are two types of correct summary according to the character length, “long” and “short”, All series of documents were tagged by CaboCha (Kudo and Matsumoto, 2003). We used person name, organization, place and proper name extracted from NE recognition (Kudo and Matsumoto, 2003) for event detection, and noun words including named entities for topic detection. FBFREE DryRun data is used to tuning parameters, i.e., the number of extracted words according to the tf*idf value, and the threshold value of KL-distance. The size that optimized the average Rouge-1(R-1) score across 30 tasks was chosen. As a result, we set tf*idf and KL-distance to 100 and 0.104, respectively. We used FormalRun as a test data, and another set consisted of 218,724 documents from 19</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>T. Kudo and Y. Matsumoto. 2003. Fast methods for kernel-based text analysis. In Proc. of 41st Annual Meeting of the Association for Computational Linguistics, pages 24–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M M Lazarescu</author>
<author>S Venkatesh</author>
<author>H H Bui</author>
</authors>
<title>Using Multiple Windows to Track Concept Drift. Intelligent Data Analysis,</title>
<date>2004</date>
<contexts>
<context position="1300" citStr="Lazarescu et al., 2004" startWordPosition="197" endWordPosition="200">to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training several data streams to</context>
</contexts>
<marker>Lazarescu, Venkatesh, Bui, 2004</marker>
<rawString>M. M. Lazarescu, S. Venkatesh, and H. H. Bui. 2004. Using Multiple Windows to Track Concept Drift. Intelligent Data Analysis, 8(1):29–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>A McCallum</author>
</authors>
<title>Pachinko Allocation: Dag-Structure Mixture Model of Topic Correlations.</title>
<date>2006</date>
<booktitle>In Proc. of the 23rd International Conference on Machine Learning,</booktitle>
<pages>577--584</pages>
<contexts>
<context position="18454" citStr="Li and McCallum, 2006" startWordPosition="3231" endWordPosition="3234">able 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). However, the method is a semi-supervised technique that needs a tagged training data. Our approach achieves performance approaching the topperforming unsupervised method, “TTM” (Celikylmaz and Hakkani-Tur, 2011), and is competitive to “PYTHY” (Toutanoval et al., 2007) and “hPAM” (Li and McCallum, 2006). Prior work including “TTM” has demonstrated the usefulness of semantic concepts for extracting salient sentences. For future work, we should be able to obtain further advantages in efficacy in our topic detection and summarization approach by disambiguating topic senses. 5 Conclusion The research described in this paper explores a method for detecting topic words over time in series of documents. The results of extrinsic evaluation showed that integration of LDA and MACD is effective for topic detection. 5http://nlp.stanford.edu/software/CRF-NER.shtml 6http://catalog.ldc.upenn.edu/LDC2002T31</context>
</contexts>
<marker>Li, McCallum, 2006</marker>
<rawString>W. Li and A. McCallum. 2006. Pachinko Allocation: Dag-Structure Mixture Model of Topic Correlations. In Proc. of the 23rd International Conference on Machine Learning, pages 577–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Mane</author>
<author>K Borner</author>
</authors>
<title>Mapping Topics and Topic Bursts in PNAS.</title>
<date>2004</date>
<booktitle>Proc. of the National Academy of Sciences of the United States of America,</booktitle>
<pages>101--5287</pages>
<contexts>
<context position="1689" citStr="Mane and Borner, 2004" startWordPosition="260" endWordPosition="263">ly increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use different ensembles obtained by training several data streams to detect concept drift (Scholz, Fumiyo Fukumoto Interdisciplinary Graduate School of Medicine and Engineering University of Yamanashi Kofu, 400-8511, JAPAN fukumoto@yamanashi.ac.jp 2007). However the ensemble method itself remains a problem that how to manage several classifiers effectively. He and Parket attempted to find bursts, periods of elevated occurrence of events as a dynamic phe</context>
</contexts>
<marker>Mane, Borner, 2004</marker>
<rawString>K. Mane and K. Borner. 2004. Mapping Topics and Topic Bursts in PNAS. Proc. of the National Academy of Sciences of the United States of America, 101:5287–5290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>Language Independent Extractive Summarization. In</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>49--52</pages>
<contexts>
<context position="12327" citStr="Mihalcea and Tarau, 2005" startWordPosition="2147" endWordPosition="2150">erefore, we first applied NE recognition to the target documents to be summarized, and then calculated tf*idf to the results of NE recognition. We extracted words whose tf*idf values are larger than a certain threshold value, and regarded these as event words. 3.2 Sentence extraction We recall that our hypothesis about key sentences in multiple documents is that they include topic and event words. Each sentence in the documents is represented using a vector of frequency weighted words that can be event or topic words. Like much previous work on extractive summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005; Wan and Yang, 2008), we used Markov Random Walk (MRW) model to compute the rank scores for the sentences. Given a set of documents to be summarized, G = (5, E) is a graph reflecting the relationships between two sentences. 5 is a set of vertices, and each vertex si in 5 is a sentence. E is a set of edges, and each edge eij in E is associated with an affinity weight f(i —* j) between sentences si and sj (i =� j). The affinity weight is computed using cosine measure between the two sentences, si and sj. Two vertices are connected if their affinity weight is larger than 0 and we let f(i —* i)= </context>
</contexts>
<marker>Mihalcea, Tarau, 2005</marker>
<rawString>R. Mihalcea and P. Tarau. 2005. Language Independent Extractive Summarization. In In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 49–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Murphy</author>
</authors>
<title>Technical Analysis of the Financial Markets.</title>
<date>1999</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="3060" citStr="Murphy, 1999" startWordPosition="480" endWordPosition="481">imes they frequently appear in the documents, and sometimes not often hamper such attempts. This paper proposes a method for detecting topic over time in series of documents. We reinforced words related to a topic with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to these documents in order to extract topic candidates. For the results of LDA, we applied Moving Average Convergence Divergence (MACD) to find topic words while He et. al., applied it to find bursts. The MACD is a technique to analyze stock market trends (Murphy, 1999). It shows the relationship between two moving averages of prices modeling bursts as intervals of topic dynamics, i.e., positive acceleration. Fukumoto et. al also applied MACD to find topics. However, they applied it only to the words with high frequencies in the documents (Fukumoto et al., 2013). In contrast, we applied it to the topic candidates obtained by LDA. We examined our method by extrinsic evaluation, i.e., we applied the results of topic detection to extractive multi-document summarization. We assume that a salient sentence includes words related to the target topic, and an event o</context>
</contexts>
<marker>Murphy, 1999</marker>
<rawString>J. Murphy. 1999. Technical Analysis of the Financial Markets. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Page</author>
<author>S Brin</author>
<author>R Motwani</author>
<author>T Winograd</author>
</authors>
<title>The Pagerank Citation Ranking: Bringing Order to the Web. In</title>
<date>1998</date>
<tech>Technical report, Stanford Digital Libraries.</tech>
<contexts>
<context position="4344" citStr="Page et al., 1998" startWordPosition="686" endWordPosition="689">cific place and time associated with some specific actions(Allan et al., 1998). We identified event words by using the traditional tf∗idf method applied to the results of named entities. Each sentence in documents is represented using a vector of frequency weighted words that can be event 241 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 241–246, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics or topic words. We used Markov Random Walk (MRW) to compute the rank scores for the sentences (Page et al., 1998). Finally, we selected a certain number of sentences according to the rank score into a summary. 2 Topic Detection 2.1 Extraction of Topic Candidates LDA presented by (Blei et al., 2003) models each document as a mixture of topics (we call it lda topic to discriminate our topic candidates), and generates a discrete probability distribution over words for each lda topic. The generative process for LDA can be described as follows: 1. For each topic k = 1, · · · , K, generate φk, multinomial distribution of words specific to the topic k from a Dirichlet distribution with parameter Q; 2. For each </context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. The Pagerank Citation Ranking: Bringing Order to the Web. In Technical report, Stanford Digital Libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Improvements in Part-of-Speech Tagging with an Application to German.</title>
<date>1995</date>
<booktitle>In Proc. of the European chapter of the Association for Computational Linguistics SIGDAT</booktitle>
<contexts>
<context position="17551" citStr="Schmid, 1995" startWordPosition="3086" endWordPosition="3087">ic detection. 4.3 DUC data We used DUC2005 consisted of 50 tasks for training, and 50 tasks of DUC2006 data for testing in order to estimate parameters. We set tf∗idf and Method R-1 Method R-1 MRW .381 Event .407 LDA .402 LDA &amp; MACD .428 Event &amp; Topic .438 PYTHY .426 HybHSum .456 hPAM .412 TTM .447 Table 2: Comparative results (DUC2007 test data) KL-distance to 80 and 0.9. The minimum entropy value was 0.050 and the number of topics and documents were 500 and 600, respectively. 45 tasks from DUC2007 were used to evaluate the performance of the method. All documents were tagged by Tree Tagger (Schmid, 1995) and Stanford Named Entity Tagger 5 (Finkel et al., 2005). We used person name, organization and location for event detection, and noun words including named entities for topic detection. AQUAINT corpus6 which consists of 1,033,461 documents are used as a corpus in LDA and MACD. Table 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). </context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>H. Schmid. 1995. Improvements in Part-of-Speech Tagging with an Application to German. In Proc. of the European chapter of the Association for Computational Linguistics SIGDAT Workshop. M. Scholz. 2007. Boosting Classifiers for Drifting Concepts. Intelligent Data Analysis, 11(1):3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Swan</author>
<author>J Allan</author>
</authors>
<title>Automatic Generation of Overview Timelines.</title>
<date>2000</date>
<booktitle>In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>38--45</pages>
<contexts>
<context position="1244" citStr="Swan and Allan, 2000" startWordPosition="188" endWordPosition="191">plied Latent Dirichlet Allocation (Blei et al., 2003) to these documents. For the results of LDA, we identified topic words by using Moving Average Convergence Divergence. In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization. The results showed that the method was effective for sentence selection in summarization. 1 Introduction As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention (Allan et al., 1998; Swan and Allan, 2000; Allan, 2003; Klinkenberg, 2004; Lazarescu et al., 2004; Folino et al., 2007). The earliest known approach is the work of Klinkenberg and Joachims (Klinkenberg and Joachims, 2000). They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept. Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends (Mane and Borner, 2004). The method used Kleinberg’s burst detection algorithm, co-occurrences of words, and graph layout technique. Scholz et. al. have attempted to use differen</context>
</contexts>
<marker>Swan, Allan, 2000</marker>
<rawString>R. Swan and J. Allan. 2000. Automatic Generation of Overview Timelines. In Proc. of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 38–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanoval</author>
<author>C Brockett</author>
<author>M Gammon</author>
<author>J Jagarlamudi</author>
<author>H Suzuki</author>
<author>L Vanderwende</author>
</authors>
<title>The Phthy Summarization System: Microsoft Research at DUC.</title>
<date>2007</date>
<booktitle>In Proc. ofDocument Understanding Conference</booktitle>
<contexts>
<context position="18419" citStr="Toutanoval et al., 2007" startWordPosition="3225" endWordPosition="3228">e used as a corpus in LDA and MACD. Table 2 shows Rouge-1 against unigrams. We can see from Table 2 that Rouge-1 obtained by our approach was also the best compared to the baselines. Table 2 also shows the performance of other research sites reported by (Celikylmaz and Hakkani-Tur, 2010). The top site was “HybHSum” by (Celikylmaz and Hakkani-Tur, 2010). However, the method is a semi-supervised technique that needs a tagged training data. Our approach achieves performance approaching the topperforming unsupervised method, “TTM” (Celikylmaz and Hakkani-Tur, 2011), and is competitive to “PYTHY” (Toutanoval et al., 2007) and “hPAM” (Li and McCallum, 2006). Prior work including “TTM” has demonstrated the usefulness of semantic concepts for extracting salient sentences. For future work, we should be able to obtain further advantages in efficacy in our topic detection and summarization approach by disambiguating topic senses. 5 Conclusion The research described in this paper explores a method for detecting topic words over time in series of documents. The results of extrinsic evaluation showed that integration of LDA and MACD is effective for topic detection. 5http://nlp.stanford.edu/software/CRF-NER.shtml 6http</context>
</contexts>
<marker>Toutanoval, Brockett, Gammon, Jagarlamudi, Suzuki, Vanderwende, 2007</marker>
<rawString>K. Toutanoval, C. Brockett, M. Gammon, J. Jagarlamudi, H. Suzuki, and L. Vanderwende. 2007. The Phthy Summarization System: Microsoft Research at DUC. In Proc. ofDocument Understanding Conference 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
</authors>
<title>Multi-Document Summarization using Cluster-based Link Analysis.</title>
<date>2008</date>
<booktitle>In Proc. of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>299--306</pages>
<contexts>
<context position="12348" citStr="Wan and Yang, 2008" startWordPosition="2151" endWordPosition="2154">NE recognition to the target documents to be summarized, and then calculated tf*idf to the results of NE recognition. We extracted words whose tf*idf values are larger than a certain threshold value, and regarded these as event words. 3.2 Sentence extraction We recall that our hypothesis about key sentences in multiple documents is that they include topic and event words. Each sentence in the documents is represented using a vector of frequency weighted words that can be event or topic words. Like much previous work on extractive summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005; Wan and Yang, 2008), we used Markov Random Walk (MRW) model to compute the rank scores for the sentences. Given a set of documents to be summarized, G = (5, E) is a graph reflecting the relationships between two sentences. 5 is a set of vertices, and each vertex si in 5 is a sentence. E is a set of edges, and each edge eij in E is associated with an affinity weight f(i —* j) between sentences si and sj (i =� j). The affinity weight is computed using cosine measure between the two sentences, si and sj. Two vertices are connected if their affinity weight is larger than 0 and we let f(i —* i)= 0 to avoid self trans</context>
</contexts>
<marker>Wan, Yang, 2008</marker>
<rawString>X. Wan and J. Yang. 2008. Multi-Document Summarization using Cluster-based Link Analysis. In Proc. of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 299–306.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>