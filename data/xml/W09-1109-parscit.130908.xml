<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001292">
<title confidence="0.973011">
Representing words as regions in vector space
</title>
<author confidence="0.995557">
Katrin Erk
</author>
<affiliation confidence="0.997676">
University of Texas at Austin
</affiliation>
<email confidence="0.999135">
katrin.erk@mail.utexas.edu
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999454461538461">
Vector space models of word meaning typi-
cally represent the meaning of a word as a vec-
tor computed by summing over all its corpus
occurrences. Words close to this point in space
can be assumed to be similar to it in meaning.
But how far around this point does the region
of similar meaning extend? In this paper we
discuss two models that represent word mean-
ing as regions in vector space. Both represen-
tations can be computed from traditional point
representations in vector space. We find that
both models perform at over 95% F-score on
a token classification task.
</bodyText>
<sectionHeader confidence="0.998975" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998757054545454">
Vector space models of word meaning (Lund and
Burgess, 1996; Landauer and Dumais, 1997; Lowe,
2001; Jones and Mewhort, 2007; Sahlgren and Karl-
gren, 2005) represent words as points in a high-
dimensional semantic space. The dimensions of the
space represent the contexts in which each target
word has been observed. Distance between vec-
tors in semantic space predicts the degree of seman-
tic similarity between the corresponding words, as
words with similar meaning tend to occur in simi-
lar contexts. Because of this property, vector space
models have been used successfully both in com-
putational linguistics (Manning et al., 2008; Snow
et al., 2006; Gorman and Curran, 2006; Sch¨utze,
1998) and in cognitive science (Landauer and Du-
mais, 1997; Lowe and McDonald, 2000; McDon-
ald and Ramscar, 2001). Given the known problems
with defining globally appropriate senses (Kilgarriff,
1997; Hanks, 2000), vector space models are espe-
cially interesting for their ability to represent word
meaning without relying on dictionary senses.
Vector space models typically compute one vec-
tor per target word (what we will call word type vec-
tors), summing co-occurrence counts over all corpus
tokens of the target. If the target word is polyse-
mous, the representation will constitute a union over
the uses or senses of the word. Such a model does
not provide information on the amount of variance
in each dimension: Do values on each dimension
vary a lot across occurrences of the target? Also, it
does not provide information on co-occurrences of
feature values in occurrences of the target. To en-
code these two types of information, we study richer
models of word meaning in vector space beyond sin-
gle point representations.
Many models of categorization in psychology
represent a concept as a region, characterized by
feature vectors with dimension weights (Smith et
al., 1988; Hampton, 1991; Nosofsky, 1986). Tak-
ing our cue from these approaches, we study two
models that represent a word as a region in vector
space rather than a point. The first model is one
that we have recently introduced for representing hy-
ponymy in vector space (Erk, 2009). We now test
its suitability as a general region model for word
meaning. This model can be viewed as a prototype-
style model that induces a region surrounding a cen-
tral vector. As it does not record co-occurrences of
feature values, we contrast it with a second model,
an exemplar-style model using a k-nearest neighbor
analysis, which can represent both degree of vari-
ance in each dimension and value co-occurrences.
Both models induce regions representations with-
out labeled data. The idea on which both models
are based is to use word token vectors to estimate a
</bodyText>
<page confidence="0.986875">
57
</page>
<note confidence="0.9898755">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 57–65,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999867666666667">
region representation. We evaluate the two region
models on a task of token classification: Given a
point in vector space, the task is predict the word
of which it is a token vector.
By representing the meaning of words as regions
in vector space, we can describe areas in which
points encode similar meanings. This description is
flexible, depending on the target word in question,
rather than uniform for all words through a fixed
distance threshold from the target’s type vector. One
possible application of region models of word mean-
ing is in the task of determining the appropriateness
of a paraphrase in a given context (Connor and Roth,
2007). This task is highly relevant for textual entail-
ment (Szpektor et al., 2008). Current vector space
approaches typically compare the target word’s to-
ken vector to the type vector of the potential para-
phrase (Mitchell and Lapata, 2008; Erk and Pado,
2008). A region model could instead test the tar-
get’s token vector for inclusion in the potential para-
phrase’s region.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99992825">
This section discusses existing vector space models
and compares vector space models in computational
linguistics to feature-based models of human con-
cept representation in psychology.
Vector space models. Vector space models rep-
resent the meaning of a target word as a vector in a
high-dimensional space (Lund and Burgess, 1996;
Landauer and Dumais, 1997; Sahlgren and Karl-
gren, 2005; Pad´o and Lapata, 2007; Jones and Me-
whort, 2007). Dimensions stand for context items
which which the target word has been observed
to co-occur, for example other words (Lund and
Burgess, 1996) or syntactic paths (Pad´o and Lapata,
2007). In the simplest case, the value on a dimension
is the raw co-occurrence count between the target
word and the context item for which the dimension
stands. Raw counts are often transformed, for ex-
ample using a log-likelihood transformation (Lowe,
2001). Sometimes the vector space as a whole is
transformed using dimensionality reduction (Lan-
dauer and Dumais, 1997).
In NLP, vector space models have featured most
prominently in information retrieval (Manning et
al., 2008), but have also been used for ontology
learning (Lin, 1998; Snow et al., 2006; Gorman
and Curran, 2006) and word sense-related tasks
(McCarthy et al., 2004; Sch¨utze, 1998). In psy-
chology, vector space models have been used to
model synonymy (Landauer and Dumais, 1997;
Pad´o and Lapata, 2007), lexical priming phenom-
ena (Lowe and McDonald, 2000), and similarity
judgments (McDonald and Ramscar, 2001). There
have also been studies on inducing hyponymy in-
formation from vector space representations. Gef-
fet and Dagan (2005) use a dimension re-weighting
scheme, then predict entailment when the most
highly weighted dimensions of two verbs stand in
a subset relation. However, they find that while re-
call of this method is good (whenever some senses
of two words stand in an entailment relation, top-
weighted dimensions of their vectors stand in a sub-
set relation), precision is problematic. Weeds, Weir
and McCarthy (2004) introduce the notion of distri-
butional generality (x is more distributionally gen-
eral than y if x occurs in more contexts than y) and
find that for hyponym-hypernym pairs from Word-
Net, hyponyms are typically more distributionally
general. (As they study only word pairs that are
known to be related by hyponymy, they test for recall
but not precision.) Erk (2009) suggests that while it
may not be possible to induce hyponymy informa-
tion from a vector space representation, it is possible
to encode it in a vector space representation after it
has been obtained through some other means.
Vector space models of word tokens. Vector
space models have mostly been used to represent
the meaning of a word type by summing its co-
occurrence counts over a complete corpus. There
are several approaches to computing vectors for in-
dividual word tokens. All of them compute word
type vectors first, then combine them into token vec-
tors. Kintsch (2001) and Mitchell and Lapata (2008)
combine the target’s type vector with that of a sin-
gle word in the target’s syntactic context. Lan-
dauer and Dumais (Landauer and Dumais, 1997)
and Sch¨utze (1998) combine the type vectors of
all the words surrounding the target token. Erk
and Pad´o (2008) combine the target’s type vector
with a vector representing the selectional preference
of a single word in the target’s syntactic context.
Smolensky (1990) focuses on integrating syntactic
information in the vector representation rather than
</bodyText>
<page confidence="0.996866">
58
</page>
<bodyText confidence="0.989579">
on representing the lexical meaning of the target.
</bodyText>
<subsectionHeader confidence="0.549545">
Feature-based models of human concept rep-
</subsectionHeader>
<bodyText confidence="0.9978831">
resentation. Many models of human concept rep-
resentation in psychology are based on vectors of
features (e.g. (Smith et al., 1988; Hampton, 1991;
Nosofsky, 1986)). Features in these models are
typically weighted to represent their importance to
the concept in question. Similarity to a given fea-
ture vector is usually taken to decrease exponentially
with distance from that vector, following Shepard’s
law (Shepard, 1987). Categorization involves com-
petition between categories. Feature-based models
of human concept representation can be broadly cat-
egorized into prototype models, which represent a
concept by a single summary representation, and ex-
emplar models, which assume that categorization is
by comparison to remembered exemplars. As an ex-
ample of a feature-based model of concept represen-
tation, we show the definition of Nosofsky’s (1986)
Generalized Context Model (GCM). This exemplar
model estimates the probability of categorizing an
exemplar e~ as a member of a concept C as
</bodyText>
<equation confidence="0.993023">
P(C |~e) = P~η∈C w~ηsim(~η, ~e) (1)
Pconcept C&apos; P~η∈C&apos; w~ηsim(~η, e)
</equation>
<bodyText confidence="0.997434333333333">
where the concept C is a set of remembered exem-
plars, w~η is an exemplar weight, and the similarity
sim(~η,~e) between η~ and e~ is defined as
</bodyText>
<equation confidence="0.981818">
Xsim(~η,~e) = exp(z � wi(ηi − ei)2) (2)
dimension i
</equation>
<bodyText confidence="0.998674958333333">
Here, z is a general sensitivity parameter, wi is a
weight for dimension i, and ηi, ei are the values
of η~ and e~ on dimension i. This model shows all
the properties listed above: It has weighted dimen-
sions through the wi. It incorporates Shepard’s law
through the exponential relation between sim and
the sum of squared value distances wi(ηi − ei)2.
Competition between categories arises through the
normalization of ~e’s similarity to C by the similar-
ity to all other categories in Eq. (1). While feature-
based models of concept representation talk about
concepts rather than word meaning, Murphy (2002)
argues that there is “overwhelming empirical evi-
dence for the conceptual basis of word meaning”
through experimental results on conceptual phenom-
ena that have also been shown to hold for words.
G¨ardenfors (2004) proposes a model that repre-
sents concepts as convex regions in a conceptual
space. Feature structures play no central role in this
model, but G¨ardenfors suggests that concepts may
be represented by a central point, such that cate-
gorization could simply be determining the nearest
central point (without positing an exponential rela-
tion between distance and similarity).
</bodyText>
<sectionHeader confidence="0.991568" genericHeader="method">
3 Models
</sectionHeader>
<bodyText confidence="0.9965555">
In this section, we present two models for represent-
ing word meaning as regions in vector space.
The centered model. The first model that we de-
fine, which we call the centered model, is prototype-
like. As the representation for a target word, it in-
duces a region surrounding the target’s type vec-
tor (Erk, 2009). Let w be the target word and
w~ its type vector. Let x~ be a point in the same
vector space. To predict whether x~ represents the
same meaning as ~w, we estimate the probability
P(IN(~x, ~w)) that x~ is in the region around ~w, using
a log-linear model:
</bodyText>
<equation confidence="0.989269333333333">
1 X P (IN(~x, ~w)) = Z exp( βIN
i fi(~x, ~w)) (3)
i
</equation>
<bodyText confidence="0.957096666666667">
where the fi are features that characterize the point
~x, and the βIN iare weights identifying the impor-
tance of the different features for the class IN. Z is a
normalizing factor that ensures that P is a probability
distribution: If P(OUT(~x, ~w)) = 1− P(IN(~x, ~w)) is
the probability that x~ is not in the region around ~w,
with associated weights βOUT
i for
the same features
</bodyText>
<equation confidence="0.60685">
fi, then Z = P i fi(~x, ~w)).
`=IN,OUT exp(Pi β`
</equation>
<bodyText confidence="0.99247375">
We define the features fi as follows: If w~ =
(w1, ... , wn), we define the feature fi(~x, ~w), for
1 &lt; i &lt; n, as the squared distance between w~ and x~
on dimension i:
</bodyText>
<equation confidence="0.99552">
fi(~x) = (wi − xi)2 (4)
</equation>
<bodyText confidence="0.997883285714286">
This model, like feature-based models of catego-
rization from psychology, has weighted dimensions
through the βi. It follows Shepard’s law – the ex-
ponential relation between similarity and distance –
through the exponential function in Eq. (3). Compe-
tition between categories is implicit in the estimation
of P(OUT(~x, ~w)).
</bodyText>
<page confidence="0.993372">
59
</page>
<bodyText confidence="0.999141078947368">
Most of the weights QIN
i can reasonably be ex-
pected to be negative, since a negative QIN
i indicates
that membership of a point x� in the w-region gets
less likely as the distance (wi−xi)2 increases. If QIN
i
has a large negative value, categorization is highly
sensitive to changes in the ith dimension. If on the
other hand, QIN
i is negative but close to zero, this
means that vector entries in dimension i can vary
greatly without much influence on categorization.
The parameters QIN
i and QOUT ineed to be estimated
from training data. Although the log-likelihood
model is a supervised learning scheme, we do not
need to take recourse to labeled data. Instead, we
use token vectors: Token vectors of w will serve
as positive training data for estimating P(IN(x, w)),
and token vectors of other words than w will con-
stitute negative training data. The amount of pre-
processing needed depends on the approach to com-
puting token vectors that we use. We will use an
approach that combines w’s type vector with that
of a single word in its syntactic context. This pre-
supposes a syntactic parse of the corpus. Note that
we could just as well have used a Sch¨utze-style ap-
proach, which does not rely on parsing.
The distributed model. The second model that
we consider is an exemplar-style, instance-based
model. The simplest instance-based models are k-
nearest neighbor classifiers, which assign to a test
item the majority label of its k nearest neighbors
among the training items. We will here use a very
simple model, doing k nearest neighbor classifica-
tion where the distance between two vectors w� and
x� is the sum of dimension distances Si with
</bodyText>
<equation confidence="0.981554666666667">
Qi|wi − xi|
Si =
maxi − mini
</equation>
<bodyText confidence="0.995790875">
maxi and mini are the maximum and minimum
values observed for dimension i, and Qi is a fea-
ture weight. We use a standard feature weighting
method, gain ratio, which is information gain nor-
malized by the entropy of feature values. Informa-
tion gain on its own has a bias towards features with
many values, which gain ratio attenuates in favor of
features with lower entropy:
</bodyText>
<equation confidence="0.9971985">
H(C) − Ey∈val(i) P(y)H(C|y) (5)
− Ey∈val(i) P(y)log2 P(y)
</equation>
<bodyText confidence="0.991237795918368">
for the set C = {IN, OUT} of classes and sets val(i)
of values seen for dimension i. We call this the dis-
tributed model. As with the centered model, we
compare it to models of concept representation: It
has weighted dimensions (Eq. (5)), and it incorpo-
rates competition between categories by storing both
positive and negative exemplars and categorizing ac-
cording to the majority among the k nearest neigh-
bors. However, it does not implement Shepard’s law.
It additionally differs from the GCM (Eq. (1)) in bas-
ing categorization on the k nearest neighbors rather
than summed similarity to all neighbors.
Like the centered model, the distributed model
needs both positive and negative training data.
Again, labeled data is not necessary as we can use
word token vectors. Positive training data consists of
tokens of the target word, and tokens of other words
are negative training data. This model does not make
use of the target’s type vector.
Above we have discussed two pieces of informa-
tion that region models can encode and that are hard
to encode in single-point models of word meaning:
variance in each dimension and co-occurrence of
feature values. The centered model encodes the vari-
ance in the values of each dimension through the
weights QIN
i , but it does not retain information on
feature values of different dimensions that tend to
co-occur. The distributed model encodes both vari-
ance in each dimension and co-occurrence of fea-
ture values through the remembered exemplars. So
the centered model should do well for monosemous
words, since it seems reasonable that their token
vectors should form a single region around the type
vector. For polysemous words, token vectors could
be more scattered in semantic space, in which case
the distributed model should do better.
Note that neither the centered nor the distributed
model is a clustering model: Both are supervised
models learning the distinctions between tokens of
the target word and other vectors. Neither of them
groups vectors in an unsupervised fashion.
Hard versus soft region boundaries. In the
current paper, we consider only regions with sharp
boundaries. In the centered model, a point x�
will be considered a member of the w-region if
P(IN(x, w)) ≥ 0.5. In the distributed model, x�
will be considered a member if the majority of its
k nearest neighbors are members. However, it is im-
</bodyText>
<equation confidence="0.74517">
Qi =
</equation>
<page confidence="0.942314">
60
</page>
<bodyText confidence="0.999770375">
portant that both models can also be used to repre-
sent regions with soft boundaries. In the centered
model, we can use P(IN(x, w)) without a thresh-
old. In the distributed model, we can use the fraction
of k that are positive instances, or we can compute
summed similarity to the positive instances like the
GCM does. So both models can be used to estimate
degrees of membership in a target word’s region.
</bodyText>
<sectionHeader confidence="0.957772" genericHeader="method">
4 Task, Data, and Implementation
</sectionHeader>
<bodyText confidence="0.999987225">
This section describes the task used for evaluation,
the data, and the implementation of the models.
Task. The main task will be for a model trained
on a target word w to predict, for a given point x� in
semantic space, whether x� is a token vector of w or
not. This task is a direct test of whether the region
induced for w succeeds in characterizing the region
in semantic space in which tokens of w will occur.
As an example, consider the target word super-
sede: Region models of supersede will be trained
on tokens of supersede in a training dataset. One
such token is supersede knowledge (i.e., knowledge
as the direct object of supersede). We compute a to-
ken vector for this occurrence by combining the type
vectors of supersede and knowledge. After train-
ing a model, we test it on tokens occurring in a test
dataset. Positive test items are tokens of supersede,
and negative test items are tokens of other words, for
example guard. An example of a positive test item
is supersede collection. The test items will consist
solely of tokens that do not occur in the training data.
Data. We focus on verbs in this paper since para-
phrase appropriateness for verbs is an important task
in the context of textual entailment. Since we sus-
pect that the centered model will be better suited to
modeling monosemous words while the distributed
model should do equally well on monosemous and
polysemous words, we first test a group of monose-
mous verbs, then a mixed group. We use WordNet
3.0 to form the two groups. The first group consists
of all verbs listed in WordNet 3.0 as being monose-
mous. We refer to this set as Mon. Since we also
want to compare the two region models on the task
of hyponymy encoding (Erk, 2009), we use as our
set of mixed monosemous and polysemous verbs the
verbs used there to test hyponymy encoding: the set
of all verbs that are hypernyms of the Mon verbs ac-
cording to WordNet 3.0. We call this set Hyp.
We use the British National Corpus (BNC) to
compute the vector space and as our source of tar-
get word tokens. We need token vectors for training
the two region models, and we need separate, previ-
ously unseen token vectors as test data. So we split
the written portion of the BNC in half at random,
leaving files intact. This yielded a training and a test
set. We computed word type vectors from the train-
ing half of the BNC, using a syntax-based vector
space (Pad´o and Lapata, 2007) of 500 dimensions,
with raw co-occurrence counts as dimension values.
We used the dv package1 to compute type vectors
from a Minipar (Lin, 1993) parse of the BNC.
We computed token vectors by combining the tar-
get verb’s type vector with the type vector of the
word occurring as the target’s direct object. We
test three methods for combining type vectors: First,
component-wise multiplication (below called mult),
which showed best results in Mitchell and Lapata’s
(2008) analysis. Second, component-wise averag-
ing (below called avg), a variant of type vector addi-
tion, a method often used for computing token vec-
tors. Third, we consider component-wise minimum
(min), which can be viewed as a kind of intersection
of the contexts with which the two words have been
observed. We used the training half of the BNC to
extract training tokens of the target verbs, and the
test half for extracting test tokens. We used only
those verb/object pairs as test tokens that did not also
occur in the training data.
We restricted the set of verbs to avoid data sparse-
ness issues, using only verbs that occurred with at
least 50 different direct objects in the training part of
the BNC. The direct objects, in turn, were restricted
to exclude overly rare and overly frequent (and thus
potentially uninformative) items. We restricted the
direct objects to those with no more than 6,500 and
no less than 270 occurrences in Mon ∪ Hyp. The
resulting set Mon consisted of 120 verbs, and Hyp
consisted of 430 verbs.
Model implementation. We implemented the
centered model using the OpenNLP maxent pack-
</bodyText>
<page confidence="0.623294">
2
</page>
<bodyText confidence="0.9839605">
age and the distributed model using TiMBL3 in the
IB1 setting with k = 5 nearest neighbors. We use bi-
</bodyText>
<footnote confidence="0.999972333333333">
1http://www.nlpado.de/∼sebastian/dv.html
2http://maxent.sourceforge.net/
3http://ilk.uvt.nl/timbl/
</footnote>
<page confidence="0.996502">
61
</page>
<table confidence="0.9993706">
centered distributed
Prec Rec F Prec Rec F
mult 100 73.2 84.5 29.4 47.5 36.3
avg 99.6 91.3 95.3 71.1 99.9 83.1
min 97.9 85.4 91.2 21.0 90.3 34.1
</table>
<tableCaption confidence="0.996067">
Table 1: Results: token classification for monosemous
verbs. Random baseline: Prec 0.8, Rec 49.8, F 1.6.
</tableCaption>
<bodyText confidence="0.98174125">
nary models throughout, such that the classification
task is always between IN and OUT. In training and
testing, each token vector was presented to a model
only once, ignoring the frequency of direct objects.
</bodyText>
<sectionHeader confidence="0.999579" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9998065">
This section reports on experiments that test the per-
formance of the two region models of word meaning
in vector space that we have presented in Sec. 3, the
centered and the distributed model.
</bodyText>
<subsectionHeader confidence="0.315524">
Experiment 1: Token classification for
monosemous verbs
</subsectionHeader>
<bodyText confidence="0.991100714285714">
In the first experiment, we test whether the two
region models can identify novel tokens of the
monosemous verbs in Mon. The task is the one de-
scribed in Sec. 4. We focus on monosemous verbs
first because we suspect that the centered model
should do better here than on polysemous verbs.
Both models were trained using token vectors com-
puted from the training half of the BNC. Token vec-
tors of the target verb were treated as positive data,
and token vectors of other verbs as negative data.4
We used resampling to restrict the number of nega-
tive items used during training, using 3% of the neg-
ative items, randomly sampled.5 We use for test-
ing only those direct objects that do not also ap-
pear in the training data, yielding 6,339 positive and
1,396,552 negative test items summed over all tar-
get verbs. The case of supersede discussed in Sec. 4
is an example of a monosemous verb according to
WordNet 3.0.
Table 1 summarizes precision, recall and F-score
results. Both models easily beat the random base-
</bodyText>
<footnote confidence="0.909063333333333">
4This simplification breaks down for 6 of the 120 verbs
(5%), which are in fact synonyms. We consider this an accept-
able level of noise.
5The number of 3% was determined on a development set
constructed by further splitting the training set into training and
development portion.
</footnote>
<table confidence="0.999963818181818">
Prec centered F distributed
Rec Prec Rec F
100 59.3 74.5 20.8 47.2 28.9
100 89.4 94.4 57.4 49.7 53.2
100 97.4 98.7 92.1 41.1 56.9
99.5 86.6 92.6 61.6 99.8 76.2
99.7 96.6 98.1 86.3 100 92.6
100 100 100 99.1 100 99.6
100 82.9 90.6 17.9 92.6 30.1
98.2 88.2 93.0 25.4 89.2 39.6
86.4 90.3 88.3 42.9 80.0 55.9
</table>
<tableCaption confidence="0.986594">
Table 2: Results: token classification for monosemous
verbs, by target frequency
</tableCaption>
<table confidence="0.999796375">
# senses centered distributed
Prec Rec F Prec Rec F
all 100 92.9 96.3 99.6 99.8 99.7
1 100 86.1 92.5 99.0 99.5 99.2
2-5 100 90.8 95.2 99.4 99.6 99.5
6-10 100 93.5 96.7 99.9 99.9 99.9
11-20 100 96.6 98.3 100 100 100
≥ 21 100 99.5 99.7 100 100 100
</table>
<tableCaption confidence="0.981884">
Table 3: Results: Token classification for polysemous
verbs, avg token computation. Random baseline: Prec
8.2, Rec 50.4, F 14.0.
</tableCaption>
<bodyText confidence="0.999737666666667">
line. The centered model shows better performance
overall than the distributed one, and the avg method
of computing token vector worked best for both
models. The centered model has extremely high
precision throughout, while the distributed model
has better recall for conditions avg and min. Ta-
ble 2 breaks down the results by the frequency of
the target verb, measured in the number of different
verb/object tokens in the training data.
</bodyText>
<subsectionHeader confidence="0.9087015">
Experiment 2: Token classification for
polysemous verbs
</subsectionHeader>
<bodyText confidence="0.999904454545455">
We now test how the centered and distributed mod-
els fare on the same task, but with a mixture of
monosemous and polysemous verbs. We use the
verbs in Hyp, which in WordNet 3.0 have on aver-
age 6.79 senses. For example, follow is a WordNet
hypernym of the monosemous supersede. It has 24
senses, among them comply and postdate. Among
its training tokens are follow instruction and follow
dinner. The first is probably the comply sense offol-
low, the second the postdate sense. An example of a
test token (i.e., occurring in the test but not the train-
</bodyText>
<figure confidence="0.9943466">
freq.
mult 50-100
100-200
200-500
avg 50 - 100
100-200
200-500
min 50-100
100-200
200-500
</figure>
<page confidence="0.995478">
62
</page>
<bodyText confidence="0.999947636363636">
ing data) is follow tea. (If tea is tea time, this is also
the postdate sense.)
We computed type vectors for the Hyp verbs and
their objects from the training half of the BNC, and
computed token vectors using the best method from
Exp. 1, avg. Again, we use for testing only those to-
kens that do not also appear in the training data. Due
to the larger amount of data, we used resampling in
the training as well as the test data, using only a ran-
dom 3% of negative tokens for testing. This yielded
25,736 positive and 670,630 negative test items.
Table 3 shows the results: The first line has the
overall results, and the following lines break down
the results by the number of senses each lemma has
in WordNet 3.0.6 Both models, centered and dis-
tributed, easily beat the random baseline. The cen-
tered model has comparable results for the Hyp as
for the Mon verbs (cf. Table 1), while the distributed
model has better results for this dataset, and better
results than the centered model. The centered model
shows a marked improvement in recall as the num-
ber of senses increases.
</bodyText>
<subsectionHeader confidence="0.786722">
Experiment 3: Encoding hyponymy
</subsectionHeader>
<bodyText confidence="0.99976475">
We first proposed the centered model as a method
for encoding hyponymy information in a vector
space representation (Erk, 2009). Hyponymy infor-
mation from another source, in this case WordNet,
was encoded in a centered region representation of
a target verb by using tokens of the verb itself as
well as tokens from its direct hyponyms in training
the model. Negative data consisted of training data
tokens that were not occurrences of the target verb
or its direct hyponyms. In the example of the verb
follow, the positive training data would contain to-
kens of follow along with tokens of supersede and
guard, another direct hyponym of follow. Negative
training tokens would include, for example, tokens
of the word destroy. The resulting centered model,
in this case of follow, was then tested on previously
unseen tokens, for example guard purpose (a token
of a hyponym) and destroy lawn (a token of a non-
hyponym), with the task of predicting whether they
were tokens of direct hyponyms of follow or not.
</bodyText>
<tableCaption confidence="0.6139925">
6The one-sense items in Table 3 are a 43 verb subset of Mon.
The reason for the difference in performance in comparison to
Table 1 is unclear, as the two sets have similar distributions of
lemma frequencies.
</tableCaption>
<table confidence="0.89449">
centered distributed
Prec Rec F Prec Rec F
95.2 43.4 59.6 68.3 58.6 63.1
</table>
<tableCaption confidence="0.993989666666667">
Table 4: Results: Identifying hyponyms based on ex-
tended hypernym representations, avg token computa-
tion. Random baseline: Prec 11.0, Rec 50.2, F 18.0
</tableCaption>
<bodyText confidence="0.99996175">
We now repeat this experiment with the dis-
tributed model. We use the direct hypernyms of the
verbs in Mon, with the same frequency restrictions
as above. We refer to this set of 273 verbs as DHyp.
We train one centered and one distributed model for
each verb w in DHyp. Positive training tokens for
training a model for a verb w ∈ DHyp are tokens
of w and of all sufficiently frequent children of w
in WordNet 3.0. Negative training tokens are to-
kens of other verbs in DHyp and their children. We
again sample a random 3% of the negative data dur-
ing both training and testing.
Table 4 shows the results. Both models again beat
the baseline. The distributed model shows slightly
better results overall, while the centered model has
by far the highest precision.
</bodyText>
<sectionHeader confidence="0.993323" genericHeader="discussions">
Discussion
</sectionHeader>
<bodyText confidence="0.996573227272727">
Performance on monosemous verbs. For the
monosemous verbs in Exp. 1, both models succeed
in inducing regions that characterize tokens of a tar-
get word with high precision as well as high recall.
The extremely high precision of the centered model
shows that in general the region surrounding the type
vector does not contain any tokens of other verbs
than the target. Concerning the distributed model, it
is to be expected that in min, and even more so in
mult, dimension values will vary more than in avg;
this could explain the huge difference between avg
and the other two conditions for this model. It is
interesting to note that the centered model achieves
better precision, while the distributed model reaches
higher recall. Maybe it will be possible in later mod-
els to combine their strengths. The breakdown by
frequency bands in Table 2 shows that in mult and
avg, the models get strictly better with more data,
while min has a precision/recall tradeoff.
Performance on polysemous verbs. For the pol-
ysemous verbs in Exp. 2, like for the monosemous
verbs in Exp. 1, both models show excellent per-
</bodyText>
<page confidence="0.998194">
63
</page>
<bodyText confidence="0.999888822222222">
formance in distinguishing tokens of the target verb
from tokens of other verbs.7 The distributed model
surpasses the centered one on this dataset. However,
it is not clear that this is because the contiguous re-
gion that the centered model infers is inappropriate
for polysemous verbs. After all the centered model,
too, achieves better performance on this dataset than
on Mon. The fact that results get better with the de-
gree of polysemy, at first surprising, may indicate
that the centered model draws an overly tight bound-
ary around the type vector and that this boundary
improves when token vectors differ more, and are
at greater distance from the type vector, as should
be the case for more polysemous lemmas. Another
possible reason for the better performance of both
models is that this dataset is larger and in particular
provides a larger set of negative data.
Encoding external information in a region
model. In the hyponymy encoding task in Exp. 3,
both models successfully encode hyponymy infor-
mation in vector space representations. The cen-
tered model manages to derive a high-precision re-
gion around the type vector, while the distributed
model makes use of outliers in the training data to
achieve higher recall.
Comparing region representations to point
representations. We now compare the two region
models to existing variants of point-based vector
space models. Both region models have dimen-
sion weights, whose function is somewhat similar to
that of log-likelihood or mutual information trans-
formations of raw co-occurrence counts: to estimate
the importance of each dimension for characteriz-
ing the target word in question. However, dimension
weights in region models are computed based on to-
ken vectors, while all co-occurrence count transfor-
mations work on type vectors.
The distributed model additionally has the ability
to represent typical co-occurrences of feature values
because the training tokens are remembered in their
entirety. The most similar mechanism in point-based
vector space models is probably dimensionality re-
duction, which strives to find latent dimensions that
explain most of the variance in the data. But again,
dimensionality reduction uses type vectors while the
</bodyText>
<footnote confidence="0.99347">
7The near-perfect performance in particular of the dis-
tributed model has been confirmed on a separate noun dataset.
</footnote>
<bodyText confidence="0.999736578947369">
distributed model stores token vectors, which can
show more variance than the type vectors alone.
Applications of region models. Region models
of word meaning are interesting for the task of test-
ing the appropriateness of paraphrases in context.
Previous models either used competition between
paraphrase candidates or a global similarity thresh-
old to decide whether to accept a paraphrase can-
didate (Mitchell and Lapata, 2008; Szpektor et al.,
2008). A region model of word meaning used for
the same task would still require a threshold, in this
case a threshold on membership probability, but the
regions for which membership is tested could dif-
fer in their size, and the extent of each region would
be learned individually from the data. To use the
model, for example to test whether trickle is a good
paraphrase for run in the color ran, we would test
whether the sentence-specific token vector for run
falls into the region of trickle.
</bodyText>
<sectionHeader confidence="0.990595" genericHeader="conclusions">
6 Conclusion and outlook
</sectionHeader>
<bodyText confidence="0.999558857142857">
In this paper, we have proposed using region models
for word meaning in vector space, predicting regions
in space in which points can be assumed to carry the
same meaning. We have studied two models, the
prototype-like centered models and the exemplar-
like distributed model, both of which are learned
without labeled data by making use of token vectors
of the target word in question. Both models show
excellent performance, with F-scores of 83%-99%,
on the task of identifying previously unseen occur-
rences of the target word.
Our aim is to to test the usability of region mod-
els for predicting paraphrase appropriateness in con-
text. The next step towards that will be to test region
models on the task of identifying synonym tokens.
Acknowledgements. Many thanks to Jason
Baldridge, David Beaver, Graham Katz, Alexander
Koller, Ray Mooney, and Manfred Pinkal for helpful
discussions. This work was supported by the Mor-
ris Memorial Grant from the New York Community
Trust.
</bodyText>
<sectionHeader confidence="0.999273" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984099666666667">
M. Connor and D. Roth. 2007. Context sensitive para-
phrasing with a single unsupervised classifier. In Pro-
ceedings of ECML-07, Warsaw, Poland.
</reference>
<page confidence="0.986578">
64
</page>
<reference confidence="0.999745">
K. Erk and S. Pado. 2008. A structured vector space
model for word meaning in context. In Proceedings of
EMNLP-08, Hawaii.
K. Erk. 2009. Supporting inferences in semantic space:
representing words as regions. In Proceedings of
IWCS-8, Tilburg, Netherlands.
P. G¨ardenfors. 2004. Conceptual spaces. MIT press,
Cambridge, MA.
M. Geffet and I. Dagan. 2005. The distributional inclu-
sion hypotheses and lexical entailment. In Proceed-
ings of ACL-05, Ann Arbor, MI.
J. Gorman and J. R. Curran. 2006. Scaling distributional
similarity to large corpora. In Proceedings ofACL ’06,
Sydney.
J. A. Hampton. 1991. The combination of prototype con-
cepts. In P. Schwanenflugel, editor, The psychology of
word meanings. Lawrence Erlbaum Associates.
P. Hanks. 2000. Do word meanings exist? Computers
and the Humanities, 34(1-2):205–215(11).
M. Jones and D. Mewhort. 2007. Representing word
menaing and order information in a composite holo-
graphic lexicon. Psychological Review, 114:1–37.
A. Kilgarriff. 1997. I don’t believe in word senses. Com-
puters and the Humanities, 31(2):91–113.
W. Kintsch. 2001. Predication. Cognitive Science,
25:173–202.
T. Landauer and S. Dumais. 1997. A solution to Platos
problem: the latent semantic analysis theory of ac-
quisition, induction, and representation of knowledge.
Psychological Review, 104(2):211–240.
D. Lin. 1993. Principle-based parsing without overgen-
eration. In Proceedings of ACL’93, Columbus, Ohio.
D. Lin. 1998. Automatic retrieval and clustering of sim-
ilar words. In COLING-ACL98, Montreal, Canada.
W. Lowe and S. McDonald. 2000. The direct route: Me-
diated priming in semantic space. In Proceedings of
the Cognitive Science Society.
W. Lowe. 2001. Towards a theory of semantic space. In
Proceedings of the Cognitive Science Society.
K. Lund and C. Burgess. 1996. Producing
high-dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods, Instruments,
and Computers, 28:203—208.
C. D. Manning, P. Raghavan, and H. Sch¨utze. 2008. In-
troduction to Information Retrieval. Cambridge Uni-
versity Press.
D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004.
Finding predominant senses in untagged text. In Pro-
ceedings ofACL’04, Barcelona, Spain.
S. McDonald and M. Ramscar. 2001. Testing the dis-
tributional hypothesis: The influence of context on
judgements of semantic similarity. In Proceedings of
the Cognitive Science Society.
J. Mitchell and M. Lapata. 2008. Vector-based models
of semantic composition. In Proceedings of ACL-08,
Columbus, OH.
G. L. Murphy. 2002. The Big Book of Concepts. MIT
Press.
R. M. Nosofsky. 1986. Attention, similarity, and the
identification-categorization relationship. Journal of
Experimental Psychology: General, 115:39–57.
S. Pad´o and M. Lapata. 2007. Dependency-based con-
struction of semantic space models. Computational
Linguistics, 33(2):161–199.
M. Sahlgren and J. Karlgren. 2005. Automatic bilingual
lexicon acquisition using random indexing of parallel
corpora. Journal of Natural Language Engineering,
Special Issue on Parallel Texts, 11(3).
H. Sch¨utze. 1998. Automatic word sense discrimination.
Computational Linguistics, 24(1).
R. Shepard. 1987. Towards a universal law of
generalization for psychological science. Science,
237(4820):1317–1323.
E. E. Smith, D. Osherson, L. J. Rips, and M. Keane.
1988. Combining prototypes: A selective modifica-
tion model. Cognitive Science, 12(4):485–527.
P. Smolensky. 1990. Tensor product variable binding and
the representation of symbolic structures in connec-
tionist systems. Artificial Intelligence, 46:159–216.
R. Snow, D. Jurafsky, and A. Y. Ng. 2006. Semantic
taxonomy induction from heterogenous evidence. In
Proceedings of COLING/ACL’06.
I. Szpektor, I. Dagan, R. Bar-Haim, and J. Goldberger.
2008. Contextual preferences. In Proceedings of
ACL-08, Columbus, OH.
J. Weeds, D. Weir, and D. McCarthy. 2004. Character-
ising measures of lexical distributional similarity. In
Proceedings of COLING-04, Geneva, Switzerland.
</reference>
<page confidence="0.999616">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.978403">
<title confidence="0.997443">Representing words as regions in vector space</title>
<author confidence="0.992178">Katrin Erk</author>
<affiliation confidence="0.999855">University of Texas at Austin</affiliation>
<email confidence="0.999682">katrin.erk@mail.utexas.edu</email>
<abstract confidence="0.999190142857143">Vector space models of word meaning typically represent the meaning of a word as a vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meanas vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Connor</author>
<author>D Roth</author>
</authors>
<title>Context sensitive paraphrasing with a single unsupervised classifier.</title>
<date>2007</date>
<booktitle>In Proceedings of ECML-07,</booktitle>
<location>Warsaw, Poland.</location>
<contexts>
<context position="4240" citStr="Connor and Roth, 2007" startWordPosition="693" endWordPosition="696">valuate the two region models on a task of token classification: Given a point in vector space, the task is predict the word of which it is a token vector. By representing the meaning of words as regions in vector space, we can describe areas in which points encode similar meanings. This description is flexible, depending on the target word in question, rather than uniform for all words through a fixed distance threshold from the target’s type vector. One possible application of region models of word meaning is in the task of determining the appropriateness of a paraphrase in a given context (Connor and Roth, 2007). This task is highly relevant for textual entailment (Szpektor et al., 2008). Current vector space approaches typically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector spac</context>
</contexts>
<marker>Connor, Roth, 2007</marker>
<rawString>M. Connor and D. Roth. 2007. Context sensitive paraphrasing with a single unsupervised classifier. In Proceedings of ECML-07, Warsaw, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pado</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP-08,</booktitle>
<location>Hawaii.</location>
<contexts>
<context position="4494" citStr="Erk and Pado, 2008" startWordPosition="735" endWordPosition="738">s encode similar meanings. This description is flexible, depending on the target word in question, rather than uniform for all words through a fixed distance threshold from the target’s type vector. One possible application of region models of word meaning is in the task of determining the appropriateness of a paraphrase in a given context (Connor and Roth, 2007). This task is highly relevant for textual entailment (Szpektor et al., 2008). Current vector space approaches typically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items </context>
</contexts>
<marker>Erk, Pado, 2008</marker>
<rawString>K. Erk and S. Pado. 2008. A structured vector space model for word meaning in context. In Proceedings of EMNLP-08, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
</authors>
<title>Supporting inferences in semantic space: representing words as regions.</title>
<date>2009</date>
<booktitle>In Proceedings of IWCS-8,</booktitle>
<location>Tilburg, Netherlands.</location>
<contexts>
<context position="2837" citStr="Erk, 2009" startWordPosition="466" endWordPosition="467">ces of feature values in occurrences of the target. To encode these two types of information, we study richer models of word meaning in vector space beyond single point representations. Many models of categorization in psychology represent a concept as a region, characterized by feature vectors with dimension weights (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986). Taking our cue from these approaches, we study two models that represent a word as a region in vector space rather than a point. The first model is one that we have recently introduced for representing hyponymy in vector space (Erk, 2009). We now test its suitability as a general region model for word meaning. This model can be viewed as a prototypestyle model that induces a region surrounding a central vector. As it does not record co-occurrences of feature values, we contrast it with a second model, an exemplar-style model using a k-nearest neighbor analysis, which can represent both degree of variance in each dimension and value co-occurrences. Both models induce regions representations without labeled data. The idea on which both models are based is to use word token vectors to estimate a 57 Proceedings of the Thirteenth C</context>
<context position="7004" citStr="Erk (2009)" startWordPosition="1139" endWordPosition="1140"> they find that while recall of this method is good (whenever some senses of two words stand in an entailment relation, topweighted dimensions of their vectors stand in a subset relation), precision is problematic. Weeds, Weir and McCarthy (2004) introduce the notion of distributional generality (x is more distributionally general than y if x occurs in more contexts than y) and find that for hyponym-hypernym pairs from WordNet, hyponyms are typically more distributionally general. (As they study only word pairs that are known to be related by hyponymy, they test for recall but not precision.) Erk (2009) suggests that while it may not be possible to induce hyponymy information from a vector space representation, it is possible to encode it in a vector space representation after it has been obtained through some other means. Vector space models of word tokens. Vector space models have mostly been used to represent the meaning of a word type by summing its cooccurrence counts over a complete corpus. There are several approaches to computing vectors for individual word tokens. All of them compute word type vectors first, then combine them into token vectors. Kintsch (2001) and Mitchell and Lapat</context>
<context position="10969" citStr="Erk, 2009" startWordPosition="1783" endWordPosition="1784">e. Feature structures play no central role in this model, but G¨ardenfors suggests that concepts may be represented by a central point, such that categorization could simply be determining the nearest central point (without positing an exponential relation between distance and similarity). 3 Models In this section, we present two models for representing word meaning as regions in vector space. The centered model. The first model that we define, which we call the centered model, is prototypelike. As the representation for a target word, it induces a region surrounding the target’s type vector (Erk, 2009). Let w be the target word and w~ its type vector. Let x~ be a point in the same vector space. To predict whether x~ represents the same meaning as ~w, we estimate the probability P(IN(~x, ~w)) that x~ is in the region around ~w, using a log-linear model: 1 X P (IN(~x, ~w)) = Z exp( βIN i fi(~x, ~w)) (3) i where the fi are features that characterize the point ~x, and the βIN iare weights identifying the importance of the different features for the class IN. Z is a normalizing factor that ensures that P is a probability distribution: If P(OUT(~x, ~w)) = 1− P(IN(~x, ~w)) is the probability that </context>
<context position="18860" citStr="Erk, 2009" startWordPosition="3174" endWordPosition="3175">bs in this paper since paraphrase appropriateness for verbs is an important task in the context of textual entailment. Since we suspect that the centered model will be better suited to modeling monosemous words while the distributed model should do equally well on monosemous and polysemous words, we first test a group of monosemous verbs, then a mixed group. We use WordNet 3.0 to form the two groups. The first group consists of all verbs listed in WordNet 3.0 as being monosemous. We refer to this set as Mon. Since we also want to compare the two region models on the task of hyponymy encoding (Erk, 2009), we use as our set of mixed monosemous and polysemous verbs the verbs used there to test hyponymy encoding: the set of all verbs that are hypernyms of the Mon verbs according to WordNet 3.0. We call this set Hyp. We use the British National Corpus (BNC) to compute the vector space and as our source of target word tokens. We need token vectors for training the two region models, and we need separate, previously unseen token vectors as test data. So we split the written portion of the BNC in half at random, leaving files intact. This yielded a training and a test set. We computed word type vect</context>
<context position="26482" citStr="Erk, 2009" startWordPosition="4501" endWordPosition="4502">ing lines break down the results by the number of senses each lemma has in WordNet 3.0.6 Both models, centered and distributed, easily beat the random baseline. The centered model has comparable results for the Hyp as for the Mon verbs (cf. Table 1), while the distributed model has better results for this dataset, and better results than the centered model. The centered model shows a marked improvement in recall as the number of senses increases. Experiment 3: Encoding hyponymy We first proposed the centered model as a method for encoding hyponymy information in a vector space representation (Erk, 2009). Hyponymy information from another source, in this case WordNet, was encoded in a centered region representation of a target verb by using tokens of the verb itself as well as tokens from its direct hyponyms in training the model. Negative data consisted of training data tokens that were not occurrences of the target verb or its direct hyponyms. In the example of the verb follow, the positive training data would contain tokens of follow along with tokens of supersede and guard, another direct hyponym of follow. Negative training tokens would include, for example, tokens of the word destroy. T</context>
</contexts>
<marker>Erk, 2009</marker>
<rawString>K. Erk. 2009. Supporting inferences in semantic space: representing words as regions. In Proceedings of IWCS-8, Tilburg, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P G¨ardenfors</author>
</authors>
<title>Conceptual spaces.</title>
<date>2004</date>
<publisher>MIT press,</publisher>
<location>Cambridge, MA.</location>
<marker>G¨ardenfors, 2004</marker>
<rawString>P. G¨ardenfors. 2004. Conceptual spaces. MIT press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Geffet</author>
<author>I Dagan</author>
</authors>
<title>The distributional inclusion hypotheses and lexical entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05,</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="6242" citStr="Geffet and Dagan (2005)" startWordPosition="1010" endWordPosition="1014">, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, they find that while recall of this method is good (whenever some senses of two words stand in an entailment relation, topweighted dimensions of their vectors stand in a subset relation), precision is problematic. Weeds, Weir and McCarthy (2004) introduce the notion of distributional generality (x is more distributionally general than y if x occurs in more contexts than y) and find that for hyponym-hypernym pairs from WordNet, hyponyms are typ</context>
</contexts>
<marker>Geffet, Dagan, 2005</marker>
<rawString>M. Geffet and I. Dagan. 2005. The distributional inclusion hypotheses and lexical entailment. In Proceedings of ACL-05, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gorman</author>
<author>J R Curran</author>
</authors>
<title>Scaling distributional similarity to large corpora.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL ’06,</booktitle>
<location>Sydney.</location>
<contexts>
<context position="1376" citStr="Gorman and Curran, 2006" startWordPosition="224" endWordPosition="227">urgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representation will constitute a unio</context>
<context position="5822" citStr="Gorman and Curran, 2006" startWordPosition="947" endWordPosition="950">96) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, they find that while recall</context>
</contexts>
<marker>Gorman, Curran, 2006</marker>
<rawString>J. Gorman and J. R. Curran. 2006. Scaling distributional similarity to large corpora. In Proceedings ofACL ’06, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hampton</author>
</authors>
<title>The combination of prototype concepts.</title>
<date>1991</date>
<editor>In P. Schwanenflugel, editor,</editor>
<contexts>
<context position="2580" citStr="Hampton, 1991" startWordPosition="420" endWordPosition="421">te a union over the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimension: Do values on each dimension vary a lot across occurrences of the target? Also, it does not provide information on co-occurrences of feature values in occurrences of the target. To encode these two types of information, we study richer models of word meaning in vector space beyond single point representations. Many models of categorization in psychology represent a concept as a region, characterized by feature vectors with dimension weights (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986). Taking our cue from these approaches, we study two models that represent a word as a region in vector space rather than a point. The first model is one that we have recently introduced for representing hyponymy in vector space (Erk, 2009). We now test its suitability as a general region model for word meaning. This model can be viewed as a prototypestyle model that induces a region surrounding a central vector. As it does not record co-occurrences of feature values, we contrast it with a second model, an exemplar-style model using a k-nearest neighbor analysis, which can rep</context>
<context position="8350" citStr="Hampton, 1991" startWordPosition="1358" endWordPosition="1359"> and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986)). Features in these models are typically weighted to represent their importance to the concept in question. Similarity to a given feature vector is usually taken to decrease exponentially with distance from that vector, following Shepard’s law (Shepard, 1987). Categorization involves competition between categories. Feature-based models of human concept representation can be broadly categorized into prototype models, which represent a concept by a single summary representation, and exemplar models, which assume that categorization is by comparison to remembered exemplars. As a</context>
</contexts>
<marker>Hampton, 1991</marker>
<rawString>J. A. Hampton. 1991. The combination of prototype concepts. In P. Schwanenflugel, editor, The psychology of word meanings. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
</authors>
<date>2000</date>
<booktitle>Do word meanings exist? Computers and the Humanities,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="1599" citStr="Hanks, 2000" startWordPosition="259" endWordPosition="260"> target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representation will constitute a union over the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimension: Do values on each dimension vary a lot across occurrences of the target? Also, it does not provid</context>
</contexts>
<marker>Hanks, 2000</marker>
<rawString>P. Hanks. 2000. Do word meanings exist? Computers and the Humanities, 34(1-2):205–215(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jones</author>
<author>D Mewhort</author>
</authors>
<title>Representing word menaing and order information in a composite holographic lexicon. Psychological Review,</title>
<date>2007</date>
<pages>114--1</pages>
<contexts>
<context position="829" citStr="Jones and Mewhort, 2007" startWordPosition="135" endWordPosition="138">vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task. 1 Introduction Vector space models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer </context>
<context position="5057" citStr="Jones and Mewhort, 2007" startWordPosition="824" endWordPosition="828">al paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items which which the target word has been observed to co-occur, for example other words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured mo</context>
</contexts>
<marker>Jones, Mewhort, 2007</marker>
<rawString>M. Jones and D. Mewhort. 2007. Representing word menaing and order information in a composite holographic lexicon. Psychological Review, 114:1–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>I don’t believe in word senses.</title>
<date>1997</date>
<journal>Computers and the Humanities,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="1585" citStr="Kilgarriff, 1997" startWordPosition="257" endWordPosition="258">exts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representation will constitute a union over the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimension: Do values on each dimension vary a lot across occurrences of the target? Also, it d</context>
</contexts>
<marker>Kilgarriff, 1997</marker>
<rawString>A. Kilgarriff. 1997. I don’t believe in word senses. Computers and the Humanities, 31(2):91–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kintsch</author>
</authors>
<date>2001</date>
<journal>Predication. Cognitive Science,</journal>
<pages>25--173</pages>
<contexts>
<context position="7581" citStr="Kintsch (2001)" startWordPosition="1237" endWordPosition="1238">recall but not precision.) Erk (2009) suggests that while it may not be possible to induce hyponymy information from a vector space representation, it is possible to encode it in a vector space representation after it has been obtained through some other means. Vector space models of word tokens. Vector space models have mostly been used to represent the meaning of a word type by summing its cooccurrence counts over a complete corpus. There are several approaches to computing vectors for individual word tokens. All of them compute word type vectors first, then combine them into token vectors. Kintsch (2001) and Mitchell and Lapata (2008) combine the target’s type vector with that of a single word in the target’s syntactic context. Landauer and Dumais (Landauer and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based mo</context>
</contexts>
<marker>Kintsch, 2001</marker>
<rawString>W. Kintsch. 2001. Predication. Cognitive Science, 25:173–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Landauer</author>
<author>S Dumais</author>
</authors>
<title>A solution to Platos problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="792" citStr="Landauer and Dumais, 1997" startWordPosition="129" endWordPosition="132">y represent the meaning of a word as a vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task. 1 Introduction Vector space models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998</context>
<context position="4978" citStr="Landauer and Dumais, 1997" startWordPosition="811" endWordPosition="814">pically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items which which the target word has been observed to co-occur, for example other words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality redu</context>
<context position="7755" citStr="Landauer and Dumais, 1997" startWordPosition="1265" endWordPosition="1268"> to encode it in a vector space representation after it has been obtained through some other means. Vector space models of word tokens. Vector space models have mostly been used to represent the meaning of a word type by summing its cooccurrence counts over a complete corpus. There are several approaches to computing vectors for individual word tokens. All of them compute word type vectors first, then combine them into token vectors. Kintsch (2001) and Mitchell and Lapata (2008) combine the target’s type vector with that of a single word in the target’s syntactic context. Landauer and Dumais (Landauer and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nos</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>T. Landauer and S. Dumais. 1997. A solution to Platos problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2):211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Principle-based parsing without overgeneration.</title>
<date>1993</date>
<booktitle>In Proceedings of ACL’93,</booktitle>
<location>Columbus, Ohio.</location>
<contexts>
<context position="19702" citStr="Lin, 1993" startWordPosition="3328" endWordPosition="3329"> National Corpus (BNC) to compute the vector space and as our source of target word tokens. We need token vectors for training the two region models, and we need separate, previously unseen token vectors as test data. So we split the written portion of the BNC in half at random, leaving files intact. This yielded a training and a test set. We computed word type vectors from the training half of the BNC, using a syntax-based vector space (Pad´o and Lapata, 2007) of 500 dimensions, with raw co-occurrence counts as dimension values. We used the dv package1 to compute type vectors from a Minipar (Lin, 1993) parse of the BNC. We computed token vectors by combining the target verb’s type vector with the type vector of the word occurring as the target’s direct object. We test three methods for combining type vectors: First, component-wise multiplication (below called mult), which showed best results in Mitchell and Lapata’s (2008) analysis. Second, component-wise averaging (below called avg), a variant of type vector addition, a method often used for computing token vectors. Third, we consider component-wise minimum (min), which can be viewed as a kind of intersection of the contexts with which the</context>
</contexts>
<marker>Lin, 1993</marker>
<rawString>D. Lin. 1993. Principle-based parsing without overgeneration. In Proceedings of ACL’93, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In COLING-ACL98,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="5777" citStr="Lin, 1998" startWordPosition="941" endWordPosition="942">er words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset r</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In COLING-ACL98, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lowe</author>
<author>S McDonald</author>
</authors>
<title>The direct route: Mediated priming in semantic space.</title>
<date>2000</date>
<booktitle>In Proceedings of the Cognitive Science Society.</booktitle>
<contexts>
<context position="1470" citStr="Lowe and McDonald, 2000" startWordPosition="239" endWordPosition="242">lgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representation will constitute a union over the uses or senses of the word. Such a model does not provide information on the amount</context>
<context position="6065" citStr="Lowe and McDonald, 2000" startWordPosition="985" endWordPosition="988">xample using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, they find that while recall of this method is good (whenever some senses of two words stand in an entailment relation, topweighted dimensions of their vectors stand in a subset relation), precision is problematic. Weeds, Weir and McCarthy (2004) introduce the notion of </context>
</contexts>
<marker>Lowe, McDonald, 2000</marker>
<rawString>W. Lowe and S. McDonald. 2000. The direct route: Mediated priming in semantic space. In Proceedings of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lowe</author>
</authors>
<title>Towards a theory of semantic space.</title>
<date>2001</date>
<booktitle>In Proceedings of the Cognitive Science Society.</booktitle>
<contexts>
<context position="804" citStr="Lowe, 2001" startWordPosition="133" endWordPosition="134">a word as a vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task. 1 Introduction Vector space models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cog</context>
<context position="5498" citStr="Lowe, 2001" startWordPosition="898" endWordPosition="899"> as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items which which the target word has been observed to co-occur, for example other words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDon</context>
</contexts>
<marker>Lowe, 2001</marker>
<rawString>W. Lowe. 2001. Towards a theory of semantic space. In Proceedings of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lund</author>
<author>C Burgess</author>
</authors>
<title>Producing high-dimensional semantic spaces from lexical cooccurrence.</title>
<date>1996</date>
<journal>Behavior Research Methods, Instruments, and Computers,</journal>
<pages>28--203</pages>
<contexts>
<context position="765" citStr="Lund and Burgess, 1996" startWordPosition="125" endWordPosition="128">of word meaning typically represent the meaning of a word as a vector computed by summing over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task. 1 Introduction Vector space models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and C</context>
<context position="4951" citStr="Lund and Burgess, 1996" startWordPosition="807" endWordPosition="810">ctor space approaches typically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items which which the target word has been observed to co-occur, for example other words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transforme</context>
</contexts>
<marker>Lund, Burgess, 1996</marker>
<rawString>K. Lund and C. Burgess. 1996. Producing high-dimensional semantic spaces from lexical cooccurrence. Behavior Research Methods, Instruments, and Computers, 28:203—208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>C. D. Manning, P. Raghavan, and H. Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Koeling</author>
<author>J Weeds</author>
<author>J Carroll</author>
</authors>
<title>Finding predominant senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL’04,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="5874" citStr="McCarthy et al., 2004" startWordPosition="955" endWordPosition="958"> simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, they find that while recall of this method is good (whenever some senses of two</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004. Finding predominant senses in untagged text. In Proceedings ofACL’04, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McDonald</author>
<author>M Ramscar</author>
</authors>
<title>Testing the distributional hypothesis: The influence of context on judgements of semantic similarity.</title>
<date>2001</date>
<booktitle>In Proceedings of the Cognitive Science Society.</booktitle>
<contexts>
<context position="1499" citStr="McDonald and Ramscar, 2001" startWordPosition="243" endWordPosition="247">rds as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representation will constitute a union over the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimensio</context>
<context position="6120" citStr="McDonald and Ramscar, 2001" startWordPosition="992" endWordPosition="995">2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, they find that while recall of this method is good (whenever some senses of two words stand in an entailment relation, topweighted dimensions of their vectors stand in a subset relation), precision is problematic. Weeds, Weir and McCarthy (2004) introduce the notion of distributional generality (x is more distributionally g</context>
</contexts>
<marker>McDonald, Ramscar, 2001</marker>
<rawString>S. McDonald and M. Ramscar. 2001. Testing the distributional hypothesis: The influence of context on judgements of semantic similarity. In Proceedings of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mitchell</author>
<author>M Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08,</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="4473" citStr="Mitchell and Lapata, 2008" startWordPosition="731" endWordPosition="734">scribe areas in which points encode similar meanings. This description is flexible, depending on the target word in question, rather than uniform for all words through a fixed distance threshold from the target’s type vector. One possible application of region models of word meaning is in the task of determining the appropriateness of a paraphrase in a given context (Connor and Roth, 2007). This task is highly relevant for textual entailment (Szpektor et al., 2008). Current vector space approaches typically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions sta</context>
<context position="7612" citStr="Mitchell and Lapata (2008)" startWordPosition="1240" endWordPosition="1243">ision.) Erk (2009) suggests that while it may not be possible to induce hyponymy information from a vector space representation, it is possible to encode it in a vector space representation after it has been obtained through some other means. Vector space models of word tokens. Vector space models have mostly been used to represent the meaning of a word type by summing its cooccurrence counts over a complete corpus. There are several approaches to computing vectors for individual word tokens. All of them compute word type vectors first, then combine them into token vectors. Kintsch (2001) and Mitchell and Lapata (2008) combine the target’s type vector with that of a single word in the target’s syntactic context. Landauer and Dumais (Landauer and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept represent</context>
<context position="32427" citStr="Mitchell and Lapata, 2008" startWordPosition="5483" endWordPosition="5486">iance in the data. But again, dimensionality reduction uses type vectors while the 7The near-perfect performance in particular of the distributed model has been confirmed on a separate noun dataset. distributed model stores token vectors, which can show more variance than the type vectors alone. Applications of region models. Region models of word meaning are interesting for the task of testing the appropriateness of paraphrases in context. Previous models either used competition between paraphrase candidates or a global similarity threshold to decide whether to accept a paraphrase candidate (Mitchell and Lapata, 2008; Szpektor et al., 2008). A region model of word meaning used for the same task would still require a threshold, in this case a threshold on membership probability, but the regions for which membership is tested could differ in their size, and the extent of each region would be learned individually from the data. To use the model, for example to test whether trickle is a good paraphrase for run in the color ran, we would test whether the sentence-specific token vector for run falls into the region of trickle. 6 Conclusion and outlook In this paper, we have proposed using region models for word</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>J. Mitchell and M. Lapata. 2008. Vector-based models of semantic composition. In Proceedings of ACL-08, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G L Murphy</author>
</authors>
<title>The Big Book of Concepts.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10065" citStr="Murphy (2002)" startWordPosition="1635" endWordPosition="1636">nsion i Here, z is a general sensitivity parameter, wi is a weight for dimension i, and ηi, ei are the values of η~ and e~ on dimension i. This model shows all the properties listed above: It has weighted dimensions through the wi. It incorporates Shepard’s law through the exponential relation between sim and the sum of squared value distances wi(ηi − ei)2. Competition between categories arises through the normalization of ~e’s similarity to C by the similarity to all other categories in Eq. (1). While featurebased models of concept representation talk about concepts rather than word meaning, Murphy (2002) argues that there is “overwhelming empirical evidence for the conceptual basis of word meaning” through experimental results on conceptual phenomena that have also been shown to hold for words. G¨ardenfors (2004) proposes a model that represents concepts as convex regions in a conceptual space. Feature structures play no central role in this model, but G¨ardenfors suggests that concepts may be represented by a central point, such that categorization could simply be determining the nearest central point (without positing an exponential relation between distance and similarity). 3 Models In thi</context>
</contexts>
<marker>Murphy, 2002</marker>
<rawString>G. L. Murphy. 2002. The Big Book of Concepts. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Nosofsky</author>
</authors>
<title>Attention, similarity, and the identification-categorization relationship.</title>
<date>1986</date>
<journal>Journal of Experimental Psychology: General,</journal>
<pages>115--39</pages>
<contexts>
<context position="2597" citStr="Nosofsky, 1986" startWordPosition="422" endWordPosition="423"> the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimension: Do values on each dimension vary a lot across occurrences of the target? Also, it does not provide information on co-occurrences of feature values in occurrences of the target. To encode these two types of information, we study richer models of word meaning in vector space beyond single point representations. Many models of categorization in psychology represent a concept as a region, characterized by feature vectors with dimension weights (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986). Taking our cue from these approaches, we study two models that represent a word as a region in vector space rather than a point. The first model is one that we have recently introduced for representing hyponymy in vector space (Erk, 2009). We now test its suitability as a general region model for word meaning. This model can be viewed as a prototypestyle model that induces a region surrounding a central vector. As it does not record co-occurrences of feature values, we contrast it with a second model, an exemplar-style model using a k-nearest neighbor analysis, which can represent both degre</context>
<context position="8367" citStr="Nosofsky, 1986" startWordPosition="1360" endWordPosition="1361">97) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986)). Features in these models are typically weighted to represent their importance to the concept in question. Similarity to a given feature vector is usually taken to decrease exponentially with distance from that vector, following Shepard’s law (Shepard, 1987). Categorization involves competition between categories. Feature-based models of human concept representation can be broadly categorized into prototype models, which represent a concept by a single summary representation, and exemplar models, which assume that categorization is by comparison to remembered exemplars. As an example of a fe</context>
</contexts>
<marker>Nosofsky, 1986</marker>
<rawString>R. M. Nosofsky. 1986. Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology: General, 115:39–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>M Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>S. Pad´o and M. Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahlgren</author>
<author>J Karlgren</author>
</authors>
<title>Automatic bilingual lexicon acquisition using random indexing of parallel corpora.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering, Special Issue on Parallel Texts,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="859" citStr="Sahlgren and Karlgren, 2005" startWordPosition="139" endWordPosition="143">g over all its corpus occurrences. Words close to this point in space can be assumed to be similar to it in meaning. But how far around this point does the region of similar meaning extend? In this paper we discuss two models that represent word meaning as regions in vector space. Both representations can be computed from traditional point representations in vector space. We find that both models perform at over 95% F-score on a token classification task. 1 Introduction Vector space models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McD</context>
<context position="5007" citStr="Sahlgren and Karlgren, 2005" startWordPosition="815" endWordPosition="819">word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensional space (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007; Jones and Mewhort, 2007). Dimensions stand for context items which which the target word has been observed to co-occur, for example other words (Lund and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1</context>
</contexts>
<marker>Sahlgren, Karlgren, 2005</marker>
<rawString>M. Sahlgren and J. Karlgren. 2005. Automatic bilingual lexicon acquisition using random indexing of parallel corpora. Journal of Natural Language Engineering, Special Issue on Parallel Texts, 11(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>H. Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Shepard</author>
</authors>
<title>Towards a universal law of generalization for psychological science.</title>
<date>1987</date>
<journal>Science,</journal>
<volume>237</volume>
<issue>4820</issue>
<contexts>
<context position="8627" citStr="Shepard, 1987" startWordPosition="1399" endWordPosition="1400">nsky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986)). Features in these models are typically weighted to represent their importance to the concept in question. Similarity to a given feature vector is usually taken to decrease exponentially with distance from that vector, following Shepard’s law (Shepard, 1987). Categorization involves competition between categories. Feature-based models of human concept representation can be broadly categorized into prototype models, which represent a concept by a single summary representation, and exemplar models, which assume that categorization is by comparison to remembered exemplars. As an example of a feature-based model of concept representation, we show the definition of Nosofsky’s (1986) Generalized Context Model (GCM). This exemplar model estimates the probability of categorizing an exemplar e~ as a member of a concept C as P(C |~e) = P~η∈C w~ηsim(~η, ~e)</context>
</contexts>
<marker>Shepard, 1987</marker>
<rawString>R. Shepard. 1987. Towards a universal law of generalization for psychological science. Science, 237(4820):1317–1323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E E Smith</author>
<author>D Osherson</author>
<author>L J Rips</author>
<author>M Keane</author>
</authors>
<title>Combining prototypes: A selective modification model.</title>
<date>1988</date>
<journal>Cognitive Science,</journal>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="2565" citStr="Smith et al., 1988" startWordPosition="416" endWordPosition="419">tation will constitute a union over the uses or senses of the word. Such a model does not provide information on the amount of variance in each dimension: Do values on each dimension vary a lot across occurrences of the target? Also, it does not provide information on co-occurrences of feature values in occurrences of the target. To encode these two types of information, we study richer models of word meaning in vector space beyond single point representations. Many models of categorization in psychology represent a concept as a region, characterized by feature vectors with dimension weights (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986). Taking our cue from these approaches, we study two models that represent a word as a region in vector space rather than a point. The first model is one that we have recently introduced for representing hyponymy in vector space (Erk, 2009). We now test its suitability as a general region model for word meaning. This model can be viewed as a prototypestyle model that induces a region surrounding a central vector. As it does not record co-occurrences of feature values, we contrast it with a second model, an exemplar-style model using a k-nearest neighbor analysis</context>
<context position="8335" citStr="Smith et al., 1988" startWordPosition="1354" endWordPosition="1357">and Dumais (Landauer and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986)). Features in these models are typically weighted to represent their importance to the concept in question. Similarity to a given feature vector is usually taken to decrease exponentially with distance from that vector, following Shepard’s law (Shepard, 1987). Categorization involves competition between categories. Feature-based models of human concept representation can be broadly categorized into prototype models, which represent a concept by a single summary representation, and exemplar models, which assume that categorization is by comparison to remembered </context>
</contexts>
<marker>Smith, Osherson, Rips, Keane, 1988</marker>
<rawString>E. E. Smith, D. Osherson, L. J. Rips, and M. Keane. 1988. Combining prototypes: A selective modification model. Cognitive Science, 12(4):485–527.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Smolensky</author>
</authors>
<title>Tensor product variable binding and the representation of symbolic structures in connectionist systems.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<pages>46--159</pages>
<contexts>
<context position="8024" citStr="Smolensky (1990)" startWordPosition="1309" endWordPosition="1310">ere are several approaches to computing vectors for individual word tokens. All of them compute word type vectors first, then combine them into token vectors. Kintsch (2001) and Mitchell and Lapata (2008) combine the target’s type vector with that of a single word in the target’s syntactic context. Landauer and Dumais (Landauer and Dumais, 1997) and Sch¨utze (1998) combine the type vectors of all the words surrounding the target token. Erk and Pad´o (2008) combine the target’s type vector with a vector representing the selectional preference of a single word in the target’s syntactic context. Smolensky (1990) focuses on integrating syntactic information in the vector representation rather than 58 on representing the lexical meaning of the target. Feature-based models of human concept representation. Many models of human concept representation in psychology are based on vectors of features (e.g. (Smith et al., 1988; Hampton, 1991; Nosofsky, 1986)). Features in these models are typically weighted to represent their importance to the concept in question. Similarity to a given feature vector is usually taken to decrease exponentially with distance from that vector, following Shepard’s law (Shepard, 19</context>
</contexts>
<marker>Smolensky, 1990</marker>
<rawString>P. Smolensky. 1990. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial Intelligence, 46:159–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL’06.</booktitle>
<contexts>
<context position="1351" citStr="Snow et al., 2006" startWordPosition="220" endWordPosition="223">meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997; Lowe, 2001; Jones and Mewhort, 2007; Sahlgren and Karlgren, 2005) represent words as points in a highdimensional semantic space. The dimensions of the space represent the contexts in which each target word has been observed. Distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, as words with similar meaning tend to occur in similar contexts. Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Sch¨utze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). Given the known problems with defining globally appropriate senses (Kilgarriff, 1997; Hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses. Vector space models typically compute one vector per target word (what we will call word type vectors), summing co-occurrence counts over all corpus tokens of the target. If the target word is polysemous, the representati</context>
<context position="5796" citStr="Snow et al., 2006" startWordPosition="943" endWordPosition="946">und and Burgess, 1996) or syntactic paths (Pad´o and Lapata, 2007). In the simplest case, the value on a dimension is the raw co-occurrence count between the target word and the context item for which the dimension stands. Raw counts are often transformed, for example using a log-likelihood transformation (Lowe, 2001). Sometimes the vector space as a whole is transformed using dimensionality reduction (Landauer and Dumais, 1997). In NLP, vector space models have featured most prominently in information retrieval (Manning et al., 2008), but have also been used for ontology learning (Lin, 1998; Snow et al., 2006; Gorman and Curran, 2006) and word sense-related tasks (McCarthy et al., 2004; Sch¨utze, 1998). In psychology, vector space models have been used to model synonymy (Landauer and Dumais, 1997; Pad´o and Lapata, 2007), lexical priming phenomena (Lowe and McDonald, 2000), and similarity judgments (McDonald and Ramscar, 2001). There have also been studies on inducing hyponymy information from vector space representations. Geffet and Dagan (2005) use a dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand in a subset relation. However, t</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>R. Snow, D. Jurafsky, and A. Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of COLING/ACL’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Szpektor</author>
<author>I Dagan</author>
<author>R Bar-Haim</author>
<author>J Goldberger</author>
</authors>
<title>Contextual preferences.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08,</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="4317" citStr="Szpektor et al., 2008" startWordPosition="706" endWordPosition="709">t in vector space, the task is predict the word of which it is a token vector. By representing the meaning of words as regions in vector space, we can describe areas in which points encode similar meanings. This description is flexible, depending on the target word in question, rather than uniform for all words through a fixed distance threshold from the target’s type vector. One possible application of region models of word meaning is in the task of determining the appropriateness of a paraphrase in a given context (Connor and Roth, 2007). This task is highly relevant for textual entailment (Szpektor et al., 2008). Current vector space approaches typically compare the target word’s token vector to the type vector of the potential paraphrase (Mitchell and Lapata, 2008; Erk and Pado, 2008). A region model could instead test the target’s token vector for inclusion in the potential paraphrase’s region. 2 Related work This section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology. Vector space models. Vector space models represent the meaning of a target word as a vector in a high-dimensi</context>
<context position="32451" citStr="Szpektor et al., 2008" startWordPosition="5487" endWordPosition="5490">n, dimensionality reduction uses type vectors while the 7The near-perfect performance in particular of the distributed model has been confirmed on a separate noun dataset. distributed model stores token vectors, which can show more variance than the type vectors alone. Applications of region models. Region models of word meaning are interesting for the task of testing the appropriateness of paraphrases in context. Previous models either used competition between paraphrase candidates or a global similarity threshold to decide whether to accept a paraphrase candidate (Mitchell and Lapata, 2008; Szpektor et al., 2008). A region model of word meaning used for the same task would still require a threshold, in this case a threshold on membership probability, but the regions for which membership is tested could differ in their size, and the extent of each region would be learned individually from the data. To use the model, for example to test whether trickle is a good paraphrase for run in the color ran, we would test whether the sentence-specific token vector for run falls into the region of trickle. 6 Conclusion and outlook In this paper, we have proposed using region models for word meaning in vector space</context>
</contexts>
<marker>Szpektor, Dagan, Bar-Haim, Goldberger, 2008</marker>
<rawString>I. Szpektor, I. Dagan, R. Bar-Haim, and J. Goldberger. 2008. Contextual preferences. In Proceedings of ACL-08, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weeds</author>
<author>D Weir</author>
<author>D McCarthy</author>
</authors>
<title>Characterising measures of lexical distributional similarity.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-04,</booktitle>
<location>Geneva, Switzerland.</location>
<marker>Weeds, Weir, McCarthy, 2004</marker>
<rawString>J. Weeds, D. Weir, and D. McCarthy. 2004. Characterising measures of lexical distributional similarity. In Proceedings of COLING-04, Geneva, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>