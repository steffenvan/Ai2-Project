<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.079764">
<title confidence="0.994068">
ICRC-HIT: A Deep Learning based Comment Sequence Labeling
System for Answer Selection Challenge
</title>
<author confidence="0.997459">
Xiaoqiang Zhou Baotian Hu Jiaxin Lin Yang Xiang Xiaolong Wang
</author>
<affiliation confidence="0.999361666666667">
Intelligence Computing Research Center
Department of Computer Science &amp;Technology
Harbin Institute of Technology, Shenzhen Graduate School
</affiliation>
<email confidence="0.95342">
{xiaoqiang.jeseph,baotianchina,dongshanjx,xiangyang.hitsz}@gmail.com
wangxl@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.998486" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999547444444445">
In this paper, we present a comment labeling
system based on a deep learning strategy. We
treat the answer selection task as a sequence
labeling problem and propose recurrent
convolution neural networks to recognize
good comments. In the recurrent architecture
of our system, our approach uses
2-dimensional convolutional neural networks
to learn the distributed representation for
question-comment pair, and assigns the labels
to the comment sequence with a recurrent
neural network over CNN. Compared with
the conditional random fields based method,
our approach performs better performance on
Macro-F1 (53.82%), and achieves the highest
accuracy (73.18%), F1-value (79.76%) on
predicting the Good class in this answer
selection challenge.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999986880000001">
The community question answering site or system
(CQA) is one kind of common platforms where
people can freely ask questions, deliver comments
and participate in discussions. The high-quality
comments given a question are the important
resources to generate useful question-answer pairs,
which are of great value for knowledge base
construction and information retrieval (IR).
However, due to the unrestricted expressions in
CQA, it still one problem to recognize the
high-quality comments from the open domain data,
which are involve in a large of noise information.
Nevertheless, the semantic relevance between
question and comment makes sense to predict the
quality of comment by modeling the semantic
matching for question-comment pair.
Prior work on predicting the class of comment
(or answer) mainly attempted to measure the
semantic similarity between question and
comment with typical classification approaches,
such as LR and SVM. To achieve the semantic
relevance matching for question-comment pair, a
large number of works focus on constructing
feature-engineering to extract the features of
question and comment as the input of models.
Beyond typical textual feature, some works
integrate the structural information (Wang et al.,
2009; Huang et al., 2007) into the discrete
representations of question-comment pairs to
improve the performances of comment classifiers.
Another option is extracting user metadata (Chen
and Nayak, 2008; Shah and Pomerantz, 2010)
from the question answering portal for enriching
the feature-engineering. Empirically the
approaches above have been shown to improve
performances on recognizing positive answers, but
they rely on large numbers of hand-crafted
features, and require various external resources
which may be difficult to obtain. Furthermore,
they suffer from the limitation of requiring
task-specific feature extraction for new domain.
Recently the works about neural network-based
distributed sentence models (Socher et al., 2012;
Kalchbrenner et al., 2014) have achieved
successes in natural language processing (NLP).
As a consequence of this success, it appears
natural to attempt to solve question answering
using similar techniques. To recognize the
high-quality answers, Hu et al. (2013) learned the
joint representation for each question-answer pair
</bodyText>
<page confidence="0.982301">
210
</page>
<note confidence="0.750671">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 210‚Äì214,
Denver, Colorado, June 4-5, 2015. cÔøΩ2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999882">
Figure 1. The architecture of comment labeling system based on deep learning
</figureCaption>
<bodyText confidence="0.999940823529412">
by taking both of the textual and non-textual
features as the input of multi-DBN model. To
achieve the answer sentence selection, Yu et al.
(2014) proposed convolution neural networks
based models to represent the question and answer
sentences. For the semantic matching between
question and answer, the methods based on deep
learning generally exploit to learn the distributed
representation of question-answer pair as the input.
Instead of extracting a variety of features, these
approaches learn the semantic features to
represent question and answer. However, these
approaches only focus on modeling the semantic
relevance between question and answer, ignoring
the semantic correlations in answer sequence.
In this work, we present a novel comment
labeling system based on deep learning. We
propose the recurrent convolutional neural
networks (R&amp;CNN) approach to assign the labels
to comments given a question. Based on the
distributed representations learned form
2-dimensional CNN (2D-CNN) matching, our
approach achieves to comment sequence learning
and predict the classes of comments. Using the
word embedding trained by provided Qatar Living
data, R&amp;CNN not only models the semantic
relevance for question and comment, but also
captures the correlative context in comment
sequence for predicting the class of comment. The
experimental results show that our system
performs better performances than the CRF based
method (Ding et al., 2008) on recognizing good
comments, and performs more adaptive on the
development and test dataset.
</bodyText>
<sectionHeader confidence="0.983255" genericHeader="introduction">
2 System Description
</sectionHeader>
<bodyText confidence="0.999987333333333">
The architecture of our comment labeling system
is a recurrent architecture (shown in Figure 1)
with a recurrent neural network over the
convolutional neural networks. Given a question,
our approach achieves to learn the semantic
relevance between question and comment by
2D-CNN matching and generate the distributed
representation of each question-comment pair.
After that, our approach uses the RNN to model
the semantic correlations in comment sequence,
and makes the quality predictions for the comment
sequence with the captured context.
</bodyText>
<subsectionHeader confidence="0.995171">
2.1 Convolutional Neural Networks for
question-comment matching
</subsectionHeader>
<bodyText confidence="0.999782714285714">
Convolutional neural networks are a natural
extension of neural networks for treating image.
Hu et al. (2014) proposed the 2D-CNN model to
do semantic matching between two sentences. In
our work, we use 2D-CNN to learn the distributed
representations for question-comment pairs.
Unlike 1D-CNN, executing the interaction
between question and answer in final multi-layer
perception (MLP) with their individual
representations, 2D-CNN maps question and
comment into a common space for learning the
representation of question-comment pair and
captures the rich matching patterns between
question and answer by layer-by-layer convolution
and pooling.
The first layer is 1D-convolution layer, whose
role is converting word embedding of question
and comment into one common space with the
sliding window, whose size k is (3 √ó 3). For the
word i on question ùëû and word j on comment ùëê,
1D-convolution can formulated as:
</bodyText>
<equation confidence="0.92689025">
ùëá ]
ùëßÃÇùëñ,ùëó
(0) = [ùëûùëñ:ùëñ+ùëò‚àí1
ùëá ,ùëêùëñ:ùëñ+ùëò‚àí1
</equation>
<bodyText confidence="0.994496">
where ùëßÃÇùëñ,ùëó
</bodyText>
<listItem confidence="0.733488">
(0) simply concatenates the vectors of
sentence segments in question ùëû and comment ùëê;
(1)
</listItem>
<page confidence="0.987263">
211
</page>
<bodyText confidence="0.999817166666667">
The 1D-convolution converts the concatenated
matrix H0 of question and comment into the
real-value matrix H1 . After that, 2D-CNN
executes deep 2D-convolution and pooling,
similar to that of traditional image input. The
output of the m`h hidden layer is computed as:
</bodyText>
<equation confidence="0.996717">
Hm = u(pùëúùëúI(wmHm‚àí1 + bm)) (2)
</equation>
<bodyText confidence="0.999149666666666">
Here, wm is the parameter matrix for the feature
maps on m`h hidden layer and bm is the bias
vector. u(. ) is the sigmoid activation function.
The final distributed representation pùë° of
question-comment pair learned from 2D-CNN
represents the semantic relevance between
question and comment, and provides the reliable
evidences to make a quality prediction for the
corresponding comment.
</bodyText>
<subsectionHeader confidence="0.964038">
2.2 Recurrent Neural Network for comment
sequence labeling
</subsectionHeader>
<bodyText confidence="0.999973636363637">
Recurrent neural network is a straightforward
adaptation of the standard feed-forward neural
network (Bengio et al., 2012) to allow it to model
sequential data. The recurrent neural network in
our work has one input layer X, one hidden layer
H for updating the hidden state, and the output
layer Y. For the time step t, the input to RNN
includes the learned representation p(t) and the
previous hidden state ‚Ñé(t ‚àí 1) . The output is
denoted as ùë¶(t). The output of input, hidden and
output layers are computed as:
</bodyText>
<equation confidence="0.999962333333333">
x(t) = wùëñp(t) + w‚Ñé‚Ñé(t ‚àí 1) + b‚Ñé
‚Ñé(t) = u(x(t))
ùë¶(t) = g(wùë¶‚Ñé(t) + bùë¶)
</equation>
<bodyText confidence="0.9933036">
where wùëñ is the matrix of connection between
CNN and the input layer of RNN; w‚Ñé plays role
in updating network state or context; and wùë¶ is
the matrix of connection between hidden layer
and output layer. Both of b‚Ñé and bùë¶ are bias
vectors. Here, u(. ) is the sigmoid activation
function; g (. ) is the softmax function. x (t) is
the joint representation of current pair and
context. Our approach is able to capture the
context by updating the hidden state ‚Ñé(t).
To train the networks proposed here, we use the
backpropagation through time with stochastic
gradient descent (SGD) algorithm. At each
training step, error vector is computed according
to cross entropy criterion, weights are updated as:
</bodyText>
<equation confidence="0.999445">
Errùëúr (t; 0) = R(t) ‚àí ùë¶(t) (6)
</equation>
<bodyText confidence="0.76869">
where ùë¶(t) is the result from our system, and
R (t) is the true class; and 0 includes all the
parameters of CNN and RNN.
</bodyText>
<sectionHeader confidence="0.999764" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.984022">
3.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999534142857143">
We evaluate our approach (R&amp;CNN) on both the
development and test data of this answer selection
challenge. The statistics of experimental dataset
are summarized in Table 1. In this dataset, there
are 3,229 questions and 21,062 answers, and the
percentage of good comments is about 50%. The
average length of comment sequence is 6.
</bodyText>
<table confidence="0.8810205">
data #question #comment #average % good
Train 2600 16541 6.36 48.78
Devel 300 1645 5.48 53.19
Test 329 1976 6.00 50.46
</table>
<tableCaption confidence="0.998799">
Table 1. Statistics of experimental dataset
</tableCaption>
<bodyText confidence="0.999925842105263">
In our approach, we use 100-dimensional word
embedding trained on the provided Qatar Living
data with Word2vec (Mikolov et al., 2013). The
maximum size of coding the sentences with word
embedding is set to be 100, and we use 3-words
sliding window for 1D-convolution. The learning
rate is initialized to be 0.01 and adapted
dynamically using ADADELTA Method (Matthew,
2012). Based on the results on development set,
all the hyperparameters of our approach are
optimized on train set.
Table 2 lists the experimental methods and the
corresponding official results. The baselines of
comment sequence labeling include the method
based on CRF and the approach CRF+V, which
integrates distributed representation learnt from
our approach (R&amp;CNN). In addition, we illustrate
the best result achieved by the supervised
feature-rich approach SFR1.
</bodyText>
<sectionHeader confidence="0.852238" genericHeader="method">
Results Methods
ICRC-HIT-primary CRF+V
ICRC-HIT-contrastive1 R&amp;CNN
ICRC-HIT-contrastive2 CRF
JAIST-contrasive1 SFR
</sectionHeader>
<tableCaption confidence="0.997991">
Table 2. The official results and experimental methods
</tableCaption>
<footnote confidence="0.991618">
1It is the approach of JAIST team in subtask-A English.
</footnote>
<page confidence="0.99584">
212
</page>
<subsectionHeader confidence="0.963531">
3.2 Results and analysis
</subsectionHeader>
<bodyText confidence="0.99468325">
Table 3 and Table 4 illustrate the results in
development and test dataset respectively. As can
be seen, our proposed R&amp;CNN outperforms CRF
and CRF+V on whole performances. Specifically,
R&amp;CNN achieves the state-of-the-art with the
accuracy 73.18%, and 79.76% in F1-value of
predicting Good class while performs 53.82% in
Macro-F1 on the test dataset.
</bodyText>
<table confidence="0.99531725">
Methods Macro. Acc. P R F1
CRF 50.56 59.82 72.41 77.37 74.81
CRF+V 52.14 61.03 74.80 76.00 75.40
R&amp;CII 52.10 60.85 75.09 75.09 75.09
</table>
<tableCaption confidence="0.99698">
Table 3. Performances on development dataset (%)
</tableCaption>
<table confidence="0.9986572">
Methods Macro. Acc. P R F1
CRF 40.54 60.12 57.90 95.89 72.21
CRF+V 49.50 67.86 65.99 91.68 76.74
R&amp;CII 53.82 73.18 74.39 85.96 79.76
SFR 57.29 72.67 80.51 78.03 79.11
</table>
<tableCaption confidence="0.999836">
Table 4. Performances on test dataset (%)
</tableCaption>
<bodyText confidence="0.999724189655173">
Compared to CRF and CRF+V, our approach
outperforms them in evolution metrics. There are
several reasons for the unsatisfying performances
of CRF and CRF+V. First, it is sparse to extract
semantic features of question-comment pairs from
short contents in baselines. In contrast, the
distributed representation learned from our model
is able to capture semantic relationship between
words of question-comment pairs based on deep
convolution and pooling. Secondly, there are large
amount of noise information involved in CQA,
such as various emotional symbols and the
abbreviated words. The feature-engineering of
CRF based method generally suffers from the
quality of dataset. Besides of that, the divergences
of class distribution between the development and
test influence the effectiveness directly. Hence,
our approach performs more powerful and
adaptive to different dataset or new domain. We
also can demonstrate this point by comparing the
experimental results of CRF and CRF+V on the
test (shown in Table 4). By integrating the
distributed representation from our R&amp;CNN,
CRF+V improves 9% on Macro-F1, 7.74% on
accuracy over CRF, and 4.53% in F1-value of
predicting Good class.
Taking only word embedding as the original
features, our approach has achieved 53.82% in
Macro-F1. In contrast, the supervised feature-rich
(SFR) approach performs 57.29% in Macro-F1 by
integrating multi-type features, such as word
embedding, features from topic models and user
metadata etc. The main reason for that is the low
performance of our approach on predicting the
answers of Potential class, which has a major
import on Macro-F1 due to the effect of
marcoaveraging. There are several factors for that
result. The first is the imbalance distribution in
training data, which is lacking of the train samples
of Potential class. So the distributed models based
purely on word embedding are not very well
equipped to learn the meaningful representations
for question and potential comments. Secondly,
Potential class is an intermediate category
(M√†rquez et al., 2015) that was quite hard to
human annotators. Hence, surface-form matching
between the words of question-comment pair is
hard to identify its correct class merely using word
embedding.
In addition, when considering the heavy
reliance of feature-engineer of SFR in comparison
to the simplicity of our approach, the Macro-F1
our approach obtained is highly encouraging.
What‚Äôs more, our model achieves the
start-of-the-art in accuracy and F1-value of Good
class. These promising results indicate the
effectiveness of our approach in predicting the
high-quality comments in CQA.
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999816666666667">
In this paper, we present a comment labeling
system based on the deep learning architecture.
Without the complicated feature-engineering and
external semantic resources, the recurrent
convolutional neural networks (R&amp;CNN)
approach proposed by us not only is able to
capture semantic matching patterns between
question and comments, but also learn the
meaningful context in the comment sequence. In
this answer selection task, our approach achieves
the state-of-the-art on recognizing good comments,
and performs better accuracy than baselines while
obtains powerful results in Macro-F1.
In the future, we would like to investigate the
methods of training the imbalance data (e.g. the
Potential class) to improve the performances of
our approach, such as the typical oversampling
and undersampling methods.
</bodyText>
<page confidence="0.998809">
213
</page>
<sectionHeader confidence="0.999214" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9979076">
This work was supported in part by the National N
atural Science Foundation of China (61272383, 61
173075 and 61203378), the Strategic Emerging In
dustry Development Special Funds of Shenzhen (J
CYJ20120613151940045).
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999887973333334">
Baotian Hu, Zhengdong Lu, Hang Li, Qingcai Chen.
2014. Convolutional neural network architectures
for matching natural language sentences. In
Proceedings of Neural Information Processing
Systems (NIPS), Montreal, Quebec, Canada. 2014.
Baoxun Wang, Bingquan Liu, Chengjie Sun, Xiaolong
Wang, and Lin Sun. 2009. Extracting Chinese
Question-Answer Pairs from Online Forums. IEEE
International Conference on Systems, Man, and
Cybernetics (SMC), pages 1159-1164. 2009.
Haifeng Hu, Bingquan Liu, Baoxun Wang, Ming Liu,
Xiaolong Wang. 2013. Multimodal DBN for
predicting high-quality answers in cQA portals. In
Proceedings of Association for Computational
Linguistics (ACL), pages 843‚Äì847, Sofia, Bulgaria.
2013.
Jizhou Huang, Ming Zhou, and Dan Yang. 2007.
Extracting chatbot knowledge from online
discussion forums. In Proceedings of International
Joint Conference on Artificial Intelligence (IJCAI),
pages 423‚Äì428, Hyderabad, India. 2007.
Lei Yu, Karl Moritz Hermann, Phil Blunsom, Stephen
Pulman. 2014. Deep learning for answer sentence
selection. In Proceeding of Neural Information
Processing Systems (NIPS): Deep Learning and
Representation Learning Workshop, Montreal,
Quebec, Canada. 2014.
Lin Chen, Richi Nayak. 2008. Expertise Analysis in a
Question Answer Portal for Author Ranking.
IEEE/WIC/ACM International Conference on Web
Intelligence and Intelligent Agent Technology
(WI-IAT), pages 134-140. 2008.
Llu√≠s M√†rquez, James Glass, Walid Magdy, Alessandro
Moschitti, Preslav Nakov, and Bilal Randeree. 2015.
SemEval-2015 Task 3: Answer Selection in
Community Question Answering. In Proceedings of
the 9th International Workshop on Semantic
Evaluation (SemEval-2015). 2015
Matthew D. Zeiler. 2012. ADADELTA: An Adaptive
Learning Rate Method. CoRR abs/1212.5701. 2012
Nai Kalchbrenner, Edward Grefenstette, and Phil
Blunsom. A convolutional neural network for
modelling sentences. In Proceedings of the
Association for Computational Linguistics (ACL),
pages 655-665, Baltimore, USA. 2014.
Richard Socher, Brody Huval, Christopher D. Manning,
and Andrew Y. Ng. 2012. Semantic
compositionality through recursive matrix-vector
spaces. In Proceedings of Empirical Methods on
Natural Language Processing and Computational
Natural Language Learning (EMNLP), pages
1201-1211, Jeju Island, Korea. 2012.
Chirag Shah and Jefferey Pomerantz. 2010. Evaluating
and predicting answer quality in community QA. In
the 33rd International Conference on Research and
development information retrieval on Research and
Development in Information Retrieval (SIGIR‚Äô10),
pages 411-418, NewYork, USA. 2010.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan
Zhu. 2008. Using conditional random fields to
extract contexts and answers of questions from
online forums. In Proceedings of Association for
Computational Linguistics (ACL), pages 710-718,
Columbus, Ohis, USA. 2008.
Tom Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word
representations in vector space. CoRR,
abs/1301.3781. 2013
Nicolas Boulanger-Lewandowski, Yoshua Bengio, and
Pascal Vincent. 2012. Modeling temporal
dependencies in high-dimensional sequences:
Application to polyphonic music generation and
transcription. In Proceedings of the 29th
International Conference on Machine Learning
(ICML), Edinburgh, Scotland, UK. 2012.
</reference>
<page confidence="0.998954">
214
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.848748">
<title confidence="0.9977055">ICRC-HIT: A Deep Learning based Comment Sequence System for Answer Selection Challenge</title>
<author confidence="0.941362">Xiaoqiang Zhou Baotian Hu Jiaxin Lin Yang Xiang Xiaolong</author>
<affiliation confidence="0.991908666666667">Intelligence Computing Research Department of Computer Science Harbin Institute of Technology, Shenzhen Graduate</affiliation>
<email confidence="0.931897">wangxl@insun.hit.edu.cn</email>
<abstract confidence="0.998905789473684">In this paper, we present a comment labeling system based on a deep learning strategy. We treat the answer selection task as a sequence labeling problem and propose recurrent convolution neural networks to recognize good comments. In the recurrent architecture of our system, our approach uses 2-dimensional convolutional neural networks to learn the distributed representation for question-comment pair, and assigns the labels to the comment sequence with a recurrent neural network over CNN. Compared with the conditional random fields based method, our approach performs better performance on Macro-F1 (53.82%), and achieves the highest accuracy (73.18%), F1-value (79.76%) on the in this answer selection challenge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Baotian Hu</author>
<author>Zhengdong Lu</author>
<author>Hang Li</author>
<author>Qingcai Chen</author>
</authors>
<title>Convolutional neural network architectures for matching natural language sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of Neural Information Processing Systems (NIPS),</booktitle>
<location>Montreal, Quebec,</location>
<contexts>
<context position="6010" citStr="Hu et al. (2014)" startWordPosition="852" endWordPosition="855"> a recurrent neural network over the convolutional neural networks. Given a question, our approach achieves to learn the semantic relevance between question and comment by 2D-CNN matching and generate the distributed representation of each question-comment pair. After that, our approach uses the RNN to model the semantic correlations in comment sequence, and makes the quality predictions for the comment sequence with the captured context. 2.1 Convolutional Neural Networks for question-comment matching Convolutional neural networks are a natural extension of neural networks for treating image. Hu et al. (2014) proposed the 2D-CNN model to do semantic matching between two sentences. In our work, we use 2D-CNN to learn the distributed representations for question-comment pairs. Unlike 1D-CNN, executing the interaction between question and answer in final multi-layer perception (MLP) with their individual representations, 2D-CNN maps question and comment into a common space for learning the representation of question-comment pair and captures the rich matching patterns between question and answer by layer-by-layer convolution and pooling. The first layer is 1D-convolution layer, whose role is converti</context>
</contexts>
<marker>Hu, Lu, Li, Chen, 2014</marker>
<rawString>Baotian Hu, Zhengdong Lu, Hang Li, Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. In Proceedings of Neural Information Processing Systems (NIPS), Montreal, Quebec, Canada. 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baoxun Wang</author>
<author>Bingquan Liu</author>
<author>Chengjie Sun</author>
<author>Xiaolong Wang</author>
<author>Lin Sun</author>
</authors>
<title>Extracting Chinese Question-Answer Pairs from Online Forums.</title>
<date>2009</date>
<booktitle>IEEE International Conference on Systems, Man, and Cybernetics (SMC),</booktitle>
<pages>1159--1164</pages>
<contexts>
<context position="2401" citStr="Wang et al., 2009" startWordPosition="331" endWordPosition="334">ment makes sense to predict the quality of comment by modeling the semantic matching for question-comment pair. Prior work on predicting the class of comment (or answer) mainly attempted to measure the semantic similarity between question and comment with typical classification approaches, such as LR and SVM. To achieve the semantic relevance matching for question-comment pair, a large number of works focus on constructing feature-engineering to extract the features of question and comment as the input of models. Beyond typical textual feature, some works integrate the structural information (Wang et al., 2009; Huang et al., 2007) into the discrete representations of question-comment pairs to improve the performances of comment classifiers. Another option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-s</context>
</contexts>
<marker>Wang, Liu, Sun, Wang, Sun, 2009</marker>
<rawString>Baoxun Wang, Bingquan Liu, Chengjie Sun, Xiaolong Wang, and Lin Sun. 2009. Extracting Chinese Question-Answer Pairs from Online Forums. IEEE International Conference on Systems, Man, and Cybernetics (SMC), pages 1159-1164. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haifeng Hu</author>
<author>Bingquan Liu</author>
<author>Baoxun Wang</author>
<author>Ming Liu</author>
<author>Xiaolong Wang</author>
</authors>
<title>Multimodal DBN for predicting high-quality answers in cQA portals.</title>
<date>2013</date>
<booktitle>In Proceedings of Association for Computational Linguistics (ACL),</booktitle>
<pages>843--847</pages>
<location>Sofia,</location>
<contexts>
<context position="3402" citStr="Hu et al. (2013)" startWordPosition="472" endWordPosition="475">ng positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extraction for new domain. Recently the works about neural network-based distributed sentence models (Socher et al., 2012; Kalchbrenner et al., 2014) have achieved successes in natural language processing (NLP). As a consequence of this success, it appears natural to attempt to solve question answering using similar techniques. To recognize the high-quality answers, Hu et al. (2013) learned the joint representation for each question-answer pair 210 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 210‚Äì214, Denver, Colorado, June 4-5, 2015. cÔøΩ2015 Association for Computational Linguistics Figure 1. The architecture of comment labeling system based on deep learning by taking both of the textual and non-textual features as the input of multi-DBN model. To achieve the answer sentence selection, Yu et al. (2014) proposed convolution neural networks based models to represent the question and answer sentences. For the semantic matching b</context>
</contexts>
<marker>Hu, Liu, Wang, Liu, Wang, 2013</marker>
<rawString>Haifeng Hu, Bingquan Liu, Baoxun Wang, Ming Liu, Xiaolong Wang. 2013. Multimodal DBN for predicting high-quality answers in cQA portals. In Proceedings of Association for Computational Linguistics (ACL), pages 843‚Äì847, Sofia, Bulgaria. 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jizhou Huang</author>
<author>Ming Zhou</author>
<author>Dan Yang</author>
</authors>
<title>Extracting chatbot knowledge from online discussion forums.</title>
<date>2007</date>
<booktitle>In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>423--428</pages>
<location>Hyderabad,</location>
<contexts>
<context position="2422" citStr="Huang et al., 2007" startWordPosition="335" endWordPosition="338"> predict the quality of comment by modeling the semantic matching for question-comment pair. Prior work on predicting the class of comment (or answer) mainly attempted to measure the semantic similarity between question and comment with typical classification approaches, such as LR and SVM. To achieve the semantic relevance matching for question-comment pair, a large number of works focus on constructing feature-engineering to extract the features of question and comment as the input of models. Beyond typical textual feature, some works integrate the structural information (Wang et al., 2009; Huang et al., 2007) into the discrete representations of question-comment pairs to improve the performances of comment classifiers. Another option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extra</context>
</contexts>
<marker>Huang, Zhou, Yang, 2007</marker>
<rawString>Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Extracting chatbot knowledge from online discussion forums. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pages 423‚Äì428, Hyderabad, India. 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Yu</author>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
<author>Stephen Pulman</author>
</authors>
<title>Deep learning for answer sentence selection.</title>
<date>2014</date>
<booktitle>In Proceeding of Neural Information Processing Systems (NIPS): Deep Learning and Representation Learning Workshop,</booktitle>
<location>Montreal, Quebec,</location>
<contexts>
<context position="3876" citStr="Yu et al. (2014)" startWordPosition="541" endWordPosition="544">s, it appears natural to attempt to solve question answering using similar techniques. To recognize the high-quality answers, Hu et al. (2013) learned the joint representation for each question-answer pair 210 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 210‚Äì214, Denver, Colorado, June 4-5, 2015. cÔøΩ2015 Association for Computational Linguistics Figure 1. The architecture of comment labeling system based on deep learning by taking both of the textual and non-textual features as the input of multi-DBN model. To achieve the answer sentence selection, Yu et al. (2014) proposed convolution neural networks based models to represent the question and answer sentences. For the semantic matching between question and answer, the methods based on deep learning generally exploit to learn the distributed representation of question-answer pair as the input. Instead of extracting a variety of features, these approaches learn the semantic features to represent question and answer. However, these approaches only focus on modeling the semantic relevance between question and answer, ignoring the semantic correlations in answer sequence. In this work, we present a novel co</context>
</contexts>
<marker>Yu, Hermann, Blunsom, Pulman, 2014</marker>
<rawString>Lei Yu, Karl Moritz Hermann, Phil Blunsom, Stephen Pulman. 2014. Deep learning for answer sentence selection. In Proceeding of Neural Information Processing Systems (NIPS): Deep Learning and Representation Learning Workshop, Montreal, Quebec, Canada. 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Chen</author>
<author>Richi Nayak</author>
</authors>
<title>Expertise Analysis in a Question Answer Portal for Author Ranking.</title>
<date>2008</date>
<booktitle>IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),</booktitle>
<pages>134--140</pages>
<contexts>
<context position="2599" citStr="Chen and Nayak, 2008" startWordPosition="359" endWordPosition="362">re the semantic similarity between question and comment with typical classification approaches, such as LR and SVM. To achieve the semantic relevance matching for question-comment pair, a large number of works focus on constructing feature-engineering to extract the features of question and comment as the input of models. Beyond typical textual feature, some works integrate the structural information (Wang et al., 2009; Huang et al., 2007) into the discrete representations of question-comment pairs to improve the performances of comment classifiers. Another option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extraction for new domain. Recently the works about neural network-based distributed sentence models (Socher et al., 2012; Kalchbrenner et al., 2014) have achieved successes in natur</context>
</contexts>
<marker>Chen, Nayak, 2008</marker>
<rawString>Lin Chen, Richi Nayak. 2008. Expertise Analysis in a Question Answer Portal for Author Ranking. IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), pages 134-140. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu√≠s M√†rquez</author>
<author>James Glass</author>
<author>Walid Magdy</author>
<author>Alessandro Moschitti</author>
<author>Preslav Nakov</author>
<author>Bilal Randeree</author>
</authors>
<date>2015</date>
<booktitle>SemEval-2015 Task 3: Answer Selection in Community Question Answering. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015).</booktitle>
<contexts>
<context position="13557" citStr="M√†rquez et al., 2015" startWordPosition="2058" endWordPosition="2061">from topic models and user metadata etc. The main reason for that is the low performance of our approach on predicting the answers of Potential class, which has a major import on Macro-F1 due to the effect of marcoaveraging. There are several factors for that result. The first is the imbalance distribution in training data, which is lacking of the train samples of Potential class. So the distributed models based purely on word embedding are not very well equipped to learn the meaningful representations for question and potential comments. Secondly, Potential class is an intermediate category (M√†rquez et al., 2015) that was quite hard to human annotators. Hence, surface-form matching between the words of question-comment pair is hard to identify its correct class merely using word embedding. In addition, when considering the heavy reliance of feature-engineer of SFR in comparison to the simplicity of our approach, the Macro-F1 our approach obtained is highly encouraging. What‚Äôs more, our model achieves the start-of-the-art in accuracy and F1-value of Good class. These promising results indicate the effectiveness of our approach in predicting the high-quality comments in CQA. 4 Conclusion In this paper, </context>
</contexts>
<marker>M√†rquez, Glass, Magdy, Moschitti, Nakov, Randeree, 2015</marker>
<rawString>Llu√≠s M√†rquez, James Glass, Walid Magdy, Alessandro Moschitti, Preslav Nakov, and Bilal Randeree. 2015. SemEval-2015 Task 3: Answer Selection in Community Question Answering. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015). 2015</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Zeiler</author>
</authors>
<title>ADADELTA: An Adaptive Learning Rate Method. CoRR abs/1212.5701.</title>
<date>2012</date>
<marker>Zeiler, 2012</marker>
<rawString>Matthew D. Zeiler. 2012. ADADELTA: An Adaptive Learning Rate Method. CoRR abs/1212.5701. 2012</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nai Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural network for modelling sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>655--665</pages>
<location>Baltimore, USA.</location>
<contexts>
<context position="3166" citStr="Kalchbrenner et al., 2014" startWordPosition="437" endWordPosition="440">er option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extraction for new domain. Recently the works about neural network-based distributed sentence models (Socher et al., 2012; Kalchbrenner et al., 2014) have achieved successes in natural language processing (NLP). As a consequence of this success, it appears natural to attempt to solve question answering using similar techniques. To recognize the high-quality answers, Hu et al. (2013) learned the joint representation for each question-answer pair 210 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 210‚Äì214, Denver, Colorado, June 4-5, 2015. cÔøΩ2015 Association for Computational Linguistics Figure 1. The architecture of comment labeling system based on deep learning by taking both of the textual and no</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nai Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for modelling sentences. In Proceedings of the Association for Computational Linguistics (ACL), pages 655-665, Baltimore, USA. 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of Empirical Methods on Natural Language Processing and Computational Natural Language Learning (EMNLP),</booktitle>
<pages>1201--1211</pages>
<location>Jeju Island,</location>
<contexts>
<context position="3138" citStr="Socher et al., 2012" startWordPosition="433" endWordPosition="436">nt classifiers. Another option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extraction for new domain. Recently the works about neural network-based distributed sentence models (Socher et al., 2012; Kalchbrenner et al., 2014) have achieved successes in natural language processing (NLP). As a consequence of this success, it appears natural to attempt to solve question answering using similar techniques. To recognize the high-quality answers, Hu et al. (2013) learned the joint representation for each question-answer pair 210 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 210‚Äì214, Denver, Colorado, June 4-5, 2015. cÔøΩ2015 Association for Computational Linguistics Figure 1. The architecture of comment labeling system based on deep learning by takin</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of Empirical Methods on Natural Language Processing and Computational Natural Language Learning (EMNLP), pages 1201-1211, Jeju Island, Korea. 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chirag Shah</author>
<author>Jefferey Pomerantz</author>
</authors>
<title>Evaluating and predicting answer quality in community QA.</title>
<date>2010</date>
<booktitle>In the 33rd International Conference on Research and development information retrieval on Research and Development in Information Retrieval (SIGIR‚Äô10),</booktitle>
<pages>411--418</pages>
<location>NewYork, USA.</location>
<contexts>
<context position="2626" citStr="Shah and Pomerantz, 2010" startWordPosition="363" endWordPosition="366">rity between question and comment with typical classification approaches, such as LR and SVM. To achieve the semantic relevance matching for question-comment pair, a large number of works focus on constructing feature-engineering to extract the features of question and comment as the input of models. Beyond typical textual feature, some works integrate the structural information (Wang et al., 2009; Huang et al., 2007) into the discrete representations of question-comment pairs to improve the performances of comment classifiers. Another option is extracting user metadata (Chen and Nayak, 2008; Shah and Pomerantz, 2010) from the question answering portal for enriching the feature-engineering. Empirically the approaches above have been shown to improve performances on recognizing positive answers, but they rely on large numbers of hand-crafted features, and require various external resources which may be difficult to obtain. Furthermore, they suffer from the limitation of requiring task-specific feature extraction for new domain. Recently the works about neural network-based distributed sentence models (Socher et al., 2012; Kalchbrenner et al., 2014) have achieved successes in natural language processing (NLP</context>
</contexts>
<marker>Shah, Pomerantz, 2010</marker>
<rawString>Chirag Shah and Jefferey Pomerantz. 2010. Evaluating and predicting answer quality in community QA. In the 33rd International Conference on Research and development information retrieval on Research and Development in Information Retrieval (SIGIR‚Äô10), pages 411-418, NewYork, USA. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin-Yew Lin</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Using conditional random fields to extract contexts and answers of questions from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of Association for Computational Linguistics (ACL),</booktitle>
<pages>710--718</pages>
<location>Columbus, Ohis, USA.</location>
<contexts>
<context position="5178" citStr="Ding et al., 2008" startWordPosition="731" endWordPosition="734"> neural networks (R&amp;CNN) approach to assign the labels to comments given a question. Based on the distributed representations learned form 2-dimensional CNN (2D-CNN) matching, our approach achieves to comment sequence learning and predict the classes of comments. Using the word embedding trained by provided Qatar Living data, R&amp;CNN not only models the semantic relevance for question and comment, but also captures the correlative context in comment sequence for predicting the class of comment. The experimental results show that our system performs better performances than the CRF based method (Ding et al., 2008) on recognizing good comments, and performs more adaptive on the development and test dataset. 2 System Description The architecture of our comment labeling system is a recurrent architecture (shown in Figure 1) with a recurrent neural network over the convolutional neural networks. Given a question, our approach achieves to learn the semantic relevance between question and comment by 2D-CNN matching and generate the distributed representation of each question-comment pair. After that, our approach uses the RNN to model the semantic correlations in comment sequence, and makes the quality predi</context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu. 2008. Using conditional random fields to extract contexts and answers of questions from online forums. In Proceedings of Association for Computational Linguistics (ACL), pages 710-718, Columbus, Ohis, USA. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space. CoRR,</title>
<date>2013</date>
<contexts>
<context position="9796" citStr="Mikolov et al., 2013" startWordPosition="1483" endWordPosition="1486">luate our approach (R&amp;CNN) on both the development and test data of this answer selection challenge. The statistics of experimental dataset are summarized in Table 1. In this dataset, there are 3,229 questions and 21,062 answers, and the percentage of good comments is about 50%. The average length of comment sequence is 6. data #question #comment #average % good Train 2600 16541 6.36 48.78 Devel 300 1645 5.48 53.19 Test 329 1976 6.00 50.46 Table 1. Statistics of experimental dataset In our approach, we use 100-dimensional word embedding trained on the provided Qatar Living data with Word2vec (Mikolov et al., 2013). The maximum size of coding the sentences with word embedding is set to be 100, and we use 3-words sliding window for 1D-convolution. The learning rate is initialized to be 0.01 and adapted dynamically using ADADELTA Method (Matthew, 2012). Based on the results on development set, all the hyperparameters of our approach are optimized on train set. Table 2 lists the experimental methods and the corresponding official results. The baselines of comment sequence labeling include the method based on CRF and the approach CRF+V, which integrates distributed representation learnt from our approach (R</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tom Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781. 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Boulanger-Lewandowski</author>
<author>Yoshua Bengio</author>
<author>Pascal Vincent</author>
</authors>
<title>Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription.</title>
<date>2012</date>
<booktitle>In Proceedings of the 29th International Conference on Machine Learning (ICML),</booktitle>
<location>Edinburgh, Scotland, UK.</location>
<marker>Boulanger-Lewandowski, Bengio, Vincent, 2012</marker>
<rawString>Nicolas Boulanger-Lewandowski, Yoshua Bengio, and Pascal Vincent. 2012. Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription. In Proceedings of the 29th International Conference on Machine Learning (ICML), Edinburgh, Scotland, UK. 2012.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>