<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000025">
<title confidence="0.9985265">
Extracting Lay Paraphrases of Specialized Expressions
from Monolingual Comparable Medical Corpora
</title>
<author confidence="0.556705">
Louise Deléger Pierre Zweigenbaum
</author>
<note confidence="0.4642685">
INSERM U872 Eq.20 CNRS, LIMSI
Paris, F-75006 France Orsay, F-91403 France
</note>
<email confidence="0.99362">
louise.deleger@spim.jussieu.fr pz@limsi.fr
</email>
<sectionHeader confidence="0.993695" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999601363636364">
Whereas multilingual comparable corpora
have been used to identify translations of
words or terms, monolingual corpora can
help identify paraphrases. The present
work addresses paraphrases found be-
tween two different discourse types: spe-
cialized and lay texts. We therefore built
comparable corpora of specialized and lay
texts in order to detect equivalent lay and
specialized expressions. We identified two
devices used in such paraphrases: nomi-
nalizations and neo-classical compounds.
The results showed that the paraphrases
had a good precision and that nominaliza-
tions were indeed relevant in the context of
studying the differences between special-
ized and lay language. Neo-classical com-
pounds were less conclusive. This study
also demonstrates that simple paraphrase
acquisition methods can also work on texts
with a rather small degree of similarity,
once similar text segments are detected.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939803921569">
Comparable corpora refer to collections of texts
sharing common characteristics. Very often com-
parable corpora consist of texts in two (or more)
languages that address the same topic without be-
ing translations of each other. But this notion
also applies to monolingual texts. In a mono-
lingual context, comparable corpora can be texts
from different sources (such as articles from var-
ious newspapers) or from different genres (such
as specialized and lay texts) but dealing with the
same general topic. Comparable corpora have
been used to perform several Natural Language
Processing tasks, such as extraction of word trans-
lations (Rapp, 1995; Chiao and Zweigenbaum,
2002) in a multilingual context or acquisition of
paraphrases (Barzilay and Lee, 2003; Shinyama
and Sekine, 2003) in a monolingual context. In
this work1, we are interested in using comparable
corpora to extract paraphrases.
Paraphrases are useful to various applications,
including information retrieval (Ibrahim et al.,
2003), information extraction (Shinyama and
Sekine, 2003), document summarization (Barzi-
lay, 2003) and text simplification (Elhadad and Su-
taria, 2007). Several methods have been designed
to extract paraphrases, many of them dealing with
comparable text corpora. A few paraphrase acqui-
sition approaches used plain monolingual corpora
to detect paraphrases, such as (Jacquemin, 1999)
who detects term variants or (Pasca and Dienes,
2005) who extract paraphrases from random Web
documents. This type of corpus does not insure
the actual existence of paraphrases and a majority
of methods have relied on corpora with a stronger
similarity between the documents, thus likely to
provide a greater amount of paraphrases. Some
paraphrase approaches used monolingual paral-
lel corpora, i.e. different translations or versions
of the same texts. For instance (Barzilay and
McKeown, 2001) detected paraphrases in a corpus
of English translations of literary novels. How-
ever such corpora are not easily available and ap-
proaches which rely instead on other types of cor-
pora are actively investigated.
Bilingual parallel corpora have been exploited
for acquiring paraphrases in English (Bannard and
Callison-Burch, 2005) and French (Max, 2008).
Comparable corpora are another useful source of
paraphrases. In this regard, only closely related
corpora have been used, especially and almost ex-
clusively corpora of news sources reporting the
</bodyText>
<footnote confidence="0.986593166666667">
1This paper is an extension of the work presented
in (Deléger and Zweigenbaum, 2008a) and (Deléger and
Zweigenbaum, 2008b), more specifically, a new corpus is
added, an additional type of paraphrase (based on neo-
classical compounds) is extracted and the evaluation is more
relevant.
</footnote>
<page confidence="0.877914">
2
</page>
<note confidence="0.9981855">
Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10,
Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP
</note>
<bodyText confidence="0.999908302325582">
same events. (Barzilay and Lee, 2003) gener-
ated paraphrase sentences from news articles us-
ing finite state automata. (Shinyama and Sekine,
2003) extracted paraphrases through the detection
of named entities anchors in a corpus of Japanese
news articles. In the medical domain, (Elhadad
and Sutaria, 2007) worked with a comparable, al-
most parallel, corpus of medical scientific articles
and their lay versions to extract paraphrases be-
tween specialized and lay languages.
We aim at detecting paraphrases in medical cor-
pora in the same line as (Elhadad and Sutaria,
2007) but for French. This type of paraphrases
would be a useful resource for text simplification
or to help authoring medical documents dedicated
to the general public. However, in a French medi-
cal context, it is difficult to obtain comparable cor-
pora of documents with a high level of similarity,
such as pairs of English scientific articles and their
translations in lay language, or news articles re-
porting the same events used in general language
(Barzilay and Lee, 2003; Shinyama and Sekine,
2003). Therefore, in addition to using this type
of comparable corpora, we also tried to rely on
corpora with less similarity but more easily avail-
able documents: lay and specialized documents
from various sources dealing with the same overall
medical topic.
We describe our experiment in building and ex-
ploiting these corpora to find paraphrases between
specialized and lay language. Issues at stake in-
volve: (i) how to collect corpora as relevant as
possible (Section 2.1); (ii) how to identify pas-
sages which potentially convey comparable in-
formation (Section 2.2); and (iii) what sorts of
paraphrases can be collected between these two
types of discourse, which is addressed in Sec-
tion 2.3, through the identification of two kinds
of paraphrases: nominalization paraphrases and
paraphrases of neo-classical compounds. An eval-
uation of the method (Section 2.4) is conducted
and results are presented (Section 3) and discussed
(Section 4).
</bodyText>
<sectionHeader confidence="0.995504" genericHeader="introduction">
2 Material and Methods
</sectionHeader>
<subsectionHeader confidence="0.991013">
2.1 Building comparable corpora of lay and
specialized texts
</subsectionHeader>
<bodyText confidence="0.999988923076924">
Today, a popular way of acquiring a corpus is col-
lecting it from the Web (Kilgarriff and Grefen-
stette, 2003), as it provides easy access to an un-
limited amount of documents. Here we focus
on monolingual comparable corpora of special-
ized and lay medical French documents, with the
objective of identifying correspondences between
the two varieties of languages in these documents.
We collected three corpora from the Web dealing
with the following three topics: nicotine addiction,
diabetes and cancer.
When dealing with a Web corpus several is-
sues arise. The first one is the relevance of
the documents retrieved to the domain targeted
and is highly dependant on the method used to
gather the documents. Possible methods include
querying a general-purpose search engine (such
as Google) with selected key words, querying a
domain-specific search engine (in domains where
they exist) indexing potentially more relevant and
trustworthy documents, or directly downloading
documents from known relevant websites. An-
other important issue specific to our type of cor-
pus is the relevance to the genre targeted, i.e. lay
vs. specialized. Hence the need to classify each
collected document as belonging to one genre or
the other. This can be done by automatic cate-
gorisation of texts or by direct knowledge of the
sources of documents. In order to obtain a corpus
as relevant as possible to the domain and to the
genres, we used direct knowledge and restricted
search for selecting the documents. In the case of
the cancer topic, we had knowledge of a website
containing comparable lay and specialized docu-
ments: the Standards, Options: Recommandations
website2 which gives access to guidelines on can-
cer for the medical specialists on the one hand and
guides for the general public on the same topics on
the other hand. This case was immediate: we only
had to download the documents from the website.
This corpus is therefore constituted of quite sim-
ilar documents (professional guidelines and their
lay versions). The other two corpora (on nico-
tine addiction and diabetes), however, were built
from heterogeneous sources through a restricted
search and are less similar. We first queried two
health search engines (the health Web portals CIS-
MeF3 and HON4) with key words. Both allow
the user to search for documents targeted to a
population (e.g., patient-oriented documents). We
also queried known relevant websites for docu-
ments dealing with our chosen topics. Those were
</bodyText>
<footnote confidence="0.999981">
2http://www.sor-cancer.fr/
3http://www.cismef.org/
4http://www.hon.ch/
</footnote>
<page confidence="0.998323">
3
</page>
<bodyText confidence="0.99996724">
French governmental websites, including that of
the HAS5 which issues guidelines for health pro-
fessionals, and that of the INPES6 which provides
educational material for the general public; as well
as health websites dedicated to the general pub-
lic, including Doctissimo7, Tabac Info Service8,
Stoptabac9 and Diabète Québec10.
The corpus dealing with the topic of diabetes
served as our development corpus for the first type
of paraphrases we extracted, the other two corpora
were used as test corpora.
Once collected, a corpus needs to be cleaned
and converted into an appropriate format to allow
further processing, i.e. extracting the textual con-
tent of the documents. HTML documents typi-
cally contain irrelevant information such as nav-
igation bars, footers and advertisements—referred
to as “boilerplate”—which can generate noise.
Boilerplate removal methods can rely on HTML
structure, visual features (placement and size of
blocks) and plain text features. We used HTML
structure (such as meta-information and density of
HTML tags) and plain text (such as spotting phone
and fax numbers and e-mails, as often appear at
the end of documents) to get rid of boilerplate.
</bodyText>
<subsectionHeader confidence="0.999923">
2.2 Aligning similar text segments
</subsectionHeader>
<bodyText confidence="0.9784728">
We hypothesize that paraphrases will be found
more reliably in text passages taken from both
sides of our comparable corpora which address
similar topics. So, as a first step, we tried to re-
late such passages. We proceeded in three steps:
</bodyText>
<listItem confidence="0.6900222">
1. as multiple topics are usually addressed in
a single text, we performed topic segmenta-
tion on each text using the TextTiling (Hearst,
1997) segmentation tool. A segment may
consist of one or several paragraphs;
</listItem>
<bodyText confidence="0.960313625">
2. we then tried to identify pairs of text seg-
ments addressing similar topics and likely to
contain paraphrases. For this we used a com-
mon, vector-based measure of text similarity:
the cosine similarity measure which we com-
puted for each pair of topic segments in the
cross-product of both corpus sides (each seg-
ment was represented as a bag of words);
</bodyText>
<footnote confidence="0.9998025">
5http://www.has-sante.fr/
6http://www.inpes.sante.fr/
7http://www.doctissimo.fr/
8http://www.tabac-info-service.fr/
9http://www.stop-tabac.ch/
10http://www.diabete.qc.ca/
</footnote>
<bodyText confidence="0.9764596">
3. we selected the best text segment pairs, that
is the pairs with a similarity score equal or
superior to 0.33, a threshold we determined
based on the results of a preliminary study
(Deléger and Zweigenbaum, 2008a).
</bodyText>
<subsectionHeader confidence="0.999909">
2.3 Extracting paraphrases
</subsectionHeader>
<bodyText confidence="0.999922047619048">
We are looking for paraphrases between two vari-
eties of language (specialized and lay), as opposed
to any kind of possible paraphrases. We there-
fore endeavoured to determine what kind of para-
phrases may be relevant in this regard. A com-
mon hypothesis (Fang, 2005) is that specialized
language uses more nominal constructions where
lay language uses more verbs instead. We test this
hypothesis and build on it to detect specialized-lay
paraphrases around noun-to-verb mappings (a first
version of this work was published in (Deléger and
Zweigenbaum, 2008b)). A second hypothesis is
that medical language contains a fair proportion of
words from Latin and Greek origins, which are re-
ferred to as neo-classical compounds. The mean-
ing of these words may be quite obscure to non-
experts readers. So one would expect to find less
of these words in lay texts and instead some sort
of paraphrases in common language. We therefore
tried to detect these paraphrases as a second type
of specialized vs. lay correspondences.
</bodyText>
<subsectionHeader confidence="0.981474">
2.3.1 Paraphrases of nominalizations
</subsectionHeader>
<bodyText confidence="0.991774523809524">
A first type of paraphrases we tried to extract
was paraphrases between nominal constructions
in the specialized side (such as treatment of the
disease) and verbal constructions in the lay side
(such as the disease is treated). This type of para-
phrases involves nominalizations of verbal phrases
and is built around the relation between a dever-
bal noun (e.g. treatment) and its base verb (e.g.
treat). Therefore, we relied on a lexicon of French
deverbal nouns paired with corresponding verbs
(Hathout et al., 2002) to detect such pairs in the
corpus segments. These noun-verb pairs served as
anchors for the detection of paraphrases. In order
to design paraphrasing patterns we extracted all
pairs of deverbal noun and verb with their contexts
from the development corpus. The study of such
pairs with their contexts allowed us to establish a
set of lexico-syntactic paraphrasing patterns11. An
example of such patterns can be seen in Table 1.
11Texts were first tagged with Treetagger (http://www.
ims.uni-stuttgart.de/projekte/corplex/TreeTagger/).
</bodyText>
<page confidence="0.993731">
4
</page>
<table confidence="0.99296625">
Specialized Lay
N1 PREP (DET) N2 V1 (DET) N2
N1 PREP (DET) N2A3 V1(DET) N2A3
N1 A2 V1(DET) N2
</table>
<tableCaption confidence="0.9235555">
Table 1: Example paraphrasing patterns (a shared
index indicates equality or synonymy. N=noun,
</tableCaption>
<bodyText confidence="0.99558075">
V=verb, A=adjective, PREP=preposition,
DET=determiner, 1 in index = pair of dever-
bal noun and verb)
The general method was to look for correspond-
ing content words (mainly noun and adjective) in
the contexts. We defined corresponding words as
either equal or synonymous (we used lexicons of
synonyms as resources12). Equals may have ei-
ther the same part-of-speech, or different parts-of-
speech, in which case stemming13 is performed to
take care of derivational variation (e.g., medicine
and medical). We then applied the patterns to both
development and test corpora.
The patterns thus designed are close to the
transformation rules of (Jacquemin, 1999) who
detects morpho-syntactico-semantic variants of
terms in plain monolingual corpora. One dif-
ference is that our patterns are built around one
specific type of morphological variation (noun to
verb variation) that seemed relevant in the context
of the specialized/lay opposition, as opposed to
any possible variation. We also identify the para-
phrases by comparing the two sides of a compara-
ble corpus while (Jacquemin, 1999) starts from a
given list of terms and searches for their variants
in a plain monolingual corpus. Finally, we do not
apply our method on terms specifically but on any
expression corresponding to the patterns.
</bodyText>
<subsectionHeader confidence="0.8351405">
2.3.2 Paraphrases of neo-classical
compounds
</subsectionHeader>
<bodyText confidence="0.99998675">
We then extracted paraphrases of neo-classical
compounds as a second type of paraphrases that
seemed relevant to the opposition between lay
and specialized languages. This means that we
looked for neo-classical compounds on one side
of the corpora and equivalents in modern lan-
guage on the other side. To do this we relied
on the morphosemantic parser DériF (Namer and
</bodyText>
<footnote confidence="0.9966855">
12The lexicons used came from the Masson and Robert dic-
tionaries.
13Stemming was performed using the Lingua::Stem
perl package (http://search.cpan.org/~snowhare/
Lingua-Stem-0.83) which is similar to the Snowball
stemmers (http://snowball.tartarus.org)
</footnote>
<bodyText confidence="0.99778875">
Zweigenbaum, 2004). DériF analyzes morpholog-
ically complex words and outputs a decomposi-
tion of those words into their components and a
definition-like gloss of the words according to the
meaning of the components in modern language
when they are from Greek or Latin origins. For
instance the French word gastrite (gastritis) is de-
composed into gastr+ite and its gloss is inflamma-
tion de l’estomac (inflammation of stomach).
We first ran the analyzer on the specialized
side of the corpora to detect neo-classical com-
pounds. Then we searched for paraphrases of
those compounds based on the output of DériF,
that is we looked for the modern-language equiva-
lents of the word components (in the case of gas-
tritis this means searching for inflammation and
stomach) close to each other within a syntactic
phrase (we empirically set a threshold of 4 words
as the maximum distance between the modern-
language translations of the components). A pat-
tern used to search those paraphrases is for in-
stance:
C → ((DET)? N PREP)? (DET)? C1 W0−4 C2
where C is a neo-classical compounds in a spe-
cialized text segment, C1 and C2 are the modern-
language components of C, N is a noun, PREP a
preposition, DET a determiner and W an arbitrary
word.
</bodyText>
<subsectionHeader confidence="0.947975">
2.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.999646142857143">
We first evaluated the quality of the extracted para-
phrases by measuring their precision, that is, the
percentage of correct results over the entire re-
sults. We computed precision for each type of
paraphrases.
We then estimated recall for the first type
of paraphrases (nominalization paraphrases): the
percentage of correct extracted paraphrases over
the total number of paraphrases that should have
been extracted. We used as gold standard a ran-
dom sample of 10 segment pairs from which we
manually extracted paraphrases.
Finally, since we aim at detecting paraphrases
between lay and specialized languages, we also
looked at the relevance of the two types we chose
to extract. That is, we evaluated the coherence of
the results with our two initial hypotheses, which
are expected to apply when both a specialized text
segment and a lay text segment convey similar
information: (1) nominalizations are more often
used in specialized texts while lay texts tend to
</bodyText>
<page confidence="0.844039">
5
</page>
<figure confidence="0.86871575">
Specialized Lay
(a) Ns ...the benefits of smoking cessation... Nl ...withdrawal symptoms of smoking cessation...
(b) Ns ...regular use of tobacco concerned... Nl ...tobacco use is the first cause...
(c) Ns ...which goes with smoking cessation... Vl ...who wants to stop smoking...
</figure>
<tableCaption confidence="0.973861666666667">
Table 2: Sample cases used to compute the conditional probability for nominalizations; (a) and (b)
represent cases where a paraphrase was expected but did not occur and (c) a case where a paraphrase was
indeed used. N = nominalization; V = verbal form.
</tableCaption>
<table confidence="0.9475895">
Specialized Lay
Cs ...glycemia is lower... Cl ...a drop of glycemia...
Cs ...the starting point of thrombosis... Cl ...the risk of thrombosis...
Cs ...especially cardiopathies and... Ml ...25% of heart diseases...
</table>
<tableCaption confidence="0.680689666666667">
Table 3: Sample cases used to compute the conditional probability for neo-classical compounds; (a) and
(b) represent cases where a paraphrase was expected but did not occur and (c) a case where a paraphrase
was indeed used. C = compound; M = modern.
</tableCaption>
<bodyText confidence="0.985518873015873">
replace them with verbs; (2) specialized texts use
more neoclassical compounds while lay texts give
a paraphrase in modern language.
To evaluate (1) we measured the conditional
probability P(Vl|Ns) that a nominalization pat-
tern Ns in a specialized segment be replaced by
a matching verbal pattern Vl in a corresponding
lay segment. These patterns are the paraphras-
ing patterns defined in Section 2.3.1 and exempli-
fied in Table 1. Table 2 gives examples of cases
taken into account when computing this probabil-
ity, i.e. cases where both text segments convey the
same information, as a nominalization in the spe-
cialized side and as a nominalization or a verbal
paraphrase in the lay side. Formally, the proba-
bility can be estimated by |P arNs→Vl|
|ExpParNs→Vl|, where
|ParNs→Vl |is the number of correct extracted
paraphrases involving a nominalization in a spe-
cialized segment and a verbal construction in the
corresponding lay segment (case (c) of Table 2),
and |ExpParNs→Vl |the expected number of para-
phrases. The expected number of paraphrases cor-
responds to the total number of instances where
a specialized text segment contains a nominal-
ization and the corresponding lay segment con-
veys the same information, expressed either as a
nominalization or as a paraphrasing verbal con-
struction (cases (a), (b) and (c) of Table 2). It
is therefore computed as the sum of |ParNs→Vl|
and |ParNs→Nl|, the latter referring to the number
of occurrences where both the specialized and lay
segments match the same nominalization pattern,
i.e., instances where a paraphrase was expected
but did not occur (cases (a) and (b) of Table 2). For
instance use of tobacco on one side and tobacco
use on the other side, as in (b), is a case where
one would have expected a paraphrase such as to-
bacco is used. Note that matching allows the same
flexibility as described in Section 2.3.1 in terms
of synonyms and morphological variants. To test
whether this tendency of using verbal construc-
tions instead of nominalizations is indeed stronger
in lay texts we also measured the reverse, i.e. the
conditional probability P(Vs|Nl), given a nomi-
nalization pattern Nl in a lay segment, that it be
replaced with a matching verbal pattern Vs in the
corresponding specialized segment, computed as
|ParNl→Vs |If our hypothesis is verified, this
 |ExpParNl →V |
reverse probability should be lower then the direct
probability.
In the same way, to evaluate (2) we measured
the conditional probability P(Ml|Cs) that a neo-
classical compound Cs in a specialized segment
be replaced by a modern-language equivalent Ml
in a corresponding lay segment. Table 3 gives ex-
amples of cases taken into account when comput-
ing this probability, that is cases where both text
segments convey the same information, as a neo-
classical compound in the specialized side and as
a neo-classical compound or a modern-language
paraphrase in the lay side. Formally, it can be
</bodyText>
<equation confidence="0.5146495">
estimated by |ParCs→Ml|
|ExpParCs→Ml|, where|P arCs→Ml|
</equation>
<bodyText confidence="0.9824555">
is the number of correct extracted paraphrases in-
volving a neo-classical compound in a specialized
</bodyText>
<page confidence="0.999085">
6
</page>
<table confidence="0.9958566">
Diabetes L Nicotine addiction S Cancer
S S L L
docs 135 600 62 620 22 16
words 580,712 461,066 595,733 603,257 641,584 228,742
segment pairs 183 547 438
</table>
<tableCaption confidence="0.984389">
Table 4: Sizes of the corpora (Number of documents, words and segment pairs; S=specialized, L=lay)
</tableCaption>
<table confidence="0.999952666666667">
Diabetes Nicotine add. Cancer
total 42 79 93
paraph.
correct 30 62 62
paraph.
precision 71.4% 78.5% 75.8%
</table>
<tableCaption confidence="0.9766705">
Table 5: Precision for nominalization paraphrases
(at the type level, not token level)
</tableCaption>
<table confidence="0.999935333333333">
Diabetes Nicotine add. Cancer
total 39 3 3
paraph.
correct 24 3 3
paraph.
precision 61.5% 100% 100%
</table>
<tableCaption confidence="0.940029">
Table 6: Precision for paraphrases of neo-classical
</tableCaption>
<bodyText confidence="0.9813881875">
compounds (at the type level, not token level)
segment and a modern-language equivalent in the
corresponding lay segment (case (c) of Table 3)
, and |ExpParCs→ml |is the expected number
of paraphrases (case (a), (b) and (c) of Table 3).
The expected number of paraphrases is the sum of
|ParCs→ml |and |ParCs→Cl|, the latter referring
to the number of occurrences where both the spe-
cialized and lay segments contains the same neo-
classical compound (instances where a paraphrase
was expected but did not occur, for instance cases
(a) and (b) of Table 3). We then measured the re-
verse, i.e. the conditional probability P(Ms|Cl),
given a neo-classical compound Cl in a lay seg-
ment, that it be replaced with a modern-language
equivalent Ms in the corresponding specialized
</bodyText>
<subsectionHeader confidence="0.500023">
|ParCl→ Ms|
</subsectionHeader>
<bodyText confidence="0.787275">
segment, computed as |ExpParCl→Ms|.
</bodyText>
<sectionHeader confidence="0.999827" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.896818">
Table 4 gives size figures for each side (lay and
specialized) of the three corpora in terms of docu-
ments, words and segment pairs.
Evaluation of the quality of the extracted para-
phrases shows that precision is rather good for
both type of paraphrases (see Tables 5 and 6), al-
though the figures cannot be considered signica-
tive for paraphrases of compounds extracted in the
tobacco and cancer corpora given the small num-
ber of paraphrases (only 3 paraphrases in both
cases).
Examples of nominalization paraphrases and
paraphrases of neo-classical compounds are given
in Tables 7 and 8. The last line of Table 7 shows
an example of incorrect paraphrase, which is due
to the synonymy link established between French
words charge and poids which is not valid in
that particular context. The last line of Table 8
also gives an incorrect example, which is caused
by the imprecision of the modern-language para-
phrase which is only partially equivalent to the
neo-classical compound.
Specialized Lay
consommation consommer de façon
régulière régulière
regular use to use in a regular
fashion
emfashion
gêne à la lecture de lire
reading difficulty prevents from reading
évolution de l’affection la maladie évolue
evolution of the the disease is evolving
condition
*prise en charge prendre du poids
the taking care of to take on weight
Table 7: Examples of extracted nominalization
paraphrases (* indicates an incorrect example)
With regard to the quantitative evaluation of the
nominalization paraphrases, we measured a 30%
recall on our sample of segment pairs, meaning
that out of the 10 manually extracted paraphrases
only 3 were automatically detected by our method.
Cases of non-detected paraphrases were due to the
restrained scope of the paraphrasing patterns, as
well as to the presence of synonyms not contained
</bodyText>
<page confidence="0.998861">
7
</page>
<bodyText confidence="0.970442090909091">
Specialized Lay
leucospermie Augmentation du nombre de
leucospermia globules blancs dans le sperme
Increase in the number of white
cells in the sperm
glycémie la quantité de sucre dans le sang
glycemia amount of sugar in the blood
prostatectomie l’ablation de la prostate
prostatectomy ablation of the prostate
*hyperglycémie le taux de sucre dans le sang
hyperglycemia proportion of sugar in the blood
</bodyText>
<tableCaption confidence="0.547793">
Table 8: Examples of extracted paraphrases of
neo-classical compounds (* indicates an incorrect
example)
in our lists.
Table 9 displays results for the investigation on
</tableCaption>
<bodyText confidence="0.999625904761905">
the coherence of our first initial hypothesis that
specialized texts use nominalizations where lay
texts use verbal constructions. The conditional
probability that a nominalization be replaced with
a verbal construction is higher for nominalizations
in specialized texts than for the reverse direction,
which means that nominalizations in specialized
texts are indeed more likely to be replaced by
verbal constructions in lay texts than nominaliza-
tions in lay texts by verbal constructions in spe-
cialized texts. Results for the second hypothe-
sis (neo-classical compounds in specialized texts
tend to be replaced by modern-language equiva-
lents in lay texts) are given in Table 10. As for the
first hypothesis, the conditional probability for the
neo-classical compounds in the specialized texts is
higher, which seems to be coherent with the ini-
tial hypothesis. However, given the very small
number of paraphrases, we cannot draw a signi-
ficative conclusion as regards this second type of
paraphrases.
</bodyText>
<sectionHeader confidence="0.998706" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999995666666667">
In this work we built comparable corpora of spe-
cialized and lay texts on which we implemented
simple paraphrase acquisition methods to extract
certain types of paraphrases that seemed rele-
vant in the context of specialized and lay lan-
guage: paraphrases based on nominalization vs.
verbal constructions and paraphrases based on
neo-classical compounds vs. modern-language ex-
pressions. The precision measured on the set of
detected paraphrases is rather good, which indi-
cates good quality of the paraphrases (hence of the
paraphrasing patterns and extracted segments).
An originality of this work lies in the fact
that, in contrast to approaches working with more
closely related comparable corpora (Barzilay and
Lee, 2003; Shinyama and Sekine, 2003; Elhadad
and Sutaria, 2007), we also gathered comparable
corpora of documents which, although addressing
the same general topics (nicotine addiction, dia-
betes), were a priori rather different since coming
from various sources and targeted to different pop-
ulations. We showed that simple paraphrase ac-
quisition methods could also work on documents
with a lesser degree of similarity, once similar seg-
ments were detected. Indeed the precision of the
extracted paraphrases is within the same range for
the three corpora we built, despite the fact that one
corpus (the cancer corpus) was composed of more
similar documents than the other two.
We extracted a type of paraphrases much less
exploited in existing work, with the exception of
(Elhadad and Sutaria, 2007), that is paraphrases
between specialized and lay language. This meant
that we had to take into account what kind of
paraphrases might be relevant, therefore the meth-
ods used to extract them were more constrained
and supervised than approaches aiming at detect-
ing any type of paraphrases. We based a part of
our work on the hypothesis that among relevant
types were paraphrases involving nominalizations
of verbal contructions, meaning that lay texts tend
to use verb phrases where specialized texts use
deverbal noun contructions. Our results seem to
support this hypothesis. Such paraphrases there-
fore seem to be interesting advice to give to au-
thors of lay texts. Future work includes testing
our method on English and comparing the results
for the two languages. We would expect them to
be fairly similar since the tendency to use nominal
constructions in scientific literature has also been
observed for English (Fang, 2005). The second
part of our work exploited the hypothesis that lay
texts use modern-language expressions where spe-
cialized texts use neo-classical compound words.
In this case, the paraphrases were too few to en-
able us to draw a significative conclusion. Testing
this method on different and larger corpora might
give more insight into the relevance of extracting
this type of paraphrases. As it is, this work is still
experimental and needs to be further investigated.
</bodyText>
<page confidence="0.996032">
8
</page>
<table confidence="0.99973875">
Diabetes Nicotine addiction Cancer
S—*L L—*S S—*L L—*S S—*L L—*S
# paraphrases 44 37 140 76 73 57
(|ParNs→Vl |or |ParNl→Vs|)
# expected paraphrases |) 712 695 1675 1626 770 772
(|ExpParNs→Vl |or |ExpParNl→Vs
Conditional Probability 0.062 0.053 0.084 0.047 0.095 0.074
(P(Vl|N3) or P(V3|Nl))
</table>
<tableCaption confidence="0.9299365">
Table 9: Conditional probability for nominalization paraphrases in both directions, specialized-lay
(S—*L) and lay-specialized (L—*S)
</tableCaption>
<table confidence="0.99979825">
Diabetes Nicotine addiction Cancer
S—*L L—*S S—*L L—*S S—*L L—*S
# paraphrases 53 40 18 0 3 0
(|ParCs→ml |or |ParCl→ms|)
# expected paraphrases 686 675 196 178 1482 1479
(|ExpParCs→ml |or |ExpParCl→ms|)
Conditional Probability 0.074 0.059 0.092 0 0.002 0
(P(Ml|C3) or P(M3|Cl))
</table>
<tableCaption confidence="0.99154">
Table 10: Conditional probability for paraphrases of neo-classical compounds in both directions
</tableCaption>
<bodyText confidence="0.999984416666667">
Its major drawback is the low number of para-
phrases, in particular for the paraphrases of neo-
classical compounds which brought inconclusive
results. In order to gain insight on the low quan-
tity of paraphrases of neo-classical compounds,
we manually looked at sample text segments from
the nicotine addiction and cancer corpora (the
two corpora where very few paraphrases were ex-
tracted) and could not find any paraphrase of neo-
classical compounds. This would seem to indicate
that the low quantity of this type of paraphrases
is due to the characteristics of the corpora rather
than to defects of our extraction technique. As
for the nominalization paraphrase, even though the
method brought more paraphrases and gave en-
couraging results, their quantity is still quite small.
The recall computed on a sample of segment pairs
is low. This is mainly due to the fact that we set up
rather rectricted paraphrasing patterns. This was
done to ensure a high precision but caused the re-
call to fall. A future step would be to improve re-
call by modifying some aspects of the paraphras-
ing patterns while trying to keep a good precision.
Regardless of recall, the number of nominaliza-
tion paraphrases in itself is also small. This can
be due to the fact that we restrict ourselves to one
specific type of paraphrases, but also to the facts
that we first align and select similar text segments,
that the coverage of our corpora might not be suffi-
cient, and that we work on comparable corpora of
lesser similarity than other methods. Future work
to increase the number of paraphrases involves us-
ing clusters of text segments instead of pairs, in-
creasing the corpus sizes and developing methods
to detect other types of paraphrases besides the
two kinds investigated here.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999992777777778">
We presented a method based on comparable med-
ical corpora to extract paraphrases between spe-
cialized and lay languages. We identified two
kinds of paraphrases, nominalization paraphrases
and paraphrases of neo-classical compounds, the
first type seeming to indeed reflect some of the
systematic differences between specialized and
lay texts while the second type brought too few
results to draw a signicative conclusion.
</bodyText>
<sectionHeader confidence="0.999455" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994088">
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, pages 597–604.
Regina Barzilay and Lillian Lee. 2003. Learn-
ing to paraphrase: An unsupervised approach us-
</reference>
<page confidence="0.94495">
9
</page>
<reference confidence="0.999830928571429">
ing multiple-sequence alignment. In HLT-NAACL,
pages 16–23, Edmonton, Canada.
Regina Barzilay and Kathleen McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In
ACL/EACL, pages 50–57.
Regina Barzilay. 2003. Information Fusion for Mul-
tidocument Summarization: Paraphrasing and Gen-
eration. Ph.D. thesis, Columbia University.
Yun-Chuang Chiao and Pierre Zweigenbaum. 2002.
Looking for French-English translations in compa-
rable medical corpora. In Proc AMIA Symp, pages
150–4.
Louise Deléger and Pierre Zweigenbaum. 2008a.
Aligning lay and specialized passages in compara-
ble medical corpora. In Stud Health Technol Inform,
volume 136, pages 89–94.
Louise Deléger and Pierre Zweigenbaum. 2008b.
Paraphrase acquisition from comparable medical
corpora of specialized and lay texts. In Proceedings
of the AMIA Annual Fall Symposium, pages 146–
150, Washington, DC.
Noemie Elhadad and Komal Sutaria. 2007. Min-
ing a lexicon of technical terms and lay equivalents.
In ACL BioNLP Workshop, pages 49–56, Prague,
Czech Republic.
Zhihui Fang. 2005. Scientific literacy: A systemic
functional linguistics perspective. Science Educa-
tion, 89(2):335–347.
Nabil Hathout, Fiammetta Namer, and Georgette Dal.
2002. An Experimental Constructional Database:
The MorTAL Project. In Many Morphologies, pages
178–209.
Marti A. Hearst. 1997. Texttiling: Segmenting text
into multi-paragraph subtopic passages. Computa-
tional Linguistics, 23(1):33–64.
Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Ex-
tracting structural paraphrases from aligned mono-
lingual corpora. In Proceedings of the second inter-
national workshop on Paraphrasing, pages 57–64,
Sapporo, Japan. Association for Computational Lin-
guistics.
Christian Jacquemin. 1999. Syntagmatic and paradig-
matic representations of term variation. In Pro-
ceedings of the 37th annual meeting of the Asso-
ciation for Computational Linguistics on Compu-
tational Linguistics, pages 341–348, College Park,
Maryland.
Adam Kilgarriff and Gregory Grefenstette. 2003. In-
troduction to the special issue on the web as corpus.
Computational Linguistics, 29(3):333–47.
Aurélien Max. 2008. Local rephrasing suggestions for
supporting the work of writers. In Proceedings of
GoTAL, Gothenburg, Sweden.
Fiammetta Namer and Pierre Zweigenbaum. 2004.
Acquiring meaning for French medical terminology:
contribution of morphosemantics. In Marius Fi-
eschi, Enrico Coiera, and Yu-Chuan Jack Li, editors,
MEDINFO, pages 535–539, San Francisco.
Marius Pasca and Peter Dienes. 2005. Aligning nee-
dles in a haystack: Paraphrase acquisition across the
web. In Proceedings of IJCNLP, pages 119–130.
Reinhard Rapp. 1995. Identifying word translations
in non-parallel texts. In Proceedings of the 33rd an-
nual meeting on Association for Computational Lin-
guistics, pages 320–322.
Yusuke Shinyama and Satoshi Sekine. 2003. Para-
phrase acquisition for information extraction. In
Proceedings of the second international workshop
on Paraphrasing (IWP), pages 65–71, Sapporo,
Japan.
</reference>
<page confidence="0.997737">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.305618">
<title confidence="0.77649">Extracting Lay Paraphrases of Specialized Expressions from Monolingual Comparable Medical Corpora</title>
<author confidence="0.966494">Louise Deléger Pierre Zweigenbaum</author>
<affiliation confidence="0.5951">INSERM U872 Eq.20 CNRS, LIMSI</affiliation>
<address confidence="0.931081">Paris, F-75006 France Orsay, F-91403 France</address>
<email confidence="0.96086">louise.deleger@spim.jussieu.frpz@limsi.fr</email>
<abstract confidence="0.999103217391304">Whereas multilingual comparable corpora have been used to identify translations of words or terms, monolingual corpora can help identify paraphrases. The present work addresses paraphrases found between two different discourse types: specialized and lay texts. We therefore built comparable corpora of specialized and lay texts in order to detect equivalent lay and specialized expressions. We identified two devices used in such paraphrases: nominalizations and neo-classical compounds. The results showed that the paraphrases had a good precision and that nominalizations were indeed relevant in the context of studying the differences between specialized and lay language. Neo-classical compounds were less conclusive. This study also demonstrates that simple paraphrase acquisition methods can also work on texts with a rather small degree of similarity, once similar text segments are detected.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>597--604</pages>
<contexts>
<context position="3366" citStr="Bannard and Callison-Burch, 2005" startWordPosition="487" endWordPosition="490">y of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used monolingual parallel corpora, i.e. different translations or versions of the same texts. For instance (Barzilay and McKeown, 2001) detected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead on other types of corpora are actively investigated. Bilingual parallel corpora have been exploited for acquiring paraphrases in English (Bannard and Callison-Burch, 2005) and French (Max, 2008). Comparable corpora are another useful source of paraphrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>16--23</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1924" citStr="Barzilay and Lee, 2003" startWordPosition="276" endWordPosition="279">n two (or more) languages that address the same topic without being translations of each other. But this notion also applies to monolingual texts. In a monolingual context, comparable corpora can be texts from different sources (such as articles from various newspapers) or from different genres (such as specialized and lay texts) but dealing with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as</context>
<context position="4066" citStr="Barzilay and Lee, 2003" startWordPosition="596" endWordPosition="599">phrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP same events. (Barzilay and Lee, 2003) generated paraphrase sentences from news articles using finite state automata. (Shinyama and Sekine, 2003) extracted paraphrases through the detection of named entities anchors in a corpus of Japanese news articles. In the medical domain, (Elhadad and Sutaria, 2007) worked with a comparable, almost parallel, corpus of medical scientific articles and their lay versions to extract paraphrases between specialized and lay languages. We aim at detecting paraphrases in medical corpora in the same line as (Elhadad and Sutaria, 2007) but for French. This type of paraphrases would be a useful resource</context>
<context position="27157" citStr="Barzilay and Lee, 2003" startWordPosition="4263" endWordPosition="4266">le paraphrase acquisition methods to extract certain types of paraphrases that seemed relevant in the context of specialized and lay language: paraphrases based on nominalization vs. verbal constructions and paraphrases based on neo-classical compounds vs. modern-language expressions. The precision measured on the set of detected paraphrases is rather good, which indicates good quality of the paraphrases (hence of the paraphrasing patterns and extracted segments). An originality of this work lies in the fact that, in contrast to approaches working with more closely related comparable corpora (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Elhadad and Sutaria, 2007), we also gathered comparable corpora of documents which, although addressing the same general topics (nicotine addiction, diabetes), were a priori rather different since coming from various sources and targeted to different populations. We showed that simple paraphrase acquisition methods could also work on documents with a lesser degree of similarity, once similar segments were detected. Indeed the precision of the extracted paraphrases is within the same range for the three corpora we built, despite the fact that one corpus (the cancer </context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In HLT-NAACL, pages 16–23, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In ACL/EACL,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="3037" citStr="Barzilay and McKeown, 2001" startWordPosition="438" endWordPosition="441">ext corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used monolingual parallel corpora, i.e. different translations or versions of the same texts. For instance (Barzilay and McKeown, 2001) detected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead on other types of corpora are actively investigated. Bilingual parallel corpora have been exploited for acquiring paraphrases in English (Bannard and Callison-Burch, 2005) and French (Max, 2008). Comparable corpora are another useful source of paraphrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen McKeown. 2001. Extracting paraphrases from a parallel corpus. In ACL/EACL, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
</authors>
<title>Information Fusion for Multidocument Summarization: Paraphrasing and Generation.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University.</institution>
<contexts>
<context position="2259" citStr="Barzilay, 2003" startWordPosition="322" endWordPosition="324">g with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount </context>
</contexts>
<marker>Barzilay, 2003</marker>
<rawString>Regina Barzilay. 2003. Information Fusion for Multidocument Summarization: Paraphrasing and Generation. Ph.D. thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Chuang Chiao</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Looking for French-English translations in comparable medical corpora.</title>
<date>2002</date>
<booktitle>In Proc AMIA Symp,</booktitle>
<pages>150--4</pages>
<contexts>
<context position="1844" citStr="Chiao and Zweigenbaum, 2002" startWordPosition="264" endWordPosition="267">texts sharing common characteristics. Very often comparable corpora consist of texts in two (or more) languages that address the same topic without being translations of each other. But this notion also applies to monolingual texts. In a monolingual context, comparable corpora can be texts from different sources (such as articles from various newspapers) or from different genres (such as specialized and lay texts) but dealing with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acqu</context>
</contexts>
<marker>Chiao, Zweigenbaum, 2002</marker>
<rawString>Yun-Chuang Chiao and Pierre Zweigenbaum. 2002. Looking for French-English translations in comparable medical corpora. In Proc AMIA Symp, pages 150–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louise Deléger</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Aligning lay and specialized passages in comparable medical corpora.</title>
<date>2008</date>
<booktitle>In Stud Health Technol Inform,</booktitle>
<volume>136</volume>
<pages>89--94</pages>
<contexts>
<context position="3668" citStr="Deléger and Zweigenbaum, 2008" startWordPosition="534" endWordPosition="537">etected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead on other types of corpora are actively investigated. Bilingual parallel corpora have been exploited for acquiring paraphrases in English (Bannard and Callison-Burch, 2005) and French (Max, 2008). Comparable corpora are another useful source of paraphrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP same events. (Barzilay and Lee, 2003) generated paraphrase sentences from news articles using finite state automata. (Shinyama and Sekine, 2003) extracted paraphrases through the detection of named entities anchors in a corpus of Japanese </context>
<context position="11056" citStr="Deléger and Zweigenbaum, 2008" startWordPosition="1691" endWordPosition="1694">ses. For this we used a common, vector-based measure of text similarity: the cosine similarity measure which we computed for each pair of topic segments in the cross-product of both corpus sides (each segment was represented as a bag of words); 5http://www.has-sante.fr/ 6http://www.inpes.sante.fr/ 7http://www.doctissimo.fr/ 8http://www.tabac-info-service.fr/ 9http://www.stop-tabac.ch/ 10http://www.diabete.qc.ca/ 3. we selected the best text segment pairs, that is the pairs with a similarity score equal or superior to 0.33, a threshold we determined based on the results of a preliminary study (Deléger and Zweigenbaum, 2008a). 2.3 Extracting paraphrases We are looking for paraphrases between two varieties of language (specialized and lay), as opposed to any kind of possible paraphrases. We therefore endeavoured to determine what kind of paraphrases may be relevant in this regard. A common hypothesis (Fang, 2005) is that specialized language uses more nominal constructions where lay language uses more verbs instead. We test this hypothesis and build on it to detect specialized-lay paraphrases around noun-to-verb mappings (a first version of this work was published in (Deléger and Zweigenbaum, 2008b)). A second hy</context>
</contexts>
<marker>Deléger, Zweigenbaum, 2008</marker>
<rawString>Louise Deléger and Pierre Zweigenbaum. 2008a. Aligning lay and specialized passages in comparable medical corpora. In Stud Health Technol Inform, volume 136, pages 89–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louise Deléger</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Paraphrase acquisition from comparable medical corpora of specialized and lay texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the AMIA Annual Fall Symposium,</booktitle>
<pages>146--150</pages>
<location>Washington, DC.</location>
<contexts>
<context position="3668" citStr="Deléger and Zweigenbaum, 2008" startWordPosition="534" endWordPosition="537">etected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead on other types of corpora are actively investigated. Bilingual parallel corpora have been exploited for acquiring paraphrases in English (Bannard and Callison-Burch, 2005) and French (Max, 2008). Comparable corpora are another useful source of paraphrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP same events. (Barzilay and Lee, 2003) generated paraphrase sentences from news articles using finite state automata. (Shinyama and Sekine, 2003) extracted paraphrases through the detection of named entities anchors in a corpus of Japanese </context>
<context position="11056" citStr="Deléger and Zweigenbaum, 2008" startWordPosition="1691" endWordPosition="1694">ses. For this we used a common, vector-based measure of text similarity: the cosine similarity measure which we computed for each pair of topic segments in the cross-product of both corpus sides (each segment was represented as a bag of words); 5http://www.has-sante.fr/ 6http://www.inpes.sante.fr/ 7http://www.doctissimo.fr/ 8http://www.tabac-info-service.fr/ 9http://www.stop-tabac.ch/ 10http://www.diabete.qc.ca/ 3. we selected the best text segment pairs, that is the pairs with a similarity score equal or superior to 0.33, a threshold we determined based on the results of a preliminary study (Deléger and Zweigenbaum, 2008a). 2.3 Extracting paraphrases We are looking for paraphrases between two varieties of language (specialized and lay), as opposed to any kind of possible paraphrases. We therefore endeavoured to determine what kind of paraphrases may be relevant in this regard. A common hypothesis (Fang, 2005) is that specialized language uses more nominal constructions where lay language uses more verbs instead. We test this hypothesis and build on it to detect specialized-lay paraphrases around noun-to-verb mappings (a first version of this work was published in (Deléger and Zweigenbaum, 2008b)). A second hy</context>
</contexts>
<marker>Deléger, Zweigenbaum, 2008</marker>
<rawString>Louise Deléger and Pierre Zweigenbaum. 2008b. Paraphrase acquisition from comparable medical corpora of specialized and lay texts. In Proceedings of the AMIA Annual Fall Symposium, pages 146– 150, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noemie Elhadad</author>
<author>Komal Sutaria</author>
</authors>
<title>Mining a lexicon of technical terms and lay equivalents.</title>
<date>2007</date>
<booktitle>In ACL BioNLP Workshop,</booktitle>
<pages>49--56</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2311" citStr="Elhadad and Sutaria, 2007" startWordPosition="328" endWordPosition="332"> corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used mono</context>
<context position="4333" citStr="Elhadad and Sutaria, 2007" startWordPosition="636" endWordPosition="639">, more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP same events. (Barzilay and Lee, 2003) generated paraphrase sentences from news articles using finite state automata. (Shinyama and Sekine, 2003) extracted paraphrases through the detection of named entities anchors in a corpus of Japanese news articles. In the medical domain, (Elhadad and Sutaria, 2007) worked with a comparable, almost parallel, corpus of medical scientific articles and their lay versions to extract paraphrases between specialized and lay languages. We aim at detecting paraphrases in medical corpora in the same line as (Elhadad and Sutaria, 2007) but for French. This type of paraphrases would be a useful resource for text simplification or to help authoring medical documents dedicated to the general public. However, in a French medical context, it is difficult to obtain comparable corpora of documents with a high level of similarity, such as pairs of English scientific artic</context>
<context position="27212" citStr="Elhadad and Sutaria, 2007" startWordPosition="4271" endWordPosition="4274">n types of paraphrases that seemed relevant in the context of specialized and lay language: paraphrases based on nominalization vs. verbal constructions and paraphrases based on neo-classical compounds vs. modern-language expressions. The precision measured on the set of detected paraphrases is rather good, which indicates good quality of the paraphrases (hence of the paraphrasing patterns and extracted segments). An originality of this work lies in the fact that, in contrast to approaches working with more closely related comparable corpora (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Elhadad and Sutaria, 2007), we also gathered comparable corpora of documents which, although addressing the same general topics (nicotine addiction, diabetes), were a priori rather different since coming from various sources and targeted to different populations. We showed that simple paraphrase acquisition methods could also work on documents with a lesser degree of similarity, once similar segments were detected. Indeed the precision of the extracted paraphrases is within the same range for the three corpora we built, despite the fact that one corpus (the cancer corpus) was composed of more similar documents than the</context>
</contexts>
<marker>Elhadad, Sutaria, 2007</marker>
<rawString>Noemie Elhadad and Komal Sutaria. 2007. Mining a lexicon of technical terms and lay equivalents. In ACL BioNLP Workshop, pages 49–56, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhihui Fang</author>
</authors>
<title>Scientific literacy: A systemic functional linguistics perspective.</title>
<date>2005</date>
<journal>Science Education,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="11350" citStr="Fang, 2005" startWordPosition="1741" endWordPosition="1742">octissimo.fr/ 8http://www.tabac-info-service.fr/ 9http://www.stop-tabac.ch/ 10http://www.diabete.qc.ca/ 3. we selected the best text segment pairs, that is the pairs with a similarity score equal or superior to 0.33, a threshold we determined based on the results of a preliminary study (Deléger and Zweigenbaum, 2008a). 2.3 Extracting paraphrases We are looking for paraphrases between two varieties of language (specialized and lay), as opposed to any kind of possible paraphrases. We therefore endeavoured to determine what kind of paraphrases may be relevant in this regard. A common hypothesis (Fang, 2005) is that specialized language uses more nominal constructions where lay language uses more verbs instead. We test this hypothesis and build on it to detect specialized-lay paraphrases around noun-to-verb mappings (a first version of this work was published in (Deléger and Zweigenbaum, 2008b)). A second hypothesis is that medical language contains a fair proportion of words from Latin and Greek origins, which are referred to as neo-classical compounds. The meaning of these words may be quite obscure to nonexperts readers. So one would expect to find less of these words in lay texts and instead </context>
<context position="28875" citStr="Fang, 2005" startWordPosition="4539" endWordPosition="4540">n the hypothesis that among relevant types were paraphrases involving nominalizations of verbal contructions, meaning that lay texts tend to use verb phrases where specialized texts use deverbal noun contructions. Our results seem to support this hypothesis. Such paraphrases therefore seem to be interesting advice to give to authors of lay texts. Future work includes testing our method on English and comparing the results for the two languages. We would expect them to be fairly similar since the tendency to use nominal constructions in scientific literature has also been observed for English (Fang, 2005). The second part of our work exploited the hypothesis that lay texts use modern-language expressions where specialized texts use neo-classical compound words. In this case, the paraphrases were too few to enable us to draw a significative conclusion. Testing this method on different and larger corpora might give more insight into the relevance of extracting this type of paraphrases. As it is, this work is still experimental and needs to be further investigated. 8 Diabetes Nicotine addiction Cancer S—*L L—*S S—*L L—*S S—*L L—*S # paraphrases 44 37 140 76 73 57 (|ParNs→Vl |or |ParNl→Vs|) # expe</context>
</contexts>
<marker>Fang, 2005</marker>
<rawString>Zhihui Fang. 2005. Scientific literacy: A systemic functional linguistics perspective. Science Education, 89(2):335–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nabil Hathout</author>
<author>Fiammetta Namer</author>
<author>Georgette Dal</author>
</authors>
<title>An Experimental Constructional Database: The MorTAL Project. In Many Morphologies,</title>
<date>2002</date>
<pages>178--209</pages>
<contexts>
<context position="12651" citStr="Hathout et al., 2002" startWordPosition="1948" endWordPosition="1951">paraphrases as a second type of specialized vs. lay correspondences. 2.3.1 Paraphrases of nominalizations A first type of paraphrases we tried to extract was paraphrases between nominal constructions in the specialized side (such as treatment of the disease) and verbal constructions in the lay side (such as the disease is treated). This type of paraphrases involves nominalizations of verbal phrases and is built around the relation between a deverbal noun (e.g. treatment) and its base verb (e.g. treat). Therefore, we relied on a lexicon of French deverbal nouns paired with corresponding verbs (Hathout et al., 2002) to detect such pairs in the corpus segments. These noun-verb pairs served as anchors for the detection of paraphrases. In order to design paraphrasing patterns we extracted all pairs of deverbal noun and verb with their contexts from the development corpus. The study of such pairs with their contexts allowed us to establish a set of lexico-syntactic paraphrasing patterns11. An example of such patterns can be seen in Table 1. 11Texts were first tagged with Treetagger (http://www. ims.uni-stuttgart.de/projekte/corplex/TreeTagger/). 4 Specialized Lay N1 PREP (DET) N2 V1 (DET) N2 N1 PREP (DET) N2</context>
</contexts>
<marker>Hathout, Namer, Dal, 2002</marker>
<rawString>Nabil Hathout, Fiammetta Namer, and Georgette Dal. 2002. An Experimental Constructional Database: The MorTAL Project. In Many Morphologies, pages 178–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Texttiling: Segmenting text into multi-paragraph subtopic passages.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="10247" citStr="Hearst, 1997" startWordPosition="1577" endWordPosition="1578">tructure (such as meta-information and density of HTML tags) and plain text (such as spotting phone and fax numbers and e-mails, as often appear at the end of documents) to get rid of boilerplate. 2.2 Aligning similar text segments We hypothesize that paraphrases will be found more reliably in text passages taken from both sides of our comparable corpora which address similar topics. So, as a first step, we tried to relate such passages. We proceeded in three steps: 1. as multiple topics are usually addressed in a single text, we performed topic segmentation on each text using the TextTiling (Hearst, 1997) segmentation tool. A segment may consist of one or several paragraphs; 2. we then tried to identify pairs of text segments addressing similar topics and likely to contain paraphrases. For this we used a common, vector-based measure of text similarity: the cosine similarity measure which we computed for each pair of topic segments in the cross-product of both corpus sides (each segment was represented as a bag of words); 5http://www.has-sante.fr/ 6http://www.inpes.sante.fr/ 7http://www.doctissimo.fr/ 8http://www.tabac-info-service.fr/ 9http://www.stop-tabac.ch/ 10http://www.diabete.qc.ca/ 3. w</context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Marti A. Hearst. 1997. Texttiling: Segmenting text into multi-paragraph subtopic passages. Computational Linguistics, 23(1):33–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali Ibrahim</author>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the second international workshop on Paraphrasing,</booktitle>
<pages>57--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2166" citStr="Ibrahim et al., 2003" startWordPosition="310" endWordPosition="313">es from various newspapers) or from different genres (such as specialized and lay texts) but dealing with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpo</context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Proceedings of the second international workshop on Paraphrasing, pages 57–64, Sapporo, Japan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>341--348</pages>
<location>College Park, Maryland.</location>
<contexts>
<context position="2542" citStr="Jacquemin, 1999" startWordPosition="364" endWordPosition="365">Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used monolingual parallel corpora, i.e. different translations or versions of the same texts. For instance (Barzilay and McKeown, 2001) detected paraphrases in a corpus of English translations of literary novels. However such corpora are no</context>
<context position="14031" citStr="Jacquemin, 1999" startWordPosition="2162" endWordPosition="2163">n, DET=determiner, 1 in index = pair of deverbal noun and verb) The general method was to look for corresponding content words (mainly noun and adjective) in the contexts. We defined corresponding words as either equal or synonymous (we used lexicons of synonyms as resources12). Equals may have either the same part-of-speech, or different parts-ofspeech, in which case stemming13 is performed to take care of derivational variation (e.g., medicine and medical). We then applied the patterns to both development and test corpora. The patterns thus designed are close to the transformation rules of (Jacquemin, 1999) who detects morpho-syntactico-semantic variants of terms in plain monolingual corpora. One difference is that our patterns are built around one specific type of morphological variation (noun to verb variation) that seemed relevant in the context of the specialized/lay opposition, as opposed to any possible variation. We also identify the paraphrases by comparing the two sides of a comparable corpus while (Jacquemin, 1999) starts from a given list of terms and searches for their variants in a plain monolingual corpus. Finally, we do not apply our method on terms specifically but on any express</context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Christian Jacquemin. 1999. Syntagmatic and paradigmatic representations of term variation. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pages 341–348, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Gregory Grefenstette</author>
</authors>
<title>Introduction to the special issue on the web as corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="6225" citStr="Kilgarriff and Grefenstette, 2003" startWordPosition="939" endWordPosition="943">sages which potentially convey comparable information (Section 2.2); and (iii) what sorts of paraphrases can be collected between these two types of discourse, which is addressed in Section 2.3, through the identification of two kinds of paraphrases: nominalization paraphrases and paraphrases of neo-classical compounds. An evaluation of the method (Section 2.4) is conducted and results are presented (Section 3) and discussed (Section 4). 2 Material and Methods 2.1 Building comparable corpora of lay and specialized texts Today, a popular way of acquiring a corpus is collecting it from the Web (Kilgarriff and Grefenstette, 2003), as it provides easy access to an unlimited amount of documents. Here we focus on monolingual comparable corpora of specialized and lay medical French documents, with the objective of identifying correspondences between the two varieties of languages in these documents. We collected three corpora from the Web dealing with the following three topics: nicotine addiction, diabetes and cancer. When dealing with a Web corpus several issues arise. The first one is the relevance of the documents retrieved to the domain targeted and is highly dependant on the method used to gather the documents. Poss</context>
</contexts>
<marker>Kilgarriff, Grefenstette, 2003</marker>
<rawString>Adam Kilgarriff and Gregory Grefenstette. 2003. Introduction to the special issue on the web as corpus. Computational Linguistics, 29(3):333–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurélien Max</author>
</authors>
<title>Local rephrasing suggestions for supporting the work of writers.</title>
<date>2008</date>
<booktitle>In Proceedings of GoTAL,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="3389" citStr="Max, 2008" startWordPosition="493" endWordPosition="494">onger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used monolingual parallel corpora, i.e. different translations or versions of the same texts. For instance (Barzilay and McKeown, 2001) detected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead on other types of corpora are actively investigated. Bilingual parallel corpora have been exploited for acquiring paraphrases in English (Bannard and Callison-Burch, 2005) and French (Max, 2008). Comparable corpora are another useful source of paraphrases. In this regard, only closely related corpora have been used, especially and almost exclusively corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapor</context>
</contexts>
<marker>Max, 2008</marker>
<rawString>Aurélien Max. 2008. Local rephrasing suggestions for supporting the work of writers. In Proceedings of GoTAL, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fiammetta Namer</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Acquiring meaning for French medical terminology: contribution of morphosemantics.</title>
<date>2004</date>
<pages>535--539</pages>
<editor>In Marius Fieschi, Enrico Coiera, and Yu-Chuan Jack Li, editors, MEDINFO,</editor>
<location>San Francisco.</location>
<marker>Namer, Zweigenbaum, 2004</marker>
<rawString>Fiammetta Namer and Pierre Zweigenbaum. 2004. Acquiring meaning for French medical terminology: contribution of morphosemantics. In Marius Fieschi, Enrico Coiera, and Yu-Chuan Jack Li, editors, MEDINFO, pages 535–539, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Peter Dienes</author>
</authors>
<title>Aligning needles in a haystack: Paraphrase acquisition across the web. In</title>
<date>2005</date>
<booktitle>Proceedings of IJCNLP,</booktitle>
<pages>119--130</pages>
<contexts>
<context position="2596" citStr="Pasca and Dienes, 2005" startWordPosition="371" endWordPosition="374">text. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detects term variants or (Pasca and Dienes, 2005) who extract paraphrases from random Web documents. This type of corpus does not insure the actual existence of paraphrases and a majority of methods have relied on corpora with a stronger similarity between the documents, thus likely to provide a greater amount of paraphrases. Some paraphrase approaches used monolingual parallel corpora, i.e. different translations or versions of the same texts. For instance (Barzilay and McKeown, 2001) detected paraphrases in a corpus of English translations of literary novels. However such corpora are not easily available and approaches which rely instead o</context>
</contexts>
<marker>Pasca, Dienes, 2005</marker>
<rawString>Marius Pasca and Peter Dienes. 2005. Aligning needles in a haystack: Paraphrase acquisition across the web. In Proceedings of IJCNLP, pages 119–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>320--322</pages>
<contexts>
<context position="1814" citStr="Rapp, 1995" startWordPosition="262" endWordPosition="263">lections of texts sharing common characteristics. Very often comparable corpora consist of texts in two (or more) languages that address the same topic without being translations of each other. But this notion also applies to monolingual texts. In a monolingual context, comparable corpora can be texts from different sources (such as articles from various newspapers) or from different genres (such as specialized and lay texts) but dealing with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text </context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, pages 320–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Paraphrase acquisition for information extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the second international workshop on Paraphrasing (IWP),</booktitle>
<pages>65--71</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="1952" citStr="Shinyama and Sekine, 2003" startWordPosition="280" endWordPosition="283">s that address the same topic without being translations of each other. But this notion also applies to monolingual texts. In a monolingual context, comparable corpora can be texts from different sources (such as articles from various newspapers) or from different genres (such as specialized and lay texts) but dealing with the same general topic. Comparable corpora have been used to perform several Natural Language Processing tasks, such as extraction of word translations (Rapp, 1995; Chiao and Zweigenbaum, 2002) in a multilingual context or acquisition of paraphrases (Barzilay and Lee, 2003; Shinyama and Sekine, 2003) in a monolingual context. In this work1, we are interested in using comparable corpora to extract paraphrases. Paraphrases are useful to various applications, including information retrieval (Ibrahim et al., 2003), information extraction (Shinyama and Sekine, 2003), document summarization (Barzilay, 2003) and text simplification (Elhadad and Sutaria, 2007). Several methods have been designed to extract paraphrases, many of them dealing with comparable text corpora. A few paraphrase acquisition approaches used plain monolingual corpora to detect paraphrases, such as (Jacquemin, 1999) who detec</context>
<context position="4173" citStr="Shinyama and Sekine, 2003" startWordPosition="612" endWordPosition="615">corpora of news sources reporting the 1This paper is an extension of the work presented in (Deléger and Zweigenbaum, 2008a) and (Deléger and Zweigenbaum, 2008b), more specifically, a new corpus is added, an additional type of paraphrase (based on neoclassical compounds) is extracted and the evaluation is more relevant. 2 Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 2–10, Suntec, Singapore, 6 August 2009. @c 2009 ACL and AFNLP same events. (Barzilay and Lee, 2003) generated paraphrase sentences from news articles using finite state automata. (Shinyama and Sekine, 2003) extracted paraphrases through the detection of named entities anchors in a corpus of Japanese news articles. In the medical domain, (Elhadad and Sutaria, 2007) worked with a comparable, almost parallel, corpus of medical scientific articles and their lay versions to extract paraphrases between specialized and lay languages. We aim at detecting paraphrases in medical corpora in the same line as (Elhadad and Sutaria, 2007) but for French. This type of paraphrases would be a useful resource for text simplification or to help authoring medical documents dedicated to the general public. However, i</context>
<context position="27184" citStr="Shinyama and Sekine, 2003" startWordPosition="4267" endWordPosition="4270">n methods to extract certain types of paraphrases that seemed relevant in the context of specialized and lay language: paraphrases based on nominalization vs. verbal constructions and paraphrases based on neo-classical compounds vs. modern-language expressions. The precision measured on the set of detected paraphrases is rather good, which indicates good quality of the paraphrases (hence of the paraphrasing patterns and extracted segments). An originality of this work lies in the fact that, in contrast to approaches working with more closely related comparable corpora (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Elhadad and Sutaria, 2007), we also gathered comparable corpora of documents which, although addressing the same general topics (nicotine addiction, diabetes), were a priori rather different since coming from various sources and targeted to different populations. We showed that simple paraphrase acquisition methods could also work on documents with a lesser degree of similarity, once similar segments were detected. Indeed the precision of the extracted paraphrases is within the same range for the three corpora we built, despite the fact that one corpus (the cancer corpus) was composed of mor</context>
</contexts>
<marker>Shinyama, Sekine, 2003</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2003. Paraphrase acquisition for information extraction. In Proceedings of the second international workshop on Paraphrasing (IWP), pages 65–71, Sapporo, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>