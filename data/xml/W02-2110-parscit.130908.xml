<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.915145">
Speech-Plans: Generating Evaluative Responses in Spoken Dialogue
</title>
<author confidence="0.630555">
M.A. Walker S. Whittaker A. Stent P. Maloor J.D. Moore M. Johnston G. Vasireddy
</author>
<affiliation confidence="0.4736265">
AT&amp;T Labs - Research
Florham Park, NJ, USA, 07932
</affiliation>
<email confidence="0.955137">
walker,stevew,pmaloor,johnston@research.att.com
</email>
<author confidence="0.4673255">
SUNY at Stony Brook
Stony Brook, NY, USA, 11794
</author>
<email confidence="0.865151">
stent@cs.sunysb.edu
</email>
<affiliation confidence="0.964917">
University of Edinburgh
</affiliation>
<address confidence="0.817591">
Edinburgh, Scotland, EH8 9LW
</address>
<email confidence="0.988765">
jmoore@cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.997132" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956666666666">
Recent work on evaluation of spoken dialogue
systems indicates that better algorithms are
needed for the presentation of complex in-
formation in speech. Current dialogue sys-
tems often rely on presenting sets of options
and their attributes sequentially. This places
a large memory burden on users, who have
to remember complex trade-offs between mul-
tiple options and their attributes. To address
these problems we build on previous work
using multiattribute decision theory to devise
speech-planning algorithms that present user-
tailored summaries, comparisons and recom-
mendations that allow users to focus on crit-
ical differences between options and their at-
tributes. We discuss the differences between
speech and text planning that result from the
particular demands of the speech situation.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.799241038461538">
Recent work on evaluating spoken dialogue systems sug-
gests that the information presentation phase of complex
dialogues is often the primary contributor to dialogue du-
ration (Walker et al., 2001). During this phase, the sys-
tem returns from a database query with a set of options
that match the user’s constraints (Figure 1). The user then
navigates through these options and refines them by offer-
ing new constraints. Depending on the number of options
returned, and the facilities provided for refinement, this
process may be quite onerous, leading to reduced user
satisfaction.
SYS: I found 9 round trips from Hartford to Orlando on
October 31st and returning Hartford on November
6th. For option 1, I have an outbound flight with U
S Air departing at 7 AM and arriving at 9 49 AM
non-stop. A return flight is with U S Air departing at
10 30 AM and arriving at 12 28 AM with 1 stopover.
Ticket price is 165 dollars. Please say next option or
flight details or I’ll take it.
USER: NEXT OPTION
SYS: For option 2, I have an outbound flight with U S Air
departing at 3 30 PM and arriving at 6 19 PM non-
stop. A return flight is with U S Air departing at
8 25 PM and arriving at 12 28 AM with 1 stopover.
Ticket price is 165 dollars. Say next option, or, flight
details, or, I’ll take it.
</bodyText>
<sectionHeader confidence="0.941167" genericHeader="method">
USER: NEXT OPTION
</sectionHeader>
<subsectionHeader confidence="0.418606">
Dialogue continues until user selects option
</subsectionHeader>
<figureCaption confidence="0.843969">
Figure 1: Information presentation phase of a Communi-
cator dialogue
</figureCaption>
<bodyText confidence="0.99616">
Even in multimodal dialogue systems, the information
presentation phase may still be laborious. For example,
consider a user’s request to Show Italian Restaurants in
the West Village in the MATCH (Multimodal Access To
City Help) dialogue system (Johnston et al., 2001). Fig-
ure 2 shows the large number of highlighted options gen-
erated in response. To make an informed choice, the user
has to access information about each restaurant by click-
ing on its icon.
In both types of dialogue system, the complexity of
having to sequentially access the set of returned options
</bodyText>
<figureCaption confidence="0.8568135">
Figure 2: MATCH’s graphical system response to Show
me Italian Restaurants in the West Village.
</figureCaption>
<bodyText confidence="0.999933341463415">
makes it hard for the user to remember information rele-
vant to making a decision. To reduce user memory load,
we need alternative strategies to sequential presentation.
In particular we require better algorithms for: (1) select-
ing the most relevant subset of options to mention, and
(2) choosing what to say about them. We need methods
to characterize the general properties of returned option
sets, and to highlight the options and attributes that are
most relevant to choosing between them.
Multi-attribute decision theory provides a detailed ac-
count of how models of user preferences can be used in
decision making (Keeney and Raiffa, 1976; Edwards and
Barron, 1994). By focusing on user preferences we can
present information that is both more concise and more
tailored to the user’s interests. Our work is an extension
of two lines of previous research that make direct use of
decision theory. Walker (1996) describes dialogue strate-
gies that (1) use decision theory to rank the options under
consideration; and (2) include content expressing an op-
tion’s utility in proposals. Carenini and Moore (2000)
apply decision theoretic models of user preferences to
the generation of textual evaluative arguments in the real-
estate domain.
We extend these techniques to the generation of
speech-plans intended to address the specific require-
ments of information presentation for complex spoken
or multimodal dialogues. We define multi-attribute de-
cision models of users’ preferences and use them to de-
vise speech-plans for SUMMARIZE, RECOMMEND and
COMPARE strategies that abstract, highlight and compare
small sets of user-relevant options and attributes. These
strategies both ensure that the discussed content is rele-
vant to users, and reduce the memory demands involved
in making complex decisions with speech or multimodal
data. These strategies are embodied in a speech-planning
module called SPUR (Speech-Planning with Utilities for
Restaurants) for the MATCH system.
In what follows we describe the development of multi-
attribute decision models for the restaurant domain and
the design and motivation of SPUR, and describe how
SPUR is integrated into the MATCH dialogue system.
</bodyText>
<sectionHeader confidence="0.9212045" genericHeader="method">
2 Multi-Attribute Decision Models in the
Restaurant Domain
</sectionHeader>
<bodyText confidence="0.984479418604651">
Multi-attribute decision models are based on the claim
that if anything is valued, it is valued for multiple rea-
sons (Keeney and Raiffa, 1976). In the restaurant do-
main, this implies that a user’s preferred restaurants op-
timize tradeoffs among restaurant attributes. To define
a model for the restaurant domain, we must determine
the attributes and their relative importance for particular
users. We use a standard procedure called SMARTER,
that has been shown to be a reliable and efficient way
of eliciting multi-attribute decision models for particular
users or user groups (Edwards and Barron, 1994).
The first step of the SMARTER procedure is to deter-
mine the structure of a tree model of the objectives in the
domain. In MATCH, the top-level objective is to select
a good restaurant. Six attributes contribute to this objec-
tive: the quantitative attributes food quality, cost, decor,
and service; and the categorical attributes food type and
neighborhood. These attributes are structured into a one-
level tree; the structure is user-independent with user-
dependent weights on the branches as explained below.
We apply this to a database of approximately 1000 restau-
rants populated with information freely available from
the web. Values for each of these attributes for each
restaurant are stored in the database.
The second step is to transform the real-domain val-
ues of attributes into single-dimension cardinal utilities
such that the highest attribute value is mapped to
100, the lowest attribute value to 0, and the others to val-
ues in the interval 0 to 100. In the restaurant database
food quality, service and decor range from 0 and 30, with
higher values more desirable, so 0 is mapped to 0 and
30 to 100 in our model. The cost attribute ranges from
$10 and $90 and higher values are less desirable, so $90
is mapped to 0 on the utility scale. Preferred values for
categorical attributes such as food type are mapped to 90,
dispreferred values to 10 and others to 50.
We next aggregate the vector of values into a
scalar in order to determine the overall utility of each
option. Heuristic tests applied to this domain suggest
that an additive model is a good approximation (See (Ed-
wards and Barron, 1994)). Thus, if ( = 1,2, H) is an
index identifying the restaurant options being evaluated,
( = 1,2, K) is an index of the attributes, and is
</bodyText>
<table confidence="0.998222">
User Food Service Decor Cost Nbhd FT Nbhd Likes Nbhd Dislikes FT Likes FT Dislikes
Quality
CK 0.41 0.10 0.03 0.16 0.06 0.24 Midtown, China- Harlem, Bronx Indian, Mexican, Vegetarian, Viet-
town, TriBeCa Chinese, Japanese, namese, Korean,
Seafood Hungarian, Ger-
man
OR 0.24 0.06 0.16 0.41 0.10 0.03 West Village, Upper East Side, French, Japanese, no-dislike
Chelsea, China- Upper West Side, Portugese, Thai,
town, TriBeCa, Uptown, Bronx, Middle Eastern
East Village Lower Manhattan
</table>
<figureCaption confidence="0.991521">
Figure 3: Sample User Models (Nbhd = Neighborhood; FT = Food Type)
</figureCaption>
<bodyText confidence="0.998455446808511">
the weight assigned to each attribute:
The final step of decision model construction is the as-
signment of weights to each attribute. Attribute
weights are user-specific, reflecting individual prefer-
ences about tradeoffs between options in the domain, and
are based on users’ subjective judgements. SMARTER’s
main advantage over other elicitation procedures is that
it only requires the user to specify the ranking of domain
attributes. Given the ranking, the weights are calculated
using the following equation, which guarantees that the
total sum of the weights add to 1, a requirement for multi-
attribute decision models:
SMARTER also specifies the standard form of ques-
tions used to elicit the rankings for a user model. We
implemented these as a sequence of web pages. The first
web page says Imagine that for whatever reason you’ve
had the horrible luck to have to eat at the worst possible
restaurant in the city. The price is 100 dollars per head,
you don’t like the type offood they have, you don’t like
the neighborhood, the food itself is terrible, the decor is
ghastly, and it has terrible service. Now imagine that a
goodfairy comes along who will grant you one wish, and
you can use that wish to improve this restaurant to the
best there is, but along only one of the following dimen-
sions. What dimension would you choose? Food Quality,
Service, Decor, Cost, Neighborhood, or Food Type? Af-
ter the user chooses an attribute, the scenario is repeated
omitting the chosen attribute, until all attributes have been
selected. Users are then asked to specify whether they
have any neighborhood or foodtype likes or dislikes.
To date, 29 different user models have been elicited
and stored in a database that SPUR accesses (see Figure
3, which shows attribute weightings and likes and dis-
likes for two users). For 25 of these users, we found
that cost and food quality are always in the top three at-
tributes, but their relative importance and that of other
attributes, such as decor, service, neighborhood and food
type, varies widely.
The user model reflects a user’s dispositional biases
about restaurant selection. These can be overridden by
situational constraints specified in a user query. For ex-
ample, as Figure 3 shows, some users express strong pref-
erences for particular food types, but these can be over-
ridden by simply requesting a different food type. Thus
dispositional biases never eliminate options from the set
of options returned by the database, they simply affect the
ranking of options.
</bodyText>
<sectionHeader confidence="0.992464" genericHeader="method">
3 The SPUR Speech planner
</sectionHeader>
<bodyText confidence="0.998187645161291">
SPUR takes as input: (1) a speech-plan goal; (2) a user
model; and (3) a set of restaurant options returned by the
database matching situational constraints specified in the
user’s query. The user model is used by SPUR to rank
the options returned from a database query and select the
content expressed about each option.
The aim of the speech-plan strategies is to filter the
information presented to the user so that only user-
relevant options and attributes are mentioned, contrasted
and highlighted. We defined three types of strategy for
SPUR: (1) RECOMMEND one of a selected set of restau-
rants; (2) COMPARE three or more selected restaurants;
(3) SUMMARIZE a selected set of restaurants. Each strat-
egy uses the overall utility to rank the options and the
weighted attribute values to select the content
for each option. For each response, SPUR outputs a:
speech-plan: a semantic representation of the se-
lected content items and the rhetorical relations
holding between them.
Template realization: a marked-up string to be
passed to the text-to-speech module;
The template-based realizer lexicalizes each attribute
value except for cost with a predicative adjective using
the following mapping: 0-13 mediocre; 14-16 de-
cent; 17-19 good; 20-22 very-good; 23-25 ex-
cellent; above 25 superb.
Carenini and Moore (2001; 2000) define a response as
tailored if it is based on a user’s known biases and pref-
erences. A response is concise if it includes only those
options with high utility, or possessing outliers with re-
spect to a population of attribute values. Conciseness is
highly desirable for speech. Because of the user’s mem-
ory load, we want to restrict the set of mentioned options
and attributes to those that are most important to the user.1
The weighted utility values for each attribute are a precise
prediction of how convincing an argument for an option
would be that includes the attribute’s content. We use the
z-score (standard value) of an option’s overall utility, or
of the weighted attribute value, to define an outlier:
The z-score expresses how many standard deviations
, a value, is away from the mean , of a population
of values . Depending on a threshhold for, different
numbers of options or attribute values are considered to
be worth mentioning. In the examples below is 1.0.
The population of values that are used to calculate
and can be (a) other attributes for the same option (for
RECOMMEND), or (b) the same attribute for other options
( for COMPARE).
We demonstrate below the differences in option rank-
ing and content selected for three different user models:
No-Model: Options are in the order that the database
returns them, and there is no ranking on the impor-
tance of attributes for each option.
CK: The user model for CK in Figure 3.
OR: The user model for OR in Figure 3.
The No-Model responses illustrate the default strategy.
They are neither tailored nor concise. We compare the
output for the CK and OR models because the different
ranking of attributes in these models leads to very differ-
ent responses. We first illustrate the effect of these user
models on option ranking and next present the RECOM-
MEND, COMPARE and SUMMARY strategies.
</bodyText>
<subsectionHeader confidence="0.997218">
3.1 The Effect of User Model on Option Ranking
</subsectionHeader>
<bodyText confidence="0.994890304347826">
To show the effects of user model on option ranking, we
present the restaurant options that match the query Show
Italian restaurants in the West Village in Figures 4 and 5
for the users CK and OR respectively. (We do not give
the No Model option here as this consists of a sequen-
tial recitation of the full option set presented in alpha-
betical order.) The first column gives the overall utility.
The other columns give the attribute values and weighted
utilities (WTD). Note that food quality contributes most
strongly to the CK model ranking, while cost contributes
most strongly to the OR model ranking. For example,
&apos;Carenini and Moore use the predicate notably-compelling
to describe such attributes.
consider the differences in overall ranking for Babbo and
Uguale for CK and OR resulting from different attribute
weightings. Babbo is fifth for OR because OR ranks food
quality second. Babbo’s 26 rating for food quality results
in 36 utils for CK, but only 21 utils for OR. Also, Babbo’s
price of $60 per person results in only 14 utils for OR; all
of the restaurants ranked higher by OR than Babbo’s are
less expensive. On the other hand, Uguale is more highly
ranked for OR than CK. This is mainly because its mod-
est price gets 28 utils for OR but only 11 for CK.
</bodyText>
<subsectionHeader confidence="0.997741">
3.2 Recommendations
</subsectionHeader>
<bodyText confidence="0.999882407407407">
The goal of a recommendation is to select the best op-
tion (based on overall utility) and provide convincing rea-
sons (based on weighted attribute values) for the user to
choose it. Figure 6 provides the algorithm for the REC-
OMMEND strategy. Sample responses for the No-Model,
CK and OR models are in Figure 7.
Consider the algorithm’s application with the OR
model (see Figure 5 for relevant values). Uguale is the
option with the highest utility ( = 69). The weighted
attribute values for Uguale are 17,4,9,28,9,2 for food
quality, service, decor, cost, neighborhood and food type
respectively. The z-scores (used for determining outliers)
are 0.57,-0.78,-0.26, 1.72,-0.26,-0.99. Only cost is men-
tioned in the recommendation, because only the z-score
of cost is greater than 1 (our setting for for these ex-
amples). A similar calculation leads to only food quality
being mentioned for CK. Our algorithm parameters are
tunable; we could redefine the value of to be 0.5 lead-
ing less extreme outliers to be mentioned.
As Figure 7 shows, the No-Model recommendation
is verbose and complex because there is no method for
highlighting relevant attributes. In contrast, the OR and
CK recommendations are shorter and clearer. Because
the system can identify outlier attributes, only attributes
that significantly contribute to an option’s utility are men-
tioned. The OR and CK recommendations differ because
different attributes are important for these two users.
</bodyText>
<listItem confidence="0.990695">
1. Select the restaurant option with highest overall utility
from returned options.
2. Identify the outliers among all the weighted attribute val-
ues for that option, using the threshold we have set for.
3. Lexicalize the real values for the outliers.
4. Generate the recommendation.
</listItem>
<figureCaption confidence="0.984305">
Figure 6: Algorithm for recommendation generation
</figureCaption>
<subsectionHeader confidence="0.859779">
3.3 Comparisons
</subsectionHeader>
<bodyText confidence="0.9878575">
The goal of a comparison is to generate several poten-
tial candidate options (those with highest overall utility)
</bodyText>
<table confidence="0.999256384615385">
Name Utility Food-Q Service Decor Cost Neighborhood Food Type (WTD)
(WTD) (WTD) (WTD) (WTD) (WTD)
Babbo 66 26(36) 24(8) 23(2) 60(5) W. Village (3) Italian (12)
Il Mulino 66 27(38) 23(7) 20(2) 65(4) W. Village (3) Italian (12)
Uguale 64 23(29) 22(7) 18(2) 33(11) W. Village (3) French, Italian (12)
Da Andrea 60 22(26) 21(6) 17(1) 28(12) W. Village (3) Italian (12)
John’s Pizzeria 59 22(26) 15(3) 13(1) 20(14) W. Village (3) Italian, Pizza (12)
Vittorio Cucina 57 22(26) 18(4) 19(2) 38(10) W. Village (3) Italian (12)
Cent’anni 56 22(26) 20(5) 15(1) 45(9) W. Village (3) Italian (12)
Marinella 56 21(24) 20(5) 17(1) 35(11) W. Village (3) Italian (12)
Bar Pitti 53 20(22) 17(4) 15(1) 31(11) W. Village (3) Italian (12)
Grand Ticino 50 19(19) 19(5) 17(1) 39(10) W. Village (3) Italian (12)
Arlecchino 48 18(17) 17(4) 15(1) 34(11) W. Village (3) Italian (12)
</table>
<figureCaption confidence="0.871122">
Figure 4: Restaurants ranked by CK model for query Italian Restaurants in the West Village; Domain attribute values
are given along with WTD = Weighted Utility for that attribute for the CK user model.
</figureCaption>
<table confidence="0.998766928571429">
Name Utility Food-Q Service Decor Cost Neighborhood Food Type (WTD)
(WTD) (WTD) (WTD) (WTD) (WTD)
Uguale 70 23(17) 22(4) 18(9) 33(28) W. Village (9) French, Italian (2)
Da Andrea 69 22(16) 21(4) 17(8) 28(31) W. Village (9) Italian (1)
John’s Pizzeria 68 22(16) 15(2) 13(5) 20(35) W. Village (9) Italian, Pizza (1)
Vittorio Cucina 64 22(16) 18(3) 19(9) 38(26) W. Village (9) Italian (1)
Babbo 62 26(21) 24(5) 23(12) 60(14) W. Village (9) Italian (1)
Marinella 62 21(14) 20(3) 17(8) 35(27) W. Village (9) Italian (1)
Trattoria Spaghetto 62 19(11) 17(2) 14(6) 25(33) W. Village (9) Italian (1)
Bar Pitti 61 20(13) 17(2) 15(7) 31(29) W. Village (9) Italian (1)
Cucina Stagionale 61 18(10) 15(2) 12(5) 23(34) W. Village (9) Italian (1)
Malatesta Trattoria 60 18(10) 16(2) 16(7) 28(31) W. Village (9) Italian (1)
Cent’anni 58 22(16) 20(3) 15(7) 45(22) W. Village (9) Italian (1)
Il Mulino 58 27(23) 23(4) 20(10) 65(11) W. Village (9) Italian (1)
</table>
<figureCaption confidence="0.98462">
Figure 5: Restaurants ranked by OR model for query Italian Restaurants in the West Village; Domain attribute values
are given along with WTD = Weighted Utility for that attribute for the OR user model.
</figureCaption>
<bodyText confidence="0.9061692">
User Recommend Output
No Bar Pitti has the best overall value among the se-
Model lected restaurants. Bar Pitti’s price is 31 dollars.
It has very good food quality and good service. It’s
in the West Village. It’s an Italian restaurant.
CK Babbo has the best overall value among the se-
lected restaurants. Babbo has superb food quality.
OR Uguale has the best overall value among the se-
lected restaurants. Da Andrea’s price is 33 dol-
lars.
</bodyText>
<figureCaption confidence="0.769596">
Figure 7: Recommendations for three different user mod-
els for a selection of Italian West Village restaurants
</figureCaption>
<bodyText confidence="0.999962272727273">
and weigh up the different reasons (expressed as differ-
ent weighted attribute values) for choosing each of them.
SPUR’s COMPARE strategy can be applied to three or
more options. If there are more than five, a subset are
first selected according the algorithm in Figure 8. Then
the content for each option is selected using the algorithm
in Figure 9. Because comparisons are inherently con-
trastive, the algorithm in Figure 9 describes a procedure
whereby if a weighted attribute value is an outlier for any
option, the attribute value is realized for all options.
Consider the algorithm in Figure 9 using the CK user
model (see Figure 4 for relevant values). The option se-
lection algorithm in Figure 8 determines that Babbo, Il
Mulino and Uguale are outliers for overall utility. Then z-
scores for the weighted attribute values are calculated for
each attribute across these options. The only attributes
whose values show significant variability are food qual-
ity, service and cost. Food quality is a negative outlier
for Uguale, service a positive outlier for Babbo, and cost
a positive outlier for Uguale. Thus these three attributes
are selected for the comparison, and their real values are
realized as in Figure 10. A similar calculation for the OR
model leads to the realization of the cost, food quality,
and decor attribute values.
Figure 10 illustrates the effect of user model on com-
parisons. The NoModel comparison has no utility model,
and hence no method for selecting outlier options or at-
tributes to be mentioned. Thus the first five restaurants
options returned are described, along with all their at-
tributes. In consequence the No-Model comparison is
lengthy and complex. The OR and CK descriptions are
shorter and focus on attributes that are both salient and
significant for the specific user.
</bodyText>
<subsectionHeader confidence="0.81842">
3.4 Summaries
</subsectionHeader>
<bodyText confidence="0.9999338">
The goal of a summary is to provide an overview of the
range of overall utility of the option set. It also describes
the dimensions along which elements of that set differ
with respect to their attribute values. The aim is to inform
users about both the range of choices and the range of rea-
</bodyText>
<subsectionHeader confidence="0.6325">
If the number of restaurants is greater than 5 then
</subsectionHeader>
<tableCaption confidence="0.625293">
– Output only those restaurants that are positive out-
liers for overall utility (outstanding restaurants)
– If there are no outstanding restaurants, output the top
5 in terms of utility value.
</tableCaption>
<figureCaption confidence="0.92703">
Figure 8: Algorithm for selecting a subset of options to
compare
</figureCaption>
<figure confidence="0.888481222222222">
1. For each option, for each attribute
(a) If the weighted attribute value is an outlier when
compared against the weighted attribute value for
other options, then add attribute to $OUTLIER-
LIST.
2. For each attribute in $OUTLIER-LIST,
(a) Lexicalize real values for the attribute;
(b) Order attributes to allow for aggregation;
(c) Generate description.
</figure>
<figureCaption confidence="0.995582">
Figure 9: Algorithm for selecting content for subset of
options to compare
</figureCaption>
<bodyText confidence="0.999892666666667">
sons for making those choices. SPUR therefore examines
the user-selected set of restaurants and determines which
attributes have the same values and which attributes have
different values. Then it simply states the ways in which
the restaurants are similar or different. Figure 11 shows
the algorithm for summary generation. Unlike the other
strategies, summaries do not use the weighted utilities for
calculations because of the potential for inconsistent lex-
icalizations of similarities and differences. Figure 12 il-
lustrates the effects of user model on summaries when Da
Andrea, Malatesta Trattoria, and Uguale are the selected
options.
</bodyText>
<sectionHeader confidence="0.996294" genericHeader="method">
4 Integration of Speech-Plans into
MATCH
</sectionHeader>
<bodyText confidence="0.959737264705882">
We have integrated SPUR into the MATCH multimodal
speech-enabled dialogue system. MATCH runs stan-
dalone on a Fujitsu PDA, providing users with mobile
access to information for New York City, and enabling
experimentation in realistic mobile settings (Figure 13).
Users interact with a multimodal user interface client
which displays a pan-able zoomable dynamic street map
of NYC. Users specify inputs via speech, gesture, hand-
writing or by a combination of these. Outputs are gener-
ated in speech, using a graphical display, or with a com-
bination of both these modes. Speech recognition is pro-
vided by AT&amp;T’s Watson engine, and TTS by AT&amp;T’s
Natural Voices. MATCH uses a finite-state approach
User Compare Three or More Strategy
No The first five restaurants follow. Bar Pitti’s price
Model is 31 dollars. It has very good food quality, good
service and decent decor. Arlecchino’s price is
34 dollars. It has good food quality, good ser-
vice and decent decor. Babbo’s price is 60 dol-
lars. It has superb food quality, excellent service
and excellent decor. Cent’anni’s price is 45 dol-
lars. It has very good food quality, very good
service and decent decor. Cucina Stagionale’s
price is 23 dollars. It has good food quality, de-
cent service and mediocre decor.
CK Among the selected restaurants, the following
offer exceptional overall value. Babbo’s price is
60 dollars. It has superb food quality, excellent
service and excellent decor. Il Mulino’s price is
65 dollars. It has superb food quality, excellent
service and very good decor. Uguale’s price is
33 dollars. It has excellent food quality, very
good service and good decor.
OR Among the selected restaurants, the following
offer exceptional overall value. Uguale’s price
is 33 dollars. It has good decor and very good
service. It’s a French, Italian restaurant. Da
Andrea’s price is 28 dollars. It has good decor
and very good service. It’s an Italian restau-
rant. John’s Pizzeria’s price is 20 dollars. It
has mediocre decor and decent service. It’s an
Italian, Pizza restaurant.
Figure 10: Comparisons for three different user models
for a selection of Italian West Village restaurants
to parse, integrate, and understand multimodal and uni-
modal inputs (Johnston and Bangalore, 2000). The mul-
timodal dialogue manager (MDM) is based on the notion
that each conversational move functions to transform the
information state. The state consists of a set of variables,
whose bindings are updated as the dialogue progresses.
Figure 14 shows a sample dialogue with MATCH us-
ing SPUR. The summary, comparison and recommenda-
tion examples are those presented above for OR. The aim
is to show these strategies in context in our working sys-
tem. In U1 the user specifies the query West Village Ital-
ian in speech. The system responds in S1 by presenting a
map of New York, zooming to the West Village and high-
lighting Italian restaurants. At this point, the user has too
many options to decide between and so s/he circles some
highlighted restaurants (Figure 15) and says summarize
(U2). The system then produces a summary (S2), high-
lighting options and attributes relevant to the user OR.
The user decides to select a different set with a gesture
(Figure 16) and compare them (U3). S3 is that compar-
ison. Since all the restaurants mentioned in S3 are ac-
ceptable the user asks the system to recommend one by
writing the word “recommend” (U4). The recommenda-
tion operates on the current dialogue context which is the
</bodyText>
<listItem confidence="0.96703">
2. Output similar attributes ordered by user rank.
3. Output different attributes ordered by user rank.
</listItem>
<figureCaption confidence="0.843719">
Figure 11: Algorithm for summary generation
</figureCaption>
<table confidence="0.998172875">
User Summary Output
No The 3 restaurants have the same price range of 28
Model to 33 dollars. They differ in food quality, service,
and decor.
CK The 3 restaurants have the same price range of 28
to 33 dollars. They differ in food quality.
OR The 3 restaurants have the same price range of 28
to 33 dollars. They differ in food quality and decor.
</table>
<figureCaption confidence="0.466543666666667">
Figure 12: Summaries for three different user models
when Da Andrea, Malatesta Trattoria, and Uguale are
selected.
</figureCaption>
<bodyText confidence="0.9996036">
selected set (from U3). This example shows how SPUR
allows users to finesse the problem of having too many
complex options to evaluate by presenting compact de-
scriptions, highlighting only those options and attributes
that are directly relevant to the user.
</bodyText>
<sectionHeader confidence="0.998177" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999907095238095">
This paper describes an approach to user-tailored gener-
ation of evaluative responses for spoken dialogue that is
based on quantitative user models. We address a press-
ing problem for current dialogue systems, namely that
sequential information presentation strategies overload
users, and do not effectively support them in making de-
cisions between complex options. We present new al-
gorithms for information presentation based on multi-
attribute decision theory that focus the presentation on
small sets of options and attributes that are significant and
salient to the user. These algorithms enable both option
and attribute selection for three different speech-plans:
summaries, recommendations and comparisons. They
have been implemented in SPUR, a speech-planner for
the MATCH dialogue system.
Much prior work that has applied models of user ex-
pertise or knowledge to the generation of tailored texts
(Cawsey, 1993; Paris, 1988) inter alia. Other previous
work has utilized models of users’ preferences or bi-
ases, and methods for automatically inferring such mod-
els from user actions (Morik,1989; Klein, 1994; Carenini
</bodyText>
<figureCaption confidence="0.960123">
Figure 13: MATCH running on Fujitsu PDA
</figureCaption>
<figure confidence="0.607091222222222">
U1 “show Italian restaurants in the West Village”
S1 [zooms to the West Village, displays Italian restaurants.
(Figure 2]
U2 [circles some highlighted restaurants and says “summa-
rize”. (Figure 15)]
S2 “The 3 restaurants have the same price range of 28 to
33 dollars. They differ in food quality and decor.”
U3 [circles a selection of restaurants and says “compare”
(Figure 16)]
</figure>
<figureCaption confidence="0.726667833333333">
S3 “Among the selected restaurants, the following offer ex-
ceptional overall value. Uguale’s price is 33 dollars. It
has excellent food quality and good decor. Da Andrea’s
price is 28 dollars. It has very good food quality and
good decor. John’s Pizzeria’s price is 20 dollars. It has
very good food quality and mediocre decor.”
</figureCaption>
<figure confidence="0.615702666666667">
U4 [writes word “recommend”]
S4 “Uguale has the best overall value among the selected
restaurants. Uguale’s price is 28 dollars.”
</figure>
<figureCaption confidence="0.996489">
Figure 14: Example dialogue with MATCH
</figureCaption>
<bodyText confidence="0.951615909090909">
and Moore, 2000; Carenini and Moore, 2001; Jameson et
al., 1995). Our work differs from these in focusing on
the particular demands of speech output, using directly
elicited models 2.
Our work is a direct extension of two lines of previ-
ous research. Walker (1996) describes speech-plans for
dialogue that (1) use decision theory to rank the options
under consideration; while (2) motivating an option’s ac-
ceptance by including content expressing its utility in
proposals for an option. Walker’s PROPOSE-EXPLICIT-
WARRANT strategy is similar to our RECOMMEND strat-
egy. We also build directly on Carenini and Moore’s text
generation algorithms for producing tailored and concise
arguments in the real-estate domain. However, this is
the first application of this approach to a speech-planning
2This direct elicitation procedure is appropriate for our ap-
plication as it is common for users to enroll with a spoken dia-
logue service.
1. For each attribute, for each option,
If attribute’s real-values all map to the same lexical
value, or if cost difference is less than 10 dollars,
then attribute is similar, otherwise it is different.
</bodyText>
<figureCaption confidence="0.989602666666667">
Figure 15: User circles subset for summary using a pen
gesture.
Figure 16: User circles subset for comparison.
</figureCaption>
<bodyText confidence="0.992624857142858">
module for a dialogue system where the requirements for
information presentation are different from when present-
ing text.
The requirements of spoken language, and our applica-
tion domain, required us to extend previous work to sup-
port the generation of both summaries and comparisons,
in addition to recommendations. One important contribu-
tion of this work is the definition of these new speech act
types. Furthermore this framework allows parameters of
the speech-plans to be highly configurable: by changing
the value of, we can experiment with different defini-
tions of the notion of outlier, and hence generate differ-
ently concise speech-plans, that highlight and compare
different sets of attributes and options.
Our initial results suggest that users should be able to
find a desirable option more efficiently using SPUR than
with existing methods. We are currently conducting a
user evaluation of SPUR to test this. We also hope to
enrich SPUR’s ability to structure the selected content,
and to interface SPUR to a sentence planner and surface
realizer.
</bodyText>
<sectionHeader confidence="0.997299" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909023255814">
G. Carenini and J.D. Moore. 2000. An empirical study
of the influence of argument conciseness on argument
effectiveness. In Proceedings of ACL 2000.
G. Carenini and J.D. Moore. 2001. An empirical study of
the influence of user tailoring on evaluative argument
effectiveness. In IJCAI, pages 1307–1314.
A. Cawsey. 1993. Planning interactive explanations. In-
ternational Journal of Man-Machine Studies, 38:169–
199.
W. Edwards and F.H. Barron. 1994. SMARTS and
SMARTER: Improved simple methods for multiat-
tribute utility measurement. Organizational Behavior
and Human Decision Processes, 60:306–325.
A. Jameson, R. Schafer, J. Simons, and T. Weis. 1995.
Adaptive provision of evaluation-oriented information:
Tasks and techniques. In IJCAI, pages 1886–1895.
M. Johnston and S. Bangalore. 2000. Finite-state mul-
timodal parsing and understanding. In Proceedings of
COLING 2000.
M. Johnston, S. Bangalore, and G. Vasireddy. 2001.
MATCH: Multimodal access to city help. In Auto-
matic Speech Recognition and Understanding Work-
shop, Trento, Italy.
R. Keeney and H. Raiffa. 1976. Decisions with Multi-
ple Objectives: Preferences and Value Tradeoffs. John
Wiley and Sons.
D. Klein. 1994. Decision Analytic Intelligent Systems:
Automated Explanation and Knowledge Acquisition.
Lawrence Erlbaum Associates.
K. Morik. 1989. User models and conversational set-
tings: Modeling the user’s wants. In A. Kobsa and
W. Wahlster, editors, User Models in Dialog Systems,
pages 364–385. Springer-Verlag.
C. Paris. 1988. Tailoring object descriptions to a
user’s level of expertise. Computational Linguistics,
14(3):64–78.
M. Walker, R. Passonneau, and J. Boland. 2001. Quanti-
tative and qualitative evaluation of DARPA communi-
cator spoken dialogue systems. In Proceedings ofACL
2001.
M. Walker. 1996. The effect of resource limits and task
complexity on collaborative planning in dialogue. Ar-
tificial Intelligence Journal, 85(1–2):181–243.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.681435">
<title confidence="0.999265">Speech-Plans: Generating Evaluative Responses in Spoken Dialogue</title>
<author confidence="0.999909">M A Walker S Whittaker A Stent P Maloor J D Moore M Johnston G Vasireddy</author>
<affiliation confidence="0.9988">AT&amp;T Labs - Research</affiliation>
<address confidence="0.998257">Florham Park, NJ, USA, 07932</address>
<email confidence="0.999716">walker,stevew,pmaloor,johnston@research.att.com</email>
<author confidence="0.821645">SUNY at Stony Brook Stony Brook</author>
<author confidence="0.821645">USA NY</author>
<email confidence="0.997606">stent@cs.sunysb.edu</email>
<affiliation confidence="0.999781">University of Edinburgh</affiliation>
<address confidence="0.997952">Edinburgh, Scotland, EH8</address>
<email confidence="0.998817">jmoore@cogsci.ed.ac.uk</email>
<abstract confidence="0.999748842105263">Recent work on evaluation of spoken dialogue systems indicates that better algorithms are needed for the presentation of complex information in speech. Current dialogue systems often rely on presenting sets of options and their attributes sequentially. This places a large memory burden on users, who have to remember complex trade-offs between multiple options and their attributes. To address these problems we build on previous work using multiattribute decision theory to devise that present usertailored summaries, comparisons and recommendations that allow users to focus on critical differences between options and their attributes. We discuss the differences between speech and text planning that result from the particular demands of the speech situation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J D Moore</author>
</authors>
<title>An empirical study of the influence of argument conciseness on argument effectiveness.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="4389" citStr="Carenini and Moore (2000)" startWordPosition="711" endWordPosition="714">ween them. Multi-attribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Keeney and Raiffa, 1976; Edwards and Barron, 1994). By focusing on user preferences we can present information that is both more concise and more tailored to the user’s interests. Our work is an extension of two lines of previous research that make direct use of decision theory. Walker (1996) describes dialogue strategies that (1) use decision theory to rank the options under consideration; and (2) include content expressing an option’s utility in proposals. Carenini and Moore (2000) apply decision theoretic models of user preferences to the generation of textual evaluative arguments in the realestate domain. We extend these techniques to the generation of speech-plans intended to address the specific requirements of information presentation for complex spoken or multimodal dialogues. We define multi-attribute decision models of users’ preferences and use them to devise speech-plans for SUMMARIZE, RECOMMEND and COMPARE strategies that abstract, highlight and compare small sets of user-relevant options and attributes. These strategies both ensure that the discussed content</context>
</contexts>
<marker>Carenini, Moore, 2000</marker>
<rawString>G. Carenini and J.D. Moore. 2000. An empirical study of the influence of argument conciseness on argument effectiveness. In Proceedings of ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J D Moore</author>
</authors>
<title>An empirical study of the influence of user tailoring on evaluative argument effectiveness.</title>
<date>2001</date>
<booktitle>In IJCAI,</booktitle>
<pages>1307--1314</pages>
<contexts>
<context position="12275" citStr="Carenini and Moore (2001" startWordPosition="1993" endWordPosition="1996">. Each strategy uses the overall utility to rank the options and the weighted attribute values to select the content for each option. For each response, SPUR outputs a: speech-plan: a semantic representation of the selected content items and the rhetorical relations holding between them. Template realization: a marked-up string to be passed to the text-to-speech module; The template-based realizer lexicalizes each attribute value except for cost with a predicative adjective using the following mapping: 0-13 mediocre; 14-16 decent; 17-19 good; 20-22 very-good; 23-25 excellent; above 25 superb. Carenini and Moore (2001; 2000) define a response as tailored if it is based on a user’s known biases and preferences. A response is concise if it includes only those options with high utility, or possessing outliers with respect to a population of attribute values. Conciseness is highly desirable for speech. Because of the user’s memory load, we want to restrict the set of mentioned options and attributes to those that are most important to the user.1 The weighted utility values for each attribute are a precise prediction of how convincing an argument for an option would be that includes the attribute’s content. We </context>
<context position="30106" citStr="Carenini and Moore, 2001" startWordPosition="4939" endWordPosition="4942">ty and decor.” U3 [circles a selection of restaurants and says “compare” (Figure 16)] S3 “Among the selected restaurants, the following offer exceptional overall value. Uguale’s price is 33 dollars. It has excellent food quality and good decor. Da Andrea’s price is 28 dollars. It has very good food quality and good decor. John’s Pizzeria’s price is 20 dollars. It has very good food quality and mediocre decor.” U4 [writes word “recommend”] S4 “Uguale has the best overall value among the selected restaurants. Uguale’s price is 28 dollars.” Figure 14: Example dialogue with MATCH and Moore, 2000; Carenini and Moore, 2001; Jameson et al., 1995). Our work differs from these in focusing on the particular demands of speech output, using directly elicited models 2. Our work is a direct extension of two lines of previous research. Walker (1996) describes speech-plans for dialogue that (1) use decision theory to rank the options under consideration; while (2) motivating an option’s acceptance by including content expressing its utility in proposals for an option. Walker’s PROPOSE-EXPLICITWARRANT strategy is similar to our RECOMMEND strategy. We also build directly on Carenini and Moore’s text generation algorithms f</context>
</contexts>
<marker>Carenini, Moore, 2001</marker>
<rawString>G. Carenini and J.D. Moore. 2001. An empirical study of the influence of user tailoring on evaluative argument effectiveness. In IJCAI, pages 1307–1314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cawsey</author>
</authors>
<title>Planning interactive explanations.</title>
<date>1993</date>
<journal>International Journal of Man-Machine Studies,</journal>
<volume>38</volume>
<pages>199</pages>
<contexts>
<context position="28945" citStr="Cawsey, 1993" startWordPosition="4753" endWordPosition="4754">ly support them in making decisions between complex options. We present new algorithms for information presentation based on multiattribute decision theory that focus the presentation on small sets of options and attributes that are significant and salient to the user. These algorithms enable both option and attribute selection for three different speech-plans: summaries, recommendations and comparisons. They have been implemented in SPUR, a speech-planner for the MATCH dialogue system. Much prior work that has applied models of user expertise or knowledge to the generation of tailored texts (Cawsey, 1993; Paris, 1988) inter alia. Other previous work has utilized models of users’ preferences or biases, and methods for automatically inferring such models from user actions (Morik,1989; Klein, 1994; Carenini Figure 13: MATCH running on Fujitsu PDA U1 “show Italian restaurants in the West Village” S1 [zooms to the West Village, displays Italian restaurants. (Figure 2] U2 [circles some highlighted restaurants and says “summarize”. (Figure 15)] S2 “The 3 restaurants have the same price range of 28 to 33 dollars. They differ in food quality and decor.” U3 [circles a selection of restaurants and says </context>
</contexts>
<marker>Cawsey, 1993</marker>
<rawString>A. Cawsey. 1993. Planning interactive explanations. International Journal of Man-Machine Studies, 38:169– 199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Edwards</author>
<author>F H Barron</author>
</authors>
<title>SMARTS and SMARTER: Improved simple methods for multiattribute utility measurement. Organizational Behavior and Human Decision Processes,</title>
<date>1994</date>
<pages>60--306</pages>
<contexts>
<context position="3951" citStr="Edwards and Barron, 1994" startWordPosition="640" endWordPosition="643">mation relevant to making a decision. To reduce user memory load, we need alternative strategies to sequential presentation. In particular we require better algorithms for: (1) selecting the most relevant subset of options to mention, and (2) choosing what to say about them. We need methods to characterize the general properties of returned option sets, and to highlight the options and attributes that are most relevant to choosing between them. Multi-attribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Keeney and Raiffa, 1976; Edwards and Barron, 1994). By focusing on user preferences we can present information that is both more concise and more tailored to the user’s interests. Our work is an extension of two lines of previous research that make direct use of decision theory. Walker (1996) describes dialogue strategies that (1) use decision theory to rank the options under consideration; and (2) include content expressing an option’s utility in proposals. Carenini and Moore (2000) apply decision theoretic models of user preferences to the generation of textual evaluative arguments in the realestate domain. We extend these techniques to the</context>
<context position="6125" citStr="Edwards and Barron, 1994" startWordPosition="973" endWordPosition="976">the Restaurant Domain Multi-attribute decision models are based on the claim that if anything is valued, it is valued for multiple reasons (Keeney and Raiffa, 1976). In the restaurant domain, this implies that a user’s preferred restaurants optimize tradeoffs among restaurant attributes. To define a model for the restaurant domain, we must determine the attributes and their relative importance for particular users. We use a standard procedure called SMARTER, that has been shown to be a reliable and efficient way of eliciting multi-attribute decision models for particular users or user groups (Edwards and Barron, 1994). The first step of the SMARTER procedure is to determine the structure of a tree model of the objectives in the domain. In MATCH, the top-level objective is to select a good restaurant. Six attributes contribute to this objective: the quantitative attributes food quality, cost, decor, and service; and the categorical attributes food type and neighborhood. These attributes are structured into a onelevel tree; the structure is user-independent with userdependent weights on the branches as explained below. We apply this to a database of approximately 1000 restaurants populated with information f</context>
<context position="7737" citStr="Edwards and Barron, 1994" startWordPosition="1248" endWordPosition="1252">ase food quality, service and decor range from 0 and 30, with higher values more desirable, so 0 is mapped to 0 and 30 to 100 in our model. The cost attribute ranges from $10 and $90 and higher values are less desirable, so $90 is mapped to 0 on the utility scale. Preferred values for categorical attributes such as food type are mapped to 90, dispreferred values to 10 and others to 50. We next aggregate the vector of values into a scalar in order to determine the overall utility of each option. Heuristic tests applied to this domain suggest that an additive model is a good approximation (See (Edwards and Barron, 1994)). Thus, if ( = 1,2, H) is an index identifying the restaurant options being evaluated, ( = 1,2, K) is an index of the attributes, and is User Food Service Decor Cost Nbhd FT Nbhd Likes Nbhd Dislikes FT Likes FT Dislikes Quality CK 0.41 0.10 0.03 0.16 0.06 0.24 Midtown, China- Harlem, Bronx Indian, Mexican, Vegetarian, Viettown, TriBeCa Chinese, Japanese, namese, Korean, Seafood Hungarian, German OR 0.24 0.06 0.16 0.41 0.10 0.03 West Village, Upper East Side, French, Japanese, no-dislike Chelsea, China- Upper West Side, Portugese, Thai, town, TriBeCa, Uptown, Bronx, Middle Eastern East Village</context>
</contexts>
<marker>Edwards, Barron, 1994</marker>
<rawString>W. Edwards and F.H. Barron. 1994. SMARTS and SMARTER: Improved simple methods for multiattribute utility measurement. Organizational Behavior and Human Decision Processes, 60:306–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jameson</author>
<author>R Schafer</author>
<author>J Simons</author>
<author>T Weis</author>
</authors>
<title>Adaptive provision of evaluation-oriented information: Tasks and techniques.</title>
<date>1995</date>
<booktitle>In IJCAI,</booktitle>
<pages>1886--1895</pages>
<contexts>
<context position="30129" citStr="Jameson et al., 1995" startWordPosition="4943" endWordPosition="4946"> a selection of restaurants and says “compare” (Figure 16)] S3 “Among the selected restaurants, the following offer exceptional overall value. Uguale’s price is 33 dollars. It has excellent food quality and good decor. Da Andrea’s price is 28 dollars. It has very good food quality and good decor. John’s Pizzeria’s price is 20 dollars. It has very good food quality and mediocre decor.” U4 [writes word “recommend”] S4 “Uguale has the best overall value among the selected restaurants. Uguale’s price is 28 dollars.” Figure 14: Example dialogue with MATCH and Moore, 2000; Carenini and Moore, 2001; Jameson et al., 1995). Our work differs from these in focusing on the particular demands of speech output, using directly elicited models 2. Our work is a direct extension of two lines of previous research. Walker (1996) describes speech-plans for dialogue that (1) use decision theory to rank the options under consideration; while (2) motivating an option’s acceptance by including content expressing its utility in proposals for an option. Walker’s PROPOSE-EXPLICITWARRANT strategy is similar to our RECOMMEND strategy. We also build directly on Carenini and Moore’s text generation algorithms for producing tailored a</context>
</contexts>
<marker>Jameson, Schafer, Simons, Weis, 1995</marker>
<rawString>A. Jameson, R. Schafer, J. Simons, and T. Weis. 1995. Adaptive provision of evaluation-oriented information: Tasks and techniques. In IJCAI, pages 1886–1895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>S Bangalore</author>
</authors>
<title>Finite-state multimodal parsing and understanding.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="25914" citStr="Johnston and Bangalore, 2000" startWordPosition="4254" endWordPosition="4257">ce and good decor. OR Among the selected restaurants, the following offer exceptional overall value. Uguale’s price is 33 dollars. It has good decor and very good service. It’s a French, Italian restaurant. Da Andrea’s price is 28 dollars. It has good decor and very good service. It’s an Italian restaurant. John’s Pizzeria’s price is 20 dollars. It has mediocre decor and decent service. It’s an Italian, Pizza restaurant. Figure 10: Comparisons for three different user models for a selection of Italian West Village restaurants to parse, integrate, and understand multimodal and unimodal inputs (Johnston and Bangalore, 2000). The multimodal dialogue manager (MDM) is based on the notion that each conversational move functions to transform the information state. The state consists of a set of variables, whose bindings are updated as the dialogue progresses. Figure 14 shows a sample dialogue with MATCH using SPUR. The summary, comparison and recommendation examples are those presented above for OR. The aim is to show these strategies in context in our working system. In U1 the user specifies the query West Village Italian in speech. The system responds in S1 by presenting a map of New York, zooming to the West Villa</context>
</contexts>
<marker>Johnston, Bangalore, 2000</marker>
<rawString>M. Johnston and S. Bangalore. 2000. Finite-state multimodal parsing and understanding. In Proceedings of COLING 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>S Bangalore</author>
<author>G Vasireddy</author>
</authors>
<title>MATCH: Multimodal access to city help. In Automatic Speech Recognition and Understanding Workshop,</title>
<date>2001</date>
<location>Trento, Italy.</location>
<contexts>
<context position="2886" citStr="Johnston et al., 2001" startWordPosition="465" endWordPosition="468">at 3 30 PM and arriving at 6 19 PM nonstop. A return flight is with U S Air departing at 8 25 PM and arriving at 12 28 AM with 1 stopover. Ticket price is 165 dollars. Say next option, or, flight details, or, I’ll take it. USER: NEXT OPTION Dialogue continues until user selects option Figure 1: Information presentation phase of a Communicator dialogue Even in multimodal dialogue systems, the information presentation phase may still be laborious. For example, consider a user’s request to Show Italian Restaurants in the West Village in the MATCH (Multimodal Access To City Help) dialogue system (Johnston et al., 2001). Figure 2 shows the large number of highlighted options generated in response. To make an informed choice, the user has to access information about each restaurant by clicking on its icon. In both types of dialogue system, the complexity of having to sequentially access the set of returned options Figure 2: MATCH’s graphical system response to Show me Italian Restaurants in the West Village. makes it hard for the user to remember information relevant to making a decision. To reduce user memory load, we need alternative strategies to sequential presentation. In particular we require better alg</context>
</contexts>
<marker>Johnston, Bangalore, Vasireddy, 2001</marker>
<rawString>M. Johnston, S. Bangalore, and G. Vasireddy. 2001. MATCH: Multimodal access to city help. In Automatic Speech Recognition and Understanding Workshop, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Keeney</author>
<author>H Raiffa</author>
</authors>
<title>Decisions with Multiple Objectives: Preferences and Value Tradeoffs.</title>
<date>1976</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="3924" citStr="Keeney and Raiffa, 1976" startWordPosition="636" endWordPosition="639">he user to remember information relevant to making a decision. To reduce user memory load, we need alternative strategies to sequential presentation. In particular we require better algorithms for: (1) selecting the most relevant subset of options to mention, and (2) choosing what to say about them. We need methods to characterize the general properties of returned option sets, and to highlight the options and attributes that are most relevant to choosing between them. Multi-attribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Keeney and Raiffa, 1976; Edwards and Barron, 1994). By focusing on user preferences we can present information that is both more concise and more tailored to the user’s interests. Our work is an extension of two lines of previous research that make direct use of decision theory. Walker (1996) describes dialogue strategies that (1) use decision theory to rank the options under consideration; and (2) include content expressing an option’s utility in proposals. Carenini and Moore (2000) apply decision theoretic models of user preferences to the generation of textual evaluative arguments in the realestate domain. We ext</context>
<context position="5664" citStr="Keeney and Raiffa, 1976" startWordPosition="902" endWordPosition="905">s involved in making complex decisions with speech or multimodal data. These strategies are embodied in a speech-planning module called SPUR (Speech-Planning with Utilities for Restaurants) for the MATCH system. In what follows we describe the development of multiattribute decision models for the restaurant domain and the design and motivation of SPUR, and describe how SPUR is integrated into the MATCH dialogue system. 2 Multi-Attribute Decision Models in the Restaurant Domain Multi-attribute decision models are based on the claim that if anything is valued, it is valued for multiple reasons (Keeney and Raiffa, 1976). In the restaurant domain, this implies that a user’s preferred restaurants optimize tradeoffs among restaurant attributes. To define a model for the restaurant domain, we must determine the attributes and their relative importance for particular users. We use a standard procedure called SMARTER, that has been shown to be a reliable and efficient way of eliciting multi-attribute decision models for particular users or user groups (Edwards and Barron, 1994). The first step of the SMARTER procedure is to determine the structure of a tree model of the objectives in the domain. In MATCH, the top-</context>
</contexts>
<marker>Keeney, Raiffa, 1976</marker>
<rawString>R. Keeney and H. Raiffa. 1976. Decisions with Multiple Objectives: Preferences and Value Tradeoffs. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
</authors>
<title>Decision Analytic Intelligent Systems: Automated Explanation and Knowledge Acquisition. Lawrence Erlbaum Associates.</title>
<date>1994</date>
<contexts>
<context position="29139" citStr="Klein, 1994" startWordPosition="4783" endWordPosition="4784">ts of options and attributes that are significant and salient to the user. These algorithms enable both option and attribute selection for three different speech-plans: summaries, recommendations and comparisons. They have been implemented in SPUR, a speech-planner for the MATCH dialogue system. Much prior work that has applied models of user expertise or knowledge to the generation of tailored texts (Cawsey, 1993; Paris, 1988) inter alia. Other previous work has utilized models of users’ preferences or biases, and methods for automatically inferring such models from user actions (Morik,1989; Klein, 1994; Carenini Figure 13: MATCH running on Fujitsu PDA U1 “show Italian restaurants in the West Village” S1 [zooms to the West Village, displays Italian restaurants. (Figure 2] U2 [circles some highlighted restaurants and says “summarize”. (Figure 15)] S2 “The 3 restaurants have the same price range of 28 to 33 dollars. They differ in food quality and decor.” U3 [circles a selection of restaurants and says “compare” (Figure 16)] S3 “Among the selected restaurants, the following offer exceptional overall value. Uguale’s price is 33 dollars. It has excellent food quality and good decor. Da Andrea’s </context>
</contexts>
<marker>Klein, 1994</marker>
<rawString>D. Klein. 1994. Decision Analytic Intelligent Systems: Automated Explanation and Knowledge Acquisition. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Morik</author>
</authors>
<title>User models and conversational settings: Modeling the user’s wants.</title>
<date>1989</date>
<booktitle>User Models in Dialog Systems,</booktitle>
<pages>364--385</pages>
<editor>In A. Kobsa and W. Wahlster, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<marker>Morik, 1989</marker>
<rawString>K. Morik. 1989. User models and conversational settings: Modeling the user’s wants. In A. Kobsa and W. Wahlster, editors, User Models in Dialog Systems, pages 364–385. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Paris</author>
</authors>
<title>Tailoring object descriptions to a user’s level of expertise.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="28959" citStr="Paris, 1988" startWordPosition="4755" endWordPosition="4756">m in making decisions between complex options. We present new algorithms for information presentation based on multiattribute decision theory that focus the presentation on small sets of options and attributes that are significant and salient to the user. These algorithms enable both option and attribute selection for three different speech-plans: summaries, recommendations and comparisons. They have been implemented in SPUR, a speech-planner for the MATCH dialogue system. Much prior work that has applied models of user expertise or knowledge to the generation of tailored texts (Cawsey, 1993; Paris, 1988) inter alia. Other previous work has utilized models of users’ preferences or biases, and methods for automatically inferring such models from user actions (Morik,1989; Klein, 1994; Carenini Figure 13: MATCH running on Fujitsu PDA U1 “show Italian restaurants in the West Village” S1 [zooms to the West Village, displays Italian restaurants. (Figure 2] U2 [circles some highlighted restaurants and says “summarize”. (Figure 15)] S2 “The 3 restaurants have the same price range of 28 to 33 dollars. They differ in food quality and decor.” U3 [circles a selection of restaurants and says “compare” (Fig</context>
</contexts>
<marker>Paris, 1988</marker>
<rawString>C. Paris. 1988. Tailoring object descriptions to a user’s level of expertise. Computational Linguistics, 14(3):64–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>R Passonneau</author>
<author>J Boland</author>
</authors>
<title>Quantitative and qualitative evaluation of DARPA communicator spoken dialogue systems.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="1398" citStr="Walker et al., 2001" startWordPosition="197" endWordPosition="200">. To address these problems we build on previous work using multiattribute decision theory to devise speech-planning algorithms that present usertailored summaries, comparisons and recommendations that allow users to focus on critical differences between options and their attributes. We discuss the differences between speech and text planning that result from the particular demands of the speech situation. 1 Introduction Recent work on evaluating spoken dialogue systems suggests that the information presentation phase of complex dialogues is often the primary contributor to dialogue duration (Walker et al., 2001). During this phase, the system returns from a database query with a set of options that match the user’s constraints (Figure 1). The user then navigates through these options and refines them by offering new constraints. Depending on the number of options returned, and the facilities provided for refinement, this process may be quite onerous, leading to reduced user satisfaction. SYS: I found 9 round trips from Hartford to Orlando on October 31st and returning Hartford on November 6th. For option 1, I have an outbound flight with U S Air departing at 7 AM and arriving at 9 49 AM non-stop. A r</context>
</contexts>
<marker>Walker, Passonneau, Boland, 2001</marker>
<rawString>M. Walker, R. Passonneau, and J. Boland. 2001. Quantitative and qualitative evaluation of DARPA communicator spoken dialogue systems. In Proceedings ofACL 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
</authors>
<title>The effect of resource limits and task complexity on collaborative planning in dialogue.</title>
<date>1996</date>
<journal>Artificial Intelligence Journal,</journal>
<pages>85--1</pages>
<contexts>
<context position="4194" citStr="Walker (1996)" startWordPosition="683" endWordPosition="684">t to say about them. We need methods to characterize the general properties of returned option sets, and to highlight the options and attributes that are most relevant to choosing between them. Multi-attribute decision theory provides a detailed account of how models of user preferences can be used in decision making (Keeney and Raiffa, 1976; Edwards and Barron, 1994). By focusing on user preferences we can present information that is both more concise and more tailored to the user’s interests. Our work is an extension of two lines of previous research that make direct use of decision theory. Walker (1996) describes dialogue strategies that (1) use decision theory to rank the options under consideration; and (2) include content expressing an option’s utility in proposals. Carenini and Moore (2000) apply decision theoretic models of user preferences to the generation of textual evaluative arguments in the realestate domain. We extend these techniques to the generation of speech-plans intended to address the specific requirements of information presentation for complex spoken or multimodal dialogues. We define multi-attribute decision models of users’ preferences and use them to devise speech-pla</context>
<context position="30328" citStr="Walker (1996)" startWordPosition="4979" endWordPosition="4980">good decor. Da Andrea’s price is 28 dollars. It has very good food quality and good decor. John’s Pizzeria’s price is 20 dollars. It has very good food quality and mediocre decor.” U4 [writes word “recommend”] S4 “Uguale has the best overall value among the selected restaurants. Uguale’s price is 28 dollars.” Figure 14: Example dialogue with MATCH and Moore, 2000; Carenini and Moore, 2001; Jameson et al., 1995). Our work differs from these in focusing on the particular demands of speech output, using directly elicited models 2. Our work is a direct extension of two lines of previous research. Walker (1996) describes speech-plans for dialogue that (1) use decision theory to rank the options under consideration; while (2) motivating an option’s acceptance by including content expressing its utility in proposals for an option. Walker’s PROPOSE-EXPLICITWARRANT strategy is similar to our RECOMMEND strategy. We also build directly on Carenini and Moore’s text generation algorithms for producing tailored and concise arguments in the real-estate domain. However, this is the first application of this approach to a speech-planning 2This direct elicitation procedure is appropriate for our application as i</context>
</contexts>
<marker>Walker, 1996</marker>
<rawString>M. Walker. 1996. The effect of resource limits and task complexity on collaborative planning in dialogue. Artificial Intelligence Journal, 85(1–2):181–243.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>