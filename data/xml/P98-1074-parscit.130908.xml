<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000081">
<title confidence="0.901165">
Flow Network Models for Word Alignment and Terminology
Extraction from Bilingual Corpora
</title>
<author confidence="0.865947">
Eric Gaussier
</author>
<affiliation confidence="0.73016">
Xerox Research Centre Europe 6, Chemin de Maupertuis 38240 Meylan F.
</affiliation>
<email confidence="0.508585">
Eric.Gaussier©xrce.xerox.com
</email>
<sectionHeader confidence="0.980224" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999934727272727">
This paper presents a new model for word align-
ments between parallel sentences, which allows
one to accurately estimate different parameters,
in a computationally efficient way. An applica-
tion of this model to bilingual terminology ex-
traction, where terms are identified in one lan-
guage and guessed, through the alignment pro-
cess, in the other one, is also described. An ex-
periment conducted on a small English-French
parallel corpus gave results with high precision,
demonstrating the validity of the model.
</bodyText>
<sectionHeader confidence="0.997665" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999231166666667">
Early works, (Gale and Church, 1993; Brown
et al., 1993), and to a certain extent (Kay and
ROscheisen, 1993), presented methods to ex-
tract 1-)lingual lexicons of words from a parallel
corpus, relying on the distribution of the words
in the set of parallel sentences (or other units).
(Brown et al., 1993) then extended their method
and established a sound probabilistic model se-
ries, relying on different parameters describing
how words within parallel sentences are aligned
to each other. On the other hand, (Dagan et
al., 1993) proposed an algorithm, borrowed to
the field of dynamic programming and based on
the output of their previous work, to find the
best alignment, subject to certain constraints,
between words in parallel sentences. A simi-
lar algorithm was used by (Vogel et al., 1996).
Investigating alignments at the sentence level
allows to clean and to refine the lexicons other-
wise extracted from a parallel corpus as a whole,.
pruning what (Melamed, 1996) calls &amp;quot;indirect
associations&amp;quot;.
Now, what differentiates the models and algo-
rithms proposed are the sets of parameters and
constraints they rely on, their ability to find an
appropriate solution under the constraints de-
fined and their ability to nicely integrate new
parameters. We want to present here a model of
the possible alignments in the form of flow net-
works. This representation allows to define dif-
ferent kinds of alignments and to find the most
probable or an approximation of this most prob-
able alignment, under certain constraints. Our
procedure presents the advantage of an accurate
modelling of the possible alignments, and can be
used on small corpora. We will introduce this
model in the next section. Section 3 describes a
particular use of this model to find term trans-
lations, and presents the results we obtained for
this task on a small corpus. Finally, the main
features of our work and the research directions
we envisage are summarized in the conlcusion.
</bodyText>
<sectionHeader confidence="0.78308" genericHeader="introduction">
2 Alignments and flow networks
</sectionHeader>
<bodyText confidence="0.999291">
Let us first consider the following aligned
sentences, with the actual alignment beween
words&apos;:
Assuming that we have probabilities of associ-
ating English and French words, one way to find
the preceding alignment is to search for the most
</bodyText>
<footnote confidence="0.95320025">
1A11 the examples consider English and French as the
source and target languages, even though the method
we propose is independent of the language pair under
consideration
</footnote>
<note confidence="0.478251">
The a lack cat eats the white mouse
</note>
<figure confidence="0.461725">
souris blanc
chat noir mange la
</figure>
<page confidence="0.996318">
444
</page>
<bodyText confidence="0.999975083333334">
probable alignment under the constraints that
any given English (resp. French) word is asso-
ciated to one and only one French (resp. En-
glish) word. We can view a connection between
an English and a French word as a flow going
from an English to a French word. The preced-
ing constraints state that the outgoing flow of
a,n English word and the ingoing one of a French
word must equal 1. We also have connections
entering the English words, from a source, and
leaving the French ones, to a sink, to control the
flow quantity we want to go through the words.
</bodyText>
<subsectionHeader confidence="0.986431">
2.1 Flow networks
</subsectionHeader>
<bodyText confidence="0.99616075">
We meet here the notion of flow networks that
we can formalise in the following way (we as-
sume that the reader has basic notions of graph
theory).
</bodyText>
<construct confidence="0.720649666666667">
Definition 1: let G = (V, E) be a directed
connected graph with m edges. A flow in G is
a vector
</construct>
<bodyText confidence="0.773552333333333">
= (P21 •••750772)T E Rm
(where T denotes the transpose of a matrix)
such as, for each vertex i E V:
</bodyText>
<equation confidence="0.998389">
E = EYu (1)
</equation>
<bodyText confidence="0.960468153846154">
where w+(i) denotes the set of edges entering
vertex i, whereas c.,./-(i) is the set of edges leav-
ing vertex i.
We can, furthermore, associate to each edge u
of G = (V, E) two numbers, bu and cu with
bu &lt; Cu, which will be called the lower capac-
ity bound and the upper capacity bound of the
edge.
Definition 2: let G = (V, E) be a directed
connected graph with lower and upper capacity
bounds. We will say that a flow (,9 in G is a
feasible flow in G if it satisfies the following
capacity constraints:
</bodyText>
<equation confidence="0.700122">
VuEE,bu &lt; cou &lt; cu (2)
</equation>
<bodyText confidence="0.9973426">
Finally, let us associate to each edge u of a di-
rected connected graph G = (V, E) with capac-
ity intervals [bu; Cu] a cost -yu, representing the
cost (or inversely the probability) to use this
edge in a flow. We can define the total cost,
</bodyText>
<equation confidence="0.852480333333333">
7 X v, associated to a flow co in G as follows:
X y = E -yu (3)
uEE
</equation>
<bodyText confidence="0.973813">
Definition 3: let G = (V, E) be a connected
graph with capacity intervals [b cub u E E and
costs 7,„ U E E. We will call minimal cost
flow the feasible flow in G for which -y x y is
minimal.
Several algorithms have been proposed to com-
pute the minimal cost flow when it exists. We
will not detail them here but refer the interested
reader to (Ford and Fulkerson, 1962; Klein,
1967).
</bodyText>
<subsectionHeader confidence="0.999038">
2.2 Alignment models
</subsectionHeader>
<bodyText confidence="0.999905882352941">
Flows and networks define a general framework
in which it is possible to model alignments be-
tween words, and to find, under certain con-
straints, the best alignment. We present now
an instance of such a model, where the only pa-
rameters involved are association probabil-
ities between English and French words, and
in which we impose that any English, respec-
tively French word, has to be aligned with one
and only one French, resp. English, word, possi-
bly empty. We can, of course, consider different
constraints. The constraints we define, though
they would yield to a complex computation for
the EM algorithm, do not privilege any direc-
tion in an underlying translation process.
This model defines for each pair of aligned
sentences a graph G(V, E) as follows:
</bodyText>
<listItem confidence="0.980105142857143">
• V comprises a source, a sink, all the English
and French words, an empty English word,
and an empty French word,
• E comprises edges from the source to all the
English words (including the empty one),
edges from all the French words (including
the empty one) to the sink, an edge from
the sink to the source, and edges from all
English words (including the empty one) to
all the French words (including the empty
one)2.
• from the source to all possible English
words (excluding the empty one), the ca-
pacity interval is [1;1],
</listItem>
<bodyText confidence="0.859274">
&apos;The empty words account for the fact that words
may not be aligned with other ones, i.e. they are not
explicitely translated for example.
</bodyText>
<page confidence="0.992912">
445
</page>
<listItem confidence="0.9143654">
• from the source to the empty English word,
the capacity interval is [0; max(le, f)1,
where If is the number of French words,
and le the number of English ones,
• from the English words (including the
empty one) to the French words (includ-
ing the empty one), the capacity interval is
[0;1],
• from the French words (excluding the
empty one) to the sink, the capacity inter-
val is [1:1],
• from the empty French word to the sink,
the capacity interval is [0; max(le,l f)],
• from the sink to the source, the capacity
interval is [0; max(le,l f)].
</listItem>
<bodyText confidence="0.999452666666667">
Once such a graph has been defined, we have
to assign cost values to its edges, to reflect
the different association probabilities. We will
now see how to define the costs so as to re-
late the minimal cost flow to a best alignment.
Let a be an alignment, under the above con-
straints, between the English sentence es, and
the French sentence f5. Such an alignment a
can be seen as a particular relation from the set
of English words with their positions, including
empty words, to the set of French words with
their positions, including empty words (in our
framework, it is formally equivalent to consider
a single empty word with larger upper capac-
ity bound or several ones with smaller upper
capacity bounds; for the sake of simplicity in
the formulas, we consider here that we add as
many empty words as necessary in the sentences
to end up with two sentences containing le + lj
words). An alignment thus connects each En-
glish word, located in position i, ei, to a French
word, in position j, h. We consider that the
probability of such a connection depends on two
distinct and independent probabilities, the one
of linking two positions, p(ap(i) = ai), and the
one of linking two words, p(a,,(ei) = fej). We
can then write:
</bodyText>
<equation confidence="0.992390833333333">
4+1 f
P(a, es, fs) = H pcap(i) = e,
L=1
ie+If
fJ p(a„(ei) = faika, e, f)r1) (4)
i=1
</equation>
<bodyText confidence="0.9948651">
where P(a, es, fs) is the probability of ob-
serving the alignment a together with
the English and French sentences, e,
and f, and (a, e, pri is a shorthand for
(a1, ai_1, el, .., fa,, ••1 fai-1)•
Since we simply rely in this model on asso-
ciation probabilities, that we assume to be in-
dependent, the only dependencies lying in the
possibilities to associate words across languages,
we can simplify the above formula and write:
</bodyText>
<equation confidence="0.99781">
le+1 f (5)
P(a, es, fs) = p(ei,faial-i
</equation>
<bodyText confidence="0.992734">
where 4-1 is a shorthand for (ai , ai_i).
p(ei, fes) is a shorthand for p(a,,(ei) = fa) that
we will use throughout the article. Due to the
=
constraints defined, we have: p(e 0 if
ai E a1, and p(ei, fa) otherwise.
Equation (5) shows that if we define the cost
associated to each edge from an English word ei
(excluding the empty word) to a French word
h (excluding the empty word) to be -y„ =
— lnp(ei, fi), the cost of an edge involving an
empty word to be c, an arbitrary small positive
value, and the cost of all the other edges (i.e. the
edges from SoP and SiP) to be 1 for example,
then the minimal cost flow defines the alignment
a for which P(a, es, f5) is maximum, under the
above constraints and approximations.
Wire can use the following general algorithm
based on maximum likelihood under the max-
imum approximation, to estimate the parame-
ters of our model:
</bodyText>
<listItem confidence="0.994917071428571">
1. set some initial value to the different pa-
rameters of the model,
2. for each sentence pair in the corpus, com-
pute the best alignment (or an approxi-
mation of this alignment) between words,
with respect to the model, and update the
counts of the different parameters with re-
spect to this alignment (the maximum like-
lihood estimators for model free distribu-
tions are based on relative frequencies, con-
ditioned by the set of best alignments in our
case),
3. go back to step 2 till an end condition is
reached.
</listItem>
<page confidence="0.997294">
446
</page>
<bodyText confidence="0.999970115384615">
This algorithm converges after a few itera-
tions. Here, we have to be carefull with step 1.
In particular, if we consider at the beginning
of the process all the possible alignments to be
equiprobable, then all the feasible flows are min-
imal cost flows. To avoid this situation, we have
to start with initial probabilities which make
use of the fact that some associations, occurring
more often in the corpus, should have a larger
probability. Probabilities based on relative fre-
quencies, or derived from the measure defined
in (Dunning, 1993), for example, allow to take
this fact into account.
We can envisage more complex models, in-
cluding distortion parameters, multiword no-
tions, or information on part-of-speech, infor-
mation derived from bilingual dictionaries or
from thesauri. The integration of new param-
eters is in general straigthforward. For multi-
word notions, we have to replace the capacity
values of edges connected to the source and the
sink with capacity intervals, which raises several
issues that we will not address in this paper. We
rather want to present now an application of the
flow network model to multilingual terminology
extraction.
</bodyText>
<sectionHeader confidence="0.9983455" genericHeader="method">
3 Multilingual terminology
extraction
</sectionHeader>
<bodyText confidence="0.999905279069767">
Several works describe methods to extract
terms, or candidate terms, in English and/or
French (Justeson and Katz, 1995; Daille, 1994;
Nkwenti-Azeh, 1992). Some more specific works
describe methods to align noun phrases within
parallel corpora (Kupiec, 1993). The under-
lying assumption beyond these works is that
the monolingually extracted units correspond to
each other cross-lingually. Unfortunately, this
is not always the case, and the above method-
ology suffers from the weaknesses pointed out
by (Wu, 1997) concerning parse-parse-match
procedures.
It is not however possible to fully reject
the notion of grammar for term extraction,
in so far as terms are highly characterized
by their internal syntactic structure. We can
also admit that lexical affinities between the
diverse constituents of a unit can provide a
good clue for termhood, but lexical affinities,
or otherwise called collocations, affect differ-
ent Linguistic units that need anyway be distin-
guished (Smadja, 1992).
Moreover, a study presented in (Gaussier,
1995) shows that terminology extraction in En-
glish and in French is not symmetric. In many
cases, it is possible to obtain a better approxi-
mation for English terms than it is for French
terms. This is partly due to the fact that
English relies on a composition of Germanic
type, as defined in (Chuquet and Paillard, 1989)
for example, to produce compounds, and of
Romance type to produce free NPs, whereas
French relies on Romance type for both, with
the classic PP attachment problems.
These remarks lead us to advocate a mixed
model, where candidate terms are identified in
English and where their French correspondent
is searched for. But since terms constitute rigid
units, lying somewhere between single word no-
tions and complete noun phrases, we should not
consider all possible French units, but only the
ones made of consecutive words.
</bodyText>
<subsectionHeader confidence="0.996624">
3.1 Model
</subsectionHeader>
<bodyText confidence="0.999981862068965">
It is possible to use flow network models to
capture relations between English and French
terms. But since we want to discover French
units, we have to add extra vertices and nodes
to our previous model, in order to account for
all possible combinations of consecutive French
words. We do that by adding several layers of
vertices, the lowest layer being associated with
the French words themselves, and each vertex
in any upper layer being linked to two consec-
utive vertices of the layer below. The uppest
layer contains only one vertex and can be seen
as representing the whole French sentence. We
will call a fertility graph the graph thus ob-
tained. Figure 1 gives an example of part of
a fertility graph (we have shown the flow val-
ues on each edge for clarity reasons; the brack-
ets delimit a nultiword candidate term; we have
not drawn the whole fertility graph encompass-
ing the French sentence, but only part of it,
the one encompassing the unit largeur de bande
utilisee, where the possible combinations of con-
secutive words are represented by A, B, and C).
Note that we restrict ourselves to lexical words
(nouns, verbs, adjectives and adverbs), not try-
ing to align grammatical words. Furthermore,
we rely on lemmas rather than inflected froms,
thus enabling us to conflate in one form all the
variants of a verb for example (we have keeped
</bodyText>
<page confidence="0.998508">
447
</page>
<figureCaption confidence="0.999632">
Figure 1: Pseudo-alignment within a fertility graph
</figureCaption>
<figure confidence="0.976690571428571">
dans
bandwidth used in
ix A \
\RA
largeur de bande utilisee
[ FSS telecommunications ]
les telecommunications SFS
</figure>
<bodyText confidence="0.9554376">
inflected forms in our figures for readability rea-
sons).
The minimal cost flow in the graphs thus de-
fined may not be directly usable. This is due to
two problems:
</bodyText>
<listItem confidence="0.9455112">
1. first, we can have ambiguous associations:
in figure 1, for example, the association be-
tween bandwidth and largeur de bande can
be obtained through the edge linking these
two units (type 1), or through two edges,
one from bandwidth to largeur de bande,
and one from bandwidth to either largeur
or bande (type 2), or even through the two
edges from bandwidth to largeur and bande
(type 3),
2. secondly, there may be conflicts between
connections: in figure 1 both largeur de
bande and telecommunications are linked to
bandwidth even though they are not con-
tiguous.
</listItem>
<bodyText confidence="0.9995192">
To solve ambiguous associations, we simply
replace each association of type 2 or 3 by the
equivalent type 1 association3. For conflicts, we
use the following heuristics: first select the con-
flicting edge with the lowest cost and assume
</bodyText>
<footnote confidence="0.774720666666667">
3We can formally define an equivalence relation, in
terms of the associations obtained, but this is beyond
the scope of this paper.
</footnote>
<bodyText confidence="0.999007">
that the association thus defined actually oc-
curred, then rerun the minimal cost flow algo-
rithm with this selected edge fixed once and for
all, and redo these two steps until there is no
more conflicting edges, replacing type 2 or 3 as-
sociations as above each time it is necessary.
Finally, the alignment obtained in this way
will be called a solved alignment4.
</bodyText>
<subsectionHeader confidence="0.99739">
3.2 Experiment
</subsectionHeader>
<bodyText confidence="0.9997938">
In order to test the previous model, we se-
lected a small bilingual corpus consisting of
1000 aligned sentences, from a corpus on satel-
lite telecommunications. We then ran the fol-
lowing algorithm, based on the previous model:
</bodyText>
<listItem confidence="0.990110727272727">
1. tag and lemmatise the English and French
texts, mark all the English candidate terms
using morpho-syntactic rules encoded in
regular expressions,
2. build a first set of association probabili-
ties, using the likelihood ratio test defined
in (Gaussier, 1995),
3. for each pair of aligned sentences, con-
struct the fertility graph allowing a candi-
date term of length n to be aligned with
units of lenth (n-2) to (n+2), define the
</listItem>
<footnote confidence="0.95632025">
4 Once the solved alignment is computed, it is possi-
ble to determine the word associations between aligned
units, through the application of the process described
in the previous section with multiword notions.
</footnote>
<page confidence="0.996051">
448
</page>
<bodyText confidence="0.985589647058823">
costs of edges linking English vertices to
French ones as the opposite of the loga-
rithm of the normalised sum of probabili-
ties of all possible word associations defined
by the edge (for the edge between multiple
(el) access (e2) to the French unit acces
(f1) mulitple (f2) it is (Eij p(ei, fj))),
all the other edges receive an arbitrary cost
value, compute the solved alignment, and
increment the count of the associations ob-
tained by overall value of the solved align-
ment,
4. select the fisrt 100 unit associations accord-
ing to their count, and consider them as
valid. Go back to step 2, excluding from
the search space the associations selected,
till all associations have been extracted.
</bodyText>
<subsectionHeader confidence="0.598563">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.999723">
To evaluate the results of the above procedure,
we manually checked each set of associations ob-
tained after each iteration of the process, going
from the first 100 to the first 500 associations.
We considered an association as being correct
if the French expression is a proper translation
of the English expression. The following table
gives the precision of the associations obtained.
</bodyText>
<table confidence="0.998931833333333">
N. Assoc. Prec.
100 98
200 97
300 96
400 95
500 90
</table>
<tableCaption confidence="0.999531">
Table 1: General results
</tableCaption>
<bodyText confidence="0.999963090909091">
The associations we are faced with represent
different linguistic units. Some consist of single
content words, whereas others represent multi-
word expressions. One of the particularity of
our process is precisely to automatically identify
multiword expressions in one language, know-
ing units in the other one. With respect to this
task, we extracted the first two hundred mul-
tiword expressions from the associations above,
and then checked wether they were valid or not.
We obtained the following results:
</bodyText>
<table confidence="0.903351333333333">
N. Assoc. Prec.
100 97
200 94
</table>
<tableCaption confidence="0.994948">
Table 2: Multiword notion results
</tableCaption>
<bodyText confidence="0.99974625">
As a comparison, (Kupiec, 1993) obtained a
precision of 90% for the first hundred associa-
tions between English and French noun phrases,
using the EM algorithm. Our experiments with
a similar method showed a precision around
92% for the first hundred associations on a set
of aligned sentences comprising the one used for
the above experiment.
An evaluation on single words, showed a pre-
cision of 98% for the first hundred and 97% for
the first two hundred. But these figures should
be seen in fact as lower bounds of actual val-
ues we can get, in so far as we have not tried
to extract single word associations from multi-
word ones. Here is an example of associations
obtained.
</bodyText>
<construct confidence="0.746554214285714">
telecommunication satellite
satelllite de telecommunication
communication satellite
satelllite de telecommunication
new satellite system
nouveau systeme de satellite
systeme de satellite nouveau
systeme de satellite entierement nouveau
operating fss telecommunication link
exploiter la liason de telecommunication du sfs
implement mise en oeuvre
wavelength longueur d&apos;onde
offer offrir, proposer
operation exploitation, operation
</construct>
<bodyText confidence="0.9999715">
The empty words (prepositions, determiners)
were extracted from the sentences. In all the
cases above, the use of prepositions and deter-
miners was consistent all over the corpus. There
are cases where two French units differ on a
preposition. In such a case, we consider that
we have two possible different translations for
the English term.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999968571428571">
We presented a new model for word alignment
based on flow networks. This model allows
us to integrate different types of constraints in
the search for the best word alignment within
aligned sentences. We showed how this model
can be applied to terminology extraction, where
candidate terms are extracted in one language,
</bodyText>
<page confidence="0.997747">
449
</page>
<bodyText confidence="0.9999708">
and discovered, through the alignment process,
in the other one. Our procedure presents three
main differences over other approaches: we do
not force term translations to fit within specific
patterns, we consider the whole sentences, thus
enabling us to remove some ambiguities, and we
rely on the association probabilities of the units
as a whole, but also on the association proba-
bilities of the elements within these units.
The main application of the work we have
described concerns the extraction of bilingual
lexicons. Such extracted lexicons can be used
in different contexts: as a source to help lexi-
cographers build bilingual dictionaries in techni-
cal domains, or as a resource for machine aided
human translation systems. In this last case,
we can envisage several ways to extend the no-
tion of translation unit in translation memory
systems, as the one proposed in (Lange et al.,
1997).
</bodyText>
<sectionHeader confidence="0.998969" genericHeader="acknowledgments">
5 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999786857142857">
Most of this work was done at the IBM-France
Scientific Centre during my PhD research, un-
der the direction of Jean-Marc Lange, to whom
I express my gratitude. Many thanks also to
Jean-Pierre Chanod, Andeas Eisele, David Hull,
and Christian Jacquemin for useful comments
on earlier versions.
</bodyText>
<sectionHeader confidence="0.999253" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998473985915494">
Peter F. Brown, Stephen A. Della Pietra, Vin-
cent J. Della Pietra, and Robert L. Mercer.
1993. The mathematics of statistical machine
translation: Parameter estimation. Compu-
tational Linguistics, 19(2).
H. Chuquet and M. PaiHard. 1989. Ap-
proche linguistique des problemes de traduc-
tion anglais-francais. Ophrys.
Ido Dagan, Kenneth W. Church, and
William A. Gale. 1993. Robust bilin-
gual word alignment for machine aided
translation. In Proceedings of the Workshop
on Very Large Corpora.
Beatrice Daille. 1994. Approche mixte pour
l&apos;extraction de terminologie : statistique lex-
icale et filtres linguistiques. Ph.D. thesis,
Univ. Paris 7.
T. Dunning. 1993. Accurate methods for the
statistics of surprise and coincidence. Com-
putational Linguistics, 19(1).
L.R. Ford and D.R. Fulkerson. 1962. Flows in
networks. Princeton University Press.
William Gale and Kenneth Church. 1993. A
program for aligning sentences in bilingual
corpora. Computational Linguistics, 19(1).
Eric Gaussier. 1995. Modeles statistiques et pa-
trons morphosyntaxiques pour l&apos;extraction de
lexiques bilingues de termes. Ph.D. thesis,
Univ. Paris 7.
John S. Justeson and Slava M. Katz. 1995.
Technical terminology: some linguistic prop-
erties and an algorithm for identification in
text. Natural Language Engineering, 1(1).
Martin Kay and M. ROscheisen. 1993. Text-
translation alignment. Computational Lin-
guistics, 19(1).
M. Klein. 1967. A primal method for minimal
cost flows, with applications to the assign-
ment and transportation problems. Manage-
ment Science.
Julian Kupiec. 1993. An algorithm for finding
noun phrase correspondences in bilingual cor-
pora. In Proceedings of the 31st Annual Meet-
ing of the Association for Computational Lin-
guistics.
Jean-Marc Lange, Eric Gaussier, and Beatrice
Dail 1997. Bricks and skeletons: some ideas
for the near future of maht. Machine Trans-
lation, 12(1).
Dan I. Melamed. 1996. Automatic construction
of clean broad-coverage translation lexicons.
In Proceedings of the Second Conference of
the Association for Machine Translation in
the Americas (AMTA).
Basile Nkwenti-Azeh. 1992. Positional and
combinational characteristics of satellite com-
munications terms. Technical report, CC1-
UMIST, Manchester.
Frank Smadja. 1992. How to compile a
bilingual collocational lexicon automatically.
In Proceedings of AAAI-92 Workshop on
Statistically-Based NLP techniques.
Stephan Vogel, Hermann Ney, and Christoph
Tillmann. 1996. Hmm-based word align-
ment in statistical translation. In Proceedings
of the Sixteenth International Conference on
Computational Linguistics.
Dekai Wu. 1997. Stochastic inversion trans-
duction grammars and bilingual parsing of
parallel corpora. Computational Linguistics,
23(3).
</reference>
<page confidence="0.997852">
450
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854373">
<title confidence="0.979353">Flow Network Models for Word Alignment and Terminology Extraction from Bilingual Corpora</title>
<author confidence="0.998397">Eric Gaussier</author>
<affiliation confidence="0.90247">Xerox Research Centre Europe 6, Chemin de Maupertuis 38240 Meylan F.</affiliation>
<email confidence="0.993527">Eric.Gaussier©xrce.xerox.com</email>
<abstract confidence="0.999065833333333">This paper presents a new model for word alignments between parallel sentences, which allows one to accurately estimate different parameters, in a computationally efficient way. An application of this model to bilingual terminology extraction, where terms are identified in one language and guessed, through the alignment process, in the other one, is also described. An experiment conducted on a small English-French parallel corpus gave results with high precision, demonstrating the validity of the model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="790" citStr="Brown et al., 1993" startWordPosition="115" endWordPosition="118"> Eric.Gaussier©xrce.xerox.com Abstract This paper presents a new model for word alignments between parallel sentences, which allows one to accurately estimate different parameters, in a computationally efficient way. An application of this model to bilingual terminology extraction, where terms are identified in one language and guessed, through the alignment process, in the other one, is also described. An experiment conducted on a small English-French parallel corpus gave results with high precision, demonstrating the validity of the model. 1 Introduction Early works, (Gale and Church, 1993; Brown et al., 1993), and to a certain extent (Kay and ROscheisen, 1993), presented methods to extract 1-)lingual lexicons of words from a parallel corpus, relying on the distribution of the words in the set of parallel sentences (or other units). (Brown et al., 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find th</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chuquet</author>
<author>M PaiHard</author>
</authors>
<title>Approche linguistique des problemes de traduction anglais-francais.</title>
<date>1989</date>
<journal>Ophrys.</journal>
<marker>Chuquet, PaiHard, 1989</marker>
<rawString>H. Chuquet and M. PaiHard. 1989. Approche linguistique des problemes de traduction anglais-francais. Ophrys.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Robust bilingual word alignment for machine aided translation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="1263" citStr="Dagan et al., 1993" startWordPosition="192" endWordPosition="195">gave results with high precision, demonstrating the validity of the model. 1 Introduction Early works, (Gale and Church, 1993; Brown et al., 1993), and to a certain extent (Kay and ROscheisen, 1993), presented methods to extract 1-)lingual lexicons of words from a parallel corpus, relying on the distribution of the words in the set of parallel sentences (or other units). (Brown et al., 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences. A similar algorithm was used by (Vogel et al., 1996). Investigating alignments at the sentence level allows to clean and to refine the lexicons otherwise extracted from a parallel corpus as a whole,. pruning what (Melamed, 1996) calls &amp;quot;indirect associations&amp;quot;. Now, what differentiates the models and algorithms proposed are the sets of parameters and constraints they rely on, their abi</context>
</contexts>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Ido Dagan, Kenneth W. Church, and William A. Gale. 1993. Robust bilingual word alignment for machine aided translation. In Proceedings of the Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Approche mixte pour l&apos;extraction de terminologie : statistique lexicale et filtres linguistiques.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ. Paris</institution>
<contexts>
<context position="11829" citStr="Daille, 1994" startWordPosition="2092" endWordPosition="2093">nformation derived from bilingual dictionaries or from thesauri. The integration of new parameters is in general straigthforward. For multiword notions, we have to replace the capacity values of edges connected to the source and the sink with capacity intervals, which raises several issues that we will not address in this paper. We rather want to present now an application of the flow network model to multilingual terminology extraction. 3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French (Justeson and Katz, 1995; Daille, 1994; Nkwenti-Azeh, 1992). Some more specific works describe methods to align noun phrases within parallel corpora (Kupiec, 1993). The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can als</context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>Beatrice Daille. 1994. Approche mixte pour l&apos;extraction de terminologie : statistique lexicale et filtres linguistiques. Ph.D. thesis, Univ. Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="11040" citStr="Dunning, 1993" startWordPosition="1971" endWordPosition="1972">n our case), 3. go back to step 2 till an end condition is reached. 446 This algorithm converges after a few iterations. Here, we have to be carefull with step 1. In particular, if we consider at the beginning of the process all the possible alignments to be equiprobable, then all the feasible flows are minimal cost flows. To avoid this situation, we have to start with initial probabilities which make use of the fact that some associations, occurring more often in the corpus, should have a larger probability. Probabilities based on relative frequencies, or derived from the measure defined in (Dunning, 1993), for example, allow to take this fact into account. We can envisage more complex models, including distortion parameters, multiword notions, or information on part-of-speech, information derived from bilingual dictionaries or from thesauri. The integration of new parameters is in general straigthforward. For multiword notions, we have to replace the capacity values of edges connected to the source and the sink with capacity intervals, which raises several issues that we will not address in this paper. We rather want to present now an application of the flow network model to multilingual termi</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Ford</author>
<author>D R Fulkerson</author>
</authors>
<title>Flows in networks.</title>
<date>1962</date>
<publisher>Princeton University Press.</publisher>
<contexts>
<context position="5327" citStr="Ford and Fulkerson, 1962" startWordPosition="939" endWordPosition="942">ected connected graph G = (V, E) with capacity intervals [bu; Cu] a cost -yu, representing the cost (or inversely the probability) to use this edge in a flow. We can define the total cost, 7 X v, associated to a flow co in G as follows: X y = E -yu (3) uEE Definition 3: let G = (V, E) be a connected graph with capacity intervals [b cub u E E and costs 7,„ U E E. We will call minimal cost flow the feasible flow in G for which -y x y is minimal. Several algorithms have been proposed to compute the minimal cost flow when it exists. We will not detail them here but refer the interested reader to (Ford and Fulkerson, 1962; Klein, 1967). 2.2 Alignment models Flows and networks define a general framework in which it is possible to model alignments between words, and to find, under certain constraints, the best alignment. We present now an instance of such a model, where the only parameters involved are association probabilities between English and French words, and in which we impose that any English, respectively French word, has to be aligned with one and only one French, resp. English, word, possibly empty. We can, of course, consider different constraints. The constraints we define, though they would yield t</context>
</contexts>
<marker>Ford, Fulkerson, 1962</marker>
<rawString>L.R. Ford and D.R. Fulkerson. 1962. Flows in networks. Princeton University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Gale</author>
<author>Kenneth Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="769" citStr="Gale and Church, 1993" startWordPosition="111" endWordPosition="114">pertuis 38240 Meylan F. Eric.Gaussier©xrce.xerox.com Abstract This paper presents a new model for word alignments between parallel sentences, which allows one to accurately estimate different parameters, in a computationally efficient way. An application of this model to bilingual terminology extraction, where terms are identified in one language and guessed, through the alignment process, in the other one, is also described. An experiment conducted on a small English-French parallel corpus gave results with high precision, demonstrating the validity of the model. 1 Introduction Early works, (Gale and Church, 1993; Brown et al., 1993), and to a certain extent (Kay and ROscheisen, 1993), presented methods to extract 1-)lingual lexicons of words from a parallel corpus, relying on the distribution of the words in the set of parallel sentences (or other units). (Brown et al., 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their prev</context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>William Gale and Kenneth Church. 1993. A program for aligning sentences in bilingual corpora. Computational Linguistics, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gaussier</author>
</authors>
<title>Modeles statistiques et patrons morphosyntaxiques pour l&apos;extraction de lexiques bilingues de termes.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ. Paris</institution>
<contexts>
<context position="12731" citStr="Gaussier, 1995" startWordPosition="2227" endWordPosition="2228">ys the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can also admit that lexical affinities between the diverse constituents of a unit can provide a good clue for termhood, but lexical affinities, or otherwise called collocations, affect different Linguistic units that need anyway be distinguished (Smadja, 1992). Moreover, a study presented in (Gaussier, 1995) shows that terminology extraction in English and in French is not symmetric. In many cases, it is possible to obtain a better approximation for English terms than it is for French terms. This is partly due to the fact that English relies on a composition of Germanic type, as defined in (Chuquet and Paillard, 1989) for example, to produce compounds, and of Romance type to produce free NPs, whereas French relies on Romance type for both, with the classic PP attachment problems. These remarks lead us to advocate a mixed model, where candidate terms are identified in English and where their Frenc</context>
<context position="17057" citStr="Gaussier, 1995" startWordPosition="2964" endWordPosition="2965">as above each time it is necessary. Finally, the alignment obtained in this way will be called a solved alignment4. 3.2 Experiment In order to test the previous model, we selected a small bilingual corpus consisting of 1000 aligned sentences, from a corpus on satellite telecommunications. We then ran the following algorithm, based on the previous model: 1. tag and lemmatise the English and French texts, mark all the English candidate terms using morpho-syntactic rules encoded in regular expressions, 2. build a first set of association probabilities, using the likelihood ratio test defined in (Gaussier, 1995), 3. for each pair of aligned sentences, construct the fertility graph allowing a candidate term of length n to be aligned with units of lenth (n-2) to (n+2), define the 4 Once the solved alignment is computed, it is possible to determine the word associations between aligned units, through the application of the process described in the previous section with multiword notions. 448 costs of edges linking English vertices to French ones as the opposite of the logarithm of the normalised sum of probabilities of all possible word associations defined by the edge (for the edge between multiple (el</context>
</contexts>
<marker>Gaussier, 1995</marker>
<rawString>Eric Gaussier. 1995. Modeles statistiques et patrons morphosyntaxiques pour l&apos;extraction de lexiques bilingues de termes. Ph.D. thesis, Univ. Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: some linguistic properties and an algorithm for identification in text.</title>
<date>1995</date>
<journal>Natural Language Engineering,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="11815" citStr="Justeson and Katz, 1995" startWordPosition="2088" endWordPosition="2091">tion on part-of-speech, information derived from bilingual dictionaries or from thesauri. The integration of new parameters is in general straigthforward. For multiword notions, we have to replace the capacity values of edges connected to the source and the sink with capacity intervals, which raises several issues that we will not address in this paper. We rather want to present now an application of the flow network model to multilingual terminology extraction. 3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French (Justeson and Katz, 1995; Daille, 1994; Nkwenti-Azeh, 1992). Some more specific works describe methods to align noun phrases within parallel corpora (Kupiec, 1993). The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structu</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: some linguistic properties and an algorithm for identification in text. Natural Language Engineering, 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
<author>M ROscheisen</author>
</authors>
<title>Texttranslation alignment.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="842" citStr="Kay and ROscheisen, 1993" startWordPosition="124" endWordPosition="127">per presents a new model for word alignments between parallel sentences, which allows one to accurately estimate different parameters, in a computationally efficient way. An application of this model to bilingual terminology extraction, where terms are identified in one language and guessed, through the alignment process, in the other one, is also described. An experiment conducted on a small English-French parallel corpus gave results with high precision, demonstrating the validity of the model. 1 Introduction Early works, (Gale and Church, 1993; Brown et al., 1993), and to a certain extent (Kay and ROscheisen, 1993), presented methods to extract 1-)lingual lexicons of words from a parallel corpus, relying on the distribution of the words in the set of parallel sentences (or other units). (Brown et al., 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, be</context>
</contexts>
<marker>Kay, ROscheisen, 1993</marker>
<rawString>Martin Kay and M. ROscheisen. 1993. Texttranslation alignment. Computational Linguistics, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Klein</author>
</authors>
<title>A primal method for minimal cost flows, with applications to the assignment and transportation problems.</title>
<date>1967</date>
<journal>Management Science.</journal>
<contexts>
<context position="5341" citStr="Klein, 1967" startWordPosition="943" endWordPosition="944">(V, E) with capacity intervals [bu; Cu] a cost -yu, representing the cost (or inversely the probability) to use this edge in a flow. We can define the total cost, 7 X v, associated to a flow co in G as follows: X y = E -yu (3) uEE Definition 3: let G = (V, E) be a connected graph with capacity intervals [b cub u E E and costs 7,„ U E E. We will call minimal cost flow the feasible flow in G for which -y x y is minimal. Several algorithms have been proposed to compute the minimal cost flow when it exists. We will not detail them here but refer the interested reader to (Ford and Fulkerson, 1962; Klein, 1967). 2.2 Alignment models Flows and networks define a general framework in which it is possible to model alignments between words, and to find, under certain constraints, the best alignment. We present now an instance of such a model, where the only parameters involved are association probabilities between English and French words, and in which we impose that any English, respectively French word, has to be aligned with one and only one French, resp. English, word, possibly empty. We can, of course, consider different constraints. The constraints we define, though they would yield to a complex co</context>
</contexts>
<marker>Klein, 1967</marker>
<rawString>M. Klein. 1967. A primal method for minimal cost flows, with applications to the assignment and transportation problems. Management Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>An algorithm for finding noun phrase correspondences in bilingual corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11954" citStr="Kupiec, 1993" startWordPosition="2109" endWordPosition="2110">ward. For multiword notions, we have to replace the capacity values of edges connected to the source and the sink with capacity intervals, which raises several issues that we will not address in this paper. We rather want to present now an application of the flow network model to multilingual terminology extraction. 3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French (Justeson and Katz, 1995; Daille, 1994; Nkwenti-Azeh, 1992). Some more specific works describe methods to align noun phrases within parallel corpora (Kupiec, 1993). The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can also admit that lexical affinities between the diverse constituents of a unit can provide a good clue for termhood, but lexical </context>
<context position="19209" citStr="Kupiec, 1993" startWordPosition="3325" endWordPosition="3326">eral results The associations we are faced with represent different linguistic units. Some consist of single content words, whereas others represent multiword expressions. One of the particularity of our process is precisely to automatically identify multiword expressions in one language, knowing units in the other one. With respect to this task, we extracted the first two hundred multiword expressions from the associations above, and then checked wether they were valid or not. We obtained the following results: N. Assoc. Prec. 100 97 200 94 Table 2: Multiword notion results As a comparison, (Kupiec, 1993) obtained a precision of 90% for the first hundred associations between English and French noun phrases, using the EM algorithm. Our experiments with a similar method showed a precision around 92% for the first hundred associations on a set of aligned sentences comprising the one used for the above experiment. An evaluation on single words, showed a precision of 98% for the first hundred and 97% for the first two hundred. But these figures should be seen in fact as lower bounds of actual values we can get, in so far as we have not tried to extract single word associations from multiword ones. </context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Julian Kupiec. 1993. An algorithm for finding noun phrase correspondences in bilingual corpora. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Marc Lange</author>
</authors>
<title>Eric Gaussier, and Beatrice Dail</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<volume>12</volume>
<issue>1</issue>
<marker>Lange, 1997</marker>
<rawString>Jean-Marc Lange, Eric Gaussier, and Beatrice Dail 1997. Bricks and skeletons: some ideas for the near future of maht. Machine Translation, 12(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan I Melamed</author>
</authors>
<title>Automatic construction of clean broad-coverage translation lexicons.</title>
<date>1996</date>
<booktitle>In Proceedings of the Second Conference of the Association for Machine Translation in the Americas (AMTA).</booktitle>
<contexts>
<context position="1705" citStr="Melamed, 1996" startWordPosition="266" endWordPosition="267">robabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences. A similar algorithm was used by (Vogel et al., 1996). Investigating alignments at the sentence level allows to clean and to refine the lexicons otherwise extracted from a parallel corpus as a whole,. pruning what (Melamed, 1996) calls &amp;quot;indirect associations&amp;quot;. Now, what differentiates the models and algorithms proposed are the sets of parameters and constraints they rely on, their ability to find an appropriate solution under the constraints defined and their ability to nicely integrate new parameters. We want to present here a model of the possible alignments in the form of flow networks. This representation allows to define different kinds of alignments and to find the most probable or an approximation of this most probable alignment, under certain constraints. Our procedure presents the advantage of an accurate mod</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>Dan I. Melamed. 1996. Automatic construction of clean broad-coverage translation lexicons. In Proceedings of the Second Conference of the Association for Machine Translation in the Americas (AMTA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Basile Nkwenti-Azeh</author>
</authors>
<title>Positional and combinational characteristics of satellite communications terms.</title>
<date>1992</date>
<tech>Technical report, CC1-UMIST,</tech>
<location>Manchester.</location>
<contexts>
<context position="11850" citStr="Nkwenti-Azeh, 1992" startWordPosition="2094" endWordPosition="2095">ived from bilingual dictionaries or from thesauri. The integration of new parameters is in general straigthforward. For multiword notions, we have to replace the capacity values of edges connected to the source and the sink with capacity intervals, which raises several issues that we will not address in this paper. We rather want to present now an application of the flow network model to multilingual terminology extraction. 3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French (Justeson and Katz, 1995; Daille, 1994; Nkwenti-Azeh, 1992). Some more specific works describe methods to align noun phrases within parallel corpora (Kupiec, 1993). The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can also admit that lexical </context>
</contexts>
<marker>Nkwenti-Azeh, 1992</marker>
<rawString>Basile Nkwenti-Azeh. 1992. Positional and combinational characteristics of satellite communications terms. Technical report, CC1-UMIST, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>How to compile a bilingual collocational lexicon automatically.</title>
<date>1992</date>
<booktitle>In Proceedings of AAAI-92 Workshop on Statistically-Based NLP techniques.</booktitle>
<contexts>
<context position="12682" citStr="Smadja, 1992" startWordPosition="2220" endWordPosition="2221">ross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can also admit that lexical affinities between the diverse constituents of a unit can provide a good clue for termhood, but lexical affinities, or otherwise called collocations, affect different Linguistic units that need anyway be distinguished (Smadja, 1992). Moreover, a study presented in (Gaussier, 1995) shows that terminology extraction in English and in French is not symmetric. In many cases, it is possible to obtain a better approximation for English terms than it is for French terms. This is partly due to the fact that English relies on a composition of Germanic type, as defined in (Chuquet and Paillard, 1989) for example, to produce compounds, and of Romance type to produce free NPs, whereas French relies on Romance type for both, with the classic PP attachment problems. These remarks lead us to advocate a mixed model, where candidate term</context>
</contexts>
<marker>Smadja, 1992</marker>
<rawString>Frank Smadja. 1992. How to compile a bilingual collocational lexicon automatically. In Proceedings of AAAI-92 Workshop on Statistically-Based NLP techniques.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>Hmm-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the Sixteenth International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1529" citStr="Vogel et al., 1996" startWordPosition="236" endWordPosition="239">arallel corpus, relying on the distribution of the words in the set of parallel sentences (or other units). (Brown et al., 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other. On the other hand, (Dagan et al., 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences. A similar algorithm was used by (Vogel et al., 1996). Investigating alignments at the sentence level allows to clean and to refine the lexicons otherwise extracted from a parallel corpus as a whole,. pruning what (Melamed, 1996) calls &amp;quot;indirect associations&amp;quot;. Now, what differentiates the models and algorithms proposed are the sets of parameters and constraints they rely on, their ability to find an appropriate solution under the constraints defined and their ability to nicely integrate new parameters. We want to present here a model of the possible alignments in the form of flow networks. This representation allows to define different kinds of </context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. Hmm-based word alignment in statistical translation. In Proceedings of the Sixteenth International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="12208" citStr="Wu, 1997" startWordPosition="2148" endWordPosition="2149"> flow network model to multilingual terminology extraction. 3 Multilingual terminology extraction Several works describe methods to extract terms, or candidate terms, in English and/or French (Justeson and Katz, 1995; Daille, 1994; Nkwenti-Azeh, 1992). Some more specific works describe methods to align noun phrases within parallel corpora (Kupiec, 1993). The underlying assumption beyond these works is that the monolingually extracted units correspond to each other cross-lingually. Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures. It is not however possible to fully reject the notion of grammar for term extraction, in so far as terms are highly characterized by their internal syntactic structure. We can also admit that lexical affinities between the diverse constituents of a unit can provide a good clue for termhood, but lexical affinities, or otherwise called collocations, affect different Linguistic units that need anyway be distinguished (Smadja, 1992). Moreover, a study presented in (Gaussier, 1995) shows that terminology extraction in English and in French is not symmetric.</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>