<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.358053">
<title confidence="0.993114">
Semantic Parsing with Combinatory Categorial Grammars
</title>
<author confidence="0.994594">
Yoav Artzi, Nicholas FitzGerald and Luke Zettlemoyer
</author>
<affiliation confidence="0.9954685">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.947698">
Seattle, WA 98195
</address>
<email confidence="0.999248">
{yoav,nfitz,lsz}@cs.washington.edu
</email>
<sectionHeader confidence="0.99863" genericHeader="abstract">
1 Abstract
</sectionHeader>
<bodyText confidence="0.999849166666667">
Semantic parsers map natural language sentences
to formal representations of their underlying
meaning. Building accurate semantic parsers
without prohibitive engineering costs is a long-
standing, open research problem.
The tutorial will describe general principles for
building semantic parsers. The presentation will
be divided into two main parts: modeling and
learning. The modeling section will include best
practices for grammar design and choice of se-
mantic representation. The discussion will be
guided by examples from several domains. To il-
lustrate the choices to be made and show how they
can be approached within a real-life representation
language, we will use λ-calculus meaning repre-
sentations. In the learning part, we will describe
a unified approach for learning Combinatory Cat-
egorial Grammar (CCG) semantic parsers, that in-
duces both a CCG lexicon and the parameters of
a parsing model. The approach learns from data
with labeled meaning representations, as well as
from more easily gathered weak supervision. It
also enables grounded learning where the seman-
tic parser is used in an interactive environment, for
example to read and execute instructions.
The ideas we will discuss are widely appli-
cable. The semantic modeling approach, while
implemented in λ-calculus, could be applied to
many other formal languages. Similarly, the al-
gorithms for inducing CCGs focus on tasks that
are formalism independent, learning the meaning
of words and estimating parsing parameters. No
prior knowledge of CCGs is required. The tuto-
rial will be backed by implementation and exper-
iments in the University of Washington Semantic
Parsing Framework (UW SPF).1
</bodyText>
<footnote confidence="0.93506">
1http://yoavartzi.com/spf
</footnote>
<sectionHeader confidence="0.962933" genericHeader="keywords">
2 Outline
</sectionHeader>
<listItem confidence="0.9727755">
1. Introduction to CCGs
2. Modeling
(a) Questions for database queries
(b) Plurality and determiner resolution in
grounded applications
(c) Event semantics and imperatives in in-
structional language
3. Learning
(a) A unified learning algorithm
(b) Learning with supervised data
i. Lexical induction with templates
ii. Unification-based learning
(c) Weakly supervised learning without la-
beled meaning representations
</listItem>
<sectionHeader confidence="0.997443" genericHeader="introduction">
3 Instructors
</sectionHeader>
<bodyText confidence="0.999265363636364">
Yoav Artzi is a Ph.D. candidate in the Computer
Science &amp; Engineering department at the Univer-
sity of Washington. His research studies the acqui-
sition of grounded natural language understanding
within interactive systems. His work focuses on
modeling semantic representations and designing
weakly supervised learning algorithms. He is a re-
cipient of the 2012 Yahoo KSC award.
Nicholas FitzGerald is a Ph.D. student at the
University of Washington. His research interests
are grounded natural language understanding and
generation. He is a recipient of an Intel Science
and Technology Center Fellowship and an NSERC
Postgraduate Scholarship.
Luke Zettlemoyer is an Assistant Professor in
the Computer Science &amp; Engineering department
at the University of Washington. His research in-
terests are in the intersections of natural language
processing, machine learning and decision mak-
ing under uncertainty. Honors include best paper
awards at UAI 2005 and ACL 2009, selection to
the DARPA CSSG, and an NSF CAREER Award.
</bodyText>
<page confidence="0.866136">
2
</page>
<reference confidence="0.780871">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, page 2,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.371328">
<title confidence="0.999235">Semantic Parsing with Combinatory Categorial Grammars</title>
<author confidence="0.975007">Nicholas FitzGerald Artzi</author>
<affiliation confidence="0.99972">Computer Science &amp; University of</affiliation>
<address confidence="0.977378">Seattle, WA</address>
<abstract confidence="0.974668243243243">1 Abstract Semantic parsers map natural language sentences to formal representations of their underlying meaning. Building accurate semantic parsers without prohibitive engineering costs is a longstanding, open research problem. The tutorial will describe general principles for building semantic parsers. The presentation will be divided into two main parts: modeling and learning. The modeling section will include best practices for grammar design and choice of semantic representation. The discussion will be guided by examples from several domains. To illustrate the choices to be made and show how they can be approached within a real-life representation we will use meaning representations. In the learning part, we will describe a unified approach for learning Combinatory Categorial Grammar (CCG) semantic parsers, that induces both a CCG lexicon and the parameters of a parsing model. The approach learns from data with labeled meaning representations, as well as from more easily gathered weak supervision. It enables where the semantic parser is used in an interactive environment, for example to read and execute instructions. The ideas we will discuss are widely applicable. The semantic modeling approach, while in could be applied to many other formal languages. Similarly, the algorithms for inducing CCGs focus on tasks that are formalism independent, learning the meaning of words and estimating parsing parameters. No prior knowledge of CCGs is required. The tutorial will be backed by implementation and experiments in the University of Washington Semantic Framework (UW</abstract>
<intro confidence="0.79584">2 Outline</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>2</pages>
<marker></marker>
<rawString>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, page 2,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bulgaria Sofia</author>
</authors>
<date>2013</date>
<booktitle>c�2013 Association for Computational Linguistics</booktitle>
<marker>Sofia, 2013</marker>
<rawString>Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>