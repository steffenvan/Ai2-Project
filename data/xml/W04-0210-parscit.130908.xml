<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000103">
<title confidence="0.981949">
Discourse Annotation and Semantic Annotation in the GNOME Corpus
</title>
<author confidence="0.997816">
Massimo Poesio
</author>
<affiliation confidence="0.787123">
University of Essex,
Department of Computer Science and Centre for Cognitive Science,
United Kingdom
</affiliation>
<sectionHeader confidence="0.980489" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999252">
The GNOME corpus was created to study the dis-
course and semantic properties of discourse entities
that affect their realization and interpretation, and
particularly salience. We discuss what information
was annotated and the methods we followed.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952282051282">
The GNOME corpus was created to study the as-
pects of discourse that appear to affect generation,
especially salience (Pearson et al., 2000; Poesio and
Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio
et al., 2004b). Particular attention was paid to the
factors affecting the generation of pronouns (Pear-
son et al., 2000; Henschel et al., 2000), demon-
stratives (Poesio and Nygren-Modjeska, To appear)
possessives (Poesio and Nissim, 2001) and definites
in general (Poesio, 2004a). These results, and the
annotated corpus, were used in the development of
both symbolic and statistical natural language gen-
eration algorithms for sentence planning (Poesio,
2000a; Henschel et al., 2000; Cheng et al., 2001),
aggregation (Cheng, 2001) and text planning (Kara-
manis, 2003). The empirical side of the project in-
volved both psychological experiments and corpus
annotation, based on a scheme based on the MATE
proposals, as well as on a detailed annotation man-
ual (Poesio, 2000b), the reliability of whose instruc-
tions was tested by extensive experiments (Poe-
sio, 2000a). More recently, the corpus has also
been used to develop and evaluate anaphora resolu-
tion systems, with a special focus on the resolution
of bridging references (Poesio, 2003; Poesio and
Alexandrov-Kabadjov, 2004; Poesio et al., 2004a)
Although the results of the studies using the
GNOME corpus mentioned above have been pub-
lished in a number of papers, and although a de-
tailed annotation manual was written and has been
available on the Web for a few years (Poesio,
2000b), none of the previously published papers dis-
cusses in detail the goals of the annotation and the
methodology that was followed, especially for the
non-anaphoric aspects. In this paper we discuss the
methods used to identify possible ‘utterances,’ the
properties of NPs and discourse entities that were
annotated, and (very briefly) anaphoric information.
.
</bodyText>
<sectionHeader confidence="0.979973" genericHeader="introduction">
2 The Data
</sectionHeader>
<bodyText confidence="0.999925736842105">
Texts from three domains were (partially) anno-
tated. The museum subcorpus consists of descrip-
tions of museum objects and brief texts about the
artists that produced them.1 The pharmaceutical
subcorpus is a selection of leaflets providing the
patients with legally mandatory information about
their medicine.2 The GNOME corpus also includes
tutorial dialogues from the Sherlock corpus col-
lected at the University of Pittsburgh. Each sub-
corpus contains about 6,000 NPs, but not all types
of annotation have been completed for all domains.
All sentences, units and NPs have been identified,
and all ‘syntactic’ properties of NPs (agreement fea-
ture and grammatical function). Anaphoric rela-
tions have been annotated in about half of the texts
in each domain; and the more complex semantic
properties (taxonomic properties, genericity, etc.) in
about 25% of these texts. The total size of the anno-
tated corpus is about 60K.
</bodyText>
<sectionHeader confidence="0.998218" genericHeader="method">
3 Identifying Utterances
</sectionHeader>
<bodyText confidence="0.9924475">
In order to use a corpus to study salience, it is es-
sential to find a way to annotate what in Center-
</bodyText>
<footnote confidence="0.873818285714286">
1The museum subcorpus extends the corpus collected to
support the ILEX and SOLE projects at the University of Ed-
inburgh (Oberlander et al., 1998).
2The leaflets in the pharmaceutical subcorpus are a subset
of the collection of all patient leaflets in the UK which was
digitized to support the ICONOCLAST project at the University
of Brighton (Scott et al., 1998).
</footnote>
<bodyText confidence="0.99907936">
ing theory (Grosz et al., 1995) are called UTTER-
ANCES, i.e., the units of text after which the local
focus is updated. In most annotations concerned
with salience, a predefined notion of utterance was
adopted, typically sentences (Miltsakaki, 2002) or
(finite) clauses (Kameyama, 1998). This approach,
however, precludes using the corpus to compare
possible definitions of utterance, one of the goals
of the GNOME annotation (Poesio et al., 2004b).
In order to do this, we marked all spans of text
that might be claimed to update the local focus, in-
cluding sentences (defined as all units of text ending
with a full stop, a question mark, or an exclama-
tion point) as well as what we called (DISCOURSE)
UNITS. Units include clauses (defined as sequences
of text containing a verbal complex, all its oblig-
atory arguments, and all postverbal adjuncts) as
well as other sentence subconstituents that might
be viewed as independently updating the local fo-
cus, such as parentheticals, preposed PPs, and (the
second element of) coordinated VPs. Examples of
clauses, verbal and non-verbal parentheticals, and
preposed PPs marked as units follow; the parenthe-
ses indicate unit boundaries. (Sentence boundaries
are not indicated.)
</bodyText>
<listItem confidence="0.984571">
(1) a. clausal unit with non-verbal parentheti-
cal: (It’s made in the shape of a real object
(– a violin))
</listItem>
<bodyText confidence="0.920174315789474">
b. clausal unit with preposed PP and em-
bedded relative clauses: ((With the de-
velopment of heraldry in the later Middle
Ages in Europe as a means of identifica-
tion), all (who were entitled (to bear arms))
wore signet-rings (engraved with their ar-
morial bearings))
As example (1b) above illustrates, subordinate units
such as clausal complements and relative clauses
were enclosed within the superordinate unit. Sub-
ordinate units also include adjunct clauses headed
by connectives such as before, after, because and
clauses in subject position. In total, the texts used
for the main study contain 505 sentences and more
than 1,000 units, including 900 finite clauses.3
Sentence and Unit Attributes Sentences have
one attribute, STYPE, specifying whether the sen-
tence is declarative, interrogative, imperative, or ex-
clamative. The attributes of units include:
</bodyText>
<listItem confidence="0.9744085">
• UTYPE: whether the unit is a main clause,
a relative clause, appositive, a parenthet-
</listItem>
<footnote confidence="0.996661666666667">
3Our instructions for marking up such elements benefited
from the discussion of clauses in (Quirk and Greenbaum, 1973)
and Marcu’s proposals for discourse units annotation (1999).
</footnote>
<bodyText confidence="0.974031571428571">
ical, etc. The possible values for this
attribute are main, relative, such-as,
appositive, parenthetical,
paren-rel, paren-app, paren-
main, subject, complement, adjunct,
coord-vp,preposed-pp, listitem,
cleft, title, disc-marker.
</bodyText>
<listItem confidence="0.953611714285714">
• VERBED: whether the unit contains a verb.
• FINITE: for verbed units, whether the verb is
finite or not.
• SUBJECT: for verbed units, whether they have
a full subject, an empty subject (expletive, as in
there sentences), or no subject (e.g., for infini-
tival clauses).
</listItem>
<bodyText confidence="0.9991533125">
Annotation Issues Marking up sentences proved
to be quite easy; marking up units, on the other
hand, required extensive annotator training. The
agreement on identifying the boundaries of units,
using the κ statistic discussed in (Carletta, 1996),
was κ = .9 (for two annotators and 500 units); the
agreement on features (2 annotators and at least 200
units) was as follows: UTYPE: κ=.76; VERBED:
κ=.9; FINITE: κ=.81. The main problems
when marking units were to identify complements,
to distinguish clausal adjuncts from prepositional
phrases, and how to mark up coordinated units. The
main problem with complements was to distinguish
non-finite complements of verbs such as want from
the non-finite part of verbal complexes containing
modal auxiliaries such as get, let, make, and have:
</bodyText>
<listItem confidence="0.9172405">
(2) a. (I would like (to be able to travel))
b. (I let him do his homework)
</listItem>
<bodyText confidence="0.999153541666666">
One problem that proved fairly difficult to han-
dle (and which, in fact, we didn’t entirely solve)
was clausal coordination. The problem was to pre-
serve enough structure to be able to compute the
previous utterance, while preserving some basic in-
tuitions about what constitutes a clause (roughly,
that by and large clauses were text spans marked
either by the presence of a semantically isolated
verb or by punctuation / layout) which are essen-
tial for annotators and are needed to specify the val-
ues of attributes. This was relatively easy to do
when two main clauses were coordinated; coordi-
nated main clauses were marked as in (3a). How-
ever, it wasn’t completely obvious what to do in the
case of coordination within a subordinate clause, as
in (3b). Because there weren’t many such cases,
rather than using the (unit) element with a spe-
cial value for UTYPE as we did for coordinated NPs
(which meant specifying all sorts of special val-
ues for attributes) we used a markup element called
(unit-coordination) to maintain the struc-
ture, and then marked up each clause separately,
as shown in (3c) (the (unit-coordination) is
marked with square brackets).
</bodyText>
<listItem confidence="0.9079692">
(3) a. (The Getty museum’s microscope still
works,) (and the case is fitted with a
drawer filled with the necessary attach-
ments).
b. (If you have any questions or are not sure
about anything, ask your doctor or your
pharmacist)
c. ((If [(you have any questions) or (you are
not sure about anything)]), ask your doctor
or your pharmacist)
The elements of text not marked up as units in-
clude: NPs, post-verbal and post-nominal PPs, non-
verbal NP modifiers, coordinated VPs in case the
second conjunct did not have arguments (4a), and
quoted parts of text, when not reported speech (4b).
(4) a. (The oestradiol and norethisterone acetate
are plant derived and synthetically pro-
duced)
b. (The inscription ’CHNETOC
BASHLHKOC CPATHARHC’)
</listItem>
<bodyText confidence="0.998282285714286">
Layout Our genres raised a few issues that, as far
as we know, have not been previously discussed in
the Centering literature. One such problem is what
to do with layout elements such as titles and list ele-
ments, which can clearly serve as the first introduc-
tion of a CF and to move the CB. One example of
title unit is unit (u1) in (5).
</bodyText>
<listItem confidence="0.544921">
(5) (u1) Side effects
</listItem>
<bodyText confidence="0.9961935">
Side effects may occur when PRODUCT-
Y is applied to large parts of the body,
We marked these layout elements as units, as in (6),
but using the special value title of the attribute
UTYPE (see above) so that we could test whether it
was better to treat them as utterances or not.
</bodyText>
<figure confidence="0.893361">
(6) &lt;unit id=&amp;quot;u1&amp;quot; utype=&amp;quot;title&amp;quot;&gt;Side
effects&lt;/unit&gt;
&lt;p&gt;&lt;s stype=&amp;quot;decl&amp;quot;&gt;&lt;unit&gt; Side
</figure>
<figureCaption confidence="0.899010333333333">
effects may occur &lt;unit&gt;when PRODUCT-
Y is applied to large parts of the body, ...
&lt;/unit&gt; ... &lt;/unit&gt; ... &lt;/s&gt; ... &lt;/p&gt;
</figureCaption>
<bodyText confidence="0.995114642857143">
Problems with Attributes The most difficult at-
tribute to mark was UTYPE, and our main problem
was to distinguish between relative clauses and par-
entheticals, since it’s not always easy to tell whether
a relative clause is restrictive or non-restrictive (see
also (Cheng et al., 2001)). In the end, we adopted
rules purely based on surface form (the presence or
absence of a comma or other bracketing device).
(See also (Quirk and Greenbaum, 1973).)
Utterances and Propositions The annotation of
units has been shown useful to identify many of the
atomic propositions expressed by a text, and was
therefore used as a basis for studying text planning
(Karamanis, 2003) and aggregation (Cheng, 2001).
</bodyText>
<sectionHeader confidence="0.7749985" genericHeader="method">
4 Properties of Discourse Entities and
their Realization
</sectionHeader>
<bodyText confidence="0.999993555555556">
The main goal of the GNOME annotation was to
study the factors that affect the realization of dis-
course entities, focusing on those entities realized as
NPs. Hence, our main concern was to identify and
to annotate the relevant properties both of discourse
entities themselves and their realizations in a partic-
ular utterance (which we will call FORWARD LOOK-
ING CENTERS, or CFs, following Centering’s termi-
nology). Both types of properties were annotated as
properties of the (ne) element, used to mark up NPs
in the corpus. Overall, we annotated 14 attributes of
(ne) elements, specifying the syntactic and seman-
tic properties of NPs and the semantic properties of
the discourse entities they realize. We discuss these
attributes in this section. We also annotated seman-
tic relations between discourse entities, particularly
when they express anaphoric relations. Anaphoric
annotation is discussed in the next section.
</bodyText>
<subsectionHeader confidence="0.999501">
4.1 Marking up NEs
</subsectionHeader>
<bodyText confidence="0.937380887096774">
The (ne) element is used to mark NPs, as in the
following example (the attributes will be discussed
below):
(7) &lt;unit finite=’finite-yes’ id=’u3’ utype=’main’
verbed=’verbed-yes’&gt;
&lt;ne id=&amp;quot;ne2&amp;quot; cat=&amp;quot;poss-np&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot;
gen=&amp;quot;neut&amp;quot; gf=&amp;quot;subj&amp;quot; lftype=&amp;quot;term&amp;quot;
onto=&amp;quot;concrete&amp;quot; ani=&amp;quot;inanimate&amp;quot;
deix=&amp;quot;deix-no&amp;quot; count=&amp;quot;undersp-count&amp;quot;
structure=&amp;quot;undersp-structure&amp;quot;
generic=&amp;quot;generic-no&amp;quot; loeb=&amp;quot;sem-function&amp;quot;&gt;
&lt;ne id=&amp;quot;ne3&amp;quot; cat=&amp;quot;this-np&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot;
gen=&amp;quot;neut&amp;quot; gf=&amp;quot;gen&amp;quot; lftype=&amp;quot;term&amp;quot;
onto=&amp;quot;concrete&amp;quot; ani=&amp;quot;inanimate&amp;quot;
deix=&amp;quot;deix-yes&amp;quot; count=&amp;quot;count-yes&amp;quot;
structure=&amp;quot;atom&amp;quot;
generic=&amp;quot;generic-no&amp;quot; loeb=&amp;quot;pragm-function&amp;quot;&gt;
This table’s
&lt;/ne&gt;
&lt;/ne&gt;
allow
&lt;ne id=&amp;quot;ne4&amp;quot; cat=&amp;quot;bare-np&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;plur&amp;quot;
gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;person&amp;quot;
ani=&amp;quot;animate&amp;quot; deix=&amp;quot;deix-no&amp;quot; count=&amp;quot;count-yes&amp;quot;
structure=&amp;quot;set&amp;quot; generic=&amp;quot;generic-yes&amp;quot; loeb=&amp;quot;sort&amp;quot;&gt;
scholars &lt;/ne&gt;
&lt;unit finite=’finite-no’ id=’u4’ utype=’complement’
verbed=’verbed-yes’&gt;
to link
&lt;ne id=&amp;quot;ne5&amp;quot; cat=&amp;quot;pers-pro&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot;
gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;concrete&amp;quot;
ani=&amp;quot;inanimate&amp;quot; deix=&amp;quot;deix-yes&amp;quot; count=&amp;quot;count-yes&amp;quot;
structure=&amp;quot;atom&amp;quot; generic=&amp;quot;generic-no&amp;quot;
loeb=&amp;quot;disc-function&amp;quot;&gt; it &lt;/ne&gt;
...
The GNOME instructions for identifying NPs derive
from those proposed in MATE (Poesio et al., 1999),
in turn derived from DRAMA (Passonneau, 1997)
and MUC-7 (Hirschman, 1998). An important dif-
ference between the instructions used for GNOME
and those developed for MATE is that instead of at-
tempting to get the annotators to recognize the NP
that realize discourse entities and only mark those,
in GNOME all NPs were marked with (ne) elements;
the separate LF TYPE attribute was used to distin-
guish between NPs with different types of denota-
tions (see below). This change made the process of
identifying nominal entities easier and potentially
automatic (even though the identification of mark-
ables was still done by hand).
As in the case of units, the main problem with
marking up NPs was coordination. Our approach
was to use a separate (ne) element to mark up the
coordinated NP, with type (CAT) value coord-np.
We only used a coord-np element if two deter-
miners were present, as in ((your doctor) and (your
pharmacist)). This approach was chosen because it
limited the number of spurious coordinations intro-
duced (in cases such as this is an interesting and
well-known example of early Byzantine jewellery),
but has the limitation that only one (ne) is marked
in cases such as Your doctor or pharmacist.
</bodyText>
<subsectionHeader confidence="0.995648">
4.2 Properties of all NPs
</subsectionHeader>
<bodyText confidence="0.999844113043479">
Some of the attributes of (ne) elements specify
properties of all NPs, whether or not they realize a
discourse entity. We discuss these first.
CAT The CAT attribute is used to mark NP type:
whether the NP is a pronoun, a definite description,
etc.. This attribute is only meant to provide a
very surface-y classification, without attempting to
group NPs in larger classes such as ‘definite NP’ and
‘indefinite NP’. The one attempt to go beyond pure
surface was the introduction of a distinction be-
tween definite descriptions that are really disguised
proper names such as the Beatles, classified as
CAT=the-pn, and all other definite descriptions,
classified as the-np. The complete list of
values for CAT is: a-np, another-np, q-np,
num-np, meas-np, that-np, this-np,
such-np, wh-np, poss-np, bare-np, pn,
the-pn, the-np, pers-pro, poss-pro,
refl-pro, rec-pro, q-pro, wh-pro,
this-pro, that-pro, num-ana (for ’nu-
merical anaphors’ such as one in I want one),
null-ana, gerund (for nominalized present
participles such as veneering furniture in the
practice of veneering furniture), coord-np, and
free-rel (for ’free relatives’ such as what you
need most in what you need most is a good rest)).
The agreement on this attribute was pretty high,
κ = .9; the one problem was the distinction be-
tween the-pn and the-np.
Agreement features: NUM, PER, and GEN These
atributes are used to annotate features that are im-
portant to study pronoun interpretation: gender,
number and person of NPs. Person and number were
generally easy to annotate, but gender was very dif-
ficult because of the presence of many references to
individual of unspecified gender, such as the maker
in the inventory gives neither the name of the maker
nor the location. This problem was solved by intro-
ducing a special undersp-gen value; indeed, un-
derspecified values were provided for all attributes.
The agreement values for these features were: GEN:
κ = .89; NUM: κ = .84; PER: κ = .9.
GF This attribute was used to annotate the gram-
matical function of the NP, a property generally
taken to play an important role in determining
the salience of the discourse entity it realizes
(Grosz et al., 1995). Our instructions for this
attribute are derived from those used in the
FRAMENET project ((Baker et al., 1998); see also
http://www.icsi.berkeley.edu/˜framenet/).
The values are subj, obj, predicate (used
for post-verbal objects in copular sentences, such
as This is (a production watch)), there-obj
(for post-verbal objects in there-sentences), comp
(for indirect objects), adjunct (for the argument
of PPs modifying VPs), gen (for NPs in deter-
miner position in possessive NPs), np-compl,
np-part, np-mod, adj-mod, and no-gf (for
NPs occurring by themselves - eg., in titles). The
agreement values for GF is κ = .85.
LF TYPE Not all NPs realize discourse entities:
some of them realize quantifiers (e.g., each coffer
in Each coffer has a lid) or predicates (e.g., NPs in
appositive position, such as the oldest son of Louis
XIV in The 1689 inventory of the Grand Dauphin,
the oldest son of Louis XIV, lists a jewel coffer of
similar form and decoration. As said above, in the
GNOME annotation all NPs are treated as markables,
but the LF TYPE attribute is used to indicate the
type of semantic object denoted by an NP: term,
quant or pred. Quantifiers were identified purely
on the basis of the value of the CAT value: all NPs
with CAT=q-np or q-pro should get a value of
quant. A more complex test was used to identify
predicative NPs: three linguistic contexts in which
NP are typically predicative were considered (appo-
sitions, postcopular position in there-sentences, and
become-style sentences) but the annotators were ex-
plicitly asked to check whether the NP was used to
express a property. Agreement was more tentative:
κ = .73 (for two annotators, 200 NPs).
Taxonomic information Two semantic attributes
capture information about the type of objects re-
ferred to (or quantifier over) by an NP. The first
attribute, ONTO, was originally introduced to distin-
guish between gerunds (event nominalizations such
as letter-writing) and bare plurals referring to con-
crete objects like scholars, both of which semanti-
cally denote collective objects (Link, 1983; Portner,
1992). Further distinctions were introduced to deal
with ‘difficult’ objects, such as diseases; particular
types of concrete objects such as medicines and per-
sons were also singled out. Distinctions captured
by the current set of values of ONTO include per-
sons, medicines, other substances, other concrete
objects; events, time intervals, or other abstract enti-
ties; spatial locations; and diseases. The agreement
value for the latest version of ONTO was κ = .8
between two annotators, 200 NPs.
The second ‘taxonomic’ attribute, ANI, is used
to annotate whether the objects referred to or quan-
tifier over by an NP are animate or inanimate. This
annotation was motivated by a number of studies
suggesting that animacy plays an important role in
salience (Prat-Sala and Branigan, 2000) and our
own experiments suggesting that animacy is much
more important than grammatical function, the-
matic roles, or order of mention in determining
which entities are most likely to be pronominal-
ized (Pearson et al., 2001). We also found that
the discrepancy between the results of Gordon et
al. (1999) and the findings of (Walker and Prince,
1996) can be explained in terms of animacy (Poesio
and Nissim, 2001). Animacy was by far the easiest
semantic attribute for our annotators: κ = .92.
</bodyText>
<subsectionHeader confidence="0.9975">
4.3 Semantic properties of Discourse Entities
</subsectionHeader>
<bodyText confidence="0.999987875">
Semantic properties that may play a role in realiza-
tion but only apply to discourse entities include:4
Structure Two attributes are used to indicate
whether the discourse entity realized by an NP refers
to a mass of certain substance or to countable ob-
jects (attribute COUNT) and, in case of countable
objects, to an atom or a set (attribute STRUCTURE).
These attributes were marked in order to study the
</bodyText>
<footnote confidence="0.662826">
4These attributes were only marked for about 25% of the
corpus.
</footnote>
<bodyText confidence="0.99995954">
factors leading to the realization of a discourse en-
tity as a bare NP, in combination with the annotation
of genericity discussed below: the reasoning being
that it should only be possible to use bare singu-
lars to realize a discourse entity described with mass
nouns (as in the ebeniste and his wife lived modestly
in a five-room apartment... with simple furniture).5
The main reason for keeping the two at-
tributes separate was that reaching agreement on
STRUCTURE was fairly easy (κ = .82 at the second
attempt) whereas COUNT was one of the most dif-
ficult attributes to mark–it took several iterations of
changes to the instructions to achieve a κ = .78, and
substantial revisions would probably still be useful.
Nevertheless, given currently accepted views deriv-
ing from Link’s work (1983), it would make more
sense to merge the two attributes.
GENERIC This attribute is used to indicate
whether the NP should be interpreted generically or
not, which was thought to affect at least two types
of discourse entity realizations: gerunds, that we
took to be event types, and bare NPs, both singular
and referring to substances (e.g., ivory) and plural.
Annotating this information proved to be very diffi-
cult, which was not surprising because genericity is
not yet a completely understood phenomenon. One
complication is that there are two types of ‘generic
NPs’: NPs referring to kinds, such as The dodo in
The dodo is extinct (being extinct is not a property
that can be predicated of individual dodos), and NPs
used in generic statements, such as Italians are good
skiers (a property of individual Italians) (Carlson
and Pelletier, 1995). Although some NPs can only
be used to express one or the other interpretation
(e.g., * A dodo is extinct), many can be used in both
ways (Dodos are extinct).
We started trying to make the very basic distinc-
tion between tokens and types one finds, e.g., in
(Lyons, 1977), but even after numerous refinements
we still encountered many problems. One of the
problems our annotators had was whether to treat
references to substances such as ivory and horn in
examples like This table’s marquetry of ivory and
horn ‘existentially,’ i.e., as referring to the partic-
ular amounts of those substances used in the ta-
ble, or ‘generically’, to refer to the kinds. In the
end we decided to follow Carlson (1977) and to
mark all of these examples as references to kinds,
i.e., as generic. A second problem were quantifiers.
Our annotators found it very hard to distinguish
</bodyText>
<footnote confidence="0.89709825">
5Apart from the cases in which bare singulars are used to re-
fer to substances, such as the interiors of this pair of coffers are
lined with tortoiseshell and brass, the few discussed exceptions
to this rule are expressions like home in I went home.
</footnote>
<bodyText confidence="0.99950075">
between quantified NPs used (non-generically) to
quantify over a specific set of individuals at a partic-
ular spatio-temporal location, as in Many lecturers
went on strike (on March 16th, 2004), and quanti-
fiers used in generic sentences, as in Many lectur-
ers went (habitually) on strike (during those years).
The last version of the instructions (not yet added to
the overall annotation manual) asked annotators to
try to identify generic sentences before attempting
to determine the value of the GENERIC attribute.
With these instructions, we finally reached a reason-
able agreement (κ = .82).
LOEB Poesio and Vieira (1998) found that of the
1,400 definite descriptions in their corpus, only
about 50% were subsequent mention or bridging
references, whereas 50% were first mentions. Of
the first mentions, about half (i.e., 25% of the to-
tal) were what Hawkins (1978) would call ’larger
situation’ definites, i.e., definite descriptions like
the pope whose referent is supposed to be part of
shared knowledge; whereas the other half includes
what Loebner (1987) calls SEMANTICALLY FUNC-
TIONAL definites, like the first man on the Moon.
Loebner claimed that the paradigmatic case of def-
initeness are not anaphoric NPs, as suggested by
familiarity theories such as Heim’s (1982), but se-
mantically functional ones such as the first person
ever to row across the Pacific on his own. In or-
der to test Loebner’s theory and compare it with one
based on familiarity, we annotated the NPs referring
to discourse entities according to whether they were
functional, relational, or sortal (Poesio, 2004a). We
achieved good reliability on this attribute (κ = .82),
and the results do suggest a much greater correlation
between functionality and definiteness than between
familiarity and definiteness (Poesio, 2004a).
</bodyText>
<sectionHeader confidence="0.989543" genericHeader="method">
5 Anaphora
</sectionHeader>
<bodyText confidence="0.99980475">
The one aspect of the GNOME annotation that has
been extensively discussed in previous papers is
anaphoric annotation (Poesio, 2004b; Poesio et al.,
2004b); we only discuss this aspect briefly here.
</bodyText>
<subsectionHeader confidence="0.99911">
5.1 Annotating Discourse Models
</subsectionHeader>
<bodyText confidence="0.999994551724138">
Anaphoric annotation raises a number of difficult
and, sometimes, unresolved semantic issues (Poe-
sio, 2004b). As part of the MATE and GNOME
projects, an extensive analysis of previously exist-
ing schemes for so-called ‘coreference annotation,’
such as the MUC-7 scheme, was carried out, high-
lighting a number of problems with such schemes,
ranging from issues with the annotation method-
ology to semantic issues. Proposals for annotat-
ing ‘coreference’ such as (Hirschman, 1998) have
been motivated by work on Information Extraction,
hence the notion of ‘coreference’ used is very diffi-
cult to relate to traditional ideas about anaphora (van
Deemter and Kibble, 2000). A distinctive feature
of the GNOME annotation (and the MATE propos-
als from which they derive (Poesio, 2004b)) are ex-
plicitly based on the DISCOURSE MODEL assump-
tion adopted almost universally by linguists (com-
putational and not) working on anaphora resolution
and generation (Webber, 1979; Heim, 1982; Kamp
and Reyle, 1993; Gundel et al., 1993). This is
the hypothesis that interpreting a discourse involves
building a shared discourse model containing DIS-
COURSE ENTITIES that may or may not ‘refer’ to
specific objects in the world, as well as the relations
between these entities. The annotation for which the
MATE scheme was developed–that we’ll call here
’anaphoric annotation,’ is meant as a partial repre-
sentation of the discourse model evoked by a text.
</bodyText>
<subsectionHeader confidence="0.999603">
5.2 Anaphoric Annotation in GNOME
</subsectionHeader>
<bodyText confidence="0.999766375">
For the GNOME corpus, we adopted a simplified ver-
sion of the MATE scheme, as for our purposes it’s
not essential to mark all semantic relations between
entities introduced by a text, but only those that may
establish a ‘link’ between two utterances. So, for
example, it was not necessary for us to mark a rela-
tion between the subject of a copular sentence and
its predicate - e.g., between the price of aluminum
siding and $3.85 or $4.02 in the example above.
In the GNOME corpus, anaphoric information is
marked by means of a special (ante) element; the
(ante) element itself specifies the index of the
anaphoric expression (a (ne) element) and the type
of semantic relation (e.g., identity), whereas one or
more embedded (anchor) elements indicate pos-
sible antecedents.6 (See (8).)
</bodyText>
<figure confidence="0.45441475">
(8) &lt;unit finite=’finite-yes’ id=’u227’&gt;
&lt;ne id=’ne546’ gf=’subj’&gt; The drawing of
&lt;ne id=’ne547’ gf=’np-compl’&gt;the corner cupboard
&lt;/ne&gt;&lt;/ne&gt;
&lt;unit finite=’no-finite’ id=’u228’&gt;,or more probably
&lt;ne id=’ne548’ gf=’no-gf’&gt; an engraving of
&lt;ne id=’ne549’ gf=’np-compl’&gt;it &lt;/ne&gt;&lt;/ne&gt;
&lt;/unit&gt;,
...
&lt;/unit&gt;
&lt;ante current=&amp;quot;ne549&amp;quot; rel=&amp;quot;ident&amp;quot;&gt; &lt;anchor ID=&amp;quot;ne547&amp;quot;&gt;
&lt;/ante&gt;
</figure>
<bodyText confidence="0.999246142857143">
Work such as (Sidner, 1979; Strube and Hahn,
1999), as well as our own preliminary analysis,
suggested that indirect realization can play a cru-
cial role in maintaining the CB. However, previ-
ous attempts at marking anaphoric information, par-
ticularly in the context of the MUC initiative, sug-
gested that while agreement on identity relations is
</bodyText>
<footnote confidence="0.7471225">
6The presence of more than one (anchor) element indi-
cates that the anaphoric expression is ambiguous.
</footnote>
<bodyText confidence="0.99997540625">
fairly easy to achieve, marking bridging references
is hard; this was confirmed by Poesio and Vieira
(1998). For these reasons, and to reduce the an-
notators’ work, we did not mark all relations. Be-
sides identity (IDENT) we only marked up three
associative relations (Hawkins, 1978): set mem-
bership (ELEMENT), subset (SUBSET), and ‘gen-
eralized possession’ (FOSS), which includes part-
of relations as well as ownership relations. We
only marked relations between objects realized by
noun phrases, excluding anaphoric references to ac-
tions, events or propositions implicitly introduced
by clauses or sentences. We also gave strict in-
structions to our annotators limiting how much to
mark.
As expected, we found a reasonable (if not
perfect) agreement on identity relations. In our
most recent analysis (two annotators looking at the
anaphoric relations between 200 NPs) we observed
no real disagreements; 79.4% of the relations were
marked up by both annotators; 12.8% by only one
of them; and in 7.7% of the cases, one of the an-
notators marked up a closer antecedent than the
other. With associative references, limiting the rela-
tions did limit the disagreements among annotators
(only 4.8% of the relations are actually marked dif-
ferently) but only 22% of bridging references were
marked in the same way by both annotators; 73.17%
of relations are marked by only one or the other
annotator. So reaching agreement on this informa-
tion involved several discussions between annota-
tors and more than one pass over the corpus.
</bodyText>
<sectionHeader confidence="0.9809035" genericHeader="method">
6 Automatically computing the Local
Focus
</sectionHeader>
<bodyText confidence="0.999018217391304">
The reader will have noticed that no attempt was
done to directly mark up properties of the local fo-
cus - e.g., which discourse entity is the CB of a par-
ticular utterance. We found that it is much easier
to annotate the ‘building blocks’ of a theory of the
local focus, and then use scripts to automatically
compute the CB. There are two advantages to this
approach: first of all, agreement on the ‘building
blocks’ is much easier to reach than agreement on
the CB–in our preliminary experiments we didn’t go
beyond κ = .6 when trying to directly identify the
CB using the definitions from (Brennan et al., 1987).
And secondly, this approach makes it possible to
compute the CB according to different ways of in-
stantiating what we call the ‘parameters of Center-
ing’ –e.g., ranking.
We developed such scripts for the work dis-
cussed in (Poesio et al., 2004b); they can be
tested on the web site associated with that paper,
http://cswww.essex.ac.uk/staff/poesio/
cbc/. These scripts have been subsequently used
to compute the CB in, e.g., (Poesio and Nissim,
2001; Poesio and Nygren-Modjeska, To appear).
</bodyText>
<sectionHeader confidence="0.976187" genericHeader="conclusions">
7 Discussions and Conclusion
</sectionHeader>
<bodyText confidence="0.999929972222222">
Corpus consistency The main lesson learned
from this effort is that actually using a corpus is the
best way both to ensure its correctness and to learn
which types of information are most useful.
Thematic Roles One attribute on which we
weren’t able to reach acceptable agreement was the
thematic role of an NP, which has been argued to
be a better indicator of salience than grammatical
function (Sidner, 1979; Stevenson et al., 1994); the
agreement value in this case was κ = .35. Other
groups however have shown that this can be done,
e.g., in Framenet (Baker et al., 1998) and more re-
cently in PropBank (Kingsbury and Palmer, 2002).
Planned Revisions of the Scheme A number of
aspects of the annotation scheme used for the cor-
pus could be improved. An obvious improvement
would be to directly annotate predicates with their
WordNet senses instead of annotating ONTO and an-
imacy. We started doing this for the annotation of
modifiers (Cheng et al., 2001), and developed an in-
terface to WordNet, but too late to redo the whole
corpus. Of the attributes, COUNT and GENERIC
were the most difficult to annotate; further tests with
these attributes could be useful.
Automatic annotation A substantial part of the
annotation work required for GNOME now could
(and should) be done automatically, or semi-
automatically. This includes, most obviously, the
identification of sentences and NPs, already done
automatically in the VENEX corpus (Poesio, 2004b);
and at least grammatical function, animacy, and
countability could be automatically annotated in
preliminary form with existing techniques, and then
corrected by hand. We also plan to use the corpus
to bootstrap techniques for automatic identification
of uniqueness and gender.
</bodyText>
<sectionHeader confidence="0.998299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999644666666667">
Special thanks to Janet Hitzeman, who collected the
first subset of the museum domain for SOLE; to Re-
nate Henschel, who completed the collection of the
museum subset and wrote the first version of the an-
notation manual; to all our annotators; and to Mi-
jail Alexandrov-Kabadjov and Nikiforos Karama-
nis, who identified a number of annotation prob-
lems. Most of this work was supported by the
EPSRC project GNOME, GR/L51126/01.
</bodyText>
<sectionHeader confidence="0.990261" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999928427480916">
C. F. Baker, C. J. Fillmore, and J. B Lowe. 1998. The Berkeley
FrameNet project. In Proc. 36th ACL.
S.E. Brennan, M.W. Friedman, and C.J. Pollard. 1987. A cen-
tering approach to pronouns. In Proc. of the 25th ACL.
J. Carletta. 1996. Assessing agreement on classification tasks:
the kappa statistic. Comp. Linguistics, 22(2):249–254.
G. N. Carlson and F. J. Pelletier, editors. 1995. The Generic
Book. University of Chicago Press.
G. N. Carlson. 1977. Reference to Kinds in English. Ph.D.
thesis, University of Massachusetts, Amherst.
H. Cheng, M. Poesio, R. Henschel, and C. Mellish. 2001.
Corpus-based NP modifier generation. In Proc. of the Sec-
ond NAACL, Pittsburgh.
H. Cheng. 2001. Modelling Aggregation Motivated Interac-
tions in Descr. Text Generation. Ph.D. thesis, Edinburgh.
P. C. Gordon, R. Hendrick, K. Ledoux, and C. L. Yang. 1999.
Processing of reference and the structure of language: an
analysis of complex noun phrases. Language and Cognitive
Processes, 14(4):353–379.
B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995. Centering:
A framework for modeling the local coherence of discourse.
Computational Linguistics, 21(2):202–225.
J. K. Gundel, N. Hedberg, and R. Zacharski. 1993. Cognitive
status and the form of referring expressions in discourse.
Language, 69(2):274–307.
J. A. Hawkins. 1978. Definiteness and Indefiniteness. Croom
Helm, London.
I. Heim. 1982. The Semantics of Definite and Indefinite Noun
Phrases. Ph.D. thesis, Univ. of Massachusetts at Amherst.
R. Henschel, H. Cheng, and M. Poesio. 2000. Pronominaliza-
tion revisited. In Proc. of 18th COLING.
L. Hirschman. 1998. MUC-7 coreference task definition, ver-
sion 3.0. In N. Chinchor, editor, In Proc. of the 7th Message
Understanding Conference.
M. Kameyama. 1998. Intra-sentential centering. In M. A.
Walker, A. K. Joshi, and E. F. Prince, editors, Centering
Theory in Discourse, chapter 6, pages 89–112. Oxford.
H. Kamp and U. Reyle. 1993. From Discourse to Logic. D.
Reidel, Dordrecht.
N. Karamanis. 2003. Entity coherence for descriptive text
structuring. Ph.D. thesis, Edinburgh.
P. Kingsbury and M. Palmer. 2002. From Treebank to Prop-
Bank. In Proc. ofLREC.
G. Link. 1983. The logical analysis of plurals and mass terms:
A lattice- theoretical approach. In R. B¨auerle, C. Schwarze,
and A. von Stechow, editors, Meaning, Use and Interpreta-
tion ofLanguage, pages 302–323. Walter de Gruyter.
S. Loebner. 1987. Definites. Journal ofSemantics, 4:279–326.
J. Lyons. 1977. Semantics. Cambridge.
D. Marcu. 1999. Instructions for manually annotating the dis-
course structures of texts. Unpublished manuscript.
E. Miltsakaki. 2002. Towards an aposynthesis of topic conti-
nuity and intrasentential anaphora. Computational Linguis-
tics, 28(3):319–355.
J. Oberlander, M. O’Donnell, A. Knott, and C. Mellish. 1998.
Conversation in the museum. New Review of Hypermedia
and Multimedia, 4:11–32.
R. J. Passonneau. 1997. Instructions for applying discourse
reference annotation for multiple applications (DRAMA).
Unpublished manuscript., December.
J. Pearson, R. Stevenson, and M. Poesio. 2000. Pronoun reso-
lution in complex sentences. In Proc. ofAMLAP, Leiden.
J. Pearson, R. Stevenson, and M Poesio. 2001. The effects of
animacy, thematic role, and surface position on the focus-
ing of entities in discourse. In M. Poesio, editor, Proc. of
SEMPRO-2001. University of Edinburgh.
M. Poesio and M. Alexandrov-Kabadjov. 2004. A general-
purpose, off the shelf anaphoric resolver. In Proc. ofLREC.
M. Poesio and B. Di Eugenio. 2001. Discourse structure
and anaphoric accessibility. In Ivana Kruijff-Korbayov´a and
Mark Steedman, editors, Proc. of the ESSLLI 2001 Work-
shop on Inf. Structure, Disc. Structure and Disc. Semantics.
M. Poesio and M. Nissim. 2001. Salience and possessive NPs:
the effect of animacy and pronominalization. In Proc. of
AMLAP (Poster Session).
M. Poesio and N. Nygren-Modjeska. To appear. Focus, activa-
tion, and this-noun phrases. In A. Branco, R. McEnery, and
R. Mitkov, editors, Anaphora Processing. John Benjamins.
M. Poesio and R. Vieira. 1998. A corpus-based investiga-
tion of definite description use. Computational Linguistics,
24(2):183–216, June.
M. Poesio, F. Bruneseaux, and L. Romary. 1999. The MATE
meta-scheme for coreference in dialogues in multiple lan-
guages. In M. Walker, editor, Proc. of the ACL Workshop on
Standards and Tools for Discourse Tagging, pages 65–74.
M. Poesio, R. Mehta, A. Maroudas, and J. Hitzeman. 2004a.
Learning to solve bridging references. In Proc. of the ACL.
M. Poesio, R. Stevenson, B. Di Eugenio, and J. M. Hitzeman.
2004b. Centering: A parametric theory and its instantia-
tions. Computational Linguistics, 30(3).
M. Poesio. 2000a. Annotating a corpus to develop and evaluate
discourse entity realization algorithms. In Proc. of the 2nd
LREC, pages 211–218, Athens, May.
M. Poesio, 2000b. The GNOME Annotation
Manual, Fourth Edition. Available from
http://www.hcrc.ed.ac.uk/ ˜ gnome.
M. Poesio. 2003. Associative descriptions and salience. In
Proc. of the EACL Workshop on Computational Treatments
ofAnaphora, Budapest.
M. Poesio. 2004a. An empirical investigation of definiteness.
In S. Kepser, editor, Proc. of the International Conference
on Linguistic Evidence, T¨ubingen, January.
M. Poesio. 2004b. The MATE/GNOME scheme for anaphoric
annotation, revisited. In Proc. of SIGDIAL, Boston, May.
P. H. Portner. 1992. Situation Theory and the Semantics of
Propositional Expressions. Ph.D. thesis, University of Mas-
sachusetts at Amherst.
M. Prat-Sala and H. Branigan. 2000. Discourse constraints
on syntactic processing in language production. Journal of
Memory and Language, 42(168–182).
R. Quirk and S. Greenbaum. 1973. A University Grammar of
English. Longman.
D. Scott, R. Power, and R. Evans. 1998. Generation as a solu-
tion to its own problem. In Proc. of the 9th INLG.
C. L. Sidner. 1979. Towards a computational theory of defi-
nite anaphora comprehension in English discourse. Ph.D.
thesis, MIT.
R. J. Stevenson, R. A. Crawley, and D. Kleinman. 1994. The-
matic roles, focus, and the representation of events. Lan-
guage and Cognitive Processes, 9:519–548.
M. Strube and U. Hahn. 1999. Functional centering–
grounding referential coherence in information structure.
Computational Linguistics, 25(3):309–344.
K. van Deemter and R. Kibble. 2000. On coreferring: Coref-
erence in MUC and related annotation schemes. Computa-
tional Linguistics, 26(4):629–637. Squib.
M. A. Walker and E. Prince. 1996. A bilateral approach to
givenness. In J. Gundel and T. Fretheim, editors, Reference
Accessibility, pages 291–306. John Benjamins.
B. L. Webber. 1979. A Formal Approach to Discourse
Anaphora. Garland, New York.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538454">
<title confidence="0.999206">Discourse Annotation and Semantic Annotation in the GNOME Corpus</title>
<author confidence="0.997282">Massimo</author>
<affiliation confidence="0.994987">University of Department of Computer Science and Centre for Cognitive</affiliation>
<address confidence="0.558687">United Kingdom</address>
<abstract confidence="0.9945395">was created to study the discourse and semantic properties of discourse entities that affect their realization and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C F Baker</author>
<author>C J Fillmore</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proc. 36th ACL.</booktitle>
<contexts>
<context position="16763" citStr="Baker et al., 1998" startWordPosition="2629" endWordPosition="2632">maker in the inventory gives neither the name of the maker nor the location. This problem was solved by introducing a special undersp-gen value; indeed, underspecified values were provided for all attributes. The agreement values for these features were: GEN: κ = .89; NUM: κ = .84; PER: κ = .9. GF This attribute was used to annotate the grammatical function of the NP, a property generally taken to play an important role in determining the salience of the discourse entity it realizes (Grosz et al., 1995). Our instructions for this attribute are derived from those used in the FRAMENET project ((Baker et al., 1998); see also http://www.icsi.berkeley.edu/˜framenet/). The values are subj, obj, predicate (used for post-verbal objects in copular sentences, such as This is (a production watch)), there-obj (for post-verbal objects in there-sentences), comp (for indirect objects), adjunct (for the argument of PPs modifying VPs), gen (for NPs in determiner position in possessive NPs), np-compl, np-part, np-mod, adj-mod, and no-gf (for NPs occurring by themselves - eg., in titles). The agreement values for GF is κ = .85. LF TYPE Not all NPs realize discourse entities: some of them realize quantifiers (e.g., each</context>
<context position="31629" citStr="Baker et al., 1998" startWordPosition="5044" endWordPosition="5047">, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has been argued to be a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can be done, e.g., in Framenet (Baker et al., 1998) and more recently in PropBank (Kingsbury and Palmer, 2002). Planned Revisions of the Scheme A number of aspects of the annotation scheme used for the corpus could be improved. An obvious improvement would be to directly annotate predicates with their WordNet senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus. Of the attributes, COUNT and GENERIC were the most difficult to annotate; further tests with these attributes could be useful. Automatic an</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. F. Baker, C. J. Fillmore, and J. B Lowe. 1998. The Berkeley FrameNet project. In Proc. 36th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>M W Friedman</author>
<author>C J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proc. of the 25th ACL.</booktitle>
<contexts>
<context position="30534" citStr="Brennan et al., 1987" startWordPosition="4862" endWordPosition="4865">al Focus The reader will have noticed that no attempt was done to directly mark up properties of the local focus - e.g., which discourse entity is the CB of a particular utterance. We found that it is much easier to annotate the ‘building blocks’ of a theory of the local focus, and then use scripts to automatically compute the CB. There are two advantages to this approach: first of all, agreement on the ‘building blocks’ is much easier to reach than agreement on the CB–in our preliminary experiments we didn’t go beyond κ = .6 when trying to directly identify the CB using the definitions from (Brennan et al., 1987). And secondly, this approach makes it possible to compute the CB according to different ways of instantiating what we call the ‘parameters of Centering’ –e.g., ranking. We developed such scripts for the work discussed in (Poesio et al., 2004b); they can be tested on the web site associated with that paper, http://cswww.essex.ac.uk/staff/poesio/ cbc/. These scripts have been subsequently used to compute the CB in, e.g., (Poesio and Nissim, 2001; Poesio and Nygren-Modjeska, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually usin</context>
</contexts>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>S.E. Brennan, M.W. Friedman, and C.J. Pollard. 1987. A centering approach to pronouns. In Proc. of the 25th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: the kappa statistic.</title>
<date>1996</date>
<journal>Comp. Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="6956" citStr="Carletta, 1996" startWordPosition="1090" endWordPosition="1091">parenmain, subject, complement, adjunct, coord-vp,preposed-pp, listitem, cleft, title, disc-marker. • VERBED: whether the unit contains a verb. • FINITE: for verbed units, whether the verb is finite or not. • SUBJECT: for verbed units, whether they have a full subject, an empty subject (expletive, as in there sentences), or no subject (e.g., for infinitival clauses). Annotation Issues Marking up sentences proved to be quite easy; marking up units, on the other hand, required extensive annotator training. The agreement on identifying the boundaries of units, using the κ statistic discussed in (Carletta, 1996), was κ = .9 (for two annotators and 500 units); the agreement on features (2 annotators and at least 200 units) was as follows: UTYPE: κ=.76; VERBED: κ=.9; FINITE: κ=.81. The main problems when marking units were to identify complements, to distinguish clausal adjuncts from prepositional phrases, and how to mark up coordinated units. The main problem with complements was to distinguish non-finite complements of verbs such as want from the non-finite part of verbal complexes containing modal auxiliaries such as get, let, make, and have: (2) a. (I would like (to be able to travel)) b. (I let hi</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>J. Carletta. 1996. Assessing agreement on classification tasks: the kappa statistic. Comp. Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<title>The Generic Book.</title>
<date>1995</date>
<editor>G. N. Carlson and F. J. Pelletier, editors.</editor>
<publisher>University of Chicago Press.</publisher>
<marker>1995</marker>
<rawString>G. N. Carlson and F. J. Pelletier, editors. 1995. The Generic Book. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Carlson</author>
</authors>
<date>1977</date>
<institution>University of Massachusetts,</institution>
<location>Amherst.</location>
<note>Reference to Kinds in English. Ph.D. thesis,</note>
<contexts>
<context position="22852" citStr="Carlson (1977)" startWordPosition="3634" endWordPosition="3635">, * A dodo is extinct), many can be used in both ways (Dodos are extinct). We started trying to make the very basic distinction between tokens and types one finds, e.g., in (Lyons, 1977), but even after numerous refinements we still encountered many problems. One of the problems our annotators had was whether to treat references to substances such as ivory and horn in examples like This table’s marquetry of ivory and horn ‘existentially,’ i.e., as referring to the particular amounts of those substances used in the table, or ‘generically’, to refer to the kinds. In the end we decided to follow Carlson (1977) and to mark all of these examples as references to kinds, i.e., as generic. A second problem were quantifiers. Our annotators found it very hard to distinguish 5Apart from the cases in which bare singulars are used to refer to substances, such as the interiors of this pair of coffers are lined with tortoiseshell and brass, the few discussed exceptions to this rule are expressions like home in I went home. between quantified NPs used (non-generically) to quantify over a specific set of individuals at a particular spatio-temporal location, as in Many lecturers went on strike (on March 16th, 200</context>
</contexts>
<marker>Carlson, 1977</marker>
<rawString>G. N. Carlson. 1977. Reference to Kinds in English. Ph.D. thesis, University of Massachusetts, Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cheng</author>
<author>M Poesio</author>
<author>R Henschel</author>
<author>C Mellish</author>
</authors>
<title>Corpus-based NP modifier generation.</title>
<date>2001</date>
<booktitle>In Proc. of the Second NAACL,</booktitle>
<location>Pittsburgh.</location>
<contexts>
<context position="1154" citStr="Cheng et al., 2001" startWordPosition="169" endWordPosition="172"> generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandrov-Kabadjov, 2004; Poesio et al., 2004a) Altho</context>
<context position="10584" citStr="Cheng et al., 2001" startWordPosition="1706" endWordPosition="1709">pecial value title of the attribute UTYPE (see above) so that we could test whether it was better to treat them as utterances or not. (6) &lt;unit id=&amp;quot;u1&amp;quot; utype=&amp;quot;title&amp;quot;&gt;Side effects&lt;/unit&gt; &lt;p&gt;&lt;s stype=&amp;quot;decl&amp;quot;&gt;&lt;unit&gt; Side effects may occur &lt;unit&gt;when PRODUCTY is applied to large parts of the body, ... &lt;/unit&gt; ... &lt;/unit&gt; ... &lt;/s&gt; ... &lt;/p&gt; Problems with Attributes The most difficult attribute to mark was UTYPE, and our main problem was to distinguish between relative clauses and parentheticals, since it’s not always easy to tell whether a relative clause is restrictive or non-restrictive (see also (Cheng et al., 2001)). In the end, we adopted rules purely based on surface form (the presence or absence of a comma or other bracketing device). (See also (Quirk and Greenbaum, 1973).) Utterances and Propositions The annotation of units has been shown useful to identify many of the atomic propositions expressed by a text, and was therefore used as a basis for studying text planning (Karamanis, 2003) and aggregation (Cheng, 2001). 4 Properties of Discourse Entities and their Realization The main goal of the GNOME annotation was to study the factors that affect the realization of discourse entities, focusing on th</context>
<context position="32010" citStr="Cheng et al., 2001" startWordPosition="5108" endWordPosition="5111">e a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can be done, e.g., in Framenet (Baker et al., 1998) and more recently in PropBank (Kingsbury and Palmer, 2002). Planned Revisions of the Scheme A number of aspects of the annotation scheme used for the corpus could be improved. An obvious improvement would be to directly annotate predicates with their WordNet senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus. Of the attributes, COUNT and GENERIC were the most difficult to annotate; further tests with these attributes could be useful. Automatic annotation A substantial part of the annotation work required for GNOME now could (and should) be done automatically, or semiautomatically. This includes, most obviously, the identification of sentences and NPs, already done automatically in the VENEX corpus (Poesio, 2004b); and at least grammatical function, animacy, and countability could be automatically annotated in preliminar</context>
</contexts>
<marker>Cheng, Poesio, Henschel, Mellish, 2001</marker>
<rawString>H. Cheng, M. Poesio, R. Henschel, and C. Mellish. 2001. Corpus-based NP modifier generation. In Proc. of the Second NAACL, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cheng</author>
</authors>
<title>Modelling Aggregation Motivated Interactions in Descr. Text Generation.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<location>Edinburgh.</location>
<contexts>
<context position="1181" citStr="Cheng, 2001" startWordPosition="174" endWordPosition="175">Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandrov-Kabadjov, 2004; Poesio et al., 2004a) Although the results of the stud</context>
<context position="10997" citStr="Cheng, 2001" startWordPosition="1775" endWordPosition="1776">n problem was to distinguish between relative clauses and parentheticals, since it’s not always easy to tell whether a relative clause is restrictive or non-restrictive (see also (Cheng et al., 2001)). In the end, we adopted rules purely based on surface form (the presence or absence of a comma or other bracketing device). (See also (Quirk and Greenbaum, 1973).) Utterances and Propositions The annotation of units has been shown useful to identify many of the atomic propositions expressed by a text, and was therefore used as a basis for studying text planning (Karamanis, 2003) and aggregation (Cheng, 2001). 4 Properties of Discourse Entities and their Realization The main goal of the GNOME annotation was to study the factors that affect the realization of discourse entities, focusing on those entities realized as NPs. Hence, our main concern was to identify and to annotate the relevant properties both of discourse entities themselves and their realizations in a particular utterance (which we will call FORWARD LOOKING CENTERS, or CFs, following Centering’s terminology). Both types of properties were annotated as properties of the (ne) element, used to mark up NPs in the corpus. Overall, we annot</context>
</contexts>
<marker>Cheng, 2001</marker>
<rawString>H. Cheng. 2001. Modelling Aggregation Motivated Interactions in Descr. Text Generation. Ph.D. thesis, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P C Gordon</author>
<author>R Hendrick</author>
<author>K Ledoux</author>
<author>C L Yang</author>
</authors>
<title>Processing of reference and the structure of language: an analysis of complex noun phrases. Language and Cognitive Processes,</title>
<date>1999</date>
<contexts>
<context position="19810" citStr="Gordon et al. (1999)" startWordPosition="3118" endWordPosition="3121">en two annotators, 200 NPs. The second ‘taxonomic’ attribute, ANI, is used to annotate whether the objects referred to or quantifier over by an NP are animate or inanimate. This annotation was motivated by a number of studies suggesting that animacy plays an important role in salience (Prat-Sala and Branigan, 2000) and our own experiments suggesting that animacy is much more important than grammatical function, thematic roles, or order of mention in determining which entities are most likely to be pronominalized (Pearson et al., 2001). We also found that the discrepancy between the results of Gordon et al. (1999) and the findings of (Walker and Prince, 1996) can be explained in terms of animacy (Poesio and Nissim, 2001). Animacy was by far the easiest semantic attribute for our annotators: κ = .92. 4.3 Semantic properties of Discourse Entities Semantic properties that may play a role in realization but only apply to discourse entities include:4 Structure Two attributes are used to indicate whether the discourse entity realized by an NP refers to a mass of certain substance or to countable objects (attribute COUNT) and, in case of countable objects, to an atom or a set (attribute STRUCTURE). These attr</context>
</contexts>
<marker>Gordon, Hendrick, Ledoux, Yang, 1999</marker>
<rawString>P. C. Gordon, R. Hendrick, K. Ledoux, and C. L. Yang. 1999. Processing of reference and the structure of language: an analysis of complex noun phrases. Language and Cognitive Processes, 14(4):353–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="3794" citStr="Grosz et al., 1995" startWordPosition="597" endWordPosition="600">enericity, etc.) in about 25% of these texts. The total size of the annotated corpus is about 60K. 3 Identifying Utterances In order to use a corpus to study salience, it is essential to find a way to annotate what in Center1The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh (Oberlander et al., 1998). 2The leaflets in the pharmaceutical subcorpus are a subset of the collection of all patient leaflets in the UK which was digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). ing theory (Grosz et al., 1995) are called UTTERANCES, i.e., the units of text after which the local focus is updated. In most annotations concerned with salience, a predefined notion of utterance was adopted, typically sentences (Miltsakaki, 2002) or (finite) clauses (Kameyama, 1998). This approach, however, precludes using the corpus to compare possible definitions of utterance, one of the goals of the GNOME annotation (Poesio et al., 2004b). In order to do this, we marked all spans of text that might be claimed to update the local focus, including sentences (defined as all units of text ending with a full stop, a questio</context>
<context position="16652" citStr="Grosz et al., 1995" startWordPosition="2611" endWordPosition="2614">was very difficult because of the presence of many references to individual of unspecified gender, such as the maker in the inventory gives neither the name of the maker nor the location. This problem was solved by introducing a special undersp-gen value; indeed, underspecified values were provided for all attributes. The agreement values for these features were: GEN: κ = .89; NUM: κ = .84; PER: κ = .9. GF This attribute was used to annotate the grammatical function of the NP, a property generally taken to play an important role in determining the salience of the discourse entity it realizes (Grosz et al., 1995). Our instructions for this attribute are derived from those used in the FRAMENET project ((Baker et al., 1998); see also http://www.icsi.berkeley.edu/˜framenet/). The values are subj, obj, predicate (used for post-verbal objects in copular sentences, such as This is (a production watch)), there-obj (for post-verbal objects in there-sentences), comp (for indirect objects), adjunct (for the argument of PPs modifying VPs), gen (for NPs in determiner position in possessive NPs), np-compl, np-part, np-mod, adj-mod, and no-gf (for NPs occurring by themselves - eg., in titles). The agreement values </context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):202–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K Gundel</author>
<author>N Hedberg</author>
<author>R Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse.</title>
<date>1993</date>
<journal>Language,</journal>
<volume>69</volume>
<issue>2</issue>
<contexts>
<context position="26315" citStr="Gundel et al., 1993" startWordPosition="4183" endWordPosition="4186"> to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial representation of the discourse model evoked by a text. 5.2 Anaphoric Annotation in GNOME For the GNOME corpus, we adopted a simplified version of the MATE scheme, as for our purposes it’s not essential to mark all semantic relations betwe</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>J. K. Gundel, N. Hedberg, and R. Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, 69(2):274–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hawkins</author>
</authors>
<title>Definiteness and Indefiniteness.</title>
<date>1978</date>
<location>Croom Helm, London.</location>
<contexts>
<context position="24127" citStr="Hawkins (1978)" startWordPosition="3845" endWordPosition="3846">turers went (habitually) on strike (during those years). The last version of the instructions (not yet added to the overall annotation manual) asked annotators to try to identify generic sentences before attempting to determine the value of the GENERIC attribute. With these instructions, we finally reached a reasonable agreement (κ = .82). LOEB Poesio and Vieira (1998) found that of the 1,400 definite descriptions in their corpus, only about 50% were subsequent mention or bridging references, whereas 50% were first mentions. Of the first mentions, about half (i.e., 25% of the total) were what Hawkins (1978) would call ’larger situation’ definites, i.e., definite descriptions like the pope whose referent is supposed to be part of shared knowledge; whereas the other half includes what Loebner (1987) calls SEMANTICALLY FUNCTIONAL definites, like the first man on the Moon. Loebner claimed that the paradigmatic case of definiteness are not anaphoric NPs, as suggested by familiarity theories such as Heim’s (1982), but semantically functional ones such as the first person ever to row across the Pacific on his own. In order to test Loebner’s theory and compare it with one based on familiarity, we annota</context>
<context position="28642" citStr="Hawkins, 1978" startWordPosition="4548" endWordPosition="4549">ect realization can play a crucial role in maintaining the CB. However, previous attempts at marking anaphoric information, particularly in the context of the MUC initiative, suggested that while agreement on identity relations is 6The presence of more than one (anchor) element indicates that the anaphoric expression is ambiguous. fairly easy to achieve, marking bridging references is hard; this was confirmed by Poesio and Vieira (1998). For these reasons, and to reduce the annotators’ work, we did not mark all relations. Besides identity (IDENT) we only marked up three associative relations (Hawkins, 1978): set membership (ELEMENT), subset (SUBSET), and ‘generalized possession’ (FOSS), which includes partof relations as well as ownership relations. We only marked relations between objects realized by noun phrases, excluding anaphoric references to actions, events or propositions implicitly introduced by clauses or sentences. We also gave strict instructions to our annotators limiting how much to mark. As expected, we found a reasonable (if not perfect) agreement on identity relations. In our most recent analysis (two annotators looking at the anaphoric relations between 200 NPs) we observed no </context>
</contexts>
<marker>Hawkins, 1978</marker>
<rawString>J. A. Hawkins. 1978. Definiteness and Indefiniteness. Croom Helm, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Heim</author>
</authors>
<title>The Semantics of Definite and Indefinite Noun Phrases.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ. of Massachusetts at Amherst.</institution>
<contexts>
<context position="26271" citStr="Heim, 1982" startWordPosition="4177" endWordPosition="4178">es with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial representation of the discourse model evoked by a text. 5.2 Anaphoric Annotation in GNOME For the GNOME corpus, we adopted a simplified version of the MATE scheme, as for our purposes it’s not es</context>
</contexts>
<marker>Heim, 1982</marker>
<rawString>I. Heim. 1982. The Semantics of Definite and Indefinite Noun Phrases. Ph.D. thesis, Univ. of Massachusetts at Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Henschel</author>
<author>H Cheng</author>
<author>M Poesio</author>
</authors>
<title>Pronominalization revisited.</title>
<date>2000</date>
<booktitle>In Proc. of 18th COLING.</booktitle>
<contexts>
<context position="795" citStr="Henschel et al., 2000" startWordPosition="117" endWordPosition="120">Kingdom Abstract The GNOME corpus was created to study the discourse and semantic properties of discourse entities that affect their realization and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotat</context>
</contexts>
<marker>Henschel, Cheng, Poesio, 2000</marker>
<rawString>R. Henschel, H. Cheng, and M. Poesio. 2000. Pronominalization revisited. In Proc. of 18th COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschman</author>
</authors>
<title>MUC-7 coreference task definition, version 3.0.</title>
<date>1998</date>
<booktitle>In Proc. of the 7th Message Understanding Conference.</booktitle>
<editor>In N. Chinchor, editor,</editor>
<contexts>
<context position="13328" citStr="Hirschman, 1998" startWordPosition="2060" endWordPosition="2061">ype=&amp;quot;term&amp;quot; onto=&amp;quot;person&amp;quot; ani=&amp;quot;animate&amp;quot; deix=&amp;quot;deix-no&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;set&amp;quot; generic=&amp;quot;generic-yes&amp;quot; loeb=&amp;quot;sort&amp;quot;&gt; scholars &lt;/ne&gt; &lt;unit finite=’finite-no’ id=’u4’ utype=’complement’ verbed=’verbed-yes’&gt; to link &lt;ne id=&amp;quot;ne5&amp;quot; cat=&amp;quot;pers-pro&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot; gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;concrete&amp;quot; ani=&amp;quot;inanimate&amp;quot; deix=&amp;quot;deix-yes&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;atom&amp;quot; generic=&amp;quot;generic-no&amp;quot; loeb=&amp;quot;disc-function&amp;quot;&gt; it &lt;/ne&gt; ... The GNOME instructions for identifying NPs derive from those proposed in MATE (Poesio et al., 1999), in turn derived from DRAMA (Passonneau, 1997) and MUC-7 (Hirschman, 1998). An important difference between the instructions used for GNOME and those developed for MATE is that instead of attempting to get the annotators to recognize the NP that realize discourse entities and only mark those, in GNOME all NPs were marked with (ne) elements; the separate LF TYPE attribute was used to distinguish between NPs with different types of denotations (see below). This change made the process of identifying nominal entities easier and potentially automatic (even though the identification of markables was still done by hand). As in the case of units, the main problem with mark</context>
<context position="25780" citStr="Hirschman, 1998" startWordPosition="4100" endWordPosition="4101">ers is anaphoric annotation (Poesio, 2004b; Poesio et al., 2004b); we only discuss this aspect briefly here. 5.1 Annotating Discourse Models Anaphoric annotation raises a number of difficult and, sometimes, unresolved semantic issues (Poesio, 2004b). As part of the MATE and GNOME projects, an extensive analysis of previously existing schemes for so-called ‘coreference annotation,’ such as the MUC-7 scheme, was carried out, highlighting a number of problems with such schemes, ranging from issues with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves b</context>
</contexts>
<marker>Hirschman, 1998</marker>
<rawString>L. Hirschman. 1998. MUC-7 coreference task definition, version 3.0. In N. Chinchor, editor, In Proc. of the 7th Message Understanding Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>Intra-sentential centering.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse, chapter 6,</booktitle>
<pages>89--112</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<location>Oxford.</location>
<contexts>
<context position="4048" citStr="Kameyama, 1998" startWordPosition="637" endWordPosition="638">corpus collected to support the ILEX and SOLE projects at the University of Edinburgh (Oberlander et al., 1998). 2The leaflets in the pharmaceutical subcorpus are a subset of the collection of all patient leaflets in the UK which was digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). ing theory (Grosz et al., 1995) are called UTTERANCES, i.e., the units of text after which the local focus is updated. In most annotations concerned with salience, a predefined notion of utterance was adopted, typically sentences (Miltsakaki, 2002) or (finite) clauses (Kameyama, 1998). This approach, however, precludes using the corpus to compare possible definitions of utterance, one of the goals of the GNOME annotation (Poesio et al., 2004b). In order to do this, we marked all spans of text that might be claimed to update the local focus, including sentences (defined as all units of text ending with a full stop, a question mark, or an exclamation point) as well as what we called (DISCOURSE) UNITS. Units include clauses (defined as sequences of text containing a verbal complex, all its obligatory arguments, and all postverbal adjuncts) as well as other sentence subconstit</context>
</contexts>
<marker>Kameyama, 1998</marker>
<rawString>M. Kameyama. 1998. Intra-sentential centering. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering Theory in Discourse, chapter 6, pages 89–112. Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>U Reyle</author>
</authors>
<date>1993</date>
<booktitle>From Discourse to Logic. D.</booktitle>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="26293" citStr="Kamp and Reyle, 1993" startWordPosition="4179" endWordPosition="4182">annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial representation of the discourse model evoked by a text. 5.2 Anaphoric Annotation in GNOME For the GNOME corpus, we adopted a simplified version of the MATE scheme, as for our purposes it’s not essential to mark all se</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>H. Kamp and U. Reyle. 1993. From Discourse to Logic. D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Karamanis</author>
</authors>
<title>Entity coherence for descriptive text structuring.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<location>Edinburgh.</location>
<contexts>
<context position="1217" citStr="Karamanis, 2003" startWordPosition="179" endWordPosition="181"> Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandrov-Kabadjov, 2004; Poesio et al., 2004a) Although the results of the studies using the GNOME corpus mentioned</context>
<context position="10967" citStr="Karamanis, 2003" startWordPosition="1771" endWordPosition="1772">ute to mark was UTYPE, and our main problem was to distinguish between relative clauses and parentheticals, since it’s not always easy to tell whether a relative clause is restrictive or non-restrictive (see also (Cheng et al., 2001)). In the end, we adopted rules purely based on surface form (the presence or absence of a comma or other bracketing device). (See also (Quirk and Greenbaum, 1973).) Utterances and Propositions The annotation of units has been shown useful to identify many of the atomic propositions expressed by a text, and was therefore used as a basis for studying text planning (Karamanis, 2003) and aggregation (Cheng, 2001). 4 Properties of Discourse Entities and their Realization The main goal of the GNOME annotation was to study the factors that affect the realization of discourse entities, focusing on those entities realized as NPs. Hence, our main concern was to identify and to annotate the relevant properties both of discourse entities themselves and their realizations in a particular utterance (which we will call FORWARD LOOKING CENTERS, or CFs, following Centering’s terminology). Both types of properties were annotated as properties of the (ne) element, used to mark up NPs in</context>
</contexts>
<marker>Karamanis, 2003</marker>
<rawString>N. Karamanis. 2003. Entity coherence for descriptive text structuring. Ph.D. thesis, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
</authors>
<title>From Treebank to PropBank. In</title>
<date>2002</date>
<booktitle>Proc. ofLREC.</booktitle>
<contexts>
<context position="31688" citStr="Kingsbury and Palmer, 2002" startWordPosition="5054" endWordPosition="5057">onsistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has been argued to be a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can be done, e.g., in Framenet (Baker et al., 1998) and more recently in PropBank (Kingsbury and Palmer, 2002). Planned Revisions of the Scheme A number of aspects of the annotation scheme used for the corpus could be improved. An obvious improvement would be to directly annotate predicates with their WordNet senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus. Of the attributes, COUNT and GENERIC were the most difficult to annotate; further tests with these attributes could be useful. Automatic annotation A substantial part of the annotation work required</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>P. Kingsbury and M. Palmer. 2002. From Treebank to PropBank. In Proc. ofLREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Link</author>
</authors>
<title>The logical analysis of plurals and mass terms: A lattice- theoretical approach. In</title>
<date>1983</date>
<booktitle>Meaning, Use and Interpretation ofLanguage,</booktitle>
<pages>302--323</pages>
<editor>R. B¨auerle, C. Schwarze, and A. von Stechow, editors,</editor>
<note>Walter de Gruyter.</note>
<contexts>
<context position="18712" citStr="Link, 1983" startWordPosition="2945" endWordPosition="2946">ion in there-sentences, and become-style sentences) but the annotators were explicitly asked to check whether the NP was used to express a property. Agreement was more tentative: κ = .73 (for two annotators, 200 NPs). Taxonomic information Two semantic attributes capture information about the type of objects referred to (or quantifier over) by an NP. The first attribute, ONTO, was originally introduced to distinguish between gerunds (event nominalizations such as letter-writing) and bare plurals referring to concrete objects like scholars, both of which semantically denote collective objects (Link, 1983; Portner, 1992). Further distinctions were introduced to deal with ‘difficult’ objects, such as diseases; particular types of concrete objects such as medicines and persons were also singled out. Distinctions captured by the current set of values of ONTO include persons, medicines, other substances, other concrete objects; events, time intervals, or other abstract entities; spatial locations; and diseases. The agreement value for the latest version of ONTO was κ = .8 between two annotators, 200 NPs. The second ‘taxonomic’ attribute, ANI, is used to annotate whether the objects referred to or </context>
</contexts>
<marker>Link, 1983</marker>
<rawString>G. Link. 1983. The logical analysis of plurals and mass terms: A lattice- theoretical approach. In R. B¨auerle, C. Schwarze, and A. von Stechow, editors, Meaning, Use and Interpretation ofLanguage, pages 302–323. Walter de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Loebner</author>
</authors>
<date>1987</date>
<journal>Definites. Journal ofSemantics, 4:279–326. J. Lyons.</journal>
<location>Semantics. Cambridge.</location>
<contexts>
<context position="24321" citStr="Loebner (1987)" startWordPosition="3874" endWordPosition="3875">es before attempting to determine the value of the GENERIC attribute. With these instructions, we finally reached a reasonable agreement (κ = .82). LOEB Poesio and Vieira (1998) found that of the 1,400 definite descriptions in their corpus, only about 50% were subsequent mention or bridging references, whereas 50% were first mentions. Of the first mentions, about half (i.e., 25% of the total) were what Hawkins (1978) would call ’larger situation’ definites, i.e., definite descriptions like the pope whose referent is supposed to be part of shared knowledge; whereas the other half includes what Loebner (1987) calls SEMANTICALLY FUNCTIONAL definites, like the first man on the Moon. Loebner claimed that the paradigmatic case of definiteness are not anaphoric NPs, as suggested by familiarity theories such as Heim’s (1982), but semantically functional ones such as the first person ever to row across the Pacific on his own. In order to test Loebner’s theory and compare it with one based on familiarity, we annotated the NPs referring to discourse entities according to whether they were functional, relational, or sortal (Poesio, 2004a). We achieved good reliability on this attribute (κ = .82), and the re</context>
</contexts>
<marker>Loebner, 1987</marker>
<rawString>S. Loebner. 1987. Definites. Journal ofSemantics, 4:279–326. J. Lyons. 1977. Semantics. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>Instructions for manually annotating the discourse structures of texts.</title>
<date>1999</date>
<note>Unpublished manuscript.</note>
<marker>Marcu, 1999</marker>
<rawString>D. Marcu. 1999. Instructions for manually annotating the discourse structures of texts. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Miltsakaki</author>
</authors>
<title>Towards an aposynthesis of topic continuity and intrasentential anaphora.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="4011" citStr="Miltsakaki, 2002" startWordPosition="632" endWordPosition="633">enter1The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh (Oberlander et al., 1998). 2The leaflets in the pharmaceutical subcorpus are a subset of the collection of all patient leaflets in the UK which was digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). ing theory (Grosz et al., 1995) are called UTTERANCES, i.e., the units of text after which the local focus is updated. In most annotations concerned with salience, a predefined notion of utterance was adopted, typically sentences (Miltsakaki, 2002) or (finite) clauses (Kameyama, 1998). This approach, however, precludes using the corpus to compare possible definitions of utterance, one of the goals of the GNOME annotation (Poesio et al., 2004b). In order to do this, we marked all spans of text that might be claimed to update the local focus, including sentences (defined as all units of text ending with a full stop, a question mark, or an exclamation point) as well as what we called (DISCOURSE) UNITS. Units include clauses (defined as sequences of text containing a verbal complex, all its obligatory arguments, and all postverbal adjuncts)</context>
</contexts>
<marker>Miltsakaki, 2002</marker>
<rawString>E. Miltsakaki. 2002. Towards an aposynthesis of topic continuity and intrasentential anaphora. Computational Linguistics, 28(3):319–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Oberlander</author>
<author>M O’Donnell</author>
<author>A Knott</author>
<author>C Mellish</author>
</authors>
<date>1998</date>
<booktitle>Conversation in the museum. New Review of Hypermedia and Multimedia,</booktitle>
<pages>4--11</pages>
<marker>Oberlander, O’Donnell, Knott, Mellish, 1998</marker>
<rawString>J. Oberlander, M. O’Donnell, A. Knott, and C. Mellish. 1998. Conversation in the museum. New Review of Hypermedia and Multimedia, 4:11–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Passonneau</author>
</authors>
<title>Instructions for applying discourse reference annotation for multiple applications (DRAMA).</title>
<date>1997</date>
<note>Unpublished manuscript.,</note>
<contexts>
<context position="13300" citStr="Passonneau, 1997" startWordPosition="2056" endWordPosition="2057">plur&amp;quot; gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;person&amp;quot; ani=&amp;quot;animate&amp;quot; deix=&amp;quot;deix-no&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;set&amp;quot; generic=&amp;quot;generic-yes&amp;quot; loeb=&amp;quot;sort&amp;quot;&gt; scholars &lt;/ne&gt; &lt;unit finite=’finite-no’ id=’u4’ utype=’complement’ verbed=’verbed-yes’&gt; to link &lt;ne id=&amp;quot;ne5&amp;quot; cat=&amp;quot;pers-pro&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot; gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;concrete&amp;quot; ani=&amp;quot;inanimate&amp;quot; deix=&amp;quot;deix-yes&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;atom&amp;quot; generic=&amp;quot;generic-no&amp;quot; loeb=&amp;quot;disc-function&amp;quot;&gt; it &lt;/ne&gt; ... The GNOME instructions for identifying NPs derive from those proposed in MATE (Poesio et al., 1999), in turn derived from DRAMA (Passonneau, 1997) and MUC-7 (Hirschman, 1998). An important difference between the instructions used for GNOME and those developed for MATE is that instead of attempting to get the annotators to recognize the NP that realize discourse entities and only mark those, in GNOME all NPs were marked with (ne) elements; the separate LF TYPE attribute was used to distinguish between NPs with different types of denotations (see below). This change made the process of identifying nominal entities easier and potentially automatic (even though the identification of markables was still done by hand). As in the case of units</context>
</contexts>
<marker>Passonneau, 1997</marker>
<rawString>R. J. Passonneau. 1997. Instructions for applying discourse reference annotation for multiple applications (DRAMA). Unpublished manuscript., December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pearson</author>
<author>R Stevenson</author>
<author>M Poesio</author>
</authors>
<title>Pronoun resolution in complex sentences.</title>
<date>2000</date>
<booktitle>In Proc. ofAMLAP,</booktitle>
<location>Leiden.</location>
<contexts>
<context position="771" citStr="Pearson et al., 2000" startWordPosition="112" endWordPosition="116">itive Science, United Kingdom Abstract The GNOME corpus was created to study the discourse and semantic properties of discourse entities that affect their realization and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well </context>
</contexts>
<marker>Pearson, Stevenson, Poesio, 2000</marker>
<rawString>J. Pearson, R. Stevenson, and M. Poesio. 2000. Pronoun resolution in complex sentences. In Proc. ofAMLAP, Leiden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pearson</author>
<author>R Stevenson</author>
<author>M Poesio</author>
</authors>
<title>The effects of animacy, thematic role, and surface position on the focusing of entities in discourse.</title>
<date>2001</date>
<booktitle>Proc. of SEMPRO-2001. University of Edinburgh. M. Poesio</booktitle>
<editor>In M. Poesio, editor,</editor>
<contexts>
<context position="19730" citStr="Pearson et al., 2001" startWordPosition="3104" endWordPosition="3107">and diseases. The agreement value for the latest version of ONTO was κ = .8 between two annotators, 200 NPs. The second ‘taxonomic’ attribute, ANI, is used to annotate whether the objects referred to or quantifier over by an NP are animate or inanimate. This annotation was motivated by a number of studies suggesting that animacy plays an important role in salience (Prat-Sala and Branigan, 2000) and our own experiments suggesting that animacy is much more important than grammatical function, thematic roles, or order of mention in determining which entities are most likely to be pronominalized (Pearson et al., 2001). We also found that the discrepancy between the results of Gordon et al. (1999) and the findings of (Walker and Prince, 1996) can be explained in terms of animacy (Poesio and Nissim, 2001). Animacy was by far the easiest semantic attribute for our annotators: κ = .92. 4.3 Semantic properties of Discourse Entities Semantic properties that may play a role in realization but only apply to discourse entities include:4 Structure Two attributes are used to indicate whether the discourse entity realized by an NP refers to a mass of certain substance or to countable objects (attribute COUNT) and, in </context>
</contexts>
<marker>Pearson, Stevenson, Poesio, 2001</marker>
<rawString>J. Pearson, R. Stevenson, and M Poesio. 2001. The effects of animacy, thematic role, and surface position on the focusing of entities in discourse. In M. Poesio, editor, Proc. of SEMPRO-2001. University of Edinburgh. M. Poesio and M. Alexandrov-Kabadjov. 2004. A generalpurpose, off the shelf anaphoric resolver. In Proc. ofLREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>B Di Eugenio</author>
</authors>
<title>Discourse structure and anaphoric accessibility.</title>
<date>2001</date>
<booktitle>In Ivana Kruijff-Korbayov´a and Mark Steedman, editors, Proc. of the ESSLLI 2001 Workshop on Inf. Structure, Disc. Structure and Disc. Semantics.</booktitle>
<marker>Poesio, Di Eugenio, 2001</marker>
<rawString>M. Poesio and B. Di Eugenio. 2001. Discourse structure and anaphoric accessibility. In Ivana Kruijff-Korbayov´a and Mark Steedman, editors, Proc. of the ESSLLI 2001 Workshop on Inf. Structure, Disc. Structure and Disc. Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>M Nissim</author>
</authors>
<title>Salience and possessive NPs: the effect of animacy and pronominalization.</title>
<date>2001</date>
<booktitle>In Proc. of AMLAP</booktitle>
<publisher>(Poster Session).</publisher>
<contexts>
<context position="643" citStr="Poesio and Nissim, 2001" startWordPosition="92" endWordPosition="95"> and Semantic Annotation in the GNOME Corpus Massimo Poesio University of Essex, Department of Computer Science and Centre for Cognitive Science, United Kingdom Abstract The GNOME corpus was created to study the discourse and semantic properties of discourse entities that affect their realization and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of th</context>
<context position="19919" citStr="Poesio and Nissim, 2001" startWordPosition="3137" endWordPosition="3140">s referred to or quantifier over by an NP are animate or inanimate. This annotation was motivated by a number of studies suggesting that animacy plays an important role in salience (Prat-Sala and Branigan, 2000) and our own experiments suggesting that animacy is much more important than grammatical function, thematic roles, or order of mention in determining which entities are most likely to be pronominalized (Pearson et al., 2001). We also found that the discrepancy between the results of Gordon et al. (1999) and the findings of (Walker and Prince, 1996) can be explained in terms of animacy (Poesio and Nissim, 2001). Animacy was by far the easiest semantic attribute for our annotators: κ = .92. 4.3 Semantic properties of Discourse Entities Semantic properties that may play a role in realization but only apply to discourse entities include:4 Structure Two attributes are used to indicate whether the discourse entity realized by an NP refers to a mass of certain substance or to countable objects (attribute COUNT) and, in case of countable objects, to an atom or a set (attribute STRUCTURE). These attributes were marked in order to study the 4These attributes were only marked for about 25% of the corpus. fact</context>
<context position="30982" citStr="Poesio and Nissim, 2001" startWordPosition="4934" endWordPosition="4937">ch than agreement on the CB–in our preliminary experiments we didn’t go beyond κ = .6 when trying to directly identify the CB using the definitions from (Brennan et al., 1987). And secondly, this approach makes it possible to compute the CB according to different ways of instantiating what we call the ‘parameters of Centering’ –e.g., ranking. We developed such scripts for the work discussed in (Poesio et al., 2004b); they can be tested on the web site associated with that paper, http://cswww.essex.ac.uk/staff/poesio/ cbc/. These scripts have been subsequently used to compute the CB in, e.g., (Poesio and Nissim, 2001; Poesio and Nygren-Modjeska, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has been argued to be a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can </context>
</contexts>
<marker>Poesio, Nissim, 2001</marker>
<rawString>M. Poesio and M. Nissim. 2001. Salience and possessive NPs: the effect of animacy and pronominalization. In Proc. of AMLAP (Poster Session).</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Poesio</author>
<author>N Nygren-Modjeska</author>
</authors>
<title>To appear. Focus, activation, and this-noun phrases.</title>
<editor>In A. Branco, R. McEnery, and R. Mitkov, editors,</editor>
<publisher>John Benjamins.</publisher>
<marker>Poesio, Nygren-Modjeska, </marker>
<rawString>M. Poesio and N. Nygren-Modjeska. To appear. Focus, activation, and this-noun phrases. In A. Branco, R. McEnery, and R. Mitkov, editors, Anaphora Processing. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Vieira</author>
</authors>
<title>A corpus-based investigation of definite description use.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="23884" citStr="Poesio and Vieira (1998)" startWordPosition="3803" endWordPosition="3806">. between quantified NPs used (non-generically) to quantify over a specific set of individuals at a particular spatio-temporal location, as in Many lecturers went on strike (on March 16th, 2004), and quantifiers used in generic sentences, as in Many lecturers went (habitually) on strike (during those years). The last version of the instructions (not yet added to the overall annotation manual) asked annotators to try to identify generic sentences before attempting to determine the value of the GENERIC attribute. With these instructions, we finally reached a reasonable agreement (κ = .82). LOEB Poesio and Vieira (1998) found that of the 1,400 definite descriptions in their corpus, only about 50% were subsequent mention or bridging references, whereas 50% were first mentions. Of the first mentions, about half (i.e., 25% of the total) were what Hawkins (1978) would call ’larger situation’ definites, i.e., definite descriptions like the pope whose referent is supposed to be part of shared knowledge; whereas the other half includes what Loebner (1987) calls SEMANTICALLY FUNCTIONAL definites, like the first man on the Moon. Loebner claimed that the paradigmatic case of definiteness are not anaphoric NPs, as sugg</context>
<context position="28468" citStr="Poesio and Vieira (1998)" startWordPosition="4517" endWordPosition="4520">&lt;/unit&gt; &lt;ante current=&amp;quot;ne549&amp;quot; rel=&amp;quot;ident&amp;quot;&gt; &lt;anchor ID=&amp;quot;ne547&amp;quot;&gt; &lt;/ante&gt; Work such as (Sidner, 1979; Strube and Hahn, 1999), as well as our own preliminary analysis, suggested that indirect realization can play a crucial role in maintaining the CB. However, previous attempts at marking anaphoric information, particularly in the context of the MUC initiative, suggested that while agreement on identity relations is 6The presence of more than one (anchor) element indicates that the anaphoric expression is ambiguous. fairly easy to achieve, marking bridging references is hard; this was confirmed by Poesio and Vieira (1998). For these reasons, and to reduce the annotators’ work, we did not mark all relations. Besides identity (IDENT) we only marked up three associative relations (Hawkins, 1978): set membership (ELEMENT), subset (SUBSET), and ‘generalized possession’ (FOSS), which includes partof relations as well as ownership relations. We only marked relations between objects realized by noun phrases, excluding anaphoric references to actions, events or propositions implicitly introduced by clauses or sentences. We also gave strict instructions to our annotators limiting how much to mark. As expected, we found </context>
</contexts>
<marker>Poesio, Vieira, 1998</marker>
<rawString>M. Poesio and R. Vieira. 1998. A corpus-based investigation of definite description use. Computational Linguistics, 24(2):183–216, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>F Bruneseaux</author>
<author>L Romary</author>
</authors>
<title>The MATE meta-scheme for coreference in dialogues in multiple languages.</title>
<date>1999</date>
<booktitle>Proc. of the ACL Workshop on Standards and Tools for Discourse Tagging,</booktitle>
<pages>65--74</pages>
<editor>In M. Walker, editor,</editor>
<contexts>
<context position="13253" citStr="Poesio et al., 1999" startWordPosition="2047" endWordPosition="2050"> allow &lt;ne id=&amp;quot;ne4&amp;quot; cat=&amp;quot;bare-np&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;plur&amp;quot; gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;person&amp;quot; ani=&amp;quot;animate&amp;quot; deix=&amp;quot;deix-no&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;set&amp;quot; generic=&amp;quot;generic-yes&amp;quot; loeb=&amp;quot;sort&amp;quot;&gt; scholars &lt;/ne&gt; &lt;unit finite=’finite-no’ id=’u4’ utype=’complement’ verbed=’verbed-yes’&gt; to link &lt;ne id=&amp;quot;ne5&amp;quot; cat=&amp;quot;pers-pro&amp;quot; per=&amp;quot;per3&amp;quot; num=&amp;quot;sing&amp;quot; gen=&amp;quot;neut&amp;quot; gf=&amp;quot;obj&amp;quot; lftype=&amp;quot;term&amp;quot; onto=&amp;quot;concrete&amp;quot; ani=&amp;quot;inanimate&amp;quot; deix=&amp;quot;deix-yes&amp;quot; count=&amp;quot;count-yes&amp;quot; structure=&amp;quot;atom&amp;quot; generic=&amp;quot;generic-no&amp;quot; loeb=&amp;quot;disc-function&amp;quot;&gt; it &lt;/ne&gt; ... The GNOME instructions for identifying NPs derive from those proposed in MATE (Poesio et al., 1999), in turn derived from DRAMA (Passonneau, 1997) and MUC-7 (Hirschman, 1998). An important difference between the instructions used for GNOME and those developed for MATE is that instead of attempting to get the annotators to recognize the NP that realize discourse entities and only mark those, in GNOME all NPs were marked with (ne) elements; the separate LF TYPE attribute was used to distinguish between NPs with different types of denotations (see below). This change made the process of identifying nominal entities easier and potentially automatic (even though the identification of markables w</context>
</contexts>
<marker>Poesio, Bruneseaux, Romary, 1999</marker>
<rawString>M. Poesio, F. Bruneseaux, and L. Romary. 1999. The MATE meta-scheme for coreference in dialogues in multiple languages. In M. Walker, editor, Proc. of the ACL Workshop on Standards and Tools for Discourse Tagging, pages 65–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Mehta</author>
<author>A Maroudas</author>
<author>J Hitzeman</author>
</authors>
<title>Learning to solve bridging references.</title>
<date>2004</date>
<booktitle>In Proc. of the ACL.</booktitle>
<contexts>
<context position="664" citStr="Poesio et al., 2004" startWordPosition="96" endWordPosition="99">in the GNOME Corpus Massimo Poesio University of Essex, Department of Computer Science and Centre for Cognitive Science, United Kingdom Abstract The GNOME corpus was created to study the discourse and semantic properties of discourse entities that affect their realization and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved bo</context>
<context position="4208" citStr="Poesio et al., 2004" startWordPosition="660" endWordPosition="663">us are a subset of the collection of all patient leaflets in the UK which was digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). ing theory (Grosz et al., 1995) are called UTTERANCES, i.e., the units of text after which the local focus is updated. In most annotations concerned with salience, a predefined notion of utterance was adopted, typically sentences (Miltsakaki, 2002) or (finite) clauses (Kameyama, 1998). This approach, however, precludes using the corpus to compare possible definitions of utterance, one of the goals of the GNOME annotation (Poesio et al., 2004b). In order to do this, we marked all spans of text that might be claimed to update the local focus, including sentences (defined as all units of text ending with a full stop, a question mark, or an exclamation point) as well as what we called (DISCOURSE) UNITS. Units include clauses (defined as sequences of text containing a verbal complex, all its obligatory arguments, and all postverbal adjuncts) as well as other sentence subconstituents that might be viewed as independently updating the local focus, such as parentheticals, preposed PPs, and (the second element of) coordinated VPs. Example</context>
<context position="25227" citStr="Poesio et al., 2004" startWordPosition="4015" endWordPosition="4018">cross the Pacific on his own. In order to test Loebner’s theory and compare it with one based on familiarity, we annotated the NPs referring to discourse entities according to whether they were functional, relational, or sortal (Poesio, 2004a). We achieved good reliability on this attribute (κ = .82), and the results do suggest a much greater correlation between functionality and definiteness than between familiarity and definiteness (Poesio, 2004a). 5 Anaphora The one aspect of the GNOME annotation that has been extensively discussed in previous papers is anaphoric annotation (Poesio, 2004b; Poesio et al., 2004b); we only discuss this aspect briefly here. 5.1 Annotating Discourse Models Anaphoric annotation raises a number of difficult and, sometimes, unresolved semantic issues (Poesio, 2004b). As part of the MATE and GNOME projects, an extensive analysis of previously existing schemes for so-called ‘coreference annotation,’ such as the MUC-7 scheme, was carried out, highlighting a number of problems with such schemes, ranging from issues with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Ext</context>
<context position="30776" citStr="Poesio et al., 2004" startWordPosition="4904" endWordPosition="4907">s’ of a theory of the local focus, and then use scripts to automatically compute the CB. There are two advantages to this approach: first of all, agreement on the ‘building blocks’ is much easier to reach than agreement on the CB–in our preliminary experiments we didn’t go beyond κ = .6 when trying to directly identify the CB using the definitions from (Brennan et al., 1987). And secondly, this approach makes it possible to compute the CB according to different ways of instantiating what we call the ‘parameters of Centering’ –e.g., ranking. We developed such scripts for the work discussed in (Poesio et al., 2004b); they can be tested on the web site associated with that paper, http://cswww.essex.ac.uk/staff/poesio/ cbc/. These scripts have been subsequently used to compute the CB in, e.g., (Poesio and Nissim, 2001; Poesio and Nygren-Modjeska, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has b</context>
</contexts>
<marker>Poesio, Mehta, Maroudas, Hitzeman, 2004</marker>
<rawString>M. Poesio, R. Mehta, A. Maroudas, and J. Hitzeman. 2004a. Learning to solve bridging references. In Proc. of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Stevenson</author>
<author>B Di Eugenio</author>
<author>J M Hitzeman</author>
</authors>
<title>Centering: A parametric theory and its instantiations.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<marker>Poesio, Stevenson, Di Eugenio, Hitzeman, 2004</marker>
<rawString>M. Poesio, R. Stevenson, B. Di Eugenio, and J. M. Hitzeman. 2004b. Centering: A parametric theory and its instantiations. Computational Linguistics, 30(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>Annotating a corpus to develop and evaluate discourse entity realization algorithms.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd LREC,</booktitle>
<pages>211--218</pages>
<location>Athens,</location>
<contexts>
<context position="1109" citStr="Poesio, 2000" startWordPosition="163" endWordPosition="164">cts of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandro</context>
</contexts>
<marker>Poesio, 2000</marker>
<rawString>M. Poesio. 2000a. Annotating a corpus to develop and evaluate discourse entity realization algorithms. In Proc. of the 2nd LREC, pages 211–218, Athens, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<date>2000</date>
<booktitle>The GNOME Annotation Manual, Fourth Edition. Available from http://www.hcrc.ed.ac.uk/ ˜ gnome.</booktitle>
<contexts>
<context position="1109" citStr="Poesio, 2000" startWordPosition="163" endWordPosition="164">cts of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandro</context>
</contexts>
<marker>Poesio, 2000</marker>
<rawString>M. Poesio, 2000b. The GNOME Annotation Manual, Fourth Edition. Available from http://www.hcrc.ed.ac.uk/ ˜ gnome.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>Associative descriptions and salience.</title>
<date>2003</date>
<booktitle>In Proc. of the EACL Workshop on Computational Treatments ofAnaphora,</booktitle>
<location>Budapest.</location>
<contexts>
<context position="1687" citStr="Poesio, 2003" startWordPosition="256" endWordPosition="257">or sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently, the corpus has also been used to develop and evaluate anaphora resolution systems, with a special focus on the resolution of bridging references (Poesio, 2003; Poesio and Alexandrov-Kabadjov, 2004; Poesio et al., 2004a) Although the results of the studies using the GNOME corpus mentioned above have been published in a number of papers, and although a detailed annotation manual was written and has been available on the Web for a few years (Poesio, 2000b), none of the previously published papers discusses in detail the goals of the annotation and the methodology that was followed, especially for the non-anaphoric aspects. In this paper we discuss the methods used to identify possible ‘utterances,’ the properties of NPs and discourse entities that wer</context>
</contexts>
<marker>Poesio, 2003</marker>
<rawString>M. Poesio. 2003. Associative descriptions and salience. In Proc. of the EACL Workshop on Computational Treatments ofAnaphora, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>An empirical investigation of definiteness.</title>
<date>2004</date>
<booktitle>Proc. of the International Conference on Linguistic Evidence, T¨ubingen,</booktitle>
<editor>In S. Kepser, editor,</editor>
<contexts>
<context position="928" citStr="Poesio, 2004" startWordPosition="137" endWordPosition="138">n and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently,</context>
<context position="24849" citStr="Poesio, 2004" startWordPosition="3961" endWordPosition="3962"> to be part of shared knowledge; whereas the other half includes what Loebner (1987) calls SEMANTICALLY FUNCTIONAL definites, like the first man on the Moon. Loebner claimed that the paradigmatic case of definiteness are not anaphoric NPs, as suggested by familiarity theories such as Heim’s (1982), but semantically functional ones such as the first person ever to row across the Pacific on his own. In order to test Loebner’s theory and compare it with one based on familiarity, we annotated the NPs referring to discourse entities according to whether they were functional, relational, or sortal (Poesio, 2004a). We achieved good reliability on this attribute (κ = .82), and the results do suggest a much greater correlation between functionality and definiteness than between familiarity and definiteness (Poesio, 2004a). 5 Anaphora The one aspect of the GNOME annotation that has been extensively discussed in previous papers is anaphoric annotation (Poesio, 2004b; Poesio et al., 2004b); we only discuss this aspect briefly here. 5.1 Annotating Discourse Models Anaphoric annotation raises a number of difficult and, sometimes, unresolved semantic issues (Poesio, 2004b). As part of the MATE and GNOME proj</context>
<context position="26077" citStr="Poesio, 2004" startWordPosition="4148" endWordPosition="4149">ve analysis of previously existing schemes for so-called ‘coreference annotation,’ such as the MUC-7 scheme, was carried out, highlighting a number of problems with such schemes, ranging from issues with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial r</context>
<context position="32499" citStr="Poesio, 2004" startWordPosition="5186" endWordPosition="5187">t senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus. Of the attributes, COUNT and GENERIC were the most difficult to annotate; further tests with these attributes could be useful. Automatic annotation A substantial part of the annotation work required for GNOME now could (and should) be done automatically, or semiautomatically. This includes, most obviously, the identification of sentences and NPs, already done automatically in the VENEX corpus (Poesio, 2004b); and at least grammatical function, animacy, and countability could be automatically annotated in preliminary form with existing techniques, and then corrected by hand. We also plan to use the corpus to bootstrap techniques for automatic identification of uniqueness and gender. Acknowledgments Special thanks to Janet Hitzeman, who collected the first subset of the museum domain for SOLE; to Renate Henschel, who completed the collection of the museum subset and wrote the first version of the annotation manual; to all our annotators; and to Mijail Alexandrov-Kabadjov and Nikiforos Karamanis, </context>
</contexts>
<marker>Poesio, 2004</marker>
<rawString>M. Poesio. 2004a. An empirical investigation of definiteness. In S. Kepser, editor, Proc. of the International Conference on Linguistic Evidence, T¨ubingen, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>The MATE/GNOME scheme for anaphoric annotation, revisited.</title>
<date>2004</date>
<booktitle>In Proc. of SIGDIAL,</booktitle>
<location>Boston,</location>
<contexts>
<context position="928" citStr="Poesio, 2004" startWordPosition="137" endWordPosition="138">n and interpretation, and particularly salience. We discuss what information was annotated and the methods we followed. 1 Introduction The GNOME corpus was created to study the aspects of discourse that appear to affect generation, especially salience (Pearson et al., 2000; Poesio and Di Eugenio, 2001; Poesio and Nissim, 2001; Poesio et al., 2004b). Particular attention was paid to the factors affecting the generation of pronouns (Pearson et al., 2000; Henschel et al., 2000), demonstratives (Poesio and Nygren-Modjeska, To appear) possessives (Poesio and Nissim, 2001) and definites in general (Poesio, 2004a). These results, and the annotated corpus, were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning (Poesio, 2000a; Henschel et al., 2000; Cheng et al., 2001), aggregation (Cheng, 2001) and text planning (Karamanis, 2003). The empirical side of the project involved both psychological experiments and corpus annotation, based on a scheme based on the MATE proposals, as well as on a detailed annotation manual (Poesio, 2000b), the reliability of whose instructions was tested by extensive experiments (Poesio, 2000a). More recently,</context>
<context position="24849" citStr="Poesio, 2004" startWordPosition="3961" endWordPosition="3962"> to be part of shared knowledge; whereas the other half includes what Loebner (1987) calls SEMANTICALLY FUNCTIONAL definites, like the first man on the Moon. Loebner claimed that the paradigmatic case of definiteness are not anaphoric NPs, as suggested by familiarity theories such as Heim’s (1982), but semantically functional ones such as the first person ever to row across the Pacific on his own. In order to test Loebner’s theory and compare it with one based on familiarity, we annotated the NPs referring to discourse entities according to whether they were functional, relational, or sortal (Poesio, 2004a). We achieved good reliability on this attribute (κ = .82), and the results do suggest a much greater correlation between functionality and definiteness than between familiarity and definiteness (Poesio, 2004a). 5 Anaphora The one aspect of the GNOME annotation that has been extensively discussed in previous papers is anaphoric annotation (Poesio, 2004b; Poesio et al., 2004b); we only discuss this aspect briefly here. 5.1 Annotating Discourse Models Anaphoric annotation raises a number of difficult and, sometimes, unresolved semantic issues (Poesio, 2004b). As part of the MATE and GNOME proj</context>
<context position="26077" citStr="Poesio, 2004" startWordPosition="4148" endWordPosition="4149">ve analysis of previously existing schemes for so-called ‘coreference annotation,’ such as the MUC-7 scheme, was carried out, highlighting a number of problems with such schemes, ranging from issues with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial r</context>
<context position="32499" citStr="Poesio, 2004" startWordPosition="5186" endWordPosition="5187">t senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus. Of the attributes, COUNT and GENERIC were the most difficult to annotate; further tests with these attributes could be useful. Automatic annotation A substantial part of the annotation work required for GNOME now could (and should) be done automatically, or semiautomatically. This includes, most obviously, the identification of sentences and NPs, already done automatically in the VENEX corpus (Poesio, 2004b); and at least grammatical function, animacy, and countability could be automatically annotated in preliminary form with existing techniques, and then corrected by hand. We also plan to use the corpus to bootstrap techniques for automatic identification of uniqueness and gender. Acknowledgments Special thanks to Janet Hitzeman, who collected the first subset of the museum domain for SOLE; to Renate Henschel, who completed the collection of the museum subset and wrote the first version of the annotation manual; to all our annotators; and to Mijail Alexandrov-Kabadjov and Nikiforos Karamanis, </context>
</contexts>
<marker>Poesio, 2004</marker>
<rawString>M. Poesio. 2004b. The MATE/GNOME scheme for anaphoric annotation, revisited. In Proc. of SIGDIAL, Boston, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Portner</author>
</authors>
<title>Situation Theory and the Semantics of Propositional Expressions.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Massachusetts at Amherst.</institution>
<contexts>
<context position="18728" citStr="Portner, 1992" startWordPosition="2947" endWordPosition="2948">-sentences, and become-style sentences) but the annotators were explicitly asked to check whether the NP was used to express a property. Agreement was more tentative: κ = .73 (for two annotators, 200 NPs). Taxonomic information Two semantic attributes capture information about the type of objects referred to (or quantifier over) by an NP. The first attribute, ONTO, was originally introduced to distinguish between gerunds (event nominalizations such as letter-writing) and bare plurals referring to concrete objects like scholars, both of which semantically denote collective objects (Link, 1983; Portner, 1992). Further distinctions were introduced to deal with ‘difficult’ objects, such as diseases; particular types of concrete objects such as medicines and persons were also singled out. Distinctions captured by the current set of values of ONTO include persons, medicines, other substances, other concrete objects; events, time intervals, or other abstract entities; spatial locations; and diseases. The agreement value for the latest version of ONTO was κ = .8 between two annotators, 200 NPs. The second ‘taxonomic’ attribute, ANI, is used to annotate whether the objects referred to or quantifier over </context>
</contexts>
<marker>Portner, 1992</marker>
<rawString>P. H. Portner. 1992. Situation Theory and the Semantics of Propositional Expressions. Ph.D. thesis, University of Massachusetts at Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Prat-Sala</author>
<author>H Branigan</author>
</authors>
<title>Discourse constraints on syntactic processing in language production.</title>
<date>2000</date>
<journal>Journal of Memory and Language,</journal>
<pages>42--168</pages>
<contexts>
<context position="19506" citStr="Prat-Sala and Branigan, 2000" startWordPosition="3068" endWordPosition="3071"> persons were also singled out. Distinctions captured by the current set of values of ONTO include persons, medicines, other substances, other concrete objects; events, time intervals, or other abstract entities; spatial locations; and diseases. The agreement value for the latest version of ONTO was κ = .8 between two annotators, 200 NPs. The second ‘taxonomic’ attribute, ANI, is used to annotate whether the objects referred to or quantifier over by an NP are animate or inanimate. This annotation was motivated by a number of studies suggesting that animacy plays an important role in salience (Prat-Sala and Branigan, 2000) and our own experiments suggesting that animacy is much more important than grammatical function, thematic roles, or order of mention in determining which entities are most likely to be pronominalized (Pearson et al., 2001). We also found that the discrepancy between the results of Gordon et al. (1999) and the findings of (Walker and Prince, 1996) can be explained in terms of animacy (Poesio and Nissim, 2001). Animacy was by far the easiest semantic attribute for our annotators: κ = .92. 4.3 Semantic properties of Discourse Entities Semantic properties that may play a role in realization but </context>
</contexts>
<marker>Prat-Sala, Branigan, 2000</marker>
<rawString>M. Prat-Sala and H. Branigan. 2000. Discourse constraints on syntactic processing in language production. Journal of Memory and Language, 42(168–182).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
</authors>
<date>1973</date>
<journal>A University Grammar of English. Longman.</journal>
<contexts>
<context position="6151" citStr="Quirk and Greenbaum, 1973" startWordPosition="970" endWordPosition="973">clude adjunct clauses headed by connectives such as before, after, because and clauses in subject position. In total, the texts used for the main study contain 505 sentences and more than 1,000 units, including 900 finite clauses.3 Sentence and Unit Attributes Sentences have one attribute, STYPE, specifying whether the sentence is declarative, interrogative, imperative, or exclamative. The attributes of units include: • UTYPE: whether the unit is a main clause, a relative clause, appositive, a parenthet3Our instructions for marking up such elements benefited from the discussion of clauses in (Quirk and Greenbaum, 1973) and Marcu’s proposals for discourse units annotation (1999). ical, etc. The possible values for this attribute are main, relative, such-as, appositive, parenthetical, paren-rel, paren-app, parenmain, subject, complement, adjunct, coord-vp,preposed-pp, listitem, cleft, title, disc-marker. • VERBED: whether the unit contains a verb. • FINITE: for verbed units, whether the verb is finite or not. • SUBJECT: for verbed units, whether they have a full subject, an empty subject (expletive, as in there sentences), or no subject (e.g., for infinitival clauses). Annotation Issues Marking up sentences p</context>
<context position="10747" citStr="Quirk and Greenbaum, 1973" startWordPosition="1734" endWordPosition="1737">e=&amp;quot;title&amp;quot;&gt;Side effects&lt;/unit&gt; &lt;p&gt;&lt;s stype=&amp;quot;decl&amp;quot;&gt;&lt;unit&gt; Side effects may occur &lt;unit&gt;when PRODUCTY is applied to large parts of the body, ... &lt;/unit&gt; ... &lt;/unit&gt; ... &lt;/s&gt; ... &lt;/p&gt; Problems with Attributes The most difficult attribute to mark was UTYPE, and our main problem was to distinguish between relative clauses and parentheticals, since it’s not always easy to tell whether a relative clause is restrictive or non-restrictive (see also (Cheng et al., 2001)). In the end, we adopted rules purely based on surface form (the presence or absence of a comma or other bracketing device). (See also (Quirk and Greenbaum, 1973).) Utterances and Propositions The annotation of units has been shown useful to identify many of the atomic propositions expressed by a text, and was therefore used as a basis for studying text planning (Karamanis, 2003) and aggregation (Cheng, 2001). 4 Properties of Discourse Entities and their Realization The main goal of the GNOME annotation was to study the factors that affect the realization of discourse entities, focusing on those entities realized as NPs. Hence, our main concern was to identify and to annotate the relevant properties both of discourse entities themselves and their reali</context>
</contexts>
<marker>Quirk, Greenbaum, 1973</marker>
<rawString>R. Quirk and S. Greenbaum. 1973. A University Grammar of English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Scott</author>
<author>R Power</author>
<author>R Evans</author>
</authors>
<title>Generation as a solution to its own problem.</title>
<date>1998</date>
<booktitle>In Proc. of the 9th INLG.</booktitle>
<contexts>
<context position="3761" citStr="Scott et al., 1998" startWordPosition="591" endWordPosition="594">operties (taxonomic properties, genericity, etc.) in about 25% of these texts. The total size of the annotated corpus is about 60K. 3 Identifying Utterances In order to use a corpus to study salience, it is essential to find a way to annotate what in Center1The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh (Oberlander et al., 1998). 2The leaflets in the pharmaceutical subcorpus are a subset of the collection of all patient leaflets in the UK which was digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). ing theory (Grosz et al., 1995) are called UTTERANCES, i.e., the units of text after which the local focus is updated. In most annotations concerned with salience, a predefined notion of utterance was adopted, typically sentences (Miltsakaki, 2002) or (finite) clauses (Kameyama, 1998). This approach, however, precludes using the corpus to compare possible definitions of utterance, one of the goals of the GNOME annotation (Poesio et al., 2004b). In order to do this, we marked all spans of text that might be claimed to update the local focus, including sentences (defined as all units of text e</context>
</contexts>
<marker>Scott, Power, Evans, 1998</marker>
<rawString>D. Scott, R. Power, and R. Evans. 1998. Generation as a solution to its own problem. In Proc. of the 9th INLG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Towards a computational theory of definite anaphora comprehension in English discourse.</title>
<date>1979</date>
<tech>Ph.D. thesis,</tech>
<institution>MIT.</institution>
<contexts>
<context position="27941" citStr="Sidner, 1979" startWordPosition="4435" endWordPosition="4436">lement itself specifies the index of the anaphoric expression (a (ne) element) and the type of semantic relation (e.g., identity), whereas one or more embedded (anchor) elements indicate possible antecedents.6 (See (8).) (8) &lt;unit finite=’finite-yes’ id=’u227’&gt; &lt;ne id=’ne546’ gf=’subj’&gt; The drawing of &lt;ne id=’ne547’ gf=’np-compl’&gt;the corner cupboard &lt;/ne&gt;&lt;/ne&gt; &lt;unit finite=’no-finite’ id=’u228’&gt;,or more probably &lt;ne id=’ne548’ gf=’no-gf’&gt; an engraving of &lt;ne id=’ne549’ gf=’np-compl’&gt;it &lt;/ne&gt;&lt;/ne&gt; &lt;/unit&gt;, ... &lt;/unit&gt; &lt;ante current=&amp;quot;ne549&amp;quot; rel=&amp;quot;ident&amp;quot;&gt; &lt;anchor ID=&amp;quot;ne547&amp;quot;&gt; &lt;/ante&gt; Work such as (Sidner, 1979; Strube and Hahn, 1999), as well as our own preliminary analysis, suggested that indirect realization can play a crucial role in maintaining the CB. However, previous attempts at marking anaphoric information, particularly in the context of the MUC initiative, suggested that while agreement on identity relations is 6The presence of more than one (anchor) element indicates that the anaphoric expression is ambiguous. fairly easy to achieve, marking bridging references is hard; this was confirmed by Poesio and Vieira (1998). For these reasons, and to reduce the annotators’ work, we did not mark </context>
<context position="31463" citStr="Sidner, 1979" startWordPosition="5015" endWordPosition="5016">swww.essex.ac.uk/staff/poesio/ cbc/. These scripts have been subsequently used to compute the CB in, e.g., (Poesio and Nissim, 2001; Poesio and Nygren-Modjeska, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has been argued to be a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can be done, e.g., in Framenet (Baker et al., 1998) and more recently in PropBank (Kingsbury and Palmer, 2002). Planned Revisions of the Scheme A number of aspects of the annotation scheme used for the corpus could be improved. An obvious improvement would be to directly annotate predicates with their WordNet senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late</context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>C. L. Sidner. 1979. Towards a computational theory of definite anaphora comprehension in English discourse. Ph.D. thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Stevenson</author>
<author>R A Crawley</author>
<author>D Kleinman</author>
</authors>
<title>Thematic roles, focus, and the representation of events.</title>
<date>1994</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>9--519</pages>
<contexts>
<context position="31488" citStr="Stevenson et al., 1994" startWordPosition="5017" endWordPosition="5020">uk/staff/poesio/ cbc/. These scripts have been subsequently used to compute the CB in, e.g., (Poesio and Nissim, 2001; Poesio and Nygren-Modjeska, To appear). 7 Discussions and Conclusion Corpus consistency The main lesson learned from this effort is that actually using a corpus is the best way both to ensure its correctness and to learn which types of information are most useful. Thematic Roles One attribute on which we weren’t able to reach acceptable agreement was the thematic role of an NP, which has been argued to be a better indicator of salience than grammatical function (Sidner, 1979; Stevenson et al., 1994); the agreement value in this case was κ = .35. Other groups however have shown that this can be done, e.g., in Framenet (Baker et al., 1998) and more recently in PropBank (Kingsbury and Palmer, 2002). Planned Revisions of the Scheme A number of aspects of the annotation scheme used for the corpus could be improved. An obvious improvement would be to directly annotate predicates with their WordNet senses instead of annotating ONTO and animacy. We started doing this for the annotation of modifiers (Cheng et al., 2001), and developed an interface to WordNet, but too late to redo the whole corpus</context>
</contexts>
<marker>Stevenson, Crawley, Kleinman, 1994</marker>
<rawString>R. J. Stevenson, R. A. Crawley, and D. Kleinman. 1994. Thematic roles, focus, and the representation of events. Language and Cognitive Processes, 9:519–548.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>U Hahn</author>
</authors>
<title>Functional centering– grounding referential coherence in information structure.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="27965" citStr="Strube and Hahn, 1999" startWordPosition="4437" endWordPosition="4440">specifies the index of the anaphoric expression (a (ne) element) and the type of semantic relation (e.g., identity), whereas one or more embedded (anchor) elements indicate possible antecedents.6 (See (8).) (8) &lt;unit finite=’finite-yes’ id=’u227’&gt; &lt;ne id=’ne546’ gf=’subj’&gt; The drawing of &lt;ne id=’ne547’ gf=’np-compl’&gt;the corner cupboard &lt;/ne&gt;&lt;/ne&gt; &lt;unit finite=’no-finite’ id=’u228’&gt;,or more probably &lt;ne id=’ne548’ gf=’no-gf’&gt; an engraving of &lt;ne id=’ne549’ gf=’np-compl’&gt;it &lt;/ne&gt;&lt;/ne&gt; &lt;/unit&gt;, ... &lt;/unit&gt; &lt;ante current=&amp;quot;ne549&amp;quot; rel=&amp;quot;ident&amp;quot;&gt; &lt;anchor ID=&amp;quot;ne547&amp;quot;&gt; &lt;/ante&gt; Work such as (Sidner, 1979; Strube and Hahn, 1999), as well as our own preliminary analysis, suggested that indirect realization can play a crucial role in maintaining the CB. However, previous attempts at marking anaphoric information, particularly in the context of the MUC initiative, suggested that while agreement on identity relations is 6The presence of more than one (anchor) element indicates that the anaphoric expression is ambiguous. fairly easy to achieve, marking bridging references is hard; this was confirmed by Poesio and Vieira (1998). For these reasons, and to reduce the annotators’ work, we did not mark all relations. Besides i</context>
</contexts>
<marker>Strube, Hahn, 1999</marker>
<rawString>M. Strube and U. Hahn. 1999. Functional centering– grounding referential coherence in information structure. Computational Linguistics, 25(3):309–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
<author>R Kibble</author>
</authors>
<title>On coreferring: Coreference in MUC and related annotation schemes.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<publisher>Squib.</publisher>
<marker>van Deemter, Kibble, 2000</marker>
<rawString>K. van Deemter and R. Kibble. 2000. On coreferring: Coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629–637. Squib.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>E Prince</author>
</authors>
<title>A bilateral approach to givenness.</title>
<date>1996</date>
<booktitle>Reference Accessibility,</booktitle>
<pages>291--306</pages>
<editor>In J. Gundel and T. Fretheim, editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="19856" citStr="Walker and Prince, 1996" startWordPosition="3126" endWordPosition="3129">xonomic’ attribute, ANI, is used to annotate whether the objects referred to or quantifier over by an NP are animate or inanimate. This annotation was motivated by a number of studies suggesting that animacy plays an important role in salience (Prat-Sala and Branigan, 2000) and our own experiments suggesting that animacy is much more important than grammatical function, thematic roles, or order of mention in determining which entities are most likely to be pronominalized (Pearson et al., 2001). We also found that the discrepancy between the results of Gordon et al. (1999) and the findings of (Walker and Prince, 1996) can be explained in terms of animacy (Poesio and Nissim, 2001). Animacy was by far the easiest semantic attribute for our annotators: κ = .92. 4.3 Semantic properties of Discourse Entities Semantic properties that may play a role in realization but only apply to discourse entities include:4 Structure Two attributes are used to indicate whether the discourse entity realized by an NP refers to a mass of certain substance or to countable objects (attribute COUNT) and, in case of countable objects, to an atom or a set (attribute STRUCTURE). These attributes were marked in order to study the 4Thes</context>
</contexts>
<marker>Walker, Prince, 1996</marker>
<rawString>M. A. Walker and E. Prince. 1996. A bilateral approach to givenness. In J. Gundel and T. Fretheim, editors, Reference Accessibility, pages 291–306. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Webber</author>
</authors>
<title>A Formal Approach to Discourse Anaphora.</title>
<date>1979</date>
<publisher>Garland,</publisher>
<location>New York.</location>
<contexts>
<context position="26259" citStr="Webber, 1979" startWordPosition="4175" endWordPosition="4176">ging from issues with the annotation methodology to semantic issues. Proposals for annotating ‘coreference’ such as (Hirschman, 1998) have been motivated by work on Information Extraction, hence the notion of ‘coreference’ used is very difficult to relate to traditional ideas about anaphora (van Deemter and Kibble, 2000). A distinctive feature of the GNOME annotation (and the MATE proposals from which they derive (Poesio, 2004b)) are explicitly based on the DISCOURSE MODEL assumption adopted almost universally by linguists (computational and not) working on anaphora resolution and generation (Webber, 1979; Heim, 1982; Kamp and Reyle, 1993; Gundel et al., 1993). This is the hypothesis that interpreting a discourse involves building a shared discourse model containing DISCOURSE ENTITIES that may or may not ‘refer’ to specific objects in the world, as well as the relations between these entities. The annotation for which the MATE scheme was developed–that we’ll call here ’anaphoric annotation,’ is meant as a partial representation of the discourse model evoked by a text. 5.2 Anaphoric Annotation in GNOME For the GNOME corpus, we adopted a simplified version of the MATE scheme, as for our purposes</context>
</contexts>
<marker>Webber, 1979</marker>
<rawString>B. L. Webber. 1979. A Formal Approach to Discourse Anaphora. Garland, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>