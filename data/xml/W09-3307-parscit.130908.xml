<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.919416">
Construction of Disambiguated Folksonomy Ontologies Using Wikipedia
Noriko Tomuro and Andriy Shepitsen
DePaul University, College of Digital Media
243 S. Wabash, Chicago, IL USA
</note>
<email confidence="0.961926">
tomuro@cs.depaul.edu, ashepits@cdm.depaul.edu
</email>
<sectionHeader confidence="0.994171" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999798482758621">
One of the difficulties in using Folk-
sonomies in computational systems is tag
ambiguity: tags with multiple meanings.
This paper presents a novel method for
building Folksonomy tag ontologies in
which the nodes are disambiguated. Our
method utilizes a clustering algorithm
called DSCBC, which was originally de-
veloped in Natural Language Processing
(NLP), to derive committees of tags, each
of which corresponds to one meaning or
domain. In this work, we use Wikipedia
as the external knowledge source for the
domains of the tags. Using the commit-
tees, an ambiguous tag is identified as one
which belongs to more than one commit-
tee. Then we apply a hierarchical agglom-
erative clustering algorithm to build an on-
tology of tags. The nodes in the derived
ontology are disambiguated in that an am-
biguous tag appears in several nodes in
the ontology, each of which corresponds
to one meaning of the tag. We evaluate the
derived ontology for its ontological den-
sity (how close similar tags are placed),
and its usefulness in applications, in par-
ticular for a personalized tag retrieval task.
The results showed marked improvements
over other approaches.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99978736">
In recent years, there has been a rapid growth in
social tagging systems – so-called Folksonomies
where users assign keywords or tags to categorize
resources. Typically, the sources of folksonomies
are web resources, and virtually any kind of infor-
mation available on the Internet, ranging from web
pages (e.g. Delicious (delicious.com)), scientific ar-
ticles (e.g. Bibsonomy (www.bibsonomy.org)) to me-
dia resources (e.g. Flickr (www.flickr.com), Last.fm
(www.last.fm)). Although tags in folksonomies are
essentially semantic concepts, they have distinct
characteristics as compared to conventional se-
mantic resources which are often used in Natu-
ral Language Processing (NLP), such as WordNet
(Miller, 1990). First, folksonomy tags are unre-
stricted – users are free to choose any words or
set of characters to formulate tags. One significant
problem arising from such free-formedness is tag
ambiguity: tags that have several meanings (e.g.
“Java” as coffee or a programming language or an
island in Indonesia). Second, folksonomy tags are
unstructured – tags assigned to a given resource
are simply enumerated in a list (although often-
times using a varying font size to indicate popu-
larity), and no special organization or categoriza-
tion of the tags is made (by the Folksonomy site).
There have been several work recently which ex-
tracted structures from folksonomy tags and con-
structed ontologies (e.g. (Clough et al., 2005),
(Schmitz, 2006)). However, most of them evalu-
ate the effect of the extracted structures only in the
context of specific applications, for instance gen-
erating user recommendations (e.g. (Shepitsen et
al., 2008)).
In this work, we develop a novel method for
constructing ontologies from folksonomy tags.
In particular, we employ a clustering algorithm
called Domain Similarity Clustering By Commit-
tee (DSCBC) (Tomuro et al., 2007). DSCBC is an
extension of an algorithm called CBC (Pantel and
Lin, 2002), and was originally developed for lexi-
cal semantics in NLP to automatically derive sin-
gle/unambiguous word meanings (as committees)
from ambiguous words. In this work, DSCBC is
effectively adopted to derive disambiguated folk-
sonomy tag committees, where a committee in this
context is a cluster of tags in which the members
share the same or very similar concept in one of
their meanings. By using DSCBC, an ambiguous
tag is identified as one which belongs to more than
</bodyText>
<page confidence="0.983207">
42
</page>
<note confidence="0.998959">
Proceedings of the 2009 Workshop on the People’s Web Meets NLP, ACL-IJCNLP 2009, pages 42–50,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999924117647059">
one committee. One of the key ideas in DSCBC is
the notion of feature domain similarity: the sim-
ilarity between the features themselves, obtained
a priori from sources external to the dataset used
at hand. For example, if data instances x and y
are represented by features f1 and f2, the feature
domain similarity refers to the similarity between
f1 and f2 (not between x and y). DSCBC uti-
lizes this feature domain similarity to derive clus-
ters whose domains are ’close’, thereby produc-
ing unambiguous committees. In this work, we in-
corporate Wikipedia as the external knowledge re-
source, and use the similarity between Wikipedia
articles to derive the committees of disambiguated
tags. Finally using the tag committees derived by
DSCBC, we build an ontology of tags by using a
modified hierarchical agglomerative clustering al-
gorithm. Ambiguous tags are mapped to several
nodes in this ontology.
Note that in this paper, we refer to the structure
derived by the hierarchical clustering algorithm as
an ’ontology’ instead of a ’taxonomy’. That is be-
cause, in the algorithm, the parent-child relation is
determined by a similarity measure only, therefore
sometimes does not correspond to the subsump-
tion relation in the strict sense.
For evaluation, we construct an ontology from
the Delicious tags, and measure the quality (onto-
logical density) of the derived ontology by com-
paring with the ontologies obtained without using
Wikipedia. We also use the derived ontology in
a personalized information retrieval task. The re-
sults show that our method achieved marked im-
provements over other approaches.
</bodyText>
<sectionHeader confidence="0.99977" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999400423076923">
Several efforts have been made recently which fo-
cused on extracting structures from folksonomies.
Clough (Clough et al., 2005) and Schmitz
(Schmitz, 2006) derived hierarchical structures
from image folksonomies (St. Andrew collection
(specialcollections.st-and.ac.uk/photcol.htm) and Flickr,
respectively). In addition to the hierarchi-
cal relation, they also derived other relations
such as ”type of”, ”aspect of”, ”same-as”, etc.
Mika (Mika, 2007) and Heymann (Heymann and
Garcia-Molina, 2006) proposed an automatic cre-
ation of tags in folksonomy networks based on
the tag co-occurrences among resources and users.
They then used a graph clustering algorithm to
connect tags which were used by the same users
and for the same resources to identify tag ’clouds’
and communities of like-minded users. However,
none of those work used NLP techniques, nor did
they deal with the tag ambiguity problem; Often-
times, highly ambiguous tags are even removed
from the data.
In our previous work (Shepitsen et al., 2008),
we used a standard hierarchical agglomerative
clustering algorithm to build a tag hierarchy. We
also considered only the most popular sense of an
ambiguous tag and ignored all other senses.
Wikipedia has been attracting much atten-
tion in the recent NLP research. For exam-
ple, Wikipedia as a lexical resource was ex-
ploited for thesauri construction (Milne et al.,
2006) and for word sense disambiguation (Mi-
halcea and Csomai, 2007). Other NLP tasks in
which Wikipedia was utilized to provide contex-
tual and domain/encyclopedia knowledge include
question-answering (Ahn et al., 2004) and infor-
mation extraction (Culotta et al., 2006). In a simi-
lar vein, (Gabrilovich and Markovitch, 2006) also
used Wikipedia to improve the accuracy for text
categorization. An interesting text retrieval appli-
cation was done by Gurevych (Gurevych et al.,
2007), in which Wikipedia was utilized to improve
the retrieval accuracy in matching the professional
interests of job applicants with the descriptions of
professions/careers.
The work presented in this paper applies an
NLP technique (the DSCBC algorithm), which in-
corporates the domain knowledge (Wikipedia) as
a critical component, to the task of extracting se-
mantic structure, in particular an ontology, from
folksonomies. Our method is novel, and the ex-
perimental results indicate that the derived ontol-
ogy was of high semantic quality.
</bodyText>
<sectionHeader confidence="0.907156" genericHeader="method">
3 Deriving Unambiguous Tag
Committees
</sectionHeader>
<bodyText confidence="0.999595">
The DSCBC algorithm, which we had developed
in our previous work (Tomuro et al., 2007), is
an extension of CBC Clustering (Pantel and Lin,
2002), modified to produce unambiguous clusters
when the data contained ambiguous instances. As-
suming the instances are represented by vectors of
features/domains, consider the following data:
</bodyText>
<equation confidence="0.903726">
a b c d
1 1 0 0
1 0 1 0
1 0 0 1
</equation>
<page confidence="0.994646">
43
</page>
<bodyText confidence="0.999994769230769">
where x, y, z are data instances, and a, b, c, d
are features. In most clustering algorithms, fea-
tures are assumed to be independent to each other,
or their dependencies are ignored. So in the ex-
ample, x is equally likely clustered with y or z,
because the similarity between x and y, and x and
z are the same (based on the Euclidean distance,
for example). However if we have a priori, gen-
eral knowledge about the features that b’s domain
is more similar to that of c than to d, it is better
to cluster x and y instead of x and z, because the
{x, y} cluster is “tighter” than the {x, z} cluster
with respect to the domains of the features.
</bodyText>
<subsectionHeader confidence="0.997675">
3.1 Feature Domain Similarity
</subsectionHeader>
<bodyText confidence="0.99991896875">
In DSCBC, the general knowledge about the fea-
tures is incorporated as a measure called Fea-
ture Domain Similarity: the similarity between
the features themselves, obtained a priori from
sources external to the dataset used at hand. In this
work, we used Wikipedia as the external knowl-
edge source, and as the features to represent the
folksonomy tags. To this end, we first obtained the
most recent dump of Wikipedia and clustered the
articles to reduce the size of the data. We call such
a cluster of Wiki articles a Wiki concept. Cluster-
ing was based on the similarity of the terms which
appeared in the articles. Detailed descriptions of
the Wikipedia data and this clustering process are
given in section 5.1. Then given a set of folkson-
omy tags T, a set of folksonomy resources R and
a set of Wiki concepts W, we defined a matrix M
of size |T  |x |W |, where the rows are tags and the
columns/features are Wiki concepts. Each entry
in this matrix, for a tag t E T and a Wiki con-
cept w E W, was computed as the cosine between
two term vectors: one for t where the features are
terms used in (all of) the resources in R to which
t was assigned (by the folksonomy users), and an-
other for w where the features are terms used in
(all of) the Wiki articles in w. Thus, the matrix
M contains the similarity values for a given tag
to all Wikipedia concepts, thereby identifying the
(Wikipedia) domains of the tag.
Using the matrix M, we define the feature do-
main similarity between two tags f and g, denoted
fd5im(f, g), as:
</bodyText>
<equation confidence="0.704776">
fd5im �j (f, g) = Ei P fZ x gj x cos(wi, wj)
qP i f2i x Pi g2i
</equation>
<bodyText confidence="0.99991664516129">
where fi is the similarity of the tag f to the ith
Wiki concept (and likewise for g), and cos(wi, wj)
is the cosine (thus similarity) between the ith and
jth Wiki concepts. In this formula, the domain
knowledge is incorporated not only through the
way a tag is represented (as a vector of Wiki con-
cepts), but also directly by cos(wi, wj), the simi-
larity between Wiki concepts themselves.
In addition to Feature Domain Similarity, we
also incorporated a measure of reference tight-
ness for folksonomy tags and Wiki concepts. This
metric measures and takes advantage of the link
structure in the folksonomy system as well as
Wikipedia. For example, when a tag was assigned
to several web pages in the folksonomy system,
some of those pages may be reachable from each
other through hyperlinks – in which case, we can
consider the tag’s domains are tight. Likewise for
Wiki concepts, if a folksonomy tag is ’similar’
to several Wiki concepts (for which the similar-
ity value is above some threshold), some of those
Wiki concepts may be reachable in the Wikipedia
structure – then we can consider the tag’s domains
are tight as well. Furthermore, based on the notion
of reference tightness within a set of resources, we
define the connectedness between two sets of re-
sources as the fraction of the resources (web pages
or Wiki concepts) in one set which are reachable to
resources in another set. We define the reference
tightness between two sets of resources 5 and U,
denoted srt(5, U), as follows.
</bodyText>
<equation confidence="0.945568666666667">
P
sES,uEU reach(s, u) + reach(u, s)
srt(S, U) = PsES nRef(s) + PuEU nRef(u)
</equation>
<bodyText confidence="0.999946714285714">
where nRef(k) is the number of outgoing refer-
ence links in the resource k, and reach(a, b) is an
indicator function which returns 1 if any reference
link from the resource in a is reachable from any
resource in b or 0 otherwise. There are two terms
in the numerator because the reachability relation
is directional.
</bodyText>
<subsectionHeader confidence="0.999336">
3.2 The DSCBC Algorithm
</subsectionHeader>
<bodyText confidence="0.999840333333333">
Using the notions of feature domain similarity and
reference tightness, we define the similarity be-
tween two tags f and g as follows.
</bodyText>
<equation confidence="0.9799075">
ds5im(f, g) = α x fd5im(f, g)
+(1 − α) x srt(Rf, Rg)
</equation>
<bodyText confidence="0.999488666666667">
where Rf is the set of references from all web
pages to which the tag f is assigned, srt(Rf, Rg)
is the reference tightness between Rf and Rg, and
</bodyText>
<page confidence="0.995059">
44
</page>
<bodyText confidence="0.999964045454545">
α is a weighting coefficient. In our experiments
(discussed in section 5), we set α to be 0.8 based
on the results of the preliminary runs.
The DSCBC algorithm is shown in Algo-
rithm 1. DSCBC is an unsupervised clustering
algorithm which automatically derives a set of
committees. A committee is a group of folkson-
omy tags which are very similar to each other. In
Phase I, a set of preliminary tag clusters are first
created. In Phase II, some of those tag clusters are
selected as committees – those which are dissimi-
lar/orthogonal to all other committees selected so
far. Then in Phase III, each tag is assigned to com-
mittees which are similar to the tag. The ds5im
function is used in Phase I and II to measure
the similarity between clusters and committees
respectively. In Phase III, an ambiguous tag is
assigned to one of more committees, where each
time the features of the assigned committee are
removed from the tag. Thus, ambiguous tags are
identified as those which belong to more than one
committee.
</bodyText>
<sectionHeader confidence="0.839627" genericHeader="method">
4 Building Folksonomy Tag Ontology
</sectionHeader>
<bodyText confidence="0.999891666666667">
After obtaining the committees by DSCBC, we or-
ganize the tags into a ontology by using a modified
hierarchical agglomerative clustering algorithm.1
We first compute the pair-wise similarity between
any two tags and sort those pairs according to the
similarity values. Then we take the most similar
pair and create the first cluster. Afterwards, we it-
erate through the whole tag/cluster pairs and sub-
stitute all instances in which either tag is a mem-
ber, if the tag is not ambiguous, by the obtained
cluster, and repeat the process until the list of pairs
is empty. The committees derived by DSCBC are
utilized to identify ambiguous tags – when a tag
belonged to more than one committee. When we
process an ambiguous tag, we first find its “core
meaning” by finding the committee to which the
tag is most similar, then remove all (non-zero) fea-
tures that are encoded in committee from all in-
stances left in the dataset. With this scheme, we
can cover all senses of an ambiguous tag, for all
such tags, during ontology generation. The simi-
larity is computed using the ds5im function de-
scribed in the previous section; the only difference
that, if one member of a pair is a cluster, it is rep-
</bodyText>
<footnote confidence="0.742394">
1Our algorithm is essentially a modification of the
Average-Link Clustering by (OConnor and Herlocker, 2001).
</footnote>
<bodyText confidence="0.935218357142857">
Input: Set of tags T. Tuning coefficients:
n - number of the most similar tags chosen for
the target tag
q - number of features for finding the centroid
Q - similarity threshold for adding tags to
committees
-y - similarity threshold for assigning tags to
committees
Output: Set of committees C. Set of tags T
where each t E T is assigned to
committees in C.
Phase I. Finding set of clusters L
foreach ti E T do
Select a set k of n most similar tj : i 7� j
add k to L if it is not already in L.
end
Phase II. Find Communities C
foreach c E L do
Find the centroid of c using only q
features shared by most of tags in the
cluster
Add c to C if its similarity to every other
cluster is lower than Q
end
Phase III. Assign tags to committees
foreach t E T do
Assign t to committee c in C if the
similarity is higher than -y
</bodyText>
<listItem confidence="0.3823695">
end
Algorithm 1: Clustering tags using DSCBC
</listItem>
<page confidence="0.997046">
45
</page>
<bodyText confidence="0.7262905">
resented by its centroid. Figure 1 shows an exam-
ple folksonomy ontology. The modified hierarchi-
cal agglomerative clustering algorithm is shown in
Algorithm 2.
</bodyText>
<note confidence="0.315761">
Sport
</note>
<figureCaption confidence="0.999115">
Figure 1: Example Folksonomy Ontology
</figureCaption>
<bodyText confidence="0.833370571428571">
Input: Set of tags T. Set of Committees C.
Output: An ontology of folksonomy tags.
L is a list containing pairs of tag/clusters with
associated similarity, initially empty.
foreach ti E T do
Compute the similarity to all other tags tj
(i 7� j), and add a pair (ti7 tj) in L.
</bodyText>
<listItem confidence="0.8709385">
end
while L is not empty do
1. Sort L by the similarity of the pairs.
2. Pop the pair with the highest similarity
</listItem>
<bodyText confidence="0.816949">
from L. Let it (ti7 α). α can be a single
tag or a cluster of tags.
</bodyText>
<listItem confidence="0.941069">
3. Make ti the parent of α.
4. Join ti with α, and create a new cluster
0.
</listItem>
<bodyText confidence="0.6992065">
if ti belongs to more than one committee
in C then
</bodyText>
<listItem confidence="0.935023272727273">
1. Find the committee c which is the
most similar to ti.
2. Remove all features intersecting
with c from ti.
end
else
1. Substitute all instances of ti in the
pairs in L by 0.
end
end
Algorithm 2: Ontology Construction Algorithm
</listItem>
<sectionHeader confidence="0.991007" genericHeader="method">
5 Experimental Evaluations
</sectionHeader>
<bodyText confidence="0.999934888888889">
We applied our proposed algorithm to data from
a real-world social tagging system Delicious and
derived a tag ontology. Then we evaluated the de-
rived ontology on two aspects: the density of the
ontology, and the usefulness of the ontology in a
personalized Information Retrieval (IR) task. Note
that in the experiments, we determined the values
for all tuning coefficients in the algorithms during
the preliminary test runs.
</bodyText>
<subsectionHeader confidence="0.885554">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999988615384615">
We first crawled the Delicious site and ob-
tained data consisting of 29,918 users, 6,403,442
resources and 1,035,177 tags. In this data,
47,184,492 annotations were made by just one
user, or for one resource, or by one tag. This dis-
tribution followed the Zipf’s law – small numbers
of tags were in frequent use and large numbers of
tags were rarely used. Our intuitions were that the
effect of using the semantic/encyclopedia knowl-
edge from Wikipedia would probably be better re-
flected in the low frequency “long tail” part of
the Zipf’s distribution rather than the high fre-
quency part. Likewise for users, we have dis-
covered in our previous research that search per-
sonalization algorithms often produce different re-
sults for users with rich profiles and for users who
have sparse profiles. This problem is known as the
”Cold Start” problem in search personalization: a
new user has very little information/history in the
profile, therefore the system cannot reliably infer
his/her interests. Since our experiments included
a personalized IR task, we decided to extract two
subsets from the data: one set containing high fre-
quency tags assigned by users with rich profiles
(randomly selected 1,000 most frequent tags en-
tered by 100 high profile users), and another con-
taining low frequency tags assigned by users with
sparse profiles (randomly selected 1,000 least fre-
quent tags entered by 100 sparse profile users). We
refer to the former set as the ”Frequent Set” and
the latter set as the ”Long Tail Set”. The total
number of resources in each dataset was 16,635
and 3,356 respectively.
Then for both datasets, we applied a part-
of speech tagger to all resources and extracted
all nouns (and discarded all other parts of
speech). We also applied the Porter Stemmer
(tartarus.org/∼martin/PorterStemmer) to eliminate terms
with inflectional variations. Finally, we repre-
</bodyText>
<figure confidence="0.999241166666667">
Russion_books
66_games
Chess
Fisher_gen
Iceland
Gym_complex
Fitness
Loosing_weight
Spassky
Pools
Soccer
Trade_meals
</figure>
<page confidence="0.999133">
46
</page>
<bodyText confidence="0.9999548">
sented each resource page as a vector of stemmed
terms, and the values were term frequencies.
As for Wikipedia, we used its English
version available from BitTorrent Network
(www.bittorrent.com). The original data (the most
recent dump, as of 24 July, 2008) contained
13,916,311 pages. In order to reduce the size
to make the computation feasible, we randomly
chose 75,000 pages (which contained at least 50
words) and applied the Maximal Complete Link
clustering algorithm to further reduce the size.
After clustering, we obtained a total of 43,876
clusters, most of which contained one or two Wiki
articles, but some of which had several articles.
We call such a Wiki article cluster Wiki concept.
As with the tag datasets, for each Wiki article
we applied the Porter Stemmer to reduce the num-
ber of the terms. Then we represented each Wiki
concept page as a vector of stemmed terms, and
the values were term frequencies.
</bodyText>
<subsectionHeader confidence="0.99547">
5.2 Evaluation 1: Ontological Density
</subsectionHeader>
<bodyText confidence="0.999996268292683">
For the first evaluation, we evaluated the derived
Delicious tag ontology directly by measuring the
topological closeness of similar semantic concepts
in the ontology. To that end, we developed a no-
tion of ontological density: all tags assigned to a
specific resource should be located close to each
other in the ontology. For instance, a web resource
java.sun.com in Delicious is assigned with various
tags such as ’Java’, ’Programming’ and ’Technol-
ogy’. Those tags should be concentrated in one
place rather than scattered over various sections in
the ontology. By measuring the distance as the
number of edges in the ontology between tags as-
signed to a specific resource, we can obtain an es-
timate of the ontology density for the resource.
Then finding the average density of all resources
can give us an approximation of the overall den-
sity of the ontology’s quality.
But here a difficulty arises for ambiguous tags
– when a tag is ambiguous and located in several
places in the ontology. In those cases, we chose
the sense (an ontology node) which is the clos-
est to the unambiguous tags assigned to the same
resource. For example, Figure 2 shows a part of
the ontology where an ambiguous tag ’NLP’ (with
two senses) is mapped: 1) Natural Language Pro-
cessing (the left one in the figure), and 2) Neuro-
linguistic programming (the right one in the fig-
ure). The target web resource is tagged with three
tags: two unambiguous tags ’POS’ and ’Porter’,
and an ambiguous tag ’NLP’. To identify the sense
of ’NLP’ for this resource, we count the number
of edges from the two unambiguous tags (’POS’,
’Porter’) to both ’NLP’ tag nodes, and select the
one which has the shortest distance. In the figure,
the first sense has the total distance of 4 (= 2 edges
from ’Pos’ + 2 edges from ’Porter’), while the sec-
ond sense has the distance 10 (= 5 edges from
’Pos’ + 5 edges from ’Porter’). Therefore, we
select the first sense (’Natural Language Process-
ing’) as the meaning of ’NLP’ for this resource.
</bodyText>
<figure confidence="0.314161">
Research
</figure>
<figureCaption confidence="0.939995">
Figure 2: Example of Ambiguous Tags in the On-
tology
</figureCaption>
<bodyText confidence="0.999958">
Formally we define the density of the ontology
T for the set of resources R, denoted Dens(T, R),
as the average density over all resources in R, as
follows.
</bodyText>
<equation confidence="0.903541">
Dens(T, R) =R |E density(r, T)
I
</equation>
<bodyText confidence="0.999966">
where density(r, T) denotes the density for the
given resource r for the ontology T, defined as:
</bodyText>
<equation confidence="0.989559">
nTags(r) − 1
density(r, T) =
argminz dist(node(i,T), node(j,T))
</equation>
<bodyText confidence="0.999840909090909">
and nTags(r) is the number of tags assigned to
r, node(k, T) is the node in T for the kth tag (as-
signed to r), and dist(n1, n2) is the number of
edges between nodes n1 and n2 in T. So the
density for the given resource is essentially the
inverse of the minimum distance among the tags
assigned to it. We computed the density value
for the ontology derived by our approach (’On-
tology Enhanced with Wiki Concepts’) and com-
pared with the ontologies obtained by using only
the resources (where a tag vector is presented by
</bodyText>
<figure confidence="0.9971458125">
POS
Web-resource
Porter
NLP
Linguistics
Psychology
Twitter
NLP
Mind
Dictionary
Language
Communic
NLP
POS Porter
Web2.0 Media
r∈R
</figure>
<page confidence="0.998746">
47
</page>
<bodyText confidence="0.999647444444444">
the stemmed terms in the resources to which the
tag is assigned), and only the tags (where a tag
vector is presented by the resource to which they
were assigned). Figures 3 and 4 show the results,
for the two datasets. For both datasets, the dif-
ferences between the three ontologies were statis-
tically significant (at p=0.05), indicating that the
encyclopedia knowledge obtained from Wikipedia
was indeed effective in deriving a semantically
dense ontology.
Here, one observation is that the relative im-
provement was more significant for the “Frequent
Set” than the “Long Tail Set”. The reason is be-
cause frequent tags are generally more ambigu-
ous than less frequent tags (as with words in gen-
eral), therefore the effect of tag disambiguation by
DSCBC was more salient, relatively, for the fre-
quent tags.
</bodyText>
<figureCaption confidence="0.999154">
Figure 3: Ontological Density for “Frequent Set”
Figure 4: Ontological Density for “Long Tail Set”
</figureCaption>
<subsectionHeader confidence="0.789536">
5.3 Evaluation 2: Personalized Information
Retrieval
</subsectionHeader>
<bodyText confidence="0.999442702702703">
For the second evaluation, we used the derived De-
licious ontology in an IR task and measured its
utility. In particular, we personalized the search
results for a given user by utilizing the tag ontol-
ogy as a way to present the user profile and infer
his/her information needs.
Using the derived ontology, we search in the on-
tology for the query tag entered by a specific user.
We first match the ontology with the user’s profile
and derive a score distribution for the nodes in the
tree which reflects the user’s general interest. To
do so, we take each tag in the user’s profile as the
initial activation point, then spread the activation
up and down the ontology tree, for all tags.
To spread activation from a given node, we
use two parameters: decay factor, which deter-
mines the amount of the interest to be transfered
to the parent/child of the current node; and damp-
ing threshold - if the interest score becomes less
than this value we stop further iteration. Thus the
resulting score distribution of the tree is effectively
personalized to the user’s general interest.
Using the obtained score distribution of a given
user, we search the tree for a query tag (of this
user). In the same way as the tags in the profile, we
spread activation over the ontology from the node
to which the tag belongs, but this time we add a
weight to emphasize the relative importance of the
query tag compared to the tags from the profile,
because the query reflects the user’s current infor-
mation needs. Finally we feed the preference vec-
tor to the modified FolkRank algorithm (Hotho et
al., 2006) to retrieve and rank the relevant web re-
sources which reflect the user-specific preferences.
Figure 5 shows the overall scheme of the person-
alized ranked retrieval using an ontological user
profile.
</bodyText>
<figureCaption confidence="0.802196">
Figure 5: Ranked Retrieval in Folksonomies using
Ontological User Profile
</figureCaption>
<bodyText confidence="0.999134">
We evaluated the retrieval results by 5-fold
cross validation. Given a test user profile, we used
</bodyText>
<figure confidence="0.999103212765957">
Ontology Enhanced Ontology Enhanced Ontology Based
with Wiki Concepts by Resources on Tags
Density
0,045
0,043
0,041
0,039
0,037
0,035
Ontology Enhanced Ontology Enhanced Ontology Based
with Wiki Concepts by Resources on Tags
Density
0,25
0,15
0,05
0,3
0,2
0,1
User Profiles
Spasskiy Loosing_weight
Russion_books
66_games Iceland Spassky
Chess Fitness Soccer
Fisher_gen
Spreading
Activation
Gym_complex
Sport
Loosing_weight
Pools
...
Tn
Trade_meals
Russion_books
66_games Iceland Spassky
Chess Fitness Soccer
Tags
Fisher_gen
Preference vector
Ranked Resourses
Users
Gym_complex
Loosing_weight
Sport
Resourses
Pools
Trade_meals
</figure>
<page confidence="0.998099">
48
</page>
<bodyText confidence="0.939843333333333">
the leave-one-out method for tags – we removed a
target tag from the user profile and treated it as a
query. All resources which the user assigned with
that tag was the relevant set. For the final results,
we computed the F-score, which is defined as stan-
dard:
</bodyText>
<equation confidence="0.5782625">
2 · Precision · Recall
Precision + Recall
</equation>
<bodyText confidence="0.9867166">
Figure 6 and 7 show the F-scores for the two
datasets. Note that ’TopN’ indicates the top N
retrieved resources. As you can see, the ontol-
ogy enhanced with the Wiki concepts was able to
better reflect the users’ interest and produced sig-
nificant improvements compared to the ontologies
built only with the Delicious resources. Moreover,
the improvements were much more significant for
the “Long Tail Set” than the “Frequent Set”, as
consistent with our intuitions – Wikipedia’s en-
cyclopedia knowledge helped enhance the infor-
mation about the less-frequent tags (assigned by
the users with sparse profiles), thereby overcom-
ing the “Cold Start” problem in search personal-
ization.
</bodyText>
<figureCaption confidence="0.86486675">
Figure 6: F-score of the Ontology for “Frequent
Set”
Figure 7: F-score of the Ontology for “Long Tail
Set”
</figureCaption>
<sectionHeader confidence="0.995992" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99993025">
In this paper, we presented a novel method for dis-
ambiguating tags and incorporating encyclopedia
knowledge from Wikipedia in building folkson-
omy ontologies for social tagging systems. We
applied our method to the data from Delicious and
showed that, not only was the derived ontology se-
mantically more dense (i.e., similar tags/concepts
are clustered in close proximity), it also proved to
be very effective in a search personalization task
as well.
For future work, we are planning on investigat-
ing different ways of incorporating the link struc-
tures of Wikipedia and web pages in the tag sim-
ilarity function (in DSCBC). Possible ideas in-
clude adding different weights on various types of
links (or links appearing in various sections of a
page/article), and using distance in the reachabil-
ity relation, for example using the work done in
Wikipedia Mining (Nakayama et al., 2008).
Finally, we are planning on applying informa-
tion extraction or summarization techniques on
Wikipedia articles to focus on sentences which
provide relevant and important information about
the subject.
</bodyText>
<sectionHeader confidence="0.998752" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99987737037037">
D. Ahn, V. Jijkoun, G. Mishene, K. Muller, M. DeR-
ijke, and S. Schlobach. 2004. Using Wikipedia at
the TREC QA Track. In Proceedings of the 13th
Text Retrieval Conference (TREC 2004).
P. Clough, H. Joho, and M. Sanderson. 2005. Auto-
matically Organizing Images Using Concept Hier-
archies. In Proceedings of the SIGIR Workshop on
Multimedia Information Retrieval.
A. Culotta, A. Mccallum, and J.Betz. 2006. Integrat-
ing Probabilistic Extraction Models and Data Min-
ing to Discover Relations and Patterns in Text. In
Proceedings of the Human Language Technology
Conference.
E. Gabrilovich and S. Markovitch. 2006. Over-
coming the Brittleness Bottleneck Using Wikipedia:
Enhancing Text Categorization with Encyclopedic
Knowledge. In Proceedings of the National Con-
ference on Artificial Intelligence.
I. Gurevych, C. Muler, and T. Zesch. 2007. What to
be? - Electronic Career Guidance Based on Seman-
tic Relatedness. In Proceedings of the 45th Annual
Meeting of the Association for Computational Lin-
guistics.
P. Heymann and H. Garcia-Molina. 2006. Collab-
orative Creation of Communal Hierarchical Tax-
onomies in Social Tagging Systems. Technical Re-
port 2006-10, Computer Science Department, April.
</reference>
<figure confidence="0.9998163125">
0
0 10 15
20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
TopN
Ontology Enhanced
with Wiki Concepts
0,15
0,13
Ontology Enhanced
by Resources
Ontology Based
on Tags
0,1
F-value
0,08
0,05
0,03
0
0 10 15
20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
TopN
F-value 0,5 Ontology Enhanced
0,45 with Wiki Concepts
0,4 Ontology Enhanced
0,35 by Resources
0,3 Ontology Based
0,25 on Tags
0,2
0,15
0,1
0,05
F=
</figure>
<page confidence="0.994775">
49
</page>
<reference confidence="0.999840214285714">
A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme.
2006. Folkrank: A Ranking Algorithm for Folk-
sonomies. In Proceedings of the FGIR.
R. Mihalcea and A. Csomai. 2007. Wikify!: Linking
Documents to Encyclopedic Knowledge. In Pro-
ceedings of the sixteenth ACM conference on Con-
ference on information and knowledge management.
P. Mika. 2007. Ontologies Are Us: A Unified Model
of Social Networks and Semantics. Web Semantics:
Science, Services and Agents on the World Wide
Web, 5(1).
G. Miller. 1990. WordNet: An Online Lexical
Database. International Journal of Lexicography,
3(4).
D. Milne, O. Medelyan, and I. Witten. 2006. Mining
Domain-Specific Thesauri from Wikipedia: A Case
Study. In Proceedings of the 2006 IEEE/WIC/ACM
International Conference on Web Intelligence.
K. Nakayama, T. Hara, and S. Nishio. 2008.
Wikipedia Mining - Wikipedia as a Corpus for
Knowledge Extraction. In Proceedings of Annual
Wikipedia Conference (Wikimania).
M. OConnor and J. Herlocker. 2001. Clustering
Items for Collaborative Filtering. In Proceedings of
SIGIR-2001 Workshop on Recommender Systems.
P. Pantel and D. Lin. 2002. Discovering Word Senses
from Text. In Proceedings of the 8th ACM Con-
ference on Knowledge Discovery and Data Mining
(KDD-02).
P. Schmitz. 2006. Inducing Ontology From Flickr
Tags. In Proceedings of the Collaborative Web Tag-
ging Workshop (WWW 06).
A. Shepitsen, J. Gemmell, B. Mobasher, and R. Burke.
2008. Personalized Recommendation in Social Tag-
ging Systems Using Hierarchical Clustering. In Pro-
ceedings of the 2008 ACM conference on Recom-
mender Systems.
N. Tomuro, S. Lytinen, K. Kanzaki, and H. Isahara.
2007. Clustering Using Feature Domain Similarity
to Discover Word Senses for Adjectives. In Pro-
ceedings of the 1st IEEE International Conference
on Semantic Computing (ICSC-2007).
</reference>
<page confidence="0.997689">
50
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.872490">
<title confidence="0.997148">Construction of Disambiguated Folksonomy Ontologies Using Wikipedia</title>
<author confidence="0.908102">Noriko Tomuro</author>
<author confidence="0.908102">Andriy</author>
<affiliation confidence="0.996687">DePaul University, College of Digital</affiliation>
<address confidence="0.99887">243 S. Wabash, Chicago, IL</address>
<email confidence="0.999631">tomuro@cs.depaul.edu,ashepits@cdm.depaul.edu</email>
<abstract confidence="0.998234">One of the difficulties in using Folkin computational systems is tags with multiple meanings. This paper presents a novel method for building Folksonomy tag ontologies in which the nodes are disambiguated. Our method utilizes a clustering algorithm called DSCBC, which was originally developed in Natural Language Processing to derive tags, each of which corresponds to one meaning or domain. In this work, we use Wikipedia as the external knowledge source for the domains of the tags. Using the committees, an ambiguous tag is identified as one which belongs to more than one committee. Then we apply a hierarchical agglomerative clustering algorithm to build an ontology of tags. The nodes in the derived ontology are disambiguated in that an ambiguous tag appears in several nodes in the ontology, each of which corresponds to one meaning of the tag. We evaluate the ontology for its denclose similar tags are placed), and its usefulness in applications, in particular for a personalized tag retrieval task. The results showed marked improvements over other approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Ahn</author>
<author>V Jijkoun</author>
<author>G Mishene</author>
<author>K Muller</author>
<author>M DeRijke</author>
<author>S Schlobach</author>
</authors>
<title>Using Wikipedia at the TREC QA Track.</title>
<date>2004</date>
<booktitle>In Proceedings of the 13th Text Retrieval Conference (TREC</booktitle>
<contexts>
<context position="7153" citStr="Ahn et al., 2004" startWordPosition="1114" endWordPosition="1117">ious work (Shepitsen et al., 2008), we used a standard hierarchical agglomerative clustering algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the tas</context>
</contexts>
<marker>Ahn, Jijkoun, Mishene, Muller, DeRijke, Schlobach, 2004</marker>
<rawString>D. Ahn, V. Jijkoun, G. Mishene, K. Muller, M. DeRijke, and S. Schlobach. 2004. Using Wikipedia at the TREC QA Track. In Proceedings of the 13th Text Retrieval Conference (TREC 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clough</author>
<author>H Joho</author>
<author>M Sanderson</author>
</authors>
<title>Automatically Organizing Images Using Concept Hierarchies.</title>
<date>2005</date>
<booktitle>In Proceedings of the SIGIR Workshop on Multimedia Information Retrieval.</booktitle>
<contexts>
<context position="2819" citStr="Clough et al., 2005" startWordPosition="430" endWordPosition="433">rs to formulate tags. One significant problem arising from such free-formedness is tag ambiguity: tags that have several meanings (e.g. “Java” as coffee or a programming language or an island in Indonesia). Second, folksonomy tags are unstructured – tags assigned to a given resource are simply enumerated in a list (although oftentimes using a varying font size to indicate popularity), and no special organization or categorization of the tags is made (by the Folksonomy site). There have been several work recently which extracted structures from folksonomy tags and constructed ontologies (e.g. (Clough et al., 2005), (Schmitz, 2006)). However, most of them evaluate the effect of the extracted structures only in the context of specific applications, for instance generating user recommendations (e.g. (Shepitsen et al., 2008)). In this work, we develop a novel method for constructing ontologies from folksonomy tags. In particular, we employ a clustering algorithm called Domain Similarity Clustering By Committee (DSCBC) (Tomuro et al., 2007). DSCBC is an extension of an algorithm called CBC (Pantel and Lin, 2002), and was originally developed for lexical semantics in NLP to automatically derive single/unambi</context>
<context position="5686" citStr="Clough et al., 2005" startWordPosition="891" endWordPosition="894">milarity measure only, therefore sometimes does not correspond to the subsumption relation in the strict sense. For evaluation, we construct an ontology from the Delicious tags, and measure the quality (ontological density) of the derived ontology by comparing with the ontologies obtained without using Wikipedia. We also use the derived ontology in a personalized information retrieval task. The results show that our method achieved marked improvements over other approaches. 2 Related Work Several efforts have been made recently which focused on extracting structures from folksonomies. Clough (Clough et al., 2005) and Schmitz (Schmitz, 2006) derived hierarchical structures from image folksonomies (St. Andrew collection (specialcollections.st-and.ac.uk/photcol.htm) and Flickr, respectively). In addition to the hierarchical relation, they also derived other relations such as ”type of”, ”aspect of”, ”same-as”, etc. Mika (Mika, 2007) and Heymann (Heymann and Garcia-Molina, 2006) proposed an automatic creation of tags in folksonomy networks based on the tag co-occurrences among resources and users. They then used a graph clustering algorithm to connect tags which were used by the same users and for the same</context>
</contexts>
<marker>Clough, Joho, Sanderson, 2005</marker>
<rawString>P. Clough, H. Joho, and M. Sanderson. 2005. Automatically Organizing Images Using Concept Hierarchies. In Proceedings of the SIGIR Workshop on Multimedia Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>A Mccallum</author>
<author>J Betz</author>
</authors>
<title>Integrating Probabilistic Extraction Models and Data Mining to Discover Relations and Patterns in Text.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference.</booktitle>
<contexts>
<context position="7203" citStr="Culotta et al., 2006" startWordPosition="1122" endWordPosition="1125">standard hierarchical agglomerative clustering algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the task of extracting semantic structure, in particular </context>
</contexts>
<marker>Culotta, Mccallum, Betz, 2006</marker>
<rawString>A. Culotta, A. Mccallum, and J.Betz. 2006. Integrating Probabilistic Extraction Models and Data Mining to Discover Relations and Patterns in Text. In Proceedings of the Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Overcoming the Brittleness Bottleneck Using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge.</title>
<date>2006</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="7258" citStr="Gabrilovich and Markovitch, 2006" startWordPosition="1131" endWordPosition="1134">ing algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the task of extracting semantic structure, in particular an ontology, from folksonomies. Our method is novel, an</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2006</marker>
<rawString>E. Gabrilovich and S. Markovitch. 2006. Overcoming the Brittleness Bottleneck Using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Gurevych</author>
<author>C Muler</author>
<author>T Zesch</author>
</authors>
<title>What to be? - Electronic Career Guidance Based on Semantic Relatedness.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7414" citStr="Gurevych et al., 2007" startWordPosition="1155" endWordPosition="1158">much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the task of extracting semantic structure, in particular an ontology, from folksonomies. Our method is novel, and the experimental results indicate that the derived ontology was of high semantic quality. 3 Deriving Unambiguous Tag Committees The DSCBC algorithm, which</context>
</contexts>
<marker>Gurevych, Muler, Zesch, 2007</marker>
<rawString>I. Gurevych, C. Muler, and T. Zesch. 2007. What to be? - Electronic Career Guidance Based on Semantic Relatedness. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Heymann</author>
<author>H Garcia-Molina</author>
</authors>
<title>Collaborative Creation of Communal Hierarchical Taxonomies in Social Tagging Systems.</title>
<date>2006</date>
<tech>Technical Report 2006-10,</tech>
<institution>Computer Science Department,</institution>
<contexts>
<context position="6054" citStr="Heymann and Garcia-Molina, 2006" startWordPosition="937" endWordPosition="940">sonalized information retrieval task. The results show that our method achieved marked improvements over other approaches. 2 Related Work Several efforts have been made recently which focused on extracting structures from folksonomies. Clough (Clough et al., 2005) and Schmitz (Schmitz, 2006) derived hierarchical structures from image folksonomies (St. Andrew collection (specialcollections.st-and.ac.uk/photcol.htm) and Flickr, respectively). In addition to the hierarchical relation, they also derived other relations such as ”type of”, ”aspect of”, ”same-as”, etc. Mika (Mika, 2007) and Heymann (Heymann and Garcia-Molina, 2006) proposed an automatic creation of tags in folksonomy networks based on the tag co-occurrences among resources and users. They then used a graph clustering algorithm to connect tags which were used by the same users and for the same resources to identify tag ’clouds’ and communities of like-minded users. However, none of those work used NLP techniques, nor did they deal with the tag ambiguity problem; Oftentimes, highly ambiguous tags are even removed from the data. In our previous work (Shepitsen et al., 2008), we used a standard hierarchical agglomerative clustering algorithm to build a tag </context>
</contexts>
<marker>Heymann, Garcia-Molina, 2006</marker>
<rawString>P. Heymann and H. Garcia-Molina. 2006. Collaborative Creation of Communal Hierarchical Taxonomies in Social Tagging Systems. Technical Report 2006-10, Computer Science Department, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hotho</author>
<author>R Jaschke</author>
<author>C Schmitz</author>
<author>G Stumme</author>
</authors>
<title>Folkrank: A Ranking Algorithm for Folksonomies.</title>
<date>2006</date>
<booktitle>In Proceedings of the FGIR.</booktitle>
<contexts>
<context position="26098" citStr="Hotho et al., 2006" startWordPosition="4446" endWordPosition="4449">hus the resulting score distribution of the tree is effectively personalized to the user’s general interest. Using the obtained score distribution of a given user, we search the tree for a query tag (of this user). In the same way as the tags in the profile, we spread activation over the ontology from the node to which the tag belongs, but this time we add a weight to emphasize the relative importance of the query tag compared to the tags from the profile, because the query reflects the user’s current information needs. Finally we feed the preference vector to the modified FolkRank algorithm (Hotho et al., 2006) to retrieve and rank the relevant web resources which reflect the user-specific preferences. Figure 5 shows the overall scheme of the personalized ranked retrieval using an ontological user profile. Figure 5: Ranked Retrieval in Folksonomies using Ontological User Profile We evaluated the retrieval results by 5-fold cross validation. Given a test user profile, we used Ontology Enhanced Ontology Enhanced Ontology Based with Wiki Concepts by Resources on Tags Density 0,045 0,043 0,041 0,039 0,037 0,035 Ontology Enhanced Ontology Enhanced Ontology Based with Wiki Concepts by Resources on Tags De</context>
</contexts>
<marker>Hotho, Jaschke, Schmitz, Stumme, 2006</marker>
<rawString>A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme. 2006. Folkrank: A Ranking Algorithm for Folksonomies. In Proceedings of the FGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>A Csomai</author>
</authors>
<title>Wikify!: Linking Documents to Encyclopedic Knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management.</booktitle>
<contexts>
<context position="7002" citStr="Mihalcea and Csomai, 2007" startWordPosition="1092" endWordPosition="1096"> those work used NLP techniques, nor did they deal with the tag ambiguity problem; Oftentimes, highly ambiguous tags are even removed from the data. In our previous work (Shepitsen et al., 2008), we used a standard hierarchical agglomerative clustering algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presente</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>R. Mihalcea and A. Csomai. 2007. Wikify!: Linking Documents to Encyclopedic Knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Mika</author>
</authors>
<title>Ontologies Are Us: A Unified Model of Social Networks and Semantics. Web Semantics: Science, Services and Agents on the World Wide Web,</title>
<date>2007</date>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="6008" citStr="Mika, 2007" startWordPosition="933" endWordPosition="934">derived ontology in a personalized information retrieval task. The results show that our method achieved marked improvements over other approaches. 2 Related Work Several efforts have been made recently which focused on extracting structures from folksonomies. Clough (Clough et al., 2005) and Schmitz (Schmitz, 2006) derived hierarchical structures from image folksonomies (St. Andrew collection (specialcollections.st-and.ac.uk/photcol.htm) and Flickr, respectively). In addition to the hierarchical relation, they also derived other relations such as ”type of”, ”aspect of”, ”same-as”, etc. Mika (Mika, 2007) and Heymann (Heymann and Garcia-Molina, 2006) proposed an automatic creation of tags in folksonomy networks based on the tag co-occurrences among resources and users. They then used a graph clustering algorithm to connect tags which were used by the same users and for the same resources to identify tag ’clouds’ and communities of like-minded users. However, none of those work used NLP techniques, nor did they deal with the tag ambiguity problem; Oftentimes, highly ambiguous tags are even removed from the data. In our previous work (Shepitsen et al., 2008), we used a standard hierarchical aggl</context>
</contexts>
<marker>Mika, 2007</marker>
<rawString>P. Mika. 2007. Ontologies Are Us: A Unified Model of Social Networks and Semantics. Web Semantics: Science, Services and Agents on the World Wide Web, 5(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>WordNet: An Online Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="2102" citStr="Miller, 1990" startWordPosition="315" endWordPosition="316">mies where users assign keywords or tags to categorize resources. Typically, the sources of folksonomies are web resources, and virtually any kind of information available on the Internet, ranging from web pages (e.g. Delicious (delicious.com)), scientific articles (e.g. Bibsonomy (www.bibsonomy.org)) to media resources (e.g. Flickr (www.flickr.com), Last.fm (www.last.fm)). Although tags in folksonomies are essentially semantic concepts, they have distinct characteristics as compared to conventional semantic resources which are often used in Natural Language Processing (NLP), such as WordNet (Miller, 1990). First, folksonomy tags are unrestricted – users are free to choose any words or set of characters to formulate tags. One significant problem arising from such free-formedness is tag ambiguity: tags that have several meanings (e.g. “Java” as coffee or a programming language or an island in Indonesia). Second, folksonomy tags are unstructured – tags assigned to a given resource are simply enumerated in a list (although oftentimes using a varying font size to indicate popularity), and no special organization or categorization of the tags is made (by the Folksonomy site). There have been several</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. WordNet: An Online Lexical Database. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>O Medelyan</author>
<author>I Witten</author>
</authors>
<title>Mining Domain-Specific Thesauri from Wikipedia: A Case Study.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence.</booktitle>
<contexts>
<context position="6940" citStr="Milne et al., 2006" startWordPosition="1083" endWordPosition="1086"> and communities of like-minded users. However, none of those work used NLP techniques, nor did they deal with the tag ambiguity problem; Oftentimes, highly ambiguous tags are even removed from the data. In our previous work (Shepitsen et al., 2008), we used a standard hierarchical agglomerative clustering algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information extraction (Culotta et al., 2006). In a similar vein, (Gabrilovich and Markovitch, 2006) also used Wikipedia to improve the accuracy for text categorization. An interesting text retrieval application was done by Gurevych (Gurevych et al., 2007), in which Wikipedia was utilized to improve the retrieval accuracy in matching the professional interests of job applicants w</context>
</contexts>
<marker>Milne, Medelyan, Witten, 2006</marker>
<rawString>D. Milne, O. Medelyan, and I. Witten. 2006. Mining Domain-Specific Thesauri from Wikipedia: A Case Study. In Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nakayama</author>
<author>T Hara</author>
<author>S Nishio</author>
</authors>
<title>Wikipedia Mining - Wikipedia as a Corpus for Knowledge Extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of Annual Wikipedia Conference (Wikimania).</booktitle>
<marker>Nakayama, Hara, Nishio, 2008</marker>
<rawString>K. Nakayama, T. Hara, and S. Nishio. 2008. Wikipedia Mining - Wikipedia as a Corpus for Knowledge Extraction. In Proceedings of Annual Wikipedia Conference (Wikimania).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M OConnor</author>
<author>J Herlocker</author>
</authors>
<title>Clustering Items for Collaborative Filtering.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR-2001 Workshop on Recommender Systems.</booktitle>
<contexts>
<context position="15199" citStr="OConnor and Herlocker, 2001" startWordPosition="2547" endWordPosition="2550">an one committee. When we process an ambiguous tag, we first find its “core meaning” by finding the committee to which the tag is most similar, then remove all (non-zero) features that are encoded in committee from all instances left in the dataset. With this scheme, we can cover all senses of an ambiguous tag, for all such tags, during ontology generation. The similarity is computed using the ds5im function described in the previous section; the only difference that, if one member of a pair is a cluster, it is rep1Our algorithm is essentially a modification of the Average-Link Clustering by (OConnor and Herlocker, 2001). Input: Set of tags T. Tuning coefficients: n - number of the most similar tags chosen for the target tag q - number of features for finding the centroid Q - similarity threshold for adding tags to committees -y - similarity threshold for assigning tags to committees Output: Set of committees C. Set of tags T where each t E T is assigned to committees in C. Phase I. Finding set of clusters L foreach ti E T do Select a set k of n most similar tj : i 7� j add k to L if it is not already in L. end Phase II. Find Communities C foreach c E L do Find the centroid of c using only q features shared b</context>
</contexts>
<marker>OConnor, Herlocker, 2001</marker>
<rawString>M. OConnor and J. Herlocker. 2001. Clustering Items for Collaborative Filtering. In Proceedings of SIGIR-2001 Workshop on Recommender Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Lin</author>
</authors>
<title>Discovering Word Senses from Text.</title>
<date>2002</date>
<booktitle>In Proceedings of the 8th ACM Conference on Knowledge Discovery and Data Mining (KDD-02).</booktitle>
<contexts>
<context position="3322" citStr="Pantel and Lin, 2002" startWordPosition="508" endWordPosition="511">l work recently which extracted structures from folksonomy tags and constructed ontologies (e.g. (Clough et al., 2005), (Schmitz, 2006)). However, most of them evaluate the effect of the extracted structures only in the context of specific applications, for instance generating user recommendations (e.g. (Shepitsen et al., 2008)). In this work, we develop a novel method for constructing ontologies from folksonomy tags. In particular, we employ a clustering algorithm called Domain Similarity Clustering By Committee (DSCBC) (Tomuro et al., 2007). DSCBC is an extension of an algorithm called CBC (Pantel and Lin, 2002), and was originally developed for lexical semantics in NLP to automatically derive single/unambiguous word meanings (as committees) from ambiguous words. In this work, DSCBC is effectively adopted to derive disambiguated folksonomy tag committees, where a committee in this context is a cluster of tags in which the members share the same or very similar concept in one of their meanings. By using DSCBC, an ambiguous tag is identified as one which belongs to more than 42 Proceedings of the 2009 Workshop on the People’s Web Meets NLP, ACL-IJCNLP 2009, pages 42–50, Suntec, Singapore, 7 August 2009</context>
<context position="8132" citStr="Pantel and Lin, 2002" startWordPosition="1266" endWordPosition="1269">interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the task of extracting semantic structure, in particular an ontology, from folksonomies. Our method is novel, and the experimental results indicate that the derived ontology was of high semantic quality. 3 Deriving Unambiguous Tag Committees The DSCBC algorithm, which we had developed in our previous work (Tomuro et al., 2007), is an extension of CBC Clustering (Pantel and Lin, 2002), modified to produce unambiguous clusters when the data contained ambiguous instances. Assuming the instances are represented by vectors of features/domains, consider the following data: a b c d 1 1 0 0 1 0 1 0 1 0 0 1 43 where x, y, z are data instances, and a, b, c, d are features. In most clustering algorithms, features are assumed to be independent to each other, or their dependencies are ignored. So in the example, x is equally likely clustered with y or z, because the similarity between x and y, and x and z are the same (based on the Euclidean distance, for example). However if we have </context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>P. Pantel and D. Lin. 2002. Discovering Word Senses from Text. In Proceedings of the 8th ACM Conference on Knowledge Discovery and Data Mining (KDD-02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schmitz</author>
</authors>
<title>Inducing Ontology From Flickr Tags.</title>
<date>2006</date>
<booktitle>In Proceedings of the Collaborative Web Tagging Workshop (WWW 06).</booktitle>
<contexts>
<context position="2836" citStr="Schmitz, 2006" startWordPosition="434" endWordPosition="435">ne significant problem arising from such free-formedness is tag ambiguity: tags that have several meanings (e.g. “Java” as coffee or a programming language or an island in Indonesia). Second, folksonomy tags are unstructured – tags assigned to a given resource are simply enumerated in a list (although oftentimes using a varying font size to indicate popularity), and no special organization or categorization of the tags is made (by the Folksonomy site). There have been several work recently which extracted structures from folksonomy tags and constructed ontologies (e.g. (Clough et al., 2005), (Schmitz, 2006)). However, most of them evaluate the effect of the extracted structures only in the context of specific applications, for instance generating user recommendations (e.g. (Shepitsen et al., 2008)). In this work, we develop a novel method for constructing ontologies from folksonomy tags. In particular, we employ a clustering algorithm called Domain Similarity Clustering By Committee (DSCBC) (Tomuro et al., 2007). DSCBC is an extension of an algorithm called CBC (Pantel and Lin, 2002), and was originally developed for lexical semantics in NLP to automatically derive single/unambiguous word meanin</context>
<context position="5714" citStr="Schmitz, 2006" startWordPosition="897" endWordPosition="898">ometimes does not correspond to the subsumption relation in the strict sense. For evaluation, we construct an ontology from the Delicious tags, and measure the quality (ontological density) of the derived ontology by comparing with the ontologies obtained without using Wikipedia. We also use the derived ontology in a personalized information retrieval task. The results show that our method achieved marked improvements over other approaches. 2 Related Work Several efforts have been made recently which focused on extracting structures from folksonomies. Clough (Clough et al., 2005) and Schmitz (Schmitz, 2006) derived hierarchical structures from image folksonomies (St. Andrew collection (specialcollections.st-and.ac.uk/photcol.htm) and Flickr, respectively). In addition to the hierarchical relation, they also derived other relations such as ”type of”, ”aspect of”, ”same-as”, etc. Mika (Mika, 2007) and Heymann (Heymann and Garcia-Molina, 2006) proposed an automatic creation of tags in folksonomy networks based on the tag co-occurrences among resources and users. They then used a graph clustering algorithm to connect tags which were used by the same users and for the same resources to identify tag ’</context>
</contexts>
<marker>Schmitz, 2006</marker>
<rawString>P. Schmitz. 2006. Inducing Ontology From Flickr Tags. In Proceedings of the Collaborative Web Tagging Workshop (WWW 06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Shepitsen</author>
<author>J Gemmell</author>
<author>B Mobasher</author>
<author>R Burke</author>
</authors>
<title>Personalized Recommendation in Social Tagging Systems Using Hierarchical Clustering.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM conference on Recommender Systems.</booktitle>
<contexts>
<context position="3030" citStr="Shepitsen et al., 2008" startWordPosition="462" endWordPosition="465">econd, folksonomy tags are unstructured – tags assigned to a given resource are simply enumerated in a list (although oftentimes using a varying font size to indicate popularity), and no special organization or categorization of the tags is made (by the Folksonomy site). There have been several work recently which extracted structures from folksonomy tags and constructed ontologies (e.g. (Clough et al., 2005), (Schmitz, 2006)). However, most of them evaluate the effect of the extracted structures only in the context of specific applications, for instance generating user recommendations (e.g. (Shepitsen et al., 2008)). In this work, we develop a novel method for constructing ontologies from folksonomy tags. In particular, we employ a clustering algorithm called Domain Similarity Clustering By Committee (DSCBC) (Tomuro et al., 2007). DSCBC is an extension of an algorithm called CBC (Pantel and Lin, 2002), and was originally developed for lexical semantics in NLP to automatically derive single/unambiguous word meanings (as committees) from ambiguous words. In this work, DSCBC is effectively adopted to derive disambiguated folksonomy tag committees, where a committee in this context is a cluster of tags in w</context>
<context position="6570" citStr="Shepitsen et al., 2008" startWordPosition="1023" endWordPosition="1026"> as ”type of”, ”aspect of”, ”same-as”, etc. Mika (Mika, 2007) and Heymann (Heymann and Garcia-Molina, 2006) proposed an automatic creation of tags in folksonomy networks based on the tag co-occurrences among resources and users. They then used a graph clustering algorithm to connect tags which were used by the same users and for the same resources to identify tag ’clouds’ and communities of like-minded users. However, none of those work used NLP techniques, nor did they deal with the tag ambiguity problem; Oftentimes, highly ambiguous tags are even removed from the data. In our previous work (Shepitsen et al., 2008), we used a standard hierarchical agglomerative clustering algorithm to build a tag hierarchy. We also considered only the most popular sense of an ambiguous tag and ignored all other senses. Wikipedia has been attracting much attention in the recent NLP research. For example, Wikipedia as a lexical resource was exploited for thesauri construction (Milne et al., 2006) and for word sense disambiguation (Mihalcea and Csomai, 2007). Other NLP tasks in which Wikipedia was utilized to provide contextual and domain/encyclopedia knowledge include question-answering (Ahn et al., 2004) and information </context>
</contexts>
<marker>Shepitsen, Gemmell, Mobasher, Burke, 2008</marker>
<rawString>A. Shepitsen, J. Gemmell, B. Mobasher, and R. Burke. 2008. Personalized Recommendation in Social Tagging Systems Using Hierarchical Clustering. In Proceedings of the 2008 ACM conference on Recommender Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tomuro</author>
<author>S Lytinen</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
</authors>
<title>Clustering Using Feature Domain Similarity to Discover Word Senses for Adjectives.</title>
<date>2007</date>
<booktitle>In Proceedings of the 1st IEEE International Conference on Semantic Computing (ICSC-2007).</booktitle>
<contexts>
<context position="3249" citStr="Tomuro et al., 2007" startWordPosition="495" endWordPosition="498">ion of the tags is made (by the Folksonomy site). There have been several work recently which extracted structures from folksonomy tags and constructed ontologies (e.g. (Clough et al., 2005), (Schmitz, 2006)). However, most of them evaluate the effect of the extracted structures only in the context of specific applications, for instance generating user recommendations (e.g. (Shepitsen et al., 2008)). In this work, we develop a novel method for constructing ontologies from folksonomy tags. In particular, we employ a clustering algorithm called Domain Similarity Clustering By Committee (DSCBC) (Tomuro et al., 2007). DSCBC is an extension of an algorithm called CBC (Pantel and Lin, 2002), and was originally developed for lexical semantics in NLP to automatically derive single/unambiguous word meanings (as committees) from ambiguous words. In this work, DSCBC is effectively adopted to derive disambiguated folksonomy tag committees, where a committee in this context is a cluster of tags in which the members share the same or very similar concept in one of their meanings. By using DSCBC, an ambiguous tag is identified as one which belongs to more than 42 Proceedings of the 2009 Workshop on the People’s Web </context>
<context position="8074" citStr="Tomuro et al., 2007" startWordPosition="1256" endWordPosition="1259">rove the retrieval accuracy in matching the professional interests of job applicants with the descriptions of professions/careers. The work presented in this paper applies an NLP technique (the DSCBC algorithm), which incorporates the domain knowledge (Wikipedia) as a critical component, to the task of extracting semantic structure, in particular an ontology, from folksonomies. Our method is novel, and the experimental results indicate that the derived ontology was of high semantic quality. 3 Deriving Unambiguous Tag Committees The DSCBC algorithm, which we had developed in our previous work (Tomuro et al., 2007), is an extension of CBC Clustering (Pantel and Lin, 2002), modified to produce unambiguous clusters when the data contained ambiguous instances. Assuming the instances are represented by vectors of features/domains, consider the following data: a b c d 1 1 0 0 1 0 1 0 1 0 0 1 43 where x, y, z are data instances, and a, b, c, d are features. In most clustering algorithms, features are assumed to be independent to each other, or their dependencies are ignored. So in the example, x is equally likely clustered with y or z, because the similarity between x and y, and x and z are the same (based on</context>
</contexts>
<marker>Tomuro, Lytinen, Kanzaki, Isahara, 2007</marker>
<rawString>N. Tomuro, S. Lytinen, K. Kanzaki, and H. Isahara. 2007. Clustering Using Feature Domain Similarity to Discover Word Senses for Adjectives. In Proceedings of the 1st IEEE International Conference on Semantic Computing (ICSC-2007).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>