<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.970321">
Semantic Interpretation of Unrealized Syntactic Material in LTAG
</title>
<author confidence="0.798715">
Olga Babko-Malaya
</author>
<affiliation confidence="0.817127">
University of Pennsylvania
</affiliation>
<email confidence="0.994989">
malayao@ldc.upenn.edu
</email>
<sectionHeader confidence="0.993816" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999728285714286">
This paper presents a LTAG-based
analysis of gapping and VP ellipsis,
which proposes that resolution of the
elided material is part of a general dis-
ambiguation procedure, which is also re-
sponsible for resolution of underspecified
representations of scope.
</bodyText>
<sectionHeader confidence="0.999264" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999680125">
The problem of ellipsis resolution is to recover
the interpretation of the elided material. For ex-
ample, in (1), the elided VP is interpreted as be-
ing identical to the verb in the preceding sen-
tence. Likewise, in the gapping structures, as
shown in (2), the interpretation of a gap is being
identified with the interpretation of the preceding
verb.
</bodyText>
<listItem confidence="0.975637">
(1) Mary likes Bill. Jane does too.
(2) Mary ate beans and others -- rice.
</listItem>
<bodyText confidence="0.999774511111111">
Whereas some approaches assume syntactic
identity between the antecedent and the elided
material (e.g. Fiengo and May 1994), others
suggest that VP ellipsises are proforms, semanti-
cally identified with their antecedents (see Dal-
rymple et al 1991, Shieber et al 1996, Hardt 1993,
1999).
This paper follows semantic approaches to el-
lipsis resolution. It adopts the LTAG semantics
of Kallmeyer and Romero 2004 and proposes
that resolution of ellipsises and gaps is part of a
general disambiguation procedure, which is also
responsible for resolution of underspecified rep-
resentations of scope.
adjunction. LTAG derivations are represented by
derivation trees that record the history of how the
elementary trees are put together. Given that
derivation steps in LTAG correspond to predi-
cate-argument applications, it is usually assumed
that LTAG semantics is based on the derivation
tree, rather than the derived tree (Kallmeyer and
Joshi 2003).
Semantic composition which we adopt is
based on LTAG semantics with semantic unifica-
tion (Kallmeyer and Romero 2004). In the deri-
vation tree, elementary trees are replaced by their
semantic representations and corresponding fea-
ture structures. Semantic representations are as
defined in Kallmeyer and Joshi 2003, except that
they do not have argument variables. These rep-
resentations consist of a set of formulas (typed λ-
expressions with labels) and a set of scope con-
straints.
Each semantic representation is linked to a
feature structure. Feature structures, as illustrated
by different examples below, include a feature i
whose values are individual variables and fea-
tures p and MaxS, whose values are proposi-
tional labels. Semantic composition consists of
feature unification. After having performed all
unifications, the union of all semantic representa-
tions is built.
Consider, for example, the semantic represen-
tations and feature structures associated with the
elementary trees of the sentence shown in (3).
</bodyText>
<figure confidence="0.924333333333333">
(3) Mary dates Bill
S
l1: date(v1, v2 )
NP VP
[i:v1]
date NP [i: v2]
NP NP
2 LTAG Semantics with Semantic Uni- Mary(x) Bill (y)
fication
</figure>
<subsectionHeader confidence="0.975769">
Mary Bill
</subsectionHeader>
<bodyText confidence="0.999162666666667">
In LTAG framework (Joshi and Schabes 1997), [i: x] [i: y]
the basic units are (elementary) trees, which can
be combined into bigger trees by substitution or
</bodyText>
<page confidence="0.994362">
91
</page>
<bodyText confidence="0.847560692307692">
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 91–96,
Sydney, July 2006. c�2006 Association for Computational Linguistics
Derivation tree: date
1 2
mary bill
Semantic composition proceeds on the derivation
tree and consists of feature unification:
The final representation of this sentence is un-
derspecified for scope, given that there are no
constraints which restrict the relative scope of
every and some. In order to obtain one of the
readings, a disambiguation mapping is needed:
Disambiguations:
</bodyText>
<equation confidence="0.984788">
1. R2 -&gt;l4, R3 -&gt;l5, N2 -&gt;l1, N3 -&gt; l2:
(4) l1: date(v1, v2 ) some(y,course(y), every(x,student(x), like(x, y)))
</equation>
<bodyText confidence="0.999537636363636">
Performing two unifications, v1=x, v2=y, we ar-
rive at the final interpretation of this sentence:
l1: date(x, y), bill(y), mary(x). This representa-
tion is interpreted conjunctively, with free vari-
ables being existentially bound.
Quantificational NPs are analyzed as multi-
component TAGs, where the scope part of the
quantifier introduces the proposition containing
the quantifier, and the predicate-argument part
introduces the restrictive clause (see Kallmeyer
and Joshi 2003).
</bodyText>
<subsectionHeader confidence="0.549093">
Final representation
</subsectionHeader>
<equation confidence="0.810119166666667">
l2: every(x, R2, N2)
l4: student(x) l4 :5R2
l3: some(y, R3, N3)
l5: course(y) l5 :5 R3
l1: like(x, y) l1 HN2 l1 :5N3
2. R2-&gt;l4, R3-&gt;l5, N3-&gt;l1, N2-&gt;l3:
</equation>
<bodyText confidence="0.944108833333333">
every(x, student(x), some(y, course(y), like(x, y))
Disambiguations are functions from proposi-
tional variables to propositional labels that re-
spect the scope constraints, such that after having
applied this mapping, the transitive closure of the
resulting scope is a partial order.
</bodyText>
<sectionHeader confidence="0.987693" genericHeader="method">
3 The Problem of Ellipsis Resolution in
LTAG semantics
</sectionHeader>
<bodyText confidence="0.950136483870968">
Given LTAG semantics, there are two possible
approaches to resolution of the elided material:
reconstruction can be done as part of the unifica-
tion process or as part of the disambiguation pro-
cedure. If reconstruction was done as unification,
the semantic representation of the elided material
would be disambiguated in the final representa-
tion. On the other hand, it is well known that
resolution of ellipsises and gaps can be ambigu-
ous. For example, the sentence in (6), discussed
in Siegel 1987 and Johnson 2003 among others,
has 2 interpretations:1
(6) Ward can’t eat caviar and his guests -- dried
beans
Can’t (eat (ward, caviar)) &amp; eat (his guests, dried
beans))
Can’t (eat(ward, caviar)) &amp; can’t (eat(his guests,
dried beans))
As this example shows, the gap in (6) can be re-
constructed by selecting either the verb or the
negated modal as its antecedent. The two inter-
pretations represent different scope readings be-
tween the conjunction and negation, which
should be analyzed as underspecified in LTAG
semantics. Resolution of gaps, therefore, cannot
be done as part of unification, since it depends on
the disambiguated interpretation. The question is
whether it is possible to define an underspecified
representation of these two readings, and what
kind of resolution mechanism can be used to dis-
ambiguate these interpretations?
</bodyText>
<listItem confidence="0.280931333333333">
1 Other cases of ambiguous interpretations of the elided
material are discussed in section 7.
(5) Every student likes some course
</listItem>
<equation confidence="0.99214705">
. S* S
l2: every(x, R2, N2)
NP [i: x, p: P1] NP VP
[p: l1, i: v1]
every student likes NP
l4: student(x)
l4 &lt; R2, P1 &lt; N2
l1: like(v1, v2)
[p:l1, i:v2]
. S*
l3: some(y, R3, N3)
NP [i: y, p: P2]
Some course
l5: course(y)
l5 &lt; R3, P2 &lt; N3
mary(x) bill(y)
[i: x] [i: y]
1 [i: v1]
2 [i: v2 ]
1 2
</equation>
<page confidence="0.979902">
92
</page>
<sectionHeader confidence="0.995084" genericHeader="method">
4 LTAG Semantics of Gapping
</sectionHeader>
<bodyText confidence="0.998433833333333">
In LTAG semantics, semantic representations are
introduced by lexicalized trees. In order to ac-
count for the analysis of gapping and VP ellipsis,
this paper proposes that semantics should be de-
fined on both lexicalized and non-lexicalized
trees. Specifically, we propose that
Interpretation of a gap (or elided VP) is the se-
mantic interpretation of a non-lexicalized S tree.
The semantic representations of lexicalized S
trees under this new approach are derived com-
positionally, given the meaning of a nonlexical-
ized S tree and the meaning of a verb.
</bodyText>
<equation confidence="0.4871905">
(7) S
NP[i:v1] VP V [Ag: v3, Pat: v4, MaxS: C1]
date
V NP [i:v2]
[Ag: v, Pat: u, MaxS: C]
l2: λuλv.C (v2)(v1)
</equation>
<bodyText confidence="0.9993745">
Non-lexicalized trees introduce a propositional
label and a propositional variable, illustrated by
l2 and C above. If a tree is a transitive S-tree,
there are two lambda bound variables, which cor-
respond to the Agent and Patient features of the
verb. Performing feature unifications (v3=v,
v4=u,C1=C) and scope constraint disambigua-
tions (C-&gt;l0), the proposition l2 will be reduced to:
λu.λv.date(v, u)(v2)(v1)= date(v1, v2).
Given this proposal, we suggest that the se-
mantics of gaps, VPE and other types of elided
material is introduced by non-lexicalized trees.
For example, the analysis of the sentence in (2) is
shown in (7). Performing feature unifications
(l2=P1, l3=P2, v=v1=v2, u=u1=u2, C=C1=C2) yields
the final representation, where l2 and l3 are un-
derspecified. There is only one disambiguation
of the variable C in this sentence: C -&gt; l0, which
gives us the desired interpretation of the sen-
tence:
</bodyText>
<equation confidence="0.813667">
l2: λuλv.eat(v, u) (y)(x) = eat(x, y)
l3: λuλv.eat(v, u) (w)(z) = eat(z, w)
</equation>
<bodyText confidence="0.999879461538462">
Resolution of the gap in this sentence is en-
forced by the feature structure of ‘and’, which
unifies MaxS as well as Agent and Patient fea-
tures. This analysis therefore accounts for the
fact that gapping “is intimately entangled with
the syntax of coordination (as opposed to VP
ellipsis)” (Johnson 2003). On the other hand, as
the next example illustrates, it is crucial that pro-
positional variables introduced by non-
lexicalized trees are not unified during semantic
composition, but rather are identified with their
antecedents as part of the disambiguation proce-
dure.
</bodyText>
<equation confidence="0.6891556">
Final Representation:
l1: l2 ∧ l3
l2: λuλv.C (y)(x) l3: λuλv.C (w)(z)
l0: eat(v, u) l0 ≤ C
mary(x), beans(y), others(z), rice(w)
</equation>
<bodyText confidence="0.999952733333334">
The sentence in (8), shown below, differs from
the previous one in the presence of a negated
modal. The interpretation of this modal intro-
duces a proposition l9: can’t(N9) and a constraint
P3 ≤ N9 . After P3 is unified with the proposition
l0, the final representation has two constraints on
the variable l0: l0≤ C and l0≤ N9, and therefore
two possible disambiguations. In the disambigua-
tion 1, C is mapped to l0, introduced by the verb
‘eat’, and propositions l2 and l3 are reduced to
eat(x, y) and eat(z, w). In the disambiguation 2,
the variable C is mapped to l9, introduced by the
modal, and l2 and l3 are reduced to can’t(eat(x,
y)) and can’t(eat(z, w)). These disambiguations
yield the desired interpretations of this sentence.
</bodyText>
<figure confidence="0.8905795">
(8) Ward can’t eat caviar and his guests -- dried
beans
(7) Mary ate beans and others -- rice.
S [p: l2, Ag: v1, Pat: u1, MaxS:C1]
Mary VP
V beans
eat
S
S [p: P1, Ag: v, Pat: u, MaxS:C]
and S [p: P2, Ag: v, Pat: u, MaxS:C]
</figure>
<equation confidence="0.825203">
l2: λu1 λv1.C1 (y)(x)
l0: eat(v1, u1), l0≤ C1
Mary(x), beans(y)
l1: P1 ∧ P2
S [p:l3, Ag:v2, Pat:u2, MaxS:C2]
others VP
rice
l3: λu2λv2.C2 (w)(z)
others(z), rice(w)
l0: date(v3, v4), l0≤C1
</equation>
<page confidence="0.86918">
93
</page>
<table confidence="0.96329725">
beans
Final Representation
l1: l2 ∧ l3 l0: eat(v, u)
l9: can’t(N9) l0≤ N9 l0≤ C
l2: λuλv C (y)(x) l3: λuλv C (w)(z)
guests(z), beans(w), caviar(y), ward(x)
Disambiguation 1: C-&gt;l0, N9 -&gt;l1:
can’t (eat(x, y) ∧ eat(z, w))
l2 l3
Disambiguation 2: C-&gt;l9, N9-&gt;l0:
can’t(eat(x, y)) ∧ can’t (eat(z, w))
l2 l3
</table>
<bodyText confidence="0.9958105">
Resolution of gaps under this analysis is done as
part of the scope resolution procedure on under-
specified representations. A crucial feature of
this analysis is that the propositions l2 and l3 are
‘underspecified’ in the final representation and
the variable C is computed during the
disambiguation, i.e. when all scope ambiguities
are being resolved. In this respect this analysis
differs from previous approaches, where the final
representation did not include any variables, ex-
cept for the arguments of quantifiers or other
scopal elements.2
</bodyText>
<footnote confidence="0.526891">
2 However, see Babko-Malaya 2004, where a similar
analysis is proposed to account for the semantics of coor-
dinated structures with quantified NPs.
</footnote>
<sectionHeader confidence="0.950417" genericHeader="method">
5 LTAG Analysis of VP Ellipsis
</sectionHeader>
<bodyText confidence="0.999878592592592">
The analysis of gapping presented above can be
easily extended to the analysis of VP ellipsis.
VPE differs from gapping in that it is not re-
stricted to coordinated structures. Whereas in the
examples above resolution of gaps was enforced
by the feature structure of ‘and’, in the case of
VPE, a similar unification, forced by pragmatic
constraints, results in recovering the elided mate-
rial.
As the example in (9) illustrates, our analysis
of VPE assumes the following modification of
the semantics of non-lexicalized trees: proposi-
tions introduced by non-lexicalized trees have
one lambda-bound variable, so that each argu-
ment is introduced by a separate proposition. For
example, the interpretation of a transitive tree
below has two propositions l1 and l2, and two
propositional variables C1 and C2. The proposi-
tion l2 corresponds to the meaning of a VP,
which is missing in the standard TAG-based
analyses. This decomposition of the meaning of a
nonlexicalized tree, therefore, can be independ-
ently motivated by the existence of modifiers
which predicate of VPs. We further assume that
the MaxS feature of the S tree corresponds to the
variable introduced by the agent (or the highest-
ranked argument).
</bodyText>
<listItem confidence="0.477461">
(9) Mary likes Bill. Jane does too.
</listItem>
<equation confidence="0.722066363636364">
S [Ag: v, Pat: u, MaxS: C1]
[i:v3] NP VP
NP [i:x] V NP [i: v4]
mary(x) [Ag: v, Pat: u, MaxS: C2]
NP[i: y]
V [Ag: v3, Pat: v4, MaxS: C]
like l0: like(v3, v4) l0≤C
Final l1: λv C1 (x)
Representation: l2: λu C2 (y) l2 ≤ C1
l0: like(v, u), l0≤ C2
Mary(x), Bill(y)
</equation>
<bodyText confidence="0.99594">
Applying disambiguations C2 -&gt; l0, C1 -&gt; l2 , we
derive the following propositions:
</bodyText>
<equation confidence="0.989414818181818">
l2: λu.like(v, u) (y)=like(v, y)
l1: λv.like(v, y) (x)=like(x, y)
S [p: l2, Ag: v1, Pat: u1, MaxS:C1]
Ward VP [p: l0]
V caviar
eat
l2: λu1 λv1.C1 (y)(x)
l0: eat(v1, u1), l0≤ C1
ward(x), caviar(y)
VP [p: P3]
S Can’t VP
l9: can’t(N9) P3 ≤ N9
S [p: P1, Ag: v, Pat: u, MaxS:C]
and S [p: P2, Ag: v, Pat: u, MaxS:C]
l1: P1 ∧ P2
S [p:l3, Ag:v2, Pat:u2, MaxS:C2]
l3: λu2λv2.C2 (w)(z)
guests(z), beans(w)
guests VP
bill(y
l1: λv C1 (v3)
l2: λu C2 (v4) l2 ≤ C1
</equation>
<page confidence="0.998796">
94
</page>
<note confidence="0.699911">
Now consider the second sentence: Jane does
too:
S [Ag: v3, MaxS: C3]
</note>
<table confidence="0.373216333333333">
NP [i: r] V
jane(r)
Final
</table>
<sectionHeader confidence="0.505747" genericHeader="method">
Representation:
</sectionHeader>
<bodyText confidence="0.986401">
This sentence introduces an intransitive tree and
one propositional variable C3. This variable is
not constrained within the sentence, and parallel
to other pro-forms, it gets its interpretation from
the previous discourse. Specifically, the interpre-
tation of the second sentence is derived by unifi-
cation of the S features of the second and the first
S-trees in (9): C3=C1, v3=v. Given that C1 is
mapped to l2 above, it corresponds to the propo-
sition being reconstructed: C3(=C1) -&gt; l2
l3: λv.like(v, u) (r) = like(r, u)
</bodyText>
<sectionHeader confidence="0.965422" genericHeader="method">
6 Scope Parallelism
</sectionHeader>
<bodyText confidence="0.9997575">
Many previous approaches impose parallelism
constraints on the interpretation of the elided ma-
terial (e.g. Fox 2000, Asher et al 2001 among
others). Under the present analysis, scope paral-
lelism comes for free. Consider, for example, the
following sentence discussed in Dalrymple et al
1991, among others, where ambiguity is resolved
in the same way in both the antecedent and at the
ellipsis site: John gave every student a test, and
Bill did too. The final interpretation of the first
sentence is given in (10) and has 2 possible dis-
ambiguations.
</bodyText>
<listItem confidence="0.446962">
(10) John gave every student a test.
</listItem>
<equation confidence="0.985671833333333">
l0: give(v, u, w)
l1: λv.C1 (x) l2: λu.C2 (y) l2 ≤ C1
l3: λw.C3 (z) l3 ≤ C2
l7: every(y, R7, N7) l5: some(z, R5, N5)
l8: student(y) l9: test(z) john(x)
l0≤ C3 l0≤ N5 l0≤ N7 l8≤ R7 l9≤ R5
</equation>
<bodyText confidence="0.8898203125">
The surface reading (every &gt;&gt; some) is derived
by the following mapping: C3-&gt;l0, C2-&gt;l3, R7-&gt;l8,
N5 -&gt; l2, C1-&gt; l7, R5-&gt;l9, N7 -&gt; l5
l2: give(v, y, z)
l5: some(x, test(x), give(v, y, z))
l7:every(y,student(y),some(x,test(x),give(v,y, z)))
l1:every(y,student(y),some(x,test(x),give(x, y, z)))
The interpretation of the second sentence is
derived by unifying the S-features of the S-trees
(as shown in the previous section). As the result,
the variables C3 and v3 are unified with the vari-
ables C1 and v. Given that C1 is being mapped to
the proposition l7 above, C3 is being recon-
structed as the proposition every(y, student(y),
some(x, test(x), give(v, y, z)) and l3 corresponds
to the desired reading of this sentence:
</bodyText>
<equation confidence="0.888215">
C3 (=C1) -&gt; l7
</equation>
<bodyText confidence="0.980504131578947">
v3=v
l3: λv. every(y, student(y),some(x, test(x), give(v,
y, z))) (r) = every(y, student(y), some(x, test(x),
give(r, y, z)))
The inverse reading (where some&gt;&gt;every) can
be obtained by the following mapping C3-&gt;l0,
C2-&gt;l3, R7-&gt;l8, N7 -&gt; l2, C1-&gt; l5, R5-&gt;l9, N5 -&gt; l7
l2: give(v, y, z)
l7: every(y, student(y), give(v, y, z))
l5:some(x,test(x),every(y,student(y),give(v,y, z)))
l1: some(x,test(x),every(y,student(y),give(x, y, z)))
Now, when the second sentence is interpreted,
C3 is unified with C1, which is being mapped to
l5: C3(=C1) -&gt; l5. The proposition l3, then, is re-
duced to: λv.some(x, test(x), every(y, student(y),
give(v, y, z))) (r) = some(x, test(x), every(y, stu-
dent(y), give(r, y, z)))
As this example illustrates, scope parallelism
follows from the present analysis, given that C3
is unified with a disambiguated interpretation of
a VP. It can also be shown that the wide scope
puzzle (Sag 1980), shown in (12) is not unex-
pected under this approach, however, the analy-
sis of this phenomenon is beyond the scope of
this paper. 3
(12) A nurse saw every patient. Dr.Smith did too.
some(x, nurse(x), every(y, patient(y), see(x, y)))
*every(y, patient(y), some(x, nurse(x), see(x, y)))
3 As Hirschbuhler 1982, Fox 2000 among others noted,
there are constructions where subjects of VPE can have
narrow scope relative to nonsubjects. For example, the
sentence A Canadian flag was hanging in front of every
building. An American flag was too has a reading in which
each building has both an American and a Canadian flag
standing in front of it. The existence of such readings does
not present a problem for the present analysis, if we adopt
an analysis of quantificational NPs proposed in Babko-
Malaya 2004.
</bodyText>
<figure confidence="0.742569142857143">
l3: λv3.C3 (v5)
NP[i:v5] VP
l3: λv3 C3 (r)
Jane(r)
(11) Bill did too.
l4: Bill(r)
l3: λv3.C3 (r)
</figure>
<page confidence="0.98972">
95
</page>
<sectionHeader confidence="0.990107" genericHeader="conclusions">
7 Antecedent Contained Deletion(ACD)
</sectionHeader>
<bodyText confidence="0.994739">
Further evidence for the proposed analysis comes
from sentences with ACD, discussed in Sag
1980, Egg and Erk 2001, Asher et al 2001, Ja-
cobson (to appear), and illustrated in (13):
</bodyText>
<note confidence="0.4956415">
(13) John wants Mary to read every book Bill
does.
</note>
<bodyText confidence="0.995339111111111">
The elided material in this sentence is under-
stood as either “Bill reads” or “Bill wants Mary
to read”. Given that ‘want’ and ‘every’ can take
different scope, four possible readings are ex-
pected. However, puzzling in this case is the un-
availability of one of these readings: *John wants
that for every book that Bill wants Mary to read,
she reads it. Let us consider the final interpreta-
tion of this sentence:
</bodyText>
<reference confidence="0.8193675">
l4: want(v0, N4) l0: λv0.C2 (want) (r)
l1: read(v, u) l2: λv.C1 (read) (x)
l6: λu.C4 (read) (y) l6 ≤ C1 l8: book(y) ∧ l3
l5: every(y, R5, N5) l3: λv3.C (z)
mary(x), john(r), bill(z)
l1≤ C1, l4≤ C2, l1≤ N5, l8≤ R5, l1≤N4
</reference>
<bodyText confidence="0.911133333333333">
The non-lexicalized S tree introduces a proposi-
tion l3 and variables C and v3. These variables
can be unified with either S features of the
‘read’-tree (i.e. C1 and v), or S features of the
‘want’-tree (i.e. C2 and v0). In the first case, the
small ellipsis interpretation is derived, and both
scope readings are available: C = C1, v3 = v
C/C1 -&gt; l6, C4-&gt; l1
l2: read(x, y), l3: read(z, y)
</bodyText>
<equation confidence="0.969386875">
every &gt;&gt; want:
N5 -&gt; lo, C2 -&gt; l4, N4 -&gt; l2, R5 -&gt;l8
l5:every(y, book(y)&amp;read(z, y),want(r, read(x, y))
l3 l2
want &gt;&gt; every:
C2 -&gt; l4, N4 -&gt; l5, N5 -&gt; l2, R5 -&gt;l8
l0:want(r,every(y,book(y)&amp;read(z,y), read(x, y)))
l3 l2
</equation>
<bodyText confidence="0.995477352941176">
If C and v3 are unified with S features of the
‘want’-tree, then the large ellipsis interpretation
is derived: C = C2, v3 = v0, C/C2 -&gt; l4, N4 -&gt; l2, C4
-&gt; l1, C1 -&gt; l6
l0: want(r, read(x, y)), l3: want(z, read(x, y))
The reading where every &gt;&gt; want is derived by
the following constraints: N5-&gt; l0, C1-&gt; l1, R5 -&gt;l8
l5: every(y, book(y) &amp; want(z, read(x,y)),
want(r, read(x, y)) l3
l0
The fourth possible reading, where want &gt;&gt;
every, however, is predicted to be unavailable
under the present assumptions. This reading,
want(r, every(y, book(y) &amp; want(z, read(x, y)),
read(x, y)), cannot be derived, since it requires
the proposition l3 to be ‘inserted’ within the
proposition l0.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930902439025">
Asher N., D. Hardt and J.Busquets. 2001. Discourse
Parallelism, Scope, and Ellipsis”, Journal of Se-
mantics, 18(1), pp. 1-25.
Babko-Malaya O. 2004 “LTAG Semantics of NP-
Coordination” in Proc. of TAG+7, Vancouver
Dalrymple M., S.Shieber and F.Pereira 1991. Ellipsis
and Higher-Order Unification. In Linguistics and
Philosophy 14.
Egg, M. and K.Erk 2001. A compositional approach
to VP ellipsis 8th International Conference on
HPSG,Trondheim, Norway
Fiengo R. and R. May 1994. Indices and Identity.
MIT Press, Cambridge
Fox, D. 2000 Economy and Semantic Intepretation,
MIT Press
Hardt, D. 1993. VP Ellipsis: Form, Meaning and
Processing. PhD Diss. Univ. of PA
Hardt, D. 1999. Dynamic Interpretation of VP Ellip-
sis. Linguistics and Philosophy. 22.2. Heim, I.
2001
Jacobson, P. (to appear) Direct Compositionality and
Variable-Free Semantics: The Case of Antecedent
Contained Deletion”, in K. Johnson (ed.), Topics in
Ellipsis, Oxford University Press.
Johnson, K. 2003. In search of the Middle Field. Ms.
Univ. of Mass.
Joshi A. and Y. Schabes 1997. Tree-Adjoining
Grammars, in G. Rozenberg and A. Salomaa (eds.)
Handbook of Formal Languages, Springer, Berlin
Kallmeyer, L. and A.K Joshi 2003. Factoring Predi-
cate Argument and Scope Semantics: Underspeci-
fied Semantics with LTAG. Research on Language
and Computation 1(1-2), 358.
Kallmeyer, L. and M. Romero. 2004. LTAG Seman-
tics with Semantic Unification. In Proceedings of
TAG+7, Vancouver, Canada
Sag, Ivan 1980 Deletion and Logical Form. Garland
Press: New York
Shieber, S., F.Pereira, and M.Dalrymple 1996. Inter-
actions of Scope and Ellipsis. In Linguistics and
Philosophy 19, pp.527-552.
</reference>
<page confidence="0.998453">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.893507">
<title confidence="0.99593">Semantic Interpretation of Unrealized Syntactic Material in LTAG</title>
<author confidence="0.898456">Olga</author>
<affiliation confidence="0.999811">University of Pennsylvania</affiliation>
<email confidence="0.999758">malayao@ldc.upenn.edu</email>
<abstract confidence="0.99938575">This paper presents a LTAG-based analysis of gapping and VP ellipsis, which proposes that resolution of the elided material is part of a general disambiguation procedure, which is also responsible for resolution of underspecified representations of scope.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>l4: want(v0, N4) l0: λv0.C2 (want) (r) l1: read(v, u) l2: λv.C1 (read) (x) l6: λu.C4 (read) (y)</title>
<booktitle>l6 ≤ C1 l8: book(y) ∧ l3 l5: every(y, R5, N5) l3: λv3.C (z) mary(x), john(r), bill(z) l1≤ C1, l4≤ C2, l1≤ N5, l8≤ R5,</booktitle>
<pages>1--4</pages>
<marker></marker>
<rawString>l4: want(v0, N4) l0: λv0.C2 (want) (r) l1: read(v, u) l2: λv.C1 (read) (x) l6: λu.C4 (read) (y) l6 ≤ C1 l8: book(y) ∧ l3 l5: every(y, R5, N5) l3: λv3.C (z) mary(x), john(r), bill(z) l1≤ C1, l4≤ C2, l1≤ N5, l8≤ R5, l1≤N4</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>