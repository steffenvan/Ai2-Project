<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007952">
<title confidence="0.9928985">
UTU: Disease Mention Recognition and Normalization with CRFs and
Vector Space Representations
</title>
<author confidence="0.999437">
Suwisa Kaewphan1,2,3∗, Kai Hakaka1∗, Filip Ginter1
</author>
<affiliation confidence="0.989602">
1 Dept. of Information Technology, University of Turku, Finland
2 Turku Centre for Computer Science (TUCS), Turku, Finland
3 The University of Turku Graduate School (UTUGS), University of Turku, Finland
</affiliation>
<email confidence="0.994222">
sukaew@utu.fi, kahaka@utu.fi, ginter@cs.utu.fi
</email>
<sectionHeader confidence="0.99394" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9991721875">
In this paper we present our system par-
ticipating in the SemEval-2014 Task 7
in both subtasks A and B, aiming at
recognizing and normalizing disease and
symptom mentions from electronic medi-
cal records respectively. In subtask A, we
used an existing NER system, NERsuite,
with our own feature set tailored for this
task. For subtask B, we combined word
vector representations and supervised ma-
chine learning to map the recognized men-
tions to the corresponding UMLS con-
cepts. Our system was placed 2nd and 5th
out of 21 participants on subtasks A and B
respectively showing competitive perfor-
mance.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929470588235">
The SemEval 2014 task 7 aims to advance the de-
velopment of tools for analyzing clinical text. The
task is organized by providing the researchers an-
notated clinical records to develop systems that
can detect the mentions of diseases and symptoms
in medical records. In particular, the SemEval task
7 comprises two subtasks, recognizing the men-
tions of diseases and symptoms (task A) and map-
ping the mentions to unique concept identifiers
that belong to the semantic group of disorders in
the Unified Medical Language System (UMLS).
Our team participated in both of these sub-
tasks. In subtask A, we used an existing named
entity recognition (NER) system, NERsuite, sup-
plemented with UMLS dictionary and normaliza-
tion similarity features. In subtask B, we com-
bined compositional word vector representations
</bodyText>
<note confidence="0.635531">
∗These authors contributed equally.
</note>
<footnote confidence="0.6633105">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.997140666666667">
with supervised machine learning to map the rec-
ognized mentions from task A to the UMLS con-
cepts. Our best systems, evaluated on strict match-
ing criteria, achieved F-score of 76.6% for the sub-
task A and accuracy of 60.1% for the subtask B,
showing competitive performance in both tasks.
</bodyText>
<sectionHeader confidence="0.6672715" genericHeader="method">
2 Task A: Named Entity Recognition
with NERSuite
</sectionHeader>
<bodyText confidence="0.99969603125">
The ML approach based on conditional random
fields (CRFs) has shown to have state-of-the-art
performance in recognizing the biological entities.
We thus performed task A by using NERsuite,
an existing NER toolkit with competitive perfor-
mance on biological entity recognition (Campos
et al., 2013).
NERsuite is a NER system that is built on
top of the CRFsuite (Okazaki, 2007). It con-
sists of three language processing modules: a to-
kenizer, a modified version of the GENIA tagger
and a named entity recognizer. NERsuite allows
user-implemented features in addition to dictio-
nary matching and features shown to benefit the
systems such as raw token, lemma, part-of-speech
(POS) and text chunk.
Prior to detecting the disease mentions by the
recognizer module of NERsuite, the clinical text
is split into sentences by using GENIA Sentence
Splitter, a supervised ML system that is known to
be well optimized for biomedical texts (Sætre et
al., 2007). The sentences are subsequently tok-
enized and POS tagged.
To represent the positive entities, the “BIO”
model was used in our system. The first tokens
of positive mentions are labeled with “B” and the
rest with “I”. Negative examples, non-entities, are
thus labeled with “O”. This model was used for
both contiguous and discontiguous entities.
The features include the normalization similar-
ity (see Section 3.3), types of medical records (dis-
charge, echo, radiology and ecg), and UMLS dic-
</bodyText>
<page confidence="0.967301">
807
</page>
<note confidence="0.759331">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 807–811,
Dublin, Ireland, August 23-24, 2014.
</note>
<table confidence="0.997881333333333">
Trained Model Precision Recall F-score
train + positive samples 77.3% 72.4% 74.8%
train + development 76.7 % 76.5% 76.6%
</table>
<tableCaption confidence="0.997082">
Table 1: The results of our different NERsuite
</tableCaption>
<bodyText confidence="0.994939885714286">
models, announced by the organizers.
tionary matching in addition to NERsuite’s own
feature generation.
The UMLS dictionary is prepared by extract-
ing the UMLS database for the semantic types de-
manded by the task. In addition to those 11 seman-
tic types, “Finding” was also included in our dic-
tionary since, according to its definition, the con-
cept is also deemed relevant for the task. Due to
the common use of acronyms, which are not ex-
tensively provided by UMLS, we also extended
the coverage of our prepared UMLS dictionary
by extracting medical acronyms from the UMLS
database using regular expression.
We assessed the effect of dictionary matching
by training the models with and without the com-
piled UMLS dictionary and evaluating against the
development set. The model trained with dictio-
nary features outperformed the one without. The
best model was obtained by training the NERsuite
with UMLS dictionary in case-number-symbol
normalization mode. In this mode, all letters,
numbers and symbols are converted to lower case,
zero (0) and underscore ( ) respectively.
The regularization parameter (C2) was selected
by using development set to evaluate the best
model. The default parameter (C2 = 1.0) gave
the best performing system and thus was used
throughout the work.
Finally, for the NER task, we submitted two
models. The first model was trained with the orig-
inal training data and duplicates of sentences with
at least one entity mention. The second model
was trained by using the combination of the first
model’s training data and development set.
</bodyText>
<subsectionHeader confidence="0.690331">
2.1 Results and Discussions
</subsectionHeader>
<bodyText confidence="0.999929125">
Our NER system from both submissions benefited
from the increased number of training examples
while the more diverse training data set gave a bet-
ter performance. The official results are shown in
table 1.
The analysis of our best performing NER sys-
tem is not possible since the gold standard of the
test data is not publicly available. We thus simply
analyze our second NER system based on the eval-
uation on the development data. The F-score of the
system was 75.1% and 88.0% for the strict and re-
laxed evaluation criteria respectively. Among all
the mistakes made by the system, the discontigu-
ous entities were the most challenging ones for the
NERsuite. In development data, the discontiguous
entities contribute about 10% of all entities, how-
ever, only 2% were recognized correctly. On the
contrary, the system did well for the other types as
73% were correctly recognized under strict crite-
ria. This demonstrates that the “BIO” model has
limitations in representing the discontiguous enti-
ties. Improving the model to better represent the
discontiguous entities can possibly boost the per-
formance of the NER system significantly.
</bodyText>
<sectionHeader confidence="0.996612" genericHeader="method">
3 Task B: Normalization with
</sectionHeader>
<subsectionHeader confidence="0.911576">
Compositional Vector Representations
</subsectionHeader>
<bodyText confidence="0.999974757575758">
Our normalization approach is based on con-
tinuous distributed word vector representations,
namely the state-of-the-art method word2vec
(Mikolov et al., 2013a). Our word2vec model
was trained on a subset of abstracts and full ar-
ticles from the PubMed and PubMed Central re-
sources. This data was used as it was readily
available to us from the EVEX resource (Van Lan-
deghem et al., 2013). Before training, all non-
alphanumeric characters were removed and all to-
kens were lower-cased. Even though a set of unan-
notated clinical reports was provided in the task
to support unsupervised learning methods, our ex-
periments on the development set showed better
performance with the model trained with PubMed
articles. This might be due to the size of the cor-
pora, as the PubMed data included billions of to-
kens whereas the provided clinical reports totaled
in over 200 million tokens.
The dimensionality of the word vectors was set
to 300 and we used the continuous skip-gram ap-
proach. For other word2vec parameters default
values were used.
One interesting feature demonstrated by
Mikolov et al. (2013b; 2013c) is that the vectors
conserve some of the semantic characteristics in
element-wise addition and subtraction. In this task
we used the same approach of simply summing
the word-level vectors to create compositional
vectors for multi-word entities and concepts, i.e.
we looked up the vectors for every token appear-
ing in a concept name or entity and summed them
to form a vector to represent the whole phrase.
</bodyText>
<page confidence="0.990809">
808
</page>
<bodyText confidence="0.9999174375">
We then formed a lexicon including all preferred
terms and synonyms of all the concepts in the
subset of UMLS defined in the task guidelines.
This lexicon is a mapping from the compositional
vector representations of the concept names into
the corresponding UMLS identifiers. To select the
best concept for a recognized entity we calculated
cosine similarity between the vector representa-
tion of the given entity and all the concept vectors
in the lexicon and the concept with the highest
similarity was chosen.
Word2vec is generally able to relate different
forms of the same word to each other, but we no-
ticed a small improvement in accuracy when pos-
sessive suffixes were removed and all tokens were
lemmatized.
</bodyText>
<subsectionHeader confidence="0.997843">
3.1 Detecting CUI-less Mentions
</subsectionHeader>
<bodyText confidence="0.999996909090909">
As some of the mentions in the training data do not
have corresponding concepts in the semantic cat-
egories listed in the task guidelines, they are an-
notated as “CUI-less”. However, our normaliza-
tion approach will always find the nearest match-
ing concept, thus getting penalized for wrong pre-
dictions in the official evaluation. To overcome
this problem, we implemented three separate steps
for detecting the “CUI-less” mentions. As the
simplest approach we set a fixed cosine similarity
threshold and if the maximal similarity falls below
it, the mention is normalized to “CUI-less”. The
threshold value was selected using a grid search to
optimize the performance on the official develop-
ment set. Although this method resulted in decent
performance, it is not capable of coping with cases
where the mention has very high similarity or even
exact match with a concept name. For instance
our system normalized “aspiration” mentions into
UMLS concept “Pulmonary aspiration” which has
a synonym “Aspiration”, thus resulting in an exact
match. To resolve this kind of cases, we used sim-
ilar approach as in the DNorm system (Leaman et
al., 2013b), where the “CUI-less” mentions occur-
ring several times in the training data were added
to the concept lexicon with concept ID “CUI-less”.
As the final step we trained a binary SVM classi-
fier to distinguish the “CUI-less” mentions. The
classifier utilized bag-of-word features as well as
the compositional vectors. The performance im-
provement provided by each of these steps is pre-
sented in table 2. This evaluation shows that each
step increases the performance considerably, but
</bodyText>
<equation confidence="0.947979333333333">
Method Strict accuracy
43.6
48.4
T + L
T + L + C
O 59.3
</equation>
<tableCaption confidence="0.559191">
Table 2: Evaluation of the different approaches
</tableCaption>
<bodyText confidence="0.9973076">
to detect CUI-less entities on the official develop-
ment set compared to a baseline without CUI-less
detection and an oracle method with perfect de-
tection. This evaluation was done with the entities
recognized by our NER system instead of the gold
standard entities. B = baseline without CUI-less
detection, T = similarity threshold, L = Lexicon-
based method, C = classifier, O = Oracle.
the overall performance is still 3.9pp below per-
fect detection.
</bodyText>
<subsectionHeader confidence="0.998723">
3.2 Acronym Resolution
</subsectionHeader>
<bodyText confidence="0.999995086956522">
Abbreviations, especially acronyms, form a con-
siderable portion of the entity mentions in clini-
cal reports. One of the problems in normalizing
the acronyms is disambiguation as one acronym
can be associated with multiple diseases. Previ-
ous normalization systems (Leaman et al., 2013b)
handle this by selecting the matching concept with
most occurrences in the training data. However,
this approach does not resolve the problem of
non-standard acronyms, i.e. acronyms that are not
known in the UMLS vocabulary or in other medi-
cal acronym dictionaries. Our goal was to resolve
both of these problems by looking at the other enti-
ties found in the same document instead of match-
ing the acronym against the concept lexicon. With
this approach for instance entity mention “CP”
was on multiple occasions correctly normalized
into the concept “Chest Pain”, even though UMLS
is not aware of this acronym for the given concept
and in fact associates it with several other con-
cepts such as “Chronic Pancreatitis” and “Cerebral
Palsy”. However, the overall gain in accuracy ob-
tained from this method was only minor.
</bodyText>
<subsectionHeader confidence="0.993353">
3.3 Normalization Feedback to Named
Entity Recognition
</subsectionHeader>
<bodyText confidence="0.9998025">
While basic exact match dictionary features pro-
vide usually a large improvement in NER perfor-
mance, they are prone to bias the system to high
precision and low recall. As both noun and ad-
jective forms of medical concepts, e.g. “atrium”
and “atrial”, are commonly used in clinical texts,
</bodyText>
<figure confidence="0.94096825">
B
T
53.5
55.4
</figure>
<page confidence="0.996907">
809
</page>
<bodyText confidence="0.999944294117647">
the entities may not have exact dictionary matches.
Moreover the different forms of medical terms
may not share a common morphological root dis-
covered by simple stemming methods, thus com-
plicating approximate matching. In this task we
tried to boost the recall of our entity recognition by
feeding back the normalization similarity informa-
tion as features. These features included the max-
imum similarity between the token and the UMLS
concepts as a numerical value as well as a boolean
feature describing whether the similarity exceeded
a certain threshold.
In addition we experimented by calculating the
similarities for bigrams and trigrams in a slid-
ing window around the tokens, but these features
did not provide any further performance improve-
ments.
</bodyText>
<subsectionHeader confidence="0.934236">
3.4 Other Directions Explored
</subsectionHeader>
<bodyText confidence="0.99995190625">
The DNorm system utilizes TF-IDF vectors to rep-
resent the entities and concepts but instead of cal-
culating cosine similarity, the system trains a rank-
ing algorithm to measure the maximal similarity
(Leaman et al., 2013a). Their evaluation, carried
out on the NCBI disease corpus (Do˘gan et al.,
2014), showed a notable improvement in perfor-
mance compared to cosine similarity. In our anal-
ysis we noticed that in 39% of the false predic-
tions made by our normalization system, the cor-
rect concept was in the top 10 most similar con-
cepts. This strongly suggested that a similar rank-
ing method might be beneficial with our system as
well. To test this we trained a linear SVM to rerank
the top 10 concepts with highest cosine similarity,
but we were not able to increase the overall per-
formance of the system. However, due to the strict
time constraints of the task, we cannot conclude
whether this approach is feasible or not.
As our compositional vectors are formed by
summing the word vectors, each word has an equal
weight in the sum. Due to this our system made
various errors where the entity was a single word
matching closely to several concepts with longer
names. For instance entity “hypertensive” was
falsely normalized to concept “Hypertensive car-
diopathy” whereas the correct concept was “Hy-
pertensive disorder”. These mistakes could have
been prevented to some extent if the more impor-
tant words had had a larger weight in the sum, e.g.
word “disorder” is of low significance when try-
ing to distinguish different disorders. However,
</bodyText>
<table confidence="0.551359">
Strict accuracy Relaxed accuracy
UTH CCB
UWM
RelAgent
IxaMed
UTU
</table>
<tableCaption confidence="0.741029">
Table 3: Official evaluation results for the top 5
teams in the normalization task.
</tableCaption>
<bodyText confidence="0.998587">
weighting the word vectors with their IDF values,
document in this case being an UMLS concept, did
not improve the performance.
</bodyText>
<sectionHeader confidence="0.948477" genericHeader="evaluation">
3.5 Results
</sectionHeader>
<bodyText confidence="0.9999878">
The official results for the normalization task are
shown in table 3. Our system achieved accuracy
of 60.1% when evaluated with the official strict
evaluation metric. This result suggests that com-
positional vector representations are a competitive
approach for entity normalization. However, the
best performing team surpassed our performance
by 14.0pp, showing that there is plenty of room for
other teams to improve. It is worth noting though
that their recall in the NER task tops ours by 8.2pp
thus drastically influencing the normalization re-
sults as well. To evaluate the normalization sys-
tems in isolation from the NER task, a separate
evaluation set with gold standard entities should
be provided.
</bodyText>
<sectionHeader confidence="0.999685" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999945210526316">
Overall, our NER system can perform well with
the same default settings of NERsuite for gene
name recognition. The performance improves
when relevant features, such as UMLS dictionary
matching and word2vec similarity are added. We
speculated that representing the nature of the data
with more suitable model can improve the system
performance further. As a part of a combined sys-
tem, the improvement on NER system can result
in the increased performance of normalization sys-
tem.
Our normalization system showed competitive
results as well, indicating that word2vec-based
vector representations are a feasible way of solv-
ing the normalization task. As future work we
would like to explore different methods for cre-
ating the compositional vectors and reassess the
applicability of the reranking approach described
in section 3.4.
</bodyText>
<figure confidence="0.990159545454545">
Team
74.1
66.0
63.9
60.4
60.1
87.3
90.9
91.2
86.2
78.3
</figure>
<page confidence="0.983468">
810
</page>
<sectionHeader confidence="0.997146" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999931666666667">
Computational resources were provided by CSC
— IT Center for Science Ltd, Espoo, Finland. This
work was supported by the Academy of Finland.
</bodyText>
<sectionHeader confidence="0.996412" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993916930232558">
David Campos, S´ergio Matos, and Jos´e Lu´ıs Oliveira.
2013. Gimli: open source and high-performance
biomedical name recognition. BMC bioinformatics,
14(1):54.
Rezarta Islamaj Do˘gan, Robert Leaman, and Zhiyong
Lu. 2014. NCBI disease corpus: a resource for dis-
ease name recognition and concept normalization.
Journal of Biomedical Informatics, 47:1–10, Feb.
Robert Leaman, Rezarta Islamaj Do˘gan, and Zhiyong
Lu. 2013a. DNorm: disease name normaliza-
tion with pairwise learning to rank. Bioinformatics,
29(22):2909–2917.
Robert Leaman, Ritu Khare, and Zhiyong Lu.
2013b. NCBI at 2013 ShARe/CLEF eHealth Shared
Task: Disorder normalization in clinical notes with
DNorm. In Proceedings of the Conference and Labs
of the Evaluation Forum.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In ICLR Workshop.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013b. Distributed rep-
resentations of words and phrases and their compo-
sitionality. In NIPS, pages 3111–3119.
Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In HLT-NAACL, pages 746–
751.
Naoaki Okazaki. 2007. CRFsuite: a fast im-
plementation of conditional random fields (CRFs).
http://www.chokkan.org/software/crfsuite/.
Rune Sætre, Kazuhiro Yoshida, Akane Yakushiji,
Yusuke Miyao, Y Matsubyashi, and Tomoko Ohta.
2007. AKANE system: protein-protein interaction
pairs in BioCreAtIvE2 challenge, PPI-IPS subtask.
In Proceedings of the BioCreative II, pages 209–
212.
Sofie Van Landeghem, Jari Bj¨orne, Chih-Hsuan Wei,
Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,
Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, Yves
Van de Peer, and Filip Ginter. 2013. Large-
scale event extraction from literature with multi-
level gene normalization. PLoS ONE, 8(4):e55814.
</reference>
<page confidence="0.998227">
811
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.608227">
<title confidence="0.993902">UTU: Disease Mention Recognition and Normalization with CRFs Vector Space Representations</title>
<author confidence="0.999974">Kai Filip</author>
<affiliation confidence="0.999853">1Dept. of Information Technology, University of Turku,</affiliation>
<address confidence="0.855989">2Turku Centre for Computer Science (TUCS), Turku,</address>
<affiliation confidence="0.792101">3The University of Turku Graduate School (UTUGS), University of Turku,</affiliation>
<email confidence="0.992355">sukaew@utu.fi,kahaka@utu.fi,ginter@cs.utu.fi</email>
<abstract confidence="0.997015117647059">In this paper we present our system participating in the SemEval-2014 Task 7 in both subtasks A and B, aiming at recognizing and normalizing disease and symptom mentions from electronic medical records respectively. In subtask A, we used an existing NER system, NERsuite, with our own feature set tailored for this task. For subtask B, we combined word vector representations and supervised machine learning to map the recognized mentions to the corresponding UMLS concepts. Our system was placed 2nd and 5th out of 21 participants on subtasks A and B respectively showing competitive performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Campos</author>
<author>S´ergio Matos</author>
<author>Jos´e Lu´ıs Oliveira</author>
</authors>
<title>Gimli: open source and high-performance biomedical name recognition.</title>
<date>2013</date>
<journal>BMC bioinformatics,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="2701" citStr="Campos et al., 2013" startWordPosition="412" endWordPosition="415">sed machine learning to map the recognized mentions from task A to the UMLS concepts. Our best systems, evaluated on strict matching criteria, achieved F-score of 76.6% for the subtask A and accuracy of 60.1% for the subtask B, showing competitive performance in both tasks. 2 Task A: Named Entity Recognition with NERSuite The ML approach based on conditional random fields (CRFs) has shown to have state-of-the-art performance in recognizing the biological entities. We thus performed task A by using NERsuite, an existing NER toolkit with competitive performance on biological entity recognition (Campos et al., 2013). NERsuite is a NER system that is built on top of the CRFsuite (Okazaki, 2007). It consists of three language processing modules: a tokenizer, a modified version of the GENIA tagger and a named entity recognizer. NERsuite allows user-implemented features in addition to dictionary matching and features shown to benefit the systems such as raw token, lemma, part-of-speech (POS) and text chunk. Prior to detecting the disease mentions by the recognizer module of NERsuite, the clinical text is split into sentences by using GENIA Sentence Splitter, a supervised ML system that is known to be well op</context>
</contexts>
<marker>Campos, Matos, Oliveira, 2013</marker>
<rawString>David Campos, S´ergio Matos, and Jos´e Lu´ıs Oliveira. 2013. Gimli: open source and high-performance biomedical name recognition. BMC bioinformatics, 14(1):54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rezarta Islamaj Do˘gan</author>
<author>Robert Leaman</author>
<author>Zhiyong Lu</author>
</authors>
<title>NCBI disease corpus: a resource for disease name recognition and concept normalization.</title>
<date>2014</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>47--1</pages>
<marker>Do˘gan, Leaman, Lu, 2014</marker>
<rawString>Rezarta Islamaj Do˘gan, Robert Leaman, and Zhiyong Lu. 2014. NCBI disease corpus: a resource for disease name recognition and concept normalization. Journal of Biomedical Informatics, 47:1–10, Feb.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Rezarta Islamaj Do˘gan</author>
<author>Zhiyong Lu</author>
</authors>
<title>DNorm: disease name normalization with pairwise learning to rank.</title>
<date>2013</date>
<journal>Bioinformatics,</journal>
<volume>29</volume>
<issue>22</issue>
<marker>Leaman, Do˘gan, Lu, 2013</marker>
<rawString>Robert Leaman, Rezarta Islamaj Do˘gan, and Zhiyong Lu. 2013a. DNorm: disease name normalization with pairwise learning to rank. Bioinformatics, 29(22):2909–2917.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Ritu Khare</author>
<author>Zhiyong Lu</author>
</authors>
<title>NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder normalization in clinical notes with DNorm.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference and Labs of the Evaluation Forum.</booktitle>
<contexts>
<context position="10331" citStr="Leaman et al., 2013" startWordPosition="1651" endWordPosition="1654">larity falls below it, the mention is normalized to “CUI-less”. The threshold value was selected using a grid search to optimize the performance on the official development set. Although this method resulted in decent performance, it is not capable of coping with cases where the mention has very high similarity or even exact match with a concept name. For instance our system normalized “aspiration” mentions into UMLS concept “Pulmonary aspiration” which has a synonym “Aspiration”, thus resulting in an exact match. To resolve this kind of cases, we used similar approach as in the DNorm system (Leaman et al., 2013b), where the “CUI-less” mentions occurring several times in the training data were added to the concept lexicon with concept ID “CUI-less”. As the final step we trained a binary SVM classifier to distinguish the “CUI-less” mentions. The classifier utilized bag-of-word features as well as the compositional vectors. The performance improvement provided by each of these steps is presented in table 2. This evaluation shows that each step increases the performance considerably, but Method Strict accuracy 43.6 48.4 T + L T + L + C O 59.3 Table 2: Evaluation of the different approaches to detect CUI</context>
<context position="11673" citStr="Leaman et al., 2013" startWordPosition="1869" endWordPosition="1872">perfect detection. This evaluation was done with the entities recognized by our NER system instead of the gold standard entities. B = baseline without CUI-less detection, T = similarity threshold, L = Lexiconbased method, C = classifier, O = Oracle. the overall performance is still 3.9pp below perfect detection. 3.2 Acronym Resolution Abbreviations, especially acronyms, form a considerable portion of the entity mentions in clinical reports. One of the problems in normalizing the acronyms is disambiguation as one acronym can be associated with multiple diseases. Previous normalization systems (Leaman et al., 2013b) handle this by selecting the matching concept with most occurrences in the training data. However, this approach does not resolve the problem of non-standard acronyms, i.e. acronyms that are not known in the UMLS vocabulary or in other medical acronym dictionaries. Our goal was to resolve both of these problems by looking at the other entities found in the same document instead of matching the acronym against the concept lexicon. With this approach for instance entity mention “CP” was on multiple occasions correctly normalized into the concept “Chest Pain”, even though UMLS is not aware of </context>
<context position="13858" citStr="Leaman et al., 2013" startWordPosition="2225" endWordPosition="2228"> maximum similarity between the token and the UMLS concepts as a numerical value as well as a boolean feature describing whether the similarity exceeded a certain threshold. In addition we experimented by calculating the similarities for bigrams and trigrams in a sliding window around the tokens, but these features did not provide any further performance improvements. 3.4 Other Directions Explored The DNorm system utilizes TF-IDF vectors to represent the entities and concepts but instead of calculating cosine similarity, the system trains a ranking algorithm to measure the maximal similarity (Leaman et al., 2013a). Their evaluation, carried out on the NCBI disease corpus (Do˘gan et al., 2014), showed a notable improvement in performance compared to cosine similarity. In our analysis we noticed that in 39% of the false predictions made by our normalization system, the correct concept was in the top 10 most similar concepts. This strongly suggested that a similar ranking method might be beneficial with our system as well. To test this we trained a linear SVM to rerank the top 10 concepts with highest cosine similarity, but we were not able to increase the overall performance of the system. However, due</context>
</contexts>
<marker>Leaman, Khare, Lu, 2013</marker>
<rawString>Robert Leaman, Ritu Khare, and Zhiyong Lu. 2013b. NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder normalization in clinical notes with DNorm. In Proceedings of the Conference and Labs of the Evaluation Forum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<booktitle>In ICLR Workshop.</booktitle>
<contexts>
<context position="7091" citStr="Mikolov et al., 2013" startWordPosition="1116" endWordPosition="1119">ities, however, only 2% were recognized correctly. On the contrary, the system did well for the other types as 73% were correctly recognized under strict criteria. This demonstrates that the “BIO” model has limitations in representing the discontiguous entities. Improving the model to better represent the discontiguous entities can possibly boost the performance of the NER system significantly. 3 Task B: Normalization with Compositional Vector Representations Our normalization approach is based on continuous distributed word vector representations, namely the state-of-the-art method word2vec (Mikolov et al., 2013a). Our word2vec model was trained on a subset of abstracts and full articles from the PubMed and PubMed Central resources. This data was used as it was readily available to us from the EVEX resource (Van Landeghem et al., 2013). Before training, all nonalphanumeric characters were removed and all tokens were lower-cased. Even though a set of unannotated clinical reports was provided in the task to support unsupervised learning methods, our experiments on the development set showed better performance with the model trained with PubMed articles. This might be due to the size of the corpora, as </context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word representations in vector space. In ICLR Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Gregory S Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In NIPS,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="7091" citStr="Mikolov et al., 2013" startWordPosition="1116" endWordPosition="1119">ities, however, only 2% were recognized correctly. On the contrary, the system did well for the other types as 73% were correctly recognized under strict criteria. This demonstrates that the “BIO” model has limitations in representing the discontiguous entities. Improving the model to better represent the discontiguous entities can possibly boost the performance of the NER system significantly. 3 Task B: Normalization with Compositional Vector Representations Our normalization approach is based on continuous distributed word vector representations, namely the state-of-the-art method word2vec (Mikolov et al., 2013a). Our word2vec model was trained on a subset of abstracts and full articles from the PubMed and PubMed Central resources. This data was used as it was readily available to us from the EVEX resource (Van Landeghem et al., 2013). Before training, all nonalphanumeric characters were removed and all tokens were lower-cased. Even though a set of unannotated clinical reports was provided in the task to support unsupervised learning methods, our experiments on the development set showed better performance with the model trained with PubMed articles. This might be due to the size of the corpora, as </context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013b. Distributed representations of words and phrases and their compositionality. In NIPS, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>746--751</pages>
<contexts>
<context position="7091" citStr="Mikolov et al., 2013" startWordPosition="1116" endWordPosition="1119">ities, however, only 2% were recognized correctly. On the contrary, the system did well for the other types as 73% were correctly recognized under strict criteria. This demonstrates that the “BIO” model has limitations in representing the discontiguous entities. Improving the model to better represent the discontiguous entities can possibly boost the performance of the NER system significantly. 3 Task B: Normalization with Compositional Vector Representations Our normalization approach is based on continuous distributed word vector representations, namely the state-of-the-art method word2vec (Mikolov et al., 2013a). Our word2vec model was trained on a subset of abstracts and full articles from the PubMed and PubMed Central resources. This data was used as it was readily available to us from the EVEX resource (Van Landeghem et al., 2013). Before training, all nonalphanumeric characters were removed and all tokens were lower-cased. Even though a set of unannotated clinical reports was provided in the task to support unsupervised learning methods, our experiments on the development set showed better performance with the model trained with PubMed articles. This might be due to the size of the corpora, as </context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig. 2013c. Linguistic regularities in continuous space word representations. In HLT-NAACL, pages 746– 751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
</authors>
<title>CRFsuite: a fast implementation of conditional random fields</title>
<date>2007</date>
<contexts>
<context position="2780" citStr="Okazaki, 2007" startWordPosition="429" endWordPosition="430"> Our best systems, evaluated on strict matching criteria, achieved F-score of 76.6% for the subtask A and accuracy of 60.1% for the subtask B, showing competitive performance in both tasks. 2 Task A: Named Entity Recognition with NERSuite The ML approach based on conditional random fields (CRFs) has shown to have state-of-the-art performance in recognizing the biological entities. We thus performed task A by using NERsuite, an existing NER toolkit with competitive performance on biological entity recognition (Campos et al., 2013). NERsuite is a NER system that is built on top of the CRFsuite (Okazaki, 2007). It consists of three language processing modules: a tokenizer, a modified version of the GENIA tagger and a named entity recognizer. NERsuite allows user-implemented features in addition to dictionary matching and features shown to benefit the systems such as raw token, lemma, part-of-speech (POS) and text chunk. Prior to detecting the disease mentions by the recognizer module of NERsuite, the clinical text is split into sentences by using GENIA Sentence Splitter, a supervised ML system that is known to be well optimized for biomedical texts (Sætre et al., 2007). The sentences are subsequent</context>
</contexts>
<marker>Okazaki, 2007</marker>
<rawString>Naoaki Okazaki. 2007. CRFsuite: a fast implementation of conditional random fields (CRFs). http://www.chokkan.org/software/crfsuite/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rune Sætre</author>
<author>Kazuhiro Yoshida</author>
<author>Akane Yakushiji</author>
<author>Yusuke Miyao</author>
<author>Y Matsubyashi</author>
<author>Tomoko Ohta</author>
</authors>
<title>AKANE system: protein-protein interaction pairs</title>
<date>2007</date>
<booktitle>in BioCreAtIvE2 challenge, PPI-IPS subtask. In Proceedings of the BioCreative II,</booktitle>
<pages>209--212</pages>
<contexts>
<context position="3350" citStr="Sætre et al., 2007" startWordPosition="519" endWordPosition="522">t is built on top of the CRFsuite (Okazaki, 2007). It consists of three language processing modules: a tokenizer, a modified version of the GENIA tagger and a named entity recognizer. NERsuite allows user-implemented features in addition to dictionary matching and features shown to benefit the systems such as raw token, lemma, part-of-speech (POS) and text chunk. Prior to detecting the disease mentions by the recognizer module of NERsuite, the clinical text is split into sentences by using GENIA Sentence Splitter, a supervised ML system that is known to be well optimized for biomedical texts (Sætre et al., 2007). The sentences are subsequently tokenized and POS tagged. To represent the positive entities, the “BIO” model was used in our system. The first tokens of positive mentions are labeled with “B” and the rest with “I”. Negative examples, non-entities, are thus labeled with “O”. This model was used for both contiguous and discontiguous entities. The features include the normalization similarity (see Section 3.3), types of medical records (discharge, echo, radiology and ecg), and UMLS dic807 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 807–811, Dublin,</context>
</contexts>
<marker>Sætre, Yoshida, Yakushiji, Miyao, Matsubyashi, Ohta, 2007</marker>
<rawString>Rune Sætre, Kazuhiro Yoshida, Akane Yakushiji, Yusuke Miyao, Y Matsubyashi, and Tomoko Ohta. 2007. AKANE system: protein-protein interaction pairs in BioCreAtIvE2 challenge, PPI-IPS subtask. In Proceedings of the BioCreative II, pages 209– 212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sofie Van Landeghem</author>
<author>Jari Bj¨orne</author>
<author>Chih-Hsuan Wei</author>
<author>Kai Hakala</author>
</authors>
<title>Sampo Pyysalo, Sophia Ananiadou, Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski,</title>
<date>2013</date>
<journal>PLoS ONE,</journal>
<volume>8</volume>
<issue>4</issue>
<location>Yves Van</location>
<marker>Van Landeghem, Bj¨orne, Wei, Hakala, 2013</marker>
<rawString>Sofie Van Landeghem, Jari Bj¨orne, Chih-Hsuan Wei, Kai Hakala, Sampo Pyysalo, Sophia Ananiadou, Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, Yves Van de Peer, and Filip Ginter. 2013. Largescale event extraction from literature with multilevel gene normalization. PLoS ONE, 8(4):e55814.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>