<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009942">
<title confidence="0.9985715">
Addressing Ambiguity in Unsupervised Part-of-Speech Induction with
Substitute Vectors
</title>
<author confidence="0.975977">
Volkan Cirik
</author>
<affiliation confidence="0.9435195">
Artificial Intelligence Laboratory
Koc University, Istanbul, Turkey
</affiliation>
<email confidence="0.996247">
vcirik@ku.edu.tr
</email>
<sectionHeader confidence="0.993829" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888333333333">
We study substitute vectors to solve the
part-of-speech ambiguity problem in an
unsupervised setting. Part-of-speech tag-
ging is a crucial preliminary process in
many natural language processing applica-
tions. Because many words in natural lan-
guages have more than one part-of-speech
tag, resolving part-of-speech ambiguity is
an important task. We claim that part-
of-speech ambiguity can be solved using
substitute vectors. A substitute vector is
constructed with possible substitutes of a
target word. This study is built on pre-
vious work which has proven that word
substitutes are very fruitful for part-of-
speech induction. Experiments show that
our methodology works for words with
high ambiguity.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999676607142857">
Learning syntactic categories of words (i.e. part-
of-speech or POS tagging) is an important pre-
processing step for many natural language pro-
cessing applications because grammatical rules
are not functions of individual words, instead, they
are functions of word categories. Unlike super-
vised POS tagging systems, POS induction sys-
tems make use of unsupervised methods. They
categorize the words without any help of annotated
data.
POS induction is a popular topic and several
studies (Christodoulopoulos et al., 2010) have
been performed. Token based methods (Berg-
Kirkpatrick and Klein, 2010; Goldwater and Grif-
fiths, 2007) categorize word occurrences into syn-
tactic groups. Type based methods (Clark, 2003;
Blunsom and Cohn, 2011) on the other hand, cat-
egorize word types and yield the ambiguity prob-
lem unlike the token based methods.
Type based methods suffer from POS ambigu-
ity because one POS tag is assigned to each word
type. However, occurrences of many words may
have different POS tags. Two examples below are
drawn from the dataset we worked on. They il-
lustrate a situation where two occurrences of the
“offers” have different POS tags. In the first sen-
tence “offers” is a noun, whereas, in the second
sentence it is a verb.
</bodyText>
<listItem confidence="0.995523857142857">
(1) “Two rival bidders for Connaught
BioSciences extended their offers to ac-
quire the Toronto-based vaccine manu-
facturer Friday.”
(2) “The company currently offers a
word-processing package for personal
computers called Legend.”
</listItem>
<bodyText confidence="0.999934">
In this study, we try to extend the state-of-the-
art unsupervised POS tagger (Yatbaz et al., 2012)
by solving the ambiguity problem it suffers be-
cause it has a type based approach. The clustering
based studies (Sch¨utze, 1995) (Mintz, 2003) rep-
resent the context of a word with a vector using
neighbour words. Similarly, (Yatbaz et al., 2012)
proposes to use word context. They claim that the
substitutes of a word have similar syntactic cate-
gories and they are determined by the context of
the word.
In addition, we suggest that the occurrences
with different part-of-speech categories of a word
should be seen in different contexts. In other
words, if we categorize the contexts of a word type
we can determine different POS tags of the word.
We represent the context of a word by construct-
ing substitute vectors using possible substitutes of
the word as (Yatbaz et al., 2012) suggests.
Table 1 illustrates the substitute vector of the oc-
currence of “offers” in (1). There is a row for each
word in the vocabulary. For instance, probability
of occurring “agreement” in the position of “of-
fers” is 80% in this context. To resolve ambiguity
</bodyText>
<page confidence="0.973527">
117
</page>
<note confidence="0.588913">
Proceedings of the ACL Student Research Workshop, pages 117–122,
</note>
<page confidence="0.397069">
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</page>
<figure confidence="0.9166046">
Probability Substitute Word
0.80 agreement
0.03 offer
0.01 proposal
0.01 bid
0.01 attempt
0.01 bids
. .
. .
. .
</figure>
<tableCaption confidence="0.932851">
Table 1: Substitute Vector for “offers” in above
sentence.
</tableCaption>
<bodyText confidence="0.999437037037037">
of a target word, we separate occurrences of the
word into different groups depending on the con-
text information represented by substitute vectors.
We conduct two experiments. In the first ex-
periment, for each word type we investigated, we
separate all occurences into two categories using
substitute vectors. In the second one we guess the
number of the categories we should separate for
each word type. Both experiments achieve bet-
ter than (Yatbaz et al., 2012) for highly ambigu-
ous words. The level of ambiguity can be mea-
sured with perplexity of word’s gold tag distribu-
tion. For instance,the gold tag perplexity of word
“offers” in the Penn Treebank Wall Street Journal
corpus we worked on equals to 1.966. Accord-
ingly, the number of different gold tags of “of-
fers” is 2. Whereas, perplexity of “board” equals
to 1.019. Although the number of different tags
for “board” is equal to 2, only a small fraction
of the tags of board differs from each other. We
can conclude that “offers” is more ambiguous than
“board”.
In this paper we present a method to solve POS
ambiguity for a type based POS induction ap-
proach. For the rest of the paper, we explain our
algorithm and the setup of our experiments. Lastly
we present the results and a conclusion.
</bodyText>
<sectionHeader confidence="0.984922" genericHeader="introduction">
2 Algorithm
</sectionHeader>
<bodyText confidence="0.986351593220339">
We claim that if we categorize contexts a word
type occurs in, we can address ambiguity by sep-
arating its occurrences before POS induction. In
order to do that, we represent contexts of word
occurrences with substitute vectors. A substi-
tute vector is formed by the whole vocabulary of
words and their corresponding probabilities of oc-
curring in the position of the target word. To cal-
culate these probabilities, as described in (Yatbaz
et al., 2012), a 4-gram language model is built
with SRILM (Stolcke, 2002) on approximately
126 million tokens of Wall Street Journal data
(1987-1994) extracted from CSR-III Text (Graff
et al., 1995).
We generate substitute vectors for all tokens in
our dataset. We want to cluster occurrences of our
target words using them. In each substitute vector,
there is a row for every word in the vocabulary.
As a result, the dimension of substitute vectors is
equal to 49,206. Thus, in order not to suffer from
the curse of dimensionality, we reduce dimensions
of substitute vectors.
Before reducing the dimensions of these vec-
tors, distance matrices are created using Jensen
distance metric for each word type in step (a) of
Figure 1. We should note that these matrices are
created with substitute vectors of each word type,
not with all of the substitute vectors.
In step (b) of Figure 1, to reduce dimensionality,
the ISOMAP algorithm (Tenenbaum et al., 2000)
is used. The output vectors of the ISOMAP al-
gorithm are in 64 dimensions. We repeated our
experiments for different numbers of dimensions
and the best results are achieved when vectors are
in 64 dimensions.
In step (c) of Figure 1, after creating vectors
in lower dimension, using a modified k-means
algorithm (Arthur and Vassilvitskii, 2007) 64-
dimensional vectors are clustered for each word
type. The number of clusters given as an input to
k-means varies with experiments. We induce num-
ber of POS tags of a word type at this step.
Previous work (Yatbaz et al., 2012) demon-
strates that clustering substitute vectors of all word
types alone has limited success in predicting part-
of-speech tag of a word. To make use of both word
identity and context information of a given type,
we use S-CODE co-occurrence modeling (Maron
et al., 2010) as (Yatbaz et al., 2012) does.
Given a pair of categorical variables, the S-
CODE model represents each of their values on a
unit sphere such that frequently co-occurring val-
ues are located closely. We construct the pairs to
feed S-CODE as follows.
In step (d) of Figure 1, the first part of the pair is
the word identity concatenated with cluster ids we
got from the previous step. The cluster ids separate
word occurrences seen in different context groups.
By doing that, we make sure that the occurrences
</bodyText>
<page confidence="0.993837">
118
</page>
<figureCaption confidence="0.999231">
Figure 1: General Flow of The Algorithm
</figureCaption>
<bodyText confidence="0.99912485">
of a same word can be separated on the unit sphere
if they are seen in different context groups.
The second part of the pair is a substitute word.
For an instance of a target word, we sample a sub-
stitute word according to the target word’s sub-
stitute vector probabilities. If occurrences of two
different or the same word types have the same
substitutes, they should be seen in the similar con-
texts. As a result, words occurring in the simi-
lar contexts will be close to each other on the unit
sphere. Furthermore, they will have the same POS
tags. We should note that the co-occurrence input
file contains all word types.
In step (e) of Figure 1, on the output of the S-
CODE sphere, the words occurring in the simi-
lar contexts and having the same word-identity are
closely located. Thus, we observe clusters on the
unit sphere. For instance, verb occurrences of “of-
fers” are close to each other on the unit sphere.
They are also close to other verbs. Furthermore,
</bodyText>
<page confidence="0.995946">
119
</page>
<bodyText confidence="0.998844">
they are separated with occurrences of “offers”
which are nouns.
Lastly, in step (f) of Figure 1, we run k-means
clustering method on the S-CODE sphere and split
word-substitute word pairs into 45 clusters be-
cause the treebank we worked on uses 45 part-
of-speech tags. The output of clustering induces
part-of-speech categories of words tokens.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999970956521739">
In this section, the setup of each experiment will
be presented. The experiments are conducted on
Penn Treebank Wall Street Journal corpus. There
are 1,173,766 tokens and, 49,206 types. Out of
49,206 word types, 1183 of them are chosen as
target words. They are fed to the algorithm de-
scribed above. Occurrences of these target words
correspond to 37.55% of the whole data. These
target words are seen in the dataset more than 100
times and less than 4000 times. This subset is cho-
sen as such because word types occurring more
than 4000 times are all with low gold tag perplex-
ity. They also increase computation time dramat-
ically. We exclude word types occurring less than
100 times, because the clustering algorithm run-
ning on 64-dimension vectors does not work accu-
rately. To avoid providing noisy results, the exper-
iments are repeated 10 times. We report many-to-
one scores of the experiments. The many-to-one
evaluation assigns each cluster to its most frequent
gold-tag. Overall result demonstrates the percent-
age of correctly assigned instances and standard
deviation in paranthesis.
</bodyText>
<subsectionHeader confidence="0.986139">
3.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999987090909091">
Because we are trying to improve (Yatbaz et al.,
2012), we select the experiment on Penn Tree-
bank Wall Street Journal corpus in that work as
our baseline and replicate it. In that experiment,
POS induction is done by using word identities
and context information represented by substitute
words. Strictly one tag is assigned to each word
type. As a result, this method inaccurately induces
POS tags for the occurrences of word types with
high gold tag perplexity. The many-to-one accu-
racy of this experiment is 64%.
</bodyText>
<subsectionHeader confidence="0.996429">
3.2 Upperbound
</subsectionHeader>
<bodyText confidence="0.999985375">
In this experiment, for each word occurence, we
concatenate the gold tag for the first part of the
pairs in the co-occurence input file. Thus, we
skipped steps (a), (b), (c). The purpose of this
experiment is to set an upperbound for all experi-
ments since we cannot cluster the word tokens any
better than the gold tags. The many-to-one accu-
racy of this experiment is 67.2%.
</bodyText>
<subsectionHeader confidence="0.995774">
3.3 Experiment 1
</subsectionHeader>
<bodyText confidence="0.9999331875">
In the algorithm section, we mention that after di-
mensionality reduction step, we cluster the vec-
tors to separate tokens of a target word seen in the
similar contexts. In this experiment, we set the
number of clusters for each type to 2. In other
words, we assume that the number of different
POS tags of each word type is equal to 2. Nev-
ertheless, separating all the words into 2 clusters
results in some inaccuracy in POS induction. That
is because not all words have POS ambiguity and
some have more than 2 different POS tags How-
ever, the main purpose of this experiment is to ob-
serve whether we can increase the POS induction
accuracy for ambiguous types with our approach.
The many-to-one accuracy of this experiment is
63.8%.
</bodyText>
<subsectionHeader confidence="0.755769">
3.4 Experiment 2
</subsectionHeader>
<bodyText confidence="0.999018916666667">
In the previous experiment, we set the number of
clusters for each word type to 2. However, the
number of different POS tags differs for each word
type. More importantly, around 41% of our target
tokens belongs to unambiguous word types. Also,
around 36% of our target tokens comes from word
types whose gold perplexity is below 1.5. That
means, the Experiment 1 splits most of our word
types that should not be separated.
In this experiment, instead of splitting all types,
we guess which types should be splitted. Also, we
guess the number of clusters for each type. We
use gap statistic (Tibshirani et al., 2001) on 64-
dimensional vectors. The Gap statistic is a sta-
tistical method to guess the number of clusters
formed in given data points. We expect that substi-
tute vectors occurring in the similar context should
be closely located in 64-dimensional space. Thus,
gap statistic can provide us the number of groups
formed by vectors in 64-dimensional space. That
number is possibly equal to the number of the
number of different POS tags of the word types.
The many-to-one accuracy of this experiment is
63.4%.
</bodyText>
<page confidence="0.987915">
120
</page>
<subsectionHeader confidence="0.801917">
3.5 Experiment 3
</subsectionHeader>
<bodyText confidence="0.999967833333333">
In this experiment, we set the number of clusters
for each type to gold number of tags of each type.
The purpose of this experiment is to observe how
the accuracy of number of tags given, which is
used at step (c), affects the system. The many-
to-one accuracy of this experiment is 63.9%.
</bodyText>
<subsectionHeader confidence="0.998521">
3.6 Overall Results
</subsectionHeader>
<bodyText confidence="0.999915083333333">
In this section we present overall results of the
experiments. We present our results in 3 sepa-
rated tables because the accuracy of these methods
varies with the ambiguity level of word types.
In Table 2, many-to-one scores of three exper-
iments are presented. Since we exclude some of
the word types, our results correspond to 37.55%
of the data. In Table 3, results for the word types
whose gold tag perplexity is lower than 1.5 are
presented. They correspond to 29.11% of the data.
Lastly, in Table 4, we present the results for word
types whose gold tag perplexity is greater than 1.5.
</bodyText>
<table confidence="0.997659">
Experiment Many-to-One Score
Baseline .64 (.01)
Experiment 1 .638 (.01)
Experiment 2 .634 (.01)
Experiment 3 .639 (.02)
</table>
<tableCaption confidence="0.958203">
Table 2: Results for the target words correspond-
ing to 37.55% of the data.
</tableCaption>
<table confidence="0.999775">
Experiment Many-to-One Score
Baseline .693 (.02)
Experiment 1 .682 (.01)
Experiment 2 .68 (.01)
Experiment 3 .684 (.02)
</table>
<tableCaption confidence="0.703151">
Table 3: Results for Target Words with gold tag
perplexity ≤1.5 which corresponds to 29.11% of
the data.
</tableCaption>
<sectionHeader confidence="0.981605" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999896387096774">
Table 2 shows that the baseline experiment is
slightly better than our experiments. That is be-
cause our experiments inaccurately induce more
than one tag to unambiguous types. Additionally,
most of our target words have low gold tag per-
plexity. Table 3 supports this claim. In Table 4,
we observe that our methods outscore the baseline
significantly. That is because, when ambiguity in-
creases, the baseline method inaccurately assigns
one POS tag to word types. On the other hand, the
gap statistic method is not fully efficient in guess-
ing the number of clusters. It sometimes separates
unambiguous types or it does not separate highly
ambiguous word types. As a result, there is a slight
difference between the results of our experiments.
Additionally, the results of our experiments
show that, accurately guessing number of clusters
plays a crucial role in this approach. Even using
the gold number of different tags in Experiment 3
does not result in a significantly accurate system.
That is because, the number of different tags does
not reflect the perplexity of a word type.
The results show that, POS ambiguity can be
addressed by using substitute vectors for word
types with high ambiguity. The accuracy of this
approach correlates with the level of ambiguity of
word types. Thus, the detection of the level of am-
biguity for word types should be the future direc-
tion of this research. We again propose that substi-
tute vector distributions could be useful to extract
perplexity information for a word type.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999683">
I would like to thank the members of the Koc Uni-
versity Artificial Intelligence Laboratory for their
help and support. Additionally, I would like to
thank two anonymous reviewers and Murat Sey-
han for their comments and suggestions.
</bodyText>
<table confidence="0.9875876">
Experiment Many-to-One Score
Baseline .458 (.01)
Experiment 1 .484
Experiment 2 .474
Experiment 3 .483 (.02)
</table>
<tableCaption confidence="0.703191">
Table 4: Results for Target Words with gold tag
perplexity ≥1.5 which corresponds to 8.44% of
the data..
</tableCaption>
<sectionHeader confidence="0.99742" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990577333333333">
D. Arthur and S. Vassilvitskii. 2007. k-means++: The
advantages of careful seeding. In Proceedings of the
eighteenth annual ACM-SIAM symposium on Dis-
crete algorithms, pages 1027–1035. Society for In-
dustrial and Applied Mathematics.
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylo-
genetic grammar induction. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, pages 1288–1297, Uppsala,
</reference>
<page confidence="0.98933">
121
</page>
<reference confidence="0.996784348484849">
Sweden, July. Association for Computational Lin-
guistics.
Phil Blunsom and Trevor Cohn. 2011. A hierarchi-
cal pitman-yor process hmm for unsupervised part
of speech induction. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
865–874, Portland, Oregon, USA, June. Association
for Computational Linguistics.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsuper-
vised pos induction: how far have we come? In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, EMNLP
’10, pages 575–584, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech induc-
tion. In Proceedings of the tenth conference on Eu-
ropean chapter of the Association for Computational
Linguistics - Volume 1, EACL ’03, pages 59–66,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Sharon Goldwater and Tom Griffiths. 2007. A fully
bayesian approach to unsupervised part-of-speech
tagging. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 744–751, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
David Graff, Roni Rosenfeld, and Doug Paul. 1995.
Csr-iii text. Linguistic Data Consortium, Philadel-
phia.
Yariv Maron, Michael Lamar, and Elie Bienenstock.
2010. Sphere embedding: An application to part-of-
speech induction. In J. Lafferty, C. K. I. Williams,
J. Shawe-Taylor, R.S. Zemel, and A. Culotta, ed-
itors, Advances in Neural Information Processing
Systems 23, pages 1567–1575.
T.H. Mintz. 2003. Frequent frames as a cue for gram-
matical categories in child directed speech. Cogni-
tion, 90(1):91–117.
Hinrich Sch¨utze. 1995. Distributional part-of-speech
tagging. In Proceedings of the seventh conference
on European chapter of the Association for Compu-
tational Linguistics, EACL ’95, pages 141–148, San
Francisco, CA, USA. Morgan Kaufmann Publishers
Inc.
Andreas Stolcke. 2002. Srilm-an extensible lan-
guage modeling toolkit. In Proceedings Interna-
tional Conference on Spoken Language Processing,
pages 257–286, November.
J.B. Tenenbaum, V. Silva, and J.C. Langford. 2000.
A global geometric framework for nonlinear dimen-
sionality reduction. Science, 290(5500):2319.
R. Tibshirani, G. Walther, and T. Hastie. 2001. Es-
timating the number of data clusters via the gap
statistic. Journal of the Royal Statistical Society B,
63:411–423.
Mehmet Ali Yatbaz, Enis Sert, and Deniz Yuret. 2012.
Learning syntactic categories using paradigmatic
representations of word context. In Proceedings of
the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 940–951, Jeju
Island, Korea, July. Association for Computational
Linguistics.
</reference>
<page confidence="0.997457">
122
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.901081">
<title confidence="0.998034">Addressing Ambiguity in Unsupervised Part-of-Speech Induction Substitute Vectors</title>
<author confidence="0.956673">Volkan</author>
<affiliation confidence="0.978678">Artificial Intelligence Koc University, Istanbul,</affiliation>
<email confidence="0.987083">vcirik@ku.edu.tr</email>
<abstract confidence="0.999143947368421">We study substitute vectors to solve the part-of-speech ambiguity problem in an unsupervised setting. Part-of-speech tagging is a crucial preliminary process in many natural language processing applications. Because many words in natural languages have more than one part-of-speech tag, resolving part-of-speech ambiguity is an important task. We claim that partof-speech ambiguity can be solved using substitute vectors. A substitute vector is constructed with possible substitutes of a target word. This study is built on previous work which has proven that word substitutes are very fruitful for part-ofspeech induction. Experiments show that our methodology works for words with high ambiguity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Arthur</author>
<author>S Vassilvitskii</author>
</authors>
<title>k-means++: The advantages of careful seeding.</title>
<date>2007</date>
<journal>Society for Industrial and Applied Mathematics.</journal>
<booktitle>In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms,</booktitle>
<pages>1027--1035</pages>
<contexts>
<context position="6833" citStr="Arthur and Vassilvitskii, 2007" startWordPosition="1109" endWordPosition="1112">n distance metric for each word type in step (a) of Figure 1. We should note that these matrices are created with substitute vectors of each word type, not with all of the substitute vectors. In step (b) of Figure 1, to reduce dimensionality, the ISOMAP algorithm (Tenenbaum et al., 2000) is used. The output vectors of the ISOMAP algorithm are in 64 dimensions. We repeated our experiments for different numbers of dimensions and the best results are achieved when vectors are in 64 dimensions. In step (c) of Figure 1, after creating vectors in lower dimension, using a modified k-means algorithm (Arthur and Vassilvitskii, 2007) 64- dimensional vectors are clustered for each word type. The number of clusters given as an input to k-means varies with experiments. We induce number of POS tags of a word type at this step. Previous work (Yatbaz et al., 2012) demonstrates that clustering substitute vectors of all word types alone has limited success in predicting partof-speech tag of a word. To make use of both word identity and context information of a given type, we use S-CODE co-occurrence modeling (Maron et al., 2010) as (Yatbaz et al., 2012) does. Given a pair of categorical variables, the SCODE model represents each </context>
</contexts>
<marker>Arthur, Vassilvitskii, 2007</marker>
<rawString>D. Arthur and S. Vassilvitskii. 2007. k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027–1035. Society for Industrial and Applied Mathematics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1288--1297</pages>
<location>Uppsala,</location>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1288–1297, Uppsala,</rawString>
</citation>
<citation valid="false">
<authors>
<author>July Sweden</author>
</authors>
<title>Association for Computational Linguistics.</title>
<marker>Sweden, </marker>
<rawString>Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
</authors>
<title>A hierarchical pitman-yor process hmm for unsupervised part of speech induction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>865--874</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1637" citStr="Blunsom and Cohn, 2011" startWordPosition="233" endWordPosition="236">ep for many natural language processing applications because grammatical rules are not functions of individual words, instead, they are functions of word categories. Unlike supervised POS tagging systems, POS induction systems make use of unsupervised methods. They categorize the words without any help of annotated data. POS induction is a popular topic and several studies (Christodoulopoulos et al., 2010) have been performed. Token based methods (BergKirkpatrick and Klein, 2010; Goldwater and Griffiths, 2007) categorize word occurrences into syntactic groups. Type based methods (Clark, 2003; Blunsom and Cohn, 2011) on the other hand, categorize word types and yield the ambiguity problem unlike the token based methods. Type based methods suffer from POS ambiguity because one POS tag is assigned to each word type. However, occurrences of many words may have different POS tags. Two examples below are drawn from the dataset we worked on. They illustrate a situation where two occurrences of the “offers” have different POS tags. In the first sentence “offers” is a noun, whereas, in the second sentence it is a verb. (1) “Two rival bidders for Connaught BioSciences extended their offers to acquire the Toronto-b</context>
</contexts>
<marker>Blunsom, Cohn, 2011</marker>
<rawString>Phil Blunsom and Trevor Cohn. 2011. A hierarchical pitman-yor process hmm for unsupervised part of speech induction. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 865–874, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos Christodoulopoulos</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Two decades of unsupervised pos induction: how far have we come?</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>575--584</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1423" citStr="Christodoulopoulos et al., 2010" startWordPosition="201" endWordPosition="204"> part-ofspeech induction. Experiments show that our methodology works for words with high ambiguity. 1 Introduction Learning syntactic categories of words (i.e. partof-speech or POS tagging) is an important preprocessing step for many natural language processing applications because grammatical rules are not functions of individual words, instead, they are functions of word categories. Unlike supervised POS tagging systems, POS induction systems make use of unsupervised methods. They categorize the words without any help of annotated data. POS induction is a popular topic and several studies (Christodoulopoulos et al., 2010) have been performed. Token based methods (BergKirkpatrick and Klein, 2010; Goldwater and Griffiths, 2007) categorize word occurrences into syntactic groups. Type based methods (Clark, 2003; Blunsom and Cohn, 2011) on the other hand, categorize word types and yield the ambiguity problem unlike the token based methods. Type based methods suffer from POS ambiguity because one POS tag is assigned to each word type. However, occurrences of many words may have different POS tags. Two examples below are drawn from the dataset we worked on. They illustrate a situation where two occurrences of the “of</context>
</contexts>
<marker>Christodoulopoulos, Goldwater, Steedman, 2010</marker>
<rawString>Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2010. Two decades of unsupervised pos induction: how far have we come? In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 575–584, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Combining distributional and morphological information for part of speech induction.</title>
<date>2003</date>
<booktitle>In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume 1, EACL ’03,</booktitle>
<pages>59--66</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1612" citStr="Clark, 2003" startWordPosition="231" endWordPosition="232">processing step for many natural language processing applications because grammatical rules are not functions of individual words, instead, they are functions of word categories. Unlike supervised POS tagging systems, POS induction systems make use of unsupervised methods. They categorize the words without any help of annotated data. POS induction is a popular topic and several studies (Christodoulopoulos et al., 2010) have been performed. Token based methods (BergKirkpatrick and Klein, 2010; Goldwater and Griffiths, 2007) categorize word occurrences into syntactic groups. Type based methods (Clark, 2003; Blunsom and Cohn, 2011) on the other hand, categorize word types and yield the ambiguity problem unlike the token based methods. Type based methods suffer from POS ambiguity because one POS tag is assigned to each word type. However, occurrences of many words may have different POS tags. Two examples below are drawn from the dataset we worked on. They illustrate a situation where two occurrences of the “offers” have different POS tags. In the first sentence “offers” is a noun, whereas, in the second sentence it is a verb. (1) “Two rival bidders for Connaught BioSciences extended their offers</context>
</contexts>
<marker>Clark, 2003</marker>
<rawString>Alexander Clark. 2003. Combining distributional and morphological information for part of speech induction. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume 1, EACL ’03, pages 59–66, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Tom Griffiths</author>
</authors>
<title>A fully bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>744--751</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1529" citStr="Goldwater and Griffiths, 2007" startWordPosition="216" endWordPosition="220">duction Learning syntactic categories of words (i.e. partof-speech or POS tagging) is an important preprocessing step for many natural language processing applications because grammatical rules are not functions of individual words, instead, they are functions of word categories. Unlike supervised POS tagging systems, POS induction systems make use of unsupervised methods. They categorize the words without any help of annotated data. POS induction is a popular topic and several studies (Christodoulopoulos et al., 2010) have been performed. Token based methods (BergKirkpatrick and Klein, 2010; Goldwater and Griffiths, 2007) categorize word occurrences into syntactic groups. Type based methods (Clark, 2003; Blunsom and Cohn, 2011) on the other hand, categorize word types and yield the ambiguity problem unlike the token based methods. Type based methods suffer from POS ambiguity because one POS tag is assigned to each word type. However, occurrences of many words may have different POS tags. Two examples below are drawn from the dataset we worked on. They illustrate a situation where two occurrences of the “offers” have different POS tags. In the first sentence “offers” is a noun, whereas, in the second sentence i</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Tom Griffiths. 2007. A fully bayesian approach to unsupervised part-of-speech tagging. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 744–751, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Roni Rosenfeld</author>
<author>Doug Paul</author>
</authors>
<date>1995</date>
<booktitle>Csr-iii text. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="5733" citStr="Graff et al., 1995" startWordPosition="925" endWordPosition="928"> we categorize contexts a word type occurs in, we can address ambiguity by separating its occurrences before POS induction. In order to do that, we represent contexts of word occurrences with substitute vectors. A substitute vector is formed by the whole vocabulary of words and their corresponding probabilities of occurring in the position of the target word. To calculate these probabilities, as described in (Yatbaz et al., 2012), a 4-gram language model is built with SRILM (Stolcke, 2002) on approximately 126 million tokens of Wall Street Journal data (1987-1994) extracted from CSR-III Text (Graff et al., 1995). We generate substitute vectors for all tokens in our dataset. We want to cluster occurrences of our target words using them. In each substitute vector, there is a row for every word in the vocabulary. As a result, the dimension of substitute vectors is equal to 49,206. Thus, in order not to suffer from the curse of dimensionality, we reduce dimensions of substitute vectors. Before reducing the dimensions of these vectors, distance matrices are created using Jensen distance metric for each word type in step (a) of Figure 1. We should note that these matrices are created with substitute vector</context>
</contexts>
<marker>Graff, Rosenfeld, Paul, 1995</marker>
<rawString>David Graff, Roni Rosenfeld, and Doug Paul. 1995. Csr-iii text. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yariv Maron</author>
<author>Michael Lamar</author>
<author>Elie Bienenstock</author>
</authors>
<title>Sphere embedding: An application to part-ofspeech induction.</title>
<date>2010</date>
<booktitle>Advances in Neural Information Processing Systems 23,</booktitle>
<pages>1567--1575</pages>
<editor>In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors,</editor>
<contexts>
<context position="7330" citStr="Maron et al., 2010" startWordPosition="1196" endWordPosition="1199">f Figure 1, after creating vectors in lower dimension, using a modified k-means algorithm (Arthur and Vassilvitskii, 2007) 64- dimensional vectors are clustered for each word type. The number of clusters given as an input to k-means varies with experiments. We induce number of POS tags of a word type at this step. Previous work (Yatbaz et al., 2012) demonstrates that clustering substitute vectors of all word types alone has limited success in predicting partof-speech tag of a word. To make use of both word identity and context information of a given type, we use S-CODE co-occurrence modeling (Maron et al., 2010) as (Yatbaz et al., 2012) does. Given a pair of categorical variables, the SCODE model represents each of their values on a unit sphere such that frequently co-occurring values are located closely. We construct the pairs to feed S-CODE as follows. In step (d) of Figure 1, the first part of the pair is the word identity concatenated with cluster ids we got from the previous step. The cluster ids separate word occurrences seen in different context groups. By doing that, we make sure that the occurrences 118 Figure 1: General Flow of The Algorithm of a same word can be separated on the unit spher</context>
</contexts>
<marker>Maron, Lamar, Bienenstock, 2010</marker>
<rawString>Yariv Maron, Michael Lamar, and Elie Bienenstock. 2010. Sphere embedding: An application to part-ofspeech induction. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 1567–1575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Mintz</author>
</authors>
<title>Frequent frames as a cue for grammatical categories in child directed speech.</title>
<date>2003</date>
<journal>Cognition,</journal>
<volume>90</volume>
<issue>1</issue>
<contexts>
<context position="2610" citStr="Mintz, 2003" startWordPosition="398" endWordPosition="399">wo occurrences of the “offers” have different POS tags. In the first sentence “offers” is a noun, whereas, in the second sentence it is a verb. (1) “Two rival bidders for Connaught BioSciences extended their offers to acquire the Toronto-based vaccine manufacturer Friday.” (2) “The company currently offers a word-processing package for personal computers called Legend.” In this study, we try to extend the state-of-theart unsupervised POS tagger (Yatbaz et al., 2012) by solving the ambiguity problem it suffers because it has a type based approach. The clustering based studies (Sch¨utze, 1995) (Mintz, 2003) represent the context of a word with a vector using neighbour words. Similarly, (Yatbaz et al., 2012) proposes to use word context. They claim that the substitutes of a word have similar syntactic categories and they are determined by the context of the word. In addition, we suggest that the occurrences with different part-of-speech categories of a word should be seen in different contexts. In other words, if we categorize the contexts of a word type we can determine different POS tags of the word. We represent the context of a word by constructing substitute vectors using possible substitute</context>
</contexts>
<marker>Mintz, 2003</marker>
<rawString>T.H. Mintz. 2003. Frequent frames as a cue for grammatical categories in child directed speech. Cognition, 90(1):91–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Distributional part-of-speech tagging.</title>
<date>1995</date>
<booktitle>In Proceedings of the seventh conference on European chapter of the Association for Computational Linguistics, EACL ’95,</booktitle>
<pages>141--148</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<marker>Sch¨utze, 1995</marker>
<rawString>Hinrich Sch¨utze. 1995. Distributional part-of-speech tagging. In Proceedings of the seventh conference on European chapter of the Association for Computational Linguistics, EACL ’95, pages 141–148, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings International Conference on Spoken Language Processing,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="5608" citStr="Stolcke, 2002" startWordPosition="908" endWordPosition="909">algorithm and the setup of our experiments. Lastly we present the results and a conclusion. 2 Algorithm We claim that if we categorize contexts a word type occurs in, we can address ambiguity by separating its occurrences before POS induction. In order to do that, we represent contexts of word occurrences with substitute vectors. A substitute vector is formed by the whole vocabulary of words and their corresponding probabilities of occurring in the position of the target word. To calculate these probabilities, as described in (Yatbaz et al., 2012), a 4-gram language model is built with SRILM (Stolcke, 2002) on approximately 126 million tokens of Wall Street Journal data (1987-1994) extracted from CSR-III Text (Graff et al., 1995). We generate substitute vectors for all tokens in our dataset. We want to cluster occurrences of our target words using them. In each substitute vector, there is a row for every word in the vocabulary. As a result, the dimension of substitute vectors is equal to 49,206. Thus, in order not to suffer from the curse of dimensionality, we reduce dimensions of substitute vectors. Before reducing the dimensions of these vectors, distance matrices are created using Jensen dist</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm-an extensible language modeling toolkit. In Proceedings International Conference on Spoken Language Processing, pages 257–286, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Tenenbaum</author>
<author>V Silva</author>
<author>J C Langford</author>
</authors>
<title>A global geometric framework for nonlinear dimensionality reduction.</title>
<date>2000</date>
<journal>Science,</journal>
<volume>290</volume>
<issue>5500</issue>
<contexts>
<context position="6490" citStr="Tenenbaum et al., 2000" startWordPosition="1053" endWordPosition="1056"> substitute vector, there is a row for every word in the vocabulary. As a result, the dimension of substitute vectors is equal to 49,206. Thus, in order not to suffer from the curse of dimensionality, we reduce dimensions of substitute vectors. Before reducing the dimensions of these vectors, distance matrices are created using Jensen distance metric for each word type in step (a) of Figure 1. We should note that these matrices are created with substitute vectors of each word type, not with all of the substitute vectors. In step (b) of Figure 1, to reduce dimensionality, the ISOMAP algorithm (Tenenbaum et al., 2000) is used. The output vectors of the ISOMAP algorithm are in 64 dimensions. We repeated our experiments for different numbers of dimensions and the best results are achieved when vectors are in 64 dimensions. In step (c) of Figure 1, after creating vectors in lower dimension, using a modified k-means algorithm (Arthur and Vassilvitskii, 2007) 64- dimensional vectors are clustered for each word type. The number of clusters given as an input to k-means varies with experiments. We induce number of POS tags of a word type at this step. Previous work (Yatbaz et al., 2012) demonstrates that clusterin</context>
</contexts>
<marker>Tenenbaum, Silva, Langford, 2000</marker>
<rawString>J.B. Tenenbaum, V. Silva, and J.C. Langford. 2000. A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500):2319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tibshirani</author>
<author>G Walther</author>
<author>T Hastie</author>
</authors>
<title>Estimating the number of data clusters via the gap statistic.</title>
<date>2001</date>
<journal>Journal of the Royal Statistical Society B,</journal>
<pages>63--411</pages>
<contexts>
<context position="12595" citStr="Tibshirani et al., 2001" startWordPosition="2109" endWordPosition="2112">riment 2 In the previous experiment, we set the number of clusters for each word type to 2. However, the number of different POS tags differs for each word type. More importantly, around 41% of our target tokens belongs to unambiguous word types. Also, around 36% of our target tokens comes from word types whose gold perplexity is below 1.5. That means, the Experiment 1 splits most of our word types that should not be separated. In this experiment, instead of splitting all types, we guess which types should be splitted. Also, we guess the number of clusters for each type. We use gap statistic (Tibshirani et al., 2001) on 64- dimensional vectors. The Gap statistic is a statistical method to guess the number of clusters formed in given data points. We expect that substitute vectors occurring in the similar context should be closely located in 64-dimensional space. Thus, gap statistic can provide us the number of groups formed by vectors in 64-dimensional space. That number is possibly equal to the number of the number of different POS tags of the word types. The many-to-one accuracy of this experiment is 63.4%. 120 3.5 Experiment 3 In this experiment, we set the number of clusters for each type to gold numbe</context>
</contexts>
<marker>Tibshirani, Walther, Hastie, 2001</marker>
<rawString>R. Tibshirani, G. Walther, and T. Hastie. 2001. Estimating the number of data clusters via the gap statistic. Journal of the Royal Statistical Society B, 63:411–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehmet Ali Yatbaz</author>
<author>Enis Sert</author>
<author>Deniz Yuret</author>
</authors>
<title>Learning syntactic categories using paradigmatic representations of word context.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>940--951</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="2468" citStr="Yatbaz et al., 2012" startWordPosition="373" endWordPosition="376">occurrences of many words may have different POS tags. Two examples below are drawn from the dataset we worked on. They illustrate a situation where two occurrences of the “offers” have different POS tags. In the first sentence “offers” is a noun, whereas, in the second sentence it is a verb. (1) “Two rival bidders for Connaught BioSciences extended their offers to acquire the Toronto-based vaccine manufacturer Friday.” (2) “The company currently offers a word-processing package for personal computers called Legend.” In this study, we try to extend the state-of-theart unsupervised POS tagger (Yatbaz et al., 2012) by solving the ambiguity problem it suffers because it has a type based approach. The clustering based studies (Sch¨utze, 1995) (Mintz, 2003) represent the context of a word with a vector using neighbour words. Similarly, (Yatbaz et al., 2012) proposes to use word context. They claim that the substitutes of a word have similar syntactic categories and they are determined by the context of the word. In addition, we suggest that the occurrences with different part-of-speech categories of a word should be seen in different contexts. In other words, if we categorize the contexts of a word type we</context>
<context position="4297" citStr="Yatbaz et al., 2012" startWordPosition="677" endWordPosition="680">bstitute Word 0.80 agreement 0.03 offer 0.01 proposal 0.01 bid 0.01 attempt 0.01 bids . . . . . . Table 1: Substitute Vector for “offers” in above sentence. of a target word, we separate occurrences of the word into different groups depending on the context information represented by substitute vectors. We conduct two experiments. In the first experiment, for each word type we investigated, we separate all occurences into two categories using substitute vectors. In the second one we guess the number of the categories we should separate for each word type. Both experiments achieve better than (Yatbaz et al., 2012) for highly ambiguous words. The level of ambiguity can be measured with perplexity of word’s gold tag distribution. For instance,the gold tag perplexity of word “offers” in the Penn Treebank Wall Street Journal corpus we worked on equals to 1.966. Accordingly, the number of different gold tags of “offers” is 2. Whereas, perplexity of “board” equals to 1.019. Although the number of different tags for “board” is equal to 2, only a small fraction of the tags of board differs from each other. We can conclude that “offers” is more ambiguous than “board”. In this paper we present a method to solve </context>
<context position="5547" citStr="Yatbaz et al., 2012" startWordPosition="896" endWordPosition="899"> POS induction approach. For the rest of the paper, we explain our algorithm and the setup of our experiments. Lastly we present the results and a conclusion. 2 Algorithm We claim that if we categorize contexts a word type occurs in, we can address ambiguity by separating its occurrences before POS induction. In order to do that, we represent contexts of word occurrences with substitute vectors. A substitute vector is formed by the whole vocabulary of words and their corresponding probabilities of occurring in the position of the target word. To calculate these probabilities, as described in (Yatbaz et al., 2012), a 4-gram language model is built with SRILM (Stolcke, 2002) on approximately 126 million tokens of Wall Street Journal data (1987-1994) extracted from CSR-III Text (Graff et al., 1995). We generate substitute vectors for all tokens in our dataset. We want to cluster occurrences of our target words using them. In each substitute vector, there is a row for every word in the vocabulary. As a result, the dimension of substitute vectors is equal to 49,206. Thus, in order not to suffer from the curse of dimensionality, we reduce dimensions of substitute vectors. Before reducing the dimensions of t</context>
<context position="7062" citStr="Yatbaz et al., 2012" startWordPosition="1151" endWordPosition="1154">y, the ISOMAP algorithm (Tenenbaum et al., 2000) is used. The output vectors of the ISOMAP algorithm are in 64 dimensions. We repeated our experiments for different numbers of dimensions and the best results are achieved when vectors are in 64 dimensions. In step (c) of Figure 1, after creating vectors in lower dimension, using a modified k-means algorithm (Arthur and Vassilvitskii, 2007) 64- dimensional vectors are clustered for each word type. The number of clusters given as an input to k-means varies with experiments. We induce number of POS tags of a word type at this step. Previous work (Yatbaz et al., 2012) demonstrates that clustering substitute vectors of all word types alone has limited success in predicting partof-speech tag of a word. To make use of both word identity and context information of a given type, we use S-CODE co-occurrence modeling (Maron et al., 2010) as (Yatbaz et al., 2012) does. Given a pair of categorical variables, the SCODE model represents each of their values on a unit sphere such that frequently co-occurring values are located closely. We construct the pairs to feed S-CODE as follows. In step (d) of Figure 1, the first part of the pair is the word identity concatenate</context>
<context position="10362" citStr="Yatbaz et al., 2012" startWordPosition="1719" endWordPosition="1722"> times are all with low gold tag perplexity. They also increase computation time dramatically. We exclude word types occurring less than 100 times, because the clustering algorithm running on 64-dimension vectors does not work accurately. To avoid providing noisy results, the experiments are repeated 10 times. We report many-toone scores of the experiments. The many-to-one evaluation assigns each cluster to its most frequent gold-tag. Overall result demonstrates the percentage of correctly assigned instances and standard deviation in paranthesis. 3.1 Baseline Because we are trying to improve (Yatbaz et al., 2012), we select the experiment on Penn Treebank Wall Street Journal corpus in that work as our baseline and replicate it. In that experiment, POS induction is done by using word identities and context information represented by substitute words. Strictly one tag is assigned to each word type. As a result, this method inaccurately induces POS tags for the occurrences of word types with high gold tag perplexity. The many-to-one accuracy of this experiment is 64%. 3.2 Upperbound In this experiment, for each word occurence, we concatenate the gold tag for the first part of the pairs in the co-occurenc</context>
</contexts>
<marker>Yatbaz, Sert, Yuret, 2012</marker>
<rawString>Mehmet Ali Yatbaz, Enis Sert, and Deniz Yuret. 2012. Learning syntactic categories using paradigmatic representations of word context. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 940–951, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>