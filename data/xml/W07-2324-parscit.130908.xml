<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031390">
<title confidence="0.9911255">
Combining Multiple Information Layers for the Automatic
Generation of Indicative Meeting Abstracts
</title>
<author confidence="0.9414">
Thomas Kleinbauer and Stephanie Becker and Tilman Becker
</author>
<affiliation confidence="0.806866">
German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.781201">
Stuhlsatzenhausweg 3, 66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.989651">
&lt;firstname.lastname&gt;@dfki.de
</email>
<sectionHeader confidence="0.979175" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999771857142857">
We describe a new application for NLG technol-
ogy: the generation of indicative, abstractive
summaries of multi-party meetings. Based on
the freely available AMI corpus of 100 hours of
recorded meetings, we are developing a summa-
rizer that uses the rich annotations in the AMI
corpus.
</bodyText>
<sectionHeader confidence="0.99551" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970714285714">
The automatic summarization of documents has
been a research topic for half a century now.
Most prominently, the automatic creation of
document extracts has been studied extensively.
However, when applying such approaches to
natural dialogs, such as meetings, the resulting
texts may differ vastly from hand-written sum-
maries: instead of concise and coherent prose,
the expected output consists of a concatenation
of speaker contributions taken from the orig-
inal dialog. Yet, these utterances were made
from each speaker’s own perspective and thus
are likely to contain first-person wording, inept
for a comprehensible summary. Additionally,
speech disfluencies or–in automated settings–
speech recognition errors might further decrease
the readability of the text. Finally, the ex-
tracted utterances are reproduced out of con-
text which can be problematic in numerous
ways, including the acceptance of the service by
the meeting participants.
In this paper, we present our ongoing research
on the generation of meeting abstracts that aims
at overcoming the outlined shortcomings. So
far, we have concentrated on indicative sum-
maries that allow the reader to quickly assess
whether the underlying meeting is relevant for
her current information need.
</bodyText>
<sectionHeader confidence="0.998756" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999691076923077">
Extractive summarization of documents has
been studied extensively over the last decades
(s. Mani and Maybury (1999) for an overview),
but faces additional challenges when applied to
natural language dialogs. Unlike carefully au-
thored articles, spontaneous utterances are of-
ten ungrammatical and contain speech disflu-
encies (Liu et al., 2006). Moreover, free dis-
cussions are naturally less well structured, e. g.,
when speakers switch topics or digress. For an
automated system, additional difficulties arise
from the limitations of current ASR systems, in-
troducing recognition errors into all subsequent
processing steps. Zechner (2001) and Murray et
al. (2005) show ways to cope with such issues.
Generative approaches, on the other hand,
are based on an internal representation of sum-
mary contents verbalized through NLG tech-
niques (e.g. Kan et al. (2001)). Such ap-
proaches have been applied to natural dis-
course domains before, for instance, Alexander-
sson (2003) generates summaries of machine–
translated phone conversations. However, we
are not aware of any prior work attempting to
generate full abstracts of multi-party interac-
tion.
</bodyText>
<sectionHeader confidence="0.992802" genericHeader="method">
3 Annotated AMI Meetings
</sectionHeader>
<bodyText confidence="0.999583888888889">
In the Ami project&apos;, circa 100 hours of meetings
have been recorded, annotated and stored in a
freely available multimodal corpus (McCowan
et al., 2005). The meetings are semi-staged,
in the sense that they are based on the pre-
defined scenario of a virtual company in which
a project team works on the task of designing
a new innovative remote control. The roles of
the four project team members are played by
</bodyText>
<footnote confidence="0.998269">
1http://www.amiproject.org
</footnote>
<page confidence="0.998119">
151
</page>
<bodyText confidence="0.9999929">
subjects which act as a project manager, a user
interface designer, a production designer, and a
marketing expert. However, the discussions of
the meeting participants are free and not pre-
scripted. Meetings typically last about 30-40
minutes.
In addition to multiple video and audio
streams, a number of annotations are included
in the corpus, such as speech transcription, syn-
tactic chunks, named entities, dialog acts, ad-
dressing, argumentative structure, hot spots,
decision points and topics.
The goal of the AMI project is to develop
automatic recognition systems for all of these
annotation layers. In section 4 we show which
layers are already used by our summarizer, see
figure 5 for an example from the current system.
However, all of these annotations are potentially
useful, very rich resources for further extensions
of our system.
</bodyText>
<subsectionHeader confidence="0.994401">
3.1 Propositional Content
</subsectionHeader>
<bodyText confidence="0.999995114285714">
Additionally, we have annotated a small sub-
set of the Ami corpus with categories from a
domain ontology to represent the propositional
content of speaker utterances. The AmiMAT-
TER ontology that we created for this purpose
models the remote control design scenario in a
formal ontology based on Dolce-Lite-Plus (Ma-
solo et al., 2003). Embedded in a comprehensive
theory of representing situations and descrip-
tions, it provides a taxonomy of relevant terms,
ordered by an IS-A relation that expresses sub-
sumption, or specialization. For instance, it
contains information such as (remote control IS-
A technical device) which expresses that the cat-
egory remote control is a sub-category of the
category technical device. Hence, a reasoner can
infer that all remote controls (which technically
would be considered instances of the category
remote control) are technical devices.
The AmiMATTER ontology covers over 20 dif-
ferent subdomains, with a total of 53,319 cat-
egories. 52,072 of those are extracted from
WordNet (Fellbaum, 1998), the remaining 1,247
cover scenario-specific concepts and the Dolce-
Lite-Plus upper model. Three subdomains—
physical objects, meeting-related categories and
project-related categories—were used to anno-
tate the discourse transcription. The current
system relies only on the annotation of rele-
vant categories, ignoring relations within or be-
yond the dialog act segment boundaries2. Fig. 1
shows an example of such an annotation: three
instances from the physical object subdomain
were created (shown as boxes) and linked to the
respective words in the source utterance above.
</bodyText>
<sectionHeader confidence="0.989891" genericHeader="method">
4 Summary Content Representation
</sectionHeader>
<bodyText confidence="0.999989833333333">
We currently concentrate on three of the above
annotation layers, topic labels, dialog acts and
propositional content. For the pre-existing topic
annotation, the recordings were split into larger
segments and labeled with one of 24 topics
matching typical activities in the remote con-
trol design scenario, e. g., “discussion” or “pre-
sentation of prototype(s)”. These segments are
used by our system as the basic structuring unit
for the summaries. In most cases, the label can
be used to verbalize the general subject of the
topic segment, with the exception of the “other”
label which is used for unknown topics.
In a similar practice, all participants’ utter-
ances in the manual transcript of the meeting
discourse were segmented and labeled with dia-
log acts such as “inform”, “suggest”, etc. ac-
cording to a scheme consisting of 15 distin-
guished dialog acts. However, our system cur-
rently discards the labels themselves, but uses
the segments as a common unit for the propo-
sitional content annotation outlined in section
3.1. We perform a frequency analysis of all an-
notated ontology instances and select the three
items that occur most often. We found this a
useful heuristic, although it sometimes produces
unexpected results (s. fig. 5: the term “beep”
stems from an ontology category of the same
name that was used to annotate a discussion
about audio signals in the corpus).
</bodyText>
<sectionHeader confidence="0.981293" genericHeader="method">
5 Text Generation
</sectionHeader>
<bodyText confidence="0.9994525">
The actual generation of the abstracts is done
in a three-step pipeline:
</bodyText>
<listItem confidence="0.999078666666667">
1. Analysis of meeting annotation layers
2. Sentence planning
3. Surface realization
</listItem>
<bodyText confidence="0.723136428571429">
In the first step, information drawn from the
annotation layers (s. section 3) is transformed
2More precisely, annotators were asked to identify
those terms in a speaker utterance that belong to one
of the three subdomains, identify the appropriate Ami-
MATTER category and create an instance of it, and con-
nect the instance with the original word.
</bodyText>
<page confidence="0.996035">
152
</page>
<figureCaption confidence="0.993349666666667">
Figure 1: Example annotation of an utterance in meeting IS1009c in the AMI corpus. The outer
sides display categories and relations of the AMIMATTER ontology in tree views, the center part
contains the meeting transcript (top) and the annotation area (bottom).
</figureCaption>
<bodyText confidence="0.992944">
into expressions in a propositional logic-like for-
malism (figure 2). These assertions are used
</bodyText>
<equation confidence="0.927456">
(topic &amp;quot;t0&amp;quot;)
(about &amp;quot;t0&amp;quot; &amp;quot;opening&amp;quot;)
(content &amp;quot;t0&amp;quot; &amp;quot;introduction&amp;quot;)
(content &amp;quot;t0&amp;quot; &amp;quot;project manager&amp;quot;)
(after &amp;quot;t0&amp;quot; &amp;quot;t1&amp;quot;) ...
</equation>
<figureCaption confidence="0.936741">
Figure 2: The input for the sentence planner:
topic t0 which is the opening of the meeting
occurs before topic t1 and contains the content
items “introduction” and “project manager”.
</figureCaption>
<bodyText confidence="0.976285166666667">
as a knowledge base by the sentence planner
PREPLAN, a hierarchical, goal-driven planner
(Andr´e, 1995). In addition to the assertions,
PREPLAN is provided with a library of plan op-
erators, each of which encodes strategies how to
reach a given goal. Figure 3 shows an exam-
</bodyText>
<figure confidence="0.5876292">
strategy: (ShowSummary)
subgoals: (WriteXMLHeader)
(for-each ?t with (topic ?t)
(ShowTopic ?t))
(WriteXMLFooter)
</figure>
<figureCaption confidence="0.999536">
Figure 3: A complex plan operator in PREPLAN
</figureCaption>
<bodyText confidence="0.999936222222222">
ple of such an operator which describes how to
reach the goal “ShowSummary” as the result of
solving three subgoals, one of which is an itera-
tion over all topics. Here, the “with”-condition
is matched against the knowledge base that was
generated before.
PREPLAN successively finds matching plan-
operators until all goals and subgoals are re-
solved. The outcome of this process is an XML-
encoded description of instructions in a logi-
cal form which is passed to the surface real-
izer, NIPsGEN (Engel, 2006), a template-based
generator. NIPsGEN converts the semantic in-
put into typed feature structures which are
then transformed into a natural language utter-
ance. A derivation tree for the XTAG-grammar
(XTAG Research Group, 2001) is created using
transformation rules which are applied to the
input structure (see figure 4 for a sample rule).
The actual syntax tree is constructed using the
derivation tree. The generation of the correct
morphological inflections is achieved by perco-
lating the morphological features through the
XTAG tree and looking up the correct inflec-
tions for all lexical leaves in the XTAG lexicon
for English. Traversing the lexical leaves from
left to right produces the natural language ut-
</bodyText>
<page confidence="0.998143">
153
</page>
<bodyText confidence="0.98973275">
$VP=VP(o:Introduction(has-topic:$T,
has-agent:$A), not(lex:))
-&gt; $VP(lex:introduce, sub:NP(o:$A),
obj:NP(o:$T))
</bodyText>
<figureCaption confidence="0.691764">
Figure 4: A NipsGEn rule: the semantic con-
cept ’Introduction()’ is lexicalized with the verb
’introduce’. The values of the features ’has-
topic’ and ’has-agent’ are realized as NP’s in
object and subject position, respectively.
</figureCaption>
<bodyText confidence="0.973168444444445">
terance.
“The meeting was opened and the meeting
group talked about the user interface, the re-
mote control and the design. They debated
the costs, the company and the project while
discussing the project budget. The signal, the
remote control and the beep were mentioned
afterwards. They talked about meeting before
closing the meeting.”
</bodyText>
<figureCaption confidence="0.991574">
Figure 5: Example of a meeting summary.
</figureCaption>
<sectionHeader confidence="0.862388" genericHeader="conclusions">
6 Current and Future Work
</sectionHeader>
<bodyText confidence="0.964226068965517">
We are currently developing the summarization
system further by adding more annotation lay-
ers to the processing pipeline.
Work has also begun on the evaluation of
meeting summaries. To this end, we will use a
task based evaluation scheme where summaries
are used by subjects to better understand previ-
ous meetings in order to join the team, replac-
ing a previous member. The quality of sum-
maries will degrade when we move from hand-
annotated layers to automatically generated an-
notations. Extrinsic evaluations as described
above will be a realistic measure for the level
of degradation.
Given the richness of the data in the AMI
corpus, we have also started work on multime-
dia summaries that will combine text with pic-
tures from the video signals and links into the
meetings3. We are experimenting with result-
based summaries, presented in a newspaper
style and timeline-based summaries, presented
in a comic-strip style.
In general, summarization of multi-party
meetings poses further challenges, like sum-
3These links are timestamps that are used by a meet-
ing player to show relevant segments.
maries from a personal perspective, and mov-
ing to related domains like instant messaging
and IRC interactions.
</bodyText>
<sectionHeader confidence="0.979276" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99941474">
Jan Alexandersson. 2003. Hybrid Discourse Mod-
elling and Summarization for a Speech-to-Speech
Translation System. Ph.D. thesis, Universtit¨at
des Saarlandes, Germany.
Elisabeth Andr´e. 1995. Ein planbasierter Ansatz zur
Generierung multimedialer Pr¨asentationen. Infix,
St. Augustin.
Ralf Engel. 2006. SPIN: A semantic parser for
spoken dialog systems. In Proceedings of the
Fifth Slovenian And First International Language
Technology Conference (IS-LTC 2006).
Christiane Fellbaum, editor. 1998. WordNet–An
Electronic Lexical Database. MIT Press.
Min-Yen Kan, Kathleen R. McKeown, and Judith L.
Klavans. 2001. Applying natural language gener-
ation to indicative summarization. In Proceedings
of 8th European Workshop on Natural Language
Generation, pages 92–100, Toulouse, France, July.
Y. Liu, E. Shriberg, A. Stolcke, D. Hillard, M. Os-
tendorf, and M. Harper. 2006. Enriching speech
recognition with automatic detection of sen-
tence boundaries and disfluencies. IEEE Transac-
tions on Audio, Speech and Language Processing,
14(5):1526–1540.
Inderjeet Mani and Mark T. Maybury, editors. 1999.
Advances in automatic text summarization. MIT
Press.
C. Masolo, S. Borgo, A. Gangemi, N. Guarino, and
A. Oltramari. 2003. Wonderweb deliverable D18
ontology library (final), December.
I. McCowan, J. Carletta, W. Kraaij, S. Ashby,
S. Bourban, M. Flynn, M. Guillemot, T. Hain,
J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lath-
oud, M. Lincoln, A. Lisowska, W. Post, D. Rei-
dsma, and P. Wellner. 2005. The Ami meeting
corpus. In Proceedings of the Measuring Behav-
ior 2005 symposium on Annotating and Measur-
ing Meeting Behavior, Wageningen, NL, Septem-
ber.
G. Murray, S. Renals, and J. Carletta. 2005. Ex-
tractive summarization of meeting recordings. In
Proceedings of the 9th European Conference on
Speech Communication and Technology, Lisbon,
Portugal, September.
XTAG Research Group. 2001. A lexicalized tree
adjoining grammar for english. Technical Report
IRCS-01-03, IRCS, University of Pennsylvania.
Klaus Zechner. 2001. Automatic Summarization of
Spoken Dialogues in Unrestricted Domains. Ph.D.
thesis, Carnegie Mellon University.
</reference>
<page confidence="0.999772">
154
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.358569">
<title confidence="0.999347">Combining Multiple Information Layers for the Generation of Indicative Meeting Abstracts</title>
<author confidence="0.95562">Kleinbauer Becker</author>
<affiliation confidence="0.465528">German Research Center for Artificial Intelligence</affiliation>
<address confidence="0.39923">Stuhlsatzenhausweg 3, 66123 Saarbr¨ucken,</address>
<email confidence="0.986077"><firstname.lastname>@dfki.de</email>
<abstract confidence="0.992177">We describe a new application for NLG technology: the generation of indicative, abstractive summaries of multi-party meetings. Based on the freely available AMI corpus of 100 hours of recorded meetings, we are developing a summarizer that uses the rich annotations in the AMI corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jan Alexandersson</author>
</authors>
<title>Hybrid Discourse Modelling and Summarization for a Speech-to-Speech Translation System.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Universtit¨at des Saarlandes,</institution>
<contexts>
<context position="2831" citStr="Alexandersson (2003)" startWordPosition="415" endWordPosition="417">reover, free discussions are naturally less well structured, e. g., when speakers switch topics or digress. For an automated system, additional difficulties arise from the limitations of current ASR systems, introducing recognition errors into all subsequent processing steps. Zechner (2001) and Murray et al. (2005) show ways to cope with such issues. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instance, Alexandersson (2003) generates summaries of machine– translated phone conversations. However, we are not aware of any prior work attempting to generate full abstracts of multi-party interaction. 3 Annotated AMI Meetings In the Ami project&apos;, circa 100 hours of meetings have been recorded, annotated and stored in a freely available multimodal corpus (McCowan et al., 2005). The meetings are semi-staged, in the sense that they are based on the predefined scenario of a virtual company in which a project team works on the task of designing a new innovative remote control. The roles of the four project team members are </context>
</contexts>
<marker>Alexandersson, 2003</marker>
<rawString>Jan Alexandersson. 2003. Hybrid Discourse Modelling and Summarization for a Speech-to-Speech Translation System. Ph.D. thesis, Universtit¨at des Saarlandes, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Andr´e</author>
</authors>
<date>1995</date>
<booktitle>Ein planbasierter Ansatz zur Generierung multimedialer Pr¨asentationen.</booktitle>
<publisher>Infix, St. Augustin.</publisher>
<marker>Andr´e, 1995</marker>
<rawString>Elisabeth Andr´e. 1995. Ein planbasierter Ansatz zur Generierung multimedialer Pr¨asentationen. Infix, St. Augustin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Engel</author>
</authors>
<title>SPIN: A semantic parser for spoken dialog systems.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth Slovenian And First International Language Technology Conference (IS-LTC</booktitle>
<contexts>
<context position="9475" citStr="Engel, 2006" startWordPosition="1466" endWordPosition="1467">er) (for-each ?t with (topic ?t) (ShowTopic ?t)) (WriteXMLFooter) Figure 3: A complex plan operator in PREPLAN ple of such an operator which describes how to reach the goal “ShowSummary” as the result of solving three subgoals, one of which is an iteration over all topics. Here, the “with”-condition is matched against the knowledge base that was generated before. PREPLAN successively finds matching planoperators until all goals and subgoals are resolved. The outcome of this process is an XMLencoded description of instructions in a logical form which is passed to the surface realizer, NIPsGEN (Engel, 2006), a template-based generator. NIPsGEN converts the semantic input into typed feature structures which are then transformed into a natural language utterance. A derivation tree for the XTAG-grammar (XTAG Research Group, 2001) is created using transformation rules which are applied to the input structure (see figure 4 for a sample rule). The actual syntax tree is constructed using the derivation tree. The generation of the correct morphological inflections is achieved by percolating the morphological features through the XTAG tree and looking up the correct inflections for all lexical leaves in </context>
</contexts>
<marker>Engel, 2006</marker>
<rawString>Ralf Engel. 2006. SPIN: A semantic parser for spoken dialog systems. In Proceedings of the Fifth Slovenian And First International Language Technology Conference (IS-LTC 2006).</rawString>
</citation>
<citation valid="true">
<title>WordNet–An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet–An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
<author>Kathleen R McKeown</author>
<author>Judith L Klavans</author>
</authors>
<title>Applying natural language generation to indicative summarization.</title>
<date>2001</date>
<booktitle>In Proceedings of 8th European Workshop on Natural Language Generation,</booktitle>
<pages>92--100</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="2723" citStr="Kan et al. (2001)" startWordPosition="397" endWordPosition="400">es, spontaneous utterances are often ungrammatical and contain speech disfluencies (Liu et al., 2006). Moreover, free discussions are naturally less well structured, e. g., when speakers switch topics or digress. For an automated system, additional difficulties arise from the limitations of current ASR systems, introducing recognition errors into all subsequent processing steps. Zechner (2001) and Murray et al. (2005) show ways to cope with such issues. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instance, Alexandersson (2003) generates summaries of machine– translated phone conversations. However, we are not aware of any prior work attempting to generate full abstracts of multi-party interaction. 3 Annotated AMI Meetings In the Ami project&apos;, circa 100 hours of meetings have been recorded, annotated and stored in a freely available multimodal corpus (McCowan et al., 2005). The meetings are semi-staged, in the sense that they are based on the predefined scenario of a virtual company in which a project team wor</context>
</contexts>
<marker>Kan, McKeown, Klavans, 2001</marker>
<rawString>Min-Yen Kan, Kathleen R. McKeown, and Judith L. Klavans. 2001. Applying natural language generation to indicative summarization. In Proceedings of 8th European Workshop on Natural Language Generation, pages 92–100, Toulouse, France, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>E Shriberg</author>
<author>A Stolcke</author>
<author>D Hillard</author>
<author>M Ostendorf</author>
<author>M Harper</author>
</authors>
<title>Enriching speech recognition with automatic detection of sentence boundaries and disfluencies.</title>
<date>2006</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing,</journal>
<volume>14</volume>
<issue>5</issue>
<contexts>
<context position="2207" citStr="Liu et al., 2006" startWordPosition="317" endWordPosition="320">on the generation of meeting abstracts that aims at overcoming the outlined shortcomings. So far, we have concentrated on indicative summaries that allow the reader to quickly assess whether the underlying meeting is relevant for her current information need. 2 Related Work Extractive summarization of documents has been studied extensively over the last decades (s. Mani and Maybury (1999) for an overview), but faces additional challenges when applied to natural language dialogs. Unlike carefully authored articles, spontaneous utterances are often ungrammatical and contain speech disfluencies (Liu et al., 2006). Moreover, free discussions are naturally less well structured, e. g., when speakers switch topics or digress. For an automated system, additional difficulties arise from the limitations of current ASR systems, introducing recognition errors into all subsequent processing steps. Zechner (2001) and Murray et al. (2005) show ways to cope with such issues. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instan</context>
</contexts>
<marker>Liu, Shriberg, Stolcke, Hillard, Ostendorf, Harper, 2006</marker>
<rawString>Y. Liu, E. Shriberg, A. Stolcke, D. Hillard, M. Ostendorf, and M. Harper. 2006. Enriching speech recognition with automatic detection of sentence boundaries and disfluencies. IEEE Transactions on Audio, Speech and Language Processing, 14(5):1526–1540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Mark T Maybury</author>
<author>editors</author>
</authors>
<title>Advances in automatic text summarization.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<marker>Mani, Maybury, editors, 1999</marker>
<rawString>Inderjeet Mani and Mark T. Maybury, editors. 1999. Advances in automatic text summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Masolo</author>
<author>S Borgo</author>
<author>A Gangemi</author>
<author>N Guarino</author>
<author>A Oltramari</author>
</authors>
<date>2003</date>
<booktitle>Wonderweb deliverable D18 ontology library (final),</booktitle>
<contexts>
<context position="4673" citStr="Masolo et al., 2003" startWordPosition="706" endWordPosition="710">hese annotation layers. In section 4 we show which layers are already used by our summarizer, see figure 5 for an example from the current system. However, all of these annotations are potentially useful, very rich resources for further extensions of our system. 3.1 Propositional Content Additionally, we have annotated a small subset of the Ami corpus with categories from a domain ontology to represent the propositional content of speaker utterances. The AmiMATTER ontology that we created for this purpose models the remote control design scenario in a formal ontology based on Dolce-Lite-Plus (Masolo et al., 2003). Embedded in a comprehensive theory of representing situations and descriptions, it provides a taxonomy of relevant terms, ordered by an IS-A relation that expresses subsumption, or specialization. For instance, it contains information such as (remote control ISA technical device) which expresses that the category remote control is a sub-category of the category technical device. Hence, a reasoner can infer that all remote controls (which technically would be considered instances of the category remote control) are technical devices. The AmiMATTER ontology covers over 20 different subdomains,</context>
</contexts>
<marker>Masolo, Borgo, Gangemi, Guarino, Oltramari, 2003</marker>
<rawString>C. Masolo, S. Borgo, A. Gangemi, N. Guarino, and A. Oltramari. 2003. Wonderweb deliverable D18 ontology library (final), December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I McCowan</author>
<author>J Carletta</author>
<author>W Kraaij</author>
<author>S Ashby</author>
<author>S Bourban</author>
<author>M Flynn</author>
<author>M Guillemot</author>
<author>T Hain</author>
<author>J Kadlec</author>
<author>V Karaiskos</author>
<author>M Kronenthal</author>
<author>G Lathoud</author>
<author>M Lincoln</author>
<author>A Lisowska</author>
<author>W Post</author>
<author>D Reidsma</author>
<author>P Wellner</author>
</authors>
<title>The Ami meeting corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the Measuring Behavior 2005 symposium on Annotating and Measuring Meeting Behavior,</booktitle>
<location>Wageningen, NL,</location>
<contexts>
<context position="3183" citStr="McCowan et al., 2005" startWordPosition="468" endWordPosition="471">. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instance, Alexandersson (2003) generates summaries of machine– translated phone conversations. However, we are not aware of any prior work attempting to generate full abstracts of multi-party interaction. 3 Annotated AMI Meetings In the Ami project&apos;, circa 100 hours of meetings have been recorded, annotated and stored in a freely available multimodal corpus (McCowan et al., 2005). The meetings are semi-staged, in the sense that they are based on the predefined scenario of a virtual company in which a project team works on the task of designing a new innovative remote control. The roles of the four project team members are played by 1http://www.amiproject.org 151 subjects which act as a project manager, a user interface designer, a production designer, and a marketing expert. However, the discussions of the meeting participants are free and not prescripted. Meetings typically last about 30-40 minutes. In addition to multiple video and audio streams, a number of annotat</context>
</contexts>
<marker>McCowan, Carletta, Kraaij, Ashby, Bourban, Flynn, Guillemot, Hain, Kadlec, Karaiskos, Kronenthal, Lathoud, Lincoln, Lisowska, Post, Reidsma, Wellner, 2005</marker>
<rawString>I. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lathoud, M. Lincoln, A. Lisowska, W. Post, D. Reidsma, and P. Wellner. 2005. The Ami meeting corpus. In Proceedings of the Measuring Behavior 2005 symposium on Annotating and Measuring Meeting Behavior, Wageningen, NL, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Murray</author>
<author>S Renals</author>
<author>J Carletta</author>
</authors>
<title>Extractive summarization of meeting recordings.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology,</booktitle>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="2527" citStr="Murray et al. (2005)" startWordPosition="364" endWordPosition="367">been studied extensively over the last decades (s. Mani and Maybury (1999) for an overview), but faces additional challenges when applied to natural language dialogs. Unlike carefully authored articles, spontaneous utterances are often ungrammatical and contain speech disfluencies (Liu et al., 2006). Moreover, free discussions are naturally less well structured, e. g., when speakers switch topics or digress. For an automated system, additional difficulties arise from the limitations of current ASR systems, introducing recognition errors into all subsequent processing steps. Zechner (2001) and Murray et al. (2005) show ways to cope with such issues. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instance, Alexandersson (2003) generates summaries of machine– translated phone conversations. However, we are not aware of any prior work attempting to generate full abstracts of multi-party interaction. 3 Annotated AMI Meetings In the Ami project&apos;, circa 100 hours of meetings have been recorded, annotated and stored in a f</context>
</contexts>
<marker>Murray, Renals, Carletta, 2005</marker>
<rawString>G. Murray, S. Renals, and J. Carletta. 2005. Extractive summarization of meeting recordings. In Proceedings of the 9th European Conference on Speech Communication and Technology, Lisbon, Portugal, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG Research Group</author>
</authors>
<title>A lexicalized tree adjoining grammar for english.</title>
<date>2001</date>
<tech>Technical Report IRCS-01-03,</tech>
<institution>IRCS, University of Pennsylvania.</institution>
<contexts>
<context position="9699" citStr="Group, 2001" startWordPosition="1499" endWordPosition="1500">ls, one of which is an iteration over all topics. Here, the “with”-condition is matched against the knowledge base that was generated before. PREPLAN successively finds matching planoperators until all goals and subgoals are resolved. The outcome of this process is an XMLencoded description of instructions in a logical form which is passed to the surface realizer, NIPsGEN (Engel, 2006), a template-based generator. NIPsGEN converts the semantic input into typed feature structures which are then transformed into a natural language utterance. A derivation tree for the XTAG-grammar (XTAG Research Group, 2001) is created using transformation rules which are applied to the input structure (see figure 4 for a sample rule). The actual syntax tree is constructed using the derivation tree. The generation of the correct morphological inflections is achieved by percolating the morphological features through the XTAG tree and looking up the correct inflections for all lexical leaves in the XTAG lexicon for English. Traversing the lexical leaves from left to right produces the natural language ut153 $VP=VP(o:Introduction(has-topic:$T, has-agent:$A), not(lex:)) -&gt; $VP(lex:introduce, sub:NP(o:$A), obj:NP(o:$T</context>
</contexts>
<marker>Group, 2001</marker>
<rawString>XTAG Research Group. 2001. A lexicalized tree adjoining grammar for english. Technical Report IRCS-01-03, IRCS, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Zechner</author>
</authors>
<title>Automatic Summarization of Spoken Dialogues in Unrestricted Domains.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="2502" citStr="Zechner (2001)" startWordPosition="361" endWordPosition="362">n of documents has been studied extensively over the last decades (s. Mani and Maybury (1999) for an overview), but faces additional challenges when applied to natural language dialogs. Unlike carefully authored articles, spontaneous utterances are often ungrammatical and contain speech disfluencies (Liu et al., 2006). Moreover, free discussions are naturally less well structured, e. g., when speakers switch topics or digress. For an automated system, additional difficulties arise from the limitations of current ASR systems, introducing recognition errors into all subsequent processing steps. Zechner (2001) and Murray et al. (2005) show ways to cope with such issues. Generative approaches, on the other hand, are based on an internal representation of summary contents verbalized through NLG techniques (e.g. Kan et al. (2001)). Such approaches have been applied to natural discourse domains before, for instance, Alexandersson (2003) generates summaries of machine– translated phone conversations. However, we are not aware of any prior work attempting to generate full abstracts of multi-party interaction. 3 Annotated AMI Meetings In the Ami project&apos;, circa 100 hours of meetings have been recorded, an</context>
</contexts>
<marker>Zechner, 2001</marker>
<rawString>Klaus Zechner. 2001. Automatic Summarization of Spoken Dialogues in Unrestricted Domains. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>