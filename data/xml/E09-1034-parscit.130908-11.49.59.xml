<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.983868">
Parsing Mildly Non-projective Dependency Structures∗
</title>
<author confidence="0.981586">
Carlos G´omez-Rodriguez David Weir and John Carroll
</author>
<affiliation confidence="0.868451">
Departamento de Computaci´on Department of Informatics
Universidade da Coru˜na, Spain University of Sussex, United Kingdom
</affiliation>
<email confidence="0.988854">
cgomezr@udc.es {davidw,johnca}@sussex.ac.uk
</email>
<sectionHeader confidence="0.993603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999830785714286">
We present parsing algorithms for vari-
ous mildly non-projective dependency for-
malisms. In particular, algorithms are pre-
sented for: all well-nested structures of
gap degree at most 1, with the same com-
plexity as the best existing parsers for con-
stituency formalisms of equivalent genera-
tive power; all well-nested structures with
gap degree bounded by any constant k;
and a new class of structures with gap de-
gree up to k that includes some ill-nested
structures. The third case includes all the
gap degree k structures in a number of de-
pendency treebanks.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999873736842105">
Dependency parsers analyse a sentence in terms
of a set of directed links (dependencies) express-
ing the head-modifier and head-complement rela-
tionships which form the basis of predicate argu-
ment structure. We take dependency structures to
be directed trees, where each node corresponds to
a word and the root of the tree marks the syn-
tactic head of the sentence. For reasons of effi-
ciency, many practical implementations of depen-
dency parsing are restricted to projective struc-
tures, in which the subtree rooted at each word
covers a contiguous substring of the sentence.
However, while free word order languages such
as Czech do not satisfy this constraint, parsing
without the projectivity constraint is computation-
ally complex. Although it is possible to parse
non-projective structures in quadratic time under a
model in which each dependency decision is inde-
pendent of all the others (McDonald et al., 2005),
</bodyText>
<footnote confidence="0.9792414">
∗Partially supported by MEC and FEDER (HUM2007-
66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR,
INCITE08E1R104022ES, INCITE08ENA305025ES, IN-
CITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe
e RI, Bolsas para Estadias INCITE – FSE cofinanced).
</footnote>
<bodyText confidence="0.999649238095238">
the problem is intractable in the absence of this as-
sumption (McDonald and Satta, 2007).
Nivre and Nilsson (2005) observe that most
non-projective dependency structures appearing
in practice are “close” to being projective, since
they contain only a small proportion of non-
projective arcs. This has led to the study of
classes of dependency structures that lie be-
tween projective and unrestricted non-projective
structures (Kuhlmann and Nivre, 2006; Havelka,
2007). Kuhlmann (2007) investigates several such
classes, based on well-nestedness and gap degree
constraints (Bodirsky et al., 2005), relating them
to lexicalised constituency grammar formalisms.
Specifically, he shows that: linear context-free
rewriting systems (LCFRS) with fan-out k (Vijay-
Shanker et al., 1987; Satta, 1992) induce the set
of dependency structures with gap degree at most
k − 1; coupled context-free grammars in which
the maximal rank of a nonterminal is k (Hotz and
Pitsch, 1996) induce the set of well-nested depen-
dency structures with gap degree at most k − 1;
and LTAGs (Joshi and Schabes, 1997) induce the
set of well-nested dependency structures with gap
degree at most 1.
These results establish that there must be
polynomial-time dependency parsing algorithms
for well-nested structures with bounded gap de-
gree, since such parsers exist for their correspond-
ing lexicalised constituency-based formalisms.
However, since most of the non-projective struc-
tures in treebanks are well-nested and have a small
gap degree (Kuhlmann and Nivre, 2006), devel-
oping efficient dependency parsing strategies for
these sets of structures has considerable practical
interest, since we would be able to parse directly
with dependencies in a data-driven manner, rather
than indirectly by constructing intermediate con-
stituency grammars and extracting dependencies
from constituency parses.
We address this problem with the following
contributions: (1) we define a parsing algorithm
</bodyText>
<note confidence="0.922965">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 291–299,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.996912">
291
</page>
<bodyText confidence="0.9999891875">
for well-nested dependency structures of gap de-
gree 1, and prove its correctness. The parser runs
in time O(n7), the same complexity as the best
existing algorithms for LTAG (Eisner and Satta,
2000), and can be optimised to O(n6) in the non-
lexicalised case; (2) we generalise the previous al-
gorithm to any well-nested dependency structure
with gap degree at most k in time O(n5+2k); (3)
we generalise the previous parsers to be able to
analyse not only well-nested structures, but also
ill-nested structures with gap degree at most k sat-
isfying certain constraints1, in time O(n4+3k); and
(4) we characterise the set of structures covered by
this parser, which we call mildly ill-nested struc-
tures, and show that it includes all the trees present
in a number of dependency treebanks.
</bodyText>
<sectionHeader confidence="0.992551" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999761384615384">
A dependency graph for a string w1 ... wn is a
graph G = (V, E), where V = {w1, ... , wn}
and E ⊆ V × V . We write the edge (wi, wj)
as wi → wj, meaning that the word wi is a syn-
tactic dependent (or a child) of wj or, conversely,
that wj is the governor (parent) of wi. We write
wi →* wj to denote that there exists a (possi-
bly empty) path from wi to wj. The projection
of a node wi, denoted bwic, is the set of reflexive-
transitive dependents of wi, that is: bwic = {wj ∈
V  |wj →* wi}. An interval (with endpoints i and
j) is a set of the form [i, j] = {wk  |i ≤ k ≤ j}.
A dependency graph is said to be a tree if it is:
</bodyText>
<listItem confidence="0.987535444444445">
(1) acyclic: wj ∈ bwic implies wi → wj ∈6 E; and
(2) each node has exactly one parent, except for
one node which we call the root or head. A graph
verifying these conditions and having a vertex set
V ⊆ {w1, ... , wn} is a partial dependency tree.
Given a dependency tree T = (V, E) and a node
u ∈ V , the subtree induced by the node u is the
graph Tu = (buc, Eu) where Eu = {wi → wj ∈
E  |wj ∈ buc}.
</listItem>
<subsectionHeader confidence="0.995541">
2.1 Properties of dependency trees
</subsectionHeader>
<bodyText confidence="0.996611428571429">
We now define the concepts of gap degree and
well-nestedness (Kuhlmann and Nivre, 2006). Let
T be a (possibly partial) dependency tree for
w1 ... wn: We say that T is projective if
an interval for every word wi. Thus every node
in the dependency structure must dominate a con-
tiguous substring in the sentence. The gap degree
</bodyText>
<footnote confidence="0.99625175">
1Parsing unrestricted ill-nested structures, even when the
gap degree is bounded, is NP-complete: these structures are
equivalent to LCFRS for which the recognition problem is
NP-complete (Satta, 1992).
</footnote>
<bodyText confidence="0.828019733333333">
of a particular node wk in T is the minimum g ∈ IlV
such that bwkc can be written as the union of g +1
intervals; that is, the number of discontinuities in
bwkc. The gap degree of the dependency tree T is
the maximum among the gap degrees of its nodes.
Note that T has gap degree 0 if and only if T is
projective. The subtrees induced by nodes wp and
wQ are interleaved if bwpc ∩ bwQc = ∅ and there
are nodes wi, wj ∈ bwpc and wk, wl ∈ bwQc such
that i &lt; k &lt; j &lt; l. A dependency tree T is
well-nested if it does not contain two interleaved
subtrees. A tree that is not well-nested is said to
be ill-nested. Note that projective trees are always
well-nested, but well-nested trees are not always
projective.
</bodyText>
<subsectionHeader confidence="0.999025">
2.2 Dependency parsing schemata
</subsectionHeader>
<bodyText confidence="0.9999721875">
The framework of parsing schemata (Sikkel,
1997) provides a uniform way to describe, anal-
yse and compare parsing algorithms. Parsing
schemata were initially defined for constituency-
based grammatical formalisms, but G´omez-
Rodriguez et al. (2008a) define a variant of the
framework for dependency-based parsers. We
use these dependency parsing schemata to de-
fine parsers and prove their correctness. Due to
space constraints, we only provide brief outlines
of the main concepts behind dependency parsing
schemata.
The parsing schema approach considers pars-
ing as deduction, generating intermediate results
called items. An initial set of items is obtained
from the input sentence, and the parsing process
involves deduction steps which produce new items
from existing ones. Each item contains informa-
tion about the sentence’s structure, and a success-
ful parsing process produces at least one final item
providing a full dependency analysis for the sen-
tence or guaranteeing its existence. In a depen-
dency parsing schema, items are defined as sets of
partial dependency trees2. To define a parser by
means of a schema, we must define an item set
and provide a set of deduction steps that operate
on it. Given an item set I, the set of final items
for strings of length n is the set of items in I that
contain a full dependency tree for some arbitrary
string of length n. A final item containing a de-
pendency tree for a particular string w1 ... wn is
said to be a correctfinal item for that string. These
</bodyText>
<footnote confidence="0.969697">
2The formalism allows items to contain forests, and the
dependency structures inside items are defined in a notation
with terminal and preterminal nodes, but these are not needed
here.
bwic is
</footnote>
<page confidence="0.986965">
292
</page>
<bodyText confidence="0.998872129032258">
concepts can be used to prove the correctness of
a parser: for each input string, a parsing schema’s
deduction steps allow us to infer a set of items,
called valid items for that string. A schema is said
to be sound if all valid final items it produces for
any arbitrary string are correct for that string. A
schema is said to be complete if all correct final
items are valid. A correct parsing schema is one
which is both sound and complete.
In constituency-based parsing schemata, deduc-
tion steps usually have grammar rules as side con-
ditions. In the case of dependency parsers it is
also possible to use grammars (Eisner and Satta,
1999), but many algorithms use a data-driven ap-
proach instead, making individual decisions about
which dependencies to create by using probabilis-
tic models (Eisner, 1996) or classifiers (Yamada
and Matsumoto, 2003). To represent these algo-
rithms as deduction systems, we use the notion
of D-rules (Covington, 1990). D-rules take the
form a → b, which says that word b can have a
as a dependent. Deduction steps in non-grammar-
based parsers can be tied to the D-rules associated
with the links they create. In this way, we ob-
tain a representation of the underlying logic of the
parser while abstracting away from control struc-
tures (the particular model used to create the de-
cisions associated with D-rules). Furthermore, the
choice points in the parsing process and the infor-
mation we can use to make decisions are made ex-
plicit in the steps linked to D-rules.
</bodyText>
<sectionHeader confidence="0.980544" genericHeader="method">
3 The WG1 parser
</sectionHeader>
<subsectionHeader confidence="0.999944">
3.1 Parsing schema for WG1
</subsectionHeader>
<bodyText confidence="0.999761">
We define WG1, a parser for well-nested depen-
dency structures of gap degree ≤ 1, as follows:
The item set is IWG1 = I1 ∪ I2, with
</bodyText>
<equation confidence="0.9975725">
I1 = {[i, j, h, o, o]  |i, j, h ∈ W,1 ≤ h ≤ n,
1 ≤ i ≤ j ≤ n,h =6j,h =6i − 1},
</equation>
<bodyText confidence="0.9999495">
where each item of the form [i, j, h, o, o] repre-
sents the set of all well-nested partial dependency
trees3 with gap degree at most 1, rooted at wh, and
such that bwhc = {wh} ∪ [i, j], and
</bodyText>
<equation confidence="0.980363666666667">
I2 = {[i, j, h,l, r]  |i, j, h,l, r ∈ W,1 ≤ h ≤ n,
1 ≤ i &lt; l ≤ r &lt; j ≤ n,h =6 j,h =6i − 1,
h =6l − 1,h =6r}
</equation>
<bodyText confidence="0.95890080952381">
3In this and subsequent schemata, we use D-rules to ex-
press parsing decisions, so partial dependency trees are as-
sumed to be taken from the set of trees licensed by a set of
D-rules.
where each item of the form [i, j, h,l, r] represents
the set of all well-nested partial dependency trees
rooted at wh such that bwhc = {wh} ∪ ([i, j] \
[l, r]), and all the nodes (except possibly h) have
gap degree at most 1. We call items of this form
gapped items, and the interval [l, r] the gap of
the item. Note that the constraints h =6 j, h =6
i + 1, h =6 l − 1, h =6 r are added to items to
avoid redundancy in the item set. Since the result
of the expression {wh} ∪ ([i, j] \ [l, r]) for a given
head can be the same for different sets of values of
i, j,l, r, we restrict these values so that we cannot
get two different items representing the same de-
pendency structures. Items t violating these con-
straints always have an alternative representation
that does not violate them, that we can express
with a normalising function nm(t) as follows:
</bodyText>
<equation confidence="0.857361">
nm([i, j, j, l, r]) = [i, j − 1, j, l, r] (if r &lt; j − 1 or r = o),
or [i, l − 1, j, o, o] (if r = j − 1).
nm([i, j, l − 1, l, r]) = [i, j, l − 1, l − 1, r](if l &gt; i + 1),
or [r + 1, j, l − 1, o, o] (if l = i + 1).
</equation>
<construct confidence="0.689403">
nm([i, j, i − 1, l, r]) = [i − 1, j, i − 1, l, r].
nm([i, j, r, l, r]) = [i, j, r, l, r − 1] (if l &lt; r),
or [i, j, r, o, o] (if l = r).
nm([i, j, h, l, r]) = [i, j, h, l, r] for all other items.
</construct>
<bodyText confidence="0.970142764705883">
When defining the deduction steps for this and
other parsers, we assume that they always produce
normalised items. For clarity, we do not explicitly
write this in the deduction steps, writing t instead
of nm(t) as antecedents and consequents of steps.
The set of initial items is defined as the set
H = {[h, h, h, o, o]  |h ∈ W,1 ≤ h ≤ n},
where each item [h, h, h, o, o] represents the set
containing the trivial partial dependency tree con-
sisting of a single node wh and no links. This
same set of hypotheses can be used for all the
parsers, so we do not make it explicit for subse-
quent schemata. Note that initial items are sepa-
rate from the item set IWG1 and not subject to its
constraints, so they do not require normalisation.
The set of final items for strings of length n in
WG1 is defined as the set
</bodyText>
<equation confidence="0.532362">
F = {[1, n, h, o, o]  |h ∈ W,1 ≤ h ≤ n},
</equation>
<bodyText confidence="0.998256">
which is the set of items in IWG1 containing de-
pendency trees for the complete input string (from
position 1 to n), with their head at any word wh.
The deduction steps of the parser can be seen in
Figure 1A.
The WG1 parser proceeds bottom-up, by build-
ing dependency subtrees and joining them to form
larger subtrees, until it finds a complete depen-
dency tree for the input sentence. The logic of
</bodyText>
<page confidence="0.950908">
293
</page>
<equation confidence="0.859464710144928">
A. WG1 parser:
[h1, h1, h1, o, o]
[i2, j2, h2, o, o]
[i2, j2, h1, o, o] wh2 → wh1
such that wh2 ∈ [i2, j2] ∧ wh1 ∈/ [i2, j2],
[h1, h1, h1, o, o]
[i2, j2, h2, l2, r2]
[i2, j2, h1, l2, r2] wh2 → wh1
such that wh2 ∈ [i2, j2] \ [l2, r2] ∧ wh1 ∈/ [i2, j2] \ [l2, r2],
Link Ungapped:
Link Gapped:
[i, j, h, �, �] [k, l, h, �, �]
[i, j, h, �, �] [j + 1, k, h, �, �] Combine Opening Gap:
Combine Ungapped: [i, l, h, j + 1, k − 1]
[i, k, h, �, �] such that j &lt; k − 1,
Combine Keeping Gap Left:
[i, j, h, l, r] [j + 1, k, h, o, o]
[i, k, h, l, r]
Combine Shrinking Gap Left:
[i, j, h, l, r] [l, k, h, o, o]
[i, j, h, k + 1, r]
B. WGK parser:
Combine Keeping Gap Right:
[i, j, h, o, o] [j + 1, k, h, l, r]
[i, k, h, l, r]
Combine Shrinking Gap Right:
[i, j, h, l, r] [k, r, h, o, o]
[i, j, h, l, k − 1]
Combine Closing Gap:
[i, j, h, l, r] [l, r, h, o, o]
[i, j, h, o, o]
Combine Shrinking Gap Centre:
[i, j, h, l, r] [l, r, h, l2, r2]
[i, j, h, l2, r2]
[h1, h1, h1, []]
[i2, j2, h2, [(l1, r1), ... , (lg, rg)]]
[i2, j2, h1, [(l1, r1), ... , (lg, rg)]] wh2 → wh1
such that wh2 ∈ [i2, j2] \ Ugp=1[lp, rp]
∧wh1 ∈/ [i2, j2] \ Ugp=1[lp, rp].
Combine Opening Gap:
[i, lq − 1, h, [(l1, r1), ... , (lq−1, rq−1)]]
[rq + 1, m, h, [(lq+1, rq+1), ... , (lg, rg)]]
Combine Shrinking Gap Right:
[i, j, h, [(l1, r1), ... , (lq−1, rq−1), (lq, r0), (ls, rs), ... , (lg, rg)]]
[rq + 1, r0, h, [(lq+1, rq+1), ... , (ls−1, rs−1)]]
[i, j, h, [(l1, r1), ... , (lg, rg)]]
such that g ≤ k
Combine Shrinking Gap Left:
[i, j, h, [(l1, r1), ... , (lq, rq), (l0, rs), (ls+1, rs+1), ... , (lg, rg)]]
[l0, ls − 1, h, [(lq+1, rq+1), ... ,(ls−1, rs−1)]]
Link:
[i, m, h, [(l1, r1), ... , (lg, rg)]] [i, j, h, [(l1, r1), ... , (lg, rg)]]
such that g ≤ k and lq ≤ rq, such that g ≤ k
Combine Keeping Gaps:
[i, j, h, [(l1, r1), ... , (lq, rq)]]
[j + 1, m, h, [(lq+1, rq+1), ... , (lg, rg)]]
[i, m, h, [(l1, r1), ... , (lg, rg)]]
such that g ≤ k,
Combine Shrinking Gap Centre:
[i, j, h, [(l1, r1), ... , (lq, rq), (l0, r0), (ls, rs), ... , (lg, rg)]]
[l0, r0, h, [(lq+1, rq+1), ... , (ls−1, rs−1)]]
[i, j, h, [(l1, r1), ... , (lg, rg)]]
such that g ≤ k
C. Additional steps to turn WG1 into MG1:
[i, j, h, l, r] [l, k, h, m, j]
[i, j, h, l, r] [l, k, h, r + 1, j] Combine Interleaving Gap C:
Combine Interleaving: [i, k, h, m, r]
[i, k, h, �, �]
such that m &lt; r + 1,
</equation>
<bodyText confidence="0.4009636">
Combine Interleaving Gap L: [i, j, h, l, r] Combine Interleaving Gap R: [i, j, h, l, r]
[l, k, h, r + 1, u] [k, m, h, r + 1, j]
[i, k, h, j + 1, u] [i, m, h, l, k − 1]
such that u &gt; j, such that k &gt; l.
D. General form of the MGk Combine step:
</bodyText>
<equation confidence="0.965065">
[ia1, iap+1 − 1, h, [(ia1+1, ia2 − 1),.. . , (iap_1+1, iap − 1)]]
[ib1, ibq+1 − 1, h, [(ib1+1, ib2 − 1), ... , (ibq_1+1, ibq − 1)]]
[imin(a1,b1), imax(ap+1,bq+1) − 1, h, [(ig1, ig1+1 − 1), ... , (igr, igr+1 − 1)]]
for each string of length n with a’s located at positions a1 ... ap(1 ≤ a1 &lt; ... &lt; ap ≤ n), b’s at positions b1 ... bq(1 ≤ b1 &lt;
... &lt; bq ≤ n), and g’s at positions g1 ... gr(2 ≤ g1 &lt; ... &lt; gr ≤ n − 1), such that 1 ≤ p ≤ k, 1 ≤ q ≤ k, 0 ≤ r ≤ k − 1,
p + q + r = n, and the string does not contain more than one consecutive appearance of the same symbol.
</equation>
<figureCaption confidence="0.998893">
Figure 1: Deduction steps for the parsers defined in the paper.
</figureCaption>
<bodyText confidence="0.999951777777778">
the parser can be understood by considering how
it infers the item corresponding to the subtree in-
duced by a particular node, given the items for the
subtrees induced by the direct dependents of that
node. Suppose that, in a complete dependency
analysis for a sentence wi ... wn, the word wh
has wd1 ... wdp as direct dependents (i.e. we have
dependency links wd1 → wh, . . . , wdp → wh).
Then, the item corresponding to the subtree in-
duced by wh is obtained from the ones correspond-
ing to the subtrees induced by wd1 ... wdp by: (1)
applying the Link Ungapped or Link Gapped step
to each of the items corresponding to the subtrees
induced by the direct dependents, and to the hy-
pothesis [h, h, h, o, o]. This allows us to infer p
items representing the result of linking each of the
dependent subtrees to the new head wh; (2) ap-
plying the various Combine steps to join all of the
</bodyText>
<page confidence="0.989566">
294
</page>
<bodyText confidence="0.9999077">
items obtained in the previous step into a single
item. The Combine steps perform a union oper-
ation between subtrees. Therefore, the result is a
dependency tree containing all the dependent sub-
trees, and with all of them linked to h: this is
the subtree induced by wh. This process is ap-
plied repeatedly to build larger subtrees, until, if
the parsing process is successful, a final item is
found containing a dependency tree for the com-
plete sentence.
</bodyText>
<subsectionHeader confidence="0.99974">
3.2 Proving correctness
</subsectionHeader>
<bodyText confidence="0.99996805">
The parsing schemata formalism can be used to
prove the correctness of a parsing schema. To
prove that WG1 is correct, we need to prove
its soundness and completeness.4 Soundness is
proven by checking that valid items always con-
tain well-nested trees. Completeness is proven by
induction, taking initial items as the base case and
showing that an item containing a correct subtree
for a string can always be obtained from items
corresponding to smaller subtrees. In order to
prove this induction step, we use the concept of
order annotations (Kuhlmann, 2007; Kuhlmann
and M¨ohl, 2007), which are strings that lexicalise
the precedence relation between the nodes of a de-
pendency tree. Given a correct subtree, we divide
the proof into cases according to the order annota-
tion of its head and we find that, for every possible
form of this order annotation, we can find a se-
quence of Combine steps to infer the relevant item
from smaller correct items.
</bodyText>
<subsectionHeader confidence="0.998201">
3.3 Computational complexity
</subsectionHeader>
<bodyText confidence="0.997773266666667">
The time complexity of WG1 is O(n7), as the
step Combine Shrinking Gap Centre works with 7
free string positions. This complexity with respect
to the length of the input is as expected for this
set of structures, since Kuhlmann (2007) shows
that they are equivalent to LTAG, and the best ex-
isting parsers for this formalism also perform in
O(n7) (Eisner and Satta, 2000). Note that the
Combine step which is the bottleneck only uses the
7 indexes, and not any other entities like D-rules,
so its O(n7) complexity does not have any addi-
tional factors due to grammar size or other vari-
ables. The space complexity of WG1 is O(n5)
for recognition, due to the 5 indexes in items, and
O(n7) for full parsing.
</bodyText>
<footnote confidence="0.96686175">
4Due to space constraints, correctness proofs for the
parsers are not given here. Full proofs are provided in the
extended version of this paper, see (G´omez-Rodriguez et al.,
2008b).
</footnote>
<bodyText confidence="0.999910428571429">
It is possible to build a variant of this parser
with time complexity O(n6), as with parsers for
unlexicalised TAG, if we work with unlexicalised
D-rules specifying the possibility of dependencies
between pairs of categories instead of pairs of
words. In order to do this, we expand the item set
with unlexicalised items of the form [i, j, C,l, r],
where C is a category, apart from the existing
items [i, j, h,l, r]. Steps in the parser are dupli-
cated, to work both with lexicalised and unlex-
icalised items, except for the Link steps, which
always work with a lexicalised item and an un-
lexicalised hypothesis to produce an unlexicalised
item, and the Combine Shrinking Gap steps, which
can work only with unlexicalised items. Steps are
added to obtain lexicalised items from their unlex-
icalised equivalents by binding the head to partic-
ular string positions. Finally, we need certain vari-
ants of the Combine Shrinking Gap steps that take
2 unlexicalised antecedents and produce a lexi-
calised consequent; an example is the following:
</bodyText>
<subsectionHeader confidence="0.472777">
Combine Shrinking Gap Centre L:
</subsectionHeader>
<bodyText confidence="0.9555279">
such that cat(wl)=C
Although this version of the algorithm reduces
time complexity with respect to the length of the
input to O(n6), it also adds a factor related to the
number of categories, as well as constant factors
due to using more kinds of items and steps than
the original WG1 algorithm. This, together with
the advantages of lexicalised dependency parsing,
may mean that the original WG1 algorithm is more
practical than this version.
</bodyText>
<sectionHeader confidence="0.922679" genericHeader="method">
4 The WGk parser
</sectionHeader>
<bodyText confidence="0.999936857142857">
The WG1 parsing schema can be generalised to
obtain a parser for all well-nested dependency
structures with gap degree bounded by a constant
k(k &gt; 1), which we call WGk parser. In order to
do this, we extend the item set so that it can contain
items with up to k gaps, and modify the deduction
steps to work with these multi-gapped items.
</bodyText>
<subsectionHeader confidence="0.99624">
4.1 Parsing schema for WGk
</subsectionHeader>
<bodyText confidence="0.55288225">
The item set ZWGk is the set of all
[i, j, h, [(l1, r1), ... , (lg, rg)]] where i, j, h, g E IlV
, 0 &lt; g &lt; k, 1 &lt; h &lt; n, 1 &lt; i &lt; j &lt; n , h =� j,
h =� i − 1; and for each p E 11,2,... , g}:
lp, rp E W, i &lt; lp &lt; rp &lt; j, rp &lt; lp+1 − 1,
h =�lp − 1, h =�rp.
An item [i, j, h, [(l1, r1), ... , (lg, rg)]] repre-
sents the set of all well-nested partial dependency
</bodyText>
<equation confidence="0.969582333333333">
[i, j, C, l, r]
[l + 1, r, C, l2, r2]
[i, j, l, l2, r2]
</equation>
<page confidence="0.994371">
295
</page>
<bodyText confidence="0.991450444444445">
trees rooted at wh such that Lwh] = {wh}U([i, j]�
Ugp=1[lp, rp]), where each interval [lp, rp] is called
a gap. The constraints h =� j, h =� i + 1, h =�
lp − 1, h =� rp are added to avoid redundancy, and
normalisation is defined as in WG1. The set of fi-
nal items is defined as the set F = {[1, n, h, []] |
h E W,1 &lt; h &lt; n}. Note that this set is the same
as in WG1, as these are the items that we denoted
[1, n, h, o, o] in the previous parser.
The deduction steps can be seen in Figure 1B.
As expected, the WG1 parser corresponds to WGk
when we make k = 1. WGk works in the same
way as WG1, except for the fact that Combine
steps can create items with more than one gap5.
The correctness proof is also analogous to that of
WG1, but we must take into account that the set of
possible order annotations is larger when k &gt; 1,
so more cases arise in the completeness proof.
</bodyText>
<subsectionHeader confidence="0.989205">
4.2 Computational complexity
</subsectionHeader>
<bodyText confidence="0.999993565217391">
The WGk parser runs in time O(n5+2k): as in
the case of WG1, the deduction step with most
free variables is Combine Shrinking Gap Cen-
tre, and in this case it has 5 + 2k free indexes.
Again, this complexity result is in line with what
could be expected from previous research in con-
stituency parsing: Kuhlmann (2007) shows that
the set of well-nested dependency structures with
gap degree at most k is closely related to cou-
pled context-free grammars in which the maxi-
mal rank of a nonterminal is k + 1; and the con-
stituency parser defined by Hotz and Pitsch (1996)
for these grammars also adds an n2 factor for each
unit increment of k. Note that a small value of
k should be enough to cover the vast majority of
the non-projective sentences found in natural lan-
guage treebanks. For example, the Prague Depen-
dency Treebank contains no structures with gap
degree greater than 4. Therefore, a WG4 parser
would be able to analyse all the well-nested struc-
tures in this treebank, which represent 99.89% of
the total. Increasing k beyond 4 would not pro-
duce further improvements in coverage.
</bodyText>
<sectionHeader confidence="0.937026" genericHeader="method">
5 Parsing ill-nested structures
</sectionHeader>
<bodyText confidence="0.994205">
The WGk parser analyses dependency structures
with bounded gap degree as long as they are
well-nested. This covers the vast majority of
5In all the parsers in this paper, Combine steps may be
applied in different orders to produce the same result, causing
spurious ambiguity. In WG1 and WGk, this can be avoided
when implementing the schemata, by adding flags to items
so as to impose a particular order.
the structures that occur in natural-language tree-
banks (Kuhlmann and Nivre, 2006), but there is
still a significant minority of sentences that con-
tain ill-nested structures. Unfortunately, the gen-
eral problem of parsing ill-nested structures is NP-
complete, even when the gap degree is bounded:
this set of structures is closely related to LCFRS
with bounded fan-out and unbounded production
length, and parsing in this formalism has been
proven to be NP-complete (Satta, 1992). The
reason for this high complexity is the problem
of unrestricted crossing configurations, appearing
when dependency subtrees are allowed to inter-
leave in every possible way. However, just as
it has been noted that most non-projective struc-
tures appearing in practice are only “slightly” non-
projective (Nivre and Nilsson, 2005), we charac-
terise a sense in which the structures appearing in
treebanks can be viewed as being only “slightly”
ill-nested. In this section, we generalise the algo-
rithms WG1 and WGk to parse a proper superset
of the set of well-nested structures in polynomial
time; and give a characterisation of this new set
of structures, which includes all the structures in
several dependency treebanks.
</bodyText>
<subsectionHeader confidence="0.998326">
5.1 The MG1 and MGk parsers
</subsectionHeader>
<bodyText confidence="0.999918269230769">
The WGk parser presented previously is based on
a bottom-up process, where Link steps are used to
link completed subtrees to a head, and Combine
steps are used to join subtrees governed by a com-
mon head to obtain a larger structure. As WGk is a
parser for well-nested structures of gap degree up
to k, its Combine steps correspond to all the ways
in which we can join two sets of sibling subtrees
meeting these constraints, and having a common
head, into another. Thus, this parser does not use
Combine steps that produce interleaved subtrees,
since these would generate items corresponding to
ill-nested structures.
We obtain a polynomial parser for a wider set of
structures of gap degree at most k, including some
ill-nested ones, by having Combine steps repre-
senting every way in which two sets of sibling sub-
trees of gap degree at most k with a common head
can be joined into another, including those produc-
ing interleaved subtrees, like the steps for gap de-
gree 1 shown in Figure 1C. Note that this does not
mean that we can build every possible ill-nested
structure: some structures with complex crossed
configurations have gap degree k, but cannot be
built by combining two structures of that gap de-
gree. More specifically, our algorithm will be able
</bodyText>
<page confidence="0.995261">
296
</page>
<bodyText confidence="0.999975885057471">
to parse a dependency structure (well-nested or
not) if there exists a binarisation of that structure
that has gap degree at most k. The parser im-
plicitly works by finding such a binarisation, since
Combine steps are always applied to two items and
no intermediate item generated by them can ex-
ceed gap degree k (not counting the position of
the head in the projection).
More formally, let T be a dependency structure
for the string w1 ... wn. A binarisation of T is
a dependency tree T0 over a set of nodes, each of
which may be unlabelled or labelled with a word
in {w1 ... wn}, such that the following conditions
hold: (1) each node has at most two children, and
(2) wz —* wj in T if and only if wz —** wj in
T�. A dependency structure is mildly ill-nested
for gap degree k if it has at least one binarisation
of gap degree &lt; k. Otherwise, we say that it is
strongly ill-nested for gap degree k. It is easy
to prove that the set of mildly ill-nested structures
for gap degree k includes all well-nested structures
with gap degree up to k.
We define MG1, a parser for mildly ill-nested
structures for gap degree 1, as follows: (1) the
item set is the same as that of WG1, except that
items can now contain any mildly ill-nested struc-
tures for gap degree 1, instead of being restricted
to well-nested structures; and (2) deduction steps
are the same as in WG1, plus the additional steps
shown in Figure 1C. These extra Combine steps
allow the parser to combine interleaved subtrees
with simple crossing configurations. The MG1
parser still runs in O(n7), as these new steps do
not use more than 7 string positions.
The proof of correctness for this parser is sim-
ilar to that of WG1. Again, we use the concept
of order annotations. The set of mildly ill-nested
structures for gap degree k can be defined as those
that only contain annotations meeting certain con-
straints. The soundness proof involves showing
that Combine steps always generate items contain-
ing trees with such annotations. Completeness is
proven by induction, by showing that if a subtree
is mildly ill-nested for gap degree k, an item for
it can be obtained from items for smaller subtrees
by applying Combine and Link steps. In the cases
where Combine steps have to be applied, the order
in which they may be used to produce a subtree
can be obtained from its head’s order annotation.
To generalise this algorithm to mildly ill-nested
structures for gap degree k, we need to add a Com-
bine step for every possible way of joining two
structures of gap degree at most k into another.
This can be done systematically by considering a
set of strings over an alphabet of three symbols:
a and b to represent intervals of words in the pro-
jection of each of the structures, and g to repre-
sent intervals that are not in the projection of ei-
ther structure, and will correspond to gaps in the
joined structure. The legal combinations of struc-
tures for gap degree k will correspond to strings
where symbols a and b each appear at most k + 1
times, g appears at most k times and is not the first
or last symbol, and there is no more than one con-
secutive appearance of any symbol. Given a string
of this form, the corresponding Combine step is
given by the expression in Figure 1D. As a particu-
lar example, the Combine Interleaving Gap C step
in Figure 1C is obtained from the string abgab.
Thus, we define the parsing schema for MGk, a
parser for mildly ill-nested structures for gap de-
gree k, as the schema where (1) the item set is
like that of WGk, except that items can now con-
tain any mildly ill-nested structures for gap degree
k, instead of being restricted to well-nested struc-
tures; and (2) the set of deduction steps consists of
a Link step as the one in WGk, plus a set of Com-
bine steps obtained as expressed in Figure 1D.
As the string used to generate a Combine step
can have length at most 3k + 2, and the result-
ing step contains an index for each symbol of the
string plus two extra indexes, the MGk parser has
complexity O(n3k+4). Note that the item and de-
duction step sets of an MGk parser are always su-
persets of those of WGk. In particular, the steps
for WGk are those obtained from strings that do
not contain abab or baba as a scattered substring.
</bodyText>
<subsectionHeader confidence="0.998462">
5.2 Mildly ill-nested dependency structures
</subsectionHeader>
<bodyText confidence="0.999875941176471">
The MGk algorithm defined in the previous sec-
tion can parse any mildly ill-nested structure for a
given gap degree k in polynomial time. We have
characterised the set of mildly ill-nested structures
for gap degree k as those having a binarisation of
gap degree &lt; k. Since a binarisation of a depen-
dency structure cannot have lower gap degree than
the original structure, this set only contains struc-
tures with gap degree at most k. Furthermore, by
the relation between MGk and WGk, we know that
it contains all the well-nested structures with gap
degree up to k.
Figure 2 shows an example of a structure that
has gap degree 1, but is strongly ill-nested for gap
degree 1. This is one of the smallest possible such
structures: by generating all the possible trees up
to 10 nodes (without counting a dummy root node
</bodyText>
<page confidence="0.988972">
297
</page>
<table confidence="0.999769357142857">
Language Structures
Total Nonprojective
Total By gap degree By nestedness
Gap Gap Gap Gap Well- Mildly Strongly
degree 1 degree 2 degree 3 deg. &gt; 3 Nested Ill-Nested Ill-Nested
Arabic 2995 205 189 13 2 1 204 1 0
Czech 87889 20353 19989 359 4 1 20257 96 0
Danish 5430 864 854 10 0 0 856 8 0
Dutch 13349 4865 4425 427 13 0 4850 15 0
Latin 3473 1743 1543 188 10 2 1552 191 0
Portuguese 9071 1718 1302 351 51 14 1711 7 0
Slovene 1998 555 443 81 21 10 550 5 0
Swedish 11042 1079 1048 19 7 5 1008 71 0
Turkish 5583 685 656 29 0 0 665 20 0
</table>
<tableCaption confidence="0.7395945">
Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appear-
ing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al.,
2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dieroski et al., 2006), Swedish (Nilsson
et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003).
</tableCaption>
<figureCaption confidence="0.893557">
Figure 2: One of the smallest strongly ill-nested structures.
This dependency structure has gap degree 1, but is only
mildly ill-nested for gap degree ≥ 2.
</figureCaption>
<bodyText confidence="0.998918428571429">
located at position 0), it can be shown that all the
structures of any gap degree k with length smaller
than 10 are well-nested or only mildly ill-nested
for that gap degree k.
Even if a structure T is strongly ill-nested for
a given gap degree, there is always some m ∈ IN
such that T is mildly ill-nested for m (since every
dependency structure can be binarised, and binari-
sations have finite gap degree). For example, the
structure in Figure 2 is mildly ill-nested for gap de-
gree 2. Therefore, MGk parsers have the property
of being able to parse any possible dependency
structure as long as we make k large enough.
In practice, structures like the one in Figure 2
do not seem to appear in dependency treebanks.
We have analysed treebanks for nine different lan-
guages, obtaining the data presented in Table 1.
None of these treebanks contain structures that are
strongly ill-nested for their gap degree. There-
fore, in any of these treebanks, the MGk parser can
parse every sentence with gap degree at most k.
</bodyText>
<sectionHeader confidence="0.997284" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999616022727273">
We have defined a parsing algorithm for well-
nested dependency structures with bounded gap
degree. In terms of computational complexity,
this algorithm is comparable to the best parsers
for related constituency-based formalisms: when
the gap degree is at most 1, it runs in O(n7),
like the fastest known parsers for LTAG, and can
be made O(n6) if we use unlexicalised depen-
dencies. When the gap degree is greater than 1,
the time complexity goes up by a factor of n2
for each extra unit of gap degree, as in parsers
for coupled context-free grammars. Most of the
non-projective sentences appearing in treebanks
are well-nested and have a small gap degree, so
this algorithm directly parses the vast majority of
the non-projective constructions present in natural
languages, without requiring the construction of a
constituency grammar as an intermediate step.
Additionally, we have defined a set of struc-
tures for any gap degree k which we call mildly
ill-nested. This set includes ill-nested structures
verifying certain conditions, and can be parsed in
O(n3k+4) with a variant of the parser for well-
nested structures. The practical interest of mildly
ill-nested structures can be seen in the data ob-
tained from several dependency treebanks, show-
ing that all of the ill-nested structures in them are
mildly ill-nested for their corresponding gap de-
gree. Therefore, our O(n3k+4) parser can analyse
all the gap degree k structures in these treebanks.
The set of mildly ill-nested structures for gap
degree k is defined as the set of structures that have
a binarisation of gap degree at most k. This defini-
tion is directly related to the way the MGk parser
works, since it implicitly finds such a binarisation.
An interesting line of future work would be to find
an equivalent characterisation of mildly ill-nested
structures which is more grammar-oriented and
would provide a more linguistic insight into these
structures. Another research direction, which we
are currently working on, is exploring how vari-
ants of the MGk parser’s strategy can be applied
to the problem of binarising LCFRS (G´omez-
Rodriguez et al., 2009).
</bodyText>
<page confidence="0.996426">
298
</page>
<sectionHeader confidence="0.989982" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999828827868853">
Susana Afonso, Eckhard Bick, Renato Haber, and Di-
ana Santos. 2002. “Floresta sint´a(c)tica”: a tree-
bank for Portuguese. In Proc. ofLREC 2002, pages
1968–1703, Las Palmas, Spain.
Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2002.
The annotation process in the Turkish treebank. In
Proc. of EACL Workshop on Linguistically Inter-
preted Corpora - LINC, Budapest, Hungary.
David Bamman and Gregory Crane. 2006. The design
and use of a Latin dependency treebank. In Proc. of
5th Workshop on Treebanks and Linguistic Theories
(TLT2006), pages 67–78.
Manuel Bodirsky, Marco Kuhlmann, and Mathias
M¨ohl. 2005. Well-nested drawings as models
of syntactic structure. Technical Report, Saar-
land University. Electronic version available at:
http://www.ps.uni-sb.de/Papers/.
Michael A. Covington. 1990. A dependency parser
for variable-word-order languages. Technical Re-
port AI-1990-01, Athens, GA.
Saˇso Dˇzeroski, Tomaˇz Erjavec, Nina Ledinek, Petr Pa-
jas, Zdenˇek ˇZabokrtsk´y, and Andreja ˇZele. 2006.
Towards a Slovene dependency treebank. In Proc.
ofLREC 2006, pages 1388–1391, Genoa, Italy.
Jason Eisner and Giorgio Satta. 1999. Efficient pars-
ing for bilexical context-free grammars and head au-
tomaton grammars. In Proc. ofACL-99, pages 457–
464, Morristown, NJ. ACL.
Jason Eisner and Giorgio Satta. 2000. A faster parsing
algorithm for lexicalized tree-adjoining grammars.
In Proc. of 5th Workshop on Tree-Adjoining Gram-
mars and Related Formalisms (TAG+5), pages 14–
19, Paris.
Jason Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Proc. of
COLING-96, pages 340–345, Copenhagen.
Carlos G´omez-Rodriguez, John Carroll, and David
Weir. 2008a. A deductive approach to dependency
parsing. In Proc. of ACL’08:HLT, pages 968–976,
Columbus, Ohio. ACL.
Carlos G´omez-Rodriguez, David Weir, and John Car-
roll. 2008b. Parsing mildly non-projective depen-
dency structures. Technical Report CSRP 600, De-
partment of Informatics, University of Sussex.
Carlos G´omez-Rodriguez, Marco Kuhlmann, Giorgio
Satta, and David Weir. 2009. Optimal reduction of
rule length in linear context-free rewriting systems.
In Proc. ofNAACL’09:HLT (to appear).
Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf,
and Emanuel Beˇska. 2004. Prague Arabic depen-
dency treebank: Development in data and tools. In
Proc. ofNEMLAR International Conference on Ara-
bic Language Resources and Tools, pages 110–117.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila
Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı
Havelka, and Marie Mikulov´a. 2006. Prague depen-
dency treebank 2.0. CDROM CAT: LDC2006T01,
ISBN 1-58563-370-4.
Jiˇr´ı Havelka. 2007. Beyond projectivity: Multilin-
gual evaluation of constraints and measures on non-
projective structures. In Proc. ofACL 2007, Prague,
Czech Republic. ACL.
G¨unter Hotz and Gisela Pitsch. 1996. On pars-
ing coupled-context-free languages. Theor. Comput.
Sci., 161(1-2):205–233. Elsevier, Essex, UK.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
adjoining grammars. In Handbook of for-
mal languages, pages 69–124. Springer-Verlag,
Berlin/Heidelberg/NY.
Matthias T. Kromann. 2003. The Danish dependency
treebank and the underlying linguistic theory. In
Proc. of the 2nd Workshop on Treebanks and Lin-
guistic Theories (TLT2003).
Marco Kuhlmann and Mathias M¨ohl. 2007. Mildly
context-sensitive dependency languages. In Proc. of
ACL 2007, Prague, Czech Republic. ACL.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In Proc.
of COLING/ACL main conference poster sessions,
pages 507–514, Morristown, NJ, USA. ACL.
Marco Kuhlmann. 2007. Dependency Structures and
Lexicalized Grammars. Doctoral dissertation, Saar-
land University, Saarbr¨ucken, Germany.
Ryan McDonald and Giorgio Satta. 2007. On the com-
plexity of non-projective data-driven dependency
parsing. In IWPT 2007: Proc. of the 10th Confer-
ence on Parsing Technologies. ACL.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proc. of
HLT/EMNLP 2005, pages 523–530, Morristown,
NJ, USA. ACL.
Jens Nilsson, Johan Hall, and Joakim Nivre. 2005.
MAMBA meets TIGER: Reconstructing a Swedish
treebank from antiquity. In Proc. of NODALIDA
2005 Special Session on Treebanks, pages 119–132.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-
projective dependency parsing. In Proc. ofACL’05,
pages 99–106, Morristown, NJ, USA. ACL.
Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur
and G¨okhan T¨ur. 2003. Building a Turkish tree-
bank. In A. Abeille, ed., Building and Exploit-
ing Syntactically-annotated Corpora. Kluwer, Dor-
drecht.
Giorgio Satta. 1992. Recognition of linear context-
free rewriting systems. In Proc. of ACL-92, pages
89–95, Morristown, NJ. ACL.
Klaas Sikkel. 1997. Parsing Schemata — A Frame-
work for Specification and Analysis of Parsing Al-
gorithms. Springer-Verlag, Berlin/Heidelberg/NY.
L. van der Beek, G. Bouma, R. Malouf, and G. van
Noord. 2002. The Alpino dependency treebank.
In Computational Linguistics in the Netherlands
(CLIN), Twente University.
K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions pro-
duced by various grammatical formalisms. In Proc.
ofACL-87, pages 104–111, Morristown, NJ. ACL.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statis-
tical dependency analysis with support vector ma-
chines. In Proc. of 8th International Workshop on
Parsing Technologies (IWPT 2003), pages 195–206.
</reference>
<page confidence="0.998632">
299
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.709038">
<title confidence="0.998841">Mildly Non-projective Dependency</title>
<author confidence="0.99937">Carlos G´omez-Rodriguez David Weir</author>
<author confidence="0.99937">John Carroll</author>
<affiliation confidence="0.954428">Departamento de Computaci´on Department of Informatics</affiliation>
<address confidence="0.768623">da Spain University of Sussex, United Kingdom</address>
<abstract confidence="0.994990333333333">We present parsing algorithms for various mildly non-projective dependency formalisms. In particular, algorithms are presented for: all well-nested structures of degree at most with the same complexity as the best existing parsers for constituency formalisms of equivalent generative power; all well-nested structures with degree bounded by any constant and a new class of structures with gap deup to includes some ill-nested structures. The third case includes all the degree in a number of dependency treebanks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susana Afonso</author>
<author>Eckhard Bick</author>
<author>Renato Haber</author>
<author>Diana Santos</author>
</authors>
<title>Floresta sint´a(c)tica”: a treebank for Portuguese.</title>
<date>2002</date>
<booktitle>In Proc. ofLREC 2002,</booktitle>
<pages>1968--1703</pages>
<location>Las Palmas,</location>
<contexts>
<context position="33296" citStr="Afonso et al., 2002" startWordPosition="6244" endWordPosition="6247"> 20257 96 0 Danish 5430 864 854 10 0 0 856 8 0 Dutch 13349 4865 4425 427 13 0 4850 15 0 Latin 3473 1743 1543 188 10 2 1552 191 0 Portuguese 9071 1718 1302 351 51 14 1711 7 0 Slovene 1998 555 443 81 21 10 550 5 0 Swedish 11042 1079 1048 19 7 5 1008 71 0 Turkish 5583 685 656 29 0 0 665 20 0 Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appearing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al., 2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dieroski et al., 2006), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). Figure 2: One of the smallest strongly ill-nested structures. This dependency structure has gap degree 1, but is only mildly ill-nested for gap degree ≥ 2. located at position 0), it can be shown that all the structures of any gap degree k with length smaller than 10 are well-nested or only mildly ill-nested for that gap degree k. Even if a structure T is strongly ill-nested for a given gap degree, there is always some m ∈ IN such that T is mildly ill-nested for m (since e</context>
</contexts>
<marker>Afonso, Bick, Haber, Santos, 2002</marker>
<rawString>Susana Afonso, Eckhard Bick, Renato Haber, and Diana Santos. 2002. “Floresta sint´a(c)tica”: a treebank for Portuguese. In Proc. ofLREC 2002, pages 1968–1703, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nart B Atalay</author>
<author>Kemal Oflazer</author>
<author>Bilge Say</author>
</authors>
<title>The annotation process in the Turkish treebank.</title>
<date>2002</date>
<booktitle>In Proc. of EACL Workshop on Linguistically Interpreted Corpora - LINC,</booktitle>
<location>Budapest, Hungary.</location>
<marker>Atalay, Oflazer, Say, 2002</marker>
<rawString>Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2002. The annotation process in the Turkish treebank. In Proc. of EACL Workshop on Linguistically Interpreted Corpora - LINC, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Gregory Crane</author>
</authors>
<title>The design and use of a Latin dependency treebank.</title>
<date>2006</date>
<booktitle>In Proc. of 5th Workshop on Treebanks and Linguistic Theories (TLT2006),</booktitle>
<pages>67--78</pages>
<contexts>
<context position="33262" citStr="Bamman and Crane, 2006" startWordPosition="6239" endWordPosition="6242">4 1 0 Czech 87889 20353 19989 359 4 1 20257 96 0 Danish 5430 864 854 10 0 0 856 8 0 Dutch 13349 4865 4425 427 13 0 4850 15 0 Latin 3473 1743 1543 188 10 2 1552 191 0 Portuguese 9071 1718 1302 351 51 14 1711 7 0 Slovene 1998 555 443 81 21 10 550 5 0 Swedish 11042 1079 1048 19 7 5 1008 71 0 Turkish 5583 685 656 29 0 0 665 20 0 Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appearing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al., 2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dieroski et al., 2006), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). Figure 2: One of the smallest strongly ill-nested structures. This dependency structure has gap degree 1, but is only mildly ill-nested for gap degree ≥ 2. located at position 0), it can be shown that all the structures of any gap degree k with length smaller than 10 are well-nested or only mildly ill-nested for that gap degree k. Even if a structure T is strongly ill-nested for a given gap degree, there is always some m ∈ IN such that T i</context>
</contexts>
<marker>Bamman, Crane, 2006</marker>
<rawString>David Bamman and Gregory Crane. 2006. The design and use of a Latin dependency treebank. In Proc. of 5th Workshop on Treebanks and Linguistic Theories (TLT2006), pages 67–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Bodirsky</author>
<author>Marco Kuhlmann</author>
<author>Mathias M¨ohl</author>
</authors>
<title>Well-nested drawings as models of syntactic structure.</title>
<date>2005</date>
<tech>Technical Report,</tech>
<institution>Saarland University.</institution>
<marker>Bodirsky, Kuhlmann, M¨ohl, 2005</marker>
<rawString>Manuel Bodirsky, Marco Kuhlmann, and Mathias M¨ohl. 2005. Well-nested drawings as models of syntactic structure. Technical Report, Saarland University. Electronic version available at: http://www.ps.uni-sb.de/Papers/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>A dependency parser for variable-word-order languages.</title>
<date>1990</date>
<tech>Technical Report AI-1990-01,</tech>
<location>Athens, GA.</location>
<contexts>
<context position="9916" citStr="Covington, 1990" startWordPosition="1668" endWordPosition="1669">plete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away from control structures (the particular model used to create the decisions associated with D-rules). Furthermore, the choice points in the parsing process and the information we can use to make decisions are made explicit in the steps linked to D-rules. 3 The WG1 parser 3.1 Parsing schema for WG1 We define </context>
</contexts>
<marker>Covington, 1990</marker>
<rawString>Michael A. Covington. 1990. A dependency parser for variable-word-order languages. Technical Report AI-1990-01, Athens, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇso Dˇzeroski</author>
</authors>
<title>Tomaˇz Erjavec, Nina Ledinek, Petr Pajas, Zdenˇek ˇZabokrtsk´y, and Andreja ˇZele.</title>
<date>2006</date>
<booktitle>In Proc. ofLREC</booktitle>
<pages>1388--1391</pages>
<location>Genoa, Italy.</location>
<marker>Dˇzeroski, 2006</marker>
<rawString>Saˇso Dˇzeroski, Tomaˇz Erjavec, Nina Ledinek, Petr Pajas, Zdenˇek ˇZabokrtsk´y, and Andreja ˇZele. 2006. Towards a Slovene dependency treebank. In Proc. ofLREC 2006, pages 1388–1391, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Giorgio Satta</author>
</authors>
<title>Efficient parsing for bilexical context-free grammars and head automaton grammars.</title>
<date>1999</date>
<booktitle>In Proc. ofACL-99,</booktitle>
<pages>457--464</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ.</location>
<contexts>
<context position="9607" citStr="Eisner and Satta, 1999" startWordPosition="1620" endWordPosition="1623">sed to prove the correctness of a parser: for each input string, a parsing schema’s deduction steps allow us to infer a set of items, called valid items for that string. A schema is said to be sound if all valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away</context>
</contexts>
<marker>Eisner, Satta, 1999</marker>
<rawString>Jason Eisner and Giorgio Satta. 1999. Efficient parsing for bilexical context-free grammars and head automaton grammars. In Proc. ofACL-99, pages 457– 464, Morristown, NJ. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Giorgio Satta</author>
</authors>
<title>A faster parsing algorithm for lexicalized tree-adjoining grammars.</title>
<date>2000</date>
<booktitle>In Proc. of 5th Workshop on Tree-Adjoining Grammars and Related Formalisms (TAG+5),</booktitle>
<pages>14--19</pages>
<location>Paris.</location>
<contexts>
<context position="4347" citStr="Eisner and Satta, 2000" startWordPosition="649" endWordPosition="652">in a data-driven manner, rather than indirectly by constructing intermediate constituency grammars and extracting dependencies from constituency parses. We address this problem with the following contributions: (1) we define a parsing algorithm Proceedings of the 12th Conference of the European Chapter of the ACL, pages 291–299, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 291 for well-nested dependency structures of gap degree 1, and prove its correctness. The parser runs in time O(n7), the same complexity as the best existing algorithms for LTAG (Eisner and Satta, 2000), and can be optimised to O(n6) in the nonlexicalised case; (2) we generalise the previous algorithm to any well-nested dependency structure with gap degree at most k in time O(n5+2k); (3) we generalise the previous parsers to be able to analyse not only well-nested structures, but also ill-nested structures with gap degree at most k satisfying certain constraints1, in time O(n4+3k); and (4) we characterise the set of structures covered by this parser, which we call mildly ill-nested structures, and show that it includes all the trees present in a number of dependency treebanks. 2 Preliminarie</context>
<context position="19607" citStr="Eisner and Satta, 2000" startWordPosition="3733" endWordPosition="3736">oof into cases according to the order annotation of its head and we find that, for every possible form of this order annotation, we can find a sequence of Combine steps to infer the relevant item from smaller correct items. 3.3 Computational complexity The time complexity of WG1 is O(n7), as the step Combine Shrinking Gap Centre works with 7 free string positions. This complexity with respect to the length of the input is as expected for this set of structures, since Kuhlmann (2007) shows that they are equivalent to LTAG, and the best existing parsers for this formalism also perform in O(n7) (Eisner and Satta, 2000). Note that the Combine step which is the bottleneck only uses the 7 indexes, and not any other entities like D-rules, so its O(n7) complexity does not have any additional factors due to grammar size or other variables. The space complexity of WG1 is O(n5) for recognition, due to the 5 indexes in items, and O(n7) for full parsing. 4Due to space constraints, correctness proofs for the parsers are not given here. Full proofs are provided in the extended version of this paper, see (G´omez-Rodriguez et al., 2008b). It is possible to build a variant of this parser with time complexity O(n6), as wit</context>
</contexts>
<marker>Eisner, Satta, 2000</marker>
<rawString>Jason Eisner and Giorgio Satta. 2000. A faster parsing algorithm for lexicalized tree-adjoining grammars. In Proc. of 5th Workshop on Tree-Adjoining Grammars and Related Formalisms (TAG+5), pages 14– 19, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc. of COLING-96,</booktitle>
<pages>340--345</pages>
<location>Copenhagen.</location>
<contexts>
<context position="9772" citStr="Eisner, 1996" startWordPosition="1646" endWordPosition="1647">ema is said to be sound if all valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away from control structures (the particular model used to create the decisions associated with D-rules). Furthermore, the choice points in the parsing process and the i</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of COLING-96, pages 340–345, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodriguez</author>
<author>John Carroll</author>
<author>David Weir</author>
</authors>
<title>A deductive approach to dependency parsing.</title>
<date>2008</date>
<booktitle>In Proc. of ACL’08:HLT,</booktitle>
<pages>968--976</pages>
<publisher>ACL.</publisher>
<location>Columbus, Ohio.</location>
<marker>G´omez-Rodriguez, Carroll, Weir, 2008</marker>
<rawString>Carlos G´omez-Rodriguez, John Carroll, and David Weir. 2008a. A deductive approach to dependency parsing. In Proc. of ACL’08:HLT, pages 968–976, Columbus, Ohio. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodriguez</author>
<author>David Weir</author>
<author>John Carroll</author>
</authors>
<title>Parsing mildly non-projective dependency structures.</title>
<date>2008</date>
<tech>Technical Report CSRP 600,</tech>
<institution>Department of Informatics, University of Sussex.</institution>
<marker>G´omez-Rodriguez, Weir, Carroll, 2008</marker>
<rawString>Carlos G´omez-Rodriguez, David Weir, and John Carroll. 2008b. Parsing mildly non-projective dependency structures. Technical Report CSRP 600, Department of Informatics, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodriguez</author>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
<author>David Weir</author>
</authors>
<title>Optimal reduction of rule length in linear context-free rewriting systems.</title>
<date>2009</date>
<booktitle>In Proc. ofNAACL’09:HLT</booktitle>
<note>(to appear).</note>
<marker>G´omez-Rodriguez, Kuhlmann, Satta, Weir, 2009</marker>
<rawString>Carlos G´omez-Rodriguez, Marco Kuhlmann, Giorgio Satta, and David Weir. 2009. Optimal reduction of rule length in linear context-free rewriting systems. In Proc. ofNAACL’09:HLT (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Otakar Smrˇz</author>
<author>Petr Zem´anek</author>
<author>Jan ˇSnaidauf</author>
<author>Emanuel Beˇska</author>
</authors>
<title>Prague Arabic dependency treebank: Development in data and tools.</title>
<date>2004</date>
<booktitle>In Proc. ofNEMLAR International Conference on Arabic Language Resources and Tools,</booktitle>
<pages>110--117</pages>
<marker>Hajiˇc, Smrˇz, Zem´anek, ˇSnaidauf, Beˇska, 2004</marker>
<rawString>Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf, and Emanuel Beˇska. 2004. Prague Arabic dependency treebank: Development in data and tools. In Proc. ofNEMLAR International Conference on Arabic Language Resources and Tools, pages 110–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Jarmila Panevov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Jiˇr´ı Havelka</author>
<author>Marie Mikulov´a</author>
</authors>
<date>2006</date>
<booktitle>Prague dependency treebank 2.0. CDROM CAT: LDC2006T01, ISBN</booktitle>
<pages>1--58563</pages>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Panevov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, and Marie Mikulov´a. 2006. Prague dependency treebank 2.0. CDROM CAT: LDC2006T01, ISBN 1-58563-370-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiˇr´ı Havelka</author>
</authors>
<title>Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures.</title>
<date>2007</date>
<booktitle>In Proc. ofACL 2007,</booktitle>
<publisher>ACL.</publisher>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2483" citStr="Havelka, 2007" startWordPosition="371" endWordPosition="372">INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe e RI, Bolsas para Estadias INCITE – FSE cofinanced). the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and </context>
</contexts>
<marker>Havelka, 2007</marker>
<rawString>Jiˇr´ı Havelka. 2007. Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures. In Proc. ofACL 2007, Prague, Czech Republic. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unter Hotz</author>
<author>Gisela Pitsch</author>
</authors>
<title>On parsing coupled-context-free languages.</title>
<date>1996</date>
<journal>Theor. Comput. Sci.,</journal>
<pages>161--1</pages>
<publisher>Elsevier,</publisher>
<location>Essex, UK.</location>
<contexts>
<context position="2978" citStr="Hotz and Pitsch, 1996" startWordPosition="443" endWordPosition="446">ncy structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and Schabes, 1997) induce the set of well-nested dependency structures with gap degree at most 1. These results establish that there must be polynomial-time dependency parsing algorithms for well-nested structures with bounded gap degree, since such parsers exist for their corresponding lexicalised constituency-based formalisms. However, since most of the non-projective structures in treebanks are well-nested and have a small gap degree (Kuhlmann and Nivre, 2006), developing efficient dependenc</context>
<context position="23897" citStr="Hotz and Pitsch (1996)" startWordPosition="4561" endWordPosition="4564">e in the completeness proof. 4.2 Computational complexity The WGk parser runs in time O(n5+2k): as in the case of WG1, the deduction step with most free variables is Combine Shrinking Gap Centre, and in this case it has 5 + 2k free indexes. Again, this complexity result is in line with what could be expected from previous research in constituency parsing: Kuhlmann (2007) shows that the set of well-nested dependency structures with gap degree at most k is closely related to coupled context-free grammars in which the maximal rank of a nonterminal is k + 1; and the constituency parser defined by Hotz and Pitsch (1996) for these grammars also adds an n2 factor for each unit increment of k. Note that a small value of k should be enough to cover the vast majority of the non-projective sentences found in natural language treebanks. For example, the Prague Dependency Treebank contains no structures with gap degree greater than 4. Therefore, a WG4 parser would be able to analyse all the well-nested structures in this treebank, which represent 99.89% of the total. Increasing k beyond 4 would not produce further improvements in coverage. 5 Parsing ill-nested structures The WGk parser analyses dependency structures</context>
</contexts>
<marker>Hotz, Pitsch, 1996</marker>
<rawString>G¨unter Hotz and Gisela Pitsch. 1996. On parsing coupled-context-free languages. Theor. Comput. Sci., 161(1-2):205–233. Elsevier, Essex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Treeadjoining grammars.</title>
<date>1997</date>
<booktitle>In Handbook of formal languages,</booktitle>
<pages>69--124</pages>
<publisher>Springer-Verlag, Berlin/Heidelberg/NY.</publisher>
<contexts>
<context position="3097" citStr="Joshi and Schabes, 1997" startWordPosition="465" endWordPosition="468">lka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and Schabes, 1997) induce the set of well-nested dependency structures with gap degree at most 1. These results establish that there must be polynomial-time dependency parsing algorithms for well-nested structures with bounded gap degree, since such parsers exist for their corresponding lexicalised constituency-based formalisms. However, since most of the non-projective structures in treebanks are well-nested and have a small gap degree (Kuhlmann and Nivre, 2006), developing efficient dependency parsing strategies for these sets of structures has considerable practical interest, since we would be able to parse </context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1997. Treeadjoining grammars. In Handbook of formal languages, pages 69–124. Springer-Verlag, Berlin/Heidelberg/NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias T Kromann</author>
</authors>
<title>The Danish dependency treebank and the underlying linguistic theory.</title>
<date>2003</date>
<booktitle>In Proc. of the 2nd Workshop on Treebanks and Linguistic Theories (TLT2003).</booktitle>
<contexts>
<context position="33195" citStr="Kromann, 2003" startWordPosition="6229" endWordPosition="6230">Nested Ill-Nested Ill-Nested Arabic 2995 205 189 13 2 1 204 1 0 Czech 87889 20353 19989 359 4 1 20257 96 0 Danish 5430 864 854 10 0 0 856 8 0 Dutch 13349 4865 4425 427 13 0 4850 15 0 Latin 3473 1743 1543 188 10 2 1552 191 0 Portuguese 9071 1718 1302 351 51 14 1711 7 0 Slovene 1998 555 443 81 21 10 550 5 0 Swedish 11042 1079 1048 19 7 5 1008 71 0 Turkish 5583 685 656 29 0 0 665 20 0 Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appearing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al., 2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dieroski et al., 2006), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). Figure 2: One of the smallest strongly ill-nested structures. This dependency structure has gap degree 1, but is only mildly ill-nested for gap degree ≥ 2. located at position 0), it can be shown that all the structures of any gap degree k with length smaller than 10 are well-nested or only mildly ill-nested for that gap degree k. Even if a structure T is strongly ill-neste</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>Matthias T. Kromann. 2003. The Danish dependency treebank and the underlying linguistic theory. In Proc. of the 2nd Workshop on Treebanks and Linguistic Theories (TLT2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Mathias M¨ohl</author>
</authors>
<title>Mildly context-sensitive dependency languages.</title>
<date>2007</date>
<booktitle>In Proc. of ACL 2007,</booktitle>
<publisher>ACL.</publisher>
<location>Prague, Czech Republic.</location>
<marker>Kuhlmann, M¨ohl, 2007</marker>
<rawString>Marco Kuhlmann and Mathias M¨ohl. 2007. Mildly context-sensitive dependency languages. In Proc. of ACL 2007, Prague, Czech Republic. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In Proc. of COLING/ACL main conference poster sessions,</booktitle>
<pages>507--514</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2467" citStr="Kuhlmann and Nivre, 2006" startWordPosition="367" endWordPosition="370">cia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe e RI, Bolsas para Estadias INCITE – FSE cofinanced). the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and L</context>
<context position="6090" citStr="Kuhlmann and Nivre, 2006" startWordPosition="1004" endWordPosition="1007">and j) is a set of the form [i, j] = {wk |i ≤ k ≤ j}. A dependency graph is said to be a tree if it is: (1) acyclic: wj ∈ bwic implies wi → wj ∈6 E; and (2) each node has exactly one parent, except for one node which we call the root or head. A graph verifying these conditions and having a vertex set V ⊆ {w1, ... , wn} is a partial dependency tree. Given a dependency tree T = (V, E) and a node u ∈ V , the subtree induced by the node u is the graph Tu = (buc, Eu) where Eu = {wi → wj ∈ E |wj ∈ buc}. 2.1 Properties of dependency trees We now define the concepts of gap degree and well-nestedness (Kuhlmann and Nivre, 2006). Let T be a (possibly partial) dependency tree for w1 ... wn: We say that T is projective if an interval for every word wi. Thus every node in the dependency structure must dominate a contiguous substring in the sentence. The gap degree 1Parsing unrestricted ill-nested structures, even when the gap degree is bounded, is NP-complete: these structures are equivalent to LCFRS for which the recognition problem is NP-complete (Satta, 1992). of a particular node wk in T is the minimum g ∈ IlV such that bwkc can be written as the union of g +1 intervals; that is, the number of discontinuities in bwk</context>
<context position="24939" citStr="Kuhlmann and Nivre, 2006" startWordPosition="4736" endWordPosition="4739"> represent 99.89% of the total. Increasing k beyond 4 would not produce further improvements in coverage. 5 Parsing ill-nested structures The WGk parser analyses dependency structures with bounded gap degree as long as they are well-nested. This covers the vast majority of 5In all the parsers in this paper, Combine steps may be applied in different orders to produce the same result, causing spurious ambiguity. In WG1 and WGk, this can be avoided when implementing the schemata, by adding flags to items so as to impose a particular order. the structures that occur in natural-language treebanks (Kuhlmann and Nivre, 2006), but there is still a significant minority of sentences that contain ill-nested structures. Unfortunately, the general problem of parsing ill-nested structures is NPcomplete, even when the gap degree is bounded: this set of structures is closely related to LCFRS with bounded fan-out and unbounded production length, and parsing in this formalism has been proven to be NP-complete (Satta, 1992). The reason for this high complexity is the problem of unrestricted crossing configurations, appearing when dependency subtrees are allowed to interleave in every possible way. However, just as it has bee</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In Proc. of COLING/ACL main conference poster sessions, pages 507–514, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
</authors>
<title>Dependency Structures and Lexicalized Grammars. Doctoral dissertation,</title>
<date>2007</date>
<institution>Saarland University,</institution>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="2500" citStr="Kuhlmann (2007)" startWordPosition="373" endWordPosition="374">2ES, INCITE08ENA305025ES, INCITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe e RI, Bolsas para Estadias INCITE – FSE cofinanced). the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and Schabes, 1997) in</context>
<context position="18816" citStr="Kuhlmann, 2007" startWordPosition="3598" endWordPosition="3599"> tree for the complete sentence. 3.2 Proving correctness The parsing schemata formalism can be used to prove the correctness of a parsing schema. To prove that WG1 is correct, we need to prove its soundness and completeness.4 Soundness is proven by checking that valid items always contain well-nested trees. Completeness is proven by induction, taking initial items as the base case and showing that an item containing a correct subtree for a string can always be obtained from items corresponding to smaller subtrees. In order to prove this induction step, we use the concept of order annotations (Kuhlmann, 2007; Kuhlmann and M¨ohl, 2007), which are strings that lexicalise the precedence relation between the nodes of a dependency tree. Given a correct subtree, we divide the proof into cases according to the order annotation of its head and we find that, for every possible form of this order annotation, we can find a sequence of Combine steps to infer the relevant item from smaller correct items. 3.3 Computational complexity The time complexity of WG1 is O(n7), as the step Combine Shrinking Gap Centre works with 7 free string positions. This complexity with respect to the length of the input is as exp</context>
<context position="23648" citStr="Kuhlmann (2007)" startWordPosition="4517" endWordPosition="4518">or the fact that Combine steps can create items with more than one gap5. The correctness proof is also analogous to that of WG1, but we must take into account that the set of possible order annotations is larger when k &gt; 1, so more cases arise in the completeness proof. 4.2 Computational complexity The WGk parser runs in time O(n5+2k): as in the case of WG1, the deduction step with most free variables is Combine Shrinking Gap Centre, and in this case it has 5 + 2k free indexes. Again, this complexity result is in line with what could be expected from previous research in constituency parsing: Kuhlmann (2007) shows that the set of well-nested dependency structures with gap degree at most k is closely related to coupled context-free grammars in which the maximal rank of a nonterminal is k + 1; and the constituency parser defined by Hotz and Pitsch (1996) for these grammars also adds an n2 factor for each unit increment of k. Note that a small value of k should be enough to cover the vast majority of the non-projective sentences found in natural language treebanks. For example, the Prague Dependency Treebank contains no structures with gap degree greater than 4. Therefore, a WG4 parser would be able</context>
</contexts>
<marker>Kuhlmann, 2007</marker>
<rawString>Marco Kuhlmann. 2007. Dependency Structures and Lexicalized Grammars. Doctoral dissertation, Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Giorgio Satta</author>
</authors>
<title>On the complexity of non-projective data-driven dependency parsing.</title>
<date>2007</date>
<booktitle>In IWPT 2007: Proc. of the 10th Conference on Parsing Technologies. ACL.</booktitle>
<contexts>
<context position="2106" citStr="McDonald and Satta, 2007" startWordPosition="314" endWordPosition="317">o not satisfy this constraint, parsing without the projectivity constraint is computationally complex. Although it is possible to parse non-projective structures in quadratic time under a model in which each dependency decision is independent of all the others (McDonald et al., 2005), ∗Partially supported by MEC and FEDER (HUM2007- 66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe e RI, Bolsas para Estadias INCITE – FSE cofinanced). the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: li</context>
</contexts>
<marker>McDonald, Satta, 2007</marker>
<rawString>Ryan McDonald and Giorgio Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In IWPT 2007: Proc. of the 10th Conference on Parsing Technologies. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP</booktitle>
<pages>523--530</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. of HLT/EMNLP 2005, pages 523–530, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
<author>Joakim Nivre</author>
</authors>
<title>MAMBA meets TIGER: Reconstructing a Swedish treebank from antiquity.</title>
<date>2005</date>
<booktitle>In Proc. of NODALIDA</booktitle>
<pages>119--132</pages>
<contexts>
<context position="33361" citStr="Nilsson et al., 2005" startWordPosition="6254" endWordPosition="6257">4425 427 13 0 4850 15 0 Latin 3473 1743 1543 188 10 2 1552 191 0 Portuguese 9071 1718 1302 351 51 14 1711 7 0 Slovene 1998 555 443 81 21 10 550 5 0 Swedish 11042 1079 1048 19 7 5 1008 71 0 Turkish 5583 685 656 29 0 0 665 20 0 Table 1: Counts of dependency trees classified by gap degree, and mild and strong ill-nestedness (for their gap degree); appearing in treebanks for Arabic (Hajiˇc et al., 2004), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), Dutch (van der Beek et al., 2002), Latin (Bamman and Crane, 2006), Portuguese (Afonso et al., 2002), Slovene (Dieroski et al., 2006), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). Figure 2: One of the smallest strongly ill-nested structures. This dependency structure has gap degree 1, but is only mildly ill-nested for gap degree ≥ 2. located at position 0), it can be shown that all the structures of any gap degree k with length smaller than 10 are well-nested or only mildly ill-nested for that gap degree k. Even if a structure T is strongly ill-nested for a given gap degree, there is always some m ∈ IN such that T is mildly ill-nested for m (since every dependency structure can be binarised, and binarisations hav</context>
</contexts>
<marker>Nilsson, Hall, Nivre, 2005</marker>
<rawString>Jens Nilsson, Johan Hall, and Joakim Nivre. 2005. MAMBA meets TIGER: Reconstructing a Swedish treebank from antiquity. In Proc. of NODALIDA 2005 Special Session on Treebanks, pages 119–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudoprojective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. ofACL’05,</booktitle>
<pages>99--106</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2132" citStr="Nivre and Nilsson (2005)" startWordPosition="318" endWordPosition="321">nt, parsing without the projectivity constraint is computationally complex. Although it is possible to parse non-projective structures in quadratic time under a model in which each dependency decision is independent of all the others (McDonald et al., 2005), ∗Partially supported by MEC and FEDER (HUM2007- 66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR, Rede Galega de Proc. da Linguaxe e RI, Bolsas para Estadias INCITE – FSE cofinanced). the problem is intractable in the absence of this assumption (McDonald and Satta, 2007). Nivre and Nilsson (2005) observe that most non-projective dependency structures appearing in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewritin</context>
<context position="25664" citStr="Nivre and Nilsson, 2005" startWordPosition="4848" endWordPosition="4851">ately, the general problem of parsing ill-nested structures is NPcomplete, even when the gap degree is bounded: this set of structures is closely related to LCFRS with bounded fan-out and unbounded production length, and parsing in this formalism has been proven to be NP-complete (Satta, 1992). The reason for this high complexity is the problem of unrestricted crossing configurations, appearing when dependency subtrees are allowed to interleave in every possible way. However, just as it has been noted that most non-projective structures appearing in practice are only “slightly” nonprojective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in treebanks can be viewed as being only “slightly” ill-nested. In this section, we generalise the algorithms WG1 and WGk to parse a proper superset of the set of well-nested structures in polynomial time; and give a characterisation of this new set of structures, which includes all the structures in several dependency treebanks. 5.1 The MG1 and MGk parsers The WGk parser presented previously is based on a bottom-up process, where Link steps are used to link completed subtrees to a head, and Combine steps are used to join subtrees gov</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudoprojective dependency parsing. In Proc. ofACL’05, pages 99–106, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Bilge Say, Dilek Zeynep Hakkani-T¨ur and G¨okhan T¨ur.</title>
<date>2003</date>
<booktitle>Building and Exploiting Syntactically-annotated Corpora.</booktitle>
<editor>In A. Abeille, ed.,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>Oflazer, 2003</marker>
<rawString>Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur and G¨okhan T¨ur. 2003. Building a Turkish treebank. In A. Abeille, ed., Building and Exploiting Syntactically-annotated Corpora. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Recognition of linear contextfree rewriting systems.</title>
<date>1992</date>
<booktitle>In Proc. of ACL-92,</booktitle>
<pages>89--95</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ.</location>
<contexts>
<context position="2805" citStr="Satta, 1992" startWordPosition="414" endWordPosition="415">ring in practice are “close” to being projective, since they contain only a small proportion of nonprojective arcs. This has led to the study of classes of dependency structures that lie between projective and unrestricted non-projective structures (Kuhlmann and Nivre, 2006; Havelka, 2007). Kuhlmann (2007) investigates several such classes, based on well-nestedness and gap degree constraints (Bodirsky et al., 2005), relating them to lexicalised constituency grammar formalisms. Specifically, he shows that: linear context-free rewriting systems (LCFRS) with fan-out k (VijayShanker et al., 1987; Satta, 1992) induce the set of dependency structures with gap degree at most k − 1; coupled context-free grammars in which the maximal rank of a nonterminal is k (Hotz and Pitsch, 1996) induce the set of well-nested dependency structures with gap degree at most k − 1; and LTAGs (Joshi and Schabes, 1997) induce the set of well-nested dependency structures with gap degree at most 1. These results establish that there must be polynomial-time dependency parsing algorithms for well-nested structures with bounded gap degree, since such parsers exist for their corresponding lexicalised constituency-based formali</context>
<context position="6529" citStr="Satta, 1992" startWordPosition="1078" endWordPosition="1079">Tu = (buc, Eu) where Eu = {wi → wj ∈ E |wj ∈ buc}. 2.1 Properties of dependency trees We now define the concepts of gap degree and well-nestedness (Kuhlmann and Nivre, 2006). Let T be a (possibly partial) dependency tree for w1 ... wn: We say that T is projective if an interval for every word wi. Thus every node in the dependency structure must dominate a contiguous substring in the sentence. The gap degree 1Parsing unrestricted ill-nested structures, even when the gap degree is bounded, is NP-complete: these structures are equivalent to LCFRS for which the recognition problem is NP-complete (Satta, 1992). of a particular node wk in T is the minimum g ∈ IlV such that bwkc can be written as the union of g +1 intervals; that is, the number of discontinuities in bwkc. The gap degree of the dependency tree T is the maximum among the gap degrees of its nodes. Note that T has gap degree 0 if and only if T is projective. The subtrees induced by nodes wp and wQ are interleaved if bwpc ∩ bwQc = ∅ and there are nodes wi, wj ∈ bwpc and wk, wl ∈ bwQc such that i &lt; k &lt; j &lt; l. A dependency tree T is well-nested if it does not contain two interleaved subtrees. A tree that is not well-nested is said to be ill</context>
<context position="25334" citStr="Satta, 1992" startWordPosition="4800" endWordPosition="4801">uity. In WG1 and WGk, this can be avoided when implementing the schemata, by adding flags to items so as to impose a particular order. the structures that occur in natural-language treebanks (Kuhlmann and Nivre, 2006), but there is still a significant minority of sentences that contain ill-nested structures. Unfortunately, the general problem of parsing ill-nested structures is NPcomplete, even when the gap degree is bounded: this set of structures is closely related to LCFRS with bounded fan-out and unbounded production length, and parsing in this formalism has been proven to be NP-complete (Satta, 1992). The reason for this high complexity is the problem of unrestricted crossing configurations, appearing when dependency subtrees are allowed to interleave in every possible way. However, just as it has been noted that most non-projective structures appearing in practice are only “slightly” nonprojective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in treebanks can be viewed as being only “slightly” ill-nested. In this section, we generalise the algorithms WG1 and WGk to parse a proper superset of the set of well-nested structures in polynomial time; and </context>
</contexts>
<marker>Satta, 1992</marker>
<rawString>Giorgio Satta. 1992. Recognition of linear contextfree rewriting systems. In Proc. of ACL-92, pages 89–95, Morristown, NJ. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaas Sikkel</author>
</authors>
<title>Parsing Schemata — A Framework for Specification and Analysis of Parsing Algorithms.</title>
<date>1997</date>
<publisher>Springer-Verlag, Berlin/Heidelberg/NY.</publisher>
<contexts>
<context position="7318" citStr="Sikkel, 1997" startWordPosition="1232" endWordPosition="1233">ee of the dependency tree T is the maximum among the gap degrees of its nodes. Note that T has gap degree 0 if and only if T is projective. The subtrees induced by nodes wp and wQ are interleaved if bwpc ∩ bwQc = ∅ and there are nodes wi, wj ∈ bwpc and wk, wl ∈ bwQc such that i &lt; k &lt; j &lt; l. A dependency tree T is well-nested if it does not contain two interleaved subtrees. A tree that is not well-nested is said to be ill-nested. Note that projective trees are always well-nested, but well-nested trees are not always projective. 2.2 Dependency parsing schemata The framework of parsing schemata (Sikkel, 1997) provides a uniform way to describe, analyse and compare parsing algorithms. Parsing schemata were initially defined for constituencybased grammatical formalisms, but G´omezRodriguez et al. (2008a) define a variant of the framework for dependency-based parsers. We use these dependency parsing schemata to define parsers and prove their correctness. Due to space constraints, we only provide brief outlines of the main concepts behind dependency parsing schemata. The parsing schema approach considers parsing as deduction, generating intermediate results called items. An initial set of items is obt</context>
</contexts>
<marker>Sikkel, 1997</marker>
<rawString>Klaas Sikkel. 1997. Parsing Schemata — A Framework for Specification and Analysis of Parsing Algorithms. Springer-Verlag, Berlin/Heidelberg/NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L van der Beek</author>
<author>G Bouma</author>
<author>R Malouf</author>
<author>G van Noord</author>
</authors>
<title>The Alpino dependency treebank.</title>
<date>2002</date>
<booktitle>In Computational Linguistics in the Netherlands (CLIN),</booktitle>
<institution>Twente University.</institution>
<marker>van der Beek, Bouma, Malouf, van Noord, 2002</marker>
<rawString>L. van der Beek, G. Bouma, R. Malouf, and G. van Noord. 2002. The Alpino dependency treebank. In Computational Linguistics in the Netherlands (CLIN), Twente University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<date>1987</date>
<booktitle>In Proc. ofACL-87,</booktitle>
<pages>104--111</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ.</location>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. 1987. Characterizing structural descriptions produced by various grammatical formalisms. In Proc. ofACL-87, pages 104–111, Morristown, NJ. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. of 8th International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>195--206</pages>
<contexts>
<context position="9816" citStr="Yamada and Matsumoto, 2003" startWordPosition="1650" endWordPosition="1653"> valid final items it produces for any arbitrary string are correct for that string. A schema is said to be complete if all correct final items are valid. A correct parsing schema is one which is both sound and complete. In constituency-based parsing schemata, deduction steps usually have grammar rules as side conditions. In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003). To represent these algorithms as deduction systems, we use the notion of D-rules (Covington, 1990). D-rules take the form a → b, which says that word b can have a as a dependent. Deduction steps in non-grammarbased parsers can be tied to the D-rules associated with the links they create. In this way, we obtain a representation of the underlying logic of the parser while abstracting away from control structures (the particular model used to create the decisions associated with D-rules). Furthermore, the choice points in the parsing process and the information we can use to make decisions are </context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proc. of 8th International Workshop on Parsing Technologies (IWPT 2003), pages 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>