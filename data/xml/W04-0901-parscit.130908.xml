<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.623574">
Interpretation in a Cognitive Architecture
</title>
<author confidence="0.550417">
Harold Paredes-Frigolett
</author>
<affiliation confidence="0.456842">
Center for the Study of Language and Information
Cordura Hall, Stanford University
</affiliation>
<address confidence="0.319703">
Stanford, CA 94305, USA
</address>
<email confidence="0.996693">
harold.paredes-frigolett@csli.stanford.edu
</email>
<sectionHeader confidence="0.988323" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995695">
The work reported in this article presents a com-
putational model of interpretation. The model pro-
poses a cognitive architecture for intelligent agents
to reason about competing analyses during interpre-
tation and leverages the positive reinforcement prin-
ciple.
</bodyText>
<sectionHeader confidence="0.971129" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.9908934">
Interpretation of natural language involve the com-
putational effort associated with repeatedly comput-
ing, interpreting and deindexing logical forms for
ambiguous parses. In our view, interpretation can
be construed as a negotiation process whereby lex-
ical, structural, semantic, common-sense and world
knowledge information and referential context are
used to assign plausibilities to competing analyses.
The approach to interpretation taken here has
been motivated by cognitive architectures for in-
telligent agents in the tradition of SOAR (Laird,
Newell, and Rosenbloom, 1987; Laird, 1991),
ACT-R (Anderson, 1993) and ICARUS (Langley et
al., 2003).
In extending cognitive architectures in this tra-
dition to deal with the problem of interpretation,
agents carry both the meaning of competing anal-
yses and the plausibilities associated with them,
which we construe as the reward function of the
agents. As more information becomes available
from the input string, reward functions are updated
and the analysis with the higher plausibility be-
comes the preferred interpretation.
2 The grammar formalism
Consider sentence (1):
</bodyText>
<listItem confidence="0.3562165">
(1) The ✧a spy ✧b watched ✧c the ✧d cop ✧o with ✧f the
✧g revolver ✧h. ✧i
</listItem>
<bodyText confidence="0.845898">
The GPSG-like grammar fragment with semantic
annotations in EPISODIC LOGIC (EL), a seman-
A. DET[def] &lt;-- The; The
</bodyText>
<listItem confidence="0.930834764705882">
B. N &lt;-- spy; spy
C. N &lt;-- cop; cop
D. N &lt;-- revolver; revolver
E. N &lt;-- N PP ; Ay[[y N&apos;] A [y PP&apos;]]
F. NP &lt;-- N[plur] ; (K N&apos;)
G. P[with-attrib] &lt;-- with ; with-attrib
H. P[with-instr] &lt;-- with ; with-instr
L NP &lt;-- DET N ; (DET&apos; N&apos;)
J. PP &lt;-- P NP ; (P&apos; NP&apos;)
K. V[past, _NP] &lt;-- watch ; (past watch)
L. ADVL[post-VP] &lt;-- PP[a-mod] ; (adv-a PP&apos;)
M. VP &lt;-- V[past, _NP] NP ; (V&apos; NP&apos;)
N. VP &lt;-- V[past, _NP]
NP ADVL[a-mod] ; (ADVL&apos;(V&apos;NP&apos;))
O. S &lt;-- NP VP ; [NP&apos; VP&apos;]
P. PUNC[tell] &lt;-- . ;
Q. S &lt;-- S[full-decl] PUNC[tell] ; (decl S&apos;)
</listItem>
<figureCaption confidence="0.759192">
Figure 1: GPSG-like grammar fragment
tic and knowledge representation language for gen-
eral NLU (Hwang and Schubert, 1993), is shown in
Figure 1.1
</figureCaption>
<sectionHeader confidence="0.943778" genericHeader="introduction">
3 Semantic analysis
</sectionHeader>
<bodyText confidence="0.905078916666667">
For sentence (1) the parser computes two initial
analyses using not only structural, but also subcate-
gorization and thematic role information as soon as
the verb is encountered.
At point g, we could be already predicting several
of the possible continuations. Based on subcatego-
rization and thematic role information for the verb
watch, there is a first analysis that results from ap-
plying rule N of our GPSG-like grammar fragment.
At point g, the first analysis is APTT❣.
✶We refer the reader to (Hwang and Schubert, 1993) for a
detailed description of EL.
</bodyText>
<figure confidence="0.959267818181818">
❆P❚❚❣: P■▲❋❣:
S[full-decl]
✕P(decl (past (The ①:[① spy]
(The ②:[② cop]
(The ③:[③ P][①((adv-a (with-instr ③))
(watch ②))])))))
S PUNC[tell]
NP VP
DET N V[past,_NP] NP ADVL[post-VP]
The spy watched
the
</figure>
<bodyText confidence="0.9899096">
We show here analysis ❆P❚❚❣ and leave
❆P❚❚✵❣, the analysis in which the prepositional
phrase attaches lower to the second NP, to the
reader. As we will see, the cognitive architecture
allows structural information, lexical factors and se-
mantic biases to be used for on-line pruning of alter-
native parses, thus keeping the lid on the explosion
of alternatives, and allowing human-like parsing be-
havior.2
For sentence (1) at point g, the semantic inter-
preter uses the semantic annotations associated
with each syntactic rule in the grammar and applies
compositional semantic interpretation rules to come
up with the parameterized unscoped logical form
P❯▲❋❣.
</bodyText>
<equation confidence="0.5038515">
P❯▲❋❣:
✕P(decl [(The ①:[① spy])
((adv-a (with-instr (The ③:[③ P])))
((past watch)(The ②:[② cop])))])
</equation>
<bodyText confidence="0.999395230769231">
We assume that (i) salient referents in the current
discourse take wide scope over all other operators
in the logical form and that they are scoped within
speech act operators, (ii) tense operators are sen-
tential operators scope within speech act operators
and salient referents, (iii) tense operators take wide
scope over nonsalient definites, (iv) nonsalient def-
inites take wider scope over operators, and finally
(v) existentials are scoped within all other operators
in the logical form.
Using the above-mentioned heuristics on
P■▲❋❣, the incremental scoper generates the
following parameterized indexical logical form:
</bodyText>
<footnote confidence="0.8345465">
2As revealed by garden path phenomena and other psy-
cholinguistic evidence.
</footnote>
<bodyText confidence="0.995688">
If we propose semantic representations that are
complete for the partial parse trees during incre-
mental processing, we can use a slightly different
version of the algorithm developed by Hwang and
Schubert for incremental deindexing.3
The incremental deindexer yields the parameter-
ized episodic logical form P❊▲❋❣.
</bodyText>
<equation confidence="0.980926538461538">
P❊▲❋❣:
✕P(l✉✶:[[✉✶ same-time ◆♦✇✶] n [✉✵ precedes ✉✶]]
[[Speaker tell Hearer (That
(l❡✶:[[❡✶ before ✉✶] n [❡✵ orients ❡✶]]
[[(The ①:[① spy]
(The ②:[② cop]
(The ③:[③ P]
[[① I ❡✶]
((with-instr ③)
(watch ②))]
)))]
** ❡✶]))]
** ✉✶])
</equation>
<bodyText confidence="0.999906217391304">
The relation ♦r✐❡♥ts introduced in P❊▲❋❣ corre-
sponds to a relation to be further particularized to a
temporal, causal or part-of relation between situa-
tions. ◆♦✇✶ corresponds to a term that refers to the
speech time of the utterance. Speaker and Hearer
stand for the speaker and the hearer of the utterance,
respectively. ❡o corresponds to a prior episode de-
scribed by the utterance situation ✉o. ✉o immedi-
ately precedes the utterance situation ✉l. ❡l is the
situation being described by ✉l and occurs at about
the same time as ✉l. That is a sentence nominal-
ization operator that takes a sentence as argument
and gives rise to a proposition-denoting term. The
expression [[① ❥ ❡l] (with-instr) ③] corresponds to
the action of the spy&apos;s watching modified so as to be
performed with something. The function ❥ is a pair-
ing function applicable to individuals and tuples.
Thus [① ❥ ❡l] is the action performed by ① that gives
rise to event ❡l. The operator ✖ is a metalogical op-
erator that corresponds to the operator coextensive-
part-of in EL. The expression ❡2 ✖ ❡l indicates that
situation ❡2 is coextensive with situation ❡l, that is,
❡l and ❡2 have the same spatiotemporal location.
</bodyText>
<footnote confidence="0.985218">
3The reader is referred to (Hwang and Schubert, 1992) for
details on the nonincremental deindexing rules.
</footnote>
<figure confidence="0.9591848">
PP[a-mod]
DET N
DET N
the cop P NP
with
</figure>
<bodyText confidence="0.998488153846154">
Once the parameterized episodic logical form has
been generated, the incremental deindexer trans-
forms the lambda expressions that abstract over the
parameters introduced by the incremental seman-
tic interpreter into episodic logical forms. To this
end, constants are introduced for the metalogical pa-
rameters. These constants stand for parameterized
terms and predicates in the resulting episodic logical
form. A-conversion is then performed for each one
of the A-expressions in the parameterized episodic
logical form.
Applying this procedure, the incremental dein-
dexer yields the episodic logical form ELT❣.
</bodyText>
<equation confidence="0.894226307692308">
ELT❣:
(✾✉✶:[[✉✶ same-time ◆♦✇✶] ❫ [✉✵ precedes ✉✶]]
[[Speaker tell Hearer (That
(✾❡✶:[[❡✶ before ✉✶] ❫ [❡✵ orients ❡✶]]
[[(The ①:[① spy]
(The ②:[② cop]
(The ③:[③ P]
[[① ❥ ❡✶]
[((with-instr ③)
(watch ②))]]
)))]
✄✄ ❡✶]))]
✄✄ ✉✶])
</equation>
<bodyText confidence="0.91465875">
Applying the same procedure for the competing
analysis, we obtain the following episodic logical
form ELTI❣.
ELTI❣:
</bodyText>
<equation confidence="0.966232454545455">
(✾✉✶:[[✉✶ same-time ◆♦✇✶] ❫
[✉✵ immediately-precedes ✉✶]]
[[Speaker tell Hearer (That
(✾❡✶:[[❡✶ before ✉✶] ❫ [❡✵ orients ❡✶]]
[[(The ①:[① spy]
(The ②:[② cop]
(The ③:[[③ revolver] ❫
[③ P]]
[① watch ②])))]
✄✄ ❡✶]))]
✄✄ ✉✶])
</equation>
<sectionHeader confidence="0.660405" genericHeader="method">
4 Expressing meaning postulates and
world knowledge
</sectionHeader>
<bodyText confidence="0.997943">
World knowledge in EPILOG, EL&apos;s implementa-
tion (Schaeffer et al., 1991), is expressed in form of
unreliable generalizations using probabilistic condi-
tionals of form 0 !♣❀☛✶❀✿✿✿❀☛n V, where a✶� ... �a♥
are controlled variables and p is a statistical prob-
ability (Bacchus, 1990). Different choices of con-
trolled variables lead lead to different readings. An
axiom of the form 0 !♣ V says that in at least (100)
x p % of the situations in which 0 is true, V will
also be true. It is assumed that in axioms of the form
0 !♣ ☛✶ - ☛n V the list of controlled variables in-
cludes all existentially quantified variables in the an-
tecedent that occur anaphorically in the consequent.
</bodyText>
<subsectionHeader confidence="0.527774">
4.1 Meaning postulates about unlocated
</subsectionHeader>
<equation confidence="0.891296894736842">
formulas
▼P 1: (✽❡✶ [[[✣ ❫ ✥] ✄✄ ❡✶] ✦
[✣ ❫ (✾❡✷:[❡✷ ✖ ❡✶][✥ ✄✄ ❡✷])]])
4.2 Meaning postulates about seeing objects
MP 2: If a person watches a thing, then that per-
son sees that thing.
(✾①:[① person]
(✾②:[② thing]
(✾❡✶:[① watch ②] ✄✄ ❡✶))) ✦❡✶❀❡✷
(✾❡✷:[❡✶ ✖ ❡✷][[① see ②] ✄✄ ❡✷])
MP 3: If a person watches an object or a per-
son with something, then that thing is a
viewing instrument.
(✾①:[① person]
(✾②:[② thing](✾③:[③ object]
(✾❡✶:[[① ❥ ❡✶] ((with-instr ③) (watch ②))] ✄✄ ❡✶])))
✦❡✶❀❡✷❀③
(✾❡✷[❡✷ ✖ ❡✶]
[③ = (K (nn viewing) instrument)] ✄✄ ❡✷)
</equation>
<listItem confidence="0.4033398">
4.3 World knowledge axioms about seeing
objects
WK 1: If someone sees something with a viewing
instrument, then she/he probably sees it
clearly.
</listItem>
<equation confidence="0.995073222222222">
(✾①:[① person]
(✾②:[② thing]
(✾❡✶:[[① ❥ ❡✶] ((with-instr
(❑ viewing-instrument))
(see ②))]
✄✄ ❡✶])) ✦✵✿✽❀❡✶❀❡✷
(✾❡✷:[❡✶ ✖ ❡✷]
[[① ❥ ❡✷] ((in-manner clear) (see ②))]
✄✄ ❡✷)
</equation>
<sectionHeader confidence="0.856718" genericHeader="method">
5 The cognitive architecture
</sectionHeader>
<bodyText confidence="0.999947892857143">
The model of incremental semantic interpretation,
scoping, and deindexing described in the previous
sections enables us to transform a partially anno-
tated parse tree into an episodic logical form suit-
able for inference. Using the procedure above, we
are in a position to integrate syntactic and semantic
information, referential context, and world knowl-
edge in the calculation of plausibility for each anal-
ysis.
A naive approach to incremental interpretation
would consist in exploiting this model to arrive at
an episodic logical form and then consider all alter-
native equally plausible. We regard this alternative
as implausible on the grounds of psycholinguistic
results on control processes of inference in on-line
text comprehension (Balota, Flores d&apos;Arcais, and
Rayner, 1990). As we will see, the model of incre-
mental interpretation proposed is based on a multi-
agent cognitive architecture in which agents are as-
signed competing interpretations.
Central to the architecture is the concept of agent
reward. A reward function is calculated for each
agent, each one of them representing an analysis. In
general, the alignment between user utility function
and agent reward function is one of the areas that is
domain-dependent in this architecture. We will ex-
plore this alignment for our domain in the following
sections.
</bodyText>
<subsectionHeader confidence="0.96382">
5.1 Value alignment
</subsectionHeader>
<bodyText confidence="0.999954130434783">
In general, the objective of each agent is to maxi-
mize its reward function. How well they optimize
the user utility function will depend on the align-
ment between the user utility function and the agent
reward function.
Notice that, in our domain, there is a disconnect
between the objectives of the agent and those of the
user, respectively. The agent commits to an analy-
sis and in so doing its fate is already sealed. How
well they end up optimizing the user utility function
will depend on variables the agent can only partially
control as this process ultimately depends on the in-
formation not yet absorbed from the input string and
on the behavior of the other agents in the architec-
ture.
The interesting point to note here is that although
this might at first glance appear as an undesirable
feature of the architecture, it actually leads to a
model in which the different agents cooperate to-
wards the ultimate goal of optimizing the user util-
ity function. Thus, instead of competing analyses
we might as well refer to them as co-operating anal-
yses.
</bodyText>
<subsectionHeader confidence="0.980828">
5.2 Agent reward function
</subsectionHeader>
<bodyText confidence="0.989337">
Reward functions for the agents are defined based
on the principle of positive reinforcement.
</bodyText>
<subsubsectionHeader confidence="0.729489">
5.2.1 Positive reinforcement principle
</subsubsectionHeader>
<bodyText confidence="0.9992736">
An analysis is preferred over another to the extent
that it satisfies the constraints of its immediate ref-
erential context and to the extent that the inferences
triggered in the knowledge base are more consistent,
more specific and more numerous.
</bodyText>
<subsubsectionHeader confidence="0.654731">
5.2.2 Heuristics
</subsubsectionHeader>
<bodyText confidence="0.998576333333333">
Based on the principle, our model uses the fol-
lowing sets of heuristics for assigning a reward
function to agents:
</bodyText>
<listItem confidence="0.974834666666667">
1. Give referential context highest precedence;
2. Give consistency of inferences drawn in the
knowledge base precedence over specificity of
inferences drawn in the knowledge base;
3. Give specificity of inferences drawn in the
knowledge base preference over subcatego-
rization information;
4. Give subcategorization information prece-
dence over the amount of inferences drawn in
the knowledge base, and
5. Consider only inferences with a minimum
level of interestingness.4
</listItem>
<bodyText confidence="0.999905230769231">
The list above is not exhaustive, but it gives us an
initial set of heuristics to define the reward func-
tion for the agents. The choice of some precedences
in the heuristics above has been psycholinguisti-
cally motivated, as shown in (Altmann and Steed-
man, 1988).5 The approach to interpretation fol-
lowed here is based on the assumption that informa-
tion from different sources enters the interpretation
process at different times and that they concurrently
restrain the number of potential analyses, as sug-
gested in recent psycholinguistic theories of human
sentence comprehension (Spivey-Knowlton and Se-
divy, 1995).
</bodyText>
<subsectionHeader confidence="0.935282">
5.3 Interpretation as learning
</subsectionHeader>
<bodyText confidence="0.999737857142857">
The process of finding a preferred interpretation at
a given time t, is the result of a process of entropy
reversal through information expressed in terms of
a set of heuristics that govern the agent reward in
this cognitive architecture. The heuristics above are
a distillation of the information required for this en-
tropy reversal process.
</bodyText>
<footnote confidence="0.953773428571429">
4With interestingness measured as a threshold on the con-
ditional probability that results in an inference chain through
world knowledge axioms expressed as probabilistic condition-
als (Bacchus, 1990).
5Altmann and Steedman dealt with referential context only.
To our knowledge, there is no psycholinguistic studies that give
us a more complete picture on the precedences stated above.
</footnote>
<subsectionHeader confidence="0.729311">
5.4 An example
</subsectionHeader>
<bodyText confidence="0.9582735">
Let us illustrate the process of agent-based interpre-
tation using our example. When processing sen-
tence (1) up to point g, we do have two analyses.
Skolemizing El=el, E2=e2, E3=e3, E4=e4,
E5=e5, Ul=ul, X=y, Y=y and Z=z, the set of
inferences drawn at point g is as follows:
</bodyText>
<equation confidence="0.9875964">
Agent1:
❋l [❊l before ❯l]
❋2 [[[[X I ❊l] (with-instr Z)] n [X watch Y]] ** ❊l]
❋3 [X spy]
❋4 [Y cop]
❋5 [❊2 � ❊l]
❋6 [[X watch Y] ** ❊2]
❋7 [[Z = (K ((nn viewing) instrument))]
❋8 [❊l � ❊3]
❋9 [[[[X I ❊3] (with-instr P)] n [X see Y]] ** ❊3]
</equation>
<bodyText confidence="0.99985125">
Facts Fl through F4 are directly obtained in the
knowledge base by asserting SLT❣ after splitting
conjunctions and top-level skolemization is per-
formed on SLT❣. El is a situation fully described
by the action of the spy watching the cop and being
modified so as to be performed with &amp;quot;something.&amp;quot;
Facts F5 and F6 are directly obtained by meaning
postulate MP 1. E2, co-extensive with El, is fully
described by the action of the spy watching the cop.
MP 3 accounts for triggering fact F7, thus setting
the expectation in Agent1&apos;s discourse model that the
incoming referent is a viewing instrument. Facts F8
and F9 are obtained using meaning postulate MP
2. E3, co-extensive with El, is fully described by the
action of the spy seeing the cop with &amp;quot;something.&amp;quot;
Notice that using facts F7 and F9 and world knowl-
edge axiom WK 1, we would also be setting the un-
certain prediction that the spy sees the cop clearly.
For our second agent, we would have the follow-
ing set of inferences in the knowledge base:
</bodyText>
<equation confidence="0.630216333333333">
Agent2:
❋l [❊l before ❯l]
❋2 [X spy]
❋3 [Y cop]
❋4 [Y with-attrib Z]
❋5 [[[X watch Y]] ** ❊l]
</equation>
<bodyText confidence="0.9988965">
fully described by the action of the spy watching a
cop carrying &amp;quot;something.&amp;quot;
</bodyText>
<subsubsectionHeader confidence="0.369589">
5.4.1 Positive reinforcement: Scenario 1
</subsubsectionHeader>
<bodyText confidence="0.999686466666667">
In this first scenario, we assume that the discourse
model is initially empty. Applying our positive re-
inforcement principle at point g, Agent1 is the most
plausible one. The verb to watch subcategorizes for
an instrumental argument and the analysis pursued
by Agent1 is initially preferred. This analysis also
leads to more inferences in the knowledge base, in-
cluding the certain prediction that the incoming NP
introduces a viewing instrument in Agent1&apos;s dis-
course model and the uncertain prediction that the
spy sees the cop clearly. Referential context does
not play a role yet since there were no discourse ref-
erents introduced initially under this scenario.
The analysis pursued up to point h by Agent1 is
shown in PPT❤.
</bodyText>
<figure confidence="0.977703619047619">
PPT❤:
S[full-decl]
S PUNC[tell]
NP VP
DET N V[past,_NP] NP ADVL[post-VP]
The spy watched
DET N
the cop P NP
with
DET N
the
N PP
revolver
At point h, we obtain SLT❤:
SLT❤:
(l✉l:[[✉l same-time ◆♦✇✶] n
[✉o immediately-precedes ✉l]]
[[Speaker tell Hearer (That
(l❡l:[[❡l before ✉l] n [❡o orients ❡l]]
[[(The ①:[① spy]
(The ②:[② cop]
</figure>
<equation confidence="0.871810714285714">
(The ③:[[③ revolver] n
[③ P]]
[[① I ❡l]
[((with-instr ③)
(watch ②)
PP[a-mod]
)]])))]
</equation>
<bodyText confidence="0.9944636">
Facts Fl to F5 are directly obtained in the knowl- ** ❡l]))]
edge base by asserting SLTI❣. El is a situation ** ✉l])
After asserting SLTh and using type-hierarchical
knowledge, the following additional facts can be
triggered in Agentl&apos;s discourse model:
</bodyText>
<equation confidence="0.65362275">
Agentl:
F✶✵ [Z revolver]
F✶✶ [Z weapon]
F✶✷ [Z instrument]
</equation>
<bodyText confidence="0.976633909090909">
Fact F✼ is inconsistent with facts F✶✵ through F✶✶
above. Thus, by a process of &amp;quot;hierarchy climbing&amp;quot;
in the knowledge base, it turns out that the variable
z introduced in SLTh is not subsumed by a generic
term denoting a viewing instrument in the knowl-
edge base, as expected at point g. By our positive
reinforcement heuristics at point h, this analysis is
not positively reinforced. It turns out to be inconsis-
tent with Agentl&apos;s prior referential context.
Agent2&apos;s discourse model at point h has led to
the following discourse model:
</bodyText>
<equation confidence="0.953687714285714">
Agent2:
F✶ [E✶ before U✶]
F✷ [X spy]
F✸ [Y cop]
F✹ [Z revolver]
F✺ [[[X watch Y]] ** E✶]
F✻ [Y with-attrib Z]
</equation>
<bodyText confidence="0.999757888888889">
Using our heuristics, the analysis preferred under
this first scenario turns out to be the one pursued
by the second agent. Notice that the agent-based
cognitive architecture will get &amp;quot;garden-pathed&amp;quot;
as the analysis initially preferred on the grounds
of subcategorization information and specificity
and interestingness of the inferences drawn in the
knowledge base proves anomalous by referential
context.
</bodyText>
<subsectionHeader confidence="0.449989">
5.4.2 Positive reinforcement: Scenario 2
</subsectionHeader>
<bodyText confidence="0.999734783783784">
In this second scenario, we assume the discourse
model initially consisting of three referents, a spy
and two cops.
Applying our positive reinforcement principle at
point g for Agentl, we have that the verb to watch
subcategorizes for an instrumental argument and the
analysis pursued by Agentl would be initially pre-
ferred based on subcategorization information for
this verb. Agentl would also get positively re-
inforced since its interpretation leads to more in-
ferences in the knowledge base and to make the
certain prediction that the incoming NP introduces
a viewing instrument and the uncertain prediction
that the spy sees the cop clearly in Agentl&apos;s dis-
course model, as we have already seen. But accord-
ing to our set of heuristics, referential context pre-
empts these preferences, as the need to resolve the
anaphoric reference the cop in the discourse model
immediately preceding sentence (1) takes prece-
dence over the other criteria at point g. The analysis
pursued by Agentl does not contribute to resolving
this anaphoric reference.
On the other hand, the analysis pursued by
Agent2 at point g raises the expectation that the cop
will be further &amp;quot;particularized&amp;quot; so as to resolve this
anaphoric reference. Given the heuristics, this ex-
pectation takes precedence over Agentl&apos;s interpre-
tation and is preferred in this cognitive architecture.
It is interesting to note that in this second scenario,
subjects are not being led down the garden path
when given the referential context in which the need
for resolving the anaphoric reference introduced by
the second NP arses at point g. Our model predicts
this behavior accordingly.
At point i, the analysis pursued by Agent 2 is the
preferred one. The resulting episodic logical form
at point i is SLTi, as shown below.
</bodyText>
<figure confidence="0.78755115">
SLTi:
(la✶:[[a✶ same-time Now✶] n
[a✵ immediately-precedes a✶]]
[[Speaker tell Hearer (That
(le✶:[[e✶ before a✶] n [e✵ orients e✶]]
[[(The x:[x spy]
(The y:[[y cop] n
(The z:[z revolver]
[y with-attrib z])]
[x watch y]))]
** e✶]))]
** a✶])
SLTi leads to the following discourse model.
Agent2:
F✶ [E✶ before U✶]
F✷ [X cop]
F✸ [Y spy]
F✹ [Z revolver]
F✺ [Y with-attrib Z]
F✻ [[X watch Y]] ** E✶]
</figure>
<sectionHeader confidence="0.964739" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999991177777778">
The work presented in this article puts forth an ap-
proach to interpretation using a cognitive architec-
ture for intelligent behavior. Our work has so far
consisted in defining agent reward based on the pos-
itive reinforcement principle. For the initial im-
plementation of the principle, we have followed a
heuristics-based approach.
Though some of the information used in the
plausibility computation is probabilistic (Bacchus,
1990), the heuristics are non-probabilistic in our
model. In defining the heuristics, we have incor-
porated recent results in psycholinguistic studies of
human sentence processing. In our view of the
interpretation process, agents contribute to arriv-
ing at a &amp;quot;preferred&amp;quot; interpretation by maintaining
a &amp;quot;more plausible&amp;quot; analysis—and its associated dis-
course model—as the most salient one, while other
less plausible analyses are kept in memory for a
given period of time by other agents. By a pro-
cess of heuristics-based plausibility computation,
the &amp;quot;most plausible analysis&amp;quot; remain active in this
architecture and take the lead during the interpreta-
tion process.
This cognitive architecture gives a plausible ac-
count of some of the issues that pervade human sen-
tence processing such as garden-path phenomena.
In so doing, we depart from serial first-analysis ap-
proaches to sentence comprehension in the tradition
of the garden-path theory of sentence processing
(Frazier and Fodor, 1978; Frazier and Clifton, 1996)
and endorse more recent psycholinguistic accounts
of this problem which view the interpretation pro-
cess as a concurrent negotiation of information from
syntactic, semantic and pragmatic sources by sev-
eral agents (Spivey-Knowlton and Sedivy, 1995).
We also aim to bridge the gap between models
of interpretation in the tradition of the garden-path
theory, which are related to symbolic approaches to
NLP, and subsymbolic approaches in the tradition of
parallel theories of sentence processing. Our model
benefits from the &amp;quot;niceties&amp;quot; of the former approach
to arrive at semantic and knowledge representations
for alternative analyses while also leveraging a cog-
nitive architecture that is suited to implement a par-
allel approach to interpretation.
</bodyText>
<sectionHeader confidence="0.996779" genericHeader="discussions">
7 Future work
</sectionHeader>
<bodyText confidence="0.999824153846154">
Our future work will focus on studying the role
agents will have in learning or refining new heuris-
tics. As a matter of fact, we believe that the archi-
tecture is well-suited to mine the context-sensitive
information that makes an analysis more plausible
than another in a given discourse situation. We see
this as a machine learning process by which agents
contribute to the common goal of &amp;quot;entropy rever-
sal&amp;quot; by learning new heuristics and applying them
during the incremental interpretation process.
Another aspect we will be focusing on in future
work is a process we call &amp;quot;signaling,&amp;quot; which we
shall illustrate using sentence (2):
</bodyText>
<listItem confidence="0.494282">
(2) Every ten minutes a man gets mugged in New York.
</listItem>
<bodyText confidence="0.752534">
Based on our interpretation algorithm, the most
plausible analysis would be the one with the
following representation.
Agent]:
SLT:
</bodyText>
<equation confidence="0.6910217">
(✾e:[[e ((attr periodic)(plur episode))] ❫
(✽ e✵ :[[e✵ member-of e]
[[(period-of e✵) = (K ((num 10)
(plur minute)))] ❫
✻(✾e✵✵:[[e✵✵ 0 e✵] ❫ [e✵✵ overlap e✵]]) ❫
[e✵ in-loc New York] ❫
(✾x:[x person]
(✾y:[y man][x mug y]))]
✄✄ e✵])
✄✄ e])
</equation>
<bodyText confidence="0.997332153846154">
In the absence of any referential context that might
indicate otherwise, our model does assign narrow
scope to the existentially quantified expression in-
troducing &amp;quot;a man&amp;quot; in the discourse model. Apply-
ing the heuristics, Agent] carries the most plausible
interpretation in which there is an episode e consist-
ing of a collection of periodically, non-overlapping
subepisodes e0, each one of them introducing a dif-
ferent individual getting mugged in New York, none
of whom is salient in the immediate referential con-
text in which sentence (2) is uttered.
Suppose that this fragment continues with sen-
tence (3):
</bodyText>
<listItem confidence="0.65457">
(3) We are in New York today to interview him.
</listItem>
<bodyText confidence="0.999960666666666">
As a result, our cognitive architecture gets &amp;quot;jungle-
pathed&amp;quot; after processing sentence (3). In this case,
Agent] is forced to come up with a single salient
referent in its discourse model, corresponding to the
poor individual who gets mugged every ten minutes
in New York. Agent] is unable to provide such a
referent.
By a process of signaling, agents cannot only be
leveraged to keep a given analysis and correspond-
ing interpretation active in memory for a given pe-
riod of time, but also to &amp;quot;send&amp;quot; information, includ-
ing referents, to other agents that might &amp;quot;request&amp;quot;
this information during their own interpretation pro-
cess. We will be studying how this signaling process
can be used to resolve anaphoric references and en-
sure discourse coherence. Our approach will consist
in implementing Schubert&apos;s dynamic skolemization
mechanism using this cognitive architecture.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998115">
Many thanks to Pat Langley for discussions on ear-
lier versions of this paper, to Dan Shapiro for dis-
cussions on value alignment theory, and to Len
Schubert for his continuous support teaching me
EL.
</bodyText>
<sectionHeader confidence="0.999108" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988046930232558">
Altmann, G. and M. Steedman. 1988. Interaction
with context during human sentence processing.
Cognition, 30:191238.
Anderson, J. R. 1993. Rules of the Mind.
Lawrence-Erlbaum, Hillsdale, NJ.
Bacchus, F. 1990. Representing and Reasoning
with Probabilistic Knowledge. MIT Press, Cam-
bridge, MA.
Balota, D.A., G.B. Flores d&apos;Arcais, and K. Rayner.
1990. Comprehension Processes in Reading.
Lawrence Erlbaum Associates, Hillsdale, NJ.
Frazier, L. and C. Clifton. 1996. Construal. MIT
Press, Cambridge, MA.
Frazier, L. and J. A. Fodor. 1978. The sausage ma-
chine: A new two-stage parsing model. Cogni-
tion, 6:291325.
Hwang, C.H. and L.K. Schubert. 1992. Tense trees
as the fine structure of discourse. In Proceed-
ings of the 30t❤ Annual Meeting of the American
Association for Computational Linguistics, pages
232240.
Hwang, C.H. and L.K. Schubert. 1993. Episodic
logic, a comprehensive, natural representation for
language understanding. Minds and Machines,
3:381419.
Laird, J. E., editor, 1991. Integrated cognitive ar-
chitectures, volume 2 (4) of SIGART Bulletin,
pages 12184. ACM.
Laird, J. E., A. Newell, and P.S. Rosenbloom. 1987.
Soar: An architecture for general intelligence.
Arti�cial Intelligence, 33:164.
Langley, P., D. Shapiro, M. Aycinena, and
M. Siliski. 2003. A value-driven architecture for
intelligent behavior. In Proceedings of the IJCAI-
2003 Workshop on Cognitive Modeling ofAgents
and Multi-Agent Interactions, pages 1018.
Schaeffer, S., C.H. Hwang, J. de Haan, and L.K.
Schubert. 1991. EPILOG: The computational
system for episodic logic. Technical report, Uni-
versity of Alberta, Edmonton.
Spivey-Knowlton, M.J. and J.C. Sedivy. 1995.
Resolving attachment ambiguities with multiple
constraints. Cognition, 55:227267.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000106">
<title confidence="0.999711">Interpretation in a Cognitive Architecture</title>
<author confidence="0.995755">Harold</author>
<affiliation confidence="0.999395">Center for the Study of Language and</affiliation>
<address confidence="0.9969385">Cordura Hall, Stanford Stanford, CA 94305,</address>
<email confidence="0.999642">harold.paredes-frigolett@csli.stanford.edu</email>
<abstract confidence="0.961363947368421">The work reported in this article presents a computational model of interpretation. The model proposes a cognitive architecture for intelligent agents to reason about competing analyses during interpretation and leverages the positive reinforcement principle. 1 Motivation Interpretation of natural language involve the computational effort associated with repeatedly computing, interpreting and deindexing logical forms for ambiguous parses. In our view, interpretation can be construed as a negotiation process whereby lexical, structural, semantic, common-sense and world knowledge information and referential context are used to assign plausibilities to competing analyses. The approach to interpretation taken here has been motivated by cognitive architectures for intelligent agents in the tradition of SOAR (Laird, Newell, and Rosenbloom, 1987; Laird, 1991), (Anderson, 1993) and et al., 2003). In extending cognitive architectures in this tradition to deal with the problem of interpretation, agents carry both the meaning of competing analyses and the plausibilities associated with them, which we construe as the reward function of the agents. As more information becomes available from the input string, reward functions are updated and the analysis with the higher plausibility becomes the preferred interpretation. 2 The grammar formalism Consider sentence (1): spywatchedthecopwith revolver The GPSG-like grammar fragment with semantic in a seman- DET[def]</abstract>
<title confidence="0.936027">N N N N PP ; NP ; P[with-attrib] P[with-instr]</title>
<author confidence="0.404657">N NP</author>
<affiliation confidence="0.4023435">PP NP ; NP&apos;) V[past,</affiliation>
<abstract confidence="0.992683411650487">ADVL[post-VP] ; PP&apos;) VP NP ; NP&apos;) VP ADVL[a-mod] ; S VP ; VP&apos;] PUNC[tell] ; S PUNC[tell] ; S&apos;) 1: grammar fragment tic and knowledge representation language for general NLU (Hwang and Schubert, 1993), is shown in 3 Semantic analysis For sentence (1) the parser computes two initial analyses using not only structural, but also subcategorization and thematic role information as soon as the verb is encountered. point we could be already predicting several of the possible continuations. Based on subcategorization and thematic role information for the verb there is a first analysis that results from applying rule N of our GPSG-like grammar fragment. point the first analysis is refer the reader to (Hwang and Schubert, 1993) for a detailed description of EL. S[full-decl] (past (The (with-instr S PUNC[tell] NP VP N NP ADVL[post-VP] The spy watched the show here analysis leave the analysis in which the prepositional phrase attaches lower to the second NP, to the reader. As we will see, the cognitive architecture allows structural information, lexical factors and semantic biases to be used for on-line pruning of alternative parses, thus keeping the lid on the explosion of alternatives, and allowing human-like parsing besentence (1) at point the semantic interpreter uses the semantic annotations associated with each syntactic rule in the grammar and applies compositional semantic interpretation rules to come up with the parameterized unscoped logical form (with-instr We assume that (i) salient referents in the current discourse take wide scope over all other operators in the logical form and that they are scoped within speech act operators, (ii) tense operators are sentential operators scope within speech act operators and salient referents, (iii) tense operators take wide scope over nonsalient definites, (iv) nonsalient definites take wider scope over operators, and finally (v) existentials are scoped within all other operators in the logical form. Using the above-mentioned heuristics on the incremental scoper generates the following parameterized indexical logical form: revealed by garden path phenomena and other psycholinguistic evidence. If we propose semantic representations that are complete for the partial parse trees during incremental processing, we can use a slightly different version of the algorithm developed by Hwang and for incremental The incremental deindexer yields the parameterepisodic logical form [[Speaker tell Hearer (That )))] relation in corresponds to a relation to be further particularized to a causal or between situato a term that refers to the time of the utterance. stand for the speaker and the hearer of the utterance, to a prior episode deby the utterance situation immediprecedes the utterance situation the being described by occurs at about same time as a sentence nominalization operator that takes a sentence as argument and gives rise to a proposition-denoting term. The ❥ corresponds to the action of the spy&apos;s watching modified so as to be with something. The function a pairing function applicable to individuals and tuples. ❥ is the action performed by gives to event The operator a metalogical opthat corresponds to the operator coextensive- EL. The expression that coextensive with situation that is, the same spatiotemporal location. reader is referred to (Hwang and Schubert, 1992) for details on the nonincremental deindexing rules. PP[a-mod] DET N DET N the cop P NP with Once the parameterized episodic logical form has been generated, the incremental deindexer transforms the lambda expressions that abstract over the parameters introduced by the incremental semantic interpreter into episodic logical forms. To this end, constants are introduced for the metalogical parameters. These constants stand for parameterized terms and predicates in the resulting episodic logical is then performed for each one the in the parameterized episodic logical form. Applying this procedure, the incremental deinyields the episodic logical form [[Speaker tell Hearer (That ❥ )))] Applying the same procedure for the competing analysis, we obtain the following episodic logical [[Speaker tell Hearer (That 4 Expressing meaning postulates and world knowledge World knowledge in EPILOG, EL&apos;s implementation (Schaeffer et al., 1991), is expressed in form of unreliable generalizations using probabilistic condiof form where ... controlled variables and a statistical probability (Bacchus, 1990). Different choices of controlled variables lead lead to different readings. An of the form that in at least (100) of the situations in which true, also be true. It is assumed that in axioms of the form list of controlled variables inexistentially quantified variables in the antecedent that occur anaphorically in the consequent. 4.1 Meaning postulates about unlocated formulas ❫ ❫ ✄✄ 4.2 Meaning postulates about seeing objects MP 2: If a person watches a thing, then that person sees that thing. MP 3: If a person watches an object or a person with something, then that thing is a viewing instrument. ❥ ((with-instr (watch (K (nn viewing) instrument)] 4.3 World knowledge axioms about seeing objects If someone sees something with a viewing instrument, then she/he probably sees it clearly. ❥ ((with-instr ❥ ((in-manner clear) (see 5 The cognitive architecture The model of incremental semantic interpretation, scoping, and deindexing described in the previous sections enables us to transform a partially annotated parse tree into an episodic logical form suitable for inference. Using the procedure above, we are in a position to integrate syntactic and semantic information, referential context, and world knowledge in the calculation of plausibility for each analysis. A naive approach to incremental interpretation would consist in exploiting this model to arrive at an episodic logical form and then consider all alternative equally plausible. We regard this alternative as implausible on the grounds of psycholinguistic results on control processes of inference in on-line text comprehension (Balota, Flores d&apos;Arcais, and Rayner, 1990). As we will see, the model of incremental interpretation proposed is based on a multiagent cognitive architecture in which agents are assigned competing interpretations. Central to the architecture is the concept of agent reward. A reward function is calculated for each agent, each one of them representing an analysis. In general, the alignment between user utility function and agent reward function is one of the areas that is domain-dependent in this architecture. We will explore this alignment for our domain in the following sections. 5.1 Value alignment In general, the objective of each agent is to maximize its reward function. How well they optimize the user utility function will depend on the alignment between the user utility function and the agent reward function. Notice that, in our domain, there is a disconnect between the objectives of the agent and those of the user, respectively. The agent commits to an analysis and in so doing its fate is already sealed. How well they end up optimizing the user utility function will depend on variables the agent can only partially control as this process ultimately depends on the information not yet absorbed from the input string and on the behavior of the other agents in the architecture. The interesting point to note here is that although this might at first glance appear as an undesirable feature of the architecture, it actually leads to a model in which the different agents cooperate towards the ultimate goal of optimizing the user utility function. Thus, instead of competing analyses we might as well refer to them as co-operating analyses. 5.2 Agent reward function Reward functions for the agents are defined based on the principle of positive reinforcement. 5.2.1 Positive reinforcement principle An analysis is preferred over another to the extent it satisfies the constraints of its immediate referential context and to the extent that the inferences triggered in the knowledge base are more consistent, more specific and more numerous. 5.2.2 Heuristics Based on the principle, our model uses the following sets of heuristics for assigning a reward function to agents: 1. Give referential context highest precedence; 2. Give consistency of inferences drawn in the knowledge base precedence over specificity of inferences drawn in the knowledge base; 3. Give specificity of inferences drawn in the knowledge base preference over subcategorization information; 4. Give subcategorization information precedence over the amount of inferences drawn in the knowledge base, and 5. Consider only inferences with a minimum of The list above is not exhaustive, but it gives us an initial set of heuristics to define the reward function for the agents. The choice of some precedences in the heuristics above has been psycholinguistically motivated, as shown in (Altmann and Steedapproach to interpretation followed here is based on the assumption that information from different sources enters the interpretation process at different times and that they concurrently restrain the number of potential analyses, as suggested in recent psycholinguistic theories of human sentence comprehension (Spivey-Knowlton and Sedivy, 1995). 5.3 Interpretation as learning The process of finding a preferred interpretation at given time the result of a process of entropy reversal through information expressed in terms of a set of heuristics that govern the agent reward in this cognitive architecture. The heuristics above are a distillation of the information required for this entropy reversal process. interestingness measured as a threshold on the conditional probability that results in an inference chain through world knowledge axioms expressed as probabilistic conditionals (Bacchus, 1990). and Steedman dealt with referential context only. To our knowledge, there is no psycholinguistic studies that give us a more complete picture on the precedences stated above. 5.4 An example Let us illustrate the process of agent-based interpretation using our example. When processing sen- (1) up to point we do have two analyses. the set of drawn at point as follows: Agent1: (with-instr Z)] watch Y]] spy] cop] watch Y] = (K ((nn viewing) instrument))] (with-instr P)] see Y]] directly obtained in the base by asserting splitting conjunctions and top-level skolemization is peron a situation fully described by the action of the spy watching the cop and being modified so as to be performed with &amp;quot;something.&amp;quot; directly obtained by meaning co-extensive with is fully described by the action of the spy watching the cop. for triggering fact thus setting expectation in discourse model that the referent is a viewing instrument. Facts obtained using meaning postulate co-extensive with is fully described by the action of the spy seeing the cop with &amp;quot;something.&amp;quot; that using facts world knowlaxiom we would also be setting the uncertain prediction that the spy sees the cop clearly. For our second agent, we would have the following set of inferences in the knowledge base: Agent2: spy] cop] with-attrib Z] watch Y]] fully described by the action of the spy watching a cop carrying &amp;quot;something.&amp;quot; 5.4.1 Positive reinforcement: Scenario 1 In this first scenario, we assume that the discourse model is initially empty. Applying our positive reprinciple at point the most one. The verb watch for an instrumental argument and the analysis pursued initially preferred. This analysis also leads to more inferences in the knowledge base, including the certain prediction that the incoming NP introduces a viewing instrument in Agent1&apos;s discourse model and the uncertain prediction that the spy sees the cop clearly. Referential context does not play a role yet since there were no discourse referents introduced initially under this scenario. analysis pursued up to point in S[full-decl] S PUNC[tell] NP VP N NP ADVL[post-VP] The spy watched DET N the cop P NP with DET N the N PP revolver point we obtain [[Speaker tell Hearer (That PP[a-mod] )]])))] directly obtained in the knowlbase by asserting a situation asserting using type-hierarchical knowledge, the following additional facts can be in discourse model: Agentl: inconsistent with facts through above. Thus, by a process of &amp;quot;hierarchy climbing&amp;quot; in the knowledge base, it turns out that the variable in not subsumed by a generic term denoting a viewing instrument in the knowlbase, as expected at point By our positive heuristics at point this analysis is not positively reinforced. It turns out to be inconsiswith prior referential context. discourse model at point led to the following discourse model: Agent2: spy] cop] revolver] watch Y]] with-attrib Z] Using our heuristics, the analysis preferred under this first scenario turns out to be the one pursued by the second agent. Notice that the agent-based cognitive architecture will get &amp;quot;garden-pathed&amp;quot; as the analysis initially preferred on the grounds of subcategorization information and specificity and interestingness of the inferences drawn in the knowledge base proves anomalous by referential context. 5.4.2 Positive reinforcement: Scenario 2 In this second scenario, we assume the discourse model initially consisting of three referents, a spy and two cops. Applying our positive reinforcement principle at we have that the verb watch subcategorizes for an instrumental argument and the pursued by be initially preferred based on subcategorization information for verb. also get positively reinforced since its interpretation leads to more inferences in the knowledge base and to make the certain prediction that the incoming NP introduces a viewing instrument and the uncertain prediction the spy sees the cop clearly in discourse model, as we have already seen. But according to our set of heuristics, referential context preempts these preferences, as the need to resolve the reference cop the discourse model immediately preceding sentence (1) takes preceover the other criteria at point The analysis by not contribute to resolving this anaphoric reference. On the other hand, the analysis pursued by point the expectation that the cop will be further &amp;quot;particularized&amp;quot; so as to resolve this anaphoric reference. Given the heuristics, this extakes precedence over interpretation and is preferred in this cognitive architecture. It is interesting to note that in this second scenario, subjects are not being led down the garden path when given the referential context in which the need for resolving the anaphoric reference introduced by second NP arses at point Our model predicts this behavior accordingly. point the analysis pursued by 2 the preferred one. The resulting episodic logical form point as shown below. [[Speaker tell Hearer (That to the following discourse model. Agent2: cop] spy] revolver] with-attrib Z] watch Y]] 6 Discussion The work presented in this article puts forth an approach to interpretation using a cognitive architecture for intelligent behavior. Our work has so far consisted in defining agent reward based on the positive reinforcement principle. For the initial implementation of the principle, we have followed a heuristics-based approach. Though some of the information used in the plausibility computation is probabilistic (Bacchus, 1990), the heuristics are non-probabilistic in our model. In defining the heuristics, we have incorporated recent results in psycholinguistic studies of human sentence processing. In our view of the interpretation process, agents contribute to arriving at a &amp;quot;preferred&amp;quot; interpretation by maintaining a &amp;quot;more plausible&amp;quot; analysis—and its associated discourse model—as the most salient one, while other less plausible analyses are kept in memory for a given period of time by other agents. By a process of heuristics-based plausibility computation, the &amp;quot;most plausible analysis&amp;quot; remain active in this architecture and take the lead during the interpretation process. This cognitive architecture gives a plausible account of some of the issues that pervade human sentence processing such as garden-path phenomena. In so doing, we depart from serial first-analysis approaches to sentence comprehension in the tradition of the garden-path theory of sentence processing (Frazier and Fodor, 1978; Frazier and Clifton, 1996) and endorse more recent psycholinguistic accounts of this problem which view the interpretation process as a concurrent negotiation of information from syntactic, semantic and pragmatic sources by several agents (Spivey-Knowlton and Sedivy, 1995). We also aim to bridge the gap between models of interpretation in the tradition of the garden-path theory, which are related to symbolic approaches to NLP, and subsymbolic approaches in the tradition of parallel theories of sentence processing. Our model benefits from the &amp;quot;niceties&amp;quot; of the former approach to arrive at semantic and knowledge representations for alternative analyses while also leveraging a cognitive architecture that is suited to implement a parallel approach to interpretation. 7 Future work Our future work will focus on studying the role agents will have in learning or refining new heuristics. As a matter of fact, we believe that the architecture is well-suited to mine the context-sensitive information that makes an analysis more plausible than another in a given discourse situation. We see this as a machine learning process by which agents contribute to the common goal of &amp;quot;entropy reversal&amp;quot; by learning new heuristics and applying them during the incremental interpretation process. Another aspect we will be focusing on in future work is a process we call &amp;quot;signaling,&amp;quot; which we shall illustrate using sentence (2): (2) Every ten minutes a man gets mugged in New York. Based on our interpretation algorithm, the most plausible analysis would be the one with the following representation. Agent]: periodic)(plur episode))] = (K ((num 10) minute)))] ❫ New York] In the absence of any referential context that might indicate otherwise, our model does assign narrow scope to the existentially quantified expression introducing &amp;quot;a man&amp;quot; in the discourse model. Applythe heuristics, the most plausible in which there is an episode consisting of a collection of periodically, non-overlapping each one of them introducing a different individual getting mugged in New York, none of whom is salient in the immediate referential context in which sentence (2) is uttered. Suppose that this fragment continues with sentence (3): (3) We are in New York today to interview him. As a result, our cognitive architecture gets &amp;quot;junglepathed&amp;quot; after processing sentence (3). In this case, forced to come up with a single salient referent in its discourse model, corresponding to the poor individual who gets mugged every ten minutes New York. unable to provide such a referent. By a process of signaling, agents cannot only be leveraged to keep a given analysis and corresponding interpretation active in memory for a given period of time, but also to &amp;quot;send&amp;quot; information, including referents, to other agents that might &amp;quot;request&amp;quot; this information during their own interpretation process. We will be studying how this signaling process can be used to resolve anaphoric references and ensure discourse coherence. Our approach will consist in implementing Schubert&apos;s dynamic skolemization mechanism using this cognitive architecture. Acknowledgments Many thanks to Pat Langley for discussions on earlier versions of this paper, to Dan Shapiro for discussions on value alignment theory, and to Len Schubert for his continuous support teaching me EL.</abstract>
<note confidence="0.94578">References Altmann, G. and M. Steedman. 1988. Interaction with context during human sentence processing. 30:191238. J. R. 1993. of the Lawrence-Erlbaum, Hillsdale, NJ. F. 1990. and Reasoning Probabilistic MIT Press, Cambridge, MA. Balota, D.A., G.B. Flores d&apos;Arcais, and K. Rayner. Processes in Lawrence Erlbaum Associates, Hillsdale, NJ. L. and C. Clifton. 1996. MIT Press, Cambridge, MA. Frazier, L. and J. A. Fodor. 1978. The sausage ma- A new two-stage parsing model. Cogni- 6:291325. Hwang, C.H. and L.K. Schubert. 1992. Tense trees</note>
<abstract confidence="0.797815727272727">the fine structure of discourse. In Proceedof the Annual Meeting of the American for Computational pages 232240. Hwang, C.H. and L.K. Schubert. 1993. Episodic logic, a comprehensive, natural representation for understanding. and 3:381419. J. E., editor, 1991. cognitive arvolume 2 (4) of pages 12184. ACM.</abstract>
<note confidence="0.6291466">Laird, J. E., A. Newell, and P.S. Rosenbloom. 1987. Soar: An architecture for general intelligence. 33:164. Langley, P., D. Shapiro, M. Aycinena, and M. Siliski. 2003. A value-driven architecture for behavior. In of the IJCAI- 2003 Workshop on Cognitive Modeling ofAgents Multi-Agent pages 1018. Schaeffer, S., C.H. Hwang, J. de Haan, and L.K. Schubert. 1991. EPILOG: The computational system for episodic logic. Technical report, University of Alberta, Edmonton. Spivey-Knowlton, M.J. and J.C. Sedivy. 1995. Resolving attachment ambiguities with multiple 55:227267.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Altmann</author>
<author>M Steedman</author>
</authors>
<title>Interaction with context during human sentence processing.</title>
<date>1988</date>
<journal>Cognition,</journal>
<pages>30--191</pages>
<contexts>
<context position="13101" citStr="Altmann and Steedman, 1988" startWordPosition="2121" endWordPosition="2125">e precedence over specificity of inferences drawn in the knowledge base; 3. Give specificity of inferences drawn in the knowledge base preference over subcategorization information; 4. Give subcategorization information precedence over the amount of inferences drawn in the knowledge base, and 5. Consider only inferences with a minimum level of interestingness.4 The list above is not exhaustive, but it gives us an initial set of heuristics to define the reward function for the agents. The choice of some precedences in the heuristics above has been psycholinguistically motivated, as shown in (Altmann and Steedman, 1988).5 The approach to interpretation followed here is based on the assumption that information from different sources enters the interpretation process at different times and that they concurrently restrain the number of potential analyses, as suggested in recent psycholinguistic theories of human sentence comprehension (Spivey-Knowlton and Sedivy, 1995). 5.3 Interpretation as learning The process of finding a preferred interpretation at a given time t, is the result of a process of entropy reversal through information expressed in terms of a set of heuristics that govern the agent reward in this</context>
</contexts>
<marker>Altmann, Steedman, 1988</marker>
<rawString>Altmann, G. and M. Steedman. 1988. Interaction with context during human sentence processing. Cognition, 30:191238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>Rules of the Mind.</title>
<date>1993</date>
<location>Lawrence-Erlbaum, Hillsdale, NJ.</location>
<contexts>
<context position="1115" citStr="Anderson, 1993" startWordPosition="148" endWordPosition="149">Interpretation of natural language involve the computational effort associated with repeatedly computing, interpreting and deindexing logical forms for ambiguous parses. In our view, interpretation can be construed as a negotiation process whereby lexical, structural, semantic, common-sense and world knowledge information and referential context are used to assign plausibilities to competing analyses. The approach to interpretation taken here has been motivated by cognitive architectures for intelligent agents in the tradition of SOAR (Laird, Newell, and Rosenbloom, 1987; Laird, 1991), ACT-R (Anderson, 1993) and ICARUS (Langley et al., 2003). In extending cognitive architectures in this tradition to deal with the problem of interpretation, agents carry both the meaning of competing analyses and the plausibilities associated with them, which we construe as the reward function of the agents. As more information becomes available from the input string, reward functions are updated and the analysis with the higher plausibility becomes the preferred interpretation. 2 The grammar formalism Consider sentence (1): (1) The ✧a spy ✧b watched ✧c the ✧d cop ✧o with ✧f the ✧g revolver ✧h. ✧i The GPSG-like g</context>
</contexts>
<marker>Anderson, 1993</marker>
<rawString>Anderson, J. R. 1993. Rules of the Mind. Lawrence-Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bacchus</author>
</authors>
<title>Representing and Reasoning with Probabilistic Knowledge.</title>
<date>1990</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="8101" citStr="Bacchus, 1990" startWordPosition="1295" endWordPosition="1296">is, we obtain the following episodic logical form ELTI❣. ELTI❣: (✾✉✶:[[✉✶ same-time ◆♦✇✶] ❫ [✉✵ immediately-precedes ✉✶]] [[Speaker tell Hearer (That (✾❡✶:[[❡✶ before ✉✶] ❫ [❡✵ orients ❡✶]] [[(The :[ spy] (The :[ cop] (The :[[ revolver] ❫ [ P]] [ watch ])))] ✄✄ ❡✶]))] ✄✄ ✉✶]) 4 Expressing meaning postulates and world knowledge World knowledge in EPILOG, EL&apos;s implementation (Schaeffer et al., 1991), is expressed in form of unreliable generalizations using probabilistic conditionals of form 0 !♣❀☛✶❀✿✿✿❀☛n V, where a✶� ... �a♥ are controlled variables and p is a statistical probability (Bacchus, 1990). Different choices of controlled variables lead lead to different readings. An axiom of the form 0 !♣ V says that in at least (100) x p % of the situations in which 0 is true, V will also be true. It is assumed that in axioms of the form 0 !♣ ☛✶ - ☛n V the list of controlled variables includes all existentially quantified variables in the antecedent that occur anaphorically in the consequent. 4.1 Meaning postulates about unlocated formulas ▼P 1: (✽❡✶ [[[✣ ❫ ✥] ✄✄ ❡✶] ✦ [✣ ❫ (✾❡✷:[❡✷ ✖ ❡✶][✥ ✄✄ ❡✷])]]) 4.2 Meaning postulates about seeing objects MP 2: If a person watches a thing, then that per</context>
<context position="14027" citStr="Bacchus, 1990" startWordPosition="2263" endWordPosition="2264">ension (Spivey-Knowlton and Sedivy, 1995). 5.3 Interpretation as learning The process of finding a preferred interpretation at a given time t, is the result of a process of entropy reversal through information expressed in terms of a set of heuristics that govern the agent reward in this cognitive architecture. The heuristics above are a distillation of the information required for this entropy reversal process. 4With interestingness measured as a threshold on the conditional probability that results in an inference chain through world knowledge axioms expressed as probabilistic conditionals (Bacchus, 1990). 5Altmann and Steedman dealt with referential context only. To our knowledge, there is no psycholinguistic studies that give us a more complete picture on the precedences stated above. 5.4 An example Let us illustrate the process of agent-based interpretation using our example. When processing sentence (1) up to point g, we do have two analyses. Skolemizing El=el, E2=e2, E3=e3, E4=e4, E5=e5, Ul=ul, X=y, Y=y and Z=z, the set of inferences drawn at point g is as follows: Agent1: ❋l [❊l before ❯l] ❋2 [[[[X I ❊l] (with-instr Z)] n [X watch Y]] ** ❊l] ❋3 [X spy] ❋4 [Y cop] ❋5 [❊2 � ❊l] ❋6 [[X watc</context>
<context position="21115" citStr="Bacchus, 1990" startWordPosition="3463" endWordPosition="3464">* e✶]))] ** a✶]) SLTi leads to the following discourse model. Agent2: F✶ [E✶ before U✶] F✷ [X cop] F✸ [Y spy] F✹ [Z revolver] F✺ [Y with-attrib Z] F✻ [[X watch Y]] ** E✶] 6 Discussion The work presented in this article puts forth an approach to interpretation using a cognitive architecture for intelligent behavior. Our work has so far consisted in defining agent reward based on the positive reinforcement principle. For the initial implementation of the principle, we have followed a heuristics-based approach. Though some of the information used in the plausibility computation is probabilistic (Bacchus, 1990), the heuristics are non-probabilistic in our model. In defining the heuristics, we have incorporated recent results in psycholinguistic studies of human sentence processing. In our view of the interpretation process, agents contribute to arriving at a &amp;quot;preferred&amp;quot; interpretation by maintaining a &amp;quot;more plausible&amp;quot; analysis—and its associated discourse model—as the most salient one, while other less plausible analyses are kept in memory for a given period of time by other agents. By a process of heuristics-based plausibility computation, the &amp;quot;most plausible analysis&amp;quot; remain active in this archite</context>
</contexts>
<marker>Bacchus, 1990</marker>
<rawString>Bacchus, F. 1990. Representing and Reasoning with Probabilistic Knowledge. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Balota</author>
<author>G B Flores d&apos;Arcais</author>
<author>K Rayner</author>
</authors>
<title>Comprehension Processes in Reading. Lawrence Erlbaum Associates,</title>
<date>1990</date>
<location>Hillsdale, NJ.</location>
<marker>Balota, d&apos;Arcais, Rayner, 1990</marker>
<rawString>Balota, D.A., G.B. Flores d&apos;Arcais, and K. Rayner. 1990. Comprehension Processes in Reading. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
<author>C Clifton</author>
</authors>
<date>1996</date>
<publisher>Construal. MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="22125" citStr="Frazier and Clifton, 1996" startWordPosition="3614" endWordPosition="3617">hile other less plausible analyses are kept in memory for a given period of time by other agents. By a process of heuristics-based plausibility computation, the &amp;quot;most plausible analysis&amp;quot; remain active in this architecture and take the lead during the interpretation process. This cognitive architecture gives a plausible account of some of the issues that pervade human sentence processing such as garden-path phenomena. In so doing, we depart from serial first-analysis approaches to sentence comprehension in the tradition of the garden-path theory of sentence processing (Frazier and Fodor, 1978; Frazier and Clifton, 1996) and endorse more recent psycholinguistic accounts of this problem which view the interpretation process as a concurrent negotiation of information from syntactic, semantic and pragmatic sources by several agents (Spivey-Knowlton and Sedivy, 1995). We also aim to bridge the gap between models of interpretation in the tradition of the garden-path theory, which are related to symbolic approaches to NLP, and subsymbolic approaches in the tradition of parallel theories of sentence processing. Our model benefits from the &amp;quot;niceties&amp;quot; of the former approach to arrive at semantic and knowledge represen</context>
</contexts>
<marker>Frazier, Clifton, 1996</marker>
<rawString>Frazier, L. and C. Clifton. 1996. Construal. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
<author>J A Fodor</author>
</authors>
<title>The sausage machine: A new two-stage parsing model.</title>
<date>1978</date>
<journal>Cognition,</journal>
<pages>6--291</pages>
<contexts>
<context position="22097" citStr="Frazier and Fodor, 1978" startWordPosition="3610" endWordPosition="3613">s the most salient one, while other less plausible analyses are kept in memory for a given period of time by other agents. By a process of heuristics-based plausibility computation, the &amp;quot;most plausible analysis&amp;quot; remain active in this architecture and take the lead during the interpretation process. This cognitive architecture gives a plausible account of some of the issues that pervade human sentence processing such as garden-path phenomena. In so doing, we depart from serial first-analysis approaches to sentence comprehension in the tradition of the garden-path theory of sentence processing (Frazier and Fodor, 1978; Frazier and Clifton, 1996) and endorse more recent psycholinguistic accounts of this problem which view the interpretation process as a concurrent negotiation of information from syntactic, semantic and pragmatic sources by several agents (Spivey-Knowlton and Sedivy, 1995). We also aim to bridge the gap between models of interpretation in the tradition of the garden-path theory, which are related to symbolic approaches to NLP, and subsymbolic approaches in the tradition of parallel theories of sentence processing. Our model benefits from the &amp;quot;niceties&amp;quot; of the former approach to arrive at sem</context>
</contexts>
<marker>Frazier, Fodor, 1978</marker>
<rawString>Frazier, L. and J. A. Fodor. 1978. The sausage machine: A new two-stage parsing model. Cognition, 6:291325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Hwang</author>
<author>L K Schubert</author>
</authors>
<title>Tense trees as the fine structure of discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30t❤ Annual Meeting of the American Association for Computational Linguistics,</booktitle>
<pages>232--240</pages>
<contexts>
<context position="6505" citStr="Hwang and Schubert, 1992" startWordPosition="1045" endWordPosition="1048">nd gives rise to a proposition-denoting term. The expression [[ ❥ ❡l] (with-instr) ] corresponds to the action of the spy&apos;s watching modified so as to be performed with something. The function ❥ is a pairing function applicable to individuals and tuples. Thus [ ❥ ❡l] is the action performed by  that gives rise to event ❡l. The operator ✖ is a metalogical operator that corresponds to the operator coextensivepart-of in EL. The expression ❡2 ✖ ❡l indicates that situation ❡2 is coextensive with situation ❡l, that is, ❡l and ❡2 have the same spatiotemporal location. 3The reader is referred to (Hwang and Schubert, 1992) for details on the nonincremental deindexing rules. PP[a-mod] DET N DET N the cop P NP with Once the parameterized episodic logical form has been generated, the incremental deindexer transforms the lambda expressions that abstract over the parameters introduced by the incremental semantic interpreter into episodic logical forms. To this end, constants are introduced for the metalogical parameters. These constants stand for parameterized terms and predicates in the resulting episodic logical form. A-conversion is then performed for each one of the A-expressions in the parameterized episodic lo</context>
</contexts>
<marker>Hwang, Schubert, 1992</marker>
<rawString>Hwang, C.H. and L.K. Schubert. 1992. Tense trees as the fine structure of discourse. In Proceedings of the 30t❤ Annual Meeting of the American Association for Computational Linguistics, pages 232240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Hwang</author>
<author>L K Schubert</author>
</authors>
<title>Episodic logic, a comprehensive, natural representation for language understanding. Minds and Machines,</title>
<date>1993</date>
<pages>3--381</pages>
<contexts>
<context position="2467" citStr="Hwang and Schubert, 1993" startWordPosition="393" endWordPosition="396">p; cop D. N &lt;-- revolver; revolver E. N &lt;-- N PP ; Ay[[y N&apos;] A [y PP&apos;]] F. NP &lt;-- N[plur] ; (K N&apos;) G. P[with-attrib] &lt;-- with ; with-attrib H. P[with-instr] &lt;-- with ; with-instr L NP &lt;-- DET N ; (DET&apos; N&apos;) J. PP &lt;-- P NP ; (P&apos; NP&apos;) K. V[past, _NP] &lt;-- watch ; (past watch) L. ADVL[post-VP] &lt;-- PP[a-mod] ; (adv-a PP&apos;) M. VP &lt;-- V[past, _NP] NP ; (V&apos; NP&apos;) N. VP &lt;-- V[past, _NP] NP ADVL[a-mod] ; (ADVL&apos;(V&apos;NP&apos;)) O. S &lt;-- NP VP ; [NP&apos; VP&apos;] P. PUNC[tell] &lt;-- . ; Q. S &lt;-- S[full-decl] PUNC[tell] ; (decl S&apos;) Figure 1: GPSG-like grammar fragment tic and knowledge representation language for general NLU (Hwang and Schubert, 1993), is shown in Figure 1.1 3 Semantic analysis For sentence (1) the parser computes two initial analyses using not only structural, but also subcategorization and thematic role information as soon as the verb is encountered. At point g, we could be already predicting several of the possible continuations. Based on subcategorization and thematic role information for the verb watch, there is a first analysis that results from applying rule N of our GPSG-like grammar fragment. At point g, the first analysis is APTT❣. ✶We refer the reader to (Hwang and Schubert, 1993) for a detailed description of E</context>
</contexts>
<marker>Hwang, Schubert, 1993</marker>
<rawString>Hwang, C.H. and L.K. Schubert. 1993. Episodic logic, a comprehensive, natural representation for language understanding. Minds and Machines, 3:381419.</rawString>
</citation>
<citation valid="true">
<title>Integrated cognitive architectures,</title>
<date>1991</date>
<journal>of SIGART Bulletin,</journal>
<volume>2</volume>
<issue>4</issue>
<pages>12--184</pages>
<editor>Laird, J. E., editor,</editor>
<publisher>ACM.</publisher>
<marker>1991</marker>
<rawString>Laird, J. E., editor, 1991. Integrated cognitive architectures, volume 2 (4) of SIGART Bulletin, pages 12184. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Laird</author>
<author>A Newell</author>
<author>P S Rosenbloom</author>
</authors>
<title>Soar: An architecture for general intelligence.</title>
<date>1987</date>
<journal>Arti�cial Intelligence,</journal>
<pages>33--1</pages>
<contexts>
<context position="1077" citStr="Laird, Newell, and Rosenbloom, 1987" startWordPosition="140" endWordPosition="144">erages the positive reinforcement principle. 1 Motivation Interpretation of natural language involve the computational effort associated with repeatedly computing, interpreting and deindexing logical forms for ambiguous parses. In our view, interpretation can be construed as a negotiation process whereby lexical, structural, semantic, common-sense and world knowledge information and referential context are used to assign plausibilities to competing analyses. The approach to interpretation taken here has been motivated by cognitive architectures for intelligent agents in the tradition of SOAR (Laird, Newell, and Rosenbloom, 1987; Laird, 1991), ACT-R (Anderson, 1993) and ICARUS (Langley et al., 2003). In extending cognitive architectures in this tradition to deal with the problem of interpretation, agents carry both the meaning of competing analyses and the plausibilities associated with them, which we construe as the reward function of the agents. As more information becomes available from the input string, reward functions are updated and the analysis with the higher plausibility becomes the preferred interpretation. 2 The grammar formalism Consider sentence (1): (1) The ✧a spy ✧b watched ✧c the ✧d cop ✧o with ✧f </context>
</contexts>
<marker>Laird, Newell, Rosenbloom, 1987</marker>
<rawString>Laird, J. E., A. Newell, and P.S. Rosenbloom. 1987. Soar: An architecture for general intelligence. Arti�cial Intelligence, 33:164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Langley</author>
<author>D Shapiro</author>
<author>M Aycinena</author>
<author>M Siliski</author>
</authors>
<title>A value-driven architecture for intelligent behavior.</title>
<date>2003</date>
<booktitle>In Proceedings of the IJCAI2003 Workshop on Cognitive Modeling ofAgents and Multi-Agent Interactions,</booktitle>
<pages>10--18</pages>
<contexts>
<context position="1149" citStr="Langley et al., 2003" startWordPosition="152" endWordPosition="155">nguage involve the computational effort associated with repeatedly computing, interpreting and deindexing logical forms for ambiguous parses. In our view, interpretation can be construed as a negotiation process whereby lexical, structural, semantic, common-sense and world knowledge information and referential context are used to assign plausibilities to competing analyses. The approach to interpretation taken here has been motivated by cognitive architectures for intelligent agents in the tradition of SOAR (Laird, Newell, and Rosenbloom, 1987; Laird, 1991), ACT-R (Anderson, 1993) and ICARUS (Langley et al., 2003). In extending cognitive architectures in this tradition to deal with the problem of interpretation, agents carry both the meaning of competing analyses and the plausibilities associated with them, which we construe as the reward function of the agents. As more information becomes available from the input string, reward functions are updated and the analysis with the higher plausibility becomes the preferred interpretation. 2 The grammar formalism Consider sentence (1): (1) The ✧a spy ✧b watched ✧c the ✧d cop ✧o with ✧f the ✧g revolver ✧h. ✧i The GPSG-like grammar fragment with semantic anno</context>
</contexts>
<marker>Langley, Shapiro, Aycinena, Siliski, 2003</marker>
<rawString>Langley, P., D. Shapiro, M. Aycinena, and M. Siliski. 2003. A value-driven architecture for intelligent behavior. In Proceedings of the IJCAI2003 Workshop on Cognitive Modeling ofAgents and Multi-Agent Interactions, pages 1018.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schaeffer</author>
<author>C H Hwang</author>
<author>J de Haan</author>
<author>L K Schubert</author>
</authors>
<title>EPILOG: The computational system for episodic logic.</title>
<date>1991</date>
<tech>Technical report,</tech>
<institution>University of Alberta,</institution>
<location>Edmonton.</location>
<marker>Schaeffer, Hwang, de Haan, Schubert, 1991</marker>
<rawString>Schaeffer, S., C.H. Hwang, J. de Haan, and L.K. Schubert. 1991. EPILOG: The computational system for episodic logic. Technical report, University of Alberta, Edmonton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Spivey-Knowlton</author>
<author>J C Sedivy</author>
</authors>
<title>Resolving attachment ambiguities with multiple constraints.</title>
<date>1995</date>
<journal>Cognition,</journal>
<pages>55--227</pages>
<contexts>
<context position="13454" citStr="Spivey-Knowlton and Sedivy, 1995" startWordPosition="2172" endWordPosition="2176">interestingness.4 The list above is not exhaustive, but it gives us an initial set of heuristics to define the reward function for the agents. The choice of some precedences in the heuristics above has been psycholinguistically motivated, as shown in (Altmann and Steedman, 1988).5 The approach to interpretation followed here is based on the assumption that information from different sources enters the interpretation process at different times and that they concurrently restrain the number of potential analyses, as suggested in recent psycholinguistic theories of human sentence comprehension (Spivey-Knowlton and Sedivy, 1995). 5.3 Interpretation as learning The process of finding a preferred interpretation at a given time t, is the result of a process of entropy reversal through information expressed in terms of a set of heuristics that govern the agent reward in this cognitive architecture. The heuristics above are a distillation of the information required for this entropy reversal process. 4With interestingness measured as a threshold on the conditional probability that results in an inference chain through world knowledge axioms expressed as probabilistic conditionals (Bacchus, 1990). 5Altmann and Steedman dea</context>
<context position="22372" citStr="Spivey-Knowlton and Sedivy, 1995" startWordPosition="3649" endWordPosition="3652">during the interpretation process. This cognitive architecture gives a plausible account of some of the issues that pervade human sentence processing such as garden-path phenomena. In so doing, we depart from serial first-analysis approaches to sentence comprehension in the tradition of the garden-path theory of sentence processing (Frazier and Fodor, 1978; Frazier and Clifton, 1996) and endorse more recent psycholinguistic accounts of this problem which view the interpretation process as a concurrent negotiation of information from syntactic, semantic and pragmatic sources by several agents (Spivey-Knowlton and Sedivy, 1995). We also aim to bridge the gap between models of interpretation in the tradition of the garden-path theory, which are related to symbolic approaches to NLP, and subsymbolic approaches in the tradition of parallel theories of sentence processing. Our model benefits from the &amp;quot;niceties&amp;quot; of the former approach to arrive at semantic and knowledge representations for alternative analyses while also leveraging a cognitive architecture that is suited to implement a parallel approach to interpretation. 7 Future work Our future work will focus on studying the role agents will have in learning or refini</context>
</contexts>
<marker>Spivey-Knowlton, Sedivy, 1995</marker>
<rawString>Spivey-Knowlton, M.J. and J.C. Sedivy. 1995. Resolving attachment ambiguities with multiple constraints. Cognition, 55:227267.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>