<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000392">
<title confidence="0.969621">
Deriving Verb-Meaning Clusters from Syntactic Structure
</title>
<author confidence="0.998647">
Paul Kingsbury, Karin Kipper
</author>
<affiliation confidence="0.997978">
Computer and Information Sciences
University of Pennsylvania
</affiliation>
<sectionHeader confidence="0.988331" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999892916666667">
This paper presents a methodology for us-
ing the argument structure of sentences, as
encoded by the PropBank project, to de-
velop clusters of verbs with similar mean-
ing and usage. These clusters can be fa-
vorably compared to the classes developed
by the VerbNet project. The most inter-
esting cases are those where the cluster-
ing methodology suggests new members for
VerbNet classes which will then be associ-
ated with the semantic predicates for that
class.
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914962962963">
There can be no doubt that meaning is dependent
upon a great number of factors. The difficulty
in higher-level comprehension in Natural Language
Processing is due to the identification of these factors
as well as the successful implementation of methods
for handling them. Early generative models of syn-
tax failed to answer the meaning question because of
their assumption that semantics was a natural out-
come of structure, thus neglecting the other factors
involved. More recent works, such as those found
in WordNet (Miller, 1985; Fellbaum, 1998) and its
descendents, fall short for the inverse reason: they
focus solely on lexical meaning while ignoring struc-
ture altogether.
Another factor in the meaning game is the rela-
tionship between individual lexical items of the same
function. How are all determiners alike, for exam-
ple, and how are they individually different? Are
there subclasses within the class of determiners, and
how do these subclasses differ from each other? Hu-
man beings are supreme pattern-matchers and assign
things to categories almost to a fault. The categories
into which semantically loaded items are grouped
must therefore be one of the factors leading to higher-
level comprehension, and knowledge of what these
categories are and how they are built can help solve
the greater meaning question.
</bodyText>
<sectionHeader confidence="0.934347" genericHeader="introduction">
2 Issue and Previous Work
</sectionHeader>
<bodyText confidence="0.999947159090909">
Much previous work in the domain of classification
of lexical items has focused on verbs. This is a nat-
ural starting place, since the verb is the hook upon
which the rest of a sentence hangs. Verbs also dis-
play a higher degree of variation in their semantics
than other lexical types. Whereas nouns, for exam-
ple, all name some kind of `thing,&apos; verbs can de-
scribe an action or a state and involve some num-
ber of non-verbal actors in the description. It is
this latter quality of verbs which most interests us
here, and indeed which has been the focus of most
previous work in verb classification. Even the most
elementary grammars of English draw a distinction
between transitive and intransitive verbs. More ad-
vanced work has refined this distinction into ever-
larger numbers of classes. For example, the land-
mark work of Levin (1993) divided over three thou-
sand verbs into 191 classes based partly on shared se-
mantics and partly on shared syntactic alternations.
More recently, the VerbNet project at Penn (Kip-
per et al., 2000) incorporated Levin&apos;s verb classifica-
tion to systematically create verb entries in a lexi-
con. On a purely semantic note, WordNet (Miller,
1985; Fellbaum, 1998) has classified much of the vo-
cabulary of English, not just verbs, in terms of rela-
tionships such as synonymy, hyponymy, and others.
Various attempts worldwide have begun focussing on
the argument structure of verbs as part of develop-
ing dependency grammars. The PropBank project
at Penn (Kingsbury and Palmer, 2002) is an exam-
ple of this process for English; similar projects are
underway for Czech (Hajicova etc), German (Broker
1998), and others. The FrameNet project at Berke-
ley (Baker et al., 1998) has classified many words in
terms of their relation to a relatively small number
of core semantic concepts such as `commerce&apos; and
`judgment&apos;. Various attempts have been made to
automatically cluster verbs into semantically mean-
ingful classes, using the Levin class as a gold stan-
dard for evaluation (Gildea, 2002; McCarthy, 2000;
Merlo and Stevenson, 2001; Schulte im Walde, 2000).
In the next two sections, we provide background on
VerbNet and PropBank which play central roles in
the cluster methodology presented here.
</bodyText>
<sectionHeader confidence="0.539948" genericHeader="method">
2.1 VerbNet
</sectionHeader>
<bodyText confidence="0.999972741935484">
VerbNet is a verb lexicon with syntactic and seman-
tic information for English verbs, referring to Levin
verb classes (Levin, 1993) for systematic construc-
tion of lexical entries. This lexicon exploits the sys-
tematic link between syntax and semantics that mo-
tivates these classes, and thus provides a clear and
regular association between syntactic and semantic
properties of verbs and verb classes (Kipper et al.,
2000; Dang et al., 2000). Each class in the hier-
archy is composed of a set of members (linked to
their WordNet synsets) and a set of syntactic frames
and semantic information for each frame. Currently,
VerbNet has over 4,000 verb senses described (3,004
lemmas) within 191 first level classes.
VerbNet has a hierarchical structure, with the first
level classes constituted by the original Levin classes.
In order to ensure that each class is coherent, so that
all its members share a common set of thematic roles,
syntactic frames and semantic predicates, some re-
structuring of the classes was required. This reorga-
nization, which was facilitated by the use of inter-
sective Levin classes (Dang et al., 1998), refined the
classes to account for semantic and syntactic differ-
ences within a class. A child subclass inherits all the
information from its parent class, and adds informa-
tion to it, which can be in terms of imposing further
restrictions on the roles, or adding syntactic frames
or semantic predicates to the subclass.
The hierarchical organization of VerbNet is illus-
trated in Figure 1. The Transfer of a Message verb
class is subdivided into three levels. At the top level
are thematic roles, syntactic frames and semantic
predicates shared by all members of the class. In
this particular case, there is a transitive frame with
the Topic (message) as the direct object (Agent Verb
Topic), as in &amp;quot;John explained trigonometry&amp;quot;, and a
frame for Topic and Recipient (Agent Verb Topic to
Recipient), as in &amp;quot;John taught math to Mary&amp;quot;. Both
syntactic frames have semantic predicates expressing
the transfer of information event, but in the first case
the Recipient is underspecified. Some of the verbs in
this class are able to participate in other syntactic
frames as well. Verbs at the second level can take
the ditransitive frame (Agent Verb Recipient Topic)
in addition to the frames and predicates inherited
from the parent class.
VerbNet uses a flat semantic representation in
which the semantics of each syntactic frame is cap-
tured by a conjunction of predicates 1, such as mo-
tion, contact, transfer info, which can be negated or
not. These predicates can take arguments over the
verb complements, as well as over implicit existen-
tially quantified event variables.
Each semantic predicate in VerbNet also include
a time function specifying whether the predicate
is true in the preparatory (during(E)), culmina-
tion (end(E)), or consequent (result(E)) stage of an
event, in a tripartite event structure is similar to that
of Moens and Steedman (1988), which allows us to
express the semantics of classes of verbs like change
of state verbs whose description requires reference to
a complex event structure.
</bodyText>
<subsectionHeader confidence="0.989089">
2.2 PropBank
</subsectionHeader>
<bodyText confidence="0.994978214285714">
In a different vein, the PropBank project (Kingsbury
and Palmer, 2002) has endeavoured to describe all
the most frequent verbs of English in terms of their
argument structure. This project has three major
differences from previous works. First, the descrip-
tion of each verb is accompanied by a rich set of
examples drawn from real language, in this case the
Wall Street Journal sections of the Penn Treebank
(Marcus, 1994). Furthermore, the descriptions are
based on the usages in the corpus, rather than a pos-
sible situation where the corpus was mined for sen-
tences fitting preconceived patterns. This results in
many instances which are perfectly well-formed but
unexpected. The best example of this is an odd usage
of the verb add: The Nasdaq composite index added
1.01 to 456.6 on paltry volume., where the context
makes it clear that add is being used as a synonym for
rise. Second, argument structure allows for a richer
set of descriptions than merely `transitive&apos;, `unac-
cusative&apos;, and so forth, since any individual verb is
allowed to have anywhere between zero and six ar-
guments. Third and perhaps most importantly, the
PropBank descriptions make explicit mention of the
different senses of verbs. This is crucial because dif-
ferent senses can have different argument structures
or different syntactic alternations, a detail which is
often glossed over in other resources. Thus, while (1)
Presently there are 64 distinct predicates described.
</bodyText>
<figure confidence="0.974349428571429">
Transfer of a Message - level 1 class
((MEMBERS )) [(cite, wn1), (demonstrate, wn1), (explain, wn1), ...]
((THEMATIC ROLES)) Agent(A), Recipient(R), Topic(T)
((SELECT RESTRICTIONS)) Agent[+animate],
Recipient[+animate],
Topic[+message]
((FRAMES and PREDICATES))
Transitive with Topic AVT transfer info(during(E),A,?,T)
Topic and Recipient AVTtoR transfer info(during(E),A,R,T)
Transfer of a Message - level 2 class
((PARENT )) Transfer of a Message - level 1
((MEMBERS )) [(dictate, wn2), (quote, wn1), (read, wn3)]
((FRAMES and PREDICATES))
Ditransitive A V R T transfer info(during(E),A,R,T)
</figure>
<figureCaption confidence="0.999777">
Figure 1: Example entries for the Transfer of a Message - levels 1 and 2 classes
</figureCaption>
<listItem confidence="0.849676833333333">
and (3) share the same argument structure, (2) and
(4) do not, because of the ungrammaticality of (4):
1 Congress passed the bill.
2 John passed the butter.
3 The bill passed.
4 *The butter passed.
</listItem>
<bodyText confidence="0.954782914893617">
Under the PropBank scheme, the similarity be-
tween pass (make bill into law) and pass (move
from one place to another) is regarded an almost-
accidental byproduct of centuries of semantic drift.
The combination of accounting for all the usages
in a large corpus and separating verb senses re-
sults in a very large database: 4358 distinct senses
spread across 3183 lexical items, with a total of over
70 000 unique tokens. PropBank annotations are
recorded as theory-neutrally as possible. Crucially,
the nomenclature of traditional thematic roles is not
used; instead, simple labels of Arg0, Arg1 and so
forth are used. Each ArgX is mapped to a specific
role on a per-verb basis, such as the roleset for give:
Arg0: giver
Arg1: gift
Arg2: given-to
ex: [Arg0 The executives] gave [Arg2 the
chefs] [Arg, a standing ovation].
Such a schema has its advantages and its draw-
backs. On the negative side, it makes it difficult to
draw comparisons between various arguments with
the same number. The meaning of Arg2 for one verb
might bear no relation to the meaning of Arg2 for
some other verb, for example. On the plus side, not
using traditional thematic roles both frees the anno-
tators from the necessity of distinguishing between
Theme and Patient, for example, while also allowing
for roles which do not have corresponding thematic
roles. For example, PropBank has a host of verbs re-
lating to the judicial process, such as jail, sentence,
imprison, and so forth. All of these take four roles;
Arg0: lawgiver
Arg1: guilty party
Arg2: term, length of jail time
Arg3: crime
ex: Dallas District Judge Jack Hampton
had sparked calls for a judicial inquiry with
his remarks to the press last December,
two weeks after [Arg0 *trace=Hampton*]
sentencing [Arg, an 18-year-old defendant]
to [Arg2 30 years in state prison] for [Arg3
killing two homosexual men in a city park.]
While Args 0 and 1 can be thought of as Agent
and Patient, traditional thematic role terminology
fails to accommodate Args 2 and 3, for all that they
are central to the meaning of the verbs.
</bodyText>
<sectionHeader confidence="0.996954" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.998437227722772">
The PropBank annotations thus provide a rich set
of actual usages which are easily divided into senses
and quantified. That is, for any verb (sense) it is
possible to collect all the usages, divide them into
their various syntactic realizations, and enumerate
these realizations. The realizations themselves are
rendered at a very basic level, encoding only the lin-
ear order of arguments. The verb itself is rendered
as rel for &apos;relation&apos;. Thus a verb such as repeal can
appear in either a simple transitive or passive:
[Arg0 West Germany] will repeal [Arg1
the unpopular turnover tax on security
transactions]. (wsj 0302)
—� Arg0 rel Arg1
...the tax will be officially repealed [Arg1
*trace=the tax*] before the end of the
current parliamentary term... (wsj 0302)
—� rel Arg1
As seen in the second example, adjuncts such as
the temporal before the end of the current parliamen-
tary term are omitted. While the bulk of annotations
fall into basic categories such as Arg0 rel Arg1 (ba-
sic transitive), Arg0 rel Arg1 Arg2 (ditransitive) and
so forth, the nature of the data and the annotation
process itself means that there is a large residue of ir-
regular syntactic realizations. As an example of the
former, consider the following sentence, where the
benefactive argument has been topicalized to the be-
ginning:
For [Arg4 Mr. Sherwin], [Arg0 a conviction]
could carry [Arg1 penalties of five years in
prison and a $250,000 fine on each count].
(wsj 1331) —� Arg4 Arg0 rel Arg1
Such a construction is certainly a natural part of
English, yet it occurs very rarely—only twice in all
of Propbank (so far). The annotation process itself
also introduces many odd, low-frequency syntactic
realizations which should be regarded as errors. For
example, occasionally annotators include one argu-
ment label twice:
...the board also was informed...of [Arg1 in-
terest] expressed by [Arg0 buy-out funds
including Kohlberg Kravis Roberts &amp; Co.
and Forstmann Little &amp; Co.], as well as by
[Arg0 Robert Bass, Morgan Stanley&apos;s buy-
out fund, and Pan Am Corp]. (wsj 2104)
—� Arg1 rel Arg0 Arg0
In cases of such conjoined constructions the an-
notation guidelines specify that the sentence should
be regarded as two overlapping sentences, with two
overlapping argument structures. Thus, for the sen-
tence above, there should properly be two instances
of `Arg1 rel Arg0&apos;, each with the same Arg1 and rel
but with different Arg0&apos;s. The annotator of this sen-
tence clearly forgot this specification. Fortunately,
PropBank is proceeding through a double blind an-
notation followed by an adjudication phase. The ad-
judication will catch and correct structures such as
the above. For the time being, however, such errors
are retained, largely for want of an efficient and ac-
curate filtering mechanism.
Other filtering on the data is performed, however.
Since the TreeBank corpus is subject to the same
Zipfian distribution of lexical items as any natural-
language database, many verbs are only poorly at-
tested. A largely arbitrary decision was made to
eliminate all verbs which had fewer than 10 attesta-
tions. Finally, again due to the ongoing nature of the
PropBank work, not all polysemous verbs have been
disambiguated. These verbs were also deleted from
the subsequent analysis. All the same, the resulting
dataset provides 921 verbs with 200 distinct syntactic
realizations of varying frequencies. Each realization
was recorded as a proportion of the number of attes-
tations of that syntactic pattern to the total num-
ber of attestations of that verb. Expressing these as
proportions rather than as raw counts allows for bet-
ter comparisons among verbs which themselves vary
widely in frequency. The proportions themselves are
then run through a standard clustering algorithm im-
plemented in R (http://www.R-project.org) which
classifies each verb by the difference between its at-
tested proportions and the proportions attested by
every other verb. Verbs with little difference, mean-
ing they attest nearly the same syntactic patterns in
nearly the same proportions, are judged to be very
similar and are likely to be grouped into the same
class. A varying number of &amp;quot;centroids&amp;quot; or proto-
types for each class can be established. Each verb
is then classified by its similarity to the centroids,
resulting in a number of classes equal to the num-
ber of centroids. The resulting classes are compared
to the existing VerbNet classes. This is at best a
noisy measure of accuracy, since many of the Prop-
Banked verbs (even fairly richly-attested ones) are
not classified in VerbNet, and many verbs which are
classified in VerbNet are not present in PropBank in
sufficient numbers to undergo the clustering analysis.
These factors are constant across all possible number
of centroids/classes, however, so at least the amount
of noise in the assessment remains constant as well.
</bodyText>
<footnote confidence="0.934436333333333">
2The probability of occurrence of words or other items
starts high and tapers off. Thus, a few occur very often
while many others occur rarely.
</footnote>
<sectionHeader confidence="0.995994" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.994933727272727">
As an initial assessment of the worth of the method-
ology, consider the case with only three clusters. The
clusters can be viewed graphically in Figure 2.
The crosses are the centroids. Such a display as
this is naturally a gross simplification of the actual
200-dimensional space the clusters are mapped in,
but it&apos;s the best that can be done on paper. If we look
at (a sample of) the membership of each of the three
clusters, we see that the three groups clearly fall into
the sets of transitive, unaccusative, and ditransitive
verbs:3
</bodyText>
<table confidence="0.989951857142857">
Class 1 Class 2 Class 3
waste repay drift
ask.01 invest die
overcome appoint crumble
feel.01 invite triple
make.05 assign float
influence recruit disappear
</table>
<bodyText confidence="0.967327">
For higher numbers of clusters a more formal
method of measuring accuracy is required. Since we
are comparing sets, the similarity of two sets A and
B can be computed with the following:
</bodyText>
<equation confidence="0.8384145">
similaritg(A, B) _ lAnBl
lAUBl
</equation>
<bodyText confidence="0.9845571375">
In other words, the similarity of two sets can be
measured as the number of elements shared by the
two sets divided by the total number of unique el-
ements in the two sets. Thus, two identical sets
({a, b} {b, a}) would have a similarity score of 1,
because the intersection contains two elements, as
does the union. Two sets a, b and a, b, ..., z would
have a very low similarity score, since the intersec-
tion contains two elements, but that is divided by the
union with 26 elements. Thus the similarity score
is dependent both on the number of matches and
the number of spurious elements present. For exam-
ple, the three clusters described above most closely
align to the VerbNet classes 13.5.1 (Get class), 45.6
(Calibratable change state class), and 48.1.1 (Appear
class), respectively, with 4, 4, and 7 matching ele-
ments. Each of these clusters is huge, however (521,
335, and 65 verbs, respectively), and the target sets
are also large as VerbNet clusters go (31, 23, and 27
verbs, respectively). These factors conspire to make
the overall similarity scores quite low (4/(521+31),
3ask.01: ask a question, as opposed to ask a favor;
feel.01: feel emotion; make.05: make money, as in &amp;quot;Paul
doesn&apos;t make nearly enough money; triple: while in most
English this would be considered a transitive verb, the
common usage in the Wall Street Journal is actually un-
acusative, as in &amp;quot;Paul&apos;s net worth tripled when he found
a $5 bill in the dryer&apos;.&amp;quot;
etc). This demonstrates how a three-cluster analy-
sis, while interesting for describing a gross syntactic
grouping, does not go very far in describing any finer-
grained meaning contrasts.
To get at the classification with real implications
for meaning we clearly need to use more, smaller clus-
ters. How many more, and how small? Since the
original set of verbs under analysis comes from 150
VerbNet classes, we can set an upper bound on the
number of clusters at 150. Then we iteratively derive
clusters for each number between 3 and 150 and find
the similarity scores for each cluster in each of those
sets. To facilitate comparison between the various
sets of clusters, we calculate the average similarity
across all the classes. This is necessary because, as
the number of clusters rises, the size of any individual
cluster is likely to fall, thus bringing the denominator
of the similarity equation down. Taken across all the
clusters, then, the similarity scores are bound to rise
regardless of improvements in the matching between
the VerbNet clusters and the automatically-derived
ones. The outcome of this procedure can be seen in
Figure 3.
Interesting peaks appear for analyses with 14 clus-
ters and around 89 clusters before the long tailing
off with more than 90 clusters. In addition, there is
a local maximum around 32 clusters. The analyses
with 14 clusters still uses very large clusters (aver-
age of 65 verbs/cluster), so that number is less useful.
The smallest cluster developed therein, however, con-
sists only of `remain&apos; and `stay.01&apos;,4 and that cluster
correctly maps to VerbNet class 47.1-1 (Exist class),
which contains verbs of staying in place.
By the time around 90 clusters are used the derived
classes themselves tend to be very small, with 34
clusters containing two or fewer verbs. In contrast,
a few clusters continue to have very large member-
ship, such as two groups (arbitrarily labeled `3&apos; and
`38&apos;) which contain 145 and 146 verbs, respectively,
and which correspond roughly to VerbNet classes
29.5 (Conjecture class) and 29.2 (Characterize class).
While 29.2 is one of the largest classes in VerbNet,
precisely why this class should seem to attract va-
grant verbs remains to be seen. More interesting,
however, are the times when the clustering process
establishes multiple clusters which are all identified
with the same VerbNet class — in effect, suggesting
subclasses where they have not previously appeared.
This trend appears even with fairly low numbers of
clusters, and it tends to be extremely consistent as to
which VerbNet clusters are split. For example, class
45.4 (Other change state), containing the `miscella-
</bodyText>
<page confidence="0.384791">
4Sense:remain.
</page>
<figure confidence="0.997788833333333">
second principal component
−0.8 −0.6 −0.4 −0.2 0.0 0.2 0.4
3 clusters
3 3 3
−1.0 −0.5 0.0 0.5
first principal component
</figure>
<figureCaption confidence="0.999165">
Figure 2: Clusters for transitive, unaccusative, and ditransitive
</figureCaption>
<equation confidence="0.937736815789474">
2
2 2
2 2 2
2 2
2 2
2 2
2 2 2 2 2 2 2
2
2 2 2 2
2 2
2
2 2 2 2 2 2
2 2 2
2 2 2 2 2 2
2 2 2 2 2 2 2
2 2 2 2
2 2 2 2
2 2 2 2
2 2 2 2 2
2 2 2 2
2 2 1
2 2 2 2
2 2
2 2
2 2 1
2 2
2 2
2 1
2 2 2
2 2 2 2 2 2 2 2 2
2 2 2 2
2 2 2 22 1
1 1 1
2 2 2 2 2 1
1 1
2 2 2 2 2 2
2 2
2 1
2 2 1 1
2
2 2 2 2 1
2 2 2 1 1
1
2
2 1 1
2 1
2 2
2 2 2
2 2 2 2 2 1 1
2 2 2 1
2 2 1 1 1 1
2 2 1 1
1 1 1 1
1
2 1 1
2 1 1
1 1 1 1 1
1
1 1 1 1 1 1 1
2 1
2 2 1 1
2 2 1
2 2 1 1 1 1
1 1
1 1 1 1 1
2 2 1 1
1
2 1
2 1 1 1
2 1 1
2 1
1 1 1 1
2 1
2 1
1 1 1 1 1 1
2 11
</equation>
<table confidence="0.962664666666667">
1
2 1 1
1 1 1 1 1
2 1 1 1
2 1 1
1 1 1
2
1 1 1 1 1
1 1 1 1 1 1 1 1
1
2 1
1
2 1 1 1 1 1
2 1 1 1 1 1 1
2 1 1
1
2 1 1 1 1
1 1 1 1 1 1 1
2 2 1
2 1 1 1
2 2
2 2 1 1 1
2 1 1
2 1 1 1
1
2 2 2 1
1 1 1
</table>
<figure confidence="0.985779315789474">
3
3
3
3
3
3
3
3
3
3
3 3
3
3
3
3
3
3
3
3
3
3
3
3 3 3 3
3 3
1
2
1
1
1
1
1
2 2 2 2
2 2
1
1
2
2
1
1
1 1
2
1
3
1
3
1
3 3
3
3
3
3
3 3
3
3
3 3
3
3
</figure>
<bodyText confidence="0.981772095238095">
neous causatives,&apos; is first split into two subclasses
even when only 9 clusters are in play, indicating
that there is more variation in the syntactic patterns
within this single class than there is between almost
any other arbitrarily-selected pair of classes. It is
hardly surprising that a collection labeled `miscella-
neous&apos; should contain such a wide variety of syntac-
tic patterns. What is surprising, and encouraging, is
the speed at which this methodology identifies this
miscellany and moves to correct it.
In one example of how previously-unclassified
verbs may be added to a VerbNet class, consider clus-
ter 20 within the 90-cluster analysis. This grouping
is optimally identified with VerbNet class 36.3 (Meet
class), verbs of combative meetings. It contains, un-
surprisingly, verbs such as fight and consult. The
clustering analysis adds, in addition, verbs such as
pull.02 (phrasal: pull out) and withdraw. The for-
mer, like all phrasal verbs, is neglected by VerbNet,
while the latter is considered to be part of the `re-
move&apos; classes (10.1 and 10.5). Yet it might be just as
natural to think of withdraw in the sense of exiting
a meeting or an engagement rather than removing
something from somewhere. For example, &amp;quot;It was
just another one of the risk factors&amp;quot; that led to the
company&apos;s decision to withdraw from the bidding, he
added (wsj 0013). Another verb placed into this clus-
ter is hedge. Impressionistically, this might appear to
be restricted to &amp;quot;hedge one&apos;s bets&amp;quot; and thus a poor
match for this fairly combative class. Upon examina-
tion of the actual usages, however, it becomes clear
that most of the time hedge is being used to mean
protect (from), as in But some investors might pre-
fer a simpler strategy than hedging their individual
holdings (wsj 1962) or Thus, buying puts after a big
market slide can be an expensive way to hedge against
risk (wsj 2415). Seen this way, hedge is a plausible
member of this class, and since it is hitherto un-
treated by VerbNet, the clustering analysis provides
a valuable suggestion for an unexpected meaning. It
also avoids erroneously attributing a change of loca-
tion predicate to the sentence.
For another example, consider cluster 25 of the
same 90-cluster analysis. The verbs in this group
contain verbs of directed motion such as put.01 and
funnel, and is identified with VerbNet class 9.3 (Fun-
nel class). The VerbNet description for this class
specifies three arguments: Agent, Theme, and Des-
tination. The Destination role is further specified
as being restricted to those cases where the Theme
and Destination end up in close contact. Thus, this
class includes usages such as put the toy in the box
but not put the money towards a new car. Another
verb which is placed into this class is cast.01, which
is restricted to a small number of near-idioms such
as cast a pall (over) and cast doubt (on). Because of
this restriction, it has not previously been handled
by VerbNet. The clustering successfully includes this
in the same class as put and funnel, even including
the selectional restriction on the types of Destina-
tion allowed, for only over and on will be found with
this sense of cast. This would also assign the correct
semantic predicates to cast.
</bodyText>
<figureCaption confidence="0.993716">
Figure 3: Outcome of clustering procedure
</figureCaption>
<sectionHeader confidence="0.972333" genericHeader="conclusions">
5 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.999986170731707">
Clustering of syntactic patterns can quickly and
automatically provide a first approximation of the
groupings into which meaning-bearing items fall.
The methodology easily captures low-level gen-
eralizations and points out shortcomings in the
&apos;gold standard&apos; verb classification against which it
was judged. Nevertheless, it is only a first pass
at transforming syntactic structure into semantics.
Additional information is available to extend the
paradigm. For example, the syntactic patterns which
were the subject of the clustering algorithm were
nothing more than the linear order of the argu-
ments of the verb. Further refinement on the syn-
tactic structure would be possible, at the expense of
multiplying the patterns. For instance, in the pre-
ceding all prepositions were stripped from the ar-
gument structure, even though PropBank includes
the preposition as part of the argument label rather
than as part of the argument itself. Also, it would
be possible to label the arguments with thematic
roles instead of the generic labels used by PropBank,
when possible, thus providing a measure of semantics
mixed in with the syntax. Kipper et al. (submitted,
2003) describes the process of mapping PropBank
argument labels onto VerbNet thematic roles. Cur-
rently, over 64% of the PropBank argument labels
have been mapped automatically, and that is with-
out recourse to the sense-disambiguated data. This
suggests that the two resources are highly compati-
ble and that the combined data could easily be used
in the clustering methodology. A larger measure of
meaning could be added if some notion of the mean-
ing of the verbs could be included in the clustering
as well. For example, WordNet synonym sets, espe-
cially as encoded in VerbNet, could be used as the
initial state of the clusters, which then could be mod-
ified by the dis/similarity of the syntactic patterns
attested by those verbs. Such refinements to the pro-
cess would in themselves be steps towards integrating
the many factors that contribute to the understand-
ing of meaning.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999747109375">
Collin F. Baker, Charles J. Fillmore, and John B.
Lowe. 1998. The Berkeley FrameNet project. In
Proceedings of the 17th International Conference
on Computational Linguistics (COLING/ACL-
98), pages 86{90, Montreal. ACL.
Hoa Trang Dang, Karin Kipper, Martha Palmer, and
Joseph Rosenzweig. 1998. Investigating regular
sense extensions based on intersective levin classes.
In Proceedings of ACL98, Montreal, Canada, Au-
gust.
Hoa Trang Dang, Karin Kipper, and Martha Palmer.
2000. Integrating compositional semantics into
a verb lexicon. In Proceedings of the Eighteenth
International Conference on Computational Lin-
guistics (COLING-2000), Saarbrucken, Germany,
July-August.
Christiane Fellbaum, editor. 1998. WordNet: An
Eletronic Lexical Database. Language, Speech and
Communications. MIT Press, Cambridge, Mas-
sachusetts.
Daniel Gildea. 2002. Probabilistic models of verb-
argument structure. In Proceedings of the 19th In-
ternational Conference on Computational Linguis-
tics (COLING-02), pages 308{314, Taipei.
Paul Kingsbury and Martha Palmer. 2002. From
treebank to propbank. In Proceedings of the 3rd
International Conference on Language Resources
and Evaluation (LREC-2002), Las Palmas, Ca-
nary Islands, Spain.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon.
In Proceedings of the Seventh National Conference
on Artificial Intelligence (AAAI-2000), Austin,
TX, July-August.
Beth Levin. 1993. English Verb Classes and Alterna-
tion, A Preliminary Investigation. The University
of Chicago Press.
Mitch Marcus. 1994. The penn treebank: A revised
corpus design for extracting predicate-argument
structure. In Proceedings of the ARPA Human
Language Technology Workshop, Princeton, NJ,
March.
Diana McCarthy. 2000. Using semantic preferences
to identify verbal participation in role switching al-
ternations. In Proceedings of the 1st Annual Meet-
ing of the North American Chapter of the ACL
(NAACL), pages 256{263, Seattle, Washington.
Paola Merlo and Suzanne Stevenson. 2001. Auto-
matic verb classification based on statistical dis-
tribution of argum ent structure. Computational
Linguistics, 27(3), September.
George Miller. 1985. Wordnet: A dictionary
browser. In Proceedings of the First International
Conference on Information in Data, Waterloo,
Ontario.
M. Moens and M. Steedman. 1988. Temporal On-
tology and Temporal Reference. Computational
Linguistics, 14:15{38.
Sabine Schulte im Walde. 2000. Clustering verbs
semantically according to their alternation be-
haviour. In In Proceedings of the 18th Interna-
tional Conference on Computational Linguistics
(COLING-00), pages 747{753, Saarbrucken, Ger-
many.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.967520">
<title confidence="0.999794">Deriving Verb-Meaning Clusters from Syntactic Structure</title>
<author confidence="0.99929">Paul Kingsbury</author>
<author confidence="0.99929">Karin</author>
<affiliation confidence="0.992981">Computer and Information University of Pennsylvania</affiliation>
<abstract confidence="0.998199692307692">This paper presents a methodology for using the argument structure of sentences, as encoded by the PropBank project, to develop clusters of verbs with similar meaning and usage. These clusters can be favorably compared to the classes developed by the VerbNet project. The most interesting cases are those where the clustering methodology suggests new members for VerbNet classes which will then be associated with the semantic predicates for that class.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics (COLING/ACL98),</booktitle>
<pages>86--90</pages>
<publisher>ACL.</publisher>
<location>Montreal.</location>
<contexts>
<context position="3662" citStr="Baker et al., 1998" startWordPosition="596" endWordPosition="599">o systematically create verb entries in a lexicon. On a purely semantic note, WordNet (Miller, 1985; Fellbaum, 1998) has classified much of the vocabulary of English, not just verbs, in terms of relationships such as synonymy, hyponymy, and others. Various attempts worldwide have begun focussing on the argument structure of verbs as part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic informatio</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of the 17th International Conference on Computational Linguistics (COLING/ACL98), pages 86{90, Montreal. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
<author>Karin Kipper</author>
<author>Martha Palmer</author>
<author>Joseph Rosenzweig</author>
</authors>
<title>Investigating regular sense extensions based on intersective levin classes.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL98,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="5319" citStr="Dang et al., 1998" startWordPosition="863" endWordPosition="866">nked to their WordNet synsets) and a set of syntactic frames and semantic information for each frame. Currently, VerbNet has over 4,000 verb senses described (3,004 lemmas) within 191 first level classes. VerbNet has a hierarchical structure, with the first level classes constituted by the original Levin classes. In order to ensure that each class is coherent, so that all its members share a common set of thematic roles, syntactic frames and semantic predicates, some restructuring of the classes was required. This reorganization, which was facilitated by the use of intersective Levin classes (Dang et al., 1998), refined the classes to account for semantic and syntactic differences within a class. A child subclass inherits all the information from its parent class, and adds information to it, which can be in terms of imposing further restrictions on the roles, or adding syntactic frames or semantic predicates to the subclass. The hierarchical organization of VerbNet is illustrated in Figure 1. The Transfer of a Message verb class is subdivided into three levels. At the top level are thematic roles, syntactic frames and semantic predicates shared by all members of the class. In this particular case, t</context>
</contexts>
<marker>Dang, Kipper, Palmer, Rosenzweig, 1998</marker>
<rawString>Hoa Trang Dang, Karin Kipper, Martha Palmer, and Joseph Rosenzweig. 1998. Investigating regular sense extensions based on intersective levin classes. In Proceedings of ACL98, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
<author>Karin Kipper</author>
<author>Martha Palmer</author>
</authors>
<title>Integrating compositional semantics into a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Computational Linguistics (COLING-2000),</booktitle>
<location>Saarbrucken, Germany, July-August.</location>
<contexts>
<context position="4636" citStr="Dang et al., 2000" startWordPosition="750" endWordPosition="753">1; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes (Kipper et al., 2000; Dang et al., 2000). Each class in the hierarchy is composed of a set of members (linked to their WordNet synsets) and a set of syntactic frames and semantic information for each frame. Currently, VerbNet has over 4,000 verb senses described (3,004 lemmas) within 191 first level classes. VerbNet has a hierarchical structure, with the first level classes constituted by the original Levin classes. In order to ensure that each class is coherent, so that all its members share a common set of thematic roles, syntactic frames and semantic predicates, some restructuring of the classes was required. This reorganization,</context>
</contexts>
<marker>Dang, Kipper, Palmer, 2000</marker>
<rawString>Hoa Trang Dang, Karin Kipper, and Martha Palmer. 2000. Integrating compositional semantics into a verb lexicon. In Proceedings of the Eighteenth International Conference on Computational Linguistics (COLING-2000), Saarbrucken, Germany, July-August.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Eletronic Lexical Database. Language, Speech and Communications.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Eletronic Lexical Database. Language, Speech and Communications. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
</authors>
<title>Probabilistic models of verbargument structure.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02),</booktitle>
<pages>308--314</pages>
<location>Taipei.</location>
<contexts>
<context position="3976" citStr="Gildea, 2002" startWordPosition="648" endWordPosition="649">e of verbs as part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of ver</context>
</contexts>
<marker>Gildea, 2002</marker>
<rawString>Daniel Gildea. 2002. Probabilistic models of verbargument structure. In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02), pages 308{314, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From treebank to propbank.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="3475" citStr="Kingsbury and Palmer, 2002" startWordPosition="564" endWordPosition="567">1 classes based partly on shared semantics and partly on shared syntactic alternations. More recently, the VerbNet project at Penn (Kipper et al., 2000) incorporated Levin&apos;s verb classification to systematically create verb entries in a lexicon. On a purely semantic note, WordNet (Miller, 1985; Fellbaum, 1998) has classified much of the vocabulary of English, not just verbs, in terms of relationships such as synonymy, hyponymy, and others. Various attempts worldwide have begun focussing on the argument structure of verbs as part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we </context>
<context position="7411" citStr="Kingsbury and Palmer, 2002" startWordPosition="1203" endWordPosition="1206">arguments over the verb complements, as well as over implicit existentially quantified event variables. Each semantic predicate in VerbNet also include a time function specifying whether the predicate is true in the preparatory (during(E)), culmination (end(E)), or consequent (result(E)) stage of an event, in a tripartite event structure is similar to that of Moens and Steedman (1988), which allows us to express the semantics of classes of verbs like change of state verbs whose description requires reference to a complex event structure. 2.2 PropBank In a different vein, the PropBank project (Kingsbury and Palmer, 2002) has endeavoured to describe all the most frequent verbs of English in terms of their argument structure. This project has three major differences from previous works. First, the description of each verb is accompanied by a rich set of examples drawn from real language, in this case the Wall Street Journal sections of the Penn Treebank (Marcus, 1994). Furthermore, the descriptions are based on the usages in the corpus, rather than a possible situation where the corpus was mined for sentences fitting preconceived patterns. This results in many instances which are perfectly well-formed but unexp</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From treebank to propbank. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002), Las Palmas, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-based construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-2000),</booktitle>
<location>Austin, TX, July-August.</location>
<contexts>
<context position="3000" citStr="Kipper et al., 2000" startWordPosition="488" endWordPosition="492"> of non-verbal actors in the description. It is this latter quality of verbs which most interests us here, and indeed which has been the focus of most previous work in verb classification. Even the most elementary grammars of English draw a distinction between transitive and intransitive verbs. More advanced work has refined this distinction into everlarger numbers of classes. For example, the landmark work of Levin (1993) divided over three thousand verbs into 191 classes based partly on shared semantics and partly on shared syntactic alternations. More recently, the VerbNet project at Penn (Kipper et al., 2000) incorporated Levin&apos;s verb classification to systematically create verb entries in a lexicon. On a purely semantic note, WordNet (Miller, 1985; Fellbaum, 1998) has classified much of the vocabulary of English, not just verbs, in terms of relationships such as synonymy, hyponymy, and others. Various attempts worldwide have begun focussing on the argument structure of verbs as part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and</context>
<context position="4616" citStr="Kipper et al., 2000" startWordPosition="746" endWordPosition="749">lo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes (Kipper et al., 2000; Dang et al., 2000). Each class in the hierarchy is composed of a set of members (linked to their WordNet synsets) and a set of syntactic frames and semantic information for each frame. Currently, VerbNet has over 4,000 verb senses described (3,004 lemmas) within 191 first level classes. VerbNet has a hierarchical structure, with the first level classes constituted by the original Levin classes. In order to ensure that each class is coherent, so that all its members share a common set of thematic roles, syntactic frames and semantic predicates, some restructuring of the classes was required. </context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-based construction of a verb lexicon. In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-2000), Austin, TX, July-August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternation, A Preliminary Investigation.</title>
<date>1993</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="2806" citStr="Levin (1993)" startWordPosition="458" endWordPosition="459">egree of variation in their semantics than other lexical types. Whereas nouns, for example, all name some kind of `thing,&apos; verbs can describe an action or a state and involve some number of non-verbal actors in the description. It is this latter quality of verbs which most interests us here, and indeed which has been the focus of most previous work in verb classification. Even the most elementary grammars of English draw a distinction between transitive and intransitive verbs. More advanced work has refined this distinction into everlarger numbers of classes. For example, the landmark work of Levin (1993) divided over three thousand verbs into 191 classes based partly on shared semantics and partly on shared syntactic alternations. More recently, the VerbNet project at Penn (Kipper et al., 2000) incorporated Levin&apos;s verb classification to systematically create verb entries in a lexicon. On a purely semantic note, WordNet (Miller, 1985; Fellbaum, 1998) has classified much of the vocabulary of English, not just verbs, in terms of relationships such as synonymy, hyponymy, and others. Various attempts worldwide have begun focussing on the argument structure of verbs as part of developing dependenc</context>
<context position="4328" citStr="Levin, 1993" startWordPosition="703" endWordPosition="704">to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes (Kipper et al., 2000; Dang et al., 2000). Each class in the hierarchy is composed of a set of members (linked to their WordNet synsets) and a set of syntactic frames and semantic information for each frame. Currently, VerbNet has over 4,000 verb senses described (3,004 lemmas) within 191 first level classes. VerbNet has a hierarch</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternation, A Preliminary Investigation. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitch Marcus</author>
</authors>
<title>The penn treebank: A revised corpus design for extracting predicate-argument structure.</title>
<date>1994</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop,</booktitle>
<location>Princeton, NJ,</location>
<contexts>
<context position="7763" citStr="Marcus, 1994" startWordPosition="1264" endWordPosition="1265">s and Steedman (1988), which allows us to express the semantics of classes of verbs like change of state verbs whose description requires reference to a complex event structure. 2.2 PropBank In a different vein, the PropBank project (Kingsbury and Palmer, 2002) has endeavoured to describe all the most frequent verbs of English in terms of their argument structure. This project has three major differences from previous works. First, the description of each verb is accompanied by a rich set of examples drawn from real language, in this case the Wall Street Journal sections of the Penn Treebank (Marcus, 1994). Furthermore, the descriptions are based on the usages in the corpus, rather than a possible situation where the corpus was mined for sentences fitting preconceived patterns. This results in many instances which are perfectly well-formed but unexpected. The best example of this is an odd usage of the verb add: The Nasdaq composite index added 1.01 to 456.6 on paltry volume., where the context makes it clear that add is being used as a synonym for rise. Second, argument structure allows for a richer set of descriptions than merely `transitive&apos;, `unaccusative&apos;, and so forth, since any individua</context>
</contexts>
<marker>Marcus, 1994</marker>
<rawString>Mitch Marcus. 1994. The penn treebank: A revised corpus design for extracting predicate-argument structure. In Proceedings of the ARPA Human Language Technology Workshop, Princeton, NJ, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Using semantic preferences to identify verbal participation in role switching alternations.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Annual Meeting of the North American Chapter of the ACL (NAACL),</booktitle>
<pages>256--263</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="3992" citStr="McCarthy, 2000" startWordPosition="650" endWordPosition="651">part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb clas</context>
</contexts>
<marker>McCarthy, 2000</marker>
<rawString>Diana McCarthy. 2000. Using semantic preferences to identify verbal participation in role switching alternations. In Proceedings of the 1st Annual Meeting of the North American Chapter of the ACL (NAACL), pages 256{263, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distribution of argum ent structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="4019" citStr="Merlo and Stevenson, 2001" startWordPosition="652" endWordPosition="655">ng dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes (Kipper et al., 2000; D</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distribution of argum ent structure. Computational Linguistics, 27(3), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>Wordnet: A dictionary browser.</title>
<date>1985</date>
<booktitle>In Proceedings of the First International Conference on Information in Data,</booktitle>
<location>Waterloo, Ontario.</location>
<contexts>
<context position="1155" citStr="Miller, 1985" startWordPosition="180" endWordPosition="181">l then be associated with the semantic predicates for that class. 1 Introduction There can be no doubt that meaning is dependent upon a great number of factors. The difficulty in higher-level comprehension in Natural Language Processing is due to the identification of these factors as well as the successful implementation of methods for handling them. Early generative models of syntax failed to answer the meaning question because of their assumption that semantics was a natural outcome of structure, thus neglecting the other factors involved. More recent works, such as those found in WordNet (Miller, 1985; Fellbaum, 1998) and its descendents, fall short for the inverse reason: they focus solely on lexical meaning while ignoring structure altogether. Another factor in the meaning game is the relationship between individual lexical items of the same function. How are all determiners alike, for example, and how are they individually different? Are there subclasses within the class of determiners, and how do these subclasses differ from each other? Human beings are supreme pattern-matchers and assign things to categories almost to a fault. The categories into which semantically loaded items are gr</context>
<context position="3142" citStr="Miller, 1985" startWordPosition="513" endWordPosition="514"> previous work in verb classification. Even the most elementary grammars of English draw a distinction between transitive and intransitive verbs. More advanced work has refined this distinction into everlarger numbers of classes. For example, the landmark work of Levin (1993) divided over three thousand verbs into 191 classes based partly on shared semantics and partly on shared syntactic alternations. More recently, the VerbNet project at Penn (Kipper et al., 2000) incorporated Levin&apos;s verb classification to systematically create verb entries in a lexicon. On a purely semantic note, WordNet (Miller, 1985; Fellbaum, 1998) has classified much of the vocabulary of English, not just verbs, in terms of relationships such as synonymy, hyponymy, and others. Various attempts worldwide have begun focussing on the argument structure of verbs as part of developing dependency grammars. The PropBank project at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small numb</context>
</contexts>
<marker>Miller, 1985</marker>
<rawString>George Miller. 1985. Wordnet: A dictionary browser. In Proceedings of the First International Conference on Information in Data, Waterloo, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moens</author>
<author>M Steedman</author>
</authors>
<date>1988</date>
<booktitle>Temporal Ontology and Temporal Reference. Computational Linguistics,</booktitle>
<pages>14--15</pages>
<contexts>
<context position="7171" citStr="Moens and Steedman (1988)" startWordPosition="1165" endWordPosition="1168">lass. VerbNet uses a flat semantic representation in which the semantics of each syntactic frame is captured by a conjunction of predicates 1, such as motion, contact, transfer info, which can be negated or not. These predicates can take arguments over the verb complements, as well as over implicit existentially quantified event variables. Each semantic predicate in VerbNet also include a time function specifying whether the predicate is true in the preparatory (during(E)), culmination (end(E)), or consequent (result(E)) stage of an event, in a tripartite event structure is similar to that of Moens and Steedman (1988), which allows us to express the semantics of classes of verbs like change of state verbs whose description requires reference to a complex event structure. 2.2 PropBank In a different vein, the PropBank project (Kingsbury and Palmer, 2002) has endeavoured to describe all the most frequent verbs of English in terms of their argument structure. This project has three major differences from previous works. First, the description of each verb is accompanied by a rich set of examples drawn from real language, in this case the Wall Street Journal sections of the Penn Treebank (Marcus, 1994). Furthe</context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>M. Moens and M. Steedman. 1988. Temporal Ontology and Temporal Reference. Computational Linguistics, 14:15{38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Clustering verbs semantically according to their alternation behaviour. In</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00),</booktitle>
<pages>747--753</pages>
<location>Saarbrucken, Germany.</location>
<contexts>
<context position="4044" citStr="Walde, 2000" startWordPosition="658" endWordPosition="659">roject at Penn (Kingsbury and Palmer, 2002) is an example of this process for English; similar projects are underway for Czech (Hajicova etc), German (Broker 1998), and others. The FrameNet project at Berkeley (Baker et al., 1998) has classified many words in terms of their relation to a relatively small number of core semantic concepts such as `commerce&apos; and `judgment&apos;. Various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the Levin class as a gold standard for evaluation (Gildea, 2002; McCarthy, 2000; Merlo and Stevenson, 2001; Schulte im Walde, 2000). In the next two sections, we provide background on VerbNet and PropBank which play central roles in the cluster methodology presented here. 2.1 VerbNet VerbNet is a verb lexicon with syntactic and semantic information for English verbs, referring to Levin verb classes (Levin, 1993) for systematic construction of lexical entries. This lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes (Kipper et al., 2000; Dang et al., 2000). Each c</context>
</contexts>
<marker>Walde, 2000</marker>
<rawString>Sabine Schulte im Walde. 2000. Clustering verbs semantically according to their alternation behaviour. In In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00), pages 747{753, Saarbrucken, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>