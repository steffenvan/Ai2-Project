<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.9943245">
DERIVBASE: Inducing and Evaluating a
Derivational Morphology Resource for German
</title>
<author confidence="0.998968">
Britta Zeller* Jan Šnajder† Sebastian Padó*
</author>
<affiliation confidence="0.971354333333333">
*Heidelberg University, Institut für Computerlinguistik
69120 Heidelberg, Germany
†University of Zagreb, Faculty of Electrical Engineering and Computing
</affiliation>
<address confidence="0.846277">
Unska 3, 10000 Zagreb, Croatia
</address>
<email confidence="0.996903">
{zeller, pado}@cl.uni-heidelberg.de jan.snajder@fer.hr
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823222222222">
Derivational models are still an under-
researched area in computational morphol-
ogy. Even for German, a rather resource-
rich language, there is a lack of large-
coverage derivational knowledge. This pa-
per describes a rule-based framework for
inducing derivational families (i.e., clus-
ters of lemmas in derivational relation-
ships) and its application to create a high-
coverage German resource, DERIVBASE,
mapping over 280k lemmas into more than
17k non-singleton clusters. We focus on the
rule component and a qualitative and quan-
titative evaluation. Our approach achieves
up to 93% precision and 71% recall. We
attribute the high precision to the fact that
our rules are based on information from
grammar books.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994193086206897">
Morphological processing is generally recognized
as an important step for many NLP tasks. Morpho-
logical analyzers such as lemmatizers and part of
speech (POS) taggers are commonly the first NLP
tools developed for any language (Koskenniemi,
1983; Brill, 1992). They are also applied in NLP
applications where little other linguistic analysis is
performed, such as linguistic annotation of corpora
or terminology acquisition; see Daille et al. (2002)
for an informative summary.
Most work on computational morphology has
focused on inflectional morphology, that is, the
handling of grammatically determined variation of
form (Bickel and Nichols, 2001), which can be
understood, overimplifying somewhat, as a normal-
ization step. Derivational morphology, which is
concerned with the formation of new words from
existing ones, has received less attention. Exam-
ples are nominalization (to understand → the un-
derstanding), verbalization (the shelf → to shelve),
and adjectivization (the size → sizable). Part of
the reason for the relative lack of attention lies in
the morphological properties of English, such as
the presence of many zero derivations (the fish →
to fish), the dominance of suffixation, and the rel-
ative absence of stem changes in derivation. For
these reasons, simple stemming algorithms (Porter,
1980) provide a cheap and accurate approximation
to English derivation.
Two major NLP resources deal with derivation.
WordNet lists so-called “morphosemantic” rela-
tions (Fellbaum et al., 2009) for English, and a
number of proposals exist for extending WordNets
in other languages with derivational relations (Bil-
gin et al., 2004; Pala and Hlaváˇcková, 2007). Cat-
Var, the “Categorial Variation Database of English”
(Habash and Dorr, 2003), is a lexicon aimed specif-
ically at derivation. It groups English nouns, verbs,
adjectives, and adverbs into derivational equiva-
lence classes or derivational families such as
askV askerN askingN askingA
Derivational families are commonly understood as
groups of derivationally related lemmas (Daille et
al., 2002; Milin et al., 2009). The lemmas in CatVar
come from various open word classes, and multiple
words may be listed for the same POS. The above
family lists two nouns: an event noun (asking) and
an agentive noun (asker). However, CatVar does
not consider prefixation, which is why, e.g., the
adjective unasked is missing.
CatVar has found application in different areas
of English NLP. Examples are the acquisition of
paraphrases that cut across POS lines, applied, for
example, in textual entailment (Szpektor and Da-
gan, 2008; Berant et al., 2012). Then there is the
induction and extension of semantic roles resources
for predicates of various parts of speech (Meyers et
al., 2004; Green et al., 2004). Finally, CatVar has
</bodyText>
<page confidence="0.912025">
1201
</page>
<note confidence="0.913055">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.993800244444444">
been used as a lexical resource to generate sentence
intersections (Thadani and McKeown, 2011).
In this paper, we describe the project of obtain-
ing derivational knowledge for German to enable
similar applications. Even though there are two
derivational resources for this language, IMSLEX
(Fitschen, 2004) and CELEX (Baayen et al., 1996),
both have shortcomings. The former does not ap-
pear to be publicly available, and the latter has a
limited coverage (50k lemmas) and does not ex-
plicitly represent derivational relationships within
families, which are necessary for fine-grained op-
timization of families. For this reason, we look
into building a novel derivational resource for Ger-
man. Unfortuantely, the approach used to build
CatVar cannot be adopted: it builds on a collection
of high-quality lexical-semantic resources such as
NOMLEX (Macleod et al., 1998), which are not
available for German.
Instead, we employ a rule-based framework to
define derivation rules that cover both suffixation
and prefixation and describes stem changes. Fol-
lowing the work of Šnajder and Dalbelo Baši´c
(2010), we define the derivational processes using
derivational rules and higher-order string transfor-
mation functions. The derivational rules induce
a partition of the language’s lemmas into deriva-
tional families. Our method is applicable to many
languages if the following are available: (1) a com-
prehensive set of lemmas (optionally including gen-
der information); (2) knowledge about admissible
derivational patterns, which can be gathered, for
example, from linguistics textbooks.
The result is a freely available high-precision
high-coverage resource for German derivational
morphology that has a structure parallel to Cat-
Var, but was obtained without using manually con-
structed lexical-semantic resources. We conduct
a thorough evaluation of the induced derivational
families both regarding precision and recall.
Plan of the paper. Section 2 discusses prior
work. Section 3 defines our derivation model that
is applied to German in Section 4. Sections 5 and
6 present our evaluation setup and results. Section
7 concludes the paper and outlines future work.
</bodyText>
<sectionHeader confidence="0.999715" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999871594594595">
Computational models of morphology have a long
tradition. Koskenniemi (1983) was the first who
analyzed and generated morphological phenomena
computationally. His two-level theory has been
applied in finite state transducers (FST) for several
languages (Karttunen and Beesley, 2005).
Many recent approaches automatically induce
morphological information from corpora. They
are either based solely on corpus statistics (Déjean,
1998), measure semantic similarity between input
and output lemma (Schone and Jurafsky, 2000),
or bootstrap derivation rules starting from seed ex-
amples (Piasecki et al., 2012). Hammarström and
Borin (2011) give an extensive overview of state-
of-the-art unsupervised learning of morphology.
Unsupervised approaches operate at the level of
word-forms and have complementary strengths and
weaknesses to rule-based approaches. On the up-
side, they do not require linguistic knowledge; on
the downside, they have a harder time distinguish-
ing between derivation and inflection, which may
result in lower precision, and are not guaranteed
to yield analyses that correspond to linguistic intu-
ition. An exception is the work by Gaussier (1999),
who applies an unsupervised model to construct
derivational families for French.
For German, several morphological tools exist.
Morphix is a classification-based analyzer and gen-
erator of German words on the inflectional level
(Finkler and Neumann, 1988). SMOR (Schmid
et al., 2004) employs a finite-state transducer to
analyze German words at the inflectional, deriva-
tional, and compositional level, and has been used
in other morphological analyzers, e.g., Morphisto
(Zielinski and Simon, 2008). The site canoonet1 of-
fers broad-coverage information about the German
language including derivational word formation.
</bodyText>
<sectionHeader confidence="0.998092" genericHeader="method">
3 Framework
</sectionHeader>
<bodyText confidence="0.9999245">
In this section, we describe our rule-based model of
derivation, its operation to define derivational fam-
ilies, and the application of the model to German.
We note that the model is purely surface-based,
i.e., it does not model any semantic regularities be-
yond those implicit in string transformations. We
begin by outlining the characteristics of German
derivational morphology.
</bodyText>
<subsectionHeader confidence="0.994642">
3.1 German Derivational Morphology
</subsectionHeader>
<bodyText confidence="0.9979584">
As German is a morphologically complex language,
we analyzed its derivation processes before imple-
menting our rule-based model. We relied on tradi-
tional grammar books and lexicons, e.g., Hoeppner
(1980) and Augst (1975), in order to linguistically
</bodyText>
<footnote confidence="0.989908">
1http://canoo.net
</footnote>
<page confidence="0.996539">
1202
</page>
<bodyText confidence="0.998775142857143">
justify our assumptions as well as to achieve the
best possible precision and coverage.
We concentrate on German derivational pro-
cesses that involve nouns, verbs, and adjectives.2
Nouns are simple to recognize due to capitaliza-
tion: stauenV – StauN (to jam – jam), essenV –
EssenN (to eat – food). Verbs bear three typical
suffixes (-en, -eln, -ern). An example of a derived
verb is festA – festigenV (tight – to tighten), where
-ig is the derivational suffix. Adjectivization works
similarlty: TagN – täglichA (day – daily).
This example shows that derivation can also in-
volve stem changes in the form of umlaut (e.g.,
a → ä) and ablaut shift, e.g., siedenV – SudN
(to boil – infusion). Other frequent processes
in German derivation are circumfixation (HaftN
– inhaftierenV (arrest – to arrest)) and prefixation
(hebenV – behebenV (to raise – to remedy)). Pre-
fixation often indicates a semantic shift, either in
terms of the general meaning (as above) or in terms
of the polarity ( klarA – unklarA (clear – unclear)).
Also note that affixes can be either Germanic, e.g.,
ölen – Ölung (to oil – oiling), or Latin/Greek, e.g.,
generieren – Generator (to generate – generator).
As this analysis shows, derivation in German
involves transformation as well as affixation pro-
cesses, which has to be taken into account when
modeling a derivational resource.
</bodyText>
<subsectionHeader confidence="0.999517">
3.2 A Rule-based Derivation Model
</subsectionHeader>
<bodyText confidence="0.998819055555555">
The purpose of a derivational model is to define
a set of transformations that correspond to valid
derivational word formation rules. Rule-based
frameworks offer convenient representations for
derivational morphology because they can take ad-
vantage of linguistic knowledge about derivation,
have interpretable representations, and can be fine-
tuned for high precision. The choice of the frame-
work is in principle arbitrary, as long as it can con-
veniently express the derivational phenomena of
a language. Typically used for this purpose are
two-level formalism rules (Karttunen and Beesley,
1992) or XFST replace rules (Beesley and Kart-
tunen, 2003).
In this paper, we adopt the modeling framework
proposed by Šnajder and Dalbelo Baši´c (2010).
The framework corresponds closely to simple,
human-readable descriptions in traditional gram-
</bodyText>
<footnote confidence="0.82569375">
2We ignore adverb derivation; the German language dis-
tinguishes between adverbial adjectives and adverbs, the latter
being a rather unproductive class and thus of no interest for
derivation (Schiller et al., 1999).
</footnote>
<bodyText confidence="0.99404498">
mar books. The expressiveness of the formalism
is equivalent to the replacement rules commonly
used in finite state frameworks, thus the rules can
be compiled into FSTs for efficient processing.
The framework makes a clear distinction be-
tween inflectional and derivational morphology and
provides separate modeling components for these
two; we only make use of the derivation modeling
component. We use an implementation of the mod-
eling framework in Haskell. For details, see the
studies by Šnajder and Dalbelo Baši´c (2008) and
Šnajder and Dalbelo Baši´c (2010).
The building blocks of the derivational compo-
nent are derivational rules (patterns) and transfor-
mation functions. A derivational rule describes the
derivation of a derived word from a basis word. A
derivational rule d is defined as a triple:
d = (t, P1, P2) (1)
where t is the transformation function that maps
the word’s stem (or lemma) into the derived word’s
stem (or lemma), while P1 and P2 are the sets of
inflectional paradigms of the basis word and the
derived word, respectively, which specify the mor-
phological properties of the rule’s input and output.
For German, our study assumes that inflectional
paradigms are combinations of part-of-speech and
gender information (for nouns).
A transformation function t : S → p(S) maps
strings to a set of strings, representing possible
transformations. At the lowest level, t is defined
in terms of atomic string replacement operations
(replacement of prefixes, suffixes, and infixes). The
framework then uses the notion of higher-order
functions – functions that take other transforma-
tions as arguments and return new transformations
as results – to succinctly define common deriva-
tional processes such as prefixation, suffixation,
and stem change. More complex word-formation
rules, such as those combining prefixation and suf-
fixation, can be obtained straightforwardly by func-
tional composition.
Table 1 summarizes the syntax we use for trans-
formation functions and shows two example deriva-
tional rules. Rule 1 defines an English adjectiviza-
tion rule. It uses the conditional try operator to
apply to nouns with and without the -ion suffix
(action – active, instinct – instinctive). Infix re-
placement is used to model stem alternation, as
shown in rule 2 for German nominalization, e.g.,
vermachtA – VermächtnisN (bequethed – bequest).
</bodyText>
<page confidence="0.903339">
1203
</page>
<figure confidence="0.376220882352941">
Function Description
sfx(s) concatenate the suffix s
dsfx(s) delete the suffix s
aifx(s1, s2) alternate the infix s1 to s2
try(t) perform transformation t, if possible
opt(t) optionally perform transformation t
uml alternate infixes for an umlaut shift:
uml = aifx({(a, ä), (o, ö), (u, ü)})
Examples
(sfx(ive) o try(dsfx(ion)), Ar , A)
1 (EN)
“derive -ive adjectives from nouns poten-
tially ending in -ion”
(sfx(nis) o try(uml), A, Ar )
2 (DE)
“derive -nis nouns from adjectives with
optional umlaut creation”
</figure>
<tableCaption confidence="0.970076">
Table 1: Transformation functions and exemplary
</tableCaption>
<bodyText confidence="0.69332775">
derivational rules in the framework by Šnajder and
Dalbelo Baši´c (2010)
N and A denote the paradigms for nouns (without
gender restriction) and adjectives, respectively.
</bodyText>
<subsectionHeader confidence="0.999182">
3.3 Induction of Derivational Families
</subsectionHeader>
<bodyText confidence="0.999989833333333">
Recall that our goal is to induce derivational fami-
lies, that is, classes of derivationally related words.
We define derivational families on the basis of
derivational rules as follows.
Given a lemma-paradigm pair (l, p) as input,
a single derivational rule d = (t, P1, P2) gen-
erates a set of possible derivations Ld(l, p) =
{(l1, p1), ... , (ln, pn)}, where p E P1 and pi E P2
for all i. Given a set of derivational rules D, we de-
fine a binary derivation relation →D between two
lemma-paradigm pairs that holds if the second pair
can be derived from the first one as:
</bodyText>
<equation confidence="0.936319">
(l1,p1) →D (l2,p2) (2)
iff Id E D. (l2,p2) E Ld(l1,p1)
</equation>
<bodyText confidence="0.999675">
Let L denote the set of lemma-paradigm pairs. The
set of derivational families defined by D on L is
given by the equivalence classes of the transitive,
symmetric, and reflexive closure of →D over L.
Note that in addition to the quality of the rules,
the properties of L plays a central role in the quality
of the induced families. High coverage of L is im-
portant because the transitivity of →D ranges only
over lemmas in L, so low coverage of L may result
in fragmented derivational families. However, L
should also not contain erroneous lemma-paradigm
pairs. The reason is that the derivational rules only
define admissible derivations, which need not be
morphologically valid, and therefore routinely over-
generate; L plays an important role in filtering out
derivations that are not attested in the data.
</bodyText>
<sectionHeader confidence="0.873174" genericHeader="method">
4 Building the Resource
</sectionHeader>
<subsectionHeader confidence="0.992177">
4.1 Derivational Rules
</subsectionHeader>
<bodyText confidence="0.999763152173913">
We implemented the derivational rules from Hoepp-
ner (1980) for verbs, nouns, and adjectives, cov-
ering all processes described in Section 3.1 (zero
derivation, prefixation, suffixation, circumfixation,
and stem changes). We found many derivational
patterns in German to be conceptually simple (e.g.,
verb-noun zero derivation) so that substantial cov-
erage can already be achieved with very simple
transformation functions. However, there are many
more complex patterns (e.g., suffixation combined
with optional stem changes) that in sum also af-
fect a considerable number of lemmas, which re-
quired us to either implement low-coverage rules
or generalize existing rules. In order to preserve
precision as much as possible, we restricted rule
application by using try instead of opt, and by using
gender information from the noun paradigms (for
example, some rules only apply to masculine nouns
and produce female nouns). As a result, we end
up with high-coverage rules, such as derivations
of person-denoting nouns (SchuleN – SchülerN
(school – pupil)) as well as high-accuracy rules
such as negation prefixes (PolN – GegenpolN (pole
– antipole)).
Even though we did not focus on the explana-
tory relevance of rules, we found that the under-
lying modeling formalism, and the methodology
used to develop the model, offer substantial lin-
guistic plausibility in practice. We had to resort to
heuristics mostly for words with derivational trans-
formations that are motivated by Latin or Greek
morphology and do not occur regularly in German,
e.g., selegierenV – SelektionN (select – selection).
In the initial development phase, we imple-
mented 154 rules, which took about 22 person-
hours. We then revised the rules with the aim of
increasing both precision and recall. To this end,
we constructed a development set comprised of a
sample of 1,000 derivational families induced us-
ing our rules. On this set, we inspected the deriva-
tional families for false positives, identified the
problematic rules, and identified unused and redun-
dant rules. In order to identify the false negatives,
we additionally sampled a list of 1,000 lemmas and
used string distance measures (cf. Section 5.1) to re-
trieve the 10 most similar words for each lemma not
</bodyText>
<page confidence="0.977413">
1204
</page>
<table confidence="0.9998007">
Process N-N N-A N-V A-A A-V V-V
Zero derivation – 1 5 – – –
Prefixation 10 – 5 5 2 9
+ Stem change – – 3 – 1 –
Suffixation 15 35 20 1 14 –
+ Stem change 2 8 7 – 3 1
Circumfixation – – 1 – – –
+ Stem change – – 1 – – –
Stem change – – 7 – – 2
Total 27 44 49 6 20 12
</table>
<tableCaption confidence="0.991853">
Table 2: Breakdown of derivation rules by category
</tableCaption>
<bodyText confidence="0.981678478260869">
of the basis and the derived word
already covered by the derivational families. The
refinement process took another 8 person-hours. It
revealed three redundant rules and seven missing
rules, leading us to a total of 158 rules.
Table 2 shows the distribution of rules with re-
spect to the derivational processes they implement
and the part of speech combinations for the ba-
sis and the derived words. All affixations occur
both with and without stem changes, mostly um-
laut shifts. Suffixation is by far the most frequently
used derivation process, and noun-verb derivation
is most diverse in terms of derivational processes.
We also estimated the reliability of derivational
rules by analyzing the accuracy of each rule on
the development set. We assigned each rule a con-
fidence rating on a three-level scale: L3 – very
reliable (high-accuracy rules), L2 – generally reli-
able, and L1 – less reliable (low-accuracy rules).
We manually analyzed the correctness of rule ap-
plications for 100 derivational families of different
size (counting 2 up to 114 lemmas), and assigned
55, 79, and 24 rules to L3, L2 and L1, respectively.
</bodyText>
<subsectionHeader confidence="0.994584">
4.2 Data and Preprocessing
</subsectionHeader>
<bodyText confidence="0.999986447368421">
For an accurate application of nominal derivation
rules, we need a lemma list with POS and gender
information. We POS-tag and lemmatize SDEWAC,
a large German-language web corpus from which
boilerplate paragraphs, ungrammatical sentences,
and duplicate pages were removed (Faaß et al.,
2010). For POS tagging and lemmatization, we use
TreeTagger (Schmid, 1994) and determine gram-
matical gender with the morphological layer of
the MATE Tools (Bohnet, 2010). We treat proper
nouns like common nouns.
We apply three language-specific filtering steps
based on observations in Section 3.1. First, we dis-
card non-capitalized nominal lemmas. Second, we
deleted verbal lemmas not ending in verb suffixes.
Third, we removed frequently occurring erroneous
comparative forms of adjectives (usually formed
by adding -er, like neuer/newer) by checking for
the presence of lemmas without -er (neu / new).
An additional complication in German concerns
prefix verbs, because prefix is separated in tensed
instances. For example, the 3rd person male singu-
lar of aufhören (to stop) is er hört auf (he stops).
Since most prefixes double as prepositions, the cor-
rect lemmas can only be reconstructed by parsing.
We parse the corpus using the MST parser (Mc-
Donald et al., 2006) and recover prefix verbs by
searching for instances of the dependency relation
labeled PTKVZ.
Since SDEWAC, as a web corpus, still contains
errors, we only take into account lemmas that occur
three times or more in the corpus. Considering the
size of SDEWAC, we consider this as a conservative
filtering step that preserves high recall and provides
a comprehensive basis for evaluation. After prepro-
cessing and filtering, we run the induction of the
derivational families as explained in Section 3 to
obtain the DERIVBASE resource.
</bodyText>
<subsectionHeader confidence="0.99928">
4.3 Statistics on DERIVBASE
</subsectionHeader>
<bodyText confidence="0.999812944444444">
The preparation of the SDEWAC corpus as ex-
plained in Section 4.2 yields 280,336 lemmas,
which we cover with our resource. We induced
a total of 239,680 derivational families from this
data, with 17,799 non-singletons and 221,881 sin-
gletons (most of them due to compound nouns).
11,039 of the families consist of two lemmas, while
the biggest contains 116 lemmas (an overgenerated
family). The biggest family with perfect precision
(i.e., it contains only morphologically related lem-
mas) contains 40 lemmas, e.g., haltenV, erhaltenV,
VerhältnisN (to hold, to uphold, relation), etc. For
comparison, CatVar v2.1 contains only 82,676 lem-
mas in 13,368 non-singleton clusters and 38,604
singletons.
The following sample family has seven members
across all three POSes and includes prefixation,
suffixation, and infix umlaut shifts:
</bodyText>
<listItem confidence="0.5381656">
taubA (numbA), TaubheitNf (numbnessN),
betäubenV (to anesthetizeV ), BetäubungNf
(anesthesiaN), betäubtA (anesthetizedA),
betäubendA (anestheticA), BetäubenNn
(act of anesthetizingN)
</listItem>
<page confidence="0.987305">
1205
</page>
<sectionHeader confidence="0.997535" genericHeader="method">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.962426">
5.1 Baselines
</subsectionHeader>
<bodyText confidence="0.999932181818182">
We use two baselines against which we compare
the induced derivational families: (1) clusters ob-
tained with the German version of Porter’s stem-
mer (Porter, 1980)3 and (2) clusters obtained us-
ing string distance-based clustering. We have con-
sidered a number of string distance measures and
tested them on the development set (cf. Section
4.1). The measure proposed by Majumder et al.
(2007) turned out to be the most effective in cap-
turing suffixal variation. For words X and Y , it is
defined as
</bodyText>
<equation confidence="0.996336666666667">
n − m + 1
D4(X, Y ) =
n + 1
</equation>
<bodyText confidence="0.9995812">
where m is the position of left-most character mis-
match, and n + 1 is the length of the longer of
the two strings. To capture prefixal variation and
stem changes, we use the n-gram based measure
proposed by Adamson and Boreham (1974):
</bodyText>
<equation confidence="0.947725333333333">
2c
Dicen(X, Y ) = 1 − (4)
x + y
</equation>
<bodyText confidence="0.999892066666667">
where x and y are the total number of distinct n-
grams in X and Y , respectively, and c is the number
of distinct n-grams shared by both words. In our
experiments, the best performance was achieved
with n = 3.
We used hierarchical agglomerative clustering
with average linkage. To reduce the computational
complexity, we performed a preclustering step by
recursively partitioning the set of lemmas sharing
the same prefix into partitions of manageable size
(1000 lemmas). Initially, we set the number of clus-
ters to be roughly equal to the number of induced
derivational families. For the final evaluation, we
optimized the number of clusters based on F1 score
on calibration and validation sets (cf. Section 5.3).
</bodyText>
<subsectionHeader confidence="0.994761">
5.2 Evaluation Methodology
</subsectionHeader>
<bodyText confidence="0.999887625">
The induction of derivational families could be eval-
uated globally as a clustering problem. Unfortu-
nately, cluster evaluation is a non-trivial task for
which there is no consensus on the best approach
(Amigó et al., 2009). We decided to perform our
evaluation at the level of pairs: we manually judge
for a set of pairs whether they are derivationally
related or not.
</bodyText>
<footnote confidence="0.899147">
3http://snowball.tartarus.org
</footnote>
<bodyText confidence="0.9999961">
We obtain the gold standard for this evaluation
by sampling lemmas from the lemma list. With ran-
dom sampling, the evaluation would be unrealistic
because a vast majority of pairs would be deriva-
tionally unrelated and count as true negatives in our
analysis. Moreover, in order to reliably estimate the
overall precision of the obtained derivational fam-
ilies, we need to evaluate on pairs sampled from
these families. On the other hand, in order to assess
recall, we need to sample from pairs that are not
included in our derivational families.
To obtain reliable estimates of both precision
and recall, we decided to draw two different sam-
ples: (1) a sample of lemma pairs sampled from
the induced derivational families, on which we
estimate precision (P-sample) and (2) a sample
of lemma pairs sampled from the set of possibly
derivationally related lemma pairs, on which we
estimate recall (R-sample). In both cases, pairs
(l1, l2) are sampled in two steps: first a lemma l1
is drawn from a non-singleton family, then the sec-
ond lemma l2 is drawn from the derivational family
of l1 (P-sample) or the set of lemmas possibly re-
lated to l1 (R-sample). The set of possibly related
lemmas is a union of the derivational family of l1,
the clusters of l1 obtained with the baseline meth-
ods, and k lemmas most similar to l1 according to
the two string distance measures. We use k = 7
in our experiments. This is based on preliminary
experiments on the development set (cf. Section
4.1), which showed that k = 7 retrieves about 92%
of the related lemmas retrieved for k = 20 with
a much smaller number of true negatives. Thus,
the evaluation on the R-sample might overestimate
the recall, but only slightly so, while the P-sample
yields a reliable estimate of precision by reducing
the number of true negatives in the sample.
Both samples contain 2400 lemma pairs each.
Lemmas included in the development set (Sec-
tion 4.1) were excluded from sampling.
</bodyText>
<subsectionHeader confidence="0.998633">
5.3 Gold Standard Annotation
</subsectionHeader>
<bodyText confidence="0.999818142857143">
Two German native speakers annotated the pairs
from the P-sample and R-samples. We defined five
categories into which all lemma pairs are classified
as shown in Table 3. We count R and M as positives
and N, C, L as negatives (cf. Section 3).4 Note
that this binary distinction would be sufficient to
compute recall and precision. However, the more
</bodyText>
<footnote confidence="0.835834">
4Ambiguous lemmas are categorized as positive (R or M)
if there is a matching sense.
</footnote>
<figure confidence="0.734969">
1 (3)
2i−m
n
i=m
1206
Label Description Example
R l1 and l2 are morphologi- kratzigA – verkratztA
cally and semantically re- (scratchy – scuffed)
lated
M l1 and l2 are morphologi- bombenV – bombigA
cally but not semantically (to bomb – smashing)
related
N no morphological relation belebtA – lobenV
(lively – to praise)
C no derivational relation, FilmendeN – filmenV
but the pair is composi- (end offilm – to film)
tionally related
L not a valid lemma (mis- HaufeN – HäufungN
</figure>
<tableCaption confidence="0.742812666666667">
lemmatization, wrong (N/A – accumulation)
gender, foreign words)
Table 3: Categories for lemma pair classification
</tableCaption>
<table confidence="0.960556">
Agreement Cohen’s r,
R-sample 0.85 0.79
P-sample 0.86 0.70
</table>
<tableCaption confidence="0.9116965">
Table 4: Inter-annotator agreement on validation
sample
</tableCaption>
<bodyText confidence="0.987681366666667">
fine-grained five-class annotation scheme provides
a more detailed picture. The separation between R
and M gives a deeper insight into the semantics of
the derivational families. Distinguishing between
C and N, in turn, allows us to identify the pairs that
are derivationally unrelated, but compositionally
related, e.g., EhemannN – EhefrauN (husband –
wife).
We first carried out a calibration phase in which
the annotators double-annotated 200 pairs from
each of the two samples and refined the annotation
guidelines. In a subsequent validation phase, we
computed inter-annotator agreements on the anno-
tations of another 200 pairs each from the P- and
the R-samples. Table 4 shows the proportion of
identical annotations by both annotators as well as
Cohen’s κ score (Cohen, 1968). We achieve sub-
stantial agreement for κ (Carletta, 1996). On the
P-sample, κ is a little lower because the distribu-
tion of the categories is skewed towards R, which
makes an agreement by chance more probable.
In our opinion, the IAA results were sufficiently
high to switch to single annotation for the produc-
tion phase. Here, each annotator annotated another
1000 pairs from the P-sample and R-sample so
that the final test set consists of 2000 pairs from
each sample. The P-sample contains 1663 positive
(R+M) and 337 negative (N+C+L) pairs, respec-
tively, the R-sample contains 575 positive and 1425
negative pairs. As expected, there are more positive
</bodyText>
<table confidence="0.9997367">
Method Precision Recall
P-sample R-sample
DERIVBASE (initial) 0.83 0.58
DERIVBASE-L123 0.83 0.71
DERIVBASE-L23 0.88 0.61
DERIVBASE-L3 0.93 0.35
R-sample
Stemming 0.66 0.07
String distance D4 0.36 0.20
String distance Dice3 0.23 0.23
</table>
<tableCaption confidence="0.999732">
Table 5: Precision and recall on test samples
</tableCaption>
<bodyText confidence="0.9661915">
pairs in the P-sample and more negative pairs in
the R-sample.
</bodyText>
<sectionHeader confidence="0.999978" genericHeader="evaluation">
6 Results
</sectionHeader>
<subsectionHeader confidence="0.999442">
6.1 Quantitative Evaluation
</subsectionHeader>
<bodyText confidence="0.999310424242424">
Table 5 presents the overall results. We eval-
uate four variants of the induced derivational
families: those obtained before rule refinement
(DERIVBASE initial), and three variants after rule
refinement: using all rules (DERIVBASE-L123),
excluding the least reliable rules (DERIVBASE-
L23), and using only highly reliable rules
(DERIVBASE-L3).
We measure the precision of our method on the
P-sample and recall on the R-sample. For the base-
lines, precision was also computed on the R-sample
(computing it on P-sample, which is obtained from
the induced derivational families, would severely
underestimate the number of false positives). We
omit the Fi score because its use for precision and
recall estimates from different samples is unclear.
DERIVBASE reaches 83% precision when us-
ing all rules and 93% precision when using only
highly reliable rules. DERIVBASE-L123 achieves
the highest recall, outperforming other methods
and variants by a large margin. Refinement of the
initial model has produced a significant improve-
ment in recall without losses in precision. The base-
lines perform worse than our method: the stemmer
we use is rather conservative, which fragments the
families and leads to a very low recall. The string
distance-based approaches achieve more balanced
precision and recall scores. Note that for these
methods, precision and recall can be traded off
against each other by varying the number of clus-
ters; we chose the number of clusters by optimizing
the Fi score on the calibration and validaton sets.
All subsequent analyses refer to DERIVBASE-
</bodyText>
<page confidence="0.965975">
1207
</page>
<table confidence="0.999567846153846">
Label TPs FPs FNs
P-sample P-sample R-sample
R 1,492 – 107
M 171 – 60
N – 216 –
C – 7 –
L – 114 –
Total 1,663 337 167
Accuracy
Coverage High Low Total
High 18 – 18
Low 53 21 74
Total 71 21 92
</table>
<tableCaption confidence="0.5437705">
Table 6: Proportions of accuracy and coverage for
direct derivations (measured on P-sample)
</tableCaption>
<table confidence="0.99995375">
P R P R
N-N 0.78 0.68 N-A 0.89 0.83
A-A 0.87 0.70 N-V 0.79 0.68
V-V 0.55 0.24 A-V 0.88 0.73
</table>
<tableCaption confidence="0.996003">
Table 7: Precision and recall across different part
</tableCaption>
<bodyText confidence="0.978584739130435">
of speech (first POS: basis; second POS: derived
word)
L123, which is the model with the highest recall.
If optimal precision is required, DERIVBASE-L3
should however be preferred.
Analysis by frequency. We cross-classified our
rules according to high/low accuracy and high/low
coverage based on the pairs in the P-sample.
We only considered directly derivationally related
(→D) pairs and defined “high accuracy” and “high
coverage” as all rules above the 25th percentile in
terms of accuracy and coverage, respectively. The
results are shown in Table 6: all high-coverage
rules are also highly accurate. Most rules are ac-
curate but infrequent. Only 21 rules have a low
accuracy, but all of them apply infrequently.
Analysis by parts of speech. Table 7 shows pre-
cision and recall values for different part of speech
combinations for the basis and derived words. High
precision and recall are achieved for N-A deriva-
tions. The recall is lowest for V-V derivations,
suggesting that the derivational phenomena for this
POS combination are not yet covered satisfactorily.
</bodyText>
<subsectionHeader confidence="0.999552">
6.2 Error analysis
</subsectionHeader>
<bodyText confidence="0.9998021">
Table 8 shows the frequencies of true positives and
false positives on the P-sample and false negatives
on the R-sample for each annotated category. True
negatives are not reported, since their analysis gives
no deeper insight.
True positives. In our analysis we treated both R
and M pairs as related, but it is interesting to see
how many of the true positives are in fact semanti-
cally unrelated. Out of 1,663 pairs, 90% are seman-
tically as well as morphologically related (R), e.g.,
</bodyText>
<tableCaption confidence="0.987721">
Table 8: Predictions over annotated categories
</tableCaption>
<construct confidence="0.404948">
alkoholisierenV – antialkoholischA (to alcoholize
– nonalcoholic), BeschuldigungN – unschuldigA
</construct>
<bodyText confidence="0.986174289473684">
(accusation – innocent). Most R pairs result from
high-accuracy rules, i.e., zero derivation, negation
prefixation and simple suffixation. The remaining
10% are only morphologically related (M), e.g.,
beschwingtA – schwingenV (cheerful – to swing),
StolzierenN – stolzA (strut – proud). In both pairs,
the two lemmas share a common semantic concept
– i.e., being in motion or being proud – but nowa-
day’s meanings have grown apart from each other.
Among the M true positives, we observe prefixa-
tion derivations in 66% of the cases, often involv-
ing prefixation at both lemmas, e.g., ErdenklicheN
– bedenklichA (imaginable – questionable).
False positives. We observe many errors in pairs
involving short lemmas, e.g., GenN – genierenV
(gene – to be embarrassed), where orthographic
context is unsufficient to reject the derivation.
About 64% of the 337 incorrect pairs are of class
N (unrelated lemmas). For example, the rule for
deriving nouns denoting a male person incorrectly
links MorseN – MörserN (Morse – mortar). Tran-
sitively applied rules often produce incorrect pairs;
e.g., SpeicheN – speicherbarA (spoke – storable)
results from the rule chain SpeicheN → SpeicherN
→ speichernV → speicherbarA (spoke → storage
→ to store → storable). Chains that involve ablaut
shifts (cf. Section 3.1) can lead to surprising re-
sults, e.g., ErringungN – rangiertA (achievement –
shunted). Meanwhile, some pairs judged as un-
related by the annotators might conceivably be
weakly related, such as schlürfenV and schlurfenV
(to sip – to shuffle), both of which refer to specific
long drawn out sounds. About 20% out of these un-
related lemma pairs is due to derivations between
proper nouns (PNs) and common nouns. This hap-
pens especially for short PNs (cf. the above exam-
ple of Morse). However, since PNs also participate
in valid derivations (e.g., Chaplin – chaplinesque),
</bodyText>
<page confidence="0.98075">
1208
</page>
<bodyText confidence="0.999981827586207">
one could investigate their impact on derivations
rather than omitting them.
Errors of the category L – 34% of the false posi-
tives – are caused during preprocessing by the lem-
matizer. They cannot be blamed on our derivational
model, but of course form part of the output.
False negatives. Errors of this type are due to
missing derivation rules, erroneous rules that leave
some lemmas undiscovered, or the absence of lem-
mas in the corpus required for transitive closure.
About 64% of the 167 missed pairs are of category
R. About half of these pairs result from a lack of
prefixation rules – mainly affecting verbs – with a
wide variety of prefixes (zu-, um-, etc.), including
prepositional prefixes like herum- (around) or fiber-
(over). We intentionally ignored these derivations,
since they frequently lead to semantically unrelated
pairs. In fact, merely five of the remaining 36%
false negative pairs (M) do not involve prefixation.
However, this analysis as well as the rather low cov-
erage for verb-involved rules (cf. Table 7) shows
that DERIVBASE might benefit from more prefix
rules. Apart from the lack of prefixation coverage
and a few other, rather infrequent rules, we did not
find any substantial deficits. Most of the remaining
errors are due to German idiosyncrasies and excep-
tional derivations, e.g., fahrenV – FahrtN (drive –
trip), where the regular zero derivation would result
in Fahr.
</bodyText>
<sectionHeader confidence="0.987887" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999756555555556">
In this paper, we present DERIVBASE, a deriva-
tional resource for German based on a rule-based
framework. A few work days were enough to build
the underlying rules with the aid of grammar text-
books. We collected derivational families for over
280,000 lemmas with high accuracy as well as solid
coverage. The resource is freely available.5
Our approach for compiling a derivational re-
source is not restricted to German. In addition
to the typologically most similar Germanic and
Romance languages, it is also applicable to agglu-
tinative languages like Finnish, or other fusional
languages like Russian. Its main requirements are
a large list of lemmas for the language (optionally
with further morphological features) and linguistic
literature on morphological patterns.
We have employed an evaluation method that
uses two separate samples to assess precision and
</bodyText>
<footnote confidence="0.849465">
5http://goo.gl/7KG2U; license cc-by-sa 3.0
</footnote>
<bodyText confidence="0.999967235294118">
recall to deal with the high number of false neg-
atives. Our analyses indicate two interesting di-
rections for future work: (a) specific handling of
proper nouns, which partake in specific derivations;
and (b) the use of graph clustering instead of the
transitive closure to avoid errors resulting from
long transitive chains.
Finally, we plan to employ distributional seman-
tics methods (Turney and Pantel, 2010) to help re-
move semantically unrelated pairs as well as distin-
guish automatically between only morphologically
(M) or both morphologically and semantically (R)
related pairs. Last, but not least, this allows us to
group derivation rules according to their semantic
properties. For example, nouns with -er suffixes
often denote persons and are agentivizations of a
basis word (Bilgin et al., 2004).
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999924714285714">
The first and third authors were supported by
the EC project EXCITEMENT (FP7 ICT-287923).
The second author was supported by the Croatian
Science Foundation (project 02.03/162: “Deriva-
tional Semantic Models for Information Retrieval”).
We thank the reviewers for their constructive com-
ments.
</bodyText>
<sectionHeader confidence="0.986213" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.872122652173913">
George W. Adamson and Jillian Boreham. 1974. The
use of an association measure based on character
structure to identify semantically related pairs of
words and document titles. Information Processing
and Management, 10(7/8):253–260.
Enrique Amigó, Julio Gonzalo, Javier Artiles, and Fe-
lisa Verdejo. 2009. A comparison of extrinsic
clustering evaluation metrics based on formal con-
straints. Information Retrieval, 12(4):461–486.
Gerhard Augst. 1975. Lexikon zur Wortbil-
dung. Forschungsberichte des Instituts für Deutsche
Sprache. Narr, Tübingen.
Harald R. Baayen, Richard Piepenbrock, and Leon Gu-
likers. 1996. The CELEX Lexical Database. Re-
lease 2. LDC96L14. Linguistic Data Consortium,
University of Pennsylvania, Philadelphia, PA.
Kenneth R Beesley and Lauri Karttunen. 2003. Finite
state morphology, volume 18. CSLI publications
Stanford.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2012. Learning entailment relations by global graph
structure optimization. Computational Linguistics,
38(1):73–111.
</reference>
<page confidence="0.948525">
1209
</page>
<reference confidence="0.997801731481482">
Balthazar Bickel and Johanna Nichols. 2001. Inflec-
tional morphology. In Timothy Shopen, editor, Lan-
guage Typology and Syntactic Description, Volume
III: Grammatical categories and the lexicon, pages
169–240. CUP, Cambridge.
Orhan Bilgin, Özlem Qetino˘glu, and Kemal Oflazer.
2004. Morphosemantic relations in and across
Wordnets. In Proceedings of the Global WordNet
Conference, pages 60–66, Brno, Czech Republic.
Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 89–97, Beijing, China.
Eric Brill. 1992. A simple rule-based part of speech
tagger. In Proceedings of the Workshop on Speech
and Natural Language, pages 112–116, Harriman,
New York.
Jean C. Carletta. 1996. Assessing agreement on clas-
sification tasks: the kappa statistic. Computational
Linguistics, 22(2):249–254.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
agreement with provision for scaled disagreement or
partial credit. Psychological Bulletin, 70:213–220.
Béatrice Daille, Cécile Fabre, and Pascale Sébillot.
2002. Applications of computational morphology.
In Paul Boucher, editor, Many Morphologies, pages
210–234. Cascadilla Press.
Hervé Déjean. 1998. Morphemes as necessary concept
for structures discovery from untagged corpora. In
Proceedings of the Joint Conferences on New Meth-
ods in Language Processing and Computational Nat-
ural Language Learning, pages 295–298, Sydney,
Australia.
Gertrud Faaß, Ulrich Heid, and Helmut Schmid. 2010.
Design and application of a gold standard for mor-
phological analysis: SMOR in validation. In Pro-
ceedings of the Seventh International Conference
on Language Resources and Evaluation, pages 803–
810.
Christiane Fellbaum, Anne Osherson, and Peter Clark.
2009. Putting semantics into WordNet’s &amp;quot;morphose-
mantic&amp;quot; links. In Proceedings of the Third Language
and Technology Conference, pages 350–358, Poz-
na´n, Poland.
Wolfgang Finkler and Günter Neumann. 1988. Mor-
phix - a fast realization of a classification-based ap-
proach to morphology. In Proceedings of 4th Aus-
trian Conference ofArtificial Intelligence, pages 11–
19, Vienna, Austria.
Arne Fitschen. 2004. Ein computerlinguistisches
Lexikon als komplexes System. Ph.D. thesis, IMS,
Universität Stuttgart.
Éric Gaussier. 1999. Unsupervised learning of deriva-
tional morphology from inflectional lexicons. In
ACL’99 Workshop Proceedings on Unsupervised
Learning in Natural Language Processing, pages
24–30, College Park, Maryland, USA.
Rebecca Green, Bonnie J. Dorr, and Philip Resnik.
2004. Inducing frame semantic verb classes from
wordnet and ldoce. In Proceedings of the 42nd An-
nual Meeting on Association for Computational Lin-
guistics, pages 375–382, Barcelona, Spain.
Nizar Habash and Bonnie Dorr. 2003. A categorial
variation database for English. In Proceedings of
the Anuual Meeting of the North American Associ-
ation for Computational Linguistics, pages 96–102,
Edmonton, Canada.
Harald Hammarström and Lars Borin. 2011. Unsuper-
vised learning of morphology. Computational Lin-
guistics, 37(2):309–350.
Wolfgang Hoeppner. 1980. Derivative Wortbildung
der deutschen Gegenwartssprache und ihre algorith-
mische Analyse. Narr, Tübingen.
Lauri Karttunen and Kenneth R Beesley. 1992. Two-
level rule compiler. Xerox Corporation. Palo Alto
Research Center.
Lauri Karttunen and Kenneth R. Beesley. 2005.
Twenty-five years of finite-state morphology. In
Antti Arppe, Lauri Carlson, Krister Lindén, Jussi Pi-
itulainen, Mickael Suominen, Martti Vainio, Hanna
Westerlund, and Anssi Yli-Jyr, editors, Inquiries
into Words, Constraints and Contexts. Festschriftfor
Kimmo Koskenniemi on his 60th Birthday, pages 71–
83. CSLI Publications, Stanford, California.
Kimmo Koskenniemi. 1983. Two-level Morphology:
A General Computational Model for Word-Form
Recognition and Production. Ph.D. thesis, Univer-
sity of Helsinki.
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A lexicon of nominalizations. In In Proceedings of
Euralex98, pages 187–193.
Prasenjit Majumder, Mandar Mitra, Swapan K. Parui,
Gobinda Kole, Pabitra Mitra, and Kalyankumar
Datta. 2007. YASS: Yet another suffix strip-
per. ACM Transactions on Information Systems,
25(4):18:1–18:20.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a
two-stage discriminative parser. In In Proceedings
of the Conference on Computational Natural Lan-
guage Learning, pages 216–220, New York, NY.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. Annotating noun ar-
gument structure for NomBank. In Proceedings of
the 4th International Conference on Language Re-
sources and Evaluation, Lisbon, Portugal.
</reference>
<page confidence="0.716493">
1210
</page>
<reference confidence="0.999687304347826">
Petar Milin, Victor Kuperman, Aleksandar Kostic, and
R Harald Baayen. 2009. Paradigms bit by bit: An
information theoretic approach to the processing of
paradigmatic structure in inflection and derivation.
Analogy in grammar: Form and acquisition, pages
214–252.
Karel Pala and Dana Hlaváˇcková. 2007. Derivational
relations in Czech WordNet. In Proceedings of the
ACL Workshop on Balto-Slavonic Natural Language
Processing: Information Extraction and Enabling
Technologies, pages 75–81.
Maciej Piasecki, Radoslaw Ramocki, and Marek
Maziarz. 2012. Recognition of Polish derivational
relations based on supervised learning scheme. In
Proceedings of the Eighth International Conference
on Language Resources and Evaluation, pages 916–
922, Istanbul, Turkey.
Martin Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
Anne Schiller, Simone Teufel, Christine Stöckert, and
Christine Thielen. 1999. Guidelines für das Tag-
ging deutscher Textcorpora mit STTS. Technical
report, Institut fur maschinelle Sprachverarbeitung,
Stuttgart.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
Smor: A German computational morphology cover-
ing derivation, composition and inflection. In Pro-
ceedings of the Fourth International Conference on
Language Resources and Evaluation, Lisbon, Portu-
gal.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44–49, Manchester, UK.
Patrick Schone and Daniel Jurafsky. 2000.
Knowledge-free induction of morphology us-
ing latent semantic analysis. In Proceedings of the
Conference on Natural Language Learning, pages
67–72, Lisbon, Portugal.
Jan Šnajder and Bojana Dalbelo Ba&amp;quot;si´c. 2008. Higher-
order functional representation of Croatian inflec-
tional morphology. In Proceedings of the 6th In-
ternational Conference on Formal Approaches to
South Slavic and Balkan Languages, pages 121–130,
Dubrovnik, Croatia.
Jan Šnajder and Bojana Dalbelo Ba&amp;quot;si´c. 2010. A
computational model of Croatian derivational mor-
phology. In Proceedings of the 7th International
Conference on Formal Approaches to South Slavic
and Balkan Languages, pages 109–118, Dubrovnik,
Croatia.
Idan Szpektor and Ido Dagan. 2008. Learning en-
tailment rules for unary templates. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics, pages 849–856, Manchester, UK.
Kapil Thadani and Kathleen McKeown. 2011. To-
wards strict sentence intersection: Decoding and
evaluation strategies. In Proceedings of the ACL
Workshop on Monolingual Text-To-Text Generation,
pages 43–53, Portland, Oregon.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37(1):141–188.
Andrea Zielinski and Christian Simon. 2008. Mor-
phisto - an open source morphological analyzer for
German. In Proceedings of the 7th International
Workshop on Finite-State Methods and Natural Lan-
guage Processing, pages 224–231, Ispra, Italy.
</reference>
<page confidence="0.991176">
1211
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.281128">
<title confidence="0.9613205">Inducing and Evaluating Derivational Morphology Resource for German</title>
<author confidence="0.990928">Jan</author>
<affiliation confidence="0.883839">University, Institut für</affiliation>
<address confidence="0.740615333333333">69120 Heidelberg, of Zagreb, Faculty of Electrical Engineering and Unska 3, 10000 Zagreb,</address>
<email confidence="0.841796">zeller@cl.uni-heidelberg.dejan.snajder@fer.hr</email>
<email confidence="0.841796">pado@cl.uni-heidelberg.dejan.snajder@fer.hr</email>
<abstract confidence="0.997695421052632">Derivational models are still an underresearched area in computational morphology. Even for German, a rather resourcerich language, there is a lack of largecoverage derivational knowledge. This paper describes a rule-based framework for families clusters of lemmas in derivational relationships) and its application to create a high- German resource, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George W Adamson</author>
<author>Jillian Boreham</author>
</authors>
<title>The use of an association measure based on character structure to identify semantically related pairs of words and document titles.</title>
<date>1974</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>10--7</pages>
<contexts>
<context position="23073" citStr="Adamson and Boreham (1974)" startWordPosition="3617" endWordPosition="3620">orter’s stemmer (Porter, 1980)3 and (2) clusters obtained using string distance-based clustering. We have considered a number of string distance measures and tested them on the development set (cf. Section 4.1). The measure proposed by Majumder et al. (2007) turned out to be the most effective in capturing suffixal variation. For words X and Y , it is defined as n − m + 1 D4(X, Y ) = n + 1 where m is the position of left-most character mismatch, and n + 1 is the length of the longer of the two strings. To capture prefixal variation and stem changes, we use the n-gram based measure proposed by Adamson and Boreham (1974): 2c Dicen(X, Y ) = 1 − (4) x + y where x and y are the total number of distinct ngrams in X and Y , respectively, and c is the number of distinct n-grams shared by both words. In our experiments, the best performance was achieved with n = 3. We used hierarchical agglomerative clustering with average linkage. To reduce the computational complexity, we performed a preclustering step by recursively partitioning the set of lemmas sharing the same prefix into partitions of manageable size (1000 lemmas). Initially, we set the number of clusters to be roughly equal to the number of induced derivatio</context>
</contexts>
<marker>Adamson, Boreham, 1974</marker>
<rawString>George W. Adamson and Jillian Boreham. 1974. The use of an association measure based on character structure to identify semantically related pairs of words and document titles. Information Processing and Management, 10(7/8):253–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Amigó</author>
<author>Julio Gonzalo</author>
<author>Javier Artiles</author>
<author>Felisa Verdejo</author>
</authors>
<title>A comparison of extrinsic clustering evaluation metrics based on formal constraints.</title>
<date>2009</date>
<journal>Information Retrieval,</journal>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="24069" citStr="Amigó et al., 2009" startWordPosition="3786" endWordPosition="3789">ng step by recursively partitioning the set of lemmas sharing the same prefix into partitions of manageable size (1000 lemmas). Initially, we set the number of clusters to be roughly equal to the number of induced derivational families. For the final evaluation, we optimized the number of clusters based on F1 score on calibration and validation sets (cf. Section 5.3). 5.2 Evaluation Methodology The induction of derivational families could be evaluated globally as a clustering problem. Unfortunately, cluster evaluation is a non-trivial task for which there is no consensus on the best approach (Amigó et al., 2009). We decided to perform our evaluation at the level of pairs: we manually judge for a set of pairs whether they are derivationally related or not. 3http://snowball.tartarus.org We obtain the gold standard for this evaluation by sampling lemmas from the lemma list. With random sampling, the evaluation would be unrealistic because a vast majority of pairs would be derivationally unrelated and count as true negatives in our analysis. Moreover, in order to reliably estimate the overall precision of the obtained derivational families, we need to evaluate on pairs sampled from these families. On the</context>
</contexts>
<marker>Amigó, Gonzalo, Artiles, Verdejo, 2009</marker>
<rawString>Enrique Amigó, Julio Gonzalo, Javier Artiles, and Felisa Verdejo. 2009. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Information Retrieval, 12(4):461–486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Augst</author>
</authors>
<title>Lexikon zur Wortbildung. Forschungsberichte des Instituts für Deutsche Sprache.</title>
<date>1975</date>
<location>Narr, Tübingen.</location>
<contexts>
<context position="8665" citStr="Augst (1975)" startWordPosition="1278" endWordPosition="1279">scribe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not model any semantic regularities beyond those implicit in string transformations. We begin by outlining the characteristics of German derivational morphology. 3.1 German Derivational Morphology As German is a morphologically complex language, we analyzed its derivation processes before implementing our rule-based model. We relied on traditional grammar books and lexicons, e.g., Hoeppner (1980) and Augst (1975), in order to linguistically 1http://canoo.net 1202 justify our assumptions as well as to achieve the best possible precision and coverage. We concentrate on German derivational processes that involve nouns, verbs, and adjectives.2 Nouns are simple to recognize due to capitalization: stauenV – StauN (to jam – jam), essenV – EssenN (to eat – food). Verbs bear three typical suffixes (-en, -eln, -ern). An example of a derived verb is festA – festigenV (tight – to tighten), where -ig is the derivational suffix. Adjectivization works similarlty: TagN – täglichA (day – daily). This example shows tha</context>
</contexts>
<marker>Augst, 1975</marker>
<rawString>Gerhard Augst. 1975. Lexikon zur Wortbildung. Forschungsberichte des Instituts für Deutsche Sprache. Narr, Tübingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald R Baayen</author>
<author>Richard Piepenbrock</author>
<author>Leon Gulikers</author>
</authors>
<date>1996</date>
<booktitle>The CELEX Lexical Database. Release 2. LDC96L14. Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="4408" citStr="Baayen et al., 1996" startWordPosition="653" endWordPosition="656">f various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. The former does not appear to be publicly available, and the latter has a limited coverage (50k lemmas) and does not explicitly represent derivational relationships within families, which are necessary for fine-grained optimization of families. For this reason, we look into building a novel derivational resource for German. Unfortuantely, the approach used to build CatVar cannot be adopted: it builds on a collection of high-quality lexical-semantic resources such as NOMLEX (Macleod et al., 1998), which are not available for German. Instead, we employ a rule-based fram</context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1996</marker>
<rawString>Harald R. Baayen, Richard Piepenbrock, and Leon Gulikers. 1996. The CELEX Lexical Database. Release 2. LDC96L14. Linguistic Data Consortium, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite state morphology, volume 18. CSLI publications Stanford.</title>
<date>2003</date>
<contexts>
<context position="10750" citStr="Beesley and Karttunen, 2003" startWordPosition="1608" endWordPosition="1612">rivational model is to define a set of transformations that correspond to valid derivational word formation rules. Rule-based frameworks offer convenient representations for derivational morphology because they can take advantage of linguistic knowledge about derivation, have interpretable representations, and can be finetuned for high precision. The choice of the framework is in principle arbitrary, as long as it can conveniently express the derivational phenomena of a language. Typically used for this purpose are two-level formalism rules (Karttunen and Beesley, 1992) or XFST replace rules (Beesley and Karttunen, 2003). In this paper, we adopt the modeling framework proposed by Šnajder and Dalbelo Baši´c (2010). The framework corresponds closely to simple, human-readable descriptions in traditional gram2We ignore adverb derivation; the German language distinguishes between adverbial adjectives and adverbs, the latter being a rather unproductive class and thus of no interest for derivation (Schiller et al., 1999). mar books. The expressiveness of the formalism is equivalent to the replacement rules commonly used in finite state frameworks, thus the rules can be compiled into FSTs for efficient processing. Th</context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Kenneth R Beesley and Lauri Karttunen. 2003. Finite state morphology, volume 18. CSLI publications Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Learning entailment relations by global graph structure optimization.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="3700" citStr="Berant et al., 2012" startWordPosition="548" endWordPosition="551">understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009). The lemmas in CatVar come from various open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though the</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2012</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2012. Learning entailment relations by global graph structure optimization. Computational Linguistics, 38(1):73–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Balthazar Bickel</author>
<author>Johanna Nichols</author>
</authors>
<title>Inflectional morphology.</title>
<date>2001</date>
<booktitle>Language Typology and Syntactic Description, Volume III: Grammatical categories and the lexicon,</booktitle>
<pages>169--240</pages>
<editor>In Timothy Shopen, editor,</editor>
<publisher>CUP, Cambridge.</publisher>
<contexts>
<context position="1744" citStr="Bickel and Nichols, 2001" startWordPosition="246" endWordPosition="249">is generally recognized as an important step for many NLP tasks. Morphological analyzers such as lemmatizers and part of speech (POS) taggers are commonly the first NLP tools developed for any language (Koskenniemi, 1983; Brill, 1992). They are also applied in NLP applications where little other linguistic analysis is performed, such as linguistic annotation of corpora or terminology acquisition; see Daille et al. (2002) for an informative summary. Most work on computational morphology has focused on inflectional morphology, that is, the handling of grammatically determined variation of form (Bickel and Nichols, 2001), which can be understood, overimplifying somewhat, as a normalization step. Derivational morphology, which is concerned with the formation of new words from existing ones, has received less attention. Examples are nominalization (to understand → the understanding), verbalization (the shelf → to shelve), and adjectivization (the size → sizable). Part of the reason for the relative lack of attention lies in the morphological properties of English, such as the presence of many zero derivations (the fish → to fish), the dominance of suffixation, and the relative absence of stem changes in derivat</context>
</contexts>
<marker>Bickel, Nichols, 2001</marker>
<rawString>Balthazar Bickel and Johanna Nichols. 2001. Inflectional morphology. In Timothy Shopen, editor, Language Typology and Syntactic Description, Volume III: Grammatical categories and the lexicon, pages 169–240. CUP, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Orhan Bilgin</author>
<author>Özlem Qetino˘glu</author>
<author>Kemal Oflazer</author>
</authors>
<title>Morphosemantic relations in and across Wordnets.</title>
<date>2004</date>
<booktitle>In Proceedings of the Global WordNet Conference,</booktitle>
<pages>60--66</pages>
<location>Brno, Czech Republic.</location>
<marker>Bilgin, Qetino˘glu, Oflazer, 2004</marker>
<rawString>Orhan Bilgin, Özlem Qetino˘glu, and Kemal Oflazer. 2004. Morphosemantic relations in and across Wordnets. In Proceedings of the Global WordNet Conference, pages 60–66, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>89--97</pages>
<location>Beijing, China.</location>
<contexts>
<context position="19912" citStr="Bohnet, 2010" startWordPosition="3115" endWordPosition="3116">tional families of different size (counting 2 up to 114 lemmas), and assigned 55, 79, and 24 rules to L3, L2 and L1, respectively. 4.2 Data and Preprocessing For an accurate application of nominal derivation rules, we need a lemma list with POS and gender information. We POS-tag and lemmatize SDEWAC, a large German-language web corpus from which boilerplate paragraphs, ungrammatical sentences, and duplicate pages were removed (Faaß et al., 2010). For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010). We treat proper nouns like common nouns. We apply three language-specific filtering steps based on observations in Section 3.1. First, we discard non-capitalized nominal lemmas. Second, we deleted verbal lemmas not ending in verb suffixes. Third, we removed frequently occurring erroneous comparative forms of adjectives (usually formed by adding -er, like neuer/newer) by checking for the presence of lemmas without -er (neu / new). An additional complication in German concerns prefix verbs, because prefix is separated in tensed instances. For example, the 3rd person male singular of aufhören (</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 89–97, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Workshop on Speech and Natural Language,</booktitle>
<pages>112--116</pages>
<location>Harriman, New York.</location>
<contexts>
<context position="1353" citStr="Brill, 1992" startWordPosition="192" endWordPosition="193">e German resource, DERIVBASE, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books. 1 Introduction Morphological processing is generally recognized as an important step for many NLP tasks. Morphological analyzers such as lemmatizers and part of speech (POS) taggers are commonly the first NLP tools developed for any language (Koskenniemi, 1983; Brill, 1992). They are also applied in NLP applications where little other linguistic analysis is performed, such as linguistic annotation of corpora or terminology acquisition; see Daille et al. (2002) for an informative summary. Most work on computational morphology has focused on inflectional morphology, that is, the handling of grammatically determined variation of form (Bickel and Nichols, 2001), which can be understood, overimplifying somewhat, as a normalization step. Derivational morphology, which is concerned with the formation of new words from existing ones, has received less attention. Example</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Eric Brill. 1992. A simple rule-based part of speech tagger. In Proceedings of the Workshop on Speech and Natural Language, pages 112–116, Harriman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean C Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: the kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="28199" citStr="Carletta, 1996" startWordPosition="4473" endWordPosition="4474">ws us to identify the pairs that are derivationally unrelated, but compositionally related, e.g., EhemannN – EhefrauN (husband – wife). We first carried out a calibration phase in which the annotators double-annotated 200 pairs from each of the two samples and refined the annotation guidelines. In a subsequent validation phase, we computed inter-annotator agreements on the annotations of another 200 pairs each from the P- and the R-samples. Table 4 shows the proportion of identical annotations by both annotators as well as Cohen’s κ score (Cohen, 1968). We achieve substantial agreement for κ (Carletta, 1996). On the P-sample, κ is a little lower because the distribution of the categories is skewed towards R, which makes an agreement by chance more probable. In our opinion, the IAA results were sufficiently high to switch to single annotation for the production phase. Here, each annotator annotated another 1000 pairs from the P-sample and R-sample so that the final test set consists of 2000 pairs from each sample. The P-sample contains 1663 positive (R+M) and 337 negative (N+C+L) pairs, respectively, the R-sample contains 575 positive and 1425 negative pairs. As expected, there are more positive M</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean C. Carletta. 1996. Assessing agreement on classification tasks: the kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>Weighted kappa: Nominal scale agreement with provision for scaled disagreement or partial credit.</title>
<date>1968</date>
<journal>Psychological Bulletin,</journal>
<pages>70--213</pages>
<contexts>
<context position="28142" citStr="Cohen, 1968" startWordPosition="4464" endWordPosition="4465">amilies. Distinguishing between C and N, in turn, allows us to identify the pairs that are derivationally unrelated, but compositionally related, e.g., EhemannN – EhefrauN (husband – wife). We first carried out a calibration phase in which the annotators double-annotated 200 pairs from each of the two samples and refined the annotation guidelines. In a subsequent validation phase, we computed inter-annotator agreements on the annotations of another 200 pairs each from the P- and the R-samples. Table 4 shows the proportion of identical annotations by both annotators as well as Cohen’s κ score (Cohen, 1968). We achieve substantial agreement for κ (Carletta, 1996). On the P-sample, κ is a little lower because the distribution of the categories is skewed towards R, which makes an agreement by chance more probable. In our opinion, the IAA results were sufficiently high to switch to single annotation for the production phase. Here, each annotator annotated another 1000 pairs from the P-sample and R-sample so that the final test set consists of 2000 pairs from each sample. The P-sample contains 1663 positive (R+M) and 337 negative (N+C+L) pairs, respectively, the R-sample contains 575 positive and 14</context>
</contexts>
<marker>Cohen, 1968</marker>
<rawString>Jacob Cohen. 1968. Weighted kappa: Nominal scale agreement with provision for scaled disagreement or partial credit. Psychological Bulletin, 70:213–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Béatrice Daille</author>
</authors>
<title>Cécile Fabre, and Pascale Sébillot.</title>
<date>2002</date>
<pages>210--234</pages>
<editor>In Paul Boucher, editor, Many Morphologies,</editor>
<publisher>Cascadilla Press.</publisher>
<marker>Daille, 2002</marker>
<rawString>Béatrice Daille, Cécile Fabre, and Pascale Sébillot. 2002. Applications of computational morphology. In Paul Boucher, editor, Many Morphologies, pages 210–234. Cascadilla Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hervé Déjean</author>
</authors>
<title>Morphemes as necessary concept for structures discovery from untagged corpora.</title>
<date>1998</date>
<booktitle>In Proceedings of the Joint Conferences on New Methods in Language Processing and Computational Natural Language Learning,</booktitle>
<pages>295--298</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="6673" citStr="Déjean, 1998" startWordPosition="987" endWordPosition="988">tion model that is applied to German in Section 4. Sections 5 and 6 present our evaluation setup and results. Section 7 concludes the paper and outlines future work. 2 Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precisio</context>
</contexts>
<marker>Déjean, 1998</marker>
<rawString>Hervé Déjean. 1998. Morphemes as necessary concept for structures discovery from untagged corpora. In Proceedings of the Joint Conferences on New Methods in Language Processing and Computational Natural Language Learning, pages 295–298, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertrud Faaß</author>
<author>Ulrich Heid</author>
<author>Helmut Schmid</author>
</authors>
<title>Design and application of a gold standard for morphological analysis: SMOR in validation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation,</booktitle>
<pages>803--810</pages>
<contexts>
<context position="19748" citStr="Faaß et al., 2010" startWordPosition="3088" endWordPosition="3091">ble (high-accuracy rules), L2 – generally reliable, and L1 – less reliable (low-accuracy rules). We manually analyzed the correctness of rule applications for 100 derivational families of different size (counting 2 up to 114 lemmas), and assigned 55, 79, and 24 rules to L3, L2 and L1, respectively. 4.2 Data and Preprocessing For an accurate application of nominal derivation rules, we need a lemma list with POS and gender information. We POS-tag and lemmatize SDEWAC, a large German-language web corpus from which boilerplate paragraphs, ungrammatical sentences, and duplicate pages were removed (Faaß et al., 2010). For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010). We treat proper nouns like common nouns. We apply three language-specific filtering steps based on observations in Section 3.1. First, we discard non-capitalized nominal lemmas. Second, we deleted verbal lemmas not ending in verb suffixes. Third, we removed frequently occurring erroneous comparative forms of adjectives (usually formed by adding -er, like neuer/newer) by checking for the presence of lemmas without -er (neu / new). </context>
</contexts>
<marker>Faaß, Heid, Schmid, 2010</marker>
<rawString>Gertrud Faaß, Ulrich Heid, and Helmut Schmid. 2010. Design and application of a gold standard for morphological analysis: SMOR in validation. In Proceedings of the Seventh International Conference on Language Resources and Evaluation, pages 803– 810.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
<author>Anne Osherson</author>
<author>Peter Clark</author>
</authors>
<title>Putting semantics into WordNet’s &amp;quot;morphosemantic&amp;quot; links.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Language and Technology Conference,</booktitle>
<pages>350--358</pages>
<location>Pozna´n,</location>
<contexts>
<context position="2596" citStr="Fellbaum et al., 2009" startWordPosition="375" endWordPosition="378">(to understand → the understanding), verbalization (the shelf → to shelve), and adjectivization (the size → sizable). Part of the reason for the relative lack of attention lies in the morphological properties of English, such as the presence of many zero derivations (the fish → to fish), the dominance of suffixation, and the relative absence of stem changes in derivation. For these reasons, simple stemming algorithms (Porter, 1980) provide a cheap and accurate approximation to English derivation. Two major NLP resources deal with derivation. WordNet lists so-called “morphosemantic” relations (Fellbaum et al., 2009) for English, and a number of proposals exist for extending WordNets in other languages with derivational relations (Bilgin et al., 2004; Pala and Hlaváˇcková, 2007). CatVar, the “Categorial Variation Database of English” (Habash and Dorr, 2003), is a lexicon aimed specifically at derivation. It groups English nouns, verbs, adjectives, and adverbs into derivational equivalence classes or derivational families such as askV askerN askingN askingA Derivational families are commonly understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009). The lemmas in CatVa</context>
</contexts>
<marker>Fellbaum, Osherson, Clark, 2009</marker>
<rawString>Christiane Fellbaum, Anne Osherson, and Peter Clark. 2009. Putting semantics into WordNet’s &amp;quot;morphosemantic&amp;quot; links. In Proceedings of the Third Language and Technology Conference, pages 350–358, Pozna´n, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Finkler</author>
<author>Günter Neumann</author>
</authors>
<title>Morphix - a fast realization of a classification-based approach to morphology.</title>
<date>1988</date>
<booktitle>In Proceedings of 4th Austrian Conference ofArtificial Intelligence,</booktitle>
<pages>11--19</pages>
<location>Vienna, Austria.</location>
<contexts>
<context position="7657" citStr="Finkler and Neumann, 1988" startWordPosition="1129" endWordPosition="1132">ementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to construct derivational families for French. For German, several morphological tools exist. Morphix is a classification-based analyzer and generator of German words on the inflectional level (Finkler and Neumann, 1988). SMOR (Schmid et al., 2004) employs a finite-state transducer to analyze German words at the inflectional, derivational, and compositional level, and has been used in other morphological analyzers, e.g., Morphisto (Zielinski and Simon, 2008). The site canoonet1 offers broad-coverage information about the German language including derivational word formation. 3 Framework In this section, we describe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not mode</context>
</contexts>
<marker>Finkler, Neumann, 1988</marker>
<rawString>Wolfgang Finkler and Günter Neumann. 1988. Morphix - a fast realization of a classification-based approach to morphology. In Proceedings of 4th Austrian Conference ofArtificial Intelligence, pages 11– 19, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne Fitschen</author>
</authors>
<title>Ein computerlinguistisches Lexikon als komplexes System.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>IMS, Universität Stuttgart.</institution>
<contexts>
<context position="4376" citStr="Fitschen, 2004" startWordPosition="649" endWordPosition="650"> resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. The former does not appear to be publicly available, and the latter has a limited coverage (50k lemmas) and does not explicitly represent derivational relationships within families, which are necessary for fine-grained optimization of families. For this reason, we look into building a novel derivational resource for German. Unfortuantely, the approach used to build CatVar cannot be adopted: it builds on a collection of high-quality lexical-semantic resources such as NOMLEX (Macleod et al., 1998), which are not available for German. Inst</context>
</contexts>
<marker>Fitschen, 2004</marker>
<rawString>Arne Fitschen. 2004. Ein computerlinguistisches Lexikon als komplexes System. Ph.D. thesis, IMS, Universität Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Éric Gaussier</author>
</authors>
<title>Unsupervised learning of derivational morphology from inflectional lexicons.</title>
<date>1999</date>
<booktitle>In ACL’99 Workshop Proceedings on Unsupervised Learning in Natural Language Processing,</booktitle>
<pages>24--30</pages>
<location>College Park, Maryland, USA.</location>
<contexts>
<context position="7401" citStr="Gaussier (1999)" startWordPosition="1095" endWordPosition="1096"> rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to construct derivational families for French. For German, several morphological tools exist. Morphix is a classification-based analyzer and generator of German words on the inflectional level (Finkler and Neumann, 1988). SMOR (Schmid et al., 2004) employs a finite-state transducer to analyze German words at the inflectional, derivational, and compositional level, and has been used in other morphological analyzers, e.g., Morphisto (Zielinski and Simon, 2008). The site canoonet1 offers broad-coverage information about the German language including derivationa</context>
</contexts>
<marker>Gaussier, 1999</marker>
<rawString>Éric Gaussier. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL’99 Workshop Proceedings on Unsupervised Learning in Natural Language Processing, pages 24–30, College Park, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Green</author>
<author>Bonnie J Dorr</author>
<author>Philip Resnik</author>
</authors>
<title>Inducing frame semantic verb classes from wordnet and ldoce.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>375--382</pages>
<location>Barcelona,</location>
<contexts>
<context position="3855" citStr="Green et al., 2004" startWordPosition="574" endWordPosition="577">nd multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. The former does not a</context>
</contexts>
<marker>Green, Dorr, Resnik, 2004</marker>
<rawString>Rebecca Green, Bonnie J. Dorr, and Philip Resnik. 2004. Inducing frame semantic verb classes from wordnet and ldoce. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 375–382, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Bonnie Dorr</author>
</authors>
<title>A categorial variation database for English.</title>
<date>2003</date>
<booktitle>In Proceedings of the Anuual Meeting of the North American Association for Computational Linguistics,</booktitle>
<pages>96--102</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2841" citStr="Habash and Dorr, 2003" startWordPosition="413" endWordPosition="416">many zero derivations (the fish → to fish), the dominance of suffixation, and the relative absence of stem changes in derivation. For these reasons, simple stemming algorithms (Porter, 1980) provide a cheap and accurate approximation to English derivation. Two major NLP resources deal with derivation. WordNet lists so-called “morphosemantic” relations (Fellbaum et al., 2009) for English, and a number of proposals exist for extending WordNets in other languages with derivational relations (Bilgin et al., 2004; Pala and Hlaváˇcková, 2007). CatVar, the “Categorial Variation Database of English” (Habash and Dorr, 2003), is a lexicon aimed specifically at derivation. It groups English nouns, verbs, adjectives, and adverbs into derivational equivalence classes or derivational families such as askV askerN askingN askingA Derivational families are commonly understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009). The lemmas in CatVar come from various open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., t</context>
</contexts>
<marker>Habash, Dorr, 2003</marker>
<rawString>Nizar Habash and Bonnie Dorr. 2003. A categorial variation database for English. In Proceedings of the Anuual Meeting of the North American Association for Computational Linguistics, pages 96–102, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Hammarström</author>
<author>Lars Borin</author>
</authors>
<title>Unsupervised learning of morphology.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="6874" citStr="Hammarström and Borin (2011)" startWordPosition="1014" endWordPosition="1017">tational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to construct derivational families fo</context>
</contexts>
<marker>Hammarström, Borin, 2011</marker>
<rawString>Harald Hammarström and Lars Borin. 2011. Unsupervised learning of morphology. Computational Linguistics, 37(2):309–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Hoeppner</author>
</authors>
<title>Derivative Wortbildung der deutschen Gegenwartssprache und ihre algorithmische Analyse.</title>
<date>1980</date>
<location>Narr, Tübingen.</location>
<contexts>
<context position="8648" citStr="Hoeppner (1980)" startWordPosition="1275" endWordPosition="1276"> this section, we describe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not model any semantic regularities beyond those implicit in string transformations. We begin by outlining the characteristics of German derivational morphology. 3.1 German Derivational Morphology As German is a morphologically complex language, we analyzed its derivation processes before implementing our rule-based model. We relied on traditional grammar books and lexicons, e.g., Hoeppner (1980) and Augst (1975), in order to linguistically 1http://canoo.net 1202 justify our assumptions as well as to achieve the best possible precision and coverage. We concentrate on German derivational processes that involve nouns, verbs, and adjectives.2 Nouns are simple to recognize due to capitalization: stauenV – StauN (to jam – jam), essenV – EssenN (to eat – food). Verbs bear three typical suffixes (-en, -eln, -ern). An example of a derived verb is festA – festigenV (tight – to tighten), where -ig is the derivational suffix. Adjectivization works similarlty: TagN – täglichA (day – daily). This </context>
<context position="15815" citStr="Hoeppner (1980)" startWordPosition="2425" endWordPosition="2427"> quality of the induced families. High coverage of L is important because the transitivity of →D ranges only over lemmas in L, so low coverage of L may result in fragmented derivational families. However, L should also not contain erroneous lemma-paradigm pairs. The reason is that the derivational rules only define admissible derivations, which need not be morphologically valid, and therefore routinely overgenerate; L plays an important role in filtering out derivations that are not attested in the data. 4 Building the Resource 4.1 Derivational Rules We implemented the derivational rules from Hoeppner (1980) for verbs, nouns, and adjectives, covering all processes described in Section 3.1 (zero derivation, prefixation, suffixation, circumfixation, and stem changes). We found many derivational patterns in German to be conceptually simple (e.g., verb-noun zero derivation) so that substantial coverage can already be achieved with very simple transformation functions. However, there are many more complex patterns (e.g., suffixation combined with optional stem changes) that in sum also affect a considerable number of lemmas, which required us to either implement low-coverage rules or generalize existi</context>
</contexts>
<marker>Hoeppner, 1980</marker>
<rawString>Wolfgang Hoeppner. 1980. Derivative Wortbildung der deutschen Gegenwartssprache und ihre algorithmische Analyse. Narr, Tübingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Kenneth R Beesley</author>
</authors>
<title>Twolevel rule compiler. Xerox Corporation. Palo Alto Research Center.</title>
<date>1992</date>
<contexts>
<context position="10698" citStr="Karttunen and Beesley, 1992" startWordPosition="1600" endWordPosition="1603">.2 A Rule-based Derivation Model The purpose of a derivational model is to define a set of transformations that correspond to valid derivational word formation rules. Rule-based frameworks offer convenient representations for derivational morphology because they can take advantage of linguistic knowledge about derivation, have interpretable representations, and can be finetuned for high precision. The choice of the framework is in principle arbitrary, as long as it can conveniently express the derivational phenomena of a language. Typically used for this purpose are two-level formalism rules (Karttunen and Beesley, 1992) or XFST replace rules (Beesley and Karttunen, 2003). In this paper, we adopt the modeling framework proposed by Šnajder and Dalbelo Baši´c (2010). The framework corresponds closely to simple, human-readable descriptions in traditional gram2We ignore adverb derivation; the German language distinguishes between adverbial adjectives and adverbs, the latter being a rather unproductive class and thus of no interest for derivation (Schiller et al., 1999). mar books. The expressiveness of the formalism is equivalent to the replacement rules commonly used in finite state frameworks, thus the rules ca</context>
</contexts>
<marker>Karttunen, Beesley, 1992</marker>
<rawString>Lauri Karttunen and Kenneth R Beesley. 1992. Twolevel rule compiler. Xerox Corporation. Palo Alto Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Kenneth R Beesley</author>
</authors>
<title>Twenty-five years of finite-state morphology.</title>
<date>2005</date>
<booktitle>Inquiries into Words, Constraints and Contexts. Festschriftfor Kimmo Koskenniemi on his 60th Birthday,</booktitle>
<pages>71--83</pages>
<editor>In Antti Arppe, Lauri Carlson, Krister Lindén, Jussi Piitulainen, Mickael Suominen, Martti Vainio, Hanna Westerlund, and Anssi Yli-Jyr, editors,</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, California.</location>
<contexts>
<context position="6523" citStr="Karttunen and Beesley, 2005" startWordPosition="966" endWordPosition="969"> evaluation of the induced derivational families both regarding precision and recall. Plan of the paper. Section 2 discusses prior work. Section 3 defines our derivation model that is applied to German in Section 4. Sections 5 and 6 present our evaluation setup and results. Section 7 concludes the paper and outlines future work. 2 Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not requi</context>
</contexts>
<marker>Karttunen, Beesley, 2005</marker>
<rawString>Lauri Karttunen and Kenneth R. Beesley. 2005. Twenty-five years of finite-state morphology. In Antti Arppe, Lauri Carlson, Krister Lindén, Jussi Piitulainen, Mickael Suominen, Martti Vainio, Hanna Westerlund, and Anssi Yli-Jyr, editors, Inquiries into Words, Constraints and Contexts. Festschriftfor Kimmo Koskenniemi on his 60th Birthday, pages 71– 83. CSLI Publications, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-level Morphology: A General Computational Model for Word-Form Recognition and Production.</title>
<date>1983</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Helsinki.</institution>
<contexts>
<context position="1339" citStr="Koskenniemi, 1983" startWordPosition="190" endWordPosition="191">reate a highcoverage German resource, DERIVBASE, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books. 1 Introduction Morphological processing is generally recognized as an important step for many NLP tasks. Morphological analyzers such as lemmatizers and part of speech (POS) taggers are commonly the first NLP tools developed for any language (Koskenniemi, 1983; Brill, 1992). They are also applied in NLP applications where little other linguistic analysis is performed, such as linguistic annotation of corpora or terminology acquisition; see Daille et al. (2002) for an informative summary. Most work on computational morphology has focused on inflectional morphology, that is, the handling of grammatically determined variation of form (Bickel and Nichols, 2001), which can be understood, overimplifying somewhat, as a normalization step. Derivational morphology, which is concerned with the formation of new words from existing ones, has received less atte</context>
<context position="6317" citStr="Koskenniemi (1983)" startWordPosition="940" endWordPosition="941">-coverage resource for German derivational morphology that has a structure parallel to CatVar, but was obtained without using manually constructed lexical-semantic resources. We conduct a thorough evaluation of the induced derivational families both regarding precision and recall. Plan of the paper. Section 2 discusses prior work. Section 3 defines our derivation model that is applied to German in Section 4. Sections 5 and 6 present our evaluation setup and results. Section 7 concludes the paper and outlines future work. 2 Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Kimmo Koskenniemi. 1983. Two-level Morphology: A General Computational Model for Word-Form Recognition and Production. Ph.D. thesis, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Macleod</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>NOMLEX: A lexicon of nominalizations. In</title>
<date>1998</date>
<booktitle>In Proceedings of Euralex98,</booktitle>
<pages>187--193</pages>
<contexts>
<context position="4934" citStr="Macleod et al., 1998" startWordPosition="734" endWordPosition="737">rivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. The former does not appear to be publicly available, and the latter has a limited coverage (50k lemmas) and does not explicitly represent derivational relationships within families, which are necessary for fine-grained optimization of families. For this reason, we look into building a novel derivational resource for German. Unfortuantely, the approach used to build CatVar cannot be adopted: it builds on a collection of high-quality lexical-semantic resources such as NOMLEX (Macleod et al., 1998), which are not available for German. Instead, we employ a rule-based framework to define derivation rules that cover both suffixation and prefixation and describes stem changes. Following the work of Šnajder and Dalbelo Baši´c (2010), we define the derivational processes using derivational rules and higher-order string transformation functions. The derivational rules induce a partition of the language’s lemmas into derivational families. Our method is applicable to many languages if the following are available: (1) a comprehensive set of lemmas (optionally including gender information); (2) k</context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>Catherine Macleod, Ralph Grishman, Adam Meyers, Leslie Barrett, and Ruth Reeves. 1998. NOMLEX: A lexicon of nominalizations. In In Proceedings of Euralex98, pages 187–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prasenjit Majumder</author>
<author>Mandar Mitra</author>
<author>Swapan K Parui</author>
<author>Gobinda Kole</author>
<author>Pabitra Mitra</author>
<author>Kalyankumar Datta</author>
</authors>
<title>YASS: Yet another suffix stripper.</title>
<date>2007</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="22705" citStr="Majumder et al. (2007)" startWordPosition="3540" endWordPosition="3543">ix umlaut shifts: taubA (numbA), TaubheitNf (numbnessN), betäubenV (to anesthetizeV ), BetäubungNf (anesthesiaN), betäubtA (anesthetizedA), betäubendA (anestheticA), BetäubenNn (act of anesthetizingN) 1205 5 Evaluation 5.1 Baselines We use two baselines against which we compare the induced derivational families: (1) clusters obtained with the German version of Porter’s stemmer (Porter, 1980)3 and (2) clusters obtained using string distance-based clustering. We have considered a number of string distance measures and tested them on the development set (cf. Section 4.1). The measure proposed by Majumder et al. (2007) turned out to be the most effective in capturing suffixal variation. For words X and Y , it is defined as n − m + 1 D4(X, Y ) = n + 1 where m is the position of left-most character mismatch, and n + 1 is the length of the longer of the two strings. To capture prefixal variation and stem changes, we use the n-gram based measure proposed by Adamson and Boreham (1974): 2c Dicen(X, Y ) = 1 − (4) x + y where x and y are the total number of distinct ngrams in X and Y , respectively, and c is the number of distinct n-grams shared by both words. In our experiments, the best performance was achieved w</context>
</contexts>
<marker>Majumder, Mitra, Parui, Kole, Mitra, Datta, 2007</marker>
<rawString>Prasenjit Majumder, Mandar Mitra, Swapan K. Parui, Gobinda Kole, Pabitra Mitra, and Kalyankumar Datta. 2007. YASS: Yet another suffix stripper. ACM Transactions on Information Systems, 25(4):18:1–18:20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a two-stage discriminative parser. In</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning,</booktitle>
<pages>216--220</pages>
<location>New York, NY.</location>
<contexts>
<context position="20713" citStr="McDonald et al., 2006" startWordPosition="3239" endWordPosition="3243"> Second, we deleted verbal lemmas not ending in verb suffixes. Third, we removed frequently occurring erroneous comparative forms of adjectives (usually formed by adding -er, like neuer/newer) by checking for the presence of lemmas without -er (neu / new). An additional complication in German concerns prefix verbs, because prefix is separated in tensed instances. For example, the 3rd person male singular of aufhören (to stop) is er hört auf (he stops). Since most prefixes double as prepositions, the correct lemmas can only be reconstructed by parsing. We parse the corpus using the MST parser (McDonald et al., 2006) and recover prefix verbs by searching for instances of the dependency relation labeled PTKVZ. Since SDEWAC, as a web corpus, still contains errors, we only take into account lemmas that occur three times or more in the corpus. Considering the size of SDEWAC, we consider this as a conservative filtering step that preserves high recall and provides a comprehensive basis for evaluation. After preprocessing and filtering, we run the induction of the derivational families as explained in Section 3 to obtain the DERIVBASE resource. 4.3 Statistics on DERIVBASE The preparation of the SDEWAC corpus as</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a two-stage discriminative parser. In In Proceedings of the Conference on Computational Natural Language Learning, pages 216–220, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekely</author>
<author>Veronika Zielinska</author>
<author>Brian Young</author>
<author>Ralph Grishman</author>
</authors>
<title>Annotating noun argument structure for NomBank.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3834" citStr="Meyers et al., 2004" startWordPosition="570" endWordPosition="573"> open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. </context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekely, Veronika Zielinska, Brian Young, and Ralph Grishman. 2004. Annotating noun argument structure for NomBank. In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petar Milin</author>
<author>Victor Kuperman</author>
<author>Aleksandar Kostic</author>
<author>R Harald Baayen</author>
</authors>
<title>Paradigms bit by bit: An information theoretic approach to the processing of paradigmatic structure in inflection and derivation. Analogy in grammar: Form and acquisition,</title>
<date>2009</date>
<pages>214--252</pages>
<contexts>
<context position="3175" citStr="Milin et al., 2009" startWordPosition="462" endWordPosition="465">antic” relations (Fellbaum et al., 2009) for English, and a number of proposals exist for extending WordNets in other languages with derivational relations (Bilgin et al., 2004; Pala and Hlaváˇcková, 2007). CatVar, the “Categorial Variation Database of English” (Habash and Dorr, 2003), is a lexicon aimed specifically at derivation. It groups English nouns, verbs, adjectives, and adverbs into derivational equivalence classes or derivational families such as askV askerN askingN askingA Derivational families are commonly understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009). The lemmas in CatVar come from various open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for</context>
</contexts>
<marker>Milin, Kuperman, Kostic, Baayen, 2009</marker>
<rawString>Petar Milin, Victor Kuperman, Aleksandar Kostic, and R Harald Baayen. 2009. Paradigms bit by bit: An information theoretic approach to the processing of paradigmatic structure in inflection and derivation. Analogy in grammar: Form and acquisition, pages 214–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karel Pala</author>
<author>Dana Hlaváˇcková</author>
</authors>
<title>Derivational relations in Czech WordNet.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Balto-Slavonic Natural Language Processing: Information Extraction and Enabling Technologies,</booktitle>
<pages>75--81</pages>
<marker>Pala, Hlaváˇcková, 2007</marker>
<rawString>Karel Pala and Dana Hlaváˇcková. 2007. Derivational relations in Czech WordNet. In Proceedings of the ACL Workshop on Balto-Slavonic Natural Language Processing: Information Extraction and Enabling Technologies, pages 75–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maciej Piasecki</author>
<author>Radoslaw Ramocki</author>
<author>Marek Maziarz</author>
</authors>
<title>Recognition of Polish derivational relations based on supervised learning scheme.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation,</booktitle>
<pages>916--922</pages>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="6844" citStr="Piasecki et al., 2012" startWordPosition="1010" endWordPosition="1013">rk. 2 Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to cons</context>
</contexts>
<marker>Piasecki, Ramocki, Maziarz, 2012</marker>
<rawString>Maciej Piasecki, Radoslaw Ramocki, and Marek Maziarz. 2012. Recognition of Polish derivational relations based on supervised learning scheme. In Proceedings of the Eighth International Conference on Language Resources and Evaluation, pages 916– 922, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="2409" citStr="Porter, 1980" startWordPosition="351" endWordPosition="352">as a normalization step. Derivational morphology, which is concerned with the formation of new words from existing ones, has received less attention. Examples are nominalization (to understand → the understanding), verbalization (the shelf → to shelve), and adjectivization (the size → sizable). Part of the reason for the relative lack of attention lies in the morphological properties of English, such as the presence of many zero derivations (the fish → to fish), the dominance of suffixation, and the relative absence of stem changes in derivation. For these reasons, simple stemming algorithms (Porter, 1980) provide a cheap and accurate approximation to English derivation. Two major NLP resources deal with derivation. WordNet lists so-called “morphosemantic” relations (Fellbaum et al., 2009) for English, and a number of proposals exist for extending WordNets in other languages with derivational relations (Bilgin et al., 2004; Pala and Hlaváˇcková, 2007). CatVar, the “Categorial Variation Database of English” (Habash and Dorr, 2003), is a lexicon aimed specifically at derivation. It groups English nouns, verbs, adjectives, and adverbs into derivational equivalence classes or derivational families </context>
<context position="22477" citStr="Porter, 1980" startWordPosition="3505" endWordPosition="3506">arison, CatVar v2.1 contains only 82,676 lemmas in 13,368 non-singleton clusters and 38,604 singletons. The following sample family has seven members across all three POSes and includes prefixation, suffixation, and infix umlaut shifts: taubA (numbA), TaubheitNf (numbnessN), betäubenV (to anesthetizeV ), BetäubungNf (anesthesiaN), betäubtA (anesthetizedA), betäubendA (anestheticA), BetäubenNn (act of anesthetizingN) 1205 5 Evaluation 5.1 Baselines We use two baselines against which we compare the induced derivational families: (1) clusters obtained with the German version of Porter’s stemmer (Porter, 1980)3 and (2) clusters obtained using string distance-based clustering. We have considered a number of string distance measures and tested them on the development set (cf. Section 4.1). The measure proposed by Majumder et al. (2007) turned out to be the most effective in capturing suffixal variation. For words X and Y , it is defined as n − m + 1 D4(X, Y ) = n + 1 where m is the position of left-most character mismatch, and n + 1 is the length of the longer of the two strings. To capture prefixal variation and stem changes, we use the n-gram based measure proposed by Adamson and Boreham (1974): 2c</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Schiller</author>
<author>Simone Teufel</author>
<author>Christine Stöckert</author>
<author>Christine Thielen</author>
</authors>
<date>1999</date>
<booktitle>Guidelines für das Tagging deutscher Textcorpora mit STTS. Technical report, Institut fur maschinelle Sprachverarbeitung,</booktitle>
<location>Stuttgart.</location>
<contexts>
<context position="11151" citStr="Schiller et al., 1999" startWordPosition="1667" endWordPosition="1670">long as it can conveniently express the derivational phenomena of a language. Typically used for this purpose are two-level formalism rules (Karttunen and Beesley, 1992) or XFST replace rules (Beesley and Karttunen, 2003). In this paper, we adopt the modeling framework proposed by Šnajder and Dalbelo Baši´c (2010). The framework corresponds closely to simple, human-readable descriptions in traditional gram2We ignore adverb derivation; the German language distinguishes between adverbial adjectives and adverbs, the latter being a rather unproductive class and thus of no interest for derivation (Schiller et al., 1999). mar books. The expressiveness of the formalism is equivalent to the replacement rules commonly used in finite state frameworks, thus the rules can be compiled into FSTs for efficient processing. The framework makes a clear distinction between inflectional and derivational morphology and provides separate modeling components for these two; we only make use of the derivation modeling component. We use an implementation of the modeling framework in Haskell. For details, see the studies by Šnajder and Dalbelo Baši´c (2008) and Šnajder and Dalbelo Baši´c (2010). The building blocks of the derivat</context>
</contexts>
<marker>Schiller, Teufel, Stöckert, Thielen, 1999</marker>
<rawString>Anne Schiller, Simone Teufel, Christine Stöckert, and Christine Thielen. 1999. Guidelines für das Tagging deutscher Textcorpora mit STTS. Technical report, Institut fur maschinelle Sprachverarbeitung, Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Arne Fitschen</author>
<author>Ulrich Heid</author>
</authors>
<title>Smor: A German computational morphology covering derivation, composition and inflection.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="7685" citStr="Schmid et al., 2004" startWordPosition="1134" endWordPosition="1137">to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to construct derivational families for French. For German, several morphological tools exist. Morphix is a classification-based analyzer and generator of German words on the inflectional level (Finkler and Neumann, 1988). SMOR (Schmid et al., 2004) employs a finite-state transducer to analyze German words at the inflectional, derivational, and compositional level, and has been used in other morphological analyzers, e.g., Morphisto (Zielinski and Simon, 2008). The site canoonet1 offers broad-coverage information about the German language including derivational word formation. 3 Framework In this section, we describe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not model any semantic regularities </context>
</contexts>
<marker>Schmid, Fitschen, Heid, 2004</marker>
<rawString>Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004. Smor: A German computational morphology covering derivation, composition and inflection. In Proceedings of the Fourth International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="19817" citStr="Schmid, 1994" startWordPosition="3100" endWordPosition="3101"> (low-accuracy rules). We manually analyzed the correctness of rule applications for 100 derivational families of different size (counting 2 up to 114 lemmas), and assigned 55, 79, and 24 rules to L3, L2 and L1, respectively. 4.2 Data and Preprocessing For an accurate application of nominal derivation rules, we need a lemma list with POS and gender information. We POS-tag and lemmatize SDEWAC, a large German-language web corpus from which boilerplate paragraphs, ungrammatical sentences, and duplicate pages were removed (Faaß et al., 2010). For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010). We treat proper nouns like common nouns. We apply three language-specific filtering steps based on observations in Section 3.1. First, we discard non-capitalized nominal lemmas. Second, we deleted verbal lemmas not ending in verb suffixes. Third, we removed frequently occurring erroneous comparative forms of adjectives (usually formed by adding -er, like neuer/newer) by checking for the presence of lemmas without -er (neu / new). An additional complication in German concerns prefix verbs, because p</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent semantic analysis.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Natural Language Learning,</booktitle>
<pages>67--72</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="6761" citStr="Schone and Jurafsky, 2000" startWordPosition="997" endWordPosition="1000"> our evaluation setup and results. Section 7 concludes the paper and outlines future work. 2 Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005). Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (Déjean, 1998), measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000), or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012). Hammarström and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An </context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>Patrick Schone and Daniel Jurafsky. 2000. Knowledge-free induction of morphology using latent semantic analysis. In Proceedings of the Conference on Natural Language Learning, pages 67–72, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Šnajder</author>
<author>Bojana Dalbelo Basi´c</author>
</authors>
<title>Higherorder functional representation of Croatian inflectional morphology.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Formal Approaches to South Slavic and Balkan Languages,</booktitle>
<pages>121--130</pages>
<location>Dubrovnik, Croatia.</location>
<marker>Šnajder, Basi´c, 2008</marker>
<rawString>Jan Šnajder and Bojana Dalbelo Ba&amp;quot;si´c. 2008. Higherorder functional representation of Croatian inflectional morphology. In Proceedings of the 6th International Conference on Formal Approaches to South Slavic and Balkan Languages, pages 121–130, Dubrovnik, Croatia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Šnajder</author>
<author>Bojana Dalbelo Basi´c</author>
</authors>
<title>A computational model of Croatian derivational morphology.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Formal Approaches to South Slavic and Balkan Languages,</booktitle>
<pages>109--118</pages>
<location>Dubrovnik, Croatia.</location>
<marker>Šnajder, Basi´c, 2010</marker>
<rawString>Jan Šnajder and Bojana Dalbelo Ba&amp;quot;si´c. 2010. A computational model of Croatian derivational morphology. In Proceedings of the 7th International Conference on Formal Approaches to South Slavic and Balkan Languages, pages 109–118, Dubrovnik, Croatia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary templates.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>849--856</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="3678" citStr="Szpektor and Dagan, 2008" startWordPosition="543" endWordPosition="547">nal families are commonly understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009). The lemmas in CatVar come from various open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applica</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 849–856, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kapil Thadani</author>
<author>Kathleen McKeown</author>
</authors>
<title>Towards strict sentence intersection: Decoding and evaluation strategies.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL Workshop on Monolingual Text-To-Text Generation,</booktitle>
<pages>43--53</pages>
<location>Portland, Oregon.</location>
<contexts>
<context position="4165" citStr="Thadani and McKeown, 2011" startWordPosition="616" endWordPosition="619">xamples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012). Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004). Finally, CatVar has 1201 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1201–1211, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011). In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996), both have shortcomings. The former does not appear to be publicly available, and the latter has a limited coverage (50k lemmas) and does not explicitly represent derivational relationships within families, which are necessary for fine-grained optimization of families. For this reason, we look into building a novel derivational resource for German. Unfor</context>
</contexts>
<marker>Thadani, McKeown, 2011</marker>
<rawString>Kapil Thadani and Kathleen McKeown. 2011. Towards strict sentence intersection: Decoding and evaluation strategies. In Proceedings of the ACL Workshop on Monolingual Text-To-Text Generation, pages 43–53, Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="37507" citStr="Turney and Pantel, 2010" startWordPosition="5968" endWordPosition="5971"> morphological features) and linguistic literature on morphological patterns. We have employed an evaluation method that uses two separate samples to assess precision and 5http://goo.gl/7KG2U; license cc-by-sa 3.0 recall to deal with the high number of false negatives. Our analyses indicate two interesting directions for future work: (a) specific handling of proper nouns, which partake in specific derivations; and (b) the use of graph clustering instead of the transitive closure to avoid errors resulting from long transitive chains. Finally, we plan to employ distributional semantics methods (Turney and Pantel, 2010) to help remove semantically unrelated pairs as well as distinguish automatically between only morphologically (M) or both morphologically and semantically (R) related pairs. Last, but not least, this allows us to group derivation rules according to their semantic properties. For example, nouns with -er suffixes often denote persons and are agentivizations of a basis word (Bilgin et al., 2004). Acknowledgments The first and third authors were supported by the EC project EXCITEMENT (FP7 ICT-287923). The second author was supported by the Croatian Science Foundation (project 02.03/162: “Derivati</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37(1):141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Zielinski</author>
<author>Christian Simon</author>
</authors>
<title>Morphisto - an open source morphological analyzer for German.</title>
<date>2008</date>
<booktitle>In Proceedings of the 7th International Workshop on Finite-State Methods and Natural Language Processing,</booktitle>
<pages>224--231</pages>
<location>Ispra, Italy.</location>
<contexts>
<context position="7899" citStr="Zielinski and Simon, 2008" startWordPosition="1164" endWordPosition="1167">n, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999), who applies an unsupervised model to construct derivational families for French. For German, several morphological tools exist. Morphix is a classification-based analyzer and generator of German words on the inflectional level (Finkler and Neumann, 1988). SMOR (Schmid et al., 2004) employs a finite-state transducer to analyze German words at the inflectional, derivational, and compositional level, and has been used in other morphological analyzers, e.g., Morphisto (Zielinski and Simon, 2008). The site canoonet1 offers broad-coverage information about the German language including derivational word formation. 3 Framework In this section, we describe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not model any semantic regularities beyond those implicit in string transformations. We begin by outlining the characteristics of German derivational morphology. 3.1 German Derivational Morphology As German is a morphologically complex language, we a</context>
</contexts>
<marker>Zielinski, Simon, 2008</marker>
<rawString>Andrea Zielinski and Christian Simon. 2008. Morphisto - an open source morphological analyzer for German. In Proceedings of the 7th International Workshop on Finite-State Methods and Natural Language Processing, pages 224–231, Ispra, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>