<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002324">
<title confidence="0.982292">
GPLSI: Supervised Sentiment Analysis in Twitter using Skipgrams
</title>
<author confidence="0.998807">
Javi Fern´andez, Yoan Guti´errez, Jos´e M. G´omez, Patricio Martinez-Barco
</author>
<affiliation confidence="0.996794">
Department of Software and Computing Systems
University of Alicante
</affiliation>
<email confidence="0.992738">
{javifm,ygutierrez,jmgomez,patricio}@dlsi.ua.es
</email>
<sectionHeader confidence="0.997339" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99855325">
In this paper we describe the system sub-
mitted for the SemEval 2014 Task 9 (Sen-
timent Analysis in Twitter) Subtask B. Our
contribution consists of a supervised ap-
proach using machine learning techniques,
which uses the terms in the dataset as fea-
tures. In this work we do not employ any
external knowledge and resources. The
novelty of our approach lies in the use
of words, ngrams and skipgrams (not-
adjacent ngrams) as features, and how they
are weighted.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999811">
The Web 2.0 has become one of the most im-
portant sources of data to extract useful and het-
erogeneous knowledge from. Texts can provide
factual information, such as descriptions and lists
of features, and opinion-based information, which
would include reviews, emotions, or feelings. This
subjective information can be expressed through
different textual genres, such as blogs, forums, so-
cial networks and microblogs.
An example of microblogging social network is
Twitter1, which has gained much popularity in the
last years. This website enables its users to send
and read text-based messages of up to 140 char-
acters, known as tweets. This site can be a vast
source of subjective information in real time; mil-
lions of users share opinions on different aspects
of their everyday life. Extracting this subjective
information has a great value for both general and
expert users. However, it is difficult to exploit it
accordingly, mainly because of the short length of
</bodyText>
<footnote confidence="0.9726534">
This work is licensed under a Creative Commons Attribu-
tion 4.0 International Licence. Page numbers and proceed-
ings footer are added by the organisers. Licence details:
creativecommons.org/licenses/by/4.0/
1http://twitter.com
</footnote>
<bodyText confidence="0.999896928571429">
the tweets, the informality, and the lack of context.
Sentiment Analysis (SA) systems must be adapted
to face the challenges of this new textual genre.
International competitions related to the assess-
ment of SA systems in Twitter have taken place.
Some of them include the TASS workshop in the
SEPLN conference (Villena-Rom´an et al., 2013),
the RepLab workshop in the CLEF conference
(Amig´o et al., 2012), and the Sentiment Analysis
in Twitter task (Task 2) in the last SemEval work-
shop (Nakov et al., 2013).
In this paper we describe the system submit-
ted for the SemEval 2014 Sentiment Analysis in
Twitter task (Task 9 Subtask B)2 (Rosenthal et al.,
2014). This task consists of performing an au-
tomatic sentiment analysis to determine whether
a message expresses a positive, negative, or neu-
tral sentiment. The organisers of this task provide
three datasets: training, development training, and
development test. The participants can use the
training and development training datasets to train
and validate their models, but the development test
dataset can only be used for validation. The size
and distribution of polarities of these datasets is
shown in Table 1. Once their systems are ready,
the participants must classify each text in the offi-
cial test corpus and send the results to the organis-
ers, who will perform the official evaluation.
</bodyText>
<table confidence="0.9920938">
Polarity Train Dev Train Dev Test
Positive 2,148 362 1,572
Neutral 2,915 448 1,640
Negative 836 187 601
Total 5,899 997 3,813
</table>
<tableCaption confidence="0.999757">
Table 1: Dataset distribution in number of tweets.
</tableCaption>
<bodyText confidence="0.779350666666667">
The goal of the present work is to create a re-
liable polarity classifier, built only from a training
set without any external knowledge and resources.
</bodyText>
<footnote confidence="0.984271">
2http://alt.qcri.org/semeval2014/
</footnote>
<page confidence="0.921882">
294
</page>
<note confidence="0.7363145">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 294–299,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999879916666667">
Our contribution consists of a supervised approach
using machine learning techniques, which uses the
terms in the dataset as features. The novelty of our
approach lies in the feature generation and weight-
ing, using not only single words and ngrams as
features but also skipgrams. This approach is de-
scribed in detail in Section 3. Subsequently, in
Section 4 we show the assessment of our model
in the competition. Finally, the conclusions and
future work are presented in Section 5. The fol-
lowing Section 2 shows some relevant background
related to this work.
</bodyText>
<sectionHeader confidence="0.999726" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999952492063493">
The goal of Sentiment analysis (SA) is to identify
the opinions expressed in text and classify texts
accordingly (Dadvar et al., 2011). Two main ap-
proaches can be followed (Annett and Kondrak,
2008; Liu, 2010; Taboada et al., 2011): lexical ap-
proaches (unsupervised SA) and machine learning
approaches (supervised SA). Lexical approaches
focus on building dictionaries and lexicons of la-
belled words. This labeling gives a score for each
word, that indicates how strong is the relation be-
tween that word and each polarity. The most com-
mon way to classify a text using these scores is
by adding the positive values and subtracting the
negative values of the terms in that text. If the to-
tal score is positive, that text is classified as pos-
itive, otherwise it is classified as negative. These
dictionaries can be created manually (Stone et al.,
1966) or automatically (Turney, 2002). Examples
of lexicons are WordNet Affect (Strapparava and
Valitutti, 2004), SentiWordNet (Esuli and Sebas-
tiani, 2006), MicroWNOP (Cerini et al., 2007) or
JRC Tonality (Balahur et al., 2009). However, it
is very difficult to collect and maintain a univer-
sal sentiment lexicon because different words may
be used in different domains (Qiu et al., 2009) and
some words are domain dependent (Turney, 2002).
The second approach uses machine learning
techniques. These techniques require the previous
creation of a corpus containing a set of classified
texts to train a classifier, which can then be applied
to classify a set of unclassified texts. The majority
of the researches employ Support Vector Machines
(Mullen and Collier, 2004; Prabowo et al., 2009;
Wilson et al., 2005) or Naive Bayes (Pang and Lee,
2004; Wiebe et al., 2005; Tan et al., 2009) classi-
fiers because they usually obtain the best results.
In this approach, texts are represented as vectors
of features, and depending on the features used
the system can reach better results (bag-of-words
and lexeme-based features are the more commonly
used (Pang and Lee, 2008)). These classifiers per-
form very well in the domain that they are trained
on, but their performance drops when the same
classifier is used in a different domain (Pang and
Lee, 2008; Tan et al., 2009).
The problem of the domain dependence is com-
mon to both approaches. When the lexicons and
classifiers generated are used in a domain different
from the one they were built for, they use to per-
form worse (Turney, 2002; Pang and Lee, 2008;
Qiu et al., 2009; Tan et al., 2009). Creating a
domain-specific lexicon or classifier means mak-
ing a manual effort. Although some studies try
to overcome this problem by generating the lexi-
cons automatically (Turney, 2002), learning from
unannotated texts (Wiebe et al., 2005) or using hy-
brid approaches (Andreevskaia and Bergler, 2008;
Bollen et al., 2011; Zhang and Ye, 2008), a min-
imal intervention from experts in the domain is
needed. In this study we use the machine learning
approach due to the promising results obtained in
previous works (Boldrini et al., 2009; Fern´andez
et al., 2011; Fern´andez et al., 2013).
</bodyText>
<sectionHeader confidence="0.997335" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9999735">
Our contribution consists of a supervised approach
using machine learning techniques, which uses the
terms in the dataset as features. In summary, our
approach starts making a basic normalisation of
each tweet in the dataset (see Section 3.1). Next,
these texts are tokenised to extract their terms, and
these terms are combined to create skipgrams (see
Section 3.2). Finally, these skipgrams are em-
ployed as features for a supervised machine learn-
ing algorithm (see Section 3.3).
</bodyText>
<subsectionHeader confidence="0.999686">
3.1 Basic normalisation
</subsectionHeader>
<bodyText confidence="0.9937884">
We perform a very basic normalisation, as we
do not want to lose the potential subjective infor-
mation given by the not normalised original text.
Each tweet in the dataset is normalised following
these steps:
</bodyText>
<listItem confidence="0.999488">
1. Lower case conversion. All the characters in
the tweet text are converted to lower case.
2. Character repetition removal. If the same
character is repeated more than 3 times, the
rest of repetitions are removed, so we can
</listItem>
<page confidence="0.993826">
295
</page>
<bodyText confidence="0.9204385625">
still recognize if a word had repeated char-
acters. For example, the words gooood and
gooooood would be normalised to goood, but
the word good would remain the same. We
assume the ambiguity of some words like the
one in the example, which can refer to the
words good and god.
3. Usernames and hashtags substitution. We
do not consider usernames and hashtags as
they are not usually the words that represent
a subjective sentence, they use to be the topic
of the tweet. They are not removed com-
pletely but they are replaced by the strings
USERNAME and HASHTAG.
So excited to go to #Alicante tomorrow
with the best friend everrrrr @John!!!!
</bodyText>
<figure confidence="0.154495777777778">
1
so excited to go to #alicante tomorrow
with the best friend everrrrr @john!!!!
1
so excited to go to #alicante tomorrow
with the best friend everrr @john!!!
1
so excited to go to HASHTAG tomorrow
with the best friend everrr USERNAME!!!
</figure>
<figureCaption confidence="0.999533">
Figure 1: Example of normalisation process.
</figureCaption>
<subsectionHeader confidence="0.990568">
3.2 Tokenisation
</subsectionHeader>
<bodyText confidence="0.973809">
Once we have normalised the texts, we extract all
their terms. In this work, we consider a term as a
group of adjacent characters of the same type (let-
ters, numbers or punctuation symbols). For exam-
ple, the text want2go!! would be tokenised to the
terms want, 2, go, and !!. Note that we employ all
the terms extracted, not filtering any of them.
Finally, we obtain the skipgrams of the terms in
the text. Skipgrams are a technique largely used in
the field of speech processing, whereby n-grams
are formed (bigrams, trigrams, etc.) but in addi-
tion to allowing adjacent sequences of words, it
also allows tokens to be skipped (Guthrie et al.,
2006). More specifically, in a k-skip-n-gram, n de-
termines the maximum number of terms, and k the
maximum number of skips allowed. In this way
skipgrams are new terms that retain part of the se-
quentiality of the terms, but in a more flexible way
than ngrams. Note that a ngram can be described
as a skipgram where k = 0. An example is shown
in Figure 2.
Normalised tweet
so excited to go to HASHTAG tomorrow
with the best friend everrr USERNAME!!!
</bodyText>
<figure confidence="0.997535733333333">
1
Single terms
(so) (excited) (to) (go) (to) (HASHTAG) (with)
(the) (best) (friend) (everrr) (USERNAME) (!!!)
1
Skipgrams (n = 2, k = 1)
(so) (so excited) (so to) (excited) (excited to)
(excited go)
(to) (to go) (to to) (go) (go to) (go HASHTAG) (to)
(to HASHTAG) (to with) (HASHTAG) (HASHTAG
with) (HASHTAG the) (with) (with the) (with best)
(the) (the best) (the friend) (best) (best friend)
(best everrr) (friend) (friend everrr) (friend
USERNAME) (everrr) (everrr USERNAME)
(everrr !!!) (USERNAME) (USERNAME !!!)
</figure>
<figureCaption confidence="0.999775">
Figure 2: Example of tokenisation process.
</figureCaption>
<subsectionHeader confidence="0.995423">
3.3 Supervised Learning
</subsectionHeader>
<bodyText confidence="0.999847714285714">
To build our model we employed Support Vector
Machines (SVM) as the supervised machine learn-
ing algorithm, as it has been proved to be effective
on text categorisation tasks and robust on large
feature spaces (Sebastiani, 2002; Mohammad et
al., 2013). More specifically, we used the Weka3
(Hall et al., 2009) LibSVM (Chang and Lin, 2011)
implementation with the default parameters (lin-
ear kernel, C = 1, c = 0.1).
The skipgrams extracted in the previous step are
employed as features for the SVM. The weight of
each feature in each text will be calculated depend-
ing on the skipgram it represents, using the for-
mula in Equation 1.
</bodyText>
<equation confidence="0.996787">
terms(s)
w(s, t) = terms(s) + skips(s, t) (1)
</equation>
<bodyText confidence="0.9997911">
Where w(s, t) represents the weight of the skip-
gram s in the text t, terms is a function that
returns the number of terms in skipgram s, and
skips is a function that returns the number of skips
of the skipgram s in the text t. This formula gives
more importance to the skipgrams with a lower
number of skips. In the example of the Figure 2,
the skipgram best friend would have a weight of
2/(2 + 0) = 1, while skipgram best everrr would
have a weight of 2/(2 + 1) = 0.66.
</bodyText>
<footnote confidence="0.952699">
3http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<page confidence="0.992811">
296
</page>
<table confidence="0.978343">
Parameters P R F1 Score
Baseline 0.630 0.604 0.580 0.447
Words n = 1 0.611 0.612 0.604 0.530
Ngrams n = 2 0.617 0.620 0.618 0.557
</table>
<equation confidence="0.944255333333333">
n = 3 0.620 0.621 0.621 0.564
n = 4 0.620 0.621 0.620 0.565
n = max 0.621 0.622 0.621 0.566
Skipgrams n = 2,k = 1 0.623 0.625 0.624 0.571
n = 2,k = 2 0.626 0.624 0.626 0.572
n = 2,k = max 0.627 0.624 0.625 0.575
n = 3,k = 1 0.620 0.616 0.617 0.566
n = 3,k = 2 0.625 0.614 0.618 0.564
n = 3,k = max 0.636 0.588 0.599 0.544
</equation>
<tableCaption confidence="0.980057">
Table 2: Experiments performed and scores obtained.
</tableCaption>
<sectionHeader confidence="0.997441" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.992442162162162">
We performed a series of experiments employ-
ing both the training corpus and the development
training corpus to create our model, and the devel-
opment test corpus to validate it. We used as base-
line the system presented to the workshop TASS
2012 (Fern´andez et al., 2013), which also uses
skipgrams and scores them depending on their
density but, instead of using the skipgrams as fea-
tures of a machine learning model, the polarity of
each text is determined by a combination of the
scores of its skipgrams.
The results of our experiments are shown in Ta-
ble 2. In this table we show the weighted precision
(P), the weighted recall (R), the weighted F-score
(F1) and the score obtained using the scorer tool
provided by the workshop organisers (Score). The
notation n = max indicates there was no limit
with the number of terms, and k = max indi-
cates there was no restriction with the number of
skips. As we can see, the presented approach out-
performs the baseline proposed and the best results
are obtained using skipgrams, specifically when
n = 2 and k = max. These are the parameters
of the system submitted to the competition.
Our main observation is that incrementing the
number of terms increases the precision of the sys-
tem. A possible explanation for this might be that
ngrams/skipgrams with a greater number of words
are more specific and representative of a given
polarity. In addition, using skipgrams insted of
ngrams also improves the precision. However, no
significant differences were found between exper-
iments with a different number of skips.
In Table 3 we can see the official results ob-
tained in the SemEval 2014 competition. The
best rank was obtained in the experiments with the
Twitter 2014 Sarcasm dataset.
</bodyText>
<table confidence="0.999611833333333">
Dataset Rank Score
Live Journal 34 0.573
SMS 2013 35 0.466
Twitter 2013 28 0.575
Twitter 2014 30 0.561
Twitter 2014 Sarcasm 8 0.539
</table>
<tableCaption confidence="0.998064">
Table 3: Official SemEval 2014 Subtask B results.
</tableCaption>
<sectionHeader confidence="0.994153" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.991735555555556">
In this paper we described the system submitted
for the SemEval 2014 Task 9 (Sentiment Analysis
in Twitter). It consists of a supervised approach
using machine learning techniques, without em-
ploying any external knowledge and resources.
The novelty of our approach lies in the feature gen-
eration and weighting, using not only single words
and ngrams as features but also skipgrams. In the
experiments performed we showed that employ-
ing skipgrams instead of single words or ngrams
improves the results for these datasets. This fact
suggests that our approach is promising and en-
courages us to continue with our research.
As future work, we plan to find new methods
to combine the weights of the skipgrams, evaluate
our approaches on different corpora and different
domains (in order to check their robustness), and
start adding external knowledge and resources.
</bodyText>
<page confidence="0.996124">
297
</page>
<sectionHeader confidence="0.982345" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999796444444444">
This research work has been partially funded by
the University ofAlicante, Generalitat Valenciana,
Spanish Government and the European Com-
mission through the projects, “Tratamiento in-
teligente de la informaci´on para la ayuda a la toma
de decisiones” (GRE12-44), ATTOS (TIN2012-
38536-C03-03), LEGOLANG (TIN2012-31224),
SAM (FP7-611312), FIRST (FP7-287607) and
ACOMP/2013/067.
</bodyText>
<sectionHeader confidence="0.987528" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997287989247312">
Enrique Amig´o, Adolfo Corujo, Julio Gonzalo, Edgar
Meij, and Maarten de Rijke. 2012. Overview of
RepLab 2012: Evaluating Online Reputation Man-
agement Systems. In Conference and Labs of the
Evaluation Forum (CLEF 2012).
Alina Andreevskaia and Sabine Bergler. 2008. When
Specialists and Generalists Work Together: Over-
coming Domain Dependence in Sentiment Tagging.
In Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics on Human
Language Technologies (ACL HLT 2008), pages
290–298.
Michelle Annett and Grzegorz Kondrak. 2008. A
Comparison of Sentiment Analysis Techniques: Po-
larizing Movie Blogs. In Proceedings of the
21st Canadian Conference on Artificial Intelligence
(CCAI2008), pages 25–35.
Alexandra Balahur, Ralf Steinberger, Erik Van Der
Goot, Bruno Pouliquen, and Mijail Kabadjov. 2009.
Opinion Mining on Newspaper Quotations. In 2009
IEEE/WIC/ACM International Joint Conference on
Web Intelligence and Intelligent Agent Technology,
pages 523–526.
Ester Boldrini, Javier Fern´andez Martinez,
Jos´e Manuel G´omez Soriano, Patricio
Martinez Barco, et al. 2009. Machine learn-
ing techniques for automatic opinion detection in
non-traditional textual genres.
Johan Bollen, Alberto Pepe, and Huina Mao. 2011.
Modeling Public Mood and Emotion: Twitter Senti-
ment and Socio-Economic Phenomena. In Fifth In-
ternational AAAI Conference on Weblogs and Social
Media (ICWSM 2011).
Sabrina Cerini, Valentina Compagnoni, Alice Demon-
tis, Maicol Formentelli, and G Gandini. 2007.
Micro-WNOp: A Gold Standard for the Evaluation
of Automatically Compiled Lexical Resources for
Opinion Mining. Language resources and linguis-
tic theory: Typology, second language acquisition,
English linguistics, pages 200–210.
Chih-chung Chang and Chih-jen Lin. 2011. LIBSVM
: A Library for Support Vector Machines. ACM
Transactions on Intelligent Systems and Technology
(TIST), 2:1–39.
Maral Dadvar, Claudia Hauff, and FMG De Jong.
2011. Scope of Negation Detection in Sentiment
Analysis. In Proceedings of the Dutch-Belgian In-
formation Retrieval Workshop (DIR 2011), pages
16–20.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sen-
tiwordnet: A Publicly Available Lexical Resource
for Opinion Mining. In Proceedings of LREC, vol-
ume 6, pages 417–422.
Javi Fern´andez, Ester Boldrini, Jos´e M. G´omez,
and Patricio Martinez-Barco. 2011. Evaluat-
ing EmotiBlog Robustness for Sentiment Analysis
Tasks. In Natural Language Processing and Infor-
mation Systems, pages 290–294.
Javi Fern´andez, Yoan Guti´errez, Jos´e M. G´omez, Patri-
cio Martinez-Barco, Andr´es Montoyo, and Rafael
Mu˜noz. 2013. Sentiment Analysis of Spanish
Tweets Using a Ranking Algorithm and Skipgrams.
In XXIX Congreso de la Sociedad Espa˜nola de
Procesamiento de Lenguaje Natural (SEPLN 2013),
pages 133–142.
David Guthrie, Ben Allison, Wei Liu, Louise Guthrie,
and Yorick Wilks. 2006. A Closer Look at Skip-
gram Modelling. In 5th international Conference on
Language Resources and Evaluation (LREC 2006),
pages 1–4.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H Witten.
2009. The WEKA Data Mining Software: an
Update. ACM SIGKDD Explorations Newsletter,
11(1):10–18.
Bing Liu. 2010. Sentiment Analysis and Subjectiv-
ity. In Handbook of Natural Language Processing,
pages 1–38.
Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. NRC-Canada: Building the State-
of-the-Art in Sentiment Analysis of Tweets. In Pro-
ceedings of the International Workshop on Semantic
Evaluation (SemEval-2013).
Tony Mullen and Nigel Collier. 2004. Sentiment Anal-
ysis using Support Vector Machines with Diverse In-
formation Sources. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 2004), pages 412–418.
Preslav Nakov, Sara Rosenthal, Alan Ritter, and
Theresa Wilson. 2013. SemEval-2013 Task 2:
Sentiment Analysis in Twitter. In Proceedings of
the International Workshop on Semantic Evaluation
(SemEval-2013), volume 2, pages 312–320.
</reference>
<page confidence="0.987119">
298
</page>
<reference confidence="0.999855984615384">
Bo Pang and Lillian Lee. 2004. A Sentimental Educa-
tion: Sentiment Analysis Using Subjectivity Sum-
marization Based on Minimum Cuts. In Proceed-
ings of the 42nd annual meeting on Association for
Computational Linguistics (ACL 2004), page 271.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2):1–135.
Rudy Prabowo, Mike Thelwall, and Wulfruna Street.
2009. Sentiment Analysis: A Combined Approach.
Journal of Informetrics, 3:143–157.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding Domain Sentiment Lexicon
through Double Propagation. In Proceedings of the
21st international Joint Conference on Artificial In-
telligence (IJCAI2009), pages 1199–1204.
Sara Rosenthal, Preslav Nakov, Alan Ritter, and
Veselin Stoyanov. 2014. SemEval-2014 Task 9:
Sentiment Analysis in Twitter. In Proceedings of
the International Workshop on Semantic Evaluation
(SemEval-2014).
Fabrizio Sebastiani. 2002. Machine Learning in Au-
tomated Text Categorization. ACM Computing Sur-
veys (CSUR), 34(1):1–47, March.
Philip J. Stone, Dexter C. Dunphy, and Marshall S.
Smith. 1966. The General Inquirer: A Computer
Approach to Content Analysis.
Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet Affect: an Affective Extension of Word-
Net. In LREC, volume 4, pages 1083–1086.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional Linguistics, 37(2):267–307.
Songbo Tan, Xueqi Cheng, Yuefen Wang, and Hongbo
Xu. 2009. Adapting Naive Bayes to Domain Adap-
tation for Sentiment Analysis. Advances in Informa-
tion Retrieval, pages 337–349.
Peter D. Turney. 2002. Thumbs Up or Thumbs
Down? Semantic Orientation Applied to Unsuper-
vised Classification of Reviews. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics (ACL 2002), pages 417–424.
Julio Villena-Rom´an, Eugenio Martinez-C´amara, Sara
Lana-Serrano, and Jos´e Carlos Gonz´alez-Crist´obal.
2013. TASS - Workshop on Sentiment Analysis
at SEPLN. Procesamiento del Lenguaje Natural,
50:37–44.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating Expressions of Opinions and
Emotions in Language. Language resources and
evaluation, 39(2-3):165–210.
Theresa Wilson, Paul Hoffmann, Swapna Somasun-
daran, Jason Kessler, Janyce Wiebe, Yejin Choi,
Claire Cardie, Ellen Riloff, and Siddharth Patward-
han. 2005. OpinionFinder: A System for Subjec-
tivity Analysis. In Proceedings of HLT/EMNLP on
Interactive Demonstrations, pages 34–35.
Min Zhang and Xingyao Ye. 2008. A Generation
Model to Unify Topic Relevance and Lexicon-based
Sentiment for Opinion Retrieval. In Proceedings of
the 31st annual international ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval (SIGIR 2008), pages 411–418, New York,
New York, USA. ACM Press.
</reference>
<page confidence="0.998656">
299
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.982870">
<title confidence="0.999959">GPLSI: Supervised Sentiment Analysis in Twitter using Skipgrams</title>
<author confidence="0.999615">Javi Fern´andez</author>
<author confidence="0.999615">Yoan Guti´errez</author>
<author confidence="0.999615">Jos´e M G´omez</author>
<author confidence="0.999615">Patricio</author>
<affiliation confidence="0.9968755">Department of Software and Computing University of</affiliation>
<abstract confidence="0.999017076923077">In this paper we describe the system subfor the 2014 Task 9 (Sen- Analysis in Twitter) Subtask Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features. In this work we do not employ any external knowledge and resources. The novelty of our approach lies in the use words, ngrams and (notadjacent ngrams) as features, and how they are weighted.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Amig´o</author>
<author>Adolfo Corujo</author>
<author>Julio Gonzalo</author>
<author>Edgar Meij</author>
<author>Maarten de Rijke</author>
</authors>
<title>Overview of RepLab 2012: Evaluating Online Reputation Management Systems.</title>
<date>2012</date>
<booktitle>In Conference and Labs of the Evaluation Forum (CLEF</booktitle>
<marker>Amig´o, Corujo, Gonzalo, Meij, de Rijke, 2012</marker>
<rawString>Enrique Amig´o, Adolfo Corujo, Julio Gonzalo, Edgar Meij, and Maarten de Rijke. 2012. Overview of RepLab 2012: Evaluating Online Reputation Management Systems. In Conference and Labs of the Evaluation Forum (CLEF 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies (ACL HLT</booktitle>
<pages>290--298</pages>
<contexts>
<context position="7140" citStr="Andreevskaia and Bergler, 2008" startWordPosition="1141" endWordPosition="1144"> different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´andez et al., 2011; Fern´andez et al., 2013). 3 Methodology Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features. In summary, our approach starts making a basic normalisation of each tweet in the dataset (see Section 3.1). Next, these texts are tokenised to extract their terms,</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2008. When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies (ACL HLT 2008), pages 290–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michelle Annett</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>A Comparison of Sentiment Analysis Techniques: Polarizing Movie Blogs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 21st Canadian Conference on Artificial Intelligence (CCAI2008),</booktitle>
<pages>25--35</pages>
<contexts>
<context position="4552" citStr="Annett and Kondrak, 2008" startWordPosition="714" endWordPosition="717">f our approach lies in the feature generation and weighting, using not only single words and ngrams as features but also skipgrams. This approach is described in detail in Section 3. Subsequently, in Section 4 we show the assessment of our model in the competition. Finally, the conclusions and future work are presented in Section 5. The following Section 2 shows some relevant background related to this work. 2 Related Work The goal of Sentiment analysis (SA) is to identify the opinions expressed in text and classify texts accordingly (Dadvar et al., 2011). Two main approaches can be followed (Annett and Kondrak, 2008; Liu, 2010; Taboada et al., 2011): lexical approaches (unsupervised SA) and machine learning approaches (supervised SA). Lexical approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dicti</context>
</contexts>
<marker>Annett, Kondrak, 2008</marker>
<rawString>Michelle Annett and Grzegorz Kondrak. 2008. A Comparison of Sentiment Analysis Techniques: Polarizing Movie Blogs. In Proceedings of the 21st Canadian Conference on Artificial Intelligence (CCAI2008), pages 25–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Balahur</author>
<author>Ralf Steinberger</author>
<author>Erik Van Der Goot</author>
<author>Bruno Pouliquen</author>
<author>Mijail Kabadjov</author>
</authors>
<title>Opinion Mining on Newspaper Quotations.</title>
<date>2009</date>
<booktitle>In 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology,</booktitle>
<pages>523--526</pages>
<marker>Balahur, Steinberger, Van Der Goot, Pouliquen, Kabadjov, 2009</marker>
<rawString>Alexandra Balahur, Ralf Steinberger, Erik Van Der Goot, Bruno Pouliquen, and Mijail Kabadjov. 2009. Opinion Mining on Newspaper Quotations. In 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, pages 523–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ester Boldrini</author>
<author>Javier Fern´andez Martinez</author>
<author>Jos´e Manuel G´omez Soriano</author>
<author>Patricio Martinez Barco</author>
</authors>
<title>Machine learning techniques for automatic opinion detection in non-traditional textual genres.</title>
<date>2009</date>
<contexts>
<context position="7374" citStr="Boldrini et al., 2009" startWordPosition="1182" endWordPosition="1185">to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´andez et al., 2011; Fern´andez et al., 2013). 3 Methodology Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features. In summary, our approach starts making a basic normalisation of each tweet in the dataset (see Section 3.1). Next, these texts are tokenised to extract their terms, and these terms are combined to create skipgrams (see Section 3.2). Finally, these skipgrams are employed as features for a supervised machine learning algorithm (see Section 3.3). 3.1 Basic normalisation We perform a very basic norm</context>
</contexts>
<marker>Boldrini, Martinez, Soriano, Barco, 2009</marker>
<rawString>Ester Boldrini, Javier Fern´andez Martinez, Jos´e Manuel G´omez Soriano, Patricio Martinez Barco, et al. 2009. Machine learning techniques for automatic opinion detection in non-traditional textual genres.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
<author>Alberto Pepe</author>
<author>Huina Mao</author>
</authors>
<title>Modeling Public Mood and Emotion: Twitter Sentiment and Socio-Economic Phenomena.</title>
<date>2011</date>
<booktitle>In Fifth International AAAI Conference on Weblogs and Social Media (ICWSM</booktitle>
<contexts>
<context position="7161" citStr="Bollen et al., 2011" startWordPosition="1145" endWordPosition="1148"> 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´andez et al., 2011; Fern´andez et al., 2013). 3 Methodology Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features. In summary, our approach starts making a basic normalisation of each tweet in the dataset (see Section 3.1). Next, these texts are tokenised to extract their terms, and these terms are </context>
</contexts>
<marker>Bollen, Pepe, Mao, 2011</marker>
<rawString>Johan Bollen, Alberto Pepe, and Huina Mao. 2011. Modeling Public Mood and Emotion: Twitter Sentiment and Socio-Economic Phenomena. In Fifth International AAAI Conference on Weblogs and Social Media (ICWSM 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabrina Cerini</author>
<author>Valentina Compagnoni</author>
<author>Alice Demontis</author>
<author>Maicol Formentelli</author>
<author>G Gandini</author>
</authors>
<title>Micro-WNOp: A Gold Standard for the Evaluation of Automatically Compiled Lexical Resources for Opinion Mining. Language resources and linguistic theory: Typology, second language acquisition, English linguistics,</title>
<date>2007</date>
<pages>200--210</pages>
<contexts>
<context position="5387" citStr="Cerini et al., 2007" startWordPosition="849" endWordPosition="852">ng gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 20</context>
</contexts>
<marker>Cerini, Compagnoni, Demontis, Formentelli, Gandini, 2007</marker>
<rawString>Sabrina Cerini, Valentina Compagnoni, Alice Demontis, Maicol Formentelli, and G Gandini. 2007. Micro-WNOp: A Gold Standard for the Evaluation of Automatically Compiled Lexical Resources for Opinion Mining. Language resources and linguistic theory: Typology, second language acquisition, English linguistics, pages 200–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-chung Chang</author>
<author>Chih-jen Lin</author>
</authors>
<title>LIBSVM : A Library for Support Vector Machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--1</pages>
<contexts>
<context position="11332" citStr="Chang and Lin, 2011" startWordPosition="1853" endWordPosition="1856">ASHTAG the) (with) (with the) (with best) (the) (the best) (the friend) (best) (best friend) (best everrr) (friend) (friend everrr) (friend USERNAME) (everrr) (everrr USERNAME) (everrr !!!) (USERNAME) (USERNAME !!!) Figure 2: Example of tokenisation process. 3.3 Supervised Learning To build our model we employed Support Vector Machines (SVM) as the supervised machine learning algorithm, as it has been proved to be effective on text categorisation tasks and robust on large feature spaces (Sebastiani, 2002; Mohammad et al., 2013). More specifically, we used the Weka3 (Hall et al., 2009) LibSVM (Chang and Lin, 2011) implementation with the default parameters (linear kernel, C = 1, c = 0.1). The skipgrams extracted in the previous step are employed as features for the SVM. The weight of each feature in each text will be calculated depending on the skipgram it represents, using the formula in Equation 1. terms(s) w(s, t) = terms(s) + skips(s, t) (1) Where w(s, t) represents the weight of the skipgram s in the text t, terms is a function that returns the number of terms in skipgram s, and skips is a function that returns the number of skips of the skipgram s in the text t. This formula gives more importance</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-chung Chang and Chih-jen Lin. 2011. LIBSVM : A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maral Dadvar</author>
<author>Claudia Hauff</author>
<author>FMG De Jong</author>
</authors>
<title>Scope of Negation Detection in Sentiment Analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Dutch-Belgian Information Retrieval Workshop</booktitle>
<pages>16--20</pages>
<location>DIR</location>
<marker>Dadvar, Hauff, De Jong, 2011</marker>
<rawString>Maral Dadvar, Claudia Hauff, and FMG De Jong. 2011. Scope of Negation Detection in Sentiment Analysis. In Proceedings of the Dutch-Belgian Information Retrieval Workshop (DIR 2011), pages 16–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A Publicly Available Lexical Resource for Opinion Mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="5354" citStr="Esuli and Sebastiani, 2006" startWordPosition="843" endWordPosition="847"> lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and </context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A Publicly Available Lexical Resource for Opinion Mining. In Proceedings of LREC, volume 6, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javi Fern´andez</author>
<author>Ester Boldrini</author>
<author>Jos´e M G´omez</author>
<author>Patricio Martinez-Barco</author>
</authors>
<title>Evaluating EmotiBlog Robustness for Sentiment Analysis Tasks.</title>
<date>2011</date>
<booktitle>In Natural Language Processing and Information Systems,</booktitle>
<pages>290--294</pages>
<marker>Fern´andez, Boldrini, G´omez, Martinez-Barco, 2011</marker>
<rawString>Javi Fern´andez, Ester Boldrini, Jos´e M. G´omez, and Patricio Martinez-Barco. 2011. Evaluating EmotiBlog Robustness for Sentiment Analysis Tasks. In Natural Language Processing and Information Systems, pages 290–294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javi Fern´andez</author>
<author>Yoan Guti´errez</author>
<author>Jos´e M G´omez</author>
<author>Patricio Martinez-Barco</author>
<author>Andr´es Montoyo</author>
<author>Rafael Mu˜noz</author>
</authors>
<title>Sentiment Analysis of Spanish Tweets Using a Ranking Algorithm and Skipgrams.</title>
<date>2013</date>
<booktitle>In XXIX Congreso de la Sociedad Espa˜nola de Procesamiento de Lenguaje Natural (SEPLN</booktitle>
<pages>133--142</pages>
<marker>Fern´andez, Guti´errez, G´omez, Martinez-Barco, Montoyo, Mu˜noz, 2013</marker>
<rawString>Javi Fern´andez, Yoan Guti´errez, Jos´e M. G´omez, Patricio Martinez-Barco, Andr´es Montoyo, and Rafael Mu˜noz. 2013. Sentiment Analysis of Spanish Tweets Using a Ranking Algorithm and Skipgrams. In XXIX Congreso de la Sociedad Espa˜nola de Procesamiento de Lenguaje Natural (SEPLN 2013), pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Guthrie</author>
<author>Ben Allison</author>
<author>Wei Liu</author>
<author>Louise Guthrie</author>
<author>Yorick Wilks</author>
</authors>
<title>A Closer Look at Skipgram Modelling.</title>
<date>2006</date>
<booktitle>In 5th international Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1--4</pages>
<contexts>
<context position="9968" citStr="Guthrie et al., 2006" startWordPosition="1624" endWordPosition="1627"> texts, we extract all their terms. In this work, we consider a term as a group of adjacent characters of the same type (letters, numbers or punctuation symbols). For example, the text want2go!! would be tokenised to the terms want, 2, go, and !!. Note that we employ all the terms extracted, not filtering any of them. Finally, we obtain the skipgrams of the terms in the text. Skipgrams are a technique largely used in the field of speech processing, whereby n-grams are formed (bigrams, trigrams, etc.) but in addition to allowing adjacent sequences of words, it also allows tokens to be skipped (Guthrie et al., 2006). More specifically, in a k-skip-n-gram, n determines the maximum number of terms, and k the maximum number of skips allowed. In this way skipgrams are new terms that retain part of the sequentiality of the terms, but in a more flexible way than ngrams. Note that a ngram can be described as a skipgram where k = 0. An example is shown in Figure 2. Normalised tweet so excited to go to HASHTAG tomorrow with the best friend everrr USERNAME!!! 1 Single terms (so) (excited) (to) (go) (to) (HASHTAG) (with) (the) (best) (friend) (everrr) (USERNAME) (!!!) 1 Skipgrams (n = 2, k = 1) (so) (so excited) (s</context>
</contexts>
<marker>Guthrie, Allison, Liu, Guthrie, Wilks, 2006</marker>
<rawString>David Guthrie, Ben Allison, Wei Liu, Louise Guthrie, and Yorick Wilks. 2006. A Closer Look at Skipgram Modelling. In 5th international Conference on Language Resources and Evaluation (LREC 2006), pages 1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA Data Mining Software: an Update.</title>
<date>2009</date>
<journal>ACM SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="11303" citStr="Hall et al., 2009" startWordPosition="1848" endWordPosition="1851">(HASHTAG) (HASHTAG with) (HASHTAG the) (with) (with the) (with best) (the) (the best) (the friend) (best) (best friend) (best everrr) (friend) (friend everrr) (friend USERNAME) (everrr) (everrr USERNAME) (everrr !!!) (USERNAME) (USERNAME !!!) Figure 2: Example of tokenisation process. 3.3 Supervised Learning To build our model we employed Support Vector Machines (SVM) as the supervised machine learning algorithm, as it has been proved to be effective on text categorisation tasks and robust on large feature spaces (Sebastiani, 2002; Mohammad et al., 2013). More specifically, we used the Weka3 (Hall et al., 2009) LibSVM (Chang and Lin, 2011) implementation with the default parameters (linear kernel, C = 1, c = 0.1). The skipgrams extracted in the previous step are employed as features for the SVM. The weight of each feature in each text will be calculated depending on the skipgram it represents, using the formula in Equation 1. terms(s) w(s, t) = terms(s) + skips(s, t) (1) Where w(s, t) represents the weight of the skipgram s in the text t, terms is a function that returns the number of terms in skipgram s, and skips is a function that returns the number of skips of the skipgram s in the text t. This </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The WEKA Data Mining Software: an Update. ACM SIGKDD Explorations Newsletter, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Subjectivity.</title>
<date>2010</date>
<booktitle>In Handbook of Natural Language Processing,</booktitle>
<pages>1--38</pages>
<contexts>
<context position="4563" citStr="Liu, 2010" startWordPosition="718" endWordPosition="719"> feature generation and weighting, using not only single words and ngrams as features but also skipgrams. This approach is described in detail in Section 3. Subsequently, in Section 4 we show the assessment of our model in the competition. Finally, the conclusions and future work are presented in Section 5. The following Section 2 shows some relevant background related to this work. 2 Related Work The goal of Sentiment analysis (SA) is to identify the opinions expressed in text and classify texts accordingly (Dadvar et al., 2011). Two main approaches can be followed (Annett and Kondrak, 2008; Liu, 2010; Taboada et al., 2011): lexical approaches (unsupervised SA) and machine learning approaches (supervised SA). Lexical approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can</context>
</contexts>
<marker>Liu, 2010</marker>
<rawString>Bing Liu. 2010. Sentiment Analysis and Subjectivity. In Handbook of Natural Language Processing, pages 1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>NRC-Canada: Building the Stateof-the-Art in Sentiment Analysis of Tweets.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2013).</booktitle>
<contexts>
<context position="11245" citStr="Mohammad et al., 2013" startWordPosition="1838" endWordPosition="1841">(to to) (go) (go to) (go HASHTAG) (to) (to HASHTAG) (to with) (HASHTAG) (HASHTAG with) (HASHTAG the) (with) (with the) (with best) (the) (the best) (the friend) (best) (best friend) (best everrr) (friend) (friend everrr) (friend USERNAME) (everrr) (everrr USERNAME) (everrr !!!) (USERNAME) (USERNAME !!!) Figure 2: Example of tokenisation process. 3.3 Supervised Learning To build our model we employed Support Vector Machines (SVM) as the supervised machine learning algorithm, as it has been proved to be effective on text categorisation tasks and robust on large feature spaces (Sebastiani, 2002; Mohammad et al., 2013). More specifically, we used the Weka3 (Hall et al., 2009) LibSVM (Chang and Lin, 2011) implementation with the default parameters (linear kernel, C = 1, c = 0.1). The skipgrams extracted in the previous step are employed as features for the SVM. The weight of each feature in each text will be calculated depending on the skipgram it represents, using the formula in Equation 1. terms(s) w(s, t) = terms(s) + skips(s, t) (1) Where w(s, t) represents the weight of the skipgram s in the text t, terms is a function that returns the number of terms in skipgram s, and skips is a function that returns </context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M. Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. NRC-Canada: Building the Stateof-the-Art in Sentiment Analysis of Tweets. In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Mullen</author>
<author>Nigel Collier</author>
</authors>
<title>Sentiment Analysis using Support Vector Machines with Diverse Information Sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004),</booktitle>
<pages>412--418</pages>
<contexts>
<context position="5967" citStr="Mullen and Collier, 2004" startWordPosition="942" endWordPosition="945">iani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009).</context>
</contexts>
<marker>Mullen, Collier, 2004</marker>
<rawString>Tony Mullen and Nigel Collier. 2004. Sentiment Analysis using Support Vector Machines with Diverse Information Sources. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), pages 412–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Alan Ritter</author>
<author>Theresa Wilson</author>
</authors>
<title>SemEval-2013 Task 2: Sentiment Analysis in Twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2013),</booktitle>
<volume>2</volume>
<pages>312--320</pages>
<contexts>
<context position="2436" citStr="Nakov et al., 2013" startWordPosition="374" endWordPosition="377">footer are added by the organisers. Licence details: creativecommons.org/licenses/by/4.0/ 1http://twitter.com the tweets, the informality, and the lack of context. Sentiment Analysis (SA) systems must be adapted to face the challenges of this new textual genre. International competitions related to the assessment of SA systems in Twitter have taken place. Some of them include the TASS workshop in the SEPLN conference (Villena-Rom´an et al., 2013), the RepLab workshop in the CLEF conference (Amig´o et al., 2012), and the Sentiment Analysis in Twitter task (Task 2) in the last SemEval workshop (Nakov et al., 2013). In this paper we describe the system submitted for the SemEval 2014 Sentiment Analysis in Twitter task (Task 9 Subtask B)2 (Rosenthal et al., 2014). This task consists of performing an automatic sentiment analysis to determine whether a message expresses a positive, negative, or neutral sentiment. The organisers of this task provide three datasets: training, development training, and development test. The participants can use the training and development training datasets to train and validate their models, but the development test dataset can only be used for validation. The size and distri</context>
</contexts>
<marker>Nakov, Rosenthal, Ritter, Wilson, 2013</marker>
<rawString>Preslav Nakov, Sara Rosenthal, Alan Ritter, and Theresa Wilson. 2013. SemEval-2013 Task 2: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2013), volume 2, pages 312–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd annual meeting on Association for Computational Linguistics (ACL 2004),</booktitle>
<pages>271</pages>
<contexts>
<context position="6046" citStr="Pang and Lee, 2004" startWordPosition="957" endWordPosition="960">However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the le</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts. In Proceedings of the 42nd annual meeting on Association for Computational Linguistics (ACL 2004), page 271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="6366" citStr="Pang and Lee, 2008" startWordPosition="1009" endWordPosition="1012">orpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this pr</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval, 2(1–2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudy Prabowo</author>
<author>Mike Thelwall</author>
<author>Wulfruna Street</author>
</authors>
<title>Sentiment Analysis: A Combined Approach.</title>
<date>2009</date>
<journal>Journal of Informetrics,</journal>
<pages>3--143</pages>
<contexts>
<context position="5989" citStr="Prabowo et al., 2009" startWordPosition="946" endWordPosition="949">rini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the do</context>
</contexts>
<marker>Prabowo, Thelwall, Street, 2009</marker>
<rawString>Rudy Prabowo, Mike Thelwall, and Wulfruna Street. 2009. Sentiment Analysis: A Combined Approach. Journal of Informetrics, 3:143–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding Domain Sentiment Lexicon through Double Propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st international Joint Conference on Artificial Intelligence (IJCAI2009),</booktitle>
<pages>1199--1204</pages>
<contexts>
<context position="5587" citStr="Qiu et al., 2009" startWordPosition="883" endWordPosition="886">nd subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as </context>
<context position="6821" citStr="Qiu et al., 2009" startWordPosition="1092" endWordPosition="1095">s, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´andez et al., 2011; Fern´andez et al., 2</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding Domain Sentiment Lexicon through Double Propagation. In Proceedings of the 21st international Joint Conference on Artificial Intelligence (IJCAI2009), pages 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<title>SemEval-2014 Task 9: Sentiment Analysis in Twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2014).</booktitle>
<contexts>
<context position="2585" citStr="Rosenthal et al., 2014" startWordPosition="400" endWordPosition="403">e lack of context. Sentiment Analysis (SA) systems must be adapted to face the challenges of this new textual genre. International competitions related to the assessment of SA systems in Twitter have taken place. Some of them include the TASS workshop in the SEPLN conference (Villena-Rom´an et al., 2013), the RepLab workshop in the CLEF conference (Amig´o et al., 2012), and the Sentiment Analysis in Twitter task (Task 2) in the last SemEval workshop (Nakov et al., 2013). In this paper we describe the system submitted for the SemEval 2014 Sentiment Analysis in Twitter task (Task 9 Subtask B)2 (Rosenthal et al., 2014). This task consists of performing an automatic sentiment analysis to determine whether a message expresses a positive, negative, or neutral sentiment. The organisers of this task provide three datasets: training, development training, and development test. The participants can use the training and development training datasets to train and validate their models, but the development test dataset can only be used for validation. The size and distribution of polarities of these datasets is shown in Table 1. Once their systems are ready, the participants must classify each text in the official te</context>
</contexts>
<marker>Rosenthal, Nakov, Ritter, Stoyanov, 2014</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Alan Ritter, and Veselin Stoyanov. 2014. SemEval-2014 Task 9: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Machine Learning in Automated Text Categorization.</title>
<date>2002</date>
<journal>ACM Computing Surveys (CSUR),</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="11221" citStr="Sebastiani, 2002" startWordPosition="1836" endWordPosition="1837"> go) (to) (to go) (to to) (go) (go to) (go HASHTAG) (to) (to HASHTAG) (to with) (HASHTAG) (HASHTAG with) (HASHTAG the) (with) (with the) (with best) (the) (the best) (the friend) (best) (best friend) (best everrr) (friend) (friend everrr) (friend USERNAME) (everrr) (everrr USERNAME) (everrr !!!) (USERNAME) (USERNAME !!!) Figure 2: Example of tokenisation process. 3.3 Supervised Learning To build our model we employed Support Vector Machines (SVM) as the supervised machine learning algorithm, as it has been proved to be effective on text categorisation tasks and robust on large feature spaces (Sebastiani, 2002; Mohammad et al., 2013). More specifically, we used the Weka3 (Hall et al., 2009) LibSVM (Chang and Lin, 2011) implementation with the default parameters (linear kernel, C = 1, c = 0.1). The skipgrams extracted in the previous step are employed as features for the SVM. The weight of each feature in each text will be calculated depending on the skipgram it represents, using the formula in Equation 1. terms(s) w(s, t) = terms(s) + skips(s, t) (1) Where w(s, t) represents the weight of the skipgram s in the text t, terms is a function that returns the number of terms in skipgram s, and skips is </context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>Fabrizio Sebastiani. 2002. Machine Learning in Automated Text Categorization. ACM Computing Surveys (CSUR), 34(1):1–47, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Stone</author>
<author>Dexter C Dunphy</author>
<author>Marshall S Smith</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<contexts>
<context position="5204" citStr="Stone et al., 1966" startWordPosition="824" endWordPosition="827">): lexical approaches (unsupervised SA) and machine learning approaches (supervised SA). Lexical approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a cla</context>
</contexts>
<marker>Stone, Dunphy, Smith, 1966</marker>
<rawString>Philip J. Stone, Dexter C. Dunphy, and Marshall S. Smith. 1966. The General Inquirer: A Computer Approach to Content Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>WordNet Affect: an Affective Extension of WordNet.</title>
<date>2004</date>
<booktitle>In LREC,</booktitle>
<volume>4</volume>
<pages>1083--1086</pages>
<contexts>
<context position="5311" citStr="Strapparava and Valitutti, 2004" startWordPosition="838" endWordPosition="841">al approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches </context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. WordNet Affect: an Affective Extension of WordNet. In LREC, volume 4, pages 1083–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="4586" citStr="Taboada et al., 2011" startWordPosition="720" endWordPosition="723">neration and weighting, using not only single words and ngrams as features but also skipgrams. This approach is described in detail in Section 3. Subsequently, in Section 4 we show the assessment of our model in the competition. Finally, the conclusions and future work are presented in Section 5. The following Section 2 shows some relevant background related to this work. 2 Related Work The goal of Sentiment analysis (SA) is to identify the opinions expressed in text and classify texts accordingly (Dadvar et al., 2011). Two main approaches can be followed (Annett and Kondrak, 2008; Liu, 2010; Taboada et al., 2011): lexical approaches (unsupervised SA) and machine learning approaches (supervised SA). Lexical approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (S</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songbo Tan</author>
<author>Xueqi Cheng</author>
<author>Yuefen Wang</author>
<author>Hongbo Xu</author>
</authors>
<title>Adapting Naive Bayes to Domain Adaptation for Sentiment Analysis. Advances in Information Retrieval,</title>
<date>2009</date>
<pages>337--349</pages>
<contexts>
<context position="6085" citStr="Tan et al., 2009" startWordPosition="965" endWordPosition="968"> and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are us</context>
</contexts>
<marker>Tan, Cheng, Wang, Xu, 2009</marker>
<rawString>Songbo Tan, Xueqi Cheng, Yuefen Wang, and Hongbo Xu. 2009. Adapting Naive Bayes to Domain Adaptation for Sentiment Analysis. Advances in Information Retrieval, pages 337–349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>417--424</pages>
<contexts>
<context position="5236" citStr="Turney, 2002" startWordPosition="830" endWordPosition="831">) and machine learning approaches (supervised SA). Lexical approaches focus on building dictionaries and lexicons of labelled words. This labeling gives a score for each word, that indicates how strong is the relation between that word and each polarity. The most common way to classify a text using these scores is by adding the positive values and subtracting the negative values of the terms in that text. If the total score is positive, that text is classified as positive, otherwise it is classified as negative. These dictionaries can be created manually (Stone et al., 1966) or automatically (Turney, 2002). Examples of lexicons are WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOP (Cerini et al., 2007) or JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be appli</context>
<context position="6783" citStr="Turney, 2002" startWordPosition="1086" endWordPosition="1087"> represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´an</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002), pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Villena-Rom´an</author>
<author>Eugenio Martinez-C´amara</author>
<author>Sara Lana-Serrano</author>
<author>Jos´e Carlos Gonz´alez-Crist´obal</author>
</authors>
<date>2013</date>
<booktitle>TASS - Workshop on Sentiment Analysis at SEPLN. Procesamiento del Lenguaje Natural,</booktitle>
<pages>50--37</pages>
<marker>Villena-Rom´an, Martinez-C´amara, Lana-Serrano, Gonz´alez-Crist´obal, 2013</marker>
<rawString>Julio Villena-Rom´an, Eugenio Martinez-C´amara, Sara Lana-Serrano, and Jos´e Carlos Gonz´alez-Crist´obal. 2013. TASS - Workshop on Sentiment Analysis at SEPLN. Procesamiento del Lenguaje Natural, 50:37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<date>2005</date>
<booktitle>Annotating Expressions of Opinions and Emotions in Language. Language resources and evaluation,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="6066" citStr="Wiebe et al., 2005" startWordPosition="961" endWordPosition="964">difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is common to both approaches. When the lexicons and classifie</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating Expressions of Opinions and Emotions in Language. Language resources and evaluation, 39(2-3):165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Paul Hoffmann</author>
<author>Swapna Somasundaran</author>
<author>Jason Kessler</author>
<author>Janyce Wiebe</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
</authors>
<title>OpinionFinder: A System for Subjectivity Analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP on Interactive Demonstrations,</booktitle>
<pages>34--35</pages>
<contexts>
<context position="6011" citStr="Wilson et al., 2005" startWordPosition="950" endWordPosition="953">JRC Tonality (Balahur et al., 2009). However, it is very difficult to collect and maintain a universal sentiment lexicon because different words may be used in different domains (Qiu et al., 2009) and some words are domain dependent (Turney, 2002). The second approach uses machine learning techniques. These techniques require the previous creation of a corpus containing a set of classified texts to train a classifier, which can then be applied to classify a set of unclassified texts. The majority of the researches employ Support Vector Machines (Mullen and Collier, 2004; Prabowo et al., 2009; Wilson et al., 2005) or Naive Bayes (Pang and Lee, 2004; Wiebe et al., 2005; Tan et al., 2009) classifiers because they usually obtain the best results. In this approach, texts are represented as vectors of features, and depending on the features used the system can reach better results (bag-of-words and lexeme-based features are the more commonly used (Pang and Lee, 2008)). These classifiers perform very well in the domain that they are trained on, but their performance drops when the same classifier is used in a different domain (Pang and Lee, 2008; Tan et al., 2009). The problem of the domain dependence is com</context>
</contexts>
<marker>Wilson, Hoffmann, Somasundaran, Kessler, Wiebe, Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Theresa Wilson, Paul Hoffmann, Swapna Somasundaran, Jason Kessler, Janyce Wiebe, Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth Patwardhan. 2005. OpinionFinder: A System for Subjectivity Analysis. In Proceedings of HLT/EMNLP on Interactive Demonstrations, pages 34–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Xingyao Ye</author>
</authors>
<title>A Generation Model to Unify Topic Relevance and Lexicon-based Sentiment for Opinion Retrieval.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>411--418</pages>
<publisher>ACM Press.</publisher>
<location>New York, New York, USA.</location>
<contexts>
<context position="7182" citStr="Zhang and Ye, 2008" startWordPosition="1149" endWordPosition="1152">09). The problem of the domain dependence is common to both approaches. When the lexicons and classifiers generated are used in a domain different from the one they were built for, they use to perform worse (Turney, 2002; Pang and Lee, 2008; Qiu et al., 2009; Tan et al., 2009). Creating a domain-specific lexicon or classifier means making a manual effort. Although some studies try to overcome this problem by generating the lexicons automatically (Turney, 2002), learning from unannotated texts (Wiebe et al., 2005) or using hybrid approaches (Andreevskaia and Bergler, 2008; Bollen et al., 2011; Zhang and Ye, 2008), a minimal intervention from experts in the domain is needed. In this study we use the machine learning approach due to the promising results obtained in previous works (Boldrini et al., 2009; Fern´andez et al., 2011; Fern´andez et al., 2013). 3 Methodology Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features. In summary, our approach starts making a basic normalisation of each tweet in the dataset (see Section 3.1). Next, these texts are tokenised to extract their terms, and these terms are combined to create sk</context>
</contexts>
<marker>Zhang, Ye, 2008</marker>
<rawString>Min Zhang and Xingyao Ye. 2008. A Generation Model to Unify Topic Relevance and Lexicon-based Sentiment for Opinion Retrieval. In Proceedings of the 31st annual international ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2008), pages 411–418, New York, New York, USA. ACM Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>