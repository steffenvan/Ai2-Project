<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001315">
<title confidence="0.992563">
Centering in-the-Large:
Computing Referential Discourse Segments
</title>
<author confidence="0.999159">
Udo Hahn &amp; Michael Strube
</author>
<affiliation confidence="0.912996">
Computational Linguistics Research Group
Freiburg University, Werthmannplatz 1
</affiliation>
<address confidence="0.732838">
D-79085 Freiburg, Germany
</address>
<email confidence="0.869706">
http://www.coling.uni-freiburg.de/
</email>
<note confidence="0.84101">
34 3
</note>
<sectionHeader confidence="0.969982" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999607">
We specify an algorithm that builds up a hi-
erarchy of referential discourse segments from
local centering data. The spatial extension and
nesting of these discourse segments constrain
the reachability of potential antecedents of an
anaphoric expression beyond the local level
of adjacent center pairs. Thus, the centering
model is scaled up to the level of the global
referential structure of discourse. An empiri-
cal evaluation of the algorithm is supplied.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999989923076923">
The centering model (Grosz et al., 1995) has evolved as
a major methodology for computational discourse analy-
sis. It provides simple, yet powerful data structures, con-
straints and rules for the local coherence of discourse. As
far as anaphora resolution is concerned, e.g., the model
requires to consider those discourse entities as potential
antecedents for anaphoric expressions in the current ut-
terance Ui , which are available in the forward-looking
centers of the immediately preceding utterance U_1. No
constraints or rules are formulated, however, that ac-
count for anaphoric relationships which spread out over
non-adjacent utterances. Hence, it is unclear how dis-
course elements which appear in utterances preceding
utterance Ui_1 are taken into consideration as potential
antecedents for anaphoric expressions in IA.
The extension of the search space for antecedents is by
no means a trivial enterprise. A simple linear backward
search of all preceding centering structures, e.g., may
not only turn out to establish illegal references but also
contradicts the cognitive principles underlying the lim-
ited attention constraint (Walker, 1996b). The solution
we propose starts from the observation that additional
constraints on valid antecedents are placed by the global
discourse structure previous utterances are embedded in.
We want to emphasize from the beginning that our pro-
posal considers only the referential properties underlying
the global discourse structure. Accordingly, we define
the extension of referential discourse segments (over sev-
eral utterances) and a hierarchy of referential discourse
segments (structuring the entire discourse)) The algo-
rithmic procedure we propose for creating and manag-
ing such segments receives local centering data as input
and generates a sort of superimposed index structure by
which the reachability of potential antecedents, in par-
ticular those prior to the immediately preceding utter-
ance, is made explicit. The adequacy of this definition
is judged by the effects centered discourse segmentation
has on the validity of anaphora resolution (cf. Section 5
for a discussion of evaluation results).
</bodyText>
<sectionHeader confidence="0.991576" genericHeader="method">
2 Global Discourse Structure
</sectionHeader>
<bodyText confidence="0.9832472">
There have been only few attempts at dealing with the
recognition and incorporation of discourse structure be-
yond the level of immediately adjacent utterances within
the centering framework. Two recent studies deal with
this topic in order to relate attentional and intentional
structures on a larger scale of global discourse coher-
ence. Passonneau (1996) proposes an algorithm for the
generation of referring expressions and Walker (1996a)
integrates centering into a cache model of attentional
state. Both studies, among other things, deal with the
supposition whether a correlation exists between partic-
ular centering transitions (which were first introduced
by Brennan et al. (1987); cf. Table 1) and intention-
based discourse segments. In particular, the role of
SHIFT-type transitions is examined from the perspective
of whether they not only indicate a shift of the topic be-
tween two immediately successive utterances but also
signal (intention-based) segment boundaries. The data
in both studies reveal that only a weak correlation be-
tween the SHIFT transitions and segment boundaries can
be observed. This finding precludes a reliable predic-
tion of segment boundaries based on the occurrence of
&apos;Our notion of referential discourse segment should not be
confounded with the intentional one originating from Grosz &amp;
Sidner (1986), for reasons discussed in Section 2.
</bodyText>
<page confidence="0.998143">
104
</page>
<bodyText confidence="0.999238833333333">
SHIFTs and vice versa. In order to accommodate to these
empirical results divergent solutions are proposed. Pas-
sonneau suggests that the centering data structures need
to be modified appropriately, while Walker concludes
that the local centering data should be left as they are
and further be complemented by a cache mechanism.
She thus intends to extend the scope of centering in ac-
cordance with cognitively plausible limits of the atten-
tional span. Walker, finally, claims that the content of
the cache, rather than the intentional discourse segment
structure, determines the accessibility of discourse enti-
ties for anaphora resolution.
</bodyText>
<tableCaption confidence="0.990797">
Table 1: Transition Types
</tableCaption>
<bodyText confidence="0.999963333333333">
As a working hypothesis, for the purposes of anaphora
resolution we subscribe to Walker&apos;s model, in particular
to that part which casts doubt on the hypothesized de-
pendency of the attentional from the intentional structure
of discourse (Grosz &amp; Sidner, 1986, p.180). We diverge
from Walker (1996a), however, in that we propose an al-
ternative to the caching mechanism, which we consider
to be methodologically more parsimonious and, at least,
to be equally effective (for an elaboration of this claim,
cf. Section 6).
The proposed extension of the centering model builds
on the methodological framework of functional center-
ing (Strube &amp; Hahn, 1996). This is an approach to cen-
tering in which issues such as thematicity or topicality
are already inherent. Its linguistic foundations relate the
ranking of theforward-looking centers and the functional
information structure of the utterances, a notion origi-
nally developed by Dana (1974). Strube &amp; Hahn (1996)
use the centering data structures to redefine Dana&apos; s tri-
chotomy between given information, theme and rheme
in terms of the centering model. The Cb(Un ), the most
highly ranked element of C (U 1)realized in Un, cor-
responds to the element which represents the given in-
formation. The theme of Un is represented by the pre-
ferred center Cp (Un) , the most highly ranked element of
C1 (Un). The theme/rheme hierarchy of Un corresponds
to the ranking in the Ci s. As a consequence, utterances
without any anaphoric expression do not have any given
elements and, therefore, no Cb. But independent of the
use of anaphoric expressions, each utterance must have a
theme and a Ci as well.
The identification of the preferred center with the
theme implies that it is of major relevance for determin-
ing the thematic progression of a text. This is reflected in
our reformulation of the two types of thematic progres-
sion (TP) which can be directly derived from centering
data (the third one requires to refer to conceptual gener-
alization hierarchies and is therefore beyond the scope of
this paper, cf. Dana (1974) for the original statement):
</bodyText>
<listItem confidence="0.992128833333333">
1. TP with a constant theme: Successive utterances
continuously share the same Cp.
2. TP with linear thematization of rhemes: An element
of the C1 (U1_1) which is not the Cp (Ui _1) appears
in Ui and becomes the Cp (Ui) after the processing
of this utterance.
</listItem>
<equation confidence="0.93965475">
C f Wi-1) [ c11 .....c3
C f [ c1, eh, •••, et
Ci(Ui_i) : [ Cl, Cj, c3] 1&lt;j&lt;s
C f [ e11 ett, •••, et I
</equation>
<tableCaption confidence="0.736899">
Table 2: Thematic Progression Patterns
</tableCaption>
<bodyText confidence="0.997928878787879">
Table 2 visualizes the abstract schemata of TP pat-
terns. In our example (cf. Table 8 in Section 4), U1 to U3
illustrate the constant theme, while U7 to (ho illustrate
the linear thematization of rhemes. In the latter case,
the theme changes in each utterance, from &amp;quot;Handbuch&amp;quot;
(manual) via &amp;quot;Inhaltsverzeichnis&amp;quot; (table of contents) to
&amp;quot;Kapitel&amp;quot; (chapter) etc. Each of the new themes are in-
troduced in the immediately preceding utterance so that
local coherence between these utterances is established.
Dana (1974) also allows for the combination and re-
cursion of these basic patterns; this way the global the-
matic coherence of a text can be described by recurrence
to these structural patterns. These principles allow for
a major extension of the original centering algorithm.
Given a reformulation of the TP constraints in center-
ing terms, it is possible to determine referential segment
boundaries and to arrange these segments in a nested,
i.e., hierarchical manner on the basis of which reacha-
bility constraints for antecedents can be formulated. Ac-
cording to the segmentation strategy of our approach, the
Cp of the end point (i.e., the last utterance) of a discourse
segment provides the major theme of the whole segment,
one which is particularly salient for anaphoric reference
relations. Whenever a relevant new theme is established,
however, it should reside in its own discourse segment,
either embedded or in parallel to another one. Anaphora
resolution can then be performed (a) with the forward-
looking centers of the linearly immediately preceding ut-
terance, (b) with the forward-looking centers of the end
point of the hierarchically immediately reachable dis-
course segment, and (c) with the preferred center of the
end point of any hierarchically reachable discourse seg-
ment (for a formalization of this constraint, cf. Table 4).
</bodyText>
<equation confidence="0.999574071428571">
Cb(Un) = Cb(Un-1)
OR Cb(Un_i) undef.
CONTINUE (C)
RETAIN (R)
Cb(Un)
Cb(Un—i)
SMOOTH-SHIFT (SS)
ROUGH-SHIFT (RS)
Cb(Un) =
Cp(Un)
Cb(
U
)
C(U)
</equation>
<page confidence="0.998686">
105
</page>
<sectionHeader confidence="0.967488" genericHeader="method">
3 Computing Global Discourse Structure
</sectionHeader>
<bodyText confidence="0.99962096875">
Prior to a discussion of the algorithmic procedure for hy-
pothesizing discourse segments based on evidence from
local centering data, we will introduce its basic build-
ing blocks. Let x denote the anaphoric expression under
consideration, which occurs in utterance Ui associated
with segment level s. The function Resolved(x, s, U1)
(cf. Table 3) is evaluated in order to determine the proper
antecedent ante for x. It consists of the evaluation of
a reachability predicate for the antecedent on which we
will concentrate here, and of the evaluation of the predi-
cate IsAnaphorFor which contains the linguistic and con-
ceptual constraints imposed on a (pro)nominal anaphor
(viz, agreement, binding, and sortal constraints) or a tex-
tual ellipsis (Hahn et al., 1996), not an issue in this paper.
The predicate IsReachable (cf. Table 4) requires ante to
be reachable from the utterance Ui associated with the
segment level s.2 Reachability is thus made dependent
on the segment structure DS of the discourse as built
up by the segmentation algorithm which is specified in
Table 6. In Table 4, the symbol &amp;quot;=$tr&amp;quot; denotes string
equality, N the natural numbers. We also introduce as a
notational convention that a discourse segment is identi-
fied by its index s and its opening and closing utterance,
viz. DS[s.beg] and DS[s.end], respectively. Hence, we
may either identify an utterance Ui by its linear text in-
dex, i, or, if it is accessible, with respect to its hierarchi-
cal discourse segment index, s (e.g., cf. Table 8 where
U3 = UDS[1.end] or U13 = UD S [3 . en al] ). The discourse
segment index is always identical to the currently valid
segment level, since the algorithm in Table 6 implements
a stack behavior. Note also that we attach the discourse
segment index s to center expressions, e.g., Cb(s, U1).
</bodyText>
<figure confidence="0.67120475">
Resolved(x, s,U,) :=
{ante if I sReachable(ante, s, U,)
A I sAnaphorFor(s, ante)
undef else
</figure>
<tableCaption confidence="0.985295">
Table 3: Resolution of Anaphora
</tableCaption>
<construct confidence="0.954781333333333">
I sReachable(ante, s, U1)
if ante E Ci(s,
else if ante E C f (8 — 1, U Ds[3-1.endj)
</construct>
<figure confidence="0.82030125">
else if (av E N : ante =str Cp(V, UDsfv.end])
A v &lt; (s — 1))
A (—,av&apos; EN : ante =str Cp(t/, UDs[vi.end])
A v &lt; vi)
</figure>
<tableCaption confidence="0.966278">
Table 4: Reachability of the Anaphoric Antecedent
</tableCaption>
<bodyText confidence="0.9967965">
Finally, the function Lift(s, i) (cf. Table 5) determines
the appropriate discourse segment level, s, of an utter-
</bodyText>
<footnote confidence="0.728793333333333">
2The ef lists in the functional centering model are totally
ordered (Strube &amp; Hahn, 1996, p.272) and we here implicitly
assume that they are accessed in the total order given.
</footnote>
<bodyText confidence="0.9989368">
ance U1 (selected by its linear text index, 0. Lift only
applies to structural configurations in the centering lists
in which themes continuously shift at three different con-
secutive segment levels and associated preferred centers
at least (cf. Table 2, lower box, for the basic pattern).
</bodyText>
<figure confidence="0.963244571428571">
Lift(s, i) :=
{Li f t(s — 1, i — 1) if
s&gt; 2 A i &gt; 3
A Cp(s, Ui—i) Cp(s — 1,U1_2)
A C p(8 — 1 , Li , —2) 0 C p(8 — 2, Ui_3)
A Cp(s, U,_i ) E C f (3 — 1, U 1-2)
s else
</figure>
<tableCaption confidence="0.984912">
Table 5: Lifting to the Appropriate Discourse Segment
</tableCaption>
<bodyText confidence="0.9994985625">
Whenever a discourse segment is created, its starting
and closing utterances are initialized to the current po-
sition in the discourse. Its end point gets continuously
incremented as the analysis proceeds until this discourse
segment DS is ultimately closed, i.e., whenever another
segment DS&apos; exists at the same or a hierarchically higher
level of embedding such that the end point of DS&apos; ex-
ceeds that of the end point of DS. Closed segments are
inaccessible for the antecedent search. In Table 8, e.g.,
the first two discourse segments at level 3 (ranging from
U5 to U5 and U8 to U11) are closed, while those at level
1 (ranging from U1 to U3), level 2 (ranging from Ug to
U7) and level 3 (ranging from U12 to U13) are open.
The main algorithm (see Table 6) consists of three ma-
jor logical blocks (s and U1 denote the current discourse
segment level and utterance, respectively).
</bodyText>
<listItem confidence="0.903800130434783">
1. Continue Current Segment. The C( s, U1_1) is
taken over for U1. If U1_1 and U1 indicate the end
of a sequence in which a series of thematizations of
rhemes have occurred, all embedded segments are
lifted by the function Lift to a higher level s&apos;. As a
result of lifting, the entire sequence (including the
final two utterances) forms a single segment. This
is trivially true for cases of a constant theme.
2. Close Embedded Segment(s).
(a) Close the embedded segment(s) and continue
another, already existing segment: If U1 does
not include any anaphoric expression which is
an element of the Cf U1_1), then match the
antecedent in the hierarchically reachable seg-
ments. Only the Cp of the utterance at the end
point of any of these segments is considered
a potential antecedent. Note that, as a side
effect, hierarchically lower segments are ulti-
mately closed when a match at higher segment
levels succeeds.
(b) Close the embedded segment and open a new,
parallel one: If none of the anaphoric ex-
pressions under consideration co-specify the
</listItem>
<page confidence="0.993727">
106
</page>
<bodyText confidence="0.95295608">
CAS - 1, U[i_Lenci]), then the entire Cf at
this segment level is checked for the given ut-
terance. If an antecedent matches, the segment
which contains U1_1 is ultimately closed, since
Ui opens a parallel segment at the same level of
embedding. Subsequent anaphora checks ex-
clude any of the preceding parallel segments
from the search for a valid antecedent and just
visit the currently open one.
(c) Open new, embedded segment: If there is no
matching antecedent in hierarchically reach-
able segments, then for utterance Ui a new, em-
bedded segment is opened.
3. Open New, Embedded Segment. If none of the
above cases applies, then for utterance Ui a new,
embedded segment is opened. In the course of pro-
cessing the following utterances, this decision may
be retracted by the function Lift. It serves as a kind
of &amp;quot;garbage collector&amp;quot; for globally insignificant dis-
course segments which, nevertheless, were reason-
able from a local perspective for reference resolu-
tion purposes. Hence, the centered discourse seg-
mentation procedure works in an incremental way
and revises only locally relevant, yet globally irrel-
evant segmentation decisions on the fly.
</bodyText>
<equation confidence="0.99000721875">
S := 1
i := 1
DS[s.beg] := i
DS[s.end) := i
while end of text
i := i 1
{Resolved(x , s, U,) I xE U,}
if 3r E R : r =str Cp(S, Us-1) (1)
then s&apos; := s
DS[Lift(s&apos;,e).encl] := i
else if -.3r ER:r E Cf (s, IA-1) (2a)
then found := FALSE
k := s
while -.found A (k &gt; 1)
k := k - 1
if 3r E R : r =str Cp(k, U[k.end])
then s := k
DS[s.end] := i
found := TRUE
else if k = s - 1 (2b)
thenif3r ER: r E
Cf(k, U[k .end])
then DS[s.beg] := i
DS[s.end] := i
found := TRUE
if-&apos;found (2c)
then s := s 1
DS[s.beg] := i
DS[s.end] := i
else s := s + 1 (3)
DS[s.beg] := i
DS[s.endj := I
</equation>
<tableCaption confidence="0.739182">
Table 6: Algorithm for Centered Segmentation
</tableCaption>
<sectionHeader confidence="0.991042" genericHeader="method">
4 A Sample Text Segmentation
</sectionHeader>
<bodyText confidence="0.992893346153846">
The text with respect to which we demonstrate the work-
ing of the algorithm (see Table 7) is taken from a German
computer magazine (c&apos;t, 1995, No.4, p.209). For ease
of presentation the text is somewhat shortened. Since
the method for computing levels of discourse segments
depends heavily on different kinds of anaphoric expres-
sions, (pro)nominal anaphors and textual ellipses are
marked by italics, and the (pro)nominal anaphors are un-
derlined, in addition. In order to convey the influence of
the German word order we provide a rough phrase-to-
phrase translation of the entire text.
The centered segmentation analysis of the sample text
is given in Table 8. The first column shows the linear text
index of each utterance. The second column contains
the centering data as computed by functional centering
(Strube &amp; Hahn, 1996). The first element of the Cf , the
preferred center, Cp, is marked by bold font. The third
column lists the centering transitions which are derived
from the Cb/Cf data of immediately successive utter-
ances (cf. Table 1 for the definitions). The fourth column
depicts the levels of discourse segments which are com-
puted by the algorithm in Table 6. Horizontal lines in-
dicate the beginning of a segment (in the algorithm, this
corresponds to a value assignment to DS[s.beg]). Verti-
cal lines show the extension of a segment (its end is fixed
by an assignment to DS[s.end}). The fifth column indi-
cates which block of the algorithm applies to the current
utterance (cf. the right margin in Table 6).
The computation starts at Ui, the headline. The
Cf (U1.) is set to &amp;quot;1260&amp;quot; which is meant as an abbre-
viation of &amp;quot;Brother HL-1260&amp;quot;. Upon initialization, the
beginning as well as the ending of the initial discourse
segment are both set to &amp;quot;1&amp;quot;. U2 and U3 simply con-
tinue this segment (block (1) of the algorithm), so Lift
does not apply. The Cp is set to &amp;quot;1260&amp;quot; in all utter-
ances of this segment. Since U4 does neither contain any
anaphoric expression which co-specifies the Cp (1, (13)
(block (1)) nor any other element of the Cf (1, U3) (block
(2a)), and as there is no hierarchically preceding seg-
ment, block (2c) applies. The segment counter s is in-
cremented and a new segment at level 2 is opened, set-
ting the beginning and the ending to &amp;quot;4&amp;quot;. The phrase
&amp;quot;das diinne Handbiichlein&amp;quot; (the thin leaflet) in U5 does
not co-specify the Cp (2, U4) but co-specifies an element
of the C1(2, U4) instead (viz. &amp;quot;Handbuch&amp;quot; (manual)).
Hence, block (3) of the algorithm applies, leading to
the creation of a new segment at level 3. The anaphor
&amp;quot;Handbuch&amp;quot; (manual) in U6 co-specifies the Cp (3, U5).
Hence block (1) applies (the occurrence of &amp;quot;1260&amp;quot; in
C f (U5) is due to the assumptions specified by Strube
&amp; Hahn (1996)). Given this configuration, the func-
tion Lift lifts the embedded segment one level, so the
</bodyText>
<page confidence="0.994496">
107
</page>
<table confidence="0.959520214285714">
(I) Brother HL-1260 (8) Kein Wunder: unter dem Inhaltsverzeichnis steht der lap-
(2) Ein Detail Mit schon beim ersten Umgang mit dem idare Hinweis, man mop sich die Seiten dieses Kapitels
groBen Brother auf: doch bitte von Diskette ausdrucken Frechheit.
One particular — is already noticed — in the first approach No wonder: beneath the table of contents — one finds the
to — the big Brother terse instruction, one should — oneself — the pages of this
(3) Im Betrieb macht er durch em n kraftiges Arbeitsgerausch section — please — from disk — print out — — impertinence.
auf sich aufmerksam, das auch im Stand-by-Modus noch (9) Ohne diesen Ausdruck sucht man vergebens nach einem
gut vemehmbar ist. Hinweis darauf, warum die Auto-Continue-Funktion in
In operation — draws — it — with a heavy noise level — der PostScript-Emulation nicht wirkt.
attention to itself — which — also — in the stand-by mode — Without this print-out, looks — one — in vain — for a hint —
is still well audible. why — the auto-continue-function — in the PostScript em-
(4) Fur Standard-Installationen kommt man gut ohne Hand- ulation — does not work.
buch aus. (10) Nach dem Einschalten zeigt das LC-Display an, daB diese
As far as standard installations are concerned-. gets — one praktische Hilfsfunktion nicht aktiv ist;
— well — by — without any manual. After switching on — depicts — the LC display — that — this
(5) Zwar erlautert das diinne Handbiichlein die Bedienung practical help function — not active — is;
der Hardware anschaulich und gut illustriert. (11) sie iiberwacht den Dateientransfer vom Computer.
Admittedly, gives — the thin leaflet— the operation of the it monitors the file transfer from the computer.
hardware— a clear description of — and — well illustrated. (12) Viele der kleinen Macken verzeiht man dem HL-1260
(6) Die Software-Seite wurde im Handbuch dagegen wenn man erste Ausdrucke in Handen halt.
stiefmiitterlich behandelt: Many of the minor defects — pardons — one — the
The software part — was — in the manual— however — like HL-1260, when — one — the first print outs — holds in
a stepmother — treated: [one&apos;s] hands.
(7) bis auf eine karge Seite mit einem Inhaltsverzeichnis zum (13) Gerasterte Grauflachen erzeugt der Brother sehr homogen
HP-Modus sucht man vergebens weitere Informationen. Raster-mode grey-scale areas — generates — the Brother —
except for one meagre page — containing the table of con- very homogeneously...
tents for the HP mode — seeks — one — in vain for further
information.
</table>
<tableCaption confidence="0.984209">
Table 7: Sample Text
</tableCaption>
<bodyText confidence="0.998510538461538">
segment which ended with U4 is now continued up to
U6 at level 2. As a consequence, the centering data of
U6 are excluded from further consideration as far as the
co-specification by any subsequent anaphoric expression
is concerned. (17 simply continues the same segment,
since the textual ellipsis &amp;quot;Seite&amp;quot; (page) refers to &amp;quot;Hand-
buch&amp;quot; (manual). The utterances U8 to U10 exhibit a typ-
ical thematization-of-the-rhemes pattern which is quite
common for the detailed description of objects. (Note
the sequence of SHIFT transitions.) Hence, block (3)
of the algorithm applies to each of the utterances and,
correspondingly, new segments at the levels 3 to 5 are
created. This behavior breaks down at the occurrence
of the anaphoric expression &amp;quot;sie&amp;quot; (it) in Un which co-
specifies the C(5, U10), viz. &amp;quot;auto-continue function&amp;quot;,
denoted by another anaphoric expression, namely &amp;quot;Hil-
fsfunktion&amp;quot; (help function) in U10. Hence, block (1) ap-
plies. The evaluation of Lift succeeds with respect to
two levels of embedding. As a result, the whole se-
quence is lifted up to level 3 and continues this segment
which started at the discourse element &amp;quot;Inhaltsverzeich-
nis&amp;quot; (list of contents). As a result of applying Lift, the
whole sequence is captured in one segment. U12 does
not contain any anaphoric expression which co-specifies
an element of the Cf (3, U11), hence block (2) of the al-
gorithm applies. The anaphor &amp;quot;HL-1260&amp;quot; does not co-
specify the Cp of the utterance which represents the end
of the hierarchically preceding discourse segment (U7),
but it co-specifies an element of the Cf (2, U7). The im-
mediately preceding segment is ultimately closed and a
parallel segment is opened at U12 (cf. block (2b)). Note
also that the algorithm does not check the Cf (3, U10) de-
spite the fact that it contains the antecedent of &amp;quot;1260&amp;quot;.
However, the occurrences of &amp;quot;1260&amp;quot; in the Cf s of Ug
and U10 are mediated by textual ellipses. If these ut-
terances contained the expression &amp;quot;1260&amp;quot; itself, the al-
gorithm would have built a different discourse structure
and, therefore, &amp;quot;1260&amp;quot; in U10 were reachable for the
anaphor in U12. Segment 3, finally, is continued by U13.
</bodyText>
<sectionHeader confidence="0.995214" genericHeader="method">
5 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.99689325">
In this section, we present some empirical data concern-
ing the centered segmentation algorithm. Our study was
based on the analysis of twelve texts from the informa-
tion technology domain (IT), of one text from a Ger-
</bodyText>
<page confidence="0.996185">
108
</page>
<table confidence="0.998460627906977">
U; Centering Data Trans. 1 Levels of Discourse Segments Block
2 3 4 5
—
Cb: – — _ 1--- 1
Cf: [1260] — 1
2c
3
1, Lift
1
3
3
3
1, Lift
2b
1
Cb: 1260 C
Cf: [1260, Umgang, Detail]
Cb: 1260 C
Cf: [1260, Betrieb, Arbeitsgerausch, Stand-by-Modus]
Cb: – —
Cf: [Standard-Installation, Handbuch]
Cb: Handbuch C
Cf: [Handbuch, 1260, Hardware, Bedienung]
Cb: Handbuch C
Cf: [Handbuch, 1260, Software]
Cb: Handbuch C
Cf: [Handbuch, Seite, 1260, HP-Modus,
Inhaltsverzeichnis, Informationen]
Cb: Inhaltsverzeichnis SS I- r
Cf: [Inhaltsverzeichnis, Hinweis, Seiten, Kapitel, r
Diskette, Frechheit]
Cb: Kapitel SS
Cf: [Kapitel, Ausdruck, Hinweis, 1260,
Auto-Continue-Funktion, PostScript-Emulation]
Cb: 1260 RS
Cf: [Auto-Continue-Funklion, 1260, LC-Display]
Cb: Auto-Continue-Funktion SS
Cf: [Auto-Continue-Funktion, Dateien-Transfer,
Computer]
Cb: – —
Cf: [1260, Macken, Ausdruck]
Cb: 1260 C
Cf: [1260, Grauflachen]
</table>
<tableCaption confidence="0.99898">
Table 8: Sample of a Centered Text Segmentation Analysis
</tableCaption>
<bodyText confidence="0.949764666666667">
man news magazine (Spiegel)3, and of two literary texts4
(Lit). Table 9 summarizes the total numbers of anaphors,
textual ellipses, utterances, and words in the test set.
</bodyText>
<table confidence="0.998366">
IT Spiegel Lit E
anaphors 197 101 198 496
ellipses 195 22 23 240
utterances 336 84 127 547
words 5241 1468 1610 8319
</table>
<tableCaption confidence="0.997929">
Table 9: Test Set
</tableCaption>
<bodyText confidence="0.973794333333333">
Table 10 and Table 11 consider the number of
anaphoric and text-elliptical expressions, respectively,
and the linear distance they have to their correspond-
ing antecedents. Note that common centering algorithms
(e.g., the one by Brennan et al. (1987)) are specified
only for the resolution of anaphors in U2_1. They are
</bodyText>
<footnote confidence="0.943729857142857">
3Japan – Der Neue der alten Garde. In Der Spiegel, Nr. 3,
1996.
4The first two chapters of a short story by the German
writer Heiner Muller (Liebesgeschichte. In Heiner Muller.
Geschichten aus der Produktion 2. Berlin: Rotbuch Verlag,
1974, pp. 57-63) and the first chapter of a novel by Uwe Johnson
(Zwei Ansichten. Frankfurt/Main: Suhrkamp Verlag, 1965.)
</footnote>
<bodyText confidence="0.999671833333333">
neither specified for anaphoric antecedents in U1, not an
issue here, nor for anaphoric antecedents beyond U1-1.
In the test set, 139 anaphors (28%) and 116 textual el-
lipses (48,3%) fall out of the (intersentential) scope of
those common algorithms. So, the problem we consider
is not a marginal one.
</bodyText>
<table confidence="0.9993644">
IT Spiegel Lit E
Ui 10 7 32 49
117 70 121 308
U,....2 28 14 24 66
U1-3 18 5 10 33
Ui-4 6 1 5 12
L11-5 6 0 1 7
U1-6 to U,_10 8 1 3 12
Ui _ 1 i to Ui-15 3 1 1 5
U,_15 to U,_20 1 2 1 4
</table>
<tableCaption confidence="0.999376">
Table 10: Anaphoric Antecedent in Utterance Ux
</tableCaption>
<bodyText confidence="0.8825614">
Table 12 and Table 13 give the success rate of the
centered segmentation algorithm for anaphors and tex-
tual ellipses, respectively. The numbers in these tables
indicate at which segment level anaphors and textual el-
lipses were correctly resolved. The category of errors
</bodyText>
<page confidence="0.991604">
109
</page>
<table confidence="0.996998">
IT Spiegel Lit E
U1-1 94 15 15 124
42 6 8 56
16 0 0 16
14 0 0 14
Lii--5 8 0 0 8
Ui-6 to Ui_10 14 1 0 15
U_11 to U_15 7 0 0 7
</table>
<tableCaption confidence="0.998597">
Table 11: Elliptical Antecedent in Utterance (/
</tableCaption>
<bodyText confidence="0.9988496">
covers erroneous analyses the algorithm produces, while
the one for false positives concerns those resolution re-
sults where a referential expression was resolved with
the hierarchically most recent antecedent but not with the
linearly most recent (obviously, the targeted) one (both of
them denote the same discourse entity). The categories
Cf (s, _1) in Tables 12 and 13 contain more elements
than the categories U2_1 in Tables 10 and 11, respec-
tively, due to the mediating property of textual ellipses in
functional centering (Strube &amp; Hahn, 1996).
</bodyText>
<table confidence="0.999128909090909">
IT Spiegel Lit E
Ui 10 7 32 49
Cf(s,Ui_i) 161 78 125 364
Cp(8 -- 1, UDS[s-1.end]) 14 9 24 47
Cf (s — 1, UDS1.9-1.encil) 7 5 9 21
Cp(s — 2, UDSts-2.enci) 1 0 1 2
C p(8 — 3, UP43-3.endi) 1 0 1 2
Cp(S _4, UDS[s-4.end) 0 0 1 1
C p(8 -- 5, Ups[s—s.endi) 0 1 0 1
errors 3 1 5 9
false positives (1) (3) (7) (11)
</table>
<tableCaption confidence="0.979321">
Table 12: Anaphoric Antecedent in Center.
</tableCaption>
<table confidence="0.999374125">
IT Spiegel Lit E
Cf(s,Ui_i) 156 18 17 191
Cp(s — I., UDSts—Lendl) 18 0 4 22
Cf (s _1, UDS[8-1.endj) 10 1 2 13
Cp(s — 2, t I D .51s-2.endl) 7 1 0 8
Cp(s _3, ( ID Sf 8-3.end]) 3 0 0 3
errors 1 2 0 3
false positives (0) (5)
</table>
<tableCaption confidence="0.998683">
Table 13: Elliptical Antecedent in Center
</tableCaption>
<bodyText confidence="0.999970185185185">
The centered segmentation algorithm reveals a pretty
good performance. This is to some extent implied by
the structural patterns we find in expository texts, viz.
their single-theme property (e.g., &amp;quot;1260&amp;quot; in the sample
text). In contrast, the literary texts in the test exhibited
a much more difficult internal structure which resem-
bled the multiple thread structure of dialogues discussed
by Rosé et al. (1995). The good news is that the seg-
mentation procedure we propose is capable of dealing
even with these more complicated structures. While only
one antecedent of a pronoun was not reachable given the
superimposed text structure, the remaining eight errors
are characterized by full definite noun phrases or proper
names. The vast majority of these phenomena can be
considered inforrnationally redundant utterances in the
terminology of Walker (1996b) for which we currently
have no solution at all. It seems to us that these kinds
of phrases may override text-grammatical structures as
evidenced by referential discourse segments and, rather,
trigger other kinds of search strategies.
Though we fed the centered segmentation algorithm
with rather long texts (up to 84 utterances), the an-
tecedents of only two anaphoric expressions had to
bridge a hierarchical distance of more than 3 levels. This
coincides with our supposition that the overall structure
computed by the algorithm should be rather flat. We
could not find an embedding of more than seven levels.
</bodyText>
<sectionHeader confidence="0.999985" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999988525">
There has always been an implicit relationship between
the local perspective of centering and the global view
of focusing on discourse structure (cf. the discussion in
Grosz et al. (1995)). However, work establishing an ex-
plicit account of how both can be joined in a computa-
tional model has not been done so far. The efforts of
Sidner (1983), e.g., have provided a variety of different
focus data structures to be used for reference resolution.
This multiplicity and the on-going growth of the number
of different entities (cf. Suri &amp; McCoy (1994)) mirrors
an increase in explanatory constructs that we consider a
methodological drawback to this approach because they
can hardly be kept control of. Our model, due to its hier-
archical nature implements a stack behavior that is also
inherent to the above mentioned proposals. We refrain,
however, from establishing a new data type (even worse,
different types of stacks) that has to be managed on its
own. There is no need for extra computations to deter-
mine the &amp;quot;segment focus&amp;quot;, since that is implicitly given
in the local centering data already available in our model.
A recent attempt at introducing global discourse no-
tions into the centering framework considers the use of a
cache model (Walker, 19966). This introduces an addi-
tional data type with its own management principles for
data storage, retrieval and update. While our proposal
for centered discourse segmentation also requires a data
structure of its own, it is better integrated into centering
than the caching model, since the cells of segment struc-
tures simply contain &amp;quot;pointers&amp;quot; that implement a direct
link to the original centering data. Hence, we avoid ex-
tra operations related to feeding and updating the cache.
The relation between our centered segmentation algo-
rithm and Walker&apos;s (1996a) integration of centering into
the cache model can be viewed from two different angles.
On the one hand, centered segmentation may be a part
of the cache model, since it provides an elaborate, non-
linear ordering of the elements within the cache. Note,
however, that our model does not require any prefixed
size corresponding to the limited attention constraint. On
the other hand, centered segmentation may replace the
</bodyText>
<page confidence="0.992246">
110
</page>
<bodyText confidence="0.999961740740741">
cache model entirely, since both are competing models
of the attentional state. Centered segmentation has also
the additional advantage of restricting the search space of
anaphoric antecedents to those discourse entities actually
referred to in the discourse, while the cache model allows
unrestricted retrieval in the main or long-term memory.
Text segmentation procedures (more with an informa-
tion retrieval motivation, rather than being related to ref-
erence resolution tasks) have also been proposed for a
coarse-grained partitioning of texts into contiguous, non-
overlapping blocks and assigning content labels to these
blocks (Hearst, 1994). The methodological basis of these
studies are lexical cohesion indicators (Morris &amp; Hirst,
1991) combined with word-level co-occurrence statis-
tics. Since the labelling is one-dimensional, this approxi-
mates our use of preferred centers of discourse segments.
These studies, however, lack the fine-grained informa-
tion of the contents of Cf lists also needed for proper
reference resolution.
Finally, many studies on discourse segmentation high-
light the role of cue words for signaling segment bound-
aries (cf., e.g., the discussion in Passonneau &amp; Litman
(1993)). However useful this strategy might be, we see
the danger that such a surface-level description may actu-
ally hide structural regularities at deeper levels of inves-
tigation illustrated by access mechanisms for centering
data at different levels of discourse segmentation.
</bodyText>
<sectionHeader confidence="0.999633" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999804533333333">
We have developed a proposal for extending the cen-
tering model to incorporate the global referential struc-
ture of discourse for reference resolution. The hierarchy
of discourse segments we compute realizes certain con-
straints on the reachability of antecedents. Moreover, the
claim is made that the hierarchy of discourse segments
implements an intuitive notion of the limited attention
constraint, as we avoid a simplistic, cognitively implausi-
ble linear backward search for potentional discourse ref-
erents. Since we operate within a functional framework,
this study also presents one of the rare formal accounts of
thematic progression patterns for full-fledged texts which
were informally introduced by Dane § (1974).
The model, nevertheless, still has several restrictions.
First, it has been developed on the basis of a small corpus
of written texts. Though these cover diverse text sorts
(viz, technical product reviews, newspaper articles and
literary narratives), we currently do not account for spo-
ken monologues as modelled, e.g., by Passonneau &amp; Lit-
man (1993) or even the intricacies of dyadic conversa-
tions Rosé et al. (1995) deal with. Second, a thorough
integration of the referential and intentional description
of discourse segments still has to be worked out.
Acknowledgments. We like to thank our colleagues in the
CLIF group for fruitful discussions and instant support, Joe
Bush who polished the text as a native speaker, the three anony-
mous reviewers for their critical comments, and, in particular,
Bonnie Webber for supplying invaluable comments to an ear-
lier draft of this paper. Michael Strube is supported by a post-
doctoral grant from DFG (Str 545/1-1).
</bodyText>
<sectionHeader confidence="0.99836" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999955339285714">
Brennan, S. E., M. W. Friedman &amp; C. J. Pollard (1987). A
centering approach to pronouns. In Proc. of the 25th Annual
Meeting of the Association for Computational Linguistics;
Stanford, Cal., 6-9 July 1987, pp. 155-162.
Dane§, F. (1974). Functional sentence perspective and the orga-
nization of the text. In F. Dand (Ed.), Papers on Functional
Sentence Perspective, pp. 106-128. Prague: Academia.
Grosz, B. J., A. K. Joshi &amp; S. Weinstein (1995). Centering:
A framework for modeling the local coherence of discourse.
Computational Linguistics, 21(2):203-225.
Grosz, B. J. &amp; C. L. Sidner (1986). Attention, intentions,
and the structure of discourse. Computational Linguistics,
12(3):175-204.
Hahn, U., K. Marked &amp; M. Strube (1996). A conceptual rea-
soning approach to textual ellipsis. In Proc. of the 12&amp;quot; Euro-
pean Conference on Artificial Intelligence (ECA! &apos;96); Bu-
dapest, Hungary, 12-16 August 1996, pp. 572-576. Chich-
ester: John Wiley.
Hearst, M. A. (1994). Multi-paragraph segmentation of expos-
itory text. In Proc. of the 32&apos;d Annual Meeting of the As-
sociation for Computational Linguistics; Las Cruces, N.M.,
27-30 June 1994, pp. 9-16.
Morris, J. &amp; G. Hirst (1991). Lexical cohesion computed by
thesaural relations as an indicator of the structure of text.
Computational Linguistics, 17(1):21-48.
Passonneau, R. J. (1996). Interaction of discourse structure
with explicitness of discourse anaphoric noun phrases. In
M. Walker, A. Joshi &amp; E. Prince (Eds.), Centering in Dis-
course. Preprint.
Passonneau, R. J. &amp; D. J. Litman (1993). Intention based seg-
mentation: Human reliability and correlation with linguistic
cues. In Proc. of the 31&amp;quot; Annual Meeting of the Associa-
tion for Computational Linguistics; Columbus, Ohio, 22-26
June 1993, pp. 148-155.
Rosé, C. P., B. Di Eugenio, L. S. Levin &amp; C. Van Ess-Dykema
(1995). Discourse processing of dialogues with multiple
threads. In Proc. of the 33&apos;d Annual Meeting of the Asso-
ciation for Computational Linguistics; Cambridge, Mass.,
26-30 June 1995, pp. 31-38.
Sidner, C. L. (1983). Focusing in the comprehension of definite
anaphora. In M. Brady &amp; R. Berwick (Eds.), Computational
Models of Discourse, pp. 267-330. Cambridge, Mass.: MIT
Press.
Strube, M. &amp; U. Hahn (1996). Functional centering. In Proc.
of the 34th Annual Meeting of the Association for Computa-
tional Linguistics; Santa Cruz, Cal., 23-28 June 1996, pp.
270-277.
Sud, L. Z. &amp; K. F. McCoy (1994). RAFT/RAPR and center-
ing: A comparison and discussion of problems related to
processing complex sentences. Computational Linguistics,
20(2):301-317.
Walker, M. A. (1996a). Centering, anaphora resolution, and
discourse structure. In M. Walker, A. Joshi &amp; E. Prince
(Eds.), Centering in Discourse. Preprint.
Walker, M. A. (1996b). Limited attention and discourse struc-
ture. Computational Linguistics, 22(2):255-264.
</reference>
<page confidence="0.9988">
111
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.811758">
<title confidence="0.9986105">Centering in-the-Large: Computing Referential Discourse Segments</title>
<author confidence="0.9999">Udo Hahn</author>
<author confidence="0.9999">Michael Strube</author>
<affiliation confidence="0.9864425">Computational Linguistics Research Group Freiburg University, Werthmannplatz 1</affiliation>
<address confidence="0.999672">D-79085 Freiburg, Germany</address>
<web confidence="0.993334">http://www.coling.uni-freiburg.de/</web>
<phone confidence="0.881968">34 3</phone>
<abstract confidence="0.995838272727273">We specify an algorithm that builds up a hierarchy of referential discourse segments from local centering data. The spatial extension and nesting of these discourse segments constrain the reachability of potential antecedents of an anaphoric expression beyond the local level of adjacent center pairs. Thus, the centering model is scaled up to the level of the global referential structure of discourse. An empirical evaluation of the algorithm is supplied.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>M W Friedman</author>
<author>C J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proc. of the 25th Annual Meeting of the Association for Computational Linguistics;</booktitle>
<pages>155--162</pages>
<location>Stanford, Cal.,</location>
<contexts>
<context position="3586" citStr="Brennan et al. (1987)" startWordPosition="521" endWordPosition="524"> and incorporation of discourse structure beyond the level of immediately adjacent utterances within the centering framework. Two recent studies deal with this topic in order to relate attentional and intentional structures on a larger scale of global discourse coherence. Passonneau (1996) proposes an algorithm for the generation of referring expressions and Walker (1996a) integrates centering into a cache model of attentional state. Both studies, among other things, deal with the supposition whether a correlation exists between particular centering transitions (which were first introduced by Brennan et al. (1987); cf. Table 1) and intentionbased discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-based) segment boundaries. The data in both studies reveal that only a weak correlation between the SHIFT transitions and segment boundaries can be observed. This finding precludes a reliable prediction of segment boundaries based on the occurrence of &apos;Our notion of referential discourse segment should not be confounded with the inte</context>
<context position="25406" citStr="Brennan et al. (1987)" startWordPosition="4239" endWordPosition="4242">flachen] Table 8: Sample of a Centered Text Segmentation Analysis man news magazine (Spiegel)3, and of two literary texts4 (Lit). Table 9 summarizes the total numbers of anaphors, textual ellipses, utterances, and words in the test set. IT Spiegel Lit E anaphors 197 101 198 496 ellipses 195 22 23 240 utterances 336 84 127 547 words 5241 1468 1610 8319 Table 9: Test Set Table 10 and Table 11 consider the number of anaphoric and text-elliptical expressions, respectively, and the linear distance they have to their corresponding antecedents. Note that common centering algorithms (e.g., the one by Brennan et al. (1987)) are specified only for the resolution of anaphors in U2_1. They are 3Japan – Der Neue der alten Garde. In Der Spiegel, Nr. 3, 1996. 4The first two chapters of a short story by the German writer Heiner Muller (Liebesgeschichte. In Heiner Muller. Geschichten aus der Produktion 2. Berlin: Rotbuch Verlag, 1974, pp. 57-63) and the first chapter of a novel by Uwe Johnson (Zwei Ansichten. Frankfurt/Main: Suhrkamp Verlag, 1965.) neither specified for anaphoric antecedents in U1, not an issue here, nor for anaphoric antecedents beyond U1-1. In the test set, 139 anaphors (28%) and 116 textual ellipses</context>
</contexts>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>Brennan, S. E., M. W. Friedman &amp; C. J. Pollard (1987). A centering approach to pronouns. In Proc. of the 25th Annual Meeting of the Association for Computational Linguistics; Stanford, Cal., 6-9 July 1987, pp. 155-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Dane§</author>
</authors>
<title>Functional sentence perspective and the organization of the text.</title>
<date>1974</date>
<booktitle>In F. Dand (Ed.), Papers on Functional Sentence Perspective,</booktitle>
<pages>106--128</pages>
<publisher>Academia.</publisher>
<location>Prague:</location>
<marker>Dane§, 1974</marker>
<rawString>Dane§, F. (1974). Functional sentence perspective and the organization of the text. In F. Dand (Ed.), Papers on Functional Sentence Perspective, pp. 106-128. Prague: Academia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<contexts>
<context position="758" citStr="Grosz et al., 1995" startWordPosition="102" endWordPosition="105">g University, Werthmannplatz 1 D-79085 Freiburg, Germany http://www.coling.uni-freiburg.de/ 34 3 Abstract We specify an algorithm that builds up a hierarchy of referential discourse segments from local centering data. The spatial extension and nesting of these discourse segments constrain the reachability of potential antecedents of an anaphoric expression beyond the local level of adjacent center pairs. Thus, the centering model is scaled up to the level of the global referential structure of discourse. An empirical evaluation of the algorithm is supplied. 1 Introduction The centering model (Grosz et al., 1995) has evolved as a major methodology for computational discourse analysis. It provides simple, yet powerful data structures, constraints and rules for the local coherence of discourse. As far as anaphora resolution is concerned, e.g., the model requires to consider those discourse entities as potential antecedents for anaphoric expressions in the current utterance Ui , which are available in the forward-looking centers of the immediately preceding utterance U_1. No constraints or rules are formulated, however, that account for anaphoric relationships which spread out over non-adjacent utterance</context>
<context position="29642" citStr="Grosz et al. (1995)" startWordPosition="5006" endWordPosition="5009">igger other kinds of search strategies. Though we fed the centered segmentation algorithm with rather long texts (up to 84 utterances), the antecedents of only two anaphoric expressions had to bridge a hierarchical distance of more than 3 levels. This coincides with our supposition that the overall structure computed by the algorithm should be rather flat. We could not find an embedding of more than seven levels. 6 Related Work There has always been an implicit relationship between the local perspective of centering and the global view of focusing on discourse structure (cf. the discussion in Grosz et al. (1995)). However, work establishing an explicit account of how both can be joined in a computational model has not been done so far. The efforts of Sidner (1983), e.g., have provided a variety of different focus data structures to be used for reference resolution. This multiplicity and the on-going growth of the number of different entities (cf. Suri &amp; McCoy (1994)) mirrors an increase in explanatory constructs that we consider a methodological drawback to this approach because they can hardly be kept control of. Our model, due to its hierarchical nature implements a stack behavior that is also inhe</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Grosz, B. J., A. K. Joshi &amp; S. Weinstein (1995). Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="4236" citStr="Grosz &amp; Sidner (1986)" startWordPosition="621" endWordPosition="624">ased discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-based) segment boundaries. The data in both studies reveal that only a weak correlation between the SHIFT transitions and segment boundaries can be observed. This finding precludes a reliable prediction of segment boundaries based on the occurrence of &apos;Our notion of referential discourse segment should not be confounded with the intentional one originating from Grosz &amp; Sidner (1986), for reasons discussed in Section 2. 104 SHIFTs and vice versa. In order to accommodate to these empirical results divergent solutions are proposed. Passonneau suggests that the centering data structures need to be modified appropriately, while Walker concludes that the local centering data should be left as they are and further be complemented by a cache mechanism. She thus intends to extend the scope of centering in accordance with cognitively plausible limits of the attentional span. Walker, finally, claims that the content of the cache, rather than the intentional discourse segment struct</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. J. &amp; C. L. Sidner (1986). Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>K Marked</author>
<author>M Strube</author>
</authors>
<title>A conceptual reasoning approach to textual ellipsis.</title>
<date>1996</date>
<booktitle>In Proc. of the 12&amp;quot; European Conference on Artificial Intelligence (ECA! &apos;96);</booktitle>
<pages>572--576</pages>
<publisher>Chichester: John Wiley.</publisher>
<location>Budapest,</location>
<contexts>
<context position="10218" citStr="Hahn et al., 1996" startWordPosition="1599" endWordPosition="1602">ntroduce its basic building blocks. Let x denote the anaphoric expression under consideration, which occurs in utterance Ui associated with segment level s. The function Resolved(x, s, U1) (cf. Table 3) is evaluated in order to determine the proper antecedent ante for x. It consists of the evaluation of a reachability predicate for the antecedent on which we will concentrate here, and of the evaluation of the predicate IsAnaphorFor which contains the linguistic and conceptual constraints imposed on a (pro)nominal anaphor (viz, agreement, binding, and sortal constraints) or a textual ellipsis (Hahn et al., 1996), not an issue in this paper. The predicate IsReachable (cf. Table 4) requires ante to be reachable from the utterance Ui associated with the segment level s.2 Reachability is thus made dependent on the segment structure DS of the discourse as built up by the segmentation algorithm which is specified in Table 6. In Table 4, the symbol &amp;quot;=$tr&amp;quot; denotes string equality, N the natural numbers. We also introduce as a notational convention that a discourse segment is identified by its index s and its opening and closing utterance, viz. DS[s.beg] and DS[s.end], respectively. Hence, we may either ident</context>
</contexts>
<marker>Hahn, Marked, Strube, 1996</marker>
<rawString>Hahn, U., K. Marked &amp; M. Strube (1996). A conceptual reasoning approach to textual ellipsis. In Proc. of the 12&amp;quot; European Conference on Artificial Intelligence (ECA! &apos;96); Budapest, Hungary, 12-16 August 1996, pp. 572-576. Chichester: John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proc. of the 32&apos;d Annual Meeting of the Association for Computational Linguistics; Las Cruces, N.M., 27-30</booktitle>
<pages>9--16</pages>
<contexts>
<context position="32335" citStr="Hearst, 1994" startWordPosition="5436" endWordPosition="5437">h are competing models of the attentional state. Centered segmentation has also the additional advantage of restricting the search space of anaphoric antecedents to those discourse entities actually referred to in the discourse, while the cache model allows unrestricted retrieval in the main or long-term memory. Text segmentation procedures (more with an information retrieval motivation, rather than being related to reference resolution tasks) have also been proposed for a coarse-grained partitioning of texts into contiguous, nonoverlapping blocks and assigning content labels to these blocks (Hearst, 1994). The methodological basis of these studies are lexical cohesion indicators (Morris &amp; Hirst, 1991) combined with word-level co-occurrence statistics. Since the labelling is one-dimensional, this approximates our use of preferred centers of discourse segments. These studies, however, lack the fine-grained information of the contents of Cf lists also needed for proper reference resolution. Finally, many studies on discourse segmentation highlight the role of cue words for signaling segment boundaries (cf., e.g., the discussion in Passonneau &amp; Litman (1993)). However useful this strategy might be</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>Hearst, M. A. (1994). Multi-paragraph segmentation of expository text. In Proc. of the 32&apos;d Annual Meeting of the Association for Computational Linguistics; Las Cruces, N.M., 27-30 June 1994, pp. 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Morris</author>
<author>G Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<pages>17--1</pages>
<contexts>
<context position="32433" citStr="Morris &amp; Hirst, 1991" startWordPosition="5448" endWordPosition="5451">onal advantage of restricting the search space of anaphoric antecedents to those discourse entities actually referred to in the discourse, while the cache model allows unrestricted retrieval in the main or long-term memory. Text segmentation procedures (more with an information retrieval motivation, rather than being related to reference resolution tasks) have also been proposed for a coarse-grained partitioning of texts into contiguous, nonoverlapping blocks and assigning content labels to these blocks (Hearst, 1994). The methodological basis of these studies are lexical cohesion indicators (Morris &amp; Hirst, 1991) combined with word-level co-occurrence statistics. Since the labelling is one-dimensional, this approximates our use of preferred centers of discourse segments. These studies, however, lack the fine-grained information of the contents of Cf lists also needed for proper reference resolution. Finally, many studies on discourse segmentation highlight the role of cue words for signaling segment boundaries (cf., e.g., the discussion in Passonneau &amp; Litman (1993)). However useful this strategy might be, we see the danger that such a surface-level description may actually hide structural regularitie</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Morris, J. &amp; G. Hirst (1991). Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1):21-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Passonneau</author>
</authors>
<title>Interaction of discourse structure with explicitness of discourse anaphoric noun phrases. In</title>
<date>1996</date>
<tech>Preprint.</tech>
<contexts>
<context position="3255" citStr="Passonneau (1996)" startWordPosition="475" endWordPosition="476">ately preceding utterance, is made explicit. The adequacy of this definition is judged by the effects centered discourse segmentation has on the validity of anaphora resolution (cf. Section 5 for a discussion of evaluation results). 2 Global Discourse Structure There have been only few attempts at dealing with the recognition and incorporation of discourse structure beyond the level of immediately adjacent utterances within the centering framework. Two recent studies deal with this topic in order to relate attentional and intentional structures on a larger scale of global discourse coherence. Passonneau (1996) proposes an algorithm for the generation of referring expressions and Walker (1996a) integrates centering into a cache model of attentional state. Both studies, among other things, deal with the supposition whether a correlation exists between particular centering transitions (which were first introduced by Brennan et al. (1987); cf. Table 1) and intentionbased discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-base</context>
</contexts>
<marker>Passonneau, 1996</marker>
<rawString>Passonneau, R. J. (1996). Interaction of discourse structure with explicitness of discourse anaphoric noun phrases. In M. Walker, A. Joshi &amp; E. Prince (Eds.), Centering in Discourse. Preprint.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Passonneau</author>
<author>D J Litman</author>
</authors>
<title>Intention based segmentation: Human reliability and correlation with linguistic cues.</title>
<date>1993</date>
<booktitle>In Proc. of the 31&amp;quot; Annual Meeting of the Association for Computational Linguistics;</booktitle>
<pages>148--155</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="32895" citStr="Passonneau &amp; Litman (1993)" startWordPosition="5517" endWordPosition="5520">blocks and assigning content labels to these blocks (Hearst, 1994). The methodological basis of these studies are lexical cohesion indicators (Morris &amp; Hirst, 1991) combined with word-level co-occurrence statistics. Since the labelling is one-dimensional, this approximates our use of preferred centers of discourse segments. These studies, however, lack the fine-grained information of the contents of Cf lists also needed for proper reference resolution. Finally, many studies on discourse segmentation highlight the role of cue words for signaling segment boundaries (cf., e.g., the discussion in Passonneau &amp; Litman (1993)). However useful this strategy might be, we see the danger that such a surface-level description may actually hide structural regularities at deeper levels of investigation illustrated by access mechanisms for centering data at different levels of discourse segmentation. 7 Conclusions We have developed a proposal for extending the centering model to incorporate the global referential structure of discourse for reference resolution. The hierarchy of discourse segments we compute realizes certain constraints on the reachability of antecedents. Moreover, the claim is made that the hierarchy of d</context>
<context position="34252" citStr="Passonneau &amp; Litman (1993)" startWordPosition="5720" endWordPosition="5724">ible linear backward search for potentional discourse referents. Since we operate within a functional framework, this study also presents one of the rare formal accounts of thematic progression patterns for full-fledged texts which were informally introduced by Dane § (1974). The model, nevertheless, still has several restrictions. First, it has been developed on the basis of a small corpus of written texts. Though these cover diverse text sorts (viz, technical product reviews, newspaper articles and literary narratives), we currently do not account for spoken monologues as modelled, e.g., by Passonneau &amp; Litman (1993) or even the intricacies of dyadic conversations Rosé et al. (1995) deal with. Second, a thorough integration of the referential and intentional description of discourse segments still has to be worked out. Acknowledgments. We like to thank our colleagues in the CLIF group for fruitful discussions and instant support, Joe Bush who polished the text as a native speaker, the three anonymous reviewers for their critical comments, and, in particular, Bonnie Webber for supplying invaluable comments to an earlier draft of this paper. Michael Strube is supported by a postdoctoral grant from DFG (Str </context>
</contexts>
<marker>Passonneau, Litman, 1993</marker>
<rawString>Passonneau, R. J. &amp; D. J. Litman (1993). Intention based segmentation: Human reliability and correlation with linguistic cues. In Proc. of the 31&amp;quot; Annual Meeting of the Association for Computational Linguistics; Columbus, Ohio, 22-26 June 1993, pp. 148-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C P Rosé</author>
<author>B Di Eugenio</author>
<author>L S Levin</author>
<author>C Van Ess-Dykema</author>
</authors>
<title>Discourse processing of dialogues with multiple threads.</title>
<date>1995</date>
<booktitle>In Proc. of the 33&apos;d Annual Meeting of the Association for Computational Linguistics;</booktitle>
<pages>31--38</pages>
<location>Cambridge, Mass.,</location>
<marker>Rosé, Di Eugenio, Levin, Van Ess-Dykema, 1995</marker>
<rawString>Rosé, C. P., B. Di Eugenio, L. S. Levin &amp; C. Van Ess-Dykema (1995). Discourse processing of dialogues with multiple threads. In Proc. of the 33&apos;d Annual Meeting of the Association for Computational Linguistics; Cambridge, Mass., 26-30 June 1995, pp. 31-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Focusing in the comprehension of definite anaphora.</title>
<date>1983</date>
<journal>In</journal>
<booktitle>Computational Models of Discourse,</booktitle>
<pages>267--330</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="29797" citStr="Sidner (1983)" startWordPosition="5037" endWordPosition="5038">wo anaphoric expressions had to bridge a hierarchical distance of more than 3 levels. This coincides with our supposition that the overall structure computed by the algorithm should be rather flat. We could not find an embedding of more than seven levels. 6 Related Work There has always been an implicit relationship between the local perspective of centering and the global view of focusing on discourse structure (cf. the discussion in Grosz et al. (1995)). However, work establishing an explicit account of how both can be joined in a computational model has not been done so far. The efforts of Sidner (1983), e.g., have provided a variety of different focus data structures to be used for reference resolution. This multiplicity and the on-going growth of the number of different entities (cf. Suri &amp; McCoy (1994)) mirrors an increase in explanatory constructs that we consider a methodological drawback to this approach because they can hardly be kept control of. Our model, due to its hierarchical nature implements a stack behavior that is also inherent to the above mentioned proposals. We refrain, however, from establishing a new data type (even worse, different types of stacks) that has to be manage</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, C. L. (1983). Focusing in the comprehension of definite anaphora. In M. Brady &amp; R. Berwick (Eds.), Computational Models of Discourse, pp. 267-330. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>U Hahn</author>
</authors>
<title>Functional centering.</title>
<date>1996</date>
<booktitle>In Proc. of the 34th Annual Meeting of the Association for Computational Linguistics;</booktitle>
<pages>270--277</pages>
<location>Santa Cruz, Cal.,</location>
<contexts>
<context position="5590" citStr="Strube &amp; Hahn, 1996" startWordPosition="833" endWordPosition="836">r the purposes of anaphora resolution we subscribe to Walker&apos;s model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse (Grosz &amp; Sidner, 1986, p.180). We diverge from Walker (1996a), however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective (for an elaboration of this claim, cf. Section 6). The proposed extension of the centering model builds on the methodological framework of functional centering (Strube &amp; Hahn, 1996). This is an approach to centering in which issues such as thematicity or topicality are already inherent. Its linguistic foundations relate the ranking of theforward-looking centers and the functional information structure of the utterances, a notion originally developed by Dana (1974). Strube &amp; Hahn (1996) use the centering data structures to redefine Dana&apos; s trichotomy between given information, theme and rheme in terms of the centering model. The Cb(Un ), the most highly ranked element of C (U 1)realized in Un, corresponds to the element which represents the given information. The theme of</context>
<context position="11837" citStr="Strube &amp; Hahn, 1996" startWordPosition="1888" endWordPosition="1891">ex s to center expressions, e.g., Cb(s, U1). Resolved(x, s,U,) := {ante if I sReachable(ante, s, U,) A I sAnaphorFor(s, ante) undef else Table 3: Resolution of Anaphora I sReachable(ante, s, U1) if ante E Ci(s, else if ante E C f (8 — 1, U Ds[3-1.endj) else if (av E N : ante =str Cp(V, UDsfv.end]) A v &lt; (s — 1)) A (—,av&apos; EN : ante =str Cp(t/, UDs[vi.end]) A v &lt; vi) Table 4: Reachability of the Anaphoric Antecedent Finally, the function Lift(s, i) (cf. Table 5) determines the appropriate discourse segment level, s, of an utter2The ef lists in the functional centering model are totally ordered (Strube &amp; Hahn, 1996, p.272) and we here implicitly assume that they are accessed in the total order given. ance U1 (selected by its linear text index, 0. Lift only applies to structural configurations in the centering lists in which themes continuously shift at three different consecutive segment levels and associated preferred centers at least (cf. Table 2, lower box, for the basic pattern). Lift(s, i) := {Li f t(s — 1, i — 1) if s&gt; 2 A i &gt; 3 A Cp(s, Ui—i) Cp(s — 1,U1_2) A C p(8 — 1 , Li , —2) 0 C p(8 — 2, Ui_3) A Cp(s, U,_i ) E C f (3 — 1, U 1-2) s else Table 5: Lifting to the Appropriate Discourse Segment Whe</context>
<context position="16980" citStr="Strube &amp; Hahn, 1996" startWordPosition="2819" endWordPosition="2822">tened. Since the method for computing levels of discourse segments depends heavily on different kinds of anaphoric expressions, (pro)nominal anaphors and textual ellipses are marked by italics, and the (pro)nominal anaphors are underlined, in addition. In order to convey the influence of the German word order we provide a rough phrase-tophrase translation of the entire text. The centered segmentation analysis of the sample text is given in Table 8. The first column shows the linear text index of each utterance. The second column contains the centering data as computed by functional centering (Strube &amp; Hahn, 1996). The first element of the Cf , the preferred center, Cp, is marked by bold font. The third column lists the centering transitions which are derived from the Cb/Cf data of immediately successive utterances (cf. Table 1 for the definitions). The fourth column depicts the levels of discourse segments which are computed by the algorithm in Table 6. Horizontal lines indicate the beginning of a segment (in the algorithm, this corresponds to a value assignment to DS[s.beg]). Vertical lines show the extension of a segment (its end is fixed by an assignment to DS[s.end}). The fifth column indicates wh</context>
<context position="18882" citStr="Strube &amp; Hahn (1996)" startWordPosition="3158" endWordPosition="3161">eding segment, block (2c) applies. The segment counter s is incremented and a new segment at level 2 is opened, setting the beginning and the ending to &amp;quot;4&amp;quot;. The phrase &amp;quot;das diinne Handbiichlein&amp;quot; (the thin leaflet) in U5 does not co-specify the Cp (2, U4) but co-specifies an element of the C1(2, U4) instead (viz. &amp;quot;Handbuch&amp;quot; (manual)). Hence, block (3) of the algorithm applies, leading to the creation of a new segment at level 3. The anaphor &amp;quot;Handbuch&amp;quot; (manual) in U6 co-specifies the Cp (3, U5). Hence block (1) applies (the occurrence of &amp;quot;1260&amp;quot; in C f (U5) is due to the assumptions specified by Strube &amp; Hahn (1996)). Given this configuration, the function Lift lifts the embedded segment one level, so the 107 (I) Brother HL-1260 (8) Kein Wunder: unter dem Inhaltsverzeichnis steht der lap(2) Ein Detail Mit schon beim ersten Umgang mit dem idare Hinweis, man mop sich die Seiten dieses Kapitels groBen Brother auf: doch bitte von Diskette ausdrucken Frechheit. One particular — is already noticed — in the first approach No wonder: beneath the table of contents — one finds the to — the big Brother terse instruction, one should — oneself — the pages of this (3) Im Betrieb macht er durch em n kraftiges Arbeitsge</context>
<context position="27359" citStr="Strube &amp; Hahn, 1996" startWordPosition="4601" endWordPosition="4604">5 U_11 to U_15 7 0 0 7 Table 11: Elliptical Antecedent in Utterance (/ covers erroneous analyses the algorithm produces, while the one for false positives concerns those resolution results where a referential expression was resolved with the hierarchically most recent antecedent but not with the linearly most recent (obviously, the targeted) one (both of them denote the same discourse entity). The categories Cf (s, _1) in Tables 12 and 13 contain more elements than the categories U2_1 in Tables 10 and 11, respectively, due to the mediating property of textual ellipses in functional centering (Strube &amp; Hahn, 1996). IT Spiegel Lit E Ui 10 7 32 49 Cf(s,Ui_i) 161 78 125 364 Cp(8 -- 1, UDS[s-1.end]) 14 9 24 47 Cf (s — 1, UDS1.9-1.encil) 7 5 9 21 Cp(s — 2, UDSts-2.enci) 1 0 1 2 C p(8 — 3, UP43-3.endi) 1 0 1 2 Cp(S _4, UDS[s-4.end) 0 0 1 1 C p(8 -- 5, Ups[s—s.endi) 0 1 0 1 errors 3 1 5 9 false positives (1) (3) (7) (11) Table 12: Anaphoric Antecedent in Center. IT Spiegel Lit E Cf(s,Ui_i) 156 18 17 191 Cp(s — I., UDSts—Lendl) 18 0 4 22 Cf (s _1, UDS[8-1.endj) 10 1 2 13 Cp(s — 2, t I D .51s-2.endl) 7 1 0 8 Cp(s _3, ( ID Sf 8-3.end]) 3 0 0 3 errors 1 2 0 3 false positives (0) (5) Table 13: Elliptical Anteceden</context>
</contexts>
<marker>Strube, Hahn, 1996</marker>
<rawString>Strube, M. &amp; U. Hahn (1996). Functional centering. In Proc. of the 34th Annual Meeting of the Association for Computational Linguistics; Santa Cruz, Cal., 23-28 June 1996, pp. 270-277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Z Sud</author>
<author>K F McCoy</author>
</authors>
<title>RAFT/RAPR and centering: A comparison and discussion of problems related to processing complex sentences.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--2</pages>
<marker>Sud, McCoy, 1994</marker>
<rawString>Sud, L. Z. &amp; K. F. McCoy (1994). RAFT/RAPR and centering: A comparison and discussion of problems related to processing complex sentences. Computational Linguistics, 20(2):301-317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
</authors>
<title>Centering, anaphora resolution, and discourse structure. In</title>
<date>1996</date>
<tech>Preprint.</tech>
<contexts>
<context position="1865" citStr="Walker, 1996" startWordPosition="269" endWordPosition="270">ormulated, however, that account for anaphoric relationships which spread out over non-adjacent utterances. Hence, it is unclear how discourse elements which appear in utterances preceding utterance Ui_1 are taken into consideration as potential antecedents for anaphoric expressions in IA. The extension of the search space for antecedents is by no means a trivial enterprise. A simple linear backward search of all preceding centering structures, e.g., may not only turn out to establish illegal references but also contradicts the cognitive principles underlying the limited attention constraint (Walker, 1996b). The solution we propose starts from the observation that additional constraints on valid antecedents are placed by the global discourse structure previous utterances are embedded in. We want to emphasize from the beginning that our proposal considers only the referential properties underlying the global discourse structure. Accordingly, we define the extension of referential discourse segments (over several utterances) and a hierarchy of referential discourse segments (structuring the entire discourse)) The algorithmic procedure we propose for creating and managing such segments receives l</context>
<context position="3338" citStr="Walker (1996" startWordPosition="487" endWordPosition="488">y the effects centered discourse segmentation has on the validity of anaphora resolution (cf. Section 5 for a discussion of evaluation results). 2 Global Discourse Structure There have been only few attempts at dealing with the recognition and incorporation of discourse structure beyond the level of immediately adjacent utterances within the centering framework. Two recent studies deal with this topic in order to relate attentional and intentional structures on a larger scale of global discourse coherence. Passonneau (1996) proposes an algorithm for the generation of referring expressions and Walker (1996a) integrates centering into a cache model of attentional state. Both studies, among other things, deal with the supposition whether a correlation exists between particular centering transitions (which were first introduced by Brennan et al. (1987); cf. Table 1) and intentionbased discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-based) segment boundaries. The data in both studies reveal that only a weak correlation</context>
<context position="5238" citStr="Walker (1996" startWordPosition="779" endWordPosition="780">extend the scope of centering in accordance with cognitively plausible limits of the attentional span. Walker, finally, claims that the content of the cache, rather than the intentional discourse segment structure, determines the accessibility of discourse entities for anaphora resolution. Table 1: Transition Types As a working hypothesis, for the purposes of anaphora resolution we subscribe to Walker&apos;s model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse (Grosz &amp; Sidner, 1986, p.180). We diverge from Walker (1996a), however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective (for an elaboration of this claim, cf. Section 6). The proposed extension of the centering model builds on the methodological framework of functional centering (Strube &amp; Hahn, 1996). This is an approach to centering in which issues such as thematicity or topicality are already inherent. Its linguistic foundations relate the ranking of theforward-looking centers and the functional information structure of the utterances, a not</context>
<context position="28826" citStr="Walker (1996" startWordPosition="4877" endWordPosition="4878">literary texts in the test exhibited a much more difficult internal structure which resembled the multiple thread structure of dialogues discussed by Rosé et al. (1995). The good news is that the segmentation procedure we propose is capable of dealing even with these more complicated structures. While only one antecedent of a pronoun was not reachable given the superimposed text structure, the remaining eight errors are characterized by full definite noun phrases or proper names. The vast majority of these phenomena can be considered inforrnationally redundant utterances in the terminology of Walker (1996b) for which we currently have no solution at all. It seems to us that these kinds of phrases may override text-grammatical structures as evidenced by referential discourse segments and, rather, trigger other kinds of search strategies. Though we fed the centered segmentation algorithm with rather long texts (up to 84 utterances), the antecedents of only two anaphoric expressions had to bridge a hierarchical distance of more than 3 levels. This coincides with our supposition that the overall structure computed by the algorithm should be rather flat. We could not find an embedding of more than </context>
<context position="30710" citStr="Walker, 1996" startWordPosition="5187" endWordPosition="5188">his approach because they can hardly be kept control of. Our model, due to its hierarchical nature implements a stack behavior that is also inherent to the above mentioned proposals. We refrain, however, from establishing a new data type (even worse, different types of stacks) that has to be managed on its own. There is no need for extra computations to determine the &amp;quot;segment focus&amp;quot;, since that is implicitly given in the local centering data already available in our model. A recent attempt at introducing global discourse notions into the centering framework considers the use of a cache model (Walker, 19966). This introduces an additional data type with its own management principles for data storage, retrieval and update. While our proposal for centered discourse segmentation also requires a data structure of its own, it is better integrated into centering than the caching model, since the cells of segment structures simply contain &amp;quot;pointers&amp;quot; that implement a direct link to the original centering data. Hence, we avoid extra operations related to feeding and updating the cache. The relation between our centered segmentation algorithm and Walker&apos;s (1996a) integration of centering into the cache m</context>
</contexts>
<marker>Walker, 1996</marker>
<rawString>Walker, M. A. (1996a). Centering, anaphora resolution, and discourse structure. In M. Walker, A. Joshi &amp; E. Prince (Eds.), Centering in Discourse. Preprint.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
</authors>
<title>Limited attention and discourse structure.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--2</pages>
<contexts>
<context position="1865" citStr="Walker, 1996" startWordPosition="269" endWordPosition="270">ormulated, however, that account for anaphoric relationships which spread out over non-adjacent utterances. Hence, it is unclear how discourse elements which appear in utterances preceding utterance Ui_1 are taken into consideration as potential antecedents for anaphoric expressions in IA. The extension of the search space for antecedents is by no means a trivial enterprise. A simple linear backward search of all preceding centering structures, e.g., may not only turn out to establish illegal references but also contradicts the cognitive principles underlying the limited attention constraint (Walker, 1996b). The solution we propose starts from the observation that additional constraints on valid antecedents are placed by the global discourse structure previous utterances are embedded in. We want to emphasize from the beginning that our proposal considers only the referential properties underlying the global discourse structure. Accordingly, we define the extension of referential discourse segments (over several utterances) and a hierarchy of referential discourse segments (structuring the entire discourse)) The algorithmic procedure we propose for creating and managing such segments receives l</context>
<context position="3338" citStr="Walker (1996" startWordPosition="487" endWordPosition="488">y the effects centered discourse segmentation has on the validity of anaphora resolution (cf. Section 5 for a discussion of evaluation results). 2 Global Discourse Structure There have been only few attempts at dealing with the recognition and incorporation of discourse structure beyond the level of immediately adjacent utterances within the centering framework. Two recent studies deal with this topic in order to relate attentional and intentional structures on a larger scale of global discourse coherence. Passonneau (1996) proposes an algorithm for the generation of referring expressions and Walker (1996a) integrates centering into a cache model of attentional state. Both studies, among other things, deal with the supposition whether a correlation exists between particular centering transitions (which were first introduced by Brennan et al. (1987); cf. Table 1) and intentionbased discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-based) segment boundaries. The data in both studies reveal that only a weak correlation</context>
<context position="5238" citStr="Walker (1996" startWordPosition="779" endWordPosition="780">extend the scope of centering in accordance with cognitively plausible limits of the attentional span. Walker, finally, claims that the content of the cache, rather than the intentional discourse segment structure, determines the accessibility of discourse entities for anaphora resolution. Table 1: Transition Types As a working hypothesis, for the purposes of anaphora resolution we subscribe to Walker&apos;s model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse (Grosz &amp; Sidner, 1986, p.180). We diverge from Walker (1996a), however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective (for an elaboration of this claim, cf. Section 6). The proposed extension of the centering model builds on the methodological framework of functional centering (Strube &amp; Hahn, 1996). This is an approach to centering in which issues such as thematicity or topicality are already inherent. Its linguistic foundations relate the ranking of theforward-looking centers and the functional information structure of the utterances, a not</context>
<context position="28826" citStr="Walker (1996" startWordPosition="4877" endWordPosition="4878">literary texts in the test exhibited a much more difficult internal structure which resembled the multiple thread structure of dialogues discussed by Rosé et al. (1995). The good news is that the segmentation procedure we propose is capable of dealing even with these more complicated structures. While only one antecedent of a pronoun was not reachable given the superimposed text structure, the remaining eight errors are characterized by full definite noun phrases or proper names. The vast majority of these phenomena can be considered inforrnationally redundant utterances in the terminology of Walker (1996b) for which we currently have no solution at all. It seems to us that these kinds of phrases may override text-grammatical structures as evidenced by referential discourse segments and, rather, trigger other kinds of search strategies. Though we fed the centered segmentation algorithm with rather long texts (up to 84 utterances), the antecedents of only two anaphoric expressions had to bridge a hierarchical distance of more than 3 levels. This coincides with our supposition that the overall structure computed by the algorithm should be rather flat. We could not find an embedding of more than </context>
<context position="30710" citStr="Walker, 1996" startWordPosition="5187" endWordPosition="5188">his approach because they can hardly be kept control of. Our model, due to its hierarchical nature implements a stack behavior that is also inherent to the above mentioned proposals. We refrain, however, from establishing a new data type (even worse, different types of stacks) that has to be managed on its own. There is no need for extra computations to determine the &amp;quot;segment focus&amp;quot;, since that is implicitly given in the local centering data already available in our model. A recent attempt at introducing global discourse notions into the centering framework considers the use of a cache model (Walker, 19966). This introduces an additional data type with its own management principles for data storage, retrieval and update. While our proposal for centered discourse segmentation also requires a data structure of its own, it is better integrated into centering than the caching model, since the cells of segment structures simply contain &amp;quot;pointers&amp;quot; that implement a direct link to the original centering data. Hence, we avoid extra operations related to feeding and updating the cache. The relation between our centered segmentation algorithm and Walker&apos;s (1996a) integration of centering into the cache m</context>
</contexts>
<marker>Walker, 1996</marker>
<rawString>Walker, M. A. (1996b). Limited attention and discourse structure. Computational Linguistics, 22(2):255-264.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>