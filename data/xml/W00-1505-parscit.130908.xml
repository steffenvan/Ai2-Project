<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.070525">
<title confidence="0.959371">
Finite State Tools for Natural Language Processing
</title>
<author confidence="0.856229">
Jan Daciuk
</author>
<affiliation confidence="0.409619">
Alfa Informatica, Rijksuniversiteit Groningen
</affiliation>
<address confidence="0.2904195">
Oude Kijk in &apos;t Jatstraat 26, Postbus 716
9700 AS Groningen, the Netherlands
</address>
<email confidence="0.999368">
e-mail: j.daciuk@let.rug.n1
</email>
<sectionHeader confidence="0.995763" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976444444445">
We describe a set of tools using deterministic,
acyclic, finite-state automata for natural language
processing applications. The core of the tool set
consists of two programs constructing finite-state au-
tomata (using two different, but related algorithms).
Other programs from the set interpret the contents
of those automata. Preprocessing scripts and user
interfaces complete the set. The tools are available
for research purposes in source form in the Internet.
</bodyText>
<sectionHeader confidence="0.997905" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999882541666667">
Finite-state automata (both acceptors and transduc-
ers) play increasingly important role in natural lan-
guage processing. Their main advantages are their
small size as compared with the data they hold (see
e.g. (Kowaltowski et al., 1993)), and the very fast
lookup of strings in an automaton — proportional to
the length of the string.
Deterministic, acyclic, finite-state automata
(DAFSA) are used in a variety of applications, in-
cluding DNA sequencing, computer virus detection,
and VLSA design. In natural language process-
ing, they are used for tasks like spelling correction,
restoration of diacritics, morphological analysis, per-
fect hashing, and acquisition of morphological de-
scriptions for morphological dictionaries. DAFSA
hold a finite set of strings of finite length, so they
can be perceived as a kind of dictionaries. Depend-
ing on the application, the contents of an automaton
may differ considerably, and so do programs that in-
terpret it. However, the basic data structure remains
the same. And so do the programs that produce au-
tomata. It is relatively easy to import data from
other systems, as the basic unit in the system is just
a string.
</bodyText>
<sectionHeader confidence="0.880553" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.99998016">
The architecture of the system is shown on figure 1.
The key data structure in the system is a string of
characters. The core of the system consists of two
programs for construction of DAFSA. They both
produce the same results, but they have different
memory requirements and run at different speeds.
The algorithms are taken from (Daciuk et al., 1998)
(newer version has just appeared in (Daciuk et al.,
2000)). The input data for both of them is a set
of strings. It may be prepared using a variety of
preprocessing scripts. The output of the programs
is a DAFSA interpreted by other application pro-
grams. The first construction program — fsa_build
— constructs an automaton from a lexicographically
sorted list of strings. It is very fast, and it needs very
little memory (see (Daciuk et al., 2000)). The other
construction program — fsa_ubuild — constructs an
automaton from a set of strings in arbitrary order.
Its speed is much lower, and it may need much
more memory (depending on the order of strings).
It can be used in situations where we are short of
disk space for sorting, and we have much core mem-
ory. Both programs accept various run-time options.
They can also use two modules: one for adding in-
formation necessary for perfect hashing, the other
one for producing guessing automata. The modules
are switched on by run-time options.
Different kinds of applications require different in-
formation to be stored in automata. The following
sections describe that in detail.
The application programs use a command line in-
terface, but an emacs interface for GNU emacs 19
is also available for tasks like spelling correction or
restoration of diacritics. Recently, a Tcl/Tk inter-
face has been added for a task of acquisition of de-
scriptions for a morphological dictionary.
The automata are represented as vectors of tran-
sitions. States are represented only implicitly. Var-
ious compression methods are provided as compile
time options. Their influence on the speed of in-
terpretation is small. However, some of them may
significantly lengthen the construction time. By us-
ing combinations of compile options one can obtain
automata that differ in size by about 40%. It is also
possible to use language-specific features, like coding
of prefixes and infixes, to get more compression.
A software package containing the system consists
of 9 programs, 3 shell scripts, 11 awk scripts, 12 perl
scripts, one emacs lisp module, and one Tcl script.
The documentation consists of 11 man pages, on-
</bodyText>
<figure confidence="0.9975390625">
GUI
Morphological
acquisition
Preprocessing
scripts
Emacs
interface
Perfect hashing
Morphological
analysis
Restoration
of diacritics
Spelling correction
Automata construction
Numbering
Pruning
</figure>
<bodyText confidence="0.999897671875">
for those that have only flectional prefixes and no in-
fixes, and another one for languages that have both
inflectional prefixes and infixes. The user must know
which script to choose. It is also up to the user to
choose appropriate run-time options of f sa_morph —
the program that performs morphological analysis.
However, the user does not need to separate the pre-
fixes or infixes from the stems in the entries. It is
done automatically by the scripts.
The morphological analysis program f sa_morph
searches for the inflected form in the automaton,
and then decodes and outputs the annotation, i.e.
the outcome of the analysis. In the basic case, the
canonical form is coded so that one letter says how
many characters to strip from the end of the inflected
form, and it is followed by the ending of the canon-
ical form. In case of flectional prefixes, the code is
supplemented by an additional letter that says how
many characters are to be deleted from the begin-
ning of the inflected form before turning it into the
canonical form. The version that handles infixes as
well has one more letter that says how far from the
beginning of the word the characters to be deleted
are.
It is also possible to analyze words not present in
the dictionary. This is done by analyzing the end-
ings, and sometimes the prefixes and infixes (e.g. in
case of German). An automaton for approximate
morphological analysis (a guessing automaton) as-
sociates endings, and sometimes prefixes and infixes
as well, with appropriate outcomes of the analysis.
But first, those associations need to be created. The
system contains several scripts to aid in that process.
They invert the inflected form, look for endings, pre-
fixes and infixes, and code them appropriately. The
association between an ending and the correspond-
ing analysis is created by inverting the inflected form
and appending the analysis as an annotation (similar
to the lexicon-based analysis). If prefixes and infixes
are present, they are moved from the inflected form
to annotations. The coding of prefixes and infixes is
very similar to that used by f sa_morph. However,
the prefixes, and infixes when needed, must be speci-
fied in the string, so that not only the beginning, but
also the end of the analyzed word can be compared
to the strings stored in a guessing automaton. The
resulting strings are data for a guessing automaton.
Automata are created in the usual way, and then
a specialized module in automata creation programs
prunes the structure. If from a given state all paths
lead to the same set of annotations, then all states
between that state and the annotations can be re-
moved with all their transitions. This significantly
reduces the size of the automaton. Further heuris-
tics can be used to improve either recall or preci-
sion of the predictions made with such tool. During
the analysis, the analyzed word is inverted, and the
consecutive letters are looked up in the automaton.
When no more letters can be recognized, all annota-
tions reachable from the state where the recognition
process stopped are decoded as the result of the anal-
ysis. The program that performs the approximative
morphological analysis — f sa_guess — has options
that turn on recognition of prefixes and infixes.
</bodyText>
<sectionHeader confidence="0.8378345" genericHeader="method">
6 Acquisition of Data for
Morphological Dictionary
</sectionHeader>
<bodyText confidence="0.999960259259259">
Morphological dictionaries are usually constructed
using morphology tools, e.g. two-level morphology.
In many advanced tools, a lexeme description is a
line containing the base form, categories (or fea-
tures) including the flectional paradigm, and often
the canonical form. It is possible to associate end-
ings, prefixes and infixes with that sort of informa-
tion in a similar manner to that used in approxi-
mate morphological analysis. So the same program
— f sa_guess — that performs the approximate mor-
phological analysis is also used (with an appropriate
option) for guessing the morphological description of
an inflected form. A user runs the program on a list
of new words, and the results can be processed using
a graphical user interface, where the user can select
descriptions, compare them, and see what they pro-
duce.
This part of the system is still under development.
The version available in the Internet does not con-
tain the Tcl/Tk interface, and it has no scripts to
help building data for guessing automata for mor-
phological data acquisition. Although the system
works well for French, efforts are under way to make
it work for German. The main problem is the use
of archiphonemes. If not treated properly, they can
inflate the automaton, and in the process some gen-
eralizations might be lost as well.
</bodyText>
<sectionHeader confidence="0.97872" genericHeader="method">
7 Auxiliary Programs
</sectionHeader>
<bodyText confidence="0.999073357142857">
In the system, there are two additional programs
that perform auxiliary tasks. The first one —
f sa_pref ix — was briefly mention is section 4,
page 2. It can be used for listing the contents of a
dictionary (an automaton). However, this is a spe-
cific instance of a more general task, i.e. listing all
words (or strings) in the automaton that have a spec-
ified prefix. In order to get the whole contents of the
automaton one simply specifies a null string.
Another program — f sa_visual — produces data
for a graph visualization software vcg. It can be
used for didactic purposes, or for debugging on tiny
data samples. Larger samples make the graphs too
large to be readable.
</bodyText>
<sectionHeader confidence="0.983799" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.998205342857143">
We have presented a set of tools based on a simple
observation, that DAFSA can be useful in variety of
natural language applications. The main data type
is an automaton representing a set of strings. For
the automata construction programs, the strings are
just sequences of symbols or characters. This makes
it easy to use data from other tools. The meaning
is attributed to the strings by application programs
that interpret them.
The tools are available in the Internet and can
freely be used for research purposes. They can han-
dle large data, e.g. they have been used to build a
morphological dictionary of German with 3,977,448
inflected forms. It took 20 minutes on a pentium
350MHz computer. They are also very fast. For ex-
ample, morphological analysis using the same Ger-
man dictionary is 7.5 times faster than that done
by mmorph. Depending on compile options, an au-
tomaton holding the German morphological dictio-
nary can take approximately 0.5 MB.
A page describing the software package, with
pointers to downloadable software and relevant in-
formation accessible through the Internet is available
at:
http : //www pg gda andac/f sa html
The package contains source code in C++, man
pages, and a few accompanying documentation files
(README, CHANGES, and INSTALL). HTML
versions of man pages are available either directly
from the same page, or as a tar archive. Another
(rather dated) software package using Mealy&apos;s au-
tomata (transducers) is also available from the same
address. That package is no longer developed, as al-
most all its features are also available in the package
described in this paper.
</bodyText>
<sectionHeader confidence="0.99739" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999705702702703">
Jan Daciuk, Richard E. Watson, and Bruce W. Wat-
son. 1998. Incremental construction of acyclic
finite-state automata and transducers. In Finite
State Methods in Natural Language Processing,
Bilkent University, Ankara, Turkey, June — July.
Jan Daciuk, Stoyan Mihov, Bruce Watson, and
Richard Watson. 2000. Incremental construction
of minimal acyclic finite state automata. Compu-
tational Linguistics, 26(1):3-16, April.
Tomasz Kowaltowski, Claudio L. Lucchesi, and
Jorge Stolfi. 1993. Minimization of binary au-
tomata. In First South American String Process-
ing Workshop, Belo Horizonte, Brasil.
Tomasz Kowaltowski, Claudio L. Lucchesi, and
Jorge Stolfi. 1998. Finite automata and efficient
lexicon implementation. Technical Report IC-98-
02, January.
Claudio Lucchiesi and Tomasz Kowaltowski. 1993.
Applications of finite automata representing large
vocabularies. Software Practice and Experience,
23(1):15-30, Jan.
Kemal Oflazer and Cemalettin Giizey. 1994.
Spelling correction in agglutinative languages. In
4th Conference on Applied Natural Language Pro-
cessing, pages 194-195, Stuttgart, Germany, Oc-
tober.
Kemal Oflazer. 1996. Error-tolerant finite state
recognition with applications to morphological
analysis and spelling correction. Computational
Linguistics, 22(1):73-89, March.
Dominique Petitpierre and Graham Russell, 1995.
MMORPH - The Multext Morphology Program.
ISSCO, 54 route des Acacias, CH-1227, Carouge,
Switzerland, version 2.3 edition, October.
Emmanuel Roche. 1995. Finite-state tools for lan-
guage processing. In ACL&apos;95. Association for
Computational Linguistics. Tutorial.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.367307">
<title confidence="0.999841">Finite State Tools for Natural Language Processing</title>
<author confidence="0.98051">Jan</author>
<note confidence="0.559538333333333">Alfa Informatica, Rijksuniversiteit Oude Kijk in &apos;t Jatstraat 26, Postbus 9700 AS Groningen, the</note>
<abstract confidence="0.9805266">We describe a set of tools using deterministic, acyclic, finite-state automata for natural language processing applications. The core of the tool set consists of two programs constructing finite-state automata (using two different, but related algorithms). Other programs from the set interpret the contents of those automata. Preprocessing scripts and user interfaces complete the set. The tools are available for research purposes in source form in the Internet.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jan Daciuk</author>
<author>Richard E Watson</author>
<author>Bruce W Watson</author>
</authors>
<title>Incremental construction of acyclic finite-state automata and transducers.</title>
<date>1998</date>
<booktitle>In Finite State Methods in Natural Language Processing,</booktitle>
<institution>Bilkent University,</institution>
<location>Ankara, Turkey,</location>
<contexts>
<context position="2232" citStr="Daciuk et al., 1998" startWordPosition="344" endWordPosition="347">y, and so do programs that interpret it. However, the basic data structure remains the same. And so do the programs that produce automata. It is relatively easy to import data from other systems, as the basic unit in the system is just a string. 2 System Architecture The architecture of the system is shown on figure 1. The key data structure in the system is a string of characters. The core of the system consists of two programs for construction of DAFSA. They both produce the same results, but they have different memory requirements and run at different speeds. The algorithms are taken from (Daciuk et al., 1998) (newer version has just appeared in (Daciuk et al., 2000)). The input data for both of them is a set of strings. It may be prepared using a variety of preprocessing scripts. The output of the programs is a DAFSA interpreted by other application programs. The first construction program — fsa_build — constructs an automaton from a lexicographically sorted list of strings. It is very fast, and it needs very little memory (see (Daciuk et al., 2000)). The other construction program — fsa_ubuild — constructs an automaton from a set of strings in arbitrary order. Its speed is much lower, and it may </context>
</contexts>
<marker>Daciuk, Watson, Watson, 1998</marker>
<rawString>Jan Daciuk, Richard E. Watson, and Bruce W. Watson. 1998. Incremental construction of acyclic finite-state automata and transducers. In Finite State Methods in Natural Language Processing, Bilkent University, Ankara, Turkey, June — July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Daciuk</author>
<author>Stoyan Mihov</author>
<author>Bruce Watson</author>
<author>Richard Watson</author>
</authors>
<title>Incremental construction of minimal acyclic finite state automata.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<pages>26--1</pages>
<contexts>
<context position="2290" citStr="Daciuk et al., 2000" startWordPosition="354" endWordPosition="357">c data structure remains the same. And so do the programs that produce automata. It is relatively easy to import data from other systems, as the basic unit in the system is just a string. 2 System Architecture The architecture of the system is shown on figure 1. The key data structure in the system is a string of characters. The core of the system consists of two programs for construction of DAFSA. They both produce the same results, but they have different memory requirements and run at different speeds. The algorithms are taken from (Daciuk et al., 1998) (newer version has just appeared in (Daciuk et al., 2000)). The input data for both of them is a set of strings. It may be prepared using a variety of preprocessing scripts. The output of the programs is a DAFSA interpreted by other application programs. The first construction program — fsa_build — constructs an automaton from a lexicographically sorted list of strings. It is very fast, and it needs very little memory (see (Daciuk et al., 2000)). The other construction program — fsa_ubuild — constructs an automaton from a set of strings in arbitrary order. Its speed is much lower, and it may need much more memory (depending on the order of strings).</context>
</contexts>
<marker>Daciuk, Mihov, Watson, Watson, 2000</marker>
<rawString>Jan Daciuk, Stoyan Mihov, Bruce Watson, and Richard Watson. 2000. Incremental construction of minimal acyclic finite state automata. Computational Linguistics, 26(1):3-16, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomasz Kowaltowski</author>
<author>Claudio L Lucchesi</author>
<author>Jorge Stolfi</author>
</authors>
<title>Minimization of binary automata.</title>
<date>1993</date>
<booktitle>In First South American String Processing Workshop,</booktitle>
<location>Belo Horizonte, Brasil.</location>
<contexts>
<context position="937" citStr="Kowaltowski et al., 1993" startWordPosition="131" endWordPosition="134"> language processing applications. The core of the tool set consists of two programs constructing finite-state automata (using two different, but related algorithms). Other programs from the set interpret the contents of those automata. Preprocessing scripts and user interfaces complete the set. The tools are available for research purposes in source form in the Internet. 1 Introduction Finite-state automata (both acceptors and transducers) play increasingly important role in natural language processing. Their main advantages are their small size as compared with the data they hold (see e.g. (Kowaltowski et al., 1993)), and the very fast lookup of strings in an automaton — proportional to the length of the string. Deterministic, acyclic, finite-state automata (DAFSA) are used in a variety of applications, including DNA sequencing, computer virus detection, and VLSA design. In natural language processing, they are used for tasks like spelling correction, restoration of diacritics, morphological analysis, perfect hashing, and acquisition of morphological descriptions for morphological dictionaries. DAFSA hold a finite set of strings of finite length, so they can be perceived as a kind of dictionaries. Depend</context>
</contexts>
<marker>Kowaltowski, Lucchesi, Stolfi, 1993</marker>
<rawString>Tomasz Kowaltowski, Claudio L. Lucchesi, and Jorge Stolfi. 1993. Minimization of binary automata. In First South American String Processing Workshop, Belo Horizonte, Brasil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomasz Kowaltowski</author>
<author>Claudio L Lucchesi</author>
<author>Jorge Stolfi</author>
</authors>
<title>Finite automata and efficient lexicon implementation.</title>
<date>1998</date>
<tech>Technical Report IC-98-02,</tech>
<marker>Kowaltowski, Lucchesi, Stolfi, 1998</marker>
<rawString>Tomasz Kowaltowski, Claudio L. Lucchesi, and Jorge Stolfi. 1998. Finite automata and efficient lexicon implementation. Technical Report IC-98-02, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Lucchiesi</author>
<author>Tomasz Kowaltowski</author>
</authors>
<title>Applications of finite automata representing large vocabularies. Software Practice and Experience,</title>
<date>1993</date>
<pages>23--1</pages>
<marker>Lucchiesi, Kowaltowski, 1993</marker>
<rawString>Claudio Lucchiesi and Tomasz Kowaltowski. 1993. Applications of finite automata representing large vocabularies. Software Practice and Experience, 23(1):15-30, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>Cemalettin Giizey</author>
</authors>
<title>Spelling correction in agglutinative languages.</title>
<date>1994</date>
<booktitle>In 4th Conference on Applied Natural Language Processing,</booktitle>
<pages>194--195</pages>
<location>Stuttgart, Germany,</location>
<marker>Oflazer, Giizey, 1994</marker>
<rawString>Kemal Oflazer and Cemalettin Giizey. 1994. Spelling correction in agglutinative languages. In 4th Conference on Applied Natural Language Processing, pages 194-195, Stuttgart, Germany, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Error-tolerant finite state recognition with applications to morphological analysis and spelling correction.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<marker>Oflazer, 1996</marker>
<rawString>Kemal Oflazer. 1996. Error-tolerant finite state recognition with applications to morphological analysis and spelling correction. Computational Linguistics, 22(1):73-89, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Petitpierre</author>
<author>Graham Russell</author>
</authors>
<title>MMORPH - The Multext Morphology Program.</title>
<date>1995</date>
<booktitle>ISSCO, 54 route des Acacias, CH-1227,</booktitle>
<location>Carouge, Switzerland, version</location>
<note>2.3 edition,</note>
<marker>Petitpierre, Russell, 1995</marker>
<rawString>Dominique Petitpierre and Graham Russell, 1995. MMORPH - The Multext Morphology Program. ISSCO, 54 route des Acacias, CH-1227, Carouge, Switzerland, version 2.3 edition, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
</authors>
<title>Finite-state tools for language processing.</title>
<date>1995</date>
<booktitle>In ACL&apos;95. Association for Computational Linguistics. Tutorial.</booktitle>
<marker>Roche, 1995</marker>
<rawString>Emmanuel Roche. 1995. Finite-state tools for language processing. In ACL&apos;95. Association for Computational Linguistics. Tutorial.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>