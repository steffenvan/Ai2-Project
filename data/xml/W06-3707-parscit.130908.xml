<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.113289">
<title confidence="0.998058">
MedSLT: A Limited-Domain Unidirectional Grammar-Based Medical
Speech Translator
</title>
<author confidence="0.999198">
Manny Rayner, Pierrette Bouillon, Nikos Chatzichrisafis, Marianne Santaholma, Marianne Starlander
</author>
<affiliation confidence="0.999315">
University of Geneva, TIM/ISSCO, 40 bvd du Pont-d’Arve, CH-1211 Geneva 4, Switzerland
</affiliation>
<email confidence="0.875279">
Emmanuel.Rayner@issco.unige.ch
Pierrette.Bouillon@issco.unige.ch, Nikos.Chatzichrisafis@vozZup.com
Marianne.Santaholma@eti.unige.ch, Marianne.Starlander@eti.unige.ch
</email>
<author confidence="0.995547">
Beth Ann Hockey
</author>
<affiliation confidence="0.994407">
UCSC/NASA Ames Research Center, Moffet Field, CA 94035
</affiliation>
<email confidence="0.991294">
bahockey@email.arc.nasa.gov
</email>
<author confidence="0.99826">
Yukie Nakao, Hitoshi Isahara, Kyoko Kanzaki
</author>
<affiliation confidence="0.999587">
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.946607">
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
</address>
<email confidence="0.995147">
yukie-n@khn.nict.go.jp,{isahara,kanzaki}@nict.go.jp
</email>
<sectionHeader confidence="0.992983" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845153846154">
MedSLT is a unidirectional medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several differ-
ent language pairs and subdomains. Vo-
cabulary ranges from about 350 to 1000
surface words, depending on the language
and subdomain. We will demo both the
system itself and the development envi-
ronment, which uses a combination of
rule-based and data-driven methods to
construct efficient recognisers, generators
and transfer rule sets from small corpora.
</bodyText>
<sectionHeader confidence="0.996746" genericHeader="method">
1 Overview
</sectionHeader>
<bodyText confidence="0.99988337037037">
The mainstream in speech translation work is for the
moment statistical, but rule-based systems are still a
very respectable alternative. In particular, nearly all
systems which have actually been deployed are rule-
based. Prominent examples are (Phraselator, 2006;
S-MINDS, 2006; MedBridge, 2006).
MedSLT (MedSLT, 2005; Bouillon et al., 2005)
is a unidirectional medical speech translation system
for use in doctor-patient diagnosis dialogues, which
covers several different language pairs and subdo-
mains. Recognition is performed using grammar-
based language models, and translation uses a rule-
based interlingual framework. The system, includ-
ing the development environment, is built on top of
Regulus (Regulus, 2006), an Open Source platform
for developing grammar-based speech applications,
which in turn sits on top of the Nuance Toolkit.
The demo will show how MedSLT can be used
to carry out non-trivial diagnostic dialogues. In par-
ticular, we will demonstrate how an integrated intel-
ligent help system counteracts the brittleness inher-
ent in rule-based processing, and rapidly leads new
users towards the supported system coverage. We
will also demo the development environment, and
show how grammars and sets of transfer rules can be
efficiently constructed from small corpora of a few
hundred to a thousand examples.
</bodyText>
<sectionHeader confidence="0.981227" genericHeader="method">
2 The MedSLT system
</sectionHeader>
<bodyText confidence="0.999983717391304">
The MedSLT demonstrator has already been exten-
sively described elsewhere (Bouillon et al., 2005;
Rayner et al., 2005a), so this section will only
present a brief summary. The main components are
a set of speech recognisers for the source languages,
a set of generators for the target languages, a transla-
tion engine, sets of rules for translating to and from
interlingua, a simple discourse engine for dealing
with context-dependent translation, and a top-level
which manages the information flow between the
other modules and the user.
MedSLT also includes an intelligent help mod-
ule, which adds robustness to the system and guides
the user towards the supported coverage. The help
module uses a backup recogniser, equipped with a
statistical language model, and matches the results
from this second recogniser against a corpus of utter-
ances which are within system coverage and trans-
late correctly. In previous studies, we showed that
the grammar-based recogniser performs much bet-
ter than the statistical one on in-coverage utterances,
but worse on out-of-coverage ones. Having the help
system available approximately doubled the speed
at which subjects learned, measured as the average
difference in semantic error rate between the results
for their first quarter-session and their last quarter-
session (Rayner et al., 2005a). It is also possible to
recover from recognition errors by selecting a dis-
played help sentence; this typically increases the
number of acceptably processed utterances by about
10% (Starlander et al., 2005).
We will demo several versions of the system, us-
ing different source languages, target languages and
subdomains. Coverage is based on standard exami-
nation questions obtained from doctors, and consists
mainly of yes/no questions, though there is also sup-
port for WH-questions and elliptical utterances. Ta-
ble 1 gives examples of the coverage in the English-
input headache version, and Table 2 summarises
recognition performance in this domain for the three
main input languages. Differences in the sizes of the
recognition vocabularies are primarily due to differ-
ences in use of inflection. Japanese, with little in-
flectional morphology, has the smallest vocabulary;
French, which inflects most parts of speech, has the
largest.
</bodyText>
<sectionHeader confidence="0.988331" genericHeader="method">
3 The development environment
</sectionHeader>
<bodyText confidence="0.991027181818182">
Although the MedSLT system is rule-based, we
would, for the usual reasons, prefer to acquire these
rules from corpora using some well-defined method.
There is, however, little or no material available for
most medical speech translation domains, including
ours. As noted in (Probst and Levin, 2002), scarcity
of data generally implies use of some strategy to ob-
tain a carefully structured training corpus. If the cor-
pus is not organised in this way, conflicts between
alternate learned rules occur, and it is hard to in-
Where?
“do you experience the pain in your jaw”
“does the pain spread to the shoulder”
When?
“have you had the pain for more than a month”
“do the headaches ever occur in the morning”
How long?
“does the pain typically last a few minutes”
“does the pain ever last more than two hours”
How often?
“do you get headaches several times a week”
“are the headaches occurring more often”
</bodyText>
<table confidence="0.917002266666667">
How?
“is it a stabbing pain”
“is the pain usually severe”
Associated symptoms?
“do you vomit when you get the headaches”
“is the pain accompanied by blurred vision”
Why?
“does bright light make the pain worse”
“do you get headaches when you eat cheese”
What helps?
“does sleep make the pain better”
“does massage help”
Background?
“do you have a history of sinus disease”
“have you had an e c g”
</table>
<tableCaption confidence="0.999855">
Table 1: Examples of English MedSLT coverage
</tableCaption>
<bodyText confidence="0.999727647058823">
duce a stable set of rules. As Probst and Levin sug-
gest, one obvious way to attack the problem is to
implement a (formal or informal) elicitation strat-
egy, which biases the informant towards translations
which are consistent with the existing ones. This is
the approach we have adopted in MedSLT.
The Regulus platform, on which MedSLT
is based, supports rapid construction of com-
plex grammar-based language models; it uses an
example-based method driven by small corpora
of disambiguated parsed examples (Rayner et al.,
2003; Rayner et al., 2006), which extracts most of
the structure of the model from a general linguis-
tically motivated resource grammar. The result is
a specialised version of the general grammar, tai-
lored to the example corpus, which can then be com-
piled into an efficient recogniser or into a genera-
</bodyText>
<table confidence="0.99968825">
Language Vocab WER SemER
English 441 6% 18%
French 1025 8% 10%
Japanese 347 4% 4%
</table>
<tableCaption confidence="0.997692">
Table 2: Recognition performance for English,
</tableCaption>
<bodyText confidence="0.994460772727273">
French and Japanese headache-domain recognisers.
“Vocab” = number of surface words in source lan-
guage recogniser vocabulary; “WER” = Word Error
Rate for source language recogniser, on in-coverage
material; “SemER” = semantic error rate for source
language recogniser, on in-coverage material.
tion module. Regulus-based recognisers and gen-
erators are easy to maintain, and grammar struc-
ture is shared automatically across different subdo-
mains. Resource grammars are available for several
languages, including English, Japanese, French and
Spanish.
Nuance recognisers derived from the resource
grammars produce both a recognition string and a
semantic representation. This representation con-
sists of a list of key/value pairs, optionally including
one level of nesting; the format of interlingua and
target language representations is similar. The for-
malism is sufficiently expressive that a reasonable
range of temporal and causal constructions can be
represented (Rayner et al., 2005b). A typical exam-
ple is shown in Figure 1. A translation rule maps
a list of key/value pairs to a list of key/value pairs,
optionally specifying conditions requiring that other
key/value pairs either be present or absent in the
source representation.
When developing new coverage for a given lan-
guage pair, the developer has two main tasks. First,
they need to add new training examples to the
corpora used to derive the specialised grammars
used for the source and target languages; second,
they must add translation rules to handle the new
key/value pairs. The simple structure of the Med-
SLT representations makes it easy to support semi-
automatic acquisition of both of these types of in-
formation. The basic principle is to attempt to find
the minimal set of new rules that can be added to the
existing set, in order to cover the new corpus exam-
ple; this is done through a short elicitation dialogue
with the developer. We illustrate this with a simple
example.
Suppose we are developing coverage for the En-
glish → Spanish version of the system, and that
the English corpus sentence “does the pain occur at
night” fails to translate. The acquisition tool first
notes that processing fails when converting from in-
terlingua to Spanish. The interlingua representation
is
[[utterance_type,ynq],
[pronoun,you],
[state,have_symptom],
[symptom,pain],[tense,present],
[prep,in_time],[time,night]]
Applying Interlingua → Spanish rules, the result is
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
failed:[time,night]]
where the tag failed indicates that the element
[time,night] could not be processed. The tool
matches the incomplete transferred representation
against a set of correctly translated examples, and
shows the developer the English and Spanish strings
for the three most similar ones, here
does it appear in the morning
-&gt; tiene el dolor por la ma˜nana
does the pain appear in the morning
-&gt; tiene el dolor por la ma˜nana
does the pain come in the morning
-&gt; tiene el dolor por la ma˜nana
This suggests that a translation for “does the pain
occur at night” consistent with the existing rules
would be “tiene el dolor por la noche”. The devel-
oper gives this example to the system, which parses
it using both the general Spanish resource grammar
and the specialised grammar used for generation in
the headache domain. The specialised grammar fails
to produce an analysis, while the resource grammar
produces two analyses,
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[[utterance_type,ynq],[pronoun,you],[state,have_symptom],
[tense,present],[symptom,headache],[sc,when],
[[clause,[[utterance_type,dcl],[pronoun,you],
[action,drink],[tense,present],[cause,coffee]]]]
</bodyText>
<figureCaption confidence="0.999567">
Figure 1: Representation of “do you get headaches when you drink coffee”
</figureCaption>
<bodyText confidence="0.98947406060606">
[tense,present],
[prep,por_temporal],
[temporal,noche]]
and
[[utterance_type,dcl],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
[temporal,noche]]
The first of these corresponds to the YN-question
reading of the sentence (“do you have the pain at
night”), while the second is the declarative reading
(“you have the pain at night”). Since the first (YN-
question) reading matches the Interlingua represen-
tation better, the acquisition tool assumes that it is
the intended one. It can now suggest two pieces of
information to extend the system’s coverage.
First, it adds the YN-question reading of “tiene
el dolor por la noche” to the corpus used to train
the specialised generation grammar. The piece
of information acquired from this example is that
[temporal,noche] should be realised in this
domain as “la noche”. Second, it compares the cor-
rect Spanish representation with the incomplete one
produced by the current set of rules, and induces a
new Interlingua to Spanish translation rule. This will
be of the form
[time,night] -&gt; [temporal,noche]
In the demo, we will show how the development
environment makes it possible to quickly add new
coverage to the system, while also checking that old
coverage is not broken.
</bodyText>
<sectionHeader confidence="0.998394" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999398021276596">
P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,
and H. Isahara. 2005. A generic multi-lingual open
source platform for limited-domain medical speech
translation. In In Proceedings of the 10th Conference
of the European Association for Machine Translation
(EAMT), Budapest, Hungary.
MedBridge, 2006. http://www.medtablet.com/index.html.
As of 15 March 2006.
MedSLT, 2005. http://sourceforge.net/projects/medslt/.
As of 15 March 2005.
Phraselator, 2006. http://www.phraselator.com. As of 15
March 2006.
K. Probst and L. Levin. 2002. Challenges in automatic
elicitation of a controlled bilingual corpus. In Pro-
ceedings of the 9th International Conference on The-
oretical and Methodological Issues in Machine Trans-
lation.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner, P. Bouillon, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, H. Isahara, K. Kankazi,
and Y. Nakao. 2005a. A methodology for comparing
grammar-based and robust approaches to speech un-
derstanding. In Proceedings of the 9th International
Conference on Spoken Language Processing (ICSLP),
Lisboa, Portugal.
M. Rayner, P. Bouillon, M. Santaholma, and Y. Nakao.
2005b. Representational and architectural issues in a
limited-domain medical speech translator. In Proceed-
ings of TALN/RECITAL, Dourdan, France.
M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting
Linguistics into Speech Recognition: The Regulus
Grammar Compiler. CSLI Press, Chicago.
Regulus, 2006. http://sourceforge.net/projects/regulus/.
As of 15 March 2006.
S-MINDS, 2006. http://www.sehda.com. As of 15
March 2006.
M. Starlander, P. Bouillon, N. Chatzichrisafis, M. Santa-
holma, M. Rayner, B.A. Hockey, H. Isahara, K. Kan-
zaki, and Y. Nakao. 2005. Practicing controlled lan-
guage through a help system integrated into the medi-
cal speech translation system (MedSLT). In Proceed-
ings of the MT Summit X, Phuket, Thailand.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000120">
<title confidence="0.9978395">MedSLT: A Limited-Domain Unidirectional Grammar-Based Speech Translator</title>
<author confidence="0.998941">Manny Rayner</author>
<author confidence="0.998941">Pierrette Bouillon</author>
<author confidence="0.998941">Nikos Chatzichrisafis</author>
<author confidence="0.998941">Marianne Santaholma</author>
<author confidence="0.998941">Marianne</author>
<affiliation confidence="0.942488">University of Geneva, TIM/ISSCO, 40 bvd du Pont-d’Arve, CH-1211 Geneva 4,</affiliation>
<author confidence="0.774524">Beth Ann Hockey</author>
<address confidence="0.572003">UCSC/NASA Ames Research Center, Moffet Field, CA</address>
<email confidence="0.981061">bahockey@email.arc.nasa.gov</email>
<author confidence="0.723708">Yukie Nakao</author>
<author confidence="0.723708">Hitoshi Isahara</author>
<author confidence="0.723708">Kyoko</author>
<affiliation confidence="0.978403">National Institute of Information and Communications</affiliation>
<address confidence="0.955145">3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan</address>
<abstract confidence="0.99842221509434">MedSLT is a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different language pairs and subdomains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be used to carry out non-trivial diagnostic dialogues. In particular, we will demonstrate how an integrated intelligent help system counteracts the brittleness inherent in rule-based processing, and rapidly leads new users towards the supported system coverage. We will also demo the development environment, and show how grammars and sets of transfer rules can be efficiently constructed from small corpora of a few hundred to a thousand examples. 2 The MedSLT system The MedSLT demonstrator has already been extensively described elsewhere (Bouillon et al., 2005; Rayner et al., 2005a), so this section will only present a brief summary. The main components are a set of speech recognisers for the source languages, a set of generators for the target languages, a translation engine, sets of rules for translating to and from interlingua, a simple discourse engine for dealing with context-dependent translation, and a top-level which manages the information flow between the other modules and the user. MedSLT also includes an intelligent help module, which adds robustness to the system and guides the user towards the supported coverage. The help module uses a backup recogniser, equipped with a statistical language model, and matches the results from this second recogniser against a corpus of utterances which are within system coverage and translate correctly. In previous studies, we showed that the grammar-based recogniser performs much better than the statistical one on in-coverage utterances, but worse on out-of-coverage ones. Having the help system available approximately doubled the speed at which subjects learned, measured as the average difference in semantic error rate between the results for their first quarter-session and their last quartersession (Rayner et al., 2005a). It is also possible to recover from recognition errors by selecting a displayed help sentence; this typically increases the number of acceptably processed utterances by about 10% (Starlander et al., 2005). We will demo several versions of the system, using different source languages, target languages and subdomains. Coverage is based on standard examination questions obtained from doctors, and consists mainly of yes/no questions, though there is also support for WH-questions and elliptical utterances. Table 1 gives examples of the coverage in the Englishinput headache version, and Table 2 summarises recognition performance in this domain for the three main input languages. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. Japanese, with little inflectional morphology, has the smallest vocabulary; French, which inflects most parts of speech, has the largest. 3 The development environment Although the MedSLT system is rule-based, we would, for the usual reasons, prefer to acquire these rules from corpora using some well-defined method. There is, however, little or no material available for most medical speech translation domains, including ours. As noted in (Probst and Levin, 2002), scarcity of data generally implies use of some strategy to obtain a carefully structured training corpus. If the corpus is not organised in this way, conflicts between learned rules occur, and it is hard to in- Where? “do you experience the pain in your jaw” “does the pain spread to the shoulder” When? “have you had the pain for more than a month” “do the headaches ever occur in the morning” How long? “does the pain typically last a few minutes” “does the pain ever last more than two hours” How often? “do you get headaches several times a week” “are the headaches occurring more often” How? “is it a stabbing pain” “is the pain usually severe” Associated symptoms? “do you vomit when you get the headaches” “is the pain accompanied by blurred vision” Why? “does bright light make the pain worse” “do you get headaches when you eat cheese” What helps? “does sleep make the pain better” “does massage help” Background? “do you have a history of sinus disease” “have you had an e c g” Table 1: Examples of English MedSLT coverage duce a stable set of rules. As Probst and Levin suggest, one obvious way to attack the problem is to implement a (formal or informal) elicitation strategy, which biases the informant towards translations which are consistent with the existing ones. This is the approach we have adopted in MedSLT. The Regulus platform, on which MedSLT is based, supports rapid construction of complex grammar-based language models; it uses an example-based method driven by small corpora of disambiguated parsed examples (Rayner et al., 2003; Rayner et al., 2006), which extracts most of the structure of the model from a general linguistically motivated resource grammar. The result is a specialised version of the general grammar, tailored to the example corpus, which can then be cominto an efficient recogniser or into a genera- Language Vocab WER SemER English 441 6% 18% French 1025 8% 10% Japanese 347 4% 4% Table 2: Recognition performance for English, French and Japanese headache-domain recognisers. “Vocab” = number of surface words in source language recogniser vocabulary; “WER” = Word Error Rate for source language recogniser, on in-coverage material; “SemER” = semantic error rate for source language recogniser, on in-coverage material. tion module. Regulus-based recognisers and generators are easy to maintain, and grammar structure is shared automatically across different subdomains. Resource grammars are available for several languages, including English, Japanese, French and Spanish. Nuance recognisers derived from the resource grammars produce both a recognition string and a semantic representation. This representation consists of a list of key/value pairs, optionally including one level of nesting; the format of interlingua and target language representations is similar. The formalism is sufficiently expressive that a reasonable range of temporal and causal constructions can be represented (Rayner et al., 2005b). A typical example is shown in Figure 1. A translation rule maps a list of key/value pairs to a list of key/value pairs, optionally specifying conditions requiring that other key/value pairs either be present or absent in the source representation. When developing new coverage for a given language pair, the developer has two main tasks. First, they need to add new training examples to the corpora used to derive the specialised grammars used for the source and target languages; second, they must add translation rules to handle the new key/value pairs. The simple structure of the Med- SLT representations makes it easy to support semiautomatic acquisition of both of these types of information. The basic principle is to attempt to find the minimal set of new rules that can be added to the existing set, in order to cover the new corpus example; this is done through a short elicitation dialogue with the developer. We illustrate this with a simple example. Suppose we are developing coverage for the Enversion of the system, and that the English corpus sentence “does the pain occur at night” fails to translate. The acquisition tool first notes that processing fails when converting from interlingua to Spanish. The interlingua representation is [[utterance_type,ynq], [pronoun,you], [state,have_symptom], [symptom,pain],[tense,present], [prep,in_time],[time,night]] Interlingua rules, the result is [[utterance_type,ynq], [pronoun,usted], [state,tener],[symptom,dolor], [tense,present], [prep,por_temporal], failed:[time,night]] the tag that the element not be processed. The tool matches the incomplete transferred representation against a set of correctly translated examples, and shows the developer the English and Spanish strings for the three most similar ones, here does it appear in the morning tiene el dolor por la does the pain appear in the morning tiene el dolor por la does the pain come in the morning tiene el dolor por la This suggests that a translation for “does the pain occur at night” consistent with the existing rules would be “tiene el dolor por la noche”. The developer gives this example to the system, which parses it using both the general Spanish resource grammar and the specialised grammar used for generation in the headache domain. The specialised grammar fails to produce an analysis, while the resource grammar produces two analyses, [[utterance_type,ynq], [pronoun,usted], [state,tener],[symptom,dolor], [[utterance_type,ynq],[pronoun,you],[state,have_symptom], [tense,present],[symptom,headache],[sc,when], [[clause,[[utterance_type,dcl],[pronoun,you], [action,drink],[tense,present],[cause,coffee]]]] Figure 1: Representation of “do you get headaches when you drink coffee” [tense,present], [prep,por_temporal], [temporal,noche]] and [[utterance_type,dcl], [pronoun,usted], [state,tener],[symptom,dolor], [tense,present], [prep,por_temporal], [temporal,noche]] The first of these corresponds to the YN-question reading of the sentence (“do you have the pain at night”), while the second is the declarative reading (“you have the pain at night”). Since the first (YNquestion) reading matches the Interlingua representation better, the acquisition tool assumes that it is the intended one. It can now suggest two pieces of information to extend the system’s coverage. First, it adds the YN-question reading of “tiene el dolor por la noche” to the corpus used to train the specialised generation grammar. The piece of information acquired from this example is that be realised in this domain as “la noche”. Second, it compares the correct Spanish representation with the incomplete one produced by the current set of rules, and induces a new Interlingua to Spanish translation rule. This will be of the form [time,night] -&gt; [temporal,noche] In the demo, we will show how the development environment makes it possible to quickly add new coverage to the system, while also checking that old coverage is not broken.</abstract>
<title confidence="0.936985">References</title>
<author confidence="0.845345666666667">A generic multi-lingual open</author>
<abstract confidence="0.64963">source platform for limited-domain medical speech</abstract>
<note confidence="0.854199916666667">In Proceedings of the 10th Conference of the European Association for Machine Translation Budapest, Hungary. MedBridge, 2006. http://www.medtablet.com/index.html. As of 15 March 2006. MedSLT, 2005. http://sourceforge.net/projects/medslt/. As of 15 March 2005. Phraselator, 2006. http://www.phraselator.com. As of 15 March 2006. K. Probst and L. Levin. 2002. Challenges in automatic of a controlled bilingual corpus. In Proceedings of the 9th International Conference on The-</note>
<title confidence="0.728491">oretical and Methodological Issues in Machine Trans-</title>
<author confidence="0.638174">An</author>
<abstract confidence="0.5621045">open source environment for compiling typed unificagrammars into speech recognisers. In Proceedof the 10th EACL (demo Budapest, Hungary.</abstract>
<author confidence="0.859441">M Rayner</author>
<author confidence="0.859441">P Bouillon</author>
<author confidence="0.859441">N Chatzichrisafis</author>
<author confidence="0.859441">B A Hockey</author>
<author confidence="0.859441">M Santaholma</author>
<author confidence="0.859441">M Starlander</author>
<author confidence="0.859441">H Isahara</author>
<author confidence="0.859441">K Kankazi</author>
<abstract confidence="0.5851685">and Y. Nakao. 2005a. A methodology for comparing grammar-based and robust approaches to speech un- In of the 9th International on Spoken Language Processing</abstract>
<address confidence="0.862441">Lisboa, Portugal.</address>
<note confidence="0.907798545454545">M. Rayner, P. Bouillon, M. Santaholma, and Y. Nakao. 2005b. Representational and architectural issues in a medical speech translator. In Proceedof Dourdan, France. Rayner, B.A. Hockey, and P. Bouillon. 2006. Linguistics into Speech Recognition: The Regulus CSLI Press, Chicago. Regulus, 2006. http://sourceforge.net/projects/regulus/. As of 15 March 2006. S-MINDS, 2006. http://www.sehda.com. As of 15 March 2006.</note>
<author confidence="0.84391">M Starlander</author>
<author confidence="0.84391">P Bouillon</author>
<author confidence="0.84391">N Chatzichrisafis</author>
<author confidence="0.84391">M Santaholma</author>
<author confidence="0.84391">M Rayner</author>
<author confidence="0.84391">B A Hockey</author>
<author confidence="0.84391">H Isahara</author>
<author confidence="0.84391">K Kan-</author>
<abstract confidence="0.79037425">zaki, and Y. Nakao. 2005. Practicing controlled language through a help system integrated into the medispeech translation system (MedSLT). In Proceedof the MT Summit Phuket, Thailand.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>N Chatzichrisafis</author>
<author>B A Hockey</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>Y Nakao</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
</authors>
<title>A generic multi-lingual open source platform for limited-domain medical speech translation. In</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Conference of the European Association for Machine Translation (EAMT),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1622" citStr="Bouillon et al., 2005" startWordPosition="191" endWordPosition="194">words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be used to carry out non-trivial diagnostic dialogues. In particul</context>
</contexts>
<marker>Bouillon, Rayner, Chatzichrisafis, Hockey, Santaholma, Starlander, Nakao, Kanzaki, Isahara, 2005</marker>
<rawString>P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey, M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki, and H. Isahara. 2005. A generic multi-lingual open source platform for limited-domain medical speech translation. In In Proceedings of the 10th Conference of the European Association for Machine Translation (EAMT), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MedBridge</author>
</authors>
<title>http://www.medtablet.com/index.html.</title>
<date>2006</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="1576" citStr="MedBridge, 2006" startWordPosition="186" endWordPosition="187">y ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be used to carry out</context>
</contexts>
<marker>MedBridge, 2006</marker>
<rawString>MedBridge, 2006. http://www.medtablet.com/index.html. As of 15 March 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MedSLT</author>
</authors>
<title>http://sourceforge.net/projects/medslt/.</title>
<date>2005</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="1598" citStr="MedSLT, 2005" startWordPosition="189" endWordPosition="190"> 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be used to carry out non-trivial diagnosti</context>
</contexts>
<marker>MedSLT, 2005</marker>
<rawString>MedSLT, 2005. http://sourceforge.net/projects/medslt/. As of 15 March 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phraselator</author>
</authors>
<title>http://www.phraselator.com.</title>
<date>2006</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="1543" citStr="Phraselator, 2006" startWordPosition="182" endWordPosition="183">ge pairs and subdomains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show ho</context>
</contexts>
<marker>Phraselator, 2006</marker>
<rawString>Phraselator, 2006. http://www.phraselator.com. As of 15 March 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Probst</author>
<author>L Levin</author>
</authors>
<title>Challenges in automatic elicitation of a controlled bilingual corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation.</booktitle>
<contexts>
<context position="5215" citStr="Probst and Levin, 2002" startWordPosition="744" endWordPosition="747">s domain for the three main input languages. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. Japanese, with little inflectional morphology, has the smallest vocabulary; French, which inflects most parts of speech, has the largest. 3 The development environment Although the MedSLT system is rule-based, we would, for the usual reasons, prefer to acquire these rules from corpora using some well-defined method. There is, however, little or no material available for most medical speech translation domains, including ours. As noted in (Probst and Levin, 2002), scarcity of data generally implies use of some strategy to obtain a carefully structured training corpus. If the corpus is not organised in this way, conflicts between alternate learned rules occur, and it is hard to inWhere? “do you experience the pain in your jaw” “does the pain spread to the shoulder” When? “have you had the pain for more than a month” “do the headaches ever occur in the morning” How long? “does the pain typically last a few minutes” “does the pain ever last more than two hours” How often? “do you get headaches several times a week” “are the headaches occurring more often</context>
</contexts>
<marker>Probst, Levin, 2002</marker>
<rawString>K. Probst and L. Levin. 2002. Challenges in automatic elicitation of a controlled bilingual corpus. In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>J Dowding</author>
</authors>
<title>An open source environment for compiling typed unification grammars into speech recognisers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th EACL (demo track),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="6782" citStr="Rayner et al., 2003" startWordPosition="1016" endWordPosition="1019">history of sinus disease” “have you had an e c g” Table 1: Examples of English MedSLT coverage duce a stable set of rules. As Probst and Levin suggest, one obvious way to attack the problem is to implement a (formal or informal) elicitation strategy, which biases the informant towards translations which are consistent with the existing ones. This is the approach we have adopted in MedSLT. The Regulus platform, on which MedSLT is based, supports rapid construction of complex grammar-based language models; it uses an example-based method driven by small corpora of disambiguated parsed examples (Rayner et al., 2003; Rayner et al., 2006), which extracts most of the structure of the model from a general linguistically motivated resource grammar. The result is a specialised version of the general grammar, tailored to the example corpus, which can then be compiled into an efficient recogniser or into a generaLanguage Vocab WER SemER English 441 6% 18% French 1025 8% 10% Japanese 347 4% 4% Table 2: Recognition performance for English, French and Japanese headache-domain recognisers. “Vocab” = number of surface words in source language recogniser vocabulary; “WER” = Word Error Rate for source language recogni</context>
</contexts>
<marker>Rayner, Hockey, Dowding, 2003</marker>
<rawString>M. Rayner, B.A. Hockey, and J. Dowding. 2003. An open source environment for compiling typed unification grammars into speech recognisers. In Proceedings of the 10th EACL (demo track), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>N Chatzichrisafis</author>
<author>B A Hockey</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>H Isahara</author>
<author>K Kankazi</author>
<author>Y Nakao</author>
</authors>
<title>A methodology for comparing grammar-based and robust approaches to speech understanding.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th International Conference on Spoken Language Processing (ICSLP),</booktitle>
<location>Lisboa, Portugal.</location>
<contexts>
<context position="2741" citStr="Rayner et al., 2005" startWordPosition="362" endWordPosition="365">The demo will show how MedSLT can be used to carry out non-trivial diagnostic dialogues. In particular, we will demonstrate how an integrated intelligent help system counteracts the brittleness inherent in rule-based processing, and rapidly leads new users towards the supported system coverage. We will also demo the development environment, and show how grammars and sets of transfer rules can be efficiently constructed from small corpora of a few hundred to a thousand examples. 2 The MedSLT system The MedSLT demonstrator has already been extensively described elsewhere (Bouillon et al., 2005; Rayner et al., 2005a), so this section will only present a brief summary. The main components are a set of speech recognisers for the source languages, a set of generators for the target languages, a translation engine, sets of rules for translating to and from interlingua, a simple discourse engine for dealing with context-dependent translation, and a top-level which manages the information flow between the other modules and the user. MedSLT also includes an intelligent help module, which adds robustness to the system and guides the user towards the supported coverage. The help module uses a backup recogniser, </context>
<context position="8190" citStr="Rayner et al., 2005" startWordPosition="1229" endWordPosition="1232">in, and grammar structure is shared automatically across different subdomains. Resource grammars are available for several languages, including English, Japanese, French and Spanish. Nuance recognisers derived from the resource grammars produce both a recognition string and a semantic representation. This representation consists of a list of key/value pairs, optionally including one level of nesting; the format of interlingua and target language representations is similar. The formalism is sufficiently expressive that a reasonable range of temporal and causal constructions can be represented (Rayner et al., 2005b). A typical example is shown in Figure 1. A translation rule maps a list of key/value pairs to a list of key/value pairs, optionally specifying conditions requiring that other key/value pairs either be present or absent in the source representation. When developing new coverage for a given language pair, the developer has two main tasks. First, they need to add new training examples to the corpora used to derive the specialised grammars used for the source and target languages; second, they must add translation rules to handle the new key/value pairs. The simple structure of the MedSLT repre</context>
</contexts>
<marker>Rayner, Bouillon, Chatzichrisafis, Hockey, Santaholma, Starlander, Isahara, Kankazi, Nakao, 2005</marker>
<rawString>M. Rayner, P. Bouillon, N. Chatzichrisafis, B.A. Hockey, M. Santaholma, M. Starlander, H. Isahara, K. Kankazi, and Y. Nakao. 2005a. A methodology for comparing grammar-based and robust approaches to speech understanding. In Proceedings of the 9th International Conference on Spoken Language Processing (ICSLP), Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>M Santaholma</author>
<author>Y Nakao</author>
</authors>
<title>Representational and architectural issues in a limited-domain medical speech translator.</title>
<date>2005</date>
<booktitle>In Proceedings of TALN/RECITAL,</booktitle>
<location>Dourdan, France.</location>
<contexts>
<context position="2741" citStr="Rayner et al., 2005" startWordPosition="362" endWordPosition="365">The demo will show how MedSLT can be used to carry out non-trivial diagnostic dialogues. In particular, we will demonstrate how an integrated intelligent help system counteracts the brittleness inherent in rule-based processing, and rapidly leads new users towards the supported system coverage. We will also demo the development environment, and show how grammars and sets of transfer rules can be efficiently constructed from small corpora of a few hundred to a thousand examples. 2 The MedSLT system The MedSLT demonstrator has already been extensively described elsewhere (Bouillon et al., 2005; Rayner et al., 2005a), so this section will only present a brief summary. The main components are a set of speech recognisers for the source languages, a set of generators for the target languages, a translation engine, sets of rules for translating to and from interlingua, a simple discourse engine for dealing with context-dependent translation, and a top-level which manages the information flow between the other modules and the user. MedSLT also includes an intelligent help module, which adds robustness to the system and guides the user towards the supported coverage. The help module uses a backup recogniser, </context>
<context position="8190" citStr="Rayner et al., 2005" startWordPosition="1229" endWordPosition="1232">in, and grammar structure is shared automatically across different subdomains. Resource grammars are available for several languages, including English, Japanese, French and Spanish. Nuance recognisers derived from the resource grammars produce both a recognition string and a semantic representation. This representation consists of a list of key/value pairs, optionally including one level of nesting; the format of interlingua and target language representations is similar. The formalism is sufficiently expressive that a reasonable range of temporal and causal constructions can be represented (Rayner et al., 2005b). A typical example is shown in Figure 1. A translation rule maps a list of key/value pairs to a list of key/value pairs, optionally specifying conditions requiring that other key/value pairs either be present or absent in the source representation. When developing new coverage for a given language pair, the developer has two main tasks. First, they need to add new training examples to the corpora used to derive the specialised grammars used for the source and target languages; second, they must add translation rules to handle the new key/value pairs. The simple structure of the MedSLT repre</context>
</contexts>
<marker>Rayner, Bouillon, Santaholma, Nakao, 2005</marker>
<rawString>M. Rayner, P. Bouillon, M. Santaholma, and Y. Nakao. 2005b. Representational and architectural issues in a limited-domain medical speech translator. In Proceedings of TALN/RECITAL, Dourdan, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>P Bouillon</author>
</authors>
<title>Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler.</title>
<date>2006</date>
<publisher>CSLI Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="6804" citStr="Rayner et al., 2006" startWordPosition="1020" endWordPosition="1023">ase” “have you had an e c g” Table 1: Examples of English MedSLT coverage duce a stable set of rules. As Probst and Levin suggest, one obvious way to attack the problem is to implement a (formal or informal) elicitation strategy, which biases the informant towards translations which are consistent with the existing ones. This is the approach we have adopted in MedSLT. The Regulus platform, on which MedSLT is based, supports rapid construction of complex grammar-based language models; it uses an example-based method driven by small corpora of disambiguated parsed examples (Rayner et al., 2003; Rayner et al., 2006), which extracts most of the structure of the model from a general linguistically motivated resource grammar. The result is a specialised version of the general grammar, tailored to the example corpus, which can then be compiled into an efficient recogniser or into a generaLanguage Vocab WER SemER English 441 6% 18% French 1025 8% 10% Japanese 347 4% 4% Table 2: Recognition performance for English, French and Japanese headache-domain recognisers. “Vocab” = number of surface words in source language recogniser vocabulary; “WER” = Word Error Rate for source language recogniser, on in-coverage ma</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2006</marker>
<rawString>M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler. CSLI Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regulus</author>
</authors>
<title>http://sourceforge.net/projects/regulus/.</title>
<date>2006</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="1997" citStr="Regulus, 2006" startWordPosition="246" endWordPosition="247">ill a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be used to carry out non-trivial diagnostic dialogues. In particular, we will demonstrate how an integrated intelligent help system counteracts the brittleness inherent in rule-based processing, and rapidly leads new users towards the supported system coverage. We will also demo the development environment, and show how grammars and sets of transfer rules can be efficiently constructed from small corpora of a few hundred to a thousand ex</context>
</contexts>
<marker>Regulus, 2006</marker>
<rawString>Regulus, 2006. http://sourceforge.net/projects/regulus/. As of 15 March 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-MINDS</author>
</authors>
<title>http://www.sehda.com.</title>
<date>2006</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="1558" citStr="S-MINDS, 2006" startWordPosition="184" endWordPosition="185">ains. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo both the system itself and the development environment, which uses a combination of rule-based and data-driven methods to construct efficient recognisers, generators and transfer rule sets from small corpora. 1 Overview The mainstream in speech translation work is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarbased language models, and translation uses a rulebased interlingual framework. The system, including the development environment, is built on top of Regulus (Regulus, 2006), an Open Source platform for developing grammar-based speech applications, which in turn sits on top of the Nuance Toolkit. The demo will show how MedSLT can be</context>
</contexts>
<marker>S-MINDS, 2006</marker>
<rawString>S-MINDS, 2006. http://www.sehda.com. As of 15 March 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Starlander</author>
<author>P Bouillon</author>
<author>N Chatzichrisafis</author>
<author>M Santaholma</author>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>H Isahara</author>
<author>K Kanzaki</author>
<author>Y Nakao</author>
</authors>
<title>Practicing controlled language through a help system integrated into the medical speech translation system (MedSLT).</title>
<date>2005</date>
<booktitle>In Proceedings of the MT Summit X,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="4159" citStr="Starlander et al., 2005" startWordPosition="582" endWordPosition="585">us studies, we showed that the grammar-based recogniser performs much better than the statistical one on in-coverage utterances, but worse on out-of-coverage ones. Having the help system available approximately doubled the speed at which subjects learned, measured as the average difference in semantic error rate between the results for their first quarter-session and their last quartersession (Rayner et al., 2005a). It is also possible to recover from recognition errors by selecting a displayed help sentence; this typically increases the number of acceptably processed utterances by about 10% (Starlander et al., 2005). We will demo several versions of the system, using different source languages, target languages and subdomains. Coverage is based on standard examination questions obtained from doctors, and consists mainly of yes/no questions, though there is also support for WH-questions and elliptical utterances. Table 1 gives examples of the coverage in the Englishinput headache version, and Table 2 summarises recognition performance in this domain for the three main input languages. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. Japanese, </context>
</contexts>
<marker>Starlander, Bouillon, Chatzichrisafis, Santaholma, Rayner, Hockey, Isahara, Kanzaki, Nakao, 2005</marker>
<rawString>M. Starlander, P. Bouillon, N. Chatzichrisafis, M. Santaholma, M. Rayner, B.A. Hockey, H. Isahara, K. Kanzaki, and Y. Nakao. 2005. Practicing controlled language through a help system integrated into the medical speech translation system (MedSLT). In Proceedings of the MT Summit X, Phuket, Thailand.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>