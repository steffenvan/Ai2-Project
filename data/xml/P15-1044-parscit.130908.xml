<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000269">
<title confidence="0.981776">
Training a Natural Language Generator From Unaligned Data
</title>
<author confidence="0.984403">
Ondˇrej Dušek and Filip Jurˇcíˇcek
</author>
<affiliation confidence="0.974155">
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
</affiliation>
<address confidence="0.837391">
Malostranské námˇestí 25, CZ-11800 Prague, Czech Republic
</address>
<email confidence="0.997877">
{odusek,jurcicek}@ufal.mff.cuni.cz
</email>
<sectionHeader confidence="0.99737" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999795">
We present a novel syntax-based natural
language generation system that is train-
able from unaligned pairs of input mean-
ing representations and output sentences.
It is divided into sentence planning, which
incrementally builds deep-syntactic de-
pendency trees, and surface realization.
Sentence planner is based on A* search
with a perceptron ranker that uses novel
differing subtree updates and a simple fu-
ture promise estimation; surface realiza-
tion uses a rule-based pipeline from the
Treex NLP toolkit.
Our first results show that training from
unaligned data is feasible, the outputs of
our generator are mostly fluent and rele-
vant.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957355555556">
We present a novel approach to natural lan-
guage generation (NLG) that does not require fine-
grained alignment in training data and uses deep
dependency syntax for sentence plans. We include
our first results on the BAGEL restaurant recom-
mendation data set of Mairesse et al. (2010).
In our setting, the task of a natural language
generator is that of converting an abstract meaning
representation (MR) into a natural language utter-
ance. This corresponds to the sentence planning
and surface realization NLG stages as described
by Reiter and Dale (2000). It also reflects the in-
tended usage in a spoken dialogue system (SDS),
where the NLG component is supposed to trans-
late a system output action into a sentence. While
the content planning NLG stage has been used in
SDS (e.g., Rieser and Lemon (2010)), we believe
that deciding upon the contents of the system’s ut-
terance is generally a task for the dialogue man-
ager. We focus mainly on the sentence planning
part in this work, and reuse an existing rule-based
surface realizer to test the capabilities of the gen-
erator in an end-to-end setting.
Current NLG systems usually require a sepa-
rate training data alignment step (Mairesse et al.,
2010; Konstas and Lapata, 2013). Many of them
use a CFG or operate in a phrase-based fashion
(Angeli et al., 2010; Mairesse et al., 2010), which
limits their ability to capture long-range syntactic
dependencies. Our generator includes alignment
learning into sentence planner training and uses
deep-syntactic trees with a rule-based surface re-
alization step, which ensures grammatical correct-
ness of the outputs. Unlike previous approaches
to trainable sentence planning (e.g., Walker et al.
(2001); Stent et al. (2004)), our generator does not
require a handcrafted base sentence planner.
This paper is structured as follows: in Section 2,
we describe the architecture of our generator. Sec-
tions 3 and 4 then provide further details on its
main components. In Section 5, we describe our
experiments on the BAGEL data set, followed by
an analysis of the results in Section 6. Section 7
compares our generator to previous related works
and Section 8 concludes the paper.
</bodyText>
<sectionHeader confidence="0.995974" genericHeader="introduction">
2 Generator Architecture
</sectionHeader>
<bodyText confidence="0.9999345">
Our generator (see Figure 1) operates in two stages
that roughly correspond to the traditional NLG
stages of sentence planning and surface realiza-
tion. In the first stage, a statistical sentence
planner generates deep-syntactic dependency trees
from the input meaning representation. These are
converted into plain text sentences in the second
stage by the (mostly rule-based) surface realizer.
We use deep-syntax dependency trees to repre-
sent the sentence plan, i.e. the intermediate data
structure between the two aforementioned stages.
These are ordered dependency trees that only con-
tain nodes for content words (nouns, full verbs, ad-
jectives, adverbs) and coordinating conjunctions.
</bodyText>
<page confidence="0.982434">
451
</page>
<note confidence="0.983983666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 451–461,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figure confidence="0.951951764705882">
meaning representation (dialogue acts)
inform(name=X, type=placetoeat,
eattype=restaurant, area=riverside,
food=Italian)
Agreement
Word ordering mostly
Compound rule-based
verb forms pipeline
(from Treex
NLP toolkit)
Grammatical
words
Punctuation
Word Inflection
Phonetic changes
plain text sentence
X is an italian restaurant by the river.
</figure>
<figureCaption confidence="0.999969">
Figure 1: Overall structure of our generator
</figureCaption>
<bodyText confidence="0.999358358974359">
Each node has a lemma and a formeme – a concise
description of its surface morphosyntactic form,
which may include prepositions and/or subordi-
nate conjunctions (Dušek et al., 2012). This struc-
ture is based on the deep-syntax trees of the Func-
tional Generative Description (Sgall et al., 1986),
but it has been simplified to fit our purposes (see
Figure 1 in the middle).
There are several reasons for taking the tra-
ditional two-step approach to generation (as op-
posed to joint approaches, see Section 7) and us-
ing deep syntax trees as the sentence plan format:
First, generating into deep syntax simplifies the
task for the statistical sentence planner – the plan-
ner does not need to handle surface morphology
and auxiliary words. Second, a rule-based syntac-
tic realizer allows us to ensure grammatical cor-
rectness of the output sentences, which would be
more difficult in a sequence-based and/or statisti-
cal approach.1 And third, a rule-based surface re-
alizer from our sentence plan format is relatively
easy to implement and can be reused for any do-
main within the same language. As in our case, it
is also possible to reuse and/or adapt an existing
surface realizer (see Section 4).
Deep-syntax annotation of sentences in the
training set is needed to train the sentence plan-
ner, but we assume automatic annotation and reuse
an existing deep-syntactic analyzer from the Treex
NLP framework (Popel and Žabokrtský, 2010).2
We use dialogue acts (DA) as defined in the
BAGEL restaurant data set of Mairesse et al.
(2010) as a MR in our experiments throughout this
paper. Here, a DA consists of a dialogue act type,
which is always “inform” in the set, and a list of
slot-value pairs (SVPs) that contain information
about a restaurant, such as food type or location
(see the top of Figure 1). Our generator can be
easily adapted to a different MR, though.
</bodyText>
<sectionHeader confidence="0.929298" genericHeader="method">
3 Sentence Planner
</sectionHeader>
<bodyText confidence="0.9990191">
The sentence planner is based on a variant of the
A* algorithm (Hart et al., 1968; Och et al., 2001;
Koehn et al., 2003). It starts from an empty sen-
tence plan tree and tries to find a path to the opti-
mal sentence plan by iteratively adding nodes. It
keeps two sets of hypotheses, i.e., candidate sen-
tence plan trees, sorted by their score – hypotheses
to expand (open set) and already expanded (closed
set). It uses the following two subcomponents to
guide the search:
</bodyText>
<listItem confidence="0.995508666666667">
• a candidate generator that is able to incre-
mentally generate candidate sentence plan
trees (see Section 3.1),
• a scorer/ranker that scores the appropriate-
ness of these trees for the input MR (see Sec-
tion 3.2).
</listItem>
<footnote confidence="0.998838875">
1This issue would become more pressing in languages
with richer morphology than English.
2See http://ufal.mff.cuni.cz/treex. Domain-
independent deep syntax analysis for several languages is
included in this framework; the English pipeline used here
involves a statistical part-of-speech tagger (Spoustová et al.,
2007) and a dependency parser (McDonald et al., 2005), fol-
lowed by a rule-based conversion to deep syntax trees.
</footnote>
<figure confidence="0.996892222222222">
candidate
generator
A* search
expand candidate
sentence plan tree
into new candidates
scorer
score candidates
to select next one
to be expanded
t-tree
sentence plan
(deep syntax tree)
be
v:fin
X-name
n:subj
italian
adj:attr
restaurant
n:obj
river
n:by+X
Sentence
planner
Surface
realizer
</figure>
<page confidence="0.931823">
452
</page>
<figureCaption confidence="0.985447">
Figure 2: Candidate generator example inputs and
outputs
</figureCaption>
<bodyText confidence="0.902019285714286">
The basic workflow of the sentence planner al-
gorithm then looks as follows:
Init: Start from an open set with a single empty
sentence plan tree and an empty closed set.
Loop: 1. Select the best-scoring candidate C
from the open set. Add C to closed
set.
</bodyText>
<listItem confidence="0.947285916666667">
2. The candidate generator generates C,
a set of possible successors to C.
These are trees that have more nodes
than C and are deemed viable. Note
that C may be empty.
3. The scorer scores all successors in
C and if they are not already in the
closed set, it adds them to the open
set.
4. Check if the best successor in the
open set scores better than the best
candidate in the closed set.
</listItem>
<bodyText confidence="0.999265666666666">
Stop: The algorithm finishes if the top score in
the open set is lower than the top score in
the closed set for d consecutive iterations,
or if there are no more candidates in the
open set. It returns the best-scoring candi-
date from both sets.
</bodyText>
<subsectionHeader confidence="0.999785">
3.1 Generating Sentence Plan Candidates
</subsectionHeader>
<bodyText confidence="0.995095181818182">
Given a sentence plan tree, which is typically in-
complete and may be even empty, the candidate
generator generates its successors by adding one
new node in all possible positions and with all pos-
sible lemmas and formemes (see Figure 2). While
a naive implementation – trying out any combina-
tion of lemmas and formemes found in the training
data – works in principle, it leads to an unman-
ageable number of candidate trees even for a very
small domain. Therefore, we include several rules
that limit the number of trees generated:
</bodyText>
<listItem confidence="0.998297769230769">
1. Lemma-formeme compatibility – only nodes
with a combination of lemma and formeme
seen in the training data are generated.
2. Syntactic viability – the new node must
be compatible with its parent node (i.e.,
this combination, including the dependency
left/right direction, must be seen in the train-
ing data).
3. Number of children – no node can have more
children than the maximum for this lemma-
formeme combination seen in the training
data.
4. Tree size – the generated tree cannot have
</listItem>
<bodyText confidence="0.653765555555555">
more nodes than trees seen in the training
data. The same limitation applies to the in-
dividual depth levels – the training data limit
the number of nodes on the n-th depth level
as well as the maximum depth of any tree.
This is further conditioned on the input SVPs
– the maximums are only taken from training
examples that contain the same SVPs that ap-
pear on the current input.
</bodyText>
<listItem confidence="0.992711538461538">
5. Weak semantic compatibility – we only in-
clude nodes that appear in the training data
alongside the elements of the input DA, i.e.,
nodes that appear in training examples con-
taining SVPs from the current input,
6. Strong semantic compatibility – for each
node (lemma and formeme), we make a
“compatibility list” of SVPs and slots that are
present in all training data examples contain-
ing this node. We then only allow generating
this node if all of them are present in the cur-
rent input DA. To allow for more generaliza-
tion, this rule can be applied just to lemmas
</listItem>
<figure confidence="0.99980324">
X-name
n:subj
X-name
n:subj
restaurant
n:obj
X-name
n:subj
bar
n:obj
be
v:fin
X-name
n:subj
restaurant
n:subj
restaurant
n:obj
t-tree
t-tree
t-tree
t-tree
Original sentence
plan tree:
Its successors (selection):
recommend
v:fin
be
v:fin
serve
v:fin
t-tree
t-tree
t-tree
t-tree
be
v:fin
be
v:fin
be
v:fin
t-tree
be
v:fin
be
v:fin
be
v:fin
t-tree
t-tree
</figure>
<page confidence="0.998494">
453
</page>
<bodyText confidence="0.99985795">
(disregarding formemes), and a certain num-
ber of SVPs/slots from the compatibility list
may be required at maximum.
Only Rules 4 (partly), 5, and 6 depend on the
format of the input meaning representation. Using
a different MR would require changing these rules
to work with atomic substructures of the new MR
instead of SVPs.
While especially Rules 5 and 6 exclude a vast
number of potential candidate trees, this limitation
is still much weaker than using hard alignment
links between the elements of the MR and the out-
put words or phrases. It leaves enough room to
generate many combinations unseen in the train-
ing data (cf. Section 6) while keeping the search
space manageable. To limit the space of potential
tree candidates even further, one could also use au-
tomatic alignment scores between the elements of
the input MR and the tree nodes (obtained using a
tool such as GIZA++ (Och and Ney, 2003)).
</bodyText>
<subsectionHeader confidence="0.999954">
3.2 Scoring Sentence Plan Trees
</subsectionHeader>
<bodyText confidence="0.999960625">
The scorer for the individual sentence plan tree
candidates is a function that maps global features
from the whole sentence plan tree t and the input
MR m to a real-valued score that describes the fit-
ness of t in the context of m.
We first describe the basic version of the scorer
and then our two improvements – differing subtree
updates and future promise estimation.
</bodyText>
<subsectionHeader confidence="0.853601">
Basic perceptron scorer
</subsectionHeader>
<bodyText confidence="0.99997375">
The basic scorer is based on the linear percep-
tron ranker of Collins and Duffy (2002), where the
score is computed as a simple dot product of the
features and the corresponding weight vector:
</bodyText>
<equation confidence="0.543026">
score(t, m) = wT · feat(t, m)
</equation>
<bodyText confidence="0.9972135">
In the training phase, the weights w are ini-
tialized to one. For each input MR, the system
tries to generate the best sentence plan tree given
current weights, ttop. The score of this tree is
then compared to the score of the correct gold-
standard tree tgold.3 If ttop =� tgold and the
gold-standard tree ranks worse than the generated
one (score(ttop, m) &gt; score(tgold, m)), the weight
vector is updated by the feature value difference of
3Note that the “gold-standard” sentence plan trees are ac-
tually produced by automatic annotation. For the purposes of
scoring, they are, however, treated as gold standard.
the generated and the gold-standard tree:
w = w + α · (feat(tgold, m) − feat(ttop, m))
where α is a predefined learning rate.
Differing subtree updates
In the basic version described above, the scorer is
trained to score full sentence plan trees. However,
it is also used to score incomplete sentence plans
during the decoding. This leads to a bias towards
bigger trees regardless of their fitness for the input
MR. Therefore, we introduced a novel modifica-
tion of the perceptron updates to improve scoring
of incomplete sentence plans: In addition to up-
dating the weights using the top-scoring candidate
ttop and the gold-standard tree tgold (see above),
we also use their differing subtrees titop, tigold for
additional updates.
Starting from the common subtree tc of ttop and
tgold, pairs of differing subtrees titop, tigold are cre-
ated by gradually adding nodes from ttop into titop
and from tgold into tigold (see Figure 3). To main-
tain the symmetry of the updates in case that the
sizes of ttop and tgold differ, more nodes may be
added in one step.4 The additional updates then
look as follows:
</bodyText>
<equation confidence="0.999116571428572">
t0top = t0gold = tc
for i in 1,... minfIttopl − Itc1, Itgoldl − 1tc11 − 1 :
titop = titop
− + node(s) from ttop
tigold = ti−1
gold + node(s) from tgold
w = w + α · (feat(tigold, m) − feat(titop, m))
</equation>
<bodyText confidence="0.995664875">
Future promise estimation
To further improve scoring of incomplete sentence
plan trees, we incorporate a simple future promise
estimation for the A* search intended to boost
scores of sentence plans that are expected to fur-
ther grow.5 It is based on the expected number
of children Ec(n) of different node types (lemma-
formeme pairs).6 Given all nodes ni ... njtj in a
</bodyText>
<footnote confidence="0.682597769230769">
4For example, if tgold has 6 more nodes than tc and ttop
has 4 more, there will be 3 pairs of differing subtrees, with
tigold having 2, 4, and 5 more nodes than tc and titop having
1, 2, and 3 more nodes than tc.
We have also evaluated a variant where both sets of sub-
trees tigold, titop were not equal in size, but this resulted in
degraded performance.
5Note that this is not the same as future path cost in
the original A* path search, but it plays an analogous role:
weighing hypotheses of different size.
6Ec(n) is measured as the average number of children
over all occurrences of the given node type in the training
data. It is expected to be domain-specific.
</footnote>
<page confidence="0.996709">
454
</page>
<figure confidence="0.997259192982456">
Top generated ttop:
Gold standard tgold:
t-tree
t-tree
cheap
adj:attr
italian
adj:attr
restaurant
n:obj
X
n:subj
be
v:fin
be
v:fin
X
n:subj
restaurant
n:obj
range
n:in+X
price
n:attr
Common subtree tc: Differing subtrees for update:
restaurant
n:obj
X
n:subj
be
v:fin
cheap
adj:attr
t1 t1
-
gold top
t-tree
+
t-tree
t-tree
restaurant
n:obj
X
n:subj
be
v:fin
be
v:fin
X
n:subj
restaurant
n:obj
range
price
n:attr
moderate
adj:attr
</figure>
<figureCaption confidence="0.999263">
Figure 3: An example of differing subtrees
</figureCaption>
<bodyText confidence="0.811373">
The gold standard tree tgold has three more nodes than the common subtree tc, while the top generated tree ttop has two more.
Only one pair of differing subtrees t1gold, t1top is built, where two nodes are added into t1gold and one node into t1top.
sentence plan tree t, the future promise is com-
puted in the following way:
</bodyText>
<equation confidence="0.689544">
max{0, Ec(ni) − c(ni)}
</equation>
<bodyText confidence="0.999227842105263">
where c(ni) is the current number of children of
node ni, A is a preset weight parameter, and E w
is the sum of the current perceptron weights. Mul-
tiplying by the weights sum makes future promise
values comparable to trees scores.
Future promise is added to tree scores through-
out the tree generation process, but it is disre-
garded for the termination criterion in the Stop
step of the generation algorithm and in perceptron
weight updates.
Averaging weights and parallel training
To speed up training using parallel processing, we
use the iterative parameter mixing approach of
McDonald et al. (2010), where training data are
split into several parts and weight updates are av-
eraged after each pass through the training data.
Following Collins (2002), we record the weights
after each training pass, take an average at the end,
and use this as the final weights for prediction.
</bodyText>
<sectionHeader confidence="0.964638" genericHeader="method">
4 Surface Realizer
</sectionHeader>
<bodyText confidence="0.935960285714286">
We use the English surface realizer from the Treex
NLP toolkit (cf. Section 2 and (Ptáˇcek, 2008)). It
is a simple pipeline of mostly rule-based blocks
that gradually change the deep-syntactic trees into
surface dependency trees, which are then lin-
earized to sentences. It includes the following
steps:
</bodyText>
<listItem confidence="0.982385636363636">
• Agreement – morphological attributes of
some nodes are deduced based on agreement
with other nodes (such as in subject-predicate
agreement).
• Word ordering – the input trees are already
ordered, so only a few rules for grammatical
words are applied.
• Compound verb forms – additional verbal
nodes are added for verbal particles (infini-
tive or phrasal verbs) and for compound ex-
pressions of tense, mood, and modality.
• Grammatical words – prepositions, subordi-
nating conjunctions, negation particles, arti-
cles, and other grammatical words are added
into the sentence.
• Punctuation – nodes for commas, final punc-
tuation, quotes, and brackets are introduced.
• Word Inflection – words are inflected accord-
ing to the information from formemes and
agreement.
• Phonetic changes – English “a” becomes
“an” based on the following word.
</listItem>
<bodyText confidence="0.999928666666667">
The realizer is designed as domain-independent
and handles most English grammatical phenom-
ena. A simple “round-trip” test – using au-
tomatic analysis with subsequent generation –
reached a BLEU score (Papineni et al., 2002)
of 89.79% against the original sentences on the
whole BAGEL data set, showing only minor dif-
ferences between the input sentence and genera-
tion output (mostly in punctuation).
</bodyText>
<equation confidence="0.947687">
�fp = A · w ·
� Itl
i=1
</equation>
<page confidence="0.995805">
455
</page>
<figureCaption confidence="0.99743">
Figure 4: Coordination structures conversion:
original (left) and our format (right).
</figureCaption>
<sectionHeader confidence="0.997479" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999989333333333">
Here we describe the data set used in our experi-
ments, the needed preprocessing steps, and the set-
tings of our generator specific to the data set.
</bodyText>
<subsectionHeader confidence="0.993348">
5.1 Data set
</subsectionHeader>
<bodyText confidence="0.999835">
We performed our experiments on the BAGEL
data set of Mairesse et al. (2010), which fits
our usage scenario in a spoken dialogue sys-
tem and is freely available.7 It contains a to-
tal of 404 sentences from a restaurant informa-
tion domain (describing the restaurant location,
food type, etc.), which correspond to 202 dia-
logue acts, i.e., each dialogue act has two para-
phrases. Restaurant names, phone numbers, and
other “non-enumerable” properties are abstracted
– replaced by an “X” symbol – throughout the gen-
eration process. Note that while the data set con-
tains alignment of source SVPs to target phrases,
we do not use it in our experiments.
For sentence planner training, we automatically
annotate all the sentences using the Treex deep
syntactic analyzer (see Section 2). The annotation
obtained from the Treex analyzer is further simpli-
fied for the sentence planner in two ways:
</bodyText>
<listItem confidence="0.971883555555556">
• Only lemmas and formemes are used in the
sentence planner. Other node attributes are
added in the surface realization step (see Sec-
tion 5.2).
• We convert the representation of coordination
structures into a format inspired by Universal
Dependencies.8 In the original Treex anno-
tation style, the conjunction heads both con-
juncts, whereas in our modification, the first
</listItem>
<footnote confidence="0.943273333333333">
7Available for download at: http://farm2.user.
srcf.net/research/bagel/.
8http://universaldependencies.github.io
</footnote>
<bodyText confidence="0.998836285714286">
conjunct is at the top, heading the coordina-
tion and the second conjunct (see Figure 4).
The coordinations can be easily converted back for
the surface realizer, and the change makes the task
easier for the sentence planner: it may first gener-
ate one node and then decide whether it will add a
conjunction and a second conjunct.
</bodyText>
<subsectionHeader confidence="0.997697">
5.2 Generator settings
</subsectionHeader>
<bodyText confidence="0.999415857142857">
In our candidate generator, we use all the limita-
tion heuristics described in Section 3.1. For strong
semantic compatibility (Rule 6), we use just lem-
mas and require at most 5 SVPs/slots from the
lemma’s compatibility list in the input DA.
We use the following feature types for our sen-
tence planner scorer:
</bodyText>
<listItem confidence="0.998137863636364">
• current tree properties – tree depth, total
number of nodes, number of repeated nodes
• tree and input DA – number of nodes per SVP
and number of repeated nodes per repeated
SVP,
• node features – lemma, formeme, and num-
ber of children of all nodes in the current tree,
and combinations thereof,
• input features – whole SVPs (slot + value),
just slots, and pairs of slots in the DA,
• combinations of node and input features,
• repeat features – occurrence of repeated lem-
mas and/or formemes in the current tree com-
bined with repeated slots in the input DA,
• dependency features – parent-child pairs for
lemmas and/or formemes, including and ex-
cluding their left-right order,
• sibling features – sibling pairs for lemmas
and/or formemes, also combined with SVPs,
• bigram features – pairs of lemmas and/or
formemes adjacent in the tree’s left-right or-
der, also combined with SVPs.
</listItem>
<bodyText confidence="0.999075857142857">
All feature values are normalized to have a mean
of 0 and a standard deviation of 1, with normaliza-
tion coefficients estimated from training data.
The feature set can be adapted for a different
MR format – it only must capture all important
parts of the MR, e.g., for a tree-like MR, the nodes
and edges, and possibly combinations thereof.
</bodyText>
<figure confidence="0.9926299">
X-area X-area and X-area
n:in+X n:in+X x n:in+X
restaurant
n:obj
X-area
n:in+X
restaurant
n:obj
and
x
</figure>
<page confidence="0.997368">
456
</page>
<table confidence="0.9999278">
Setup 10% BLEU for training portion 100% 10% NIST for training portion 100%
20% 30% 50% 20% 30% 50%
Basic perc. 46.90 52.81 55.43 54.53 54.24 4.295 4.652 4.669 4.758 4.643
+ Diff-tree upd. 44.16 50.86 53.61 55.71 58.70 3.846 4.406 4.532 4.674 4.876
+ Future promise 37.25 53.57 53.80 58.15 59.89 3.331 4.549 4.607 5.071 5.231
</table>
<tableCaption confidence="0.999965">
Table 1: Evaluation on the BAGEL data set (averaged over all ten cross-validation folds)
</tableCaption>
<bodyText confidence="0.9976558">
“Training portion” denotes the percentage of the training data used in the experiment. “Basic perc.” = basic perceptron updates,
“+ Diff-tree upd.” = with differing subtree perceptron updates, “+ Future promise” = with future promise estimation. BLEU
scores are shown as percentages.
Based on our preliminary experiments, we use
100 passes over the training data and limit the
number of iterations d that do not improve score
to 3 for training and 4 for testing. We use a hard
maximum of 200 sentence planner iterations per
input DA. The learning rate α is set to 0.1. We use
training data parts of 36 or 37 training examples
(1/10th of the full training set) in parallel training.
If future promise is used, its weight λ is set to 0.3.
The Treex English realizer expects not only
lemmas and formemes, but also additional gram-
matical attributes for all nodes. In our experi-
ments, we simply use the most common values
found in the training data for the particular nodes
as this is sufficient for our domain. In larger do-
mains, some of these attributes may have to be also
included in sentence plans.
</bodyText>
<sectionHeader confidence="0.999831" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999982421052632">
Same as Mairesse et al. (2010), we use 10-fold
cross-validation where DAs seen at training time
are never used for testing, i.e., both paraphrases or
none of them are present in the full training set.
We evaluate using BLEU and NIST scores (Pap-
ineni et al., 2002; Doddington, 2002) against both
reference paraphrases for a given test DA.
The results of our generator are shown in Ta-
ble 1, both for standard perceptron updates and our
improvements – differing subtree updates and fu-
ture promise estimation (see Section 3.2).
Our generator did not achieve the same perfor-
mance as that of Mairesse et al. (2010) (ca. 67%).9
However, our task is substantially harder since
the generator also needs to learn the alignment
of phrases to SVPs and determine whether all re-
quired information is present on the output (see
also Section 7). Our differing tree updates clearly
bring a substantial improvement over standard per-
</bodyText>
<footnote confidence="0.6810065">
9Mairesse et al. (2010) do not give a precise BLEU score
number in their paper, they only show the values in a graph.
</footnote>
<bodyText confidence="0.9931412">
ceptron updates, and scores keep increasing with
bigger amounts of training data used, whereas
with plain perceptron updates, the scores stay flat.
The increase with 100% is smaller since all train-
ing DAs are in fact used twice, each time with a
different paraphrase.10 A larger training set with
different DAs should bring a bigger improvement.
Using future promise estimation boosts the scores
even further, by a smaller amount for BLEU but
noticeably for NIST. Both improvements on the
full training set are considered statistically signif-
icant at 95% confidence level by the paired boot-
strap resampling test (Koehn, 2004). A manual in-
spection of a small sample of the results confirmed
that the automatic scores reflect the quality of the
generated sentences well.
If we look closer at the generated sentences (see
Table 2), it becomes clear that the generator learns
to produce meaningful utterances which mostly
correspond well to the input DA. It is able to pro-
duce original paraphrases and generalizes to pre-
viously unseen DAs.
On the other hand, not all required information
is always present, and some facts are sometimes
repeated or irrelevant information appears. This
mostly happens with input slot-value pairs that oc-
cur only rarely in the training data; we believe that
a larger training set will solve this problem. Alter-
natively, one could introduce additional scorer fea-
tures to discourage conflicting information. An-
other problem is posed by repeated slots in the in-
put DA, which are sometimes not reflected prop-
erly in the generated sentence. This suggests that
a further refinement of the scorer feature set may
be needed.
10We used the two paraphrases that come with each DA
as independent training instances. While having two differ-
ent gold-standard outputs for a single input is admittedly not
ideal for a discriminative learner, it still brings an improve-
ment in our case.
</bodyText>
<page confidence="0.97129">
457
</page>
<equation confidence="0.978336916666667">
Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, near=X-near, food=Continental, food=French)
Reference X is a French and continental restaurant near X.
Generated X is a French and continental restaurant near X.
Input DA inform(name=X-name, type=placetoeat, area=riverside, near=X-near, eattype=restaurant)
Reference X restaurant is near X on the riverside.
Generated X is a restaurant in the riverside area near X.
Input DA inform(name=X-name, type=placetoeat, area=X-area, pricerange=moderate, eattype=restaurant)
Reference X is a moderately priced restaurant in X.
Generated X is a restaurant in the X area.
Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, area=riverside, food=French)
Reference X is a French restaurant on the riverside.
Generated X is a French restaurant in the riverside area which serves French food.
Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, pricerange=moderate,
area=X-area, food=Contemporary, food=English)
Reference X is a moderately priced English contemporary restaurant in X.
Generated X is an English restaurant in the X area which serves expensive food in the moderate price range
located in X.
Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, area=citycentre, near=X-near,
food=&amp;quot;Chinese takeaway&amp;quot;, food=Japanese)
Reference X is a Chinese takeaway and Japanese restaurant in the city centre near X.
Generated X is a Japanese restaurant in the centre of town near X and X.
Input DA inform(name=X-name, type=placetoeat, pricerange=moderate, eattype=restaurant)
Reference X is a restaurant that offers moderate price range.
Generated X is a restaurant in the moderate price range.
</equation>
<tableCaption confidence="0.885134">
Table 2: Example generated sentences
Sentences generated when training on the full set and using differing subtree updates and future promise estimation.
</tableCaption>
<sectionHeader confidence="0.999626" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999876228070176">
Previous trainable methods in sentence planning
use in principle two techniques: First, in the over-
generation and ranking approach (Walker et al.,
2001; Stent et al., 2004), many sentence plans are
generated using a rule-based planner and then the
best one is selected by a statistical ranker. Second,
parameter optimization trains adjustable parame-
ters of a handcrafted generator to produce outputs
with desired properties (Paiva and Evans, 2005;
Mairesse and Walker, 2008). As opposed to our
approach, both methods require an existing hand-
crafted sentence planner.
Other previous works combine sentence plan-
ning and surface realization into a single step and
do not require a handcrafted base module. Wong
and Mooney (2007) experiment with a phrase-
based machine translation system, comparing and
combining it with an inverted semantic parser
based on synchronous context-free grammars. Lu
et al. (2009) use tree conditional random fields
over hybrid trees that combine natural language
phrases with formal semantic expressions. Angeli
et al. (2010) generate text from database records
through a sequence of classifiers, gradually se-
lecting database records, fields, and correspond-
ing textual realizations to describe them. Konstas
and Lapata (2013) recast the whole NLG problem
as parsing over a probabilistic context-free gram-
mar estimated from database records and their de-
scriptions. Mairesse et al. (2010) convert input
DAs into “semantic stacks”, which correspond to
natural language phrases and contain slots and
their values on top of each other. Their genera-
tion model uses two dynamic Bayesian networks:
the first one performs an ordering of the input se-
mantic stacks, inserting intermediary stacks which
correspond to grammatical phrases, the second
one then produces a concrete surface realization.
Dethlefs et al. (2013) approach generation as a
sequence labeling task and use a conditional ran-
dom field classifier, assigning a word or a phrase
to each input MR element.
Unlike our work, the joint approaches typi-
cally include the alignment of input MR elements
to output words in a separate preprocessing step
(Wong and Mooney, 2007; Angeli et al., 2010), or
require pre-aligned training data (Mairesse et al.,
2010; Dethlefs et al., 2013). In addition, their ba-
sic algorithm often requires a specific input MR
format, e.g., a tree (Wong and Mooney, 2007; Lu
et al., 2009) or a flat database (Angeli et al., 2010;
Konstas and Lapata, 2013; Mairesse et al., 2010).
While dependency-based deep syntax has been
used previously in statistical NLG, the approaches
known to us (Bohnet et al., 2010; Belz et al., 2012;
Ballesteros et al., 2014) focus only on the surface
realization step and do not include a sentence plan-
</bodyText>
<page confidence="0.996294">
458
</page>
<bodyText confidence="0.999986083333333">
ner, whereas our work is mainly focused on statis-
tical sentence planning and uses a rule-based real-
izer.
Our approach to sentence planning is most sim-
ilar to Zettlemoyer and Collins (2007), which use
a candidate generator and a perceptron ranker for
CCG parsing. Apart from proceeding in the in-
verse direction and using dependency trees, we use
only very generic rules in our candidate generator
instead of language-specific ones, and we incorpo-
rate differing subtree updates and future promise
estimation into our ranker.
</bodyText>
<sectionHeader confidence="0.994062" genericHeader="conclusions">
8 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.990089974358974">
We have presented a novel natural language gen-
erator, capable of learning from unaligned pairs
of input meaning representation and output utter-
ances. It consists of a novel, A*-search-based sen-
tence planner and a largely rule-based surface re-
alizer from the Treex NLP toolkit. The sentence
planner is, to our knowledge, first to use depen-
dency syntax and learn alignment of semantic el-
ements to words or phrases jointly with sentence
planning.
We tested our generator on the BAGEL restau-
rant information data set of Mairesse et al. (2010).
We have achieved very promising results, the ut-
terances produced by our generator are mostly flu-
ent and relevant. They did not surpass the BLEU
score of the original authors; however, our task is
substantially harder as our generator does not re-
quire fine-grained alignments on the input. Our
novel feature of the sentence planner ranker – us-
ing differing subtrees for perceptron weight up-
dates – has brought a significant performance im-
provement.
The generator source code, along with config-
uration files for experiments on the BAGEL data
set, is available for download on Github.11
In future work, we plan to evaluate our genera-
tor on further domains, such as geographic infor-
mation (Kate et al., 2005), weather reports (Liang
et al., 2009), or flight information (Dahl et al.,
1994). In order to improve the performance of our
generator and remove the dependency on domain-
specific features, we plan to replace the percep-
tron ranker with a neural network. We also want
to experiment with removing the dependency on
the Treex surface realizer by generating directly
into dependency trees or structures into which de-
11https://github.com/UFAL-DSG/tgen
pendency trees can be converted in a language-
independent way.
</bodyText>
<sectionHeader confidence="0.997722" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999978583333333">
This work was funded by the Ministry of Edu-
cation, Youth and Sports of the Czech Republic
under the grant agreement LK11221 and core re-
search funding, SVV project 260 104, and GAUK
grant 2058214 of Charles University in Prague. It
used language resources stored and distributed by
the LINDAT/CLARIN project of the Ministry of
Education, Youth and Sports of the Czech Repub-
lic (project LM2010013).
The authors would like to thank Lukáš Žilka,
Ondˇrej Plátek, and the anonymous reviewers for
helpful comments on the draft.
</bodyText>
<sectionHeader confidence="0.999397" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9988616">
G. Angeli, P. Liang, and D. Klein. 2010. A simple
domain-independent probabilistic approach to gen-
eration. In Proc. of the 2010 Conference on Empir-
ical Methods in Natural Language Processing, page
502–512.
M. Ballesteros, S. Mille, and L. Wanner. 2014.
Classifiers for data-driven deep sentence genera-
tion. In Proceedings of the 8th International Natural
Language Generation Conference, pages 108–112,
Philadelphia.
A. Belz, B. Bohnet, S. Mille, L. Wanner, and M. White.
2012. The Surface Realisation Task: Recent De-
velopments and Future Plans. In INLG 2012, pages
136–140.
B. Bohnet, L. Wanner, S. Mille, and A. Burga. 2010.
Broad coverage multilingual deep sentence genera-
tion with a stochastic multi-level realizer. In Proc.
of the 23rd International Conference on Computa-
tional Linguistics, page 98–106.
M. Collins and N. Duffy. 2002. New ranking algo-
rithms for parsing and tagging: Kernels over discrete
structures, and the voted perceptron. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, page 263–270, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
M. Collins. 2002. Discriminative training methods
for hidden Markov models: Theory and experiments
with perceptron algorithms. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing-Volume 10, page 1–8. Associa-
tion for Computational Linguistics.
D. A. Dahl, M. Bates, M. Brown, W. Fisher,
K. Hunicke-Smith, D. Pallett, E. Rudnicky, and
E. Shriberg. 1994. Expanding the scope of the ATIS
</reference>
<page confidence="0.995515">
459
</page>
<reference confidence="0.998911598130842">
task: the ATIS-3 corpus. In in Proc. ARPA Hu-
man Language Technology Workshop ’92, Plains-
boro, NJ, pages 43–48. Morgan Kaufmann.
N. Dethlefs, H. Hastie, H. Cuayáhuitl, and O. Lemon.
2013. Conditional Random Fields for Responsive
Surface Realisation using Global Features. In Pro-
ceedings ofACL, Sofia.
G. Doddington. 2002. Automatic evaluation
of machine translation quality using N-gram co-
occurrence statistics. In Proceedings of the Sec-
ond International Conference on Human Language
Technology Research, pages 138–145, San Fran-
cisco, CA, USA. Morgan Kaufmann Publishers Inc.
O. Du&amp;quot;sek, Z. Žabokrtský, M. Popel, M. Majli&amp;quot;s,
M. Novák, and D. Mareˇcek. 2012. Formemes
in English-Czech deep syntactic MT. In Proceed-
ings of the Seventh Workshop on Statistical Machine
Translation, page 267–274, Montreal.
P. E. Hart, N. J. Nilsson, and B. Raphael. 1968. A
formal basis for the heuristic determination of mini-
mum cost paths. IEEE Transactions on Systems Sci-
ence and Cybernetics, 4(2):100–107.
R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005.
Learning to transform natural to formal languages.
In Proceedings of the National Conference on Ar-
tificial Intelligence, volume 20. Menlo Park, CA;
Cambridge, MA; London; AAAI Press; MIT Press;
1999.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statis-
tical phrase-based translation. In Proceedings of
NAACL-HLT - Volume 1, page 48–54, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
P. Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP, page 388–395.
I. Konstas and M. Lapata. 2013. A global model for
concept-to-text generation. Journal of Artificial In-
telligence Research, 48:305–346.
P. Liang, M. I. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
Proceedings of the Joint Conference of the 47th An-
nual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
of the AFNLP: Volume 1-Volume 1, page 91–99.
W. Lu, H. T. Ng, and W. S. Lee. 2009. Natural
language generation with tree conditional random
fields. In Proc. of the 2009 Conference on Empir-
ical Methods in Natural Language Processing: Vol-
ume 1-Volume 1, page 400–409.
F. Mairesse and M. Walker. 2008. Trainable gen-
eration of big-five personality styles through data-
driven parameter estimation. In Proc. of the 46th
Annual Meeting of the ACL (ACL), page 165–173.
F. Mairesse, M. Ga&amp;quot;si´c, F. Jurˇcíˇcek, S. Keizer, B. Thom-
son, K. Yu, and S. Young. 2010. Phrase-based sta-
tistical language generation using graphical models
and active learning. In Proc. of the 48th Annual
Meeting of the ACL, page 1552–1561.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc.
2005. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
page 523–530.
R. McDonald, K. Hall, and G. Mann. 2010. Dis-
tributed training strategies for the structured percep-
tron. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 456–464. Association for Computational Lin-
guistics.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
F. J. Och, N. Ueffing, and H. Ney. 2001. An efficient
A* search algorithm for statistical machine trans-
lation. In Proceedings of the Workshop on Data-
driven Methods in Machine Translation - Volume 14,
page 1–8, Stroudsburg, PA, USA. Association for
Computational Linguistics.
D. S. Paiva and R. Evans. 2005. Empirically-based
control of natural language generation. In Proc.
of the 43rd Annual Meeting of ACL, page 58–65,
Stroudsburg, PA, USA. ACL.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
BLEU: a method for automatic evaluation of ma-
chine translation. In Proceedings of the 40th annual
meeting of the Association for Computational Lin-
guistics, page 311–318.
M. Popel and Z. Žabokrtský. 2010. TectoMT: modu-
lar NLP framework. In Proceedings of IceTAL, 7th
International Conference on Natural Language Pro-
cessing, page 293–304, Reykjavík.
J. Ptáˇcek. 2008. Two tectogrammatical realizers side
by side: Case of English and Czech. In Fourth In-
ternational Workshop on Human-Computer Conver-
sation, Bellagio, Italy.
E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge Univ. Press.
V. Rieser and O. Lemon. 2010. Natural language gen-
eration as planning under uncertainty for spoken dia-
logue systems. In Empirical methods in natural lan-
guage generation, page 105–120.
P. Sgall, E. Hajiˇcová, and J. Panevová. 1986. The
meaning of the sentence in its semantic and prag-
matic aspects. D. Reidel, Dordrecht.
</reference>
<page confidence="0.98926">
460
</page>
<reference confidence="0.999883392857143">
D. J. Spoustová, J. Hajiˇc, J. Votrubec, P. Krbec, and
P. Kvˇetoˇn. 2007. The Best of Two Worlds: Co-
operation of Statistical and Rule-based Taggers for
Czech. In Proceedings of the Workshop on Balto-
Slavonic Natural Language Processing: Informa-
tion Extraction and Enabling Technologies, pages
67–74. Association for Computational Linguistics.
A. Stent, R. Prasad, and M. Walker. 2004. Trainable
sentence planning for complex information presen-
tation in spoken dialog systems. In Proceedings of
the 42nd Annual Meeting on Association for Com-
putational Linguistics, pages 79–86.
M. A. Walker, O. Rambow, and M. Rogati. 2001.
SPoT: a trainable sentence planner. In Proc. of
2nd meeting of NAACL, page 1–8, Stroudsburg, PA,
USA. ACL.
Y. W. Wong and R. J. Mooney. 2007. Generation
by inverting a semantic parser that uses statistical
machine translation. In Proc. of Human Language
Technologies: The Conference of the North Amer-
ican Chapter of the ACL (NAACL-HLT-07), page
172–179.
L. S. Zettlemoyer and M. Collins. 2007. Online learn-
ing of relaxed CCG grammars for parsing to logi-
cal form. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 678–687, Prague.
</reference>
<page confidence="0.999433">
461
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.344665">
<title confidence="0.998911">Training a Natural Language Generator From Unaligned Data</title>
<author confidence="0.429225">Dušek</author>
<affiliation confidence="0.95955">Charles University in Prague, Faculty of Mathematics and Institute of Formal and Applied</affiliation>
<address confidence="0.962679">Malostranské námˇestí 25, CZ-11800 Prague, Czech</address>
<email confidence="0.966493">odusek@ufal.mff.cuni.cz</email>
<email confidence="0.966493">jurcicek@ufal.mff.cuni.cz</email>
<abstract confidence="0.991883888888889">We present a novel syntax-based natural language generation system that is trainable from unaligned pairs of input meaning representations and output sentences. It is divided into sentence planning, which incrementally builds deep-syntactic dependency trees, and surface realization. Sentence planner is based on A* search with a perceptron ranker that uses novel differing subtree updates and a simple future promise estimation; surface realization uses a rule-based pipeline from the Treex NLP toolkit. Our first results show that training from unaligned data is feasible, the outputs of our generator are mostly fluent and relevant.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Angeli</author>
<author>P Liang</author>
<author>D Klein</author>
</authors>
<title>A simple domain-independent probabilistic approach to generation.</title>
<date>2010</date>
<booktitle>In Proc. of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>502--512</pages>
<contexts>
<context position="2259" citStr="Angeli et al., 2010" startWordPosition="355" endWordPosition="358">put action into a sentence. While the content planning NLG stage has been used in SDS (e.g., Rieser and Lemon (2010)), we believe that deciding upon the contents of the system’s utterance is generally a task for the dialogue manager. We focus mainly on the sentence planning part in this work, and reuse an existing rule-based surface realizer to test the capabilities of the generator in an end-to-end setting. Current NLG systems usually require a separate training data alignment step (Mairesse et al., 2010; Konstas and Lapata, 2013). Many of them use a CFG or operate in a phrase-based fashion (Angeli et al., 2010; Mairesse et al., 2010), which limits their ability to capture long-range syntactic dependencies. Our generator includes alignment learning into sentence planner training and uses deep-syntactic trees with a rule-based surface realization step, which ensures grammatical correctness of the outputs. Unlike previous approaches to trainable sentence planning (e.g., Walker et al. (2001); Stent et al. (2004)), our generator does not require a handcrafted base sentence planner. This paper is structured as follows: in Section 2, we describe the architecture of our generator. Sections 3 and 4 then pro</context>
<context position="29837" citStr="Angeli et al. (2010)" startWordPosition="4900" endWordPosition="4903"> and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2010) generate text from database records through a sequence of classifiers, gradually selecting database records, fields, and corresponding textual realizations to describe them. Konstas and Lapata (2013) recast the whole NLG problem as parsing over a probabilistic context-free grammar estimated from database records and their descriptions. Mairesse et al. (2010) convert input DAs into “semantic stacks”, which correspond to natural language phrases and contain slots and their values on top of each other. Their generation model uses two dynamic Bayesian networks: the first one performs an ordering </context>
<context position="31214" citStr="Angeli et al., 2010" startWordPosition="5120" endWordPosition="5123">on. Dethlefs et al. (2013) approach generation as a sequence labeling task and use a conditional random field classifier, assigning a word or a phrase to each input MR element. Unlike our work, the joint approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG parsing. Apart from proceeding in the i</context>
</contexts>
<marker>Angeli, Liang, Klein, 2010</marker>
<rawString>G. Angeli, P. Liang, and D. Klein. 2010. A simple domain-independent probabilistic approach to generation. In Proc. of the 2010 Conference on Empirical Methods in Natural Language Processing, page 502–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ballesteros</author>
<author>S Mille</author>
<author>L Wanner</author>
</authors>
<title>Classifiers for data-driven deep sentence generation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Natural Language Generation Conference,</booktitle>
<pages>108--112</pages>
<location>Philadelphia.</location>
<contexts>
<context position="31439" citStr="Ballesteros et al., 2014" startWordPosition="5156" endWordPosition="5159">cally include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG parsing. Apart from proceeding in the inverse direction and using dependency trees, we use only very generic rules in our candidate generator instead of language-specific ones, and we incorporate differing subtree updates and future promise estimation into our ran</context>
</contexts>
<marker>Ballesteros, Mille, Wanner, 2014</marker>
<rawString>M. Ballesteros, S. Mille, and L. Wanner. 2014. Classifiers for data-driven deep sentence generation. In Proceedings of the 8th International Natural Language Generation Conference, pages 108–112, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Belz</author>
<author>B Bohnet</author>
<author>S Mille</author>
<author>L Wanner</author>
<author>M White</author>
</authors>
<title>The Surface Realisation Task: Recent Developments and Future Plans. In INLG</title>
<date>2012</date>
<pages>136--140</pages>
<contexts>
<context position="31412" citStr="Belz et al., 2012" startWordPosition="5152" endWordPosition="5155">int approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG parsing. Apart from proceeding in the inverse direction and using dependency trees, we use only very generic rules in our candidate generator instead of language-specific ones, and we incorporate differing subtree updates and future prom</context>
</contexts>
<marker>Belz, Bohnet, Mille, Wanner, White, 2012</marker>
<rawString>A. Belz, B. Bohnet, S. Mille, L. Wanner, and M. White. 2012. The Surface Realisation Task: Recent Developments and Future Plans. In INLG 2012, pages 136–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>L Wanner</author>
<author>S Mille</author>
<author>A Burga</author>
</authors>
<title>Broad coverage multilingual deep sentence generation with a stochastic multi-level realizer.</title>
<date>2010</date>
<booktitle>In Proc. of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>98--106</pages>
<contexts>
<context position="31393" citStr="Bohnet et al., 2010" startWordPosition="5148" endWordPosition="5151">like our work, the joint approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG parsing. Apart from proceeding in the inverse direction and using dependency trees, we use only very generic rules in our candidate generator instead of language-specific ones, and we incorporate differing subtree upda</context>
</contexts>
<marker>Bohnet, Wanner, Mille, Burga, 2010</marker>
<rawString>B. Bohnet, L. Wanner, S. Mille, and A. Burga. 2010. Broad coverage multilingual deep sentence generation with a stochastic multi-level realizer. In Proc. of the 23rd International Conference on Computational Linguistics, page 98–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12477" citStr="Collins and Duffy (2002)" startWordPosition="2050" endWordPosition="2053">ween the elements of the input MR and the tree nodes (obtained using a tool such as GIZA++ (Och and Ney, 2003)). 3.2 Scoring Sentence Plan Trees The scorer for the individual sentence plan tree candidates is a function that maps global features from the whole sentence plan tree t and the input MR m to a real-valued score that describes the fitness of t in the context of m. We first describe the basic version of the scorer and then our two improvements – differing subtree updates and future promise estimation. Basic perceptron scorer The basic scorer is based on the linear perceptron ranker of Collins and Duffy (2002), where the score is computed as a simple dot product of the features and the corresponding weight vector: score(t, m) = wT · feat(t, m) In the training phase, the weights w are initialized to one. For each input MR, the system tries to generate the best sentence plan tree given current weights, ttop. The score of this tree is then compared to the score of the correct goldstandard tree tgold.3 If ttop =� tgold and the gold-standard tree ranks worse than the generated one (score(ttop, m) &gt; score(tgold, m)), the weight vector is updated by the feature value difference of 3Note that the “gold-sta</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>M. Collins and N. Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, page 263–270, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>page</pages>
<contexts>
<context position="17136" citStr="Collins (2002)" startWordPosition="2866" endWordPosition="2867">ights. Multiplying by the weights sum makes future promise values comparable to trees scores. Future promise is added to tree scores throughout the tree generation process, but it is disregarded for the termination criterion in the Stop step of the generation algorithm and in perceptron weight updates. Averaging weights and parallel training To speed up training using parallel processing, we use the iterative parameter mixing approach of McDonald et al. (2010), where training data are split into several parts and weight updates are averaged after each pass through the training data. Following Collins (2002), we record the weights after each training pass, take an average at the end, and use this as the final weights for prediction. 4 Surface Realizer We use the English surface realizer from the Treex NLP toolkit (cf. Section 2 and (Ptáˇcek, 2008)). It is a simple pipeline of mostly rule-based blocks that gradually change the deep-syntactic trees into surface dependency trees, which are then linearized to sentences. It includes the following steps: • Agreement – morphological attributes of some nodes are deduced based on agreement with other nodes (such as in subject-predicate agreement). • Word </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, page 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Dahl</author>
<author>M Bates</author>
<author>M Brown</author>
<author>W Fisher</author>
<author>K Hunicke-Smith</author>
<author>D Pallett</author>
<author>E Rudnicky</author>
<author>E Shriberg</author>
</authors>
<title>Expanding the scope of the ATIS task: the ATIS-3 corpus.</title>
<date>1994</date>
<booktitle>In in Proc. ARPA Human Language Technology Workshop ’92, Plainsboro, NJ,</booktitle>
<pages>43--48</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="33400" citStr="Dahl et al., 1994" startWordPosition="5480" endWordPosition="5483">uthors; however, our task is substantially harder as our generator does not require fine-grained alignments on the input. Our novel feature of the sentence planner ranker – using differing subtrees for perceptron weight updates – has brought a significant performance improvement. The generator source code, along with configuration files for experiments on the BAGEL data set, is available for download on Github.11 In future work, we plan to evaluate our generator on further domains, such as geographic information (Kate et al., 2005), weather reports (Liang et al., 2009), or flight information (Dahl et al., 1994). In order to improve the performance of our generator and remove the dependency on domainspecific features, we plan to replace the perceptron ranker with a neural network. We also want to experiment with removing the dependency on the Treex surface realizer by generating directly into dependency trees or structures into which de11https://github.com/UFAL-DSG/tgen pendency trees can be converted in a languageindependent way. Acknowledgments This work was funded by the Ministry of Education, Youth and Sports of the Czech Republic under the grant agreement LK11221 and core research funding, SVV p</context>
</contexts>
<marker>Dahl, Bates, Brown, Fisher, Hunicke-Smith, Pallett, Rudnicky, Shriberg, 1994</marker>
<rawString>D. A. Dahl, M. Bates, M. Brown, W. Fisher, K. Hunicke-Smith, D. Pallett, E. Rudnicky, and E. Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In in Proc. ARPA Human Language Technology Workshop ’92, Plainsboro, NJ, pages 43–48. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Dethlefs</author>
<author>H Hastie</author>
<author>H Cuayáhuitl</author>
<author>O Lemon</author>
</authors>
<title>Conditional Random Fields for Responsive Surface Realisation using Global Features.</title>
<date>2013</date>
<booktitle>In Proceedings ofACL,</booktitle>
<location>Sofia.</location>
<contexts>
<context position="30621" citStr="Dethlefs et al. (2013)" startWordPosition="5018" endWordPosition="5021">scribe them. Konstas and Lapata (2013) recast the whole NLG problem as parsing over a probabilistic context-free grammar estimated from database records and their descriptions. Mairesse et al. (2010) convert input DAs into “semantic stacks”, which correspond to natural language phrases and contain slots and their values on top of each other. Their generation model uses two dynamic Bayesian networks: the first one performs an ordering of the input semantic stacks, inserting intermediary stacks which correspond to grammatical phrases, the second one then produces a concrete surface realization. Dethlefs et al. (2013) approach generation as a sequence labeling task and use a conditional random field classifier, assigning a word or a phrase to each input MR element. Unlike our work, the joint approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konst</context>
</contexts>
<marker>Dethlefs, Hastie, Cuayáhuitl, Lemon, 2013</marker>
<rawString>N. Dethlefs, H. Hastie, H. Cuayáhuitl, and O. Lemon. 2013. Conditional Random Fields for Responsive Surface Realisation using Global Features. In Proceedings ofACL, Sofia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using N-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Conference on Human Language Technology Research,</booktitle>
<pages>138--145</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="24280" citStr="Doddington, 2002" startWordPosition="4061" endWordPosition="4062">ot only lemmas and formemes, but also additional grammatical attributes for all nodes. In our experiments, we simply use the most common values found in the training data for the particular nodes as this is sufficient for our domain. In larger domains, some of these attributes may have to be also included in sentence plans. 6 Results Same as Mairesse et al. (2010), we use 10-fold cross-validation where DAs seen at training time are never used for testing, i.e., both paraphrases or none of them are present in the full training set. We evaluate using BLEU and NIST scores (Papineni et al., 2002; Doddington, 2002) against both reference paraphrases for a given test DA. The results of our generator are shown in Table 1, both for standard perceptron updates and our improvements – differing subtree updates and future promise estimation (see Section 3.2). Our generator did not achieve the same performance as that of Mairesse et al. (2010) (ca. 67%).9 However, our task is substantially harder since the generator also needs to learn the alignment of phrases to SVPs and determine whether all required information is present on the output (see also Section 7). Our differing tree updates clearly bring a substant</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>G. Doddington. 2002. Automatic evaluation of machine translation quality using N-gram cooccurrence statistics. In Proceedings of the Second International Conference on Human Language Technology Research, pages 138–145, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Dusek</author>
<author>Z Žabokrtský</author>
<author>M Popel</author>
<author>M Majlis</author>
<author>M Novák</author>
<author>D Mareˇcek</author>
</authors>
<title>Formemes in English-Czech deep syntactic MT.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>267--274</pages>
<location>Montreal.</location>
<marker>Dusek, Žabokrtský, Popel, Majlis, Novák, Mareˇcek, 2012</marker>
<rawString>O. Du&amp;quot;sek, Z. Žabokrtský, M. Popel, M. Majli&amp;quot;s, M. Novák, and D. Mareˇcek. 2012. Formemes in English-Czech deep syntactic MT. In Proceedings of the Seventh Workshop on Statistical Machine Translation, page 267–274, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P E Hart</author>
<author>N J Nilsson</author>
<author>B Raphael</author>
</authors>
<title>A formal basis for the heuristic determination of minimum cost paths.</title>
<date>1968</date>
<journal>IEEE Transactions on Systems Science and Cybernetics,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="6434" citStr="Hart et al., 1968" startWordPosition="1008" endWordPosition="1011">ng deep-syntactic analyzer from the Treex NLP framework (Popel and Žabokrtský, 2010).2 We use dialogue acts (DA) as defined in the BAGEL restaurant data set of Mairesse et al. (2010) as a MR in our experiments throughout this paper. Here, a DA consists of a dialogue act type, which is always “inform” in the set, and a list of slot-value pairs (SVPs) that contain information about a restaurant, such as food type or location (see the top of Figure 1). Our generator can be easily adapted to a different MR, though. 3 Sentence Planner The sentence planner is based on a variant of the A* algorithm (Hart et al., 1968; Och et al., 2001; Koehn et al., 2003). It starts from an empty sentence plan tree and tries to find a path to the optimal sentence plan by iteratively adding nodes. It keeps two sets of hypotheses, i.e., candidate sentence plan trees, sorted by their score – hypotheses to expand (open set) and already expanded (closed set). It uses the following two subcomponents to guide the search: • a candidate generator that is able to incrementally generate candidate sentence plan trees (see Section 3.1), • a scorer/ranker that scores the appropriateness of these trees for the input MR (see Section 3.2)</context>
</contexts>
<marker>Hart, Nilsson, Raphael, 1968</marker>
<rawString>P. E. Hart, N. J. Nilsson, and B. Raphael. 1968. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2):100–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning to transform natural to formal languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<volume>20</volume>
<publisher>AAAI Press; MIT Press;</publisher>
<location>Menlo Park, CA; Cambridge, MA; London;</location>
<contexts>
<context position="33319" citStr="Kate et al., 2005" startWordPosition="5467" endWordPosition="5470">mostly fluent and relevant. They did not surpass the BLEU score of the original authors; however, our task is substantially harder as our generator does not require fine-grained alignments on the input. Our novel feature of the sentence planner ranker – using differing subtrees for perceptron weight updates – has brought a significant performance improvement. The generator source code, along with configuration files for experiments on the BAGEL data set, is available for download on Github.11 In future work, we plan to evaluate our generator on further domains, such as geographic information (Kate et al., 2005), weather reports (Liang et al., 2009), or flight information (Dahl et al., 1994). In order to improve the performance of our generator and remove the dependency on domainspecific features, we plan to replace the perceptron ranker with a neural network. We also want to experiment with removing the dependency on the Treex surface realizer by generating directly into dependency trees or structures into which de11https://github.com/UFAL-DSG/tgen pendency trees can be converted in a languageindependent way. Acknowledgments This work was funded by the Ministry of Education, Youth and Sports of the </context>
</contexts>
<marker>Kate, Wong, Mooney, 2005</marker>
<rawString>R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005. Learning to transform natural to formal languages. In Proceedings of the National Conference on Artificial Intelligence, volume 20. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-HLT -</booktitle>
<volume>1</volume>
<pages>48--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6473" citStr="Koehn et al., 2003" startWordPosition="1016" endWordPosition="1019">reex NLP framework (Popel and Žabokrtský, 2010).2 We use dialogue acts (DA) as defined in the BAGEL restaurant data set of Mairesse et al. (2010) as a MR in our experiments throughout this paper. Here, a DA consists of a dialogue act type, which is always “inform” in the set, and a list of slot-value pairs (SVPs) that contain information about a restaurant, such as food type or location (see the top of Figure 1). Our generator can be easily adapted to a different MR, though. 3 Sentence Planner The sentence planner is based on a variant of the A* algorithm (Hart et al., 1968; Och et al., 2001; Koehn et al., 2003). It starts from an empty sentence plan tree and tries to find a path to the optimal sentence plan by iteratively adding nodes. It keeps two sets of hypotheses, i.e., candidate sentence plan trees, sorted by their score – hypotheses to expand (open set) and already expanded (closed set). It uses the following two subcomponents to guide the search: • a candidate generator that is able to incrementally generate candidate sentence plan trees (see Section 3.1), • a scorer/ranker that scores the appropriateness of these trees for the input MR (see Section 3.2). 1This issue would become more pressin</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of NAACL-HLT - Volume 1, page 48–54, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>388--395</pages>
<contexts>
<context position="25656" citStr="Koehn, 2004" startWordPosition="4289" endWordPosition="4290">es, and scores keep increasing with bigger amounts of training data used, whereas with plain perceptron updates, the scores stay flat. The increase with 100% is smaller since all training DAs are in fact used twice, each time with a different paraphrase.10 A larger training set with different DAs should bring a bigger improvement. Using future promise estimation boosts the scores even further, by a smaller amount for BLEU but noticeably for NIST. Both improvements on the full training set are considered statistically significant at 95% confidence level by the paired bootstrap resampling test (Koehn, 2004). A manual inspection of a small sample of the results confirmed that the automatic scores reflect the quality of the generated sentences well. If we look closer at the generated sentences (see Table 2), it becomes clear that the generator learns to produce meaningful utterances which mostly correspond well to the input DA. It is able to produce original paraphrases and generalizes to previously unseen DAs. On the other hand, not all required information is always present, and some facts are sometimes repeated or irrelevant information appears. This mostly happens with input slot-value pairs t</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP, page 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Konstas</author>
<author>M Lapata</author>
</authors>
<title>A global model for concept-to-text generation.</title>
<date>2013</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>48--305</pages>
<contexts>
<context position="2177" citStr="Konstas and Lapata, 2013" startWordPosition="339" endWordPosition="342">ken dialogue system (SDS), where the NLG component is supposed to translate a system output action into a sentence. While the content planning NLG stage has been used in SDS (e.g., Rieser and Lemon (2010)), we believe that deciding upon the contents of the system’s utterance is generally a task for the dialogue manager. We focus mainly on the sentence planning part in this work, and reuse an existing rule-based surface realizer to test the capabilities of the generator in an end-to-end setting. Current NLG systems usually require a separate training data alignment step (Mairesse et al., 2010; Konstas and Lapata, 2013). Many of them use a CFG or operate in a phrase-based fashion (Angeli et al., 2010; Mairesse et al., 2010), which limits their ability to capture long-range syntactic dependencies. Our generator includes alignment learning into sentence planner training and uses deep-syntactic trees with a rule-based surface realization step, which ensures grammatical correctness of the outputs. Unlike previous approaches to trainable sentence planning (e.g., Walker et al. (2001); Stent et al. (2004)), our generator does not require a handcrafted base sentence planner. This paper is structured as follows: in S</context>
<context position="30037" citStr="Konstas and Lapata (2013)" startWordPosition="4928" endWordPosition="4931"> realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2010) generate text from database records through a sequence of classifiers, gradually selecting database records, fields, and corresponding textual realizations to describe them. Konstas and Lapata (2013) recast the whole NLG problem as parsing over a probabilistic context-free grammar estimated from database records and their descriptions. Mairesse et al. (2010) convert input DAs into “semantic stacks”, which correspond to natural language phrases and contain slots and their values on top of each other. Their generation model uses two dynamic Bayesian networks: the first one performs an ordering of the input semantic stacks, inserting intermediary stacks which correspond to grammatical phrases, the second one then produces a concrete surface realization. Dethlefs et al. (2013) approach genera</context>
</contexts>
<marker>Konstas, Lapata, 2013</marker>
<rawString>I. Konstas and M. Lapata. 2013. A global model for concept-to-text generation. Journal of Artificial Intelligence Research, 48:305–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>1</volume>
<pages>91--99</pages>
<contexts>
<context position="33357" citStr="Liang et al., 2009" startWordPosition="5473" endWordPosition="5476">not surpass the BLEU score of the original authors; however, our task is substantially harder as our generator does not require fine-grained alignments on the input. Our novel feature of the sentence planner ranker – using differing subtrees for perceptron weight updates – has brought a significant performance improvement. The generator source code, along with configuration files for experiments on the BAGEL data set, is available for download on Github.11 In future work, we plan to evaluate our generator on further domains, such as geographic information (Kate et al., 2005), weather reports (Liang et al., 2009), or flight information (Dahl et al., 1994). In order to improve the performance of our generator and remove the dependency on domainspecific features, we plan to replace the perceptron ranker with a neural network. We also want to experiment with removing the dependency on the Treex surface realizer by generating directly into dependency trees or structures into which de11https://github.com/UFAL-DSG/tgen pendency trees can be converted in a languageindependent way. Acknowledgments This work was funded by the Ministry of Education, Youth and Sports of the Czech Republic under the grant agreeme</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>P. Liang, M. I. Jordan, and D. Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, page 91–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lu</author>
<author>H T Ng</author>
<author>W S Lee</author>
</authors>
<title>Natural language generation with tree conditional random fields.</title>
<date>2009</date>
<booktitle>In Proc. of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>400--409</pages>
<contexts>
<context position="29691" citStr="Lu et al. (2009)" startWordPosition="4879" endWordPosition="4882">nker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2010) generate text from database records through a sequence of classifiers, gradually selecting database records, fields, and corresponding textual realizations to describe them. Konstas and Lapata (2013) recast the whole NLG problem as parsing over a probabilistic context-free grammar estimated from database records and their descriptions. Mairesse et al. (2010) convert input DAs into “semantic stacks”, which correspond to natural language phrases and c</context>
<context position="31174" citStr="Lu et al., 2009" startWordPosition="5112" endWordPosition="5115">produces a concrete surface realization. Dethlefs et al. (2013) approach generation as a sequence labeling task and use a conditional random field classifier, assigning a word or a phrase to each input MR element. Unlike our work, the joint approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG</context>
</contexts>
<marker>Lu, Ng, Lee, 2009</marker>
<rawString>W. Lu, H. T. Ng, and W. S. Lee. 2009. Natural language generation with tree conditional random fields. In Proc. of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, page 400–409.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M Walker</author>
</authors>
<title>Trainable generation of big-five personality styles through datadriven parameter estimation.</title>
<date>2008</date>
<booktitle>In Proc. of the 46th Annual Meeting of the ACL (ACL),</booktitle>
<pages>165--173</pages>
<contexts>
<context position="29261" citStr="Mairesse and Walker, 2008" startWordPosition="4813" endWordPosition="4816">generated sentences Sentences generated when training on the full set and using differing subtree updates and future promise estimation. 7 Related Work Previous trainable methods in sentence planning use in principle two techniques: First, in the overgeneration and ranking approach (Walker et al., 2001; Stent et al., 2004), many sentence plans are generated using a rule-based planner and then the best one is selected by a statistical ranker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2010) generate text from data</context>
</contexts>
<marker>Mairesse, Walker, 2008</marker>
<rawString>F. Mairesse and M. Walker. 2008. Trainable generation of big-five personality styles through datadriven parameter estimation. In Proc. of the 46th Annual Meeting of the ACL (ACL), page 165–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M Gasi´c</author>
<author>F Jurˇcíˇcek</author>
<author>S Keizer</author>
<author>B Thomson</author>
<author>K Yu</author>
<author>S Young</author>
</authors>
<title>Phrase-based statistical language generation using graphical models and active learning.</title>
<date>2010</date>
<booktitle>In Proc. of the 48th Annual Meeting of the ACL,</booktitle>
<pages>1552--1561</pages>
<marker>Mairesse, Gasi´c, Jurˇcíˇcek, Keizer, Thomson, Yu, Young, 2010</marker>
<rawString>F. Mairesse, M. Ga&amp;quot;si´c, F. Jurˇcíˇcek, S. Keizer, B. Thomson, K. Yu, and S. Young. 2010. Phrase-based statistical language generation using graphical models and active learning. In Proc. of the 48th Annual Meeting of the ACL, page 1552–1561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, page 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Hall</author>
<author>G Mann</author>
</authors>
<title>Distributed training strategies for the structured perceptron.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>456--464</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16986" citStr="McDonald et al. (2010)" startWordPosition="2840" endWordPosition="2843">x{0, Ec(ni) − c(ni)} where c(ni) is the current number of children of node ni, A is a preset weight parameter, and E w is the sum of the current perceptron weights. Multiplying by the weights sum makes future promise values comparable to trees scores. Future promise is added to tree scores throughout the tree generation process, but it is disregarded for the termination criterion in the Stop step of the generation algorithm and in perceptron weight updates. Averaging weights and parallel training To speed up training using parallel processing, we use the iterative parameter mixing approach of McDonald et al. (2010), where training data are split into several parts and weight updates are averaged after each pass through the training data. Following Collins (2002), we record the weights after each training pass, take an average at the end, and use this as the final weights for prediction. 4 Surface Realizer We use the English surface realizer from the Treex NLP toolkit (cf. Section 2 and (Ptáˇcek, 2008)). It is a simple pipeline of mostly rule-based blocks that gradually change the deep-syntactic trees into surface dependency trees, which are then linearized to sentences. It includes the following steps: </context>
</contexts>
<marker>McDonald, Hall, Mann, 2010</marker>
<rawString>R. McDonald, K. Hall, and G. Mann. 2010. Distributed training strategies for the structured perceptron. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 456–464. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11963" citStr="Och and Ney, 2003" startWordPosition="1960" endWordPosition="1963">structures of the new MR instead of SVPs. While especially Rules 5 and 6 exclude a vast number of potential candidate trees, this limitation is still much weaker than using hard alignment links between the elements of the MR and the output words or phrases. It leaves enough room to generate many combinations unseen in the training data (cf. Section 6) while keeping the search space manageable. To limit the space of potential tree candidates even further, one could also use automatic alignment scores between the elements of the input MR and the tree nodes (obtained using a tool such as GIZA++ (Och and Ney, 2003)). 3.2 Scoring Sentence Plan Trees The scorer for the individual sentence plan tree candidates is a function that maps global features from the whole sentence plan tree t and the input MR m to a real-valued score that describes the fitness of t in the context of m. We first describe the basic version of the scorer and then our two improvements – differing subtree updates and future promise estimation. Basic perceptron scorer The basic scorer is based on the linear perceptron ranker of Collins and Duffy (2002), where the score is computed as a simple dot product of the features and the correspo</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>An efficient A* search algorithm for statistical machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings of the Workshop on Datadriven Methods in Machine Translation - Volume 14,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6452" citStr="Och et al., 2001" startWordPosition="1012" endWordPosition="1015">nalyzer from the Treex NLP framework (Popel and Žabokrtský, 2010).2 We use dialogue acts (DA) as defined in the BAGEL restaurant data set of Mairesse et al. (2010) as a MR in our experiments throughout this paper. Here, a DA consists of a dialogue act type, which is always “inform” in the set, and a list of slot-value pairs (SVPs) that contain information about a restaurant, such as food type or location (see the top of Figure 1). Our generator can be easily adapted to a different MR, though. 3 Sentence Planner The sentence planner is based on a variant of the A* algorithm (Hart et al., 1968; Och et al., 2001; Koehn et al., 2003). It starts from an empty sentence plan tree and tries to find a path to the optimal sentence plan by iteratively adding nodes. It keeps two sets of hypotheses, i.e., candidate sentence plan trees, sorted by their score – hypotheses to expand (open set) and already expanded (closed set). It uses the following two subcomponents to guide the search: • a candidate generator that is able to incrementally generate candidate sentence plan trees (see Section 3.1), • a scorer/ranker that scores the appropriateness of these trees for the input MR (see Section 3.2). 1This issue woul</context>
</contexts>
<marker>Och, Ueffing, Ney, 2001</marker>
<rawString>F. J. Och, N. Ueffing, and H. Ney. 2001. An efficient A* search algorithm for statistical machine translation. In Proceedings of the Workshop on Datadriven Methods in Machine Translation - Volume 14, page 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Paiva</author>
<author>R Evans</author>
</authors>
<title>Empirically-based control of natural language generation.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of ACL,</booktitle>
<pages>58--65</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29233" citStr="Paiva and Evans, 2005" startWordPosition="4809" endWordPosition="4812">ange. Table 2: Example generated sentences Sentences generated when training on the full set and using differing subtree updates and future promise estimation. 7 Related Work Previous trainable methods in sentence planning use in principle two techniques: First, in the overgeneration and ranking approach (Walker et al., 2001; Stent et al., 2004), many sentence plans are generated using a rule-based planner and then the best one is selected by a statistical ranker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2</context>
</contexts>
<marker>Paiva, Evans, 2005</marker>
<rawString>D. S. Paiva and R. Evans. 2005. Empirically-based control of natural language generation. In Proc. of the 43rd Annual Meeting of ACL, page 58–65, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="18643" citStr="Papineni et al., 2002" startWordPosition="3105" endWordPosition="3108">words – prepositions, subordinating conjunctions, negation particles, articles, and other grammatical words are added into the sentence. • Punctuation – nodes for commas, final punctuation, quotes, and brackets are introduced. • Word Inflection – words are inflected according to the information from formemes and agreement. • Phonetic changes – English “a” becomes “an” based on the following word. The realizer is designed as domain-independent and handles most English grammatical phenomena. A simple “round-trip” test – using automatic analysis with subsequent generation – reached a BLEU score (Papineni et al., 2002) of 89.79% against the original sentences on the whole BAGEL data set, showing only minor differences between the input sentence and generation output (mostly in punctuation). �fp = A · w · � Itl i=1 455 Figure 4: Coordination structures conversion: original (left) and our format (right). 5 Experimental Setup Here we describe the data set used in our experiments, the needed preprocessing steps, and the settings of our generator specific to the data set. 5.1 Data set We performed our experiments on the BAGEL data set of Mairesse et al. (2010), which fits our usage scenario in a spoken dialogue </context>
<context position="24261" citStr="Papineni et al., 2002" startWordPosition="4056" endWordPosition="4060">lish realizer expects not only lemmas and formemes, but also additional grammatical attributes for all nodes. In our experiments, we simply use the most common values found in the training data for the particular nodes as this is sufficient for our domain. In larger domains, some of these attributes may have to be also included in sentence plans. 6 Results Same as Mairesse et al. (2010), we use 10-fold cross-validation where DAs seen at training time are never used for testing, i.e., both paraphrases or none of them are present in the full training set. We evaluate using BLEU and NIST scores (Papineni et al., 2002; Doddington, 2002) against both reference paraphrases for a given test DA. The results of our generator are shown in Table 1, both for standard perceptron updates and our improvements – differing subtree updates and future promise estimation (see Section 3.2). Our generator did not achieve the same performance as that of Mairesse et al. (2010) (ca. 67%).9 However, our task is substantially harder since the generator also needs to learn the alignment of phrases to SVPs and determine whether all required information is present on the output (see also Section 7). Our differing tree updates clear</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, page 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popel</author>
<author>Z Žabokrtský</author>
</authors>
<title>TectoMT: modular NLP framework.</title>
<date>2010</date>
<booktitle>In Proceedings of IceTAL, 7th International Conference on Natural Language Processing,</booktitle>
<pages>293--304</pages>
<location>Reykjavík.</location>
<contexts>
<context position="5901" citStr="Popel and Žabokrtský, 2010" startWordPosition="910" endWordPosition="913">mmatical correctness of the output sentences, which would be more difficult in a sequence-based and/or statistical approach.1 And third, a rule-based surface realizer from our sentence plan format is relatively easy to implement and can be reused for any domain within the same language. As in our case, it is also possible to reuse and/or adapt an existing surface realizer (see Section 4). Deep-syntax annotation of sentences in the training set is needed to train the sentence planner, but we assume automatic annotation and reuse an existing deep-syntactic analyzer from the Treex NLP framework (Popel and Žabokrtský, 2010).2 We use dialogue acts (DA) as defined in the BAGEL restaurant data set of Mairesse et al. (2010) as a MR in our experiments throughout this paper. Here, a DA consists of a dialogue act type, which is always “inform” in the set, and a list of slot-value pairs (SVPs) that contain information about a restaurant, such as food type or location (see the top of Figure 1). Our generator can be easily adapted to a different MR, though. 3 Sentence Planner The sentence planner is based on a variant of the A* algorithm (Hart et al., 1968; Och et al., 2001; Koehn et al., 2003). It starts from an empty se</context>
</contexts>
<marker>Popel, Žabokrtský, 2010</marker>
<rawString>M. Popel and Z. Žabokrtský. 2010. TectoMT: modular NLP framework. In Proceedings of IceTAL, 7th International Conference on Natural Language Processing, page 293–304, Reykjavík.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ptáˇcek</author>
</authors>
<title>Two tectogrammatical realizers side by side: Case of English and Czech.</title>
<date>2008</date>
<booktitle>In Fourth International Workshop on Human-Computer Conversation,</booktitle>
<location>Bellagio, Italy.</location>
<marker>Ptáˇcek, 2008</marker>
<rawString>J. Ptáˇcek. 2008. Two tectogrammatical realizers side by side: Case of English and Czech. In Fourth International Workshop on Human-Computer Conversation, Bellagio, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>R Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge Univ. Press.</publisher>
<contexts>
<context position="1506" citStr="Reiter and Dale (2000)" startWordPosition="223" endWordPosition="226">utputs of our generator are mostly fluent and relevant. 1 Introduction We present a novel approach to natural language generation (NLG) that does not require finegrained alignment in training data and uses deep dependency syntax for sentence plans. We include our first results on the BAGEL restaurant recommendation data set of Mairesse et al. (2010). In our setting, the task of a natural language generator is that of converting an abstract meaning representation (MR) into a natural language utterance. This corresponds to the sentence planning and surface realization NLG stages as described by Reiter and Dale (2000). It also reflects the intended usage in a spoken dialogue system (SDS), where the NLG component is supposed to translate a system output action into a sentence. While the content planning NLG stage has been used in SDS (e.g., Rieser and Lemon (2010)), we believe that deciding upon the contents of the system’s utterance is generally a task for the dialogue manager. We focus mainly on the sentence planning part in this work, and reuse an existing rule-based surface realizer to test the capabilities of the generator in an end-to-end setting. Current NLG systems usually require a separate trainin</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>E. Reiter and R. Dale. 2000. Building Natural Language Generation Systems. Cambridge Univ. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rieser</author>
<author>O Lemon</author>
</authors>
<title>Natural language generation as planning under uncertainty for spoken dialogue systems.</title>
<date>2010</date>
<booktitle>In Empirical methods in natural language generation,</booktitle>
<pages>105--120</pages>
<contexts>
<context position="1756" citStr="Rieser and Lemon (2010)" startWordPosition="268" endWordPosition="271">We include our first results on the BAGEL restaurant recommendation data set of Mairesse et al. (2010). In our setting, the task of a natural language generator is that of converting an abstract meaning representation (MR) into a natural language utterance. This corresponds to the sentence planning and surface realization NLG stages as described by Reiter and Dale (2000). It also reflects the intended usage in a spoken dialogue system (SDS), where the NLG component is supposed to translate a system output action into a sentence. While the content planning NLG stage has been used in SDS (e.g., Rieser and Lemon (2010)), we believe that deciding upon the contents of the system’s utterance is generally a task for the dialogue manager. We focus mainly on the sentence planning part in this work, and reuse an existing rule-based surface realizer to test the capabilities of the generator in an end-to-end setting. Current NLG systems usually require a separate training data alignment step (Mairesse et al., 2010; Konstas and Lapata, 2013). Many of them use a CFG or operate in a phrase-based fashion (Angeli et al., 2010; Mairesse et al., 2010), which limits their ability to capture long-range syntactic dependencies</context>
</contexts>
<marker>Rieser, Lemon, 2010</marker>
<rawString>V. Rieser and O. Lemon. 2010. Natural language generation as planning under uncertainty for spoken dialogue systems. In Empirical methods in natural language generation, page 105–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sgall</author>
<author>E Hajiˇcová</author>
<author>J Panevová</author>
</authors>
<title>The meaning of the sentence in its semantic and pragmatic aspects.</title>
<date>1986</date>
<location>D. Reidel, Dordrecht.</location>
<marker>Sgall, Hajiˇcová, Panevová, 1986</marker>
<rawString>P. Sgall, E. Hajiˇcová, and J. Panevová. 1986. The meaning of the sentence in its semantic and pragmatic aspects. D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Spoustová</author>
<author>J Hajiˇc</author>
<author>J Votrubec</author>
<author>P Krbec</author>
<author>P Kvˇetoˇn</author>
</authors>
<title>The Best of Two Worlds: Cooperation of Statistical and Rule-based Taggers for Czech.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on BaltoSlavonic Natural Language Processing: Information Extraction and Enabling Technologies,</booktitle>
<pages>67--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Spoustová, Hajiˇc, Votrubec, Krbec, Kvˇetoˇn, 2007</marker>
<rawString>D. J. Spoustová, J. Hajiˇc, J. Votrubec, P. Krbec, and P. Kvˇetoˇn. 2007. The Best of Two Worlds: Cooperation of Statistical and Rule-based Taggers for Czech. In Proceedings of the Workshop on BaltoSlavonic Natural Language Processing: Information Extraction and Enabling Technologies, pages 67–74. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
<author>R Prasad</author>
<author>M Walker</author>
</authors>
<title>Trainable sentence planning for complex information presentation in spoken dialog systems.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2665" citStr="Stent et al. (2004)" startWordPosition="412" endWordPosition="415">ting. Current NLG systems usually require a separate training data alignment step (Mairesse et al., 2010; Konstas and Lapata, 2013). Many of them use a CFG or operate in a phrase-based fashion (Angeli et al., 2010; Mairesse et al., 2010), which limits their ability to capture long-range syntactic dependencies. Our generator includes alignment learning into sentence planner training and uses deep-syntactic trees with a rule-based surface realization step, which ensures grammatical correctness of the outputs. Unlike previous approaches to trainable sentence planning (e.g., Walker et al. (2001); Stent et al. (2004)), our generator does not require a handcrafted base sentence planner. This paper is structured as follows: in Section 2, we describe the architecture of our generator. Sections 3 and 4 then provide further details on its main components. In Section 5, we describe our experiments on the BAGEL data set, followed by an analysis of the results in Section 6. Section 7 compares our generator to previous related works and Section 8 concludes the paper. 2 Generator Architecture Our generator (see Figure 1) operates in two stages that roughly correspond to the traditional NLG stages of sentence planni</context>
<context position="28959" citStr="Stent et al., 2004" startWordPosition="4768" endWordPosition="4771">enerated X is a Japanese restaurant in the centre of town near X and X. Input DA inform(name=X-name, type=placetoeat, pricerange=moderate, eattype=restaurant) Reference X is a restaurant that offers moderate price range. Generated X is a restaurant in the moderate price range. Table 2: Example generated sentences Sentences generated when training on the full set and using differing subtree updates and future promise estimation. 7 Related Work Previous trainable methods in sentence planning use in principle two techniques: First, in the overgeneration and ranking approach (Walker et al., 2001; Stent et al., 2004), many sentence plans are generated using a rule-based planner and then the best one is selected by a statistical ranker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translat</context>
</contexts>
<marker>Stent, Prasad, Walker, 2004</marker>
<rawString>A. Stent, R. Prasad, and M. Walker. 2004. Trainable sentence planning for complex information presentation in spoken dialog systems. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>O Rambow</author>
<author>M Rogati</author>
</authors>
<title>SPoT: a trainable sentence planner.</title>
<date>2001</date>
<booktitle>In Proc. of 2nd meeting of NAACL,</booktitle>
<pages>1--8</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2644" citStr="Walker et al. (2001)" startWordPosition="408" endWordPosition="411">r in an end-to-end setting. Current NLG systems usually require a separate training data alignment step (Mairesse et al., 2010; Konstas and Lapata, 2013). Many of them use a CFG or operate in a phrase-based fashion (Angeli et al., 2010; Mairesse et al., 2010), which limits their ability to capture long-range syntactic dependencies. Our generator includes alignment learning into sentence planner training and uses deep-syntactic trees with a rule-based surface realization step, which ensures grammatical correctness of the outputs. Unlike previous approaches to trainable sentence planning (e.g., Walker et al. (2001); Stent et al. (2004)), our generator does not require a handcrafted base sentence planner. This paper is structured as follows: in Section 2, we describe the architecture of our generator. Sections 3 and 4 then provide further details on its main components. In Section 5, we describe our experiments on the BAGEL data set, followed by an analysis of the results in Section 6. Section 7 compares our generator to previous related works and Section 8 concludes the paper. 2 Generator Architecture Our generator (see Figure 1) operates in two stages that roughly correspond to the traditional NLG stag</context>
<context position="28938" citStr="Walker et al., 2001" startWordPosition="4764" endWordPosition="4767">city centre near X. Generated X is a Japanese restaurant in the centre of town near X and X. Input DA inform(name=X-name, type=placetoeat, pricerange=moderate, eattype=restaurant) Reference X is a restaurant that offers moderate price range. Generated X is a restaurant in the moderate price range. Table 2: Example generated sentences Sentences generated when training on the full set and using differing subtree updates and future promise estimation. 7 Related Work Previous trainable methods in sentence planning use in principle two techniques: First, in the overgeneration and ranking approach (Walker et al., 2001; Stent et al., 2004), many sentence plans are generated using a rule-based planner and then the best one is selected by a statistical ranker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phraseb</context>
</contexts>
<marker>Walker, Rambow, Rogati, 2001</marker>
<rawString>M. A. Walker, O. Rambow, and M. Rogati. 2001. SPoT: a trainable sentence planner. In Proc. of 2nd meeting of NAACL, page 1–8, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Generation by inverting a semantic parser that uses statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of Human Language Technologies: The Conference of the North American Chapter of the ACL (NAACL-HLT-07),</booktitle>
<pages>172--179</pages>
<contexts>
<context position="29512" citStr="Wong and Mooney (2007)" startWordPosition="4853" endWordPosition="4856">ration and ranking approach (Walker et al., 2001; Stent et al., 2004), many sentence plans are generated using a rule-based planner and then the best one is selected by a statistical ranker. Second, parameter optimization trains adjustable parameters of a handcrafted generator to produce outputs with desired properties (Paiva and Evans, 2005; Mairesse and Walker, 2008). As opposed to our approach, both methods require an existing handcrafted sentence planner. Other previous works combine sentence planning and surface realization into a single step and do not require a handcrafted base module. Wong and Mooney (2007) experiment with a phrasebased machine translation system, comparing and combining it with an inverted semantic parser based on synchronous context-free grammars. Lu et al. (2009) use tree conditional random fields over hybrid trees that combine natural language phrases with formal semantic expressions. Angeli et al. (2010) generate text from database records through a sequence of classifiers, gradually selecting database records, fields, and corresponding textual realizations to describe them. Konstas and Lapata (2013) recast the whole NLG problem as parsing over a probabilistic context-free </context>
<context position="30934" citStr="Wong and Mooney, 2007" startWordPosition="5071" endWordPosition="5074"> values on top of each other. Their generation model uses two dynamic Bayesian networks: the first one performs an ordering of the input semantic stacks, inserting intermediary stacks which correspond to grammatical phrases, the second one then produces a concrete surface realization. Dethlefs et al. (2013) approach generation as a sequence labeling task and use a conditional random field classifier, assigning a word or a phrase to each input MR element. Unlike our work, the joint approaches typically include the alignment of input MR elements to output words in a separate preprocessing step (Wong and Mooney, 2007; Angeli et al., 2010), or require pre-aligned training data (Mairesse et al., 2010; Dethlefs et al., 2013). In addition, their basic algorithm often requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas </context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Y. W. Wong and R. J. Mooney. 2007. Generation by inverting a semantic parser that uses statistical machine translation. In Proc. of Human Language Technologies: The Conference of the North American Chapter of the ACL (NAACL-HLT-07), page 172–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>678--687</pages>
<location>Prague.</location>
<contexts>
<context position="31709" citStr="Zettlemoyer and Collins (2007)" startWordPosition="5203" endWordPosition="5206">ften requires a specific input MR format, e.g., a tree (Wong and Mooney, 2007; Lu et al., 2009) or a flat database (Angeli et al., 2010; Konstas and Lapata, 2013; Mairesse et al., 2010). While dependency-based deep syntax has been used previously in statistical NLG, the approaches known to us (Bohnet et al., 2010; Belz et al., 2012; Ballesteros et al., 2014) focus only on the surface realization step and do not include a sentence plan458 ner, whereas our work is mainly focused on statistical sentence planning and uses a rule-based realizer. Our approach to sentence planning is most similar to Zettlemoyer and Collins (2007), which use a candidate generator and a perceptron ranker for CCG parsing. Apart from proceeding in the inverse direction and using dependency trees, we use only very generic rules in our candidate generator instead of language-specific ones, and we incorporate differing subtree updates and future promise estimation into our ranker. 8 Conclusions and Further Work We have presented a novel natural language generator, capable of learning from unaligned pairs of input meaning representation and output utterances. It consists of a novel, A*-search-based sentence planner and a largely rule-based su</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>L. S. Zettlemoyer and M. Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 678–687, Prague.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>