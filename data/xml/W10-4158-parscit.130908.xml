<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000864">
<title confidence="0.986763">
Jumping Distance based Chinese Person Name Disambiguation1
</title>
<author confidence="0.999617">
Yu Hong Fei Pei Yue-hui Yang Jian-min Yao Qiao-ming Zhu
</author>
<affiliation confidence="0.999634">
School of Computer Science and Technology, Soochow University
</affiliation>
<address confidence="0.711226">
No.1 Shizi street, Suzhou City, Jiansu Province, China
</address>
<email confidence="0.965351">
{hongy, 20094527004, 0727401137, jyao, qmzhu}@suda.edu.cn
</email>
<sectionHeader confidence="0.992869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99907925">
In this paper, we describe a Chinese person
name disambiguation system for news articles
and report the results obtained on the data set of
the CLP 2010 Bakeoff-31. The main task of the
Bakeoff is to identify different persons from the
news stories that contain the same person-name
string. Compared to the traditional methods,
two additional features are used in our system:
</bodyText>
<listItem confidence="0.8789345">
1) n-grams co-occurred with target name string;
2) Jumping distance among the n-grams. On the
</listItem>
<bodyText confidence="0.6811655">
basis, we propose a two-stage clustering algo-
rithm to improve the low recall.
</bodyText>
<sectionHeader confidence="0.943237" genericHeader="method">
1 Our Novel Try
</sectionHeader>
<bodyText confidence="0.99986425">
For this task, we propose a Jumping-Distance
based n-gram model (abbr. DJ n-gram) to de-
scribe the semantics of the closest contexts of
the target person-name strings.
The generation of the DJ n-gram model
mainly involves two steps. First, we mine the
Jumping tree for the target string; second, we
give the statistical description of the tree.
</bodyText>
<listItem confidence="0.891785">
• Jumping Tree
</listItem>
<bodyText confidence="0.999709333333334">
Given a target string, we firstly extract the
sentence where it locates as its closest context.
Then we segment the sentence into n-
grams(Chen et al. ,2009) (only Bi-gram and Tri-
gram are used in this paper). For each n-gram,
we regard it as the beginning of a jumping jour-
ney. And the places where we jump are the sen-
tences which involve the n-gram. By the same
way, we segment the sentences into n-grams
which will be regarded as the new beginnings to
open further jumping. The procedure will run
iteratively until there are no sentences in the
</bodyText>
<note confidence="0.397343">
1 Supported by the National Natural Science Foundation
of China under Grant No. 60970057, No.60873105.
</note>
<bodyText confidence="0.999923722222222">
document (viz. the document which involves
the target string) can be used to jump. Actually,
we find there are only 3 jumps in average in our
previous test and simultaneously 11 sentences
in a document can be involved into the jumping
journey. Thus, we can obtain a Jumping Tree
where each jumping route from the initially n-
gram (viz. the gram in the closes context) refer
to a branch. And for each intermediate node, its
child-nodes are the n-grams co-occurred with it
in the same sentences.
The motivation to generate the Jumping Tree
is to imitate the thinking model of human rec-
ognizing the word senses and semantics. In de-
tail, for each intermediate node of the tree, its
child-nodes all come from its closest contexts,
especially the nodes co-occur with it in the
same sentences which involve the real grammar
and semantic relations. Thus the child-nodes
normally provide the natural inference for its
word sense. For example, given the string
“SARS”, we can deduce its sense from its child
nodes “Severe”, “Acute”, “Respiratory” and
“Syndromes” even if we see the string for the
first time. On the basis, the procedure of infer-
ence run iteratively, that is, the tree always use
the child nodes deduce the meaning of their fa-
ther nodes then further ancestor nodes until the
root. Thus the tree acts as a hierarchical under-
standing procedure. Additionally, the distances
among nodes in the tree give the degree of se-
mantic relation.
In the task of person-name disambiguation,
we use the Jumping Tree to deduce the identi-
ties and backgrounds of a person. Each branch
of the tree refers to a property of the person.
</bodyText>
<listItem confidence="0.989458">
• Jumping-Distance based n-gram model
</listItem>
<bodyText confidence="0.999412285714286">
In this paper, we give a simple statistical
model to describe the Jumping Tree. Given a
node in the tree (viz. an n-gram), we record the
steps jumping from the root to it, viz. the depth
of the node in the tree. Then based on the priori-
trained TFIDF value, we calculate the genera-
tion probability of the node as follows:
</bodyText>
<equation confidence="0.975396666666667">
P TF a

depth
</equation>
<bodyText confidence="0.999837545454546">
where the a denotes the smoothing factor.
In fact, we create more comprehensive mod-
els to describe the semantic correlations among
the nodes in the Jumping Tree. The models well
use the distances among the nodes in local
Jumping Tree (viz. the tree generated based on
the test document) and that normalized on the
large-scale training data to calculate the prob-
ability of n-grams correboratively generate a
semantics. They try to imitate the thinking
model of human combine differents features to
understand panoramic knowledge. In the task of
name disambiguation, we can use the models to
improve the distinguishment of different per-
sons who have the same name. And we have
illustrate the well effectiveness on the topic de-
scription and relevance measurement in other
tasks, such as Link Detection. But we actually
didn’t use the models to perform the task of
name diaambiguation this time with the aim to
purely evaluate the usefulness of the Jumping
Tree.
</bodyText>
<sectionHeader confidence="0.975799" genericHeader="method">
2 Systems
</sectionHeader>
<bodyText confidence="0.999839">
For the task of Chinese person name disam-
biguation, we submitted two systems as follows:
</bodyText>
<listItem confidence="0.973066">
• System1
</listItem>
<bodyText confidence="0.999958185185185">
The system involves two main components:
DJ-based name Identification error detection
and DJ-based person name disambiguation.
The first component, viz. DJ-based name
segmentation error detection, aims to distin-
guish the target string referring to person name
from that referring to something else. Such as,
the string “咘⍋” can be a person name “Hai
Huang” but also a name of sea “the Yellow
Sea”. And the detection component focuses on
obtaining the pure person name “Hai Huang”.
The detection component firstly establish two
classes of features which respectively describe
the nature of human and that of things. Such as,
the features “professor”, “research”, “honest” et
al., can roughly be determined as the nature of
human, and conversely the features “solid”,
“collapse”, “deep” et al., can be that of things.
For obtaining the features, we extract 10,000
documents that discuss person, eg. “Albert Ein-
stein” and 6000 documents that discuss tech-
nology, science, geography, et.al., from
Wikipedia2. For each document, we generate its
Jumping Tree, and regard the nodes in the tree
as the features. After that, we combine the
weights of the same features and normalized the
value by dividing that by the average weight in
the specific class of features.
Based on the two classes of features, given a
target string and the document where it occurs,
the detection component firstly generate the
Jumping Tree of the document, and then deter-
mines whether the string is person name or
things by measuring the similarity of the tree to
the classes of features. Here, we simply use the
VSM and Cosine metric ΰBagga and Baldwin,
1998α to obtain the similarity.
The second component, viz. DJ-based person
name disambiguation, firstly generates the
Jumping trees for all documents that involve
specific person name. And a two-stage cluster-
ing algorithm is adopted to divide the docu-
ments and refer each cluster to a person. The
first stage of the algorithm runs a strict division
which focuses on obtaining high precision. The
second stage performs a soft division which is
used to improve recall. The two-stage clustering
algorithm(Ikeda et al.,2009) initially obtains the
optimal parameters that respectively refer to the
maximum precision and recall based on training
data, and then regards a statistical tradeoff as
the final value of the parameters. Here, the Af-
finity Propagation clustering tools (Frey BJ and
Dueck D, 2007) is in use.
</bodyText>
<listItem confidence="0.967231">
• System2
</listItem>
<bodyText confidence="0.999793952380953">
The system is similar to the system1 except
that it additionally involve Named Entity Identi-
fication (Artiles et.al,2009B; Popescu,O. and
Magnini, B.,2007)before the two-stage cluster-
ing in the component of person name disam-
biguation. In detail, given a person name and
the documents that it occurs in, the disambigua-
tion component of System2 firstly adopt NER
CRF++ toolkit3 provided by MSRA to identify
Named Entities(Chen et al., 2006) that involve
the given name string, such as the entity “ᴢ催
ᯢ” (viz. Gao-ming Li in English) when given
the target name string “催ᯢ”(viz. Ming Gao in
English). Thus the documents can be roughly
divided into different clusters of Named Entities
without name segmentation errors. After that,
we additionally adopt the two-stage clustering
algorithm to further divide each cluster. Thus
we can deal with the issue of disambiguation
without the interruption of name segmentation
errors.
</bodyText>
<sectionHeader confidence="0.790092" genericHeader="method">
3 Data sets
</sectionHeader>
<listItem confidence="0.982559">
• Training dataset: They contain about 30
Chinese personal names, and a document set of
about 100-300 news articles from collection of
Xinhua news documents in a time span of four-
teen years are provided for each personal name.
• External dataset: Chinese Wikipedia2 per-
sonal attribution (Cucerzan, 2007; Nguyen and
Cao,2008).
• Test dataset: There are about 26 Chinese
personal names, which are similar to train data
sets.
</listItem>
<sectionHeader confidence="0.997922" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999340428571428">
The systems that run on test dataset are evalu-
ated by both B-Cubed (Bagga and Baldwin,
1998; Artiles et al.,2009A) and P-IP (Artiles et
al., 2007 ;Artiles et al.,2009A). And the systems
that run on training dataset were only evaluated
by B-Cubed.
In experiments, we firstly evaluate the per-
formance of name segmentation error detection
on the training dataset. For comparison, we ad-
ditionally perform another detection method
which only using Name Entity Identifcation
(NER CRF++ tools) to distinguish name-strings
from the discarded ones. The results are shown
in table 1. We can find that our error detection
method can achieve more recall than NER, but
lower precision.
Besides, we evaluate the performance of the
two-stage clustering in the component of name
disambiguation step by step. Four steps are in
use to evaluate the first-stage clustering method
as follows:
</bodyText>
<listItem confidence="0.541763">
•
</listItem>
<bodyText confidence="0.981217125">
DJ2
This step look like to run the system1 men-
tionedin in section 3 which don’t involve the
prior-division of documents by using NER be-
fore the first-stage clustering in the component
of name disambiguation. Especially it don’t
perform the second-stage clustering to improve
the recall probability.
</bodyText>
<listItem confidence="0.937281">
• DJ2+NER
</listItem>
<bodyText confidence="0.998193333333333">
This step is similar to the step of DJ2 men-
tioned above except that it perform the prior-
divison of documents by using NER.
</bodyText>
<listItem confidence="0.941826">
• NER+DJ
</listItem>
<bodyText confidence="0.99878">
This step is also similar to the step of DJ2 ex-
cept that its name segmentation error detection
performs by using the NER.
</bodyText>
<listItem confidence="0.890605">
• NER2+DJ
</listItem>
<bodyText confidence="0.999288416666666">
This step is similar to the step of NER+DJ
except that it involve the treatment of prior-
divison as that in DJ2+NER.
The performances of the four steps are shown
in table 2. We can find that all steps achieve
poor recall. And the step of DJ2 achieve the best
F-score although it don’t involve the prior-
division. That is because NER is helpful to im-
prove precision but not recall, as shown in table
1. Conversely, DJ2 can avoid the bias caused by
the procedure of greatly maximizing the preci-
sion.
</bodyText>
<table confidence="0.998853333333333">
P recall F-score
DJ-based 0.62 0.81 0.70
NER-based 0.91 0.77 0.71
</table>
<tableCaption confidence="0.989664">
Table 1: Performance of name segmentation
error detection
</tableCaption>
<table confidence="0.9998928">
P IP F-score
DJ2 80.49 53.85 60.12
DJ2+NER 88.56 51.30 59.02
NER+DJ 93.27 46.78 57.44
NER2+DJ 97.79 42.13 55.47
</table>
<tableCaption confidence="0.998566">
Table 2: Performances of the-stage clustering
</tableCaption>
<bodyText confidence="0.992982666666667">
Additionally, another two steps are used to
evluate the both two stages of clustering in
name disambiguation. The steps are as follows:
</bodyText>
<listItem confidence="0.948923">
• DJ2+NER_2
</listItem>
<bodyText confidence="0.955570333333333">
This step is similar to the step of DJ2+NER
except that it additionally run the second-stage
clustering to improve recall.
</bodyText>
<listItem confidence="0.90024">
• NER2+DJ 2
</listItem>
<bodyText confidence="0.999190428571428">
This step also run the second-stage clustering
on the basis of NER2+DJ.
The performances of the two step are shown
in table 3. We can find that the F-scores both
have been improved substantially. And the two
steps still maintain the original distribution be-
tween precision and recall. That is, the
DJ2+NER_2, which has outperformance on re-
call in the name segmentation error detection,
still maintain the higher recall at the second-
stage clustering. And NER2+DJ_2 also main-
tains higher precision. This illustrates that the
clustering has no ability to remedy the short-
comings of NER in the prior-division.
</bodyText>
<table confidence="0.999499666666667">
P IP F-score
DJ2+NER_2 82.65 63.40 66.59
NER2+DJ_2 87.71 60.45 66.23
</table>
<tableCaption confidence="0.999725">
Table 3: Performances of two-stage clustering
</tableCaption>
<bodyText confidence="0.999326714285714">
The test results of the two systems mentioned in
section 3 are shown in the table 4. We also
show the performances of each stage clustering
as that on training dataset. We can find that the
poor performance mainly come from the low
recall, which illustrates that the DJ-based n-
gram disambiguation is not robust.
</bodyText>
<table confidence="0.997699363636363">
B-Cubed
precision recall F-Score
System1(one 85.26 28.43 37.74
t ) 84.51 44.17 51.42
System1(both
t
P-IP
P IP F-Score
System2(one 88.4 39.47 50.52
t ) 88.36 55.23 63.89
System2(both
</table>
<tableCaption confidence="0.786765">
Table 4 :Test results
5.Conclusions
</tableCaption>
<bodyText confidence="0.9916718125">
thm to help raise the recall score.
In this paper, we report a hybrid Chinese per-
sonal disambiguation system and a novel algo-
rithm for extract useful global n-gram features
from the context .Experiment showed that our
algorithm performed high precision and poor
recall. Furthermore, two-stage clustering can
handl a change in the one-stage clustering algo-
rithm, especially for recall score. In the future,
we will investigate global new types of features
to improve the recall score and local new types
of features to improve the precision score. For
instance, the location and organization besides
the person in the named-entities. And we try to
use Hierarchical Agglomerative Clustering al-
gori
</bodyText>
<note confidence="0.6259956">
References
Artiles J, J Gonzalo and S Sekine. 2007. The
SemEval-2007 WePS Evaluation:
for the Web People Search
The SemEval-2007, 64-69, Associa-
</note>
<reference confidence="0.957745952380953">
tion for Computational Linguistics.
Artiles Javier, Julio Gonzalo and Satoshi Se-
kine.2009A.
2 Evaluation Campaign:
overview of the Web People Search Cluster-
ing
In 2nd Web People Search
Evaluation Workshop (WePS 2009), 18th
WWW Conference.
Artiles J, E
and J Gonzalo. 2009B.The
Role of Named Entities in Web People
Search. Proceedings of the 2009 Conference
on Empirical Methods Natural Language
Processing,
August 2009.
Bagga A and Baldwin B. 1998. Entity-based
cross-document coreferenceing using the
Vector Space Model.Proceedings of the
international conference on computational
linguistics. Volume 1, 79-85.
Chen,Ying., Sophia Yat., Mei Lee and Chu-Ren
Huang. 2009.
Roubust Informa-
tion Extraction System for Web Personal
Names In 2nd Web People Search Evaluation
Workshop (WePS 2009), 18th WWW Con-
ference.
Chen Wen-liang, Zhang Yu-jie. 2006. Chinese
Named Entity Recognition with Conditional
Random Fields. Proceedings of the Fifth
SIGHAN Workshop on Chinese Language
Processing.
Cucerzan, Silviu. 2007. Large scale named en-
tity Disambiguation based on Wikipedia data.
In The EMNLP-CoNLL-2007.
Frey BJ and Dueck D. 2007. Clustering by
Passing Messages Between Data
Points .science, 2007 - sciencemag.org.
Ikeda MS, Ono I, Sato MY and Nakagawa H.
2009. Person Name disambiguation on the
Web by Two-Stage Clusteri
</reference>
<figure confidence="0.862110222222222">
“Establish-
inga benchmark
Task.”,
“WePS
Task,”
Amig´o
534–542,Singapore,
17th
PolyUHK:A
</figure>
<reference confidence="0.988683444444444">
ng. In 2nd Web
People Search Evaluation Workshop(WePS
2009),18th WWW Conference.
Popescu,O and Magnini, B. 2007. IRST-
BP:Web People Search Using Name Enti-
ties.Proceeding s of the 4th International
Workshop on Semantic Evaluations (SemE-
val-2007), 195-198, Prague June 2007. Asso-
ciation for Computational Linguistics.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000088">
<title confidence="0.997249">Distance based Chinese Person Name</title>
<author confidence="0.999901">Yu Hong Fei Pei Yue-hui Yang Jian-min Yao Qiao-ming Zhu</author>
<affiliation confidence="1">School of Computer Science and Technology, Soochow University</affiliation>
<address confidence="0.996561">No.1 Shizi street, Suzhou City, Jiansu Province, China</address>
<email confidence="0.93286">hongy@suda.edu.cn</email>
<email confidence="0.93286">20094527004@suda.edu.cn</email>
<email confidence="0.93286">0727401137@suda.edu.cn</email>
<email confidence="0.93286">jyao@suda.edu.cn</email>
<email confidence="0.93286">qmzhu@suda.edu.cn</email>
<abstract confidence="0.99778096875">In this paper, we describe a Chinese person name disambiguation system for news articles and report the results obtained on the data set of CLP 2010 The main task of the Bakeoff is to identify different persons from the news stories that contain the same person-name string. Compared to the traditional methods, two additional features are used in our system: 1) n-grams co-occurred with target name string; 2) Jumping distance among the n-grams. On the basis, we propose a two-stage clustering algorithm to improve the low recall. Novel Try For this task, we propose a Jumping-Distance based n-gram model (abbr. DJ n-gram) to describe the semantics of the closest contexts of the target person-name strings. The generation of the DJ n-gram model mainly involves two steps. First, we mine the Jumping tree for the target string; second, we give the statistical description of the tree. • Jumping Tree Given a target string, we firstly extract the sentence where it locates as its closest context. Then we segment the sentence into ngrams(Chen et al. ,2009) (only Bi-gram and Trigram are used in this paper). For each n-gram, we regard it as the beginning of a jumping journey. And the places where we jump are the sentences which involve the n-gram. By the same way, we segment the sentences into n-grams which will be regarded as the new beginnings to open further jumping. The procedure will run iteratively until there are no sentences in the by the National Natural Science Foundation of China under Grant No. 60970057, No.60873105. document (viz. the document which involves the target string) can be used to jump. Actually, we find there are only 3 jumps in average in our previous test and simultaneously 11 sentences in a document can be involved into the jumping journey. Thus, we can obtain a Jumping Tree where each jumping route from the initially ngram (viz. the gram in the closes context) refer to a branch. And for each intermediate node, its child-nodes are the n-grams co-occurred with it in the same sentences. The motivation to generate the Jumping Tree is to imitate the thinking model of human recognizing the word senses and semantics. In detail, for each intermediate node of the tree, its child-nodes all come from its closest contexts, especially the nodes co-occur with it in the same sentences which involve the real grammar and semantic relations. Thus the child-nodes normally provide the natural inference for its word sense. For example, given the string “SARS”, we can deduce its sense from its child nodes “Severe”, “Acute”, “Respiratory” and “Syndromes” even if we see the string for the first time. On the basis, the procedure of inference run iteratively, that is, the tree always use the child nodes deduce the meaning of their father nodes then further ancestor nodes until the root. Thus the tree acts as a hierarchical understanding procedure. Additionally, the distances among nodes in the tree give the degree of semantic relation. In the task of person-name disambiguation, we use the Jumping Tree to deduce the identities and backgrounds of a person. Each branch of the tree refers to a property of the person. • Jumping-Distance based n-gram model In this paper, we give a simple statistical model to describe the Jumping Tree. Given a node in the tree (viz. an n-gram), we record the steps jumping from the root to it, viz. the depth of the node in the tree. Then based on the prioritrained TFIDF value, we calculate the generation probability of the node as follows: TF  depth the the smoothing factor. In fact, we create more comprehensive models to describe the semantic correlations among the nodes in the Jumping Tree. The models well use the distances among the nodes in local Jumping Tree (viz. the tree generated based on the test document) and that normalized on the large-scale training data to calculate the probability of n-grams correboratively generate a semantics. They try to imitate the thinking model of human combine differents features to understand panoramic knowledge. In the task of name disambiguation, we can use the models to improve the distinguishment of different persons who have the same name. And we have illustrate the well effectiveness on the topic description and relevance measurement in other tasks, such as Link Detection. But we actually didn’t use the models to perform the task of name diaambiguation this time with the aim to purely evaluate the usefulness of the Jumping Tree. 2 Systems For the task of Chinese person name disambiguation, we submitted two systems as follows: • System1 The system involves two main components: DJ-based name Identification error detection and DJ-based person name disambiguation. The first component, viz. DJ-based name segmentation error detection, aims to distinguish the target string referring to person name from that referring to something else. Such as, string can be a person name “Hai Huang” but also a name of sea “the Yellow Sea”. And the detection component focuses on obtaining the pure person name “Hai Huang”. The detection component firstly establish two classes of features which respectively describe the nature of human and that of things. Such as, the features “professor”, “research”, “honest” et al., can roughly be determined as the nature of human, and conversely the features “solid”, “collapse”, “deep” et al., can be that of things. For obtaining the features, we extract 10,000 documents that discuss person, eg. “Albert Einstein” and 6000 documents that discuss technology, science, geography, et.al., from For each document, we generate its Jumping Tree, and regard the nodes in the tree as the features. After that, we combine the weights of the same features and normalized the value by dividing that by the average weight in the specific class of features. Based on the two classes of features, given a target string and the document where it occurs, the detection component firstly generate the Jumping Tree of the document, and then determines whether the string is person name or things by measuring the similarity of the tree to the classes of features. Here, we simply use the and Cosine metric and Baldwin, obtain the similarity. The second component, viz. DJ-based person name disambiguation, firstly generates the Jumping trees for all documents that involve specific person name. And a two-stage clustering algorithm is adopted to divide the documents and refer each cluster to a person. The first stage of the algorithm runs a strict division which focuses on obtaining high precision. The second stage performs a soft division which is used to improve recall. The two-stage clustering algorithm(Ikeda et al.,2009) initially obtains the optimal parameters that respectively refer to the maximum precision and recall based on training data, and then regards a statistical tradeoff as the final value of the parameters. Here, the Affinity Propagation clustering tools (Frey BJ and Dueck D, 2007) is in use. • System2 The system is similar to the system1 except that it additionally involve Named Entity Identification (Artiles et.al,2009B; Popescu,O. and Magnini, B.,2007)before the two-stage clustering in the component of person name disambiguation. In detail, given a person name and the documents that it occurs in, the disambiguation component of System2 firstly adopt NER by MSRA to identify Named Entities(Chen et al., 2006) that involve given name string, such as the entity (viz. Gao-ming Li in English) when given target name string Ming Gao in English). Thus the documents can be roughly divided into different clusters of Named Entities without name segmentation errors. After that, we additionally adopt the two-stage clustering algorithm to further divide each cluster. Thus we can deal with the issue of disambiguation without the interruption of name segmentation errors. 3 Data sets • Training dataset: They contain about 30 Chinese personal names, and a document set of about 100-300 news articles from collection of Xinhua news documents in a time span of fourteen years are provided for each personal name.</abstract>
<note confidence="0.696242">External dataset: Chinese personal attribution (Cucerzan, 2007; Nguyen and Cao,2008). • Test dataset: There are about 26 Chinese</note>
<abstract confidence="0.927429015873016">personal names, which are similar to train data sets. 4 Experiments The systems that run on test dataset are evaluated by both B-Cubed (Bagga and Baldwin, 1998; Artiles et al.,2009A) and P-IP (Artiles et al., 2007 ;Artiles et al.,2009A). And the systems that run on training dataset were only evaluated by B-Cubed. In experiments, we firstly evaluate the performance of name segmentation error detection on the training dataset. For comparison, we additionally perform another detection method which only using Name Entity Identifcation (NER CRF++ tools) to distinguish name-strings from the discarded ones. The results are shown in table 1. We can find that our error detection method can achieve more recall than NER, but lower precision. Besides, we evaluate the performance of the two-stage clustering in the component of name disambiguation step by step. Four steps are in use to evaluate the first-stage clustering method as follows: • This step look like to run the system1 mentionedin in section 3 which don’t involve the prior-division of documents by using NER before the first-stage clustering in the component of name disambiguation. Especially it don’t perform the second-stage clustering to improve the recall probability. • step is similar to the step of mentioned above except that it perform the priordivison of documents by using NER. • NER+DJ step is also similar to the step of except that its name segmentation error detection performs by using the NER. • This step is similar to the step of NER+DJ except that it involve the treatment of prioras that in The performances of the four steps are shown in table 2. We can find that all steps achieve recall. And the step of achieve the best F-score although it don’t involve the priordivision. That is because NER is helpful to improve precision but not recall, as shown in table Conversely, can avoid the bias caused by the procedure of greatly maximizing the precision. P recall F-score DJ-based 0.62 0.81 0.70 NER-based 0.91 0.77 0.71 Table 1: Performance of name error detection P IP F-score 80.49 53.85 60.12 88.56 51.30 59.02 NER+DJ 93.27 46.78 57.44 97.79 42.13 55.47 Table 2: Performances of the-stage clustering Additionally, another two steps are used to evluate the both two stages of clustering in name disambiguation. The steps are as follows: • step is similar to the step of except that it additionally run the second-stage clustering to improve recall. • 2 This step also run the second-stage clustering the basis of The performances of the two step are shown in table 3. We can find that the F-scores both have been improved substantially. And the two steps still maintain the original distribution between precision and recall. That is, the which has outperformance on recall in the name segmentation error detection, still maintain the higher recall at the secondclustering. And also maintains higher precision. This illustrates that the clustering has no ability to remedy the shortcomings of NER in the prior-division. P IP F-score 82.65 63.40 66.59 87.71 60.45 66.23 Table 3: Performances of two-stage clustering The test results of the two systems mentioned in section 3 are shown in the table 4. We also show the performances of each stage clustering as that on training dataset. We can find that the poor performance mainly come from the low recall, which illustrates that the DJ-based ngram disambiguation is not robust. B-Cubed precision recall F-Score System1(one 85.26 28.43 37.74 84.51 44.17 51.42 System1(both t P-IP P IP F-Score System2(one 88.4 39.47 50.52 t ) 88.36 55.23 63.89 System2(both Table 4 :Test results 5.Conclusions to help raise the recall this paper, we report a hybrid Chinese perdisambiguation system and a novel algorithm for extract useful global n-gram features from the context .Experiment showed that our algorithm performed high precision and poor recall. Furthermore, two-stage clustering can a change in the one-stage clustering algorithm, especially for recall score. In the future, we will investigate global new types of features to improve the recall score and local new types of features to improve the precision score. For instance, the location and organization besides the person in the named-entities. And we try to Hierarchical Agglomerative Clustering algori</abstract>
<note confidence="0.925416571428572">References Artiles J, J Gonzalo and S Sekine. 2007. The SemEval-2007 WePS Evaluation: for the Web People Search The SemEval-2007, 64-69, Association for Computational Linguistics. Artiles Javier, Julio Gonzalo and Satoshi Sekine.2009A. 2 Evaluation Campaign: overview of the Web People Search Clustering In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference. Artiles J, E and J Gonzalo. 2009B.The Role of Named Entities in Web People Search. Proceedings of the 2009 Conference on Empirical Methods Natural Language Processing, August 2009. Bagga A and Baldwin B. 1998. Entity-based cross-document coreferenceing using the Vector Space Model.Proceedings of the international conference on computational linguistics. Volume 1, 79-85. Chen,Ying., Sophia Yat., Mei Lee and Chu-Ren Huang. 2009.</note>
<title confidence="0.662684333333333">Roubust Information Extraction System for Web Personal Names In 2nd Web People Search Evaluation</title>
<note confidence="0.633174272727273">Workshop (WePS 2009), 18th WWW Conference. Chen Wen-liang, Zhang Yu-jie. 2006. Chinese Named Entity Recognition with Conditional Random Fields. Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing. Cucerzan, Silviu. 2007. Large scale named entity Disambiguation based on Wikipedia data. In The EMNLP-CoNLL-2007. Frey BJ and Dueck D. 2007. Clustering by</note>
<title confidence="0.574796">Passing Messages Between Data</title>
<note confidence="0.939279">Points .science, 2007 sciencemag.org. Ikeda MS, Ono I, Sato MY and Nakagawa H. 2009. Person Name disambiguation on the Web by Two-Stage Clusteri “Establishinga benchmark Task.”, “WePS Task,” Amig´o 534–542,Singapore, 17th PolyUHK:A ng. In 2nd Web People Search Evaluation Workshop(WePS 2009),18th WWW Conference. Popescu,O and Magnini, B. 2007. IRST- BP:Web People Search Using Name Entis of the International on Semantic Evaluations 195-198, Prague June 2007. Association for Computational Linguistics.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>tion for Computational Linguistics. Artiles Javier, Julio Gonzalo and Satoshi Sekine.2009A. 2 Evaluation Campaign: overview of the Web People Search Clustering</title>
<marker></marker>
<rawString>tion for Computational Linguistics. Artiles Javier, Julio Gonzalo and Satoshi Sekine.2009A. 2 Evaluation Campaign: overview of the Web People Search Clustering</rawString>
</citation>
<citation valid="false">
<booktitle>In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</booktitle>
<marker></marker>
<rawString>In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Artiles</author>
<author>E</author>
<author>J Gonzalo</author>
</authors>
<title>2009B.The Role of Named Entities in Web People Search.</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Conference on Empirical Methods Natural Language Processing,</booktitle>
<marker>Artiles, E, Gonzalo, 2009</marker>
<rawString>Artiles J, E and J Gonzalo. 2009B.The Role of Named Entities in Web People Search. Proceedings of the 2009 Conference on Empirical Methods Natural Language Processing, August 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bagga</author>
<author>B Baldwin</author>
</authors>
<title>Entity-based cross-document coreferenceing using the Vector Space Model.Proceedings of the international conference on computational linguistics.</title>
<date>1998</date>
<volume>1</volume>
<pages>79--85</pages>
<contexts>
<context position="6560" citStr="Bagga and Baldwin, 1998" startWordPosition="1094" endWordPosition="1097">r each document, we generate its Jumping Tree, and regard the nodes in the tree as the features. After that, we combine the weights of the same features and normalized the value by dividing that by the average weight in the specific class of features. Based on the two classes of features, given a target string and the document where it occurs, the detection component firstly generate the Jumping Tree of the document, and then determines whether the string is person name or things by measuring the similarity of the tree to the classes of features. Here, we simply use the VSM and Cosine metric ΰBagga and Baldwin, 1998α to obtain the similarity. The second component, viz. DJ-based person name disambiguation, firstly generates the Jumping trees for all documents that involve specific person name. And a two-stage clustering algorithm is adopted to divide the documents and refer each cluster to a person. The first stage of the algorithm runs a strict division which focuses on obtaining high precision. The second stage performs a soft division which is used to improve recall. The two-stage clustering algorithm(Ikeda et al.,2009) initially obtains the optimal parameters that respectively refer to the maximum pre</context>
<context position="8837" citStr="Bagga and Baldwin, 1998" startWordPosition="1457" endWordPosition="1460"> the issue of disambiguation without the interruption of name segmentation errors. 3 Data sets • Training dataset: They contain about 30 Chinese personal names, and a document set of about 100-300 news articles from collection of Xinhua news documents in a time span of fourteen years are provided for each personal name. • External dataset: Chinese Wikipedia2 personal attribution (Cucerzan, 2007; Nguyen and Cao,2008). • Test dataset: There are about 26 Chinese personal names, which are similar to train data sets. 4 Experiments The systems that run on test dataset are evaluated by both B-Cubed (Bagga and Baldwin, 1998; Artiles et al.,2009A) and P-IP (Artiles et al., 2007 ;Artiles et al.,2009A). And the systems that run on training dataset were only evaluated by B-Cubed. In experiments, we firstly evaluate the performance of name segmentation error detection on the training dataset. For comparison, we additionally perform another detection method which only using Name Entity Identifcation (NER CRF++ tools) to distinguish name-strings from the discarded ones. The results are shown in table 1. We can find that our error detection method can achieve more recall than NER, but lower precision. Besides, we evalua</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Bagga A and Baldwin B. 1998. Entity-based cross-document coreferenceing using the Vector Space Model.Proceedings of the international conference on computational linguistics. Volume 1, 79-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>Sophia Yat</author>
<author>Mei Lee</author>
<author>Chu-Ren Huang</author>
</authors>
<date>2009</date>
<marker>Chen, Yat, Lee, Huang, 2009</marker>
<rawString>Chen,Ying., Sophia Yat., Mei Lee and Chu-Ren Huang. 2009.</rawString>
</citation>
<citation valid="false">
<title>Roubust Information Extraction System for Web Personal Names</title>
<booktitle>In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</booktitle>
<marker></marker>
<rawString>Roubust Information Extraction System for Web Personal Names In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Wen-liang</author>
<author>Zhang Yu-jie</author>
</authors>
<title>Chinese Named Entity Recognition with Conditional Random Fields.</title>
<date>2006</date>
<booktitle>Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing.</booktitle>
<marker>Wen-liang, Yu-jie, 2006</marker>
<rawString>Chen Wen-liang, Zhang Yu-jie. 2006. Chinese Named Entity Recognition with Conditional Random Fields. Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large scale named entity Disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In The EMNLP-CoNLL-2007.</booktitle>
<contexts>
<context position="8611" citStr="Cucerzan, 2007" startWordPosition="1420" endWordPosition="1421">be roughly divided into different clusters of Named Entities without name segmentation errors. After that, we additionally adopt the two-stage clustering algorithm to further divide each cluster. Thus we can deal with the issue of disambiguation without the interruption of name segmentation errors. 3 Data sets • Training dataset: They contain about 30 Chinese personal names, and a document set of about 100-300 news articles from collection of Xinhua news documents in a time span of fourteen years are provided for each personal name. • External dataset: Chinese Wikipedia2 personal attribution (Cucerzan, 2007; Nguyen and Cao,2008). • Test dataset: There are about 26 Chinese personal names, which are similar to train data sets. 4 Experiments The systems that run on test dataset are evaluated by both B-Cubed (Bagga and Baldwin, 1998; Artiles et al.,2009A) and P-IP (Artiles et al., 2007 ;Artiles et al.,2009A). And the systems that run on training dataset were only evaluated by B-Cubed. In experiments, we firstly evaluate the performance of name segmentation error detection on the training dataset. For comparison, we additionally perform another detection method which only using Name Entity Identifcat</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Cucerzan, Silviu. 2007. Large scale named entity Disambiguation based on Wikipedia data. In The EMNLP-CoNLL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frey BJ</author>
<author>D Dueck</author>
</authors>
<title>Clustering by Passing Messages Between Data Points .science,</title>
<date>2007</date>
<note>sciencemag.org.</note>
<marker>BJ, Dueck, 2007</marker>
<rawString>Frey BJ and Dueck D. 2007. Clustering by Passing Messages Between Data Points .science, 2007 - sciencemag.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ikeda MS</author>
<author>I Ono</author>
<author>Sato MY</author>
<author>H Nakagawa</author>
</authors>
<title>Person Name disambiguation on the Web by Two-Stage Clusteri</title>
<date>2009</date>
<marker>MS, Ono, MY, Nakagawa, 2009</marker>
<rawString>Ikeda MS, Ono I, Sato MY and Nakagawa H. 2009. Person Name disambiguation on the Web by Two-Stage Clusteri</rawString>
</citation>
<citation valid="false">
<authors>
<author>ng</author>
</authors>
<booktitle>In 2nd Web People Search Evaluation Workshop(WePS 2009),18th WWW Conference.</booktitle>
<marker>ng, </marker>
<rawString>ng. In 2nd Web People Search Evaluation Workshop(WePS 2009),18th WWW Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Popescu</author>
<author>B Magnini</author>
</authors>
<title>IRSTBP:Web People Search Using Name</title>
<date>2007</date>
<booktitle>Entities.Proceeding s of the 4th International Workshop on Semantic Evaluations (SemEval-2007), 195-198,</booktitle>
<location>Prague</location>
<marker>Popescu, Magnini, 2007</marker>
<rawString>Popescu,O and Magnini, B. 2007. IRSTBP:Web People Search Using Name Entities.Proceeding s of the 4th International Workshop on Semantic Evaluations (SemEval-2007), 195-198, Prague June 2007. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>