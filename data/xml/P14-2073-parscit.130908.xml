<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003057">
<title confidence="0.949734">
Particle Filter Rejuvenation and Latent Dirichlet Allocation
</title>
<author confidence="0.984846">
Chandler May,† Alex Clemmer‡ and Benjamin Van Durme††Human Language Technology Center of Excellence
</author>
<affiliation confidence="0.8392475">
Johns Hopkins University
‡Microsoft
</affiliation>
<email confidence="0.996852">
cjmay@jhu.edu,clemmer.alexander@gmail.com,vandurme@cs.jhu.edu
</email>
<sectionHeader confidence="0.998586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999765714285714">
Previous research has established sev-
eral methods of online learning for la-
tent Dirichlet allocation (LDA). How-
ever, streaming learning for LDA—
allowing only one pass over the data and
constant storage complexity—is not as
well explored. We use reservoir sam-
pling to reduce the storage complexity
of a previously-studied online algorithm,
namely the particle filter, to constant. We
then show that a simpler particle filter im-
plementation performs just as well, and
that the quality of the initialization dom-
inates other factors of performance.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918081081081">
We extend a popular model, latent Dirichlet al-
location (LDA), to unbounded streams of docu-
ments. In order for inference to be practical in
this setting it must use constant space asymptoti-
cally and run in pseudo-linear time, perhaps O(n)
or O(n log n).
Canini et al. (2009) presented a method for LDA
inference based on particle filters, where a sam-
ple set of models is updated online with each new
token observed from a stream. In general, these
models should be regularly resampled and rejuve-
nated using Markov Chain Monte Carlo (MCMC)
steps over the history in order to improve the ef-
ficiency of the particle filter (Gilks and Berzuini,
2001). The particle filter of Canini et al. (2009) re-
juvenates over independent draws from the history
by storing all past observations and states. This al-
gorithm thus has linear storage complexity and is
not an online learning algorithm in a strict sense
(B¨orschinger and Johnson, 2012).
In the current work we propose using reservoir
sampling in the rejuvenation step to reduce the
storage complexity of the particle filter to O(1).
This improvement is practically useful in the
large-data setting and is also scientifically interest-
ing in that it recovers some of the cognitive plau-
sibility which originally motivated B¨orschinger
and Johnson (2012). However, in experiments on
the dataset studied by Canini et al. (2009), we
show that rejuvenation does not benefit the par-
ticle filter’s performance. Rather, performance
is dominated by the effects of random initializa-
tion (a problem for which we provide a correction
while abiding by the same constraints as Canini et
al. (2009)). This result re-opens the question of
whether rejuvenation is of practical importance in
online learning for static Bayesian models.
</bodyText>
<sectionHeader confidence="0.990189" genericHeader="method">
2 Latent Dirichlet Allocation
</sectionHeader>
<bodyText confidence="0.998975454545454">
For a sequence of N words collected into doc-
uments of varying length, we denote the j-th
word as wj, and the document it occurs in as di.
LDA (Blei et al., 2003) “explains” the occurrence
of each word by postulating that a document was
generated by repeatedly: (1) sampling a topic z
from θ(d), the document-specific mixture of T top-
ics, and (2) sampling a word w from φ(z), the
probability distribution the z-th topic defines over
the vocabulary.
The goal is to infer θ and φ, under the model:
</bodyText>
<equation confidence="0.999629">
wi  |zi, φ(zi) ∼ Categorical(φ(zi))
φ(z) ∼ Dirichlet(β)
zi  |θ(di) ∼ Categorical(θ(di))
θ(d) ∼ Dirichlet(α)
</equation>
<page confidence="0.939174">
446
</page>
<bodyText confidence="0.7043694">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 446–451,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
initialize weights W(p) 0= 1/P for p = 1, ... ,P
for i = 1, ... ,N do
for p = 1, ... ,P do
</bodyText>
<equation confidence="0.966181411764706">
set W�p) = W(p)i−1P(wi  |z(p)
i−1, wi−1)
sample z(p) iw.p. P(z(p)
i  |z(p)
i−1, wi).
if 11W11−2
2 &lt; ESS then
for j E R(i) do
for p = 1, ... ,P do
sample z(p)
j w.p.
P(z(p)
j  |z(p)
i\j, wi)
set W(p)
i = 1/P for each particle
Algorithm 1: Particle filtering for LDA.
</equation>
<bodyText confidence="0.999696576923077">
Computing φ and θ exactly is generally in-
tractable, motivating methods for approximate in-
ference such as variational Bayesian inference
(Blei et al., 2003), expectation propagation (Minka
and Lafferty, 2002), and collapsed Gibbs sampling
(Griffiths and Steyvers, 2004).
A limitation of these techniques is they require
multiple passes over the data to obtain good sam-
ples of φ and θ. This requirement makes them im-
practical when the corpus is too large to fit directly
into memory and in particular when the corpus
grows without bound. This motivates online learn-
ing techniques, including sampling-based meth-
ods (Banerjee and Basu, 2007; Canini et al., 2009)
and stochastic variational inference (Hoffman et
al., 2010; Mimno et al., 2012; Hoffman et al.,
2013). However, where these approaches gener-
ally assume the ability to draw independent sam-
ples from the full dataset, we consider the case
when it is infeasible to access arbitrary elements
from the history. The one existing algorithm that
can be directly applied under this constraint, to
our knowledge, is the streaming variational Bayes
framework (Broderick et al., 2013) in which the
posterior is recursively updated as new data arrives
using a variational approximation.
</bodyText>
<sectionHeader confidence="0.998575" genericHeader="method">
3 Online LDA Using Particle Filters
</sectionHeader>
<bodyText confidence="0.999954518518519">
Particle filters are a family of sequential Monte
Carlo (SMC) sampling algorithms designed to es-
timate the posterior distribution of a system with
dynamic state (Doucet et al., 2001). A particle fil-
ter approximates the posterior by a weighted sam-
ple of points, or particles, from the state space.
The particle cloud is updated recursively for each
new observation using importance sampling (an
approach called sequential importance sampling).
Canini et al. (2009) apply this approach to LDA
after analytically integrating out φ and θ, obtain-
ing a Rao-Blackwellized particle filter (Doucet et
al., 2000) that estimates the collapsed posterior
P(z  |w). In this setting, the P particles are sam-
ples of the topic assignment vector z(p), and they
are propagated forward in state space one token at
a time. In general, the larger P is, the more ac-
curately we approximate the posterior; for small
P, the approximation of the tails of the poste-
rior will be particularly poor (Pitt and Shephard,
1999). However, a larger value of P increases the
runtime and storage requirements of the algorithm.
We now describe the Rao-Blackwellized parti-
cle filter for LDA in detail (pseudocode is given in
Algorithm 1). At the moment token i is observed,
the particles form a discrete approximation of the
posterior up to the (i − 1)-th word:
</bodyText>
<equation confidence="0.959626">
ωi−1Izi−1(z(p)
(p) i−1)
</equation>
<bodyText confidence="0.99981975">
where Iz(z0) is the indicator function, evaluating
to 1 if z = z0 and 0 otherwise. Now each par-
ticle p is propagated forward by drawing a topic
zi from the conditional posterior distribution
</bodyText>
<equation confidence="0.957604">
(p)
P(z(p)
i  |z(p)
i−1, wi) and scaling the particle weight
by P(wi  |z(p)
</equation>
<bodyText confidence="0.948495142857143">
i−1, wi−1). The particle cloud now
approximates the posterior up to the i-th word:
ωi Izi(z(p)
(p) i ).
Dropping the superscript (p) for notational conve-
nience, the conditional posterior used in the prop-
agation step is given by
</bodyText>
<equation confidence="0.999246">
P(zi|zi−1,wi) ∝ P(zi,wi  |zi−1,wi−1)
nzi,i\i + β
(wi)
n(·)
zi,i\i + Wβ
</equation>
<bodyText confidence="0.9744212">
where n(wi) is the number of times word wi has
zi,i\i
been assigned topic zi so far, n(·)
zi,i\i is the num-
ber of times any word has been assigned topic zi,
n(di)i is the number of times topic zi has been as-
signed to any word in document di, and n(di) is the
,i\i
number of words observed in document di. The
particle weights are scaled as
</bodyText>
<equation confidence="0.951390166666667">
P(wi  |z(p) i ,wi)P(z(p) i |z(p)
i−1)
Q(z(p) i |z(p)
i−1, wi)
= P(wi  |z(p)
i−1, wi−1)
�P(zi−1  |wi−1) ≈
p
�P(zi  |wi) ≈
p
nzi,i\i+ α
(di)
n(di)
·,i\i + Tα
ω(p)
i ∝
(p)
ωi−1
</equation>
<page confidence="0.99301">
447
</page>
<bodyText confidence="0.9998635">
where Q is the proposal distribution for the parti-
cle state transition; in our case,
</bodyText>
<equation confidence="0.876414333333333">
Q(z(p) i |z(p)
i−1, wi) = P(z(p) i |z(p)
i−1, wi),
</equation>
<bodyText confidence="0.999092217391304">
minimizing the variance of the importance weights
conditioned on wi and zi−1 (Doucet et al., 2000).
Over time the particle weights tend to diverge.
To combat this inefficiency, after every state tran-
sition we estimate the effective sample size (ESS)
of the particle weights as�ωi�−2
2 (Liu and Chen,
1998) and resample the particles when that esti-
mate drops below a prespecified threshold. Sev-
eral resampling strategies have been proposed
(Doucet et al., 2000); we perform multinomial
resampling as in Pitt and Shephard (1999) and
Ahmed et al. (2011), treating the weights as un-
normalized probability masses on the particles.
After resampling we are likely to have several
copies of the same particle, yielding a degenerate
approximation to the posterior. To reintroduce di-
versity to the particle cloud we take MCMC steps
over a sequence of states from the history (Doucet
et al., 2000; Gilks and Berzuini, 2001). We call the
indices of these states the rejuvenation sequence,
denoted R(i) (Canini et al., 2009). The transition
probability for a state j E R(i) is given by
</bodyText>
<equation confidence="0.97867">
P(zj  |zN\j, wN) OC n(wj) n(dj) + α
zj,N\j + β zj,N\j
n(·) n(dj) + Tα
zj,N\j + Wβ ·,N\j
</equation>
<bodyText confidence="0.999990833333333">
where subscript N\j denotes counts up to token
N, excluding those for token j.
The rejuvenation sequence can be chosen by
the practitioner. Choosing a long sequence (large
|R(i)|) may result in a more accurate posterior ap-
proximation but also increases runtime and stor-
age requirements. The tokens in R(i) may be cho-
sen uniformly at random from the history or under
a biased scheme that favors recent observations.
The particle filter studied empirically by Canini et
al. (2009) stored the entire history, incurring lin-
ear storage complexity in the size of the stream.
Ahmed et al. (2011) instead sampled ten docu-
ments from the most recent 1000, achieving con-
stant storage complexity at the cost of a recency
bias. If we want to fit a model to a long non-
i.i.d. stream, we require an unbiased rejuvenation
sequence as well as sub-linear storage complexity.
</bodyText>
<sectionHeader confidence="0.998056" genericHeader="method">
4 Reservoir Sampling
</sectionHeader>
<bodyText confidence="0.997748125">
Reservoir sampling is a widely-used family of al-
gorithms for choosing an array (“reservoir”) of k
items. The most common example, presented in
Vitter (1985) as Algorithm R, chooses k elements
of a stream such that each possible subset of k el-
ements is equiprobable. This effects sampling k
items uniformly without replacement, using run-
time O(n) (constant per update) and storage O(k).
</bodyText>
<figure confidence="0.706649444444444">
Initialize k-element array R ;
Stream S ;
for i = 1, ... ,k do
R[i] ← S[i] ;
for i = k + 1, ... ,length(S) do
j ← random(1, i);
if j ≤ k then
R[j] ← S[i] ;
Algorithm 2: Algorithm R for reservoir sampling
</figure>
<bodyText confidence="0.9991781">
To ensure constant space over an unbounded
stream, we draw the rejuvenation sequence R(i)
uniformly from a reservoir. As each token of the
training data is ingested by the particle filter, we
decide to insert that token into the reservoir, or not,
independent of the other tokens in the current doc-
ument. Thus, at the end of step i of the particle fil-
ter, each of the i tokens seen so far in the training
sequence has an equal probability of being in the
reservoir, hence being selected for rejuvenation.
</bodyText>
<sectionHeader confidence="0.999639" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999844944444444">
We evaluate our particle filter on three datasets
studied in Canini et al. (2009): diff3, rel3,
and sim3. Each of these datasets is a collection
of posts under three categories from the 20 News-
groups dataset.1 We use a 60% training/40% test-
ing split of this data that is available online.2
We preprocess the data by splitting each line
on non-alphabet characters, converting the result-
ing tokens to lower-case, and filtering out any to-
kens that appear in a list of common English stop
words. In addition, we remove the header of ev-
ery file and filter every line that does not contain
a non-trailing space (which removes embedded
ASCII-encoded attachments). Finally, we shuffle
the order of the documents. After these steps, we
compute the vocabulary for each dataset as the set
of all non-singleton types in the training data aug-
mented with a special out-of-vocabulary symbol.
</bodyText>
<footnote confidence="0.7793955">
1diff3: {rec.sport.baseball, sci.space,
alt.atheism}; rel3: talk.politics.{misc,
guns, mideast}; and sim3: comp.{graphics,
os.ms-windows.misc, windows.x}.
2http://qwone.com/˜jason/20Newsgroups/
20news-bydate.tar.gz
</footnote>
<page confidence="0.994608">
448
</page>
<figureCaption confidence="0.999769">
Figure 1: Fixed initialization with different reservoir sizes.
</figureCaption>
<bodyText confidence="0.999979766666667">
During training we report the out-of-sample
NMI, calculated by holding the word proportions
φ fixed, running five sweeps of collapsed Gibbs
sampling on the test set, and computing the topic
for each document as the topic assigned to the
most tokens in that document. Two Gibbs sweeps
have been shown to yield good performance in
practice (Yao et al., 2009); we increase the num-
ber of sweeps to five after inspecting the stability
on our dataset. The variance of the particle filter is
often large, so for each experiment we perform 30
runs and plot the mean NMI inside bands spanning
one sample standard deviation in either direction.
Fixed Initialization. Our first set of experi-
ments has a similar parameterization3 to the exper-
iments of Canini et al. (2009) except we draw the
rejuvenation sequence from a reservoir. We initial-
ize the particle filter with 200 Gibbs sweeps on the
first 10% of each dataset. Then, for each dataset,
for rejuvenation disabled, rejuvenation based on
a reservoir of size 1000, and rejuvenation based
on the entire history (in turn), we perform 30 runs
of the particle filter from that fixed initial model.
Our results (Figure 1) resemble those of Canini et
al. (2009); we believe the discrepancies are mostly
attributable to differences in preprocessing.
In these experiments, the initial model was not
chosen arbitrarily. Rather, an initial model that
yielded out-of-sample NMI close to the initial out-
of-sample NMI scores reported in the previous
</bodyText>
<equation confidence="0.879117">
3T = 3, α = β = 0.1, P = 100, ess = 20, |R(i) |= 30
</equation>
<figureCaption confidence="0.999527">
Figure 2: Variable initialization with different initialization
sample sizes.
</figureCaption>
<bodyText confidence="0.999848266666667">
study was chosen from a set of 100 candidates.
Variable Initialization. We now investigate the
significance of the initial model selection step used
in the previous experiments. We run a new set
of experiments in which the reservoir size is held
fixed at 1000 and the size of the initialization sam-
ple is varied. Specifically, we vary the size of
the initialization sample, in documents, between
zero (corresponding to no Gibbs initialization), 30,
100, and 300, and also perform a run of batch
Gibbs sampling (with no particle filter). In each
case, 2000 Gibbs sweeps are performed. In these
experiments, the initial models are not held fixed;
for each of the 30 runs for each dataset, the initial
model was generated by a different Gibbs chain.
The results for these experiments, depicted in Fig-
ure 2, indicate that the size of the initialization
sample improves mean NMI and reduces variance,
and that the variance of the particle filter itself is
dominated by the variance of the initial model.
Tuned Initialization. We observed previously
that variance in the Gibbs initialization of the
model contributes significantly to variance of the
overall algorithm, as measured by NMI. With
this in mind, we consider whether we can reduce
variance in the initialization by tuning the initial
model. Thus we perform a set of experiments in
which we perform Gibbs initialization 20 times
on the initialization set, setting the particle filter’s
initial model to the model out of these 20 with
</bodyText>
<page confidence="0.999081">
449
</page>
<figureCaption confidence="0.999025">
Figure 3: Variable initialization with tuning.
</figureCaption>
<bodyText confidence="0.999984285714286">
the highest in-sample NMI. This procedure is per-
formed independently for each run of the particle
filter. We may not always have labeled data for
initialization, so we also consider a variation in
which Gibbs initialization is performed 20 times
on the first 80% of the initialization sample, held-
out perplexity (per word) is estimated on the re-
maining 20%, using a first-moment particle learn-
ing approximation (Scott and Baldridge, 2013),
and the particle filter is started from the model
out of these 20 with the lowest held-out perplex-
ity. The results, shown in Figure 3, show that we
can ameliorate the variance due to initialization by
tuning the initial model to NMI or perplexity.
</bodyText>
<sectionHeader confidence="0.999059" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999942155555556">
Motivated by a desire for cognitive plausibility,
B¨orschinger and Johnson (2011) used a particle
filter to learn Bayesian word segmentation mod-
els, following the work of Canini et al. (2009).
They later showed that rejuvenation improved per-
formance (B¨orschinger and Johnson, 2012), but
this impaired cognitive plausibility by necessitat-
ing storage of all previous states and observations.
We attempted to correct this by drawing the re-
juvenation sequence from a reservoir, but our re-
sults indicate that the particle filter for LDA on our
dataset is highly sensitive to initialization and not
influenced by rejuvenation.
In the experiments of B¨orschinger and Johnson
(2012), the particle cloud appears to be resampled
once per utterance with a large rejuvenation se-
quence;4 each particle takes many more rejuvena-
tion MCMC steps than new state transitions and
thus resembles a batch MCMC sampler. In our ex-
periments resampling is done on the order of once
per document, leading to less than one rejuvena-
tion step per transition. Future work should care-
fully note this ratio: sampling history much more
often than new states improves performance but
contradicts the intuition behind particle filters.
We have also shown that tuning the initial model
using in-sample NMI or held-out perplexity can
improve mean NMI and reduce variance. Perplex-
ity (or likelihood) is often used to estimate model
performance in LDA (Blei et al., 2003; Griffiths
and Steyvers, 2004; Wallach et al., 2009; Hoff-
man et al., 2010), and does not compare the in-
ferred model against gold-standard labels, yet it
appears to be a good proxy for NMI in our experi-
ment. Thus, if initialization continues to be crucial
to performance, at least we may have the flexibil-
ity of initializing without gold-standard labels.
We have focused on NMI as our evaluation met-
ric for comparison with Canini et al. (2009). How-
ever, evaluation of topic models is a subject of con-
siderable debate (Wallach et al., 2009; Yao et al.,
2009; Newman et al., 2010; Mimno et al., 2011)
and it may be informative to investigate the effects
of initialization and rejuvenation using other met-
rics such as perplexity or semantic coherence.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.988467333333333">
We have proposed reservoir sampling for reduc-
ing the storage complexity of a particle filter from
linear to constant. This work was motivated as
an expected improvement on the model of Canini
et al. (2009). However, in the process of estab-
lishing an empirical baseline we discovered that
rejuvenation does not play a significant role in
the experiments of Canini et al. (2009). More-
over, we found that performance of the particle
filter was strongly affected by the random initial-
ization of the model, and suggested a simple ap-
proach to reduce the variability therein without
using additional data. In conclusion, it is now
an open question whether—and if so, under what
assumptions—rejuvenation benefits particle filters
for LDA and similar static Bayesian models.
Acknowledgments We thank Frank Ferraro,
Keith Levin, and Mark Dredze for discussions.
</bodyText>
<footnote confidence="0.9915575">
4The ESS threshold is P; the rejuvenation sequence is 100
or 1600 utterances, almost one sixth of the training data.
</footnote>
<page confidence="0.996539">
450
</page>
<sectionHeader confidence="0.99604" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999624702970297">
Amr Ahmed, Qirong Ho, Jacob Eisenstein, Eric P.
Xing, Alexander J. Smola, and Choon Hui Teo.
2011. Unified analysis of streaming news. In Pro-
ceedings of the 20th International World Wide Web
Conference (WWW), pages 267–276.
Arindam Banerjee and Sugato Basu. 2007. Topic
models over text streams: A study of batch and on-
line unsupervised learning. In Proceedings of the
7th SIAM International Conference on Data Mining
(SDM), pages 431–436.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022, Jan.
Benjamin B¨orschinger and Mark Johnson. 2011. A
particle filter algorithm for Bayesian wordsegmen-
tation. In Proceedings of the Australasian Lan-
guage Technology Association Workshop (ALTA),
pages 10–18.
Benjamin B¨orschinger and Mark Johnson. 2012. Us-
ing rejuvenation to improve particle filtering for
Bayesian word segmentation. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 85–89.
Tamara Broderick, Nicholas Boyd, Andre Wibisono,
Ashia C. Wilson, and Michael I. Jordan. 2013.
Streaming variational Bayes. In Advances in Neu-
ral Information Processing Systems 26 (NIPS).
Kevin R. Canini, Lei Shi, and Thomas L. Griffiths.
2009. Online inference of topics with latent Dirich-
let allocation. In Proceedings of the 12th Inter-
national Conference on Artificial Intelligence and
Statistics (AISTATS).
Arnaud Doucet, Nando de Freitas, Kevin Murphy, and
Stuart Russell. 2000. Rao-Blackwellised particle
filtering for dynamic Bayesian networks. In Pro-
ceedings of the 16th Conference on Uncertainty in
Artificial Intelligence (UAI), pages 176–183.
Arnaud Doucet, Nando de Freitas, and Neil Gordon,
editors. 2001. Sequential Monte Carlo Methods in
Practice. Springer, New York.
Walter R. Gilks and Carlo Berzuini. 2001. Following a
moving target—Monte Carlo inference for dynamic
Bayesian models. Journal of the Royal Statistical
Society, 63(1):127–146.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences, 101(suppl 1):5228–5235, Apr.
Matthew D. Hoffman, David M. Blei, and Francis
Bach. 2010. Online learning for latent Dirichlet
allocation. In Advances in Neural Information Pro-
cessing Systems 23 (NIPS).
Matthew D. Hoffman, David M. Blei, Chong Wang,
and John Paisley. 2013. Stochastic variational in-
ference. Journal of Machine Learning Research,
14:1303–1347, May.
Jun S. Liu and Rong Chen. 1998. Sequential Monte
Carlo methods for dynamic systems. Journal of
the American Statistical Association, 93(443):1032–
1044, Sep.
David Mimno, Hanna M. Wallach, Edmund Talley,
Miriam Leenders, and Andrew McCallum. 2011.
Optimizing semantic coherence in topic models. In
Proceedings of the Conference on Empirical Meth-
ods on Natural Language Processing (EMNLP),
pages 262–272.
David Mimno, Matthew D. Hoffman, and David M.
Blei. 2012. Sparse stochastic inference for la-
tent Dirichlet allocation. In Proceedings of the
29th International Conference on Machine Learning
(ICML).
Thomas Minka and John Lafferty. 2002. Expectation-
propagation for the generative aspect model. In Pro-
ceedings of the 18th Conference on Uncertainty in
Artificial Intelligence (UAI), pages 352–359.
David Newman, Jey Han Lau, Karl Grieser, and Tim-
othy Baldwin. 2010. Automatic evaluation of topic
coherence. In Human Language Technologies: 11th
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL HLT), pages 100–108.
Michael K. Pitt and Neil Shephard. 1999. Filtering via
simulation: Auxiliary particle filters. Journal of the
American Statistical Association, 94(446):590–599,
Jun.
James G. Scott and Jason Baldridge. 2013. A recur-
sive estimate for the predictive likelihood in a topic
model. In Proceedings of the 16th International
Conference on Artificial Intelligence and Statistics
(AISTATS).
Jeffrey S. Vitter. 1985. Random sampling with a reser-
voir. ACM Transactions on Mathematical Software,
11(1):37–57, Mar.
Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov,
and David Mimno. 2009. Evaluation methods for
topic models. In Proceedings of the 26th Interna-
tional Conference on Machine Learning (ICML).
Limin Yao, David Mimno, and Andrew McCallum.
2009. Efficient methods for topic model inference
on streaming document collections. In 15th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 937–946.
</reference>
<page confidence="0.998746">
451
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.397022">
<title confidence="0.98989">Particle Filter Rejuvenation and Latent Dirichlet Allocation</title>
<author confidence="0.612967">Alex</author>
<author confidence="0.612967">Van_Language Technology Center of Johns Hopkins</author>
<abstract confidence="0.993965666666666">Previous research has established sevmethods of for latent Dirichlet allocation (LDA). Howfor LDA— allowing only one pass over the data and constant storage complexity—is not as well explored. We use reservoir sampling to reduce the storage complexity of a previously-studied online algorithm, namely the particle filter, to constant. We then show that a simpler particle filter implementation performs just as well, and that the quality of the initialization dominates other factors of performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amr Ahmed</author>
<author>Qirong Ho</author>
<author>Jacob Eisenstein</author>
<author>Eric P Xing</author>
<author>Alexander J Smola</author>
<author>Choon Hui Teo</author>
</authors>
<title>Unified analysis of streaming news.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th International World Wide Web Conference (WWW),</booktitle>
<pages>267--276</pages>
<contexts>
<context position="8164" citStr="Ahmed et al. (2011)" startWordPosition="1356" endWordPosition="1359">ion; in our case, Q(z(p) i |z(p) i−1, wi) = P(z(p) i |z(p) i−1, wi), minimizing the variance of the importance weights conditioned on wi and zi−1 (Doucet et al., 2000). Over time the particle weights tend to diverge. To combat this inefficiency, after every state transition we estimate the effective sample size (ESS) of the particle weights as�ωi�−2 2 (Liu and Chen, 1998) and resample the particles when that estimate drops below a prespecified threshold. Several resampling strategies have been proposed (Doucet et al., 2000); we perform multinomial resampling as in Pitt and Shephard (1999) and Ahmed et al. (2011), treating the weights as unnormalized probability masses on the particles. After resampling we are likely to have several copies of the same particle, yielding a degenerate approximation to the posterior. To reintroduce diversity to the particle cloud we take MCMC steps over a sequence of states from the history (Doucet et al., 2000; Gilks and Berzuini, 2001). We call the indices of these states the rejuvenation sequence, denoted R(i) (Canini et al., 2009). The transition probability for a state j E R(i) is given by P(zj |zN\j, wN) OC n(wj) n(dj) + α zj,N\j + β zj,N\j n(·) n(dj) + Tα zj,N\j +</context>
</contexts>
<marker>Ahmed, Ho, Eisenstein, Xing, Smola, Teo, 2011</marker>
<rawString>Amr Ahmed, Qirong Ho, Jacob Eisenstein, Eric P. Xing, Alexander J. Smola, and Choon Hui Teo. 2011. Unified analysis of streaming news. In Proceedings of the 20th International World Wide Web Conference (WWW), pages 267–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arindam Banerjee</author>
<author>Sugato Basu</author>
</authors>
<title>Topic models over text streams: A study of batch and online unsupervised learning.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th SIAM International Conference on Data Mining (SDM),</booktitle>
<pages>431--436</pages>
<contexts>
<context position="4424" citStr="Banerjee and Basu, 2007" startWordPosition="715" endWordPosition="718">nd θ exactly is generally intractable, motivating methods for approximate inference such as variational Bayesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 On</context>
</contexts>
<marker>Banerjee, Basu, 2007</marker>
<rawString>Arindam Banerjee and Sugato Basu. 2007. Topic models over text streams: A study of batch and online unsupervised learning. In Proceedings of the 7th SIAM International Conference on Data Mining (SDM), pages 431–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="2779" citStr="Blei et al., 2003" startWordPosition="433" endWordPosition="436">t studied by Canini et al. (2009), we show that rejuvenation does not benefit the particle filter’s performance. Rather, performance is dominated by the effects of random initialization (a problem for which we provide a correction while abiding by the same constraints as Canini et al. (2009)). This result re-opens the question of whether rejuvenation is of practical importance in online learning for static Bayesian models. 2 Latent Dirichlet Allocation For a sequence of N words collected into documents of varying length, we denote the j-th word as wj, and the document it occurs in as di. LDA (Blei et al., 2003) “explains” the occurrence of each word by postulating that a document was generated by repeatedly: (1) sampling a topic z from θ(d), the document-specific mixture of T topics, and (2) sampling a word w from φ(z), the probability distribution the z-th topic defines over the vocabulary. The goal is to infer θ and φ, under the model: wi |zi, φ(zi) ∼ Categorical(φ(zi)) φ(z) ∼ Dirichlet(β) zi |θ(di) ∼ Categorical(θ(di)) θ(d) ∼ Dirichlet(α) 446 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 446–451, Baltimore, Maryland, USA, June 23-25 </context>
<context position="17201" citStr="Blei et al., 2003" startWordPosition="2852" endWordPosition="2855">tion MCMC steps than new state transitions and thus resembles a batch MCMC sampler. In our experiments resampling is done on the order of once per document, leading to less than one rejuvenation step per transition. Future work should carefully note this ratio: sampling history much more often than new states improves performance but contradicts the intuition behind particle filters. We have also shown that tuning the initial model using in-sample NMI or held-out perplexity can improve mean NMI and reduce variance. Perplexity (or likelihood) is often used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) a</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin B¨orschinger</author>
<author>Mark Johnson</author>
</authors>
<title>A particle filter algorithm for Bayesian wordsegmentation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop (ALTA),</booktitle>
<pages>10--18</pages>
<marker>B¨orschinger, Johnson, 2011</marker>
<rawString>Benjamin B¨orschinger and Mark Johnson. 2011. A particle filter algorithm for Bayesian wordsegmentation. In Proceedings of the Australasian Language Technology Association Workshop (ALTA), pages 10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin B¨orschinger</author>
<author>Mark Johnson</author>
</authors>
<title>Using rejuvenation to improve particle filtering for Bayesian word segmentation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>85--89</pages>
<marker>B¨orschinger, Johnson, 2012</marker>
<rawString>Benjamin B¨orschinger and Mark Johnson. 2012. Using rejuvenation to improve particle filtering for Bayesian word segmentation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 85–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara Broderick</author>
<author>Nicholas Boyd</author>
<author>Andre Wibisono</author>
<author>Ashia C Wilson</author>
<author>Michael I Jordan</author>
</authors>
<title>Streaming variational Bayes.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems 26 (NIPS).</booktitle>
<contexts>
<context position="4918" citStr="Broderick et al., 2013" startWordPosition="793" endWordPosition="796"> corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 Online LDA Using Particle Filters Particle filters are a family of sequential Monte Carlo (SMC) sampling algorithms designed to estimate the posterior distribution of a system with dynamic state (Doucet et al., 2001). A particle filter approximates the posterior by a weighted sample of points, or particles, from the state space. The particle cloud is updated recursively for each new observation using importance sampling (an approach called sequential importance sampling). Canini et al. (2009</context>
</contexts>
<marker>Broderick, Boyd, Wibisono, Wilson, Jordan, 2013</marker>
<rawString>Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C. Wilson, and Michael I. Jordan. 2013. Streaming variational Bayes. In Advances in Neural Information Processing Systems 26 (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin R Canini</author>
<author>Lei Shi</author>
<author>Thomas L Griffiths</author>
</authors>
<title>Online inference of topics with latent Dirichlet allocation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS).</booktitle>
<contexts>
<context position="1102" citStr="Canini et al. (2009)" startWordPosition="157" endWordPosition="160">is not as well explored. We use reservoir sampling to reduce the storage complexity of a previously-studied online algorithm, namely the particle filter, to constant. We then show that a simpler particle filter implementation performs just as well, and that the quality of the initialization dominates other factors of performance. 1 Introduction We extend a popular model, latent Dirichlet allocation (LDA), to unbounded streams of documents. In order for inference to be practical in this setting it must use constant space asymptotically and run in pseudo-linear time, perhaps O(n) or O(n log n). Canini et al. (2009) presented a method for LDA inference based on particle filters, where a sample set of models is updated online with each new token observed from a stream. In general, these models should be regularly resampled and rejuvenated using Markov Chain Monte Carlo (MCMC) steps over the history in order to improve the efficiency of the particle filter (Gilks and Berzuini, 2001). The particle filter of Canini et al. (2009) rejuvenates over independent draws from the history by storing all past observations and states. This algorithm thus has linear storage complexity and is not an online learning algor</context>
<context position="2453" citStr="Canini et al. (2009)" startWordPosition="377" endWordPosition="380">n step to reduce the storage complexity of the particle filter to O(1). This improvement is practically useful in the large-data setting and is also scientifically interesting in that it recovers some of the cognitive plausibility which originally motivated B¨orschinger and Johnson (2012). However, in experiments on the dataset studied by Canini et al. (2009), we show that rejuvenation does not benefit the particle filter’s performance. Rather, performance is dominated by the effects of random initialization (a problem for which we provide a correction while abiding by the same constraints as Canini et al. (2009)). This result re-opens the question of whether rejuvenation is of practical importance in online learning for static Bayesian models. 2 Latent Dirichlet Allocation For a sequence of N words collected into documents of varying length, we denote the j-th word as wj, and the document it occurs in as di. LDA (Blei et al., 2003) “explains” the occurrence of each word by postulating that a document was generated by repeatedly: (1) sampling a topic z from θ(d), the document-specific mixture of T topics, and (2) sampling a word w from φ(z), the probability distribution the z-th topic defines over the</context>
<context position="4446" citStr="Canini et al., 2009" startWordPosition="719" endWordPosition="722"> intractable, motivating methods for approximate inference such as variational Bayesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 Online LDA Using Particl</context>
<context position="8625" citStr="Canini et al., 2009" startWordPosition="1431" endWordPosition="1434">everal resampling strategies have been proposed (Doucet et al., 2000); we perform multinomial resampling as in Pitt and Shephard (1999) and Ahmed et al. (2011), treating the weights as unnormalized probability masses on the particles. After resampling we are likely to have several copies of the same particle, yielding a degenerate approximation to the posterior. To reintroduce diversity to the particle cloud we take MCMC steps over a sequence of states from the history (Doucet et al., 2000; Gilks and Berzuini, 2001). We call the indices of these states the rejuvenation sequence, denoted R(i) (Canini et al., 2009). The transition probability for a state j E R(i) is given by P(zj |zN\j, wN) OC n(wj) n(dj) + α zj,N\j + β zj,N\j n(·) n(dj) + Tα zj,N\j + Wβ ·,N\j where subscript N\j denotes counts up to token N, excluding those for token j. The rejuvenation sequence can be chosen by the practitioner. Choosing a long sequence (large |R(i)|) may result in a more accurate posterior approximation but also increases runtime and storage requirements. The tokens in R(i) may be chosen uniformly at random from the history or under a biased scheme that favors recent observations. The particle filter studied empirica</context>
<context position="10841" citStr="Canini et al. (2009)" startWordPosition="1828" endWordPosition="1831"> reservoir sampling To ensure constant space over an unbounded stream, we draw the rejuvenation sequence R(i) uniformly from a reservoir. As each token of the training data is ingested by the particle filter, we decide to insert that token into the reservoir, or not, independent of the other tokens in the current document. Thus, at the end of step i of the particle filter, each of the i tokens seen so far in the training sequence has an equal probability of being in the reservoir, hence being selected for rejuvenation. 5 Experiments We evaluate our particle filter on three datasets studied in Canini et al. (2009): diff3, rel3, and sim3. Each of these datasets is a collection of posts under three categories from the 20 Newsgroups dataset.1 We use a 60% training/40% testing split of this data that is available online.2 We preprocess the data by splitting each line on non-alphabet characters, converting the resulting tokens to lower-case, and filtering out any tokens that appear in a list of common English stop words. In addition, we remove the header of every file and filter every line that does not contain a non-trailing space (which removes embedded ASCII-encoded attachments). Finally, we shuffle the </context>
<context position="12679" citStr="Canini et al. (2009)" startWordPosition="2114" endWordPosition="2117">sampling on the test set, and computing the topic for each document as the topic assigned to the most tokens in that document. Two Gibbs sweeps have been shown to yield good performance in practice (Yao et al., 2009); we increase the number of sweeps to five after inspecting the stability on our dataset. The variance of the particle filter is often large, so for each experiment we perform 30 runs and plot the mean NMI inside bands spanning one sample standard deviation in either direction. Fixed Initialization. Our first set of experiments has a similar parameterization3 to the experiments of Canini et al. (2009) except we draw the rejuvenation sequence from a reservoir. We initialize the particle filter with 200 Gibbs sweeps on the first 10% of each dataset. Then, for each dataset, for rejuvenation disabled, rejuvenation based on a reservoir of size 1000, and rejuvenation based on the entire history (in turn), we perform 30 runs of the particle filter from that fixed initial model. Our results (Figure 1) resemble those of Canini et al. (2009); we believe the discrepancies are mostly attributable to differences in preprocessing. In these experiments, the initial model was not chosen arbitrarily. Rathe</context>
<context position="15961" citStr="Canini et al. (2009)" startWordPosition="2655" endWordPosition="2658">itialization sample, heldout perplexity (per word) is estimated on the remaining 20%, using a first-moment particle learning approximation (Scott and Baldridge, 2013), and the particle filter is started from the model out of these 20 with the lowest held-out perplexity. The results, shown in Figure 3, show that we can ameliorate the variance due to initialization by tuning the initial model to NMI or perplexity. 6 Discussion Motivated by a desire for cognitive plausibility, B¨orschinger and Johnson (2011) used a particle filter to learn Bayesian word segmentation models, following the work of Canini et al. (2009). They later showed that rejuvenation improved performance (B¨orschinger and Johnson, 2012), but this impaired cognitive plausibility by necessitating storage of all previous states and observations. We attempted to correct this by drawing the rejuvenation sequence from a reservoir, but our results indicate that the particle filter for LDA on our dataset is highly sensitive to initialization and not influenced by rejuvenation. In the experiments of B¨orschinger and Johnson (2012), the particle cloud appears to be resampled once per utterance with a large rejuvenation sequence;4 each particle t</context>
<context position="17644" citStr="Canini et al. (2009)" startWordPosition="2929" endWordPosition="2932">g in-sample NMI or held-out perplexity can improve mean NMI and reduce variance. Perplexity (or likelihood) is often used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects of initialization and rejuvenation using other metrics such as perplexity or semantic coherence. 7 Conclusion We have proposed reservoir sampling for reducing the storage complexity of a particle filter from linear to constant. This work was motivated as an expected improvement on the model of Canini et al. (2009). However, in the process of establishing an empirical baseline we discovere</context>
</contexts>
<marker>Canini, Shi, Griffiths, 2009</marker>
<rawString>Kevin R. Canini, Lei Shi, and Thomas L. Griffiths. 2009. Online inference of topics with latent Dirichlet allocation. In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnaud Doucet</author>
<author>Nando de Freitas</author>
<author>Kevin Murphy</author>
<author>Stuart Russell</author>
</authors>
<title>Rao-Blackwellised particle filtering for dynamic Bayesian networks.</title>
<date>2000</date>
<booktitle>In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>176--183</pages>
<marker>Doucet, de Freitas, Murphy, Russell, 2000</marker>
<rawString>Arnaud Doucet, Nando de Freitas, Kevin Murphy, and Stuart Russell. 2000. Rao-Blackwellised particle filtering for dynamic Bayesian networks. In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence (UAI), pages 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnaud Doucet</author>
</authors>
<title>Nando de Freitas,</title>
<date>2001</date>
<booktitle>Sequential Monte Carlo Methods in Practice.</booktitle>
<editor>and Neil Gordon, editors.</editor>
<publisher>Springer,</publisher>
<location>New York.</location>
<marker>Doucet, 2001</marker>
<rawString>Arnaud Doucet, Nando de Freitas, and Neil Gordon, editors. 2001. Sequential Monte Carlo Methods in Practice. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter R Gilks</author>
<author>Carlo Berzuini</author>
</authors>
<title>Following a moving target—Monte Carlo inference for dynamic Bayesian models.</title>
<date>2001</date>
<journal>Journal of the Royal Statistical Society,</journal>
<volume>63</volume>
<issue>1</issue>
<contexts>
<context position="1474" citStr="Gilks and Berzuini, 2001" startWordPosition="221" endWordPosition="224">model, latent Dirichlet allocation (LDA), to unbounded streams of documents. In order for inference to be practical in this setting it must use constant space asymptotically and run in pseudo-linear time, perhaps O(n) or O(n log n). Canini et al. (2009) presented a method for LDA inference based on particle filters, where a sample set of models is updated online with each new token observed from a stream. In general, these models should be regularly resampled and rejuvenated using Markov Chain Monte Carlo (MCMC) steps over the history in order to improve the efficiency of the particle filter (Gilks and Berzuini, 2001). The particle filter of Canini et al. (2009) rejuvenates over independent draws from the history by storing all past observations and states. This algorithm thus has linear storage complexity and is not an online learning algorithm in a strict sense (B¨orschinger and Johnson, 2012). In the current work we propose using reservoir sampling in the rejuvenation step to reduce the storage complexity of the particle filter to O(1). This improvement is practically useful in the large-data setting and is also scientifically interesting in that it recovers some of the cognitive plausibility which orig</context>
<context position="8526" citStr="Gilks and Berzuini, 2001" startWordPosition="1415" endWordPosition="1418">iu and Chen, 1998) and resample the particles when that estimate drops below a prespecified threshold. Several resampling strategies have been proposed (Doucet et al., 2000); we perform multinomial resampling as in Pitt and Shephard (1999) and Ahmed et al. (2011), treating the weights as unnormalized probability masses on the particles. After resampling we are likely to have several copies of the same particle, yielding a degenerate approximation to the posterior. To reintroduce diversity to the particle cloud we take MCMC steps over a sequence of states from the history (Doucet et al., 2000; Gilks and Berzuini, 2001). We call the indices of these states the rejuvenation sequence, denoted R(i) (Canini et al., 2009). The transition probability for a state j E R(i) is given by P(zj |zN\j, wN) OC n(wj) n(dj) + α zj,N\j + β zj,N\j n(·) n(dj) + Tα zj,N\j + Wβ ·,N\j where subscript N\j denotes counts up to token N, excluding those for token j. The rejuvenation sequence can be chosen by the practitioner. Choosing a long sequence (large |R(i)|) may result in a more accurate posterior approximation but also increases runtime and storage requirements. The tokens in R(i) may be chosen uniformly at random from the his</context>
</contexts>
<marker>Gilks, Berzuini, 2001</marker>
<rawString>Walter R. Gilks and Carlo Berzuini. 2001. Following a moving target—Monte Carlo inference for dynamic Bayesian models. Journal of the Royal Statistical Society, 63(1):127–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences, 101(suppl</booktitle>
<pages>1--5228</pages>
<contexts>
<context position="4056" citStr="Griffiths and Steyvers, 2004" startWordPosition="653" endWordPosition="656">istics initialize weights W(p) 0= 1/P for p = 1, ... ,P for i = 1, ... ,N do for p = 1, ... ,P do set W�p) = W(p)i−1P(wi |z(p) i−1, wi−1) sample z(p) iw.p. P(z(p) i |z(p) i−1, wi). if 11W11−2 2 &lt; ESS then for j E R(i) do for p = 1, ... ,P do sample z(p) j w.p. P(z(p) j |z(p) i\j, wi) set W(p) i = 1/P for each particle Algorithm 1: Particle filtering for LDA. Computing φ and θ exactly is generally intractable, motivating methods for approximate inference such as variational Bayesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dat</context>
<context position="17231" citStr="Griffiths and Steyvers, 2004" startWordPosition="2856" endWordPosition="2859">n new state transitions and thus resembles a batch MCMC sampler. In our experiments resampling is done on the order of once per document, leading to less than one rejuvenation step per transition. Future work should carefully note this ratio: sampling history much more often than new states improves performance but contradicts the intuition behind particle filters. We have also shown that tuning the initial model using in-sample NMI or held-out perplexity can improve mean NMI and reduce variance. Perplexity (or likelihood) is often used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to in</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101(suppl 1):5228–5235, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Hoffman</author>
<author>David M Blei</author>
<author>Francis Bach</author>
</authors>
<title>Online learning for latent Dirichlet allocation.</title>
<date>2010</date>
<booktitle>In Advances in Neural Information Processing Systems 23 (NIPS).</booktitle>
<contexts>
<context position="4505" citStr="Hoffman et al., 2010" startWordPosition="727" endWordPosition="730">such as variational Bayesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 Online LDA Using Particle Filters Particle filters are a family of sequential Monte</context>
<context position="17276" citStr="Hoffman et al., 2010" startWordPosition="2864" endWordPosition="2868">CMC sampler. In our experiments resampling is done on the order of once per document, leading to less than one rejuvenation step per transition. Future work should carefully note this ratio: sampling history much more often than new states improves performance but contradicts the intuition behind particle filters. We have also shown that tuning the initial model using in-sample NMI or held-out perplexity can improve mean NMI and reduce variance. Perplexity (or likelihood) is often used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects of initialization and r</context>
</contexts>
<marker>Hoffman, Blei, Bach, 2010</marker>
<rawString>Matthew D. Hoffman, David M. Blei, and Francis Bach. 2010. Online learning for latent Dirichlet allocation. In Advances in Neural Information Processing Systems 23 (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Hoffman</author>
<author>David M Blei</author>
<author>Chong Wang</author>
<author>John Paisley</author>
</authors>
<title>Stochastic variational inference.</title>
<date>2013</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>14</volume>
<contexts>
<context position="4548" citStr="Hoffman et al., 2013" startWordPosition="735" endWordPosition="738">ei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 Online LDA Using Particle Filters Particle filters are a family of sequential Monte Carlo (SMC) sampling algorithms designed t</context>
</contexts>
<marker>Hoffman, Blei, Wang, Paisley, 2013</marker>
<rawString>Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. 2013. Stochastic variational inference. Journal of Machine Learning Research, 14:1303–1347, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun S Liu</author>
<author>Rong Chen</author>
</authors>
<title>Sequential Monte Carlo methods for dynamic systems.</title>
<date>1998</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>93</volume>
<issue>443</issue>
<pages>1044</pages>
<contexts>
<context position="7919" citStr="Liu and Chen, 1998" startWordPosition="1317" endWordPosition="1320"> as P(wi |z(p) i ,wi)P(z(p) i |z(p) i−1) Q(z(p) i |z(p) i−1, wi) = P(wi |z(p) i−1, wi−1) �P(zi−1 |wi−1) ≈ p �P(zi |wi) ≈ p nzi,i\i+ α (di) n(di) ·,i\i + Tα ω(p) i ∝ (p) ωi−1 447 where Q is the proposal distribution for the particle state transition; in our case, Q(z(p) i |z(p) i−1, wi) = P(z(p) i |z(p) i−1, wi), minimizing the variance of the importance weights conditioned on wi and zi−1 (Doucet et al., 2000). Over time the particle weights tend to diverge. To combat this inefficiency, after every state transition we estimate the effective sample size (ESS) of the particle weights as�ωi�−2 2 (Liu and Chen, 1998) and resample the particles when that estimate drops below a prespecified threshold. Several resampling strategies have been proposed (Doucet et al., 2000); we perform multinomial resampling as in Pitt and Shephard (1999) and Ahmed et al. (2011), treating the weights as unnormalized probability masses on the particles. After resampling we are likely to have several copies of the same particle, yielding a degenerate approximation to the posterior. To reintroduce diversity to the particle cloud we take MCMC steps over a sequence of states from the history (Doucet et al., 2000; Gilks and Berzuini</context>
</contexts>
<marker>Liu, Chen, 1998</marker>
<rawString>Jun S. Liu and Rong Chen. 1998. Sequential Monte Carlo methods for dynamic systems. Journal of the American Statistical Association, 93(443):1032– 1044, Sep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Edmund Talley</author>
<author>Miriam Leenders</author>
<author>Andrew McCallum</author>
</authors>
<title>Optimizing semantic coherence in topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP),</booktitle>
<pages>262--272</pages>
<contexts>
<context position="17799" citStr="Mimno et al., 2011" startWordPosition="2958" endWordPosition="2961">DA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects of initialization and rejuvenation using other metrics such as perplexity or semantic coherence. 7 Conclusion We have proposed reservoir sampling for reducing the storage complexity of a particle filter from linear to constant. This work was motivated as an expected improvement on the model of Canini et al. (2009). However, in the process of establishing an empirical baseline we discovered that rejuvenation does not play a significant role in the experiments of Canini et al. (2009). Moreover, we found that performance of the particle filter</context>
</contexts>
<marker>Mimno, Wallach, Talley, Leenders, McCallum, 2011</marker>
<rawString>David Mimno, Hanna M. Wallach, Edmund Talley, Miriam Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP), pages 262–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Matthew D Hoffman</author>
<author>David M Blei</author>
</authors>
<title>Sparse stochastic inference for latent Dirichlet allocation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 29th International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4525" citStr="Mimno et al., 2012" startWordPosition="731" endWordPosition="734">yesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally assume the ability to draw independent samples from the full dataset, we consider the case when it is infeasible to access arbitrary elements from the history. The one existing algorithm that can be directly applied under this constraint, to our knowledge, is the streaming variational Bayes framework (Broderick et al., 2013) in which the posterior is recursively updated as new data arrives using a variational approximation. 3 Online LDA Using Particle Filters Particle filters are a family of sequential Monte Carlo (SMC) samplin</context>
</contexts>
<marker>Mimno, Hoffman, Blei, 2012</marker>
<rawString>David Mimno, Matthew D. Hoffman, and David M. Blei. 2012. Sparse stochastic inference for latent Dirichlet allocation. In Proceedings of the 29th International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Minka</author>
<author>John Lafferty</author>
</authors>
<title>Expectationpropagation for the generative aspect model.</title>
<date>2002</date>
<booktitle>In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>352--359</pages>
<contexts>
<context position="3995" citStr="Minka and Lafferty, 2002" startWordPosition="645" endWordPosition="648">ne 23-25 2014. c�2014 Association for Computational Linguistics initialize weights W(p) 0= 1/P for p = 1, ... ,P for i = 1, ... ,N do for p = 1, ... ,P do set W�p) = W(p)i−1P(wi |z(p) i−1, wi−1) sample z(p) iw.p. P(z(p) i |z(p) i−1, wi). if 11W11−2 2 &lt; ESS then for j E R(i) do for p = 1, ... ,P do sample z(p) j w.p. P(z(p) j |z(p) i\j, wi) set W(p) i = 1/P for each particle Algorithm 1: Particle filtering for LDA. Computing φ and θ exactly is generally intractable, motivating methods for approximate inference such as variational Bayesian inference (Blei et al., 2003), expectation propagation (Minka and Lafferty, 2002), and collapsed Gibbs sampling (Griffiths and Steyvers, 2004). A limitation of these techniques is they require multiple passes over the data to obtain good samples of φ and θ. This requirement makes them impractical when the corpus is too large to fit directly into memory and in particular when the corpus grows without bound. This motivates online learning techniques, including sampling-based methods (Banerjee and Basu, 2007; Canini et al., 2009) and stochastic variational inference (Hoffman et al., 2010; Mimno et al., 2012; Hoffman et al., 2013). However, where these approaches generally ass</context>
</contexts>
<marker>Minka, Lafferty, 2002</marker>
<rawString>Thomas Minka and John Lafferty. 2002. Expectationpropagation for the generative aspect model. In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence (UAI), pages 352–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Jey Han Lau</author>
<author>Karl Grieser</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic evaluation of topic coherence.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT),</booktitle>
<pages>100--108</pages>
<contexts>
<context position="17778" citStr="Newman et al., 2010" startWordPosition="2954" endWordPosition="2957">odel performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects of initialization and rejuvenation using other metrics such as perplexity or semantic coherence. 7 Conclusion We have proposed reservoir sampling for reducing the storage complexity of a particle filter from linear to constant. This work was motivated as an expected improvement on the model of Canini et al. (2009). However, in the process of establishing an empirical baseline we discovered that rejuvenation does not play a significant role in the experiments of Canini et al. (2009). Moreover, we found that performance o</context>
</contexts>
<marker>Newman, Lau, Grieser, Baldwin, 2010</marker>
<rawString>David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT), pages 100–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael K Pitt</author>
<author>Neil Shephard</author>
</authors>
<title>Filtering via simulation: Auxiliary particle filters.</title>
<date>1999</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>94</volume>
<issue>446</issue>
<contexts>
<context position="6048" citStr="Pitt and Shephard, 1999" startWordPosition="977" endWordPosition="980">g importance sampling (an approach called sequential importance sampling). Canini et al. (2009) apply this approach to LDA after analytically integrating out φ and θ, obtaining a Rao-Blackwellized particle filter (Doucet et al., 2000) that estimates the collapsed posterior P(z |w). In this setting, the P particles are samples of the topic assignment vector z(p), and they are propagated forward in state space one token at a time. In general, the larger P is, the more accurately we approximate the posterior; for small P, the approximation of the tails of the posterior will be particularly poor (Pitt and Shephard, 1999). However, a larger value of P increases the runtime and storage requirements of the algorithm. We now describe the Rao-Blackwellized particle filter for LDA in detail (pseudocode is given in Algorithm 1). At the moment token i is observed, the particles form a discrete approximation of the posterior up to the (i − 1)-th word: ωi−1Izi−1(z(p) (p) i−1) where Iz(z0) is the indicator function, evaluating to 1 if z = z0 and 0 otherwise. Now each particle p is propagated forward by drawing a topic zi from the conditional posterior distribution (p) P(z(p) i |z(p) i−1, wi) and scaling the particle wei</context>
<context position="8140" citStr="Pitt and Shephard (1999)" startWordPosition="1351" endWordPosition="1354">or the particle state transition; in our case, Q(z(p) i |z(p) i−1, wi) = P(z(p) i |z(p) i−1, wi), minimizing the variance of the importance weights conditioned on wi and zi−1 (Doucet et al., 2000). Over time the particle weights tend to diverge. To combat this inefficiency, after every state transition we estimate the effective sample size (ESS) of the particle weights as�ωi�−2 2 (Liu and Chen, 1998) and resample the particles when that estimate drops below a prespecified threshold. Several resampling strategies have been proposed (Doucet et al., 2000); we perform multinomial resampling as in Pitt and Shephard (1999) and Ahmed et al. (2011), treating the weights as unnormalized probability masses on the particles. After resampling we are likely to have several copies of the same particle, yielding a degenerate approximation to the posterior. To reintroduce diversity to the particle cloud we take MCMC steps over a sequence of states from the history (Doucet et al., 2000; Gilks and Berzuini, 2001). We call the indices of these states the rejuvenation sequence, denoted R(i) (Canini et al., 2009). The transition probability for a state j E R(i) is given by P(zj |zN\j, wN) OC n(wj) n(dj) + α zj,N\j + β zj,N\j </context>
</contexts>
<marker>Pitt, Shephard, 1999</marker>
<rawString>Michael K. Pitt and Neil Shephard. 1999. Filtering via simulation: Auxiliary particle filters. Journal of the American Statistical Association, 94(446):590–599, Jun.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James G Scott</author>
<author>Jason Baldridge</author>
</authors>
<title>A recursive estimate for the predictive likelihood in a topic model.</title>
<date>2013</date>
<booktitle>In Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS).</booktitle>
<contexts>
<context position="15507" citStr="Scott and Baldridge, 2013" startWordPosition="2579" endWordPosition="2582">m Gibbs initialization 20 times on the initialization set, setting the particle filter’s initial model to the model out of these 20 with 449 Figure 3: Variable initialization with tuning. the highest in-sample NMI. This procedure is performed independently for each run of the particle filter. We may not always have labeled data for initialization, so we also consider a variation in which Gibbs initialization is performed 20 times on the first 80% of the initialization sample, heldout perplexity (per word) is estimated on the remaining 20%, using a first-moment particle learning approximation (Scott and Baldridge, 2013), and the particle filter is started from the model out of these 20 with the lowest held-out perplexity. The results, shown in Figure 3, show that we can ameliorate the variance due to initialization by tuning the initial model to NMI or perplexity. 6 Discussion Motivated by a desire for cognitive plausibility, B¨orschinger and Johnson (2011) used a particle filter to learn Bayesian word segmentation models, following the work of Canini et al. (2009). They later showed that rejuvenation improved performance (B¨orschinger and Johnson, 2012), but this impaired cognitive plausibility by necessita</context>
</contexts>
<marker>Scott, Baldridge, 2013</marker>
<rawString>James G. Scott and Jason Baldridge. 2013. A recursive estimate for the predictive likelihood in a topic model. In Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey S Vitter</author>
</authors>
<title>Random sampling with a reservoir.</title>
<date>1985</date>
<journal>ACM Transactions on Mathematical Software,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="9807" citStr="Vitter (1985)" startWordPosition="1638" endWordPosition="1639">article filter studied empirically by Canini et al. (2009) stored the entire history, incurring linear storage complexity in the size of the stream. Ahmed et al. (2011) instead sampled ten documents from the most recent 1000, achieving constant storage complexity at the cost of a recency bias. If we want to fit a model to a long noni.i.d. stream, we require an unbiased rejuvenation sequence as well as sub-linear storage complexity. 4 Reservoir Sampling Reservoir sampling is a widely-used family of algorithms for choosing an array (“reservoir”) of k items. The most common example, presented in Vitter (1985) as Algorithm R, chooses k elements of a stream such that each possible subset of k elements is equiprobable. This effects sampling k items uniformly without replacement, using runtime O(n) (constant per update) and storage O(k). Initialize k-element array R ; Stream S ; for i = 1, ... ,k do R[i] ← S[i] ; for i = k + 1, ... ,length(S) do j ← random(1, i); if j ≤ k then R[j] ← S[i] ; Algorithm 2: Algorithm R for reservoir sampling To ensure constant space over an unbounded stream, we draw the rejuvenation sequence R(i) uniformly from a reservoir. As each token of the training data is ingested b</context>
</contexts>
<marker>Vitter, 1985</marker>
<rawString>Jeffrey S. Vitter. 1985. Random sampling with a reservoir. ACM Transactions on Mathematical Software, 11(1):37–57, Mar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna M Wallach</author>
<author>Iain Murray</author>
<author>Ruslan Salakhutdinov</author>
<author>David Mimno</author>
</authors>
<title>Evaluation methods for topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="17253" citStr="Wallach et al., 2009" startWordPosition="2860" endWordPosition="2863">us resembles a batch MCMC sampler. In our experiments resampling is done on the order of once per document, leading to less than one rejuvenation step per transition. Future work should carefully note this ratio: sampling history much more often than new states improves performance but contradicts the intuition behind particle filters. We have also shown that tuning the initial model using in-sample NMI or held-out perplexity can improve mean NMI and reduce variance. Perplexity (or likelihood) is often used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects </context>
</contexts>
<marker>Wallach, Murray, Salakhutdinov, Mimno, 2009</marker>
<rawString>Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, and David Mimno. 2009. Evaluation methods for topic models. In Proceedings of the 26th International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>David Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Efficient methods for topic model inference on streaming document collections.</title>
<date>2009</date>
<booktitle>In 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>937--946</pages>
<contexts>
<context position="12275" citStr="Yao et al., 2009" startWordPosition="2045" endWordPosition="2048">seball, sci.space, alt.atheism}; rel3: talk.politics.{misc, guns, mideast}; and sim3: comp.{graphics, os.ms-windows.misc, windows.x}. 2http://qwone.com/˜jason/20Newsgroups/ 20news-bydate.tar.gz 448 Figure 1: Fixed initialization with different reservoir sizes. During training we report the out-of-sample NMI, calculated by holding the word proportions φ fixed, running five sweeps of collapsed Gibbs sampling on the test set, and computing the topic for each document as the topic assigned to the most tokens in that document. Two Gibbs sweeps have been shown to yield good performance in practice (Yao et al., 2009); we increase the number of sweeps to five after inspecting the stability on our dataset. The variance of the particle filter is often large, so for each experiment we perform 30 runs and plot the mean NMI inside bands spanning one sample standard deviation in either direction. Fixed Initialization. Our first set of experiments has a similar parameterization3 to the experiments of Canini et al. (2009) except we draw the rejuvenation sequence from a reservoir. We initialize the particle filter with 200 Gibbs sweeps on the first 10% of each dataset. Then, for each dataset, for rejuvenation disab</context>
<context position="17757" citStr="Yao et al., 2009" startWordPosition="2950" endWordPosition="2953">used to estimate model performance in LDA (Blei et al., 2003; Griffiths and Steyvers, 2004; Wallach et al., 2009; Hoffman et al., 2010), and does not compare the inferred model against gold-standard labels, yet it appears to be a good proxy for NMI in our experiment. Thus, if initialization continues to be crucial to performance, at least we may have the flexibility of initializing without gold-standard labels. We have focused on NMI as our evaluation metric for comparison with Canini et al. (2009). However, evaluation of topic models is a subject of considerable debate (Wallach et al., 2009; Yao et al., 2009; Newman et al., 2010; Mimno et al., 2011) and it may be informative to investigate the effects of initialization and rejuvenation using other metrics such as perplexity or semantic coherence. 7 Conclusion We have proposed reservoir sampling for reducing the storage complexity of a particle filter from linear to constant. This work was motivated as an expected improvement on the model of Canini et al. (2009). However, in the process of establishing an empirical baseline we discovered that rejuvenation does not play a significant role in the experiments of Canini et al. (2009). Moreover, we fou</context>
</contexts>
<marker>Yao, Mimno, McCallum, 2009</marker>
<rawString>Limin Yao, David Mimno, and Andrew McCallum. 2009. Efficient methods for topic model inference on streaming document collections. In 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 937–946.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>