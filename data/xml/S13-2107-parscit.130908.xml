<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.116227">
<title confidence="0.9898365">
NIL UCM: Extracting Drug-Drug interactions from text through
combination of sequence and tree kernels
</title>
<author confidence="0.959741">
Behrouz Bokharaeian, Alberto Diaz
</author>
<affiliation confidence="0.6807575">
Natural Interaction Based on Language Group
Universidad Complutense de Madrid
</affiliation>
<address confidence="0.969659">
Madrid 28011, Spain
</address>
<email confidence="0.998145">
{bokharaeian, albertodiaz}@fdi.ucm.es
</email>
<sectionHeader confidence="0.995583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999746214285714">
A drug-drug interaction (DDI) occurs when
one drug affects the level or activity of another
drug. Semeval 2013 DDI Extraction challenge
is going to be held with the aim of identify-
ing the state of the art relation extraction algo-
rithms. In this paper we firstly review some of
the existing approaches in relation extraction
generally and biomedical relations especially.
And secondly we will explain our SVM based
approaches that use lexical, morphosyntactic
and parse tree features. Our combination of
sequence and tree kernels have shown promis-
ing performance with a best result of 0.54 F1
macroaverage on the test dataset.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974146341464">
A drug-drug interaction occurs when one drug af-
fects the level or activity of another drug, for in-
stance, drug concentrations. This interaction can
result on reducing its effectiveness or possibly in-
creasing its side effects (Stockley, 2007). There are
some helpful DDIs but most of them are danger-
ous (Aronson, 2007), for example, patients that take
clarithromycin and glibenclamide concurrently may
experiment hypoglycaemia.
There is a great amount of information about DDI
described in papers that health experts have to con-
sult in order to be updated. The development of tools
for extracting this type of information from biomed-
ical texts would produce a clear benefit for these pro-
fessionals reducing the time necessary to review the
literature. Semeval 2013 DDI Extraction challenge
decided to being held with the aim of identifying the
state of the art algorithms for automatically extract-
ing DDI from biomedical articles. This challenge
has two tasks: recognition and classification of drug
names and extraction of drug-drug interactions. For
the second task, the input corpus contains annota-
tions with the drug names.
A previous Workshop on Drug-Drug Interaction
Extraction (Segura-Bedmar et al., 2011) was held
in 2011 in Huelva, Spain. The main difference is
that the new challenge includes the classification of
the drug-drug interactions in four types depending
on the information that is described in the sentence
making the task much more complicated than be-
fore. Additionally the current task involves DDIs
from two different corpora with different character-
istics (Segura-Bedmar et al., 2013).
We participated in the task of extracting drug-drug
interactions with two approaches that exploit a rich
set of tree and sequence features. Our implemented
methods utilize a SVM classifier with a linear ker-
nel and a rich set of lexical, morphosyntactic and se-
mantic features (e.g. trigger words) extracted from
texts. In addition some tree features such as shortest
path and subtree features are used.
</bodyText>
<sectionHeader confidence="0.99969" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99772025">
Due to the importance of detecting biological and
medical relations several methods have been applied
for extracting biological relation information from
text. In (Song et al., 2010) is presented a method for
extracting protein-protein interaction (PPI) through
combination of an active learning technique and a
semi-supervised SVM.
Another motivating work can be found in (Chen et
</bodyText>
<page confidence="0.980717">
644
</page>
<bodyText confidence="0.9970421">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 644–650, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
al., 2011) in which a PPI Pair Extractor was devel-
oped that consists of a SVM for binary classification
which exploits a linear kernel with a rich set of fea-
tures based on linguistic analysis, contextual words,
interaction words, interaction patterns and specific
domain information.
Another PPI extraction method have been devel-
oped in (Li et al., 2010). They have applied an en-
semble kernel composed of a feature-based kernel
and a structure-based kernel. A more recent research
on tree kernels has been carried out by (Guodong
et al., 2010). They have introduced a context-
sensitive convolution tree kernel, which specifies
both context-free and context-sensitive sub-trees by
taking into account the paths of their ancestor nodes
as their contexts to capture structural information in
the tree structure. A recent work (Sim˜oes et al.,
2013) has introduced an approach for Relationship
Extraction (RE) based on labeled graph kernels. The
proposed kernel is a specification of a random walk
kernel that exploits two properties: the words be-
tween the candidate entities and the combination of
information from distinct sources. A comparative
survey regarding different kernel based approaches
and their performance can be found in (Frunza and
Inkpen, 2008).
Using external knowledge and resources to the
target sentence is another research direction in the
relation extraction task that Chan and Roth have
investigated in (Chan and Roth, 2010). They
have reported some improvements by using exter-
nal sources such as Wikipedia, comparing to basic
supervised learning systems. Thomas and his col-
leagues in (Thomas et al., 2011) have developed
a majority voting ensemble of contrasting machine
learning methods using different linguistic feature
spaces.
A more systematic and high quality investigation
about feature selection in kernel based relation ex-
pression can be found in (Jiang and Zhai, 2011).
They have explored a large space of features for re-
lation extraction and assess the effectiveness of se-
quences, syntactic parse trees and dependency parse
trees as feature subspaces and sentence representa-
tion. They conclude that, by means of a set of ba-
sic unit features from each subspace, a reasonably
good performance can be achieved. But when the
three subspaces are combined, the performance can
slightly improve, which shows sequence, syntactic
and dependency relations have much overlap for the
task of relation extraction.
Although most of the previous researches in
biomedical domain has been carried out with respect
to protein-protein interaction extraction, and more
recently on drug-drug interaction extraction, other
types of biomedical relations are being studied: e.g.
gene-disease (Airola et al., 2008), disease-treatment
(Jung et al., 2012) and drug-disease.
</bodyText>
<sectionHeader confidence="0.997442" genericHeader="method">
3 Dataset
</sectionHeader>
<bodyText confidence="0.999987057142857">
The dataset for the DDIExtraction 2013 task con-
tains documents from two sources. It includes Med-
Line abstracts and documents from the DrugBank
database describing drug-drug interactions (Segura-
Bedmar et al., 2013). These documents are anno-
tated with drug entities and with information about
drug pair interactions: true or false.
In the training corpus the interaction type is also
annotated. There are 4 types of interactions: effect,
mechanism, int, advice.
The challenge corpus is divided into training and
evaluation datasets (Table 1). The DrugBank train-
ing data consists of 572 documents with 5675 sen-
tences. This subset contains 12929 entities and
26005 drug pair interactions. On the other hand, the
MedLine training data consists of 142 abstracts with
1301 sentences, 1836 entities and 1787 pairs.
The distribution of positive and negative exam-
ples are similar in both subsets, 12.98% of positives
instances on MedLine and 14.57% on DrugBank.
With respect to the distribution of categories, the fig-
ures show that there is a small number of positive
instances for categories int and advice on the Med-
Line subset. The effect type is the most frequent,
outmatching itself on the MedLine subset.
The evaluation corpus contains 158 abstracts with
973 sentences and 5265 drug pair interactions from
Drugbank, and 33 abstracts with 326 sentences and
451 drug pair interactions from Medline. It is worth
to emphasize that the distribution of positive and
negative examples is a bit greater (2.22%) in the
DrugBank subset compared to the training data, but
is almost doubled with respect to MedLine (12,98%
to 21,06%). The categories advice and int have very
few positive instances in the MedLine subset.
</bodyText>
<page confidence="0.997166">
645
</page>
<table confidence="0.999658333333333">
Training pairs negative DDIs positive DDIs effect mechanism advice int
DrugBank 26005 22217 3788 1535 1257 818 178
MedLine 1787 1555 232 152 62 8 10
Test pairs negative DDIs positive DDIs effect mechanism advice int
DrugBank 5265 4381 884 298 278 214 94
MedLine 451 356 95 62 24 7 2
</table>
<tableCaption confidence="0.999873">
Table 1: Basic statistics of the training and test datasets.
</tableCaption>
<sectionHeader confidence="0.968389" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.999976105263158">
Initially several experiments have been developed to
explore the performance of shallow linguistic (SL)
and parse tree based methods on a subset of the train-
ing corpus. Although the SL kernel achieved consid-
erably good results we have found that the best op-
tion was the combination of different kernels using
linguistic and tree features.
Our implemented kernel based approach consists
of four different processes that have been applied se-
quentially: preprocessing, feature extraction, feature
selection and classification (Figure 1). Our two sub-
mitted results were obtained by two different strate-
gies. In the first outcome, all the DDIs and type of
interactions were extracted in one step, as a 5-class
categorization problem. The second run was carried
out in two steps, initially the DDIs were detected and
then the positively predicted DDIs were used to de-
termine the type of the interaction. In the next sub-
section the four different processes are described.
</bodyText>
<subsectionHeader confidence="0.995781">
4.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999928777777778">
In this phase we have carried out two types of text
preprocessing steps before training the classifier.
We have removed some stop words in special
places in the sentences that clearly were a matter of
concern and caused some inaccuracy, for example,
removing question marks at the beginning of a sen-
tence. We also carried out a normalization task for
some tokens because of usage of different used en-
codings and processing methods, mainly html tags.
</bodyText>
<subsectionHeader confidence="0.967143">
4.2 Feature extraction
</subsectionHeader>
<bodyText confidence="0.968806666666667">
Initially 49 feature classes were extracted for each
instance that correspond to a drug pair interaction
between Drug1 and Drug2:
</bodyText>
<listItem confidence="0.9936555">
• Word Features: Include Words of Drug1, words
of Drug2, words between Drug1 and Drug2,
</listItem>
<figureCaption confidence="0.9990365">
Figure 1: The different processes followed for our two
submitted results.
</figureCaption>
<bodyText confidence="0.9973632">
three words before Drug1 and three words after
Drug2. Lemmas and stems of all these words.
We have used TreeTagger to obtain lemmas and
Paice/Husk Stemmer (Paice, 1990) to obtain
stems.
</bodyText>
<listItem confidence="0.8800576">
• Morphosyntactic Features: Include Part-of-
speech (POS) tags of each drug words (Drug1
and Drug2), POS of the previous 3 and next 3
words. We have used TreeTagger.
• Constituency parse tree features: Include short-
est path between Drug1 and Drug2 in the con-
stituency parse tree, shortest path between first
token in the sentence and Drug1, and shortest
path between Drug2 and last token in the sen-
tence in the parse tree, and all subtrees gener-
</listItem>
<page confidence="0.98915">
646
</page>
<bodyText confidence="0.907271333333333">
ated from the constituency parse tree. We have
used Stanford parser 1 for producing tree fea-
tures.
</bodyText>
<listItem confidence="0.96960175">
• Conjunction features: We have produced some
new conjunction features by combination of
different word features and morphosyntactic
features such as POSLEMMA and POSSTEM
for all the words before Drug1, words between
Drug1 and Drug2 and words after Drug2.
• verbs features: Include verbs between Drug1
and Drug2, first verb before Drug1 and first
verb after Drug2. Their stem, lemma and their
conjunction features are also included.
• negation features: Only if the sentence contains
negation statements. The features extracted in-
clude the left side tokens of the negation scope,
the right side tokens of the negation scope and
the tokens inside the negation scope. We have
used NegEx2 as negation detection algorithm.
</listItem>
<bodyText confidence="0.999951111111111">
Finally we have deployed a bag of words ap-
proach (BoW) for each feature class in order to ob-
tain the final representation for each instance. We
have limited the size of the vocabulary in the BoW
representation with a different number depending on
the data subset. We carried out several experiments
to fix these numbers and at the end we have used
1000 words/feature class for MedLine and 6000
words/feature class for DrugBank.
</bodyText>
<subsectionHeader confidence="0.998136">
4.3 Feature selection
</subsectionHeader>
<bodyText confidence="0.999962769230769">
We have conducted some feature selection experi-
ments to select the best features for improving the
results and reducing running time. We have finally
used Information Gain ranker to eliminate the less
effective features. We have computed the informa-
tion gain for each feature class as the linear combi-
nation of the information gain of each corresponding
word. Empirically we have selected the best 42 fea-
ture classes.
On the other hand, we have done a preliminary
study of the effect of the negation related features.
We have found more than 3000 sentences contain-
ing negation, most of them corresponds to sentences
</bodyText>
<footnote confidence="0.999802">
1http://nlp.stanford.edu/software/lex-parser.shtml
2http://code.google.com/p/negex/
</footnote>
<bodyText confidence="0.99940325">
associated with negative examples of interactions.
However, these features have been eliminated be-
cause we have not obtained a clear improvement
when we combined them with the other features.
</bodyText>
<subsectionHeader confidence="0.992141">
4.4 Classification
</subsectionHeader>
<bodyText confidence="0.999219333333333">
First we have performed several experiments with
different supervised machine learning approaches
such as SVM, Naivebayes, Randomtree, Random
forest, Multilayer perceptron in addition to combina-
tion of methods. Finally we decided to use a SVM
approach, the Weka Sequential Minimal Optimiza-
tion (SMO) algorithm. We used the inner product of
the BoW vectors as similarity function.
We have submitted two approaches:
</bodyText>
<listItem confidence="0.886010222222222">
• approach 1: SVM (Weka SMO) with 5 cate-
gories (effect, mechanism, int, advice and null).
• approach 2: We have extracted final results in
two stages. In the first step we have used a
SVM (Weka SMO) with 2 categories (positive
and negative) and then we have used a second
SVM classifier with 4 classes on positive ex-
tracted DDIs to train and extract the type of in-
teraction in the test dataset.
</listItem>
<bodyText confidence="0.999888166666667">
The classifiers have been applied separately with
each data subset, that is, a classifier per approach has
been developed using the DrugBank training subset
and has been evaluated using the DrugBank test sub-
set, and the same process has been applied with the
MedLine training and test subset.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.99993875">
In this section we first show the evaluation results
with our two approaches. Secondly an error analy-
sis was carried out with a development set extracted
from the training corpus.
</bodyText>
<subsectionHeader confidence="0.999789">
5.1 Test data results
</subsectionHeader>
<bodyText confidence="0.99995475">
We have submitted two runs that corresponds with
the approaches described in the previous section.
Table 2 shows the results obtained with the first ap-
proach (one step) and Table 3 shows the results with
the second approach (two steps).
It can be observed that the results on detection of
DDI are better with the approach 2: 0.656 against
0.588 on F1. This result is a consequence that we
</bodyText>
<page confidence="0.996984">
647
</page>
<table confidence="0.999958142857143">
Run P R F1
NILUCM1 (All) 0.632 0.464 0.535
NILUCM2 (All) 0.547 0.507 0.526
NILUCM1 (Drugbank) 0.651 0.498 0.565
NILUCM2 (Drugbank) 0.558 0.542 0.550
NILUCM1 (Medline) 0.333 0.074 0.121
NILUCM2 (Medline) 0.221 0.073 0.110
</table>
<tableCaption confidence="0.999984">
Table 4: Macroaverage test set results.
</tableCaption>
<bodyText confidence="0.999946551724138">
have more information to obtain the detection of the
interaction if we use the information from all the dif-
ferent types than if we obtain it joining the results
obtained per each category. With respect to detec-
tion and classification the results are also better with
approach 2 for a similar reason: 0.548 against 0.517
on F1.
With respect to the categories, in the more pop-
ulated ones the general tendency of better results
from approach 2 continues, especially in effect type:
0.556 against 0.489. With respect to advice and int,
the recall is better in approach 2 but the improve-
ment in precision is greater in approach1 giving a
better result on F1 to approach 1, especially in int
type: 0.427 against 0.393.
Table 4 shows the macroaverage results separated
by subset data. The best results obtained for ap-
proach 1 are due to that this type of average gives
equal weight to each category, favouring then the
categories with less instances.
Other important insight that can be extracted from
this table is that our results are much better for Drug-
Bank dataset with both approaches. These results
can be justified due to high similarity between sen-
tences in Drugbank training and test corpus. In fact
the Medline corpus commonly has more words un-
related to DDI subjects. In addition to this argument,
the smaller number of training pairs in the Medline
corpus can be other reason to obtain worst results.
</bodyText>
<subsectionHeader confidence="0.998864">
5.2 Error analysis
</subsectionHeader>
<bodyText confidence="0.999905258064516">
We have extracted a stratified development corpus
from the training corpus in order to perform an error
analysis. We have used a 10% of the training corpus.
It contains 2779 pairs, of which 397 are DDIs. Table
5 shows the results obtained with the two submitted
approaches.
The results with our development corpus shows
the same tendency, that is, approach 2 is better than
approach 1 on detection of DDI and on microav-
erage classification. On the other hand, results are
higher than those on test corpus because the infor-
mation contained in the development corpus is more
similar to the rest of training corpus than informa-
tion on the test set.
We have performed an analysis of the errors pro-
duced for both approaches in the Detection and
Classification of DDI subtask. The errors obtained
are 112 false positives (Fp) and 116 false negatives
(Fn) associated to approach 1, and 111 false posi-
tives (Fp) and 112 false negatives (Fn) to approach
2. Apart from the comments explained in the pre-
vious section about the small number of instances
on the MedLine subset, we think the main problem
is related with the management of long sentences
with complex syntax. These sentences are more dif-
ficult for our approaches because the complexity of
the sentence generates more errors in the tokenizing
and parsing processes affecting the representation of
the instances both in training and test phases. We
show below some false positives and false negatives
examples.
</bodyText>
<listItem confidence="0.99608825">
• The effects of ERGOMAR may be potentiated
by triacetyloleandomycin which inhibits the
metabolism of ergotamine. DrugBank. False
negative.
• Prior administration of 4-methylpyrazole (90
mg kg(-1) body weight) was shown to prevent
the conversion of 1,3-difluoro-2-propanol
(100 mg kg(-1) body weight) to (-)-erythro-
fluorocitrate in vivo and to eliminate the
fluoride and citrate elevations seen in 1,3-
difluoro-2-propanol-intoxicated animals Med-
Line. False negative.
• Drug Interactions with Antacids Administra-
tion of 120 mg of fexofenadine hydrochloride
(2 x 60 mg capsule) within 15 minutes of an
aluminum and magnesium containing antacid
(Maalox ) decreased fexofenadine AUC by
41% and cmax by 43%. DrugBank. False pos-
itive.
• Dexamethasone at 10(-10) M or retinyl acetate
</listItem>
<page confidence="0.990467">
648
</page>
<table confidence="0.998435285714286">
approach 1 Tp Fp Fn total P R F1
Detection of DDI 557 359 422 979 0.608 0.569 0.588
Detection and classification of DDI 490 426 489 979 0.535 0.501 0.517
Score for type mechanism 147 122 155 302 0.546 0.487 0.515
Score for type effect 200 258 160 360 0.437 0.556 0.489
Score for type advice 115 39 106 221 0.747 0.520 0.613
Score for type int 28 7 68 96 0.800 0.292 0.427
</table>
<tableCaption confidence="0.956216">
Table 2: Test corpus results (approach1).
</tableCaption>
<table confidence="0.999315714285714">
approach 2 Tp Fp Fn total P R F1
Detection of DDI 631 315 348 979 0.667 0.645 0.656
Detection and classification of DDI 527 419 452 979 0.557 0.538 0.548
Score for type mechanism 146 102 156 302 0.589 0.483 0.531
Score for type effect 210 186 150 360 0.530 0.583 0.556
Score for type advice 139 96 82 221 0.591 0.629 0.610
Score for type int 32 35 64 96 0.478 0.333 0.393
</table>
<tableCaption confidence="0.991401">
Table 3: Test corpus results (approach2).
</tableCaption>
<table confidence="0.9986525">
approach 1 Tp Fp Fn total P R F1
Detection of DDI: 292 101 105 397 0.743 0.736 0.739
Detection and Classification of DDI: 281 112 116 397 0.715 0.708 0.711
approach 2 Tp Fp Fn total P R F1
Detection of DDI: 296 102 101 397 0.744 0.746 0.745
Detection and Classification of DDI: 285 111 112 397 0.720 0.718 0.719
</table>
<tableCaption confidence="0.99985">
Table 5: Error analysis with a development corpus.
</tableCaption>
<bodyText confidence="0.9819915">
at about 3 X 10(-9) M inhibits proliferation
stimulated by EGF. MedLine. False positive.
</bodyText>
<sectionHeader confidence="0.999619" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999550290322581">
In this paper we have shown our approaches for
the Semeval 2013 DDI Extraction challenge. We
have explored different combinations of tree and se-
quence features using the Sequential Minimal Opti-
mization algorithm.
The first approach uses a SVM with 5 categories,
and the second one extracts the final results in two
steps: detection with all the categories, and classifi-
cation on the positive instances. The results are bet-
ter for approach 2 mainly due to the improvement on
the detection subtask because the information from
all the categories is used.
We think some of our errors come from using a
general tool (Stanford parser) to obtain the parse tree
of the sentences. In the future we are going to ex-
plore other biomedical parsers and tokenizers.
With respect to the data used, we think the Med-
Line dataset needs to be greater in order to ob-
tain more significant analysis and results. Our ap-
proaches are especially affected by this issue be-
cause the small number of positive instances on ad-
vice and int categories implies that the algorithm can
not learn to classify new instances accurately. On
the other hand, although n-fold cross validation is
considered as the best model validation technique,
it was time consuming for DDI and need powerful
processors.
Another interesting future work is related with
the application of simplification techniques in order
to solve the problems in the processing of complex
long sentences (Buyko et al., 2011).
</bodyText>
<page confidence="0.998863">
649
</page>
<sectionHeader confidence="0.990368" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999916369230769">
A. Airola, S. Pyysalo, J. Bjorne, T. Pahikkala, F. Ginter,
T. Salakoski. 2008. Allpaths graph kernel for protein-
protein interaction extraction with evaluation of cross-
corpus learning BMC Bioinformatics, 9(Suppl 11):S2.
JK. Aronson. 2007. Communicating information about
drug interactions. British Journal of Clinical Pharma-
cology, 63(6):637–639.
E. Buyko, E. Faessler, J. Wermter, U. Hahn 2011. Syn-
tactic Simplification and Semantic Enrichment - Trim-
ming Dependency Graphs for Event Extraction. Com-
putational Intelligence, 27(4):610–644.
Y. Chen, F. Liu, B. Manderick. 2011. Extract Protein-
Protein Interactions from the Literature Using Support
Vector Machines with Feature Selection. Biomedi-
cal Engineering, Trends, Researchs and Technologies,
2011.
YS. Chan and D. Roth. 2010. Exploiting Background
Knowledge for Relation Extraction COLING ’10
Proceedings of the 23rd International Conference on
Computational Linguistics, pp:152–160.
O. Frunza and D. Inkpen. 2010. Extraction of disease-
treatment semantic relations from biomedical sen-
tences Proceedings of the 2010 Workshop on Biomed-
ical Natural Language Processing, pp:91–98.
Z. Guodong, Q. Longhua, F. Jianxi. 2010. Tree kernel-
based semantic relation extraction with rich syntactic
and semantic information International Journal on In-
formation Sciences,, 180(8):1313–1325.
J. Jiang and C. Zhai. 2011. A systematic exploration of
the feature space for relation extraction Proceedings
of Human Language Technologies: The Conference
of the North American Chapter of the Association for
Computational Linguistics (NAACLHLT07), pp:113–
120.
H. Jung, S. Choi, S. Lee, S. Song. 2012. Survey on
Kernel-Based Relation Extraction.
L. Li, J. Ping, D. Huang. 2010. Protein-Protein Interac-
tion Extraction from Biomedical Literatures Based on
a Combined Kernel Journal of Information &amp; Compu-
tational Science, 7(5):1065–1073.
Chris D. Paice 1990. Another stemmer. ACM SIGIR
Forum, 24(3):56–61.
I. Segura-Bedmar, P. Martinez, D. S´anchez-Cisneros.
2011. Proceedings of the 1st Challenge task on Drug-
Drug Interaction Extraction (DDIExtraction 2011)
CEUR Workshop Proceedings, Vol. 761.
I. Segura-Bedmar, P. Martnez, M. Herrero-Zazo. 2013
SemEval-2013 Task 9: Extraction of Drug-Drug In-
teractions from Biomedical Texts. In Proceedings of
the 7th International Workshop on Semantic Evalua-
tion (SemEval 2013).
G. Sim˜oes, D. Matos, H. Galhardas. 2013. A Labeled
Graph Kernel for Relationship Extraction. CoRR,
abs/1302.4874.
M. Song, H. Yu, W. Han. 2010. Combining active learn-
ing and semi-supervised learning techniques to extract
protein interaction sentences. International Workshop
on Data Mining in Bioinformatics .
I H Stockley. 2007. Stockley’s Drug Interaction. Phar-
maceutical Press.
P. Thomas, M. Neves, I. Solt, D. Tikk, U. Leser. 2011.
Relation extraction for drug- drug interactions using
ensemble learning Proceedings of the First Challenge
task on Drug-Drug Interaction Extraction (DDIEx-
traction 2011), pp:11–17.
</reference>
<page confidence="0.997973">
650
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.729911">
<title confidence="0.975147">NIL UCM: Extracting Drug-Drug interactions from text through combination of sequence and tree kernels</title>
<author confidence="0.961013">Behrouz Bokharaeian</author>
<author confidence="0.961013">Alberto</author>
<affiliation confidence="0.9648495">Natural Interaction Based on Language Universidad Complutense de</affiliation>
<address confidence="0.814226">Madrid 28011,</address>
<abstract confidence="0.996909666666667">A drug-drug interaction (DDI) occurs when one drug affects the level or activity of another drug. Semeval 2013 DDI Extraction challenge is going to be held with the aim of identifying the state of the art relation extraction algorithms. In this paper we firstly review some of the existing approaches in relation extraction generally and biomedical relations especially. And secondly we will explain our SVM based approaches that use lexical, morphosyntactic and parse tree features. Our combination of sequence and tree kernels have shown promising performance with a best result of 0.54 F1 macroaverage on the test dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Airola</author>
<author>S Pyysalo</author>
<author>J Bjorne</author>
<author>T Pahikkala</author>
<author>F Ginter</author>
<author>T Salakoski</author>
</authors>
<title>Allpaths graph kernel for proteinprotein interaction extraction with evaluation of crosscorpus learning BMC Bioinformatics, 9(Suppl 11):S2.</title>
<date>2008</date>
<contexts>
<context position="6308" citStr="Airola et al., 2008" startWordPosition="957" endWordPosition="960">sentation. They conclude that, by means of a set of basic unit features from each subspace, a reasonably good performance can be achieved. But when the three subspaces are combined, the performance can slightly improve, which shows sequence, syntactic and dependency relations have much overlap for the task of relation extraction. Although most of the previous researches in biomedical domain has been carried out with respect to protein-protein interaction extraction, and more recently on drug-drug interaction extraction, other types of biomedical relations are being studied: e.g. gene-disease (Airola et al., 2008), disease-treatment (Jung et al., 2012) and drug-disease. 3 Dataset The dataset for the DDIExtraction 2013 task contains documents from two sources. It includes MedLine abstracts and documents from the DrugBank database describing drug-drug interactions (SeguraBedmar et al., 2013). These documents are annotated with drug entities and with information about drug pair interactions: true or false. In the training corpus the interaction type is also annotated. There are 4 types of interactions: effect, mechanism, int, advice. The challenge corpus is divided into training and evaluation datasets (T</context>
</contexts>
<marker>Airola, Pyysalo, Bjorne, Pahikkala, Ginter, Salakoski, 2008</marker>
<rawString>A. Airola, S. Pyysalo, J. Bjorne, T. Pahikkala, F. Ginter, T. Salakoski. 2008. Allpaths graph kernel for proteinprotein interaction extraction with evaluation of crosscorpus learning BMC Bioinformatics, 9(Suppl 11):S2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aronson</author>
</authors>
<title>Communicating information about drug interactions.</title>
<date>2007</date>
<journal>British Journal of Clinical Pharmacology,</journal>
<volume>63</volume>
<issue>6</issue>
<contexts>
<context position="1239" citStr="Aronson, 2007" startWordPosition="187" endWordPosition="188">ical relations especially. And secondly we will explain our SVM based approaches that use lexical, morphosyntactic and parse tree features. Our combination of sequence and tree kernels have shown promising performance with a best result of 0.54 F1 macroaverage on the test dataset. 1 Introduction A drug-drug interaction occurs when one drug affects the level or activity of another drug, for instance, drug concentrations. This interaction can result on reducing its effectiveness or possibly increasing its side effects (Stockley, 2007). There are some helpful DDIs but most of them are dangerous (Aronson, 2007), for example, patients that take clarithromycin and glibenclamide concurrently may experiment hypoglycaemia. There is a great amount of information about DDI described in papers that health experts have to consult in order to be updated. The development of tools for extracting this type of information from biomedical texts would produce a clear benefit for these professionals reducing the time necessary to review the literature. Semeval 2013 DDI Extraction challenge decided to being held with the aim of identifying the state of the art algorithms for automatically extracting DDI from biomedic</context>
</contexts>
<marker>Aronson, 2007</marker>
<rawString>JK. Aronson. 2007. Communicating information about drug interactions. British Journal of Clinical Pharmacology, 63(6):637–639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Buyko</author>
<author>E Faessler</author>
<author>J Wermter</author>
<author>U Hahn</author>
</authors>
<title>Syntactic Simplification and Semantic Enrichment - Trimming Dependency Graphs for Event Extraction.</title>
<date>2011</date>
<journal>Computational Intelligence,</journal>
<volume>27</volume>
<issue>4</issue>
<marker>Buyko, Faessler, Wermter, Hahn, 2011</marker>
<rawString>E. Buyko, E. Faessler, J. Wermter, U. Hahn 2011. Syntactic Simplification and Semantic Enrichment - Trimming Dependency Graphs for Event Extraction. Computational Intelligence, 27(4):610–644.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chen</author>
<author>F Liu</author>
<author>B Manderick</author>
</authors>
<title>Extract ProteinProtein Interactions from the Literature Using Support Vector Machines with Feature Selection. Biomedical Engineering, Trends, Researchs and Technologies,</title>
<date>2011</date>
<marker>Chen, Liu, Manderick, 2011</marker>
<rawString>Y. Chen, F. Liu, B. Manderick. 2011. Extract ProteinProtein Interactions from the Literature Using Support Vector Machines with Feature Selection. Biomedical Engineering, Trends, Researchs and Technologies, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chan</author>
<author>D Roth</author>
</authors>
<title>Exploiting Background Knowledge for Relation Extraction</title>
<date>2010</date>
<booktitle>COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>152--160</pages>
<contexts>
<context position="5031" citStr="Chan and Roth, 2010" startWordPosition="764" endWordPosition="767">im˜oes et al., 2013) has introduced an approach for Relationship Extraction (RE) based on labeled graph kernels. The proposed kernel is a specification of a random walk kernel that exploits two properties: the words between the candidate entities and the combination of information from distinct sources. A comparative survey regarding different kernel based approaches and their performance can be found in (Frunza and Inkpen, 2008). Using external knowledge and resources to the target sentence is another research direction in the relation extraction task that Chan and Roth have investigated in (Chan and Roth, 2010). They have reported some improvements by using external sources such as Wikipedia, comparing to basic supervised learning systems. Thomas and his colleagues in (Thomas et al., 2011) have developed a majority voting ensemble of contrasting machine learning methods using different linguistic feature spaces. A more systematic and high quality investigation about feature selection in kernel based relation expression can be found in (Jiang and Zhai, 2011). They have explored a large space of features for relation extraction and assess the effectiveness of sequences, syntactic parse trees and depen</context>
</contexts>
<marker>Chan, Roth, 2010</marker>
<rawString>YS. Chan and D. Roth. 2010. Exploiting Background Knowledge for Relation Extraction COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics, pp:152–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Frunza</author>
<author>D Inkpen</author>
</authors>
<title>Extraction of diseasetreatment semantic relations from biomedical sentences</title>
<date>2010</date>
<booktitle>Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,</booktitle>
<pages>91--98</pages>
<marker>Frunza, Inkpen, 2010</marker>
<rawString>O. Frunza and D. Inkpen. 2010. Extraction of diseasetreatment semantic relations from biomedical sentences Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, pp:91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Guodong</author>
<author>Q Longhua</author>
<author>F Jianxi</author>
</authors>
<title>Tree kernelbased semantic relation extraction with rich syntactic and semantic information</title>
<date>2010</date>
<journal>International Journal on Information Sciences,,</journal>
<volume>180</volume>
<issue>8</issue>
<contexts>
<context position="4130" citStr="Guodong et al., 2010" startWordPosition="629" endWordPosition="632">, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics al., 2011) in which a PPI Pair Extractor was developed that consists of a SVM for binary classification which exploits a linear kernel with a rich set of features based on linguistic analysis, contextual words, interaction words, interaction patterns and specific domain information. Another PPI extraction method have been developed in (Li et al., 2010). They have applied an ensemble kernel composed of a feature-based kernel and a structure-based kernel. A more recent research on tree kernels has been carried out by (Guodong et al., 2010). They have introduced a contextsensitive convolution tree kernel, which specifies both context-free and context-sensitive sub-trees by taking into account the paths of their ancestor nodes as their contexts to capture structural information in the tree structure. A recent work (Sim˜oes et al., 2013) has introduced an approach for Relationship Extraction (RE) based on labeled graph kernels. The proposed kernel is a specification of a random walk kernel that exploits two properties: the words between the candidate entities and the combination of information from distinct sources. A comparative </context>
</contexts>
<marker>Guodong, Longhua, Jianxi, 2010</marker>
<rawString>Z. Guodong, Q. Longhua, F. Jianxi. 2010. Tree kernelbased semantic relation extraction with rich syntactic and semantic information International Journal on Information Sciences,, 180(8):1313–1325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>C Zhai</author>
</authors>
<title>A systematic exploration of the feature space for relation extraction</title>
<date>2011</date>
<booktitle>Proceedings of Human Language Technologies: The Conference of the North American Chapter of the Association for Computational Linguistics (NAACLHLT07),</booktitle>
<pages>113--120</pages>
<contexts>
<context position="5486" citStr="Jiang and Zhai, 2011" startWordPosition="833" endWordPosition="836">ledge and resources to the target sentence is another research direction in the relation extraction task that Chan and Roth have investigated in (Chan and Roth, 2010). They have reported some improvements by using external sources such as Wikipedia, comparing to basic supervised learning systems. Thomas and his colleagues in (Thomas et al., 2011) have developed a majority voting ensemble of contrasting machine learning methods using different linguistic feature spaces. A more systematic and high quality investigation about feature selection in kernel based relation expression can be found in (Jiang and Zhai, 2011). They have explored a large space of features for relation extraction and assess the effectiveness of sequences, syntactic parse trees and dependency parse trees as feature subspaces and sentence representation. They conclude that, by means of a set of basic unit features from each subspace, a reasonably good performance can be achieved. But when the three subspaces are combined, the performance can slightly improve, which shows sequence, syntactic and dependency relations have much overlap for the task of relation extraction. Although most of the previous researches in biomedical domain has </context>
</contexts>
<marker>Jiang, Zhai, 2011</marker>
<rawString>J. Jiang and C. Zhai. 2011. A systematic exploration of the feature space for relation extraction Proceedings of Human Language Technologies: The Conference of the North American Chapter of the Association for Computational Linguistics (NAACLHLT07), pp:113– 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jung</author>
<author>S Choi</author>
<author>S Lee</author>
<author>S Song</author>
</authors>
<title>Survey on Kernel-Based Relation Extraction.</title>
<date>2012</date>
<contexts>
<context position="6347" citStr="Jung et al., 2012" startWordPosition="962" endWordPosition="965">f a set of basic unit features from each subspace, a reasonably good performance can be achieved. But when the three subspaces are combined, the performance can slightly improve, which shows sequence, syntactic and dependency relations have much overlap for the task of relation extraction. Although most of the previous researches in biomedical domain has been carried out with respect to protein-protein interaction extraction, and more recently on drug-drug interaction extraction, other types of biomedical relations are being studied: e.g. gene-disease (Airola et al., 2008), disease-treatment (Jung et al., 2012) and drug-disease. 3 Dataset The dataset for the DDIExtraction 2013 task contains documents from two sources. It includes MedLine abstracts and documents from the DrugBank database describing drug-drug interactions (SeguraBedmar et al., 2013). These documents are annotated with drug entities and with information about drug pair interactions: true or false. In the training corpus the interaction type is also annotated. There are 4 types of interactions: effect, mechanism, int, advice. The challenge corpus is divided into training and evaluation datasets (Table 1). The DrugBank training data con</context>
</contexts>
<marker>Jung, Choi, Lee, Song, 2012</marker>
<rawString>H. Jung, S. Choi, S. Lee, S. Song. 2012. Survey on Kernel-Based Relation Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Li</author>
<author>J Ping</author>
<author>D Huang</author>
</authors>
<title>Protein-Protein Interaction Extraction from Biomedical Literatures Based on a Combined Kernel</title>
<date>2010</date>
<journal>Journal of Information &amp; Computational Science,</journal>
<volume>7</volume>
<issue>5</issue>
<contexts>
<context position="3941" citStr="Li et al., 2010" startWordPosition="597" endWordPosition="600">hen et 644 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 644–650, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics al., 2011) in which a PPI Pair Extractor was developed that consists of a SVM for binary classification which exploits a linear kernel with a rich set of features based on linguistic analysis, contextual words, interaction words, interaction patterns and specific domain information. Another PPI extraction method have been developed in (Li et al., 2010). They have applied an ensemble kernel composed of a feature-based kernel and a structure-based kernel. A more recent research on tree kernels has been carried out by (Guodong et al., 2010). They have introduced a contextsensitive convolution tree kernel, which specifies both context-free and context-sensitive sub-trees by taking into account the paths of their ancestor nodes as their contexts to capture structural information in the tree structure. A recent work (Sim˜oes et al., 2013) has introduced an approach for Relationship Extraction (RE) based on labeled graph kernels. The proposed kern</context>
</contexts>
<marker>Li, Ping, Huang, 2010</marker>
<rawString>L. Li, J. Ping, D. Huang. 2010. Protein-Protein Interaction Extraction from Biomedical Literatures Based on a Combined Kernel Journal of Information &amp; Computational Science, 7(5):1065–1073.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris D Paice</author>
</authors>
<title>Another stemmer.</title>
<date>1990</date>
<journal>ACM SIGIR Forum,</journal>
<volume>24</volume>
<issue>3</issue>
<contexts>
<context position="10354" citStr="Paice, 1990" startWordPosition="1614" endWordPosition="1615"> out a normalization task for some tokens because of usage of different used encodings and processing methods, mainly html tags. 4.2 Feature extraction Initially 49 feature classes were extracted for each instance that correspond to a drug pair interaction between Drug1 and Drug2: • Word Features: Include Words of Drug1, words of Drug2, words between Drug1 and Drug2, Figure 1: The different processes followed for our two submitted results. three words before Drug1 and three words after Drug2. Lemmas and stems of all these words. We have used TreeTagger to obtain lemmas and Paice/Husk Stemmer (Paice, 1990) to obtain stems. • Morphosyntactic Features: Include Part-ofspeech (POS) tags of each drug words (Drug1 and Drug2), POS of the previous 3 and next 3 words. We have used TreeTagger. • Constituency parse tree features: Include shortest path between Drug1 and Drug2 in the constituency parse tree, shortest path between first token in the sentence and Drug1, and shortest path between Drug2 and last token in the sentence in the parse tree, and all subtrees gener646 ated from the constituency parse tree. We have used Stanford parser 1 for producing tree features. • Conjunction features: We have prod</context>
</contexts>
<marker>Paice, 1990</marker>
<rawString>Chris D. Paice 1990. Another stemmer. ACM SIGIR Forum, 24(3):56–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Martinez</author>
<author>D S´anchez-Cisneros</author>
</authors>
<date>2011</date>
<booktitle>Proceedings of the 1st Challenge task on DrugDrug Interaction Extraction (DDIExtraction 2011) CEUR Workshop Proceedings,</booktitle>
<volume>761</volume>
<marker>Segura-Bedmar, Martinez, S´anchez-Cisneros, 2011</marker>
<rawString>I. Segura-Bedmar, P. Martinez, D. S´anchez-Cisneros. 2011. Proceedings of the 1st Challenge task on DrugDrug Interaction Extraction (DDIExtraction 2011) CEUR Workshop Proceedings, Vol. 761.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Martnez</author>
<author>M Herrero-Zazo</author>
</authors>
<title>SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from Biomedical Texts.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="2531" citStr="Segura-Bedmar et al., 2013" startWordPosition="383" endWordPosition="386">fication of drug names and extraction of drug-drug interactions. For the second task, the input corpus contains annotations with the drug names. A previous Workshop on Drug-Drug Interaction Extraction (Segura-Bedmar et al., 2011) was held in 2011 in Huelva, Spain. The main difference is that the new challenge includes the classification of the drug-drug interactions in four types depending on the information that is described in the sentence making the task much more complicated than before. Additionally the current task involves DDIs from two different corpora with different characteristics (Segura-Bedmar et al., 2013). We participated in the task of extracting drug-drug interactions with two approaches that exploit a rich set of tree and sequence features. Our implemented methods utilize a SVM classifier with a linear kernel and a rich set of lexical, morphosyntactic and semantic features (e.g. trigger words) extracted from texts. In addition some tree features such as shortest path and subtree features are used. 2 Related work Due to the importance of detecting biological and medical relations several methods have been applied for extracting biological relation information from text. In (Song et al., 2010</context>
</contexts>
<marker>Segura-Bedmar, Martnez, Herrero-Zazo, 2013</marker>
<rawString>I. Segura-Bedmar, P. Martnez, M. Herrero-Zazo. 2013 SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from Biomedical Texts. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sim˜oes</author>
<author>D Matos</author>
<author>H Galhardas</author>
</authors>
<title>A Labeled Graph Kernel for Relationship Extraction.</title>
<date>2013</date>
<location>CoRR, abs/1302.4874.</location>
<marker>Sim˜oes, Matos, Galhardas, 2013</marker>
<rawString>G. Sim˜oes, D. Matos, H. Galhardas. 2013. A Labeled Graph Kernel for Relationship Extraction. CoRR, abs/1302.4874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Song</author>
<author>H Yu</author>
<author>W Han</author>
</authors>
<title>Combining active learning and semi-supervised learning techniques to extract protein interaction sentences.</title>
<date>2010</date>
<booktitle>International Workshop on Data Mining in Bioinformatics .</booktitle>
<contexts>
<context position="3132" citStr="Song et al., 2010" startWordPosition="478" endWordPosition="481">mar et al., 2013). We participated in the task of extracting drug-drug interactions with two approaches that exploit a rich set of tree and sequence features. Our implemented methods utilize a SVM classifier with a linear kernel and a rich set of lexical, morphosyntactic and semantic features (e.g. trigger words) extracted from texts. In addition some tree features such as shortest path and subtree features are used. 2 Related work Due to the importance of detecting biological and medical relations several methods have been applied for extracting biological relation information from text. In (Song et al., 2010) is presented a method for extracting protein-protein interaction (PPI) through combination of an active learning technique and a semi-supervised SVM. Another motivating work can be found in (Chen et 644 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 644–650, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics al., 2011) in which a PPI Pair Extractor was developed that consists of a SVM for binary classification which exploits a linear kernel with a ric</context>
</contexts>
<marker>Song, Yu, Han, 2010</marker>
<rawString>M. Song, H. Yu, W. Han. 2010. Combining active learning and semi-supervised learning techniques to extract protein interaction sentences. International Workshop on Data Mining in Bioinformatics .</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Stockley</author>
</authors>
<title>Stockley’s Drug Interaction.</title>
<date>2007</date>
<publisher>Pharmaceutical Press.</publisher>
<contexts>
<context position="1163" citStr="Stockley, 2007" startWordPosition="173" endWordPosition="174">w some of the existing approaches in relation extraction generally and biomedical relations especially. And secondly we will explain our SVM based approaches that use lexical, morphosyntactic and parse tree features. Our combination of sequence and tree kernels have shown promising performance with a best result of 0.54 F1 macroaverage on the test dataset. 1 Introduction A drug-drug interaction occurs when one drug affects the level or activity of another drug, for instance, drug concentrations. This interaction can result on reducing its effectiveness or possibly increasing its side effects (Stockley, 2007). There are some helpful DDIs but most of them are dangerous (Aronson, 2007), for example, patients that take clarithromycin and glibenclamide concurrently may experiment hypoglycaemia. There is a great amount of information about DDI described in papers that health experts have to consult in order to be updated. The development of tools for extracting this type of information from biomedical texts would produce a clear benefit for these professionals reducing the time necessary to review the literature. Semeval 2013 DDI Extraction challenge decided to being held with the aim of identifying th</context>
</contexts>
<marker>Stockley, 2007</marker>
<rawString>I H Stockley. 2007. Stockley’s Drug Interaction. Pharmaceutical Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Thomas</author>
<author>M Neves</author>
<author>I Solt</author>
<author>D Tikk</author>
<author>U Leser</author>
</authors>
<title>Relation extraction for drug- drug interactions using ensemble learning</title>
<date>2011</date>
<booktitle>Proceedings of the First Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011),</booktitle>
<pages>11--17</pages>
<contexts>
<context position="5213" citStr="Thomas et al., 2011" startWordPosition="793" endWordPosition="796">xploits two properties: the words between the candidate entities and the combination of information from distinct sources. A comparative survey regarding different kernel based approaches and their performance can be found in (Frunza and Inkpen, 2008). Using external knowledge and resources to the target sentence is another research direction in the relation extraction task that Chan and Roth have investigated in (Chan and Roth, 2010). They have reported some improvements by using external sources such as Wikipedia, comparing to basic supervised learning systems. Thomas and his colleagues in (Thomas et al., 2011) have developed a majority voting ensemble of contrasting machine learning methods using different linguistic feature spaces. A more systematic and high quality investigation about feature selection in kernel based relation expression can be found in (Jiang and Zhai, 2011). They have explored a large space of features for relation extraction and assess the effectiveness of sequences, syntactic parse trees and dependency parse trees as feature subspaces and sentence representation. They conclude that, by means of a set of basic unit features from each subspace, a reasonably good performance can</context>
</contexts>
<marker>Thomas, Neves, Solt, Tikk, Leser, 2011</marker>
<rawString>P. Thomas, M. Neves, I. Solt, D. Tikk, U. Leser. 2011. Relation extraction for drug- drug interactions using ensemble learning Proceedings of the First Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pp:11–17.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>