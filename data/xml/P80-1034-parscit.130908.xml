<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.023994">
<sectionHeader confidence="0.642596333333333" genericHeader="method">
FUTURE PROSPECTS FOR COMPUTATIONAL LINGUISTICS
Gary G. Hendrix
SRI International
</sectionHeader>
<bodyText confidence="0.995634833333333">
Preparation of this paper was supported by the Defense Advance Research Projects Agency
under contract N00039-79-C-0118 with the Naval Electronic Systems Command. The views
expressed are those of the author.
A. Introduction
For over two decades, researchers in artificial
intelligence and computational linguistics have sought
to discover principles that would allow computer
systems to process natural languages such as English.
This work has been pursued both to further the
scientific goals of providing a framework for a
computational theory of natural-language communication
and to further the engineering goals of creating
computer-based systems that can communicate with their:.
human users in human terms. Although the goal of
fluent machine-based neutral-language understanding
remains elusive, considerable progress has been made
and future prospects appear bright both for the
advancement of the science and for its application to
the creation of practical systems.
In particular, after 20 years of nurture in the
academic nest, natural-language processing is beginning
to test its wings in the commercial world [8]. By the
end of the decade, natural-language systems are likely
to be in widespread use, bringing computer resources to
large numbers of non-computer specialists and bringing
new credibility (and hopefully new levels of funding)
to the research community.
B. Basis for Optimism
My optimism is based on an extrapolation of three
major trends currently affecting the field:
</bodyText>
<listItem confidence="0.913653714285714">
(1) The emergence of an engineering/applications
discipline within the computational-
linguistics community.
(2) The continuing rapid development of new
computing hardware coupled with the beginning
of a movement from time-sharing to personal
computers.
(3) A shift from syntax and semantics as the
principle objects of study to the development
of theories that cast language use in terms
of a broader theory of goal-motivated
behavior and that seek primarily to explain
how a speaker&apos;s cognitive state motivates him
to engage in an act of communication, how a
</listItem>
<bodyText confidence="0.98697094">
speaker devises utterances with which to
perform the act, and how acts of
communication affect the cognitive states- of
hearers.
C. The Impact of Engineering
The emergence of an engineering discipline may
strike many researchers in the field as being largely
detached from the mainstream of current work. But I
believe that, for better or worse, this discipline will
have a major and continuing influence on our research
community. The public at large tends, often unfairly,
to view a science through the products and concrete
results it produces, rather than through the mysteries
of nature it reveals. Thus, the chemist is seen as the
person who produces fertilizer, food coloring and nylon
stockings; the biologist finds cures for diseases; and
the physicist produces moon rockets, semiconductors,
and nuclear power plants. What has computational
linguistics produced that has affected the lives of
individuals outside the limits of its own close-knit
community? As long as the answer remains. &amp;quot;virtually
nothing,&amp;quot; our work will generally be viewed as an ivory
tower enterprise. As soon as the answer becomes a set
of useful computer systems, we will be viewed as the
people who produce such systems and who aspire to
produce better ones.
My point here is that the commercial marketplace
will tend to judge both our science and our engineering
in terms of our existing or potential engineering
products. This is, of course, rather unfair to the
science; but I believe that it bodes well for our
future. After all, most of the current sponsors of
research on computational linguistics understand the
scientific nature of the enterprise and are likely to
continue their support even in the face of minor
successes on the engineering front. The impact of an
engineering arm can only add to our field&apos;s basis of
support by bringing in new suport from the commercial
sector.
One note of caution is appropriate, however.
There is a real possibility that as commercial
enterprises enter the natural-language field, they will
seek to build in-house groups by attracting researchers
from universities and nonprofit institutions. Although
this would result in the creation of more jobs for
computational linguists, it would also result in
proprietary barriers being established between research
groups. The net effect in the short term might
actually be to retard scientific progress.
D. The State of Applied Work
</bodyText>
<listItem confidence="0.940665">
1. Accessing Databases
</listItem>
<bodyText confidence="0.9997265">
Currently, the most commercially viable task
for natural-language processing is that of providing
access to databases. This is because databases are
among the few types of symbolic knowledge
representations that are computationally efficient, are
in widespread use, and have a semantics that is well
understood.
In the last few years, several systems,
including LADDER [9], PLANES [29], REL [26j, and ROBOT
[8], have achieved relatively high levels of
proficiency in this area when applied to particular
databases. ROBOT has been introduced as a commercial
product that runs on large, mainframe computers. A
pilot REL product is currently under development that
will run on a relatively large personal machine, the HP
9845. This system, or something very much like it,
seems likely to reach the marketplace within the next
two or three years. Should ROBOT- and REL-like systems
prove to be commercial successes, other systems with
increasing levels of sophistication are sure to follow.
</bodyText>
<listItem confidence="0.466225">
2. Immediate Problems
</listItem>
<bodyText confidence="0.99950875">
A major obstacle currently limiting the
commercial viability of natural-language access to
databases is the problem of telling systems about the
vocabulary, concepts and linguistic constructions
associated with new databases. The most proficient of
the application systems have been hand-tailored with
extensive knowledge for accessing just ONE database.
Some systems (e.g., ROBOT and REL) have achieved a
</bodyText>
<page confidence="0.997413">
131
</page>
<bodyText confidence="0.997229083333334">
degree of transportability by using the database itself
as a source of knowledge for guiding linguistic
processes. However, the knowledge available in the
database is generally rather limited. High-performance
systems need access to information about the larger
enterprise that provides the context in which the
database is to be used.
As pointed out by Tennant [27], users who are
given natural-language access to a database expect not
only to retrieve information directly stored there, but
also to compute &amp;quot;reasonable&amp;quot; derivative information.
For example, if a database has the location of two
ships, users will expect the system to be able to
provide the distance between them--an item of
information not directly recorded in the database, but
easily computed from the existing data. In general,
any system thatis to be widely accepted by users must
not only provide access to database information, but
must also enhance that primary information by providing
procedures that calculate secondary attributes from the
data actually stored. Data enhancement procedures are
currently provided by LADDER and a few other hand-built
systems. But work is needed to devise means for
allowing system users to specify their own database
enhancement functions and to couple their functions
with the natural-language component.
Efforts are now underway (e.g. [26] [13]) to
simplify the task of acquiring and coding the knowledge
needed to transport high-performance systems from one
database to another. It appears likely that soon much
of this task can be automated or performed by a
database administrator, rather than by a computational
linguist. When this is achieved, natural-language
access to data is likely to move rapidly into
widespread use.
E. New Hardware
VLSI (Very Large Scale Integration of computer
circuits on single chips) is revolutionizing the
computer industry. Within the last year, new personal
computer systems have been announced that, at
relatively low cost, will provide throughputs rivaling
that of the Digital Equipment KA-10, the time-sharing
research machine of choice as recently as seven years
ago. Although specifications for the new machines
differ, a typical configuration will support a very
large (32 bit) virtual address space, which is
important for knowledge-intensive natural-language
processing, and will provide approximately 20 megabytes
of local storage, enough for a reasonable-size
database.
Such machines will provide a great deal of
personal computing power at costs that are initially
not much greater than those for a single user&apos;s access
to a time-shared system, and that are likely to fall
rapidly. Hardware costs reductions will be
particularly significant for the many small research
groups that do not have enough demand to justify the
purchase of a large, time-shared machine.
The new generation of machines will have the
virtual address space and the speed needed to overcome
many of the technical bottlenecks that have hampered
research in the past. For example, researchers may be
able to spend less time worrying about how to optimize
inner loops or how to split large programs into
multiple forks. The effort saved can be devoted to the
problems of language research itself.
The new machines will also make it economical to
bring co 3iderable computing to people in all sectors
of the economy, including government, the military,
small business, and to smaller units within large
businesses. Detached from the computer wizards that
staff the batch processing center or the time-shared
facility, users of the new personal machines will need
to be more self reliant. Yet, as the use of personal
computers spread, these users are likely to be
increasingly less sophisticated about computation.
Thus, there will be an increasing demand to make
personal computers easier to use. As the price of
computation drops (and the price of human labor
continues to soar), the use of sophisticated means for
interacting intelligently with a broad class of
computer users will become more and more attractive and
demands for natural-language interfaces are likely to
mushroom.
F. Future Directions for Basic Research
1. The Research Base
Work on computational linguistics appears to
be focusing on a rather different set of issues than
those that received attention a few years ago. In
particular, mechanisms for dealing with syntax and the
literal propositional content of sentences have become
fairly well understood, so that now there is increasing
interest in the study of language as a component in a
broader system of goal-motivated behavior. Within this
framework, dialogue participation is not studied as a
detached linguistic phenomenon, but as an activity of
the total intellect, requiring close coordination
between language-specific and general cognitive
processing.
Several characteristics of the communicative
use of language pose significant problems. Utterances
are typically spare, omitting information easily
inferred by the hearer from shared knowledge about the
domain of discourse. Speakers depend on their hearers
to use such knowledge together with the context of the
preceding discourse to make partially specified ideas
precise. In addition, the literal content of an
utterance must be interpreted within the context of the
beliefs, goals, and plans of the dialogue participants,
so that a hearer can move beyond literal content to the
intentions that lie behind the utterance. Furthermore,
it is not sufficient to consider an utterance as being
addressed to a single purpose; typically it serves
multiple purposes: it highlights certain objects and
relationships, conveys an attitude toward them, and
provides links to previous utterances in addition to
communicating some propositional content.
An examination of the current state of the
art in natural-language processing systems reveals
several deficiencies in the combination and
coordination of language-specific and general-purpose
reasoning capabilities. Although there are some
systems that coordinate different kinds of language-
specific capabilities [3] [12] [20] [16] [30] L17J,
and some that reason about limited action scenarios
[21] [15] [19] [25] to arrive at an interpretation of
what has been said, and others that attempt to account
for some of the ways in which context affects meaning
[7] [10] [18] [14], one or more of the following
crucial limitations is evident in every natural-
language processing system constructed to date:
Interpretation is literal (only propositional
content is determined).
The user&apos;s knowledge and beliefs are assumed to be
id.ntical with the system&apos;s.
The user&apos;s plans and goals (especially as distinct
from those of the system) are ignored.
Initial progress has been made in overcoming some of
these limitations. Wilensky [28] has investigated the
use of goals and plans in a computer system that
interprets stories (see also [22] [4]). Allen and
Perrault [1] and Cohen [6] have examined the
interaction between beliefs and plans in task-oriented
dialogues and have implemented a system that uses
</bodyText>
<page confidence="0.9911">
132
</page>
<bodyText confidence="0.999924888888889">
information about what its &amp;quot;hearer&amp;quot; knows in order to
plan and to recognize a limited set of speech acts
(Searle [23] [24j). These efforts have demonstrated
the viability of incorporating planning capabilities in
a natural-language processing system, but more robust
reasoning and planning capabilities are needed to
approach the smooth integration of language-specific
and general reasoning capabilities required for fluent
communication in natural language.
</bodyText>
<listItem confidence="0.509155">
2. Some Predictions
</listItem>
<bodyText confidence="0.999927422222223">
Basic research provides a leading indicator
with which to predict new directions in applied science
and engineering; but I know of no leading indicator for
basic research itself. About the best we can do is to
consider the current state of the art, seek to identify
central problems, and predict that those problems will
be the ones receiving the most attention.
The view of language use as an activity of
the total intellect makes it clear that advances in
computational linguistics will be closely tied to
advances in research on general-purpose common-sense
reasoning. Hobbs [11], for example, has argued that 10
seemingly different and fundamental problems of
computational linguistics may all be reduced to
problems of common-sense deduction, and Cohen&apos;s work
clearly ties language to planning.
The problems of planning and reasoning are,
of course, central problems for the whole of Al. But
computational linguistics brings to these problems its
own special requirements, such as the need to consider
the beliefs, goals, and possible actions of multiple
agents, and the need to precipitate the achievement of
multiple goals through the performance of actions with
multiple-faceted primary effects. There are similar
needs in other applications, but nowhere do they arise
more naturally than in human language.
In addition to a growing emphasis on general-
purpose reasoning capabilities, I believe that the next
few years will see an increased interest in natural-
language generation, language acquisition, information-
science applications, multimedia communication, and
speech.
Generation: In comparison with
interpretation, generation has received relatively
little attention as a subject of study. One
explanation is that computer systems have more control
over output than input, and therefore have been able to
rely on canned phrases for output. Whatever the reason
for past neglect, it is clear that generation deserves
increased attention. As computer systems acquire more
complex knowledge bases, they will require better means
of communicating their knowledge. More importantly,
for a system to carry on a reasonable dialogue with a
user, it must not only interpret inputs but also
respond appropriately in context, generating responses
that are custom tailored to the (assumed) needs and
mental state of the user.
Hopefully, much of the same research that is
needed on planning and reasoning to move beyond literal
content in interpretation will provide a basis for
sophisticated generation.
Acquisition: Another generally neglected
area, at least computationally, is that of language
acquisition. Berwick [2] has made an interesting
start in this area with his work on the acquisition of
grammar rules. Equally important is work on
acquisition of new vocabulary, either through reasoning
by analogy [5] or simply by being told new words [13].
Because language acquisition (particularly vocabulary
acquisition) is essential for moving natural-language
systems to new domains, I believe considerable
resources are likely to be devoted to this problem and
that therefore rapid progress will ensue.
Information Science: One of the greatest
resources of our society is the wealth of knowledge
recorded in natural-language texts; but there are major
obstacles to placing relevant texts in the hands of
those who need them. Even when texts are made
available in machine-readable form, documents relevant
to the solution of particular problems are notoriously
difficult to locate. Although computational
linguistics has no ready solution to the problems of
information science, I believe that it is the only real
source of hope, and that the future is likely to bring
increased cooperation between workers in the two
fields.
Multimedia Communication: The use of natural
language is, of course, only one of several means of
communication available to humans. In viewing language
use from a broader framework of goal-directed activity,
the use of other media and their possible interactions
with language, with one another, and with general-
purpose problem-solving facilities becomes increasingly
important as a subject of study.
Many of the most central problems of
computational linguistics come up in the use of any
medium of communication. For example, one can easily
imagine something like speech acts being performed
through the use of pictures and gestures rather than
through utterances in language. In fact, these types
of communicative acts are what people use to
communicate when they share no verbal language in
common.
As computer systems with high-quality
graphics displays, voice synthesizers, and other types
of output devices come into widespread use, an
interesting practical problem will be that of deciding
what medium or mixture of media is most appropriate for
presenting information to users under a given set of
circumstances. I believe we can look forward to rapid
progress on the use of multimedia communication,
especially in mixtures of text and graphics (e.g., as
in the use of a natural-language text to help explain a
graphics display).
Spoken Input: In the long term, the greatest
promise for a broad range of practical applications
lies in accessing computers through (continuous) spoken
language, rather than through typed input. Given its
tremendous economic importance, I believe a major new
attack on this problem is likely to be mounted before
the end of the decade, but I would be uncomfortable
predicting its outcome.
Although continuous speech input may be some
years away, excellent possibilities currently exist for
the creation of systems that combine discrete word
recognition with practical natural-language processing.
Such systems are well worth pursuing as an important
interim step toward providing machines with fully
natural communications abilities.
G. Problems of Technology Transfer
The expected progress in basic research over the
next few years will, of course, eventually have
considerable impact on the development of practical
systems. Even in the near term, basic research is
certain to produce many spinoffs that, in simplified
form, will provide practical benefits for applied
systems. But the problems of transferring scientific
progress from the laboratory to the marketplace must
not be underestimated. In particular, techniques that
work well on carefully selected laboratory problems are
often difficult to use on a large-scale basis.
(Perhaps this is because of the standard scientific
practice of selecting as a subject for experimentation
the simplest problem exhibiting the phenomena of
interest.)
</bodyText>
<page confidence="0.998022">
133
</page>
<bodyText confidence="0.999957971428572">
As an example of this difficulty, consider
knowledge representation. Currently, conventional
database management systems (DBMSs) are the only
systems in widespread use for storing symbolic
information. The Al community, of course, has a number
of methods for maintaining more sophisticated knowledge
bases of, say, formulas in first-order logic. But
their complexity and requirements for great amounts of
computer resources (both memory and time) have
prevented any such systems from becoming a commercially
viable alternative to standard DBMSs.
I believe that systems that maintain mooels of the
ongoing dialogue and the changing physical context (as
in, for example, Grosz [7] and Robinson [19]) or that
reason about the mental states of users will eventually.
become important in practical applications. But the
computational requirements for such systems are so much
greater than those of current applied systems that they
will have little commercial viability for some time.
Fortunately, the linguistic coverage of several
current systems appears to be adequate for many
practical purposes, so commercialization need not wait
for more advanced techniques to be transferred. On the
other hand, applied systems currently are only barely
up to their tasks, and therefore there is a need for an
ongoing examination of basic research results to find
ways of repackaging advanced techniques in cost-
effective forms.
In general, the basic science and the application
of computational linguistics should be pursued in
parallel, with each aiding the other. Engineering can
aid the science by anchoring it to actual needs and by
pointing out new problems. Basic science can provide
engineering with techniques that provide new
Opportunities for practical application.
</bodyText>
<page confidence="0.998141">
134
</page>
<sectionHeader confidence="0.99445" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999826833333333">
I. Allen, J. &amp; C. Perrault. 1978. Participating in
Dialogues: Understanding via plan deduction.
Proceedings, Second National Conference, Canadian
Society for Computational Studies of Intelligence,
Toronto, Canada.
2. Berwick, R. C., 1980. Computational Analogues of
Constraints on Grammars: A Model of Syntactic
Acquisition. The 18th Annual Meeting of the
Association for Computational Linguistics,
Philadelphia, Pennsylvania, June 1980.
3. Bobrow, D. G., et al. 1977. GUS, A Frame Driven
Dialog System. Artificial Intelligence, 8, 155-
173.
4. Carbonell, J. G. 1978. Computer Models of Social
and Political Reasoning. Ph.D. Thesis, Yale
University, New Haven, Connecticut.
5. Carbonell, J. G. 1980. Metaphor--A Key to
Extensible Semantic Analysis. The 18th Annual
Meeting of the Association for Computational
Linguistics, Philadelphia, Pennsylvania, June
1980.
6. Cohen, P. 1978. On knowing what to say: planning
speech acts. Technical Report No. 118, Department
of Computer Science, University of Toronto.
January 1978.
7. Grosz, B. J., 1978. Focusing in Dialog.
Proceedings of TINLAP-2, Urbana, Illinois, 24-26
July, 1978.
8. L. R. Harris, 1977. User Oriented Data Base Query
with the ROBOT Natural Language Query System.
Proc. Third International Conference on Very
Large Data Bases, Tokyo (October 1977).
9. G. G. Hendrix, E. D. Sacerdoti, D. Sagalowicz, and
J. Slocum, 1978. Developing a Natural Language
Interface to Complex Data. ACM Transactions on
Database Systems, Vol. 3, No. 2 (June 1978).
10. Hobbs, J. 1979. Coherence and coreference.
Cognitive Science. Vol. 3, No. 1, 67-90.
11. Hobbs, J. 1980. Selective inferencing. Third
National Conference of Canadian Society for
Computational Studies of Intelligence. Victoria,
British Columbia. May 1980.
12. Landsbergen, S. P. J., 1976. Syntax and Formal
Semantics of English in PHLIQA1. In Coling 76,
Preprints of the 6th International Conference on
Computational Linguistics, Ottawa, Ontario,
Canada, 28 June - 2 July 1976. No. 21.
13. Lewis, w. H., and Hendrix, G. G., 1979. Machine
Intelligence: Research and Applications -- First
Semiannual Report. SRI International, Menlo Park,
California, October 8, 1979.
14. Mann, W., J. Moore, &amp; J. Levin 1977. A
comprehension model for human dialogue.
Proceedings, International Joint Conference on
Artificial Intelligence, 77-87, Cambridge, Mass.
August 1977.
15. Novak, G. 1977. Representations of knowledge in a
program for solving physics problems. Proceedings,
International Joint Conference on Artificial
Intelligence, 286-291, Cambridge, Mass. August
1977.
16. Petrick, S. R. 1978. Automatic Syntactic and
Semantic Analysis. In Proceedings of the
Interdsciplainary Conference on Automated Text
Processing (Bielefeld, German Federal Republic, 8-
12 November 1976). Edited by J. Petofi and S.
Allen. Reidel, Dordrecht, Holland.
17. Reddy, D. R., et al. 1977. Speech Understanding
Systems: A Summary of Results of the Five-Year
Research Effort. Department of Computer Science.
Carnegie-Mellon University, Pittsburgh,
Pennsylvania, August, 1977.
18. Rieger, C. 1975. Conceptual Overlays: A Mechanism
for the Interpretation of Sentence Meaning in
Context. Technical Report 7R-354. Computer Science
Department, University of Maryland, College Park,
Maryland. February 1975.
19. Robinson, Ann E. The Interpretation of Verb
Phrases in Dialogues. Technical Note 206,
Artificial Intelligence Center, SRI International,
Menlo Park, Ca., January 1980.
20. Sager, N. and R. Grishman. 1975. The Restriction
Language for Computer Grammars. Communications of
the ACM, 1975, 18, 390-400.
21. Schenk, R. C., and Yale A.I. 1975. SAM--A Story
Understander. Yale University, Department of
Computer Science Research Report.
22. Schank, R. and R. Abelson. 1977. Scripts, plans,
goals, and understanding. Hillsdale N.J.: Laurence
Erlbaum Associates.
23. Searle, J. 1969. Speech acts: An essay in the
philosophy of language. Cambridge, England:
Cambridge University Press.
24. Searle, J 1975. Indirect speech acts. In P. Cole
and J. Morgan (Eds.), Syntax and semantics, Vol.
3, 59-82. New York: Academic Press.
25. Sidner, C. L. 1979. A Computational Model of Co-
Reference Comprehension in English. Ph.D. Thesis,
Massachusetts Institute of Technology, Cambridge,
Massachusetts.
26. F. B. Thompson and B. H. Thompson, 1975. Practical
Natural Language Processing: The REL System as
Prototype. In M. Rubinoff and M. C. Yovits, eds.,
Advances in Computers 13 (Academic Press, New
York, 1975).
27. H. Tennant, &amp;quot;Experience with the Evaluation of
Natural Language Question Answerers,&amp;quot; &amp;Proc. Sixth
International Joint Conference on Artificial
Intelligened, Tokyo, Japan (August 1979).
28. Wilensky, R. 1978. &amp;quot;Understanding Goal-Based
Stories.&amp;quot; Yale University, New Haven, Connecticut.
Ph.D. Thesis.
29. D. Waltz, &amp;quot;Natural Language Access to a Large Data
Base: an Engineering Approach,&amp;quot; Proc. 4th
Internatioal Joint Conference on Artificial
Intelligence, Tbilisi, USSR, pp. 868-872
(September 1975).
30. Woods, W. A., et al. 1976. Speech Understanding
Systems: Final Report. BBB Report No. 3438, Bolt
Beranek and Newman, Cambridge, Massachusetts.
</reference>
<page confidence="0.998791">
135
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000080">
<title confidence="0.999003">FUTURE PROSPECTS FOR COMPUTATIONAL LINGUISTICS</title>
<author confidence="0.999998">Gary G Hendrix</author>
<affiliation confidence="0.997732">SRI International</affiliation>
<abstract confidence="0.998257146993319">of this paper by the Defense Advance Research Projects Agency under contract N00039-79-C-0118 with the Naval Electronic Systems Command. The views expressed are those of the author. For over two decades, researchers in artificial intelligence and computational linguistics have sought to discover principles that would allow computer systems to process natural languages such as English. This work has been pursued both to further the scientific goals of providing a framework for a computational theory of natural-language communication and to further the engineering goals of creating computer-based systems that can communicate with their:. human users in human terms. Although the goal of fluent machine-based neutral-language understanding remains elusive, considerable progress has been made and future prospects appear bright both for the advancement of the science and for its application to the creation of practical systems. In particular, after 20 years of nurture in the academic nest, natural-language processing is beginning to test its wings in the commercial world [8]. By the end of the decade, natural-language systems are likely to be in widespread use, bringing computer resources to large numbers of non-computer specialists and bringing new credibility (and hopefully new levels of funding) to the research community. Basisfor My optimism is based on an extrapolation of three major trends currently affecting the field: (1) The emergence of an engineering/applications discipline within the computationallinguistics community. (2) The continuing rapid development of new computing hardware coupled with the beginning of a movement from time-sharing to personal computers. (3) A shift from syntax and semantics as the principle objects of study to the development of theories that cast language use in terms of a broader theory of goal-motivated behavior and that seek primarily to explain how a speaker&apos;s cognitive state motivates him to engage in an act of communication, how a speaker devises utterances with which to perform the act, and how acts of affect the cognitive of hearers. The Impact of The emergence of an engineering discipline may strike many researchers in the field as being largely detached from the mainstream of current work. But I believe that, for better or worse, this discipline will have a major and continuing influence on our research community. The public at large tends, often unfairly, to view a science through the products and concrete results it produces, rather than through the mysteries of nature it reveals. Thus, the chemist is seen as the person who produces fertilizer, food coloring and nylon stockings; the biologist finds cures for diseases; and the physicist produces moon rockets, semiconductors, and nuclear power plants. What has computational linguistics produced that has affected the lives of individuals outside the limits of its own close-knit community? As long as the answer remains. &amp;quot;virtually nothing,&amp;quot; our work will generally be viewed as an ivory tower enterprise. As soon as the answer becomes a set of useful computer systems, we will be viewed as the people who produce such systems and who aspire to produce better ones. My point here is that the commercial marketplace will tend to judge both our science and our engineering in terms of our existing or potential engineering products. This is, of course, rather unfair to the science; but I believe that it bodes well for our future. After all, most of the current sponsors of research on computational linguistics understand the scientific nature of the enterprise and are likely to continue their support even in the face of minor successes on the engineering front. The impact of an engineering arm can only add to our field&apos;s basis of support by bringing in new suport from the commercial sector. One note of caution is appropriate, however. There is a real possibility that as commercial enterprises enter the natural-language field, they will seek to build in-house groups by attracting researchers from universities and nonprofit institutions. Although this would result in the creation of more jobs for computational linguists, it would also result in proprietary barriers being established between research groups. The net effect in the short term might actually be to retard scientific progress. The State of AppliedWork 1. Accessing Databases Currently, the most commercially viable task for natural-language processing is that of providing access to databases. This is because databases are among the few types of symbolic knowledge representations that are computationally efficient, are in widespread use, and have a semantics that is well understood. In the last few years, several systems, including LADDER [9], PLANES [29], REL [26j, and ROBOT [8], have achieved relatively high levels of proficiency in this area when applied to particular databases. ROBOT has been introduced as a commercial product that runs on large, mainframe computers. A pilot REL product is currently under development that will run on a relatively large personal machine, the HP 9845. This system, or something very much like it, seems likely to reach the marketplace within the next two or three years. Should ROBOTand REL-like systems prove to be commercial successes, other systems with increasing levels of sophistication are sure to follow. 2. Immediate Problems A major obstacle currently limiting the commercial viability of natural-language access to databases is the problem of telling systems about the vocabulary, concepts and linguistic constructions associated with new databases. The most proficient of the application systems have been hand-tailored with extensive knowledge for accessing just ONE database. Some systems (e.g., ROBOT and REL) have achieved a 131 degree of transportability by using the database itself a source of knowledge linguistic processes. However, the knowledge available in the database is generally rather limited. High-performance to information about the larger enterprise that provides the context in which the database is to be used. pointed out by Tennant who are given natural-language access to a database expect not only to retrieve information directly stored there, but also to compute &amp;quot;reasonable&amp;quot; derivative information. For example, if a database has the location of two ships, users will expect the system to be able to provide the distance between them--an item of information not directly recorded in the database, but easily computed from the existing data. In general, any system thatis to be widely accepted by users must not only provide access to database information, but must also enhance that primary information by providing procedures that calculate secondary attributes from the data actually stored. Data enhancement procedures are provided by a few other hand-built systems. But work is needed to devise means for allowing system users to specify their own database enhancement functions and to couple their functions with the natural-language component. Efforts are now underway (e.g. [26] [13]) to simplify the task of acquiring and coding the knowledge needed to transport high-performance systems from one database to another. It appears likely that soon much of this task can be automated or performed by a database administrator, rather than by a computational linguist. When this is achieved, natural-language access to data is likely to move rapidly into widespread use. New VLSI (Very Large Scale Integration of computer circuits on single chips) is revolutionizing the computer industry. Within the last year, new personal computer systems have been announced that, at relatively low cost, will provide throughputs rivaling that of the Digital Equipment KA-10, the time-sharing research machine of choice as recently as seven years ago. Although specifications for the new machines differ, a typical configuration will support a very large (32 bit) virtual address space, which is important for knowledge-intensive natural-language processing, and will provide approximately 20 megabytes of local storage, enough for a reasonable-size database. Such machines will provide a great deal of personal computing power at costs that are initially not much greater than those for a single user&apos;s access to a time-shared system, and that are likely to fall rapidly. Hardware costs reductions will be particularly significant for the many small research groups that do not have enough demand to justify the purchase of a large, time-shared machine. The new generation of machines will have the virtual address space and the speed needed to overcome many of the technical bottlenecks that have hampered research in the past. For example, researchers may be able to spend less time worrying about how to optimize inner loops or how to split large programs into multiple forks. The effort saved can be devoted to the problems of language research itself. The new machines will also make it economical to bring co 3iderable computing to people in all sectors of the economy, including government, the military, small business, and to smaller units within large businesses. Detached from the computer wizards that staff the batch processing center or the time-shared facility, users of the new personal machines will need to be more self reliant. Yet, as the use of personal computers spread, these users are likely to be increasingly less sophisticated about computation. Thus, there will be an increasing demand to make personal computers easier to use. As the price of computation drops (and the price of human labor continues to soar), the use of sophisticated means for interacting intelligently with a broad class of computer users will become more and more attractive and demands for natural-language interfaces are likely to mushroom. Future Directionsfor Basic The ResearchBase Work on computational linguistics appears to be focusing on a rather different set of issues than those that received attention a few years ago. In particular, mechanisms for dealing with syntax and the literal propositional content of sentences have become fairly well understood, so that now there is increasing interest in the study of language as a component in a broader system of goal-motivated behavior. Within this framework, dialogue participation is not studied as a detached linguistic phenomenon, but as an activity of the total intellect, requiring close coordination between language-specific and general cognitive processing. Several characteristics of the communicative use of language pose significant problems. Utterances are typically spare, omitting information easily inferred by the hearer from shared knowledge about the domain of discourse. Speakers depend on their hearers to use such knowledge together with the context of the preceding discourse to make partially specified ideas precise. In addition, the literal content of an utterance must be interpreted within the context of the beliefs, goals, and plans of the dialogue participants, so that a hearer can move beyond literal content to the intentions that lie behind the utterance. Furthermore, it is not sufficient to consider an utterance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. examination of the current state of in processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagecapabilities [3] [12] [20] [16] [30] and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach the smooth integration of language-specific and general reasoning capabilities required for fluent communication in natural language. Basic research provides a leading indicator with which to predict new directions in applied science and engineering; but I know of no leading indicator for basic research itself. About the best we can do is to consider the current state of the art, seek to identify central problems, and predict that those problems will be the ones receiving the most attention. The view of language use as an activity of the total intellect makes it clear that advances in computational linguistics will be closely tied to advances in research on general-purpose common-sense Hobbs example, has argued that 10 seemingly different and fundamental problems of computational linguistics may all be reduced to problems of common-sense deduction, and Cohen&apos;s work clearly ties language to planning. The problems of planning and reasoning are, of course, central problems for the whole of Al. But computational linguistics brings to these problems its own special requirements, such as the need to consider the beliefs, goals, and possible actions of multiple agents, and the need to precipitate the achievement of multiple goals through the performance of actions with multiple-faceted primary effects. There are similar in other applications, but nowhere arise more naturally than in human language. In addition to a growing emphasis on generalpurpose reasoning capabilities, I believe that the next few years will see an increased interest in naturallanguage generation, language acquisition, informationscience applications, multimedia communication, and speech. Generation:In comparison with interpretation, generation has received relatively little attention as a subject of study. One explanation is that computer systems have more control over output than input, and therefore have been able to rely on canned phrases for output. Whatever the reason for past neglect, it is clear that generation deserves increased attention. As computer systems acquire more complex knowledge bases, they will require better means of communicating their knowledge. More importantly, for a system to carry on a reasonable dialogue with a user, it must not only interpret inputs but also respond appropriately in context, generating responses that are custom tailored to the (assumed) needs and mental state of the user. Hopefully, much of the same research that is needed on planning and reasoning to move beyond literal in interpretation will provide for sophisticated generation. Acquisition:Another generally neglected area, at least computationally, is that of language acquisition. Berwick [2] has made an interesting start in this area with his work on the acquisition of grammar rules. Equally important is work on acquisition of new vocabulary, either through reasoning by analogy [5] or simply by being told new words [13]. Because language acquisition (particularly vocabulary acquisition) is essential for moving natural-language systems to new domains, I believe considerable resources are likely to be devoted to this problem and that therefore rapid progress will ensue. Science:One of the greatest resources of our society is the wealth of knowledge recorded in natural-language texts; but there are major obstacles to placing relevant texts in the hands of those who need them. Even when texts are made available in machine-readable form, documents relevant to the solution of particular problems are notoriously difficult to locate. Although computational linguistics has no ready solution to the problems of information science, I believe that it is the only real source of hope, and that the future is likely to bring increased cooperation between workers in the two fields. Communication:The use of natural language is, of course, only one of several means of communication available to humans. In viewing language use from a broader framework of goal-directed activity, the use of other media and their possible interactions with language, with one another, and with generalpurpose problem-solving facilities becomes increasingly important as a subject of study. Many of the most central problems of computational linguistics come up in the use of any medium of communication. For example, one can easily imagine something like speech acts being performed the use of pictures rather than through utterances in language. In fact, these types of communicative acts are what people use to communicate when they share no verbal language in common. As computer systems with high-quality graphics displays, voice synthesizers, and other types of output devices come into widespread use, an interesting practical problem will be that of deciding what medium or mixture of media is most appropriate for presenting information to users under a given set of circumstances. I believe we can look forward to rapid progress on the use of multimedia communication, especially in mixtures of text and graphics (e.g., as in the use of a natural-language text to help explain a graphics display). Input:In the long term, the greatest promise for a broad range of practical applications lies in accessing computers through (continuous) spoken language, rather than through typed input. Given its tremendous economic importance, I believe a major new attack on this problem is likely to be mounted before the end of the decade, but I would be uncomfortable predicting its outcome. Although continuous speech input may be some years away, excellent possibilities currently exist for the creation of systems that combine discrete word recognition with practical natural-language processing. Such systems are well worth pursuing as an important interim step toward providing machines with fully natural communications abilities. Problemsof Transfer The expected progress in basic research over the will, of course, eventually have considerable impact on the development of practical systems. Even in the near term, basic research is certain to produce many spinoffs that, in simplified form, will provide practical benefits for applied systems. But the problems of transferring scientific progress from the laboratory to the marketplace must not be underestimated. In particular, techniques that work well on carefully selected laboratory problems are often difficult to use on a large-scale basis. (Perhaps this is because of the standard scientific practice of selecting as a subject for experimentation the simplest problem exhibiting the phenomena of interest.) 133 As an example of this difficulty, consider knowledge representation. Currently, conventional database management systems (DBMSs) are the only systems in widespread use for storing symbolic information. The Al community, of course, has a number of methods for maintaining more sophisticated knowledge bases of, say, formulas in first-order logic. But their complexity and requirements for great amounts of computer resources (both memory and time) have prevented any such systems from becoming a commercially viable alternative to standard DBMSs. I believe that systems that maintain mooels of the ongoing dialogue and the changing physical context (as in, for example, Grosz [7] and Robinson [19]) or that reason about the mental states of users will eventually. become important in practical applications. But the computational requirements for such systems are so much greater than those of current applied systems that they will have little commercial viability for some time. Fortunately, the linguistic coverage of several current systems appears to be adequate for many practical purposes, so commercialization need not wait for more advanced techniques to be transferred. On the other hand, applied systems currently are only barely to their tasks, and therefore there is a need for ongoing examination of basic research results to find ways of repackaging advanced techniques in costeffective forms. In general, the basic science and the application of computational linguistics should be pursued in parallel, with each aiding the other. Engineering can aid the science by anchoring it to actual needs and by pointing out new problems. Basic science can provide engineering with techniques that provide new Opportunities for practical application.</abstract>
<note confidence="0.638411">134 REFERENCES I. Allen, J. &amp; C. Perrault. 1978. Participating in Dialogues: Understanding via plan deduction. Proceedings, Second National Conference, Canadian</note>
<affiliation confidence="0.620439">Society for Computational Studies of Intelligence,</affiliation>
<address confidence="0.930302">Toronto, Canada.</address>
<note confidence="0.949323446153846">2. Berwick, R. C., 1980. Computational Analogues of Constraints on Grammars: A Model of Syntactic Acquisition. The 18th Annual Meeting of the Association for Computational Linguistics, Philadelphia, Pennsylvania, June 1980. 3. Bobrow, D. G., et al. 1977. GUS, A Frame Driven Dialog System. Artificial Intelligence, 8, 155- 173. 4. Carbonell, J. G. 1978. Computer Models of Social and Political Reasoning. Ph.D. Thesis, Yale University, New Haven, Connecticut. 5. Carbonell, J. G. 1980. Metaphor--A Key to Extensible Semantic Analysis. The 18th Annual Meeting of the Association for Computational Linguistics, Philadelphia, Pennsylvania, June 1980. 6. Cohen, P. 1978. On knowing what to say: planning speech acts. Technical Report No. 118, Department of Computer Science, University of Toronto. January 1978. 7. Grosz, B. J., 1978. Focusing in Dialog. Proceedings of TINLAP-2, Urbana, Illinois, 24-26 July, 1978. 8. L. R. Harris, 1977. User Oriented Data Base Query with the ROBOT Natural Language Query System. Proc. Third International Conference on Very Large Data Bases, Tokyo (October 1977). 9. G. G. Hendrix, E. D. Sacerdoti, D. Sagalowicz, and J. Slocum, 1978. Developing a Natural Language Interface to Complex Data. ACM Transactions on Database Systems, Vol. 3, No. 2 (June 1978). 10. Hobbs, J. 1979. Coherence and coreference. Cognitive Science. Vol. 3, No. 1, 67-90. 11. Hobbs, J. 1980. Selective inferencing. Third National Conference of Canadian Society for Computational Studies of Intelligence. Victoria, British Columbia. May 1980. 12. Landsbergen, S. P. J., 1976. Syntax and Formal Semantics of English in PHLIQA1. In Coling 76, Preprints of the 6th International Conference on Computational Linguistics, Ottawa, Ontario, Canada, 28 June - 2 July 1976. No. 21. 13. Lewis, w. H., and Hendrix, G. G., 1979. Machine Intelligence: Research and Applications -- First Semiannual Report. SRI International, Menlo Park, California, October 8, 1979. 14. Mann, W., J. Moore, &amp; J. Levin 1977. A comprehension model for human dialogue. Proceedings, International Joint Conference on Artificial Intelligence, 77-87, Cambridge, Mass. August 1977. 15. Novak, G. 1977. Representations of knowledge in a program for solving physics problems. Proceedings, International Joint Conference on Artificial Intelligence, 286-291, Cambridge, Mass. August 1977. 16. Petrick, S. R. 1978. Automatic Syntactic and Semantic Analysis. In Proceedings of the Interdsciplainary Conference on Automated Text Processing (Bielefeld, German Federal Republic, 8- November 1976). Edited by J. Petofi Allen. Reidel, Dordrecht, Holland. 17. Reddy, D. R., et al. 1977. Speech Understanding Systems: A Summary of Results of the Five-Year Research Effort. Department of Computer Science.</note>
<affiliation confidence="0.87699">Carnegie-Mellon University, Pittsburgh,</affiliation>
<address confidence="0.851386">Pennsylvania, August, 1977.</address>
<degree confidence="0.562231666666667">18. Rieger, C. 1975. Conceptual Overlays: A Mechanism for the Interpretation of Sentence Meaning in Context. Technical Report 7R-354. Computer Science</degree>
<affiliation confidence="0.866052">Department, University of Maryland, College Park,</affiliation>
<address confidence="0.447522">Maryland. February 1975.</address>
<note confidence="0.8355884">19. Robinson, Ann E. The Interpretation of Verb Phrases in Dialogues. Technical Note 206, Artificial Intelligence Center, SRI International, Menlo Park, Ca., January 1980. 20. Sager, N. and R. Grishman. 1975. The Restriction Language for Computer Grammars. Communications of the ACM, 1975, 18, 390-400. 21. Schenk, R. C., and Yale A.I. 1975. SAM--A Story Understander. Yale University, Department of Computer Science Research Report. 22. Schank, R. and R. Abelson. 1977. Scripts, plans, goals, and understanding. Hillsdale N.J.: Laurence Erlbaum Associates. 23. Searle, J. 1969. Speech acts: An essay in the philosophy of language. Cambridge, England: Cambridge University Press. 24. Searle, J 1975. Indirect speech acts. In P. Cole and J. Morgan (Eds.), Syntax and semantics, Vol. 3, 59-82. New York: Academic Press. 25. Sidner, C. L. 1979. A Computational Model of Co-</note>
<affiliation confidence="0.9692655">Reference Comprehension in English. Ph.D. Thesis, Massachusetts Institute of Technology, Cambridge,</affiliation>
<address confidence="0.909574">Massachusetts.</address>
<note confidence="0.952719619047619">26. F. B. Thompson and B. H. Thompson, 1975. Practical Natural Language Processing: The REL System as Prototype. In M. Rubinoff and M. C. Yovits, eds., Advances in Computers 13 (Academic Press, New York, 1975). 27. H. Tennant, &amp;quot;Experience with the Evaluation of Natural Language Question Answerers,&amp;quot; &amp;Proc. Sixth International Joint Conference on Artificial Intelligened, Tokyo, Japan (August 1979). 28. Wilensky, R. 1978. &amp;quot;Understanding Goal-Based Stories.&amp;quot; Yale University, New Haven, Connecticut. Ph.D. Thesis. 29. D. Waltz, &amp;quot;Natural Language Access to a Large Data Base: an Engineering Approach,&amp;quot; Proc. 4th Internatioal Joint Conference on Artificial Intelligence, Tbilisi, USSR, pp. 868-872 (September 1975). 30. Woods, W. A., et al. 1976. Speech Understanding Systems: Final Report. BBB Report No. 3438, Bolt Beranek and Newman, Cambridge, Massachusetts. 135</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Allen</author>
<author>J</author>
<author>C Perrault</author>
</authors>
<title>Participating in Dialogues: Understanding via plan deduction.</title>
<date>1978</date>
<booktitle>Proceedings, Second National Conference, Canadian Society for Computational Studies of Intelligence,</booktitle>
<location>Toronto, Canada.</location>
<marker>Allen, J, Perrault, 1978</marker>
<rawString> I. Allen, J. &amp; C. Perrault. 1978. Participating in Dialogues: Understanding via plan deduction. Proceedings, Second National Conference, Canadian Society for Computational Studies of Intelligence, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Berwick</author>
</authors>
<title>Computational Analogues of Constraints on Grammars: A Model of Syntactic Acquisition.</title>
<date>1980</date>
<booktitle>The 18th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Philadelphia, Pennsylvania,</location>
<contexts>
<context position="16149" citStr="[2]" startWordPosition="2466" endWordPosition="2466">equire better means of communicating their knowledge. More importantly, for a system to carry on a reasonable dialogue with a user, it must not only interpret inputs but also respond appropriately in context, generating responses that are custom tailored to the (assumed) needs and mental state of the user. Hopefully, much of the same research that is needed on planning and reasoning to move beyond literal content in interpretation will provide a basis for sophisticated generation. Acquisition: Another generally neglected area, at least computationally, is that of language acquisition. Berwick [2] has made an interesting start in this area with his work on the acquisition of grammar rules. Equally important is work on acquisition of new vocabulary, either through reasoning by analogy [5] or simply by being told new words [13]. Because language acquisition (particularly vocabulary acquisition) is essential for moving natural-language systems to new domains, I believe considerable resources are likely to be devoted to this problem and that therefore rapid progress will ensue. Information Science: One of the greatest resources of our society is the wealth of knowledge recorded in natural-</context>
</contexts>
<marker>2.</marker>
<rawString>Berwick, R. C., 1980. Computational Analogues of Constraints on Grammars: A Model of Syntactic Acquisition. The 18th Annual Meeting of the Association for Computational Linguistics, Philadelphia, Pennsylvania, June 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
</authors>
<date>1977</date>
<journal>GUS, A Frame Driven Dialog System. Artificial Intelligence,</journal>
<volume>8</volume>
<pages>155</pages>
<contexts>
<context position="12062" citStr="[3]" startWordPosition="1842" endWordPosition="1842">t to consider an utterance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of</context>
</contexts>
<marker>3.</marker>
<rawString>Bobrow, D. G., et al. 1977. GUS, A Frame Driven Dialog System. Artificial Intelligence, 8, 155-</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Carbonell</author>
</authors>
<title>Computer Models of Social and Political Reasoning.</title>
<date>1978</date>
<tech>Ph.D. Thesis,</tech>
<institution>Yale University,</institution>
<location>New Haven, Connecticut.</location>
<contexts>
<context position="12881" citStr="[4]" startWordPosition="1976" endWordPosition="1976">h context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach the smooth integration of language-specific and general reasoning capabilities required for fluent communic</context>
</contexts>
<marker>4.</marker>
<rawString>Carbonell, J. G. 1978. Computer Models of Social and Political Reasoning. Ph.D. Thesis, Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Carbonell</author>
</authors>
<title>Metaphor--A Key to Extensible Semantic Analysis.</title>
<date>1980</date>
<booktitle>The 18th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Philadelphia, Pennsylvania,</location>
<contexts>
<context position="16343" citStr="[5]" startWordPosition="2498" endWordPosition="2498">ly in context, generating responses that are custom tailored to the (assumed) needs and mental state of the user. Hopefully, much of the same research that is needed on planning and reasoning to move beyond literal content in interpretation will provide a basis for sophisticated generation. Acquisition: Another generally neglected area, at least computationally, is that of language acquisition. Berwick [2] has made an interesting start in this area with his work on the acquisition of grammar rules. Equally important is work on acquisition of new vocabulary, either through reasoning by analogy [5] or simply by being told new words [13]. Because language acquisition (particularly vocabulary acquisition) is essential for moving natural-language systems to new domains, I believe considerable resources are likely to be devoted to this problem and that therefore rapid progress will ensue. Information Science: One of the greatest resources of our society is the wealth of knowledge recorded in natural-language texts; but there are major obstacles to placing relevant texts in the hands of those who need them. Even when texts are made available in machine-readable form, documents relevant to th</context>
</contexts>
<marker>5.</marker>
<rawString>Carbonell, J. G. 1980. Metaphor--A Key to Extensible Semantic Analysis. The 18th Annual Meeting of the Association for Computational Linguistics, Philadelphia, Pennsylvania, June</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cohen</author>
</authors>
<title>On knowing what to say: planning speech acts.</title>
<date>1978</date>
<tech>Technical Report No. 118,</tech>
<institution>Department of Computer Science, University of Toronto.</institution>
<contexts>
<context position="12920" citStr="[6]" startWordPosition="1983" endWordPosition="1983"> [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach the smooth integration of language-specific and general reasoning capabilities required for fluent communication in natural language. 2. Some Pred</context>
</contexts>
<marker>6.</marker>
<rawString>Cohen, P. 1978. On knowing what to say: planning speech acts. Technical Report No. 118, Department of Computer Science, University of Toronto. January 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
</authors>
<title>Focusing in Dialog.</title>
<date>1978</date>
<booktitle>Proceedings of TINLAP-2,</booktitle>
<location>Urbana, Illinois,</location>
<contexts>
<context position="12307" citStr="[7]" startWordPosition="1886" endWordPosition="1886">communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] </context>
<context position="20782" citStr="[7]" startWordPosition="3169" endWordPosition="3169">tly, conventional database management systems (DBMSs) are the only systems in widespread use for storing symbolic information. The Al community, of course, has a number of methods for maintaining more sophisticated knowledge bases of, say, formulas in first-order logic. But their complexity and requirements for great amounts of computer resources (both memory and time) have prevented any such systems from becoming a commercially viable alternative to standard DBMSs. I believe that systems that maintain mooels of the ongoing dialogue and the changing physical context (as in, for example, Grosz [7] and Robinson [19]) or that reason about the mental states of users will eventually. become important in practical applications. But the computational requirements for such systems are so much greater than those of current applied systems that they will have little commercial viability for some time. Fortunately, the linguistic coverage of several current systems appears to be adequate for many practical purposes, so commercialization need not wait for more advanced techniques to be transferred. On the other hand, applied systems currently are only barely up to their tasks, and therefore there</context>
</contexts>
<marker>7.</marker>
<rawString>Grosz, B. J., 1978. Focusing in Dialog. Proceedings of TINLAP-2, Urbana, Illinois, 24-26 July, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Harris</author>
</authors>
<title>User Oriented Data Base Query with the ROBOT Natural Language Query System.</title>
<date>1977</date>
<booktitle>Proc. Third International Conference on Very Large Data Bases,</booktitle>
<location>Tokyo</location>
<contexts>
<context position="1207" citStr="[8]" startWordPosition="172" endWordPosition="172">a computational theory of natural-language communication and to further the engineering goals of creating computer-based systems that can communicate with their:. human users in human terms. Although the goal of fluent machine-based neutral-language understanding remains elusive, considerable progress has been made and future prospects appear bright both for the advancement of the science and for its application to the creation of practical systems. In particular, after 20 years of nurture in the academic nest, natural-language processing is beginning to test its wings in the commercial world [8]. By the end of the decade, natural-language systems are likely to be in widespread use, bringing computer resources to large numbers of non-computer specialists and bringing new credibility (and hopefully new levels of funding) to the research community. B. Basis for Optimism My optimism is based on an extrapolation of three major trends currently affecting the field: (1) The emergence of an engineering/applications discipline within the computationallinguistics community. (2) The continuing rapid development of new computing hardware coupled with the beginning of a movement from time-sharing</context>
<context position="4978" citStr="[8]" startWordPosition="766" endWordPosition="766">ietary barriers being established between research groups. The net effect in the short term might actually be to retard scientific progress. D. The State of Applied Work 1. Accessing Databases Currently, the most commercially viable task for natural-language processing is that of providing access to databases. This is because databases are among the few types of symbolic knowledge representations that are computationally efficient, are in widespread use, and have a semantics that is well understood. In the last few years, several systems, including LADDER [9], PLANES [29], REL [26j, and ROBOT [8], have achieved relatively high levels of proficiency in this area when applied to particular databases. ROBOT has been introduced as a commercial product that runs on large, mainframe computers. A pilot REL product is currently under development that will run on a relatively large personal machine, the HP 9845. This system, or something very much like it, seems likely to reach the marketplace within the next two or three years. Should ROBOT- and REL-like systems prove to be commercial successes, other systems with increasing levels of sophistication are sure to follow. 2. Immediate Problems A</context>
</contexts>
<marker>8.</marker>
<rawString>L. R. Harris, 1977. User Oriented Data Base Query with the ROBOT Natural Language Query System. Proc. Third International Conference on Very Large Data Bases, Tokyo (October 1977).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G Hendrix</author>
<author>E D Sacerdoti</author>
<author>D Sagalowicz</author>
<author>J Slocum</author>
</authors>
<title>Developing a Natural Language Interface to Complex Data.</title>
<date>1978</date>
<journal>ACM Transactions on Database Systems,</journal>
<volume>3</volume>
<contexts>
<context position="4940" citStr="[9]" startWordPosition="759" endWordPosition="759">nguists, it would also result in proprietary barriers being established between research groups. The net effect in the short term might actually be to retard scientific progress. D. The State of Applied Work 1. Accessing Databases Currently, the most commercially viable task for natural-language processing is that of providing access to databases. This is because databases are among the few types of symbolic knowledge representations that are computationally efficient, are in widespread use, and have a semantics that is well understood. In the last few years, several systems, including LADDER [9], PLANES [29], REL [26j, and ROBOT [8], have achieved relatively high levels of proficiency in this area when applied to particular databases. ROBOT has been introduced as a commercial product that runs on large, mainframe computers. A pilot REL product is currently under development that will run on a relatively large personal machine, the HP 9845. This system, or something very much like it, seems likely to reach the marketplace within the next two or three years. Should ROBOT- and REL-like systems prove to be commercial successes, other systems with increasing levels of sophistication are s</context>
</contexts>
<marker>9.</marker>
<rawString>G. G. Hendrix, E. D. Sacerdoti, D. Sagalowicz, and J. Slocum, 1978. Developing a Natural Language Interface to Complex Data. ACM Transactions on Database Systems, Vol. 3, No. 2 (June 1978).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Coherence and coreference.</title>
<date>1979</date>
<journal>Cognitive Science.</journal>
<volume>3</volume>
<pages>67--90</pages>
<contexts>
<context position="12312" citStr="[10]" startWordPosition="1887" endWordPosition="1887">unicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and C</context>
</contexts>
<marker>10.</marker>
<rawString>Hobbs, J. 1979. Coherence and coreference. Cognitive Science. Vol. 3, No. 1, 67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Selective inferencing.</title>
<date>1980</date>
<booktitle>Third National Conference of Canadian Society for Computational Studies of Intelligence.</booktitle>
<location>Victoria, British Columbia.</location>
<contexts>
<context position="14110" citStr="[11]" startWordPosition="2164" endWordPosition="2164">. 2. Some Predictions Basic research provides a leading indicator with which to predict new directions in applied science and engineering; but I know of no leading indicator for basic research itself. About the best we can do is to consider the current state of the art, seek to identify central problems, and predict that those problems will be the ones receiving the most attention. The view of language use as an activity of the total intellect makes it clear that advances in computational linguistics will be closely tied to advances in research on general-purpose common-sense reasoning. Hobbs [11], for example, has argued that 10 seemingly different and fundamental problems of computational linguistics may all be reduced to problems of common-sense deduction, and Cohen&apos;s work clearly ties language to planning. The problems of planning and reasoning are, of course, central problems for the whole of Al. But computational linguistics brings to these problems its own special requirements, such as the need to consider the beliefs, goals, and possible actions of multiple agents, and the need to precipitate the achievement of multiple goals through the performance of actions with multiple-fac</context>
</contexts>
<marker>11.</marker>
<rawString>Hobbs, J. 1980. Selective inferencing. Third National Conference of Canadian Society for Computational Studies of Intelligence. Victoria, British Columbia. May 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P J Landsbergen</author>
</authors>
<title>Syntax and Formal Semantics of English in PHLIQA1.</title>
<date>1976</date>
<booktitle>In Coling 76, Preprints of the 6th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<location>Ottawa, Ontario,</location>
<contexts>
<context position="12067" citStr="[12]" startWordPosition="1843" endWordPosition="1843"> consider an utterance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the </context>
</contexts>
<marker>12.</marker>
<rawString>Landsbergen, S. P. J., 1976. Syntax and Formal Semantics of English in PHLIQA1. In Coling 76, Preprints of the 6th International Conference on Computational Linguistics, Ottawa, Ontario, Canada, 28 June - 2 July 1976. No. 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>w H Lewis</author>
<author>G G Hendrix</author>
</authors>
<date>1979</date>
<booktitle>Machine Intelligence: Research and Applications -- First Semiannual Report. SRI International,</booktitle>
<location>Menlo Park, California,</location>
<contexts>
<context position="7345" citStr="[13]" startWordPosition="1126" endWordPosition="1126"> computed from the existing data. In general, any system thatis to be widely accepted by users must not only provide access to database information, but must also enhance that primary information by providing procedures that calculate secondary attributes from the data actually stored. Data enhancement procedures are currently provided by LADDER and a few other hand-built systems. But work is needed to devise means for allowing system users to specify their own database enhancement functions and to couple their functions with the natural-language component. Efforts are now underway (e.g. [26] [13]) to simplify the task of acquiring and coding the knowledge needed to transport high-performance systems from one database to another. It appears likely that soon much of this task can be automated or performed by a database administrator, rather than by a computational linguist. When this is achieved, natural-language access to data is likely to move rapidly into widespread use. E. New Hardware VLSI (Very Large Scale Integration of computer circuits on single chips) is revolutionizing the computer industry. Within the last year, new personal computer systems have been announced that, at rela</context>
<context position="16382" citStr="[13]" startWordPosition="2506" endWordPosition="2506">at are custom tailored to the (assumed) needs and mental state of the user. Hopefully, much of the same research that is needed on planning and reasoning to move beyond literal content in interpretation will provide a basis for sophisticated generation. Acquisition: Another generally neglected area, at least computationally, is that of language acquisition. Berwick [2] has made an interesting start in this area with his work on the acquisition of grammar rules. Equally important is work on acquisition of new vocabulary, either through reasoning by analogy [5] or simply by being told new words [13]. Because language acquisition (particularly vocabulary acquisition) is essential for moving natural-language systems to new domains, I believe considerable resources are likely to be devoted to this problem and that therefore rapid progress will ensue. Information Science: One of the greatest resources of our society is the wealth of knowledge recorded in natural-language texts; but there are major obstacles to placing relevant texts in the hands of those who need them. Even when texts are made available in machine-readable form, documents relevant to the solution of particular problems are n</context>
</contexts>
<marker>13.</marker>
<rawString>Lewis, w. H., and Hendrix, G. G., 1979. Machine Intelligence: Research and Applications -- First Semiannual Report. SRI International, Menlo Park, California, October 8, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>J Moore</author>
<author>J Levin</author>
</authors>
<title>A comprehension model for human dialogue.</title>
<date>1977</date>
<booktitle>Proceedings, International Joint Conference on Artificial Intelligence,</booktitle>
<pages>77--87</pages>
<location>Cambridge, Mass.</location>
<contexts>
<context position="12322" citStr="[14]" startWordPosition="1889" endWordPosition="1889">some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] h</context>
</contexts>
<marker>14.</marker>
<rawString>Mann, W., J. Moore, &amp; J. Levin 1977. A comprehension model for human dialogue. Proceedings, International Joint Conference on Artificial Intelligence, 77-87, Cambridge, Mass. August 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Novak</author>
</authors>
<title>Representations of knowledge in a program for solving physics problems.</title>
<date>1977</date>
<booktitle>Proceedings, International Joint Conference on Artificial Intelligence,</booktitle>
<pages>286--291</pages>
<location>Cambridge, Mass.</location>
<contexts>
<context position="12150" citStr="[15]" startWordPosition="1857" endWordPosition="1857">multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these lim</context>
</contexts>
<marker>15.</marker>
<rawString>Novak, G. 1977. Representations of knowledge in a program for solving physics problems. Proceedings, International Joint Conference on Artificial Intelligence, 286-291, Cambridge, Mass. August</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Petrick</author>
</authors>
<title>Automatic Syntactic and Semantic Analysis.</title>
<date>1978</date>
<booktitle>In Proceedings of the Interdsciplainary Conference on Automated Text Processing</booktitle>
<location>Bielefeld, German Federal Republic,</location>
<note>Edited by</note>
<contexts>
<context position="12077" citStr="[16]" startWordPosition="1845" endWordPosition="1845">an utterance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) ar</context>
</contexts>
<marker>16.</marker>
<rawString>Petrick, S. R. 1978. Automatic Syntactic and Semantic Analysis. In Proceedings of the Interdsciplainary Conference on Automated Text Processing (Bielefeld, German Federal Republic, 8-12 November 1976). Edited by J. Petofi and S. Allen. Reidel, Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Reddy</author>
</authors>
<title>Speech Understanding Systems: A Summary of Results of the Five-Year Research Effort.</title>
<date>1977</date>
<institution>Department of Computer Science. Carnegie-Mellon University,</institution>
<location>Pittsburgh, Pennsylvania,</location>
<marker>17.</marker>
<rawString>Reddy, D. R., et al. 1977. Speech Understanding Systems: A Summary of Results of the Five-Year Research Effort. Department of Computer Science. Carnegie-Mellon University, Pittsburgh, Pennsylvania, August, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
</authors>
<title>Conceptual Overlays: A Mechanism for the Interpretation of Sentence Meaning in Context.</title>
<date>1975</date>
<tech>Technical Report 7R-354.</tech>
<institution>Computer Science Department, University of Maryland, College Park,</institution>
<location>Maryland.</location>
<contexts>
<context position="12317" citStr="[18]" startWordPosition="1888" endWordPosition="1888">ting some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen </context>
</contexts>
<marker>18.</marker>
<rawString>Rieger, C. 1975. Conceptual Overlays: A Mechanism for the Interpretation of Sentence Meaning in Context. Technical Report 7R-354. Computer Science Department, University of Maryland, College Park, Maryland. February 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann E Robinson</author>
</authors>
<title>The Interpretation of Verb Phrases in Dialogues.</title>
<date>1980</date>
<booktitle>Technical Note 206, Artificial Intelligence Center, SRI International,</booktitle>
<location>Menlo Park, Ca.,</location>
<contexts>
<context position="12155" citStr="[19]" startWordPosition="1858" endWordPosition="1858">ple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitati</context>
<context position="20800" citStr="[19]" startWordPosition="3172" endWordPosition="3172"> database management systems (DBMSs) are the only systems in widespread use for storing symbolic information. The Al community, of course, has a number of methods for maintaining more sophisticated knowledge bases of, say, formulas in first-order logic. But their complexity and requirements for great amounts of computer resources (both memory and time) have prevented any such systems from becoming a commercially viable alternative to standard DBMSs. I believe that systems that maintain mooels of the ongoing dialogue and the changing physical context (as in, for example, Grosz [7] and Robinson [19]) or that reason about the mental states of users will eventually. become important in practical applications. But the computational requirements for such systems are so much greater than those of current applied systems that they will have little commercial viability for some time. Fortunately, the linguistic coverage of several current systems appears to be adequate for many practical purposes, so commercialization need not wait for more advanced techniques to be transferred. On the other hand, applied systems currently are only barely up to their tasks, and therefore there is a need for an </context>
</contexts>
<marker>19.</marker>
<rawString>Robinson, Ann E. The Interpretation of Verb Phrases in Dialogues. Technical Note 206, Artificial Intelligence Center, SRI International, Menlo Park, Ca., January 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sager</author>
<author>R Grishman</author>
</authors>
<title>The Restriction Language for Computer Grammars.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<pages>390--400</pages>
<contexts>
<context position="12072" citStr="[20]" startWordPosition="1844" endWordPosition="1844">ider an utterance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the syste</context>
</contexts>
<marker>20.</marker>
<rawString>Sager, N. and R. Grishman. 1975. The Restriction Language for Computer Grammars. Communications of the ACM, 1975, 18, 390-400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schenk</author>
<author>A I Yale</author>
</authors>
<date>1975</date>
<institution>SAM--A Story Understander. Yale University, Department of Computer Science Research Report.</institution>
<contexts>
<context position="12145" citStr="[21]" startWordPosition="1856" endWordPosition="1856">rves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of thes</context>
</contexts>
<marker>21.</marker>
<rawString>Schenk, R. C., and Yale A.I. 1975. SAM--A Story Understander. Yale University, Department of Computer Science Research Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>R Abelson</author>
</authors>
<title>Scripts, plans, goals, and understanding. Hillsdale N.J.: Laurence Erlbaum Associates.</title>
<date>1977</date>
<contexts>
<context position="12877" citStr="[22]" startWordPosition="1975" endWordPosition="1975"> which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach the smooth integration of language-specific and general reasoning capabilities required for fluent comm</context>
</contexts>
<marker>22.</marker>
<rawString>Schank, R. and R. Abelson. 1977. Scripts, plans, goals, and understanding. Hillsdale N.J.: Laurence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Speech acts: An essay in the philosophy of language. Cambridge, England:</title>
<date>1969</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="13165" citStr="[23]" startWordPosition="2023" endWordPosition="2023">d to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach the smooth integration of language-specific and general reasoning capabilities required for fluent communication in natural language. 2. Some Predictions Basic research provides a leading indicator with which to predict new directions in applied science and engineering; but I know of no leading indicator for basic research itself. About the best we can do is to consider the current state </context>
</contexts>
<marker>23.</marker>
<rawString>Searle, J. 1969. Speech acts: An essay in the philosophy of language. Cambridge, England: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Indirect speech acts. In</title>
<date>1975</date>
<volume>3</volume>
<pages>59--82</pages>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<marker>24.</marker>
<rawString>Searle, J 1975. Indirect speech acts. In P. Cole and J. Morgan (Eds.), Syntax and semantics, Vol. 3, 59-82. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>A Computational Model of CoReference Comprehension in English.</title>
<date>1979</date>
<tech>Ph.D. Thesis,</tech>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="12160" citStr="[25]" startWordPosition="1859" endWordPosition="1859">urposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. </context>
</contexts>
<marker>25.</marker>
<rawString>Sidner, C. L. 1979. A Computational Model of CoReference Comprehension in English. Ph.D. Thesis, Massachusetts Institute of Technology, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F B Thompson</author>
<author>B H Thompson</author>
</authors>
<title>Practical Natural Language Processing: The REL System as Prototype.</title>
<date>1975</date>
<booktitle>Advances in Computers 13</booktitle>
<editor>In M. Rubinoff and M. C. Yovits, eds.,</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="7340" citStr="[26]" startWordPosition="1125" endWordPosition="1125">asily computed from the existing data. In general, any system thatis to be widely accepted by users must not only provide access to database information, but must also enhance that primary information by providing procedures that calculate secondary attributes from the data actually stored. Data enhancement procedures are currently provided by LADDER and a few other hand-built systems. But work is needed to devise means for allowing system users to specify their own database enhancement functions and to couple their functions with the natural-language component. Efforts are now underway (e.g. [26] [13]) to simplify the task of acquiring and coding the knowledge needed to transport high-performance systems from one database to another. It appears likely that soon much of this task can be automated or performed by a database administrator, rather than by a computational linguist. When this is achieved, natural-language access to data is likely to move rapidly into widespread use. E. New Hardware VLSI (Very Large Scale Integration of computer circuits on single chips) is revolutionizing the computer industry. Within the last year, new personal computer systems have been announced that, at</context>
</contexts>
<marker>26.</marker>
<rawString>F. B. Thompson and B. H. Thompson, 1975. Practical Natural Language Processing: The REL System as Prototype. In M. Rubinoff and M. C. Yovits, eds., Advances in Computers 13 (Academic Press, New York, 1975).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tennant</author>
</authors>
<title>Experience with the Evaluation of Natural Language Question Answerers,&amp;quot;</title>
<date>1979</date>
<booktitle>Proc. Sixth International Joint Conference on Artificial Intelligened,</booktitle>
<location>Tokyo, Japan</location>
<contexts>
<context position="6353" citStr="[27]" startWordPosition="974" endWordPosition="974">nguistic constructions associated with new databases. The most proficient of the application systems have been hand-tailored with extensive knowledge for accessing just ONE database. Some systems (e.g., ROBOT and REL) have achieved a 131 degree of transportability by using the database itself as a source of knowledge for guiding linguistic processes. However, the knowledge available in the database is generally rather limited. High-performance systems need access to information about the larger enterprise that provides the context in which the database is to be used. As pointed out by Tennant [27], users who are given natural-language access to a database expect not only to retrieve information directly stored there, but also to compute &amp;quot;reasonable&amp;quot; derivative information. For example, if a database has the location of two ships, users will expect the system to be able to provide the distance between them--an item of information not directly recorded in the database, but easily computed from the existing data. In general, any system thatis to be widely accepted by users must not only provide access to database information, but must also enhance that primary information by providing pro</context>
</contexts>
<marker>27.</marker>
<rawString>H. Tennant, &amp;quot;Experience with the Evaluation of Natural Language Question Answerers,&amp;quot; &amp;Proc. Sixth International Joint Conference on Artificial Intelligened, Tokyo, Japan (August 1979).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Understanding Goal-Based Stories.&amp;quot;</title>
<date>1978</date>
<tech>Ph.D. Thesis.</tech>
<institution>Yale University,</institution>
<location>New Haven, Connecticut.</location>
<contexts>
<context position="12773" citStr="[28]" startWordPosition="1957" endWordPosition="1957">e at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ignored. Initial progress has been made in overcoming some of these limitations. Wilensky [28] has investigated the use of goals and plans in a computer system that interprets stories (see also [22] [4]). Allen and Perrault [1] and Cohen [6] have examined the interaction between beliefs and plans in task-oriented dialogues and have implemented a system that uses 132 information about what its &amp;quot;hearer&amp;quot; knows in order to plan and to recognize a limited set of speech acts (Searle [23] [24j). These efforts have demonstrated the viability of incorporating planning capabilities in a natural-language processing system, but more robust reasoning and planning capabilities are needed to approach</context>
</contexts>
<marker>28.</marker>
<rawString>Wilensky, R. 1978. &amp;quot;Understanding Goal-Based Stories.&amp;quot; Yale University, New Haven, Connecticut. Ph.D. Thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Waltz</author>
</authors>
<title>Natural Language Access to a Large Data Base: an Engineering Approach,&amp;quot;</title>
<date>1975</date>
<booktitle>Proc. 4th Internatioal Joint Conference on Artificial Intelligence,</booktitle>
<pages>868--872</pages>
<location>Tbilisi, USSR,</location>
<contexts>
<context position="4953" citStr="[29]" startWordPosition="761" endWordPosition="761">would also result in proprietary barriers being established between research groups. The net effect in the short term might actually be to retard scientific progress. D. The State of Applied Work 1. Accessing Databases Currently, the most commercially viable task for natural-language processing is that of providing access to databases. This is because databases are among the few types of symbolic knowledge representations that are computationally efficient, are in widespread use, and have a semantics that is well understood. In the last few years, several systems, including LADDER [9], PLANES [29], REL [26j, and ROBOT [8], have achieved relatively high levels of proficiency in this area when applied to particular databases. ROBOT has been introduced as a commercial product that runs on large, mainframe computers. A pilot REL product is currently under development that will run on a relatively large personal machine, the HP 9845. This system, or something very much like it, seems likely to reach the marketplace within the next two or three years. Should ROBOT- and REL-like systems prove to be commercial successes, other systems with increasing levels of sophistication are sure to follow</context>
</contexts>
<marker>29.</marker>
<rawString>D. Waltz, &amp;quot;Natural Language Access to a Large Data Base: an Engineering Approach,&amp;quot; Proc. 4th Internatioal Joint Conference on Artificial Intelligence, Tbilisi, USSR, pp. 868-872 (September 1975).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Speech Understanding Systems: Final Report.</title>
<date>1976</date>
<tech>BBB Report No. 3438,</tech>
<institution>Bolt Beranek and Newman,</institution>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="12082" citStr="[30]" startWordPosition="1846" endWordPosition="1846">terance as being addressed to a single purpose; typically it serves multiple purposes: it highlights certain objects and relationships, conveys an attitude toward them, and provides links to previous utterances in addition to communicating some propositional content. An examination of the current state of the art in natural-language processing systems reveals several deficiencies in the combination and coordination of language-specific and general-purpose reasoning capabilities. Although there are some systems that coordinate different kinds of languagespecific capabilities [3] [12] [20] [16] [30] L17J, and some that reason about limited action scenarios [21] [15] [19] [25] to arrive at an interpretation of what has been said, and others that attempt to account for some of the ways in which context affects meaning [7] [10] [18] [14], one or more of the following crucial limitations is evident in every naturallanguage processing system constructed to date: Interpretation is literal (only propositional content is determined). The user&apos;s knowledge and beliefs are assumed to be id.ntical with the system&apos;s. The user&apos;s plans and goals (especially as distinct from those of the system) are ign</context>
</contexts>
<marker>30.</marker>
<rawString>Woods, W. A., et al. 1976. Speech Understanding Systems: Final Report. BBB Report No. 3438, Bolt Beranek and Newman, Cambridge, Massachusetts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>