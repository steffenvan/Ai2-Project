<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.820677">
<title confidence="0.967378">
Language, Embodiment and Social Intelligence
</title>
<author confidence="0.995048">
Matthew Stone
</author>
<affiliation confidence="0.9790385">
Computer Science and Cognitive Science
Rutgers, The State University of New Jersey
</affiliation>
<address confidence="0.989701">
110 Frelinghuysen Road, Piscataway NJ 08854-8019
</address>
<email confidence="0.997999">
Matthew.Stone@Rutgers.EDU
</email>
<sectionHeader confidence="0.995528" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999556833333333">
It is an honor to have this chance to tie together
themes from my recent research, and to sketch
some challenges and opportunities for NLG in
face-to-face conversational interaction.
Communication reflects our general involvement
in one anothers’ lives. Through the choices we man-
ifest with one another, we share our thoughts and
feelings, strengthen our relationships and further our
joint projects. We rely not only on words to artic-
ulate our perspectives, but also on a heterogeneous
array of accompanying efforts: embodied deixis, ex-
pressive movement, presentation of iconic imagery
and instrumental action in the world. Words show-
case the distinctive linguistic knowledge which hu-
man communication exploits. But people’s diverse
choices in conversation in fact come together to re-
veal multifaceted, interrelated meanings, in which
all our actions, verbal and nonverbal, fit the situation
and further social purposes. In the best case, they let
interlocutors understand not just each other’s words,
but each other.
As NLG researchers, I argue, we have good rea-
son to work towards models of social cognition that
embrace the breadth of conversation. Scientifically,
it connects us to an emerging consensus in favor of
a general human pragmatic competence, rooted in
capacities for engagement, coordination, shared in-
tentionality and extended relationships. Technically,
it lets us position ourselves as part of an emerging
revolution in integrative Artificial Intelligence, char-
acterized by research challenges like human–robot
interaction and the design of virtual humans, and
applications in assistive and educational technology
and interactive entertainment.
Researchers are already hard at work to place our
accounts of embodied action in conversation in con-
tact with pragmatic theories derived from text dis-
course and spoken dialogue. In my own experi-
ence, such work proves both illuminating and ex-
citing. For example, it challenges us to support and
refine theories of discourse coherence by accounting
for the discourse relations and default inference that
determine the joint interpretation of coverbal gesture
and its accompanying speech (Lascarides and Stone,
2008). And it challenges us to show how speak-
ers work across modalities to engage with, disam-
biguate, and (on acceptance) recapitulate each oth-
ers’ communicative actions, to ground their mean-
ings (Lascarides and Stone, In Preparation). The
closer we look at conversation, the more we can fit
all its behaviors into a unitary framework—inviting
us to implement behavioral control for embodied so-
cial agents through a pervasive analogy to NLG.
We can already pursue such implementations eas-
ily. Computationally, motion is just sequence data,
and we can manipulate it in parallel ways to the
speech data we already use in spoken language gen-
eration (Stone et al., 2004). At a higher level, we
can represent an embodied performance through a
matrix of discrete actions selected and synchronized
to an abstract time-line, as in our RUTH system (De-
Carlo et al., 2004; Stone and Oh, 2008). This lets us
use any NLG method that manipulates structured se-
lections of discrete actions as an architecture for the
production of embodied behavior. Templates, as in
(Stone and DeCarlo, 2003; Stone et al., 2004), offer
</bodyText>
<page confidence="0.965711">
5
</page>
<bodyText confidence="0.999480153846154">
a good illustration.
Nevertheless, face-to-face dialogue does demand
qualitatively new capabilities. In fact, people’s
choices and meanings in interactive conversation are
profoundly informed by their social settings. We
are a long way from general models that could al-
low NLG systems to recognize and exploit these
connections in the words and other behaviors they
use. In my experience, even the simplest social prac-
tices, such as interlocutors’ cooperation on an on-
going practical task, require new models of linguis-
tic meaning and discourse context. For example,
systems must be creative to evoke the distinctions
that matter for their ongoing task, and use mean-
ings that are not programmed or learned but invented
on the fly (DeVault and Stone, 2004). They must
count on their interlocutors to recognize the back-
ground knowledge they presuppose by general infer-
ence from the logic of their behavior as a coopera-
tive contribution to the task (Thomason et al., 2006).
Such reasoning becomes particularly important in
problematic cases, such as when systems must fine-
tune the form and meaning of a clarification request
so that the response is more likely to resolve a pend-
ing task ambiguity (DeVault and Stone, 2007). I ex-
pect many further exciting developments in our un-
derstanding of meaning and interpretation as we en-
rich the social intelligence of NLG.
Modeling efforts will remain crucial to the explo-
ration of these new capabilities. When we build and
assemble models of actions and interpretations, we
get systems that can plan their own behavior simply
by exploiting what they know about communication.
These systems give new evidence about the informa-
tion and problem-solving that’s involved. The chal-
lenge is that these models must describe semantics
and pragmatics, as well as syntax and behavior. My
own slow progress (Cassell et al., 2000; Stone et al.,
2003; Koller and Stone, 2007) shows that there’s
still lots of hard work needed to develop suitable
techniques. I keep going because of the method-
ological payoffs I see on the horizon. Modeling lets
us take social intelligence seriously as a general im-
plementation principle, and thus to aim for systems
whose multimodal behavior matches the flexibility
and coordination that distinguishes our own embod-
ied meanings. More generally, modeling replaces
programming with data fitting, and a good model of
action and interpretation in particular would let an
agent’s own experience in conversational interaction
determine the repertoire of behaviors and meanings
it uses to make itself understood.
</bodyText>
<sectionHeader confidence="0.977623" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999345666666667">
To colleagues and coauthors, especially David DeVault
and the organizers of INLG 2008, and to NSF IGERT
0549115, CCF 0541185 and HSD 0624191.
</bodyText>
<sectionHeader confidence="0.99851" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999803102564103">
J. Cassell, M. Stone, and H. Yan. 2000. Coordination
and context-dependence in the generation of embodied
conversation. In INLG, pages 171–178.
D. DeCarlo, M. Stone, C. Revilla, and J. J. Venditti.
2004. Specifying and animating facial signals for dis-
course in embodied conversational agents. Computer
Animation and Virtual Worlds, 15(1):27–38.
D. DeVault and M. Stone. 2004. Interpreting vague ut-
terances in context. In COLING, pages 1247–1253.
D. DeVault and M. Stone. 2007. Managing ambiguities
across utterances in dialogue. In DECALOG: Work-
shop on the Semantics and Pragmatics ofDialogue.
A. Koller and M. Stone. 2007. Sentence generation as a
planning problem. In ACL, pages 336–343.
A. Lascarides and M. Stone. 2008. Discourse coherence
and gesture interpretation. Ms, Edinburgh–Rutgers.
A. Lascarides and M. Stone. In Preparation. Grounding
and gesture. Ms, Edinburgh–Rutgers.
M. Stone and D. DeCarlo. 2003. Crafting the illusion
of meaning: Template-based generation of embodied
conversational behavior. In Computer Animation and
Social Agents (CASA), pages 11–16.
M. Stone and I. Oh. 2008. Modeling facial ex-
pression of uncertainty in conversational animation.
In I. Wachsmuth and G. Knoblich, editors, Model-
ing Communication with Robots and Virtual Humans,
pages 57–76. Springer.
M. Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer.
2003. Microplanning with communicative inten-
tions: The SPUD system. Computational Intelligence,
19(4):311–381.
M. Stone, D. DeCarlo, I. Oh, C. Rodriguez, A. Stere,
A. Lees, and C. Bregler. 2004. Speaking with
hands: Creating animated conversational characters
from recordings of human performance. ACM Trans-
actions on Graphics, 23(3):506–513.
R. Thomason, M. Stone, and D. DeVault. 2006. Enlight-
ened update: a computational architecture for presup-
position accommodation. Ms, Michigan–Rutgers.
</reference>
<page confidence="0.998785">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.128445">
<title confidence="0.998559">Language, Embodiment and Social Intelligence</title>
<author confidence="0.997341">Matthew</author>
<affiliation confidence="0.999109">Computer Science and Cognitive Rutgers, The State University of New</affiliation>
<address confidence="0.99667">110 Frelinghuysen Road, Piscataway NJ</address>
<email confidence="0.946559">Matthew.Stone@Rutgers.EDU</email>
<abstract confidence="0.9998618">It is an honor to have this chance to tie together themes from my recent research, and to sketch some challenges and opportunities for NLG in face-to-face conversational interaction. Communication reflects our general involvement in one anothers’ lives. Through the choices we manifest with one another, we share our thoughts and feelings, strengthen our relationships and further our joint projects. We rely not only on words to articulate our perspectives, but also on a heterogeneous array of accompanying efforts: embodied deixis, expressive movement, presentation of iconic imagery and instrumental action in the world. Words showcase the distinctive linguistic knowledge which human communication exploits. But people’s diverse choices in conversation in fact come together to reveal multifaceted, interrelated meanings, in which all our actions, verbal and nonverbal, fit the situation and further social purposes. In the best case, they let interlocutors understand not just each other’s words, but each other. As NLG researchers, I argue, we have good reason to work towards models of social cognition that embrace the breadth of conversation. Scientifically, it connects us to an emerging consensus in favor of a general human pragmatic competence, rooted in capacities for engagement, coordination, shared intentionality and extended relationships. Technically, it lets us position ourselves as part of an emerging revolution in integrative Artificial Intelligence, characterized by research challenges like human–robot interaction and the design of virtual humans, and applications in assistive and educational technology and interactive entertainment. Researchers are already hard at work to place our accounts of embodied action in conversation in contact with pragmatic theories derived from text discourse and spoken dialogue. In my own experience, such work proves both illuminating and exciting. For example, it challenges us to support and refine theories of discourse coherence by accounting for the discourse relations and default inference that determine the joint interpretation of coverbal gesture and its accompanying speech (Lascarides and Stone, 2008). And it challenges us to show how speakers work across modalities to engage with, disambiguate, and (on acceptance) recapitulate each others’ communicative actions, to ground their meanings (Lascarides and Stone, In Preparation). The closer we look at conversation, the more we can fit all its behaviors into a unitary framework—inviting us to implement behavioral control for embodied social agents through a pervasive analogy to NLG. We can already pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we already use in spoken language generation (Stone et al., 2004). At a higher level, we can represent an embodied performance through a matrix of discrete actions selected and synchronized an abstract time-line, as in our (De- Carlo et al., 2004; Stone and Oh, 2008). This lets us use any NLG method that manipulates structured selections of discrete actions as an architecture for the production of embodied behavior. Templates, as in (Stone and DeCarlo, 2003; Stone et al., 2004), offer 5 a good illustration. Nevertheless, face-to-face dialogue does demand qualitatively new capabilities. In fact, people’s choices and meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other behaviors they use. In my experience, even the simplest social practices, such as interlocutors’ cooperation on an ongoing practical task, require new models of linguistic meaning and discourse context. For example, systems must be creative to evoke the distinctions that matter for their ongoing task, and use meanings that are not programmed or learned but invented on the fly (DeVault and Stone, 2004). They must count on their interlocutors to recognize the background knowledge they presuppose by general inference from the logic of their behavior as a cooperative contribution to the task (Thomason et al., 2006). Such reasoning becomes particularly important in problematic cases, such as when systems must finetune the form and meaning of a clarification request so that the response is more likely to resolve a pending task ambiguity (DeVault and Stone, 2007). I expect many further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of action and interpretation in particular would let an agent’s own experience in conversational interaction determine the repertoire of behaviors and meanings it uses to make itself understood.</abstract>
<note confidence="0.695753777777778">Acknowledgments To colleagues and coauthors, especially David DeVault and the organizers of INLG 2008, and to NSF IGERT 0549115, CCF 0541185 and HSD 0624191. References J. Cassell, M. Stone, and H. Yan. 2000. Coordination and context-dependence in the generation of embodied In pages 171–178. D. DeCarlo, M. Stone, C. Revilla, and J. J. Venditti.</note>
<abstract confidence="0.9440738">2004. Specifying and animating facial signals for disin embodied conversational agents. and Virtual 15(1):27–38. D. DeVault and M. Stone. 2004. Interpreting vague utin context. In pages 1247–1253. D. DeVault and M. Stone. 2007. Managing ambiguities utterances in dialogue. In Workon the Semantics and Pragmatics A. Koller and M. Stone. 2007. Sentence generation as a problem. In pages 336–343. A. Lascarides and M. Stone. 2008. Discourse coherence gesture interpretation. A. Lascarides and M. Stone. In Preparation. Grounding gesture. M. Stone and D. DeCarlo. 2003. Crafting the illusion of meaning: Template-based generation of embodied behavior. In Animation and Agents pages 11–16. M. Stone and I. Oh. 2008. Modeling facial expression of uncertainty in conversational animation. I. Wachsmuth and G. Knoblich, editors, Model- Communication with Robots and Virtual pages 57–76. Springer. M. Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer. 2003. Microplanning with communicative inten- The SPUD system. 19(4):311–381. M. Stone, D. DeCarlo, I. Oh, C. Rodriguez, A. Stere, A. Lees, and C. Bregler. 2004. Speaking with hands: Creating animated conversational characters recordings of human performance. Transon 23(3):506–513. R. Thomason, M. Stone, and D. DeVault. 2006. Enlightened update: a computational architecture for presupaccommodation.</abstract>
<intro confidence="0.855727">6</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>M Stone</author>
<author>H Yan</author>
</authors>
<title>Coordination and context-dependence in the generation of embodied conversation.</title>
<date>2000</date>
<booktitle>In INLG,</booktitle>
<pages>171--178</pages>
<contexts>
<context position="5360" citStr="Cassell et al., 2000" startWordPosition="830" endWordPosition="833">further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of action and interpretation in particular would let an agent’s own experience in con</context>
</contexts>
<marker>Cassell, Stone, Yan, 2000</marker>
<rawString>J. Cassell, M. Stone, and H. Yan. 2000. Coordination and context-dependence in the generation of embodied conversation. In INLG, pages 171–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D DeCarlo</author>
<author>M Stone</author>
<author>C Revilla</author>
<author>J J Venditti</author>
</authors>
<title>Specifying and animating facial signals for discourse in embodied conversational agents. Computer Animation and Virtual Worlds,</title>
<date>2004</date>
<contexts>
<context position="3259" citStr="DeCarlo et al., 2004" startWordPosition="489" endWordPosition="493">closer we look at conversation, the more we can fit all its behaviors into a unitary framework—inviting us to implement behavioral control for embodied social agents through a pervasive analogy to NLG. We can already pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we already use in spoken language generation (Stone et al., 2004). At a higher level, we can represent an embodied performance through a matrix of discrete actions selected and synchronized to an abstract time-line, as in our RUTH system (DeCarlo et al., 2004; Stone and Oh, 2008). This lets us use any NLG method that manipulates structured selections of discrete actions as an architecture for the production of embodied behavior. Templates, as in (Stone and DeCarlo, 2003; Stone et al., 2004), offer 5 a good illustration. Nevertheless, face-to-face dialogue does demand qualitatively new capabilities. In fact, people’s choices and meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other beh</context>
</contexts>
<marker>DeCarlo, Stone, Revilla, Venditti, 2004</marker>
<rawString>D. DeCarlo, M. Stone, C. Revilla, and J. J. Venditti. 2004. Specifying and animating facial signals for discourse in embodied conversational agents. Computer Animation and Virtual Worlds, 15(1):27–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D DeVault</author>
<author>M Stone</author>
</authors>
<title>Interpreting vague utterances in context.</title>
<date>2004</date>
<booktitle>In COLING,</booktitle>
<pages>1247--1253</pages>
<contexts>
<context position="4260" citStr="DeVault and Stone, 2004" startWordPosition="650" endWordPosition="653">meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other behaviors they use. In my experience, even the simplest social practices, such as interlocutors’ cooperation on an ongoing practical task, require new models of linguistic meaning and discourse context. For example, systems must be creative to evoke the distinctions that matter for their ongoing task, and use meanings that are not programmed or learned but invented on the fly (DeVault and Stone, 2004). They must count on their interlocutors to recognize the background knowledge they presuppose by general inference from the logic of their behavior as a cooperative contribution to the task (Thomason et al., 2006). Such reasoning becomes particularly important in problematic cases, such as when systems must finetune the form and meaning of a clarification request so that the response is more likely to resolve a pending task ambiguity (DeVault and Stone, 2007). I expect many further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of</context>
</contexts>
<marker>DeVault, Stone, 2004</marker>
<rawString>D. DeVault and M. Stone. 2004. Interpreting vague utterances in context. In COLING, pages 1247–1253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D DeVault</author>
<author>M Stone</author>
</authors>
<title>Managing ambiguities across utterances in dialogue.</title>
<date>2007</date>
<booktitle>In DECALOG: Workshop on the Semantics and Pragmatics ofDialogue.</booktitle>
<contexts>
<context position="4724" citStr="DeVault and Stone, 2007" startWordPosition="727" endWordPosition="730">evoke the distinctions that matter for their ongoing task, and use meanings that are not programmed or learned but invented on the fly (DeVault and Stone, 2004). They must count on their interlocutors to recognize the background knowledge they presuppose by general inference from the logic of their behavior as a cooperative contribution to the task (Thomason et al., 2006). Such reasoning becomes particularly important in problematic cases, such as when systems must finetune the form and meaning of a clarification request so that the response is more likely to resolve a pending task ambiguity (DeVault and Stone, 2007). I expect many further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own</context>
</contexts>
<marker>DeVault, Stone, 2007</marker>
<rawString>D. DeVault and M. Stone. 2007. Managing ambiguities across utterances in dialogue. In DECALOG: Workshop on the Semantics and Pragmatics ofDialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>M Stone</author>
</authors>
<title>Sentence generation as a planning problem.</title>
<date>2007</date>
<booktitle>In ACL,</booktitle>
<pages>336--343</pages>
<contexts>
<context position="5405" citStr="Koller and Stone, 2007" startWordPosition="838" endWordPosition="841">standing of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of action and interpretation in particular would let an agent’s own experience in conversational interaction determine the reperto</context>
</contexts>
<marker>Koller, Stone, 2007</marker>
<rawString>A. Koller and M. Stone. 2007. Sentence generation as a planning problem. In ACL, pages 336–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lascarides</author>
<author>M Stone</author>
</authors>
<title>Discourse coherence and gesture interpretation.</title>
<date>2008</date>
<journal>Ms, Edinburgh–Rutgers. A. Lascarides</journal>
<booktitle>In Preparation. Grounding and gesture. Ms,</booktitle>
<location>Edinburgh–Rutgers.</location>
<contexts>
<context position="2404" citStr="Lascarides and Stone, 2008" startWordPosition="349" endWordPosition="352">design of virtual humans, and applications in assistive and educational technology and interactive entertainment. Researchers are already hard at work to place our accounts of embodied action in conversation in contact with pragmatic theories derived from text discourse and spoken dialogue. In my own experience, such work proves both illuminating and exciting. For example, it challenges us to support and refine theories of discourse coherence by accounting for the discourse relations and default inference that determine the joint interpretation of coverbal gesture and its accompanying speech (Lascarides and Stone, 2008). And it challenges us to show how speakers work across modalities to engage with, disambiguate, and (on acceptance) recapitulate each others’ communicative actions, to ground their meanings (Lascarides and Stone, In Preparation). The closer we look at conversation, the more we can fit all its behaviors into a unitary framework—inviting us to implement behavioral control for embodied social agents through a pervasive analogy to NLG. We can already pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we a</context>
</contexts>
<marker>Lascarides, Stone, 2008</marker>
<rawString>A. Lascarides and M. Stone. 2008. Discourse coherence and gesture interpretation. Ms, Edinburgh–Rutgers. A. Lascarides and M. Stone. In Preparation. Grounding and gesture. Ms, Edinburgh–Rutgers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>D DeCarlo</author>
</authors>
<title>Crafting the illusion of meaning: Template-based generation of embodied conversational behavior.</title>
<date>2003</date>
<booktitle>In Computer Animation and Social Agents (CASA),</booktitle>
<pages>11--16</pages>
<contexts>
<context position="3474" citStr="Stone and DeCarlo, 2003" startWordPosition="525" endWordPosition="528">eady pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we already use in spoken language generation (Stone et al., 2004). At a higher level, we can represent an embodied performance through a matrix of discrete actions selected and synchronized to an abstract time-line, as in our RUTH system (DeCarlo et al., 2004; Stone and Oh, 2008). This lets us use any NLG method that manipulates structured selections of discrete actions as an architecture for the production of embodied behavior. Templates, as in (Stone and DeCarlo, 2003; Stone et al., 2004), offer 5 a good illustration. Nevertheless, face-to-face dialogue does demand qualitatively new capabilities. In fact, people’s choices and meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other behaviors they use. In my experience, even the simplest social practices, such as interlocutors’ cooperation on an ongoing practical task, require new models of linguistic meaning and discourse context. For example, sy</context>
</contexts>
<marker>Stone, DeCarlo, 2003</marker>
<rawString>M. Stone and D. DeCarlo. 2003. Crafting the illusion of meaning: Template-based generation of embodied conversational behavior. In Computer Animation and Social Agents (CASA), pages 11–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>I Oh</author>
</authors>
<title>Modeling facial expression of uncertainty in conversational animation.</title>
<date>2008</date>
<booktitle>Modeling Communication with Robots and Virtual Humans,</booktitle>
<pages>57--76</pages>
<editor>In I. Wachsmuth and G. Knoblich, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="3280" citStr="Stone and Oh, 2008" startWordPosition="494" endWordPosition="497">ersation, the more we can fit all its behaviors into a unitary framework—inviting us to implement behavioral control for embodied social agents through a pervasive analogy to NLG. We can already pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we already use in spoken language generation (Stone et al., 2004). At a higher level, we can represent an embodied performance through a matrix of discrete actions selected and synchronized to an abstract time-line, as in our RUTH system (DeCarlo et al., 2004; Stone and Oh, 2008). This lets us use any NLG method that manipulates structured selections of discrete actions as an architecture for the production of embodied behavior. Templates, as in (Stone and DeCarlo, 2003; Stone et al., 2004), offer 5 a good illustration. Nevertheless, face-to-face dialogue does demand qualitatively new capabilities. In fact, people’s choices and meanings in interactive conversation are profoundly informed by their social settings. We are a long way from general models that could allow NLG systems to recognize and exploit these connections in the words and other behaviors they use. In m</context>
</contexts>
<marker>Stone, Oh, 2008</marker>
<rawString>M. Stone and I. Oh. 2008. Modeling facial expression of uncertainty in conversational animation. In I. Wachsmuth and G. Knoblich, editors, Modeling Communication with Robots and Virtual Humans, pages 57–76. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>C Doran</author>
<author>B Webber</author>
<author>T Bleam</author>
<author>M Palmer</author>
</authors>
<title>Microplanning with communicative intentions: The SPUD system.</title>
<date>2003</date>
<journal>Computational Intelligence,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="5380" citStr="Stone et al., 2003" startWordPosition="834" endWordPosition="837">opments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by exploiting what they know about communication. These systems give new evidence about the information and problem-solving that’s involved. The challenge is that these models must describe semantics and pragmatics, as well as syntax and behavior. My own slow progress (Cassell et al., 2000; Stone et al., 2003; Koller and Stone, 2007) shows that there’s still lots of hard work needed to develop suitable techniques. I keep going because of the methodological payoffs I see on the horizon. Modeling lets us take social intelligence seriously as a general implementation principle, and thus to aim for systems whose multimodal behavior matches the flexibility and coordination that distinguishes our own embodied meanings. More generally, modeling replaces programming with data fitting, and a good model of action and interpretation in particular would let an agent’s own experience in conversational interact</context>
</contexts>
<marker>Stone, Doran, Webber, Bleam, Palmer, 2003</marker>
<rawString>M. Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer. 2003. Microplanning with communicative intentions: The SPUD system. Computational Intelligence, 19(4):311–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>D DeCarlo</author>
<author>I Oh</author>
<author>C Rodriguez</author>
<author>A Stere</author>
<author>A Lees</author>
<author>C Bregler</author>
</authors>
<title>Speaking with hands: Creating animated conversational characters from recordings of human performance.</title>
<date>2004</date>
<journal>ACM Transactions on Graphics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="3065" citStr="Stone et al., 2004" startWordPosition="457" endWordPosition="460">s work across modalities to engage with, disambiguate, and (on acceptance) recapitulate each others’ communicative actions, to ground their meanings (Lascarides and Stone, In Preparation). The closer we look at conversation, the more we can fit all its behaviors into a unitary framework—inviting us to implement behavioral control for embodied social agents through a pervasive analogy to NLG. We can already pursue such implementations easily. Computationally, motion is just sequence data, and we can manipulate it in parallel ways to the speech data we already use in spoken language generation (Stone et al., 2004). At a higher level, we can represent an embodied performance through a matrix of discrete actions selected and synchronized to an abstract time-line, as in our RUTH system (DeCarlo et al., 2004; Stone and Oh, 2008). This lets us use any NLG method that manipulates structured selections of discrete actions as an architecture for the production of embodied behavior. Templates, as in (Stone and DeCarlo, 2003; Stone et al., 2004), offer 5 a good illustration. Nevertheless, face-to-face dialogue does demand qualitatively new capabilities. In fact, people’s choices and meanings in interactive conve</context>
</contexts>
<marker>Stone, DeCarlo, Oh, Rodriguez, Stere, Lees, Bregler, 2004</marker>
<rawString>M. Stone, D. DeCarlo, I. Oh, C. Rodriguez, A. Stere, A. Lees, and C. Bregler. 2004. Speaking with hands: Creating animated conversational characters from recordings of human performance. ACM Transactions on Graphics, 23(3):506–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Thomason</author>
<author>M Stone</author>
<author>D DeVault</author>
</authors>
<title>Enlightened update: a computational architecture for presupposition accommodation.</title>
<date>2006</date>
<location>Ms, Michigan–Rutgers.</location>
<contexts>
<context position="4474" citStr="Thomason et al., 2006" startWordPosition="686" endWordPosition="689">her behaviors they use. In my experience, even the simplest social practices, such as interlocutors’ cooperation on an ongoing practical task, require new models of linguistic meaning and discourse context. For example, systems must be creative to evoke the distinctions that matter for their ongoing task, and use meanings that are not programmed or learned but invented on the fly (DeVault and Stone, 2004). They must count on their interlocutors to recognize the background knowledge they presuppose by general inference from the logic of their behavior as a cooperative contribution to the task (Thomason et al., 2006). Such reasoning becomes particularly important in problematic cases, such as when systems must finetune the form and meaning of a clarification request so that the response is more likely to resolve a pending task ambiguity (DeVault and Stone, 2007). I expect many further exciting developments in our understanding of meaning and interpretation as we enrich the social intelligence of NLG. Modeling efforts will remain crucial to the exploration of these new capabilities. When we build and assemble models of actions and interpretations, we get systems that can plan their own behavior simply by e</context>
</contexts>
<marker>Thomason, Stone, DeVault, 2006</marker>
<rawString>R. Thomason, M. Stone, and D. DeVault. 2006. Enlightened update: a computational architecture for presupposition accommodation. Ms, Michigan–Rutgers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>