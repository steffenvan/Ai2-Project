<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001788">
<title confidence="0.996464">
Utterance Classification in AutoTutor
</title>
<author confidence="0.9887495">
Andrew Max Eric Johanna Heather Arthur
Olney Louwerse Matthews Marineau Hite-Mitchell Graesser
</author>
<affiliation confidence="0.9983715">
Institute for Intelligent Systems
University of Memphis
</affiliation>
<address confidence="0.760573">
Memphis, TN 38152
</address>
<email confidence="0.997989">
aolney@memphis.edu
</email>
<sectionHeader confidence="0.998594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999835090909091">
This paper describes classification of typed
student utterances within AutoTutor, an intel-
ligent tutoring system. Utterances are classi-
fied to one of 18 categories, including 16
question categories. The classifier presented
uses part of speech tagging, cascaded finite
state transducers, and simple disambiguation
rules. Shallow NLP is well suited to the task:
session log file analysis reveals significant
classification of eleven question categories,
frozen expressions, and assertions.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974050000001">
AutoTutor is a domain-portable intelligent tutoring
system (ITS) with current versions in the domains of
physics and computer literacy (Graesser et al. 1999;
Olney et al. 2002). AutoTutor, like many other ITSs, is
an intersection of applications, including tutoring,
mixed-initiative dialogue, and question answering. In
each of these, utterance classification, particularly ques-
tion classification, plays a critical role.
In tutoring, utterance classification can be used to
track the student&apos;s level of understanding. Contribution
and question classifications can both play a role: contri-
butions may be compared to an expected answer
(Graesser et al. 2001) and questions may be scored by
how &amp;quot;deep&amp;quot; they are. For example, The PREG model
(Otero and Graesser 2001) predicts under what circum-
stances students will ask &amp;quot;deep&amp;quot; questions, i.e. those that
reveal a greater level of cognitive processing than who,
what, when, or where questions. A student who is only
asking shallow questions, or no questions at all, is pre-
dicted by PREG to not have a situation-level under-
standing (van Dijk and Kintsch 1983) and thus to learn
less and forget faster. The key point is that different
metrics for tracking student understanding are applica-
ble to questions and contributions. Distinguishing them
via classification is a first step to applying a metric.
In mixed-initiative dialog systems, utterance classifi-
cation can be used to detect shifts in initiative. For ex-
ample, a mixed-initiative system that asks, &amp;quot;Where
would you like to travel&amp;quot;, could respond to the question,
&amp;quot;Where can I travel for $200?&amp;quot; (Allen 1999) by giving a
list of cities. In this example, the user is taking the ini-
tiative by requesting more information. In order to re-
spond properly, the system must detect that the user has
taken initiative before it can respond appropriately; oth-
erwise it might try to interpret the user&apos;s utterance as a
travel destination. In this sense, questions mark redirec-
tion of the dialogue, whereas contributions are continua-
tions of the dialogue. In order for a user to redirect the
dialogue and thus exercise initiative, a mixed-initiative
system must be able to distinguish questions and contri-
butions.
Question classification as early as Lehnert (1978)
has been used as a basis for answering questions, a trend
that continues today (Voorhees 2001). A common fea-
ture of these question-answering systems is that they
first determine the expected answer type implicit in the
question. For example, &amp;quot;How much does a pretzel cost&amp;quot;
might be classified according to the answer type of
MONEY or QUANTITY. Knowledge of the expected an-
swer type can be used to narrow the search space for the
answer, either online (Brill et al. 2001) or in a database
(Harabagiu et al. 2000). Accordingly, question answer-
ing calls for a finer discrimination of question types as
opposed to only distinguishing questions from contribu-
tions.
AutoTutor uses utterance classification to track stu-
dent progress, to determine initiative, and to answer
questions. By virtue of being embedded in AutoTutor,
the utterance classifier presented here has an unusual set
of constraints, both practical and theoretical. On the
practical side, AutoTutor is a web-based application that
performs in real time; thus utterance classification must
also proceed in real time. For that reason, the classifier
uses a minimum of resources, including part of speech
tagging (Brill 1995; Sekine and Grishman 1995) and
cascaded finite state transducers defining the categories.
Theoretically speaking, AutoTutor must also recognize
questions in a meaningful way to both question answer-
ing and tutoring. The question taxonomy utilized, that
of Graesser et al (1992), is an extension of Lehnert&apos;s
(1978) taxonomy for question answering and has been
applied to human tutoring (Graesser et al. 1992;
Graesser and Person 1994).
This paper outlines the utterance classifier and quan-
tifies its performance. In particular, Section 2 presents
AutoTutor. Section 3 presents the utterance taxonomy.
Section 4 describes the classifier algorithm. Section 5
delineates the training process and results. Section 6
presents evaluation of the classifier on real AutoTutor
sessions. Section 7 concludes the paper.
</bodyText>
<sectionHeader confidence="0.997082" genericHeader="introduction">
2 AutoTutor
</sectionHeader>
<bodyText confidence="0.958209561403509">
AutoTutor is an ITS applicable to any content domain.
Two distinct domain applications of AutoTutor are
available on the Internet, for computer literacy and con-
ceptual physics. The computer literacy AutoTutor,
which has now been used in experimental evaluations
by over 200 students, tutors students on core computer
literacy topics covered in an introductory course, such
as operating systems, the Internet, and hardware. The
topics covered by the physics AutoTutor are grounded
in basic Newtonian mechanics and are of a similar in-
troductory nature. It has been well documented that
AutoTutor promotes learning gains in both versions
(Person et al. 2001).
AutoTutor simulates the dialog patterns and peda-
gogical strategies of human tutors in a conversational
interface that supports mixed-initiative dialog. AutoTu-
tor’s architecture is comprised of seven highly modular
components: (1) an animated agent, (2) a curriculum
script, (3) a speech act classifier, (4) latent semantic
analysis (LSA), (5) a dialog move generator, (6) a Dia-
log Advancer Network, and (7) a question-answering
tool (Graesser et al. 1998; Graesser et al. 2001;
Graesser et al. 2001; Person et al. 2000; Person et al.
2001; Wiemer-Hastings et al. 1998).
A tutoring session begins with a brief introduction
from AutoTutor’s three-dimensional animated agent.
AutoTutor then asks the student a question from one of
topics in the curriculum script. The curriculum script
contains lesson-specific tutor-initiated dialog, including
important concepts, questions, cases, and problems
(Graesser and Person 1994; Graesser et al. 1995;
McArthur et al. 1990; Putnam 1987). The student sub-
mits a response to the question by typing and pressing
the “Submit” button. The student’s contribution is then
segmented, parsed (Sekine and Grishman 1995) and
sent through a rule-based utterance classifier. The clas-
sification process makes use of only the contribution
text and part-of-speech tag provided by the parser.
Mixed-initiative dialog starts with utterance classifi-
cation and ends with dialog move generation, which can
include question answering, repeating the question for
the student, or just encouraging the student. Concur-
rently, the LSA module evaluates the quality of the stu-
dent contributions, and in the tutor-initiative mode, the
dialog move generator selects one or a combination of
specific dialog moves that is both conversationally and
pedagogically appropriate (Person et al 2000; Person et
al. 2001). The Dialog Advancer Network (DAN) is the
intermediary of dialog move generation in all instances,
using information from the speech act classifier and
LSA to select the next dialog move type and appropriate
discourse markers. The dialog move generator selects
the actual move. There are twelve types of dialog
move: Pump, Hint, Splice, Prompt, Prompt Response,
Elaboration, Summary, and five forms of immediate
short-feedback (Graesser and Person 1994; Graesser et
al. 1995; Person and Graesser 1999).
</bodyText>
<sectionHeader confidence="0.920307" genericHeader="method">
3 An utterance taxonomy
</sectionHeader>
<bodyText confidence="0.999624133333333">
The framework for utterance classification in Table 1 is
familiar to taxonomies in the cognitive sciences
(Graesser et al. 1992; Graesser and Person 1994). The
most notable system within this framework is QUALM
(Lehnert 1978), which utilizes twelve of the question
categories. The taxonomy can be divided into 3 distinct
groups, questions, frozen expressions, and contribu-
tions. Each of these will be discussed in turn.
The conceptual basis of the question categories
arises from the observation that the same question may
be asked in different ways, e.g. &amp;quot;What happened?&amp;quot; and
&amp;quot;How did this happen?&amp;quot; Correspondingly, a single lexi-
cal stem for a question, like &amp;quot;What&amp;quot; can be polysemous,
e.g. both in a definition category, &amp;quot;What is the definition
of gravity?&amp;quot; and metacommunicative, &amp;quot;What did you
say?&amp;quot; Furthermore, implicit questions can arise in tutor-
ing via directives and some assertions, e.g. &amp;quot;Tell me
about gravity&amp;quot; and &amp;quot;I don&apos;t know what gravity is.&amp;quot; In
AutoTutor these information seeking utterances are
classified to one of the 16 question categories.
The emphases on queried concepts rather than ortho-
graphic forms make the categories listed in Table 1 bear
a strong resemblance to speech acts. Indeed, Graesser
et al. (1992) propose that the categories be distinguished
in precisely the same way as speech acts, using seman-
tic, conceptual, and pragmatic criteria as opposed to
syntactic and lexical criteria. Speech acts presumably
transcend these surface criteria: it is not what is being
said as what is done by the saying (Austin, 1962; Searle,
1975).
</bodyText>
<figure confidence="0.929119238095238">
Category Example
Questions
Verification
Disjunctive
Concept Completion
Feature Specification
Quantification
Definition
Example
Comparison
Interpretation
Causal Antecedent
Causal Consequence
Goal Orientation
Instrumental/Procedural
Enablement
Expectational
Judgmental
Frozen Expressions
Metacognitive
Metacommunicative
</figure>
<bodyText confidence="0.97646052631579">
Does the pumpkin land in his hands?
Is the pumpkin accelerating or decelerating?
Where will the pumpkin land?
What are the components of the forces acting on the pumpkin?
How far will the pumpkin travel?
What is acceleration?
What is an example of Newton&apos;s Third Law?
What is the difference between speed and velocity?
What is happening in this situation with the runner and pumpkin?
What caused the pumpkin to fall?
What happens when the runner speeds up?
Why did you ignore air resistance?
How do you calculate force?
What principle allows you to ignore the vertical component of the force?
Why doesn&apos;t the pumpkin land behind the runner?
What do you think of my explanation?
I don&apos;t understand.
Could you repeat that?
Contribution The pumpkin will land in the runner&apos;s hands
</bodyText>
<tableCaption confidence="0.987436">
Table 1. AutoTutor’s utterance taxonomy.
</tableCaption>
<bodyText confidence="0.999989046511628">
The close relation to speech acts underscores what a
difficult task classifying conceptual questions can be.
Jurafsky and Martin (2000) describe the problem of
interpreting speech acts using pragmatic and semantic
inference as AI-complete, i.e. impossible without creat-
ing a full artificial intelligence. The alternative ex-
plored in this paper is cue or surface-based
classification, using no context.
It is particularly pertinent to the present discussion
that the sixteen qualitative categories are employed in a
quantitative classification process. That is to say that
for the present purposes of classification, a question
must belong to one and only one category. On the one
hand this idealization is necessary to obtain easily ana-
lyzed performance data and to create a well-balanced
training corpus. On the other hand, it is not entirely
accurate because some questions may be assigned to
multiple categories, suggesting a polythetic coding
scheme (Graesser et al. 1992). Inter-rater reliability is
used in the current study as a benchmark to gauge this
potential effect.
Frozen expressions consist of metacognitive and
metacommunicative utterances. Metacognitive utter-
ances describe the cognitive state of the student, and
they therefore require a different response than ques-
tions or assertions. AutoTutor responds to metacogni-
tive utterances with canned expressions such as, &amp;quot;Why
don&apos;t you give me what you know, and we&apos;ll take it from
there.&amp;quot; Metacommunicative acts likewise refer to the
dialogue between tutor and student, often calling for a
repetition of the tutor&apos;s last utterance. Two key points
are worth noting: frozen expressions have a much
smaller variability than questions or contributions, and
frozen expressions may be followed by some content,
making them more properly treated as questions. For
example, &amp;quot;I don&apos;t understand&amp;quot; is frozen, but &amp;quot;I don&apos;t un-
derstand gravity&amp;quot; is a more appropriately a question.
Contributions in the taxonomy can be viewed as
anything that is not frozen or a question; in fact, that is
essentially how the classifier works. Contributions in
AutoTutor, either as responses to questions or un-
prompted, are tracked to evaluate student performance
via LSA, forming the basis for feedback.
</bodyText>
<sectionHeader confidence="0.997503" genericHeader="method">
4 Classifier Algorithm
</sectionHeader>
<bodyText confidence="0.999170260869565">
The present approach ignores the semantic and prag-
matic context of the questions, and utilizes surface fea-
tures to classify questions. This shallow approach
parallels work in question answering (Srihari and Li
2000; Soubbotin and Soubbotin 2002; Moldovan et al
1999). Specifically, the classifier uses tagging provided
by ApplePie (Sekine and Grishman 1995) followed by
cascaded finite state transducers defining the categories.
The finite state transducers are roughly described in
Table 2. Every transducer is given a chance to match,
and a disambiguation routine is applied at the end to
select a single category.
Immediately after tagging, transducers are applied to
check for frozen expressions. A frozen expression must
match, and the utterance must be free of any nouns, i.e.
not frozen+content, for the utterance to be classified as
frozen. Next the utterance is checked for question
stems, e.g. WHAT, HOW, WHY, etc. and question
mark punctuation. If question stems are buried in the
utterance, e.g. &amp;quot;I don&apos;t know what gravity is&amp;quot;, a move-
ment rule transforms the utterance, placing the stem at
the beginning. Likewise if a question ends with a ques-
tion mark but has no stem, an AUX stem is placed at the
beginning of the utterance. In this way the same trans-
ducers can be applied to both direct and indirect ques-
tions. At this stage, if the utterance does not possess a
question stem and is not followed by a question mark,
the utterance is classified as a contribution.
Two sets of finite state transducers are applied to po-
tential questions, keyword transducers and syntactic
pattern transducers. Keyword transducers replace a set
of keywords specific to a category with a symbol for
that category. This extra step simplifies the syntactic
pattern transducers that look for the category symbol in
their pattern. The definition keyword transducer, for
example, replaces &amp;quot;definition&amp;quot;, &amp;quot;define&amp;quot;, &amp;quot;meaning&amp;quot;,
&amp;quot;means&amp;quot;, and &amp;quot;understanding&amp;quot; with &amp;quot;KEYDEF&amp;quot;. For
most categories, the keyword list is quite extensive and
exceeds the space limitations of Table 2. Keyword
transducers also add the category symbol to a list when
they match; this list is used for disambiguation. Syntac-
tic pattern transducers likewise match, putting a cate-
gory symbol on a separate disambiguation list.
In the disambiguation routine, both lists are con-
sulted, and the first category symbol found on both lists
determines the classification of the utterance. Clearly
</bodyText>
<table confidence="0.983451617647059">
Utterance Category Finite state transducer pattern
Verification ^AUX
Disjunctive ^AUX ... or
Concept Completion ^(Who|What|When|Where)
Feature Specification ^What ... keyword
keyword
Quantification ^What AUX ... keyword
^How (ADJ|ADV)
^MODAL you ... keyword
Definition ^What AUX ... (keyword|a? (ADJ|ADV)* N
^MODAL you ... keyword
what a? (ADJ|ADV)* N BE
Example ^AUX ... keyword
^What AUX ... keyword
Comparison ^What AUX ... keyword
^How ... keyword
^MODAL you ... keyword
Interpretation keyword
Causal Antecedent ^(Why|How) AUX ... (VBpast|keyword)
^(WH|How) ... keyword
Causal Consequence
Goal Orientation ^(What|Why) AUX ART? (NP|SUBJPRO|keyword)
^What ... keyword
Instrumental/Procedural ^(WH|How) AUX ART? (N|PRO)
^(WH|How) ... keyword
^MODAL you ... keyword
Enablement ^(WH|How) ... keyword
Expectational ^Why AUX ... NEG
Judgmental (should|keyword) (N|PRO)
(you|your) ... keyword
Frozen (no nouns) ^SUBJPRO ... keyword
^VB ... keyword ... OBJPRO
^AUX ... SUBJPRO ... keyword
Contribution Everything else
</table>
<tableCaption confidence="0.999908">
Table 2. Finite state transducer patterns
</tableCaption>
<bodyText confidence="0.999870857142857">
ordering of transducers affects which symbols are clos-
est to the beginning of the list. Ordering is particularly
relevant when considering categories like concept com-
pletion, which match more freely than other categories.
Ordering gives rarer and stricter categories a chance to
match first; this strategy is common in stemming (Paice
1990).
</bodyText>
<sectionHeader confidence="0.997604" genericHeader="method">
5 Training
</sectionHeader>
<bodyText confidence="0.999885545454546">
The classifier was built by hand in a cyclical process of
inspecting questions, inducing rules, and testing the
results. The training data was derived from brainstorm-
ing sessions whose goal was to generate questions as
lexically and syntactically distinct as possible. Of the
brainstormed questions, only when all five raters agreed
on the category was a question used for training; this
approach filtered out polythetic questions and left only
archetypes.
Intuitive analysis suggested that the majority of
questions have at most a two-part pattern consisting of a
syntactic template and/or a keyword identifiable for that
category. A trivial example is disjunction, whose syn-
tactic template is auxiliary-initial and corresponding
keyword is “or”. Other categories were similarly de-
fined either by one or more patterns of initial constitu-
ents, or a keyword, or both. To promote
generalizability, extra care was given not to overfit the
training data. Specifically, keywords or syntactic pat-
terns were only used to define categories when they
occurred more than once or were judged highly diagnos-
tic.
</bodyText>
<tableCaption confidence="0.957345">
Table 3. Contingency Table.
</tableCaption>
<bodyText confidence="0.999846166666667">
The results of the training process are shown in Ta-
ble 4. Results from each category were compiled in 2 x
2 contingency tables like Table 3, where tp stands for
&amp;quot;true positive&amp;quot; and fn for &amp;quot;false negative&amp;quot;.
Recall, fallout, precision, and f-measure were calcu-
lated in the following way for each category:
</bodyText>
<equation confidence="0.9967792">
tp / ( tp + fn )
fp / ( fp + tn )
tp / ( tp + fp )
2 * Recall * Precision
Recall + Precision
</equation>
<bodyText confidence="0.999276302325581">
Recall and fallout are often used in signal detection
analysis to calculate a measure called d’ (Green and
Swets 1966). Under this analysis, the performance of
the classifier is significantly more favorable than under
the F-measure, principally because the fallout, or false
alarm rate, is so low. Both in training and evaluation,
however, the data violate assumptions of normality that
d’ requires.
As explained in Section 3, a contribution classifica-
tion is the default when no other classification can be
given. As such, no training data was created for contri-
butions. Likewise frozen expressions were judged to be
essentially a closed class of phrases and do not require
training. Absence of training results for these categories
is represented by double stars in Table 4.
During the training process, the classifier was never
tested on unseen data. A number of factors it difficult to
obtain questions suitable for testing purposes. Brain-
stormed questions are an unreliable source of testing
data because they are not randomly sampled. In gen-
eral, corpora proved to be an unsatisfactory source of
questions due to low inter-rater reliability and skewed
distribution of categories.
Low inter-rater reliability often could be traced to
anaphora and pragmatic context. For example, the
question &amp;quot;Do you know what the concept of group cell
is?&amp;quot; might license a definition or verification, depending
on the common ground. &amp;quot;Do you know what it is?&amp;quot;
could equally license a number of categories, depending
on the referent of &amp;quot;it&amp;quot;. Such questions are clearly be-
yond the scope of a classifier that does not use context.
The skewed distribution of the question categories
and their infrequency necessitates use of an extraction
algorithm to locate them. Simply looking for question
marks is not enough: our estimates predict that raters
would need to classify more than 5,000 questions ex-
tracted from the Wall Street Journal this way to get a
mere 20 instances of the rarest types. A bootstrapping
approach using machine learning is a possible alterna-
tive that will be explored in the future (Abney 2002).
Regardless of these difficulties, the strongest evalua-
tion results from using the classifier in a real world task,
with real world data.
</bodyText>
<sectionHeader confidence="0.999324" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999952666666667">
The classifier was used in AutoTutor sessions through-
out the year of 2002. The log files from these sessions
contained 9094 student utterances, each of which was
classified by an expert. The expert ratings were com-
pared to the classifier&apos;s ratings, forming a 2 x 2 contin-
gency table for each category as in Table 4.
To expedite ratings, utterances extracted from the
log files were split into two groups, contributions and
non-contributions, according to their logged classifica-
tion. Expert judges were assigned to a group and in-
structed to classify a set of utterances to one of the 18
categories. Though inter-rater reliability using the
</bodyText>
<figure confidence="0.952942111111111">
Classifier
Expert
present ❑present
present
❑present
tp fp
fn tn
Recall =
Fallout =
</figure>
<table confidence="0.971644407407407">
Precision =
F-measure =
Training Data AutoTutor Performance
CATEGORY Recall Fallout Precision F-measure Recall Fallout Precision F-measure Likelihood Ratio
Contribution ** ** ** ** 0.983 0.054 0.999 0.991 1508.260
Frozen ** ** ** ** 0.899 0.002 0.849 0.873 978.810
Concept 0.844 0.035 0.761 0.800 0.857 0.003 0.444 0.585 235.800
Completion 0.545 0.009 0.545 0.545 0.550 0.000 0.917 0.688 135.360
Interpretation 0.667 0.002 0.941 0.780 0.424 0.001 0.583 0.491 131.770
Definition 0.969 0.004 0.969 0.969 0.520 0.004 0.255 0.342 103.880
Verification 0.955 0.011 0.778 0.857 1.000 0.004 0.132 0.233 55.460
Comparison 0.949 0.002 0.982 0.966 0.556 0.003 0.139 0.222 43.710
Quantification 0.833 0.010 0.833 0.833 1.000 0.000 0.667 0.800 33.870
Expecational 0.545 0.009 0.545 0.545 1.000 0.000 1.000 1.000 20.230
Procedural 0.926 0.006 0.893 0.909 1.000 0.001 0.143 0.250 14.490
Goal 0.842 0.010 0.865 0.853 0.500 0.001 0.167 0.250 12.050
Orientation 0.926 0.000 1.000 0.962 0.333 0.000 0.250 0.286 11.910
Judgmental 0.667 0.017 0.667 0.667 0.200 0.001 0.083 0.118 8.350*
Disjunction 0.824 0.006 0.824 0.824 0.000 0.000 0.000 0.000 0.000*
Causal 0.875 0.006 0.903 0.889 0.000 0.000 0.000 0.000 0.000*
Antecedent 0.811 0.008 0.882 0.845 0.000 0.000 0.000 0.000 0.000*
Feature 0.950 0.008 0.826 0.884 ** ** ** ** **
Specification
Enablement
Causal
Consequent
Example
</table>
<tableCaption confidence="0.999809">
Table 4. Training data and AutoTutor results.
</tableCaption>
<bodyText confidence="0.99998746875">
kappa statistic (Carletta 1996) may be calculated for
each group, the distribution of categories in the contri-
bution group was highly skewed and warrants further
discussion.
Skewed categories bias the kappa statistic to low
values even when the proportion of rater agreement is
very high (Feinstein and Cicchetti 1990a; Feinstein and
Cicchetti 1990b). In the contribution group, judges can
expect to see mostly one category, contribution,
whereas judges in the non-contribution group can ex-
pect to see the other 17 categories. Expected agreement
by chance for the contribution group was 98%. Corre-
spondingly, inter-rater reliability using the kappa statis-
tic was low for the contribution group, .5 despite 99%
proportion agreement, and high for non-contribution
group, .93.
However, the .93 inter-rater agreement can be ex-
tended to all of the utterance categories. Due to classi-
fier error, the non-contribution group consisted of 38%
contributions. Thus the .93 agreement applies to contri-
butions in this group. Equal proportion of agreement
for contribution classifications in both groups, 99%,
suggests that the differences in kappa solely reflect dif-
ferences in category skew across groups. Under this
analysis, dividing the utterances into two groups im-
proved the distribution of categories for the calculation
of kappa (Feinstein and Cicchetti 1990b).
Expert judges classified questions with a .93 kappa,
which supports a monothetic classification scheme for
this application. In Section 3 the possibility was raised
of a polythetic scheme for question classification, i.e.
one in which two categories could be assigned to a
given question. If a polythetic scheme were truly neces-
sary, one would expect inter-rater reliability to suffer in
a monothetic classification task. High inter-rater reli-
ability on the monothetic classification task renders
polythetic schemes superfluous for this application.
The recall column for evaluation in Table 4 is gener-
ally much higher than corresponding cells in the preci-
sion column. The disparity implies a high rate of false
positives for each of the categories. One possible ex-
planation is the reconstruction algorithm applied during
classification. It was observed that, particularly in the
language of physics, student used question stems in ut-
terances that were not questions, e.g. “The ball will land
when ...” Such falsely reconstructed questions account
for 40% of the questions detected by the classifier.
Whether modifying the reconstruction algorithm would
improve F-measure, i.e. improve precision without sac-
rificing recall, is a question for future research.
The distribution of categories is highly skewed: 97%
of the utterances were contributions, and example ques-
tions never occurred at all. In addition to recall, fallout,
precision, and F-measure, significance tests were calcu-
lated for each category&apos;s contingency table to insure that
the cells were statistically significant. Since most of the
categories had at least one cell with an expected value
of less than 1, Fisher&apos;s exact test is more appropriate for
significance testing than likelihood ratios or chi-square
(Pedersen 1996). Those categories that are not signifi-
cant are starred; all other categories are significant, p &lt;
.001.
Though not appropriate for hypothesis testing in this
instance, likelihood ratios provide a comparison of clas-
sifier performance across categories. Likelihood ratios
are particularly useful when comparing common and
rare events (Dunning 1993; Plaunt and Norgard 1998),
making them natural here given the rareness of most
question categories and the frequency of contributions.
The likelihood ratios in the rightmost column of Table 4
are on a natural logarithmic scale, -2lnλ, so procedural
at e . 5 x 20.23 = 24711 is more likely than goal orientation,
at e . 5 x 14.49 = 1401, with respect to the base rate, or null
hypothesis.
To judge overall performance on the AutoTutor ses-
sions, an average weighted F-measure may be calcu-
lated by summing the products of all category F-
measures with their frequencies:
The average weighted F-measure reflects real world
performance since accuracy on frequently occurring
classes is weighted more. The average weighted F-
measure for the evaluation data is .98, mostly due to the
great frequency of contributions (.97 of all utterances)
and the high associated F-measure. Without weighting,
the average F-measure for the significant cells is .54.
With respect to the three applications mentioned, i)
tracking student understanding, ii) mixed-initiative dia-
logue, and iii) questions answering, the classifier is do-
ing extremely well on the first two and adequately on
the last. The first two applications for the most part
require distinguishing questions from contributions,
which the classifier does extremely well, F-measure =
.99. Question answering, on the other hand, can benefit
from more precise identification of the question type,
and the average unweighted F-measure for the signifi-
cant questions is .48.
</bodyText>
<sectionHeader confidence="0.999286" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999948733333333">
One of the objectives of this work was to see how well a
classifier could perform with a minimum of resources.
Using no context and only surface features, the classi-
fier performed with an average weighted F-measure of
.98 on real world data.
However, the question remains how performance
will fare as rare questions become more frequent. Scaf-
folding student questions has become a hot topic re-
cently (Graesser et al. 2003). In a system that greatly
promotes question-asking, the weighted average of .97
will tend to drift closer to the unweighted average of
.54. Thus there is clearly more work to be done.
Future directions include using bootstrapping meth-
ods and statistical techniques on tutoring corpora and
using context to disambiguate question classification.
</bodyText>
<sectionHeader confidence="0.998118" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999831666666667">
This research was supported by the Office of Naval Re-
search (N00014-00-1-0600) and the National Science
Foundation (SBR 9720314 and REC 0106965). Any
opinions, findings, and conclusions or recommendations
expressed in this material are those of the authors and
do not necessarily reflect the views of ONR or NSF.
</bodyText>
<sectionHeader confidence="0.993723" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.322682903225807">
Abney, Steven. 2002. Bootstrapping. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, 360-367.
Allen, J.F. 1999. Mixed Initiative Interaction. Proc.
IEEE Intelligent Systems 14(6).
Austin, John. 1962. How to do things with words. Har-
vard University Press, Cambridge, MA.
Brill, Eric. 1995. Transformation-based error-driven
learning and natural language processing: a case study
in part-of-speech tagging. Computational Linguistics,
21(4), 543-566.
Brill, Eric, J. Lin, M. Banko, S. Dumais, and A. Ng.
2001. Data-intensive question answering. Proceed-
ings of the 10th Annual Text Retrieval Conference
(TREC-10).
Carletta, J. 1996. Assessing agreement on classification
tasks: the kappa statistic. Computational Linguistics,
22(2), 249-254.
Dunning, Ted. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics 19, 61-74.
Feinstein, Alvan R. and Domenic V. Cicchetti. 1990a.
High agreement but low kappa: the problems of two
paradoxes. Journal of Clinical Epidemiology, 43(6),
543-549.
Feinstein, Alvan R. and Domenic V. Cicchetti. 1990b.
High agreement but low kappa: II. resolving the para-
doxes. Journal of Clinical Epidemiology, 43(6), 551-
558.
Graesser, Arthur, John Burger, Jack Carroll, Albert Cor-
bett, Lisa Ferro, Douglas Gordon, Warren Greiff,
</reference>
<figure confidence="0.64822625">
∑ F −measure × tp +
N
Favg =
fn
</figure>
<reference confidence="0.997909257142858">
Sanda Harabagiu, Kay Howell, Henry Kelly, Diane
Litman, Max Louwerse, Allison Moore, Adrian Pell,
John Prange, Ellen Voorhees, and Wayne Ward.
2003. Question generation and answering systems,
R&amp;D for technology-enabled learning systems: re-
search roadmap. Unpublished manuscript.
Graesser, Arthur, Natalie Person, and John Huber. 1992.
Mechanisms that generate questions. In T. Lauer, E.
Peacock, and A. Graesser (Eds), Questions and infor-
mation systems. Earlbaum, Hillsdale, NJ.
Graesser, Arthur and Natalie Person. 1994. Question ask-
ing during tutoring. American Educational Research
Journal, 31(1), 104-137.
Graesser, Arthur, Natalie Person, and J.P. Magliano.
1995. Collaborative dialog patterns in naturalistic
one-on-one tutoring. Applied Cognitive Psychology,
9, 359-387.
Graesser, Arthur, Kurt van Lehn, Carolyn Rose, Pamela
Jordan, and Derek Harter. 2001. Intelligent tutoring
systems with conversational dialogue. AI Magazine
22(4), 39-52.
Graesser, Arthur, Peter Wiemer-Hastings, K. Wiemer-
Hastings, Roger Kreuz, and the TRG. 1999. AutoTu-
tor: A simulation of a human tutor. Journal of Cogni-
tive Systems Research 1, 35-51.
Green, David and John Swets. 1966. Signal detection
theory and psychophysics. John Wiley, New York.
Harabagiu, Sanda, D. Moldovan, M. Pasca, R. Mihalcea,
M. Surdeanu, R. Bunescu, R. Girju, V. Rus, and P.
Morarescu. 2000. FALCON: Boosting knowledge for
answer engines. In Proceedings of the 9th Text Re-
trieval Conference (TREC-9).
Jurafsky, Daniel and James Martin. 2000. Speech and
language processing. Prentice Hall, NJ.
Lehnert, Wendy. 1978. The Process of Question Answer-
ing. Lawrence Erlbaum Associates, Hillsdale, NJ.
McArthur, D., C. Stasz, and M. Zmuidzinas. 1990. Tu-
toring techniques in algebra. Cognition and Instruc-
tion, 7, 197-244.
Moldovan, Dan, Sanda Harabagiu, Marius Pasca, Rada
Mihalcea, Richard Goodrum, Roxana Girju, and
Vaslie Rus. 1999. Lasso: a tool for surfing the an-
swer net Proceedings of the 8th Annual Text Retrieval
Conference (TREC-8), 65-73.
Olney, Andrew, Natalie Person, Max Louwerse, and Ar-
thur Graesser. 2002. AutoTutor: a conversational tu-
toring environment. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, Demonstration Abstracts, 108-109.
Otero, J. and Arthur Graesser. 2001. PREG: Elements
of a model of question asking. Cognition &amp; Instruc-
tion 19, 143-175.
Paice, C.D. 1990. Another stemmer. SIGIR Forum 24 (3),
56-61.
Pedersen, Ted. 1996. Fishing for exactness. In Proceed-
ings of the South-Central SAS Users Group Confer-
ence, Austin, TX.
Person, Natalie and Arthur Graesser. 1999. Evolution
of discourse in cross-age tutoring. In A.M.
O’Donnell and A. King (Eds.), Cognitive perspec-
tives on peer learning (pp. 69-86). Erlbaum, Mah-
wah, NJ.
Person, Natalie, Arthur Graesser, L. Bautista, E.C.
Mathews, and the Tutoring Research Group 2001.
Evaluating student learning gains in two versions of
AutoTutor. In J. D. Moore, C. L. Redfield, and W. L.
Johnson (Eds.) Artificial intelligence in education:
AI-ED in the wired and wireless future (pp. 286-
293). IOS Press, Amsterdam.
Person, Natalie, Arthur Graesser, Derek Harter, E. C.
Mathews, and the Tutoring Research Group (2000).
Dialog move generation and conversation manage-
ment in AutoTutor. Proceedings for the AAAI Fall
Symposium Series: Building Dialogue Systems for
Tutorial Applications. Falmouth, Massachusetts.
Plaunt, Christian and Barbara Norgard. 1998. An asso-
ciation-based method for automatic indexing with a
controlled vocabulary. Journal of the American Soci-
ety of Information Science, 49(10), 888-902.
Putnam, R. T. 1987. Structuring and adjusting content
for students: A study of live and simulated tutoring
of addition. American Educational Research Jour-
nal, 24, 13-48.
Searle, John. 1975. A taxonomy of illocutionary acts. In
K. Gunderson, (Ed.), Language, mind, and knowl-
edge. University of Minnesota Press, Minneapolis,
MN.
Sekine, S. and R. Grishman. 1995. A corpus-based
probabilistic grammar with only two nonterminals.
Fourth International Workshop on Parsing Technol-
ogy.
Soubbotin, M. M., and S. M. Soubbotin. 2002. Patterns
of potential answer expressions as clues to the right
answers. Proceedings of the 10th Annual Text Re-
trieval Conference (TREC-10).
Srihari, Rohini and Wei Li. 2000. A question answering
system supported by information extraction. Pro-
ceedings of the 6th Applied Natural Language Proc-
essing Conference (ANLP-2000), 166-172.
Van Dijk, T. A., and W. Kintsch. 1983. Strategies of dis-
course comprehension. New York: Academic.
Voorhees, Ellen. 2001. Overview of the TREC 2001
question answering track. Proceedings of the 10th
Annual Text Retrieval Conference (TREC-10), 400-
410.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.490126">
<title confidence="0.999909">Utterance Classification in AutoTutor</title>
<author confidence="0.999346">Andrew Max Eric Johanna Heather Arthur</author>
<affiliation confidence="0.931758666666667">Olney Louwerse Matthews Marineau Hite-Mitchell Graesser Institute for Intelligent University of</affiliation>
<address confidence="0.655298">Memphis, TN</address>
<email confidence="0.998777">aolney@memphis.edu</email>
<abstract confidence="0.995061666666667">This paper describes classification of typed student utterances within AutoTutor, an intelligent tutoring system. Utterances are classified to one of 18 categories, including 16 question categories. The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules. Shallow NLP is well suited to the task: session log file analysis reveals significant classification of eleven question categories, frozen expressions, and assertions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<date>2002</date>
<booktitle>Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>360--367</pages>
<contexts>
<context position="20437" citStr="Abney 2002" startWordPosition="3145" endWordPosition="3146">ries, depending on the referent of &amp;quot;it&amp;quot;. Such questions are clearly beyond the scope of a classifier that does not use context. The skewed distribution of the question categories and their infrequency necessitates use of an extraction algorithm to locate them. Simply looking for question marks is not enough: our estimates predict that raters would need to classify more than 5,000 questions extracted from the Wall Street Journal this way to get a mere 20 instances of the rarest types. A bootstrapping approach using machine learning is a possible alternative that will be explored in the future (Abney 2002). Regardless of these difficulties, the strongest evaluation results from using the classifier in a real world task, with real world data. 6 Evaluation The classifier was used in AutoTutor sessions throughout the year of 2002. The log files from these sessions contained 9094 student utterances, each of which was classified by an expert. The expert ratings were compared to the classifier&apos;s ratings, forming a 2 x 2 contingency table for each category as in Table 4. To expedite ratings, utterances extracted from the log files were split into two groups, contributions and non-contributions, accord</context>
</contexts>
<marker>Abney, 2002</marker>
<rawString>Abney, Steven. 2002. Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, 360-367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Mixed Initiative Interaction.</title>
<date>1999</date>
<booktitle>Proc. IEEE Intelligent Systems</booktitle>
<volume>14</volume>
<issue>6</issue>
<contexts>
<context position="2348" citStr="Allen 1999" startWordPosition="345" endWordPosition="346">tions at all, is predicted by PREG to not have a situation-level understanding (van Dijk and Kintsch 1983) and thus to learn less and forget faster. The key point is that different metrics for tracking student understanding are applicable to questions and contributions. Distinguishing them via classification is a first step to applying a metric. In mixed-initiative dialog systems, utterance classification can be used to detect shifts in initiative. For example, a mixed-initiative system that asks, &amp;quot;Where would you like to travel&amp;quot;, could respond to the question, &amp;quot;Where can I travel for $200?&amp;quot; (Allen 1999) by giving a list of cities. In this example, the user is taking the initiative by requesting more information. In order to respond properly, the system must detect that the user has taken initiative before it can respond appropriately; otherwise it might try to interpret the user&apos;s utterance as a travel destination. In this sense, questions mark redirection of the dialogue, whereas contributions are continuations of the dialogue. In order for a user to redirect the dialogue and thus exercise initiative, a mixed-initiative system must be able to distinguish questions and contributions. Questio</context>
</contexts>
<marker>Allen, 1999</marker>
<rawString>Allen, J.F. 1999. Mixed Initiative Interaction. Proc. IEEE Intelligent Systems 14(6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Austin</author>
</authors>
<title>How to do things with words.</title>
<date>1962</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="9546" citStr="Austin, 1962" startWordPosition="1456" endWordPosition="1457">ow what gravity is.&amp;quot; In AutoTutor these information seeking utterances are classified to one of the 16 question categories. The emphases on queried concepts rather than orthographic forms make the categories listed in Table 1 bear a strong resemblance to speech acts. Indeed, Graesser et al. (1992) propose that the categories be distinguished in precisely the same way as speech acts, using semantic, conceptual, and pragmatic criteria as opposed to syntactic and lexical criteria. Speech acts presumably transcend these surface criteria: it is not what is being said as what is done by the saying (Austin, 1962; Searle, 1975). Category Example Questions Verification Disjunctive Concept Completion Feature Specification Quantification Definition Example Comparison Interpretation Causal Antecedent Causal Consequence Goal Orientation Instrumental/Procedural Enablement Expectational Judgmental Frozen Expressions Metacognitive Metacommunicative Does the pumpkin land in his hands? Is the pumpkin accelerating or decelerating? Where will the pumpkin land? What are the components of the forces acting on the pumpkin? How far will the pumpkin travel? What is acceleration? What is an example of Newton&apos;s Third La</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>Austin, John. 1962. How to do things with words. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>543--566</pages>
<contexts>
<context position="4173" citStr="Brill 1995" startWordPosition="638" endWordPosition="639">nation of question types as opposed to only distinguishing questions from contributions. AutoTutor uses utterance classification to track student progress, to determine initiative, and to answer questions. By virtue of being embedded in AutoTutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical. On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real time. For that reason, the classifier uses a minimum of resources, including part of speech tagging (Brill 1995; Sekine and Grishman 1995) and cascaded finite state transducers defining the categories. Theoretically speaking, AutoTutor must also recognize questions in a meaningful way to both question answering and tutoring. The question taxonomy utilized, that of Graesser et al (1992), is an extension of Lehnert&apos;s (1978) taxonomy for question answering and has been applied to human tutoring (Graesser et al. 1992; Graesser and Person 1994). This paper outlines the utterance classifier and quantifies its performance. In particular, Section 2 presents AutoTutor. Section 3 presents the utterance taxonomy.</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill, Eric. 1995. Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging. Computational Linguistics, 21(4), 543-566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>J Lin</author>
<author>M Banko</author>
<author>S Dumais</author>
<author>A Ng</author>
</authors>
<title>Data-intensive question answering.</title>
<date>2001</date>
<booktitle>Proceedings of the 10th Annual Text Retrieval Conference (TREC-10).</booktitle>
<contexts>
<context position="3462" citStr="Brill et al. 2001" startWordPosition="529" endWordPosition="532">e initiative, a mixed-initiative system must be able to distinguish questions and contributions. Question classification as early as Lehnert (1978) has been used as a basis for answering questions, a trend that continues today (Voorhees 2001). A common feature of these question-answering systems is that they first determine the expected answer type implicit in the question. For example, &amp;quot;How much does a pretzel cost&amp;quot; might be classified according to the answer type of MONEY or QUANTITY. Knowledge of the expected answer type can be used to narrow the search space for the answer, either online (Brill et al. 2001) or in a database (Harabagiu et al. 2000). Accordingly, question answering calls for a finer discrimination of question types as opposed to only distinguishing questions from contributions. AutoTutor uses utterance classification to track student progress, to determine initiative, and to answer questions. By virtue of being embedded in AutoTutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical. On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real </context>
</contexts>
<marker>Brill, Lin, Banko, Dumais, Ng, 2001</marker>
<rawString>Brill, Eric, J. Lin, M. Banko, S. Dumais, and A. Ng. 2001. Data-intensive question answering. Proceedings of the 10th Annual Text Retrieval Conference (TREC-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: the kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>249--254</pages>
<contexts>
<context position="22747" citStr="Carletta 1996" startWordPosition="3504" endWordPosition="3505">6 0.006 0.893 0.909 1.000 0.001 0.143 0.250 14.490 Goal 0.842 0.010 0.865 0.853 0.500 0.001 0.167 0.250 12.050 Orientation 0.926 0.000 1.000 0.962 0.333 0.000 0.250 0.286 11.910 Judgmental 0.667 0.017 0.667 0.667 0.200 0.001 0.083 0.118 8.350* Disjunction 0.824 0.006 0.824 0.824 0.000 0.000 0.000 0.000 0.000* Causal 0.875 0.006 0.903 0.889 0.000 0.000 0.000 0.000 0.000* Antecedent 0.811 0.008 0.882 0.845 0.000 0.000 0.000 0.000 0.000* Feature 0.950 0.008 0.826 0.884 ** ** ** ** ** Specification Enablement Causal Consequent Example Table 4. Training data and AutoTutor results. kappa statistic (Carletta 1996) may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion. Skewed categories bias the kappa statistic to low values even when the proportion of rater agreement is very high (Feinstein and Cicchetti 1990a; Feinstein and Cicchetti 1990b). In the contribution group, judges can expect to see mostly one category, contribution, whereas judges in the non-contribution group can expect to see the other 17 categories. Expected agreement by chance for the contribution group was 98%. Correspondingly, inter-rater reliabilit</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Carletta, J. 1996. Assessing agreement on classification tasks: the kappa statistic. Computational Linguistics, 22(2), 249-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>61--74</pages>
<contexts>
<context position="26209" citStr="Dunning 1993" startWordPosition="4025" endWordPosition="4026">e to insure that the cells were statistically significant. Since most of the categories had at least one cell with an expected value of less than 1, Fisher&apos;s exact test is more appropriate for significance testing than likelihood ratios or chi-square (Pedersen 1996). Those categories that are not significant are starred; all other categories are significant, p &lt; .001. Though not appropriate for hypothesis testing in this instance, likelihood ratios provide a comparison of classifier performance across categories. Likelihood ratios are particularly useful when comparing common and rare events (Dunning 1993; Plaunt and Norgard 1998), making them natural here given the rareness of most question categories and the frequency of contributions. The likelihood ratios in the rightmost column of Table 4 are on a natural logarithmic scale, -2lnλ, so procedural at e . 5 x 20.23 = 24711 is more likely than goal orientation, at e . 5 x 14.49 = 1401, with respect to the base rate, or null hypothesis. To judge overall performance on the AutoTutor sessions, an average weighted F-measure may be calculated by summing the products of all category Fmeasures with their frequencies: The average weighted F-measure re</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, Ted. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics 19, 61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvan R Feinstein</author>
<author>Domenic V Cicchetti</author>
</authors>
<title>High agreement but low kappa: the problems of two paradoxes.</title>
<date>1990</date>
<journal>Journal of Clinical Epidemiology,</journal>
<volume>43</volume>
<issue>6</issue>
<pages>543--549</pages>
<contexts>
<context position="23033" citStr="Feinstein and Cicchetti 1990" startWordPosition="3547" endWordPosition="3550">4 0.824 0.000 0.000 0.000 0.000 0.000* Causal 0.875 0.006 0.903 0.889 0.000 0.000 0.000 0.000 0.000* Antecedent 0.811 0.008 0.882 0.845 0.000 0.000 0.000 0.000 0.000* Feature 0.950 0.008 0.826 0.884 ** ** ** ** ** Specification Enablement Causal Consequent Example Table 4. Training data and AutoTutor results. kappa statistic (Carletta 1996) may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion. Skewed categories bias the kappa statistic to low values even when the proportion of rater agreement is very high (Feinstein and Cicchetti 1990a; Feinstein and Cicchetti 1990b). In the contribution group, judges can expect to see mostly one category, contribution, whereas judges in the non-contribution group can expect to see the other 17 categories. Expected agreement by chance for the contribution group was 98%. Correspondingly, inter-rater reliability using the kappa statistic was low for the contribution group, .5 despite 99% proportion agreement, and high for non-contribution group, .93. However, the .93 inter-rater agreement can be extended to all of the utterance categories. Due to classifier error, the non-contribution group </context>
</contexts>
<marker>Feinstein, Cicchetti, 1990</marker>
<rawString>Feinstein, Alvan R. and Domenic V. Cicchetti. 1990a. High agreement but low kappa: the problems of two paradoxes. Journal of Clinical Epidemiology, 43(6), 543-549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvan R Feinstein</author>
<author>Domenic V Cicchetti</author>
</authors>
<title>High agreement but low kappa: II. resolving the paradoxes.</title>
<date>1990</date>
<journal>Journal of Clinical Epidemiology,</journal>
<volume>43</volume>
<issue>6</issue>
<pages>551--558</pages>
<contexts>
<context position="23033" citStr="Feinstein and Cicchetti 1990" startWordPosition="3547" endWordPosition="3550">4 0.824 0.000 0.000 0.000 0.000 0.000* Causal 0.875 0.006 0.903 0.889 0.000 0.000 0.000 0.000 0.000* Antecedent 0.811 0.008 0.882 0.845 0.000 0.000 0.000 0.000 0.000* Feature 0.950 0.008 0.826 0.884 ** ** ** ** ** Specification Enablement Causal Consequent Example Table 4. Training data and AutoTutor results. kappa statistic (Carletta 1996) may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion. Skewed categories bias the kappa statistic to low values even when the proportion of rater agreement is very high (Feinstein and Cicchetti 1990a; Feinstein and Cicchetti 1990b). In the contribution group, judges can expect to see mostly one category, contribution, whereas judges in the non-contribution group can expect to see the other 17 categories. Expected agreement by chance for the contribution group was 98%. Correspondingly, inter-rater reliability using the kappa statistic was low for the contribution group, .5 despite 99% proportion agreement, and high for non-contribution group, .93. However, the .93 inter-rater agreement can be extended to all of the utterance categories. Due to classifier error, the non-contribution group </context>
</contexts>
<marker>Feinstein, Cicchetti, 1990</marker>
<rawString>Feinstein, Alvan R. and Domenic V. Cicchetti. 1990b. High agreement but low kappa: II. resolving the paradoxes. Journal of Clinical Epidemiology, 43(6), 551-558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>John Burger</author>
<author>Jack Carroll</author>
<author>Albert Corbett</author>
<author>Lisa Ferro</author>
<author>Douglas Gordon</author>
<author>Warren Greiff</author>
<author>Sanda Harabagiu</author>
<author>Kay Howell</author>
<author>Henry Kelly</author>
<author>Diane Litman</author>
<author>Max Louwerse</author>
</authors>
<title>Question generation and answering systems, R&amp;D for technology-enabled learning systems: research roadmap.</title>
<date>2003</date>
<location>Allison Moore, Adrian Pell, John Prange, Ellen Voorhees, and</location>
<note>Unpublished manuscript.</note>
<contexts>
<context position="28154" citStr="Graesser et al. 2003" startWordPosition="4337" endWordPosition="4340">.99. Question answering, on the other hand, can benefit from more precise identification of the question type, and the average unweighted F-measure for the significant questions is .48. 7 Conclusion One of the objectives of this work was to see how well a classifier could perform with a minimum of resources. Using no context and only surface features, the classifier performed with an average weighted F-measure of .98 on real world data. However, the question remains how performance will fare as rare questions become more frequent. Scaffolding student questions has become a hot topic recently (Graesser et al. 2003). In a system that greatly promotes question-asking, the weighted average of .97 will tend to drift closer to the unweighted average of .54. Thus there is clearly more work to be done. Future directions include using bootstrapping methods and statistical techniques on tutoring corpora and using context to disambiguate question classification. 8 Acknowledgements This research was supported by the Office of Naval Research (N00014-00-1-0600) and the National Science Foundation (SBR 9720314 and REC 0106965). Any opinions, findings, and conclusions or recommendations expressed in this material are </context>
</contexts>
<marker>Graesser, Burger, Carroll, Corbett, Ferro, Gordon, Greiff, Harabagiu, Howell, Kelly, Litman, Louwerse, 2003</marker>
<rawString>Graesser, Arthur, John Burger, Jack Carroll, Albert Corbett, Lisa Ferro, Douglas Gordon, Warren Greiff, Sanda Harabagiu, Kay Howell, Henry Kelly, Diane Litman, Max Louwerse, Allison Moore, Adrian Pell, John Prange, Ellen Voorhees, and Wayne Ward. 2003. Question generation and answering systems, R&amp;D for technology-enabled learning systems: research roadmap. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Natalie Person</author>
<author>John Huber</author>
</authors>
<title>Mechanisms that generate questions. In</title>
<date>1992</date>
<location>Earlbaum, Hillsdale, NJ.</location>
<contexts>
<context position="4450" citStr="Graesser et al (1992)" startWordPosition="676" endWordPosition="679">sifier presented here has an unusual set of constraints, both practical and theoretical. On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real time. For that reason, the classifier uses a minimum of resources, including part of speech tagging (Brill 1995; Sekine and Grishman 1995) and cascaded finite state transducers defining the categories. Theoretically speaking, AutoTutor must also recognize questions in a meaningful way to both question answering and tutoring. The question taxonomy utilized, that of Graesser et al (1992), is an extension of Lehnert&apos;s (1978) taxonomy for question answering and has been applied to human tutoring (Graesser et al. 1992; Graesser and Person 1994). This paper outlines the utterance classifier and quantifies its performance. In particular, Section 2 presents AutoTutor. Section 3 presents the utterance taxonomy. Section 4 describes the classifier algorithm. Section 5 delineates the training process and results. Section 6 presents evaluation of the classifier on real AutoTutor sessions. Section 7 concludes the paper. 2 AutoTutor AutoTutor is an ITS applicable to any content domain. Tw</context>
<context position="8125" citStr="Graesser et al. 1992" startWordPosition="1228" endWordPosition="1231"> is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to taxonomies in the cognitive sciences (Graesser et al. 1992; Graesser and Person 1994). The most notable system within this framework is QUALM (Lehnert 1978), which utilizes twelve of the question categories. The taxonomy can be divided into 3 distinct groups, questions, frozen expressions, and contributions. Each of these will be discussed in turn. The conceptual basis of the question categories arises from the observation that the same question may be asked in different ways, e.g. &amp;quot;What happened?&amp;quot; and &amp;quot;How did this happen?&amp;quot; Correspondingly, a single lexical stem for a question, like &amp;quot;What&amp;quot; can be polysemous, e.g. both in a definition category, &amp;quot;What</context>
<context position="11676" citStr="Graesser et al. 1992" startWordPosition="1769" endWordPosition="1772">urface-based classification, using no context. It is particularly pertinent to the present discussion that the sixteen qualitative categories are employed in a quantitative classification process. That is to say that for the present purposes of classification, a question must belong to one and only one category. On the one hand this idealization is necessary to obtain easily analyzed performance data and to create a well-balanced training corpus. On the other hand, it is not entirely accurate because some questions may be assigned to multiple categories, suggesting a polythetic coding scheme (Graesser et al. 1992). Inter-rater reliability is used in the current study as a benchmark to gauge this potential effect. Frozen expressions consist of metacognitive and metacommunicative utterances. Metacognitive utterances describe the cognitive state of the student, and they therefore require a different response than questions or assertions. AutoTutor responds to metacognitive utterances with canned expressions such as, &amp;quot;Why don&apos;t you give me what you know, and we&apos;ll take it from there.&amp;quot; Metacommunicative acts likewise refer to the dialogue between tutor and student, often calling for a repetition of the tuto</context>
</contexts>
<marker>Graesser, Person, Huber, 1992</marker>
<rawString>Graesser, Arthur, Natalie Person, and John Huber. 1992. Mechanisms that generate questions. In T. Lauer, E. Peacock, and A. Graesser (Eds), Questions and information systems. Earlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Natalie Person</author>
</authors>
<title>Question asking during tutoring.</title>
<date>1994</date>
<journal>American Educational Research Journal,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>104--137</pages>
<contexts>
<context position="4607" citStr="Graesser and Person 1994" startWordPosition="701" endWordPosition="704"> performs in real time; thus utterance classification must also proceed in real time. For that reason, the classifier uses a minimum of resources, including part of speech tagging (Brill 1995; Sekine and Grishman 1995) and cascaded finite state transducers defining the categories. Theoretically speaking, AutoTutor must also recognize questions in a meaningful way to both question answering and tutoring. The question taxonomy utilized, that of Graesser et al (1992), is an extension of Lehnert&apos;s (1978) taxonomy for question answering and has been applied to human tutoring (Graesser et al. 1992; Graesser and Person 1994). This paper outlines the utterance classifier and quantifies its performance. In particular, Section 2 presents AutoTutor. Section 3 presents the utterance taxonomy. Section 4 describes the classifier algorithm. Section 5 delineates the training process and results. Section 6 presents evaluation of the classifier on real AutoTutor sessions. Section 7 concludes the paper. 2 AutoTutor AutoTutor is an ITS applicable to any content domain. Two distinct domain applications of AutoTutor are available on the Internet, for computer literacy and conceptual physics. The computer literacy AutoTutor, whi</context>
<context position="6569" citStr="Graesser and Person 1994" startWordPosition="991" endWordPosition="994">ssifier, (4) latent semantic analysis (LSA), (5) a dialog move generator, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, parsed (Sekine and Grishman 1995) and sent through a rule-based utterance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the st</context>
<context position="7923" citStr="Graesser and Person 1994" startWordPosition="1196" endWordPosition="1199">og move generator selects one or a combination of specific dialog moves that is both conversationally and pedagogically appropriate (Person et al 2000; Person et al. 2001). The Dialog Advancer Network (DAN) is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to taxonomies in the cognitive sciences (Graesser et al. 1992; Graesser and Person 1994). The most notable system within this framework is QUALM (Lehnert 1978), which utilizes twelve of the question categories. The taxonomy can be divided into 3 distinct groups, questions, frozen expressions, and contributions. Each of these will be discussed in turn. The conceptual basis of the question categories arises from the observation that the same question may be</context>
</contexts>
<marker>Graesser, Person, 1994</marker>
<rawString>Graesser, Arthur and Natalie Person. 1994. Question asking during tutoring. American Educational Research Journal, 31(1), 104-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Natalie Person</author>
<author>J P Magliano</author>
</authors>
<title>Collaborative dialog patterns in naturalistic one-on-one tutoring.</title>
<date>1995</date>
<journal>Applied Cognitive Psychology,</journal>
<volume>9</volume>
<pages>359--387</pages>
<contexts>
<context position="6591" citStr="Graesser et al. 1995" startWordPosition="995" endWordPosition="998">ic analysis (LSA), (5) a dialog move generator, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, parsed (Sekine and Grishman 1995) and sent through a rule-based utterance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, t</context>
<context position="7945" citStr="Graesser et al. 1995" startWordPosition="1200" endWordPosition="1203">one or a combination of specific dialog moves that is both conversationally and pedagogically appropriate (Person et al 2000; Person et al. 2001). The Dialog Advancer Network (DAN) is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to taxonomies in the cognitive sciences (Graesser et al. 1992; Graesser and Person 1994). The most notable system within this framework is QUALM (Lehnert 1978), which utilizes twelve of the question categories. The taxonomy can be divided into 3 distinct groups, questions, frozen expressions, and contributions. Each of these will be discussed in turn. The conceptual basis of the question categories arises from the observation that the same question may be asked in different wa</context>
</contexts>
<marker>Graesser, Person, Magliano, 1995</marker>
<rawString>Graesser, Arthur, Natalie Person, and J.P. Magliano. 1995. Collaborative dialog patterns in naturalistic one-on-one tutoring. Applied Cognitive Psychology, 9, 359-387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Kurt van Lehn</author>
<author>Carolyn Rose</author>
<author>Pamela Jordan</author>
<author>Derek Harter</author>
</authors>
<title>Intelligent tutoring systems with conversational dialogue.</title>
<date>2001</date>
<journal>AI Magazine</journal>
<volume>22</volume>
<issue>4</issue>
<pages>39--52</pages>
<marker>Graesser, van Lehn, Rose, Jordan, Harter, 2001</marker>
<rawString>Graesser, Arthur, Kurt van Lehn, Carolyn Rose, Pamela Jordan, and Derek Harter. 2001. Intelligent tutoring systems with conversational dialogue. AI Magazine 22(4), 39-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Peter Wiemer-Hastings</author>
<author>K WiemerHastings</author>
<author>Roger Kreuz</author>
<author>the TRG</author>
</authors>
<title>AutoTutor: A simulation of a human tutor.</title>
<date>1999</date>
<journal>Journal of Cognitive Systems Research</journal>
<volume>1</volume>
<pages>35--51</pages>
<contexts>
<context position="895" citStr="Graesser et al. 1999" startWordPosition="116" endWordPosition="119">yped student utterances within AutoTutor, an intelligent tutoring system. Utterances are classified to one of 18 categories, including 16 question categories. The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules. Shallow NLP is well suited to the task: session log file analysis reveals significant classification of eleven question categories, frozen expressions, and assertions. 1 Introduction AutoTutor is a domain-portable intelligent tutoring system (ITS) with current versions in the domains of physics and computer literacy (Graesser et al. 1999; Olney et al. 2002). AutoTutor, like many other ITSs, is an intersection of applications, including tutoring, mixed-initiative dialogue, and question answering. In each of these, utterance classification, particularly question classification, plays a critical role. In tutoring, utterance classification can be used to track the student&apos;s level of understanding. Contribution and question classifications can both play a role: contributions may be compared to an expected answer (Graesser et al. 2001) and questions may be scored by how &amp;quot;deep&amp;quot; they are. For example, The PREG model (Otero and Graess</context>
</contexts>
<marker>Graesser, Wiemer-Hastings, WiemerHastings, Kreuz, TRG, 1999</marker>
<rawString>Graesser, Arthur, Peter Wiemer-Hastings, K. WiemerHastings, Roger Kreuz, and the TRG. 1999. AutoTutor: A simulation of a human tutor. Journal of Cognitive Systems Research 1, 35-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Green</author>
<author>John Swets</author>
</authors>
<title>Signal detection theory and psychophysics.</title>
<date>1966</date>
<publisher>John Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="18456" citStr="Green and Swets 1966" startWordPosition="2825" endWordPosition="2828">ategories when they occurred more than once or were judged highly diagnostic. Table 3. Contingency Table. The results of the training process are shown in Table 4. Results from each category were compiled in 2 x 2 contingency tables like Table 3, where tp stands for &amp;quot;true positive&amp;quot; and fn for &amp;quot;false negative&amp;quot;. Recall, fallout, precision, and f-measure were calculated in the following way for each category: tp / ( tp + fn ) fp / ( fp + tn ) tp / ( tp + fp ) 2 * Recall * Precision Recall + Precision Recall and fallout are often used in signal detection analysis to calculate a measure called d’ (Green and Swets 1966). Under this analysis, the performance of the classifier is significantly more favorable than under the F-measure, principally because the fallout, or false alarm rate, is so low. Both in training and evaluation, however, the data violate assumptions of normality that d’ requires. As explained in Section 3, a contribution classification is the default when no other classification can be given. As such, no training data was created for contributions. Likewise frozen expressions were judged to be essentially a closed class of phrases and do not require training. Absence of training results for t</context>
</contexts>
<marker>Green, Swets, 1966</marker>
<rawString>Green, David and John Swets. 1966. Signal detection theory and psychophysics. John Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>D Moldovan</author>
<author>M Pasca</author>
<author>R Mihalcea</author>
<author>M Surdeanu</author>
<author>R Bunescu</author>
<author>R Girju</author>
<author>V Rus</author>
<author>P Morarescu</author>
</authors>
<title>FALCON: Boosting knowledge for answer engines.</title>
<date>2000</date>
<booktitle>In Proceedings of the 9th Text Retrieval Conference (TREC-9).</booktitle>
<contexts>
<context position="3503" citStr="Harabagiu et al. 2000" startWordPosition="537" endWordPosition="540">em must be able to distinguish questions and contributions. Question classification as early as Lehnert (1978) has been used as a basis for answering questions, a trend that continues today (Voorhees 2001). A common feature of these question-answering systems is that they first determine the expected answer type implicit in the question. For example, &amp;quot;How much does a pretzel cost&amp;quot; might be classified according to the answer type of MONEY or QUANTITY. Knowledge of the expected answer type can be used to narrow the search space for the answer, either online (Brill et al. 2001) or in a database (Harabagiu et al. 2000). Accordingly, question answering calls for a finer discrimination of question types as opposed to only distinguishing questions from contributions. AutoTutor uses utterance classification to track student progress, to determine initiative, and to answer questions. By virtue of being embedded in AutoTutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical. On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real time. For that reason, the classifier use</context>
</contexts>
<marker>Harabagiu, Moldovan, Pasca, Mihalcea, Surdeanu, Bunescu, Girju, Rus, Morarescu, 2000</marker>
<rawString>Harabagiu, Sanda, D. Moldovan, M. Pasca, R. Mihalcea, M. Surdeanu, R. Bunescu, R. Girju, V. Rus, and P. Morarescu. 2000. FALCON: Boosting knowledge for answer engines. In Proceedings of the 9th Text Retrieval Conference (TREC-9).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James Martin</author>
</authors>
<title>Speech and language processing.</title>
<date>2000</date>
<publisher>Prentice Hall, NJ.</publisher>
<contexts>
<context position="10835" citStr="Jurafsky and Martin (2000)" startWordPosition="1641" endWordPosition="1644">appening in this situation with the runner and pumpkin? What caused the pumpkin to fall? What happens when the runner speeds up? Why did you ignore air resistance? How do you calculate force? What principle allows you to ignore the vertical component of the force? Why doesn&apos;t the pumpkin land behind the runner? What do you think of my explanation? I don&apos;t understand. Could you repeat that? Contribution The pumpkin will land in the runner&apos;s hands Table 1. AutoTutor’s utterance taxonomy. The close relation to speech acts underscores what a difficult task classifying conceptual questions can be. Jurafsky and Martin (2000) describe the problem of interpreting speech acts using pragmatic and semantic inference as AI-complete, i.e. impossible without creating a full artificial intelligence. The alternative explored in this paper is cue or surface-based classification, using no context. It is particularly pertinent to the present discussion that the sixteen qualitative categories are employed in a quantitative classification process. That is to say that for the present purposes of classification, a question must belong to one and only one category. On the one hand this idealization is necessary to obtain easily an</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel and James Martin. 2000. Speech and language processing. Prentice Hall, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy Lehnert</author>
</authors>
<title>The Process of Question Answering. Lawrence Erlbaum Associates,</title>
<date>1978</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="2991" citStr="Lehnert (1978)" startWordPosition="450" endWordPosition="451">In this example, the user is taking the initiative by requesting more information. In order to respond properly, the system must detect that the user has taken initiative before it can respond appropriately; otherwise it might try to interpret the user&apos;s utterance as a travel destination. In this sense, questions mark redirection of the dialogue, whereas contributions are continuations of the dialogue. In order for a user to redirect the dialogue and thus exercise initiative, a mixed-initiative system must be able to distinguish questions and contributions. Question classification as early as Lehnert (1978) has been used as a basis for answering questions, a trend that continues today (Voorhees 2001). A common feature of these question-answering systems is that they first determine the expected answer type implicit in the question. For example, &amp;quot;How much does a pretzel cost&amp;quot; might be classified according to the answer type of MONEY or QUANTITY. Knowledge of the expected answer type can be used to narrow the search space for the answer, either online (Brill et al. 2001) or in a database (Harabagiu et al. 2000). Accordingly, question answering calls for a finer discrimination of question types as </context>
<context position="8223" citStr="Lehnert 1978" startWordPosition="1245" endWordPosition="1246">assifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to taxonomies in the cognitive sciences (Graesser et al. 1992; Graesser and Person 1994). The most notable system within this framework is QUALM (Lehnert 1978), which utilizes twelve of the question categories. The taxonomy can be divided into 3 distinct groups, questions, frozen expressions, and contributions. Each of these will be discussed in turn. The conceptual basis of the question categories arises from the observation that the same question may be asked in different ways, e.g. &amp;quot;What happened?&amp;quot; and &amp;quot;How did this happen?&amp;quot; Correspondingly, a single lexical stem for a question, like &amp;quot;What&amp;quot; can be polysemous, e.g. both in a definition category, &amp;quot;What is the definition of gravity?&amp;quot; and metacommunicative, &amp;quot;What did you say?&amp;quot; Furthermore, implicit q</context>
</contexts>
<marker>Lehnert, 1978</marker>
<rawString>Lehnert, Wendy. 1978. The Process of Question Answering. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McArthur</author>
<author>C Stasz</author>
<author>M Zmuidzinas</author>
</authors>
<title>Tutoring techniques in algebra.</title>
<date>1990</date>
<journal>Cognition and Instruction,</journal>
<volume>7</volume>
<pages>197--244</pages>
<contexts>
<context position="6613" citStr="McArthur et al. 1990" startWordPosition="999" endWordPosition="1002"> a dialog move generator, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, parsed (Sekine and Grishman 1995) and sent through a rule-based utterance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, the LSA module evaluate</context>
</contexts>
<marker>McArthur, Stasz, Zmuidzinas, 1990</marker>
<rawString>McArthur, D., C. Stasz, and M. Zmuidzinas. 1990. Tutoring techniques in algebra. Cognition and Instruction, 7, 197-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Sanda Harabagiu</author>
<author>Marius Pasca</author>
<author>Rada Mihalcea</author>
<author>Richard Goodrum</author>
<author>Roxana Girju</author>
<author>Vaslie Rus</author>
</authors>
<title>Lasso: a tool for surfing the answer net</title>
<date>1999</date>
<booktitle>Proceedings of the 8th Annual Text Retrieval Conference (TREC-8),</booktitle>
<pages>65--73</pages>
<contexts>
<context position="13226" citStr="Moldovan et al 1999" startWordPosition="2006" endWordPosition="2009">ppropriately a question. Contributions in the taxonomy can be viewed as anything that is not frozen or a question; in fact, that is essentially how the classifier works. Contributions in AutoTutor, either as responses to questions or unprompted, are tracked to evaluate student performance via LSA, forming the basis for feedback. 4 Classifier Algorithm The present approach ignores the semantic and pragmatic context of the questions, and utilizes surface features to classify questions. This shallow approach parallels work in question answering (Srihari and Li 2000; Soubbotin and Soubbotin 2002; Moldovan et al 1999). Specifically, the classifier uses tagging provided by ApplePie (Sekine and Grishman 1995) followed by cascaded finite state transducers defining the categories. The finite state transducers are roughly described in Table 2. Every transducer is given a chance to match, and a disambiguation routine is applied at the end to select a single category. Immediately after tagging, transducers are applied to check for frozen expressions. A frozen expression must match, and the utterance must be free of any nouns, i.e. not frozen+content, for the utterance to be classified as frozen. Next the utteranc</context>
</contexts>
<marker>Moldovan, Harabagiu, Pasca, Mihalcea, Goodrum, Girju, Rus, 1999</marker>
<rawString>Moldovan, Dan, Sanda Harabagiu, Marius Pasca, Rada Mihalcea, Richard Goodrum, Roxana Girju, and Vaslie Rus. 1999. Lasso: a tool for surfing the answer net Proceedings of the 8th Annual Text Retrieval Conference (TREC-8), 65-73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Olney</author>
<author>Natalie Person</author>
<author>Max Louwerse</author>
<author>Arthur Graesser</author>
</authors>
<title>AutoTutor: a conversational tutoring environment.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Demonstration Abstracts,</booktitle>
<pages>108--109</pages>
<contexts>
<context position="915" citStr="Olney et al. 2002" startWordPosition="120" endWordPosition="123">s within AutoTutor, an intelligent tutoring system. Utterances are classified to one of 18 categories, including 16 question categories. The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules. Shallow NLP is well suited to the task: session log file analysis reveals significant classification of eleven question categories, frozen expressions, and assertions. 1 Introduction AutoTutor is a domain-portable intelligent tutoring system (ITS) with current versions in the domains of physics and computer literacy (Graesser et al. 1999; Olney et al. 2002). AutoTutor, like many other ITSs, is an intersection of applications, including tutoring, mixed-initiative dialogue, and question answering. In each of these, utterance classification, particularly question classification, plays a critical role. In tutoring, utterance classification can be used to track the student&apos;s level of understanding. Contribution and question classifications can both play a role: contributions may be compared to an expected answer (Graesser et al. 2001) and questions may be scored by how &amp;quot;deep&amp;quot; they are. For example, The PREG model (Otero and Graesser 2001) predicts un</context>
</contexts>
<marker>Olney, Person, Louwerse, Graesser, 2002</marker>
<rawString>Olney, Andrew, Natalie Person, Max Louwerse, and Arthur Graesser. 2002. AutoTutor: a conversational tutoring environment. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Demonstration Abstracts, 108-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Otero</author>
<author>Arthur Graesser</author>
</authors>
<title>PREG: Elements of a model of question asking.</title>
<date>2001</date>
<journal>Cognition &amp; Instruction</journal>
<volume>19</volume>
<pages>143--175</pages>
<contexts>
<context position="1503" citStr="Otero and Graesser 2001" startWordPosition="206" endWordPosition="209">sser et al. 1999; Olney et al. 2002). AutoTutor, like many other ITSs, is an intersection of applications, including tutoring, mixed-initiative dialogue, and question answering. In each of these, utterance classification, particularly question classification, plays a critical role. In tutoring, utterance classification can be used to track the student&apos;s level of understanding. Contribution and question classifications can both play a role: contributions may be compared to an expected answer (Graesser et al. 2001) and questions may be scored by how &amp;quot;deep&amp;quot; they are. For example, The PREG model (Otero and Graesser 2001) predicts under what circumstances students will ask &amp;quot;deep&amp;quot; questions, i.e. those that reveal a greater level of cognitive processing than who, what, when, or where questions. A student who is only asking shallow questions, or no questions at all, is predicted by PREG to not have a situation-level understanding (van Dijk and Kintsch 1983) and thus to learn less and forget faster. The key point is that different metrics for tracking student understanding are applicable to questions and contributions. Distinguishing them via classification is a first step to applying a metric. In mixed-initiativ</context>
</contexts>
<marker>Otero, Graesser, 2001</marker>
<rawString>Otero, J. and Arthur Graesser. 2001. PREG: Elements of a model of question asking. Cognition &amp; Instruction 19, 143-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
</authors>
<title>Another stemmer.</title>
<date>1990</date>
<journal>SIGIR Forum</journal>
<volume>24</volume>
<issue>3</issue>
<pages>56--61</pages>
<contexts>
<context position="16800" citStr="Paice 1990" startWordPosition="2549" endWordPosition="2550">w) ... keyword Expectational ^Why AUX ... NEG Judgmental (should|keyword) (N|PRO) (you|your) ... keyword Frozen (no nouns) ^SUBJPRO ... keyword ^VB ... keyword ... OBJPRO ^AUX ... SUBJPRO ... keyword Contribution Everything else Table 2. Finite state transducer patterns ordering of transducers affects which symbols are closest to the beginning of the list. Ordering is particularly relevant when considering categories like concept completion, which match more freely than other categories. Ordering gives rarer and stricter categories a chance to match first; this strategy is common in stemming (Paice 1990). 5 Training The classifier was built by hand in a cyclical process of inspecting questions, inducing rules, and testing the results. The training data was derived from brainstorming sessions whose goal was to generate questions as lexically and syntactically distinct as possible. Of the brainstormed questions, only when all five raters agreed on the category was a question used for training; this approach filtered out polythetic questions and left only archetypes. Intuitive analysis suggested that the majority of questions have at most a two-part pattern consisting of a syntactic template and</context>
</contexts>
<marker>Paice, 1990</marker>
<rawString>Paice, C.D. 1990. Another stemmer. SIGIR Forum 24 (3), 56-61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Fishing for exactness.</title>
<date>1996</date>
<booktitle>In Proceedings of the South-Central SAS Users Group Conference,</booktitle>
<location>Austin, TX.</location>
<contexts>
<context position="25863" citStr="Pedersen 1996" startWordPosition="3975" endWordPosition="3976">. improve precision without sacrificing recall, is a question for future research. The distribution of categories is highly skewed: 97% of the utterances were contributions, and example questions never occurred at all. In addition to recall, fallout, precision, and F-measure, significance tests were calculated for each category&apos;s contingency table to insure that the cells were statistically significant. Since most of the categories had at least one cell with an expected value of less than 1, Fisher&apos;s exact test is more appropriate for significance testing than likelihood ratios or chi-square (Pedersen 1996). Those categories that are not significant are starred; all other categories are significant, p &lt; .001. Though not appropriate for hypothesis testing in this instance, likelihood ratios provide a comparison of classifier performance across categories. Likelihood ratios are particularly useful when comparing common and rare events (Dunning 1993; Plaunt and Norgard 1998), making them natural here given the rareness of most question categories and the frequency of contributions. The likelihood ratios in the rightmost column of Table 4 are on a natural logarithmic scale, -2lnλ, so procedural at e</context>
</contexts>
<marker>Pedersen, 1996</marker>
<rawString>Pedersen, Ted. 1996. Fishing for exactness. In Proceedings of the South-Central SAS Users Group Conference, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie Person</author>
<author>Arthur Graesser</author>
</authors>
<title>Evolution of discourse in cross-age tutoring.</title>
<date>1999</date>
<booktitle>In A.M. O’Donnell</booktitle>
<pages>69--86</pages>
<location>Erlbaum, Mahwah, NJ.</location>
<contexts>
<context position="7972" citStr="Person and Graesser 1999" startWordPosition="1204" endWordPosition="1207">f specific dialog moves that is both conversationally and pedagogically appropriate (Person et al 2000; Person et al. 2001). The Dialog Advancer Network (DAN) is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to taxonomies in the cognitive sciences (Graesser et al. 1992; Graesser and Person 1994). The most notable system within this framework is QUALM (Lehnert 1978), which utilizes twelve of the question categories. The taxonomy can be divided into 3 distinct groups, questions, frozen expressions, and contributions. Each of these will be discussed in turn. The conceptual basis of the question categories arises from the observation that the same question may be asked in different ways, e.g. &amp;quot;What happened?&amp;quot; a</context>
</contexts>
<marker>Person, Graesser, 1999</marker>
<rawString>Person, Natalie and Arthur Graesser. 1999. Evolution of discourse in cross-age tutoring. In A.M. O’Donnell and A. King (Eds.), Cognitive perspectives on peer learning (pp. 69-86). Erlbaum, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie Person</author>
<author>Arthur Graesser</author>
<author>L Bautista</author>
<author>E C Mathews</author>
</authors>
<title>and the Tutoring Research Group</title>
<date>2001</date>
<pages>286--293</pages>
<publisher>IOS Press,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="5649" citStr="Person et al. 2001" startWordPosition="857" endWordPosition="860">y content domain. Two distinct domain applications of AutoTutor are available on the Internet, for computer literacy and conceptual physics. The computer literacy AutoTutor, which has now been used in experimental evaluations by over 200 students, tutors students on core computer literacy topics covered in an introductory course, such as operating systems, the Internet, and hardware. The topics covered by the physics AutoTutor are grounded in basic Newtonian mechanics and are of a similar introductory nature. It has been well documented that AutoTutor promotes learning gains in both versions (Person et al. 2001). AutoTutor simulates the dialog patterns and pedagogical strategies of human tutors in a conversational interface that supports mixed-initiative dialog. AutoTutor’s architecture is comprised of seven highly modular components: (1) an animated agent, (2) a curriculum script, (3) a speech act classifier, (4) latent semantic analysis (LSA), (5) a dialog move generator, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins wi</context>
<context position="7470" citStr="Person et al. 2001" startWordPosition="1128" endWordPosition="1131"> The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, the LSA module evaluates the quality of the student contributions, and in the tutor-initiative mode, the dialog move generator selects one or a combination of specific dialog moves that is both conversationally and pedagogically appropriate (Person et al 2000; Person et al. 2001). The Dialog Advancer Network (DAN) is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table 1 is familiar to tax</context>
</contexts>
<marker>Person, Graesser, Bautista, Mathews, 2001</marker>
<rawString>Person, Natalie, Arthur Graesser, L. Bautista, E.C. Mathews, and the Tutoring Research Group 2001. Evaluating student learning gains in two versions of AutoTutor. In J. D. Moore, C. L. Redfield, and W. L. Johnson (Eds.) Artificial intelligence in education: AI-ED in the wired and wireless future (pp. 286-293). IOS Press, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie Person</author>
<author>Arthur Graesser</author>
<author>Derek Harter</author>
<author>E C Mathews</author>
</authors>
<title>and the Tutoring Research Group</title>
<date>2000</date>
<location>Falmouth, Massachusetts.</location>
<contexts>
<context position="6169" citStr="Person et al. 2000" startWordPosition="937" endWordPosition="940"> been well documented that AutoTutor promotes learning gains in both versions (Person et al. 2001). AutoTutor simulates the dialog patterns and pedagogical strategies of human tutors in a conversational interface that supports mixed-initiative dialog. AutoTutor’s architecture is comprised of seven highly modular components: (1) an animated agent, (2) a curriculum script, (3) a speech act classifier, (4) latent semantic analysis (LSA), (5) a dialog move generator, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, par</context>
<context position="7449" citStr="Person et al 2000" startWordPosition="1124" endWordPosition="1127">terance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, the LSA module evaluates the quality of the student contributions, and in the tutor-initiative mode, the dialog move generator selects one or a combination of specific dialog moves that is both conversationally and pedagogically appropriate (Person et al 2000; Person et al. 2001). The Dialog Advancer Network (DAN) is the intermediary of dialog move generation in all instances, using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers. The dialog move generator selects the actual move. There are twelve types of dialog move: Pump, Hint, Splice, Prompt, Prompt Response, Elaboration, Summary, and five forms of immediate short-feedback (Graesser and Person 1994; Graesser et al. 1995; Person and Graesser 1999). 3 An utterance taxonomy The framework for utterance classification in Table</context>
</contexts>
<marker>Person, Graesser, Harter, Mathews, 2000</marker>
<rawString>Person, Natalie, Arthur Graesser, Derek Harter, E. C. Mathews, and the Tutoring Research Group (2000). Dialog move generation and conversation management in AutoTutor. Proceedings for the AAAI Fall Symposium Series: Building Dialogue Systems for Tutorial Applications. Falmouth, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Plaunt</author>
<author>Barbara Norgard</author>
</authors>
<title>An association-based method for automatic indexing with a controlled vocabulary.</title>
<date>1998</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>49</volume>
<issue>10</issue>
<pages>888--902</pages>
<contexts>
<context position="26235" citStr="Plaunt and Norgard 1998" startWordPosition="4027" endWordPosition="4030">at the cells were statistically significant. Since most of the categories had at least one cell with an expected value of less than 1, Fisher&apos;s exact test is more appropriate for significance testing than likelihood ratios or chi-square (Pedersen 1996). Those categories that are not significant are starred; all other categories are significant, p &lt; .001. Though not appropriate for hypothesis testing in this instance, likelihood ratios provide a comparison of classifier performance across categories. Likelihood ratios are particularly useful when comparing common and rare events (Dunning 1993; Plaunt and Norgard 1998), making them natural here given the rareness of most question categories and the frequency of contributions. The likelihood ratios in the rightmost column of Table 4 are on a natural logarithmic scale, -2lnλ, so procedural at e . 5 x 20.23 = 24711 is more likely than goal orientation, at e . 5 x 14.49 = 1401, with respect to the base rate, or null hypothesis. To judge overall performance on the AutoTutor sessions, an average weighted F-measure may be calculated by summing the products of all category Fmeasures with their frequencies: The average weighted F-measure reflects real world performa</context>
</contexts>
<marker>Plaunt, Norgard, 1998</marker>
<rawString>Plaunt, Christian and Barbara Norgard. 1998. An association-based method for automatic indexing with a controlled vocabulary. Journal of the American Society of Information Science, 49(10), 888-902.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R T Putnam</author>
</authors>
<title>Structuring and adjusting content for students: A study of live and simulated tutoring of addition.</title>
<date>1987</date>
<journal>American Educational Research Journal,</journal>
<volume>24</volume>
<pages>13--48</pages>
<contexts>
<context position="6627" citStr="Putnam 1987" startWordPosition="1003" endWordPosition="1004">or, (6) a Dialog Advancer Network, and (7) a question-answering tool (Graesser et al. 1998; Graesser et al. 2001; Graesser et al. 2001; Person et al. 2000; Person et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, parsed (Sekine and Grishman 1995) and sent through a rule-based utterance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, the LSA module evaluates the quality </context>
</contexts>
<marker>Putnam, 1987</marker>
<rawString>Putnam, R. T. 1987. Structuring and adjusting content for students: A study of live and simulated tutoring of addition. American Educational Research Journal, 24, 13-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Searle</author>
</authors>
<title>A taxonomy of illocutionary acts. In</title>
<date>1975</date>
<editor>K. Gunderson, (Ed.),</editor>
<institution>University of Minnesota Press,</institution>
<location>Minneapolis, MN.</location>
<contexts>
<context position="9561" citStr="Searle, 1975" startWordPosition="1458" endWordPosition="1459">y is.&amp;quot; In AutoTutor these information seeking utterances are classified to one of the 16 question categories. The emphases on queried concepts rather than orthographic forms make the categories listed in Table 1 bear a strong resemblance to speech acts. Indeed, Graesser et al. (1992) propose that the categories be distinguished in precisely the same way as speech acts, using semantic, conceptual, and pragmatic criteria as opposed to syntactic and lexical criteria. Speech acts presumably transcend these surface criteria: it is not what is being said as what is done by the saying (Austin, 1962; Searle, 1975). Category Example Questions Verification Disjunctive Concept Completion Feature Specification Quantification Definition Example Comparison Interpretation Causal Antecedent Causal Consequence Goal Orientation Instrumental/Procedural Enablement Expectational Judgmental Frozen Expressions Metacognitive Metacommunicative Does the pumpkin land in his hands? Is the pumpkin accelerating or decelerating? Where will the pumpkin land? What are the components of the forces acting on the pumpkin? How far will the pumpkin travel? What is acceleration? What is an example of Newton&apos;s Third Law? What is the </context>
</contexts>
<marker>Searle, 1975</marker>
<rawString>Searle, John. 1975. A taxonomy of illocutionary acts. In K. Gunderson, (Ed.), Language, mind, and knowledge. University of Minnesota Press, Minneapolis, MN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
<author>R Grishman</author>
</authors>
<title>A corpus-based probabilistic grammar with only two nonterminals.</title>
<date>1995</date>
<booktitle>Fourth International Workshop on Parsing Technology.</booktitle>
<contexts>
<context position="4200" citStr="Sekine and Grishman 1995" startWordPosition="640" endWordPosition="643">estion types as opposed to only distinguishing questions from contributions. AutoTutor uses utterance classification to track student progress, to determine initiative, and to answer questions. By virtue of being embedded in AutoTutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical. On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real time. For that reason, the classifier uses a minimum of resources, including part of speech tagging (Brill 1995; Sekine and Grishman 1995) and cascaded finite state transducers defining the categories. Theoretically speaking, AutoTutor must also recognize questions in a meaningful way to both question answering and tutoring. The question taxonomy utilized, that of Graesser et al (1992), is an extension of Lehnert&apos;s (1978) taxonomy for question answering and has been applied to human tutoring (Graesser et al. 1992; Graesser and Person 1994). This paper outlines the utterance classifier and quantifies its performance. In particular, Section 2 presents AutoTutor. Section 3 presents the utterance taxonomy. Section 4 describes the cl</context>
<context position="6799" citStr="Sekine and Grishman 1995" startWordPosition="1028" endWordPosition="1031">son et al. 2001; Wiemer-Hastings et al. 1998). A tutoring session begins with a brief introduction from AutoTutor’s three-dimensional animated agent. AutoTutor then asks the student a question from one of topics in the curriculum script. The curriculum script contains lesson-specific tutor-initiated dialog, including important concepts, questions, cases, and problems (Graesser and Person 1994; Graesser et al. 1995; McArthur et al. 1990; Putnam 1987). The student submits a response to the question by typing and pressing the “Submit” button. The student’s contribution is then segmented, parsed (Sekine and Grishman 1995) and sent through a rule-based utterance classifier. The classification process makes use of only the contribution text and part-of-speech tag provided by the parser. Mixed-initiative dialog starts with utterance classification and ends with dialog move generation, which can include question answering, repeating the question for the student, or just encouraging the student. Concurrently, the LSA module evaluates the quality of the student contributions, and in the tutor-initiative mode, the dialog move generator selects one or a combination of specific dialog moves that is both conversationall</context>
<context position="13317" citStr="Sekine and Grishman 1995" startWordPosition="2018" endWordPosition="2021">is not frozen or a question; in fact, that is essentially how the classifier works. Contributions in AutoTutor, either as responses to questions or unprompted, are tracked to evaluate student performance via LSA, forming the basis for feedback. 4 Classifier Algorithm The present approach ignores the semantic and pragmatic context of the questions, and utilizes surface features to classify questions. This shallow approach parallels work in question answering (Srihari and Li 2000; Soubbotin and Soubbotin 2002; Moldovan et al 1999). Specifically, the classifier uses tagging provided by ApplePie (Sekine and Grishman 1995) followed by cascaded finite state transducers defining the categories. The finite state transducers are roughly described in Table 2. Every transducer is given a chance to match, and a disambiguation routine is applied at the end to select a single category. Immediately after tagging, transducers are applied to check for frozen expressions. A frozen expression must match, and the utterance must be free of any nouns, i.e. not frozen+content, for the utterance to be classified as frozen. Next the utterance is checked for question stems, e.g. WHAT, HOW, WHY, etc. and question mark punctuation. I</context>
</contexts>
<marker>Sekine, Grishman, 1995</marker>
<rawString>Sekine, S. and R. Grishman. 1995. A corpus-based probabilistic grammar with only two nonterminals. Fourth International Workshop on Parsing Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M M Soubbotin</author>
<author>S M Soubbotin</author>
</authors>
<title>Patterns of potential answer expressions as clues to the right answers.</title>
<date>2002</date>
<booktitle>Proceedings of the 10th Annual Text Retrieval Conference (TREC-10).</booktitle>
<contexts>
<context position="13204" citStr="Soubbotin and Soubbotin 2002" startWordPosition="2002" endWordPosition="2005">nderstand gravity&amp;quot; is a more appropriately a question. Contributions in the taxonomy can be viewed as anything that is not frozen or a question; in fact, that is essentially how the classifier works. Contributions in AutoTutor, either as responses to questions or unprompted, are tracked to evaluate student performance via LSA, forming the basis for feedback. 4 Classifier Algorithm The present approach ignores the semantic and pragmatic context of the questions, and utilizes surface features to classify questions. This shallow approach parallels work in question answering (Srihari and Li 2000; Soubbotin and Soubbotin 2002; Moldovan et al 1999). Specifically, the classifier uses tagging provided by ApplePie (Sekine and Grishman 1995) followed by cascaded finite state transducers defining the categories. The finite state transducers are roughly described in Table 2. Every transducer is given a chance to match, and a disambiguation routine is applied at the end to select a single category. Immediately after tagging, transducers are applied to check for frozen expressions. A frozen expression must match, and the utterance must be free of any nouns, i.e. not frozen+content, for the utterance to be classified as fro</context>
</contexts>
<marker>Soubbotin, Soubbotin, 2002</marker>
<rawString>Soubbotin, M. M., and S. M. Soubbotin. 2002. Patterns of potential answer expressions as clues to the right answers. Proceedings of the 10th Annual Text Retrieval Conference (TREC-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohini Srihari</author>
<author>Wei Li</author>
</authors>
<title>A question answering system supported by information extraction.</title>
<date>2000</date>
<booktitle>Proceedings of the 6th Applied Natural Language Processing Conference (ANLP-2000),</booktitle>
<pages>166--172</pages>
<contexts>
<context position="13174" citStr="Srihari and Li 2000" startWordPosition="1998" endWordPosition="2001">rozen, but &amp;quot;I don&apos;t understand gravity&amp;quot; is a more appropriately a question. Contributions in the taxonomy can be viewed as anything that is not frozen or a question; in fact, that is essentially how the classifier works. Contributions in AutoTutor, either as responses to questions or unprompted, are tracked to evaluate student performance via LSA, forming the basis for feedback. 4 Classifier Algorithm The present approach ignores the semantic and pragmatic context of the questions, and utilizes surface features to classify questions. This shallow approach parallels work in question answering (Srihari and Li 2000; Soubbotin and Soubbotin 2002; Moldovan et al 1999). Specifically, the classifier uses tagging provided by ApplePie (Sekine and Grishman 1995) followed by cascaded finite state transducers defining the categories. The finite state transducers are roughly described in Table 2. Every transducer is given a chance to match, and a disambiguation routine is applied at the end to select a single category. Immediately after tagging, transducers are applied to check for frozen expressions. A frozen expression must match, and the utterance must be free of any nouns, i.e. not frozen+content, for the utt</context>
</contexts>
<marker>Srihari, Li, 2000</marker>
<rawString>Srihari, Rohini and Wei Li. 2000. A question answering system supported by information extraction. Proceedings of the 6th Applied Natural Language Processing Conference (ANLP-2000), 166-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T A Van Dijk</author>
<author>W Kintsch</author>
</authors>
<title>Strategies of discourse comprehension.</title>
<date>1983</date>
<publisher>Academic.</publisher>
<location>New York:</location>
<marker>Van Dijk, Kintsch, 1983</marker>
<rawString>Van Dijk, T. A., and W. Kintsch. 1983. Strategies of discourse comprehension. New York: Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Voorhees</author>
</authors>
<title>Overview of the TREC</title>
<date>2001</date>
<booktitle>Proceedings of the 10th Annual Text Retrieval Conference (TREC-10),</booktitle>
<pages>400--410</pages>
<contexts>
<context position="3086" citStr="Voorhees 2001" startWordPosition="466" endWordPosition="467">respond properly, the system must detect that the user has taken initiative before it can respond appropriately; otherwise it might try to interpret the user&apos;s utterance as a travel destination. In this sense, questions mark redirection of the dialogue, whereas contributions are continuations of the dialogue. In order for a user to redirect the dialogue and thus exercise initiative, a mixed-initiative system must be able to distinguish questions and contributions. Question classification as early as Lehnert (1978) has been used as a basis for answering questions, a trend that continues today (Voorhees 2001). A common feature of these question-answering systems is that they first determine the expected answer type implicit in the question. For example, &amp;quot;How much does a pretzel cost&amp;quot; might be classified according to the answer type of MONEY or QUANTITY. Knowledge of the expected answer type can be used to narrow the search space for the answer, either online (Brill et al. 2001) or in a database (Harabagiu et al. 2000). Accordingly, question answering calls for a finer discrimination of question types as opposed to only distinguishing questions from contributions. AutoTutor uses utterance classific</context>
</contexts>
<marker>Voorhees, 2001</marker>
<rawString>Voorhees, Ellen. 2001. Overview of the TREC 2001 question answering track. Proceedings of the 10th Annual Text Retrieval Conference (TREC-10), 400-410.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>