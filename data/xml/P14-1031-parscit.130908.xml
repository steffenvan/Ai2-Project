<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009189">
<title confidence="0.9995275">
Context-aware Learning for Sentence-level Sentiment Analysis
with Posterior Regularization
</title>
<author confidence="0.99793">
Bishan Yang
</author>
<affiliation confidence="0.994475">
Department of Computer Science
Cornell University
</affiliation>
<email confidence="0.998387">
bishan@cs.cornell.edu
</email>
<sectionHeader confidence="0.993885" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998504">
This paper proposes a novel context-aware
method for analyzing sentiment at the
level of individual sentences. Most ex-
isting machine learning approaches suf-
fer from limitations in the modeling of
complex linguistic structures across sen-
tences and often fail to capture non-
local contextual cues that are important
for sentiment interpretation. In contrast,
our approach allows structured modeling
of sentiment while taking into account
both local and global contextual infor-
mation. Specifically, we encode intu-
itive lexical and discourse knowledge as
expressive constraints and integrate them
into the learning of conditional random
field models via posterior regularization.
The context-aware constraints provide ad-
ditional power to the CRF model and can
guide semi-supervised learning when la-
beled data is limited. Experiments on
standard product review datasets show that
our method outperforms the state-of-the-
art methods in both the supervised and
semi-supervised settings.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99980375">
The ability to extract sentiment from text is cru-
cial for many opinion-mining applications such as
opinion summarization, opinion question answer-
ing and opinion retrieval. Accordingly, extract-
ing sentiment at the fine-grained level (e.g. at the
sentence- or phrase-level) has received increasing
attention recently due to its challenging nature and
its importance in supporting these opinion analysis
tasks (Pang and Lee, 2008).
In this paper, we focus on the task of sentence-
level sentiment classification in online reviews.
Typical approaches to the task employ supervised
</bodyText>
<author confidence="0.677159">
Claire Cardie
</author>
<affiliation confidence="0.985787">
Department of Computer Science
Cornell University
</affiliation>
<email confidence="0.989671">
cardie@cs.cornell.edu
</email>
<bodyText confidence="0.9998651">
machine learning algorithms with rich features
and take into account the interactions between
words to handle compositional effects such as po-
larity reversal (e.g. (Nakagawa et al., 2010;
Socher et al., 2013)). Still, their methods can en-
counter difficulty when the sentence on its own
does not contain strong enough sentiment signals
(due to the lack of statistical evidence or the re-
quirement for background knowledge). Consider
the following review for example,
</bodyText>
<figureCaption confidence="0.801664">
1. Hearing the music in real stereo is a true reve-
lation. 2. You can feel that the music is no longer
constrained by the mono recording. 3. In fact, it
is more like the players are performing on a stage
in front of you ...
</figureCaption>
<bodyText confidence="0.98617608">
Existing feature-based classifiers may be effective
in identifying the positive sentiment of the first
sentence due to the use of the word revelation,
but they could be less effective in the last two sen-
tences due to the lack of explicit sentiment signals.
However, if we examine these sentences within the
discourse context, we can see that: the second sen-
tence expresses sentiment towards the same aspect
– the music – as the first sentence; the third sen-
tence expands the second sentence with the dis-
course connective In fact. These discourse-level
relations help indicate that sentence 2 and 3 are
likely to have positive sentiment as well.
The importance of discourse for sentiment anal-
ysis has become increasingly recognized. Most
existing work considers discourse relations be-
tween adjacent sentences or clauses and incor-
porates them as constraints (Kanayama and Na-
sukawa, 2006; Zhou et al., 2011) or features in
classifiers Trivedi and Eisenstein (2013; Lazari-
dou et al. (2013). Very little work has explored
long-distance discourse relations for sentiment
analysis. Somasundaran et al. (2008) defines
coreference relations on opinion targets and ap-
plies them to constrain the polarity of sentences.
</bodyText>
<page confidence="0.984025">
325
</page>
<note confidence="0.8309385">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999987769230769">
However, the discourse relations were obtained
from fine-grained annotations and implemented as
hard constraints on polarity.
Obtaining sentiment labels at the fine-grained
level is costly. Semi-supervised techniques have
been proposed for sentence-level sentiment classi-
fication (T¨ackstr¨om and McDonald, 2011a; Qu et
al., 2012). However, they rely on a large amount
of document-level sentiment labels that may not
be naturally available in many domains.
In this paper, we propose a sentence-level senti-
ment classification method that can (1) incorporate
rich discourse information at both local and global
levels; (2) encode discourse knowledge as soft
constraints during learning; (3) make use of un-
labeled data to enhance learning. Specifically, we
use the Conditional Random Field (CRF) model
as the learner for sentence-level sentiment classi-
fication, and incorporate rich discourse and lexi-
cal knowledge as soft constraints into the learn-
ing of CRF parameters via Posterior Regulariza-
tion (PR) (Ganchev et al., 2010). As a framework
for structured learning with constraints, PR has
been successfully applied to many structural NLP
tasks (Ganchev et al., 2009; Ganchev et al., 2010;
Ganchev and Das, 2013). Our work is the first to
explore PR for sentiment analysis. Unlike most
previous work, we explore a rich set of structural
constraints that cannot be naturally encoded in the
feature-label form, and show that such constraints
can improve the performance of the CRF model.
We evaluate our approach on the sentence-
level sentiment classification task using two stan-
dard product review datasets. Experimental re-
sults show that our model outperforms state-of-
the-art methods in both the supervised and semi-
supervised settings. We also show that dis-
course knowledge is highly useful for improving
sentence-level sentiment classification.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999722737704918">
There has been a large amount of work on sen-
timent analysis at various levels of granular-
ity (Pang and Lee, 2008). In this paper, we focus
on the study of sentence-level sentiment classifi-
cation. Existing machine learning approaches for
the task can be classified based on the use of two
ideas. The first idea is to exploit sentiment sig-
nals at the sentence level by learning the relevance
of sentiment and words while taking into account
the context in which they occur: Nakagawa et
al. (2010) uses tree-CRF to model word interac-
tions based on dependency tree structures; Choi
and Cardie (2008) applies compositional inference
rules to handle polarity reversal; Socher et al.
(2011) and Socher et al. (2013) compute composi-
tional vector representations for words and phrases
and use them as features in a classifier.
The second idea is to exploit sentiment signals
at the inter-sentential level. Polanyi and Zaenen
(2006) argue that discourse structure is important
in polarity classification. Various attempts have
been made to incorporate discourse relations into
sentiment analysis: Pang and Lee (2004) explored
the consistency of subjectivity between neighbor-
ing sentences; Mao and Lebanon (2007),McDon-
ald et al. (2007), and T¨ackstr¨om and McDonald
(2011a) developed structured learning models to
capture sentiment dependencies between adjacent
sentences; Kanayama and Nasukawa (2006) and
Zhou et al. (2011) use discourse relations to con-
strain two text segments to have either the same
polarity or opposite polarities; Trivedi and Eisen-
stein (2013) and Lazaridou et al. (2013) encode
the discourse connectors as model features in su-
pervised classifiers. Very little work has explored
long-distance discourse relations. Somasundaran
et al. (2008) define opinion target relations and ap-
ply them to constrain the polarity of text segments
annotated with target relations. Recently, Zhang
et al. (2013) explored the use of explanatory dis-
course relations as soft constraints in a Markov
Logic Network framework for extracting subjec-
tive text segments.
Leveraging both ideas, our approach exploits
sentiment signals from both intra-sentential and
inter-sentential context. It has the advantages of
utilizing rich discourse knowledge at different lev-
els of context and encoding it as soft constraints
during learning.
Our approach is also semi-supervised. Com-
pared to the existing work on semi-supervised
learning for sentence-level sentiment classification
(T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om and
McDonald, 2011b; Qu et al., 2012), our work
does not rely on a large amount of coarse-grained
(document-level) labeled data, instead, distant
supervision mainly comes from linguistically-
motivated constraints.
Our work also relates to the study of posterior
regularization (PR) (Ganchev et al., 2010). PR has
been successfully applied to many structured NLP
</bodyText>
<page confidence="0.99844">
326
</page>
<bodyText confidence="0.999929636363636">
tasks such as dependency parsing, information ex-
traction and cross-lingual learning tasks (Ganchev
et al., 2009; Bellare et al., 2009; Ganchev et al.,
2010; Ganchev and Das, 2013). Most previous
work using PR mainly experiments with feature-
label constraints. In contrast, we explore a rich
set of linguistically-motivated constraints which
cannot be naturally formulated in the feature-label
form. We also show that constraints derived from
the discourse context can be highly useful for dis-
ambiguating sentence-level sentiment.
</bodyText>
<sectionHeader confidence="0.994042" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999981388888889">
In this section, we present the details of our pro-
posed approach. We formulate the sentence-level
sentiment classification task as a sequence label-
ing problem. The inputs to the model are sentence-
segmented documents annotated with sentence-
level sentiment labels (positive, negative or neu-
tral) along with a set of unlabeled documents.
During prediction, the model outputs sentiment la-
bels for a sequence of sentences in the test docu-
ment. We utilize conditional random fields and use
Posterior Regularization (PR) to learn their param-
eters with a rich set of context-aware constraints.
In what follows, we first briefly describe the
framework of Posterior Regularization. Then we
introduce the context-aware constraints derived
based on intuitive discourse and lexical knowl-
edge. Finally we describe how to perform learning
and inference with these constraints.
</bodyText>
<subsectionHeader confidence="0.998941">
3.1 Posterior Regularization
</subsectionHeader>
<bodyText confidence="0.99960725">
PR is a framework for structured learning with
constraints (Ganchev et al., 2010). In this work,
we apply PR in the context of CRFs for sentence-
level sentiment classification.
Denote x as a sequence of sentences within a
document and y as a vector of sentiment labels
associated with x. The CRF model the following
conditional probabilities:
</bodyText>
<equation confidence="0.997992">
exp(θ · f(x, y))
pθ(y|x) =
Zθ(x)
</equation>
<bodyText confidence="0.995897833333333">
where f(x, y) are the model features, θ are the
model parameters, and Zθ(x) = Ey exp(θ ·
f(x, y)) is a normalization constant. The objec-
tive function for a standard CRF is to maximize
the log-likelihood over a collection of labeled doc-
uments plus a regularization term:
</bodyText>
<equation confidence="0.949967">
log pθ(y|x) − ||θ||2 2
2δ2
</equation>
<bodyText confidence="0.9991944">
PR makes the assumption that the labeled data
we have is not enough for learning good model
parameters, but we have a set of constraints on the
posterior distribution of the labels. We can define
the set of desirable posterior distrbutions as
</bodyText>
<equation confidence="0.993618">
2 = {q(Y) : Eq[φ(X,Y)] = b} (1)
</equation>
<bodyText confidence="0.999898923076923">
where φ is a constraint function, b is a vector of
desired values of the expectations of the constraint
functions under the distribution q 1. Note that the
distribution q is defined over a collection of un-
labeled documents where the constraint functions
apply, and we assume independence between doc-
uments.
The PR objective can be written as the origi-
nal model objective penalized with a regulariza-
tion term, which minimizes the KL-divergence be-
tween the desired model posteriors and the learned
model posteriors with an L2 penalty 2 for the con-
straint violations.
</bodyText>
<equation confidence="0.956341666666667">
{KL(q(Y)||pθ(Y|X))
(2)
+ β||Eq[φ(X, Y)] − b||22}
</equation>
<bodyText confidence="0.999619833333333">
The objective can be optimized by an EM-like
scheme that iteratively solves the minimization
problem and the maximization problem. Solving
the minimization problem is equivalent to solving
its dual since the objective is convex. The dual
problem is
</bodyText>
<equation confidence="0.8856815">
arg mλaxλ · b − log Zλ(X) − 1 ||λ||2 (3)
4β 2
</equation>
<bodyText confidence="0.999967333333333">
We optimize the objective function 2 using
stochastic projected gradient, and compute the
learning rate using AdaGrad (Duchi et al., 2010).
</bodyText>
<subsectionHeader confidence="0.999952">
3.2 Context-aware Posterior Constraints
</subsectionHeader>
<bodyText confidence="0.999387">
We develop a rich set of context-aware poste-
rior constraints for sentence-level sentiment anal-
ysis by exploiting lexical and discourse knowl-
edge. Specifically, we construct the lexical con-
straints by extracting sentiment-bearing patterns
</bodyText>
<footnote confidence="0.675372666666667">
1In general, inequality constraints can also be used. We
focus on the equality constraints since we found them to ex-
press the sentiment-relevant constraints well.
2Other convex functions can be used for the penalty. We
use L2 norm because it works well in practice. β is a regular-
ization constant
</footnote>
<equation confidence="0.8785915">
max L(θ) = max
θ θ
E
(X,y)
maxL(θ) − min
θ q∈Q
</equation>
<page confidence="0.983194">
327
</page>
<bodyText confidence="0.999947565217391">
within sentences and construct the discourse-level
constraints by extracting discourse relations that
indicate sentiment coherence or sentiment changes
both within and across sentences. Each constraint
can be formulated as equality between the expec-
tation of a constraint function value and a desired
value set by prior knowledge. The equality is not
strictly enforced (due to the regularization in the
PR objective 2). Therefore all the constraints are
applied as soft constraints. Table 1 provides in-
tuitive description and examples for all the con-
straints used in our model.
Lexical Patterns The existence of a polarity-
carrying word alone may not correctly indicate the
polarity of the sentence, as the polarity can be re-
versed by other polarity-reversing words. We ex-
tract lexical patterns that consist of polar words
and negators 3, and apply the heuristics based on
compositional semantics (Choi and Cardie, 2008)
to assign a sentiment value to each pattern.
We encode the extracted lexical patterns along
with their sentiment values as feature-label con-
straints. The constraint function can be written as
</bodyText>
<equation confidence="0.9826495">
φw(x, y) = � fw(xi, yi)
i
</equation>
<bodyText confidence="0.999982136363636">
where fw(xi, yi) is a feature function which has
value 1 when sentence xi contains the lexical pat-
tern w and its sentiment label yi equals to the ex-
pected sentiment value and has value 0 otherwise.
The constraint expectation value is set to be the
prior probability of associating w with its senti-
ment value. Note that sentences with neutral senti-
ment can also contain such lexical patterns. There-
fore we allow the lexical patterns to be assigned a
neutral sentiment with a prior probability ro (we
compute this value as the empirical probability of
neutral sentiment in the training documents). Us-
ing the polarity indicated by lexical patterns to
constrain the sentiment of sentences is quite ag-
gressive. Therefore we only consider lexical pat-
terns that are strongly discriminative (many opin-
ion words in the lexicon only indicate sentiment
with weak strength). The selected lexical patterns
include a handful of seed patterns (such as “pros”
and “cons”) and the lexical patterns that have high
precision (larger then 0.9) of predicting sentiment
in the training data.
</bodyText>
<footnote confidence="0.92091875">
3The polar words are identified using the MPQA lexicon
and the negators are identified using a handful of seed words
extended by the General Inquirer dictionary and WordNet as
described in (Choi and Cardie, 2008).
</footnote>
<bodyText confidence="0.999685404255319">
Discourse Connectives. Lexical patterns can
be limited in capturing contextual information
since they only look at interactions between words
within an expression. To capture context at the
clause or sentence level, we consider discourse
connectives, which are cue phrases or words that
indicate discourse relations between adjacent sen-
tences or clauses. To identify discourse connec-
tives, we apply a discourse tagger trained on the
Penn Discourse Treebank (Prasad et al., 2008) 4
to our data. Discourse connectives are tagged with
four senses: Expansion, Contingency, Compari-
son, Temporal.
Discourse connectives can operate at both intra-
sentential and inter-sentential level. For example,
the word “although” is often used to connect two
polar clauses within a sentence, while the word
“however” is often used to at the beginning of
the sentence to connect two polar sentences. It
is important to distinguish these two types of dis-
course connectives. We consider a discourse con-
nective to be intra-sentential if it has the Com-
parison sense and connects two polar clauses with
opposite polarities (determined by the lexical pat-
terns). We construct a feature-label constraint for
each intra-sentential discourse connective and set
its expected sentiment value to be neutral.
Unlike the intra-sentential discourse connec-
tives, the inter-sentential discourse connectives
can indicate sentiment transitions between sen-
tences. Intuitively, discourse connectives with
the senses of Expansion (e.g. also, for example,
furthermore) and Contingency (e.g. as a result,
hence, because) are likely to indicate sentiment
coherence; discourse connectives with the sense
of Comparison (e.g. but, however, nevertheless)
are likely to indicate sentiment changes. This in-
tuition is reasonable but it assumes the two sen-
tences connected by the discourse connective are
both polar sentences. In general, discourse con-
nectives can also be used to connect non-polar
(neutral) sentences. Thus it is hard to directly
constrain the posterior expectation for each type
of sentiment transitions using inter-sentential dis-
course connectives.
Instead, we impose constraints on the model
posteriors by reducing constraint violations. We
</bodyText>
<footnote confidence="0.9915245">
4http://www.cis.upenn.edu/˜epitler/
discourse.html
</footnote>
<page confidence="0.972326">
328
</page>
<table confidence="0.99866925">
Types Description and Examples Inter-sentential
Lexical patterns The sentence containing a polar lexical pattern w tends to have the polarity
indicated by w. Example lexical patterns are annoying, hate, amazing, not dis-
appointed, no concerns, favorite, recommend.
Discourse Connectives The sentence containing a discourse connective c which connects its two clauses
(clause) that have opposite polarities indicated by the lexical patterns tends to have neu-
tral sentiment. Example connectives are while, although, though, but.
Discourse Connectives Two adjacent sentences which are connected by a discourse connective c tends ✓
(sentence) to have the same polarity if c indicates a Expansion or Contingency relation,
e.g. also, for example, in fact, because ; opposite polarities if c indicates a
Comparison relation, e.g. otherwise, nevertheless, however.
Coreference The sentences which contain coreferential entities appeared as targets of opinion ✓
expressions tend to have the same polarity.
Listing patterns A series of sentences connected via a listing tend to have the same polarity. ✓
Global labels Thesentence-level polarity tends to be consistent with the document-level po- ✓
larity.
</table>
<tableCaption confidence="0.999894">
Table 1: Summarization of Posterior Constraints for Sentence-level Sentiment Classification
</tableCaption>
<bodyText confidence="0.760266">
define the following constraint function:
</bodyText>
<equation confidence="0.98506">
�φc,s(x, y) = fc,s(xi, yi, yi−1)
i
</equation>
<bodyText confidence="0.995750107142857">
where c denotes a discourse connective, s indi-
cates its sense, and fc,s is a penalty function that
takes value 1.0 when yi and yi−1 form a contradic-
tory sentiment transition, that is, yi polar yi−1 if
s E {Expansion, Contingency}, or yi =polar yi−1
if s = Comparison. The desired value for the con-
straint expectation is set to 0 so that the model is
encouraged to have less constraint violations.
Opinion Coreference Sentences in a discourse
can be linked by many types of coherence rela-
tions (Jurafsky et al., 2000). Coreference is one
of the commonly used relations in written text.
In this work, we explore coreference in the con-
text of sentence-level sentiment analysis. We con-
sider a set of polar sentences to be linked by the
opinion coreference relation if they contain core-
ferring opinion-related entities. For example, the
following sentences express opinions towards “the
speaker phone”, “The speaker phone” and “it” re-
spectively. As these opinion targets are corefer-
ential (referring to the same entity “the speaker
phone”), they are linked by the opinion corefer-
ence relation 5.
My favorite features are the speaker
phone and the radio. The speaker
phone is very functional. I use it in
the car, very audible even with freeway
noise.
</bodyText>
<footnote confidence="0.9136132">
5In general, the opinion-related entities include both the
opinion targets and the opinion holders. In this work, we
only consider the targets since we experiment with single-
author product reviews. The opinion holders can be included
in a similar way as the opinion targets.
</footnote>
<bodyText confidence="0.999948">
Our coreference relations indicated by opinion
targets overlap with the same target relation intro-
duced in (Somasundaran et al., 2009). The dif-
ferences are: (1) we encode the coreference re-
lations as soft constraints during learning instead
of applying them as hard constraints during infer-
ence time; (2) our constraints can apply to both
polar and non-polar sentences; (3) our identifica-
tion of coreference relations is automatic without
any fine-grained annotations for opinion targets.
To extract coreferential opinion targets, we ap-
ply Stanford’s coreference system (Lee et al.,
2013) to extract coreferential mentions in the doc-
ument, and then apply a set of syntactic rules to
identify opinion targets from the extracted men-
tions. The syntactic rules correspond to the
shortest dependency paths between an opinion
word and an extracted mention. We consider
the 10 most frequent dependency paths in the
training data. Example dependency paths include
nsubj(opinion, mention), nobj(opinion, mention),
and amod(mention, opinion).
For sentences connected by the opinion coref-
erence relation, we expect their sentiment to be
consistent. To encode this intuition, we define the
following constraint function:
</bodyText>
<equation confidence="0.9869105">
�φcoref(x, y) = fcoref(xi, xj, yi, yj)
i,ant(i)=j,j≥0
</equation>
<bodyText confidence="0.999883875">
where ant(i) denotes the index of the sentence
which contains an antecedent target of the target
mentioned in sentence i (the antecedent relations
over pairs of opinion targets can be constructed
using the coreference resolver), and fcoref is a
penalty function which takes value 1.0 when the
expected sentiment coherency is violated, that is,
yi polar yj. Similar to the inter-sentential dis-
</bodyText>
<page confidence="0.996088">
329
</page>
<bodyText confidence="0.999826363636364">
course connectives, modeling opinion coreference
via constraint violations allows the model to han-
dle neutral sentiment. The expected value of the
constraint functions is set to 0.
Listing Patterns Another type of coherence re-
lations we observe in online reviews is listing,
where a reviewer expresses his/her opinions by
listing a series of statements followed by a se-
quence of numbers. For example, “1. It’s smaller
than the ipod mini .... 2. It has a removable battery
....”. We expect sentences connected by a listing
to have consistent sentiment. We implement this
constraint in the same form as the coreference con-
straint (the antecedent assignments are constructed
from the numberings).
Global Sentiment Previous studies have
demonstrated the value of document-level sen-
timent in guiding the semi-supervised learning
of sentence-level sentiment (T¨ackstr¨om and
McDonald, 2011b; Qu et al., 2012). In this work,
we also take into account this information and
encode it as posterior constraints. Note that these
constraints are not necessary for our model and
can be applied when the document-level sentiment
labels are naturally available.
Based on an analysis of the Amazon review
data, we observe that sentence-level sentiment
usually doesn’t conflict with the document-level
sentiment in terms of polarity. For example, the
proportion of negative sentences in the positive
documents is very small compared to the propor-
tion of positive sentences. To encode this intuition,
we define the following constraint function:
</bodyText>
<equation confidence="0.974998666666667">
n
Og(x, y) = 6(yi polar g)/n
i
</equation>
<bodyText confidence="0.999987">
where g E {positive, negative} denotes the sen-
timent value of a polar document, n is the total
number of sentences in x, and 6 is an indicator
function. We hope the expectation of the con-
straint function takes a small value. In our experi-
ments, we set the expected value to be the empiri-
cal estimate of the probability of “conflicting” sen-
timent in polar documents using the training data.
</bodyText>
<subsectionHeader confidence="0.998838">
3.3 Training and Inference
</subsectionHeader>
<bodyText confidence="0.99882625">
During training, we need to compute the constraint
expectations and the feature expectations under
the auxiliary distribution q at each gradient step.
We can derive q by solving the dual problem in 3:
</bodyText>
<equation confidence="0.999037333333333">
exp(B &apos; f(x, y) + A &apos; O(x, y))
q(y|x) = (4)
Zλ,θ(X)
</equation>
<bodyText confidence="0.998888423076923">
where Zλ,θ(X) is a normalization constant. Most
of our constraints can be factorized in the same
way as factorizing the model features in the first-
order CRF model, and we can compute the expec-
tations under q very efficiently using the forward-
backward algorithm. However, some of our dis-
course constraints (opinion coreference and list-
ing) can break the tractable structure of the model.
For constraints with higher-order structures, we
use Gibbs Sampling (Geman and Geman, 1984) to
approximate the expectations. Given a sequence
x, we sample a label yi at each position i by com-
puting the unnormalized conditional probabilities
p(yi = l|y−i) a exp(B &apos; f(x, yi = l, y−i) + A &apos;
O(x, yi = l, y−i)) and renormalizing them. Since
the possible label assignments only differ at posi-
tion i, we can make the computation efficient by
maintaining the structure of the coreference clus-
ters and precomputing the constraint function for
different types of violations.
During inference, we find the best label assign-
ment by computing arg maxy q(y|x). For doc-
uments where the higher-order constraints apply,
we use the same Gibbs sampler as described above
to infer the most likely label assignment, other-
wise, we use the Viterbi algorithm.
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999897235294118">
We experimented with two product review
datasets for sentence-level sentiment classifica-
tion: the Customer Review (CR) data (Hu and Liu,
2004)6 which contains 638 reviews of 14 prod-
ucts such as cameras and cell phones, and the
Multi-domain Amazon (MD) data from the test set
of T¨ackstr¨om and McDonald (2011a) which con-
tains 294 reivews from 5 different domains. As in
Qu et al. (2012), we chose the books, electronics
and music domains for evaluation. Each domain
also comes with 33,000 extra reviews with only
document-level sentiment labels.
We evaluated our method in two settings: su-
pervised and semi-supervised. In the supervised
setting, we treated the test data as unlabeled data
and performed transductive learning. In the semi-
supervised setting, our unlabeled data consists of
</bodyText>
<footnote confidence="0.9926805">
6Available at http://www.cs.uic.edu/˜liub/
FBS/sentiment-analysis.html.
</footnote>
<page confidence="0.998176">
330
</page>
<bodyText confidence="0.99996714893617">
both the available unlabeled data and the test data.
For each domain in the MD dataset, we made
use of no more than 100 unlabeled documents in
which our posterior constraints apply. We adopted
the evaluation schemes used in previous work: 10-
fold cross validation for the CR dataset and 3-fold
cross validation for the MD dataset. We also report
both two-way classification (positive vs. negative)
and three-way classification results (positive, neg-
ative or neutral). We use accuracy as the per-
formance measure. In our tables, boldface num-
bers are statistically significant by paired t-test for
p &lt; 0.05 against the best baseline developed in
this paper 7.
We trained our model using a CRF incorpo-
rated with the proposed posterior constraints. For
the CRF features, we include the tokens, the part-
of-speech tags, the prior polarities of lexical pat-
terns indicated by the opinion lexicon and the
negator lexicon, the number of positive and neg-
ative tokens and the output of the vote-flip algo-
rithm (Choi and Cardie, 2009). In addition, we in-
clude the discourse connectives as local or transi-
tion features and the document-level sentiment la-
bels as features (only available in the MD dataset).
We set the CRF regularization parameter Q = 1
and set the posterior regularization parameter Q
and -y (a trade-off parameter we introduce to bal-
ance the supervised objective and the posterior
regularizer in 2) by using grid search 8. For
approximation inference with higher-order con-
straints, we perform 2000 Gibbs sampling itera-
tions where the first 1000 iterations are burn-in it-
erations. To make the results more stable, we con-
struct three Markov chains that run in parallel, and
select the sample with the largest objective value.
All posterior constraints were developed using
the training data on each training fold. For the MD
dataset, we also used the dvd domain as additional
labeled data for developing the constraints.
Baselines. We compared our method to a num-
ber of baselines: (1) CRF: CRF with the same set
of model features as in our method. (2) CRF-
INF: CRF augmented with inference constraints.
We can incorporate the proposed constraints (con-
straints derived from lexical patterns and discourse
connectives) as hard constraints into CRF during
</bodyText>
<footnote confidence="0.9970896">
7Significance test was not conducted over the previous
methods as we do not have their results for each fold.
8We conducted 10-fold cross-validation on each training
fold with the parameter space: Q : [0.01, 0.05, 0.1, 0.5, 1.0]
and γ : [0.1, 0.5, 1.0, 5.0, 10.0].
</footnote>
<table confidence="0.996528777777778">
Methods CR MD
CRF 81.1 67.0
CRF-inflex 80.9 66.4
CRF-infdisc 81.1 67.2
PRlex 81.8 69.7
PR 82.7 70.6
Previous work
TreeCRF (Nakagawa et al., 2010) 81.4 -
Dropout LR (Wang and Manning, 2013) 82.1 -
</table>
<tableCaption confidence="0.9805105">
Table 2: Accuracy results (%) for supervised sen-
timent classification (two-way)
</tableCaption>
<table confidence="0.999641454545454">
Books Electronics Music Avg
VoteFlip 44.6 45.0 47.8 45.8
DocOracle 53.6 50.5 63.0 55.7
CRF 57.4 57.5 61.8 58.9
CRF-inflex 56.7 56.4 60.4 57.8
CRF-infdisc 57.2 57.6 62.1 59.0
PRlex 60.3 59.9 63.2 61.1
PR 61.6 61.0 64.4 62.3
Previous work
HCRF 55.9 61.0 58.7 58.5
MEM 59.7 59.6 63.8 61.0
</table>
<tableCaption confidence="0.998315">
Table 3: Accuracy results (%) for semi-supervised
</tableCaption>
<bodyText confidence="0.9789247">
sentiment classification (three-way) on the MD
dataset
inference by manually setting A in equation 4 to a
large value,9. When A is large enough, it is equiva-
lent to adding hard constraints to the viterbi infer-
ence. To better understand the different effects of
lexical and discourse constraints, we report results
for applying only the lexical constraints (CRF-
INFlex) as well as results for applying only the
discourse constraints (CRF-INFdiac). (3) PRlex:
a variant of our PR model which only applies the
lexical constraints. For the three-way classifica-
tion task on the MD dataset, we also implemented
the following baselines: (4) VOTEFLIP: a rule-
based algorithm that leverages the positive, nega-
tive and neutral cues along with the effect of nega-
tion to determine the sentence sentiment (Choi
and Cardie, 2009). (5) DOCORACLE: assigns
each sentence the label of its corresponding doc-
ument.
</bodyText>
<subsectionHeader confidence="0.764785">
4.1 Results
</subsectionHeader>
<bodyText confidence="0.9993734">
We first report results on a binary (positive or neg-
ative) sentence-level sentiment classification task.
For this task, we used the supervised setting and
performed transductive learning for our model.
Table 2 shows the accuracy results. We can see
</bodyText>
<footnote confidence="0.995693">
9We set A to 1000 for the lexical constraints and -1000 to
the discourse connective constraints in the experiments
</footnote>
<page confidence="0.99022">
331
</page>
<table confidence="0.999409777777778">
Books Electronics Music
pos/neg/neu pos/neg/neu pos/neg/neu
VoteFlip 43/42/47 45/46/44 50/46/46
DocOracle 54/60/49 57/54/42 72/65/52
CRF 47/51/64 60/61/52 67/60/58
CRF-inflea 46/52/63 59/61/50 65/59/57
CRF-infdisc 47/51/64 60/61/52 67/61/59
PRlea 50/56/66 64/63/53 67/64/59
PR 52/56/68 64/66/53 69/65/60
</table>
<tableCaption confidence="0.989684">
Table 4: F1 scores for each sentiment cate-
</tableCaption>
<bodyText confidence="0.999023623529412">
gory (positive, negative and neutral) for semi-
supervised sentiment classification on the MD
dataset
that PR significantly outperforms all other base-
lines in both the CR dataset and the MD dataset
(average accuracy across domains is reported).
The poor performance of CRF-INFlex indicates
that directly applying lexical constraints as hard
constraints during inference could only hurt the
performance. CRF-INFdzac slightly outperforms
CRF but the improvement is not significant. In
contrast, both PRlex and PR significantly outper-
form CRF, which implies that incorporating lex-
ical and discourse constraints as posterior con-
straints is much more effective. The superior per-
formance of PR over PRlex further suggests that
the proper use of discourse information can signif-
icantly improve accuracy for sentence-level senti-
ment classification.
We also analyzed the model’s performance on a
three-way sentiment classification task. By intro-
ducing the “neutral” category, the sentiment clas-
sification problem becomes harder. Table 4 shows
the results in terms of accuracy for each domain
in the MD dataset. We can see that both PR and
PRlex significantly outperform all other baselines
in all domains. The rule-based baseline VOTE-
FLIP gave the weakest performance because it has
no prediction power on sentences with no opinion
words. DOCORACLE performs much better than
VOTEFLIP and performs especially well on the
Music domain. This indicates that the document-
level sentiment is a very strong indicator of the
sentence-level sentiment label. For the CRF base-
line and its invariants, we observe a similar per-
formance trend as in the two-way classification
task: there is nearly no performance improve-
ment from applying the lexical and discourse-
connective-based constraints during CRF infer-
ence. In contrast, both PRlex and PR provide
substantial improvements over CRF. This con-
firms that encoding lexical and discourse knowl-
edge as posterior constraints allows the feature-
based model to gain additional learning power
for sentence-level sentiment prediction. In par-
ticular, incorporating discourse constraints leads
to consistent improvements to our model. This
demonstrates that our modeling of discourse in-
formation is effective and that taking into account
the discourse context is important for improving
sentence-level sentiment analysis. We also com-
pare our results to the previously published results
on the same dataset. HCRF (T¨ackstr¨om and Mc-
Donald, 2011a) and MEM (Qu et al., 2012) are
two state-of-the-art semi-supervised methods for
sentence-level sentiment classification. We can
see that our best model PR gives the best results
in most categories.
Table 4 shows the results in terms of F1 scores
for each sentiment category (positive, negative and
neutral). We can see that the PR models are able to
provide improvements over all the sentiment cate-
gories compared to all the baselines in general. We
observe that the DOCORACLE baseline provides
very strong F1 scores on the positive and nega-
tive categories especially in the Books and Mu-
sic domains, but very poor F1 on the neutral cate-
gory. This is because it over-predicts the polar sen-
tences in the polar documents, and predicts no po-
lar sentences in the neutral documents. In contrast,
our PR models provide more balanced F1 scores
among all the sentiment categories. Compared to
the CRF baseline and its variants, we found that
the PR models can greatly improve the precision
of predicting positive and negative sentences, re-
sulting in a significant improvement on the pos-
itive/negative F1 scores. However, the improve-
ment on the neutral category is modest. A plausi-
ble explanation is that most of our constraints fo-
cus on discriminating polar sentences. They can
help reduce the errors of misclassifying polar sen-
tences, but the model needs more constraints in
order to distinguish neutral sentences from polar
sentences. We plan to address this issue in future
work.
</bodyText>
<subsectionHeader confidence="0.742602">
4.2 Discussion
</subsectionHeader>
<bodyText confidence="0.9999914">
We analyze the errors to better understand the mer-
its and limitations of the PR model. We found
that the PR model is able to correct many CRF
errors caused by the lack of labeled data. The first
row in Table 5 shows an example of such errors.
</bodyText>
<page confidence="0.991791">
332
</page>
<table confidence="0.9996015">
Example Sentences CRF PR
Example 1: (neg) If I could, I would like to return it or exchange (neu) x ✓
for something better.(/neg)
Example 2: (neg) Things I wasn’t a fan of – the ending was to (neu) (pos) x ✓
cutesy for my taste.(/neg) (neg) Also, all of the side characters
(particularly the mom, vee, and the teacher) were incredibly flat
and stereotypical to me.(/neg)
Example 3: (neg) I also have excessive noise when I talk and (neg) (pos) x (neg) (pos) x
have phone in my pocket while walking.(/neg) (neu) But other
models are no better.(/neu)
</table>
<tableCaption confidence="0.99975">
Table 5: Example sentences where PR succeeds and fails to correct the mistakes of CRF
</tableCaption>
<bodyText confidence="0.99995348">
The lexical features return and exchange may
be good indicators of negative sentiment for the
sentence. However, with limited labeled data, the
CRF learner can only associate very weak senti-
ment signals to these features. In contrast, the PR
model is able to associate stronger sentiment sig-
nals to these features by leveraging unlabeled data
for indirect supervision. A simple lexicon-based
constraint during inference time may also correct
this case. However, hard-constraint baselines can
hardly improve the performance in general be-
cause the contributions of different constraints are
not learned and their combination may not lead to
better predictions. This is also demonstrated by
the limited performance of CRF-INF in our exper-
iments.
We also found that the discourse constraints
play an important role in improving the sentiment
prediction. The lexical constraints alone are of-
ten not sufficient since their coverage is limited by
the sentiment lexicon and they can only constrain
sentiment locally. On the contrary, discourse con-
straints are not dependent on sentiment lexicons,
and more importantly, they can provide sentiment
preferences on multiple sentences at the same
time. When combining discourse constraints with
features from different sentences, the PR model
becomes more powerful in disambiguating senti-
ment. The second example in Table 5 shows that
the PR model learned with discourse constraints
correctly predicts the sentiment of two sentences
where no lexical constraints apply.
However, discourse constraints are not always
helpful. One reason is that they do not constrain
the neutral sentiment. As a result they could not
help disambiguate neutral sentiment from polar
sentiment, such as the third example in Table 5.
This is also a problem for most of our lexical con-
straints. In general, it is hard to learn reliable indi-
cators for the neutral sentiment. In the MD dataset,
a neutral label may be given because the sentence
contains mixed sentiment or no sentiment or it is
off-topic. We plan to explore more refined con-
straints that can deal with the neutral sentiment in
future work. Another limitation of the discourse
constraints is that they could be affected by the er-
rors of the discourse parser and the coreference re-
solver. A potential way to address this issue is to
learn discourse constraints jointly with sentiment.
We plan to study this in future research.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999967625">
In this paper, we propose a context-aware ap-
proach for learning sentence-level sentiment. Our
approach incorporates intuitive lexical and dis-
course knowledge as expressive constraints while
training a conditional random field model via pos-
terior regularization. We explore a rich set of
context-aware constraints at both intra- and inter-
sentential levels, and demonstrate their effective-
ness in the analysis of sentence-level sentiment.
While we focus on the sentence-level task, our ap-
proach can be easily extended to handle sentiment
analysis at finer levels of granularity. Our exper-
iments show that our model achieves better accu-
racy than existing supervised and semi-supervised
models for the sentence-level sentiment classifica-
tion task.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999867428571429">
This work was supported in part by DARPA-BAA-
12-47 DEFT grant #12475008 and NSF grant
BCS-0904822. We thank Igor Labutov for help-
ful discussion and suggestions; Oscar T¨ackstr¨om
and Lizhen Qu for providing their Amazon review
datasets; and the anonymous reviewers for helpful
comments and suggestions.
</bodyText>
<sectionHeader confidence="0.995784" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.901731">
Kedar Bellare, Gregory Druck, and Andrew McCal-
lum. 2009. Alternating projections for learning
</reference>
<page confidence="0.996501">
333
</page>
<reference confidence="0.99945570093458">
with expectation constraints. In Proceedings of the
Twenty-Fifth Conference on Uncertainty in Artificial
Intelligence, pages 43–50. AUAI Press.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 793–801. Association
for Computational Linguistics.
Yejin Choi and Claire Cardie. 2009. Adapting a po-
larity lexicon using integer linear programming for
domain-specific sentiment classification. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 2-
Volume 2, pages 590–598. Association for Compu-
tational Linguistics.
John Duchi, Elad Hazan, and Yoram Singer. 2010.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12:2121–2159.
Kuzman Ganchev and Dipanjan Das. 2013. Cross-
lingual discriminative learning of sequence models
with posterior regularization.
Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction via
bitext projection constraints. In Proceedings of the
ACL-IJCNLP, pages 369–377.
Kuzman Ganchev, Joao Grac¸a, Jennifer Gillenwater,
and Ben Taskar. 2010. Posterior regularization for
structured latent variable models. The Journal of
Machine Learning Research, 99:2001–2049.
Stuart Geman and Donald Geman. 1984. Stochas-
tic relaxation, gibbs distributions, and the bayesian
restoration of images. Pattern Analysis and Machine
Intelligence, IEEE Transactions on, (6):721–741.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177.
ACM.
Dan Jurafsky, James H Martin, Andrew Kehler, Keith
Vander Linden, and Nigel Ward. 2000. Speech
and language processing: An introduction to natu-
ral language processing, computational linguistics,
and speech recognition, volume 2. MIT Press.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. In Proceedings of the
2006 Conference on Empirical Methods in Natural
Language Processing, pages 355–363. Association
for Computational Linguistics.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A bayesian model for joint
unsupervised induction of sentiment, aspect and
discourse representations. In To Appear in Proceed-
ings of the 51th Annual Meeting of the Association
for Computational Linguistics, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2013. Deterministic coreference resolution
based on entity-centric, precision-ranked rules.
Yi Mao and Guy Lebanon. 2007. Isotonic conditional
random fields and local sentiment flow. Advances in
neural information processing systems, 19:961.
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeff Reynar. 2007. Structured mod-
els for fine-to-coarse sentiment analysis. In An-
nual Meeting-Association For Computational Lin-
guistics, volume 45, page 432.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using crfs with hidden variables. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 786–794.
Association for Computational Linguistics.
Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: Sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd annual meeting on Association for Compu-
tational Linguistics, page 271. Association for Com-
putational Linguistics.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Now Pub.
Livia Polanyi and Annie Zaenen. 2006. Contextual
valence shifters. In Computing attitude and affect in
text: Theory and applications, pages 1–10. Springer.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind K Joshi, and Bon-
nie L Webber. 2008. The penn discourse treebank
2.0. In LREC. Citeseer.
Lizhen Qu, Rainer Gemulla, and Gerhard Weikum.
2012. A weakly supervised model for sentence-level
semantic orientation analysis with multiple experts.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 149–159. Association for Computational Lin-
guistics.
Richard Socher, Jeffrey Pennington, Eric H Huang,
Andrew Y Ng, and Christopher D Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151–161. Association for
Computational Linguistics.
</reference>
<page confidence="0.988771">
334
</page>
<reference confidence="0.999796136363636">
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of EMNLP.
Swapna Somasundaran, Janyce Wiebe, and Josef Rup-
penhofer. 2008. Discourse level opinion interpre-
tation. In Proceedings of the 22nd International
Conference on Computational Linguistics-Volume 1,
pages 801–808. Association for Computational Lin-
guistics.
Swapna Somasundaran, Galileo Namata, Janyce
Wiebe, and Lise Getoor. 2009. Supervised and
unsupervised methods in employing discourse rela-
tions for improving opinion polarity classification.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1-Volume 1, pages 170–179. Association for Com-
putational Linguistics.
Oscar T¨ackstr¨om and Ryan McDonald. 2011a. Dis-
covering fine-grained sentiment with latent variable
structured prediction models. In Advances in Infor-
mation Retrieval, pages 368–374. Springer.
Oscar T¨ackstr¨om and Ryan McDonald. 2011b. Semi-
supervised latent variable models for sentence-level
sentiment analysis.
Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse
connectors for latent subjectivity in sentiment analy-
sis. In Proceedings of NAACL-HLT, pages 808–813.
Sida Wang and Christopher Manning. 2013. Fast
dropout training. In Proceedings of the 30th Inter-
national Conference on Machine Learning (ICML-
13), pages 118–126.
Qi Zhang, Jin Qian, Huan Chen, Jihua Kang, and Xu-
anjing Huang. 2013. Discourse level explanatory
relation extraction from product reviews using first-
order logic.
Lanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei,
and Kam-Fai Wong. 2011. Unsupervised discovery
of discourse relations for eliminating intra-sentence
polarity ambiguities. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 162–171. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.999164">
335
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.837952">
<title confidence="0.9994835">Context-aware Learning for Sentence-level Sentiment with Posterior Regularization</title>
<author confidence="0.984883">Bishan</author>
<affiliation confidence="0.9292835">Department of Computer Cornell</affiliation>
<email confidence="0.998992">bishan@cs.cornell.edu</email>
<abstract confidence="0.999173153846154">This paper proposes a novel context-aware method for analyzing sentiment at the level of individual sentences. Most existing machine learning approaches suffer from limitations in the modeling of complex linguistic structures across sentences and often fail to capture nonlocal contextual cues that are important for sentiment interpretation. In contrast, our approach allows structured modeling of sentiment while taking into account both local and global contextual information. Specifically, we encode intuitive lexical and discourse knowledge as expressive constraints and integrate them into the learning of conditional random field models via posterior regularization. The context-aware constraints provide additional power to the CRF model and can guide semi-supervised learning when labeled data is limited. Experiments on standard product review datasets show that our method outperforms the state-of-theart methods in both the supervised and semi-supervised settings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kedar Bellare</author>
<author>Gregory Druck</author>
<author>Andrew McCallum</author>
</authors>
<title>Alternating projections for learning with expectation constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>43--50</pages>
<publisher>AUAI Press.</publisher>
<contexts>
<context position="8797" citStr="Bellare et al., 2009" startWordPosition="1320" endWordPosition="1323">ork on semi-supervised learning for sentence-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om and McDonald, 2011b; Qu et al., 2012), our work does not rely on a large amount of coarse-grained (document-level) labeled data, instead, distant supervision mainly comes from linguisticallymotivated constraints. Our work also relates to the study of posterior regularization (PR) (Ganchev et al., 2010). PR has been successfully applied to many structured NLP 326 tasks such as dependency parsing, information extraction and cross-lingual learning tasks (Ganchev et al., 2009; Bellare et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Most previous work using PR mainly experiments with featurelabel constraints. In contrast, we explore a rich set of linguistically-motivated constraints which cannot be naturally formulated in the feature-label form. We also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment. 3 Approach In this section, we present the details of our proposed approach. We formulate the sentence-level sentiment classification task as a sequence labeling problem. The inputs to the model are sente</context>
</contexts>
<marker>Bellare, Druck, McCallum, 2009</marker>
<rawString>Kedar Bellare, Gregory Druck, and Andrew McCallum. 2009. Alternating projections for learning with expectation constraints. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, pages 43–50. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with compositional semantics as structural inference for subsentential sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>793--801</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6389" citStr="Choi and Cardie (2008)" startWordPosition="970" endWordPosition="973">sification. 2 Related Work There has been a large amount of work on sentiment analysis at various levels of granularity (Pang and Lee, 2008). In this paper, we focus on the study of sentence-level sentiment classification. Existing machine learning approaches for the task can be classified based on the use of two ideas. The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon </context>
<context position="13636" citStr="Choi and Cardie, 2008" startWordPosition="2098" endWordPosition="2101">red value set by prior knowledge. The equality is not strictly enforced (due to the regularization in the PR objective 2). Therefore all the constraints are applied as soft constraints. Table 1 provides intuitive description and examples for all the constraints used in our model. Lexical Patterns The existence of a polaritycarrying word alone may not correctly indicate the polarity of the sentence, as the polarity can be reversed by other polarity-reversing words. We extract lexical patterns that consist of polar words and negators 3, and apply the heuristics based on compositional semantics (Choi and Cardie, 2008) to assign a sentiment value to each pattern. We encode the extracted lexical patterns along with their sentiment values as feature-label constraints. The constraint function can be written as φw(x, y) = � fw(xi, yi) i where fw(xi, yi) is a feature function which has value 1 when sentence xi contains the lexical pattern w and its sentiment label yi equals to the expected sentiment value and has value 0 otherwise. The constraint expectation value is set to be the prior probability of associating w with its sentiment value. Note that sentences with neutral sentiment can also contain such lexical</context>
<context position="15137" citStr="Choi and Cardie, 2008" startWordPosition="2347" endWordPosition="2350">e sentiment of sentences is quite aggressive. Therefore we only consider lexical patterns that are strongly discriminative (many opinion words in the lexicon only indicate sentiment with weak strength). The selected lexical patterns include a handful of seed patterns (such as “pros” and “cons”) and the lexical patterns that have high precision (larger then 0.9) of predicting sentiment in the training data. 3The polar words are identified using the MPQA lexicon and the negators are identified using a handful of seed words extended by the General Inquirer dictionary and WordNet as described in (Choi and Cardie, 2008). Discourse Connectives. Lexical patterns can be limited in capturing contextual information since they only look at interactions between words within an expression. To capture context at the clause or sentence level, we consider discourse connectives, which are cue phrases or words that indicate discourse relations between adjacent sentences or clauses. To identify discourse connectives, we apply a discourse tagger trained on the Penn Discourse Treebank (Prasad et al., 2008) 4 to our data. Discourse connectives are tagged with four senses: Expansion, Contingency, Comparison, Temporal. Discour</context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with compositional semantics as structural inference for subsentential sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 793–801. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>590--598</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27297" citStr="Choi and Cardie, 2009" startWordPosition="4244" endWordPosition="4247">and three-way classification results (positive, negative or neutral). We use accuracy as the performance measure. In our tables, boldface numbers are statistically significant by paired t-test for p &lt; 0.05 against the best baseline developed in this paper 7. We trained our model using a CRF incorporated with the proposed posterior constraints. For the CRF features, we include the tokens, the partof-speech tags, the prior polarities of lexical patterns indicated by the opinion lexicon and the negator lexicon, the number of positive and negative tokens and the output of the vote-flip algorithm (Choi and Cardie, 2009). In addition, we include the discourse connectives as local or transition features and the document-level sentiment labels as features (only available in the MD dataset). We set the CRF regularization parameter Q = 1 and set the posterior regularization parameter Q and -y (a trade-off parameter we introduce to balance the supervised objective and the posterior regularizer in 2) by using grid search 8. For approximation inference with higher-order constraints, we perform 2000 Gibbs sampling iterations where the first 1000 iterations are burn-in iterations. To make the results more stable, we c</context>
<context position="30220" citStr="Choi and Cardie, 2009" startWordPosition="4726" endWordPosition="4729"> the viterbi inference. To better understand the different effects of lexical and discourse constraints, we report results for applying only the lexical constraints (CRFINFlex) as well as results for applying only the discourse constraints (CRF-INFdiac). (3) PRlex: a variant of our PR model which only applies the lexical constraints. For the three-way classification task on the MD dataset, we also implemented the following baselines: (4) VOTEFLIP: a rulebased algorithm that leverages the positive, negative and neutral cues along with the effect of negation to determine the sentence sentiment (Choi and Cardie, 2009). (5) DOCORACLE: assigns each sentence the label of its corresponding document. 4.1 Results We first report results on a binary (positive or negative) sentence-level sentiment classification task. For this task, we used the supervised setting and performed transductive learning for our model. Table 2 shows the accuracy results. We can see 9We set A to 1000 for the lexical constraints and -1000 to the discourse connective constraints in the experiments 331 Books Electronics Music pos/neg/neu pos/neg/neu pos/neg/neu VoteFlip 43/42/47 45/46/44 50/46/46 DocOracle 54/60/49 57/54/42 72/65/52 CRF 47/</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Yejin Choi and Claire Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 590–598. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2121</pages>
<contexts>
<context position="12089" citStr="Duchi et al., 2010" startWordPosition="1854" endWordPosition="1857"> KL-divergence between the desired model posteriors and the learned model posteriors with an L2 penalty 2 for the constraint violations. {KL(q(Y)||pθ(Y|X)) (2) + β||Eq[φ(X, Y)] − b||22} The objective can be optimized by an EM-like scheme that iteratively solves the minimization problem and the maximization problem. Solving the minimization problem is equivalent to solving its dual since the objective is convex. The dual problem is arg mλaxλ · b − log Zλ(X) − 1 ||λ||2 (3) 4β 2 We optimize the objective function 2 using stochastic projected gradient, and compute the learning rate using AdaGrad (Duchi et al., 2010). 3.2 Context-aware Posterior Constraints We develop a rich set of context-aware posterior constraints for sentence-level sentiment analysis by exploiting lexical and discourse knowledge. Specifically, we construct the lexical constraints by extracting sentiment-bearing patterns 1In general, inequality constraints can also be used. We focus on the equality constraints since we found them to express the sentiment-relevant constraints well. 2Other convex functions can be used for the penalty. We use L2 norm because it works well in practice. β is a regularization constant max L(θ) = max θ θ E (X</context>
</contexts>
<marker>Duchi, Hazan, Singer, 2010</marker>
<rawString>John Duchi, Elad Hazan, and Yoram Singer. 2010. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121–2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Crosslingual discriminative learning of sequence models with posterior regularization.</title>
<date>2013</date>
<contexts>
<context position="5146" citStr="Ganchev and Das, 2013" startWordPosition="767" endWordPosition="770">h local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning. Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) (Ganchev et al., 2010). As a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks (Ganchev et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Our work is the first to explore PR for sentiment analysis. Unlike most previous work, we explore a rich set of structural constraints that cannot be naturally encoded in the feature-label form, and show that such constraints can improve the performance of the CRF model. We evaluate our approach on the sentencelevel sentiment classification task using two standard product review datasets. Experimental results show that our model outperforms state-ofthe-art methods in both the supervised and semisupervised settings. We also show that discourse knowledge is highly useful for improving sentence</context>
<context position="8843" citStr="Ganchev and Das, 2013" startWordPosition="1328" endWordPosition="1331">-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om and McDonald, 2011b; Qu et al., 2012), our work does not rely on a large amount of coarse-grained (document-level) labeled data, instead, distant supervision mainly comes from linguisticallymotivated constraints. Our work also relates to the study of posterior regularization (PR) (Ganchev et al., 2010). PR has been successfully applied to many structured NLP 326 tasks such as dependency parsing, information extraction and cross-lingual learning tasks (Ganchev et al., 2009; Bellare et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Most previous work using PR mainly experiments with featurelabel constraints. In contrast, we explore a rich set of linguistically-motivated constraints which cannot be naturally formulated in the feature-label form. We also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment. 3 Approach In this section, we present the details of our proposed approach. We formulate the sentence-level sentiment classification task as a sequence labeling problem. The inputs to the model are sentencesegmented documents annotated with sentence</context>
</contexts>
<marker>Ganchev, Das, 2013</marker>
<rawString>Kuzman Ganchev and Dipanjan Das. 2013. Crosslingual discriminative learning of sequence models with posterior regularization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP,</booktitle>
<pages>369--377</pages>
<contexts>
<context position="5100" citStr="Ganchev et al., 2009" startWordPosition="759" endWordPosition="762">ncorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning. Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) (Ganchev et al., 2010). As a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks (Ganchev et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Our work is the first to explore PR for sentiment analysis. Unlike most previous work, we explore a rich set of structural constraints that cannot be naturally encoded in the feature-label form, and show that such constraints can improve the performance of the CRF model. We evaluate our approach on the sentencelevel sentiment classification task using two standard product review datasets. Experimental results show that our model outperforms state-ofthe-art methods in both the supervised and semisupervised settings. We also show that discourse kno</context>
<context position="8775" citStr="Ganchev et al., 2009" startWordPosition="1316" endWordPosition="1319">ared to the existing work on semi-supervised learning for sentence-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om and McDonald, 2011b; Qu et al., 2012), our work does not rely on a large amount of coarse-grained (document-level) labeled data, instead, distant supervision mainly comes from linguisticallymotivated constraints. Our work also relates to the study of posterior regularization (PR) (Ganchev et al., 2010). PR has been successfully applied to many structured NLP 326 tasks such as dependency parsing, information extraction and cross-lingual learning tasks (Ganchev et al., 2009; Bellare et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Most previous work using PR mainly experiments with featurelabel constraints. In contrast, we explore a rich set of linguistically-motivated constraints which cannot be naturally formulated in the feature-label form. We also show that constraints derived from the discourse context can be highly useful for disambiguating sentence-level sentiment. 3 Approach In this section, we present the details of our proposed approach. We formulate the sentence-level sentiment classification task as a sequence labeling problem. The inputs </context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the ACL-IJCNLP, pages 369–377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joao Grac¸a</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>99--2001</pages>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Joao Grac¸a, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. The Journal of Machine Learning Research, 99:2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Donald Geman</author>
</authors>
<title>Stochastic relaxation, gibbs distributions, and the bayesian restoration of images.</title>
<date>1984</date>
<journal>Pattern Analysis and Machine Intelligence, IEEE Transactions on,</journal>
<pages>6--721</pages>
<contexts>
<context position="24651" citStr="Geman and Geman, 1984" startWordPosition="3815" endWordPosition="3818">ary distribution q at each gradient step. We can derive q by solving the dual problem in 3: exp(B &apos; f(x, y) + A &apos; O(x, y)) q(y|x) = (4) Zλ,θ(X) where Zλ,θ(X) is a normalization constant. Most of our constraints can be factorized in the same way as factorizing the model features in the firstorder CRF model, and we can compute the expectations under q very efficiently using the forwardbackward algorithm. However, some of our discourse constraints (opinion coreference and listing) can break the tractable structure of the model. For constraints with higher-order structures, we use Gibbs Sampling (Geman and Geman, 1984) to approximate the expectations. Given a sequence x, we sample a label yi at each position i by computing the unnormalized conditional probabilities p(yi = l|y−i) a exp(B &apos; f(x, yi = l, y−i) + A &apos; O(x, yi = l, y−i)) and renormalizing them. Since the possible label assignments only differ at position i, we can make the computation efficient by maintaining the structure of the coreference clusters and precomputing the constraint function for different types of violations. During inference, we find the best label assignment by computing arg maxy q(y|x). For documents where the higher-order const</context>
</contexts>
<marker>Geman, Geman, 1984</marker>
<rawString>Stuart Geman and Donald Geman. 1984. Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (6):721–741.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="25554" citStr="Hu and Liu, 2004" startWordPosition="3965" endWordPosition="3968">fer at position i, we can make the computation efficient by maintaining the structure of the coreference clusters and precomputing the constraint function for different types of violations. During inference, we find the best label assignment by computing arg maxy q(y|x). For documents where the higher-order constraints apply, we use the same Gibbs sampler as described above to infer the most likely label assignment, otherwise, we use the Viterbi algorithm. 4 Experiments We experimented with two product review datasets for sentence-level sentiment classification: the Customer Review (CR) data (Hu and Liu, 2004)6 which contains 638 reviews of 14 products such as cameras and cell phones, and the Multi-domain Amazon (MD) data from the test set of T¨ackstr¨om and McDonald (2011a) which contains 294 reivews from 5 different domains. As in Qu et al. (2012), we chose the books, electronics and music domains for evaluation. Each domain also comes with 33,000 extra reviews with only document-level sentiment labels. We evaluated our method in two settings: supervised and semi-supervised. In the supervised setting, we treated the test data as unlabeled data and performed transductive learning. In the semisuper</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Jurafsky</author>
<author>James H Martin</author>
<author>Andrew Kehler</author>
<author>Keith Vander Linden</author>
<author>Nigel Ward</author>
</authors>
<title>Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition, volume 2.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="19281" citStr="Jurafsky et al., 2000" startWordPosition="2962" endWordPosition="2965">vel Sentiment Classification define the following constraint function: �φc,s(x, y) = fc,s(xi, yi, yi−1) i where c denotes a discourse connective, s indicates its sense, and fc,s is a penalty function that takes value 1.0 when yi and yi−1 form a contradictory sentiment transition, that is, yi polar yi−1 if s E {Expansion, Contingency}, or yi =polar yi−1 if s = Comparison. The desired value for the constraint expectation is set to 0 so that the model is encouraged to have less constraint violations. Opinion Coreference Sentences in a discourse can be linked by many types of coherence relations (Jurafsky et al., 2000). Coreference is one of the commonly used relations in written text. In this work, we explore coreference in the context of sentence-level sentiment analysis. We consider a set of polar sentences to be linked by the opinion coreference relation if they contain coreferring opinion-related entities. For example, the following sentences express opinions towards “the speaker phone”, “The speaker phone” and “it” respectively. As these opinion targets are coreferential (referring to the same entity “the speaker phone”), they are linked by the opinion coreference relation 5. My favorite features are </context>
</contexts>
<marker>Jurafsky, Martin, Kehler, Linden, Ward, 2000</marker>
<rawString>Dan Jurafsky, James H Martin, Andrew Kehler, Keith Vander Linden, and Nigel Ward. 2000. Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition, volume 2. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>355--363</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3410" citStr="Kanayama and Nasukawa, 2006" startWordPosition="512" endWordPosition="516">However, if we examine these sentences within the discourse context, we can see that: the second sentence expresses sentiment towards the same aspect – the music – as the first sentence; the third sentence expands the second sentence with the discourse connective In fact. These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well. The importance of discourse for sentiment analysis has become increasingly recognized. Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013). Very little work has explored long-distance discourse relations for sentiment analysis. Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations</context>
<context position="7184" citStr="Kanayama and Nasukawa (2006)" startWordPosition="1082" endWordPosition="1085">s and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov </context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 355–363. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations.</title>
<date>2013</date>
<booktitle>In To Appear in Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="3511" citStr="Lazaridou et al. (2013)" startWordPosition="529" endWordPosition="533"> expresses sentiment towards the same aspect – the music – as the first sentence; the third sentence expands the second sentence with the discourse connective In fact. These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well. The importance of discourse for sentiment analysis has become increasingly recognized. Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013). Very little work has explored long-distance discourse relations for sentiment analysis. Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity. Obtaining sentiment labels at the fine-grained leve</context>
<context position="7377" citStr="Lazaridou et al. (2013)" startWordPosition="1115" endWordPosition="1118">ortant in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments. Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context. It has t</context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations. In To Appear in Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Angel Chang</author>
<author>Yves Peirsman</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Deterministic coreference resolution based on entity-centric, precision-ranked rules.</title>
<date>2013</date>
<contexts>
<context position="20874" citStr="Lee et al., 2013" startWordPosition="3214" endWordPosition="3217"> way as the opinion targets. Our coreference relations indicated by opinion targets overlap with the same target relation introduced in (Somasundaran et al., 2009). The differences are: (1) we encode the coreference relations as soft constraints during learning instead of applying them as hard constraints during inference time; (2) our constraints can apply to both polar and non-polar sentences; (3) our identification of coreference relations is automatic without any fine-grained annotations for opinion targets. To extract coreferential opinion targets, we apply Stanford’s coreference system (Lee et al., 2013) to extract coreferential mentions in the document, and then apply a set of syntactic rules to identify opinion targets from the extracted mentions. The syntactic rules correspond to the shortest dependency paths between an opinion word and an extracted mention. We consider the 10 most frequent dependency paths in the training data. Example dependency paths include nsubj(opinion, mention), nobj(opinion, mention), and amod(mention, opinion). For sentences connected by the opinion coreference relation, we expect their sentiment to be consistent. To encode this intuition, we define the following </context>
</contexts>
<marker>Lee, Chang, Peirsman, Chambers, Surdeanu, Jurafsky, 2013</marker>
<rawString>Heeyoung Lee, Angel Chang, Yves Peirsman, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2013. Deterministic coreference resolution based on entity-centric, precision-ranked rules.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Mao</author>
<author>Guy Lebanon</author>
</authors>
<title>Isotonic conditional random fields and local sentiment flow. Advances in neural information processing systems,</title>
<date>2007</date>
<pages>19--961</pages>
<contexts>
<context position="6995" citStr="Mao and Lebanon (2007)" startWordPosition="1058" endWordPosition="1061">nd Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them t</context>
</contexts>
<marker>Mao, Lebanon, 2007</marker>
<rawString>Yi Mao and Guy Lebanon. 2007. Isotonic conditional random fields and local sentiment flow. Advances in neural information processing systems, 19:961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeff Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Annual Meeting-Association For Computational Linguistics,</booktitle>
<volume>45</volume>
<pages>432</pages>
<contexts>
<context position="7018" citStr="McDonald et al. (2007)" startWordPosition="1061" endWordPosition="1065">s compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarit</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeff Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Annual Meeting-Association For Computational Linguistics, volume 45, page 432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using crfs with hidden variables.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>786--794</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2024" citStr="Nakagawa et al., 2010" startWordPosition="280" endWordPosition="283">level (e.g. at the sentence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks (Pang and Lee, 2008). In this paper, we focus on the task of sentencelevel sentiment classification in online reviews. Typical approaches to the task employ supervised Claire Cardie Department of Computer Science Cornell University cardie@cs.cornell.edu machine learning algorithms with rich features and take into account the interactions between words to handle compositional effects such as polarity reversal (e.g. (Nakagawa et al., 2010; Socher et al., 2013)). Still, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge). Consider the following review for example, 1. Hearing the music in real stereo is a true revelation. 2. You can feel that the music is no longer constrained by the mono recording. 3. In fact, it is more like the players are performing on a stage in front of you ... Existing feature-based classifiers may be effective in identifying the positive sentiment of the f</context>
<context position="6288" citStr="Nakagawa et al. (2010)" startWordPosition="954" endWordPosition="957">s. We also show that discourse knowledge is highly useful for improving sentence-level sentiment classification. 2 Related Work There has been a large amount of work on sentiment analysis at various levels of granularity (Pang and Lee, 2008). In this paper, we focus on the study of sentence-level sentiment classification. Existing machine learning approaches for the task can be classified based on the use of two ideas. The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang an</context>
<context position="28940" citStr="Nakagawa et al., 2010" startWordPosition="4516" endWordPosition="4519">method. (2) CRFINF: CRF augmented with inference constraints. We can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during 7Significance test was not conducted over the previous methods as we do not have their results for each fold. 8We conducted 10-fold cross-validation on each training fold with the parameter space: Q : [0.01, 0.05, 0.1, 0.5, 1.0] and γ : [0.1, 0.5, 1.0, 5.0, 10.0]. Methods CR MD CRF 81.1 67.0 CRF-inflex 80.9 66.4 CRF-infdisc 81.1 67.2 PRlex 81.8 69.7 PR 82.7 70.6 Previous work TreeCRF (Nakagawa et al., 2010) 81.4 - Dropout LR (Wang and Manning, 2013) 82.1 - Table 2: Accuracy results (%) for supervised sentiment classification (two-way) Books Electronics Music Avg VoteFlip 44.6 45.0 47.8 45.8 DocOracle 53.6 50.5 63.0 55.7 CRF 57.4 57.5 61.8 58.9 CRF-inflex 56.7 56.4 60.4 57.8 CRF-infdisc 57.2 57.6 62.1 59.0 PRlex 60.3 59.9 63.2 61.1 PR 61.6 61.0 64.4 62.3 Previous work HCRF 55.9 61.0 58.7 58.5 MEM 59.7 59.6 63.8 61.0 Table 3: Accuracy results (%) for semi-supervised sentiment classification (three-way) on the MD dataset inference by manually setting A in equation 4 to a large value,9. When A is la</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using crfs with hidden variables. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 786–794. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>271</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6900" citStr="Pang and Lee (2004)" startWordPosition="1045" endWordPosition="1048"> (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance d</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd annual meeting on Association for Computational Linguistics, page 271. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Now Pub.</title>
<date>2008</date>
<contexts>
<context position="1604" citStr="Pang and Lee, 2008" startWordPosition="220" endWordPosition="223">ta is limited. Experiments on standard product review datasets show that our method outperforms the state-of-theart methods in both the supervised and semi-supervised settings. 1 Introduction The ability to extract sentiment from text is crucial for many opinion-mining applications such as opinion summarization, opinion question answering and opinion retrieval. Accordingly, extracting sentiment at the fine-grained level (e.g. at the sentence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks (Pang and Lee, 2008). In this paper, we focus on the task of sentencelevel sentiment classification in online reviews. Typical approaches to the task employ supervised Claire Cardie Department of Computer Science Cornell University cardie@cs.cornell.edu machine learning algorithms with rich features and take into account the interactions between words to handle compositional effects such as polarity reversal (e.g. (Nakagawa et al., 2010; Socher et al., 2013)). Still, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical</context>
<context position="5907" citStr="Pang and Lee, 2008" startWordPosition="889" endWordPosition="892">cannot be naturally encoded in the feature-label form, and show that such constraints can improve the performance of the CRF model. We evaluate our approach on the sentencelevel sentiment classification task using two standard product review datasets. Experimental results show that our model outperforms state-ofthe-art methods in both the supervised and semisupervised settings. We also show that discourse knowledge is highly useful for improving sentence-level sentiment classification. 2 Related Work There has been a large amount of work on sentiment analysis at various levels of granularity (Pang and Lee, 2008). In this paper, we focus on the study of sentence-level sentiment classification. Existing machine learning approaches for the task can be classified based on the use of two ideas. The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) comp</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Now Pub.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Annie Zaenen</author>
</authors>
<title>Contextual valence shifters. In Computing attitude and affect in text: Theory and applications,</title>
<date>2006</date>
<pages>1--10</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6716" citStr="Polanyi and Zaenen (2006)" startWordPosition="1020" endWordPosition="1023">e first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polariti</context>
</contexts>
<marker>Polanyi, Zaenen, 2006</marker>
<rawString>Livia Polanyi and Annie Zaenen. 2006. Contextual valence shifters. In Computing attitude and affect in text: Theory and applications, pages 1–10. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind K Joshi</author>
<author>Bonnie L Webber</author>
</authors>
<title>The penn discourse treebank 2.0. In LREC.</title>
<date>2008</date>
<publisher>Citeseer.</publisher>
<contexts>
<context position="15617" citStr="Prasad et al., 2008" startWordPosition="2418" endWordPosition="2421">are identified using a handful of seed words extended by the General Inquirer dictionary and WordNet as described in (Choi and Cardie, 2008). Discourse Connectives. Lexical patterns can be limited in capturing contextual information since they only look at interactions between words within an expression. To capture context at the clause or sentence level, we consider discourse connectives, which are cue phrases or words that indicate discourse relations between adjacent sentences or clauses. To identify discourse connectives, we apply a discourse tagger trained on the Penn Discourse Treebank (Prasad et al., 2008) 4 to our data. Discourse connectives are tagged with four senses: Expansion, Contingency, Comparison, Temporal. Discourse connectives can operate at both intrasentential and inter-sentential level. For example, the word “although” is often used to connect two polar clauses within a sentence, while the word “however” is often used to at the beginning of the sentence to connect two polar sentences. It is important to distinguish these two types of discourse connectives. We consider a discourse connective to be intra-sentential if it has the Comparison sense and connects two polar clauses with o</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind K Joshi, and Bonnie L Webber. 2008. The penn discourse treebank 2.0. In LREC. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lizhen Qu</author>
<author>Rainer Gemulla</author>
<author>Gerhard Weikum</author>
</authors>
<title>A weakly supervised model for sentence-level semantic orientation analysis with multiple experts.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>149--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4264" citStr="Qu et al., 2012" startWordPosition="630" endWordPosition="633">relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity. Obtaining sentiment labels at the fine-grained level is costly. Semi-supervised techniques have been proposed for sentence-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; Qu et al., 2012). However, they rely on a large amount of document-level sentiment labels that may not be naturally available in many domains. In this paper, we propose a sentence-level sentiment classification method that can (1) incorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning. Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraint</context>
<context position="8336" citStr="Qu et al., 2012" startWordPosition="1252" endWordPosition="1255">explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments. Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context. It has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning. Our approach is also semi-supervised. Compared to the existing work on semi-supervised learning for sentence-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om and McDonald, 2011b; Qu et al., 2012), our work does not rely on a large amount of coarse-grained (document-level) labeled data, instead, distant supervision mainly comes from linguisticallymotivated constraints. Our work also relates to the study of posterior regularization (PR) (Ganchev et al., 2010). PR has been successfully applied to many structured NLP 326 tasks such as dependency parsing, information extraction and cross-lingual learning tasks (Ganchev et al., 2009; Bellare et al., 2009; Ganchev et al., 2010; Ganchev and Das, 2013). Most previous work using PR mainly experiments with featurelabel constraints. In contrast, </context>
<context position="22847" citStr="Qu et al., 2012" startWordPosition="3514" endWordPosition="3517">iewer expresses his/her opinions by listing a series of statements followed by a sequence of numbers. For example, “1. It’s smaller than the ipod mini .... 2. It has a removable battery ....”. We expect sentences connected by a listing to have consistent sentiment. We implement this constraint in the same form as the coreference constraint (the antecedent assignments are constructed from the numberings). Global Sentiment Previous studies have demonstrated the value of document-level sentiment in guiding the semi-supervised learning of sentence-level sentiment (T¨ackstr¨om and McDonald, 2011b; Qu et al., 2012). In this work, we also take into account this information and encode it as posterior constraints. Note that these constraints are not necessary for our model and can be applied when the document-level sentiment labels are naturally available. Based on an analysis of the Amazon review data, we observe that sentence-level sentiment usually doesn’t conflict with the document-level sentiment in terms of polarity. For example, the proportion of negative sentences in the positive documents is very small compared to the proportion of positive sentences. To encode this intuition, we define the follow</context>
<context position="25798" citStr="Qu et al. (2012)" startWordPosition="4009" endWordPosition="4012">computing arg maxy q(y|x). For documents where the higher-order constraints apply, we use the same Gibbs sampler as described above to infer the most likely label assignment, otherwise, we use the Viterbi algorithm. 4 Experiments We experimented with two product review datasets for sentence-level sentiment classification: the Customer Review (CR) data (Hu and Liu, 2004)6 which contains 638 reviews of 14 products such as cameras and cell phones, and the Multi-domain Amazon (MD) data from the test set of T¨ackstr¨om and McDonald (2011a) which contains 294 reivews from 5 different domains. As in Qu et al. (2012), we chose the books, electronics and music domains for evaluation. Each domain also comes with 33,000 extra reviews with only document-level sentiment labels. We evaluated our method in two settings: supervised and semi-supervised. In the supervised setting, we treated the test data as unlabeled data and performed transductive learning. In the semisupervised setting, our unlabeled data consists of 6Available at http://www.cs.uic.edu/˜liub/ FBS/sentiment-analysis.html. 330 both the available unlabeled data and the test data. For each domain in the MD dataset, we made use of no more than 100 un</context>
<context position="33513" citStr="Qu et al., 2012" startWordPosition="5216" endWordPosition="5219">firms that encoding lexical and discourse knowledge as posterior constraints allows the featurebased model to gain additional learning power for sentence-level sentiment prediction. In particular, incorporating discourse constraints leads to consistent improvements to our model. This demonstrates that our modeling of discourse information is effective and that taking into account the discourse context is important for improving sentence-level sentiment analysis. We also compare our results to the previously published results on the same dataset. HCRF (T¨ackstr¨om and McDonald, 2011a) and MEM (Qu et al., 2012) are two state-of-the-art semi-supervised methods for sentence-level sentiment classification. We can see that our best model PR gives the best results in most categories. Table 4 shows the results in terms of F1 scores for each sentiment category (positive, negative and neutral). We can see that the PR models are able to provide improvements over all the sentiment categories compared to all the baselines in general. We observe that the DOCORACLE baseline provides very strong F1 scores on the positive and negative categories especially in the Books and Music domains, but very poor F1 on the ne</context>
</contexts>
<marker>Qu, Gemulla, Weikum, 2012</marker>
<rawString>Lizhen Qu, Rainer Gemulla, and Gerhard Weikum. 2012. A weakly supervised model for sentence-level semantic orientation analysis with multiple experts. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 149–159. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Jeffrey Pennington</author>
<author>Eric H Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Semi-supervised recursive autoencoders for predicting sentiment distributions.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>151--161</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6477" citStr="Socher et al. (2011)" startWordPosition="982" endWordPosition="985">various levels of granularity (Pang and Lee, 2008). In this paper, we focus on the study of sentence-level sentiment classification. Existing machine learning approaches for the task can be classified based on the use of two ideas. The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured</context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Jeffrey Pennington, Eric H Huang, Andrew Y Ng, and Christopher D Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 151–161. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2046" citStr="Socher et al., 2013" startWordPosition="284" endWordPosition="287">ence- or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks (Pang and Lee, 2008). In this paper, we focus on the task of sentencelevel sentiment classification in online reviews. Typical approaches to the task employ supervised Claire Cardie Department of Computer Science Cornell University cardie@cs.cornell.edu machine learning algorithms with rich features and take into account the interactions between words to handle compositional effects such as polarity reversal (e.g. (Nakagawa et al., 2010; Socher et al., 2013)). Still, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge). Consider the following review for example, 1. Hearing the music in real stereo is a true revelation. 2. You can feel that the music is no longer constrained by the mono recording. 3. In fact, it is more like the players are performing on a stage in front of you ... Existing feature-based classifiers may be effective in identifying the positive sentiment of the first sentence due to t</context>
<context position="6502" citStr="Socher et al. (2013)" startWordPosition="987" endWordPosition="990">rity (Pang and Lee, 2008). In this paper, we focus on the study of sentence-level sentiment classification. Existing machine learning approaches for the task can be classified based on the use of two ideas. The first idea is to exploit sentiment signals at the sentence level by learning the relevance of sentiment and words while taking into account the context in which they occur: Nakagawa et al. (2010) uses tree-CRF to model word interactions based on dependency tree structures; Choi and Cardie (2008) applies compositional inference rules to handle polarity reversal; Socher et al. (2011) and Socher et al. (2013) compute compositional vector representations for words and phrases and use them as features in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to captu</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
<author>Josef Ruppenhofer</author>
</authors>
<title>Discourse level opinion interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1,</booktitle>
<pages>801--808</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3627" citStr="Somasundaran et al. (2008)" startWordPosition="545" endWordPosition="548">second sentence with the discourse connective In fact. These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well. The importance of discourse for sentiment analysis has become increasingly recognized. Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013). Very little work has explored long-distance discourse relations for sentiment analysis. Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity. Obtaining sentiment labels at the fine-grained level is costly. Semi-supervised techniques have been proposed for sentence-level sentiment classification (T¨ackstr¨om </context>
<context position="7546" citStr="Somasundaran et al. (2008)" startWordPosition="1138" endWordPosition="1141">tency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments. Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context. It has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning. Our approach is also semi-supervi</context>
</contexts>
<marker>Somasundaran, Wiebe, Ruppenhofer, 2008</marker>
<rawString>Swapna Somasundaran, Janyce Wiebe, and Josef Ruppenhofer. 2008. Discourse level opinion interpretation. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 801–808. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Galileo Namata</author>
<author>Janyce Wiebe</author>
<author>Lise Getoor</author>
</authors>
<title>Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>170--179</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="20420" citStr="Somasundaran et al., 2009" startWordPosition="3145" endWordPosition="3148">one”), they are linked by the opinion coreference relation 5. My favorite features are the speaker phone and the radio. The speaker phone is very functional. I use it in the car, very audible even with freeway noise. 5In general, the opinion-related entities include both the opinion targets and the opinion holders. In this work, we only consider the targets since we experiment with singleauthor product reviews. The opinion holders can be included in a similar way as the opinion targets. Our coreference relations indicated by opinion targets overlap with the same target relation introduced in (Somasundaran et al., 2009). The differences are: (1) we encode the coreference relations as soft constraints during learning instead of applying them as hard constraints during inference time; (2) our constraints can apply to both polar and non-polar sentences; (3) our identification of coreference relations is automatic without any fine-grained annotations for opinion targets. To extract coreferential opinion targets, we apply Stanford’s coreference system (Lee et al., 2013) to extract coreferential mentions in the document, and then apply a set of syntactic rules to identify opinion targets from the extracted mention</context>
</contexts>
<marker>Somasundaran, Namata, Wiebe, Getoor, 2009</marker>
<rawString>Swapna Somasundaran, Galileo Namata, Janyce Wiebe, and Lise Getoor. 2009. Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 170–179. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
</authors>
<title>Discovering fine-grained sentiment with latent variable structured prediction models.</title>
<date>2011</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>368--374</pages>
<publisher>Springer.</publisher>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan McDonald. 2011a. Discovering fine-grained sentiment with latent variable structured prediction models. In Advances in Information Retrieval, pages 368–374. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
</authors>
<title>Semisupervised latent variable models for sentence-level sentiment analysis.</title>
<date>2011</date>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan McDonald. 2011b. Semisupervised latent variable models for sentence-level sentiment analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rakshit Trivedi</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Discourse connectors for latent subjectivity in sentiment analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>808--813</pages>
<contexts>
<context position="3486" citStr="Trivedi and Eisenstein (2013" startWordPosition="525" endWordPosition="528"> see that: the second sentence expresses sentiment towards the same aspect – the music – as the first sentence; the third sentence expands the second sentence with the discourse connective In fact. These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well. The importance of discourse for sentiment analysis has become increasingly recognized. Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013). Very little work has explored long-distance discourse relations for sentiment analysis. Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity. Obtaining sentiment labels</context>
<context position="7349" citStr="Trivedi and Eisenstein (2013)" startWordPosition="1109" endWordPosition="1113">ue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments. Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-</context>
</contexts>
<marker>Trivedi, Eisenstein, 2013</marker>
<rawString>Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse connectors for latent subjectivity in sentiment analysis. In Proceedings of NAACL-HLT, pages 808–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sida Wang</author>
<author>Christopher Manning</author>
</authors>
<title>Fast dropout training.</title>
<date>2013</date>
<booktitle>In Proceedings of the 30th International Conference on Machine Learning (ICML13),</booktitle>
<pages>118--126</pages>
<contexts>
<context position="28983" citStr="Wang and Manning, 2013" startWordPosition="4524" endWordPosition="4527">erence constraints. We can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during 7Significance test was not conducted over the previous methods as we do not have their results for each fold. 8We conducted 10-fold cross-validation on each training fold with the parameter space: Q : [0.01, 0.05, 0.1, 0.5, 1.0] and γ : [0.1, 0.5, 1.0, 5.0, 10.0]. Methods CR MD CRF 81.1 67.0 CRF-inflex 80.9 66.4 CRF-infdisc 81.1 67.2 PRlex 81.8 69.7 PR 82.7 70.6 Previous work TreeCRF (Nakagawa et al., 2010) 81.4 - Dropout LR (Wang and Manning, 2013) 82.1 - Table 2: Accuracy results (%) for supervised sentiment classification (two-way) Books Electronics Music Avg VoteFlip 44.6 45.0 47.8 45.8 DocOracle 53.6 50.5 63.0 55.7 CRF 57.4 57.5 61.8 58.9 CRF-inflex 56.7 56.4 60.4 57.8 CRF-infdisc 57.2 57.6 62.1 59.0 PRlex 60.3 59.9 63.2 61.1 PR 61.6 61.0 64.4 62.3 Previous work HCRF 55.9 61.0 58.7 58.5 MEM 59.7 59.6 63.8 61.0 Table 3: Accuracy results (%) for semi-supervised sentiment classification (three-way) on the MD dataset inference by manually setting A in equation 4 to a large value,9. When A is large enough, it is equivalent to adding hard</context>
</contexts>
<marker>Wang, Manning, 2013</marker>
<rawString>Sida Wang and Christopher Manning. 2013. Fast dropout training. In Proceedings of the 30th International Conference on Machine Learning (ICML13), pages 118–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Zhang</author>
<author>Jin Qian</author>
<author>Huan Chen</author>
<author>Jihua Kang</author>
<author>Xuanjing Huang</author>
</authors>
<title>Discourse level explanatory relation extraction from product reviews using firstorder logic.</title>
<date>2013</date>
<contexts>
<context position="7699" citStr="Zhang et al. (2013)" startWordPosition="1162" endWordPosition="1165">arning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework for extracting subjective text segments. Leveraging both ideas, our approach exploits sentiment signals from both intra-sentential and inter-sentential context. It has the advantages of utilizing rich discourse knowledge at different levels of context and encoding it as soft constraints during learning. Our approach is also semi-supervised. Compared to the existing work on semi-supervised learning for sentence-level sentiment classification (T¨ackstr¨om and McDonald, 2011a; T¨ackstr¨om </context>
</contexts>
<marker>Zhang, Qian, Chen, Kang, Huang, 2013</marker>
<rawString>Qi Zhang, Jin Qian, Huan Chen, Jihua Kang, and Xuanjing Huang. 2013. Discourse level explanatory relation extraction from product reviews using firstorder logic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lanjun Zhou</author>
<author>Binyang Li</author>
<author>Wei Gao</author>
<author>Zhongyu Wei</author>
<author>Kam-Fai Wong</author>
</authors>
<title>Unsupervised discovery of discourse relations for eliminating intra-sentence polarity ambiguities.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>162--171</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3430" citStr="Zhou et al., 2011" startWordPosition="517" endWordPosition="520">sentences within the discourse context, we can see that: the second sentence expresses sentiment towards the same aspect – the music – as the first sentence; the third sentence expands the second sentence with the discourse connective In fact. These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well. The importance of discourse for sentiment analysis has become increasingly recognized. Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints (Kanayama and Nasukawa, 2006; Zhou et al., 2011) or features in classifiers Trivedi and Eisenstein (2013; Lazaridou et al. (2013). Very little work has explored long-distance discourse relations for sentiment analysis. Somasundaran et al. (2008) defines coreference relations on opinion targets and applies them to constrain the polarity of sentences. 325 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 325–335, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics However, the discourse relations were obtained from fine-grained annotations and implemented as </context>
<context position="7207" citStr="Zhou et al. (2011)" startWordPosition="1087" endWordPosition="1090">tures in a classifier. The second idea is to exploit sentiment signals at the inter-sentential level. Polanyi and Zaenen (2006) argue that discourse structure is important in polarity classification. Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007),McDonald et al. (2007), and T¨ackstr¨om and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al. (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al. (2013) encode the discourse connectors as model features in supervised classifiers. Very little work has explored long-distance discourse relations. Somasundaran et al. (2008) define opinion target relations and apply them to constrain the polarity of text segments annotated with target relations. Recently, Zhang et al. (2013) explored the use of explanatory discourse relations as soft constraints in a Markov Logic Network framework</context>
</contexts>
<marker>Zhou, Li, Gao, Wei, Wong, 2011</marker>
<rawString>Lanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei, and Kam-Fai Wong. 2011. Unsupervised discovery of discourse relations for eliminating intra-sentence polarity ambiguities. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 162–171. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>