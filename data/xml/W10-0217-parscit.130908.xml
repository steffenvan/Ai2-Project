<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.042346">
<title confidence="0.965369">
Hierarchical versus Flat Classification of Emotions in Text
</title>
<author confidence="0.968377">
Diman Ghazi (a), Diana Inkpen (a), Stan Szpakowicz (a, b)
</author>
<affiliation confidence="0.9582">
(a) School of Information Technology and Engineering, University of Ottawa
(b) Institute of Computer Science, Polish Academy of Sciences
</affiliation>
<email confidence="0.946675">
{dghaz038,diana,szpak}@site.uottawa.ca
</email>
<sectionHeader confidence="0.992914" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999462923076923">
We explore the task of automatic classifica-
tion of texts by the emotions expressed. Our
novel method arranges neutrality, polarity and
emotions hierarchically. We test the method
on two datasets and show that it outperforms
the corresponding “flat” approach, which does
not take into account the hierarchical informa-
tion. The highly imbalanced structure of most
of the datasets in this area, particularly the two
datasets with which we worked, has a dramat-
ic effect on the performance of classification.
The hierarchical approach helps alleviate the
effect.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999780672131148">
Computational approaches to emotion analysis
have focused on various emotion modalities, but
there was only limited effort in the direction of
automatic recognition of emotion in text (Aman,
2007).
Oleveres et al.(1998), as one of the first works in
emotion detection in text, uses a simple Natural
Language Parser for keyword spotting, phrase
length measurement and emoticon identification.
They apply a rule-based expert system to construct
emotion scores based on the parsed text and con-
textual information. However their simple word-
level analysis system is not sufficient when the
emotion is expressed by more complicated phrases
and sentences.
More advanced systems for textual emotion recog-
nition performed sentence-level analysis. Liu et al.
(2003), proposed an approach aimed at understand-
ing the underlying semantics of language using
large-scale real-world commonsense knowledge to
classify sentences into “basic” emotion categories.
They developed a commonsense affect model
enabling the analysis of the affective qualities of
text in a robust way.
In SemEval 2007, one of the tasks was carried out
in an unsupervised setting and the emphasis was on
the study of emotion in lexical semantics (Strappa-
rava and Mihalcea, 2008; Chaumartin, 2007; Koza-
reva et al., 2007; Katz et al., 2007). Neviarouskaya
et al.(2009) applied a rule-based approach to affect
recognition from a blog text. However, statistical
and machine learning approaches have became a
method of choice for constructing a wide variety of
NLP applications (Wiebe et al., 2005).
There has been previous work using statistical
methods and supervised machine learning, includ-
ing (Aman, 2007; Katz et al., 2007; Alm, 2008;
Wilson et al., 2009). Most of that research concen-
trated on feature selections and applying lexical
semantics rather than on different learning
schemes. In particular, only flat classification has
been considered.
According to Kiritchenko et al. (2006), “Hierar-
chical categorization deals with categorization
problems where categories are organized in hierar-
chies”. Hierarchical text categorization places new
items into a collection with a predefined hierar-
chical structure. The categories are partially or-
dered, usually from more generic to more specific.
Koller and Sahami (1997) carried out the first
proper study of a hierarchical text categorization
problem in 1997. More work in hierarchical text
categorization has been reported later. Keshtkar
and Inkpen (2009) applied a hierarchical approach
to mood classification: classifying blog posts into
132 moods. The connection with our work is only
indirect, because – even though moods and emo-
tions may seem similar – their hierarchy structure
and the classification task are quite different. The
work reported in (Kiritchenko et al., 2006) is more
general. It explores two main aspects of hierarchic-
</bodyText>
<page confidence="0.9557">
140
</page>
<note confidence="0.7524985">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 140–146,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999684375">
al text categorization: learning algorithms and per-
formance evaluation.
In this paper, we extend our preliminary work
(Ghazi et al., 2010) on hierarchical classification.
Hierarchical classification is a new approach to
emotional analysis, which considers the relation
between neutrality, polarity and emotion of a text.
The main idea is to arrange these categories and
their interconnections into a hierarchy and leverage
it in the classification process.
We categorize sentences into six basic emotion
classes; there also may, naturally, be no emotion in
a sentence. The emotions are happiness, sadness,
fear, anger, disgust, and surprise (Ekman, 1992).
In one of the datasets we applied, we did consider
the class non-emotional.
For these categories, we have considered two
forms of hierarchy for classification, with two or
three levels. In the two-level method, we explore
the effect of neutral instances on one dataset and
the effect of polarity on the other dataset. In the
three-level hierarchy, we consider neutrality and
polarity together.
Our experiments on data annotated with emotions
show performance which exceeds that of the corre-
sponding flat approach.
Section 2 of this paper gives an overview of the
datasets and feature sets. Section 3 describes both
hierarchical classification methods and their
evaluation with respect to flat classification results.
Section 4 discusses future work and presents a few
conclusions.
</bodyText>
<sectionHeader confidence="0.816138" genericHeader="introduction">
2 Data and Feature Sets
2.1 Datasets
</sectionHeader>
<bodyText confidence="0.999972428571428">
The statistical methods typically require training
and test corpora, manually annotated with respect
to each language-processing task to be learned
(Wiebe et al., 2005). One of the datasets in our
experiments is a corpus of blog sentences anno-
tated with Ekman’s emotion labels (Aman, 2007).
The second dataset is a sentence-annotated corpus
resource divided into three parts for large-scale
exploration of affect in children’s stories (Alm,
2008).
In the first dataset, each sentence is tagged by a
dominant emotion in the sentence, or labelled as
non-emotional. The dataset contains 173 weblog
posts annotated by two judges. Table 1 shows the
details of the dataset.
In the second dataset, two annotators have anno-
tated 176 stories. The affects considered are the
same as Ekman’s six emotions, except that the
surprise class is subdivided into positive surprise
and negative surprise. We run our experiments on
only sentences with high agreement- sentences
with the same affective labels annotated by both
annotators. That is the version of the dataset which
merged angry and disgusted instances and com-
bined the positive and negative surprise classes.
The resulting dataset, therefore, has only five
classes (Alm, 2008). Table 1 presents more details
about the datasets, including the range of frequen-
cies for the class distribution (Min is the proportion
of sentences with the most infrequent class, Max is
the proportion for sentences with the most frequent
class.) The proportion of the most frequent class
also gives us a baseline for the accuracies of our
classifiers (since the poorest baseline classifier
could always choose the most frequent class).
</bodyText>
<tableCaption confidence="0.999081">
Table 1. Datasets specifications.
</tableCaption>
<table confidence="0.9969234">
Domain Size # classes Min-Max%
Aman’s Weblogs 2090 7 6-38 %
Data set
Alm’s Stories 1207 5 9-36%
Data set
</table>
<subsectionHeader confidence="0.996916">
2.2 Feature sets
</subsectionHeader>
<bodyText confidence="0.998699571428571">
In (Ghazi et al., 2010), three sets of features – one
corpus-based and two lexically-based – are com-
pared on Aman’s datasets. The first experiment is a
corpus-based classification which uses unigrams
(bag-of-words). In the second experiment, classifi-
cation was based on features derived from the
Prior-Polarity lexicon1 (Wilson et al. 2009); the
features were the tokens common between the
prior-polarity lexicon and the chosen dataset. In the
last experiment, we used a combination of the
emotional lists of words from Roget’s Thesaurus2
(Aman and Szpakowicz, 2008) and WordNet Af-
fect3 (Strapparava and Valitutti, 2004); we call it
the polarity feature set.
</bodyText>
<footnote confidence="0.991079">
1 www.cs.pitt.edu/mpqa
2 The 1987 Penguin’s Roget’s Thesaurus was used.
3 www.cse.unt.edu/~rada/affective
text/data/WordNetAffectEmotioLists.tar.gz
</footnote>
<page confidence="0.997079">
141
</page>
<bodyText confidence="0.999962333333334">
Based on the results and the discussion in (Ghazi et
al., 2010), we decided to use the polarity feature
set in our experiments. This feature set has certain
advantages. It is quite a bit smaller than the uni-
gram features, and we have observed that they ap-
pear to be more meaningful. For example, the
unigram features include (inevitably non-
emotional) names of people and countries. It is
also possible to have misspelled tokens in uni-
grams, while the prior-polarity lexicon features are
well-defined words usually considered as polar.
Besides, lexical features are known to be more
domain- and corpus-independent. Last but not
least, our chosen feature set significantly outper-
forms the third set.
</bodyText>
<subsectionHeader confidence="0.994507">
2.3 Classification
</subsectionHeader>
<bodyText confidence="0.999987476923077">
As a classification algorithm, we use the support
vector machines (SVM) algorithm with tenfold
cross-validation as a testing option. It is shown that
SVM obtains good performance in text classifica-
tion: it scales well to the large numbers of features
(Kennedy and Inkpen, 2006; Aman, 2007).
We apply the same settings at each level of the
hierarchy for our hierarchical approach classifica-
tion.
In hierarchical categorization, categories are organ-
ized into levels (Kiritchenko et al., 2006). We use
the hierarchical categories to put more knowledge
into our classification method as the category hier-
archies are carefully composed manually to repre-
sent our knowledge of the subject. We will achieve
that in two forms of hierarchy. A two-level hierar-
chy represents the relation of emotion and neutral-
ity in text, as well as the relation of positive and
negative polarity. These two relations are exam-
ined in two different experiments, each on a sepa-
rate dataset.
A three-level hierarchy is concerned with the rela-
tion between polarity and emotions along with the
relation between neutrality and emotion. We as-
sume that, of Ekman&apos;s six emotions, happiness be-
longs to the positive polarity class, while the other
five emotions have negative polarity. This is quite
similar to the three-level hierarchy of affect labels
used by Alm (2008). In her diagram, she considers
happiness and positive surprise as positive, and the
rest as negative emotions. She has not, however,
used this model in the classification approach:
classification experiments were only run at three
separate affect levels. She also considers positive
and negative surprise as one Surprise class.
For each level of our proposed hierarchy, we run
two sets of experiments. In the first set, we assume
that all the instances are correctly classified at the
preceding levels, so we only need to be concerned
with local mistakes. Because we do not have to
deal with instances misclassified at the previous
level, we call these results reference results.
In the second set of experiments, the methodology
is different than in (Ghazi et al. 2010). In that work
both training and testing of subsequent levels is
based on the results of preceding levels. A question
arises, however: once we have good data available,
why train on incorrect data which result from mis-
takes at the preceding level? That is why we de-
cided to train on correctly-labelled data and when
testing, to compute global results by cumulating
the mistakes from all the levels of the hierarchical
classification. In other words, classification mis-
takes at one level of the hierarchy carry on as mis-
takes at the next levels. Therefore, we talk of
global results because we compute the accuracy,
precision, recall and F-measure globally, based on
the results at all levels. These results characterize
the hierarchical classification approach when test-
ing on new sentences: the classifiers are applied in
a pipeline order: level 1, then level 2 on the results
of the previous level (then level 3 if we are in the
three-level setting).
In the next section, we show the experiments and
results on our chosen datasets.
</bodyText>
<sectionHeader confidence="0.999707" genericHeader="evaluation">
3 Results and discussions
</sectionHeader>
<subsectionHeader confidence="0.969782">
3.1 Two-level classification
</subsectionHeader>
<bodyText confidence="0.999965">
This section has two parts. The main goal of the
first part is to find out how the presence of neutral
instances affects the performance of features for
distinguishing between emotional classes in
Aman’s dataset. This was motivated by a similar
work in polarity classification (Wilson et al.,
2009).
In the second part, we discuss the effect of consid-
ering positive and negative polarity of emotions for
five affect classes in Alm’s dataset.
</bodyText>
<page confidence="0.997413">
142
</page>
<tableCaption confidence="0.9727415">
Table 2. Two-level emotional classification on Aman’s dataset (the highest precision, recall, and F-measure val-
ues for each class are shown in bold). The results of the flat classification are repeated for convenience.
</tableCaption>
<table confidence="0.9671223">
Two-level classification Flat classification
Precision Recall F-measure Precision Recall F-measure
1st level emo 0.88 0.85 0.86 -- -- --
non-emo 0.88 0.81 0.84 0.54 0.87 0.67
happiness 0.59 0.95 0.71 0.74 0.60 0.66
2nd level sadness 0.77 0.49 0.60 0.69 0.42 0.52
reference results fear 0.91 0.49 0.63 0.82 0.49 0.62
surprise 0.75 0.32 0.45 0.64 0.27 0.38
disgust 0.66 0.35 0.45 0.68 0.31 0.43
anger 0.72 0.33 0.46 0.67 0.26 0.38
Accuracy 68.32% 61.67%
non-emo 0.88 0.81 0.84 0.54 0.87 0.67
happiness 0.56 0.86 0.68 0.74 0.60 0.66
2-level experi- sadness 0.64 0.42 0.51 0.69 0.42 0.52
ment fear 0.75 0.43 0.55 0.82 0.49 0.62
global results surprise 0.56 0.29 0.38 0.64 0.27 0.38
disgust 0.52 0.29 0.37 0.68 0.31 0.43
anger 0.55 0.27 0.36 0.67 0.26 0.38
Accuracy 65.50% 61.67%
3.1.1 Neutral-Emotional
</table>
<bodyText confidence="0.998170869565217">
At the first level, emotional versus non-emotional
classification tries to determine whether an in-
stance is neutral or emotional. The second step
takes all instances which level 1 classified as emo-
tional, and tries to classify them into one of Ek-
man&apos;s six emotions. Table 2 presents the result of
experiments and, for comparison, the flat classifi-
cation results. A comparison of the results in both
experiments with flat classification shows that in
both cases the accuracy of two-level approach is
significantly better than the accuracy of flat classi-
fication.
One of the results worth discussing further is the
precision of the non-emotional class: it increases
while recall decreases. We will see the same pat-
tern in further experiments. This happens to the
classes which used to dominate in flat classifica-
tion but they no longer dominate in hierarchical
classification. Classifiers tends to give priority to a
dominant class, so more instances are placed in
this class; thus, classification achieves low preci-
sion and high recall. Hierarchical methods tend to
produce higher precision.
The difference between precision and recall of the
happiness class in the flat approach and the two-
level approach cannot be ignored. It can be ex-
plained as follows: at the second level there are no
more non-emotional instances, so the happiness
class dominates, with 42% of all the instances. As
explained before, this gives high recall and low
precision for the happiness class. We hope to ad-
dress this big gap between precision and recall of
the happiness class in the next experiments, three-
level classification. It separates happiness from the
other five emotions, so it makes the number of in-
stances of each level more balanced.
Our main focus is comparing hierarchical and flat
classification, assuming all the other parameters
are fixed. We mention, however, the best previous
results achieved by Aman (2007) on the same data-
set. Her best result was obtained by combining
corpus-based unigrams, features derived from
emotional lists of words from Roget’s Thesaurus
(explained in 2.2) and common words between the
dataset and WordNetAffect. She also applied SVM
with tenfold cross validation. The results appear in
</bodyText>
<tableCaption confidence="0.9878495">
Table 3.
Table 3. Aman’s best results on her data set.
</tableCaption>
<table confidence="0.971143">
Precision Recall F-Measure
happiness 0.813 0.698 0.751
sadness 0.605 0.416 0.493
fear 0.868 0.513 0.645
surprise 0.723 0.409 0.522
disgust 0.672 0.488 0.566
anger 0.650 0.436 0.522
non-emo 0.587 0.625 0.605
</table>
<page confidence="0.984761">
143
</page>
<tableCaption confidence="0.98364">
Table 4. Two-level emotional classification on Alm’s dataset (the highest precision, recall, and F-measure val-
ues for each class are shown in bold).
</tableCaption>
<table confidence="0.998742933333333">
Two-level classification Flat classification
Precision Recall F-measure Precision Recall F-measure
1st level neg 0.81 0.93 0.87 -- -- --
2nd level pos 0.84 0.64 0.72 0.56 0.86 0.68
reference results sadness 0.65 0.68 0.66 0.67 0.53 0.59
Accuracy fear 0.59 0.40 0.47 0.59 0.38 0.46
surprise 0.45 0.21 0.29 0.35 0.10 0.16
anger 0.49 0.73 0.59 0.54 0.43 0.48
59.07% 57.41%
2-level experiment happiness 0.84 0.64 0.72 0.56 0.86 0.68
global results sadness 0.55 0.61 0.58 0.67 0.53 0.59
Accuracy fear 0.45 0.39 0.42 0.59 0.38 0.46
surprise 0.27 0.21 0.19 0.35 0.10 0.16
anger 0.43 0.68 0.53 0.54 0.43 0.48
56.57% 57.41%
</table>
<bodyText confidence="0.999947428571428">
By comparing the reference results in Table 2 with
Aman’s result shown in Table 3, our results on two
classes, non-emo and sadness are significantly bet-
ter. Even though recall of our experiments is high-
er for happiness class, the precision makes the F-
measure to be lower. The reason behind the differ-
ence between the precisions is the same as their
difference between in our hierarchical and flat
comparisons. As it was also mentioned there we
hope to address this problem in three-level classifi-
cation. Both precision and recall of the sadness in
our experiments is higher than Aman’s results. We
have a higher precision for fear, but recall is
slightly lower. For the last three classes our preci-
sion is higher while recall is significantly lower.
The size of these three classes, which are the smal-
lest classes in the dataset, appears to be the reason.
It is possible that the small set of features that we
are using will recall fewer instances of these
classes comparing to the bigger feature sets used
by Aman (2007).
</bodyText>
<subsubsectionHeader confidence="0.563179">
3.1.2 Negative-Positive polarity
</subsubsectionHeader>
<bodyText confidence="0.999981454545455">
These experiments have been run on Alm’s dataset
with five emotion classes. This part is based on the
assumption that the happiness class is positive and
the remaining four classes are negative.
At the first level, positive versus negative classifi-
cation tries to determine whether an instance bears
a positive emotion. The second step takes all in-
stances which level 1 classified as negative, and
tries to classify them into one of the four negative
classes, namely sadness, fear, surprise and anger-
disgust. The results show a higher accuracy in ref-
erence results while it is slightly lower for global
results. In terms of precision and recall, however,
there is a high increase in precision of positive
(happiness) class while the recall decreases.
The results show a higher accuracy in reference
results while it is slightly lower for global results.
In terms of precision and recall, however, there is a
high increase in precision of positive (happiness)
class while the recall decreases.
We also see a higher F-measure for all classes in
the reference results. That confirms the consistency
between the result in Table 2 and Table 4.
In the global measurements, recall is higher for all
the classes at the second level, but the F-measure is
higher only for three classes.
Here we cannot compare our results with the best
previous results achieved by Alm (2008), because
the datasets and the experiments are not the same.
She reports the accuracy of the classification re-
sults for three sub-corpora separately. She random-
ly selected neutral instances from the annotated
data and added them to the dataset, which makes it
</bodyText>
<page confidence="0.997154">
144
</page>
<bodyText confidence="0.997764">
different than the data set we used in our experi-
ments.
</bodyText>
<subsectionHeader confidence="0.998185">
3.2 Three-level classification
</subsectionHeader>
<bodyText confidence="0.999926238095238">
In this approach, we go even further: we break the
seven-class classification task into three levels.
The first level defines whether the instance is emo-
tional. At the second level the instances defined as
emotional by the first level will be classified on
their polarity. At the third level, we assume that the
instances of happiness class have positive polarity
and the other five emotions negative polarity. That
is why we take the negative instances from the
second level and classify them into the five nega-
tive emotion classes. Table 5 presents the results of
this classification. The results show that the accu-
racy of both reference results and global results are
higher than flat classification, but the accuracy of
the global results is not significantly better.
At the first and second level, the F-measure of no-
emotion and happiness classes is significantly bet-
ter. At the third level, except in the class disgust,
we see an increase in the F-measure of all classes
in comparison with both the two-level and flat
classification.
</bodyText>
<tableCaption confidence="0.975924">
Table 5. Three-level emotional classification on Aman’s data-
set (the highest precision, recall, and F-measure values for
each class are shown in bold)
</tableCaption>
<table confidence="0.99572795">
Three-level Classification
Precision Recall F
1st level emo 0.88 0.85 0.86
non-emo 0.88 0.81 0.84
2nd level positive 0.89 0.65 0.75
reference results negative 0.79 0.94 0.86
3rd level sadness 0.63 0.54 0.59
reference results fear 0.88 0.52 0.65
surprise 0.79 0.37 0.50
disgust 0.42 0.38 0.40
anger 0.38 0.71 0.49
Accuracy 65.5%
non-emo 0.88 0.81 0.84
3-level experi- happiness 0.77 0.62 0.69
ment sadness 0.43 0.49 0.46
global results fear 0.52 0.4 0.45
surprise 0.46 0.32 0.38
disgust 0.31 0.31 0.31
anger 0.35 0.55 0.43
Accuracy 62.2%
</table>
<bodyText confidence="0.9999260625">
Also, as shown by the two-level experiments, the
results of the second level of the reference results
approach an increase in the precision of the happi-
ness class. That makes the instances defined as
happiness more precise.
By comparing the results with Table 3, which is
the best previous results, we see an increase in the
precision of happiness class and its F-measure
consequently; therefore in these results we get a
higher F-measure for three classes, non-emo, sad-
ness and fear. We get the same F-measure for hap-
piness and slightly lower F-measure for surprise
but we still have a lower F-measure for the other
two classes, namely, disgust and anger. The other
difference is the high increase in the recall value
for fear.
</bodyText>
<sectionHeader confidence="0.999137" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999964772727273">
The focus of this study was a comparison of the
hierarchical and flat classification approaches to
emotional analysis and classification. In the emo-
tional classification we noticed that having a
dominant class in the dataset degrades the results
significantly. A classifier trained on imbalanced
data gives biased results for the classes with more
instances. Our results, based on a novel method,
shows that the hierarchical classification approach
is better at dealing with the highly imbalanced
data. We also saw a considerable improvement in
the classification results when we did not deal with
the errors from previous steps and slightly better
results when we evaluated the results globally.
In the future, we will consider different levels of
our hierarchy as different tasks which could be
handled differently. Each of the tasks has its own
specification. We can, therefore, definitely benefit
from analyzing each task separately and defining
different sets of features and classification methods
for each task rather than using the same method for
every task.
</bodyText>
<page confidence="0.998517">
145
</page>
<sectionHeader confidence="0.990308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990908905405406">
Alm, C.: “Affect in text and speech”, PhD disserta-
tion, University of Illinois at Urbana-
Champaign, Department of Linguistics (2008)
Aman, S.: “Identifying Expressions of Emotion in
Text”, Master&apos;s thesis, University of Ottawa, Ot-
tawa, Canada (2007)
Aman, S., Szpakowicz, S.: “Using Roget’s Thesau-
rus for Fine-grained Emotion Recognition”.
Proc. Conf. on Natural Language Processing
(IJCNLP), Hyderabad, India, 296-302 (2008)
Chaumartin. F.: “Upar7: A knowledge-based sys-
tem for headline sentiment tagging”, Proc. Se-
mEval-2007, Prague, Czech Republic, June
(2007)
Ekman, P.: “An Argument for Basic Emotions”,
Cognition and Emotion, 6, 169-200 (1992)
Ghazi, D., Inkpen, D., Szpakowicz, S.: “Hierar-
chical approach to emotion recognition and clas-
sification in texts”, A. Farzindar and V. Keselj
(eds.), Proc. 23rd Canadian Conference on Ar-
tificial Intelligence, Ottawa, ON. Lecture Notes
in Artificial Intelligence 6085, Springer Verlag,
40–50 (2010)
Katz, P., Singleton, M., Wicentowski, R.: “Swat-
mp: the semeval-2007 systems for task 5 and
task 14”, Proc. SemEval-2007, Prague, Czech
Republic, June (2007)
Kennedy, A., Inkpen, D.: “Sentiment classification
of movie reviews using contextual valence shif-
ter”, Computational Intelligence 22. 110-125
(2006)
Keshtkar, F., Inkpen, D.: “Using Sentiment Orien-
tation Features for Mood Classification in Blog
Corpus”, IEEE International Conf. on NLP and
KE, Dalian, China, Sep. 24-27 (2009)
Kiritchenko, S., Matwin, S., Nock, R., Famili,
F.: “Learning and Evaluation in the Presence of
Class Hierarchies: Application to Text Categori-
zation”, Lecture Notes in Artificial Intelligence
4013, Springer, 395-406 (2006)
Koller, D., Sahami, M.: “Hierarchically Classify-
ing Documents Using Very Few Words”. Proc.
International Conference on Machine Learning,
170-178 (1997)
Kozareva, Z., Navarro, B., Vazquez, S., Montoyo,
A.: “UA-ZBSA: A headline emotion classifica-
tion through web information”, Proc. SemEval-
2007, Prague, Czech Republic, June (2007)
Liu, H., Lieberman, H., Selker, T.: “A Model of
Textual Affect Sensing using Real-World
Knowledge”. In Proc. IUI 2003, 125-132 (2003)
Neviarouskaya, A., Prendinger, H., and Ishizuka,
M.: “Compositionality Principle in Recognition
of Fine-Grained Emotions from Text”, In: Pro-
ceedings of Third International Conference on
Weblogs and Social Media (ICWSM’09),
AAAI, San Jose, California, US, 278-281 (2009)
Olveres, J., Billinghurst, M., Savage, J., Holden,
A.: “Intelligent, Expressive Avatars”. In Proc. of
the WECC’98, 47-55 (1998)
Strapparava, C., Mihalcea, R.: “SemEval-2007
Task 14: Affective Text” (2007)
Strapparava, C., Mihalcea, R.: “Learning to Identi-
fy Emotions in Text”, Proc. ACM Symposium
on Applied computing, Fortaleza, Brazil, 1556-
1560 (2008)
Wilson, T., Wiebe, J., Hoffmann, P.: “Recognizing
contextual polarity: an exploration of features
for phrase-level sentiment analysis”, Computa-
tional Linguistics 35(3), 399-433 (2009)
Wiebe, J., Wilson, T., Cardie, C.: “Annotating
Expressions of Opinions and Emotions in Lan-
guage”, Language Resources and Evaluation 39,
165-210 (2005)
</reference>
<page confidence="0.998753">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.605943">
<title confidence="0.999488">Hierarchical versus Flat Classification of Emotions in Text</title>
<affiliation confidence="0.9523145">of Information Technology and Engineering, University of Ottawa of Computer Science, Polish Academy of Sciences</affiliation>
<email confidence="0.829523">dghaz038@site.uottawa.ca</email>
<email confidence="0.829523">diana@site.uottawa.ca</email>
<email confidence="0.829523">szpak@site.uottawa.ca</email>
<abstract confidence="0.9762795">We explore the task of automatic classification of texts by the emotions expressed. Our novel method arranges neutrality, polarity and emotions hierarchically. We test the method on two datasets and show that it outperforms the corresponding “flat” approach, which does not take into account the hierarchical information. The highly imbalanced structure of most of the datasets in this area, particularly the two datasets with which we worked, has a dramatic effect on the performance of classification. The hierarchical approach helps alleviate the effect.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Alm</author>
</authors>
<title>Affect in text and speech”,</title>
<date>2008</date>
<institution>University of Illinois at UrbanaChampaign, Department of Linguistics</institution>
<note>PhD dissertation,</note>
<contexts>
<context position="2567" citStr="Alm, 2008" startWordPosition="383" endWordPosition="384">f the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and Sahami (1997) carried out the</context>
<context position="5866" citStr="Alm, 2008" startWordPosition="877" endWordPosition="878"> their evaluation with respect to flat classification results. Section 4 discusses future work and presents a few conclusions. 2 Data and Feature Sets 2.1 Datasets The statistical methods typically require training and test corpora, manually annotated with respect to each language-processing task to be learned (Wiebe et al., 2005). One of the datasets in our experiments is a corpus of blog sentences annotated with Ekman’s emotion labels (Aman, 2007). The second dataset is a sentence-annotated corpus resource divided into three parts for large-scale exploration of affect in children’s stories (Alm, 2008). In the first dataset, each sentence is tagged by a dominant emotion in the sentence, or labelled as non-emotional. The dataset contains 173 weblog posts annotated by two judges. Table 1 shows the details of the dataset. In the second dataset, two annotators have annotated 176 stories. The affects considered are the same as Ekman’s six emotions, except that the surprise class is subdivided into positive surprise and negative surprise. We run our experiments on only sentences with high agreement- sentences with the same affective labels annotated by both annotators. That is the version of the </context>
<context position="10098" citStr="Alm (2008)" startWordPosition="1544" endWordPosition="1545">archy. A two-level hierarchy represents the relation of emotion and neutrality in text, as well as the relation of positive and negative polarity. These two relations are examined in two different experiments, each on a separate dataset. A three-level hierarchy is concerned with the relation between polarity and emotions along with the relation between neutrality and emotion. We assume that, of Ekman&apos;s six emotions, happiness belongs to the positive polarity class, while the other five emotions have negative polarity. This is quite similar to the three-level hierarchy of affect labels used by Alm (2008). In her diagram, she considers happiness and positive surprise as positive, and the rest as negative emotions. She has not, however, used this model in the classification approach: classification experiments were only run at three separate affect levels. She also considers positive and negative surprise as one Surprise class. For each level of our proposed hierarchy, we run two sets of experiments. In the first set, we assume that all the instances are correctly classified at the preceding levels, so we only need to be concerned with local mistakes. Because we do not have to deal with instanc</context>
<context position="19085" citStr="Alm (2008)" startWordPosition="3022" endWordPosition="3023">results show a higher accuracy in reference results while it is slightly lower for global results. In terms of precision and recall, however, there is a high increase in precision of positive (happiness) class while the recall decreases. We also see a higher F-measure for all classes in the reference results. That confirms the consistency between the result in Table 2 and Table 4. In the global measurements, recall is higher for all the classes at the second level, but the F-measure is higher only for three classes. Here we cannot compare our results with the best previous results achieved by Alm (2008), because the datasets and the experiments are not the same. She reports the accuracy of the classification results for three sub-corpora separately. She randomly selected neutral instances from the annotated data and added them to the dataset, which makes it 144 different than the data set we used in our experiments. 3.2 Three-level classification In this approach, we go even further: we break the seven-class classification task into three levels. The first level defines whether the instance is emotional. At the second level the instances defined as emotional by the first level will be classi</context>
</contexts>
<marker>Alm, 2008</marker>
<rawString>Alm, C.: “Affect in text and speech”, PhD dissertation, University of Illinois at UrbanaChampaign, Department of Linguistics (2008)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Aman</author>
</authors>
<title>Identifying Expressions of Emotion in Text”, Master&apos;s thesis,</title>
<date>2007</date>
<institution>University of Ottawa,</institution>
<location>Ottawa, Canada</location>
<contexts>
<context position="1072" citStr="Aman, 2007" startWordPosition="154" endWordPosition="155">. We test the method on two datasets and show that it outperforms the corresponding “flat” approach, which does not take into account the hierarchical information. The highly imbalanced structure of most of the datasets in this area, particularly the two datasets with which we worked, has a dramatic effect on the performance of classification. The hierarchical approach helps alleviate the effect. 1 Introduction Computational approaches to emotion analysis have focused on various emotion modalities, but there was only limited effort in the direction of automatic recognition of emotion in text (Aman, 2007). Oleveres et al.(1998), as one of the first works in emotion detection in text, uses a simple Natural Language Parser for keyword spotting, phrase length measurement and emoticon identification. They apply a rule-based expert system to construct emotion scores based on the parsed text and contextual information. However their simple wordlevel analysis system is not sufficient when the emotion is expressed by more complicated phrases and sentences. More advanced systems for textual emotion recognition performed sentence-level analysis. Liu et al. (2003), proposed an approach aimed at understan</context>
<context position="2537" citStr="Aman, 2007" startWordPosition="377" endWordPosition="378">ust way. In SemEval 2007, one of the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and</context>
<context position="5709" citStr="Aman, 2007" startWordPosition="855" endWordPosition="856">ng flat approach. Section 2 of this paper gives an overview of the datasets and feature sets. Section 3 describes both hierarchical classification methods and their evaluation with respect to flat classification results. Section 4 discusses future work and presents a few conclusions. 2 Data and Feature Sets 2.1 Datasets The statistical methods typically require training and test corpora, manually annotated with respect to each language-processing task to be learned (Wiebe et al., 2005). One of the datasets in our experiments is a corpus of blog sentences annotated with Ekman’s emotion labels (Aman, 2007). The second dataset is a sentence-annotated corpus resource divided into three parts for large-scale exploration of affect in children’s stories (Alm, 2008). In the first dataset, each sentence is tagged by a dominant emotion in the sentence, or labelled as non-emotional. The dataset contains 173 weblog posts annotated by two judges. Table 1 shows the details of the dataset. In the second dataset, two annotators have annotated 176 stories. The affects considered are the same as Ekman’s six emotions, except that the surprise class is subdivided into positive surprise and negative surprise. We </context>
<context position="9053" citStr="Aman, 2007" startWordPosition="1375" endWordPosition="1376">ssible to have misspelled tokens in unigrams, while the prior-polarity lexicon features are well-defined words usually considered as polar. Besides, lexical features are known to be more domain- and corpus-independent. Last but not least, our chosen feature set significantly outperforms the third set. 2.3 Classification As a classification algorithm, we use the support vector machines (SVM) algorithm with tenfold cross-validation as a testing option. It is shown that SVM obtains good performance in text classification: it scales well to the large numbers of features (Kennedy and Inkpen, 2006; Aman, 2007). We apply the same settings at each level of the hierarchy for our hierarchical approach classification. In hierarchical categorization, categories are organized into levels (Kiritchenko et al., 2006). We use the hierarchical categories to put more knowledge into our classification method as the category hierarchies are carefully composed manually to represent our knowledge of the subject. We will achieve that in two forms of hierarchy. A two-level hierarchy represents the relation of emotion and neutrality in text, as well as the relation of positive and negative polarity. These two relation</context>
<context position="15328" citStr="Aman (2007)" startWordPosition="2398" endWordPosition="2399">on-emotional instances, so the happiness class dominates, with 42% of all the instances. As explained before, this gives high recall and low precision for the happiness class. We hope to address this big gap between precision and recall of the happiness class in the next experiments, threelevel classification. It separates happiness from the other five emotions, so it makes the number of instances of each level more balanced. Our main focus is comparing hierarchical and flat classification, assuming all the other parameters are fixed. We mention, however, the best previous results achieved by Aman (2007) on the same dataset. Her best result was obtained by combining corpus-based unigrams, features derived from emotional lists of words from Roget’s Thesaurus (explained in 2.2) and common words between the dataset and WordNetAffect. She also applied SVM with tenfold cross validation. The results appear in Table 3. Table 3. Aman’s best results on her data set. Precision Recall F-Measure happiness 0.813 0.698 0.751 sadness 0.605 0.416 0.493 fear 0.868 0.513 0.645 surprise 0.723 0.409 0.522 disgust 0.672 0.488 0.566 anger 0.650 0.436 0.522 non-emo 0.587 0.625 0.605 143 Table 4. Two-level emotional</context>
<context position="17685" citStr="Aman (2007)" startWordPosition="2792" endWordPosition="2793">As it was also mentioned there we hope to address this problem in three-level classification. Both precision and recall of the sadness in our experiments is higher than Aman’s results. We have a higher precision for fear, but recall is slightly lower. For the last three classes our precision is higher while recall is significantly lower. The size of these three classes, which are the smallest classes in the dataset, appears to be the reason. It is possible that the small set of features that we are using will recall fewer instances of these classes comparing to the bigger feature sets used by Aman (2007). 3.1.2 Negative-Positive polarity These experiments have been run on Alm’s dataset with five emotion classes. This part is based on the assumption that the happiness class is positive and the remaining four classes are negative. At the first level, positive versus negative classification tries to determine whether an instance bears a positive emotion. The second step takes all instances which level 1 classified as negative, and tries to classify them into one of the four negative classes, namely sadness, fear, surprise and angerdisgust. The results show a higher accuracy in reference results </context>
</contexts>
<marker>Aman, 2007</marker>
<rawString>Aman, S.: “Identifying Expressions of Emotion in Text”, Master&apos;s thesis, University of Ottawa, Ottawa, Canada (2007)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Aman</author>
<author>S Szpakowicz</author>
</authors>
<title>Using Roget’s Thesaurus for Fine-grained Emotion Recognition”.</title>
<date>2008</date>
<booktitle>Proc. Conf. on Natural Language Processing (IJCNLP),</booktitle>
<location>Hyderabad,</location>
<contexts>
<context position="7802" citStr="Aman and Szpakowicz, 2008" startWordPosition="1182" endWordPosition="1185">ta set Alm’s Stories 1207 5 9-36% Data set 2.2 Feature sets In (Ghazi et al., 2010), three sets of features – one corpus-based and two lexically-based – are compared on Aman’s datasets. The first experiment is a corpus-based classification which uses unigrams (bag-of-words). In the second experiment, classification was based on features derived from the Prior-Polarity lexicon1 (Wilson et al. 2009); the features were the tokens common between the prior-polarity lexicon and the chosen dataset. In the last experiment, we used a combination of the emotional lists of words from Roget’s Thesaurus2 (Aman and Szpakowicz, 2008) and WordNet Affect3 (Strapparava and Valitutti, 2004); we call it the polarity feature set. 1 www.cs.pitt.edu/mpqa 2 The 1987 Penguin’s Roget’s Thesaurus was used. 3 www.cse.unt.edu/~rada/affective text/data/WordNetAffectEmotioLists.tar.gz 141 Based on the results and the discussion in (Ghazi et al., 2010), we decided to use the polarity feature set in our experiments. This feature set has certain advantages. It is quite a bit smaller than the unigram features, and we have observed that they appear to be more meaningful. For example, the unigram features include (inevitably nonemotional) name</context>
</contexts>
<marker>Aman, Szpakowicz, 2008</marker>
<rawString>Aman, S., Szpakowicz, S.: “Using Roget’s Thesaurus for Fine-grained Emotion Recognition”. Proc. Conf. on Natural Language Processing (IJCNLP), Hyderabad, India, 296-302 (2008)</rawString>
</citation>
<citation valid="true">
<authors>
<author>F</author>
</authors>
<title>Upar7: A knowledge-based system for headline sentiment tagging”,</title>
<date>2007</date>
<booktitle>Proc. SemEval-2007,</booktitle>
<location>Prague, Czech Republic,</location>
<marker>F, 2007</marker>
<rawString>Chaumartin. F.: “Upar7: A knowledge-based system for headline sentiment tagging”, Proc. SemEval-2007, Prague, Czech Republic, June (2007)</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ekman</author>
</authors>
<title>An Argument for Basic Emotions”,</title>
<date>1992</date>
<journal>Cognition and Emotion,</journal>
<volume>6</volume>
<pages>169--200</pages>
<contexts>
<context position="4600" citStr="Ekman, 1992" startWordPosition="682" endWordPosition="683">s and performance evaluation. In this paper, we extend our preliminary work (Ghazi et al., 2010) on hierarchical classification. Hierarchical classification is a new approach to emotional analysis, which considers the relation between neutrality, polarity and emotion of a text. The main idea is to arrange these categories and their interconnections into a hierarchy and leverage it in the classification process. We categorize sentences into six basic emotion classes; there also may, naturally, be no emotion in a sentence. The emotions are happiness, sadness, fear, anger, disgust, and surprise (Ekman, 1992). In one of the datasets we applied, we did consider the class non-emotional. For these categories, we have considered two forms of hierarchy for classification, with two or three levels. In the two-level method, we explore the effect of neutral instances on one dataset and the effect of polarity on the other dataset. In the three-level hierarchy, we consider neutrality and polarity together. Our experiments on data annotated with emotions show performance which exceeds that of the corresponding flat approach. Section 2 of this paper gives an overview of the datasets and feature sets. Section </context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Ekman, P.: “An Argument for Basic Emotions”, Cognition and Emotion, 6, 169-200 (1992)</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ghazi</author>
<author>D Inkpen</author>
<author>Szpakowicz</author>
</authors>
<title>S.: “Hierarchical approach to emotion recognition and classification</title>
<date>2010</date>
<booktitle>Proc. 23rd Canadian Conference on Artificial Intelligence, Ottawa, ON. Lecture Notes in Artificial Intelligence 6085,</booktitle>
<pages>40--50</pages>
<editor>in texts”, A. Farzindar and V. Keselj (eds.),</editor>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="4084" citStr="Ghazi et al., 2010" startWordPosition="605" endWordPosition="608">s only indirect, because – even though moods and emotions may seem similar – their hierarchy structure and the classification task are quite different. The work reported in (Kiritchenko et al., 2006) is more general. It explores two main aspects of hierarchic140 Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 140–146, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics al text categorization: learning algorithms and performance evaluation. In this paper, we extend our preliminary work (Ghazi et al., 2010) on hierarchical classification. Hierarchical classification is a new approach to emotional analysis, which considers the relation between neutrality, polarity and emotion of a text. The main idea is to arrange these categories and their interconnections into a hierarchy and leverage it in the classification process. We categorize sentences into six basic emotion classes; there also may, naturally, be no emotion in a sentence. The emotions are happiness, sadness, fear, anger, disgust, and surprise (Ekman, 1992). In one of the datasets we applied, we did consider the class non-emotional. For th</context>
<context position="7259" citStr="Ghazi et al., 2010" startWordPosition="1100" endWordPosition="1103">). Table 1 presents more details about the datasets, including the range of frequencies for the class distribution (Min is the proportion of sentences with the most infrequent class, Max is the proportion for sentences with the most frequent class.) The proportion of the most frequent class also gives us a baseline for the accuracies of our classifiers (since the poorest baseline classifier could always choose the most frequent class). Table 1. Datasets specifications. Domain Size # classes Min-Max% Aman’s Weblogs 2090 7 6-38 % Data set Alm’s Stories 1207 5 9-36% Data set 2.2 Feature sets In (Ghazi et al., 2010), three sets of features – one corpus-based and two lexically-based – are compared on Aman’s datasets. The first experiment is a corpus-based classification which uses unigrams (bag-of-words). In the second experiment, classification was based on features derived from the Prior-Polarity lexicon1 (Wilson et al. 2009); the features were the tokens common between the prior-polarity lexicon and the chosen dataset. In the last experiment, we used a combination of the emotional lists of words from Roget’s Thesaurus2 (Aman and Szpakowicz, 2008) and WordNet Affect3 (Strapparava and Valitutti, 2004); w</context>
<context position="10869" citStr="Ghazi et al. 2010" startWordPosition="1667" endWordPosition="1670">the classification approach: classification experiments were only run at three separate affect levels. She also considers positive and negative surprise as one Surprise class. For each level of our proposed hierarchy, we run two sets of experiments. In the first set, we assume that all the instances are correctly classified at the preceding levels, so we only need to be concerned with local mistakes. Because we do not have to deal with instances misclassified at the previous level, we call these results reference results. In the second set of experiments, the methodology is different than in (Ghazi et al. 2010). In that work both training and testing of subsequent levels is based on the results of preceding levels. A question arises, however: once we have good data available, why train on incorrect data which result from mistakes at the preceding level? That is why we decided to train on correctly-labelled data and when testing, to compute global results by cumulating the mistakes from all the levels of the hierarchical classification. In other words, classification mistakes at one level of the hierarchy carry on as mistakes at the next levels. Therefore, we talk of global results because we compute</context>
</contexts>
<marker>Ghazi, Inkpen, Szpakowicz, 2010</marker>
<rawString>Ghazi, D., Inkpen, D., Szpakowicz, S.: “Hierarchical approach to emotion recognition and classification in texts”, A. Farzindar and V. Keselj (eds.), Proc. 23rd Canadian Conference on Artificial Intelligence, Ottawa, ON. Lecture Notes in Artificial Intelligence 6085, Springer Verlag, 40–50 (2010)</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Katz</author>
<author>M Singleton</author>
<author>R Wicentowski</author>
</authors>
<title>Swatmp: the semeval-2007 systems for task 5 and task 14”,</title>
<date>2007</date>
<booktitle>Proc. SemEval-2007,</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2171" citStr="Katz et al., 2007" startWordPosition="321" endWordPosition="324">xtual emotion recognition performed sentence-level analysis. Liu et al. (2003), proposed an approach aimed at understanding the underlying semantics of language using large-scale real-world commonsense knowledge to classify sentences into “basic” emotion categories. They developed a commonsense affect model enabling the analysis of the affective qualities of text in a robust way. In SemEval 2007, one of the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been </context>
</contexts>
<marker>Katz, Singleton, Wicentowski, 2007</marker>
<rawString>Katz, P., Singleton, M., Wicentowski, R.: “Swatmp: the semeval-2007 systems for task 5 and task 14”, Proc. SemEval-2007, Prague, Czech Republic, June (2007)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennedy</author>
<author>D Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifter”,</title>
<date>2006</date>
<journal>Computational Intelligence</journal>
<volume>22</volume>
<pages>110--125</pages>
<contexts>
<context position="9040" citStr="Kennedy and Inkpen, 2006" startWordPosition="1371" endWordPosition="1374">d countries. It is also possible to have misspelled tokens in unigrams, while the prior-polarity lexicon features are well-defined words usually considered as polar. Besides, lexical features are known to be more domain- and corpus-independent. Last but not least, our chosen feature set significantly outperforms the third set. 2.3 Classification As a classification algorithm, we use the support vector machines (SVM) algorithm with tenfold cross-validation as a testing option. It is shown that SVM obtains good performance in text classification: it scales well to the large numbers of features (Kennedy and Inkpen, 2006; Aman, 2007). We apply the same settings at each level of the hierarchy for our hierarchical approach classification. In hierarchical categorization, categories are organized into levels (Kiritchenko et al., 2006). We use the hierarchical categories to put more knowledge into our classification method as the category hierarchies are carefully composed manually to represent our knowledge of the subject. We will achieve that in two forms of hierarchy. A two-level hierarchy represents the relation of emotion and neutrality in text, as well as the relation of positive and negative polarity. These</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>Kennedy, A., Inkpen, D.: “Sentiment classification of movie reviews using contextual valence shifter”, Computational Intelligence 22. 110-125 (2006)</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keshtkar</author>
<author>D Inkpen</author>
</authors>
<title>Using Sentiment Orientation Features for Mood Classification in Blog Corpus”,</title>
<date>2009</date>
<booktitle>IEEE International Conf. on NLP and KE,</booktitle>
<location>Dalian, China,</location>
<contexts>
<context position="3339" citStr="Keshtkar and Inkpen (2009)" startWordPosition="492" endWordPosition="495">schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and Sahami (1997) carried out the first proper study of a hierarchical text categorization problem in 1997. More work in hierarchical text categorization has been reported later. Keshtkar and Inkpen (2009) applied a hierarchical approach to mood classification: classifying blog posts into 132 moods. The connection with our work is only indirect, because – even though moods and emotions may seem similar – their hierarchy structure and the classification task are quite different. The work reported in (Kiritchenko et al., 2006) is more general. It explores two main aspects of hierarchic140 Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 140–146, Los Angeles, California, June 2010. c�2010 Association for Computational Lingu</context>
</contexts>
<marker>Keshtkar, Inkpen, 2009</marker>
<rawString>Keshtkar, F., Inkpen, D.: “Using Sentiment Orientation Features for Mood Classification in Blog Corpus”, IEEE International Conf. on NLP and KE, Dalian, China, Sep. 24-27 (2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kiritchenko</author>
<author>S Matwin</author>
<author>R Nock</author>
<author>F Famili</author>
</authors>
<title>Learning and Evaluation in the Presence of Class Hierarchies: Application to Text Categorization”,</title>
<date>2006</date>
<journal>Lecture Notes in Artificial Intelligence</journal>
<volume>4013</volume>
<pages>395--406</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="2821" citStr="Kiritchenko et al. (2006)" startWordPosition="418" endWordPosition="421">09) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and Sahami (1997) carried out the first proper study of a hierarchical text categorization problem in 1997. More work in hierarchical text categorization has been reported later. Keshtkar and Inkpen (2009) applied a hierarchical approach to mood classification: classifying blog posts in</context>
<context position="9254" citStr="Kiritchenko et al., 2006" startWordPosition="1403" endWordPosition="1406">domain- and corpus-independent. Last but not least, our chosen feature set significantly outperforms the third set. 2.3 Classification As a classification algorithm, we use the support vector machines (SVM) algorithm with tenfold cross-validation as a testing option. It is shown that SVM obtains good performance in text classification: it scales well to the large numbers of features (Kennedy and Inkpen, 2006; Aman, 2007). We apply the same settings at each level of the hierarchy for our hierarchical approach classification. In hierarchical categorization, categories are organized into levels (Kiritchenko et al., 2006). We use the hierarchical categories to put more knowledge into our classification method as the category hierarchies are carefully composed manually to represent our knowledge of the subject. We will achieve that in two forms of hierarchy. A two-level hierarchy represents the relation of emotion and neutrality in text, as well as the relation of positive and negative polarity. These two relations are examined in two different experiments, each on a separate dataset. A three-level hierarchy is concerned with the relation between polarity and emotions along with the relation between neutrality </context>
</contexts>
<marker>Kiritchenko, Matwin, Nock, Famili, 2006</marker>
<rawString>Kiritchenko, S., Matwin, S., Nock, R., Famili, F.: “Learning and Evaluation in the Presence of Class Hierarchies: Application to Text Categorization”, Lecture Notes in Artificial Intelligence 4013, Springer, 395-406 (2006)</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Koller</author>
<author>M Sahami</author>
</authors>
<title>Hierarchically Classifying Documents Using Very Few Words”.</title>
<date>1997</date>
<booktitle>Proc. International Conference on Machine Learning,</booktitle>
<pages>170--178</pages>
<contexts>
<context position="3151" citStr="Koller and Sahami (1997)" startWordPosition="464" endWordPosition="467">Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and Sahami (1997) carried out the first proper study of a hierarchical text categorization problem in 1997. More work in hierarchical text categorization has been reported later. Keshtkar and Inkpen (2009) applied a hierarchical approach to mood classification: classifying blog posts into 132 moods. The connection with our work is only indirect, because – even though moods and emotions may seem similar – their hierarchy structure and the classification task are quite different. The work reported in (Kiritchenko et al., 2006) is more general. It explores two main aspects of hierarchic140 Proceedings of the NAAC</context>
</contexts>
<marker>Koller, Sahami, 1997</marker>
<rawString>Koller, D., Sahami, M.: “Hierarchically Classifying Documents Using Very Few Words”. Proc. International Conference on Machine Learning, 170-178 (1997)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Kozareva</author>
<author>B Navarro</author>
<author>S Vazquez</author>
<author>Montoyo</author>
</authors>
<title>A.: “UA-ZBSA: A headline emotion classification through web information”,</title>
<date>2007</date>
<booktitle>Proc. SemEval2007,</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2151" citStr="Kozareva et al., 2007" startWordPosition="316" endWordPosition="320">advanced systems for textual emotion recognition performed sentence-level analysis. Liu et al. (2003), proposed an approach aimed at understanding the underlying semantics of language using large-scale real-world commonsense knowledge to classify sentences into “basic” emotion categories. They developed a commonsense affect model enabling the analysis of the affective qualities of text in a robust way. In SemEval 2007, one of the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat clas</context>
</contexts>
<marker>Kozareva, Navarro, Vazquez, Montoyo, 2007</marker>
<rawString>Kozareva, Z., Navarro, B., Vazquez, S., Montoyo, A.: “UA-ZBSA: A headline emotion classification through web information”, Proc. SemEval2007, Prague, Czech Republic, June (2007)</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>H Lieberman</author>
<author>Selker</author>
</authors>
<title>T.: “A Model of Textual Affect Sensing using Real-World Knowledge”.</title>
<date>2003</date>
<booktitle>In Proc. IUI</booktitle>
<pages>125--132</pages>
<contexts>
<context position="1631" citStr="Liu et al. (2003)" startWordPosition="236" endWordPosition="239">n of automatic recognition of emotion in text (Aman, 2007). Oleveres et al.(1998), as one of the first works in emotion detection in text, uses a simple Natural Language Parser for keyword spotting, phrase length measurement and emoticon identification. They apply a rule-based expert system to construct emotion scores based on the parsed text and contextual information. However their simple wordlevel analysis system is not sufficient when the emotion is expressed by more complicated phrases and sentences. More advanced systems for textual emotion recognition performed sentence-level analysis. Liu et al. (2003), proposed an approach aimed at understanding the underlying semantics of language using large-scale real-world commonsense knowledge to classify sentences into “basic” emotion categories. They developed a commonsense affect model enabling the analysis of the affective qualities of text in a robust way. In SemEval 2007, one of the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach t</context>
</contexts>
<marker>Liu, Lieberman, Selker, 2003</marker>
<rawString>Liu, H., Lieberman, H., Selker, T.: “A Model of Textual Affect Sensing using Real-World Knowledge”. In Proc. IUI 2003, 125-132 (2003)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Neviarouskaya</author>
<author>H Prendinger</author>
<author>M Ishizuka</author>
</authors>
<title>Compositionality Principle in Recognition of Fine-Grained Emotions from Text”, In:</title>
<date>2009</date>
<booktitle>Proceedings of Third International Conference on Weblogs and Social Media (ICWSM’09), AAAI,</booktitle>
<pages>278--281</pages>
<location>San Jose, California, US,</location>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2009</marker>
<rawString>Neviarouskaya, A., Prendinger, H., and Ishizuka, M.: “Compositionality Principle in Recognition of Fine-Grained Emotions from Text”, In: Proceedings of Third International Conference on Weblogs and Social Media (ICWSM’09), AAAI, San Jose, California, US, 278-281 (2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Olveres</author>
<author>M Billinghurst</author>
<author>J Savage</author>
<author>A “Intelligent Holden</author>
</authors>
<title>Expressive Avatars”.</title>
<date>1998</date>
<booktitle>In Proc. of the WECC’98,</booktitle>
<pages>47--55</pages>
<marker>Olveres, Billinghurst, Savage, Holden, 1998</marker>
<rawString>Olveres, J., Billinghurst, M., Savage, J., Holden, A.: “Intelligent, Expressive Avatars”. In Proc. of the WECC’98, 47-55 (1998)</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>R Mihalcea</author>
</authors>
<date>2007</date>
<booktitle>SemEval-2007 Task 14: Affective Text”</booktitle>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>Strapparava, C., Mihalcea, R.: “SemEval-2007 Task 14: Affective Text” (2007)</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>R Mihalcea</author>
</authors>
<title>Learning to Identify Emotions in Text”,</title>
<date>1556</date>
<booktitle>Proc. ACM Symposium on Applied computing,</booktitle>
<location>Fortaleza,</location>
<marker>Strapparava, Mihalcea, 1556</marker>
<rawString>Strapparava, C., Mihalcea, R.: “Learning to Identify Emotions in Text”, Proc. ACM Symposium on Applied computing, Fortaleza, Brazil, 1556-1560 (2008)</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity: an exploration of features for phrase-level sentiment analysis”,</title>
<date>2009</date>
<journal>Computational Linguistics</journal>
<volume>35</volume>
<issue>3</issue>
<pages>399--433</pages>
<contexts>
<context position="2589" citStr="Wilson et al., 2009" startWordPosition="385" endWordPosition="388"> was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hierarchical structure. The categories are partially ordered, usually from more generic to more specific. Koller and Sahami (1997) carried out the first proper study of</context>
<context position="7576" citStr="Wilson et al. 2009" startWordPosition="1147" endWordPosition="1150">for the accuracies of our classifiers (since the poorest baseline classifier could always choose the most frequent class). Table 1. Datasets specifications. Domain Size # classes Min-Max% Aman’s Weblogs 2090 7 6-38 % Data set Alm’s Stories 1207 5 9-36% Data set 2.2 Feature sets In (Ghazi et al., 2010), three sets of features – one corpus-based and two lexically-based – are compared on Aman’s datasets. The first experiment is a corpus-based classification which uses unigrams (bag-of-words). In the second experiment, classification was based on features derived from the Prior-Polarity lexicon1 (Wilson et al. 2009); the features were the tokens common between the prior-polarity lexicon and the chosen dataset. In the last experiment, we used a combination of the emotional lists of words from Roget’s Thesaurus2 (Aman and Szpakowicz, 2008) and WordNet Affect3 (Strapparava and Valitutti, 2004); we call it the polarity feature set. 1 www.cs.pitt.edu/mpqa 2 The 1987 Penguin’s Roget’s Thesaurus was used. 3 www.cse.unt.edu/~rada/affective text/data/WordNetAffectEmotioLists.tar.gz 141 Based on the results and the discussion in (Ghazi et al., 2010), we decided to use the polarity feature set in our experiments. T</context>
<context position="12256" citStr="Wilson et al., 2009" startWordPosition="1896" endWordPosition="1899">esting on new sentences: the classifiers are applied in a pipeline order: level 1, then level 2 on the results of the previous level (then level 3 if we are in the three-level setting). In the next section, we show the experiments and results on our chosen datasets. 3 Results and discussions 3.1 Two-level classification This section has two parts. The main goal of the first part is to find out how the presence of neutral instances affects the performance of features for distinguishing between emotional classes in Aman’s dataset. This was motivated by a similar work in polarity classification (Wilson et al., 2009). In the second part, we discuss the effect of considering positive and negative polarity of emotions for five affect classes in Alm’s dataset. 142 Table 2. Two-level emotional classification on Aman’s dataset (the highest precision, recall, and F-measure values for each class are shown in bold). The results of the flat classification are repeated for convenience. Two-level classification Flat classification Precision Recall F-measure Precision Recall F-measure 1st level emo 0.88 0.85 0.86 -- -- -- non-emo 0.88 0.81 0.84 0.54 0.87 0.67 happiness 0.59 0.95 0.71 0.74 0.60 0.66 2nd level sadness </context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Wilson, T., Wiebe, J., Hoffmann, P.: “Recognizing contextual polarity: an exploration of features for phrase-level sentiment analysis”, Computational Linguistics 35(3), 399-433 (2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>C Cardie</author>
</authors>
<title>Annotating Expressions of Opinions and</title>
<date>2005</date>
<journal>Emotions in Language”, Language Resources and Evaluation</journal>
<volume>39</volume>
<pages>165--210</pages>
<contexts>
<context position="2426" citStr="Wiebe et al., 2005" startWordPosition="359" endWordPosition="362"> categories. They developed a commonsense affect model enabling the analysis of the affective qualities of text in a robust way. In SemEval 2007, one of the tasks was carried out in an unsupervised setting and the emphasis was on the study of emotion in lexical semantics (Strapparava and Mihalcea, 2008; Chaumartin, 2007; Kozareva et al., 2007; Katz et al., 2007). Neviarouskaya et al.(2009) applied a rule-based approach to affect recognition from a blog text. However, statistical and machine learning approaches have became a method of choice for constructing a wide variety of NLP applications (Wiebe et al., 2005). There has been previous work using statistical methods and supervised machine learning, including (Aman, 2007; Katz et al., 2007; Alm, 2008; Wilson et al., 2009). Most of that research concentrated on feature selections and applying lexical semantics rather than on different learning schemes. In particular, only flat classification has been considered. According to Kiritchenko et al. (2006), “Hierarchical categorization deals with categorization problems where categories are organized in hierarchies”. Hierarchical text categorization places new items into a collection with a predefined hiera</context>
<context position="5588" citStr="Wiebe et al., 2005" startWordPosition="832" endWordPosition="835">ity and polarity together. Our experiments on data annotated with emotions show performance which exceeds that of the corresponding flat approach. Section 2 of this paper gives an overview of the datasets and feature sets. Section 3 describes both hierarchical classification methods and their evaluation with respect to flat classification results. Section 4 discusses future work and presents a few conclusions. 2 Data and Feature Sets 2.1 Datasets The statistical methods typically require training and test corpora, manually annotated with respect to each language-processing task to be learned (Wiebe et al., 2005). One of the datasets in our experiments is a corpus of blog sentences annotated with Ekman’s emotion labels (Aman, 2007). The second dataset is a sentence-annotated corpus resource divided into three parts for large-scale exploration of affect in children’s stories (Alm, 2008). In the first dataset, each sentence is tagged by a dominant emotion in the sentence, or labelled as non-emotional. The dataset contains 173 weblog posts annotated by two judges. Table 1 shows the details of the dataset. In the second dataset, two annotators have annotated 176 stories. The affects considered are the sam</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Wiebe, J., Wilson, T., Cardie, C.: “Annotating Expressions of Opinions and Emotions in Language”, Language Resources and Evaluation 39, 165-210 (2005)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>