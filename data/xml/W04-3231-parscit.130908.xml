<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000024">
<title confidence="0.996252">
A Hybrid Model for Morpho-Syntactic Annotation of German
with a Large Tagset
</title>
<author confidence="0.946095">
Julia TRUSHKINA and Erhard HINRICHS,
</author>
<affiliation confidence="0.989334">
University of Tubingen,
</affiliation>
<address confidence="0.605826">
Seminar fiir Sprachwissenschaft, Wilhelmstrasse 19,
72074 Tubingen, Germany,
j ulAsfs . uni-tuebingen. de , ehAsfs . uni-tuebingen. de
</address>
<sectionHeader confidence="0.863951" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999955777777778">
This paper presents a hybrid rule-based and sta-
tistical model for morpho-syntactic annotation
of German, a highly ambiguous inflectional lan-
guage. The proposed model makes use of a man-
ually annotated corpus of moderate size and at-
tains an accuracy of 92.04%, which corresponds
to a 7.34% improvement of the best results re-
ported by other researchers for the task of an-
notation of German with a large tagset.
</bodyText>
<sectionHeader confidence="0.993776" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991350369230769">
Morphological information, such as case, num-
ber and gender, plays an important role in pars-
ing highly inflectional languages, such as Ger-
man and Czech. It can help to resolve syntactic
ambiguity in chunking and is particularly use-
ful in dependency parsing of languages with free
word-order, since it partly determines the argu-
ment structure of the sentence.
More often than not, tagsets standardly used
for part-of-speech (POS) tagging do not reflect
fine-grained morphological distinctions within
word classes, since the inclusion of morpholo-
gical information in POS labels typically results
in large tagsets. For example, for Czech a tagset
containing more than a thousand tags was re-
ported in (Hajie and Hladka, 1997). This in
turn raises the question as to which methods
are suitable for automatic assignment of POS
labels with tagsets of such size and the accom-
panying data sparseness problem.
A stochastic approach that aims at reduc-
ing data-sparseness for large tagsets has been
described in (Tufi§, 2000). The approach is
based on the idea of using a reduced tagset for
an intermediate n-gram tagging step. It pro-
vides high accuracy for Romanian and Hunga-
rian. However, as was shown in (Hinrichs and
Trushkina, 2003), the approach has a rather low
performance on German data due to the higher
ambiguity rate of German (cf. statistics in Ta-
ble 1).
For Czech, a hybrid model with rule-based
and statistical modules (Hajie et al., 2001)
has yielded excellent results. A similar hy-
brid tagging system was successfully designed
for English (Tapanainen and Voutilainen, 1994).
Given the previous success of hybrid models for
other languages, the purpose of this paper is to
apply such models for German, which, due to
its high ambiguity rates, provides a particularly
challenging case for the task at hand.
2 Architecture of the model
The model has a layered and sequential ar-
chitecture consisting of morphological analysis,
rule-based disambiguation and statistical tag-
ging. The order of these modules reflects the
relative strengths of the rule-based and statisti-
cal methods involved.
The morphological analyzer provides all pos-
sible analyses for a given sequence of tokens.
This highly ambiguous output is then fed to the
rule-based module. Its task is to reduce the can-
didate analyses to be considered by the statis-
tical module. If used cautiously, the rule-based
method will rule out only those candidates for
which it has sufficient evidence and will retain
all those that are contextually plausible. The
task of the statistical module is to disambiguate
the remaining cases of ambiguity. Statistical
disambiguation is made considerably easier by
the rule-based pre-filtering module, since the re-
maining set of hypotheses is greatly reduced.
This reduction in search space corresponds to a
gain in precision compared to purely statistical
disambiguation.
</bodyText>
<sectionHeader confidence="0.989363" genericHeader="introduction">
3 Data
</sectionHeader>
<bodyText confidence="0.999753">
The taz newspaper portion of the Tübingen
Treebank of German (Tfil3a-D/Z) (Telljohann
et al., 2003) provides the basis for the expe-
riments reported in this paper. The treebank
is manually annotated with morphological in-
formation, constituent structures and argument
</bodyText>
<note confidence="0.5372535">
language and source of the statistics average # ambiguous tagset
analyses tokens size
</note>
<table confidence="0.927917875">
German (current paper) 7.10 68.87% 718
Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171
(Hajie and Hladka, 1997) 2.36 not avail. 882
Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail.
English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139
German (STTS) (current paper) 1.77 39.57% 54
Romanian (Tufi§, 2000) 1.71 38.17% 410
Hungarian (Tufi§ et al., 2000) 1.33 31.90% &gt; 1265
</table>
<tableCaption confidence="0.999901">
Table 1: Ambiguity of German data in comparison to other languages
</tableCaption>
<bodyText confidence="0.99986305">
function information. The treebank tagset is
based on the Stuttgart-Tübingen tagset (STTS)
(Schiller et al., 1995), the widely accepted in-
ventory of POS categories for German, which
contains 54 distinct POS labels. The STTS
tagset is enriched by morpho-syntactic features
such as case, number, person, gender, tense and
mood. The resulting tagset distinguishes 718
tags. The treebank tagset is used in the statis-
tical and combined model experiments, as well
as in the evaluation of all modules. 11 361 to-
kens from the corpus were set apart for test data
and 5 891 tokens for development data. 104 049
tokens were used as training data. The statis-
tical component also uses 115 098 tokens from
the second part of the treebank for weakly su-
pervised training. These tokens are annotated
only with constituent structures and argument
functions and do not have morphological infor-
mation.
</bodyText>
<sectionHeader confidence="0.959958" genericHeader="method">
4 Data ambiguity
</sectionHeader>
<bodyText confidence="0.991111375">
Table 1 presents ambiguity rates for German
estimated on the test data. Analyses for the to-
kens in the test data were generated by the Xe-
rox morphological analyzer&apos; and then mapped
into the treebank tagset. The average number
of analyses is counted as the ratio between the
number of analyses assigned to the tokens in the
text and the total number of tokens in the text.
The percentage of ambiguous tokens in the data
is provided in column 3.
For comparison, ambiguity rates reported in
the literature for other languages, as well as for
pure POS tagging of German, are included in
the table. What this comparison shows is that
morpho-syntactic annotation of German consti-
tutes a much harder task than the same prob-
</bodyText>
<footnote confidence="0.509595">
&apos;Consult www.xrce.xerox.com/competencies/content-
analysis/demos/german.de.html for more information.
</footnote>
<bodyText confidence="0.999408111111111">
lem for other languages or for pure POS tagging
of German. The average number of analyses is
double that of Czech and at least by factor of
4 higher than for the other languages and for
POS tagging of German. This is reflected in
the percentage of ambiguous tokens, which is
almost twice as big compared to Romanian and
to POS tagging of German and more than twice
compared to Hungarian.
</bodyText>
<sectionHeader confidence="0.823301" genericHeader="method">
5 Rule-based disambiguation module
</sectionHeader>
<bodyText confidence="0.999928086956522">
The initial set of analyses for the rule-based
disambiguation module is provided by the Xe-
rox morphological analyzer, whose tagset makes
even more fine-grained distinctions than the
treebank tagset. These finer distinctions are
in some cases useful in order to precisely deli-
neate the applicability of highly specific disam-
biguation rules. After rule-based disambigua-
tion the Xerox tagset is mapped into the tree-
bank tagset, which is used by the statistical
module.
The rule-based disambiguation module was
developed in the Xerox Incremental Parsing
System (XIP) (Ait-Mokhtar et al., 2002). It
consists of a POS disambiguation submodule
and a subsequent morphological disambigua-
tion submodule. An earlier version of the mor-
phological disambiguation submodule which ap-
plied to noun phrases only was described in
(Hinrichs and Trushkina, 2002). This submo-
dule has now been generalized to other parts of
speech and has been combined with POS dis-
ambiguation submodule.
</bodyText>
<subsectionHeader confidence="0.967823">
5.1 Disambiguation rules
</subsectionHeader>
<bodyText confidence="0.998086833333333">
Two types of disambiguation rules are used in
the XIP system: syntactic heuristics and con-
cord rules. They jointly provide an effective way
to reduce morpho-syntactic ambiguity.
Concord rules are based on mutual agree-
ment constraints between lexical nodes within
one phrase, e.g. between articles and nouns
within one noun phrase. They are, therefore,
best suited for morphological disambiguation of
lexical nodes that make up phrasal categories.
Syntactic heuristics rely on constraints that a
surrounding context imposes on the set of pos-
sible analyses for a given token and can, there-
fore, be used for both POS and morphological
disambiguation.
In the remainder of the subsection we will il-
lustrate the use of the two types of rules with
sentence (1).2
</bodyText>
<equation confidence="0.974874">
(1) Der/ART/PRELS/PDS Fahrer/NN
konnte/VMFIN nicht/PTKNEG
mehr/ADV/VVIMP/PIS/PIAT brem-
sen/VVFIN/VVINF.
</equation>
<bodyText confidence="0.973755613333333">
The driver could not break anymore.
The POS-disambiguation module applies its
rules in sequential order, eliminating readings
that violate constraints stated in the rules.
First, the relative pronoun reading (PRELS) can
be eliminated in sentence-initial position. The
demonstrative pronoun reading (PDS) is also
ungrammatical in sentence-initial position fol-
lowed by an unambiguous noun (NN) and a fi-
nite verb (VMFIN), since it cannot construct
a phrase with the noun. This constraint re-
lies on the theory of topological fields (Hale,
1985), according to which only one element or
phrase can occupy a Vorfeld position (i.e., the
position between a clause boundary and a finite
verb). A finite verb reading (VVFIN) of brem-
sen in clause-final position can be eliminated
since there is a preceding unambiguous finite
verb. An imperative verb reading (VVIMP) is
ungrammatical in a non-clause-initial position
and can also be deleted.
All the constraints mentioned above eliminate
ungrammatical readings. Another possible op-
eration of the disambiguation rules is to identify
the correct analysis among the set of legitimate
readings and to delete all the others. A heuris-
tic of this type chooses an adverbial reading for
mehr if the immediate left context contains a
negation particle (PTKNEG).
After the application of POS disambigua-
tion rules the sentence is further processed
by the morphological disambiguation module.
2For expository purposes, (1) shows only POS ambi-
guity but ignores morphological features.
Table 2 demonstrates the remaining mor-
phological ambiguity for each token of the
sentence. Morphological information is en-
coded in the tags after the fullstop separa-
tor. For articles and nouns this informa-
tion contains case (accusative, dative, genitive
or nominative), number (singular or plural)
and gender (feminine, masculine, neutral or
underspecified (*)) values; verbal morphology
includes person (1st, 2nd or 3rd), number
(singular or plural), mood (indicative or sub-
junctive (k)) and tense (past or present) values.
(2) Der ART.dsf, ART.gsf, ART.nsm
ART.gp*, ART.gpf, ART.gpn,
ART.gpm
Fahrer NN.asm, NN.dsm, NN.nsm
NN.apm, NN.gpm, NN.npm
konnte VVFIN.3sit, VVFIN.1sit
nicht PTKNEG
mehr ADV
bremsen VVINF
$.
Concord rules in the morphological disam-
biguation module rely on the fact that lexical
nodes within the same NP mutually constrain
each other as to the set of possible readings.
Application of such rules leads to elimination of
all non-shared readings on tokens Der Fahrer,
reducing the set of possible analyses to . gpm
and .nsm for both tokens. Further disambigua-
tion of the tokens Der Fahrer is performed by a
syntactic heuristic that restricts the use of geni-
tive NPs to positions preceded by a preposition
or another NP. Resolving the person ambiguity
of the finite verb is based on the absence of a
nominative pronoun with first person value in
the clause, which allows to eliminate the first
person reading of the verb.
This example has shown that concord rules in
conjunction with syntactic heuristics can effec-
tively reduce the number of candidate readings.
</bodyText>
<subsectionHeader confidence="0.996889">
5.2 Evaluation of the rule-based
disambiguation module
</subsectionHeader>
<bodyText confidence="0.999867333333333">
Table 2 provides the results of the experi-
ments with the rule-based disambiguation mo-
dule. The first line gives a baseline for the
module performance as the performance of the
morphological analyzer. The next two lines
stand for the POS and morphological disam-
biguation modules, respectively.
The table contains numbers for precision, re-
call and f-measure, as well as the percentage of
</bodyText>
<table confidence="0.901904166666667">
ambiguity
module precision recall F-measure LE DE tokens rate
morph. analyzer 13.61% 96.64% 23.86% 100% 0% 68.76% 9.87
POS disamb. 19.93% 96.11% 33.01% 86.01% 13.99% 59.79% 7.39
morph. disamb. 42.53% 94.86% 58.73% 64.51% 35.49% 31.05% 4.96
+ adding analyses 46.93% 95.64% 62.97% 60.12% 39.88% 30.13% 4.44
</table>
<tableCaption confidence="0.999791">
Table 2: Evaluation of the rule-based disambiguation module
</tableCaption>
<bodyText confidence="0.988853333333333">
ambiguous tokens in the test data together with
the ambiguity rate for ambiguous tokens. To
simplify comparison with the results obtained
by other researchers, the formulas described in
the earlier literature (Hajie et al., 2001) are
used:
</bodyText>
<figure confidence="0.698743142857143">
#Tokens with a correct tag
Precision =
#Analyses generated
#Tokens with a correct tag
#Tokens in data
2 * Precision * Recall
Precision + Recall
</figure>
<bodyText confidence="0.999637927272727">
Following (Volk and Schneider, 1998) we split
the errors made by the module into lexical er-
rors (LE; column 5) and disambiguation errors
(DE; column 6). Lexical errors are caused by
the morphological analyzer: the correct analy-
sis is not present among the set of analyses as-
signed by it. Disambiguation errors are proper
errors of the module: the correct analysis was
deleted during rule application.
As column 5 (LE) of Table 2 shows, the ma-
jority of the errors are lexical errors which are
due to the deficiency of the morphological ana-
lyzer. A big part of such errors concerns foreign
material and proper names — these lexemes do
not contain necessary morphological clues for
successful identification of correct analyses and
are often confused with other parts of speech:
common nouns, adjectives and verbs.
An attempt was made to decrease the initial
error rate caused by the morphological analyzer.
Unknown words were looked up in the exter-
nal list of foreign material words and proper
names extracted from the training data, as well
as in the list of personal names extracted from
the online newspapers of the period of 2001-
2003.3 If the lists contained the unknown word,
the analyses provided by the morphological an-
alyzer were replaced with the analyses from the
lists.4 Performance of the disambiguation mo-
dule run on such an extended input is shown in
the last line of Table 2.
Another major source of lexical errors is the
confusion between adverbs and predicative ad-
jectives, the annotation of which is often guided
by semantic criteria and constitutes a difficult
case for the morphological analyzer. Together
with errors caused by rule over-application, le-
xical errors lead to a decreased recall.
The low precision (46.93%) of the module is
due to the remaining ambiguity on the tokens.
The disambiguation rules are mostly elimina-
tive in nature, and in many cases surrounding
context does not provide enough evidence for
deleting an analysis as ungrammatical.
While for some applications the ambiguity on
30% of tokens and high accuracy may be a rea-
sonable starting point, for dependency parsing,
which relies on unique morphological analyses of
verbs and their arguments and modifiers, such
a high rate of ambiguity constitutes a major
obstacle in reliably identifying the dependency
structure. Therefore, further means for decreas-
ing the ambiguity rate are needed. This addi-
tional disambiguation is performed by the sta-
tistical module.
</bodyText>
<sectionHeader confidence="0.98809" genericHeader="method">
6 Statistical module
</sectionHeader>
<bodyText confidence="0.999882">
(Hinrichs and Trushkina, 2003) have shown that
a tagger based on probabilistic phrase structure
grammars (PCFGs) is better suited for the task
of morpho-syntactic annotation of German than
n-gram taggers, which currently are the most-
widely used class of taggers for natural language
processing. The reason for this lies in the fact
that PCFGs are able to incorporate more global
structural information and can therefore cap-
ture long-distance dependencies between tokens
that have to be taken into account for correct
</bodyText>
<equation confidence="0.9987605">
Recall =
F — measure =
</equation>
<footnote confidence="0.454042">
3Thanks to Christian Biemann for making this list
</footnote>
<table confidence="0.584088666666667">
available for us. 4Analyses were added to 1.62% of tokens in test data.
module precision recall F-measure no tag LE DE
statistical 89.20% 88.10% 88.68% 1.23% 11.55% 88.45%
</table>
<tableCaption confidence="0.99917">
Table 3: Evaluation of the statistical module
</tableCaption>
<bodyText confidence="0.9970231">
assignment of morpho-syntactic categories.5
A PCFG tagger described in (Hinrichs and
Trushkina, 2003) was used as a statistical mo-
dule of the combined system presented in the
current paper. The tagger was retrained on a
larger set of training data. The initial grammar
and lexicon of the tagger were also extended.
The extension involved inclusion of new rules
in the grammar and of new tokens and their
analyses in the lexicon.
</bodyText>
<subsectionHeader confidence="0.996445">
6.1 PCFG tagger
</subsectionHeader>
<bodyText confidence="0.992652085106383">
The PCFG parser LoPar (Schmid, 2000) was
used in the statistical module experiments.
LoPar provides a tagging mode which defines
the best tag sequence as the sequence of those
tags that yield the maximal product of the in-
side and outside probabilities among the can-
didate tags for a given token. Thus, the tag-
ger bases its decision about tag assignment on
both the probability of a tag, given the token,
and the probability of a tag, given the full sur-
rounding context of the token. However, due to
the independence assumption about the distri-
bution of words and phrases which is inherent
in the PCFGs, the influence of the surround-
ing context tends to decrease the further it is
removed from the focus token. To weaken this
independence assumption, systematic transfor-
mations of the tree structures and enrichment of
the node label set are introduced so as to boost
those contextual features that are external to
individual local trees.
The tagger was trained on the 104 048 tokens
from the Tfiba-D/Z treebank with transformed
tree representations. In line with techniques
and insights of (Pereira and Schabes, 1992),
115 098 tokens from the second part of the tree-
bank are used for weakly supervised training of
the statistical module. These tokens, although
5We are aware of the fact that the term long-distance
dependencies in linguistics usually refers to unbound de-
pendencies between fillers and arguments. Here we are
using the term more loosely to refer to dependencies be-
tween tokens that more often than not involve a large
context window. Well-known cases of this sort in Ger-
man are dependencies between verbs and separable ver-
bal particles (the latter can be confused with adverbs,
pre- or postpositions) and between finite and non-finite
verbs in complex verb forms.
tagged and labeled only partially, help to reduce
data sparseness problem and lead to improved
performance. Further improvement is due to
the inclusion of 60 901 tokens from the Negra
corpus into the tagger lexicon. The lexicon is
also extended by a list of possible morphologi-
cal analyses for each unknown word.6 The eval-
uation of the statistical module is given in the
next subsection.
</bodyText>
<subsectionHeader confidence="0.999619">
6.2 Evaluation of the statistical module
</subsectionHeader>
<bodyText confidence="0.9999873">
Table 3 summarizes the performance of the sta-
tistical module. Precision, recall and f-measure
are calculated in the same way as for the rule-
based module. The additional metric no tag
represents the percentage of tokens for which no
tag was assigned. The tagger is unable to assign
a tag to a token if the PCFG cannot provide any
parse for a sentence due to data sparseness.7
In case of the statistical module, errors are
considered lexical if the correct tag is not
present in the lexicon of the tagger. Otherwise
they are viewed as disambiguation errors.8 It
is important to note that the set of analyses
provided for a token in the input of the rule-
based module may be different from the set of
analyses contained in the tagger lexicon for the
same token, since the tagger lexicon is com-
piled from the training data and augmented by
the analyses from the morphological analyzer
for unknown tokens, whereas the input for the
rule-based module consists almost exclusively of
the analyses provided by the morphological an-
alyzer.9 Therefore, the tagger lexicon may con-
tain correct analyses for words which are un-
known to the morphological analyzer. Given
that the test and the training data come from
the same source of newspaper articles, such im-
provement of the tagger lexicon over the mor-
phological analyzer often happens for proper
names and foreign material tokens. This fact,
</bodyText>
<footnote confidence="0.997959875">
6Such a list was generated by the Xerox morphologi-
cal analyzer.
7This adverse effect on recall is clearly due to the
modest size of the training data and should be alleviated
as more training data are added.
8Distribution of errors is given only for tagged tokens.
&apos;Only for some unknown tokens analyses were taken
from the external lists.
</footnote>
<table confidence="0.970091333333333">
experiments precision recall F-measure no tag LE RBE SE
full input 90.23% 86.29% 88.22% 4.37% 0% 42.98% 57.02%
partial input 90.59% 87.67% 89.11% 3.23% 8.12% 19.54% 72.34%
</table>
<tableCaption confidence="0.999612">
Table 4: Evaluation of the combined model
</tableCaption>
<bodyText confidence="0.999784230769231">
together with the fact that the statistical mo-
dule has to assign only one tag, explains the
opposite distribution of lexical and disambigua-
tion errors for the statistical module.
The combined model aims at bringing to-
gether the strengths of the rule-based and the
statistical approaches: the rule-based module
accurately narrows down the set of possible
analyses for input tokens and provides unique
analyses for almost 70% of the tokens. The sta-
tistical module resolves the remaining ambigu-
ity, selecting for every token the most probable
reading, given the context.
</bodyText>
<sectionHeader confidence="0.967343" genericHeader="method">
7 Combined model
</sectionHeader>
<bodyText confidence="0.999854984375">
Two experiments were performed with the com-
bined model. In the first experiment all analy-
ses left after application of the rule-based mo-
dule are provided as input to the statistical mo-
dule. The search space of the statistical module
is thus restricted to the readings that the rule-
based component considers grammatical. In
case there is a single analysis for a token avail-
able, it remains unchanged. The main advan-
tage of such a strategy is the elimination of un-
grammatical readings prior to probabilistic pro-
cessing. This helps to avoid errors made in cases
that are traditionally hard for statistical mo-
dels and are comparatively easy for rule-based
approaches (such as long distance dependencies
among tags). The drawback of the strategy,
however, consists in carrying all the errors of
the rule-based component into the final model
performance, which mainly concerns unknown
words: the rule-based module will produce an
error if the lexicon or the guesser of the mor-
phological analyzer provides a set of hypotheses
that does not include the correct analysis.
In the second experiment the input to the sta-
tistical model was limited to the categories that
are most reliably tagged by the rule-based mo-
dule. This provides the intended division of la-
bor between the two modules according to their
strengths: the rule-based component eliminates
analyses in sure cases and performs disambigua-
tion based on long-distance relations, whereas
the statistical module resolves remaining ambi-
guity and assigns tags to unknown tokens.
The input to the statistical model in the se-
cond experiment was prepared in the follow-
ing way: all unambiguous analyses produced by
the rule-based module are included in the in-
put, except for the analyses of predicative ad-
jectives (the morphological analyzer often mis-
takens them for adverbs), of imperative verbs
(these are often erroneous analyses that are ac-
tually foreign material), and of proper nouns
without morphology. In addition, all analyses
that have unambiguous POS readings of arti-
cle, attributive adjective, finite verb, demon-
strative, relative or personal pronoun are in-
cluded in the input for the statistical module,
since these parts of speech in most cases are
tagged correctly by the rule-based module and
since resolution of remaining morphological am-
biguity for them does not usually constitute a
problem for the statistical module. Due to the
unreliable treatment of unknown words by the
rule-based component, the statistical module is
used as its own pre-processor to identify cate-
gories that most often correspond to unknown
words. These categories include foreign mate-
rial (FM), special symbols (XY) and pronomi-
nal adverbs (PROP). The tags for these cate-
gories are then included into the input to the
combined model, replacing the analyses of the
rule-based module.
The results achieved in the experiments de-
scribed above are given in the next subsection.
</bodyText>
<subsectionHeader confidence="0.990016">
7.1 Evaluation of the combined model
</subsectionHeader>
<bodyText confidence="0.999582083333333">
Table 4 presents the performance of the com-
bined model. The first line provides statistics
for the model that takes full input from the rule-
based module. The second line demonstrates
performance of the model that takes partial in-
put of most reliable categories from the rule-
based component. To reflect the impact of the
errors by the rule-based component on the error
rate of the model, the disambiguation errors are
split into errors of the rule-based module (RBE;
column 7) and errors of the statistical module
(SE; column 8).
</bodyText>
<table confidence="0.996754">
errors POS case number gender person tense mood
SE 27.54% 40.51% 2.01% 10.03% 0.94% 0.00% 0.80%
RBE 62.87% 20.79% 1.49% 2.48% 0.00% 0.00% 0.00%
LE 70.24% 5.95% 3.57% 1.19% 0.00% 0.00% 0.00%
all 37.91% 33.85% 2.03% 7.83% 0.68% 0.00% 0.58%
</table>
<tableCaption confidence="0.996829">
Table 5: Error analysis for the combined model with partial input
</tableCaption>
<table confidence="0.976484666666667">
experiments precision recall F-measure no tag LE RBE SE
full input 92.04% 88.35% 90.16% 4.00% 0% 22.93% 77.07%
partial input 91.82% 89.02% 90.40% 3.05% 0% 10.21% 89.79%
</table>
<tableCaption confidence="0.999218">
Table 6: Evaluation of the combined model given the perfect lexicon
</tableCaption>
<subsectionHeader confidence="0.871838">
7.2 Error analysis for the best model
</subsectionHeader>
<bodyText confidence="0.990407365853659">
Table 5 demonstrates the distribution of errors
among the morpho-syntactic features. In the
second column (POS) the percentage of errors
involving POS categories is presented. Columns
3-6 provide the error distribution that occur
(only) in one of the morphological feature va-
lues, while the values of the other morphological
features and of the POS category are correct.
Errors involving more than one morphological
feature are ignored, since in such cases it is un-
clear which feature is ultimately responsible for
the error. Isolating errors of morphological fea-
tures in this way clearly demonstrates that case,
together with POS, is the hardest category to
disambiguate correctly.
8 Using a perfect lexicon
The error analysis of the model performance
demonstrates a high rate of lexical errors, i.e.
errors caused by the deficiency of the mor-
phological analyzer: lexical errors amount to
11.55% in the statistical module (see Table 3)
and to 60.12% in the rule-based module (see Ta-
ble 2). An additional experiment which aims at
the evaluation of the proper model and disre-
gards the initial lexical error rate was designed.
In this experiment, a set of possible analyses for
every token was augmented by a correct ana-
lysis in case it was not originally provided by
the morphological analyzer. The data were fur-
ther processed as described in the experiments
above. The experiment facilitates comparison
of the current model to the models described
in the literature which usually assume a perfect
lexicon available.10
1°Compare, for example, the recall of 100% reported
for the morphological analyzer in (Haji6 et al., 2001).
The performance of the model given the per-
fect lexicon is shown in Table 6. The im-
provement over the basic model performance
amounts to 1.29% in f-measure and 1.45% in
precision.
</bodyText>
<sectionHeader confidence="0.977219" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999982285714286">
The combined model outperforms the rule-
based and statistical modules applied in iso-
lation. The best result of the model attains
an accuracy of 92.04%, which corresponds to a
7.34% improvement of the best results reported
by other researchers for the same task for Ger-
man (Lezius et al., 1996).
By comparison, the best results for standard
POS tagging of German achieved an accuracy of
96.70% (Brants, 1998). The difference in per-
formance reflects the relative difficulty of the
task. Morpho-syntactic annotation with a large
tagset is much harder than standard POS tag-
ging described in (Brants, 1998), since it em-
ploys a tagset which is 13 times larger than
the standard POS tagset STTS used in (Brants,
1998) and since it has to deal with much more
severe data ambiguity (cf. statistics for &amp;quot;Ger-
man&amp;quot; and &amp;quot;German (STTS)&amp;quot; in Table 1).
Expansion of the tagset, on the other hand,
allows for a much higher range of applications
for the tagger. Among the possible applications
is the use of the tagger in dependency parsing.
Identification of the case value on noun phrases
plays a crucial role in correct dependency as-
signment for languages with free word-order,
such as German. To assess the utility of the
model for this task, an additional evaluation on
only the case value (disregarding POS and all
other morphological features) was performed,
resulting in a precision of 92.26%. This eva-
luation demonstrates that the model provides
a sound basis for the correct assignment of de-
pendencies and highlights the applicability of
the model.
</bodyText>
<sectionHeader confidence="0.987768" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996406024691358">
Salah Alt-Mokhtar, Jean-Pierre Chanod, and
Claude Roux. 2002. Robustness beyond shal-
lowness: Incremental deep parsing. Journal
of Natural Language Engineering, 8:121-144.
Thorsten Brants, 1998. TnT-A Statistical Part-
of-Speech Tagger. Universitat des Saarlan-
des, Computational Linguistics, Saarbriicken,
Germany.
Jan Hajie and Barbora Hladka. 1997. Proba-
bilistic and rule-based tagger of an inflective
language - a comparison. In Proceedings of
ANLP&apos;97, pages 111-118, Washington, D.C.,
USA.
Jan Hajie, Pavel Krbec, Pavel Kvetori, Karel
Oliva, and Vladimir Petkevie. 2001. Se-
rial combination of rules and statistics: A
case study in Czech tagging. In Proceedings
ACL&apos;2001, pages 260-267, Toulouse, France.
Erhard W. Hinrichs and Julia Trushkina. 2002.
Forging agreement: Morphological disam-
biguation of noun phrases. In Proceedings of
the First Workshop on Treebanks and Lin-
guistic Theory (TLT&apos;2002), pages 78-95, So-
zopol, Bulgaria.
Erhard W. Hinrichs and Julia Trushkina. 2003.
N-gram and PCFG models for morpho-
syntactic tagging of German. In Proceedings
of Second Workshop on Tree banks and Lin-
guistic Theories (TLT&apos;2003), pages 177-188,
VaxjO, Sweden.
Tilman HOhle. 1985. Der Begriff &amp;quot;Mittelfeld&amp;quot;,
Anmerkungen fiber die Theorie der topolo-
gischen Felder. In Akten des Siebten Interna-
tionalen Germanistenkongresses 1985, pages
329-340, Gottingen, Germany.
Wolfgang Lezius, Reinhard Rapp, and Man-
fred Wettler. 1996. A morphology-system
and part-of-speech tagger for German. In
Proceedings of KONVENS&apos;96, Bielefeld, Ger-
many.
Kemal Oflazer and GOkhan Tiir. 1996. Com-
bining hand-crafted rules and unsuper-
vised learning in constraint-based morpho-
logical disambiguation. In Proceedings of the
EMNLP&apos;96, Philadelphia, PA, USA.
Fernando Pereira and Yves Schabes. 1992.
Inside-outside reestimation for partially
bracketed corpora. In Proceedings of
ACL&apos;92, pages 128-135, Newark, DE, USA.
Anne Schiller, Simone Teufel, and Christine
Thielen. 1995. Guidelines fiir das Tagging
deutscher Textkorpora mit STTS. Technical
report, Universitat Stuttgart and Universitat
Tübingen, September.
Helmut Schmid 2000. Lopar: Design
and implementation. Technical Report 149,
IMS Stuttgart. Arbeitspapiere des Sonder-
forschungsbereiches 340.
Pasi Tapanainen and Atro Voutilainen. 1994.
Tagging accurately - Don&apos;t guess if you know.
In Proceedings of ANLP&apos;94, Stuttgart, Ger-
many.
Heike Telljohann, Erhard W. Hinrichs, and San-
dra Kiibler, 2003. Stylebook for the Tubingen
Tree bank of Written German (Tikl3a-D/Z).
Seminar fiir Sprachwissenschaft, Universitat
Tübingen, Tübingen, Germany.
Dan Tufi§, Peter Dienes, Csaba Oravecz, and
Things Varadi. 2000. Principled hidden
tagset design for Tiered Tagging of Hun-
garian. In Proceedings of LREC&apos;2000, pages
1421-1426, Athens, Greece.
Dan Tufi§. 2000. Using a large set of EAGLES-
compliant morpho-syntactic descriptors as
a tagset for probabilistic tagging. In Pro-
ceedings of LREC&apos;2000, pages 1105-1112,
Athens, Greece.
Martin Volk and Gerold Schneider. 1998. Com-
paring a statistical and a rule-based tagger for
German. In Proceedings of KONVENS&apos;98,
Bonn, Germany.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.305649">
<title confidence="0.997945">A Hybrid Model for Morpho-Syntactic Annotation of with a Large Tagset</title>
<author confidence="0.994153">Julia TRUSHKINA</author>
<author confidence="0.994153">Erhard</author>
<affiliation confidence="0.985908">University of</affiliation>
<address confidence="0.611067">Seminar fiir Sprachwissenschaft, Wilhelmstrasse 72074 Tubingen,</address>
<email confidence="0.724723">julAsfs.uni-tuebingen.de,ehAsfs.uni-tuebingen.de</email>
<abstract confidence="0.9948179">This paper presents a hybrid rule-based and statistical model for morpho-syntactic annotation of German, a highly ambiguous inflectional language. The proposed model makes use of a manually annotated corpus of moderate size and atan accuracy of which corresponds to a 7.34% improvement of the best results reported by other researchers for the task of annotation of German with a large tagset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah Alt-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>Robustness beyond shallowness: Incremental deep parsing.</title>
<date>2002</date>
<journal>Journal of Natural Language Engineering,</journal>
<pages>8--121</pages>
<marker>Alt-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>Salah Alt-Mokhtar, Jean-Pierre Chanod, and Claude Roux. 2002. Robustness beyond shallowness: Incremental deep parsing. Journal of Natural Language Engineering, 8:121-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT-A Statistical Partof-Speech Tagger. Universitat des Saarlandes, Computational Linguistics,</title>
<date>1998</date>
<location>Saarbriicken, Germany.</location>
<contexts>
<context position="27385" citStr="Brants, 1998" startWordPosition="4405" endWordPosition="4406">et al., 2001). The performance of the model given the perfect lexicon is shown in Table 6. The improvement over the basic model performance amounts to 1.29% in f-measure and 1.45% in precision. 9 Conclusion The combined model outperforms the rulebased and statistical modules applied in isolation. The best result of the model attains an accuracy of 92.04%, which corresponds to a 7.34% improvement of the best results reported by other researchers for the same task for German (Lezius et al., 1996). By comparison, the best results for standard POS tagging of German achieved an accuracy of 96.70% (Brants, 1998). The difference in performance reflects the relative difficulty of the task. Morpho-syntactic annotation with a large tagset is much harder than standard POS tagging described in (Brants, 1998), since it employs a tagset which is 13 times larger than the standard POS tagset STTS used in (Brants, 1998) and since it has to deal with much more severe data ambiguity (cf. statistics for &amp;quot;German&amp;quot; and &amp;quot;German (STTS)&amp;quot; in Table 1). Expansion of the tagset, on the other hand, allows for a much higher range of applications for the tagger. Among the possible applications is the use of the tagger in depen</context>
</contexts>
<marker>Brants, 1998</marker>
<rawString>Thorsten Brants, 1998. TnT-A Statistical Partof-Speech Tagger. Universitat des Saarlandes, Computational Linguistics, Saarbriicken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajie</author>
<author>Barbora Hladka</author>
</authors>
<title>Probabilistic and rule-based tagger of an inflective language - a comparison.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP&apos;97,</booktitle>
<pages>111--118</pages>
<location>Washington, D.C., USA.</location>
<contexts>
<context position="1425" citStr="Hajie and Hladka, 1997" startWordPosition="219" endWordPosition="222">ghly inflectional languages, such as German and Czech. It can help to resolve syntactic ambiguity in chunking and is particularly useful in dependency parsing of languages with free word-order, since it partly determines the argument structure of the sentence. More often than not, tagsets standardly used for part-of-speech (POS) tagging do not reflect fine-grained morphological distinctions within word classes, since the inclusion of morphological information in POS labels typically results in large tagsets. For example, for Czech a tagset containing more than a thousand tags was reported in (Hajie and Hladka, 1997). This in turn raises the question as to which methods are suitable for automatic assignment of POS labels with tagsets of such size and the accompanying data sparseness problem. A stochastic approach that aims at reducing data-sparseness for large tagsets has been described in (Tufi§, 2000). The approach is based on the idea of using a reduced tagset for an intermediate n-gram tagging step. It provides high accuracy for Romanian and Hungarian. However, as was shown in (Hinrichs and Trushkina, 2003), the approach has a rather low performance on German data due to the higher ambiguity rate of G</context>
<context position="3996" citStr="Hajie and Hladka, 1997" startWordPosition="626" endWordPosition="629">d pre-filtering module, since the remaining set of hypotheses is greatly reduced. This reduction in search space corresponds to a gain in precision compared to purely statistical disambiguation. 3 Data The taz newspaper portion of the Tübingen Treebank of German (Tfil3a-D/Z) (Telljohann et al., 2003) provides the basis for the experiments reported in this paper. The treebank is manually annotated with morphological information, constituent structures and argument language and source of the statistics average # ambiguous tagset analyses tokens size German (current paper) 7.10 68.87% 718 Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171 (Hajie and Hladka, 1997) 2.36 not avail. 882 Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail. English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139 German (STTS) (current paper) 1.77 39.57% 54 Romanian (Tufi§, 2000) 1.71 38.17% 410 Hungarian (Tufi§ et al., 2000) 1.33 31.90% &gt; 1265 Table 1: Ambiguity of German data in comparison to other languages function information. The treebank tagset is based on the Stuttgart-Tübingen tagset (STTS) (Schiller et al., 1995), the widely accepted inventory of POS categories for German, which contains 54 distinct POS labels</context>
</contexts>
<marker>Hajie, Hladka, 1997</marker>
<rawString>Jan Hajie and Barbora Hladka. 1997. Probabilistic and rule-based tagger of an inflective language - a comparison. In Proceedings of ANLP&apos;97, pages 111-118, Washington, D.C., USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajie</author>
<author>Pavel Krbec</author>
<author>Pavel Kvetori</author>
<author>Karel Oliva</author>
<author>Vladimir Petkevie</author>
</authors>
<title>Serial combination of rules and statistics: A case study in Czech tagging.</title>
<date>2001</date>
<booktitle>In Proceedings ACL&apos;2001,</booktitle>
<pages>260--267</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="2146" citStr="Hajie et al., 2001" startWordPosition="342" endWordPosition="345">bels with tagsets of such size and the accompanying data sparseness problem. A stochastic approach that aims at reducing data-sparseness for large tagsets has been described in (Tufi§, 2000). The approach is based on the idea of using a reduced tagset for an intermediate n-gram tagging step. It provides high accuracy for Romanian and Hungarian. However, as was shown in (Hinrichs and Trushkina, 2003), the approach has a rather low performance on German data due to the higher ambiguity rate of German (cf. statistics in Table 1). For Czech, a hybrid model with rule-based and statistical modules (Hajie et al., 2001) has yielded excellent results. A similar hybrid tagging system was successfully designed for English (Tapanainen and Voutilainen, 1994). Given the previous success of hybrid models for other languages, the purpose of this paper is to apply such models for German, which, due to its high ambiguity rates, provides a particularly challenging case for the task at hand. 2 Architecture of the model The model has a layered and sequential architecture consisting of morphological analysis, rule-based disambiguation and statistical tagging. The order of these modules reflects the relative strengths of t</context>
<context position="12497" citStr="Hajie et al., 2001" startWordPosition="1959" endWordPosition="1962">ell as the percentage of ambiguity module precision recall F-measure LE DE tokens rate morph. analyzer 13.61% 96.64% 23.86% 100% 0% 68.76% 9.87 POS disamb. 19.93% 96.11% 33.01% 86.01% 13.99% 59.79% 7.39 morph. disamb. 42.53% 94.86% 58.73% 64.51% 35.49% 31.05% 4.96 + adding analyses 46.93% 95.64% 62.97% 60.12% 39.88% 30.13% 4.44 Table 2: Evaluation of the rule-based disambiguation module ambiguous tokens in the test data together with the ambiguity rate for ambiguous tokens. To simplify comparison with the results obtained by other researchers, the formulas described in the earlier literature (Hajie et al., 2001) are used: #Tokens with a correct tag Precision = #Analyses generated #Tokens with a correct tag #Tokens in data 2 * Precision * Recall Precision + Recall Following (Volk and Schneider, 1998) we split the errors made by the module into lexical errors (LE; column 5) and disambiguation errors (DE; column 6). Lexical errors are caused by the morphological analyzer: the correct analysis is not present among the set of analyses assigned by it. Disambiguation errors are proper errors of the module: the correct analysis was deleted during rule application. As column 5 (LE) of Table 2 shows, the major</context>
</contexts>
<marker>Hajie, Krbec, Kvetori, Oliva, Petkevie, 2001</marker>
<rawString>Jan Hajie, Pavel Krbec, Pavel Kvetori, Karel Oliva, and Vladimir Petkevie. 2001. Serial combination of rules and statistics: A case study in Czech tagging. In Proceedings ACL&apos;2001, pages 260-267, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard W Hinrichs</author>
<author>Julia Trushkina</author>
</authors>
<title>Forging agreement: Morphological disambiguation of noun phrases.</title>
<date>2002</date>
<booktitle>In Proceedings of the First Workshop on Treebanks and Linguistic Theory (TLT&apos;2002),</booktitle>
<pages>78--95</pages>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="7362" citStr="Hinrichs and Trushkina, 2002" startWordPosition="1168" endWordPosition="1171">istinctions are in some cases useful in order to precisely delineate the applicability of highly specific disambiguation rules. After rule-based disambiguation the Xerox tagset is mapped into the treebank tagset, which is used by the statistical module. The rule-based disambiguation module was developed in the Xerox Incremental Parsing System (XIP) (Ait-Mokhtar et al., 2002). It consists of a POS disambiguation submodule and a subsequent morphological disambiguation submodule. An earlier version of the morphological disambiguation submodule which applied to noun phrases only was described in (Hinrichs and Trushkina, 2002). This submodule has now been generalized to other parts of speech and has been combined with POS disambiguation submodule. 5.1 Disambiguation rules Two types of disambiguation rules are used in the XIP system: syntactic heuristics and concord rules. They jointly provide an effective way to reduce morpho-syntactic ambiguity. Concord rules are based on mutual agreement constraints between lexical nodes within one phrase, e.g. between articles and nouns within one noun phrase. They are, therefore, best suited for morphological disambiguation of lexical nodes that make up phrasal categories. Synt</context>
</contexts>
<marker>Hinrichs, Trushkina, 2002</marker>
<rawString>Erhard W. Hinrichs and Julia Trushkina. 2002. Forging agreement: Morphological disambiguation of noun phrases. In Proceedings of the First Workshop on Treebanks and Linguistic Theory (TLT&apos;2002), pages 78-95, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard W Hinrichs</author>
<author>Julia Trushkina</author>
</authors>
<title>N-gram and PCFG models for morphosyntactic tagging of German.</title>
<date>2003</date>
<booktitle>In Proceedings of Second Workshop on Tree banks and Linguistic Theories (TLT&apos;2003),</booktitle>
<pages>177--188</pages>
<location>VaxjO,</location>
<contexts>
<context position="1929" citStr="Hinrichs and Trushkina, 2003" startWordPosition="304" endWordPosition="307"> large tagsets. For example, for Czech a tagset containing more than a thousand tags was reported in (Hajie and Hladka, 1997). This in turn raises the question as to which methods are suitable for automatic assignment of POS labels with tagsets of such size and the accompanying data sparseness problem. A stochastic approach that aims at reducing data-sparseness for large tagsets has been described in (Tufi§, 2000). The approach is based on the idea of using a reduced tagset for an intermediate n-gram tagging step. It provides high accuracy for Romanian and Hungarian. However, as was shown in (Hinrichs and Trushkina, 2003), the approach has a rather low performance on German data due to the higher ambiguity rate of German (cf. statistics in Table 1). For Czech, a hybrid model with rule-based and statistical modules (Hajie et al., 2001) has yielded excellent results. A similar hybrid tagging system was successfully designed for English (Tapanainen and Voutilainen, 1994). Given the previous success of hybrid models for other languages, the purpose of this paper is to apply such models for German, which, due to its high ambiguity rates, provides a particularly challenging case for the task at hand. 2 Architecture </context>
<context position="15158" citStr="Hinrichs and Trushkina, 2003" startWordPosition="2394" endWordPosition="2397">ses surrounding context does not provide enough evidence for deleting an analysis as ungrammatical. While for some applications the ambiguity on 30% of tokens and high accuracy may be a reasonable starting point, for dependency parsing, which relies on unique morphological analyses of verbs and their arguments and modifiers, such a high rate of ambiguity constitutes a major obstacle in reliably identifying the dependency structure. Therefore, further means for decreasing the ambiguity rate are needed. This additional disambiguation is performed by the statistical module. 6 Statistical module (Hinrichs and Trushkina, 2003) have shown that a tagger based on probabilistic phrase structure grammars (PCFGs) is better suited for the task of morpho-syntactic annotation of German than n-gram taggers, which currently are the mostwidely used class of taggers for natural language processing. The reason for this lies in the fact that PCFGs are able to incorporate more global structural information and can therefore capture long-distance dependencies between tokens that have to be taken into account for correct Recall = F — measure = 3Thanks to Christian Biemann for making this list available for us. 4Analyses were added t</context>
</contexts>
<marker>Hinrichs, Trushkina, 2003</marker>
<rawString>Erhard W. Hinrichs and Julia Trushkina. 2003. N-gram and PCFG models for morphosyntactic tagging of German. In Proceedings of Second Workshop on Tree banks and Linguistic Theories (TLT&apos;2003), pages 177-188, VaxjO, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman HOhle</author>
</authors>
<title>Der Begriff &amp;quot;Mittelfeld&amp;quot;, Anmerkungen fiber die Theorie der topologischen Felder.</title>
<date>1985</date>
<booktitle>In Akten des Siebten Internationalen Germanistenkongresses</booktitle>
<pages>329--340</pages>
<location>Gottingen, Germany.</location>
<marker>HOhle, 1985</marker>
<rawString>Tilman HOhle. 1985. Der Begriff &amp;quot;Mittelfeld&amp;quot;, Anmerkungen fiber die Theorie der topologischen Felder. In Akten des Siebten Internationalen Germanistenkongresses 1985, pages 329-340, Gottingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Lezius</author>
<author>Reinhard Rapp</author>
<author>Manfred Wettler</author>
</authors>
<title>A morphology-system and part-of-speech tagger for German.</title>
<date>1996</date>
<booktitle>In Proceedings of KONVENS&apos;96,</booktitle>
<location>Bielefeld, Germany.</location>
<contexts>
<context position="27271" citStr="Lezius et al., 1996" startWordPosition="4385" endWordPosition="4388">erfect lexicon available.10 1°Compare, for example, the recall of 100% reported for the morphological analyzer in (Haji6 et al., 2001). The performance of the model given the perfect lexicon is shown in Table 6. The improvement over the basic model performance amounts to 1.29% in f-measure and 1.45% in precision. 9 Conclusion The combined model outperforms the rulebased and statistical modules applied in isolation. The best result of the model attains an accuracy of 92.04%, which corresponds to a 7.34% improvement of the best results reported by other researchers for the same task for German (Lezius et al., 1996). By comparison, the best results for standard POS tagging of German achieved an accuracy of 96.70% (Brants, 1998). The difference in performance reflects the relative difficulty of the task. Morpho-syntactic annotation with a large tagset is much harder than standard POS tagging described in (Brants, 1998), since it employs a tagset which is 13 times larger than the standard POS tagset STTS used in (Brants, 1998) and since it has to deal with much more severe data ambiguity (cf. statistics for &amp;quot;German&amp;quot; and &amp;quot;German (STTS)&amp;quot; in Table 1). Expansion of the tagset, on the other hand, allows for a m</context>
</contexts>
<marker>Lezius, Rapp, Wettler, 1996</marker>
<rawString>Wolfgang Lezius, Reinhard Rapp, and Manfred Wettler. 1996. A morphology-system and part-of-speech tagger for German. In Proceedings of KONVENS&apos;96, Bielefeld, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>GOkhan Tiir</author>
</authors>
<title>Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation.</title>
<date>1996</date>
<booktitle>In Proceedings of the EMNLP&apos;96,</booktitle>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="4095" citStr="Oflazer and Tiir, 1996" startWordPosition="643" endWordPosition="646"> search space corresponds to a gain in precision compared to purely statistical disambiguation. 3 Data The taz newspaper portion of the Tübingen Treebank of German (Tfil3a-D/Z) (Telljohann et al., 2003) provides the basis for the experiments reported in this paper. The treebank is manually annotated with morphological information, constituent structures and argument language and source of the statistics average # ambiguous tagset analyses tokens size German (current paper) 7.10 68.87% 718 Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171 (Hajie and Hladka, 1997) 2.36 not avail. 882 Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail. English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139 German (STTS) (current paper) 1.77 39.57% 54 Romanian (Tufi§, 2000) 1.71 38.17% 410 Hungarian (Tufi§ et al., 2000) 1.33 31.90% &gt; 1265 Table 1: Ambiguity of German data in comparison to other languages function information. The treebank tagset is based on the Stuttgart-Tübingen tagset (STTS) (Schiller et al., 1995), the widely accepted inventory of POS categories for German, which contains 54 distinct POS labels. The STTS tagset is enriched by morpho-syntactic features such as case, number, person, gender, te</context>
</contexts>
<marker>Oflazer, Tiir, 1996</marker>
<rawString>Kemal Oflazer and GOkhan Tiir. 1996. Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation. In Proceedings of the EMNLP&apos;96, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yves Schabes</author>
</authors>
<title>Inside-outside reestimation for partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of ACL&apos;92,</booktitle>
<pages>128--135</pages>
<location>Newark, DE, USA.</location>
<contexts>
<context position="17498" citStr="Pereira and Schabes, 1992" startWordPosition="2781" endWordPosition="2784"> due to the independence assumption about the distribution of words and phrases which is inherent in the PCFGs, the influence of the surrounding context tends to decrease the further it is removed from the focus token. To weaken this independence assumption, systematic transformations of the tree structures and enrichment of the node label set are introduced so as to boost those contextual features that are external to individual local trees. The tagger was trained on the 104 048 tokens from the Tfiba-D/Z treebank with transformed tree representations. In line with techniques and insights of (Pereira and Schabes, 1992), 115 098 tokens from the second part of the treebank are used for weakly supervised training of the statistical module. These tokens, although 5We are aware of the fact that the term long-distance dependencies in linguistics usually refers to unbound dependencies between fillers and arguments. Here we are using the term more loosely to refer to dependencies between tokens that more often than not involve a large context window. Well-known cases of this sort in German are dependencies between verbs and separable verbal particles (the latter can be confused with adverbs, pre- or postpositions) </context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>Fernando Pereira and Yves Schabes. 1992. Inside-outside reestimation for partially bracketed corpora. In Proceedings of ACL&apos;92, pages 128-135, Newark, DE, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Schiller</author>
<author>Simone Teufel</author>
<author>Christine Thielen</author>
</authors>
<title>Guidelines fiir das Tagging deutscher Textkorpora mit STTS.</title>
<date>1995</date>
<tech>Technical report,</tech>
<institution>Universitat Stuttgart and Universitat Tübingen,</institution>
<contexts>
<context position="4497" citStr="Schiller et al., 1995" startWordPosition="705" endWordPosition="708">ics average # ambiguous tagset analyses tokens size German (current paper) 7.10 68.87% 718 Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171 (Hajie and Hladka, 1997) 2.36 not avail. 882 Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail. English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139 German (STTS) (current paper) 1.77 39.57% 54 Romanian (Tufi§, 2000) 1.71 38.17% 410 Hungarian (Tufi§ et al., 2000) 1.33 31.90% &gt; 1265 Table 1: Ambiguity of German data in comparison to other languages function information. The treebank tagset is based on the Stuttgart-Tübingen tagset (STTS) (Schiller et al., 1995), the widely accepted inventory of POS categories for German, which contains 54 distinct POS labels. The STTS tagset is enriched by morpho-syntactic features such as case, number, person, gender, tense and mood. The resulting tagset distinguishes 718 tags. The treebank tagset is used in the statistical and combined model experiments, as well as in the evaluation of all modules. 11 361 tokens from the corpus were set apart for test data and 5 891 tokens for development data. 104 049 tokens were used as training data. The statistical component also uses 115 098 tokens from the second part of the</context>
</contexts>
<marker>Schiller, Teufel, Thielen, 1995</marker>
<rawString>Anne Schiller, Simone Teufel, and Christine Thielen. 1995. Guidelines fiir das Tagging deutscher Textkorpora mit STTS. Technical report, Universitat Stuttgart and Universitat Tübingen, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Lopar: Design and implementation.</title>
<date>2000</date>
<booktitle>IMS Stuttgart. Arbeitspapiere des Sonderforschungsbereiches 340.</booktitle>
<tech>Technical Report 149,</tech>
<contexts>
<context position="16417" citStr="Schmid, 2000" startWordPosition="2601" endWordPosition="2602">on recall F-measure no tag LE DE statistical 89.20% 88.10% 88.68% 1.23% 11.55% 88.45% Table 3: Evaluation of the statistical module assignment of morpho-syntactic categories.5 A PCFG tagger described in (Hinrichs and Trushkina, 2003) was used as a statistical module of the combined system presented in the current paper. The tagger was retrained on a larger set of training data. The initial grammar and lexicon of the tagger were also extended. The extension involved inclusion of new rules in the grammar and of new tokens and their analyses in the lexicon. 6.1 PCFG tagger The PCFG parser LoPar (Schmid, 2000) was used in the statistical module experiments. LoPar provides a tagging mode which defines the best tag sequence as the sequence of those tags that yield the maximal product of the inside and outside probabilities among the candidate tags for a given token. Thus, the tagger bases its decision about tag assignment on both the probability of a tag, given the token, and the probability of a tag, given the full surrounding context of the token. However, due to the independence assumption about the distribution of words and phrases which is inherent in the PCFGs, the influence of the surrounding </context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Helmut Schmid 2000. Lopar: Design and implementation. Technical Report 149, IMS Stuttgart. Arbeitspapiere des Sonderforschungsbereiches 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pasi Tapanainen</author>
<author>Atro Voutilainen</author>
</authors>
<title>Tagging accurately - Don&apos;t guess if you know.</title>
<date>1994</date>
<booktitle>In Proceedings of ANLP&apos;94,</booktitle>
<location>Stuttgart, Germany.</location>
<contexts>
<context position="2282" citStr="Tapanainen and Voutilainen, 1994" startWordPosition="361" endWordPosition="364">ata-sparseness for large tagsets has been described in (Tufi§, 2000). The approach is based on the idea of using a reduced tagset for an intermediate n-gram tagging step. It provides high accuracy for Romanian and Hungarian. However, as was shown in (Hinrichs and Trushkina, 2003), the approach has a rather low performance on German data due to the higher ambiguity rate of German (cf. statistics in Table 1). For Czech, a hybrid model with rule-based and statistical modules (Hajie et al., 2001) has yielded excellent results. A similar hybrid tagging system was successfully designed for English (Tapanainen and Voutilainen, 1994). Given the previous success of hybrid models for other languages, the purpose of this paper is to apply such models for German, which, due to its high ambiguity rates, provides a particularly challenging case for the task at hand. 2 Architecture of the model The model has a layered and sequential architecture consisting of morphological analysis, rule-based disambiguation and statistical tagging. The order of these modules reflects the relative strengths of the rule-based and statistical methods involved. The morphological analyzer provides all possible analyses for a given sequence of tokens</context>
<context position="4161" citStr="Tapanainen and Voutilainen, 1994" startWordPosition="652" endWordPosition="655">d to purely statistical disambiguation. 3 Data The taz newspaper portion of the Tübingen Treebank of German (Tfil3a-D/Z) (Telljohann et al., 2003) provides the basis for the experiments reported in this paper. The treebank is manually annotated with morphological information, constituent structures and argument language and source of the statistics average # ambiguous tagset analyses tokens size German (current paper) 7.10 68.87% 718 Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171 (Hajie and Hladka, 1997) 2.36 not avail. 882 Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail. English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139 German (STTS) (current paper) 1.77 39.57% 54 Romanian (Tufi§, 2000) 1.71 38.17% 410 Hungarian (Tufi§ et al., 2000) 1.33 31.90% &gt; 1265 Table 1: Ambiguity of German data in comparison to other languages function information. The treebank tagset is based on the Stuttgart-Tübingen tagset (STTS) (Schiller et al., 1995), the widely accepted inventory of POS categories for German, which contains 54 distinct POS labels. The STTS tagset is enriched by morpho-syntactic features such as case, number, person, gender, tense and mood. The resulting tagset distinguishes 718 tags. The tre</context>
</contexts>
<marker>Tapanainen, Voutilainen, 1994</marker>
<rawString>Pasi Tapanainen and Atro Voutilainen. 1994. Tagging accurately - Don&apos;t guess if you know. In Proceedings of ANLP&apos;94, Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard W Hinrichs</author>
<author>Sandra Kiibler</author>
</authors>
<title>Stylebook for the Tubingen Tree bank of Written German (Tikl3a-D/Z). Seminar fiir Sprachwissenschaft,</title>
<date>2003</date>
<location>Universitat Tübingen, Tübingen, Germany.</location>
<contexts>
<context position="3674" citStr="Telljohann et al., 2003" startWordPosition="578" endWordPosition="581">utiously, the rule-based method will rule out only those candidates for which it has sufficient evidence and will retain all those that are contextually plausible. The task of the statistical module is to disambiguate the remaining cases of ambiguity. Statistical disambiguation is made considerably easier by the rule-based pre-filtering module, since the remaining set of hypotheses is greatly reduced. This reduction in search space corresponds to a gain in precision compared to purely statistical disambiguation. 3 Data The taz newspaper portion of the Tübingen Treebank of German (Tfil3a-D/Z) (Telljohann et al., 2003) provides the basis for the experiments reported in this paper. The treebank is manually annotated with morphological information, constituent structures and argument language and source of the statistics average # ambiguous tagset analyses tokens size German (current paper) 7.10 68.87% 718 Czech (Hajie and Hladka, 1997) 3.65 not avail. 1171 (Hajie and Hladka, 1997) 2.36 not avail. 882 Turkish (Oflazer and Tiir, 1996) 1.83 50.66% not avail. English (Tapanainen and Voutilainen, 1994) 1.77 not avail. 139 German (STTS) (current paper) 1.77 39.57% 54 Romanian (Tufi§, 2000) 1.71 38.17% 410 Hungaria</context>
</contexts>
<marker>Telljohann, Hinrichs, Kiibler, 2003</marker>
<rawString>Heike Telljohann, Erhard W. Hinrichs, and Sandra Kiibler, 2003. Stylebook for the Tubingen Tree bank of Written German (Tikl3a-D/Z). Seminar fiir Sprachwissenschaft, Universitat Tübingen, Tübingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufi§</author>
<author>Peter Dienes</author>
<author>Csaba Oravecz</author>
<author>Things Varadi</author>
</authors>
<title>Principled hidden tagset design for Tiered Tagging of Hungarian.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC&apos;2000,</booktitle>
<pages>1421--1426</pages>
<location>Athens, Greece.</location>
<marker>Tufi§, Dienes, Oravecz, Varadi, 2000</marker>
<rawString>Dan Tufi§, Peter Dienes, Csaba Oravecz, and Things Varadi. 2000. Principled hidden tagset design for Tiered Tagging of Hungarian. In Proceedings of LREC&apos;2000, pages 1421-1426, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufi§</author>
</authors>
<title>Using a large set of EAGLEScompliant morpho-syntactic descriptors as a tagset for probabilistic tagging.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC&apos;2000,</booktitle>
<pages>1105--1112</pages>
<location>Athens, Greece.</location>
<marker>Tufi§, 2000</marker>
<rawString>Dan Tufi§. 2000. Using a large set of EAGLEScompliant morpho-syntactic descriptors as a tagset for probabilistic tagging. In Proceedings of LREC&apos;2000, pages 1105-1112, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Gerold Schneider</author>
</authors>
<title>Comparing a statistical and a rule-based tagger for German.</title>
<date>1998</date>
<booktitle>In Proceedings of KONVENS&apos;98,</booktitle>
<location>Bonn, Germany.</location>
<contexts>
<context position="12688" citStr="Volk and Schneider, 1998" startWordPosition="1991" endWordPosition="1994">3.99% 59.79% 7.39 morph. disamb. 42.53% 94.86% 58.73% 64.51% 35.49% 31.05% 4.96 + adding analyses 46.93% 95.64% 62.97% 60.12% 39.88% 30.13% 4.44 Table 2: Evaluation of the rule-based disambiguation module ambiguous tokens in the test data together with the ambiguity rate for ambiguous tokens. To simplify comparison with the results obtained by other researchers, the formulas described in the earlier literature (Hajie et al., 2001) are used: #Tokens with a correct tag Precision = #Analyses generated #Tokens with a correct tag #Tokens in data 2 * Precision * Recall Precision + Recall Following (Volk and Schneider, 1998) we split the errors made by the module into lexical errors (LE; column 5) and disambiguation errors (DE; column 6). Lexical errors are caused by the morphological analyzer: the correct analysis is not present among the set of analyses assigned by it. Disambiguation errors are proper errors of the module: the correct analysis was deleted during rule application. As column 5 (LE) of Table 2 shows, the majority of the errors are lexical errors which are due to the deficiency of the morphological analyzer. A big part of such errors concerns foreign material and proper names — these lexemes do not</context>
</contexts>
<marker>Volk, Schneider, 1998</marker>
<rawString>Martin Volk and Gerold Schneider. 1998. Comparing a statistical and a rule-based tagger for German. In Proceedings of KONVENS&apos;98, Bonn, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>