<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.130993">
<title confidence="0.987572">
Automatic Term Ambiguity Detection
</title>
<author confidence="0.974414">
Tyler Baldwin Yunyao Li Bogdan Alexe Ioana R. Stanoi
</author>
<affiliation confidence="0.887689">
IBM Research - Almaden
</affiliation>
<address confidence="0.995118">
650 Harry Road, San Jose, CA 95120, USA
</address>
<email confidence="0.999118">
{tbaldwi,yunyaoli,balexe,irs}@us.ibm.com
</email>
<sectionHeader confidence="0.997392" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906157894737">
While the resolution of term ambiguity is
important for information extraction (IE)
systems, the cost of resolving each in-
stance of an entity can be prohibitively
expensive on large datasets. To combat
this, this work looks at ambiguity detec-
tion at the term, rather than the instance,
level. By making a judgment about the
general ambiguity of a term, a system is
able to handle ambiguous and unambigu-
ous cases differently, improving through-
put and quality. To address the term
ambiguity detection problem, we employ
a model that combines data from lan-
guage models, ontologies, and topic mod-
eling. Results over a dataset of entities
from four product domains show that the
proposed approach achieves significantly
above baseline F-measure of 0.96.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99988876">
Many words, phrases, and referring expressions
are semantically ambiguous. This phenomenon,
commonly referred to as polysemy, represents a
problem for NLP applications, many of which in-
herently assume a single sense. It can be particu-
larly problematic for information extraction (IE),
as IE systems often wish to extract information
about only one sense of polysemous terms. If
nothing is done to account for this polysemy, fre-
quent mentions of unrelated senses can drastically
harm performance.
Several NLP tasks, such as word sense disam-
biguation, word sense induction, and named en-
tity disambiguation, address this ambiguity prob-
lem to varying degrees. While the goals and initial
data assumptions vary between these tasks, all of
them attempt to map an instance of a term seen
in context to an individual sense. While making
a judgment for every instance may be appropri-
ate for small or medium sized data sets, the cost
of applying these ambiguity resolution procedures
becomes prohibitively expensive on large data sets
of tens to hundreds of million items. To combat
this, this work zooms out to examine the ambigu-
ity problem at a more general level.
To do so, we define an IE-centered ambiguity
detection problem, which ties the notion of am-
biguity to a given topical domain. For instance,
given that the terms Call of Juarez and A New
Beginning can both reference video games, we
would like to discover that only the latter case is
likely to appear frequently in non-video game con-
texts. The goal is to make a binary decision as
to whether, given a term and a domain, we can
expect every instance of that term to reference an
entity in that domain. By doing so, we segregate
ambiguous terms from their unambiguous coun-
terparts. Using this segregation allows ambiguous
and unambiguous instances to be treated differ-
ently while saving the processing time that might
normally be spent attempting to disambiguate in-
dividual instances of unambiguous terms.
Previous approaches to handling word ambigu-
ity employ a variety of disparate methods, vari-
ously relying on structured ontologies, gleaming
insight from general word usage patterns via lan-
guage models, or clustering the contexts in which
words appear. This work employs an ambiguity
detection pipeline that draws inspiration from all
of these methods to achieve high performance.
</bodyText>
<sectionHeader confidence="0.987731" genericHeader="method">
2 Term Ambiguity Detection (TAD)
</sectionHeader>
<bodyText confidence="0.997475714285714">
A term can be ambiguous in many ways. It may
have non-referential senses in which it shares a
name with a common word or phrase, such as in
the films Brave and 2012. A term may have refer-
ential senses across topical domains, such as The
Girl with the Dragon Tattoo, which may reference
either the book or the film adaptation. Terms may
</bodyText>
<page confidence="0.97861">
804
</page>
<bodyText confidence="0.936406727272727">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 804–809,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
also be ambiguous within a topical domain. For
instance, the term Final Fantasy may refer to the
video game franchise or one of several individual
games within the franchise. In this work we con-
cern ourselves with the first two types of ambigu-
ity, as within topical domain ambiguity tends to
pose a less severe problem for IE systems.
IE systems are often asked to perform extrac-
tion over a dictionary of terms centered around
a single topic. For example, in brand manage-
ment, customers may give a list of product names
and ask for sentiment about each product. With
this use case in mind, we define the term ambigu-
ity detection (TAD) problem as follows: Given a
term and a corresponding topic domain, determine
whether the term uniquely references a member
of that topic domain. That is, given a term such
as Brave and a category such as film, the task is
make a binary decision as to whether all instances
of Brave reference a film by that name.
</bodyText>
<subsectionHeader confidence="0.95956">
2.1 Framework
</subsectionHeader>
<bodyText confidence="0.999990057142857">
Our TAD framework is a hybrid approach consist-
ing of three modules (Figure 1). The first module
is primarily designed to detect non-referential am-
biguity. This module examines n-gram data from
a large text collection. Data from The Corpus of
Contemporary American English (Davies, 2008 )
was used to build our n-grams.
The rationale behind the n-gram module is
based on the understanding that terms appearing
in non-named entity contexts are likely to be non-
referential, and terms that can be non-referential
are ambiguous. Therefore, detecting terms that
have non-referential usages can also be used to
detect ambiguity. Since we wish for the ambigu-
ity detection determination to be fast, we develop
our method to make this judgment solely on the
n-gram probability, without the need to examine
each individual usage context. To do so, we as-
sume that an all lowercased version of the term is
a reasonable proxy for non-named entity usages in
formal text. After removing stopwords from the
term, we calculate the n-gram probability of the
lower-cased form of the remaining words. If the
probability is above a certain threshold, the term
is labeled as ambiguous. If the term is below the
threshold, it is tentatively labeled as unambiguous
and passed to the next module. To avoid making
judgments of ambiguity based on very infrequent
uses, the ambiguous-unambiguous determination
threshold is empirically determined by minimiz-
ing error over held out data.
The second module employs ontologies to de-
tect across domain ambiguity. Two ontologies
were examined. To further handle the common
phrase case, Wiktionary1 was used as a dictionary.
Terms that have multiple senses in Wiktionary
were labeled as ambiguous. The second ontology
used was Wikipedia disambiguation pages. All
terms that had a disambiguation page were marked
as ambiguous.
The final module attempts to detect both non-
referential and across domain ambiguity by clus-
tering the contexts in which words appear. To do
so, we utilized the popular Latent Dirichlet Allo-
cation (LDA (Blei et al., 2003)) topic modeling
method. LDA represents a document as a distri-
bution of topics, and each topic as a distribution
of words. As our domain of interest is Twitter,
we performed clustering over a large collection of
tweets. For a given term, all tweets that contained
the term were used as a document collection. Fol-
lowing standard procedure, stopwords and infre-
quent words were removed before topic modeling
was performed. Since the clustering mechanism
was designed to make predictions over the already
filtered data of the other modules, it adopts a con-
servative approach to predicting ambiguity. If the
category term (e.g., film) or a synonym from the
WordNet synset does not appear in the 10 most
heavily weighted words for any cluster, the term is
marked as ambiguous.
A term is labeled as ambiguous if any one of
the three modules predicts that it is ambiguous,
but only labeled as unambiguous if all three mod-
ules make this prediction. This design allows each
module to be relatively conservative in predicting
ambiguity, keeping precision of ambiguity predic-
tion high, under the assumption that other modules
will compensate for the corresponding drop in re-
call.
</bodyText>
<sectionHeader confidence="0.995748" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997911">
3.1 Data Set
</subsectionHeader>
<bodyText confidence="0.977734166666667">
Initial Term Sets We collected a data set of terms
from four topical domains: books, films, video
games, and cameras. Terms for the first three do-
mains are lists of books, films, and video games
respectively from the years 2000-2011 from db-
pedia (Auer et al., 2007), while the initial terms
</bodyText>
<footnote confidence="0.989089">
1http://www.wiktionary.org/
</footnote>
<page confidence="0.984931">
805
</page>
<table confidence="0.9945424">
Tweet Term Category Judgment
Woke up from a nap to find a beautiful mind on. #win A Beautiful Mind film yes
I Love Tyler Perry ; He Has A Beautiful Mind. A Beautiful Mind film no
I might put it in the top 1. RT @CourtesyFlushMo Splice. Top 5 worst movies ever Splice film yes
Splice is a great, free replacement to iMove for your iPhone, Splice film no
</table>
<tableCaption confidence="0.999493">
Table 1: Example tweet annotations.
</tableCaption>
<figureCaption confidence="0.9880875">
Figure 1: Overview of the ambiguity detection
framework.
</figureCaption>
<bodyText confidence="0.993653208333333">
for cameras includes all the cameras from the six
most popular brands on flickr2.
Gold Standard A set of 100 terms per domain
were chosen at random from the initial term sets.
Rather than annotating each term directly, am-
biguity was determined by examining actual us-
age. Specifically, for each term, usage examples
were extracted from large amounts of Twitter data.
Tweets for the video game and film categories were
extracted from the TREC Twitter corpus.3 The
less common book and camera cases were ex-
tracted from a subset of all tweets from September
1st-9th, 2012.
For each term, two annotators were given the
term, the corresponding topic domain, and 10 ran-
domly selected tweets containing the term. They
were then asked to make a binary judgment as to
whether the usage of the term in the tweet referred
to an instance of the given category. The degree
of ambiguity is then determined by calculating the
percentage of tweets that did not reference a mem-
ber of the topic domain. Some example judgments
are given in Table 1. If all individual tweet judg-
ments for a term were marked as referring to a
</bodyText>
<footnote confidence="0.9997995">
2http://www.flickr.com/cameras/
3http://trec.nist.gov/data/tweets/
</footnote>
<table confidence="0.999968">
Configuration Precision Recall F-measure
Baseline 0.675 1.0 0.806
NG 0.979 0.848 0.909
ON 0.979 0.704 0.819
CL 0.946 0.848 0.895
NG + ON 0.980 0.919 0.948
NG + CL 0.942 0.963 0.952
ON + CL 0.945 0.956 0.950
NG + ON + CL 0.943 0.978 0.960
</table>
<tableCaption confidence="0.993809">
Table 2: Performance of various framework con-
figurations on the test data.
</tableCaption>
<bodyText confidence="0.999721666666667">
member of the topic domain, the term was marked
as fully unambiguous within the data examined.
All other cases were considered ambiguous.4
Inter-annotator agreement was high, with raw
agreement of 94% (κ = 0.81). Most disagree-
ments on individual tweet judgments had little ef-
fect on the final judgment of a term as ambiguous
or unambiguous, and those that did were resolved
internally.
</bodyText>
<subsectionHeader confidence="0.997602">
3.2 Evaluation and Results
</subsectionHeader>
<bodyText confidence="0.99990995">
Effectiveness To understand the contribution of
the n-gram (NG), ontology (ON), and clustering
(CL) based modules, we ran each separately, as
well as every possible combination. Results are
shown in Table 2, where they are compared to a
majority class (ambiguous) baseline.
As shown, all configurations outperform the
baseline. Of the three individual modules, the n-
gram and clustering methods achieve F-measure
of around 0.9, while the ontology-based module
performs only modestly above baseline. Unsur-
prisingly, the ontology method is affected heav-
ily by its coverage, so its poor performance is pri-
marily attributable to low recall. As noted, many
IE tasks may involve sets of entities that are not
found in common ontologies, limiting the ability
of the ontology-based method alone. Additionally,
ontologies may be apt to list cases of strict ambi-
guity, rather than practical ambiguity. That is, an
ontology may list a term as ambiguous if there are
</bodyText>
<footnote confidence="0.998317">
4The annotated data is available at http:
//researcher.watson.ibm.com/researcher/
view_person_subpage.php?id=4757.
</footnote>
<page confidence="0.99849">
806
</page>
<bodyText confidence="0.999842184210526">
several potential named entities it could refer to,
even if the vast majority of references were to only
a single entity.
Combining any two methods produced substan-
tial performance increases over any of the individ-
ual runs. The final system that employed all mod-
ules produced an F-measure of 0.960, a significant
(p &lt; 0.01) absolute increase of 15.4% over the
baseline.
Usefulness To establish that term ambiguity de-
tection is actually helpful for IE, we conducted
a preliminary study by integrating our pipeline
into a commercially available rule-based IE sys-
tem (Chiticariu et al., 2010; Alexe et al., 2012).
The system takes a list of product names as input
and outputs tweets associated with each product.
It utilizes rules that employ more conservative ex-
traction for ambiguous entities.
Experiments were conducted over several mil-
lion tweets using the terms from the video game
and camera domains. When no ambiguity detec-
tion was performed, all terms were treated as un-
ambiguous. The system produced very poor pre-
cision of 0.16 when no ambiguity detection was
used, due to the extraction of irrelevant instances
of ambiguous objects. In contrast, the system pro-
duced precision of 0.96 when ambiguity detection
was employed. However, the inclusion of disam-
biguation did reduce the overall recall; the system
that employed disambiguation returned only about
57% of the true positives returned by the system
that did not employ disambiguation. Although
this reduction in recall is significant, the overall
impact of disambiguation is clearly positive, due
to the stark difference in precision. Nonetheless,
this limited study suggests that there is substantial
room for improvement in the extraction system, al-
though this is out of the scope of the current work.
</bodyText>
<sectionHeader confidence="0.999977" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999887979591837">
Polysemy is a known problem for many NLP-
related applications. Machine translation systems
can suffer, as ambiguity in the source language
may lead to incorrect translations, and unambigu-
ous sentences in one language may become am-
biguous in another (Carpuat and Wu, 2007; Chan
et al., 2007). Ambiguity in queries can also hin-
der the performance of information retrieval sys-
tems (Wang and Agichtein, 2010; Zhong and Ng,
2012).
The ambiguity detection problem is similar to
the well studied problems of named entity dis-
ambiguation (NED) and word sense disambigua-
tion (WSD). However, these tasks assume that
the number of senses a word has is given, essen-
tially assuming that the ambiguity detection prob-
lem has already been solved. This makes these
tasks inapplicable in many IE instances where the
amount of ambiguity is not known ahead of time.
Both named entity and word sense disambigua-
tion are extensively studied, and surveys on each
are available (Nadeau and Sekine, 2007; Navigli,
2009).
Another task that shares similarities with TAD
is word sense induction (WSI). Like NED and
WSD, WSI frames the ambiguity problem as one
of determining the sense of each individual in-
stance, rather than the term as a whole. Unlike
those approaches, the word sense induction task
attempts to both figure out the number of senses a
word has, and what they are. WSI is unsupervised,
relying solely on the information that surrounds
word mentions in the text.
Many different clustering-based WSI methods
have been examined. Pantel and Lin (2002) em-
ploy a clustering by committee method that itera-
tively adds words to clusters based on their sim-
ilarities. Topic model-based methods have been
attempted using variations of Latent Dirichlet Al-
location (Brody and Lapata, 2009) and Hierarchi-
cal Dirichlet Processes (Lau et al., 2012). Sev-
eral graph-based methods have also been exam-
ined (Klapaftis and Manandhar, 2010; Navigli and
Crisafulli, 2010). Although the words that sur-
round the target word are the primary source of
contextual information in most cases, additional
feature sources such as syntax (Van de Cruys,
2008) and semantic relations (Chen and Palmer,
2004) have also been explored.
</bodyText>
<sectionHeader confidence="0.995179" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999219090909091">
This paper introduced the term ambiguity detec-
tion task, which detects whether a term is am-
biguous relative to a topical domain. Unlike other
ambiguity resolution tasks, the ambiguity detec-
tion problem makes general ambiguity judgments
about terms, rather than resolving individual in-
stances. By doing so, it eliminates the need for
ambiguity resolution on unambiguous objects, al-
lowing for increased throughput of IE systems on
large data sets.
Our solution for the term ambiguity detection
</bodyText>
<page confidence="0.993094">
807
</page>
<bodyText confidence="0.999897052631579">
task is based on a combined model with three dis-
tinct modules based on n-grams, ontologies, and
clustering. Our initial study suggests that the com-
bination of different modules designed for differ-
ent types of ambiguity used in our solution is ef-
fective in determining whether a term is ambigu-
ous for a given domain. Additionally, an exami-
nation of a typical use case confirms that the pro-
posed solution is likely to be useful in improving
the performance of an IE system that does not em-
ploy any disambiguation.
Although the task as presented here was mo-
tivated with information extraction in mind, it is
possible that term ambiguity detection could be
useful for other tasks. For instance, TAD could
be used to aid word sense induction more gener-
ally, or could be applied as part of other tasks such
as coreference resolution. We leave this avenue of
examination to future work.
</bodyText>
<sectionHeader confidence="0.999157" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999949333333333">
We would like to thank the anonymous review-
ers of ACL for helpful comments and suggestions.
We also thank Howard Ho and Rajasekar Krishna-
murthy for help with data annotation and Shivaku-
mar Vaithyanathan for his comments on a prelim-
inary version of this work.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702974358975">
Bogdan Alexe, Mauricio A. Hern´andez, Kirsten Hil-
drum, Rajasekar Krishnamurthy, Georgia Koutrika,
Meenakshi Nagarajan, Haggai Roitman, Michal
Shmueli-Scheuer, Ioana Roxana Stanoi, Chitra
Venkatramani, and Rohit Wagle. 2012. Surfacing
time-critical insights from social media. In SIG-
MOD Conference, pages 657–660.
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. Dbpedia: a nucleus for a web of open data.
In Proceedings of the 6th international The seman-
tic web and 2nd Asian conference on Asian semantic
web conference, ISWC’07/ASWC’07, pages 722–
735, Berlin, Heidelberg. Springer-Verlag.
David Blei, Andrew Ng, and Micheal I. Jordan. 2003.
Latent dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022, January.
Samuel Brody and Mirella Lapata. 2009. Bayesian
word sense induction. In Proceedings of the 12th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, EACL ’09,
pages 103–111, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Marine Carpuat and Dekai Wu. 2007. Improving sta-
tistical machine translation using word sense disam-
biguation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pages 61–72.
Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007. Word sense disambiguation improves statisti-
cal machine translation. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics, pages 33–40, Prague, Czech Republic,
June. Association for Computational Linguistics.
Jinying Chen and Martha Palmer. 2004. Chinese verb
sense discrimination using an em clustering model
with rich linguistic features. In Proceedings of the
42nd Annual Meeting on Association for Computa-
tional Linguistics, ACL ’04, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao
Li, Sriram Raghavan, Frederick Reiss, and Shivaku-
mar Vaithyanathan. 2010. SystemT: An algebraic
approach to declarative information extraction. In
ACL, pages 128–137.
Mark Davies. 2008-. The corpus of contempo-
rary american english: 450 million words, 1990-
present. Avialable online at: http://corpus.
byu.edu/coca/.
Ioannis P. Klapaftis and Suresh Manandhar. 2010.
Word sense induction &amp; disambiguation using hi-
erarchical random graphs. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, EMNLP ’10, pages 745–755,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word sense in-
duction for novel sense detection. In Proceedings of
the 13th Conference of the European Chapter of the
Association for Computational Linguistics, EACL
’12, pages 591–601, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
David Nadeau and Satoshi Sekine. 2007. A survey
of named entity recognition and classification. Lin-
guisticae Investigationes, 30(1):3–26.
Roberto Navigli and Giuseppe Crisafulli. 2010. Induc-
ing word senses to improve web search result clus-
tering. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’10, pages 116–126, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Comput. Surv., 41(2):10:1–10:69,
February.
Patrick Pantel and Dekang Lin. 2002. Discovering
word senses from text. In Proceedings of the eighth
</reference>
<page confidence="0.982351">
808
</page>
<reference confidence="0.995776130434783">
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’02, pages
613–619, New York, NY, USA. ACM.
Tim Van de Cruys. 2008. Using three way data for
word sense discrimination. In Proceedings of the
22nd International Conference on Computational
Linguistics - Volume 1, COLING ’08, pages 929–
936, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Yu Wang and Eugene Agichtein. 2010. Query ambigu-
ity revisited: Clickthrough measures for distinguish-
ing informational and ambiguous queries. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 361–364,
Los Angeles, California, June. Association for Com-
putational Linguistics.
Zhi Zhong and Hwee Tou Ng. 2012. Word sense
disambiguation improves information retrieval. In
Proceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 273–282, Jeju Island, Korea,
July. Association for Computational Linguistics.
</reference>
<page confidence="0.998893">
809
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.864829">
<title confidence="0.999953">Automatic Term Ambiguity Detection</title>
<author confidence="0.999028">Tyler Baldwin Yunyao Li Bogdan Alexe Ioana R</author>
<affiliation confidence="0.999824">IBM Research -</affiliation>
<address confidence="0.999801">650 Harry Road, San Jose, CA 95120,</address>
<abstract confidence="0.99145395">While the resolution of term ambiguity is important for information extraction (IE) systems, the cost of resolving each instance of an entity can be prohibitively expensive on large datasets. To combat this, this work looks at ambiguity detection at the term, rather than the instance, level. By making a judgment about the general ambiguity of a term, a system is able to handle ambiguous and unambiguous cases differently, improving throughput and quality. To address the term ambiguity detection problem, we employ a model that combines data from language models, ontologies, and topic modeling. Results over a dataset of entities from four product domains show that the proposed approach achieves significantly above baseline F-measure of 0.96.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bogdan Alexe</author>
<author>Mauricio A Hern´andez</author>
<author>Kirsten Hildrum</author>
<author>Rajasekar Krishnamurthy</author>
<author>Georgia Koutrika</author>
<author>Meenakshi Nagarajan</author>
<author>Haggai Roitman</author>
</authors>
<title>Surfacing time-critical insights from social media.</title>
<date>2012</date>
<booktitle>In SIGMOD Conference,</booktitle>
<pages>657--660</pages>
<institution>Michal Shmueli-Scheuer, Ioana Roxana Stanoi, Chitra Venkatramani, and Rohit</institution>
<marker>Alexe, Hern´andez, Hildrum, Krishnamurthy, Koutrika, Nagarajan, Roitman, 2012</marker>
<rawString>Bogdan Alexe, Mauricio A. Hern´andez, Kirsten Hildrum, Rajasekar Krishnamurthy, Georgia Koutrika, Meenakshi Nagarajan, Haggai Roitman, Michal Shmueli-Scheuer, Ioana Roxana Stanoi, Chitra Venkatramani, and Rohit Wagle. 2012. Surfacing time-critical insights from social media. In SIGMOD Conference, pages 657–660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: a nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07,</booktitle>
<pages>722--735</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="8358" citStr="Auer et al., 2007" startWordPosition="1368" endWordPosition="1371">ambiguous, but only labeled as unambiguous if all three modules make this prediction. This design allows each module to be relatively conservative in predicting ambiguity, keeping precision of ambiguity prediction high, under the assumption that other modules will compensate for the corresponding drop in recall. 3 Experimental Evaluation 3.1 Data Set Initial Term Sets We collected a data set of terms from four topical domains: books, films, video games, and cameras. Terms for the first three domains are lists of books, films, and video games respectively from the years 2000-2011 from dbpedia (Auer et al., 2007), while the initial terms 1http://www.wiktionary.org/ 805 Tweet Term Category Judgment Woke up from a nap to find a beautiful mind on. #win A Beautiful Mind film yes I Love Tyler Perry ; He Has A Beautiful Mind. A Beautiful Mind film no I might put it in the top 1. RT @CourtesyFlushMo Splice. Top 5 worst movies ever Splice film yes Splice is a great, free replacement to iMove for your iPhone, Splice film no Table 1: Example tweet annotations. Figure 1: Overview of the ambiguity detection framework. for cameras includes all the cameras from the six most popular brands on flickr2. Gold Standard </context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: a nucleus for a web of open data. In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07, pages 722– 735, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Micheal I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="6886" citStr="Blei et al., 2003" startWordPosition="1122" endWordPosition="1125">held out data. The second module employs ontologies to detect across domain ambiguity. Two ontologies were examined. To further handle the common phrase case, Wiktionary1 was used as a dictionary. Terms that have multiple senses in Wiktionary were labeled as ambiguous. The second ontology used was Wikipedia disambiguation pages. All terms that had a disambiguation page were marked as ambiguous. The final module attempts to detect both nonreferential and across domain ambiguity by clustering the contexts in which words appear. To do so, we utilized the popular Latent Dirichlet Allocation (LDA (Blei et al., 2003)) topic modeling method. LDA represents a document as a distribution of topics, and each topic as a distribution of words. As our domain of interest is Twitter, we performed clustering over a large collection of tweets. For a given term, all tweets that contained the term were used as a document collection. Following standard procedure, stopwords and infrequent words were removed before topic modeling was performed. Since the clustering mechanism was designed to make predictions over the already filtered data of the other modules, it adopts a conservative approach to predicting ambiguity. If t</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Micheal I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Mirella Lapata</author>
</authors>
<title>Bayesian word sense induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09,</booktitle>
<pages>103--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15374" citStr="Brody and Lapata, 2009" startWordPosition="2511" endWordPosition="2514">ining the sense of each individual instance, rather than the term as a whole. Unlike those approaches, the word sense induction task attempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations (Chen and Palmer, 2004) have also been explored. 5 Conclusion This paper introduced the term ambiguity detection task, which detects whether a term is ambiguous relative to a topical domain. Unlike other ambiguity resolution tas</context>
</contexts>
<marker>Brody, Lapata, 2009</marker>
<rawString>Samuel Brody and Mirella Lapata. 2009. Bayesian word sense induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09, pages 103–111, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>61--72</pages>
<contexts>
<context position="13882" citStr="Carpuat and Wu, 2007" startWordPosition="2266" endWordPosition="2269"> disambiguation. Although this reduction in recall is significant, the overall impact of disambiguation is clearly positive, due to the stark difference in precision. Nonetheless, this limited study suggests that there is substantial room for improvement in the extraction system, although this is out of the scope of the current work. 4 Related Work Polysemy is a known problem for many NLPrelated applications. Machine translation systems can suffer, as ambiguity in the source language may lead to incorrect translations, and unambiguous sentences in one language may become ambiguous in another (Carpuat and Wu, 2007; Chan et al., 2007). Ambiguity in queries can also hinder the performance of information retrieval systems (Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and wor</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="13902" citStr="Chan et al., 2007" startWordPosition="2270" endWordPosition="2273">ugh this reduction in recall is significant, the overall impact of disambiguation is clearly positive, due to the stark difference in precision. Nonetheless, this limited study suggests that there is substantial room for improvement in the extraction system, although this is out of the scope of the current work. 4 Related Work Polysemy is a known problem for many NLPrelated applications. Machine translation systems can suffer, as ambiguity in the source language may lead to incorrect translations, and unambiguous sentences in one language may become ambiguous in another (Carpuat and Wu, 2007; Chan et al., 2007). Ambiguity in queries can also hinder the performance of information retrieval systems (Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and word sense disambiguati</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007. Word sense disambiguation improves statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 33–40, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinying Chen</author>
<author>Martha Palmer</author>
</authors>
<title>Chinese verb sense discrimination using an em clustering model with rich linguistic features.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15769" citStr="Chen and Palmer, 2004" startWordPosition="2573" endWordPosition="2576">employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations (Chen and Palmer, 2004) have also been explored. 5 Conclusion This paper introduced the term ambiguity detection task, which detects whether a term is ambiguous relative to a topical domain. Unlike other ambiguity resolution tasks, the ambiguity detection problem makes general ambiguity judgments about terms, rather than resolving individual instances. By doing so, it eliminates the need for ambiguity resolution on unambiguous objects, allowing for increased throughput of IE systems on large data sets. Our solution for the term ambiguity detection 807 task is based on a combined model with three distinct modules bas</context>
</contexts>
<marker>Chen, Palmer, 2004</marker>
<rawString>Jinying Chen and Martha Palmer. 2004. Chinese verb sense discrimination using an em clustering model with rich linguistic features. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Chiticariu</author>
<author>Rajasekar Krishnamurthy</author>
<author>Yunyao Li</author>
<author>Sriram Raghavan</author>
<author>Frederick Reiss</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>SystemT: An algebraic approach to declarative information extraction.</title>
<date>2010</date>
<booktitle>In ACL,</booktitle>
<pages>128--137</pages>
<contexts>
<context position="12420" citStr="Chiticariu et al., 2010" startWordPosition="2033" endWordPosition="2036">ew_person_subpage.php?id=4757. 806 several potential named entities it could refer to, even if the vast majority of references were to only a single entity. Combining any two methods produced substantial performance increases over any of the individual runs. The final system that employed all modules produced an F-measure of 0.960, a significant (p &lt; 0.01) absolute increase of 15.4% over the baseline. Usefulness To establish that term ambiguity detection is actually helpful for IE, we conducted a preliminary study by integrating our pipeline into a commercially available rule-based IE system (Chiticariu et al., 2010; Alexe et al., 2012). The system takes a list of product names as input and outputs tweets associated with each product. It utilizes rules that employ more conservative extraction for ambiguous entities. Experiments were conducted over several million tweets using the terms from the video game and camera domains. When no ambiguity detection was performed, all terms were treated as unambiguous. The system produced very poor precision of 0.16 when no ambiguity detection was used, due to the extraction of irrelevant instances of ambiguous objects. In contrast, the system produced precision of 0.</context>
</contexts>
<marker>Chiticariu, Krishnamurthy, Li, Raghavan, Reiss, Vaithyanathan, 2010</marker>
<rawString>Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao Li, Sriram Raghavan, Frederick Reiss, and Shivakumar Vaithyanathan. 2010. SystemT: An algebraic approach to declarative information extraction. In ACL, pages 128–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Davies</author>
</authors>
<title>The corpus of contemporary american english: 450 million words,</title>
<date>2008</date>
<note>Avialable online at: http://corpus. byu.edu/coca/.</note>
<contexts>
<context position="5111" citStr="Davies, 2008" startWordPosition="838" endWordPosition="839">problem as follows: Given a term and a corresponding topic domain, determine whether the term uniquely references a member of that topic domain. That is, given a term such as Brave and a category such as film, the task is make a binary decision as to whether all instances of Brave reference a film by that name. 2.1 Framework Our TAD framework is a hybrid approach consisting of three modules (Figure 1). The first module is primarily designed to detect non-referential ambiguity. This module examines n-gram data from a large text collection. Data from The Corpus of Contemporary American English (Davies, 2008 ) was used to build our n-grams. The rationale behind the n-gram module is based on the understanding that terms appearing in non-named entity contexts are likely to be nonreferential, and terms that can be non-referential are ambiguous. Therefore, detecting terms that have non-referential usages can also be used to detect ambiguity. Since we wish for the ambiguity detection determination to be fast, we develop our method to make this judgment solely on the n-gram probability, without the need to examine each individual usage context. To do so, we assume that an all lowercased version of the </context>
</contexts>
<marker>Davies, 2008</marker>
<rawString>Mark Davies. 2008-. The corpus of contemporary american english: 450 million words, 1990-present. Avialable online at: http://corpus. byu.edu/coca/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis P Klapaftis</author>
<author>Suresh Manandhar</author>
</authors>
<title>Word sense induction &amp; disambiguation using hierarchical random graphs.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>745--755</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15514" citStr="Klapaftis and Manandhar, 2010" startWordPosition="2533" endWordPosition="2536">ttempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations (Chen and Palmer, 2004) have also been explored. 5 Conclusion This paper introduced the term ambiguity detection task, which detects whether a term is ambiguous relative to a topical domain. Unlike other ambiguity resolution tasks, the ambiguity detection problem makes general ambiguity judgments about terms, rather than resolving individual instances. By doing so, </context>
</contexts>
<marker>Klapaftis, Manandhar, 2010</marker>
<rawString>Ioannis P. Klapaftis and Suresh Manandhar. 2010. Word sense induction &amp; disambiguation using hierarchical random graphs. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 745–755, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>Paul Cook</author>
<author>Diana McCarthy</author>
<author>David Newman</author>
<author>Timothy Baldwin</author>
</authors>
<title>Word sense induction for novel sense detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12,</booktitle>
<pages>591--601</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15430" citStr="Lau et al., 2012" startWordPosition="2520" endWordPosition="2523">erm as a whole. Unlike those approaches, the word sense induction task attempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations (Chen and Palmer, 2004) have also been explored. 5 Conclusion This paper introduced the term ambiguity detection task, which detects whether a term is ambiguous relative to a topical domain. Unlike other ambiguity resolution tasks, the ambiguity detection problem makes general ambigu</context>
</contexts>
<marker>Lau, Cook, McCarthy, Newman, Baldwin, 2012</marker>
<rawString>Jey Han Lau, Paul Cook, Diana McCarthy, David Newman, and Timothy Baldwin. 2012. Word sense induction for novel sense detection. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12, pages 591–601, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Satoshi Sekine</author>
</authors>
<title>A survey of named entity recognition and classification.</title>
<date>2007</date>
<journal>Linguisticae Investigationes,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="14588" citStr="Nadeau and Sekine, 2007" startWordPosition="2383" endWordPosition="2386">mation retrieval systems (Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and word sense disambiguation are extensively studied, and surveys on each are available (Nadeau and Sekine, 2007; Navigli, 2009). Another task that shares similarities with TAD is word sense induction (WSI). Like NED and WSD, WSI frames the ambiguity problem as one of determining the sense of each individual instance, rather than the term as a whole. Unlike those approaches, the word sense induction task attempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method t</context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognition and classification. Linguisticae Investigationes, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Giuseppe Crisafulli</author>
</authors>
<title>Inducing word senses to improve web search result clustering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>116--126</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15545" citStr="Navigli and Crisafulli, 2010" startWordPosition="2537" endWordPosition="2540">number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations (Chen and Palmer, 2004) have also been explored. 5 Conclusion This paper introduced the term ambiguity detection task, which detects whether a term is ambiguous relative to a topical domain. Unlike other ambiguity resolution tasks, the ambiguity detection problem makes general ambiguity judgments about terms, rather than resolving individual instances. By doing so, it eliminates the need for ambi</context>
</contexts>
<marker>Navigli, Crisafulli, 2010</marker>
<rawString>Roberto Navigli and Giuseppe Crisafulli. 2010. Inducing word senses to improve web search result clustering. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 116–126, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Comput. Surv.,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="14604" citStr="Navigli, 2009" startWordPosition="2387" endWordPosition="2388">(Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and word sense disambiguation are extensively studied, and surveys on each are available (Nadeau and Sekine, 2007; Navigli, 2009). Another task that shares similarities with TAD is word sense induction (WSI). Like NED and WSD, WSI frames the ambiguity problem as one of determining the sense of each individual instance, rather than the term as a whole. Unlike those approaches, the word sense induction task attempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively </context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Comput. Surv., 41(2):10:1–10:69, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02,</booktitle>
<pages>613--619</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="15146" citStr="Pantel and Lin (2002)" startWordPosition="2475" endWordPosition="2478">ied, and surveys on each are available (Nadeau and Sekine, 2007; Navigli, 2009). Another task that shares similarities with TAD is word sense induction (WSI). Like NED and WSD, WSI frames the ambiguity problem as one of determining the sense of each individual instance, rather than the term as a whole. Unlike those approaches, the word sense induction task attempts to both figure out the number of senses a word has, and what they are. WSI is unsupervised, relying solely on the information that surrounds word mentions in the text. Many different clustering-based WSI methods have been examined. Pantel and Lin (2002) employ a clustering by committee method that iteratively adds words to clusters based on their similarities. Topic model-based methods have been attempted using variations of Latent Dirichlet Allocation (Brody and Lapata, 2009) and Hierarchical Dirichlet Processes (Lau et al., 2012). Several graph-based methods have also been examined (Klapaftis and Manandhar, 2010; Navigli and Crisafulli, 2010). Although the words that surround the target word are the primary source of contextual information in most cases, additional feature sources such as syntax (Van de Cruys, 2008) and semantic relations </context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02, pages 613–619, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
</authors>
<title>Using three way data for word sense discrimination.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08,</booktitle>
<pages>929--936</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Van de Cruys, 2008</marker>
<rawString>Tim Van de Cruys. 2008. Using three way data for word sense discrimination. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08, pages 929– 936, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Wang</author>
<author>Eugene Agichtein</author>
</authors>
<title>Query ambiguity revisited: Clickthrough measures for distinguishing informational and ambiguous queries.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>361--364</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="14015" citStr="Wang and Agichtein, 2010" startWordPosition="2288" endWordPosition="2291">to the stark difference in precision. Nonetheless, this limited study suggests that there is substantial room for improvement in the extraction system, although this is out of the scope of the current work. 4 Related Work Polysemy is a known problem for many NLPrelated applications. Machine translation systems can suffer, as ambiguity in the source language may lead to incorrect translations, and unambiguous sentences in one language may become ambiguous in another (Carpuat and Wu, 2007; Chan et al., 2007). Ambiguity in queries can also hinder the performance of information retrieval systems (Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and word sense disambiguation are extensively studied, and surveys on each are available (Nadeau and Sekine, 2007; Navigli, 2009). Another t</context>
</contexts>
<marker>Wang, Agichtein, 2010</marker>
<rawString>Yu Wang and Eugene Agichtein. 2010. Query ambiguity revisited: Clickthrough measures for distinguishing informational and ambiguous queries. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 361–364, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Word sense disambiguation improves information retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>273--282</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="14036" citStr="Zhong and Ng, 2012" startWordPosition="2292" endWordPosition="2295"> precision. Nonetheless, this limited study suggests that there is substantial room for improvement in the extraction system, although this is out of the scope of the current work. 4 Related Work Polysemy is a known problem for many NLPrelated applications. Machine translation systems can suffer, as ambiguity in the source language may lead to incorrect translations, and unambiguous sentences in one language may become ambiguous in another (Carpuat and Wu, 2007; Chan et al., 2007). Ambiguity in queries can also hinder the performance of information retrieval systems (Wang and Agichtein, 2010; Zhong and Ng, 2012). The ambiguity detection problem is similar to the well studied problems of named entity disambiguation (NED) and word sense disambiguation (WSD). However, these tasks assume that the number of senses a word has is given, essentially assuming that the ambiguity detection problem has already been solved. This makes these tasks inapplicable in many IE instances where the amount of ambiguity is not known ahead of time. Both named entity and word sense disambiguation are extensively studied, and surveys on each are available (Nadeau and Sekine, 2007; Navigli, 2009). Another task that shares simil</context>
</contexts>
<marker>Zhong, Ng, 2012</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2012. Word sense disambiguation improves information retrieval. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 273–282, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>