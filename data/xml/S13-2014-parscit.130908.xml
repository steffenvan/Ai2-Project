<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002498">
<title confidence="0.7124325">
KUL: A Data-driven Approach to Temporal Parsing of Documents
Oleksandr Kolomiyets
</title>
<author confidence="0.557598333333333">
KU Leuven
Celestijnenlaan 200A
Heverlee 3001, Belgium
</author>
<affiliation confidence="0.990433">
Department of Computer Science
</affiliation>
<email confidence="0.6444955">
oleksandr.kolomiyets
@cs.kuleuven.be
</email>
<note confidence="0.521595333333333">
Marie-Francine Moens
KU Leuven
Celestijnenlaan 200A
</note>
<author confidence="0.63805">
Heverlee 3001, Belgium
</author>
<affiliation confidence="0.991527">
Department of Computer Science
</affiliation>
<email confidence="0.994391">
sien.moens@cs.kuleuven.be
</email>
<sectionHeader confidence="0.995562" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969307692308">
This paper describes a system for temporal
processing of text, which participated in the
Temporal Evaluations 2013 campaign. The
system employs a number of machine learning
classifiers to perform the core tasks of: identi-
fication of time expressions and events, recog-
nition of their attributes, and estimation of
temporal links between recognized events and
times. The central feature of the proposed sys-
tem is temporal parsing – an approach which
identifies temporal relation arguments (event-
event and event-timex pairs) and the semantic
label of the relation as a single decision.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999610222222222">
Temporal Evaluations 2013 (TempEval-3) is
the third iteration of temporal evaluations (after
TempEval-1 (Verhagen et al., 2007) and TempEval-
2 (Verhagen et al., 2010)) which addresses the
task of temporal information processing of text. In
contrast to the previous evaluation campaigns where
the temporal relation recognition task was simpli-
fied by restricting grammatical context (events in
adjacent sentences, events and times in the same
sentences) and proposed relation pairs, TempEval-3
does not set any context in which temporal re-
lations have to be identified. Thus, for temporal
relation recognition the challenges consist of: first,
detecting a pair of events, or an event and a time
that constitutes a temporal relation; and, second,
determining what semantic label to assign to the
proposed pair. Moreover, TempEval-3 proposes the
task of end-to-end temporal processing in which
</bodyText>
<page confidence="0.982705">
83
</page>
<bodyText confidence="0.999849">
events and times, their attributes and relations have
to be identified from a raw text input.
In this paper we present a data-driven approach
to all-around temporal processing of text. A num-
ber of machine-learning detectors were designed to
recognize temporal “markables” (events and times)
and their attributes. The key feature of our approach
is that argument pairs, as well as relations between
them, are jointly estimated without specifying in ad-
vance the context in which these pairs have to occur.
</bodyText>
<sectionHeader confidence="0.990091" genericHeader="method">
2 Our Approach
</sectionHeader>
<subsectionHeader confidence="0.986816">
2.1 Timex Processing
2.1.1 Timex Recognition and Normalization
</subsectionHeader>
<bodyText confidence="0.9997245">
The proposed method for timex recognition im-
plements a supervised machine learning approach
that processes each chunk-phrase derived from the
parse tree. Time expressions are detected by the
model as phrasal chunks in the parse with their cor-
responding spans. In addition, the model is boot-
strapped by substitutions of temporal triggers with
their synonyms learned by the Latent Words Lan-
guage Model (Deschacht et al., 2012) as described in
(Kolomiyets et al., 2011). We implemented a logis-
tic regression model that makes use of the following
features:
</bodyText>
<listItem confidence="0.951065928571429">
• the head word of the phrase and its POS tag;
• all tokens and POS tags in the phrase as a bag
of words;
• the word-shape representation of the head word
and the entire phrase, e.g. Xxxxx 99 for the
expression April 30;
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 83–87, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
• the condensed word-shape representation for
the head word and the entire phrase, e.g. X(x)
(9) for the expression April 30;
• the concatenated string of the syntactic types of
the children of the phrase in the parse tree;
• the depth in the parse tree.
</listItem>
<bodyText confidence="0.999617739130435">
In addition, we considered a special label for sin-
gle tokens of time expressions. In this way, we
detect parts of temporal expressions if they cannot
be found in the chunk-based fashion. In detail, if
a token is recognized as part of a timex and satis-
fies the pre-condition on its POS tag, we employ a
“look-behind” rule for the phrasal chunk to match
the begin token of the temporal expression. The le-
gitimate start POS tags are determiners, adjectives,
and cardinals. Another set of rules specifies unsuit-
able timexes, such as single cardinals with values
outside predefined ranges of day-of-month, month-
of-year and year numbers.
Normalization of temporal expressions is a pro-
cess of estimating standard temporal values and
types for temporal expressions. Due to a large vari-
ance of expressions denoting the same date and
vagueness in language, rule-based approaches are
usually employed for the normalization task, and our
implementation is a rule-based system. The nor-
malization procedure is the same as described in
(Kolomiyets and Moens, 2010), which participated
in TempEval-2.
</bodyText>
<subsectionHeader confidence="0.996914">
2.2 Event Processing
</subsectionHeader>
<bodyText confidence="0.998941714285714">
The proposed method to event recognition imple-
ments a supervised machine learning approach that
classifies every single token in the input sentence as
an event instance of a specific semantic type. We im-
plemented a logistic regression model with features
largely derived from the work of Bethard and Martin
(2006):
</bodyText>
<listItem confidence="0.998399">
• the token, its lemma, coarse and fine-grained
POS tags, token’s suffixes and affixes;
• token’s hypernyms and derivations in Word-
Net;
• the grammatical class of the chunk, in which
the token occurs;
• the lemma of the governing verb of the token;
• phrasal chunks in the contextual window;
• the light verb feature for the governing verb;
• the polarity of the token’s context;
• the determiner of the token and the sentence’s
subject;
</listItem>
<bodyText confidence="0.999589">
In addition, we classify the tense attribute for the
detected event by applying a set of thirteen hand-
crafted rules.
</bodyText>
<subsectionHeader confidence="0.998754">
2.3 Temporal Relation Processing
</subsectionHeader>
<bodyText confidence="0.999941333333333">
Temporal relation recognition is the most difficult
task of temporal information processing, as it re-
quires recognitions of argument pairs, and subse-
quent classifications of relation types. Our ap-
proach employs a shift-reduce parsing technique,
which treats each document as a dependency struc-
ture of annotations labeled with temporal relations
(Kolomiyets et al., 2012). On the one hand, the ad-
vantage of the model is that the relation arguments
and the relation between them are extracted as a sin-
gle decision of a statistical classification model. On
the other hand, such a decision is local and might
not lead to the optimal global solution1. The follow-
ing features for deterministic shift-reduce temporal
parsing are employed:
</bodyText>
<listItem confidence="0.9985233">
• the token, its lemma, suffixes, coarse and fine-
grained POS tags;
• the governing verb, its POS tag and suffixes;
• the sentence’s root verb, its lemma and POS
tag;
• features for a prepositional phrase occurrence,
and domination by an auxiliary or modal verb;
• features for the presence of a temporal signal in
the chunk and co-occurrence in the same sen-
tence;
• a feature indicating if the sentence root verb
lemmas of the arguments are the same;
• the temporal relation between the argument and
the document creation time (DCT) (see below);
• a feature indicating if one argument is labeled
as a semantic role of the other;
• timex value generation pattern (e.g. YYYY-MM
for 2013-02, or PXY for P5Y) and timex
granularity (e.g. DAY-OF-MONTH for Friday,
MONTH-OF-YEAR for February etc.);
</listItem>
<footnote confidence="0.997521">
1For further details on the deterministic temporal parsing
model we refer the reader to (Kolomiyets et al., 2012).
</footnote>
<page confidence="0.98168">
84
</page>
<table confidence="0.99997475">
Training Test P R F1
TimeBank TimeBank 0.907 0.99 0.947
10-fold
AQUAINT 0.755 0.972 0.850
Silver 0.736 0.963 0.834
AQUAINT TimeBank 0.918 0.986 0.951
AQUAINT 0.795 0.970 0.874
10-fold
Silver 0.746 0.959 0.851
Silver TimeBank 0.941 0.976 0.958
AQUAINT 0.822 0.955 0.883
Silver 10-fold 0.798 0.944 0.865
</table>
<tableCaption confidence="0.999495">
Table 1: Results for timex detection in different corpora.
</tableCaption>
<bodyText confidence="0.998576285714286">
As one of the features above provides information
about the temporal relation between the argument
and the DCT, we employ an interval-based algebra
to classify relations between timexes and the DCT.
In case the argument is an event, we use a simple
logistic regression classifier with the following fea-
tures:
</bodyText>
<listItem confidence="0.9991375">
• the event token, its lemma, coarse and fine-
grained POS tags;
• tense, polarity, modality and aspect attributes;
• the token’s suffixes;
• the governing verb, its POS tag, tense and the
grammatical class of the chunk, in which the
event occurs;
• preceding tokens of the chunk;
</listItem>
<sectionHeader confidence="0.999929" genericHeader="evaluation">
3 Results
</sectionHeader>
<subsectionHeader confidence="0.999715">
3.1 Pre-Evaluation Results
</subsectionHeader>
<bodyText confidence="0.99989475">
The following results are obtained by 10-fold cross-
validations and corpus cross-validations with re-
spect to the evaluation criteria and metrics used in
TempEval-2. Tables 1 and 2 present the results for
the timex recognition and normalization tasks (Task
A), and, Tables 3 and 4 present the results for the
event recognition task (Task B).
As can be seen from the pre-evaluation results, the
most accurate classification of timexes on all cor-
pora in terms of F1 score is achieved for the model
trained on the Silver corpus. As for timex normaliza-
tion, the performances on TimeBank and the Silver
</bodyText>
<table confidence="0.99462675">
Test Corpus Type Acc. Value Acc.
TimeBank 0.847 0.742
AQUAINT 0.852 0.714
Silver 0.853 0.739
</table>
<tableCaption confidence="0.726617">
Table 2: Results for normalization in different corpora.
</tableCaption>
<table confidence="0.999967916666667">
Training Test P R F1
TimeBank TimeBank 0.82 0.641 0.72
10-fold
AQUAINT 0.864 0.649 0.741
Silver 0.888 0.734 0.804
AQUAINT TimeBank 0.766 0.575 0.657
AQUAINT 0.900 0.776 0.836
10-fold
Silver 0.869 0.755 0.808
Silver TimeBank 0.827 0.717 0.768
AQUAINT 0.906 0.807 0.854
Silver 10-fold 0.916 0.888 0.902
</table>
<tableCaption confidence="0.959475">
Table 3: Results for event detection in different corpora.
</tableCaption>
<table confidence="0.9999231">
Training Test Class Acc.
TimeBank TimeBank 10-fold 0.691
AQUAINT 0.717
Silver 0.804
AQUAINT TimeBank 0.620
AQUAINT 10-fold 0.830
Silver 0.794
Silver TimeBank 0.724
AQUAINT 0.829
Silver 10-fold 0.900
</table>
<tableCaption confidence="0.982295">
Table 4: Results for event classification in different cor-
pora.
</tableCaption>
<bodyText confidence="0.9992542">
corpus are not very different for type and value accu-
racies. Similarly, we observe the tendency for a bet-
ter performance on larger datasets with an exception
for 10-fold cross-validation using the AQUAINT
corpus.
</bodyText>
<subsectionHeader confidence="0.999247">
3.2 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999946666666667">
For the official evaluations we submitted three runs
of the system, one of which addresses Tasks A
and B (timex and event recognition)2, one (KUL-
</bodyText>
<footnote confidence="0.945024">
2During the official evaluation period, this run was re-
submitted with no changes in the output together with KUL-
TE3RunABC, which led to duplicate evaluation results known
</footnote>
<page confidence="0.997925">
85
</page>
<table confidence="0.9995168">
Run Relaxed Evaluation
P R F1 Rank
KULRun-1 0.929 0.769 0.836 21/23
KUL-0.921 0.754 0.829 22/23
TE3RunABC
Run Strict Evaluation
P R F1 Rank
KULRun-1 0.77 0.63 0.693 22/23
KUL- 0.814 0.667 0.733 15/23
TE3RunABC
</table>
<tableCaption confidence="0.998479">
Table 5: Results for the timex detection task.
</tableCaption>
<bodyText confidence="0.999936115384615">
TE3RunABC) provides a full temporal informa-
tion processing pipeline (Task ABC), and the one
for Task C only (KUL-TaskC). For KULRun-1 we
employed the recognition models described above,
all trained on the aggregated corpus comprising
all three available training corpora in the evalua-
tions. For KUL-TE3RunABC we also trained the
markable recognition models on the aggregated cor-
pus, but the event recognition output was slightly
changed in order to merge multiple consequent
events of the same semantic class into a single multi-
token event. The temporal dependency parsing
model was trained on the TimeBank and AQUAINT
corpora only, with a reduced set of relation labels.
This decision was motivated by the time constraints
and the training time needed. The final relation la-
bel set contains the following temporal relation la-
bels: BEFORE, AFTER, DURING, DURING INV,
INCLUDES and IS INCLUDED. Below we present
the obtained results for each task separately. The re-
sults for Task A are presented in Tables 5 and 6, for
Task B in Tables 7 and 8, and, for Task ABC and
Task-C-only in Table 9. It is worth mentioning that
for Task B the aspect value was provided as NONE,
thus this evaluation criterion is not representative for
our system.
</bodyText>
<sectionHeader confidence="0.997162" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.8614038">
For TempEval-3 we proposed a number of statisti-
cal and rule-based approaches. For Task A we em-
ployed a logistic regression classifier whose output
as KULRun-1 and KULRun-2. Further in the paper, we refer to
this run as simply to KULRun-1.
</bodyText>
<table confidence="0.999673769230769">
Run Rank
KULRun-1 F1 18/23
Value Type
0.629 0.741
Accuracy
Value Type 14/23
0.752 0.886
F1
KUL- Value Type 19/23
0.621 0.733
TE3RunABC Accuracy
Value Type 15/23
0.750 0.885
</table>
<tableCaption confidence="0.781516">
Table 6: Results for the timex normalization task.
</tableCaption>
<table confidence="0.99967275">
Run P R F1 Rank
KULRun-1 0.807 0.779 0.792 5/15
KUL- 0.776 0.765 0.77 12/15
TE3RunABC
</table>
<tableCaption confidence="0.868513">
Table 7: Results for the event detection task.
</tableCaption>
<table confidence="0.999928928571429">
Run Rank
KULRun-1 F1 3/15
Class Tense Aspect
0.701 n.a. n.a.
Accuracy 3/15
Class Tense Aspect
0.884 n.a. n.a.
KUL- F1 5/15
TE3RunABC
Class Tense Aspect
0.687 0.497 0.632
Accuracy 1/15
Class Tense Aspect
0.891 0.644 0.82
</table>
<tableCaption confidence="0.894099">
Table 8: Results for the event attribute recognition task.
</tableCaption>
<table confidence="0.999884">
Run P R F1 Rank
KUL- 0.18 0.202 0.191 8/8
TE3RunABC
KUL-TaskC 0.234 0.265 0.248 10/13
</table>
<tableCaption confidence="0.991559">
Table 9: Results for Tasks ABC (end-to-end processing)
and C (gold entities are given).
</tableCaption>
<bodyText confidence="0.976559">
was augmented by a small number of hand-crafted
rules to increase the recall. For the temporal ex-
</bodyText>
<page confidence="0.988521">
86
</page>
<bodyText confidence="0.99998756097561">
pression normalization subtask we employed a rule-
based system which estimates the attribute values for
the recognized timexes. For Task B we proposed
a logistic regression classifier which processes in-
put tokens and classifies them as event instances of
particular semantic classes. The optional tense at-
tribute was estimated by a number of manually de-
signed rules. For the most difficult tasks, Task ABC
and Task C, we proposed a dependency parsing tech-
nique that jointly learns from data what arguments
constitute a temporal relation and what the temporal
relation label is. Due to evaluation time constraints
and the time needed to model training, we reduced
the set of relation labels and trained the model on
two small annotated corpora.
The evaluations evidenced that the use of larger
annotated data sets did not improve the timex recog-
nition performance as it was expected from the pre-
evaluations. Interestingly, we did not observe the ex-
pected improvement in terms of recall, as it was the
case in the pre-evaluations. Yet, the timex normal-
ization performance levels in the official evaluations
were slightly higher than in the pre-evaluations. In
contrast to timex recognition, the use of a large an-
notated corpus improved the results for event recog-
nition. The pilot implementation of a temporal
parser for newswire articles showed the lowest per-
formance in the evaluations for Task ABC, but still
provided decent results for Task C. One of the ad-
vantages of the proposed temporal parser is that the
parser selects arguments for a temporal relation and
classifies it at the same time. The decision is drawn
by a statistical model trained on the annotated data,
that is, the parser does not consider any particular
predefined grammatical context in which the relation
arguments have to be found. Another weak point of
the parser is that it requires a large volume of high-
quality annotations and long training times. The last
two facts made it impossible to fully evaluate the
proposed temporal parsing model, and we will fur-
ther investigate the effectiveness of the model.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999681333333333">
The presented research was supporter by the TER-
ENCE (EU FP7-257410) and MUSE (EU FP7-
296703) projects.
</bodyText>
<sectionHeader confidence="0.996377" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999773472222223">
Steven Bethard and James H Martin. 2006. Identification
of Event Mentions and their Semantic Class. In Pro-
ceedings of the 2006 Conference on Empirical Meth-
ods in Natural Language Processing, pages 146–154.
Association for Computational Linguistics.
Koen Deschacht, Jan De Belder, and Marie-Francine
Moens. 2012. The Latent Words Language Model.
Computer Speech &amp; Language.
Oleksandr Kolomiyets and Marie-Francine Moens. 2010.
Kul: Recognition and Normalization of Temporal Ex-
pressions. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 325–328.
Association for Computational Linguistics.
Oleksandr Kolomiyets, Steven Bethard, and Marie-
Francine Moens. 2011. Model-Portability Experi-
ments for Textual Temporal Analysis. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 271–276.
Oleksandr Kolomiyets, Steven Bethard, and Marie-
Francine Moens. 2012. Extracting Narrative Time-
lines as Temporal Dependency Structures. In Proceed-
ings of the 50th Annual Meeting of the Association for
Computational Linguistics, pages 88–97. Association
for Computational Linguistics.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 Task 15: TempEval Temporal
Relation Identification. In Proceedings of the 4th In-
ternational Workshop on Semantic Evaluations, pages
75–80. Association for Computational Linguistics.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 Task 13:
TempEval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57–62. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.999476">
87
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.122707">
<title confidence="0.833503">KUL: A Data-driven Approach to Temporal Parsing of Documents Oleksandr KU Celestijnenlaan</title>
<author confidence="0.603534">Heverlee</author>
<affiliation confidence="0.927123">Department of Computer</affiliation>
<email confidence="0.733203">@cs.kuleuven.be</email>
<title confidence="0.506227333333333">Marie-Francine KU Celestijnenlaan</title>
<author confidence="0.434298">Heverlee</author>
<affiliation confidence="0.948356">Department of Computer</affiliation>
<email confidence="0.91382">sien.moens@cs.kuleuven.be</email>
<abstract confidence="0.999103642857143">This paper describes a system for temporal processing of text, which participated in the Temporal Evaluations 2013 campaign. The system employs a number of machine learning classifiers to perform the core tasks of: identification of time expressions and events, recognition of their attributes, and estimation of temporal links between recognized events and times. The central feature of the proposed system is temporal parsing – an approach which identifies temporal relation arguments (eventand event-timex pairs) and semantic the relation as a single decision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>James H Martin</author>
</authors>
<title>Identification of Event Mentions and their Semantic Class.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>146--154</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5114" citStr="Bethard and Martin (2006)" startWordPosition="790" endWordPosition="793">ns denoting the same date and vagueness in language, rule-based approaches are usually employed for the normalization task, and our implementation is a rule-based system. The normalization procedure is the same as described in (Kolomiyets and Moens, 2010), which participated in TempEval-2. 2.2 Event Processing The proposed method to event recognition implements a supervised machine learning approach that classifies every single token in the input sentence as an event instance of a specific semantic type. We implemented a logistic regression model with features largely derived from the work of Bethard and Martin (2006): • the token, its lemma, coarse and fine-grained POS tags, token’s suffixes and affixes; • token’s hypernyms and derivations in WordNet; • the grammatical class of the chunk, in which the token occurs; • the lemma of the governing verb of the token; • phrasal chunks in the contextual window; • the light verb feature for the governing verb; • the polarity of the token’s context; • the determiner of the token and the sentence’s subject; In addition, we classify the tense attribute for the detected event by applying a set of thirteen handcrafted rules. 2.3 Temporal Relation Processing Temporal r</context>
</contexts>
<marker>Bethard, Martin, 2006</marker>
<rawString>Steven Bethard and James H Martin. 2006. Identification of Event Mentions and their Semantic Class. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 146–154. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Jan De Belder</author>
<author>Marie-Francine Moens</author>
</authors>
<title>The Latent Words Language Model.</title>
<date>2012</date>
<journal>Computer Speech &amp; Language.</journal>
<marker>Deschacht, De Belder, Moens, 2012</marker>
<rawString>Koen Deschacht, Jan De Belder, and Marie-Francine Moens. 2012. The Latent Words Language Model. Computer Speech &amp; Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oleksandr Kolomiyets</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Kul: Recognition and Normalization of Temporal Expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>325--328</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4744" citStr="Kolomiyets and Moens, 2010" startWordPosition="733" endWordPosition="736">ags are determiners, adjectives, and cardinals. Another set of rules specifies unsuitable timexes, such as single cardinals with values outside predefined ranges of day-of-month, monthof-year and year numbers. Normalization of temporal expressions is a process of estimating standard temporal values and types for temporal expressions. Due to a large variance of expressions denoting the same date and vagueness in language, rule-based approaches are usually employed for the normalization task, and our implementation is a rule-based system. The normalization procedure is the same as described in (Kolomiyets and Moens, 2010), which participated in TempEval-2. 2.2 Event Processing The proposed method to event recognition implements a supervised machine learning approach that classifies every single token in the input sentence as an event instance of a specific semantic type. We implemented a logistic regression model with features largely derived from the work of Bethard and Martin (2006): • the token, its lemma, coarse and fine-grained POS tags, token’s suffixes and affixes; • token’s hypernyms and derivations in WordNet; • the grammatical class of the chunk, in which the token occurs; • the lemma of the governin</context>
</contexts>
<marker>Kolomiyets, Moens, 2010</marker>
<rawString>Oleksandr Kolomiyets and Marie-Francine Moens. 2010. Kul: Recognition and Normalization of Temporal Expressions. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 325–328. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oleksandr Kolomiyets</author>
<author>Steven Bethard</author>
<author>MarieFrancine Moens</author>
</authors>
<title>Model-Portability Experiments for Textual Temporal Analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>271--276</pages>
<contexts>
<context position="2883" citStr="Kolomiyets et al., 2011" startWordPosition="427" endWordPosition="430">d without specifying in advance the context in which these pairs have to occur. 2 Our Approach 2.1 Timex Processing 2.1.1 Timex Recognition and Normalization The proposed method for timex recognition implements a supervised machine learning approach that processes each chunk-phrase derived from the parse tree. Time expressions are detected by the model as phrasal chunks in the parse with their corresponding spans. In addition, the model is bootstrapped by substitutions of temporal triggers with their synonyms learned by the Latent Words Language Model (Deschacht et al., 2012) as described in (Kolomiyets et al., 2011). We implemented a logistic regression model that makes use of the following features: • the head word of the phrase and its POS tag; • all tokens and POS tags in the phrase as a bag of words; • the word-shape representation of the head word and the entire phrase, e.g. Xxxxx 99 for the expression April 30; Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 83–87, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics • the condensed word-shape representation f</context>
</contexts>
<marker>Kolomiyets, Bethard, Moens, 2011</marker>
<rawString>Oleksandr Kolomiyets, Steven Bethard, and MarieFrancine Moens. 2011. Model-Portability Experiments for Textual Temporal Analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 271–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oleksandr Kolomiyets</author>
<author>Steven Bethard</author>
<author>MarieFrancine Moens</author>
</authors>
<title>Extracting Narrative Timelines as Temporal Dependency Structures.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6074" citStr="Kolomiyets et al., 2012" startWordPosition="945" endWordPosition="948"> verb; • the polarity of the token’s context; • the determiner of the token and the sentence’s subject; In addition, we classify the tense attribute for the detected event by applying a set of thirteen handcrafted rules. 2.3 Temporal Relation Processing Temporal relation recognition is the most difficult task of temporal information processing, as it requires recognitions of argument pairs, and subsequent classifications of relation types. Our approach employs a shift-reduce parsing technique, which treats each document as a dependency structure of annotations labeled with temporal relations (Kolomiyets et al., 2012). On the one hand, the advantage of the model is that the relation arguments and the relation between them are extracted as a single decision of a statistical classification model. On the other hand, such a decision is local and might not lead to the optimal global solution1. The following features for deterministic shift-reduce temporal parsing are employed: • the token, its lemma, suffixes, coarse and finegrained POS tags; • the governing verb, its POS tag and suffixes; • the sentence’s root verb, its lemma and POS tag; • features for a prepositional phrase occurrence, and domination by an a</context>
<context position="7341" citStr="Kolomiyets et al., 2012" startWordPosition="1160" endWordPosition="1163">presence of a temporal signal in the chunk and co-occurrence in the same sentence; • a feature indicating if the sentence root verb lemmas of the arguments are the same; • the temporal relation between the argument and the document creation time (DCT) (see below); • a feature indicating if one argument is labeled as a semantic role of the other; • timex value generation pattern (e.g. YYYY-MM for 2013-02, or PXY for P5Y) and timex granularity (e.g. DAY-OF-MONTH for Friday, MONTH-OF-YEAR for February etc.); 1For further details on the deterministic temporal parsing model we refer the reader to (Kolomiyets et al., 2012). 84 Training Test P R F1 TimeBank TimeBank 0.907 0.99 0.947 10-fold AQUAINT 0.755 0.972 0.850 Silver 0.736 0.963 0.834 AQUAINT TimeBank 0.918 0.986 0.951 AQUAINT 0.795 0.970 0.874 10-fold Silver 0.746 0.959 0.851 Silver TimeBank 0.941 0.976 0.958 AQUAINT 0.822 0.955 0.883 Silver 10-fold 0.798 0.944 0.865 Table 1: Results for timex detection in different corpora. As one of the features above provides information about the temporal relation between the argument and the DCT, we employ an interval-based algebra to classify relations between timexes and the DCT. In case the argument is an event, w</context>
</contexts>
<marker>Kolomiyets, Bethard, Moens, 2012</marker>
<rawString>Oleksandr Kolomiyets, Steven Bethard, and MarieFrancine Moens. 2012. Extracting Narrative Timelines as Temporal Dependency Structures. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 88–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2007 Task 15: TempEval Temporal Relation Identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>75--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1070" citStr="Verhagen et al., 2007" startWordPosition="144" endWordPosition="147">ations 2013 campaign. The system employs a number of machine learning classifiers to perform the core tasks of: identification of time expressions and events, recognition of their attributes, and estimation of temporal links between recognized events and times. The central feature of the proposed system is temporal parsing – an approach which identifies temporal relation arguments (eventevent and event-timex pairs) and the semantic label of the relation as a single decision. 1 Introduction Temporal Evaluations 2013 (TempEval-3) is the third iteration of temporal evaluations (after TempEval-1 (Verhagen et al., 2007) and TempEval2 (Verhagen et al., 2010)) which addresses the task of temporal information processing of text. In contrast to the previous evaluation campaigns where the temporal relation recognition task was simplified by restricting grammatical context (events in adjacent sentences, events and times in the same sentences) and proposed relation pairs, TempEval-3 does not set any context in which temporal relations have to be identified. Thus, for temporal relation recognition the challenges consist of: first, detecting a pair of events, or an event and a time that constitutes a temporal relatio</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. Semeval-2007 Task 15: TempEval Temporal Relation Identification. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 75–80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>Semeval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>57--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1108" citStr="Verhagen et al., 2010" startWordPosition="151" endWordPosition="154">ys a number of machine learning classifiers to perform the core tasks of: identification of time expressions and events, recognition of their attributes, and estimation of temporal links between recognized events and times. The central feature of the proposed system is temporal parsing – an approach which identifies temporal relation arguments (eventevent and event-timex pairs) and the semantic label of the relation as a single decision. 1 Introduction Temporal Evaluations 2013 (TempEval-3) is the third iteration of temporal evaluations (after TempEval-1 (Verhagen et al., 2007) and TempEval2 (Verhagen et al., 2010)) which addresses the task of temporal information processing of text. In contrast to the previous evaluation campaigns where the temporal relation recognition task was simplified by restricting grammatical context (events in adjacent sentences, events and times in the same sentences) and proposed relation pairs, TempEval-3 does not set any context in which temporal relations have to be identified. Thus, for temporal relation recognition the challenges consist of: first, detecting a pair of events, or an event and a time that constitutes a temporal relation; and, second, determining what seman</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. Semeval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57–62. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>