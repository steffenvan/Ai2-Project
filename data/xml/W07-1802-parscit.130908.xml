<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.994264">
Converting Grammatical Framework to Regulus
</title>
<author confidence="0.996881">
Peter Ljunglöf
</author>
<affiliation confidence="0.998463">
Department of Linguistics
Göteborg University
</affiliation>
<address confidence="0.50385">
Gothenburg, Sweden
</address>
<email confidence="0.99562">
peb@ling.gu.se
</email>
<sectionHeader confidence="0.997346" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999655625">
We present an algorithm for converting
Grammatical Framework grammars (Ranta,
2004) into the Regulus unification-based
framework (Rayner et al., 2006). The main
purpose is to take advantage of the Regulus-
to-Nuance compiler for generating opti-
mized speech recognition grammars. But
there is also a theoretical interest in knowing
how similar the two grammar formalisms
are.
Since Grammatical Framework is more ex-
pressive than Regulus, the resulting Regu-
lus grammars can be overgenerating. We
therefore describe a subclass of Grammati-
cal Framework for which the algorithm re-
sults in an equivalent Regulus grammar.
</bodyText>
<sectionHeader confidence="0.993722" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.999856928571429">
In this section we describe the grammar formalism
Grammatical Framework (GF), and discuss its ex-
pressive power and the present options for creat-
ing speech recognition grammars (SRGs). The main
problem is that the size of the grammar can explode
when inflectional parameters are expanded. In this
paper we try to solve this problem by converting to
a formalism for which there is an optimized SRG
compiler. This formalism is Regulus, which is de-
scribed together with its SRG compiler.
The formal details are left out of the descriptions
in this section and can instead be found in section 2.
In section 3 the conversion algorithm is presented in
detail, and in section 4 there is a short discussion.
</bodyText>
<subsectionHeader confidence="0.980502">
1.1 Grammatical Framework
</subsectionHeader>
<bodyText confidence="0.999745142857143">
Grammatical Framework (Ranta, 2004) is a gram-
mar formalism based on type theory. The main fea-
ture is the separation of abstract and concrete syn-
tax, which makes it very suitable for writing mul-
tilingual grammars. A rich module system also fa-
cilitates grammar writing as an engineering task, by
reusing common grammars.
</bodyText>
<subsectionHeader confidence="0.986244">
1.1.1 Separating abstract and concrete syntax
</subsectionHeader>
<bodyText confidence="0.99970508">
The main idea of GF is the separation of ab-
stract and concrete syntax, a distinction which is
shared with several other grammar formalisms such
as Abstract Categorial Grammars (de Groote, 2001),
Lambda Grammar (Muskens, 2003) and Higher Or-
der Grammar (Pollard, 2004). The abstract part of
a grammar defines a set of abstract syntactic struc-
tures, called abstract terms or trees; and the concrete
part defines a relation between abstract structures
and concrete structures.
GF has a linearization perspective to grammar
writing, where the relation between abstract and
concrete is viewed as a mapping from abstract to
concrete structures, called linearization terms. In
some cases the mapping can be partial or even many-
valued.
Although not exploited in many well-known
grammar formalisms, a clear separation between ab-
stract and concrete syntax gives some advantages.
High-level language descriptions: When describ-
ing the abstract syntax, the grammar writer can
choose not to care about language specific de-
tails, such as inflection and word order.
Multilingual grammars: It is possible to define
different concrete syntaxes for one particular
</bodyText>
<page confidence="0.969605">
9
</page>
<note confidence="0.584428">
Proceedings of SPEECHGRAM 2007, pages 9–16,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.998830411764706">
abstract syntax. Multilingual grammars can be
used as a model for interlingua translation, but
also to simplify localization of language tech-
nology applications.
Resource grammars: The abstract syntax of one
grammar can be used as a concrete syntax of
another grammar. This makes it possible to im-
plement grammar resources to be used in sev-
eral different application domains.
These points are currently exploited in the GF Re-
source Grammar Library (Ranta et al., 2006), which
is a multilingual GF grammar with a common ab-
stract syntax for 13 languages. The grammati-
cal coverage is similar to the Core Language En-
gine (Rayner et al., 2000). The main purpose of
the Grammar Library is as a resource for writing
domain-specific grammars.
</bodyText>
<subsectionHeader confidence="0.974391">
1.1.2 Abstract syntax
</subsectionHeader>
<bodyText confidence="0.999852470588235">
The abstract theory of GF is a version of Martin-
Löf’s (1984) dependent type theory. A grammar
consists of declarations of categories and functions.
Categories can depend on other categories. Func-
tion declarations can bind variables to be used in de-
pendent types, and also take functions as arguments,
thus giving rise to higher-order functions. Since the
abstract syntax also permits function definitions, the
expressive power of GF abstract syntax is Turing-
complete.
In this article we restrict ourselves to an impor-
tant subclass of GF, where there are no dependent
types and no higher-order functions. This subclass
is called context-free GF, and is an instance of Gen-
eralized Context-Free Grammar (Pollard, 1984).
The abstract syntax of a context-free GF grammar
consists of a set of function typings of the form
</bodyText>
<equation confidence="0.952237">
fA1 → · · · → A� → A
</equation>
<bodyText confidence="0.9998172">
This typing says that f is a function taking δ argu-
ments with categories Al ... Aa and returning a cat-
egory A. This is equivalent to a context-free gram-
mar without terminal symbols. Note however, that
the function f would be written A → Al ... Aa as
an ordinary context-free rule. I.e., the left-hand side
of a context-free rule corresponds to the result of the
function, which is written to the right. The restric-
tion to a context-free backbone is not severe, since
the concrete syntax is so expressive.
</bodyText>
<subsectionHeader confidence="0.965806">
1.1.3 Concrete syntax
</subsectionHeader>
<bodyText confidence="0.999949055555556">
Linearizations are written as terms in a typed
functional programming language, which is limited
to ensure decidability in generation and in parsing.
The language has records and finite-domain func-
tions (called tables); and the basic types are termi-
nal lists (called strings) and finite data types (called
parameter types). There are also local definitions,
lambda-abstractions and global function definitions.
The parameters are declared by the grammar; they
can be hierarchical but not recursive, to ensure finite-
ness.
The language of linearization terms is quite com-
plex, but it can be compiled to a normalized form
which is called canonical GF. In this paper we as-
sume that all linearizations are in canonical form.
A canonical concrete GF grammar contains declara-
tions of all parameter types, and linearization defini-
tions for all abstract functions.
</bodyText>
<subsectionHeader confidence="0.983058">
1.1.4 Expressive power
</subsectionHeader>
<bodyText confidence="0.999969347826087">
The expressive power of context-free GF solely
depends on the possibility of discontinuous con-
stituents. This means that one grammatical phrase
can be split into several parts occurring in different
places in the sentence. Discontinuous constituents
permit a simple and compositional way of treating,
e.g., German compound verbs, where the particle
commonly is moved to the end of the sentence.
Ljunglöf (2004) showed that context-free GF is
equivalent to Multiple Context-Free Grammar (Seki
et al., 1991), which is known to be parseable in time
polynomial in the length of the input string. From a
converted Multiple CFG, each constituent can be ex-
tracted as a context-free rule, which will result in a
possibly overgenerating context-free grammar. This
context-free grammar can be output from the GF
system in several different speech recognition for-
mats, as described by Bringert (2007).
There is a severe problem with the conversion
from GF to Multiple CFG however – the size of
the resulting grammar tend to explode when the in-
flectional parameters are expanded. Large gram-
mars such as many of the languages in the Resource
</bodyText>
<page confidence="0.992638">
10
</page>
<bodyText confidence="0.9998232">
Grammar Library simply cannot be converted. One
solution would be to optimize the conversion algo-
rithm, e.g., by interleaving parameter expansion and
grammar compaction. Another solution would be
to translate into a grammar formalism which does
not have this size explosion. This is where Regulus
comes in – if we could translate GF grammars into
Regulus grammars, we could make use of the re-
search already put into the Regulus-to-Nuance com-
piler, and would not have to reinvent the wheel.
</bodyText>
<subsectionHeader confidence="0.964927">
1.2 Regulus
</subsectionHeader>
<bodyText confidence="0.9999774">
Regulus is an open-source toolkit for writing
grammar-based speech recognition systems (Rayner
et al., 2006).1 The central part is the Regulus gram-
mar formalism and a compiler for creating speech
recognition grammars. The toolkit has been en-
hanced with templates for developing e.g., speech
translation systems and dialogue systems. There is
also an English resource grammar, which can be
used for grammar specialization using explanation-
based learning (Rayner et al., 2006, chapters 9–10).
</bodyText>
<subsectionHeader confidence="0.963155">
1.2.1 Unification of finite parameters
</subsectionHeader>
<bodyText confidence="0.99997295">
The Regulus formalism is a context-free gram-
mar, enhanced with unification of finite parameters.
This means that the formalism is equivalent to a
context-free grammar.
Each context-free category (e.g., Noun) has a
number of features (e.g., Number and Gender)
with a finite domain of values (e.g., Sg/Pl and
Masc/Fem/Neutr). The feature values are specified
using a record paired with the grammatical category.
Logical variables can be used for unifying features
of different constituents in the rule. It is possible to
define macros for simplifying common tasks, e.g.,
when implementing a lexicon.
Compared to Grammatical Framework, the Regu-
lus formalism is quite restricted. There is no clear
distinction between abstract and concrete syntax,
and there is no advanced module system in which to
define grammatical resources. Also, Regulus lacks
discontinuous constituents, which reduces the ex-
pressive power considerably.
</bodyText>
<footnote confidence="0.924038666666667">
1More information about Regulus, including download in-
formation, can be found on the project homepage: http:
//www.issco.unige.ch/projects/regulus/
</footnote>
<subsectionHeader confidence="0.381842">
1.2.2 Compiling Regulus to Nuance GSL
</subsectionHeader>
<bodyText confidence="0.999803692307692">
Nuance Communications (2003) has developed
a context-free grammar format for speech recogni-
tion, which has become one of the de facto stan-
dards for speech recognition. The grammar format
is called Nuance Grammar Specification Language
(GSL). The format has some special features, such
as semantic tagging and probabilistic grammar rules.
There are also restrictions in the format, most no-
tably that the grammars must not be left-recursive.
The Regulus formalism is designed to be able to
make use of the special features in Nuance GSL, and
the compiler can always create correct GSL gram-
mars without left-recursion.
</bodyText>
<sectionHeader confidence="0.997038" genericHeader="introduction">
2 Formal definitions
</sectionHeader>
<bodyText confidence="0.99763775">
In this section we give formal definitions of rules and
linearization terms in GF, grammar rules and terms
in Regulus, and the intermediate structures we will
be using.
</bodyText>
<subsectionHeader confidence="0.985515">
2.1 GF grammar rules
</subsectionHeader>
<bodyText confidence="0.999811">
Since we are only interested in GF grammars with
a context-free backbone, the abstract syntax is a
context-free grammar where each rule has a unique
name. The rules are written as typings in a func-
tional language:
</bodyText>
<equation confidence="0.988697">
f� A1 � � � � � Aa � A
</equation>
<bodyText confidence="0.99983575">
As mentioned earlier, this declaration corresponds to
the context-free rule A —* Al ... Aa.
Linearizations are written as function definitions,
f xi ... xa = t, where xi ... xa are variables that
occur in the linearization term t. An alternative way
of writing this is to name the variables consistently
for each rule, and then the linearization term t it-
self is sufficient as a linearization definition. We
adopt this idea and use the uniform variable names
$1... $6 in each linearization. With this approach
we also distinguish the argument variables from the
parameter variables which get bound in tables.
</bodyText>
<subsectionHeader confidence="0.973054">
2.2 GF linearization terms and substructures
</subsectionHeader>
<bodyText confidence="0.999930666666667">
A parameter type P is just a set of parameter values
{pl, ... , pn1. Note that all parameter types must
be disjoint, i.e., each parameter should belong to
</bodyText>
<page confidence="0.996233">
11
</page>
<bodyText confidence="0.999669857142857">
exactly one parameter type. Linearizations are de-
fined by association linearization terms to the ab-
stract functions. Note that the definition of terms is
slightly more general than the definition in GF, since
we want to include reduced terms in the definition.
The relation between the introduced classes are as
follows:
</bodyText>
<table confidence="0.891884090909091">
P ⊂ VPar1 ⊂ V ⊂ T
VStr J
Terms (t ∈ T) are defined inductively as follows:
t ::= $n argument
 |&amp;quot;s&amp;quot; string
 |t ++ t&apos; concatenation
 |p pattern
 |{r1 = t1; ... ; rn = tn} record
 |t.r projection
 |[p1 ⇒ t1; ... ; pn ⇒ tn] table
 |t1!t2 selection
</table>
<bodyText confidence="0.935700181818182">
where n &gt; 0 is a positive integer, p ∈ P is a pattern,
and r ∈ R is a record label. The class R of record
labels is just a finite class of atomic values. The ar-
gument reference $n denotes the nth argument of
the linearization function.
Patterns (p ∈ P) are pairs x0π of variables, x,
and sets of parameters, π = {p1 ... pn}. The pa-
rameters p1 ... pn all must belong to the same pa-
rameter type P, i.e., π ⊆ P. The meaning of the
pattern is that x is bound to one of the parameters in
π. If π = P we can skip that part and simply write
x. Conversely, if x is not used elsewhere in the term,
we can skip it and simply write π.
Note that a pattern is a term in itself, but in GF
it will always occur as a single variable x or as a
single parameter p. However, after the conversion
algorithm has transformed tables into records, pat-
terns will become first class terms.
Reduced terms (v ∈ V) are subterms of ordinary
terms. A reduced term is a term which does not
contain a table or a selection, and where projections
only occur in the form $n.ρ, where ρ ∈ R* is a se-
</bodyText>
<equation confidence="0.899978333333333">
quence of labels:
v ::= $n.ρ
 |»s»
 |v ++ v&apos;
 |p
 |{r1 = v1; ... ;rn = vn}
</equation>
<bodyText confidence="0.693744666666667">
Reduced parameter terms (vp ∈ VPar) are sub-
terms of reduced terms, which correspond to param-
eters:
</bodyText>
<equation confidence="0.520277">
vp ::= $n.ρ  |p
</equation>
<bodyText confidence="0.864663428571429">
Reduced string terms (vs ∈ VStr) are subterms
of reduced terms, which correspond to strings:
vs ::= $n.ρ  |&amp;quot;s»  |vs ++ v&apos;s
Note that this is equivalent to a sequence of argu-
ment projections and string constants, which in turn
is equivalent to a right-hand side in a context-free
rule.
</bodyText>
<subsectionHeader confidence="0.995981">
2.3 Regulus grammar rules and terms
</subsectionHeader>
<bodyText confidence="0.97542225">
A Regulus grammar is a unification-based phrase-
structure grammar. It consists of grammar rules,
which in turn is built up using Regulus terms.
Regulus rules are regular context-free grammar
rules, where each category is augmented with a Reg-
ulus term:
A:v → σ0 A1:v1 σ1 ... Aδ:vδ σδ
where each Ai is a context-free category, each vi is
a Regulus term, and each σi is a (possibly empty)
sequence of terminal tokens.
Regulus terms are flat records where all values
are patterns (pi = xi0πi):2
</bodyText>
<equation confidence="0.785032">
vr ::= {r1 = p1; ... ;rn = pn}
</equation>
<bodyText confidence="0.999976375">
In this sense, Regulus terms are just subterms of re-
duced terms. However, a Regulus term can include
one of the two special labels sem and gsem, cor-
responding to return values and global slot-filling
in Nuance GSL, respectively. They can contain
complex structures, such as deeply nested lists and
records. Using these it is possible to define the syn-
tactical structure of a phrase.
</bodyText>
<footnote confidence="0.919624">
2This is a slight abuse of syntax – in Regulus the record row
ri = xi@Tri is written as two separate rows ri = xi; ri = Tri.
</footnote>
<page confidence="0.998314">
12
</page>
<sectionHeader confidence="0.986898" genericHeader="method">
3 Converting GF to Regulus
</sectionHeader>
<bodyText confidence="0.998975666666667">
In this section we describe an algorithm for convert-
ing any context-free GF rule into a set of Regulus
rules. This conversion is done in three steps:
</bodyText>
<listItem confidence="0.998502285714286">
1. Tables and table selections are removed from
the GF term, resulting in several reduced terms
and sets of constraints.
2. The results are massaged into Regulus terms
for the left-hand side and the right-hand side.
3. Finally, GF abstract syntax is used to create the
final Regulus rules.
</listItem>
<bodyText confidence="0.972000714285714">
In the final step, the abstract syntax is added as a se-
mantic value in the Regulus rules. This makes it pos-
sible to get back the GF abstract syntax tree, when
using Regulus (or Nuance) for parsing the grammar.
Example As a running example we will use a stan-
dard English GF rule for combining transitive verbs
with noun phrases:
</bodyText>
<equation confidence="0.989117">
vp : TV → NP → VP
= {s = [n ⇒ $1.s!n ++ $2.s]}
</equation>
<bodyText confidence="0.93416175">
The idea is that a verb phrase has a parametrical
number (n), which it inherits from the verb. When
the verb phrase is used in a sentence, the number
will depend on the inherent number of the subject.
</bodyText>
<subsectionHeader confidence="0.8196835">
3.1 Converting tables to unification-based
records
</subsectionHeader>
<bodyText confidence="0.998992411764706">
The main difference between GF and Regulus is that
the former has tables and the latter has unification.
The problem when converting from GF to Regulus
is therefore how to get rid of the tables and selec-
tions. We present an algorithm for removing tables
and selections, by replacing them with logical vari-
ables and equality constraints.
The basic idea is to translate each row pi ⇒ ti
in a table into a record {p = pi; v = ti}. The
variables in ti which are bound by pi become log-
ical variables. Thus the original table gives rise to n
different records (if n is the number of table rows),
which in the end becomes n different Regulus terms.
A table selection t!t0 then has to be translated into
the value t.v of the table, and a constraint is added
that the selection term t0 and the pattern t.p of the
table should be unified.
</bodyText>
<subsubsectionHeader confidence="0.908068">
Step 1: Removing tables and selections
</subsubsectionHeader>
<bodyText confidence="0.999315833333333">
We define a nondeterministic reduction operation
=⇒ . The meaning of t =⇒ v/Γ is that the term t ∈
T is converted to the reduced term v ∈ V together
with the set of constraints Γ ⊆ VPar × VPar. Each
constraint in Γ is of the form vp =.v0 p, where vp and
v0p are reduced parameter terms.
</bodyText>
<listItem confidence="0.978339">
• Each row pi ⇒ ti in a table is reduced to a
record containing the pattern pi and the reduced
value vi:
</listItem>
<equation confidence="0.9854295">
ti =⇒ vi/Γi
[... ; pi ⇒ ti; ...] =⇒ {p = pi; v = vi}/Γi
</equation>
<bodyText confidence="0.998347">
Note that this rule is nondeterministic – the ta-
ble is reduced to n different terms, where n is
the number of table rows.
</bodyText>
<listItem confidence="0.999066333333333">
• A table selection t!t0 is reduced to the value v.v,
with the added constraint that the pattern v.p
and the selection term v0 should unify:
</listItem>
<equation confidence="0.9989465">
t =⇒ v0/Γ t0 =⇒ v0p/Γ0
t!t0=⇒v/ΓΓ0(vp=.v0p)
</equation>
<bodyText confidence="0.996323">
Note that since t0 denotes a parameter, it will be
reduced to a parameter term, v0p ∈ VPar.
</bodyText>
<listItem confidence="0.9831595">
• A record projection t.r is reduced to a projec-
tion v.r:
vr = prj(v, r)
• All other term constructors are reduced com-
</listItem>
<bodyText confidence="0.890030333333333">
positionally, i.e., by reducing the internal terms
recursively.
The function prj(v, r) calculates the projection of
r on the simple term v. Since there are only two
reduced term constructors that can correspond to a
record, there are only two cases in the definition:
</bodyText>
<equation confidence="0.960014666666667">
prj({... ;r = vr; ...}, r) = vr
prj($n.p , r) = $n.ρr
vp = prj(v0, p)
v = prj(vo, v)
t =⇒ v/Γ
t.r =⇒ vr/Γ
</equation>
<page confidence="0.994669">
13
</page>
<bodyText confidence="0.993115833333333">
Example The original linearization term of the ex-
ample contains one table and one selection. The
selection $1.s!n is reduced to $1.sv with the added
constraint $1.sp .= n. And since there is only one
row in the table, the example term is reduced to one
single term vvp with the constraints Γvp:
</bodyText>
<equation confidence="0.953833">
vvp = {s = {p = n; v = $1.sv ++ $2.s}}
Γvp = $1.sp .= n
</equation>
<subsectionHeader confidence="0.999772">
3.2 Building Regulus terms
</subsectionHeader>
<bodyText confidence="0.9981415">
The reduced term and the constraints from the first
step do not constitute a Regulus grammar rule, but
they have to be massaged into the correct form. This
is done in four small steps below.
</bodyText>
<subsubsectionHeader confidence="0.953646">
Step 2a: Flattening the reduced term
</subsubsectionHeader>
<bodyText confidence="0.999136">
After the conversion t ==&gt;. v/Γ, we have a re-
duced term v E V and a set of constraints Γ E
VPar x VPar. Now we convert v into a set of con-
straints and add to the constraint store Γ:
</bodyText>
<listItem confidence="0.8803077">
• For each subterm v&apos; in v denoting a parameter,
add $0.p .= v&apos; to Γ. The path p is the sequence
of labels for getting from v to v&apos;, i.e., v&apos; = v.p.
We also create a set of “proto rules” Σ E R* xVStr:
• For each subterm v&apos; in v denoting a string, add
p —* v&apos; to Σ. The path p is the same as above.
Example There is one subterm in vvp denoting a
parameter, so we add $0.sp =. n to Γvp. There is
one subterm in vvp that denotes a string, so we let
Σvp contain sv —* $1.sv ++ $2.s.
</listItem>
<subsubsectionHeader confidence="0.956996">
Step 2b: Simplifying the constraints
</subsubsectionHeader>
<bodyText confidence="0.997202333333333">
Now we have two constraint stores, Σ and Γ, of
which the latter can be partially evaluated into a sim-
pler form.
</bodyText>
<listItem confidence="0.928072333333333">
1. For each constraint of the form $n1.p1 .=
$n2.p2, we replace it with two new constraints
$ni.pi =. x, where x is a fresh variable.3
2. For each constraint of the form x1@7r1 .=
x2@7r2 , there are two possibilities:
3Recall that x is just a shorthand for x@it, where it is the set
of all parameters.
• If 7r1 and 7r2 are disjoint, then the con-
straint is contradictive and we remove v,
Γ and Σ from the list of results.
• Otherwise, we replace each occurrence of
xi@7ri in v and in Γ, by x@7r, where x is a
fresh variable and 7r = 7r1 n 7r2.
Example We do not have to do anything to Γvp,
since all constraints already are in simplified form.
</listItem>
<subsubsectionHeader confidence="0.748044">
Step 2c: Building Regulus terms
</subsubsectionHeader>
<bodyText confidence="0.9983395">
Now Γ only contains constraints of the form
$n.p .= p where p = x@7r. We transform these
constraints into the Regulus records T0, T1, ... , Ta
in the following way:
</bodyText>
<listItem confidence="0.962314">
• For each constraint $n.p =. p, add the record
row {p = p} to Tn.
</listItem>
<bodyText confidence="0.70602225">
Note that the labels in the Regulus terms are se-
quences of GF labels.
Example The constraints in Γvp now give rise to
the Regulus terms:
</bodyText>
<equation confidence="0.999864333333333">
Tvp,0 = {sp = n}
Tvp,1 = {sp = n}
Tvp,2 = {}
</equation>
<subsectionHeader confidence="0.999914">
3.3 Building a Regulus grammar
</subsectionHeader>
<bodyText confidence="0.999723714285714">
To be able to create Regulus grammar rules from the
Regulus terms T0 ... Ta, we need to look at the ab-
stract syntax in the GF grammar. In this section we
will assume that the typing of the linearization in
question is f : A1 —* · · · —* Aa —* A.
Regulus (and Nuance GSL) permits the use of ar-
bitrary nested lists in the special sem feature. We
will use the nested list for representing a GF abstract
syntax tree which then will be returned directly by
Nuance after the parsing has succeeded. This is im-
portant since the arguments to the function can be
permuted in the linearization, which then means that
the arguments in the Regulus rule are permuted as
well.
</bodyText>
<page confidence="0.997116">
14
</page>
<note confidence="0.5827195">
Step 3a: Adding GF abstract syntax to the
Regulus terms
</note>
<bodyText confidence="0.998651">
The abstract syntax tree of the original rule is put
as a sem value in the left-hand side term T0:
</bodyText>
<listItem confidence="0.9935795">
• Add the row {sem=[f x1 ... xδ]} to T0.
• For each 1 ≤ i ≤ 6, add {sem=xi} to Ti.
</listItem>
<bodyText confidence="0.97717">
Note that the x1 ... xδ should be fresh variables, not
used elsewhere in the terms.
</bodyText>
<equation confidence="0.6999242">
Example After adding semantics, the example
terms become:
Tvp,0 = {sp = n; sem = [vp x y]}
Tvp,1 = {sp = n; sem = x}
Tvp,2 = {sem = y}
</equation>
<bodyText confidence="0.7709534">
Step 3b: Building Regulus grammar rules
Finally, we can transform the proto rules in Σ into
Regulus grammar rules:
• For each proto rule p0 → v1 ++ · · · ++ vm in
Σ, create a new Regulus rule:
</bodyText>
<equation confidence="0.915299">
Ap0 : T0 → vi ... v&apos;
</equation>
<bodyText confidence="0.9998945">
where the terms in the right-hand side are cal-
culated as follows:
</bodyText>
<equation confidence="0.821071">
(”s”)O = ”s”
($n.p)° = An p : Tn
</equation>
<bodyText confidence="0.94239425">
Example From the single proto rule in Σvp we cre-
ate the Regulus rule:
VPs, : Tvp,0 → TVs, : Tvp,1 NPs : Tvp,2
where the terms Tvp,i are described above.
</bodyText>
<sectionHeader confidence="0.999913" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999955666666667">
We have presented an algorithm for converting
GF grammars with a context-free backbone into
unification-based Regulus grammars. The algorithm
is simple and straightforward, which is an indication
that the formalisms are more similar than one might
have guessed beforehand.
</bodyText>
<subsectionHeader confidence="0.994623">
4.1 Equivalence of the grammars
</subsectionHeader>
<bodyText confidence="0.999987636363636">
The presented algorithm does not necessarily yield
an equivalent grammar. This is a consequence of the
fact that context-free GF is equivalent to Multiple
CFG, and that Multiple CFG is much more expres-
sive than context-free grammars.
However, if the original grammar does not make
use of multiple constituents, the conversion is equiv-
alent. Note that the grammar might very well con-
tain multiple constituents, but if there is no right-
hand side that refers to both constituents simultane-
ously the equivalence is still preserved.
</bodyText>
<subsectionHeader confidence="0.952156">
4.2 Complexity issues
</subsectionHeader>
<bodyText confidence="0.9998815">
As mentioned earlier, each GF function might give
rise to several Regulus rules, so in one sense the re-
sulting grammar is bigger than the original. How-
ever, the actual size in terms of memory usage does
not differ (except maybe linear because of differ-
ences in syntax).
</bodyText>
<subsectionHeader confidence="0.899569">
4.2.1 The number of rules
</subsectionHeader>
<bodyText confidence="0.8269025">
The number of Regulus rules for one single GF
linearization term is equal to:
</bodyText>
<equation confidence="0.722918333333333">
�
|Σ|
φ
</equation>
<bodyText confidence="0.999919333333333">
where |Σ |is the number of discontinuous con-
stituents, and 0 ranges over all tables in the lin-
earization term. This is easy to see, since it is
only tables that are reduced nondeterministically,
and each proto rule in Σ gives rise to one Regulus
rule.
</bodyText>
<subsubsectionHeader confidence="0.682172">
4.2.2 The size of the grammar
</subsubsectionHeader>
<bodyText confidence="0.99969725">
The total size of the final grammar can be larger
than the original GF grammar. This is because the
Regulus grammar will contain lots of copies of the
same structures, e.g., everything outside of a table
has to be duplicated in for each table row. The the-
oretical limit is the same as above – the number of
constituents, times the the total product of all table
rows – but in practice the grammar explosion is not
that extreme.
Since the increase in size is due to copying, the
Regulus grammar can be compacted by the use of
macros (Rayner et al., 2006, section 4.5). This could
</bodyText>
<page confidence="0.642937">
|0|
15
</page>
<bodyText confidence="0.9981505">
probably be implemented in the algorithm directly,
but we have not yet investigated this idea.
</bodyText>
<subsubsectionHeader confidence="0.513572">
4.2.3 Time complexity
</subsubsectionHeader>
<bodyText confidence="0.999845090909091">
The time complexity of the algorithm is approxi-
mately equivalent to the size of the resulting Regu-
lus grammar. The first step (in section 3.1), can be
implemented as a single pass through the term and
is therefore linear in the size of the resulting terms.
The post-processing steps (in section 3.2) are also
linear in the size of the terms and constraints. Fi-
nally, the steps for building grammar rules does not
depend on the term size at all. Thus, the time com-
plexity is linear in the size of the final Regulus gram-
mar.
</bodyText>
<subsectionHeader confidence="0.883544">
4.3 Using Regulus as a compiler for speech
recognition grammars
</subsectionHeader>
<bodyText confidence="0.9999062">
By presenting an algorithm for converting GF gram-
mars into Regulus, it is possible to further use the
Regulus-to-Nuance compiler for getting an opti-
mized speech recognition grammar. The advantage
to compiling Nuance grammars directly from GF is
clear: the Regulus project has developed and imple-
mented several optimizations (Rayner et al., 2006,
chapter 8), which would have to be reimplemented
in a direct GF-to-Nuance compiler.
As previously mentioned in section 1.1.4, there is
a speech recognition grammar compiler already im-
plemented in GF (Bringert, 2007), which uses the
equivalence of GF and Multiple CFG. An interest-
ing future investigation would be to compare the two
approaches on realistic grammars.
</bodyText>
<sectionHeader confidence="0.999637" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99987">
Björn Bringert. 2007. Speech recognition grammar com-
pilation in Grammatical Framework. Submitted to
SpeechGram 2007.
Philippe de Groote. 2001. Towards abstract categorial
grammars. In 39th Meeting of the Association for
Computational Linguistics, Toulouse, France.
Peter Ljunglöf. 2004. Expressivity and Complexity of
the Grammatical Framework. Ph.D. thesis, Göteborg
University and Chalmers University of Technology,
November.
Per Martin-Löf. 1984. Intuitionistic Type Theory. Bib-
liopolis, Napoli.
Reinhard Muskens. 2003. Language, lambdas, and logic.
In Geert-Jan Kruijff and Richard Oehrle, editors, Reo-
surce Sensitivity in Binding and Anaphora, pages 23–
54. Kluwer.
Nuance Communications, Inc., 2003. Nuance Speech
Recognition System 8.5: Grammar Developer’s
Guide, December.
Carl Pollard. 1984. Generalised Phrase Structure Gram-
mars, Head Grammars and Natural Language. Ph.D.
thesis, Stanford University.
Carl Pollard. 2004. Higher-order categorial grammar. In
Michel Moortgat, editor, International Conference on
Categorial Grammars, Montpellier, France.
Aarne Ranta, Ali El-Dada, and Janna Khegai,
2006. The GF Resource Grammar Library.
Can be downloaded from the GF homepage
http://www.cs.chalmers.se/~aarne/GF
Aarne Ranta. 2004. Grammatical Framework, a type-
theoretical grammar formalism. Journal of Functional
Programming, 14(2):145–189.
Manny Rayner, Dave Carter, Pierrette Bouillon, Vassilis
Digalakis, and Mats Wirén. 2000. The Spoken Lan-
guage Translator. Cambridge University Press.
Manny Rayner, Beth Ann Hockey, and Pierrette Bouil-
lon. 2006. Putting Linguistics into Speech Recogni-
tion: The Regulus Grammar Compiler. CSLI Publica-
tions.
Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free gram-
mars. Theoretical Computer Science, 88:191–229.
</reference>
<page confidence="0.998698">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000076">
<title confidence="0.999702">Converting Grammatical Framework to Regulus</title>
<author confidence="0.999012">Peter Ljunglöf</author>
<affiliation confidence="0.9999535">Department of Linguistics Göteborg University</affiliation>
<address confidence="0.946671">Gothenburg, Sweden</address>
<email confidence="0.985016">peb@ling.gu.se</email>
<abstract confidence="0.996368599290781">We present an algorithm for converting Grammatical Framework grammars (Ranta, 2004) into the Regulus unification-based framework (Rayner et al., 2006). The main purpose is to take advantage of the Regulusto-Nuance compiler for generating optimized speech recognition grammars. But there is also a theoretical interest in knowing how similar the two grammar formalisms are. Since Grammatical Framework is more expressive than Regulus, the resulting Regulus grammars can be overgenerating. We therefore describe a subclass of Grammatical Framework for which the algorithm results in an equivalent Regulus grammar. 1 Background In this section we describe the grammar formalism Grammatical Framework (GF), and discuss its expressive power and the present options for creating speech recognition grammars (SRGs). The main problem is that the size of the grammar can explode when inflectional parameters are expanded. In this paper we try to solve this problem by converting to a formalism for which there is an optimized SRG compiler. This formalism is Regulus, which is described together with its SRG compiler. The formal details are left out of the descriptions in this section and can instead be found in section 2. In section 3 the conversion algorithm is presented in detail, and in section 4 there is a short discussion. 1.1 Grammatical Framework Grammatical Framework (Ranta, 2004) is a grammar formalism based on type theory. The main feature is the separation of abstract and concrete syntax, which makes it very suitable for writing multilingual grammars. A rich module system also facilitates grammar writing as an engineering task, by reusing common grammars. 1.1.1 Separating abstract and concrete syntax The main idea of GF is the separation of abstract and concrete syntax, a distinction which is shared with several other grammar formalisms such as Abstract Categorial Grammars (de Groote, 2001), Lambda Grammar (Muskens, 2003) and Higher Order Grammar (Pollard, 2004). The abstract part of a grammar defines a set of abstract syntactic structures, called abstract terms or trees; and the concrete part defines a relation between abstract structures and concrete structures. has a to grammar writing, where the relation between abstract and concrete is viewed as a mapping from abstract to concrete structures, called linearization terms. In some cases the mapping can be partial or even manyvalued. Although not exploited in many well-known grammar formalisms, a clear separation between abstract and concrete syntax gives some advantages. language descriptions: describing the abstract syntax, the grammar writer can choose not to care about language specific details, such as inflection and word order. grammars: is possible to define different concrete syntaxes for one particular 9 of SPEECHGRAM pages 9–16, Czech Republic, June 2007. Association for Computational Linguistics abstract syntax. Multilingual grammars can be used as a model for interlingua translation, but also to simplify localization of language technology applications. grammars: abstract syntax of one grammar can be used as a concrete syntax of another grammar. This makes it possible to implement grammar resources to be used in several different application domains. These points are currently exploited in the GF Resource Grammar Library (Ranta et al., 2006), which is a multilingual GF grammar with a common abstract syntax for 13 languages. The grammatical coverage is similar to the Core Language Engine (Rayner et al., 2000). The main purpose of the Grammar Library is as a resource for writing domain-specific grammars. 1.1.2 Abstract syntax The abstract theory of GF is a version of Martin- Löf’s (1984) dependent type theory. A grammar consists of declarations of categories and functions. Categories can depend on other categories. Function declarations can bind variables to be used in dependent types, and also take functions as arguments, thus giving rise to higher-order functions. Since the abstract syntax also permits function definitions, the expressive power of GF abstract syntax is Turingcomplete. In this article we restrict ourselves to an important subclass of GF, where there are no dependent types and no higher-order functions. This subclass called and is an instance of Generalized Context-Free Grammar (Pollard, 1984). The abstract syntax of a context-free GF grammar consists of a set of function typings of the form · · · → typing says that a function taking arguwith categories returning a cat- This is equivalent to a context-free grammar without terminal symbols. Note however, that function be written an ordinary context-free rule. I.e., the left-hand side of a context-free rule corresponds to the result of the function, which is written to the right. The restriction to a context-free backbone is not severe, since the concrete syntax is so expressive. 1.1.3 Concrete syntax Linearizations are written as terms in a typed functional programming language, which is limited to ensure decidability in generation and in parsing. The language has records and finite-domain functions (called tables); and the basic types are terminal lists (called strings) and finite data types (called parameter types). There are also local definitions, lambda-abstractions and global function definitions. The parameters are declared by the grammar; they can be hierarchical but not recursive, to ensure finiteness. The language of linearization terms is quite complex, but it can be compiled to a normalized form which is called canonical GF. In this paper we assume that all linearizations are in canonical form. A canonical concrete GF grammar contains declarations of all parameter types, and linearization definitions for all abstract functions. 1.1.4 Expressive power The expressive power of context-free GF solely depends on the possibility of discontinuous constituents. This means that one grammatical phrase can be split into several parts occurring in different places in the sentence. Discontinuous constituents permit a simple and compositional way of treating, e.g., German compound verbs, where the particle commonly is moved to the end of the sentence. Ljunglöf (2004) showed that context-free GF is equivalent to Multiple Context-Free Grammar (Seki et al., 1991), which is known to be parseable in time polynomial in the length of the input string. From a converted Multiple CFG, each constituent can be extracted as a context-free rule, which will result in a possibly overgenerating context-free grammar. This context-free grammar can be output from the GF system in several different speech recognition formats, as described by Bringert (2007). There is a severe problem with the conversion from GF to Multiple CFG however – the size of the resulting grammar tend to explode when the inflectional parameters are expanded. Large grammars such as many of the languages in the Resource 10 Grammar Library simply cannot be converted. One solution would be to optimize the conversion algorithm, e.g., by interleaving parameter expansion and grammar compaction. Another solution would be to translate into a grammar formalism which does not have this size explosion. This is where Regulus comes in – if we could translate GF grammars into Regulus grammars, we could make use of the research already put into the Regulus-to-Nuance compiler, and would not have to reinvent the wheel. 1.2 Regulus Regulus is an open-source toolkit for writing grammar-based speech recognition systems (Rayner al., central part is the Regulus grammar formalism and a compiler for creating speech recognition grammars. The toolkit has been enhanced with templates for developing e.g., speech translation systems and dialogue systems. There is also an English resource grammar, which can be used for grammar specialization using explanationbased learning (Rayner et al., 2006, chapters 9–10). 1.2.1 Unification of finite parameters The Regulus formalism is a context-free grammar, enhanced with unification of finite parameters. This means that the formalism is equivalent to a context-free grammar. context-free category (e.g., has a of features (e.g., a finite domain of values (e.g., The feature values are specified using a record paired with the grammatical category. Logical variables can be used for unifying features of different constituents in the rule. It is possible to define macros for simplifying common tasks, e.g., when implementing a lexicon. Compared to Grammatical Framework, the Regulus formalism is quite restricted. There is no clear distinction between abstract and concrete syntax, and there is no advanced module system in which to define grammatical resources. Also, Regulus lacks discontinuous constituents, which reduces the expressive power considerably. information about Regulus, including download incan be found on the project homepage: //www.issco.unige.ch/projects/regulus/ 1.2.2 Compiling Regulus to Nuance GSL Nuance Communications (2003) has developed a context-free grammar format for speech recognition, which has become one of the de facto standards for speech recognition. The grammar format is called Nuance Grammar Specification Language (GSL). The format has some special features, such as semantic tagging and probabilistic grammar rules. There are also restrictions in the format, most notably that the grammars must not be left-recursive. The Regulus formalism is designed to be able to make use of the special features in Nuance GSL, and the compiler can always create correct GSL grammars without left-recursion. 2 Formal definitions In this section we give formal definitions of rules and linearization terms in GF, grammar rules and terms in Regulus, and the intermediate structures we will be using. 2.1 GF grammar rules Since we are only interested in GF grammars with a context-free backbone, the abstract syntax is a context-free grammar where each rule has a unique name. The rules are written as typings in a functional language: � � � � As mentioned earlier, this declaration corresponds to context-free rule Linearizations are written as function definitions, where variables that in the linearization term An alternative way of writing this is to name the variables consistently each rule, and then the linearization term itself is sufficient as a linearization definition. We adopt this idea and use the uniform variable names each linearization. With this approach we also distinguish the argument variables from the parameter variables which get bound in tables. 2.2 GF linearization terms and substructures parameter type just a set of parameter values ... , Note that all parameter types must be disjoint, i.e., each parameter should belong to 11 exactly one parameter type. Linearizations are defined by association linearization terms to the abstract functions. Note that the definition of terms is slightly more general than the definition in GF, since we want to include reduced terms in the definition. The relation between the introduced classes are as follows: defined inductively as follows: t ::= p argument string concatenation pattern | | |  |t.r record projection |  |table selection | &gt; a positive integer, a pattern, a record label. The class record labels is just a finite class of atomic values. The arreference the argument of the linearization function. pairs variables, sets of parameters, The pamust belong to the same patype meaning of the is that bound to one of the parameters in If P can skip that part and simply write Conversely, if not used elsewhere in the term, can skip it and simply write Note that a pattern is a term in itself, but in GF will always occur as a single variable as a parameter after the conversion algorithm has transformed tables into records, patterns will become first class terms. terms subterms of ordinary terms. A reduced term is a term which does not contain a table or a selection, and where projections occur in the form where a sequence of labels: parameter terms subterms of reduced terms, which correspond to parameters: string terms subterms of reduced terms, which correspond to strings: Note that this is equivalent to a sequence of argument projections and string constants, which in turn is equivalent to a right-hand side in a context-free rule. 2.3 Regulus grammar rules and terms A Regulus grammar is a unification-based phrasestructure grammar. It consists of grammar rules, which in turn is built up using Regulus terms. rules regular context-free grammar rules, where each category is augmented with a Regulus term: each a context-free category, each Regulus term, and each a (possibly empty) sequence of terminal tokens. terms flat records where all values patterns In this sense, Regulus terms are just subterms of reduced terms. However, a Regulus term can include of the two special labels corresponding to return values and global slot-filling in Nuance GSL, respectively. They can contain complex structures, such as deeply nested lists and records. Using these it is possible to define the syntactical structure of a phrase. is a slight abuse of syntax – in Regulus the record row written as two separate rows 12 3 Converting GF to Regulus In this section we describe an algorithm for converting any context-free GF rule into a set of Regulus rules. This conversion is done in three steps: 1. Tables and table selections are removed from the GF term, resulting in several reduced terms and sets of constraints. 2. The results are massaged into Regulus terms for the left-hand side and the right-hand side. 3. Finally, GF abstract syntax is used to create the final Regulus rules. In the final step, the abstract syntax is added as a semantic value in the Regulus rules. This makes it possible to get back the GF abstract syntax tree, when using Regulus (or Nuance) for parsing the grammar. a running example we will use a standard English GF rule for combining transitive verbs with noun phrases: : TV = The idea is that a verb phrase has a parametrical which it inherits from the verb. When the verb phrase is used in a sentence, the number will depend on the inherent number of the subject. 3.1 Converting tables to unification-based records The main difference between GF and Regulus is that the former has tables and the latter has unification. The problem when converting from GF to Regulus is therefore how to get rid of the tables and selections. We present an algorithm for removing tables and selections, by replacing them with logical variables and equality constraints. basic idea is to translate each row a table into a record The in are bound by logvariables. Thus the original table gives rise to records (if the number of table rows), in the end becomes Regulus terms. table selection has to be translated into value the table, and a constraint is added the selection term the pattern the table should be unified. Step 1: Removing tables and selections We define a nondeterministic reduction operation The meaning of that the term converted to the reduced term the set of constraints Each in of the form where reduced parameter terms. Each row a table is reduced to a containing the pattern the reduced Note that this rule is nondeterministic – the tais reduced to terms, where the number of table rows. A table selection reduced to the value the added constraint that the pattern the selection term unify: that since a parameter, it will be to a parameter term, A record projection reduced to a projec- • All other term constructors are reduced compositionally, i.e., by reducing the internal terms recursively. function the projection of the simple term Since there are only two reduced term constructors that can correspond to a record, there are only two cases in the definition: = , = 13 original linearization term of the example contains one table and one selection. The reduced to the added And since there is only one row in the table, the example term is reduced to one term the constraints 3.2 Building Regulus terms The reduced term and the constraints from the first step do not constitute a Regulus grammar rule, but they have to be massaged into the correct form. This is done in four small steps below. Step 2a: Flattening the reduced term the conversion we have a reterm a set of constraints Now we convert a set of conand add to the constraint store For each subterm in a parameter, The path the sequence labels for getting from i.e., = also create a set of “proto rules” For each subterm in a string, to The path the same as above. is one subterm in a so we add n There is subterm in denotes a string, so we let Step 2b: Simplifying the constraints we have two constraint stores, of which the latter can be partially evaluated into a simpler form. For each constraint of the form we replace it with two new constraints where a fresh For each constraint of the form there are two possibilities: that just a shorthand for where the set of all parameters. If disjoint, then the conis contradictive and we remove the list of results. • Otherwise, we replace each occurrence of in by where a variable and do not have to do anything to since all constraints already are in simplified form. Step 2c: Building Regulus terms contains constraints of the form We transform these into the Regulus records ... , in the following way: For each constraint add the record Note that the labels in the Regulus terms are sequences of GF labels. constraints in give rise to the Regulus terms: 3.3 Building a Regulus grammar To be able to create Regulus grammar rules from the terms we need to look at the abstract syntax in the GF grammar. In this section we will assume that the typing of the linearization in is · · · —* Regulus (and Nuance GSL) permits the use of arnested lists in the special We will use the nested list for representing a GF abstract syntax tree which then will be returned directly by Nuance after the parsing has succeeded. This is important since the arguments to the function can be permuted in the linearization, which then means that the arguments in the Regulus rule are permuted as well. 14 Step 3a: Adding GF abstract syntax to the Regulus terms The abstract syntax tree of the original rule is put a in the left-hand side term Add the row For each add that the be fresh variables, not used elsewhere in the terms. adding semantics, the example terms become: Step 3b: Building Regulus grammar rules we can transform the proto rules in Regulus grammar rules: For each proto rule · · in create a new Regulus rule: where the terms in the right-hand side are calculated as follows: = = p the single proto rule in create the Regulus rule: : the terms described above. 4 Discussion We have presented an algorithm for converting GF grammars with a context-free backbone into unification-based Regulus grammars. The algorithm is simple and straightforward, which is an indication that the formalisms are more similar than one might have guessed beforehand. 4.1 Equivalence of the grammars The presented algorithm does not necessarily yield an equivalent grammar. This is a consequence of the fact that context-free GF is equivalent to Multiple CFG, and that Multiple CFG is much more expressive than context-free grammars. However, if the original grammar does not make use of multiple constituents, the conversion is equivalent. Note that the grammar might very well contain multiple constituents, but if there is no righthand side that refers to both constituents simultaneously the equivalence is still preserved. 4.2 Complexity issues As mentioned earlier, each GF function might give rise to several Regulus rules, so in one sense the resulting grammar is bigger than the original. However, the actual size in terms of memory usage does not differ (except maybe linear because of differences in syntax). 4.2.1 The number of rules The number of Regulus rules for one single GF linearization term is equal to: � φ the number of discontinuous conand over all tables in the linearization term. This is easy to see, since it is only tables that are reduced nondeterministically, each proto rule in rise to one Regulus rule. 4.2.2 The size of the grammar The total size of the final grammar can be larger than the original GF grammar. This is because the Regulus grammar will contain lots of copies of the same structures, e.g., everything outside of a table has to be duplicated in for each table row. The theoretical limit is the same as above – the number of constituents, times the the total product of all table rows – but in practice the grammar explosion is not that extreme. Since the increase in size is due to copying, the Regulus grammar can be compacted by the use of macros (Rayner et al., 2006, section 4.5). This could 15 probably be implemented in the algorithm directly, but we have not yet investigated this idea. 4.2.3 Time complexity The time complexity of the algorithm is approximately equivalent to the size of the resulting Regulus grammar. The first step (in section 3.1), can be implemented as a single pass through the term and is therefore linear in the size of the resulting terms. The post-processing steps (in section 3.2) are also linear in the size of the terms and constraints. Finally, the steps for building grammar rules does not depend on the term size at all. Thus, the time complexity is linear in the size of the final Regulus grammar. 4.3 Using Regulus as a compiler for speech recognition grammars By presenting an algorithm for converting GF grammars into Regulus, it is possible to further use the Regulus-to-Nuance compiler for getting an optimized speech recognition grammar. The advantage to compiling Nuance grammars directly from GF is clear: the Regulus project has developed and implemented several optimizations (Rayner et al., 2006, chapter 8), which would have to be reimplemented in a direct GF-to-Nuance compiler. As previously mentioned in section 1.1.4, there is a speech recognition grammar compiler already implemented in GF (Bringert, 2007), which uses the equivalence of GF and Multiple CFG. An interesting future investigation would be to compare the two approaches on realistic grammars.</abstract>
<note confidence="0.631404625">References Björn Bringert. 2007. Speech recognition grammar compilation in Grammatical Framework. Submitted to SpeechGram 2007. Philippe de Groote. 2001. Towards abstract categorial In Meeting of the Association for Toulouse, France. Ljunglöf. 2004. and Complexity of</note>
<affiliation confidence="0.74924">Grammatical Ph.D. thesis, Göteborg University and Chalmers University of Technology,</affiliation>
<address confidence="0.858937">November. Martin-Löf. 1984. Type Bibliopolis, Napoli.</address>
<note confidence="0.7956375625">Reinhard Muskens. 2003. Language, lambdas, and logic. Geert-Jan Kruijff and Richard Oehrle, editors, Reo- Sensitivity in Binding and pages 23– 54. Kluwer. Communications, Inc., 2003. Speech Recognition System 8.5: Grammar Developer’s December. Pollard. 1984. Phrase Structure Gram- Head Grammars and Natural Ph.D. thesis, Stanford University. Carl Pollard. 2004. Higher-order categorial grammar. In Moortgat, editor, Conference on Montpellier, France. Aarne Ranta, Ali El-Dada, and Janna Khegai, GF Resource Grammar Can be downloaded from the GF homepage</note>
<web confidence="0.987924">http://www.cs.chalmers.se/~aarne/GF</web>
<note confidence="0.915446">Aarne Ranta. 2004. Grammatical Framework, a typegrammar formalism. of Functional 14(2):145–189.</note>
<author confidence="0.6529775">Spoken Lan-</author>
<affiliation confidence="0.988767">Cambridge University Press.</affiliation>
<note confidence="0.71691025">Manny Rayner, Beth Ann Hockey, and Pierrette Bouil- 2006. Linguistics into Speech Recogni- The Regulus Grammar CSLI Publications. Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free gram- Computer 88:191–229. 16</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Björn Bringert</author>
</authors>
<title>Speech recognition grammar compilation in Grammatical Framework.</title>
<date>2007</date>
<note>Submitted to SpeechGram</note>
<contexts>
<context position="7026" citStr="Bringert (2007)" startWordPosition="1114" endWordPosition="1115">ositional way of treating, e.g., German compound verbs, where the particle commonly is moved to the end of the sentence. Ljunglöf (2004) showed that context-free GF is equivalent to Multiple Context-Free Grammar (Seki et al., 1991), which is known to be parseable in time polynomial in the length of the input string. From a converted Multiple CFG, each constituent can be extracted as a context-free rule, which will result in a possibly overgenerating context-free grammar. This context-free grammar can be output from the GF system in several different speech recognition formats, as described by Bringert (2007). There is a severe problem with the conversion from GF to Multiple CFG however – the size of the resulting grammar tend to explode when the inflectional parameters are expanded. Large grammars such as many of the languages in the Resource 10 Grammar Library simply cannot be converted. One solution would be to optimize the conversion algorithm, e.g., by interleaving parameter expansion and grammar compaction. Another solution would be to translate into a grammar formalism which does not have this size explosion. This is where Regulus comes in – if we could translate GF grammars into Regulus gr</context>
</contexts>
<marker>Bringert, 2007</marker>
<rawString>Björn Bringert. 2007. Speech recognition grammar compilation in Grammatical Framework. Submitted to SpeechGram 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe de Groote</author>
</authors>
<title>Towards abstract categorial grammars.</title>
<date>2001</date>
<booktitle>In 39th Meeting of the Association for Computational Linguistics,</booktitle>
<location>Toulouse, France.</location>
<marker>de Groote, 2001</marker>
<rawString>Philippe de Groote. 2001. Towards abstract categorial grammars. In 39th Meeting of the Association for Computational Linguistics, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Ljunglöf</author>
</authors>
<title>Expressivity and Complexity of the Grammatical Framework.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Göteborg University and Chalmers University of Technology,</institution>
<contexts>
<context position="6547" citStr="Ljunglöf (2004)" startWordPosition="1038" endWordPosition="1039">hat all linearizations are in canonical form. A canonical concrete GF grammar contains declarations of all parameter types, and linearization definitions for all abstract functions. 1.1.4 Expressive power The expressive power of context-free GF solely depends on the possibility of discontinuous constituents. This means that one grammatical phrase can be split into several parts occurring in different places in the sentence. Discontinuous constituents permit a simple and compositional way of treating, e.g., German compound verbs, where the particle commonly is moved to the end of the sentence. Ljunglöf (2004) showed that context-free GF is equivalent to Multiple Context-Free Grammar (Seki et al., 1991), which is known to be parseable in time polynomial in the length of the input string. From a converted Multiple CFG, each constituent can be extracted as a context-free rule, which will result in a possibly overgenerating context-free grammar. This context-free grammar can be output from the GF system in several different speech recognition formats, as described by Bringert (2007). There is a severe problem with the conversion from GF to Multiple CFG however – the size of the resulting grammar tend </context>
</contexts>
<marker>Ljunglöf, 2004</marker>
<rawString>Peter Ljunglöf. 2004. Expressivity and Complexity of the Grammatical Framework. Ph.D. thesis, Göteborg University and Chalmers University of Technology, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per Martin-Löf</author>
</authors>
<title>Intuitionistic Type Theory. Bibliopolis,</title>
<date>1984</date>
<location>Napoli.</location>
<marker>Martin-Löf, 1984</marker>
<rawString>Per Martin-Löf. 1984. Intuitionistic Type Theory. Bibliopolis, Napoli.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Muskens</author>
</authors>
<title>Language, lambdas, and logic.</title>
<date>2003</date>
<booktitle>In Geert-Jan Kruijff and Richard Oehrle, editors, Reosurce Sensitivity in Binding and Anaphora,</booktitle>
<pages>23--54</pages>
<publisher>Kluwer.</publisher>
<contexts>
<context position="2088" citStr="Muskens, 2003" startWordPosition="325" endWordPosition="326">1 Grammatical Framework Grammatical Framework (Ranta, 2004) is a grammar formalism based on type theory. The main feature is the separation of abstract and concrete syntax, which makes it very suitable for writing multilingual grammars. A rich module system also facilitates grammar writing as an engineering task, by reusing common grammars. 1.1.1 Separating abstract and concrete syntax The main idea of GF is the separation of abstract and concrete syntax, a distinction which is shared with several other grammar formalisms such as Abstract Categorial Grammars (de Groote, 2001), Lambda Grammar (Muskens, 2003) and Higher Order Grammar (Pollard, 2004). The abstract part of a grammar defines a set of abstract syntactic structures, called abstract terms or trees; and the concrete part defines a relation between abstract structures and concrete structures. GF has a linearization perspective to grammar writing, where the relation between abstract and concrete is viewed as a mapping from abstract to concrete structures, called linearization terms. In some cases the mapping can be partial or even manyvalued. Although not exploited in many well-known grammar formalisms, a clear separation between abstract </context>
</contexts>
<marker>Muskens, 2003</marker>
<rawString>Reinhard Muskens. 2003. Language, lambdas, and logic. In Geert-Jan Kruijff and Richard Oehrle, editors, Reosurce Sensitivity in Binding and Anaphora, pages 23– 54. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance Communications</author>
<author>Inc</author>
</authors>
<title>Nuance Speech Recognition System 8.5: Grammar Developer’s Guide,</title>
<date>2003</date>
<marker>Communications, Inc, 2003</marker>
<rawString>Nuance Communications, Inc., 2003. Nuance Speech Recognition System 8.5: Grammar Developer’s Guide, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
</authors>
<title>Generalised Phrase Structure Grammars, Head Grammars and Natural Language.</title>
<date>1984</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="4609" citStr="Pollard, 1984" startWordPosition="719" endWordPosition="720">s of declarations of categories and functions. Categories can depend on other categories. Function declarations can bind variables to be used in dependent types, and also take functions as arguments, thus giving rise to higher-order functions. Since the abstract syntax also permits function definitions, the expressive power of GF abstract syntax is Turingcomplete. In this article we restrict ourselves to an important subclass of GF, where there are no dependent types and no higher-order functions. This subclass is called context-free GF, and is an instance of Generalized Context-Free Grammar (Pollard, 1984). The abstract syntax of a context-free GF grammar consists of a set of function typings of the form fA1 → · · · → A� → A This typing says that f is a function taking δ arguments with categories Al ... Aa and returning a category A. This is equivalent to a context-free grammar without terminal symbols. Note however, that the function f would be written A → Al ... Aa as an ordinary context-free rule. I.e., the left-hand side of a context-free rule corresponds to the result of the function, which is written to the right. The restriction to a context-free backbone is not severe, since the concret</context>
</contexts>
<marker>Pollard, 1984</marker>
<rawString>Carl Pollard. 1984. Generalised Phrase Structure Grammars, Head Grammars and Natural Language. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
</authors>
<title>Higher-order categorial grammar.</title>
<date>2004</date>
<booktitle>International Conference on Categorial Grammars,</booktitle>
<editor>In Michel Moortgat, editor,</editor>
<location>Montpellier, France.</location>
<contexts>
<context position="2129" citStr="Pollard, 2004" startWordPosition="332" endWordPosition="333">work (Ranta, 2004) is a grammar formalism based on type theory. The main feature is the separation of abstract and concrete syntax, which makes it very suitable for writing multilingual grammars. A rich module system also facilitates grammar writing as an engineering task, by reusing common grammars. 1.1.1 Separating abstract and concrete syntax The main idea of GF is the separation of abstract and concrete syntax, a distinction which is shared with several other grammar formalisms such as Abstract Categorial Grammars (de Groote, 2001), Lambda Grammar (Muskens, 2003) and Higher Order Grammar (Pollard, 2004). The abstract part of a grammar defines a set of abstract syntactic structures, called abstract terms or trees; and the concrete part defines a relation between abstract structures and concrete structures. GF has a linearization perspective to grammar writing, where the relation between abstract and concrete is viewed as a mapping from abstract to concrete structures, called linearization terms. In some cases the mapping can be partial or even manyvalued. Although not exploited in many well-known grammar formalisms, a clear separation between abstract and concrete syntax gives some advantages</context>
</contexts>
<marker>Pollard, 2004</marker>
<rawString>Carl Pollard. 2004. Higher-order categorial grammar. In Michel Moortgat, editor, International Conference on Categorial Grammars, Montpellier, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
<author>Ali El-Dada</author>
<author>Janna Khegai</author>
</authors>
<date>2006</date>
<booktitle>The GF Resource Grammar Library.</booktitle>
<contexts>
<context position="3605" citStr="Ranta et al., 2006" startWordPosition="555" endWordPosition="558">s for one particular 9 Proceedings of SPEECHGRAM 2007, pages 9–16, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics abstract syntax. Multilingual grammars can be used as a model for interlingua translation, but also to simplify localization of language technology applications. Resource grammars: The abstract syntax of one grammar can be used as a concrete syntax of another grammar. This makes it possible to implement grammar resources to be used in several different application domains. These points are currently exploited in the GF Resource Grammar Library (Ranta et al., 2006), which is a multilingual GF grammar with a common abstract syntax for 13 languages. The grammatical coverage is similar to the Core Language Engine (Rayner et al., 2000). The main purpose of the Grammar Library is as a resource for writing domain-specific grammars. 1.1.2 Abstract syntax The abstract theory of GF is a version of MartinLöf’s (1984) dependent type theory. A grammar consists of declarations of categories and functions. Categories can depend on other categories. Function declarations can bind variables to be used in dependent types, and also take functions as arguments, thus givin</context>
</contexts>
<marker>Ranta, El-Dada, Khegai, 2006</marker>
<rawString>Aarne Ranta, Ali El-Dada, and Janna Khegai, 2006. The GF Resource Grammar Library.</rawString>
</citation>
<citation valid="false">
<note>Can be downloaded from the GF homepage http://www.cs.chalmers.se/~aarne/GF</note>
<marker></marker>
<rawString>Can be downloaded from the GF homepage http://www.cs.chalmers.se/~aarne/GF</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Grammatical Framework, a typetheoretical grammar formalism.</title>
<date>2004</date>
<journal>Journal of Functional Programming,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="1533" citStr="Ranta, 2004" startWordPosition="234" endWordPosition="235">speech recognition grammars (SRGs). The main problem is that the size of the grammar can explode when inflectional parameters are expanded. In this paper we try to solve this problem by converting to a formalism for which there is an optimized SRG compiler. This formalism is Regulus, which is described together with its SRG compiler. The formal details are left out of the descriptions in this section and can instead be found in section 2. In section 3 the conversion algorithm is presented in detail, and in section 4 there is a short discussion. 1.1 Grammatical Framework Grammatical Framework (Ranta, 2004) is a grammar formalism based on type theory. The main feature is the separation of abstract and concrete syntax, which makes it very suitable for writing multilingual grammars. A rich module system also facilitates grammar writing as an engineering task, by reusing common grammars. 1.1.1 Separating abstract and concrete syntax The main idea of GF is the separation of abstract and concrete syntax, a distinction which is shared with several other grammar formalisms such as Abstract Categorial Grammars (de Groote, 2001), Lambda Grammar (Muskens, 2003) and Higher Order Grammar (Pollard, 2004). Th</context>
</contexts>
<marker>Ranta, 2004</marker>
<rawString>Aarne Ranta. 2004. Grammatical Framework, a typetheoretical grammar formalism. Journal of Functional Programming, 14(2):145–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
<author>Dave Carter</author>
<author>Pierrette Bouillon</author>
<author>Vassilis Digalakis</author>
<author>Mats Wirén</author>
</authors>
<title>The Spoken Language Translator.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3775" citStr="Rayner et al., 2000" startWordPosition="586" endWordPosition="589">ultilingual grammars can be used as a model for interlingua translation, but also to simplify localization of language technology applications. Resource grammars: The abstract syntax of one grammar can be used as a concrete syntax of another grammar. This makes it possible to implement grammar resources to be used in several different application domains. These points are currently exploited in the GF Resource Grammar Library (Ranta et al., 2006), which is a multilingual GF grammar with a common abstract syntax for 13 languages. The grammatical coverage is similar to the Core Language Engine (Rayner et al., 2000). The main purpose of the Grammar Library is as a resource for writing domain-specific grammars. 1.1.2 Abstract syntax The abstract theory of GF is a version of MartinLöf’s (1984) dependent type theory. A grammar consists of declarations of categories and functions. Categories can depend on other categories. Function declarations can bind variables to be used in dependent types, and also take functions as arguments, thus giving rise to higher-order functions. Since the abstract syntax also permits function definitions, the expressive power of GF abstract syntax is Turingcomplete. In this artic</context>
</contexts>
<marker>Rayner, Carter, Bouillon, Digalakis, Wirén, 2000</marker>
<rawString>Manny Rayner, Dave Carter, Pierrette Bouillon, Vassilis Digalakis, and Mats Wirén. 2000. The Spoken Language Translator. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
<author>Beth Ann Hockey</author>
<author>Pierrette Bouillon</author>
</authors>
<title>Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler.</title>
<date>2006</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="7879" citStr="Rayner et al., 2006" startWordPosition="1253" endWordPosition="1256">source 10 Grammar Library simply cannot be converted. One solution would be to optimize the conversion algorithm, e.g., by interleaving parameter expansion and grammar compaction. Another solution would be to translate into a grammar formalism which does not have this size explosion. This is where Regulus comes in – if we could translate GF grammars into Regulus grammars, we could make use of the research already put into the Regulus-to-Nuance compiler, and would not have to reinvent the wheel. 1.2 Regulus Regulus is an open-source toolkit for writing grammar-based speech recognition systems (Rayner et al., 2006).1 The central part is the Regulus grammar formalism and a compiler for creating speech recognition grammars. The toolkit has been enhanced with templates for developing e.g., speech translation systems and dialogue systems. There is also an English resource grammar, which can be used for grammar specialization using explanationbased learning (Rayner et al., 2006, chapters 9–10). 1.2.1 Unification of finite parameters The Regulus formalism is a context-free grammar, enhanced with unification of finite parameters. This means that the formalism is equivalent to a context-free grammar. Each conte</context>
<context position="23952" citStr="Rayner et al., 2006" startWordPosition="4235" endWordPosition="4238">in Σ gives rise to one Regulus rule. 4.2.2 The size of the grammar The total size of the final grammar can be larger than the original GF grammar. This is because the Regulus grammar will contain lots of copies of the same structures, e.g., everything outside of a table has to be duplicated in for each table row. The theoretical limit is the same as above – the number of constituents, times the the total product of all table rows – but in practice the grammar explosion is not that extreme. Since the increase in size is due to copying, the Regulus grammar can be compacted by the use of macros (Rayner et al., 2006, section 4.5). This could |0| 15 probably be implemented in the algorithm directly, but we have not yet investigated this idea. 4.2.3 Time complexity The time complexity of the algorithm is approximately equivalent to the size of the resulting Regulus grammar. The first step (in section 3.1), can be implemented as a single pass through the term and is therefore linear in the size of the resulting terms. The post-processing steps (in section 3.2) are also linear in the size of the terms and constraints. Finally, the steps for building grammar rules does not depend on the term size at all. Thus</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2006</marker>
<rawString>Manny Rayner, Beth Ann Hockey, and Pierrette Bouillon. 2006. Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Seki</author>
<author>Takashi Matsumara</author>
<author>Mamoru Fujii</author>
<author>Tadao Kasami</author>
</authors>
<title>On multiple context-free grammars.</title>
<date>1991</date>
<journal>Theoretical Computer Science,</journal>
<pages>88--191</pages>
<contexts>
<context position="6642" citStr="Seki et al., 1991" startWordPosition="1050" endWordPosition="1053">rations of all parameter types, and linearization definitions for all abstract functions. 1.1.4 Expressive power The expressive power of context-free GF solely depends on the possibility of discontinuous constituents. This means that one grammatical phrase can be split into several parts occurring in different places in the sentence. Discontinuous constituents permit a simple and compositional way of treating, e.g., German compound verbs, where the particle commonly is moved to the end of the sentence. Ljunglöf (2004) showed that context-free GF is equivalent to Multiple Context-Free Grammar (Seki et al., 1991), which is known to be parseable in time polynomial in the length of the input string. From a converted Multiple CFG, each constituent can be extracted as a context-free rule, which will result in a possibly overgenerating context-free grammar. This context-free grammar can be output from the GF system in several different speech recognition formats, as described by Bringert (2007). There is a severe problem with the conversion from GF to Multiple CFG however – the size of the resulting grammar tend to explode when the inflectional parameters are expanded. Large grammars such as many of the la</context>
</contexts>
<marker>Seki, Matsumara, Fujii, Kasami, 1991</marker>
<rawString>Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science, 88:191–229.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>