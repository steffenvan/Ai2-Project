<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.9615702">
SOLVING ANALOGIES ON WORDS: AN ALGORITHM
Yves Lepage
ATR Interpreting Telecommunications Research Labs,
Hikaridai 2-2, Seika-ty6, SOraku-gun, KyOto 619-0288, Japan
lepage@itl . atr. . co. jp
</note>
<sectionHeader confidence="0.972831" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999947818181818">
To introduce the algorithm presented in this pa-
per, we take a path that is inverse to the his-
torical development of the idea of analogy (see
(Hoffman 95)). This is necessary, because a
certain incomprehension is faced when speak-
ing about linguistic analogy, i.e., it is generally
given a broader and more psychological defini-
tion. Also, with our proposal being computa-
tional, it is impossible to ignore works about
analogy in computer science, which has come
to mean artificial intelligence.
</bodyText>
<sectionHeader confidence="0.922614" genericHeader="method">
1 A Survey of Works on Analogy
</sectionHeader>
<bodyText confidence="0.99977">
This paper is not intended to be an exhaustive
study. For a more comprehensive study on the
subject, see (Hoffman 95).
</bodyText>
<subsectionHeader confidence="0.995652">
1.1 Metaphors, or Implicit Analogies
</subsectionHeader>
<bodyText confidence="0.999947285714286">
Beginning with works in psychology and arti-
ficial intelligence, (Gentner 83) is a milestone
study of a possible modeling of analogies such
as, &amp;quot;an atom is like the solar system&amp;quot; adequate
for artificial intelligence. In these analogies, two
domains are mapped, one onto the other, thus
modeling of the domain becomes necessary.
</bodyText>
<subsectionHeader confidence="0.612968">
sun nucleus
</subsectionHeader>
<bodyText confidence="0.9975628">
planet 4 electron
In addition, properties (expressed by clauses,
formulae, etc.) are transferred from one domain
onto the other, and their number somehow de-
termines the quality of the analogy.
</bodyText>
<equation confidence="0.74441025">
attracts (sun, 4 attracts (nucleus ,
planet) electron)
moremassive(sun, L moremassive(nucleus,
planet) electron)
</equation>
<bodyText confidence="0.99770425">
However, Gentner&apos;s explicit description of
sentences as &amp;quot;an A is like a B&amp;quot; as analo-
gies is subject to criticism. Others (e.g.
(Steinhart 94)) prefer to call these sentences
metaphors&apos;, the validity of which rests on sen-
tences of the kind, &amp;quot;A is to B as C is to D&amp;quot;, for
which the name analogy2 is reserved. In other
words, some metaphors are supported by analo-
gies. For instance, the metaphor, &amp;quot;an atom is
like the solar system&amp;quot;, relies on the analogy, &amp;quot;an
electron is to the nucleus, as a planet is to the
sun&amp;quot; .3
The answer of the Al community is com-
plex because they have headed directly to more
complex problems. For them, in analogies or
metaphors (Hall 89):
</bodyText>
<listItem confidence="0.90763375">
• two different domains appear
• for both domains, modeling of a knowledge-
base is necessary
• mapping of objects and transfer of proper-
ties are different operations
• the quality of analogies has to be evalu-
ated as a function of the strength (number,
truth, etc.) of properties transferred.
</listItem>
<bodyText confidence="0.998713">
We must drastically simplify all this and
enunciate a simpler problem (whose resolution
may not necessarily be simple). This can be
achieved by simplifying data types, and conse-
quently the characteristics of the problem.
</bodyText>
<footnote confidence="0.9450473">
&apos;If the fact that properties are carried over char-
acterises such sentences, then etymologically they are
metaphors: In Greek, pherein: to carry; ineta-: between,
among, with, after. &amp;quot;Metaphor&amp;quot; means to transfer, to
carry over.
2In Greek, logos, -logia: ratio, proportion, reason, dis-
course; ana-: top-down, again, anew. &amp;quot;Analogy&amp;quot; means
the same proportions, similar ratios.
&apos;This complies with Aristotle&apos;s definitions in the
Poetics.
</footnote>
<page confidence="0.984085">
728
</page>
<subsectionHeader confidence="0.867447">
1.2 Multiplicity vs Unicity of Domains
</subsectionHeader>
<bodyText confidence="0.999962666666667">
In the field of natural language processing, there
have been plenty of works on pronunciation of
English by analogy, some being very much con-
cerned with reproducing human behavior (see
(Damper &amp; Eastmond 96)). Here is an illustra-
tion of the task from (Pirelli Sz Federici 94):
</bodyText>
<equation confidence="0.617495">
vane /vejn/
Ig Lh
sane x = /sejn/
</equation>
<bodyText confidence="0.9997480625">
Similarly to AT approaches, two domains ap-
pear (graphemic and phonemic). Consequently,
the functions f, g and h are of different types
because their domains and ranges are of differ-
ent data types.
Similarly to AT again, a common feature in
such pronouncing systems is the use of data
bases of written and phonetic forms. Regard-
ing his own model, (Yvon 94) comments that:
The [...] model crucially relies upon the
existence of numerous paradigmatic rela-
tionships in lexical data bases.
Paradigmatic relationships being relation-
ships in which four words intervene, they are
in fact morphological analogies: &amp;quot;reaction is to
reactor, as faction is to factor&amp;quot;.
</bodyText>
<equation confidence="0.886618">
reactor L reaction
g g
factor L faction
</equation>
<bodyText confidence="0.999613642857143">
Contrasting sharply with Al approaches,
morphological analogies apply in only one do-
main, that of words. As a consequence,
the number of relationships between analogical
terms decreases from three (f, g and h) to two
(1 and g). Moreover, because all four terms
intervening in the analogy are from the same
domain, the domains and ranges of f and g
are identical. Finally, morphological analogies
can be regarded as simple equations indepen-
dent of any knowledge about the language in
which they are written. This standpoint elim-
inates the need for any knowledge base or dic-
tionary.
</bodyText>
<footnote confidence="0.691854666666667">
reactor L reaction
g g
factor -4 x?
</footnote>
<subsectionHeader confidence="0.979754">
1.3 Unicity vs Multiplicity of Changes
</subsectionHeader>
<bodyText confidence="0.999966257142857">
Solving morphological analogies remains diffi-
cult because several simultaneous changes may
be required to transform one word into a sec-
ond (for instance, doer undo requires the
deletion of the suffix -er and the insertion of
the prefix un-). This problem has yet to be
solved satisfactorily. For example, in (Yvon 94),
only one change at a time is allowed, and
multiple changes are captured by successive
applications of morphological analogies (cas-
cade model). However, there are cases in the
morphology of some languages where multiple
changes at the same time are mandatory, for
instance in semitic languages.
&amp;quot;One change at a time&amp;quot;, is also found in (Na-
ga.o 84) for a translation method, called trans-
lation by analogy, where the translation of an
input sentence is an adaptation of translations
of similar sentences retrieved from a data base.
The difficulty of handling multiple changes is
remedied by feeding the system with new exam-
ples differing by only one word commutation at
a time. (Sadler and Vendelmans 90) proposed a
different solution with an algebra on.trees: dif-
ferences on strings are reflected by adding or
subtracting trees. Although this seems a more
convincing answer, the use of data bases would
resume, as would the multiplicity of domains.
Our goal is a true analogy-solver, i.e., an algo-
rithm which, on receiving three words as input,
outputs a word, analogical to the input. For
that, we thus have to answer the hard problem
of: (1) performing multiple changes (2) using
a unique data-type (words) (3) without dictio-
nary nor any external knowledge.
</bodyText>
<subsectionHeader confidence="0.999624">
1.4 Analogies on Words
</subsectionHeader>
<bodyText confidence="0.999535916666667">
We have finished our review of the problem and
ended up with what was the starting point of
our work. In linguistic works, analogy is de-
fined by Saussure, after Humboldt and Baudoin
de Courtenay, as the operation by which, given
two forms of a given word, and only one form
of a second word, the missing form is coined&apos;,
&amp;quot;honor is to honorem as orator is to Oratorenz&amp;quot;
noted Oratorem : orator = honoreni : honor.
This is the same definition as the one given by
Aristotle himself, &amp;quot;A is to B as C is to D&amp;quot;, pos-
tulating identity of types for A, B, C, and D.
</bodyText>
<footnote confidence="0.726236666666667">
4Latin: Orator (orator, speaker) and honor (honour)
nominative singular, aratorem and honorem accusative
singular.
</footnote>
<page confidence="0.995659">
729
</page>
<bodyText confidence="0.999791176470588">
However, while analogy has been mentioned
and used, algorithmic ways to solve analogies
seem to have never been proposed, maybe be-
cause the operation, is so &amp;quot;intuitive&amp;quot;. We (Lep-
age &amp; Ando 96) recently gave a tentative com-
putational explanation which was not always
valid because false analogies were captured. It
did not constitute an algorithm either.
The only work on solving analogies on words
seems to be Copycat ((Hofstadter et al. 94)
and (Hoffman 95)), &apos;which solves such puzzles
as: abc : abbccc = zjk : x. Unfortunately it
does not seem to use a truly dedicated algo-
rithm, rather, following the AT approach, it uses
a formalisation of the domain with such func-
tions as, &amp;quot;previous in alphabet&amp;quot;, &amp;quot;rank in
alphabet&amp;quot;, etc.
</bodyText>
<sectionHeader confidence="0.67506" genericHeader="method">
2 Foundations of the Algorithm
</sectionHeader>
<subsectionHeader confidence="0.954877">
2.1 The First Term as an Axis
</subsectionHeader>
<bodyText confidence="0.997850666666667">
(Itkonen and Haukioja 97) give a program in
Prolog to solve analogies in sentences, as a refu-
tation of Chomsky, according to whom analogy
would not be operational in syntax, because it
delivers non-grammatical sentences. That anal-
ogy would apply also to syntax, was advocated
decades ago by Hermann Paul and Bloomfield.
Chomsky&apos;s claim is unfair, because it supposes
that analogy applies only on the symbol level.
Itkonen and Haukioja show that analogy, when
controlled by some structural level, does deliver
perfectly grammatical sentences. What is of
interest to us, is the essence of their method,
which is the seed for our algorithm:
Sentence D is formed by going through
sentences B and C one element at a time
and inspecting the relations of each ele-
ment to the structure of sentence A (plus
the part of sentence D that is ready).
Hence, sentence A is the axis against which sen-
tences B and C are compared, and by opposition
to which output sentence D is built.
reader: unreadable = doer : x x = undoable
The method will thus be: (a) look for those
parts which are not common to A and B on one
hand, and not common to A and C on the other
and (b) put them together in the right order.
</bodyText>
<subsectionHeader confidence="0.999324">
2.2 Common Subsequences
</subsectionHeader>
<bodyText confidence="0.999129076923077">
Looking for common subsequences of A and B
(resp. A and C) solves problem (a) by comple-
mentation. (Wagner Sz Fischer 74) is a method
to find longest common subsequences by com-
puting edit distance matrices, yielding the min-
imal number of edit operations (insertion, dele-
tion, substitution) necessary to transform one
string into another.
For instance, the following matrices give the
distance between like and unlike on one hand,
and between like and known on the other hand,
in their right bottom cells: dist(like, unlike) = 2
and dist(like, known) = 5
</bodyText>
<figure confidence="0.6204956">
unlike kno W 72
1 1 2 2 3 4 5 1 1 2 3 4 5
i 2 2 3 2 3 4 i 2 2 3 4 5
k 3 3 3 3 2 3 k 2 3 3 4 5
e 4 4 4 4 3 2 3 3 4 4 5
</figure>
<subsectionHeader confidence="0.99636">
2.3 Similitude between Words
</subsectionHeader>
<bodyText confidence="0.99998725">
We call similitude between A and B the length
of their longest common subsequence. It is also
equal to the length of A, minus the number of
its characters deleted or replaced to produce B.
This number we call pdist(A,B), because it is
a pseudo-distance, which can be computed ex-
actly as the edit distances, except that inser-
tions cost 0.
</bodyText>
<equation confidence="0.863767333333333">
sim(A, B) .1 A I — pdist(A, B)
For instance, pdist(unlike,like) = 2, while
pdist(//ke, unlike) = 0.
</equation>
<table confidence="0.982608285714286">
like
1 1 1 1 unlike
72 2 2 2 2
2 2 2 2 1 1 1 0 0
3 2 2 2 1. 2 2 1 0
4 3 2 2 3 3 2 1
5 4 3 2 4 4 3 2 1
</table>
<bodyText confidence="0.991924333333333">
Characters inserted into B or C may be left
aside, precisely because they are those charac-
ters of B and C, absent from A, that we want
to assemble into the solution, D.
As A is the axis in the resolution of analogy,
graphically we make it the vertical axis around
which the computation of pseudo-distances
takes place. For instance, for like : unlike =
known: x,
</bodyText>
<table confidence="0.955567">
o n k unlike
11 1 1 1 / 1 1 0 0 0 0
2 2 2 2 2 i 2 2 1 0 0 0
2 2 2 2 2 k 3 3 2 1 0 0
3 3 3 3 3 e 4 4 3 2 1 0
</table>
<page confidence="0.942675">
730
</page>
<subsectionHeader confidence="0.976652">
2.4 The Coverage Constraint
</subsectionHeader>
<bodyText confidence="0.999968714285714">
It is easy to verify that there is no solution to an
analogy if some characters of A appear neither
in B nor in C. The contrapositive says that,
for an analogy to hold, any character of A has
to appear in either B or C. Hence, the sum
of the similitudes of A with B and C must be
greater than or equal to its length: sim(A, B)-1-
</bodyText>
<equation confidence="0.974222">
sim(A, C) &gt; A I, or, equivalently,
I A I &gt; pdist(A,B)-1- pdist(A, C)
</equation>
<bodyText confidence="0.955663583333333">
When the length of A is greater than the sum
of the pseudo-distances, some subsequences of
A are common to all strings in the same order.
Such subsequences have to be copied into the
solution D. We call com(A,B,C , D) the sum
of the length of such subsequences. The del-
icate point is that this sum depends precisely
on the solution D being currently built by the
algorithm.
To summarise, for analogy A:B= C:D to
hold, the following constraint must be verified:
I Al = pdist(A,B)-1-pdist(A,C)+com(A,B,C,D)
</bodyText>
<sectionHeader confidence="0.996322" genericHeader="method">
3 The Algorithm
</sectionHeader>
<subsectionHeader confidence="0.999977">
3.1 Computation of Matrices
</subsectionHeader>
<bodyText confidence="0.915512761904762">
Our method relies on the computation of two
pseudo-distance matrices between the three first
terms of the analogy. A result by (Ukkonen 85)
says that it is sufficient to compute a diagonal
band plus two extra bands on each of its sides in
the edit distance matrix, in order to get the ex-
act distance, if the value of the overall distance
is known to be less than some given thresh-
old. This result applies to pseudo-distances,
and is used to reduce the computation of the
two pseudo-distance matrices. The width of the
extra bands is obtained by trying to satisfy the
coverage constraint with the value of the current
pseudo-distance in the other matrix.
proc compute_matrices(A,B,C , pd AB, PdAc)
compute pseudo-distances matrices with
extra bands of pd AB 12 and pdAc/2
if I A I &gt; pdist(A,B)+ pdist(A, C)
main component
else
compute_matrices(A,B,C,
</bodyText>
<listItem confidence="0.81345875">
max(I A I — pdist(A, C),pdAB + 1),
max(I A I — pdist(A, B),pdAc + 1))
end if
end proc compute_matrices
</listItem>
<subsectionHeader confidence="0.993155">
3.2 Main Component
</subsectionHeader>
<bodyText confidence="0.981353896551724">
Once enough in the matrices has been com-
puted, the principle of the algorithm is to follow
the paths along which longest common subse-
quences are found, simultaneously in both ma-
trices, copying characters into the solution ac-
cordingly. At each time, the positions in both
matrices must be on the same horizontal line,
i.e. at a same position in A, in order to ensure
a right order while building the solution, D.
Determining the paths is done by compar-
ing the current cell in the matrix with its three
previous ones (horizontal, vertical or diagonal),
according to the technique in (Wagner &amp; Fis-
cher 74). As a consequence, paths are followed
from the end of words down to their begin-
ning. The nine possible combinations (three di-
rections in two matrices) can be divided into
two groups: either the directions are the same
in both matrices, or they are different.
The following sketchesthe al-
gorithm. com(A, B, C, D) has been initialised
to: I A I — (pdist(A,B) pdist(A,C)). tA, 2B
and ic are the current positions in A, B and
C. dir AB (resp. dirAc) is the direction of the
path in matrix A x B (resp. A x C) from the
current position. &amp;quot;copy&amp;quot; means to copy a char-
acter from a word at the beginning of D and to
move to the previous character in that word.
if constraint(iA,iBliC,Com(A, B ,C , D))
</bodyText>
<equation confidence="0.853508692307692">
case: dir AB = dir AC = diagonal
if AFA] = B[iB] = C[ic]
decrement com(A, B ,C , D)
end if
copy B[iB] C[icl — ApAr
case: dir AB = dir Ac = horizontal
copy charb/ min(pdist(A[1..iA],B[1..iB]),
pdist(A[1..iA],C[1..ic]))
case: dir AB = dir Ac = vertical
move only in A (change horizontal line)
case: dir AB dir Ac
if dir AB = horizontal
copy BPB]
</equation>
<bodyText confidence="0.992295333333333">
&apos;In this case, we move in the three words at the
same time. Also, the character arithinetics factors,
in view of generalisations, different operations: if the
three current characters in A, B and C are equal, copy
this character, otherwise copy that character from B
or C that is different from the one in A. If all current
characters are different, this is a failure.
bThe word with less similitude with A is chosen, so
as to make up for its delay.
</bodyText>
<page confidence="0.971231">
731
</page>
<figure confidence="0.3091114">
else if dirAB = vertical
move in A and C
else same thing by exchanging B and C
end if
end if
</figure>
<subsectionHeader confidence="0.97312">
3.3 Early Termination in Case of
Failure
</subsectionHeader>
<bodyText confidence="0.99983975">
Complete computation of both matrices is not
necessary to detect a failure. It is obvious when
a letter in A does not appear in B or C. This
may already be detected before any matrix com-
putation.
Also, checking the coverage constraint allows
the algorithm to stop as soon as non-satisfying
moves have been performed.
</bodyText>
<subsectionHeader confidence="0.996326">
3.4 An Example
</subsectionHeader>
<bodyText confidence="0.999447285714286">
We will show how the analogy like: unlike =
known : x is solved by the algorithm.
The algorithm first verifies that all letters
of like are present either in unlike or known.
Then, the minimum computation is done for the
pseudo-distances matrices, i.e. only the mini-
mal diagonal band is computed.
</bodyText>
<equation confidence="0.8549122">
ek i 1 n t k n o w n
. . 0 1 1 1 1 1 . .
. . 0 1 2 . i . 2 2 . .
. 0 1 2 . . k . . 3 3 .
0 1 2 . . . 6 . . . 4 4
</equation>
<bodyText confidence="0.52472965">
As the coverage constraint is verified, the
main component is called. It follows the paths
noted by values in circles in the matrices.
ek • i @ (nu 0 / k 0 now • •
• • 0 •
. ap 1 2 . i . 2 0 . .
. 1 2 . . k . . 33 .
ID 1 2 . . . e . . . 4 (4)
The succession of moves triggers the following
copies into the solution:
dirAB dirAc copy
diagonal diagonal n
diagonal diagonal w
diagonal diagonal o
diagonal diagonal n
horizontal horizontal k
horizontal diagonal n
horizontal diagonal u
At each step, the coverage constraint being veri-
fied, finally, the solution x = unknown is ouptut.
</bodyText>
<sectionHeader confidence="0.73671" genericHeader="method">
4 Properties and Coverage
</sectionHeader>
<subsectionHeader confidence="0.768938">
4.1 Trivial Cases, Mirroring
</subsectionHeader>
<bodyText confidence="0.933066">
Trivial cases of analogies are, of course, solved
by the algorithm, like: A:A= A:x x=
A or A: A = C:x x = C. Also, by
construction, A: B= C: x and A: C=B:x
deliver the same solution.
With this construction, mirroring poses no
problem. If we note A the mirror of word A,
</bodyText>
<sectionHeader confidence="0.454047" genericHeader="method">
then A:B=C:D A:B=C:D.
</sectionHeader>
<subsectionHeader confidence="0.9971485">
4.2 Prefixing, Suffixing, Parallel
Infixing
</subsectionHeader>
<bodyText confidence="0.99980175">
Appendix A lists a number of examples, actu-
ally solved by the algorithm, from simple to
complex, which illustrate the algorithm&apos;s per-
formance.
</bodyText>
<subsectionHeader confidence="0.999376">
4.3 Reduplication and Permutation
</subsectionHeader>
<bodyText confidence="0.999872333333333">
The previous form of the algorithm does not
produce reduplication. This would be neces-
sary if we wanted to obtain, for example, plu-
</bodyText>
<equation confidence="0.647163">
rals in Indonesian&apos;: orang : orang-amng =
burung : x x = burung-burung . In this
</equation>
<bodyText confidence="0.998479375">
case, our algorithm delivers, x = orang-burung,
because preference is given to leave prefixes un-
changed. However, the algorithm may be easily
modified so that it applies repeatedly so as to
obtain the desired solutionG.
Permutation is not captured by the algo-
rithm. An example (q with a and u) in Proto-
semitic is: yagtilu : yugtilu = qatal : (MA
</bodyText>
<subsectionHeader confidence="0.9831965">
4.4 Language-independence/Code-
dependence
</subsectionHeader>
<bodyText confidence="0.999827928571429">
Because the present algorithm performs compu-
tation only on a symbol level, it may be applied
to any language. It is thus language indepen-
dent. This is fortunate, as analogy in linguistics
certainly derives from a more general psycho-
logical operation ((Gentner 83), (Itkonen 94)),
which seems to be universal among human be-
ings. Examples in Section A illustrate the lan-
guage independence of the algorithm.
Conversely, the symbols determine the granu-
larity of the analogies computed. Consequently,
a commutation not reflected in the coding sys-
tem will not be captured. This may be illus-
trated by a Japanese example in three different
</bodyText>
<footnote confidence="0.9044482">
5orang (human being) singular, orang-orang plural,
burung (bird).
6Similarly, it is easy to apply the algorithm in a
transducer-like way so that it modifies, by analogy, parts
of an input string.
</footnote>
<page confidence="0.99347">
732
</page>
<bodyText confidence="0.977844066666667">
codings: the native writing system, the Hep-
burn transcription and the official, strict rec-
ommendation (kunrei).
Kanji/Kana: of-4-D : &apos;f it = ft &lt; :x
Hepburn: nzatsu: machimasu = hataraku: x
Kunrei: nzatu: matima.su = hataraku: x
x = hatarakimasu
The algorithm does not solve the first two analo-
gies (solutions: t, hatarakimasu) be-
cause it does not solve the elementary analogies,
o:=&lt; : and tsu : chi = ku: ki, which
are beyond the symbol level&apos;.
More generally speaking, the interaction of
analogy with coding seems the basis of a fre-
quent reasoning principle:
</bodyText>
<equation confidence="0.957322">
f(A) : f(B) = f(C) :x A:BEC: f (x)
</equation>
<bodyText confidence="0.991886777777778">
Only the first analogy holds on the symbol level
and, as is, is solved by our algorithm. f is an
encoding function for which an inverse exists.
A striking application of this principle is the
resolution of some Copycat puzzles, like:
abc: abd = ijk : x x
Using a binary ASCII representation, which re-
flects sequence in the alphabet, our algorithm
produces:
</bodyText>
<equation confidence="0.992974333333333">
011000010110001001100011 : 011000010110001001100100
= 011010010110101001101011 : X
X = 011010010110101001101100 = 2j1
</equation>
<bodyText confidence="0.999995166666667">
In other words, coding is the key to many
analogies. More generally we follow (Itkonen
and Haukioja 97) when they claim that analogy
is an operation against which formal represen-
tations should also be assessed. But for that, of
course, we needed an automatic analogy-solver.
</bodyText>
<sectionHeader confidence="0.903694" genericHeader="method">
Conclusion
</sectionHeader>
<bodyText confidence="0.95199159375">
We have proposed an algorithm which solves
analogies on words, i.e. when possible it coins
a fourth word when given three words. It re-
lies on the computation of pseudo-distances be-
tween strings. The verification of a constraint,
relevant for analogy, limits the computation of
matrix cells, and permits early termination in
case of failure.
This algorithm has been proved to handle
many different cases in many different lan-
guages. In particular, it handles parallel infix-
ing, a property necessary for the morphological
description of semitic languages. Reduplication
is an easy extension.
This algorithm is independent of any lan-
guage, but not coding-independent: it consti-
tutes a trial at inspecting how much can be
achieved using only pure computation on sym-
bols, without any external knowledge. We are
inclined to advocate that much in the matter of
usual analogies, is a question of symbolic rep-
resentation, i.e. a question of encoding into a
form solvable by a purely symbolic algorithm
like the one we proposed.
Set in this way, even analogies of geometrical
type can be solved under a convenient represen-
tation.
An adequate description (or coding), with no
reduplication, is:
obj(big)Sz obj(small)c obj(big) obj(big)Sz .x
obj=circle• Szobj=circle obj=square.
This is actually solved by our algorithm:
</bodyText>
<equation confidence="0.616899">
obj(small)c obj(big)
X = Stobj=square
</equation>
<bodyText confidence="0.581884333333333">
70ne could imagine extending the algorithm by
para.metrising it with such predefined analogical
relations.
</bodyText>
<sectionHeader confidence="0.63496" genericHeader="method">
A Examples
</sectionHeader>
<bodyText confidence="0.9998995">
The following examples show actual resolution
of analogies by the algorithm. They illustrate
what the algorithm achieves on real linguistic
examples.
</bodyText>
<sectionHeader confidence="0.611153" genericHeader="method">
A.1 Insertion or deletion of prefixes or
suffixes
</sectionHeader>
<bodyText confidence="0.652115">
Latin: oratorenz: orator = honorenz: x
</bodyText>
<equation confidence="0.956952125">
x = honor
French: repression: repres.sionnaire = reaction: x
x = reactionnaire
Malay: tinggal: ketinggalan = duduk: x
x = kedudukan
Chinese: : 4**= : x
x = &amp;WA
: X =&gt; X =
</equation>
<page confidence="0.997389">
733
</page>
<note confidence="0.876144">
A.2 Exchange of prefixes or suffixes
</note>
<bodyText confidence="0.434321">
English: wolf: wolves = leaf: x
</bodyText>
<equation confidence="0.9736096">
x = leaves
Malay: kawan: mengawani = kerning: x
x = inengelilingi
Malay: keras: men geraskan = kena: x
x = men genakan
Polish: wyszedlee: wyszlai = poszedlei: x
x = posziae
A.3 Infixing and umlaut
Japanese: AZ : = : x
x =
German: king: Iiingste = scharf : x
x = scharfste
German: filehen : er floh = schliefien : x
x = er schloft
Polish: zgubiony : zgubieni = zmartwiony: x
x = zmartwieni
Akkadian: ukaggad: uktanak§&amp;quot;ad = ugakgad: x
x = zatanak,§ad
A.4 Parallel infixing
Proto-semitic: yasriqu: sariq = yanqiniu: x
x = naqinz
Arabic: huzila : huzal= ,sudi`a : x
x = pad&apos;
Arabic: arsala : mursilun = aslama : x
x = 11111.811.11111.12
</equation>
<sectionHeader confidence="0.966755" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99767090140845">
Robert I. Damper &amp; John E.G. Eastman
Pronouncing Text by Analogy
Proceedings of COLING-96, Copenhagen,
August 1996, pp. 268-269.
Dedre Gentner
Structure Mapping: A Theoretical Model for
Analogy
Cognitive Science, 1983, vol. 7, no 2, pp. 155-
170.
Rogers P. Hall
Computational Approaches to Analogical
- Reasoning: A Comparative Analysis
Artificial Intelligence, Vol. 39, No. 1, May
1989, pp. 39-120.
Douglas Hofsta.dter and the Fluid Analogies Re-
search Group
Fluid Concepts and Creative Analogies
Basic Books, New-York, 1994.
Robert R. Hoffman
Monster Analogies
Al Magazine, Fall 1995, vol. 11, pp 11-35.
Esa Itkonen
Iconicity, analogy, and universal grammar
Journal of Pragmatics, 1994, vol. 22, pp. 37-
53.
Esa Itkonen and Jussi Haukioja
A rehabilitation of analogy in syntax (and
elsewhere)
in Andras Kertesz (ed.) Metalinguistik ini
Wandel: die kognitive Wende in Wis-
senschaftstheorie und Linguistik Frankfurt
a/M, Peter Lang, 1997, pp. 131-177.
Yves Lepage &amp; Ando Shin-Ichi
Saussurian analogy: a theoretical account
and its application
Proceedings of COLING-96, Copenhagen,
August 1996, pp. 717-722.
Nagao Makoto
A Framework of a Mechanical Translation be-
tween Japanese and English by Analogy Prin-
ciple
in Artificial 6 Human Intelligence, Alick
Elithorn and Ranan Banerji eds., Elsevier
Science Publishers, NATO 1984.
Vito Pirelli &amp; Stefano Federici
&amp;quot;Derivational&amp;quot; paradigms in morphonology
Proceedings of COLING-94, Kyoto, August
1994, Vol. I, pp 234-240.
Victor Sadler and Ronald Vendelmans
Pilot implementation of a bilingual knowl-
edge bank
Proceedings of COLING-90, Helsinki, 1990,
vol 3, pp. 449-451.
Eric Steinhart
Analogical Truth Conditions for Metaphors
Metaphor and Symbolic Activity, 1994, 9(3),
pp 161-178.
Esko likkonen
Algorithms for Approximate String Matching
Information and Control, 64, 1985, pp. 100-
118.
Robert A. Wagner and Michael J. Fischer
The String-to-String Correction Problem
Journal for the Association of Computing
Machinery, Vol. 21, No. 1, January 1974, pp.
168-173.
Francois Yvon
Paradigmatic Cascades: a Linguistically
Sound Model of Pronunciation by Analogy
Proceedings of ACL-EACL-97, Madrid, 1994,
pp 428-435.
</reference>
<page confidence="0.998348">
734
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.655525">
<title confidence="0.999157">SOLVING ANALOGIES ON WORDS: AN ALGORITHM</title>
<author confidence="0.999407">Yves Lepage</author>
<affiliation confidence="0.999609">ATR Interpreting Telecommunications Research Labs,</affiliation>
<address confidence="0.968055">Hikaridai 2-2, Seika-ty6, SOraku-gun, KyOto 619-0288, Japan</address>
<intro confidence="0.679815">lepage@itl . atr. . co. jp</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
<author>E G John</author>
</authors>
<title>Eastman Pronouncing Text by Analogy</title>
<date>1996</date>
<booktitle>Proceedings of COLING-96, Copenhagen,</booktitle>
<pages>268--269</pages>
<marker>Damper, John, 1996</marker>
<rawString>Robert I. Damper &amp; John E.G. Eastman Pronouncing Text by Analogy Proceedings of COLING-96, Copenhagen, August 1996, pp. 268-269.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dedre Gentner</author>
</authors>
<title>Structure Mapping: A Theoretical Model for Analogy</title>
<marker>Gentner, </marker>
<rawString>Dedre Gentner Structure Mapping: A Theoretical Model for Analogy</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cognitive Science</author>
</authors>
<date>1983</date>
<volume>7</volume>
<pages>155--170</pages>
<marker>Science, 1983</marker>
<rawString>Cognitive Science, 1983, vol. 7, no 2, pp. 155-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rogers</author>
</authors>
<title>Hall Computational Approaches to Analogical - Reasoning: A Comparative Analysis</title>
<date>1989</date>
<journal>Artificial Intelligence,</journal>
<volume>39</volume>
<pages>39--120</pages>
<marker>Rogers, 1989</marker>
<rawString>Rogers P. Hall Computational Approaches to Analogical - Reasoning: A Comparative Analysis Artificial Intelligence, Vol. 39, No. 1, May 1989, pp. 39-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Hofsta dter</author>
</authors>
<title>and the Fluid Analogies Research Group Fluid Concepts and Creative Analogies Basic Books,</title>
<date>1994</date>
<location>New-York,</location>
<marker>dter, 1994</marker>
<rawString>Douglas Hofsta.dter and the Fluid Analogies Research Group Fluid Concepts and Creative Analogies Basic Books, New-York, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Robert</author>
</authors>
<title>Hoffman Monster Analogies Al Magazine,</title>
<date>1995</date>
<volume>11</volume>
<pages>11--35</pages>
<location>Fall</location>
<marker>Robert, 1995</marker>
<rawString>Robert R. Hoffman Monster Analogies Al Magazine, Fall 1995, vol. 11, pp 11-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esa Itkonen</author>
</authors>
<title>Iconicity, analogy, and universal grammar</title>
<date>1994</date>
<journal>Journal of Pragmatics,</journal>
<volume>22</volume>
<pages>37--53</pages>
<marker>Itkonen, 1994</marker>
<rawString>Esa Itkonen Iconicity, analogy, and universal grammar Journal of Pragmatics, 1994, vol. 22, pp. 37-53.</rawString>
</citation>
<citation valid="false">
<title>Esa Itkonen and Jussi Haukioja A rehabilitation of analogy</title>
<note>in syntax (and elsewhere)</note>
<marker></marker>
<rawString>Esa Itkonen and Jussi Haukioja A rehabilitation of analogy in syntax (and elsewhere)</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Metalinguistik ini Wandel: die kognitive Wende in Wissenschaftstheorie und Linguistik Frankfurt a/M, Peter Lang,</booktitle>
<pages>131--177</pages>
<editor>in Andras Kertesz (ed.)</editor>
<marker>1997</marker>
<rawString>in Andras Kertesz (ed.) Metalinguistik ini Wandel: die kognitive Wende in Wissenschaftstheorie und Linguistik Frankfurt a/M, Peter Lang, 1997, pp. 131-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Lepage</author>
</authors>
<title>Ando Shin-Ichi Saussurian analogy: a theoretical account and its application</title>
<date>1996</date>
<booktitle>Proceedings of COLING-96, Copenhagen,</booktitle>
<pages>717--722</pages>
<marker>Lepage, 1996</marker>
<rawString>Yves Lepage &amp; Ando Shin-Ichi Saussurian analogy: a theoretical account and its application Proceedings of COLING-96, Copenhagen, August 1996, pp. 717-722.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nagao Makoto</author>
</authors>
<title>A Framework of a Mechanical Translation between Japanese and English by Analogy Principle</title>
<marker>Makoto, </marker>
<rawString>Nagao Makoto A Framework of a Mechanical Translation between Japanese and English by Analogy Principle</rawString>
</citation>
<citation valid="true">
<date>1984</date>
<booktitle>in Artificial 6 Human Intelligence, Alick Elithorn and Ranan Banerji eds., Elsevier Science Publishers,</booktitle>
<location>NATO</location>
<marker>1984</marker>
<rawString>in Artificial 6 Human Intelligence, Alick Elithorn and Ranan Banerji eds., Elsevier Science Publishers, NATO 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vito Pirelli</author>
<author>Stefano Federici</author>
</authors>
<title>Derivational&amp;quot; paradigms in morphonology</title>
<date>1994</date>
<booktitle>Proceedings of COLING-94, Kyoto,</booktitle>
<volume>Vol. I,</volume>
<pages>234--240</pages>
<marker>Pirelli, Federici, 1994</marker>
<rawString>Vito Pirelli &amp; Stefano Federici &amp;quot;Derivational&amp;quot; paradigms in morphonology Proceedings of COLING-94, Kyoto, August 1994, Vol. I, pp 234-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Sadler</author>
<author>Ronald</author>
</authors>
<title>Vendelmans Pilot implementation of a bilingual knowledge bank</title>
<date>1990</date>
<booktitle>Proceedings of COLING-90,</booktitle>
<volume>3</volume>
<pages>449--451</pages>
<location>Helsinki,</location>
<marker>Sadler, Ronald, 1990</marker>
<rawString>Victor Sadler and Ronald Vendelmans Pilot implementation of a bilingual knowledge bank Proceedings of COLING-90, Helsinki, 1990, vol 3, pp. 449-451.</rawString>
</citation>
<citation valid="true">
<title>Eric Steinhart Analogical Truth Conditions for Metaphors Metaphor and Symbolic Activity,</title>
<date>1994</date>
<volume>9</volume>
<issue>3</issue>
<pages>161--178</pages>
<marker>1994</marker>
<rawString>Eric Steinhart Analogical Truth Conditions for Metaphors Metaphor and Symbolic Activity, 1994, 9(3), pp 161-178.</rawString>
</citation>
<citation valid="true">
<title>Esko likkonen Algorithms for Approximate String Matching Information and</title>
<date>1985</date>
<journal>Control,</journal>
<volume>64</volume>
<pages>100--118</pages>
<marker>1985</marker>
<rawString>Esko likkonen Algorithms for Approximate String Matching Information and Control, 64, 1985, pp. 100-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Wagner</author>
<author>J Michael</author>
</authors>
<title>Fischer The String-to-String Correction Problem Journal for the</title>
<date>1974</date>
<journal>Association of Computing Machinery,</journal>
<volume>21</volume>
<pages>168--173</pages>
<marker>Wagner, Michael, 1974</marker>
<rawString>Robert A. Wagner and Michael J. Fischer The String-to-String Correction Problem Journal for the Association of Computing Machinery, Vol. 21, No. 1, January 1974, pp. 168-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francois Yvon</author>
</authors>
<title>Paradigmatic Cascades: a Linguistically Sound Model of Pronunciation by Analogy</title>
<date>1994</date>
<booktitle>Proceedings of ACL-EACL-97,</booktitle>
<pages>428--435</pages>
<location>Madrid,</location>
<marker>Yvon, 1994</marker>
<rawString>Francois Yvon Paradigmatic Cascades: a Linguistically Sound Model of Pronunciation by Analogy Proceedings of ACL-EACL-97, Madrid, 1994, pp 428-435.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>