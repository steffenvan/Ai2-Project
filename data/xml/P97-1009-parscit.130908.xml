<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998112">
Using Syntactic Dependency as Local Context to Resolve Word
Sense Ambiguity
</title>
<author confidence="0.997832">
Dekang Lin
</author>
<affiliation confidence="0.82044575">
Department of Computer Science
University of Manitoba
Winnipeg, Manitoba, Canada R3T 2N2
lindekOcs.urnanitoba.ca
</affiliation>
<sectionHeader confidence="0.992979" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999262454545454">
Most previous corpus-based algorithms dis-
ambiguate a word with a classifier trained
from previous usages of the same word.
Separate classifiers have to be trained for
different words. We present an algorithm
that uses the same knowledge sources to
disambiguate different words. The algo-
rithm does not require a sense-tagged cor-
pus and exploits the fact that two different
words are likely to have similar meanings if
they occur in identical local contexts.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985230032786885">
Given a word, its context and its possible meanings,
the problem of word sense disambiguation (WSD) is
to determine the meaning of the word in that con-
text. WSD is useful in many natural language tasks,
such as choosing the correct word in machine trans-
lation and coreference resolution.
In several recent proposals (Hearst, 1991; Bruce
and Wiebe, 1994; Leacock, Towwell, and Voorhees,
1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky,
1994), statistical and machine learning techniques
were used to extract classifiers from hand-tagged
corpus. Yarowsky (Yarowsky, 1995) proposed an
unsupervised method that used heuristics to obtain
seed classifications and expanded the results to the
other parts of the corpus, thus avoided the need to
hand-annotate any examples.
Most previous corpus-based WSD algorithms de-
termine the meanings of polysemous words by ex-
ploiting their local contexts. A basic intuition that
underlies those algorithms is the following:
(1) Two occurrences of the same word have
identical meanings if they have similar local
contexts.
In other words, most previous corpus-based WSD al-
gorithms learn to disambiguate a polysemous word
from previous usages of the same word. This has sev-
eral undesirable consequences. Firstly, a word must
occur thousands of times before a good classifier can
be learned. In Yarowsky&apos;s experiment (Yarowsky,
1995), an average of 3936 examples were used to
disambiguate between two senses. In Ng and Lee&apos;s
experiment, 192,800 occurrences of 191 words were
used as training examples. There are thousands of
polysemous words, e.g., there are 11,562 polysemous
nouns in WordNet. For every polysemous word to
occur thousands of times each, the corpus must con-
tain billions of words. Secondly, learning to disam-
biguate a word from the previous usages of the same
word means that whatever was learned for one word
is not used on other words, which obviously missed
generality in natural languages. Thirdly, these algo-
rithms cannot deal with words for which classifiers
have not been learned.
In this paper, we present a WSD algorithm that
relies on a different intuition:
(2) Two different words are likely to have similar
meanings if they occur in identical local
contexts.
Consider the sentence:
(3) The new facility will employ 500 of the
existing 600 employees
The word &amp;quot;facility&amp;quot; has 5 possible meanings in
WordNet 1.5 (Miller, 1990): (a) installation, (b)
proficiency/technique, (c) adeptness, (d) readiness,
(e) toilet/bathroom. To disambiguate the word, we
consider other words that appeared in an identical
local context as &amp;quot;facility&amp;quot; in (3). Table 1 is a list
of words that have also been used as the subject of
&amp;quot;employ&amp;quot; in a 25-million-word Wall Street Journal
corpus. The &amp;quot;freq&amp;quot; column are the number of times
these words were used as the subject of &amp;quot;employ&amp;quot;.
</bodyText>
<page confidence="0.999505">
64
</page>
<tableCaption confidence="0.999709">
Table 1: Subjects of &amp;quot;employ&amp;quot; with highest likelihood ratio
</tableCaption>
<table confidence="0.996693545454546">
word freq logA word freq logA
ORG 64 50.4 machine 3 6.56
plant 14 31.0 corporation 3 6.47
company 27 28.6 manufacturer 3 6.21
operation 8 23.0 insurance company 2 6.06
industry 9 14.6 aerospace 2 5.81
firm 8 13.5 memory device 1 5.79
pirate 2 12.1 department 3 5.55
unit 9 9.32 foreign office 1 5.41
shift 3 8.48 enterprise 2 5.39
postal service 2 7.73 pilot 2 5.37
</table>
<bodyText confidence="0.935526333333333">
ORG includes all proper names recognized as organizations
The logA column are their likelihood ratios (Dun-
ning, 1993). The meaning of &amp;quot;facility&amp;quot; in (3) can
be determined by choosing one of its 5 senses that
is most similar&apos; to the meanings of words in Table
1. This way, a polysemous word is disambiguated
with past usages of other words. Whether or not it
appears in the corpus is irrelevant.
Our approach offers several advantages:
</bodyText>
<listItem confidence="0.974501666666667">
• The same knowledge sources are used for all
words, as opposed to using a separate classifier
for each individual word.
• It requires a much smaller corpus that needs not
be sense-tagged.
• It is able to deal with words that are infrequent
or do not even appear in the corpus.
• The same mechanism can also be used to infer
the semantic categories of unknown words.
</listItem>
<bodyText confidence="0.9998069">
The required resources of the algorithm include
the following: (a) an untagged text corpus, (b) a
broad-coverage parser, (c) a concept hierarchy, such
as the WordNet (Miller, 1990) or Roget&apos;s Thesaurus,
and (d) a similarity measure between concepts.
In the next section, we introduce our definition of
local contexts and the database of local contexts. A
description of the disambiguation algorithm is pre-
sented in Section 3. Section 4 discusses the evalua-
tion results.
</bodyText>
<sectionHeader confidence="0.991627" genericHeader="introduction">
2 Local Context
</sectionHeader>
<bodyText confidence="0.997231576923077">
Psychological experiments show that humans are
able to resolve word sense ambiguities given a narrow
window of surrounding words (Choueka and Lusig-
nan, 1985). Most WSD algorithms take as input
ito be defined in Section 3.1
a polysemous word and its local context. Different
systems have different definitions of local contexts.
In (Leacock, Towwell, and Voorhees, 1996), the lo-
cal context of a word is an unordered set of words in
the sentence containing the word and the preceding
sentence. In (Ng and Lee. 1996), a local context of a
word consists of an ordered sequence of 6 surround-
ing part-of-speech tags, its morphological features,
and a set of collocations.
In our approach, a local context of a word is de-
fined in terms of the syntactic dependencies between
the word and other words in the same sentence.
A dependency relationship (Hudson, 1984;
Mel&apos;euk, 1987) is an asymmetric binary relation-
ship between a word called head (or governor, par-
ent), and another word called modifier (or depen-
dent, daughter). Dependency grammars represent
sentence structures as a set of dependency relation-
ships. Normally the dependency relationships form
a tree that connects all the words in a sentence. An
example dependency structure is shown in (4).
</bodyText>
<equation confidence="0.96378">
corn
(4)
/
spec subj
sp
the boy chased a brown dog
</equation>
<bodyText confidence="0.9760747">
The local context of a word W is a triple that
corresponds to a dependency relationship in which
W is the head or the modifier:
(type word position)
where type is the type of the dependency relation-
ship, such as subj (subject), adjn (adjunct), comp I
(first complement), etc.; word is the word related to
W via the dependency relationship; and posit ion
can either be head or mod. The position indicates
whether word is the head or the modifier in depen-
</bodyText>
<page confidence="0.999272">
65
</page>
<bodyText confidence="0.999819833333333">
dency relation. Since a word may be involved in sev-
eral dependency relationships, each occurrence of a
word may have multiple local contexts.
The local contexts of the two nouns &amp;quot;boy&amp;quot; and
&amp;quot;dog&amp;quot; in (4) are as follows (the dependency relations
between nouns and their determiners are ignored):
</bodyText>
<subsectionHeader confidence="0.581863">
Word Local Contexts
</subsectionHeader>
<bodyText confidence="0.925614">
boy (subj chase head)
dog (adjn brown mod) (compl chase head)
Using a broad coverage parser to parse a corpus,
we construct a Local Context Database. An en-
try in the database is a pair:
</bodyText>
<equation confidence="0.485705">
(6) (/c, C(/c))
</equation>
<bodyText confidence="0.999973285714286">
where lc is a local context and C(lc) is a set of (word
frequency likelihood)-triples. Each triple speci-
fies how often word occurred in lc and the likelihood
ratio of lc and word. The likelihood ratio is obtained
by treating word and /c as a bigram and computed
with the formula in (Dunning, 1993). The database
entry corresponding to Table 1 is as follows:
</bodyText>
<equation confidence="0.943447666666667">
[ lc = (subj employ head)
C(lc) = ((ORG 64 50.4) (plant 14 31.0)
(pilot 2 5.37))
</equation>
<sectionHeader confidence="0.981851" genericHeader="method">
3 The Approach
</sectionHeader>
<bodyText confidence="0.999976555555556">
The polysemous words in the input text are disam-
biguated in the following steps:
Step A. Parse the input text and extract local con-
texts of each word. Let LC. denote the set of
local contexts of all occurrences of w in the in-
put text.
Step B. Search the local context database and find
words that appeared in an identical local con-
text as w. They are called selectors of w:
</bodyText>
<subsectionHeader confidence="0.449738">
Selectors w= (H C(/c)) — {w}.
</subsectionHeader>
<bodyText confidence="0.9995888">
Step C. Select a sense s of w that maximizes the
similarity between w and Selectors.
Step D. The sense s is assigned to all occurrences
of w in the input text. This implements the
&amp;quot;one sense per discourse&amp;quot; heuristic advocated
in (Gale, Church, and Yarowsky, 1992).
Step C. needs further explanation. In the next sub-
section, we define the similarity between two word
senses (or concepts). We then explain how the simi-
larity between a word and its selectors is maximized.
</bodyText>
<subsectionHeader confidence="0.999507">
3.1 Similarity between Two Concepts
</subsectionHeader>
<bodyText confidence="0.999861428571429">
There have been several proposed measures for sim-
ilarity between two concepts (Lee, Kim, and Lee,
1989; Rada et al., 1989; Resnik, 1995b; Wu and
Palmer, 1994). All of those similarity measures
are defined directly by a formula. We use instead
an information-theoretic definition of similarity that
can be derived from the following assumptions:
</bodyText>
<construct confidence="0.180642666666667">
Assumption 1: The commonality between A and
B is measured by
I (common (A, B))
</construct>
<bodyText confidence="0.9090098">
where cornmon(A, B) is a proposition that states the
commonalities between A and B; /(s) is the amount
of information contained in the proposition s.
Assumption 2: The differences between A and B
is measured by
</bodyText>
<equation confidence="0.56946">
I (describe(A, B)) — I (common(A, B))
</equation>
<bodyText confidence="0.986586548387097">
where describe(A, B) is a proposition that describes
what A and B are.
Assumption 3: The similarity between A and B,
sim(A, B), is a function of their commonality and
differences. That is,
sim(A, B) = f (I (common(A, B)), I (describe(A, B)))
The domain of f (x, y) is {(x , y)ix &gt; 0, y &gt; 0, y &gt; x}.
Assumption 4: Similarity is independent of the
unit used in the information measure.
According to Information Theory (Cover and
Thomas, 1991), /(s) = —log bP(s), where P(s) is
the probability of s and b is the unit. When b = 2,
/(s) is the number of bits needed to encode s. Since
log bx =12412 , Assumption 4 means that the func-
tion f must satisfy the following condition:
Vc &gt; 0, f(x, y) f (cx,
Assumption 5: Similarity is additive with respect
to commonality.
If cornman(A, B) consists of two independent
parts, then the sim(A, B) is the sum of the simi-
larities computed when each part of the commonal-
ity is considered. In other words: f (xi + x2, y) =
f(xi,y)+ f(x2,y).
A corollary of Assumption 5 is that Vy, f(0, y) =
f (x + 0, y) — f (x,y) = 0, which means that when
there is no commonality between A and B, their
similarity is 0, no matter how different they are.
For example, the similarity between &amp;quot;depth-first
search&amp;quot; and &amp;quot;leather sofa&amp;quot; is neither higher nor lower
than the similarity between &amp;quot;rectangle&amp;quot; and &amp;quot;inter-
est rate&amp;quot;.
</bodyText>
<page confidence="0.951765">
66
</page>
<bodyText confidence="0.883763714285714">
Assumption 6: The similarity between a pair of
identical objects is 1.
When A and B are identical. knowning their
commonalities means knowing what they are, i.e.,
I (comman(A, B)) = I (describe(A. B)). Therefore,
the function f must have the following property:
Vx, f (x, x) = 1.
Assumption 7: The function f (x. y) is continu-
ous.
Similarity Theorem: The similarity between A
and B is measured by the ratio between the amount
of information needed to state the commonality of A
and B and the information needed to fully describe
what A and B are:
</bodyText>
<equation confidence="0.963227666666667">
logP(cornmon (A. B))
sim( B)
&apos; logP(describe(A, B))
</equation>
<bodyText confidence="0.9644385">
Proof: To prove the theorem. we need to show
f(x,y) = s. Since f(x,y) = f(s.1) (due to As-
sumption 4), we only need to show that when LI, is a
rational number, f (x,y) = . The result can be gen-
eralized to all real numbers because f is continuous
and for any real number, there are rational numbers
that are infinitely close to it.
Suppose m and n are positive integers.
</bodyText>
<equation confidence="0.856624">
f (nx, y) = f ((n — 1)x. y) + f (x. y) = n f (x y)
</equation>
<bodyText confidence="0.673676">
(due to Assumption 5). Thus. f (x, y) = ;-; f (nx, y).
Substituting fi for x in this equation:
</bodyText>
<equation confidence="0.988853">
= nf( y) = n f (x • ny) = n(741- f (mx • ny))
Since E is rational, there exist m and n such that
=
flym
f (x, y) =f (7- = -f(1.1) =
m fly in y
</equation>
<bodyText confidence="0.978244230769231">
Q.E.D.
For example. Figure 1 is a fragment of the Word-
Net. The nodes are concepts (or synsets as they are
called in the WordNet). The links represent IS-A
relationships. The number attached to a node C is
the probability P(C) that a randomly selected noun
refers to an instance of C. The probabilities are
estimated by the frequency of concepts in SemCor
(Miller et al., 1994), a sense-tagged subset of the
Brown corpus.
If x is a Hill and y is a Coast, the commonality
between x and p is that &amp;quot;x is a GeoForm and y
is a GeoForm&amp;quot;. The information contained in this
</bodyText>
<figure confidence="0.493644333333333">
entfty 0.395
inanimar-object 0.167
inatural- bject 0.0163
geological-fo ation 0.00176
0.000113 natural-ilevation shlre 0.0000836
0.0000189 hill coast 0.0000216
</figure>
<figureCaption confidence="0.998141">
Figure 1: A fragment of WordNet
</figureCaption>
<bodyText confidence="0.7266435">
statement is —2 x logP(GeoF arm). The similarity
between the concepts Hill and Coast is:
</bodyText>
<equation confidence="0.999052833333333">
2 x logP(GeoForm)
sim(Hill Coast) =
log P(Hill) + log P(Coast)
Generally speaking,
2xlogP(n, C.)
(7) sim(c, ci) logP(C)-i-logP(C&apos;)
</equation>
<bodyText confidence="0.999853333333333">
where p(ni co is the probability of that an object
belongs to all the maximally specific super classes
(Cts) of both C and C&apos;.
</bodyText>
<subsectionHeader confidence="0.9980355">
3.2 Disambiguation by Maximizing
Similarity
</subsectionHeader>
<bodyText confidence="0.999946769230769">
We now provide the details of Step C in our algo-
rithm. The input to this step consists of a polyse-
mous word V110 and its selectors {WI, W2 WO.
The word Wi has ni senses: {sii, • • • , sin. }*
Step C.1: Construct a similarity matrix (8). The
rows and columns represent word senses. The
matrix is divided into (k 1) x (k + 1) blocks.
The blocks on the diagonal are all Os. The el-
ements in block Sii are the similarity measures
between the senses of Wi and the senses of It:).
Similarity measures lower than a threshold 0 are
considered to be noise and are ignored. In our
experiments, 9 = 0.2 was used.
</bodyText>
<equation confidence="0.950747666666667">
S if i j and
S1)(1, sim(sal, sim ) &gt; 0
0 otherwise
f (r, y)
Therefore,
0.59
</equation>
<page confidence="0.989507">
67
</page>
<table confidence="0.824987857142857">
SOI ... 50n Ski ... Sknk
SO1 0 Sok
SOno
Sll 510 Slk
Sin&apos;
Ski Sic() 0
Sknh
Step C.2: Let A be the set of polysemous words in
{Wo,.••,Wk}:
A = {W,Int &gt; 1}
Step C.3: Find a sense of words in A that gets the
highest total support from other words. Call
this sense Si:
(8)
</table>
<tableCaption confidence="0.9732665">
Table 2: Modifiees of &amp;quot;new&amp;quot; with the highest likeli-
hood ratios
</tableCaption>
<table confidence="0.999089636363636">
word freq logA word freq logA
post 432 952.9 bonds 223 245.4
issue 805 902.8 capital 178 241.8
product 675 888.6 order 228 236.5
rule 459 875.8 version 158 223.7
law 356 541.5 position 236 207.3
technology 237 382.7 high 152 201.2
generation 150 323.2 contract 279 198.1
model 207 319.3 bill 208 194.9
job 260 269.2 venture 123 193.7
system 318 251.8 program 283 183.8
</table>
<equation confidence="0.7220985">
argrnax,, Esupport(sii,Wi)
i=o
where sii is a word sense such that Wi E A and
1 E [1, nil and support(sii,Wi) is the support
sii gets from
support(sii,Wi) = max Sii(/,m)
mE[1,ni]
Step C.4: The sense of is chosen to be
Remove Wi„,.. from A.
A &lt;- A -
</equation>
<bodyText confidence="0.6436754">
Step C.5: Modify the similarity matrix to remove
the similarity values between other senses of
W.i„ and senses of other words. For all 1, j,
m, such that 1 E [1,ni,..] and 1 0 Imax and
j imax and m E [1, nil&apos;
</bodyText>
<equation confidence="0.836825">
Sim.„i(1,rn) 4- 0
</equation>
<subsectionHeader confidence="0.866324">
Step C.6: Repeat from Step C.3 unless imax = 0.
3.3 Walk Through Examples
</subsectionHeader>
<bodyText confidence="0.983244">
Let&apos;s consider again the word &amp;quot;facility&amp;quot; in (3). It
has two local contexts: subject of &amp;quot;employ&amp;quot; (subj
employ head) and modifiee of &amp;quot;new&amp;quot; (adjn new
mod). Table 1 lists words that appeared in the first
local context. Table 2 lists words that appeared in
the second local context. Only words with top-20
likelihood ratio were used in our experiments.
The two groups of words are merged and used as
the selectors of &amp;quot;facility&amp;quot;. The words &amp;quot;facility&amp;quot; has
5 senses in the WordNet.
</bodyText>
<listItem confidence="0.998656166666667">
1. something created to provide a particular ser-
vice;
2. proficiency, technique;
3. adeptness, deftness, quickness;
4. readiness, effortlessness;
5. toilet, lavatory.
</listItem>
<bodyText confidence="0.998063">
Senses 1 and 5 are subclasses of artifact. Senses 2
and 3 are kinds of state. Sense 4 is a kind of ab-
straction. Many of the selectors in Tables 1 and
Table 2 have artifact senses, such as &amp;quot;post&amp;quot;, &amp;quot;prod-
uct&amp;quot;, &amp;quot;system&amp;quot;, &amp;quot;unit&amp;quot;, &amp;quot;memory device&amp;quot;, &amp;quot;ma-
chine&amp;quot;, &amp;quot;plant&amp;quot;, &amp;quot;model&amp;quot;, &amp;quot;program&amp;quot;, etc. There-
fore, Senses 1 and 5 of &amp;quot;facility&amp;quot; received much
more support, 5.37 and 2.42 respectively, than other
senses. Sense 1 is selected.
Consider another example that involves an un-
known proper name:
</bodyText>
<listItem confidence="0.43661">
(9) DreamLand employed 20 programmers.
</listItem>
<bodyText confidence="0.999443111111111">
We treat unknown proper nouns as a polysemous
word which could refer to a person, an organization,
or a location. Since &amp;quot;DreamLand&amp;quot; is the subject of
&amp;quot;employed&amp;quot;, its meaning is determined by maximiz-
ing the similarity between one of {person, organiza-
tion, locaton} and the words in Table 1. Since Table
1 contains many &amp;quot;organization&amp;quot; words, the support
for the &amp;quot;organization&amp;quot; sense is much higher than the
others.
</bodyText>
<sectionHeader confidence="0.998997" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.995688">
We used a subset of the SemCor (Miller et al., 1994)
to evaluate our algorithm.
</bodyText>
<page confidence="0.998396">
68
</page>
<subsectionHeader confidence="0.969721">
4.1 Evaluation Criteria
</subsectionHeader>
<bodyText confidence="0.999357545454545">
General-purpose lexical resources, such as Word-
Net, Longman Dictionary of Contemporary English
(LDOCE), and Roget&apos;s Thesaurus, strive to achieve
completeness. They often make subtle distinctions
between word senses. As a result, when the WSD
task is defined as choosing a sense out of a list of
senses in a general-purpose lexical resource, even hu-
mans may frequently disagree with one another on
what the correct sense should be.
The subtle distinctions between different word
senses are often unnecessary. Therefore, we relaxed
the correctness criterion. A selected sense sanswer
is correct if it is &amp;quot;similar enough&amp;quot; to the sense tag
S key in SemCor. We experimented with three in-
terpretations of &amp;quot;similar enough&amp;quot;. The strictest in-
terpretation is SiM(Sanswer, skey)=1, which is true
only when sanswer=skey. The most relaxed inter-
pretation is SiM(Sanewer, S key) &gt;0, which is true if
sanswer and skey are the descendents of the same
top-level concepts in WordNet (e.g., entity, group,
location, etc.). A compromise between these two is
SiM(Sanswer, Skey) &gt; 0.27, where 0.27 is the average
similarity of 50,000 randomly generated pairs (w, w&apos;)
in which w and w&apos; belong to the same Roget&apos;s cate-
gory.
We use three words &amp;quot;duty&amp;quot;, &amp;quot;interest&amp;quot; and &amp;quot;line&amp;quot;
as examples to provide a rough idea about what
sim(sanswer, skey) &gt; 0.27 means.
The word &amp;quot;duty&amp;quot; has three senses in WordNet 1.5.
The similarity between the three senses are all below
0.27, although the similarity between Senses 1 (re-
sponsibility) and 2 (assignment, chore) is very close
(0.26) to the threshold.
The word &amp;quot;interest&amp;quot; has 8 senses. Senses 1 (sake,
benefit) and 7 (interestingness) are merged.2 Senses
3 (fixed charge for borrowing money), 4 (a right or
legal share of something), and 5 (financial interest
in something) are merged. The word &amp;quot;interest&amp;quot; is
reduced to a 5-way ambiguous word. The other
three senses are 2 (curiosity), 6 (interest group) and
8 (pastime, hobby).
The word &amp;quot;line&amp;quot; has 27 senses. The similarity
threshold 0.27 reduces the number of senses to 14.
The reduced senses are
</bodyText>
<listItem confidence="0.936243666666667">
• Senses 1, 5, 17 and 24: something that is com-
municated between people or groups.
1: a mark that is long relative to its width
</listItem>
<footnote confidence="0.7868814">
5: a linear string of words expressing some
idea
2The similarities between senses of the same word are
computed during scoring. We do not actually change the
WordNet hierarchy
</footnote>
<listItem confidence="0.946321571428571">
17: a mark indicating positions or bounds of
the playing area
24: as in &amp;quot;drop me a line when you get there&amp;quot;
• Senses 2, 3, 9, 14, 18: group
2: a formation of people or things beside one
another
3: a formation of people or things one after
another
9: a connected series of events or actions or
developments
14: the descendants of one individual
18: common carrier
• Sense 4: a single frequency (or very narrow
band) of radiation in a spectrum
• Senses 6 and 25: cognitive process
6: line of reasoning
25: a conceptual separation or demarcation
• Senses 7, 15, and 26: instrumentation
7: electrical cable
15: telephone line
26: assembly line
• Senses 8 and 10: shape
8: a length (straight or curved) without
breadth or thickness
10: wrinkle, furrow, crease, crinkle, seam, line
• Senses 11 and 16: any road or path affording
passage from one place to another;
11: pipeline
16: railway
• Sense 12: location, a spatial location defined by
a real or imaginary unidimensional extent;
• Senses 13 and 27: human action
13: acting in conformity
27: occupation, line of work;
• Sense 19: something long and thin and flexible
• Sense 20: product line, line of products
• Sense 21: space for one line of print (one col-
umn wide and 1/14 inch deep) used to measure
advertising
• Sense 22: credit line, line of credit
• Sense 23: a succession of notes forming a dis-
tinctived sequence
</listItem>
<bodyText confidence="0.991416">
where each group is a reduced sense and the numbers
are original WordNet sense numbers.
</bodyText>
<page confidence="0.998827">
69
</page>
<sectionHeader confidence="0.610664" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999824810810811">
We used a 25-million-word Wall Street Journal cor-
pus (part of LDC/DCI3 CDROM) to construct the
local context database. The text was parsed in
126 hours on a SPARC-Ultra 1/140 with 96MB
of memory. We then extracted from the parse
trees 8,665,362 dependency relationships in which
the head or the modifier is a noun. We then fil-
tered out (lc, word) pairs with a likelihood ratio
lower than 5 (an arbitrary threshold). The resulting
database contains 354,670 local contexts with a to-
tal of 1,067,451 words in them (Table 1 is counted
as one local context with 20 words in it).
Since the local context database is constructed
from WSJ corpus which are mostly business news,
we only used the &amp;quot;press reportage&amp;quot; part of Sem-
Cor which consists of 7 files with about 2000 words
each. Furthermore, we only applied our algorithm
to nouns. Table 3 shows the results on 2,832 polyse-
mous nouns in SemCor. This number also includes
proper nouns that do not contain simple markers
(e.g., Mr., Inc.) to indicate its category. Such a
proper noun is treated as a 3-way ambiguous word:
person, organization, or location. We also showed
as a baseline the performance of the simple strategy
of always choosing the first sense of a word in the
WordNet. Since the WordNet senses are ordered ac-
cording to their frequency in SemCor, choosing the
first sense is roughly the same as choosing the sense
with highest prior probability, except that we are
not using all the files in SemCor.
It can be seen from Table 3 that our algorithm
performed slightly worse than the baseline when
the strictest correctness criterion is used. However,
when the condition is relaxed, its performance gain
is much lager than the baseline. This means that
when the algorithm makes mistakes, the mistakes
tend to be close to the correct answer.
</bodyText>
<sectionHeader confidence="0.9735855" genericHeader="method">
5 Discussion
5.1 Related Work
</sectionHeader>
<bodyText confidence="0.997566444444444">
The Step C in Section 3.2 is similar to Resnik&apos;s noun
group disambiguation (Resnik, 1995a), although he
did not address the question of the creation of noun
groups.
The earlier work on WSD that is most similar to
ours is (Li, Szpakowicz, and Matwin, 1995). They
proposed a set of heuristic rules that are based on
the idea that objects of the same or similar verbs are
similar.
</bodyText>
<footnote confidence="0.907596">
3http://www.ldc.upenn.edu/
</footnote>
<subsectionHeader confidence="0.960877">
5.2 Weak Contexts
</subsectionHeader>
<bodyText confidence="0.999867">
Our algorithm treats all local contexts equally in
its decision-making. However, some local contexts
hardly provide any constraint on the meaning of a
word. For example, the object of &amp;quot;get&amp;quot; can practi-
cally be anything. This type of contexts should be
filtered out or discounted in decision-making.
</bodyText>
<subsectionHeader confidence="0.941349">
5.3 Idiomatic Usages
</subsectionHeader>
<bodyText confidence="0.9804375">
Our assumption that similar words appear in iden-
tical context does not always hold. For example,
</bodyText>
<reference confidence="0.499299142857143">
(10) ... the condition in which the heart beats
between 150 and 200 beats a minute
The most frequent subjects of &amp;quot;beat&amp;quot; (according to
our local context database) are the following:
(11) PER, badge, bidder, bunch, challenger,
democrat, Dewey, grass, mummification, pimp,
police, return, semi, and soldier.
</reference>
<bodyText confidence="0.99873375">
where PER refers to proper names recognized as per-
sons. None of these is similar to the &amp;quot;body part&amp;quot;
meaning of &amp;quot;heart&amp;quot;. In fact, &amp;quot;heart&amp;quot; is the only body
part that beats.
</bodyText>
<sectionHeader confidence="0.999086" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998946857142857">
We have presented a new algorithm for word sense
disambiguation. Unlike most previous corpus-
based WSD algorithm where separate classifiers are
trained for different words, we use the same lo-
cal context database and a concept hierarchy as
the knowledge sources for disambiguating all words.
This allows our algorithm to deal with infrequent
words or unknown proper nouns.
Unnecessarily subtle distinction between word
senses is a well-known problem for evaluating WSD
algorithms with general-purpose lexical resources.
Our use of similarity measure to relax the correct-
ness criterion provides a possible solution to this
problem.
</bodyText>
<sectionHeader confidence="0.989095" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<copyright confidence="0.596816666666667">
This research has also been partially supported by
NSERC Research Grant 0GP121338 and by the In-
stitute for Robotics and Intelligent Systems.
</copyright>
<sectionHeader confidence="0.996979" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.5614762">
Bruce, Rebecca and Janyce Wiebe. 1994. Word-
sense disambiguation using decomposable models.
In Proceedings of the 32nd Annual Meeting of the
Associations for Computational Linguistics, pages
139-145, Las Cruces, New Mexico.
</reference>
<page confidence="0.998905">
70
</page>
<tableCaption confidence="0.997267">
Table 3: Performance on polysemous nouns in 7 SemCor files
</tableCaption>
<table confidence="0.45265275">
correctness criterion our algorithm first sense in WordNet
sim(sanswer, skey ) &gt; 0 73.6% 67.2%
SiM(.9 answer, 8 key) ..._&gt; 0.27 68.5% 64.2%
SiM(S answer , S key) = 1 56.1% 58.9%
</table>
<reference confidence="0.999567759036145">
Choueka., Y. and S. Lusignan. 1985. Disambigua-
tion by short contexts. Computer and the Hu-
manities, 19:147-157.
Cover, Thomas M. and Joy A. Thomas. 1991. El-
ements of information theory. Wiley series in
telecommunications. Wiley, New York.
Dunning, Ted. 1993. Accurate methods for the
statistics of surprise and coincidence. Computa-
tional Linguistics, 19(1):61-74, March.
Gale, W., K. Church, and D. Yarowsky. 1992. A
method for disambiguating word senses in a large
corpus. Computers and the Humannities, 26:415-
439.
Hearst, Marti. 1991. noun homograph disambigua-
tion using local context in large text corpora. In
Conference on Research and Development in In-
formation Retrieval ACM/SIGIR, pages 36-47,
Pittsburgh, PA.
Hudson, Richard. 1984. Word Grammar. Basil
Blackwell Publishers Limited., Oxford, England.
Leacock, Claudia, Goeffrey Towwell, and Ellen M.
Voorhees. 1996. Towards building contextual rep-
resentations of word senses using statistical mod-
els. In Corpus Processing for Lexical Acquisition.
The MIT Press, chapter 6, pages 97-113.
Lee, Joon Ho, Myoung Ho Kim, and Yoon Joon Lee.
1989. Information retrieval based on conceptual
distance in is-a hierarchies. Journal of Documen-
tation, 49(2):188-207, June.
Li, Xiaobin, Stan Szpakowicz, and Stan Matwin.
1995. A wordnet-based algorithm for word sense
disambiguation. In Proceedings of IJCAI-95,
pages 1368-1374, Montreal, Canada, August.
Mel&apos;euk, Igor A. 1987. Dependency syntax: theory
and practice. State University of New York Press,
Albany.
Miller, George A. 1990. WordNet: An on-line lexi-
cal database. International Journal of Lexicogra-
phy, 3(4):235-312.
Miller, George A., Martin Chodorow, Shari Landes,
Claudia Leacock, and robert G. Thomas. 1994.
Using a semantic concordance for sense identifi-
cation. In Proceedings of the ARPA Human Lan-
guage Technology Workshop.
Ng, Hwee Tow and Hian Beng Lee. 1996. Integrat-
ing multiple knowledge sources to disambiguate
word sense: An examplar-based approach. In Pro-
ceedings of 34th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 40-47,
Santa Cruz, California.
Rada, Roy, Hafedh Mili, Ellen Bicknell, and Maria
Blettner. 1989. Development and application
ofa metric on semantic nets. IEEE Transaction
on Systems, Man, and Cybernetics, 19(1):17-30,
February.
Resnik, Philip. 1995a. Disambiguating noun group-
ings with respect to wordnet senses. In Third
Workshop on Very Large Corpora. Association for
Computational Linguistics.
Resnik, Philip. 1995b. Using information content
to evaluate semantic similarity in a taxonomy.
In Proceedings of IJCAI-95, pages 448-453, Mon-
treal, Canada, August.
Wu, Zhibia.o and Martha Palmer. 1994. Verb se-
mantics and lexical selection. In Proceedings of
the 32nd Annual Meeting of the Associations for
Computational Linguistics, pages 133-138, Las
Cruces, New Mexico.
Yarowsky, David. 1992. Word-sense disambigua-
tion using statistical models of Roget&apos;s cate-
gories trained on large corpora. In Proceedings
of COLING-92, Nantes, France.
Yarowsky, David. 1994. Decision lists for lexical am-
biguity resolution: Application to accent restora-
tion in spanish and french. In Proceedings of 32nd
Annual Meeting of the Association for Computa-
tional Linguistics, pages 88-95, Las Cruces, NM,
June.
Yarowsky, David. 1995. Unsupervised word sense
disambiguation rivaling supervised methods. In
Proceedings of 33rd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 189-
196, Cambridge, Massachusetts, June.
</reference>
<page confidence="0.999143">
71
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965314">
<title confidence="0.99587">Using Syntactic Dependency as Local Context to Resolve Word Sense Ambiguity</title>
<author confidence="0.999336">Dekang Lin</author>
<affiliation confidence="0.9998795">Department of Computer Science University of Manitoba</affiliation>
<address confidence="0.998591">Winnipeg, Manitoba, Canada R3T 2N2</address>
<email confidence="0.997744">lindekOcs.urnanitoba.ca</email>
<abstract confidence="0.998081416666667">Most previous corpus-based algorithms disambiguate a word with a classifier trained from previous usages of the same word. Separate classifiers have to be trained for different words. We present an algorithm that uses the same knowledge sources to disambiguate different words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>the condition in which the heart beats between 150 and 200 beats a minute The most frequent subjects of &amp;quot;beat&amp;quot; (according to our local context database) are the following:</title>
<marker></marker>
<rawString>(10) ... the condition in which the heart beats between 150 and 200 beats a minute The most frequent subjects of &amp;quot;beat&amp;quot; (according to our local context database) are the following:</rawString>
</citation>
<citation valid="false">
<authors>
<author>badge PER</author>
<author>bunch bidder</author>
<author>democrat challenger</author>
<author>Dewey</author>
</authors>
<note>grass, mummification, pimp, police, return, semi, and soldier.</note>
<marker>PER, bidder, challenger, Dewey, </marker>
<rawString>(11) PER, badge, bidder, bunch, challenger, democrat, Dewey, grass, mummification, pimp, police, return, semi, and soldier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Bruce</author>
<author>Janyce Wiebe</author>
</authors>
<title>Wordsense disambiguation using decomposable models.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics,</booktitle>
<pages>139--145</pages>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="1033" citStr="Bruce and Wiebe, 1994" startWordPosition="157" endWordPosition="160">ithm that uses the same knowledge sources to disambiguate different words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the followi</context>
</contexts>
<marker>Bruce, Wiebe, 1994</marker>
<rawString>Bruce, Rebecca and Janyce Wiebe. 1994. Wordsense disambiguation using decomposable models. In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics, pages 139-145, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
<author>S Lusignan</author>
</authors>
<title>Disambiguation by short contexts.</title>
<date>1985</date>
<booktitle>Computer and the Humanities,</booktitle>
<pages>19--147</pages>
<contexts>
<context position="5368" citStr="Choueka and Lusignan, 1985" startWordPosition="868" endWordPosition="872">ources of the algorithm include the following: (a) an untagged text corpus, (b) a broad-coverage parser, (c) a concept hierarchy, such as the WordNet (Miller, 1990) or Roget&apos;s Thesaurus, and (d) a similarity measure between concepts. In the next section, we introduce our definition of local contexts and the database of local contexts. A description of the disambiguation algorithm is presented in Section 3. Section 4 discusses the evaluation results. 2 Local Context Psychological experiments show that humans are able to resolve word sense ambiguities given a narrow window of surrounding words (Choueka and Lusignan, 1985). Most WSD algorithms take as input ito be defined in Section 3.1 a polysemous word and its local context. Different systems have different definitions of local contexts. In (Leacock, Towwell, and Voorhees, 1996), the local context of a word is an unordered set of words in the sentence containing the word and the preceding sentence. In (Ng and Lee. 1996), a local context of a word consists of an ordered sequence of 6 surrounding part-of-speech tags, its morphological features, and a set of collocations. In our approach, a local context of a word is defined in terms of the syntactic dependencie</context>
</contexts>
<marker>Choueka, Lusignan, 1985</marker>
<rawString>Choueka., Y. and S. Lusignan. 1985. Disambiguation by short contexts. Computer and the Humanities, 19:147-157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Joy A Thomas</author>
</authors>
<title>Elements of information theory. Wiley series in telecommunications.</title>
<date>1991</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="9955" citStr="Cover and Thomas, 1991" startWordPosition="1676" endWordPosition="1679"> between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a proposition that describes what A and B are. Assumption 3: The similarity between A and B, sim(A, B), is a function of their commonality and differences. That is, sim(A, B) = f (I (common(A, B)), I (describe(A, B))) The domain of f (x, y) is {(x , y)ix &gt; 0, y &gt; 0, y &gt; x}. Assumption 4: Similarity is independent of the unit used in the information measure. According to Information Theory (Cover and Thomas, 1991), /(s) = —log bP(s), where P(s) is the probability of s and b is the unit. When b = 2, /(s) is the number of bits needed to encode s. Since log bx =12412 , Assumption 4 means that the function f must satisfy the following condition: Vc &gt; 0, f(x, y) f (cx, Assumption 5: Similarity is additive with respect to commonality. If cornman(A, B) consists of two independent parts, then the sim(A, B) is the sum of the similarities computed when each part of the commonality is considered. In other words: f (xi + x2, y) = f(xi,y)+ f(x2,y). A corollary of Assumption 5 is that Vy, f(0, y) = f (x + 0, y) — f </context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>Cover, Thomas M. and Joy A. Thomas. 1991. Elements of information theory. Wiley series in telecommunications. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="4041" citStr="Dunning, 1993" startWordPosition="645" endWordPosition="647">e number of times these words were used as the subject of &amp;quot;employ&amp;quot;. 64 Table 1: Subjects of &amp;quot;employ&amp;quot; with highest likelihood ratio word freq logA word freq logA ORG 64 50.4 machine 3 6.56 plant 14 31.0 corporation 3 6.47 company 27 28.6 manufacturer 3 6.21 operation 8 23.0 insurance company 2 6.06 industry 9 14.6 aerospace 2 5.81 firm 8 13.5 memory device 1 5.79 pirate 2 12.1 department 3 5.55 unit 9 9.32 foreign office 1 5.41 shift 3 8.48 enterprise 2 5.39 postal service 2 7.73 pilot 2 5.37 ORG includes all proper names recognized as organizations The logA column are their likelihood ratios (Dunning, 1993). The meaning of &amp;quot;facility&amp;quot; in (3) can be determined by choosing one of its 5 senses that is most similar&apos; to the meanings of words in Table 1. This way, a polysemous word is disambiguated with past usages of other words. Whether or not it appears in the corpus is irrelevant. Our approach offers several advantages: • The same knowledge sources are used for all words, as opposed to using a separate classifier for each individual word. • It requires a much smaller corpus that needs not be sense-tagged. • It is able to deal with words that are infrequent or do not even appear in the corpus. • The</context>
<context position="7775" citStr="Dunning, 1993" startWordPosition="1289" endWordPosition="1290">(4) are as follows (the dependency relations between nouns and their determiners are ignored): Word Local Contexts boy (subj chase head) dog (adjn brown mod) (compl chase head) Using a broad coverage parser to parse a corpus, we construct a Local Context Database. An entry in the database is a pair: (6) (/c, C(/c)) where lc is a local context and C(lc) is a set of (word frequency likelihood)-triples. Each triple specifies how often word occurred in lc and the likelihood ratio of lc and word. The likelihood ratio is obtained by treating word and /c as a bigram and computed with the formula in (Dunning, 1993). The database entry corresponding to Table 1 is as follows: [ lc = (subj employ head) C(lc) = ((ORG 64 50.4) (plant 14 31.0) (pilot 2 5.37)) 3 The Approach The polysemous words in the input text are disambiguated in the following steps: Step A. Parse the input text and extract local contexts of each word. Let LC. denote the set of local contexts of all occurrences of w in the input text. Step B. Search the local context database and find words that appeared in an identical local context as w. They are called selectors of w: Selectors w= (H C(/c)) — {w}. Step C. Select a sense s of w that maxi</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, Ted. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61-74, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and the Humannities,</title>
<date>1992</date>
<pages>26--415</pages>
<contexts>
<context position="8598" citStr="Gale, Church, and Yarowsky, 1992" startWordPosition="1441" endWordPosition="1445">text are disambiguated in the following steps: Step A. Parse the input text and extract local contexts of each word. Let LC. denote the set of local contexts of all occurrences of w in the input text. Step B. Search the local context database and find words that appeared in an identical local context as w. They are called selectors of w: Selectors w= (H C(/c)) — {w}. Step C. Select a sense s of w that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption </context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, W., K. Church, and D. Yarowsky. 1992. A method for disambiguating word senses in a large corpus. Computers and the Humannities, 26:415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>noun homograph disambiguation using local context in large text corpora.</title>
<date>1991</date>
<booktitle>In Conference on Research and Development in Information Retrieval ACM/SIGIR,</booktitle>
<pages>36--47</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="1010" citStr="Hearst, 1991" startWordPosition="155" endWordPosition="156">esent an algorithm that uses the same knowledge sources to disambiguate different words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those al</context>
</contexts>
<marker>Hearst, 1991</marker>
<rawString>Hearst, Marti. 1991. noun homograph disambiguation using local context in large text corpora. In Conference on Research and Development in Information Retrieval ACM/SIGIR, pages 36-47, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Hudson</author>
</authors>
<title>Word Grammar.</title>
<date>1984</date>
<publisher>Basil Blackwell Publishers Limited.,</publisher>
<location>Oxford, England.</location>
<contexts>
<context position="6064" citStr="Hudson, 1984" startWordPosition="990" endWordPosition="991">and its local context. Different systems have different definitions of local contexts. In (Leacock, Towwell, and Voorhees, 1996), the local context of a word is an unordered set of words in the sentence containing the word and the preceding sentence. In (Ng and Lee. 1996), a local context of a word consists of an ordered sequence of 6 surrounding part-of-speech tags, its morphological features, and a set of collocations. In our approach, a local context of a word is defined in terms of the syntactic dependencies between the word and other words in the same sentence. A dependency relationship (Hudson, 1984; Mel&apos;euk, 1987) is an asymmetric binary relationship between a word called head (or governor, parent), and another word called modifier (or dependent, daughter). Dependency grammars represent sentence structures as a set of dependency relationships. Normally the dependency relationships form a tree that connects all the words in a sentence. An example dependency structure is shown in (4). corn (4) / spec subj sp the boy chased a brown dog The local context of a word W is a triple that corresponds to a dependency relationship in which W is the head or the modifier: (type word position) where t</context>
</contexts>
<marker>Hudson, 1984</marker>
<rawString>Hudson, Richard. 1984. Word Grammar. Basil Blackwell Publishers Limited., Oxford, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Goeffrey Towwell</author>
<author>Ellen M Voorhees</author>
</authors>
<title>Towards building contextual representations of word senses using statistical models.</title>
<date>1996</date>
<booktitle>In Corpus Processing for Lexical Acquisition. The MIT Press, chapter 6,</booktitle>
<pages>97--113</pages>
<contexts>
<context position="1071" citStr="Leacock, Towwell, and Voorhees, 1996" startWordPosition="161" endWordPosition="165"> knowledge sources to disambiguate different words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same wo</context>
<context position="5579" citStr="Leacock, Towwell, and Voorhees, 1996" startWordPosition="901" endWordPosition="905">arity measure between concepts. In the next section, we introduce our definition of local contexts and the database of local contexts. A description of the disambiguation algorithm is presented in Section 3. Section 4 discusses the evaluation results. 2 Local Context Psychological experiments show that humans are able to resolve word sense ambiguities given a narrow window of surrounding words (Choueka and Lusignan, 1985). Most WSD algorithms take as input ito be defined in Section 3.1 a polysemous word and its local context. Different systems have different definitions of local contexts. In (Leacock, Towwell, and Voorhees, 1996), the local context of a word is an unordered set of words in the sentence containing the word and the preceding sentence. In (Ng and Lee. 1996), a local context of a word consists of an ordered sequence of 6 surrounding part-of-speech tags, its morphological features, and a set of collocations. In our approach, a local context of a word is defined in terms of the syntactic dependencies between the word and other words in the same sentence. A dependency relationship (Hudson, 1984; Mel&apos;euk, 1987) is an asymmetric binary relationship between a word called head (or governor, parent), and another</context>
</contexts>
<marker>Leacock, Towwell, Voorhees, 1996</marker>
<rawString>Leacock, Claudia, Goeffrey Towwell, and Ellen M. Voorhees. 1996. Towards building contextual representations of word senses using statistical models. In Corpus Processing for Lexical Acquisition. The MIT Press, chapter 6, pages 97-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joon Ho Lee</author>
<author>Myoung Ho Kim</author>
<author>Yoon Joon Lee</author>
</authors>
<title>Information retrieval based on conceptual distance in is-a hierarchies.</title>
<date>1989</date>
<journal>Journal of Documentation,</journal>
<pages>49--2</pages>
<contexts>
<context position="8944" citStr="Lee, Kim, and Lee, 1989" startWordPosition="1498" endWordPosition="1502"> C(/c)) — {w}. Step C. Select a sense s of w that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1: The commonality between A and B is measured by I (common (A, B)) where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a pro</context>
</contexts>
<marker>Lee, Kim, Lee, 1989</marker>
<rawString>Lee, Joon Ho, Myoung Ho Kim, and Yoon Joon Lee. 1989. Information retrieval based on conceptual distance in is-a hierarchies. Journal of Documentation, 49(2):188-207, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaobin Li</author>
<author>Stan Szpakowicz</author>
<author>Stan Matwin</author>
</authors>
<title>A wordnet-based algorithm for word sense disambiguation.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI-95,</booktitle>
<pages>1368--1374</pages>
<location>Montreal, Canada,</location>
<marker>Li, Szpakowicz, Matwin, 1995</marker>
<rawString>Li, Xiaobin, Stan Szpakowicz, and Stan Matwin. 1995. A wordnet-based algorithm for word sense disambiguation. In Proceedings of IJCAI-95, pages 1368-1374, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mel&apos;euk</author>
</authors>
<title>Dependency syntax: theory and practice.</title>
<date>1987</date>
<publisher>State University of New York Press,</publisher>
<location>Albany.</location>
<contexts>
<context position="6080" citStr="Mel&apos;euk, 1987" startWordPosition="992" endWordPosition="993">context. Different systems have different definitions of local contexts. In (Leacock, Towwell, and Voorhees, 1996), the local context of a word is an unordered set of words in the sentence containing the word and the preceding sentence. In (Ng and Lee. 1996), a local context of a word consists of an ordered sequence of 6 surrounding part-of-speech tags, its morphological features, and a set of collocations. In our approach, a local context of a word is defined in terms of the syntactic dependencies between the word and other words in the same sentence. A dependency relationship (Hudson, 1984; Mel&apos;euk, 1987) is an asymmetric binary relationship between a word called head (or governor, parent), and another word called modifier (or dependent, daughter). Dependency grammars represent sentence structures as a set of dependency relationships. Normally the dependency relationships form a tree that connects all the words in a sentence. An example dependency structure is shown in (4). corn (4) / spec subj sp the boy chased a brown dog The local context of a word W is a triple that corresponds to a dependency relationship in which W is the head or the modifier: (type word position) where type is the type </context>
</contexts>
<marker>Mel&apos;euk, 1987</marker>
<rawString>Mel&apos;euk, Igor A. 1987. Dependency syntax: theory and practice. State University of New York Press, Albany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="3061" citStr="Miller, 1990" startWordPosition="478" endWordPosition="479">d from the previous usages of the same word means that whatever was learned for one word is not used on other words, which obviously missed generality in natural languages. Thirdly, these algorithms cannot deal with words for which classifiers have not been learned. In this paper, we present a WSD algorithm that relies on a different intuition: (2) Two different words are likely to have similar meanings if they occur in identical local contexts. Consider the sentence: (3) The new facility will employ 500 of the existing 600 employees The word &amp;quot;facility&amp;quot; has 5 possible meanings in WordNet 1.5 (Miller, 1990): (a) installation, (b) proficiency/technique, (c) adeptness, (d) readiness, (e) toilet/bathroom. To disambiguate the word, we consider other words that appeared in an identical local context as &amp;quot;facility&amp;quot; in (3). Table 1 is a list of words that have also been used as the subject of &amp;quot;employ&amp;quot; in a 25-million-word Wall Street Journal corpus. The &amp;quot;freq&amp;quot; column are the number of times these words were used as the subject of &amp;quot;employ&amp;quot;. 64 Table 1: Subjects of &amp;quot;employ&amp;quot; with highest likelihood ratio word freq logA word freq logA ORG 64 50.4 machine 3 6.56 plant 14 31.0 corporation 3 6.47 company 27 28</context>
<context position="4905" citStr="Miller, 1990" startWordPosition="798" endWordPosition="799">the corpus is irrelevant. Our approach offers several advantages: • The same knowledge sources are used for all words, as opposed to using a separate classifier for each individual word. • It requires a much smaller corpus that needs not be sense-tagged. • It is able to deal with words that are infrequent or do not even appear in the corpus. • The same mechanism can also be used to infer the semantic categories of unknown words. The required resources of the algorithm include the following: (a) an untagged text corpus, (b) a broad-coverage parser, (c) a concept hierarchy, such as the WordNet (Miller, 1990) or Roget&apos;s Thesaurus, and (d) a similarity measure between concepts. In the next section, we introduce our definition of local contexts and the database of local contexts. A description of the disambiguation algorithm is presented in Section 3. Section 4 discusses the evaluation results. 2 Local Context Psychological experiments show that humans are able to resolve word sense ambiguities given a narrow window of surrounding words (Choueka and Lusignan, 1985). Most WSD algorithms take as input ito be defined in Section 3.1 a polysemous word and its local context. Different systems have differe</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Miller, George A. 1990. WordNet: An on-line lexical database. International Journal of Lexicography, 3(4):235-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Martin Chodorow</author>
<author>Shari Landes</author>
<author>Claudia Leacock</author>
<author>robert G Thomas</author>
</authors>
<title>Using a semantic concordance for sense identification.</title>
<date>1994</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="12487" citStr="Miller et al., 1994" startWordPosition="2172" endWordPosition="2175">(x y) (due to Assumption 5). Thus. f (x, y) = ;-; f (nx, y). Substituting fi for x in this equation: = nf( y) = n f (x • ny) = n(741- f (mx • ny)) Since E is rational, there exist m and n such that = flym f (x, y) =f (7- = -f(1.1) = m fly in y Q.E.D. For example. Figure 1 is a fragment of the WordNet. The nodes are concepts (or synsets as they are called in the WordNet). The links represent IS-A relationships. The number attached to a node C is the probability P(C) that a randomly selected noun refers to an instance of C. The probabilities are estimated by the frequency of concepts in SemCor (Miller et al., 1994), a sense-tagged subset of the Brown corpus. If x is a Hill and y is a Coast, the commonality between x and p is that &amp;quot;x is a GeoForm and y is a GeoForm&amp;quot;. The information contained in this entfty 0.395 inanimar-object 0.167 inatural- bject 0.0163 geological-fo ation 0.00176 0.000113 natural-ilevation shlre 0.0000836 0.0000189 hill coast 0.0000216 Figure 1: A fragment of WordNet statement is —2 x logP(GeoF arm). The similarity between the concepts Hill and Coast is: 2 x logP(GeoForm) sim(Hill Coast) = log P(Hill) + log P(Coast) Generally speaking, 2xlogP(n, C.) (7) sim(c, ci) logP(C)-i-logP(C&apos;)</context>
<context position="16833" citStr="Miller et al., 1994" startWordPosition="2956" endWordPosition="2959">than other senses. Sense 1 is selected. Consider another example that involves an unknown proper name: (9) DreamLand employed 20 programmers. We treat unknown proper nouns as a polysemous word which could refer to a person, an organization, or a location. Since &amp;quot;DreamLand&amp;quot; is the subject of &amp;quot;employed&amp;quot;, its meaning is determined by maximizing the similarity between one of {person, organization, locaton} and the words in Table 1. Since Table 1 contains many &amp;quot;organization&amp;quot; words, the support for the &amp;quot;organization&amp;quot; sense is much higher than the others. 4 Evaluation We used a subset of the SemCor (Miller et al., 1994) to evaluate our algorithm. 68 4.1 Evaluation Criteria General-purpose lexical resources, such as WordNet, Longman Dictionary of Contemporary English (LDOCE), and Roget&apos;s Thesaurus, strive to achieve completeness. They often make subtle distinctions between word senses. As a result, when the WSD task is defined as choosing a sense out of a list of senses in a general-purpose lexical resource, even humans may frequently disagree with one another on what the correct sense should be. The subtle distinctions between different word senses are often unnecessary. Therefore, we relaxed the correctness</context>
</contexts>
<marker>Miller, Chodorow, Landes, Leacock, Thomas, 1994</marker>
<rawString>Miller, George A., Martin Chodorow, Shari Landes, Claudia Leacock, and robert G. Thomas. 1994. Using a semantic concordance for sense identification. In Proceedings of the ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tow Ng</author>
<author>Hian Beng Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach.</title>
<date>1996</date>
<booktitle>In Proceedings of 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<location>Santa Cruz, California.</location>
<contexts>
<context position="1089" citStr="Ng and Lee, 1996" startWordPosition="166" endWordPosition="169">ferent words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same word have identical </context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>Ng, Hwee Tow and Hian Beng Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach. In Proceedings of 34th Annual Meeting of the Association for Computational Linguistics, pages 40-47, Santa Cruz, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Rada</author>
<author>Hafedh Mili</author>
<author>Ellen Bicknell</author>
<author>Maria Blettner</author>
</authors>
<title>Development and application ofa metric on semantic nets.</title>
<date>1989</date>
<journal>IEEE Transaction on Systems, Man, and Cybernetics,</journal>
<pages>19--1</pages>
<contexts>
<context position="8963" citStr="Rada et al., 1989" startWordPosition="1503" endWordPosition="1506">lect a sense s of w that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1: The commonality between A and B is measured by I (common (A, B)) where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a proposition that descr</context>
</contexts>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Rada, Roy, Hafedh Mili, Ellen Bicknell, and Maria Blettner. 1989. Development and application ofa metric on semantic nets. IEEE Transaction on Systems, Man, and Cybernetics, 19(1):17-30, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Disambiguating noun groupings with respect to wordnet senses.</title>
<date>1995</date>
<booktitle>In Third Workshop on Very Large Corpora. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8977" citStr="Resnik, 1995" startWordPosition="1507" endWordPosition="1508"> that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1: The commonality between A and B is measured by I (common (A, B)) where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a proposition that describes what A an</context>
<context position="22636" citStr="Resnik, 1995" startWordPosition="3953" endWordPosition="3954">r, choosing the first sense is roughly the same as choosing the sense with highest prior probability, except that we are not using all the files in SemCor. It can be seen from Table 3 that our algorithm performed slightly worse than the baseline when the strictest correctness criterion is used. However, when the condition is relaxed, its performance gain is much lager than the baseline. This means that when the algorithm makes mistakes, the mistakes tend to be close to the correct answer. 5 Discussion 5.1 Related Work The Step C in Section 3.2 is similar to Resnik&apos;s noun group disambiguation (Resnik, 1995a), although he did not address the question of the creation of noun groups. The earlier work on WSD that is most similar to ours is (Li, Szpakowicz, and Matwin, 1995). They proposed a set of heuristic rules that are based on the idea that objects of the same or similar verbs are similar. 3http://www.ldc.upenn.edu/ 5.2 Weak Contexts Our algorithm treats all local contexts equally in its decision-making. However, some local contexts hardly provide any constraint on the meaning of a word. For example, the object of &amp;quot;get&amp;quot; can practically be anything. This type of contexts should be filtered out o</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, Philip. 1995a. Disambiguating noun groupings with respect to wordnet senses. In Third Workshop on Very Large Corpora. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI-95,</booktitle>
<pages>448--453</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="8977" citStr="Resnik, 1995" startWordPosition="1507" endWordPosition="1508"> that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1: The commonality between A and B is measured by I (common (A, B)) where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a proposition that describes what A an</context>
<context position="22636" citStr="Resnik, 1995" startWordPosition="3953" endWordPosition="3954">r, choosing the first sense is roughly the same as choosing the sense with highest prior probability, except that we are not using all the files in SemCor. It can be seen from Table 3 that our algorithm performed slightly worse than the baseline when the strictest correctness criterion is used. However, when the condition is relaxed, its performance gain is much lager than the baseline. This means that when the algorithm makes mistakes, the mistakes tend to be close to the correct answer. 5 Discussion 5.1 Related Work The Step C in Section 3.2 is similar to Resnik&apos;s noun group disambiguation (Resnik, 1995a), although he did not address the question of the creation of noun groups. The earlier work on WSD that is most similar to ours is (Li, Szpakowicz, and Matwin, 1995). They proposed a set of heuristic rules that are based on the idea that objects of the same or similar verbs are similar. 3http://www.ldc.upenn.edu/ 5.2 Weak Contexts Our algorithm treats all local contexts equally in its decision-making. However, some local contexts hardly provide any constraint on the meaning of a word. For example, the object of &amp;quot;get&amp;quot; can practically be anything. This type of contexts should be filtered out o</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, Philip. 1995b. Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of IJCAI-95, pages 448-453, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibia o Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="9000" citStr="Wu and Palmer, 1994" startWordPosition="1509" endWordPosition="1512"> the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1: The commonality between A and B is measured by I (common (A, B)) where cornmon(A, B) is a proposition that states the commonalities between A and B; /(s) is the amount of information contained in the proposition s. Assumption 2: The differences between A and B is measured by I (describe(A, B)) — I (common(A, B)) where describe(A, B) is a proposition that describes what A and B are. Assumption 3: </context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Zhibia.o and Martha Palmer. 1994. Verb semantics and lexical selection. In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics, pages 133-138, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING-92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="1105" citStr="Yarowsky, 1992" startWordPosition="170" endWordPosition="171">algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same word have identical meanings if they</context>
<context position="8599" citStr="Yarowsky, 1992" startWordPosition="1444" endWordPosition="1445">ated in the following steps: Step A. Parse the input text and extract local contexts of each word. Let LC. denote the set of local contexts of all occurrences of w in the input text. Step B. Search the local context database and find words that appeared in an identical local context as w. They are called selectors of w: Selectors w= (H C(/c)) — {w}. Step C. Select a sense s of w that maximizes the similarity between w and Selectors. Step D. The sense s is assigned to all occurrences of w in the input text. This implements the &amp;quot;one sense per discourse&amp;quot; heuristic advocated in (Gale, Church, and Yarowsky, 1992). Step C. needs further explanation. In the next subsection, we define the similarity between two word senses (or concepts). We then explain how the similarity between a word and its selectors is maximized. 3.1 Similarity between Two Concepts There have been several proposed measures for similarity between two concepts (Lee, Kim, and Lee, 1989; Rada et al., 1989; Resnik, 1995b; Wu and Palmer, 1994). All of those similarity measures are defined directly by a formula. We use instead an information-theoretic definition of similarity that can be derived from the following assumptions: Assumption 1</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>Yarowsky, David. 1992. Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora. In Proceedings of COLING-92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution: Application to accent restoration in spanish and french.</title>
<date>1994</date>
<booktitle>In Proceedings of 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--95</pages>
<location>Las Cruces, NM,</location>
<contexts>
<context position="1122" citStr="Yarowsky, 1994" startWordPosition="172" endWordPosition="173">ot require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same word have identical meanings if they have similar loc</context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>Yarowsky, David. 1994. Decision lists for lexical ambiguity resolution: Application to accent restoration in spanish and french. In Proceedings of 32nd Annual Meeting of the Association for Computational Linguistics, pages 88-95, Las Cruces, NM, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<location>Cambridge, Massachusetts,</location>
<contexts>
<context position="1251" citStr="Yarowsky, 1995" startWordPosition="188" endWordPosition="189"> in identical local contexts. 1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context. WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution. In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus. Yarowsky (Yarowsky, 1995) proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples. Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts. A basic intuition that underlies those algorithms is the following: (1) Two occurrences of the same word have identical meanings if they have similar local contexts. In other words, most previous corpus-based WSD algorithms learn to disambiguate a polysemous word from previous usag</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, David. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of 33rd Annual Meeting of the Association for Computational Linguistics, pages 189-196, Cambridge, Massachusetts, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>