<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001636">
<title confidence="0.979039">
Lsislif: CRF and Logistic Regression for Opinion Target Extraction and
Sentiment Polarity Analysis
</title>
<author confidence="0.998073">
Hussam Hamdan Patrice Bellot Frederic Bechet
</author>
<affiliation confidence="0.999455">
Aix-Marseille University Aix-Marseille University Aix-Marseille University
</affiliation>
<email confidence="0.995236">
hussam.hamdan@lsis.org patrice.bellot@lsis.org frederic.bechet@lif.univ-mrs.fr
</email>
<sectionHeader confidence="0.995602" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935388888889">
This paper describes our contribution in Opin-
ion Target Extraction OTE and Sentiment Po-
larity sub tasks of SemEval 2015 ABSA task.
A CRF model with IOB notation has been
adopted for OTE with several groups of fea-
tures including syntactic, lexical, semantic,
sentiment lexicon features. Our submission
for OTE is ranked fifth over twenty submis-
sions. A Logistic Regression model with a
weighting schema of positive and negative la-
bels have been used for sentiment polarity;
several groups of features (lexical, syntac-
tic, semantic, lexicon and Z score) are ex-
tracted. Our submission for Sentiment Polar-
ity is ranked third over ten submissions on the
restaurant data set, third over thirteen on the
laptops data set, but the first over eleven on
the hotel data set that is out-of-domain set.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999892553191489">
Sentiment Analysis (SA) has become more and
more interesting since the year 2000, many tech-
niques in Natural Language Processing have been
used to understand the expressed sentiment on an
entity.
Many levels of granularity have been also distin-
guished: Document Level SA considers the whole
document is about an entity and classifies whether
the expressed sentiment is positive, negative or neu-
tral; Sentence Level SA determines the sentiment of
each sentence, some papers have focused on Clause
Level SA, but they are still not enough; Entity or
Aspect-Based SA performs finer-grained analysis in
which all entities and their aspects should be ex-
tracted and the sentiment towards them should also
be determined.
Aspect-Based SA task consists of several sub-
problems, the document is about many entities
which could be for example a restaurant, a laptop,
a printer. Users may refer to an entity by different
writings, but normally there are not a lot of vari-
ations to indicate the same entity, each entity has
many aspects which could be its parts or attributes.
Some aspects could be another entity such as screen
of laptop, but most work did not take this case into
account. Therefore, we could define the opinion by
the quintuple (Liu, 2012) (ei, aij, sijkl, hk, tl) where
ei is the entity i, aij are the aspects of the entity i,
sijkl is the expressed sentiment on the aspect at the
time tl , hk the holder which created the document or
the text. This definition does not take into account
that the entity has aspects that could have also other
aspects which leads to an aspect hierarchy, in order
to avoid this information loss, few work has handled
this issue, they proposed to represent the aspect as a
tree of aspect terms.
In this paper, we focus on Opinion Target Extrac-
tion (OTE) and Sentiment Polarity towards a target
or a category. The description of each subtask is
provided by ABSA organizers (Pontiki et al., 2015).
For OTE or aspect term extraction, a CRF model is
proposed with IOB annotation and several groups of
features including syntactic, lexical, semantic, sen-
timent lexicon features. For aspect term polarity de-
tection, a logistic regression classifier is trained with
weighting schema for positive and negative labels
and several groups of features are extracted includ-
</bodyText>
<page confidence="0.996493">
753
</page>
<bodyText confidence="0.8817417">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 753–758,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
ing lexical, syntactic, semantic, lexicon and Z score
features.
The rest of this paper is organized as follows. Sec-
tion 2 outlines existing work in aspect extraction and
polarity detection. Section 3 describes our system
for aspect term extraction. Aspect term polarity de-
tection is presented in Section 4. Section 6 shows
the conclusion and the future work.
</bodyText>
<sectionHeader confidence="0.999757" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.994762675000001">
Aspect-Based Sentiment Analysis consists of sev-
eral sub tasks. Some papers have proposed different
methods for aspect detection and sentiment polarity
analysis, others have proposed joint models in or-
der to obtain the aspect and their sentiments from
the same model, these models are generally unsu-
pervised or semi-supervised.
The earliest work on aspect detection from on-
line reviews presented by Hu and Liu (Hu and Liu,
2004) that used association rule mining based on
Apriori algorithm to extract frequent noun phrases
as product features, for polarity detection they used
two seed sets of 30 positive and negative adjectives,
then WordNet has been used to find and add the syn-
onyms of the seed words. Infrequent features had
been processed by finding the noun related to an
opinionated word.
Opinion Digger (Moghaddam and Ester, 2010)
also used Apriori algorithm to extract the frequent
aspects. KNN algorithm is applied to estimate the
aspect rating scaling from 1 to 5 stands for (Excel-
lent, Good, Average, Poor, Terrible).
Supervised methods uses normally the CRF or
HMM models. Jin and Ho (Jin and Ho, 2009)
applied a lexicalized HMM model to extract as-
pects using the words and their part-of-speech tags
in order to learn a model, then unsupervised al-
gorithm for determining the aspect sentiment us-
ing the nearest opinion word to the aspect and tak-
ing into account the polarity reversal words (such
as not). A CRF model was used by Jakob and
Gurevych (Jakob and Gurevych, 2010) with the fol-
lowing features: tokens, POS tags, syntactic depen-
dency (if the aspect has a relation with the opinion-
ated word), word distance (the distance between the
word in the closest noun phrase and the opinion-
ated word), and opinion sentences (each token in the
sentence containing an opinionated expression is la-
beled by this feature), the input of this method is also
the opinionated expressions, they use these expres-
sions for predicting the aspect sentiment using the
dependency parsing for retrieving the pair aspect-
expression from the training set. A CRF model is
also used by (Hamdan et al., 2014b) with lexical and
POS features.
Unsupervised methods based on LDA (Latent
Dirichlet allocation) have been proposed. Brody and
Elhadad (Brody and Elhadad, 2010) used LDA to
figure ou the aspects, determined the number of top-
ics by applying a clustering method, then they used
a similar method proposed by Hatzivassiloglou and
McKeown (Hatzivassiloglou and McKeown, 1997)
to extract the conjunctive adjectives, but not the dis-
junctive due to the specificity of the domain, seed
sets were used and assigned scores, these scores
were propagated using propagation method through
the aspect-sentiment graph building from the pairs
of aspect and related adjectives. Lin and He (Lin
et al., 2012) proposed Joint model of Sentiment
and Topic (JST) which extends the state-of-the-art
topic model (LDA) by adding a sentiment layer, this
model is fully unsupervised and it can detect senti-
ment and topic simultaneously. Wei and Gulla (Wei
and Gulla, 2010) modeled the hierarchical relation
between product aspects. They defined Sentiment
Ontology Tree (SOT) to formulate the knowledge of
hierarchical relationships among product attributes
and tackled the problem of sentiment analysis as a
hierarchical classification problem. Unsupervised
hierarchical aspect Sentiment model (HASM) was
proposed by Kim et al (Kim et al., 3 07) to discover
a hierarchical structure of aspect-based sentiments
from unlabeled online reviews.
Aspect term polarity detection can be seen as a
sentence level sentiment analysis. Therefore, many
papers can be mentioned. Supervised methods have
been widely exploited for this purpose, a classi-
fication algorithms with a wise feature extraction
could achieve good results (Mohammad et al., 2013)
(Hamdan et al., 2015a) (Hamdan et al., 4 29).
</bodyText>
<sectionHeader confidence="0.990754" genericHeader="method">
3 Opinion Target Expression (OTE)
</sectionHeader>
<bodyText confidence="0.999155">
An opinion target expression (OTE) is an expres-
sion used in the given text to refer to an aspect or
</bodyText>
<page confidence="0.992658">
754
</page>
<bodyText confidence="0.999177058823529">
an aspect term related to the reviewed entity. The
objective of OTE slot is to extract all opinion tar-
get expressions in a restaurant review, OTE could
be a word or multiple words. For this purpose, we
have used CRF (Conditional Random Field) which
have proved its performance in information extrac-
tion. We choose the IOB notation for representing
each sentence in the review. Therefore, we distin-
guish the terms at the Beginning, the Inside and the
Outside of OTE. For example, for this review ”But
the staff was so horrible to us.” Where staff is OTE,
the target of each word will be:
But:O the:O staff:B was:O so:O horrible:O to:O
us:O.
We extract for each single word the following fea-
tures for the word itself and the 2 and 3 previous and
subsequent words, respectively.
-word lemma using WordNet.
-word POS using NLTK parser.
-word shape: the shape of each character in the word
(capital letter, small letter, digit, punctuation, other
symbol)
-word type: the type of the word (uppercase, digit,
symbol, combination)
-Named entity: the IOB annotation for the named
entity extracted from the review using Senna (Col-
lobert, 2011).
-chunk: the chunk of the word (NP, VP, PP) ex-
tracted using Senna.
-polarity: the sum of word polarity score calculated
using Bing Liu Lexicon (Hu and Liu, 2004) and
MPQA subjectivity Lexicon (Wilson et al., 2005).
-Prefixes (all prefixes having length between one to
four ).
-Suffixes (all suffixes having length between one to
four).
-Stop word: if the word is a stop word or not.
-if the initial letter is uppercase, if all letters are up-
percase, All letters lowercase, All letters digit, Con-
tains a uppercase letter, Contains a lowercase letter,
Contains a digit, Contains a alphabet letter, Contains
a symbol.
We also extract the value of each two successive fea-
tures in the the range -2,2 (the previous and subse-
quent two words of actual word) for the following
features:
word surface, word POS, word chunk, word shape,
word type.
Finally, we extract the value of each three successive
features in the the range -1,1 for the two features:
word POS and word lemma.
</bodyText>
<subsectionHeader confidence="0.975779">
3.1 Experiments
</subsectionHeader>
<bodyText confidence="0.997335555555556">
The data set is extracted from restaurant reviews,
provided by SemEval 2015 ABSA organizers
(Pontiki et al., 2015). Table 1 shows the training
and testing data sets statistics of restaurant reviews,
where each review is composed of several sentences
and each sentence may contain several OTE.
CRFsuite tool is used for this experiment with lbfgs
algorithm. This tool is fast in training and tagging
(Okazaki, 2007).
</bodyText>
<table confidence="0.998462">
Data Reviews Sentences OTE
Train 254 1315 1654
Test 96 685 845
</table>
<tableCaption confidence="0.9679855">
Table 1. Training and testing data sets for restaurant
OTE slot.
</tableCaption>
<bodyText confidence="0.999239333333333">
Our submission is ranked fifth with the F1 score
over twenty submissions with gain of 14% over the
baseline provided by the organizers. This baseline
uses the training reviews to create for each category
c a list of targets to which it is linked to. Then, given
a test sentence s and a category c, the baseline finds
the first occurrence in s of each target encountered
in cs list. Table 2 shows our system and the baseline
results.
</bodyText>
<table confidence="0.997134333333333">
Experiment Recall Precision F1 Score
Our System 0.55 0.72 0.62
Baseline - - 0.48
</table>
<tableCaption confidence="0.999802">
Table 2. The results of OTE slot.
</tableCaption>
<sectionHeader confidence="0.954919" genericHeader="method">
4 Sentiment Polarity
</sectionHeader>
<bodyText confidence="0.9999528">
For a given set of aspect terms within a sentence, we
determine whether the polarity of each aspect term is
positive, negative, neutral. For example, the system
should extract the polarity of fajitas and salads
in the following sentence: ”I hated their fajitas, but
their salads were great”, fajitas: negative and sal-
ads: positive.
This sub-task can be seen as sentence level or
phrase level sentiment Analysis. At the first step,
we detect the context of the aspect term or OTE,
</bodyText>
<page confidence="0.993323">
755
</page>
<bodyText confidence="0.99417364516129">
the context is the aspect term itself and all the
surrounding terms enclosed between two separators
like (,, ;, !), if another aspect term is also enclosed
by these separators we consider it as a separator
instead, and we do not take the terms after it or
before it (according to its direction to the current
aspect term). If the sentence has only an aspect term
the separators will be the beginning and the end of
the sentence.
For example, for this review ”It took half an hour to
get our check, which was perfect since we could sit,
have drinks and talk!” where we have two aspect
terms drinks and check, the context of check will
be ”It took half an hour to get our check” and the
context of drinks will be ”have drinks and talk!”.
Another example, ”All the money went into the
interior decoration, none of it went to the chefs.”.
The context for interior decoration will be ”All the
money went into the interior decoration” and the
context for chefs will be ”none of it went to the
chefs”.
At the second step, we should determine the polar-
ity, which could be positive, negative, neutral. We
propose to use a logistic regression classifier with
weighting schema of positive and negative labels
with the following features:
- Word n-grams Features
Unigrams and bigrams are extracted for each
word in the context without any stemming or
stop-word removing, all terms with occurrence less
than 3 are removed from the feature space.
</bodyText>
<subsectionHeader confidence="0.70607">
- Sentiment Lexicon-based Features
</subsectionHeader>
<bodyText confidence="0.996771066666667">
The system extracts four features from the man-
ual constructed lexicons (Bing Liu Lexicon (Hu and
Liu, 2004) and MPQA subjectivity Lexicon (Wilson
et al., 2005)) and six features from the automatic
ones (NRC Hashtag Sentiment Lexicon (Moham-
mad, 6 07), Sentiment140 Lexicon (Mohammad
et al., 2013), and SentiWordNet (Baccianella et al.,
2010)). For each context the number of positive
words, the number of negative ones, the number of
positive words divided by the number of negative
ones and the polarity of the last word are extracted
from manual constructed lexicons. In addition to
the sum of the positive scores and the sum of the
negative scores from the automatic constructed
lexicons.
</bodyText>
<sectionHeader confidence="0.663465" genericHeader="method">
- Negation Features
</sectionHeader>
<bodyText confidence="0.999920714285714">
The rule-based algorithm presented in Christo-
pher Potts Sentiment Symposium Tutorial is
implemented. This algorithm appends a negation
suffix to all words that appear within a negation
scope which is determined by the negation key and
a certain punctuation. All these words are added to
the feature space.
</bodyText>
<sectionHeader confidence="0.694954" genericHeader="method">
4- Z score Features
</sectionHeader>
<bodyText confidence="0.999718764705883">
Z score can distinguish the importance of each
term in each class, their performances have been
proved (Hamdan et al., 2014a). We assume as in
the mentioned work that the term frequencies are
following the multi-nomial distribution. Thus, Z
score can be seen as a standardization of the term
frequency using multi-nomial distribution. We com-
pute the Z score for each term ti in a class Cj (tij) by
calculating its term relative frequency tfrij in a par-
ticular class Cj, as well as the mean (meani) which
is the term probability over the whole corpus multi-
plied by nj the number of terms in the class Cj, and
standard deviation (sdi) of term ti according to the
underlying corpus (see Eq.1). We tested different
threshold for choosing the words which have higher
Z score, we found 3 is the best one for restaurant
data and 4 for laptop data.
</bodyText>
<equation confidence="0.934154333333333">
tfrij − meani
Zscore(ti) = (1)
sdi
</equation>
<bodyText confidence="0.999951333333333">
Thus, we added the number of words having Z score
higher than 3,4 in each class positive,negative and
neutral, the two classes which have the maximum
number and minimum numbers of words having Z
score higher than the threshold. These 5 features
have been added to the feature space.
</bodyText>
<subsectionHeader confidence="0.392414">
- Brown Cluster Features
</subsectionHeader>
<bodyText confidence="0.999596428571428">
Each word in the text is mapped to its cluster in
Brown clusters, 1000 features are added to feature
space where each feature represents the number
of words in the text mapped to each cluster. The
1000 clusters is provided in Twitter Word Clusters
of CMU ARK group which were constructed from
approximately 56 million tweets.
</bodyText>
<page confidence="0.996314">
756
</page>
<sectionHeader confidence="0.414145" genericHeader="method">
- Category Feature
</sectionHeader>
<bodyText confidence="0.9998265">
We also added the category of each OTE as a fea-
ture to the feature space.
</bodyText>
<subsectionHeader confidence="0.984662">
4.1 Experiments
</subsectionHeader>
<bodyText confidence="0.999753689655173">
In addition to the restaurant data set presented in
tabel 1, two other data sets statistics are presented
in table 3 (Laptops data which consists of training
and testing data sets while the Hotel test set is out
of domain set that was provided to test our model on
new domain without having training data).
We trained a L1-regularized Logistic regression
classifier implemented in LIBLINEAR, which has
given good results in several papers (Hamdan et al.,
2015b) (Hamdan et al., 2015a). The classifier is
trained on the training data set using the previous
features with the three polarities (positive, nega-
tive, and neutral) as labels. A weighting schema is
adapted for each class, we use the weighting option
-wi which enables a use of different cost parameter
C for different classes. Since the training data is un-
balanced, this weighting schema adjusts the proba-
bility of each label. Thus, we tuned the classifier in
adjusting the cost parameter C of Logistic Regres-
sion, weight wpos of positive class and weight wneg
of negative class.
We used the 1/10 of training data set for tuning
the three parameters in the two data sets (Restaurant,
Laptop), all combinations of C in range 0.1 to to 4
by step 0.1, wpos in range 1 to 8 by step 0.1, wneg in
range 1 to 8 by step 0.1 are tested. The combination
C=0.3, textitwpos=1.2, wneg=1.9 have been chosen
for the restaurant set and C=0.2 wpos=2.1 wneg=1.9
for the laptops set.
</bodyText>
<table confidence="0.998618">
Data Reviews Sentences OTE
Train Lap 277 1739 1973
Test Lap 173 761 949
Test hotel 30 266 339
</table>
<tableCaption confidence="0.940234">
Table 3. Data set statistics for Hotel and Laptops
Reviews.
</tableCaption>
<bodyText confidence="0.983882285714286">
Table 4 shows the results of our system on the three
data sets. It should note that we use the trained
classifier on restaurant data set for predicting the
polarity in the Hotel test set the out-of-domain set.
Our system outperforms the baseline over the three
data set. The gain is of 11.95%, 7.9%, 14.16% in
restaurant, laptop, hotel reviews respectively. The
baseline of Hotels is the majority baseline while
the other baselines are provide by the organizers
which use a trained SVM on the BOW features and
the category name feature in each data set. Our
system is ranked third over ten submissions in the
restaurant data set, third over thirteen in the laptops
set, and the first over eleven in the hotel set.
</bodyText>
<table confidence="0.9990638">
Experiment Correct All Accuracy
Restaurant
Our system 638 845 75.5
Baseline 537 845 63.55
Laptops
Our system 739 949 77.87
Baseline 664 949 69.97
Hotels
Our system 291 339 85.84
Baseline 243 339 71.68
</table>
<tableCaption confidence="0.980899">
Table 4. Results of sentiment polarity in Restaurant,
laptops, hotels reviews.
</tableCaption>
<sectionHeader confidence="0.958237" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.9999085">
We have built two systems for opinion target extrac-
tion of restaurant data set, and sentiment polarity
analysis for three data sets (restaurant and laptops)
and one out-of-domain set (hotel). We have used
supervised tagger for OTE, trained a CRF model
with several features. A Logistic regression classi-
fier is used for sentiment polarity where we adopted
a weighting schema in each domain and applied
the same classifier and weighting schema trained on
restaurant set on the Hotel test set. In future work,
we will focus on using parsing tree for determining
the context of OTE instead of the syntactic method.
And play with other types of features for the two
subtasks OTE and Sentiment Polarity.
</bodyText>
<sectionHeader confidence="0.996799" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.604293857142857">
Baccianella, S., Esuli, A., and Sebastiani, F. (2010). Sen-
tiWordNet 3.0: An enhanced lexical resource for sen-
timent analysis and opinion mining. In in Proc. of
LREC.
Brody, S. and Elhadad, N. (2010). An unsupervised
aspect-sentiment model for online reviews. In Human
Language Technologies: The 2010 Annual Conference
</reference>
<page confidence="0.991611">
757
</page>
<reference confidence="0.994835847619047">
of the North American Chapter of the Association for
Computational Linguistics, HLT ’10, pages 804–812.
Association for Computational Linguistics.
Collobert, R. (2011). Deep learning for efficient dis-
criminative parsing. In Gordon, G. J. and Dunson,
D. B., editors, Proceedings of the Fourteenth Interna-
tional Conference on Artificial Intelligence and Statis-
tics (AISTATS-11), volume 15, pages 224–232. Journal
of Machine Learning Research - Workshop and Con-
ference Proceedings.
Hamdan, H., Bechet, F., and Bellot, P. (2013-04-29). Ex-
periments with DBpedia, WordNet and SentiWordNet
as resources for sentiment analysis in micro-blogging.
In International Workshop on Semantic Evaluation
SemEval-2013 (NAACL Workshop).
Hamdan, H., Bellot, P., and Bechet, F. (2014a). The im-
pact of z score on twitter sentiment analysis. In In
Proceedings of the Eighth International Workshop on
Semantic Evaluation (SemEval 2014), page 636.
Hamdan, H., Bellot, P., and Bechet, F. (2014b). Super-
vised methods for aspect-based sentiment analysis. In
In Proceedings of the Eighth International Workshop
on Semantic Evaluation (SemEval 2014).
Hamdan, H., Bellot, P., and Bechet, F. (2015a). lsislif:
Feature extraction and label weighting for sentiment
analysis in twitter. In In Proceedings of the 9th Inter-
national Workshop on Semantic Evaluation (SemEval
2015).
Hamdan, H., Bellot, P., and Bechet, F. (2015b). Senti-
ment lexicon-based features for sentiment analysis in
short text. In In Proceeding of the 16th International
Conference on Intelligent Text Processing and Compu-
tational Linguistics.
Hatzivassiloglou, V. and McKeown, K. R. (1997). Pre-
dicting the semantic orientation of adjectives. In Pro-
ceedings of the Eighth Conference on European Chap-
ter of the Association for Computational Linguistics,
EACL ’97, pages 174–181. Association for Computa-
tional Linguistics.
Hu, M. and Liu, B. (2004). Mining and summariz-
ing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ’04, pages
168–177. ACM.
Jakob, N. and Gurevych, I. (2010). Extracting opinion
targets in a single- and cross-domain setting with con-
ditional random fields. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP ’10, pages 1035–1045.
Association for Computational Linguistics.
Jin, W. and Ho, H. H. (2009). A novel lexicalized HMM-
based learning framework for web opinion mining-
NOTE FROM ACM: A joint ACM conference com-
mittee has determined that the authors of this article vi-
olated ACM’s publication policy on simultaneous sub-
missions. therefore ACM has shut off access to this pa-
per. In Proceedings of the 26th Annual International
Conference on Machine Learning, ICML ’09, pages
465–472. ACM.
Kim, S., Zhang, J., Chen, Z., Oh, A., and Liu, S. (2013-
07). A hierarchical aspect-sentiment model for on-
line reviews. In Proceedings of The Twenty-Seventh
AAAI Conference on Artificial Intelligence (AAAI-13).
AAAI.
Lin, C., He, Y., Everson, R., and Ruger, S. (2012).
Weakly supervised joint sentiment-topic detection
from text. 24(6):1134–1145.
Liu, B. (2012). Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan &amp; Claypool Publishers.
Moghaddam, S. and Ester, M. (2010). Opinion dig-
ger: An unsupervised opinion miner from unstruc-
tured product reviews. In Proceedings of the 19th
ACM International Conference on Information and
Knowledge Management, CIKM ’10, pages 1825–
1828. ACM.
Mohammad, S. (2012-06-07). #emotional tweets. In
*SEM 2012: The First Joint Conference on Lexical
and Computational Semantics Volume 1: Proceedings
of the main conference and the shared task, and Vol-
ume 2: Proceedings of the Sixth International Work-
shop on Semantic Evaluation (SemEval 2012), pages
246–255. Association for Computational Linguistics.
Mohammad, S. M., Kiritchenko, S., and Zhu, X. (2013).
NRCCanada: Building the state-of-the-art in senti-
ment analysis of tweets. In In Proceedings of the Inter-
national Workshop on Semantic Evaluation, SemEval
13.
Okazaki, N. (2007). CRFsuite: a fast implementation of
Conditional Random Fields (CRFs).
Pontiki, M., Galanis, D., Papageogiou, H., Manandhar,
S., and Androutsopoulos, I. (2015). SemEval-2015
task 12: Aspect based sentiment analysis. In In Pro-
ceedings of the 9th International Workshop on Seman-
tic Evaluation (SemEval 2015).
Wei, W. and Gulla, J. A. (2010). Sentiment learning on
product reviews via sentiment ontology tree. In In
Proceedings of the 48th Annual Meeting of the ACL,
pages 404–413. ACL.
Wilson, T., Hoffmann, P., Somasundaran, S., Kessler, J.,
Wiebe, J., Choi, Y., Cardie, C., Riloff, E., and Patward-
han, S. (2005). OpinionFinder: A system for subjec-
tivity analysis. In Proceedings of HLT/EMNLP on In-
teractive Demonstrations, HLT-Demo ’05, pages 34–
35. Association for Computational Linguistics.
</reference>
<page confidence="0.99712">
758
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.830530">
<title confidence="0.998992">Lsislif: CRF and Logistic Regression for Opinion Target Extraction Sentiment Polarity Analysis</title>
<author confidence="0.995993">Hussam Hamdan Patrice Bellot Frederic Bechet</author>
<affiliation confidence="0.99932">Aix-Marseille University Aix-Marseille University Aix-Marseille University</affiliation>
<email confidence="0.845282">hussam.hamdan@lsis.orgpatrice.bellot@lsis.orgfrederic.bechet@lif.univ-mrs.fr</email>
<abstract confidence="0.999350052631579">This paper describes our contribution in Opinion Target Extraction OTE and Sentiment Polarity sub tasks of SemEval 2015 ABSA task. A CRF model with IOB notation has been adopted for OTE with several groups of features including syntactic, lexical, semantic, sentiment lexicon features. Our submission for OTE is ranked fifth over twenty submissions. A Logistic Regression model with a weighting schema of positive and negative labels have been used for sentiment polarity; several groups of features (lexical, syntactic, semantic, lexicon and Z score) are extracted. Our submission for Sentiment Polarity is ranked third over ten submissions on the restaurant data set, third over thirteen on the laptops data set, but the first over eleven on the hotel data set that is out-of-domain set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Baccianella</author>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In</title>
<date>2010</date>
<booktitle>in Proc. of LREC.</booktitle>
<contexts>
<context position="13484" citStr="Baccianella et al., 2010" startWordPosition="2217" endWordPosition="2220">egative labels with the following features: - Word n-grams Features Unigrams and bigrams are extracted for each word in the context without any stemming or stop-word removing, all terms with occurrence less than 3 are removed from the feature space. - Sentiment Lexicon-based Features The system extracts four features from the manual constructed lexicons (Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005)) and six features from the automatic ones (NRC Hashtag Sentiment Lexicon (Mohammad, 6 07), Sentiment140 Lexicon (Mohammad et al., 2013), and SentiWordNet (Baccianella et al., 2010)). For each context the number of positive words, the number of negative ones, the number of positive words divided by the number of negative ones and the polarity of the last word are extracted from manual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Features The rule-based algorithm presented in Christopher Potts Sentiment Symposium Tutorial is implemented. This algorithm appends a negation suffix to all words that appear within a negation scope which is determined by the negation ke</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Baccianella, S., Esuli, A., and Sebastiani, F. (2010). SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In in Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brody</author>
<author>N Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>804--812</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6224" citStr="Brody and Elhadad, 2010" startWordPosition="1001" endWordPosition="1004"> distance between the word in the closest noun phrase and the opinionated word), and opinion sentences (each token in the sentence containing an opinionated expression is labeled by this feature), the input of this method is also the opinionated expressions, they use these expressions for predicting the aspect sentiment using the dependency parsing for retrieving the pair aspectexpression from the training set. A CRF model is also used by (Hamdan et al., 2014b) with lexical and POS features. Unsupervised methods based on LDA (Latent Dirichlet allocation) have been proposed. Brody and Elhadad (Brody and Elhadad, 2010) used LDA to figure ou the aspects, determined the number of topics by applying a clustering method, then they used a similar method proposed by Hatzivassiloglou and McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment graph building from the pairs of aspect and related adjectives. Lin and He (Lin et al., 2012) proposed Joint model of Sentiment and Topic (JST) which extends the st</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Brody, S. and Elhadad, N. (2010). An unsupervised aspect-sentiment model for online reviews. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 804–812. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
</authors>
<title>Deep learning for efficient discriminative parsing.</title>
<date>2011</date>
<booktitle>Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS-11),</booktitle>
<volume>15</volume>
<pages>224--232</pages>
<editor>In Gordon, G. J. and Dunson, D. B., editors,</editor>
<contexts>
<context position="9092" citStr="Collobert, 2011" startWordPosition="1463" endWordPosition="1465">horrible to us.” Where staff is OTE, the target of each word will be: But:O the:O staff:B was:O so:O horrible:O to:O us:O. We extract for each single word the following features for the word itself and the 2 and 3 previous and subsequent words, respectively. -word lemma using WordNet. -word POS using NLTK parser. -word shape: the shape of each character in the word (capital letter, small letter, digit, punctuation, other symbol) -word type: the type of the word (uppercase, digit, symbol, combination) -Named entity: the IOB annotation for the named entity extracted from the review using Senna (Collobert, 2011). -chunk: the chunk of the word (NP, VP, PP) extracted using Senna. -polarity: the sum of word polarity score calculated using Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005). -Prefixes (all prefixes having length between one to four ). -Suffixes (all suffixes having length between one to four). -Stop word: if the word is a stop word or not. -if the initial letter is uppercase, if all letters are uppercase, All letters lowercase, All letters digit, Contains a uppercase letter, Contains a lowercase letter, Contains a digit, Contains a alphabet letter, Con</context>
</contexts>
<marker>Collobert, 2011</marker>
<rawString>Collobert, R. (2011). Deep learning for efficient discriminative parsing. In Gordon, G. J. and Dunson, D. B., editors, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS-11), volume 15, pages 224–232. Journal of Machine Learning Research - Workshop and Conference Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hamdan</author>
<author>F Bechet</author>
<author>P Bellot</author>
</authors>
<title>Experiments with DBpedia, WordNet and SentiWordNet as resources for sentiment analysis in micro-blogging.</title>
<date>2013</date>
<booktitle>In International Workshop on Semantic Evaluation SemEval-2013 (NAACL Workshop).</booktitle>
<marker>Hamdan, Bechet, Bellot, 2013</marker>
<rawString>Hamdan, H., Bechet, F., and Bellot, P. (2013-04-29). Experiments with DBpedia, WordNet and SentiWordNet as resources for sentiment analysis in micro-blogging. In International Workshop on Semantic Evaluation SemEval-2013 (NAACL Workshop).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hamdan</author>
<author>P Bellot</author>
<author>F Bechet</author>
</authors>
<title>The impact of z score on twitter sentiment analysis.</title>
<date>2014</date>
<booktitle>In In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<pages>636</pages>
<contexts>
<context position="6063" citStr="Hamdan et al., 2014" startWordPosition="978" endWordPosition="981">vych, 2010) with the following features: tokens, POS tags, syntactic dependency (if the aspect has a relation with the opinionated word), word distance (the distance between the word in the closest noun phrase and the opinionated word), and opinion sentences (each token in the sentence containing an opinionated expression is labeled by this feature), the input of this method is also the opinionated expressions, they use these expressions for predicting the aspect sentiment using the dependency parsing for retrieving the pair aspectexpression from the training set. A CRF model is also used by (Hamdan et al., 2014b) with lexical and POS features. Unsupervised methods based on LDA (Latent Dirichlet allocation) have been proposed. Brody and Elhadad (Brody and Elhadad, 2010) used LDA to figure ou the aspects, determined the number of topics by applying a clustering method, then they used a similar method proposed by Hatzivassiloglou and McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment gra</context>
<context position="14304" citStr="Hamdan et al., 2014" startWordPosition="2352" endWordPosition="2355">anual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Features The rule-based algorithm presented in Christopher Potts Sentiment Symposium Tutorial is implemented. This algorithm appends a negation suffix to all words that appear within a negation scope which is determined by the negation key and a certain punctuation. All these words are added to the feature space. 4- Z score Features Z score can distinguish the importance of each term in each class, their performances have been proved (Hamdan et al., 2014a). We assume as in the mentioned work that the term frequencies are following the multi-nomial distribution. Thus, Z score can be seen as a standardization of the term frequency using multi-nomial distribution. We compute the Z score for each term ti in a class Cj (tij) by calculating its term relative frequency tfrij in a particular class Cj, as well as the mean (meani) which is the term probability over the whole corpus multiplied by nj the number of terms in the class Cj, and standard deviation (sdi) of term ti according to the underlying corpus (see Eq.1). We tested different threshold fo</context>
</contexts>
<marker>Hamdan, Bellot, Bechet, 2014</marker>
<rawString>Hamdan, H., Bellot, P., and Bechet, F. (2014a). The impact of z score on twitter sentiment analysis. In In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014), page 636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hamdan</author>
<author>P Bellot</author>
<author>F Bechet</author>
</authors>
<title>Supervised methods for aspect-based sentiment analysis.</title>
<date>2014</date>
<booktitle>In In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="6063" citStr="Hamdan et al., 2014" startWordPosition="978" endWordPosition="981">vych, 2010) with the following features: tokens, POS tags, syntactic dependency (if the aspect has a relation with the opinionated word), word distance (the distance between the word in the closest noun phrase and the opinionated word), and opinion sentences (each token in the sentence containing an opinionated expression is labeled by this feature), the input of this method is also the opinionated expressions, they use these expressions for predicting the aspect sentiment using the dependency parsing for retrieving the pair aspectexpression from the training set. A CRF model is also used by (Hamdan et al., 2014b) with lexical and POS features. Unsupervised methods based on LDA (Latent Dirichlet allocation) have been proposed. Brody and Elhadad (Brody and Elhadad, 2010) used LDA to figure ou the aspects, determined the number of topics by applying a clustering method, then they used a similar method proposed by Hatzivassiloglou and McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment gra</context>
<context position="14304" citStr="Hamdan et al., 2014" startWordPosition="2352" endWordPosition="2355">anual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Features The rule-based algorithm presented in Christopher Potts Sentiment Symposium Tutorial is implemented. This algorithm appends a negation suffix to all words that appear within a negation scope which is determined by the negation key and a certain punctuation. All these words are added to the feature space. 4- Z score Features Z score can distinguish the importance of each term in each class, their performances have been proved (Hamdan et al., 2014a). We assume as in the mentioned work that the term frequencies are following the multi-nomial distribution. Thus, Z score can be seen as a standardization of the term frequency using multi-nomial distribution. We compute the Z score for each term ti in a class Cj (tij) by calculating its term relative frequency tfrij in a particular class Cj, as well as the mean (meani) which is the term probability over the whole corpus multiplied by nj the number of terms in the class Cj, and standard deviation (sdi) of term ti according to the underlying corpus (see Eq.1). We tested different threshold fo</context>
</contexts>
<marker>Hamdan, Bellot, Bechet, 2014</marker>
<rawString>Hamdan, H., Bellot, P., and Bechet, F. (2014b). Supervised methods for aspect-based sentiment analysis. In In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hamdan</author>
<author>P Bellot</author>
<author>F Bechet</author>
</authors>
<title>lsislif: Feature extraction and label weighting for sentiment analysis in twitter. In</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="7795" citStr="Hamdan et al., 2015" startWordPosition="1239" endWordPosition="1242">oduct attributes and tackled the problem of sentiment analysis as a hierarchical classification problem. Unsupervised hierarchical aspect Sentiment model (HASM) was proposed by Kim et al (Kim et al., 3 07) to discover a hierarchical structure of aspect-based sentiments from unlabeled online reviews. Aspect term polarity detection can be seen as a sentence level sentiment analysis. Therefore, many papers can be mentioned. Supervised methods have been widely exploited for this purpose, a classification algorithms with a wise feature extraction could achieve good results (Mohammad et al., 2013) (Hamdan et al., 2015a) (Hamdan et al., 4 29). 3 Opinion Target Expression (OTE) An opinion target expression (OTE) is an expression used in the given text to refer to an aspect or 754 an aspect term related to the reviewed entity. The objective of OTE slot is to extract all opinion target expressions in a restaurant review, OTE could be a word or multiple words. For this purpose, we have used CRF (Conditional Random Field) which have proved its performance in information extraction. We choose the IOB notation for representing each sentence in the review. Therefore, we distinguish the terms at the Beginning, the I</context>
<context position="16263" citStr="Hamdan et al., 2015" startWordPosition="2696" endWordPosition="2699">structed from approximately 56 million tweets. 756 - Category Feature We also added the category of each OTE as a feature to the feature space. 4.1 Experiments In addition to the restaurant data set presented in tabel 1, two other data sets statistics are presented in table 3 (Laptops data which consists of training and testing data sets while the Hotel test set is out of domain set that was provided to test our model on new domain without having training data). We trained a L1-regularized Logistic regression classifier implemented in LIBLINEAR, which has given good results in several papers (Hamdan et al., 2015b) (Hamdan et al., 2015a). The classifier is trained on the training data set using the previous features with the three polarities (positive, negative, and neutral) as labels. A weighting schema is adapted for each class, we use the weighting option -wi which enables a use of different cost parameter C for different classes. Since the training data is unbalanced, this weighting schema adjusts the probability of each label. Thus, we tuned the classifier in adjusting the cost parameter C of Logistic Regression, weight wpos of positive class and weight wneg of negative class. We used the 1/10 of</context>
</contexts>
<marker>Hamdan, Bellot, Bechet, 2015</marker>
<rawString>Hamdan, H., Bellot, P., and Bechet, F. (2015a). lsislif: Feature extraction and label weighting for sentiment analysis in twitter. In In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hamdan</author>
<author>P Bellot</author>
<author>F Bechet</author>
</authors>
<title>Sentiment lexicon-based features for sentiment analysis in short text.</title>
<date>2015</date>
<booktitle>In In Proceeding of the 16th International Conference on Intelligent Text Processing and Computational Linguistics.</booktitle>
<contexts>
<context position="7795" citStr="Hamdan et al., 2015" startWordPosition="1239" endWordPosition="1242">oduct attributes and tackled the problem of sentiment analysis as a hierarchical classification problem. Unsupervised hierarchical aspect Sentiment model (HASM) was proposed by Kim et al (Kim et al., 3 07) to discover a hierarchical structure of aspect-based sentiments from unlabeled online reviews. Aspect term polarity detection can be seen as a sentence level sentiment analysis. Therefore, many papers can be mentioned. Supervised methods have been widely exploited for this purpose, a classification algorithms with a wise feature extraction could achieve good results (Mohammad et al., 2013) (Hamdan et al., 2015a) (Hamdan et al., 4 29). 3 Opinion Target Expression (OTE) An opinion target expression (OTE) is an expression used in the given text to refer to an aspect or 754 an aspect term related to the reviewed entity. The objective of OTE slot is to extract all opinion target expressions in a restaurant review, OTE could be a word or multiple words. For this purpose, we have used CRF (Conditional Random Field) which have proved its performance in information extraction. We choose the IOB notation for representing each sentence in the review. Therefore, we distinguish the terms at the Beginning, the I</context>
<context position="16263" citStr="Hamdan et al., 2015" startWordPosition="2696" endWordPosition="2699">structed from approximately 56 million tweets. 756 - Category Feature We also added the category of each OTE as a feature to the feature space. 4.1 Experiments In addition to the restaurant data set presented in tabel 1, two other data sets statistics are presented in table 3 (Laptops data which consists of training and testing data sets while the Hotel test set is out of domain set that was provided to test our model on new domain without having training data). We trained a L1-regularized Logistic regression classifier implemented in LIBLINEAR, which has given good results in several papers (Hamdan et al., 2015b) (Hamdan et al., 2015a). The classifier is trained on the training data set using the previous features with the three polarities (positive, negative, and neutral) as labels. A weighting schema is adapted for each class, we use the weighting option -wi which enables a use of different cost parameter C for different classes. Since the training data is unbalanced, this weighting schema adjusts the probability of each label. Thus, we tuned the classifier in adjusting the cost parameter C of Logistic Regression, weight wpos of positive class and weight wneg of negative class. We used the 1/10 of</context>
</contexts>
<marker>Hamdan, Bellot, Bechet, 2015</marker>
<rawString>Hamdan, H., Bellot, P., and Bechet, F. (2015b). Sentiment lexicon-based features for sentiment analysis in short text. In In Proceeding of the 16th International Conference on Intelligent Text Processing and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Eighth Conference on European Chapter of the Association for Computational Linguistics, EACL ’97,</booktitle>
<pages>174--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6434" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="1034" endWordPosition="1037">e input of this method is also the opinionated expressions, they use these expressions for predicting the aspect sentiment using the dependency parsing for retrieving the pair aspectexpression from the training set. A CRF model is also used by (Hamdan et al., 2014b) with lexical and POS features. Unsupervised methods based on LDA (Latent Dirichlet allocation) have been proposed. Brody and Elhadad (Brody and Elhadad, 2010) used LDA to figure ou the aspects, determined the number of topics by applying a clustering method, then they used a similar method proposed by Hatzivassiloglou and McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment graph building from the pairs of aspect and related adjectives. Lin and He (Lin et al., 2012) proposed Joint model of Sentiment and Topic (JST) which extends the state-of-the-art topic model (LDA) by adding a sentiment layer, this model is fully unsupervised and it can detect sentiment and topic simultaneously. Wei and Gulla (Wei and Gulla, 2010) modeled the hierarchical </context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Hatzivassiloglou, V. and McKeown, K. R. (1997). Predicting the semantic orientation of adjectives. In Proceedings of the Eighth Conference on European Chapter of the Association for Computational Linguistics, EACL ’97, pages 174–181. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4396" citStr="Hu and Liu, 2004" startWordPosition="697" endWordPosition="700">tion. Section 3 describes our system for aspect term extraction. Aspect term polarity detection is presented in Section 4. Section 6 shows the conclusion and the future work. 2 Related Work Aspect-Based Sentiment Analysis consists of several sub tasks. Some papers have proposed different methods for aspect detection and sentiment polarity analysis, others have proposed joint models in order to obtain the aspect and their sentiments from the same model, these models are generally unsupervised or semi-supervised. The earliest work on aspect detection from online reviews presented by Hu and Liu (Hu and Liu, 2004) that used association rule mining based on Apriori algorithm to extract frequent noun phrases as product features, for polarity detection they used two seed sets of 30 positive and negative adjectives, then WordNet has been used to find and add the synonyms of the seed words. Infrequent features had been processed by finding the noun related to an opinionated word. Opinion Digger (Moghaddam and Ester, 2010) also used Apriori algorithm to extract the frequent aspects. KNN algorithm is applied to estimate the aspect rating scaling from 1 to 5 stands for (Excellent, Good, Average, Poor, Terrible</context>
<context position="9254" citStr="Hu and Liu, 2004" startWordPosition="1491" endWordPosition="1494">llowing features for the word itself and the 2 and 3 previous and subsequent words, respectively. -word lemma using WordNet. -word POS using NLTK parser. -word shape: the shape of each character in the word (capital letter, small letter, digit, punctuation, other symbol) -word type: the type of the word (uppercase, digit, symbol, combination) -Named entity: the IOB annotation for the named entity extracted from the review using Senna (Collobert, 2011). -chunk: the chunk of the word (NP, VP, PP) extracted using Senna. -polarity: the sum of word polarity score calculated using Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005). -Prefixes (all prefixes having length between one to four ). -Suffixes (all suffixes having length between one to four). -Stop word: if the word is a stop word or not. -if the initial letter is uppercase, if all letters are uppercase, All letters lowercase, All letters digit, Contains a uppercase letter, Contains a lowercase letter, Contains a digit, Contains a alphabet letter, Contains a symbol. We also extract the value of each two successive features in the the range -2,2 (the previous and subsequent two words of actual word) for the fol</context>
<context position="13251" citStr="Hu and Liu, 2004" startWordPosition="2182" endWordPosition="2185">l be ”none of it went to the chefs”. At the second step, we should determine the polarity, which could be positive, negative, neutral. We propose to use a logistic regression classifier with weighting schema of positive and negative labels with the following features: - Word n-grams Features Unigrams and bigrams are extracted for each word in the context without any stemming or stop-word removing, all terms with occurrence less than 3 are removed from the feature space. - Sentiment Lexicon-based Features The system extracts four features from the manual constructed lexicons (Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005)) and six features from the automatic ones (NRC Hashtag Sentiment Lexicon (Mohammad, 6 07), Sentiment140 Lexicon (Mohammad et al., 2013), and SentiWordNet (Baccianella et al., 2010)). For each context the number of positive words, the number of negative ones, the number of positive words divided by the number of negative ones and the polarity of the last word are extracted from manual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Featu</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Hu, M. and Liu, B. (2004). Mining and summarizing customer reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04, pages 168–177. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Jakob</author>
<author>I Gurevych</author>
</authors>
<title>Extracting opinion targets in a single- and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>1035--1045</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5455" citStr="Jakob and Gurevych, 2010" startWordPosition="876" endWordPosition="879">rithm to extract the frequent aspects. KNN algorithm is applied to estimate the aspect rating scaling from 1 to 5 stands for (Excellent, Good, Average, Poor, Terrible). Supervised methods uses normally the CRF or HMM models. Jin and Ho (Jin and Ho, 2009) applied a lexicalized HMM model to extract aspects using the words and their part-of-speech tags in order to learn a model, then unsupervised algorithm for determining the aspect sentiment using the nearest opinion word to the aspect and taking into account the polarity reversal words (such as not). A CRF model was used by Jakob and Gurevych (Jakob and Gurevych, 2010) with the following features: tokens, POS tags, syntactic dependency (if the aspect has a relation with the opinionated word), word distance (the distance between the word in the closest noun phrase and the opinionated word), and opinion sentences (each token in the sentence containing an opinionated expression is labeled by this feature), the input of this method is also the opinionated expressions, they use these expressions for predicting the aspect sentiment using the dependency parsing for retrieving the pair aspectexpression from the training set. A CRF model is also used by (Hamdan et a</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Jakob, N. and Gurevych, I. (2010). Extracting opinion targets in a single- and cross-domain setting with conditional random fields. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 1035–1045. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W Jin</author>
<author>H H Ho</author>
</authors>
<title>A novel lexicalized HMMbased learning framework for web opinion miningNOTE FROM ACM: A joint ACM conference committee has determined that the authors of this article violated ACM’s publication policy on simultaneous submissions. therefore ACM has shut off access to this paper.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09,</booktitle>
<pages>465--472</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5084" citStr="Jin and Ho, 2009" startWordPosition="811" endWordPosition="814">t frequent noun phrases as product features, for polarity detection they used two seed sets of 30 positive and negative adjectives, then WordNet has been used to find and add the synonyms of the seed words. Infrequent features had been processed by finding the noun related to an opinionated word. Opinion Digger (Moghaddam and Ester, 2010) also used Apriori algorithm to extract the frequent aspects. KNN algorithm is applied to estimate the aspect rating scaling from 1 to 5 stands for (Excellent, Good, Average, Poor, Terrible). Supervised methods uses normally the CRF or HMM models. Jin and Ho (Jin and Ho, 2009) applied a lexicalized HMM model to extract aspects using the words and their part-of-speech tags in order to learn a model, then unsupervised algorithm for determining the aspect sentiment using the nearest opinion word to the aspect and taking into account the polarity reversal words (such as not). A CRF model was used by Jakob and Gurevych (Jakob and Gurevych, 2010) with the following features: tokens, POS tags, syntactic dependency (if the aspect has a relation with the opinionated word), word distance (the distance between the word in the closest noun phrase and the opinionated word), and</context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Jin, W. and Ho, H. H. (2009). A novel lexicalized HMMbased learning framework for web opinion miningNOTE FROM ACM: A joint ACM conference committee has determined that the authors of this article violated ACM’s publication policy on simultaneous submissions. therefore ACM has shut off access to this paper. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09, pages 465–472. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>J Zhang</author>
<author>Z Chen</author>
<author>A Oh</author>
<author>S Liu</author>
</authors>
<title>A hierarchical aspect-sentiment model for online reviews.</title>
<date>2013</date>
<booktitle>In Proceedings of The Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13).</booktitle>
<publisher>AAAI.</publisher>
<marker>Kim, Zhang, Chen, Oh, Liu, 2013</marker>
<rawString>Kim, S., Zhang, J., Chen, Z., Oh, A., and Liu, S. (2013-07). A hierarchical aspect-sentiment model for online reviews. In Proceedings of The Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13). AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>Y He</author>
<author>R Everson</author>
<author>S Ruger</author>
</authors>
<title>Weakly supervised joint sentiment-topic detection from text.</title>
<date>2012</date>
<pages>24--6</pages>
<contexts>
<context position="6753" citStr="Lin et al., 2012" startWordPosition="1085" endWordPosition="1088">nt Dirichlet allocation) have been proposed. Brody and Elhadad (Brody and Elhadad, 2010) used LDA to figure ou the aspects, determined the number of topics by applying a clustering method, then they used a similar method proposed by Hatzivassiloglou and McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment graph building from the pairs of aspect and related adjectives. Lin and He (Lin et al., 2012) proposed Joint model of Sentiment and Topic (JST) which extends the state-of-the-art topic model (LDA) by adding a sentiment layer, this model is fully unsupervised and it can detect sentiment and topic simultaneously. Wei and Gulla (Wei and Gulla, 2010) modeled the hierarchical relation between product aspects. They defined Sentiment Ontology Tree (SOT) to formulate the knowledge of hierarchical relationships among product attributes and tackled the problem of sentiment analysis as a hierarchical classification problem. Unsupervised hierarchical aspect Sentiment model (HASM) was proposed by </context>
</contexts>
<marker>Lin, He, Everson, Ruger, 2012</marker>
<rawString>Lin, C., He, Y., Everson, R., and Ruger, S. (2012). Weakly supervised joint sentiment-topic detection from text. 24(6):1134–1145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="2355" citStr="Liu, 2012" startWordPosition="366" endWordPosition="367">s should be extracted and the sentiment towards them should also be determined. Aspect-Based SA task consists of several subproblems, the document is about many entities which could be for example a restaurant, a laptop, a printer. Users may refer to an entity by different writings, but normally there are not a lot of variations to indicate the same entity, each entity has many aspects which could be its parts or attributes. Some aspects could be another entity such as screen of laptop, but most work did not take this case into account. Therefore, we could define the opinion by the quintuple (Liu, 2012) (ei, aij, sijkl, hk, tl) where ei is the entity i, aij are the aspects of the entity i, sijkl is the expressed sentiment on the aspect at the time tl , hk the holder which created the document or the text. This definition does not take into account that the entity has aspects that could have also other aspects which leads to an aspect hierarchy, in order to avoid this information loss, few work has handled this issue, they proposed to represent the aspect as a tree of aspect terms. In this paper, we focus on Opinion Target Extraction (OTE) and Sentiment Polarity towards a target or a category</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Liu, B. (2012). Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Moghaddam</author>
<author>M Ester</author>
</authors>
<title>Opinion digger: An unsupervised opinion miner from unstructured product reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM ’10,</booktitle>
<pages>1825--1828</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4807" citStr="Moghaddam and Ester, 2010" startWordPosition="764" endWordPosition="767">n the aspect and their sentiments from the same model, these models are generally unsupervised or semi-supervised. The earliest work on aspect detection from online reviews presented by Hu and Liu (Hu and Liu, 2004) that used association rule mining based on Apriori algorithm to extract frequent noun phrases as product features, for polarity detection they used two seed sets of 30 positive and negative adjectives, then WordNet has been used to find and add the synonyms of the seed words. Infrequent features had been processed by finding the noun related to an opinionated word. Opinion Digger (Moghaddam and Ester, 2010) also used Apriori algorithm to extract the frequent aspects. KNN algorithm is applied to estimate the aspect rating scaling from 1 to 5 stands for (Excellent, Good, Average, Poor, Terrible). Supervised methods uses normally the CRF or HMM models. Jin and Ho (Jin and Ho, 2009) applied a lexicalized HMM model to extract aspects using the words and their part-of-speech tags in order to learn a model, then unsupervised algorithm for determining the aspect sentiment using the nearest opinion word to the aspect and taking into account the polarity reversal words (such as not). A CRF model was used </context>
</contexts>
<marker>Moghaddam, Ester, 2010</marker>
<rawString>Moghaddam, S. and Ester, M. (2010). Opinion digger: An unsupervised opinion miner from unstructured product reviews. In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM ’10, pages 1825– 1828. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
</authors>
<title>emotional tweets.</title>
<date>2012</date>
<booktitle>In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>246--255</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Mohammad, 2012</marker>
<rawString>Mohammad, S. (2012-06-07). #emotional tweets. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), pages 246–255. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Mohammad</author>
<author>S Kiritchenko</author>
<author>X Zhu</author>
</authors>
<title>NRCCanada: Building the state-of-the-art in sentiment analysis of tweets. In</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval 13.</booktitle>
<contexts>
<context position="7774" citStr="Mohammad et al., 2013" startWordPosition="1235" endWordPosition="1238">l relationships among product attributes and tackled the problem of sentiment analysis as a hierarchical classification problem. Unsupervised hierarchical aspect Sentiment model (HASM) was proposed by Kim et al (Kim et al., 3 07) to discover a hierarchical structure of aspect-based sentiments from unlabeled online reviews. Aspect term polarity detection can be seen as a sentence level sentiment analysis. Therefore, many papers can be mentioned. Supervised methods have been widely exploited for this purpose, a classification algorithms with a wise feature extraction could achieve good results (Mohammad et al., 2013) (Hamdan et al., 2015a) (Hamdan et al., 4 29). 3 Opinion Target Expression (OTE) An opinion target expression (OTE) is an expression used in the given text to refer to an aspect or 754 an aspect term related to the reviewed entity. The objective of OTE slot is to extract all opinion target expressions in a restaurant review, OTE could be a word or multiple words. For this purpose, we have used CRF (Conditional Random Field) which have proved its performance in information extraction. We choose the IOB notation for representing each sentence in the review. Therefore, we distinguish the terms at</context>
<context position="13439" citStr="Mohammad et al., 2013" startWordPosition="2211" endWordPosition="2214">er with weighting schema of positive and negative labels with the following features: - Word n-grams Features Unigrams and bigrams are extracted for each word in the context without any stemming or stop-word removing, all terms with occurrence less than 3 are removed from the feature space. - Sentiment Lexicon-based Features The system extracts four features from the manual constructed lexicons (Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005)) and six features from the automatic ones (NRC Hashtag Sentiment Lexicon (Mohammad, 6 07), Sentiment140 Lexicon (Mohammad et al., 2013), and SentiWordNet (Baccianella et al., 2010)). For each context the number of positive words, the number of negative ones, the number of positive words divided by the number of negative ones and the polarity of the last word are extracted from manual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Features The rule-based algorithm presented in Christopher Potts Sentiment Symposium Tutorial is implemented. This algorithm appends a negation suffix to all words that appear within a negation</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Mohammad, S. M., Kiritchenko, S., and Zhu, X. (2013). NRCCanada: Building the state-of-the-art in sentiment analysis of tweets. In In Proceedings of the International Workshop on Semantic Evaluation, SemEval 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Okazaki</author>
</authors>
<title>CRFsuite: a fast implementation of Conditional Random Fields (CRFs).</title>
<date>2007</date>
<contexts>
<context position="10493" citStr="Okazaki, 2007" startWordPosition="1700" endWordPosition="1701">face, word POS, word chunk, word shape, word type. Finally, we extract the value of each three successive features in the the range -1,1 for the two features: word POS and word lemma. 3.1 Experiments The data set is extracted from restaurant reviews, provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015). Table 1 shows the training and testing data sets statistics of restaurant reviews, where each review is composed of several sentences and each sentence may contain several OTE. CRFsuite tool is used for this experiment with lbfgs algorithm. This tool is fast in training and tagging (Okazaki, 2007). Data Reviews Sentences OTE Train 254 1315 1654 Test 96 685 845 Table 1. Training and testing data sets for restaurant OTE slot. Our submission is ranked fifth with the F1 score over twenty submissions with gain of 14% over the baseline provided by the organizers. This baseline uses the training reviews to create for each category c a list of targets to which it is linked to. Then, given a test sentence s and a category c, the baseline finds the first occurrence in s of each target encountered in cs list. Table 2 shows our system and the baseline results. Experiment Recall Precision F1 Score </context>
</contexts>
<marker>Okazaki, 2007</marker>
<rawString>Okazaki, N. (2007). CRFsuite: a fast implementation of Conditional Random Fields (CRFs).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pontiki</author>
<author>D Galanis</author>
<author>H Papageogiou</author>
<author>S Manandhar</author>
<author>I Androutsopoulos</author>
</authors>
<title>SemEval-2015 task 12: Aspect based sentiment analysis.</title>
<date>2015</date>
<booktitle>In In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="3042" citStr="Pontiki et al., 2015" startWordPosition="489" endWordPosition="492">pects of the entity i, sijkl is the expressed sentiment on the aspect at the time tl , hk the holder which created the document or the text. This definition does not take into account that the entity has aspects that could have also other aspects which leads to an aspect hierarchy, in order to avoid this information loss, few work has handled this issue, they proposed to represent the aspect as a tree of aspect terms. In this paper, we focus on Opinion Target Extraction (OTE) and Sentiment Polarity towards a target or a category. The description of each subtask is provided by ABSA organizers (Pontiki et al., 2015). For OTE or aspect term extraction, a CRF model is proposed with IOB annotation and several groups of features including syntactic, lexical, semantic, sentiment lexicon features. For aspect term polarity detection, a logistic regression classifier is trained with weighting schema for positive and negative labels and several groups of features are extracted includ753 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 753–758, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics ing lexical, syntactic, semantic, lexicon and Z</context>
<context position="10193" citStr="Pontiki et al., 2015" startWordPosition="1650" endWordPosition="1653">tters digit, Contains a uppercase letter, Contains a lowercase letter, Contains a digit, Contains a alphabet letter, Contains a symbol. We also extract the value of each two successive features in the the range -2,2 (the previous and subsequent two words of actual word) for the following features: word surface, word POS, word chunk, word shape, word type. Finally, we extract the value of each three successive features in the the range -1,1 for the two features: word POS and word lemma. 3.1 Experiments The data set is extracted from restaurant reviews, provided by SemEval 2015 ABSA organizers (Pontiki et al., 2015). Table 1 shows the training and testing data sets statistics of restaurant reviews, where each review is composed of several sentences and each sentence may contain several OTE. CRFsuite tool is used for this experiment with lbfgs algorithm. This tool is fast in training and tagging (Okazaki, 2007). Data Reviews Sentences OTE Train 254 1315 1654 Test 96 685 845 Table 1. Training and testing data sets for restaurant OTE slot. Our submission is ranked fifth with the F1 score over twenty submissions with gain of 14% over the baseline provided by the organizers. This baseline uses the training re</context>
</contexts>
<marker>Pontiki, Galanis, Papageogiou, Manandhar, Androutsopoulos, 2015</marker>
<rawString>Pontiki, M., Galanis, D., Papageogiou, H., Manandhar, S., and Androutsopoulos, I. (2015). SemEval-2015 task 12: Aspect based sentiment analysis. In In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wei</author>
<author>J A Gulla</author>
</authors>
<title>Sentiment learning on product reviews via sentiment ontology tree. In</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the ACL,</booktitle>
<pages>404--413</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7008" citStr="Wei and Gulla, 2010" startWordPosition="1126" endWordPosition="1129">d McKeown (Hatzivassiloglou and McKeown, 1997) to extract the conjunctive adjectives, but not the disjunctive due to the specificity of the domain, seed sets were used and assigned scores, these scores were propagated using propagation method through the aspect-sentiment graph building from the pairs of aspect and related adjectives. Lin and He (Lin et al., 2012) proposed Joint model of Sentiment and Topic (JST) which extends the state-of-the-art topic model (LDA) by adding a sentiment layer, this model is fully unsupervised and it can detect sentiment and topic simultaneously. Wei and Gulla (Wei and Gulla, 2010) modeled the hierarchical relation between product aspects. They defined Sentiment Ontology Tree (SOT) to formulate the knowledge of hierarchical relationships among product attributes and tackled the problem of sentiment analysis as a hierarchical classification problem. Unsupervised hierarchical aspect Sentiment model (HASM) was proposed by Kim et al (Kim et al., 3 07) to discover a hierarchical structure of aspect-based sentiments from unlabeled online reviews. Aspect term polarity detection can be seen as a sentence level sentiment analysis. Therefore, many papers can be mentioned. Supervi</context>
</contexts>
<marker>Wei, Gulla, 2010</marker>
<rawString>Wei, W. and Gulla, J. A. (2010). Sentiment learning on product reviews via sentiment ontology tree. In In Proceedings of the 48th Annual Meeting of the ACL, pages 404–413. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>P Hoffmann</author>
<author>S Somasundaran</author>
<author>J Kessler</author>
<author>J Wiebe</author>
<author>Y Choi</author>
<author>C Cardie</author>
<author>E Riloff</author>
<author>S Patwardhan</author>
</authors>
<title>OpinionFinder: A system for subjectivity analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP on Interactive Demonstrations, HLT-Demo ’05,</booktitle>
<pages>pages</pages>
<contexts>
<context position="9306" citStr="Wilson et al., 2005" startWordPosition="1499" endWordPosition="1502">d 3 previous and subsequent words, respectively. -word lemma using WordNet. -word POS using NLTK parser. -word shape: the shape of each character in the word (capital letter, small letter, digit, punctuation, other symbol) -word type: the type of the word (uppercase, digit, symbol, combination) -Named entity: the IOB annotation for the named entity extracted from the review using Senna (Collobert, 2011). -chunk: the chunk of the word (NP, VP, PP) extracted using Senna. -polarity: the sum of word polarity score calculated using Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005). -Prefixes (all prefixes having length between one to four ). -Suffixes (all suffixes having length between one to four). -Stop word: if the word is a stop word or not. -if the initial letter is uppercase, if all letters are uppercase, All letters lowercase, All letters digit, Contains a uppercase letter, Contains a lowercase letter, Contains a digit, Contains a alphabet letter, Contains a symbol. We also extract the value of each two successive features in the the range -2,2 (the previous and subsequent two words of actual word) for the following features: word surface, word POS, word chunk,</context>
<context position="13303" citStr="Wilson et al., 2005" startWordPosition="2190" endWordPosition="2193">d step, we should determine the polarity, which could be positive, negative, neutral. We propose to use a logistic regression classifier with weighting schema of positive and negative labels with the following features: - Word n-grams Features Unigrams and bigrams are extracted for each word in the context without any stemming or stop-word removing, all terms with occurrence less than 3 are removed from the feature space. - Sentiment Lexicon-based Features The system extracts four features from the manual constructed lexicons (Bing Liu Lexicon (Hu and Liu, 2004) and MPQA subjectivity Lexicon (Wilson et al., 2005)) and six features from the automatic ones (NRC Hashtag Sentiment Lexicon (Mohammad, 6 07), Sentiment140 Lexicon (Mohammad et al., 2013), and SentiWordNet (Baccianella et al., 2010)). For each context the number of positive words, the number of negative ones, the number of positive words divided by the number of negative ones and the polarity of the last word are extracted from manual constructed lexicons. In addition to the sum of the positive scores and the sum of the negative scores from the automatic constructed lexicons. - Negation Features The rule-based algorithm presented in Christophe</context>
</contexts>
<marker>Wilson, Hoffmann, Somasundaran, Kessler, Wiebe, Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Wilson, T., Hoffmann, P., Somasundaran, S., Kessler, J., Wiebe, J., Choi, Y., Cardie, C., Riloff, E., and Patwardhan, S. (2005). OpinionFinder: A system for subjectivity analysis. In Proceedings of HLT/EMNLP on Interactive Demonstrations, HLT-Demo ’05, pages 34– 35. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>