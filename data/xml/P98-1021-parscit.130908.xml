<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.991108">
Spoken Dialogue Interpretation with the DOP Model
</title>
<author confidence="0.994964">
Rens Bod
</author>
<affiliation confidence="0.997589">
Department of Computational Linguistics
University of Amsterdam
</affiliation>
<address confidence="0.925112">
Spuistraat 134, 1012 VB Amsterdam
</address>
<email confidence="0.990905">
rens.bod@let.uva.n1
</email>
<sectionHeader confidence="0.993516" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988761904762">
We show how the DOP model can be used for fast and
robust processing of spoken input in a practical spoken
dialogue system called OVIS. OVIS, Openbaar
Vervoer Informatie Systeem (&amp;quot;Public Transport Infor-
mation System&amp;quot;), is a Dutch spoken language infor-
mation system which operates over ordinary telephone
lines. The prototype system is the immediate goal of
the NWOI Priority Programme &amp;quot;Language and Speech
Technology&amp;quot;. In this paper, we extend the original
DOP model to context-sensitive interpretation of
spoken input. The system we describe uses the OVIS
corpus (10,000 trees enriched with compositional
semantics) to compute from an input word-graph the
best utterance together with its meaning. Dialogue
context is taken into account by dividing up the OVIS
corpus into context-dependent subcorpora. Each
system question triggers a subcorpus by which the user
answer is analyzed and interpreted. Our experiments
indicate that the context-sensitive DOP model obtains
better accuracy than the original model, allowing for
fast and robust processing of spoken input.
</bodyText>
<sectionHeader confidence="0.998208" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999363333333333">
The Data-Oriented Parsing (DOP) model (cf. Bod
1992, 1995; Bod &amp; Kaplan 1998; Scha 1992; Sima&apos;an
1995, 1997; Rajman 1995) is a probabilistic parsing
model which does not single out a narrowly predefined
set of structures as the statistically significant ones. It
accomplishes this by maintaining a large corpus of
analyses of previously occurring utterances. New
utterances are analyzed by combining subtrees from
the corpus. The occurrence-frequencies of the subtrees
are used to estimate the most probable analysis of an
utterance.
To date, DOP has mainly been applied to
corpora of trees labeled with syntactic annotations.
Let us illustrate this with a very simple example.
Suppose that a corpus consists of only two trees:
</bodyText>
<equation confidence="0.937739666666667">
(1)
// 7NS
NP /NVP NP z\VP
I
John V NP Pier V NP
I I I I
</equation>
<subsectionHeader confidence="0.150055">
likes Mary hates Susan
</subsectionHeader>
<bodyText confidence="0.913271555555556">
I Netherlands Organization for Scientific Research
To combine subtrees, a node-substitution operation
indicated as 0 is used. Node-substitution identifies the
leftmost nonterminal frontier node of one tree with the
root node of a second tree (i.e., the second tree is
substituted on the leftmost nonterminal frontier node
of the first tree). A new input sentence such as Mary
likes Susan can thus be parsed by combining subtrees
from this corpus, as in (2):
</bodyText>
<figure confidence="0.921531230769231">
/rNs NP
NP VP Mary NP VP
V NP Mary V NP
I I I
likes likes Susan
Other derivations may yield the same parse tree; for
instance:
o V = zNS
hies NP /VP
Mary V
likes
NP
Susan
</figure>
<bodyText confidence="0.999644">
DOP computes the probability of substituting a subtree
t on a specific node as the probability of selecting t
among all subtrees in the corpus that could be
substituted on that node. This probability is equal to
the number of occurrences of t, divided by the total
number of occurrences of subtrees t&apos; with the same
root label as t. Let rl(t) return the root label of t then:
P(() = #(() It&apos;:rl(e)=rl(t)#(0. The probability of a
derivation is computed by the product of the
probabilities of the subtrees is consists of. The
probability of a parse tree is computed by the sum of
the probabilities of all derivations that produce that
parse tree.
Bod (1992) demonstrated that DOP can be
implemented using conventional context-free parsing
techniques. However, the computation of the most
probable parse of a sentence is NP-hard (Sima&apos;an
1996). The most probable parse can be estimated by
iterative Monte Carlo sampling (Bod 1995), but
efficient algorithms exist only for sub-optimal
solutions such as the most likely derivation of a
sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled
</bodyText>
<figure confidence="0.9657345">
NP
Susan
NP
NP zs\VP Mary
V NP
Susan
</figure>
<page confidence="0.99358">
138
</page>
<bodyText confidence="0.999973720930233">
recall parse&amp;quot; of a sentence (Goodman 1996). So far,
the syntactic DOP model has been tested on the ATIS
corpus and the Wall Street Journal corpus, obtaining
significantly better test results than other stochastic
parsers (Charniak 1996). For example, Goodman
(1998) compares the results of his DOP parser to a
replication of Pereira &amp; Schabes (1992) on the same
training and test data. While the Pereira &amp; Schabes
method achieves 79.2% zero-crossing brackets
accuracy, DOP obtains 86.1% on the same data
(Goodman 1998: p. 179, table 4.4). Thus the DOP
method outperforms the Pereira &amp; Schabes method
with an accuracy-increase of 6.9%, or an error-
reduction of 33%. Goodman also performs a statistical
analysis using t-test, showing that the differences are
statistically significant beyond the 98th percentile.
In Bod et al. (1996), it was shown how DOP
can be generalized to semantic interpretation by using
corpora annotated with compositional semantics. In
the current paper, we extend the DOP model to
spoken dialogue understanding, and we show how it
can be used as an efficient and robust NLP component
in a practical spoken dialogue system called OVIS.
OVIS, Openbaar Vervoer Informatie Systeem (&amp;quot;Public
Transport Information System&amp;quot;), is a Dutch spoken
language information system which operates over
ordinary telephone lines. The prototype system is the
immediate goal of the NWO Priority Programme
&amp;quot;Language and Speech Technology&amp;quot;.
The backbone of any DOP model is an
annotated language corpus. In the following section,
we therefore start with a description of the corpus that
was developed for the OVIS system, the &amp;quot;OVIS
corpus&amp;quot;. We then show how this corpus can be used by
DOP to compute the most likely meaning M of a word
string W: argmaxm P(M, W). Next we demonstrate how
the dialogue context C can be integrated so as to
compute argmaxm P(M, W I C). Finally, we interface
DOP with speech and show how the most likely
meaning M of an acoustic utterance A given dialogue
context C is computed: argmaxm P(M, A I C). The last
section of this paper deals with the experimental
evaluation of the model.
</bodyText>
<sectionHeader confidence="0.771915" genericHeader="introduction">
2. The OVIS corpus: trees enriched with
compositional frame semantics
</sectionHeader>
<bodyText confidence="0.8050871">
The OVIS corpus currently consists of 10,000 syntac-
tically and semantically annotated user utterances
that were collected on the basis of a pilot version of
the OVIS system2. The user utterances are answers to
system questions such as From where to where do you
want to travel?, At what time do you want to travel from
Utrecht to Leiden?, Could you please repeat your
destination?.
For the syntactic annotation of the OVIS user
utterances, a tag set of 40 lexical/syntactic categories
</bodyText>
<footnote confidence="0.986561333333333">
2 The pilot version is based on a German system developed
by Philips Dialogue Systems in Aachen (Aust et al. 1995),
adapted to Dutch.
</footnote>
<bodyText confidence="0.998208">
was developed. This tag set was deliberately kept
small so as to improve the robustness of the DOP
parser. A correlate of this robustness is that the parser
will overgenerate, but as long as the probability model
can accurately select the correct utterance-analysis
from all possible analyses, this overgeneration is not
problematic. Robustness is further achieved by a
special category, called ERROR. This category is used
for stutters, false starts, and repairs. No grammar is
used to determine the correct syntactic annotation;
there is a small set of guidelines, that has the degree
of detail necessary to avoid an &amp;quot;anything goes&amp;quot;
attitude in the annotator, but leaves room for the
annotator&apos;s perception of the structure of the utterance
(see Bonnema et al. 1997).
The semantic annotations are based on the
update language defined for the OVIS dialogue
manager by Veldhuijzen van Zanten (1996). This
language consists of a hierarchical frame structure
with slots and values for the origin and destination of
a train connection, for the time at which the user
wants to arrive or depart, etc. The distinction between
slots and values can be regarded as a special case of
ground and focus distinction (Vallduvi 1990). Updates
specify the ground and focus of the user utterances.
For example, the utterance lk wil niet vandaag maar
morgen naar Almere (literally: &amp;quot;I want not today but
tomorrow to Almere&amp;quot;) yields the following update:
</bodyText>
<listItem confidence="0.4996975">
(4) user.wants.M# today];[! tomorrow]);
destination.place.town.almere)
</listItem>
<bodyText confidence="0.999559888888889">
An important property of this update language is that
it allows encoding of speech-act information (v. Noord
et al. 1997). The &amp;quot;#&amp;quot; in the update means that the
information between the square brackets (representing
the focus of the user-utterance) must be retracted,
while the &amp;quot;!&amp;quot; denotes the corrected information.
This update language is used to semantically
enrich the syntactic nodes of the OVIS trees by means
of the following annotation convention:
</bodyText>
<listItem confidence="0.971886125">
• Every meaningful lexical node is annotated with a
slot and/or value from the update language which
represents the meaning of the lexical item.
• Every meaningful non-lexical node is annotated
with a formula schema which indicates how its
meaning representation can be put together out of
the meaning representations assigned to its daughter
nodes.
</listItem>
<bodyText confidence="0.999934818181818">
In the examples below, these schemata use the
variable dl to indicate the meaning of the leftmost
daughter constituent, d2 to indicate the meaning of
the second daughter node constituent, etc. For
instance, the full (syntactic and semantic) annotation
for the above sentence lk wil niet vandaag maar
morgen naar Almere is given in figure (5).
Note that the top-node meaning of (5) is
compositionally built up out of the meanings of its
sub-constituents. Substituting the meaning represen-
tations into the corresponding variables yields the
</bodyText>
<page confidence="0.994726">
139
</page>
<bodyText confidence="0.91716625">
update expression (4). The OVIS annotations are in
contrast with other corpora and systems (e.g. Miller et
al. 1996), in that our annotation convention exploits
the Principle of Compositionality of Meaning.3
</bodyText>
<figure confidence="0.9902636">
CON MP P NP
1
tomorrow destination.place town almere
I I I I
maar morgen naar almere
</figure>
<figureCaption confidence="0.992481">
Figure (6) gives an example of the ERROR category
for the annotation of the ill-formed sentence Van
</figureCaption>
<figure confidence="0.901444">
Voorburg naar van Venlo naar Voorburg (&amp;quot;From
Voorburg to from Venlo to Voorburg&amp;quot;):
ERROR MP
NIP
(dl ;d2) MP
MP .Nd I .d2
P NP P NP
Iorigin.place tomivenlo destination.place town.rburg
I I
origin.place town.voorburg van vetdo naw voorburg
I I
tan voorburg
</figure>
<bodyText confidence="0.984500769230769">
Note that the ERROR category has no semantic
annotation; in the top-node semantics of Van Voorburg
3 To maintain our annotation convention in the face of
phenomena such as non-standard quantifier scope or
discontinuous constituents may create complications in the
syntactic or semantic analyses assigned to certain
sentences and their constituents. It is therefore not clear yet
whether our current treatment ought to be viewed as
completely general, or whether a more sophisticated
treatment in the vein of van den Berg et al. (1994) should be
worked out.
naar van Venlo naar Voorburg, the meaning of the
false start Van Voorburg naar is thus absent:
</bodyText>
<equation confidence="0.798938">
(7) (origin.place.town.venlo ;
destination.place.town.voorburg)
</equation>
<bodyText confidence="0.999976454545454">
The manual annotation of 10,000 OVIS utterances
may seem a laborious and error-prone process. In order
to expedite this task, a flexible and powerful
annotation workbench (SEMTAGS) was developed by
Bonnema (1996). SEMTAGS is a graphical interface,
written in C using the X V IEW toolkit. It offers all
functionality needed for examining, evaluating, and
editing syntactic and semantic analyses. SEMTAGS is
mainly used for correcting the output of the DOP
parser. After the first 100 OVIS utterances were
annotated and checked by hand, the parser used the
subtrees of these annotations to produce analyses for
the next 100 OVIS utterances. These new analyses
were checked and corrected by the annotator using
SEMTAGS, and were added to the total set of
annotations. This new set of 200 analyses was then
used by the DOP parser to predict the analyses for a
next subset of OVIS utterances. In this incremental,
bootstrapping way, 10,000 OVIS utterances were
annotated in approximately 600 hours (supervision
included). For further information on OVIS and how to
obtain the corpus, see http://earth.let.uva.n1/—rens.
</bodyText>
<sectionHeader confidence="0.5941305" genericHeader="method">
3. Using the OVIS corpus for data-oriented
semantic analysis
</sectionHeader>
<bodyText confidence="0.999966727272727">
An important advantage of a corpus annotated
according to the Principle of Compositionality of
Meaning is that the subtrees can directly be used by
DOP for computing syntactic/semantic representations
for new utterances. The only difference is that we now
have composite labels which do not only contain
syntactic but also semantic information. By way of
illustration, we show how a representation for the
input utterance lk wil van Venlo naar Almere (&amp;quot;I want
from Venlo to Almere&amp;quot;) can be constructed out of
subtrees from the trees in figures (5) and (6):
</bodyText>
<footnote confidence="0.4787032">
MP
dl.d2
NP
desti nation. place town.almere
naar almere
</footnote>
<figure confidence="0.99956552">
user
I V
ik wants
wil
MP
d I .d2
MP
(d I ;d2)
MP MP
d I .d2 dl .d2
NP
origin.place town venlo
I I
van veMo
dl .d2
PER V VP MP
user wants dl .c12 (d I ;d2)
ik wi/
MP
[dId2]
ADV MP
today
niet vandaag
/Nd I .d2 destination.place
NP naar
</figure>
<page confidence="0.91682">
140
</page>
<bodyText confidence="0.916962">
which yields the following top-node update semantics:
</bodyText>
<equation confidence="0.909378666666667">
(9) user.wants.
(origin.place.town.venlo;
destination.place.town.almere)
</equation>
<bodyText confidence="0.999653785714286">
The probability calculations for the semantic DOP
model are similar to the original DOP model. That is,
the probability of a subtree t is equal to the number of
occurrences of t in the corpus divided by the number
of occurrences of all subtrees t&apos; that can be substituted
on the same node as t. The probability of a derivation
D = ti ... 0 t„ is the product of the probabilities of its
subtrees ti. The probability of a parse tree T is the sum
of the probabilities of all derivations D that produce T.
And the probability of a meaning M and a word string
W is the sum of the probabilities of all parse trees T of
W whose top-node meaning is logically equivalent to
M (see Bod et al. 1996).
As with the most probable parse, the most
probable meaning M of a word string W cannot be
computed in deterministic polynomial time. Although
the most probable meaning can be estimated by
iterative Monte Carlo sampling (see Bod 1995), the
computation of a sufficiently large number of random
derivations is currently not efficient enough for a
practical application. To date, only the most likely
derivation can be computed in near to real-time (by a
best-first Viterbi optimization algorithm). We there-
fore assume that most of the probability mass for each
top-node meaning is focussed on a single derivation.
Under this assumption, the most likely meaning of a
string is the top-node meaning generated by the most
likely derivation of that string (see also section 5).
</bodyText>
<sectionHeader confidence="0.960476" genericHeader="method">
4. Extending DOP to dialogue context:
context-dependent subcorpora
</sectionHeader>
<bodyText confidence="0.982010538461539">
We now extend the semantic DOP model to compute
the most likely meaning of a sentence given the
previous dialogue. In general, the probability of a top-
node meaning M and a particular word string Wi given
a dialogue-context C, = Wi_i, Wi_2 ... W1 is given by
P(M, Wi I Wi-1, Wi-2
Since the OVIS user utterances are typically answers
to previous system questions, we assume that the
meaning of a word string Wi does not depend on the
full dialogue context but only on the previous
(system) question Wi.i. Under this assumption,
P(M, Wi I Ci) = P(M, Wi I Wi_1)
For DOP, this formula means that the update
semantics of a user utterance Wi is computed on the
basis of the subcorpus which contains all OVIS
utterances (with their annotations) that are answers to
the system question Wi_1. This gives rise to the
following interesting model for dialogue processing:
each system question triggers a context-dependent
domain (a subcorpus) by which the user answer is
analyzed and interpreted. Since the number of
different system questions is a small closed set (see
Veldhuijzen van Zanten 1996), we can create off-line
for each subcorpus the corresponding DOP parser.
In OVIS, the following context-dependent
subcorpora can be distinguished:
</bodyText>
<listItem confidence="0.998203714285714">
(1) place subcorpus: utterances following questions
like From where to where do you want to travel?
What is your destination?, etc.
(2) date subcorpus: utterances following questions
like When do you want to travel?, When do you want
to leave from X?, When do you want to arrive in Y?,
etc.
(3) lime subcorpus: utterances following questions
like At what time do you want to travel? At what time
do you want to leave from X?, At what time do you
want to arrive in Y?, etc.
(4) yes/no subcorpus: utterances following y/n-
questions like Did you say that ... ? Thus you want to
arrive at...?
</listItem>
<bodyText confidence="0.999751619047619">
Note that a subcorpus can contain utterances whose
topic goes beyond the previous system question. For
example, if the system asks From where to where do
you want to travel?, and the user answers with: From
Amsterdam to Groningen tomorrow morning, then the
date-expression tomorrow morning ends up in the
place-subcorpus.
It is interesting to note that this context-
sensitive DOP model can easily be generalized to
domain-dependent interpretation: a corpus is clustered
into subcorpora, where each subcorpus corresponds to
a topic-dependent domain. A new utterance is
interpreted by the domain in which it gets highest
probability. Since small subcorpora tend to assign
higher probabilities to utterances than large
subcorpora (because relative frequencies of subtrees
in small corpora tend to be higher), it follows that a
language user strives for the smallest, most specific
domain in which the perceived utterance can be
analyzed, thus establishing a most specific common
ground.
</bodyText>
<figure confidence="0.994949421052632">
dl d2
VP
dl.d2
MP
OThd
MP MP
dl.d2 d I .d2
PER
User
ik
V
wants
KW
origimplace
van
NP NP
town.venlo destination.place town.almere
I
venlo naar alnzere
</figure>
<page confidence="0.986222">
141
</page>
<sectionHeader confidence="0.97787" genericHeader="method">
5. Interfacing DOP with speech
</sectionHeader>
<bodyText confidence="0.9999279375">
So far, we have dealt with the estimation of the
probability P(M, W I C) of a meaning M and a word
string W given a dialogue context C. However, in
spoken dialogue processing, the word string W is not
given. The input for DOP in the OVIS system are
word-graphs produced by the speech recognizer (these
word-graphs are generated by our project partners from
the University of Nijmegen).
A word-graph is a compact representation for
all sequences of words that the speech recognizer
hypothesizes for an acoustic utterance A (see e.g.
figure 10). The nodes of the graph represent points in
time, and a transition between two nodes i and j,
represents a word w that may have been uttered
between the corresponding points in time. For
convenience we refer to transitions in the word-graph
using the notation &lt;i, j, w&gt;. The word-graphs are
optimized to eliminate epsilon transitions. Such
transitions represent periods of time when the speech
recognizer hypothesizes that no words are uttered.
Each transition is associated with an acoustic score.
This is the negative logarithm (of base 10) of the
acoustic probability P(a I w) for a hypothesized word
w normalized by the length of w. Reconverting these
acoustic scores into their corresponding probabilities,
the acoustic probability P(A I W) for a hypothesized
word string W can be computed by the product of the
probabilities associated to each transition in the
corresponding word-graph path. Figure (10) shows an
example of a simplified word-graph for the uttered
sentence lk wil graag vannzorgen naar Leiden (&amp;quot;I&apos;d like
to go this morning to Leiden&amp;quot;):
</bodyText>
<equation confidence="0.9936826">
(10)
ik xil graag van Maam naar Leiden
(46.31) (64.86) (95.42) (96.97) ((21.33) (54.75) (11S65)
vanmorgen
(258.80)
</equation>
<bodyText confidence="0.967246039215686">
The probabilistic interface between DOP and speech
word-graphs thus consists of the interface between the
DOP probabilities P(M, W I C) and the word-graph
probabilities P(A I W) so as to compute the probability
P(M, A I C) and argmaxm P(M, A I C). We start by
rewriting P(M, A I C) as:
P(M, A I C) = Ew P(M, W, A IC)
= w P(M, W I C) • P(A I M, W, C)
The probability P(M, W I C) is computed by the
dialogue-sensitive DOP model as explained in the
previous section. To estimate the probability
P(A I M, W, C) on the basis of the information
available in the word-graphs, we must make the
following independence assumption: the acoustic
utterance A depends only on the word string W, and
not on its context C and meaning M (cf. Bod &amp; Scha
1994). Under this assumption:
P(M, A C) = Ew P(M, W I C) • P(A I W)
To make fast computation feasible, we furthermore
assume that most of the probability mass for each
meaning and acoustic utterance is focused on a single
word string W (this will allow for efficient Viterbi best
first search):
P(M, A I C) = P(M, W I C) P(A I W)
Thus, the probability of a meaning M for an acoustic
utterance A given a context C is computed by the
product of the DOP probability P(M, W I C) and the
word-graph probability P(A I W).
As to the parsing of word-graphs, it is well-
known that parsing algorithms for word strings can
easily be generalized to word-graphs (e.g. van Noord
1995). For word strings, the initialization of the chart
usually consists of entering each word wi into chart
entry &lt;i, i+1&gt;. For word-graphs, a transition &lt;i, j, w&gt;
corresponds to a word w between positions i and j
where j is not necessarily equal to i+1 as is the case
for word strings (see figure 10). It is thus easy to see
that for word-graphs the initialization of the chart
consists of entering each word w from transition
&lt;i, j, w&gt; into chart entry &lt;i, j&gt;. Next, parsing
proceeds with the subtrees that are triggered by the
dialogue context C (provided that all subtrees are
converted into equivalent rewrite rules -- see Bod
1992, Sima&apos;an 1995). The most likely derivation is
computed by a bottom-up best-first CKY parser
adapted to DOP (Sima&apos;an 1995, 1997). This parser has
a time complexity which is cubic in the number of
word-graph nodes and linear in the grammar size. The
top-node meaning of the tree resulting from the most
likely derivation is taken as the best meaning M for
an utterance A given context C.
</bodyText>
<sectionHeader confidence="0.99095" genericHeader="evaluation">
6. Evaluation
</sectionHeader>
<bodyText confidence="0.999955">
In our experimental evaluation of DOP we were
interested in the following questions:
</bodyText>
<listItem confidence="0.9978495">
(1) Is DOP fast enough for practical spoken
dialogue understanding?
(2) Can we constrain the OVIS subtrees without
loosing accuracy?
(3) What is the impact of dialogue context on the
accuracy?
</listItem>
<bodyText confidence="0.997120727272727">
For all experiments, we used a random split of the
10,000 OVIS trees into a 90% training set and a 10%
test set. The training set was divided up into the four
subcorpora described in section 4, which served to
create the corresponding DOP parsers. The 1000 word-
graphs for the test set utterances were used as input.
For each word-graph, the previous system question
was known to determine the particular DOP parser.
while the user utterances were kept apart. As to the
complexity of the word-graphs: the average number of
transitions per word is 4.2, and the average number of
</bodyText>
<figure confidence="0.48605625">
randaag
(113.22)
Laren
(loo.49)
</figure>
<page confidence="0.992844">
142
</page>
<bodyText confidence="0.999962769230769">
words per word-graph path is 4.6. All experiments were
run on an SGI Indigo with a MIPS R10000 processor
and 640 Mbyte of core memory.
To establish the semantic accuracy of the
system, the best meanings produced by the DOP
parser were compared with the meanings in the test
set. Besides an exact match metric, we also used a
more fine-grained evaluation for the semantic
accuracy. Following the proposals in Boros et al.
(1996) and van Noord et al. (1997), we translated
each update meaning into a set of semantic units,
where a unit is triple &lt;CommunicativeFunction,
Slot, value&gt;. For instance, the next example
</bodyText>
<equation confidence="0.836171166666667">
user.wants.travel.destination.
([# place.town.almere];
[1 place.town.alkmaar])
translates as:
&lt;denial, destination_town, almere&gt;
&lt;correction, destination_town, alkmaar&gt;
</equation>
<bodyText confidence="0.999104681818182">
Both the updates in the OVIS test set and the updates
produced by the DOP parser were translated into
semantic units of the form given above. The semantic
accuracy was then evaluated in three different ways:
(1) match, the percentage of updates which were
exactly correct (i.e. which exactly matched the
updates in the test set); (2) precision, the number of
correct semantic units divided by the number of
semantic units which were produced; (3) recall, the
number of correct semantic units divided by the
number of semantic units in the test set.
As to question (1), we already suspect that it is not
efficient to use all OVIS subtrees. We therefore
performed experiments with versions of DOP where
the subtree collection is restricted to subtrees with a
certain maximum depth. The following table shows for
four different maximum depths (where the maximum
number of frontier words is limited to 3), the number
of subtree types in the training set, the semantic
accuracy in terms of match, precision and recall (as
percentages), and the average CPU time per word-
graph in seconds.
</bodyText>
<table confidence="0.978006">
subtree- semantic accuracy
#subtrees CPU time
depth match precision recall
1 3191 76.2 79.4 82.1 0.21
2 10545 78.5 83.0 84.3 0.86
3 32140 79.8 84.7 86.2 2.76
4 64486 80.6 85.8 86.9 6.03
</table>
<tableCaption confidence="0.999934">
Table 1: Experimental results on OVIS word-graphs
</tableCaption>
<bodyText confidence="0.999780636363636">
The experiments show that at subtree-depth 4 the
highest accuracy is achieved, but that only for
subtree-depths 1 and 2 are the processing times fast
enough for practical applications. Thus there is a
trade-off between efficiency and accuracy: the
efficiency deteriorates if the accuracy improves. We
believe that a match of 78.5% and a corresponding
precision and recall of resp. 83.0% and 84.3% (for the
fast processing times at depth 2) is promising enough
for further research. Moreover, by testing DOP directly
on the word strings (without the word-graphs), a match
of 97.8% was achieved. This shows that linguistic
ambiguities do not play a significant role in this
domain. The actual problem are the ambiguities in the
word-graphs (i.e. the multiple paths).
Secondly, we are concerned with the question as to
whether we can impose constraints on the subtrees
other than their depth, in such a way that the accuracy
does not deteriorate and perhaps even improves. To
answer this question, we kept the maximal subtree-
depth constant at 3, and employed the following
constraints:
</bodyText>
<listItem confidence="0.9180408">
• Eliminating once-occurring subtrees: this led to a
considerable decrease for all metrics; e.g. match
decreased from 79.8% to 75.5%.
• Restricting subtree lexicalization: restricting the
maximum number of words in the subtree frontiers
</listItem>
<bodyText confidence="0.8263444">
to resp. 3, 2 and 1, showed a consistent decrease in
semantic accuracy similar to the restriction of the
subtree depth in table 1. The match dropped from
79.8% to 76.9% if each subtree was lexicalized
with only one word.
</bodyText>
<listItem confidence="0.722757">
• Eliminating subtrees with only non-head words:
</listItem>
<bodyText confidence="0.987259071428571">
this led also to a decrease in accuracy; the most
stringent metric decreased from 79.8% to 77.1%.
Evidently, there can be important relations in OVIS
that involve non-head words.
Finally, we are interested in the impact of dialogue
context on semantic accuracy. To test this, we
neglected the previous system questions and created
one DOP parser for the whole training set. The
semantic accuracy metric match dropped from 79.8%
to 77.4% (for depth 3). Moreover, the CPU time per
sentence deteriorated by a factor of 4 (which is
mainly due to the fact that larger training sets yield
slower DOP parsers).
The following result nicely illustrates how the
dialogue context can contribute to better predictions
for the correct meaning of an utterance. In parsing the
word-graph corresponding to the acoustic utterance
Donderdag acht februari (&amp;quot;Thursday eight February&amp;quot;),
the DOP model without dialogue context assigned
highest probability to a derivation yielding the word
string Dordrecht acht februari and its meaning. The
uttered word Donderdag was thus interpreted as the
town Dordrecht which was indeed among the other
hypothesized words in the word-graph. If the DOP
model took into account the dialogue context, the
previous system question When do you want to leave?
was known and thus triggered the subtrees from the
date-subcorpus only, which now correctly assigned the
</bodyText>
<page confidence="0.997113">
143
</page>
<bodyText confidence="0.9974755">
highest probability to Donderdag acht februari and its
meaning, rather than to Dordrecht acht februari.
</bodyText>
<sectionHeader confidence="0.986642" genericHeader="conclusions">
7. Conclusions
</sectionHeader>
<bodyText confidence="0.999949457142857">
We showed how the DOP model can be used for
efficient and robust processing of spoken input in the
OVIS spoken dialogue system. The system we
described uses syntactically and semantically
analyzed subtrees from the OVIS corpus to compute
from an input word-graph the best utterance together
with its meaning. We showed how dialogue context is
integrated by dividing up the OVIS corpus into
context-dependent subcorpora. Each system question
triggers a subcorpus by which the user utterance is
analyzed and interpreted.
Efficiency was achieved by computing the
most probable derivation rather than the most probable
parse, and by restricting the depth and lexicalization
of the OVIS subtrees. Robustness was achieved by the
shallow syntactic/semantic annotations, including the
use of the productive ERROR label for repairs and
false starts. The experimental evaluation showed that
DOP&apos;s blending of lexical relations with syntactic-
semantic structure yields promising results. The
experiments also indicated that elimination of
subtrees diminishes the semantic accuracy, even
when intuitively unimportant subtrees with only non-
head words are discarded. Neglecting dialogue context
also diminished the accuracy.
As future research, we want to investigate
further optimization techniques for DOP, including
finite-state approximations. We want to enrich the
OVIS utterances with discourse annotations, such as
co-reference links, in order to cope with anaphora
resolution. We will also extend the annotations with
feature structures and/or functional structures
associated with the surface structures so as to deal
with more complex linguistic phenomena (see Bod &amp;
Kaplan 1998).
</bodyText>
<sectionHeader confidence="0.998359" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998754">
We are grateful to Khalil Sima&apos;an for using his DOP
parser, and to Remko Bonnema for using SEMTAGS
and the relevant semantic interfaces. We also thank
Remko Bonnema, Ronald Kaplan, Remko Scha and
Khalil Sima&apos;an for helpful discussions and comments.
The OVIS corpus was annotated by Mike de Kreek
and Sascha Schtitz. This research was supported by
NWO, the Netherlands Organization for Scientific
Research (Priority Programme Language and Speech
Technology).
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999863671428571">
H. Aust, M. Oerder, F. Seide and V. Steinbiss. 1995. &amp;quot;The
Philips automatic train timetable information system&amp;quot;,
Speech Communication, 17, pp 249-262.
M. van den Berg, R. Bod and R. Scha, 1994. &amp;quot;A Corpus-
Based Approach to Semantic Interpretation&amp;quot;, Proceedings
Ninth Amsterdam Colloquium, Amsterdam, The Netherlands.
R. Bod, 1992. &amp;quot;A Computational Model of Language
Performance: Data Oriented Parsing&amp;quot;, Proceedings COLING-
92, Nantes, France.
R. Bod, 1995. Enriching Linguistics with Statistics:
Performance Models of Natural Language, ILLC Dissertation
Series 1995-14, University of Amsterdam.
R. Bod and R. Scha, 1994. &amp;quot;Prediction and Disambiguation
by means of Data-Oriented Parsing&amp;quot;, Proceedings Twente
Workshop on Language Technology (TWLT8), Twente, The
Netherlands.
R. Bod, R. Bonnema and R. Scha, 1996. &amp;quot;A Data-Oriented
Approach to Semantic Interpretation&amp;quot;, Proceedings Work -
shop on Corpus-Oriented Semantic Analysis, ECAI-96,
Budapest, Hungary.
R. Bod and R. Kaplan, 1998. &amp;quot;A Probabilistic Corpus-Driven
Model for Lexical-Functional Analysis&amp;quot;, this proceedings.
R. Bonnema, 1996. Data-Oriented Semantics, Master&apos;s
Thesis, Department of Computational Linguistics, University
of Amsterdam, The Netherlands.
R. Bonnema, R. Bod and R. Scha, 1997. &amp;quot;A DOP Model for
Semantic Interpretation&amp;quot;, Proceedings ACL/EACL-97 ,
Madrid, Spain.
M. Boros et al. 1996. &amp;quot;Towards understanding spontaneous
speech: word accuracy vs. concept accuracy.&amp;quot; Proceedings
ICSLP&apos;96, Philadelphia (PA).
E. Charniak, 1996. &amp;quot;Tree-bank Grammars&amp;quot;, Proceedings
AAAI-96, Menlo Park (Ca).
J. Goodman, 1996. &amp;quot;Efficient Algorithms for Parsing the DOP
Model&amp;quot;, Proceedings Empirical Methods in Natural Language
Processing, Philadelphia (PA).
J. Goodman, 1998. Parsing Inside-Out, Ph.D. thesis, Harvard
University, Massachusetts.
S. Miller et al. 1996. &amp;quot;A fully statistical approach to natural
language interfaces&amp;quot;, Proceedings ACL&apos;96, Santa Cruz (Ca.).
G. van Noord, 1995. &amp;quot;The intersection of finite state
automata and definite clause grammars&amp;quot;, Proceedings
ACL&apos;95 , Boston, Massachusetts.
G. van Noord, G. Bouma, R. Koeling and M. Nederhof, 1997.
Robust Grammatical Analysis for Spoken Dialogue Systems,
unpublished manuscript.
F. Pereira and Y. Schabes, 1992. &amp;quot;Inside-Outside Reestima-
tion from Partially Bracketed Corpora&amp;quot;, Proceedings ACL&apos;92,
Newark, Delaware.
M. Rajman 1995. &amp;quot;Approche Probabiliste de l&apos;Analyse
Syntaxique&amp;quot;, Traitement Automatique des Gangues, 36(1-2).
R. Scha 1992. &amp;quot;Virtuele Grammatica&apos;s en Creatieve Algorit-
men&amp;quot;, Gramma/77l 1(1).
K. Sima&apos;an, 1995. &amp;quot;An optimized algorithm for Data Oriented
Parsing&amp;quot;, In: R. Mitkov and N. Nicolov (eds.), Recent
Advances in Natural Language Processing 1995, volume 136
of Current Issues in Linguistic Theory. John Benjamins,
Amsterdam.
K. Sima&apos;an, 1996. &amp;quot;Computational Complexity of
Probabilistic Disambiguation by means of Tree Grammars&amp;quot;,
Proceedings COLING-96, Copenhagen, Denmark.
K. Sima&apos;an, 1997. &amp;quot;Explanation-Based Learning of Data-
Oriented Parsing&amp;quot;, in T. Ellison (ed.) CoNLL9 7:
Computational Natural Language Learning, ACL&apos;97, Madrid,
Spain.
E. Vallduvi, 1990. The Informational Component. Ph.D.
thesis, University of Pennsylvania, PA.
G. Veldhuijzen van Zanten, 1996. Semantics of update
expressions. Technical Report 24. NWO Priority Programme
Language and Speech Technology, The Hague.
</reference>
<page confidence="0.998594">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.577443">
<title confidence="0.997605">Spoken Dialogue Interpretation with the DOP Model</title>
<author confidence="0.978461">Rens Bod</author>
<affiliation confidence="0.999685">Department of Computational Linguistics University of Amsterdam</affiliation>
<address confidence="0.993254">Spuistraat 134, 1012 VB Amsterdam</address>
<email confidence="0.605433">rens.bod@let.uva.n1</email>
<abstract confidence="0.999071409090909">We show how the DOP model can be used for fast and robust processing of spoken input in a practical spoken dialogue system called OVIS. OVIS, Openbaar Vervoer Informatie Systeem (&amp;quot;Public Transport Information System&amp;quot;), is a Dutch spoken language information system which operates over ordinary telephone lines. The prototype system is the immediate goal of the NWOI Priority Programme &amp;quot;Language and Speech Technology&amp;quot;. In this paper, we extend the original DOP model to context-sensitive interpretation of spoken input. The system we describe uses the OVIS corpus (10,000 trees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Aust</author>
<author>M Oerder</author>
<author>F Seide</author>
<author>V Steinbiss</author>
</authors>
<title>The Philips automatic train timetable information system&amp;quot;,</title>
<date>1995</date>
<journal>Speech Communication,</journal>
<volume>17</volume>
<pages>249--262</pages>
<contexts>
<context position="6612" citStr="Aust et al. 1995" startWordPosition="1081" endWordPosition="1084">l frame semantics The OVIS corpus currently consists of 10,000 syntactically and semantically annotated user utterances that were collected on the basis of a pilot version of the OVIS system2. The user utterances are answers to system questions such as From where to where do you want to travel?, At what time do you want to travel from Utrecht to Leiden?, Could you please repeat your destination?. For the syntactic annotation of the OVIS user utterances, a tag set of 40 lexical/syntactic categories 2 The pilot version is based on a German system developed by Philips Dialogue Systems in Aachen (Aust et al. 1995), adapted to Dutch. was developed. This tag set was deliberately kept small so as to improve the robustness of the DOP parser. A correlate of this robustness is that the parser will overgenerate, but as long as the probability model can accurately select the correct utterance-analysis from all possible analyses, this overgeneration is not problematic. Robustness is further achieved by a special category, called ERROR. This category is used for stutters, false starts, and repairs. No grammar is used to determine the correct syntactic annotation; there is a small set of guidelines, that has the </context>
</contexts>
<marker>Aust, Oerder, Seide, Steinbiss, 1995</marker>
<rawString>H. Aust, M. Oerder, F. Seide and V. Steinbiss. 1995. &amp;quot;The Philips automatic train timetable information system&amp;quot;, Speech Communication, 17, pp 249-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van den Berg</author>
<author>R Bod</author>
<author>R Scha</author>
</authors>
<title>A CorpusBased Approach to Semantic Interpretation&amp;quot;,</title>
<date>1994</date>
<booktitle>Proceedings Ninth Amsterdam Colloquium,</booktitle>
<location>Amsterdam, The Netherlands.</location>
<marker>van den Berg, Bod, Scha, 1994</marker>
<rawString>M. van den Berg, R. Bod and R. Scha, 1994. &amp;quot;A CorpusBased Approach to Semantic Interpretation&amp;quot;, Proceedings Ninth Amsterdam Colloquium, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
</authors>
<title>A Computational Model of Language Performance: Data Oriented Parsing&amp;quot;,</title>
<date>1992</date>
<booktitle>Proceedings COLING92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="1321" citStr="Bod 1992" startWordPosition="192" endWordPosition="193">tem we describe uses the OVIS corpus (10,000 trees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input. 1. Introduction The Data-Oriented Parsing (DOP) model (cf. Bod 1992, 1995; Bod &amp; Kaplan 1998; Scha 1992; Sima&apos;an 1995, 1997; Rajman 1995) is a probabilistic parsing model which does not single out a narrowly predefined set of structures as the statistically significant ones. It accomplishes this by maintaining a large corpus of analyses of previously occurring utterances. New utterances are analyzed by combining subtrees from the corpus. The occurrence-frequencies of the subtrees are used to estimate the most probable analysis of an utterance. To date, DOP has mainly been applied to corpora of trees labeled with syntactic annotations. Let us illustrate this w</context>
<context position="3362" citStr="Bod (1992)" startWordPosition="549" endWordPosition="550">a subtree t on a specific node as the probability of selecting t among all subtrees in the corpus that could be substituted on that node. This probability is equal to the number of occurrences of t, divided by the total number of occurrences of subtrees t&apos; with the same root label as t. Let rl(t) return the root label of t then: P(() = #(() It&apos;:rl(e)=rl(t)#(0. The probability of a derivation is computed by the product of the probabilities of the subtrees is consists of. The probability of a parse tree is computed by the sum of the probabilities of all derivations that produce that parse tree. Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street J</context>
<context position="21276" citStr="Bod 1992" startWordPosition="3538" endWordPosition="3539">nitialization of the chart usually consists of entering each word wi into chart entry &lt;i, i+1&gt;. For word-graphs, a transition &lt;i, j, w&gt; corresponds to a word w between positions i and j where j is not necessarily equal to i+1 as is the case for word strings (see figure 10). It is thus easy to see that for word-graphs the initialization of the chart consists of entering each word w from transition &lt;i, j, w&gt; into chart entry &lt;i, j&gt;. Next, parsing proceeds with the subtrees that are triggered by the dialogue context C (provided that all subtrees are converted into equivalent rewrite rules -- see Bod 1992, Sima&apos;an 1995). The most likely derivation is computed by a bottom-up best-first CKY parser adapted to DOP (Sima&apos;an 1995, 1997). This parser has a time complexity which is cubic in the number of word-graph nodes and linear in the grammar size. The top-node meaning of the tree resulting from the most likely derivation is taken as the best meaning M for an utterance A given context C. 6. Evaluation In our experimental evaluation of DOP we were interested in the following questions: (1) Is DOP fast enough for practical spoken dialogue understanding? (2) Can we constrain the OVIS subtrees without</context>
</contexts>
<marker>Bod, 1992</marker>
<rawString>R. Bod, 1992. &amp;quot;A Computational Model of Language Performance: Data Oriented Parsing&amp;quot;, Proceedings COLING92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
</authors>
<title>Enriching Linguistics with Statistics: Performance Models of Natural Language, ILLC Dissertation Series 1995-14,</title>
<date>1995</date>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="3634" citStr="Bod 1995" startWordPosition="589" endWordPosition="590">ot label as t. Let rl(t) return the root label of t then: P(() = #(() It&apos;:rl(e)=rl(t)#(0. The probability of a derivation is computed by the product of the probabilities of the subtrees is consists of. The probability of a parse tree is computed by the sum of the probabilities of all derivations that produce that parse tree. Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira </context>
<context position="13926" citStr="Bod 1995" startWordPosition="2278" endWordPosition="2279">a derivation D = ti ... 0 t„ is the product of the probabilities of its subtrees ti. The probability of a parse tree T is the sum of the probabilities of all derivations D that produce T. And the probability of a meaning M and a word string W is the sum of the probabilities of all parse trees T of W whose top-node meaning is logically equivalent to M (see Bod et al. 1996). As with the most probable parse, the most probable meaning M of a word string W cannot be computed in deterministic polynomial time. Although the most probable meaning can be estimated by iterative Monte Carlo sampling (see Bod 1995), the computation of a sufficiently large number of random derivations is currently not efficient enough for a practical application. To date, only the most likely derivation can be computed in near to real-time (by a best-first Viterbi optimization algorithm). We therefore assume that most of the probability mass for each top-node meaning is focussed on a single derivation. Under this assumption, the most likely meaning of a string is the top-node meaning generated by the most likely derivation of that string (see also section 5). 4. Extending DOP to dialogue context: context-dependent subcor</context>
</contexts>
<marker>Bod, 1995</marker>
<rawString>R. Bod, 1995. Enriching Linguistics with Statistics: Performance Models of Natural Language, ILLC Dissertation Series 1995-14, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
<author>R Scha</author>
</authors>
<title>Prediction and Disambiguation by means of Data-Oriented Parsing&amp;quot;,</title>
<date>1994</date>
<booktitle>Proceedings Twente Workshop on Language Technology (TWLT8),</booktitle>
<location>Twente, The Netherlands.</location>
<contexts>
<context position="19979" citStr="Bod &amp; Scha 1994" startWordPosition="3296" endWordPosition="3299">(M, W I C) and the word-graph probabilities P(A I W) so as to compute the probability P(M, A I C) and argmaxm P(M, A I C). We start by rewriting P(M, A I C) as: P(M, A I C) = Ew P(M, W, A IC) = w P(M, W I C) • P(A I M, W, C) The probability P(M, W I C) is computed by the dialogue-sensitive DOP model as explained in the previous section. To estimate the probability P(A I M, W, C) on the basis of the information available in the word-graphs, we must make the following independence assumption: the acoustic utterance A depends only on the word string W, and not on its context C and meaning M (cf. Bod &amp; Scha 1994). Under this assumption: P(M, A C) = Ew P(M, W I C) • P(A I W) To make fast computation feasible, we furthermore assume that most of the probability mass for each meaning and acoustic utterance is focused on a single word string W (this will allow for efficient Viterbi best first search): P(M, A I C) = P(M, W I C) P(A I W) Thus, the probability of a meaning M for an acoustic utterance A given a context C is computed by the product of the DOP probability P(M, W I C) and the word-graph probability P(A I W). As to the parsing of word-graphs, it is wellknown that parsing algorithms for word string</context>
</contexts>
<marker>Bod, Scha, 1994</marker>
<rawString>R. Bod and R. Scha, 1994. &amp;quot;Prediction and Disambiguation by means of Data-Oriented Parsing&amp;quot;, Proceedings Twente Workshop on Language Technology (TWLT8), Twente, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
<author>R Bonnema</author>
<author>R Scha</author>
</authors>
<title>A Data-Oriented Approach to Semantic Interpretation&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings Work -shop on Corpus-Oriented Semantic Analysis, ECAI-96,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="4660" citStr="Bod et al. (1996)" startWordPosition="753" endWordPosition="756">parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Thus the DOP method outperforms the Pereira &amp; Schabes method with an accuracy-increase of 6.9%, or an errorreduction of 33%. Goodman also performs a statistical analysis using t-test, showing that the differences are statistically significant beyond the 98th percentile. In Bod et al. (1996), it was shown how DOP can be generalized to semantic interpretation by using corpora annotated with compositional semantics. In the current paper, we extend the DOP model to spoken dialogue understanding, and we show how it can be used as an efficient and robust NLP component in a practical spoken dialogue system called OVIS. OVIS, Openbaar Vervoer Informatie Systeem (&amp;quot;Public Transport Information System&amp;quot;), is a Dutch spoken language information system which operates over ordinary telephone lines. The prototype system is the immediate goal of the NWO Priority Programme &amp;quot;Language and Speech Te</context>
<context position="13691" citStr="Bod et al. 1996" startWordPosition="2237" endWordPosition="2240">he original DOP model. That is, the probability of a subtree t is equal to the number of occurrences of t in the corpus divided by the number of occurrences of all subtrees t&apos; that can be substituted on the same node as t. The probability of a derivation D = ti ... 0 t„ is the product of the probabilities of its subtrees ti. The probability of a parse tree T is the sum of the probabilities of all derivations D that produce T. And the probability of a meaning M and a word string W is the sum of the probabilities of all parse trees T of W whose top-node meaning is logically equivalent to M (see Bod et al. 1996). As with the most probable parse, the most probable meaning M of a word string W cannot be computed in deterministic polynomial time. Although the most probable meaning can be estimated by iterative Monte Carlo sampling (see Bod 1995), the computation of a sufficiently large number of random derivations is currently not efficient enough for a practical application. To date, only the most likely derivation can be computed in near to real-time (by a best-first Viterbi optimization algorithm). We therefore assume that most of the probability mass for each top-node meaning is focussed on a single</context>
</contexts>
<marker>Bod, Bonnema, Scha, 1996</marker>
<rawString>R. Bod, R. Bonnema and R. Scha, 1996. &amp;quot;A Data-Oriented Approach to Semantic Interpretation&amp;quot;, Proceedings Work -shop on Corpus-Oriented Semantic Analysis, ECAI-96, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
<author>R Kaplan</author>
</authors>
<title>A Probabilistic Corpus-Driven Model for Lexical-Functional Analysis&amp;quot;, this proceedings.</title>
<date>1998</date>
<tech>Master&apos;s Thesis,</tech>
<institution>Department of Computational Linguistics, University of Amsterdam, The Netherlands.</institution>
<contexts>
<context position="1346" citStr="Bod &amp; Kaplan 1998" startWordPosition="195" endWordPosition="198">uses the OVIS corpus (10,000 trees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input. 1. Introduction The Data-Oriented Parsing (DOP) model (cf. Bod 1992, 1995; Bod &amp; Kaplan 1998; Scha 1992; Sima&apos;an 1995, 1997; Rajman 1995) is a probabilistic parsing model which does not single out a narrowly predefined set of structures as the statistically significant ones. It accomplishes this by maintaining a large corpus of analyses of previously occurring utterances. New utterances are analyzed by combining subtrees from the corpus. The occurrence-frequencies of the subtrees are used to estimate the most probable analysis of an utterance. To date, DOP has mainly been applied to corpora of trees labeled with syntactic annotations. Let us illustrate this with a very simple example</context>
</contexts>
<marker>Bod, Kaplan, 1998</marker>
<rawString>R. Bod and R. Kaplan, 1998. &amp;quot;A Probabilistic Corpus-Driven Model for Lexical-Functional Analysis&amp;quot;, this proceedings. R. Bonnema, 1996. Data-Oriented Semantics, Master&apos;s Thesis, Department of Computational Linguistics, University of Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bonnema</author>
<author>R Bod</author>
<author>R Scha</author>
</authors>
<title>A DOP Model for Semantic Interpretation&amp;quot;,</title>
<date>1997</date>
<booktitle>Proceedings ACL/EACL-97 ,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="7400" citStr="Bonnema et al. 1997" startWordPosition="1207" endWordPosition="1210">e parser will overgenerate, but as long as the probability model can accurately select the correct utterance-analysis from all possible analyses, this overgeneration is not problematic. Robustness is further achieved by a special category, called ERROR. This category is used for stutters, false starts, and repairs. No grammar is used to determine the correct syntactic annotation; there is a small set of guidelines, that has the degree of detail necessary to avoid an &amp;quot;anything goes&amp;quot; attitude in the annotator, but leaves room for the annotator&apos;s perception of the structure of the utterance (see Bonnema et al. 1997). The semantic annotations are based on the update language defined for the OVIS dialogue manager by Veldhuijzen van Zanten (1996). This language consists of a hierarchical frame structure with slots and values for the origin and destination of a train connection, for the time at which the user wants to arrive or depart, etc. The distinction between slots and values can be regarded as a special case of ground and focus distinction (Vallduvi 1990). Updates specify the ground and focus of the user utterances. For example, the utterance lk wil niet vandaag maar morgen naar Almere (literally: &amp;quot;I w</context>
</contexts>
<marker>Bonnema, Bod, Scha, 1997</marker>
<rawString>R. Bonnema, R. Bod and R. Scha, 1997. &amp;quot;A DOP Model for Semantic Interpretation&amp;quot;, Proceedings ACL/EACL-97 , Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Boros</author>
</authors>
<title>Towards understanding spontaneous speech: word accuracy vs. concept accuracy.&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings ICSLP&apos;96,</booktitle>
<location>Philadelphia (PA).</location>
<marker>Boros, 1996</marker>
<rawString>M. Boros et al. 1996. &amp;quot;Towards understanding spontaneous speech: word accuracy vs. concept accuracy.&amp;quot; Proceedings ICSLP&apos;96, Philadelphia (PA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Tree-bank Grammars&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings AAAI-96, Menlo Park (Ca).</booktitle>
<contexts>
<context position="4066" citStr="Charniak 1996" startWordPosition="660" endWordPosition="661">es. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Thus the DOP method outperforms the Pereira &amp; Schabes method with an accuracy-increase of 6.9%, or an errorreduction of 33%. Goodman also performs a statistical analysis using t-test, showing that the differences are statistically significant beyond the 98th percentile. In Bod et al. (1996), it w</context>
</contexts>
<marker>Charniak, 1996</marker>
<rawString>E. Charniak, 1996. &amp;quot;Tree-bank Grammars&amp;quot;, Proceedings AAAI-96, Menlo Park (Ca).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<title>Efficient Algorithms for Parsing the DOP Model&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings Empirical Methods in Natural Language Processing,</booktitle>
<location>Philadelphia (PA).</location>
<contexts>
<context position="3872" citStr="Goodman 1996" startWordPosition="630" endWordPosition="631">is computed by the sum of the probabilities of all derivations that produce that parse tree. Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Thus the DOP method outperforms the Pereira &amp; Schabes method with an accuracy-increase of 6.9%, or an e</context>
</contexts>
<marker>Goodman, 1996</marker>
<rawString>J. Goodman, 1996. &amp;quot;Efficient Algorithms for Parsing the DOP Model&amp;quot;, Proceedings Empirical Methods in Natural Language Processing, Philadelphia (PA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<date>1998</date>
<tech>Parsing Inside-Out, Ph.D. thesis,</tech>
<institution>Harvard University,</institution>
<location>Massachusetts.</location>
<contexts>
<context position="4095" citStr="Goodman (1998)" startWordPosition="664" endWordPosition="665">of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Thus the DOP method outperforms the Pereira &amp; Schabes method with an accuracy-increase of 6.9%, or an errorreduction of 33%. Goodman also performs a statistical analysis using t-test, showing that the differences are statistically significant beyond the 98th percentile. In Bod et al. (1996), it was shown how DOP can be gener</context>
</contexts>
<marker>Goodman, 1998</marker>
<rawString>J. Goodman, 1998. Parsing Inside-Out, Ph.D. thesis, Harvard University, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
</authors>
<title>A fully statistical approach to natural language interfaces&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings ACL&apos;96,</booktitle>
<location>Santa Cruz (Ca.).</location>
<marker>Miller, 1996</marker>
<rawString>S. Miller et al. 1996. &amp;quot;A fully statistical approach to natural language interfaces&amp;quot;, Proceedings ACL&apos;96, Santa Cruz (Ca.).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
</authors>
<title>The intersection of finite state automata and definite clause grammars&amp;quot;,</title>
<date>1995</date>
<booktitle>Proceedings ACL&apos;95 ,</booktitle>
<location>Boston, Massachusetts.</location>
<marker>van Noord, 1995</marker>
<rawString>G. van Noord, 1995. &amp;quot;The intersection of finite state automata and definite clause grammars&amp;quot;, Proceedings ACL&apos;95 , Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
<author>G Bouma</author>
<author>R Koeling</author>
<author>M Nederhof</author>
</authors>
<title>Robust Grammatical Analysis for Spoken Dialogue Systems,</title>
<date>1997</date>
<note>unpublished manuscript.</note>
<marker>van Noord, Bouma, Koeling, Nederhof, 1997</marker>
<rawString>G. van Noord, G. Bouma, R. Koeling and M. Nederhof, 1997. Robust Grammatical Analysis for Spoken Dialogue Systems, unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>Y Schabes</author>
</authors>
<title>Inside-Outside Reestimation from Partially Bracketed Corpora&amp;quot;,</title>
<date>1992</date>
<booktitle>Proceedings ACL&apos;92,</booktitle>
<location>Newark, Delaware.</location>
<contexts>
<context position="4179" citStr="Pereira &amp; Schabes (1992)" startWordPosition="677" endWordPosition="680">st probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Thus the DOP method outperforms the Pereira &amp; Schabes method with an accuracy-increase of 6.9%, or an errorreduction of 33%. Goodman also performs a statistical analysis using t-test, showing that the differences are statistically significant beyond the 98th percentile. In Bod et al. (1996), it was shown how DOP can be generalized to semantic interpretation by using corpora annotated with compositional sema</context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>F. Pereira and Y. Schabes, 1992. &amp;quot;Inside-Outside Reestimation from Partially Bracketed Corpora&amp;quot;, Proceedings ACL&apos;92, Newark, Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rajman</author>
</authors>
<title>Approche Probabiliste de l&apos;Analyse Syntaxique&amp;quot;,</title>
<date>1995</date>
<journal>Gramma/77l</journal>
<booktitle>Traitement Automatique des Gangues, 36(1-2). R. Scha</booktitle>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="1391" citStr="Rajman 1995" startWordPosition="204" endWordPosition="205">ompositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input. 1. Introduction The Data-Oriented Parsing (DOP) model (cf. Bod 1992, 1995; Bod &amp; Kaplan 1998; Scha 1992; Sima&apos;an 1995, 1997; Rajman 1995) is a probabilistic parsing model which does not single out a narrowly predefined set of structures as the statistically significant ones. It accomplishes this by maintaining a large corpus of analyses of previously occurring utterances. New utterances are analyzed by combining subtrees from the corpus. The occurrence-frequencies of the subtrees are used to estimate the most probable analysis of an utterance. To date, DOP has mainly been applied to corpora of trees labeled with syntactic annotations. Let us illustrate this with a very simple example. Suppose that a corpus consists of only two </context>
</contexts>
<marker>Rajman, 1995</marker>
<rawString>M. Rajman 1995. &amp;quot;Approche Probabiliste de l&apos;Analyse Syntaxique&amp;quot;, Traitement Automatique des Gangues, 36(1-2). R. Scha 1992. &amp;quot;Virtuele Grammatica&apos;s en Creatieve Algoritmen&amp;quot;, Gramma/77l 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sima&apos;an</author>
</authors>
<title>An optimized algorithm for Data Oriented Parsing&amp;quot;, In:</title>
<date>1995</date>
<booktitle>Recent Advances in Natural Language Processing 1995, volume 136 of Current Issues in Linguistic Theory. John Benjamins,</booktitle>
<editor>R. Mitkov and N. Nicolov (eds.),</editor>
<location>Amsterdam.</location>
<contexts>
<context position="1371" citStr="Sima&apos;an 1995" startWordPosition="201" endWordPosition="202">rees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input. 1. Introduction The Data-Oriented Parsing (DOP) model (cf. Bod 1992, 1995; Bod &amp; Kaplan 1998; Scha 1992; Sima&apos;an 1995, 1997; Rajman 1995) is a probabilistic parsing model which does not single out a narrowly predefined set of structures as the statistically significant ones. It accomplishes this by maintaining a large corpus of analyses of previously occurring utterances. New utterances are analyzed by combining subtrees from the corpus. The occurrence-frequencies of the subtrees are used to estimate the most probable analysis of an utterance. To date, DOP has mainly been applied to corpora of trees labeled with syntactic annotations. Let us illustrate this with a very simple example. Suppose that a corpus c</context>
<context position="3771" citStr="Sima&apos;an 1995" startWordPosition="610" endWordPosition="611"> by the product of the probabilities of the subtrees is consists of. The probability of a parse tree is computed by the sum of the probabilities of all derivations that produce that parse tree. Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replication of Pereira &amp; Schabes (1992) on the same training and test data. While the Pereira &amp; Schabes method achieves 79.2% zero-crossing brackets accuracy, DOP obtains 86.1% on the same data (Goodman 1998: p. 179, table 4.4). Th</context>
<context position="21291" citStr="Sima&apos;an 1995" startWordPosition="3540" endWordPosition="3541">ion of the chart usually consists of entering each word wi into chart entry &lt;i, i+1&gt;. For word-graphs, a transition &lt;i, j, w&gt; corresponds to a word w between positions i and j where j is not necessarily equal to i+1 as is the case for word strings (see figure 10). It is thus easy to see that for word-graphs the initialization of the chart consists of entering each word w from transition &lt;i, j, w&gt; into chart entry &lt;i, j&gt;. Next, parsing proceeds with the subtrees that are triggered by the dialogue context C (provided that all subtrees are converted into equivalent rewrite rules -- see Bod 1992, Sima&apos;an 1995). The most likely derivation is computed by a bottom-up best-first CKY parser adapted to DOP (Sima&apos;an 1995, 1997). This parser has a time complexity which is cubic in the number of word-graph nodes and linear in the grammar size. The top-node meaning of the tree resulting from the most likely derivation is taken as the best meaning M for an utterance A given context C. 6. Evaluation In our experimental evaluation of DOP we were interested in the following questions: (1) Is DOP fast enough for practical spoken dialogue understanding? (2) Can we constrain the OVIS subtrees without loosing accura</context>
</contexts>
<marker>Sima&apos;an, 1995</marker>
<rawString>K. Sima&apos;an, 1995. &amp;quot;An optimized algorithm for Data Oriented Parsing&amp;quot;, In: R. Mitkov and N. Nicolov (eds.), Recent Advances in Natural Language Processing 1995, volume 136 of Current Issues in Linguistic Theory. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sima&apos;an</author>
</authors>
<title>Computational Complexity of Probabilistic Disambiguation by means of Tree Grammars&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings COLING-96,</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="3547" citStr="Sima&apos;an 1996" startWordPosition="575" endWordPosition="576">ccurrences of t, divided by the total number of occurrences of subtrees t&apos; with the same root label as t. Let rl(t) return the root label of t then: P(() = #(() It&apos;:rl(e)=rl(t)#(0. The probability of a derivation is computed by the product of the probabilities of the subtrees is consists of. The probability of a parse tree is computed by the sum of the probabilities of all derivations that produce that parse tree. Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques. However, the computation of the most probable parse of a sentence is NP-hard (Sima&apos;an 1996). The most probable parse can be estimated by iterative Monte Carlo sampling (Bod 1995), but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence (Bod 1995, Sima&apos;an 1995) or the &amp;quot;labelled NP Susan NP NP zs\VP Mary V NP Susan 138 recall parse&amp;quot; of a sentence (Goodman 1996). So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers (Charniak 1996). For example, Goodman (1998) compares the results of his DOP parser to a replica</context>
</contexts>
<marker>Sima&apos;an, 1996</marker>
<rawString>K. Sima&apos;an, 1996. &amp;quot;Computational Complexity of Probabilistic Disambiguation by means of Tree Grammars&amp;quot;, Proceedings COLING-96, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sima&apos;an</author>
</authors>
<title>Explanation-Based Learning of DataOriented Parsing&amp;quot;,</title>
<date>1997</date>
<booktitle>CoNLL9 7: Computational Natural Language Learning, ACL&apos;97,</booktitle>
<editor>in T. Ellison (ed.)</editor>
<location>Madrid, Spain.</location>
<marker>Sima&apos;an, 1997</marker>
<rawString>K. Sima&apos;an, 1997. &amp;quot;Explanation-Based Learning of DataOriented Parsing&amp;quot;, in T. Ellison (ed.) CoNLL9 7: Computational Natural Language Learning, ACL&apos;97, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Vallduvi</author>
</authors>
<title>The Informational Component.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania, PA.</institution>
<contexts>
<context position="7850" citStr="Vallduvi 1990" startWordPosition="1283" endWordPosition="1284">ry to avoid an &amp;quot;anything goes&amp;quot; attitude in the annotator, but leaves room for the annotator&apos;s perception of the structure of the utterance (see Bonnema et al. 1997). The semantic annotations are based on the update language defined for the OVIS dialogue manager by Veldhuijzen van Zanten (1996). This language consists of a hierarchical frame structure with slots and values for the origin and destination of a train connection, for the time at which the user wants to arrive or depart, etc. The distinction between slots and values can be regarded as a special case of ground and focus distinction (Vallduvi 1990). Updates specify the ground and focus of the user utterances. For example, the utterance lk wil niet vandaag maar morgen naar Almere (literally: &amp;quot;I want not today but tomorrow to Almere&amp;quot;) yields the following update: (4) user.wants.M# today];[! tomorrow]); destination.place.town.almere) An important property of this update language is that it allows encoding of speech-act information (v. Noord et al. 1997). The &amp;quot;#&amp;quot; in the update means that the information between the square brackets (representing the focus of the user-utterance) must be retracted, while the &amp;quot;!&amp;quot; denotes the corrected informati</context>
</contexts>
<marker>Vallduvi, 1990</marker>
<rawString>E. Vallduvi, 1990. The Informational Component. Ph.D. thesis, University of Pennsylvania, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Veldhuijzen van Zanten</author>
</authors>
<title>Semantics of update expressions.</title>
<date>1996</date>
<tech>Technical Report 24. NWO Priority</tech>
<marker>van Zanten, 1996</marker>
<rawString>G. Veldhuijzen van Zanten, 1996. Semantics of update expressions. Technical Report 24. NWO Priority Programme Language and Speech Technology, The Hague.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>