<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.981607">
Unsupervised Induction of Sentence Compression Rules
</title>
<author confidence="0.943718">
Jo˜ao Cordeiro
</author>
<affiliation confidence="0.962845">
CLT and Bioinformatics
University of Beira Interior
</affiliation>
<address confidence="0.503314">
Covilh˜a, Portugal
</address>
<email confidence="0.960783">
jpaulo@di.ubi.pt
</email>
<author confidence="0.947531">
Ga¨el Dias
</author>
<affiliation confidence="0.964772">
CLT and Bioinformatics
University of Beira Interior
</affiliation>
<address confidence="0.498437">
Covilh˜a, Portugal
</address>
<email confidence="0.944426">
ddg@di.ubi.pt
</email>
<author confidence="0.756185">
Pavel Brazdil
</author>
<affiliation confidence="0.7852645">
LIAAD
University of Porto
</affiliation>
<address confidence="0.765202">
Porto, Portugal
</address>
<email confidence="0.985471">
pbrazdil@liaad.up.pt
</email>
<sectionHeader confidence="0.994793" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960285714286">
In this paper, we propose a new unsu-
pervised approach to sentence compres-
sion based on shallow linguistic process-
ing. For that purpose, paraphrase extrac-
tion and alignment is performed over web
news stories extracted automatically from
the web on a daily basis to provide struc-
tured data examples to the learning pro-
cess. Compression rules are then learned
through the application of Inductive Logic
Programming techniques. Qualitative and
quantitative evaluations suggests that this
is a worth following approach, which
might be even improved in the future.
</bodyText>
<sectionHeader confidence="0.998066" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999654333333333">
Sentence compression, simplification or summa-
rization has been an active research subject dur-
ing this decade. A set of approaches involving
machine learning algorithms and statistical mod-
els have been experimented and documented in the
literature and several of these are described next.
</bodyText>
<sectionHeader confidence="0.667868" genericHeader="related work">
1.1 Related Work
</sectionHeader>
<bodyText confidence="0.9983808">
In (Knight &amp; Marcu, 2002) two methods were
proposed, one is a probabilistic model - the
noisy channel model - where the probabili-
ties for sentence reduction (P{Scompress|S)}
1) are estimated from a training set of 1035
(Sentence, Sentencecompress) pairs, manually
crafted, while considering lexical and syntacti-
cal features. The other approach learns syntac-
tic tree rewriting rules, defined through four op-
erators: SHIFT, REDUCE DROP and ASSIGN.
Sequences of these operators are learned from the
training set, and each sequence defines a complete
1In the original paper the P(tIs) notation is used, where t
is the sentence in the target language and s the original sen-
tence in the source language.
transformation from an original sentence to the
compressed version.
In the work of (Le Nguyen &amp; Ho, 2004)
two sentence reduction algorithms were also pro-
posed. The first one is based on template-
translation learning, a method inherited from the
machine translation field, which learns lexical
transformation rules2, by observing a set of 1500
(Sentence, Sentencereduced) pair, selected from
a news agency and manually tuned to obtain the
training data. Due to complexity difficulties found
for the application of this big lexical ruleset, they
proposed an improvement where a stochastic Hid-
den Markov Model is trained to help in the deci-
sion of which sequence of possible lexical reduc-
tion rules should be applied to a specific case.
An unsupervised approach was included in the
work of (Turner &amp; Charniak, 2005), where train-
ing data are automatically extracted from the Penn
Treebank corpus, to fit a noisy channel model,
similar to the one used by (Knight &amp; Marcu,
2002). Although it seems an interesting approach
to provide new training instances, it still be depen-
dent upon data manually labeled.
More recently, the work of (Clarke &amp; Lapata,
2006) devise a different and quite curious ap-
proach, where the sentence compression task is
defined as an optimization goal, from an Integer
Programming problem. Several constraints are de-
fined, according to language models, linguistic,
and syntactical features. Although this is an unsu-
pervised approach, without using any paralel cor-
pus, it is completely knowledge driven, like a set
of crafted rules and heuristics incorporated into a
system to solve a certain problem.
</bodyText>
<subsectionHeader confidence="0.944143">
1.2 Our Proposal
</subsectionHeader>
<bodyText confidence="0.991487">
In this paper, we propose a new approach to
this research field, which follows an unsupervised
methodology to learn sentence compression rules
</bodyText>
<footnote confidence="0.508288">
2Those rules are named there as template-reduction rules.
</footnote>
<note confidence="0.853183333333333">
15
Proceedings of the 2009 Workshop on Language Generation and Summarisation, ACL-IJCNLP 2009, pages 15–22,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99947">
based on shallow linguistic processing. We de-
signed a system composed of four main steps
working in pipeline, where the first three are re-
sponsible for data extraction and preparation and
in the last one the induction process takes place.
The first step gathers web news stories from re-
lated news events collected on a daily basis from
which paraphrases are extracted. In the second
step, word alignment between two sentences of
a paraphrase is processed. In the third step, spe-
cial regions from these aligned paraphrases, called
bubbles, are extracted and conveniently prepro-
cessed to feed the induction process. The whole
sequence is schematized in figure 1.
</bodyText>
<figureCaption confidence="0.999638">
Figure 1: The Pipeline Architecture.
</figureCaption>
<bodyText confidence="0.998517461538462">
The induction process generates sentence re-
duction rules which have the following general
structure: Lcond∧Xcond∧Rcond ⇒ suppress(X).
This means that the sentence segment X will
be eliminated if certain conditions hold over left
(L), middle (X) and right (R) segments3. In
Figure 2, we present seven different rules which
have been automatically induced from our archi-
tecture. These rules are formed by the conjunc-
tion of several literals, and they define constraints
under which certain sentence subparts may be
deleted, therefore compressing or simplifying the
sentence. The X symbol stands for the segment
</bodyText>
<footnote confidence="0.8377955">
3For the sake of simplicity and compact representation,
we will omit the rule consequent, which is always the same
</footnote>
<equation confidence="0.981894875">
(”⇒ suppress(X)”), whenever a rule is presented.
Z(X) = 1 ∧ Lc = NP ∧ X1 = JJ ∧ R1 = IN (1)
Z(X) = 1 ∧ Lc = NP ∧ X1 = RB ∧ R1 = IN (2)
Z(X) = 2 ∧ L1 = and ∧ X1 = the ∧ R1 = JJ (3)
Z(X) = 2 ∧ L1 = the ∧ X2 = of ∧ R1 = NN (4)
Z(X) = 2 ∧ L1 = the ∧ Xc = NP ∧ R1 = NN (5)
Z(X) = 3 ∧ Lc = PP ∧ X1 = the ∧ Rc = NP (6)
Z(X) = 3 ∧ Lc = NP ∧ X1 = and ∧ R2 = V B (7)
</equation>
<figureCaption confidence="0.974042">
Figure 2: Learned Sentence Compression Rules.
</figureCaption>
<bodyText confidence="0.943924586206897">
to be dropped, L(*) and R(*) are conditions over
the left and right contexts respectively. The nu-
meric subscripts indicate the positions4 where a
segment constraint holds and the c subscript stands
for a syntactic chunk type. The Z(•) function com-
putes the length of a given segment, by counting
the number of words it contains. For instance, the
first rule means that a word5 will be eliminated if
we have a NP (Noun Phrase) chunk in the left
context, and a preposition or subordinating con-
junction, in the right context (R1 = IN). The rule
also requires that the elimination word must be an
adjective, as we have X1 = JJ.
This rule would be applied to the following seg-
ment6
[NP mutual/jj funds/nns information/nn]
[ADJP available/jj] [PP on/in] [NP
reuters.com/nn]
and would delete the word available giving rise
to the simplified segment:
[NP mutual/jj funds/nns information/nn]
[PP on/in] [NP reuters.com/nn].
Comparatively to all existing works, we propose
in this paper a framework capable to extract com-
pression rules in a real world environment. More-
over, it is fully unsupervised as, at any step of the
process, examples do not need to be labeled.
In the remaining of the paper, we will present
the overall architecture which achieves precision
</bodyText>
<footnote confidence="0.972934875">
4The position starts with 1 and is counted from left to
right, on the word segments, except for the left context, where
it is counted reversely.
5As we have Z(X) = 1, the candidate segment size to
eliminate is equal to one.
6The segment is marked with part-of-speech tags (POS)
and chunked with a shallow parser. Both transformations
were made with the OpenNLP toolkit.
</footnote>
<page confidence="0.94928">
16
</page>
<bodyText confidence="0.96996">
values up to 85.72%, correctness up to 4.03 in 5
and utility up to 85.72%.
</bodyText>
<sectionHeader confidence="0.973354" genericHeader="method">
2 Data Preparation
</sectionHeader>
<bodyText confidence="0.999905333333333">
Creating relevant training sets, with some thou-
sands examples is a difficult task, as well as is the
migration of such a system to process other lan-
guages. Therefore, we propose an unsupervised
methodology to automatically create a training set
of aligned paraphrases, from electronically avail-
able texts on the web. This step is done through
step one and step two of Figure 1, and the details
are described in the next two subsections.
</bodyText>
<subsectionHeader confidence="0.998823">
2.1 Paraphrase Extraction
</subsectionHeader>
<bodyText confidence="0.999791114285714">
Our system collects web news stories on a daily
basis, and organized them into clusters, which
are exclusively related to different and unique
events, happening each day: ”a company acqui-
sition”, ”a presidential speech”, ”a bomb attack”,
etc. Usually, such clusters contain near 30 small
or medium news articles, collected from differ-
ent media sources. This environment proves to be
very fruitful for paraphrase extraction, since we
have many sentences conveying similar informa-
tion yet written in a different form.
A few unsupervised metrics have been applied
to automatic paraphrase identification and extrac-
tion (Barzilay &amp; Lee, 2003; Dolan et al., 2004).
However, these unsupervised methodologies show
a major drawback by extracting quasi-exact or
even exact match pairs of sentences as they rely
on classical string similarity measures such as the
Edit Distance in the case of (Dolan et al., 2004)
and Word N-gram Overlap for (Barzilay &amp; Lee,
2003). Such pairs are useless for our purpose,
since we aim to identify asymmetrical paraphrase
pairs to be used for sentence compression rule
induction, as explained in (Cordeiro et al., Oct
2007). There we proposed a new metric, the
Sumo-Metric, specially designed for asymmetrical
entailed pairs identification, and proved better per-
formance over previous established metrics, even
in the specific case when tested with the Microsoft
Paraphrase Research Corpus (Dolan et al., 2004),
which contains mainly symmetrical cases. For a
given sentence pair, having each sentence x and
y words, and with A exclusive links between the
sentences, the Sumo-Metric is defined in Equation
8 and 9.
</bodyText>
<equation confidence="0.9894645">
S(x, y, A) if S(x, y, A) &lt; 1.0
0 if A = 0
e−k∗S(x,r,λ) otherwise
(8)
</equation>
<bodyText confidence="0.754565">
where
</bodyText>
<equation confidence="0.996359333333333">
S(x, y, A) = α log2( x(9)
A) + β log2( y A)
with α, Q ∈ [0, 1] and α + Q = 1.
</equation>
<bodyText confidence="0.999991">
We have shown (Cordeiro et al., Oct 2007) that
Sumo-Metric outperforms all state-of-the-art met-
rics over all tested corpora and allows to identify-
ing similar sentences with high probability to be
paraphrases. In Figure 3, we provide the reader
with an example of an extracted paraphrase.
</bodyText>
<listItem confidence="0.994993666666667">
(1) To the horror of their fans, Miss Ball
and Arnaz were divorced in 1960.
(2) Ball and Arnaz divorced in 1960.
</listItem>
<figureCaption confidence="0.852007">
Figure 3: An Assymetrical Paraphrase
</figureCaption>
<subsectionHeader confidence="0.998407">
2.2 Paraphrase Alignment
</subsectionHeader>
<bodyText confidence="0.999989578947369">
From a corpus of asymmetrical paraphrases, we
then use biology-based gene alignment algorithms
to align the words contained in each of the two
sentences within each paraphrase. For that pur-
pose, we implemented two well established algo-
rithms, one identifying local alignments (Smith
&amp; Waterman, 1981) and the other one computing
global alignments (Needleman &amp; Wunsch, 1970).
We also proposed a convenient dynamic strategy
(Cordeiro et al., 2007), which chooses the best
alignment algorithm to be applied to a specific
case at runtime.
The difference between local and global se-
quence alignments is illustrated below, where we
use letters, instead of words, to better fit our paper
space constraints. Suppose that we have the fol-
lowing two sequences: [D,H,M,S,T,P,R,Q,I,S]
and [T,P,Q,I,S,D,H,S] a global alignment
would produce the following pair.
</bodyText>
<equation confidence="0.8807505">
D H M S T P R Q I S _ _ _
_ _ _ _ T P _ Q I S D H S
</equation>
<bodyText confidence="0.999820333333333">
For the same two sequences, a local alignment
strategy could generate two or more aligned sub-
sequences as follows.
</bodyText>
<equation confidence="0.994875">
S(Sa, Sb) = I
17
|D H M S ||T P R Q I S|
|D H — S ||T P — Q I S|
</equation>
<bodyText confidence="0.98401975">
Hence, at this stage of the process, we end with a
corpus of aligned7 asymmetrical paraphrases. In
Figure 4, we present the alignment of the para-
phrase of Figure 3.
</bodyText>
<listItem confidence="0.95335975">
(1) To the horror of their fans ,
(2) —— ——— —————— —— ————— ———— —
(1)Miss Ball and Arnaz were divorced in 1960.
(2)———— Ball and Arnaz ————divorced in 1960.
</listItem>
<figureCaption confidence="0.99114">
Figure 4: An Aligned Paraphrase
</figureCaption>
<bodyText confidence="0.9998874">
The next section describes how we use this
structured data to extract instances which are go-
ing to feed a learning system.
Equation 10 to decide whether a bubble should be
extracted or not.
</bodyText>
<equation confidence="0.989976">
Z(L) − Z(X) + Z(R) &gt; 0 (10)
</equation>
<bodyText confidence="0.9995088">
where L and R stand for the left and right contexts,
respectively, and X is the middle region. The Z(•)
function computes the length of a given segment,
in terms of number of words. For example, in the
first and last examples of Figure 5, we have: 2 −
1+5 = 6 &gt; 0 and 4−3+4 = 5 &gt; 0. In this case,
both bubbles will be extracted. This condition is
defined to prevent from extracting eccentric cases,
as the ones shown in the examples shown in Figure
6, where the conditions respectively fail: 0 − 8 +
</bodyText>
<equation confidence="0.5588595">
3 = −5 &lt; 0 and 1 − 7 + 2 = −4 &lt; 0.
—— ——— —————— —— ————— ———— — ————
</equation>
<bodyText confidence="0.729707">
To the horror of their fans , Miss Ball and Arnaz
</bodyText>
<note confidence="0.498786">
Ball and Arnaz
</note>
<sectionHeader confidence="0.442637" genericHeader="method">
3 Bubble Extraction
</sectionHeader>
<bodyText confidence="0.976857315789474">
In order to learn rewriting rules, we have focus
our experiences on a special kind of data, se-
lected from the corpus of aligned sentences, and
we named this data as Bubbles8. Given two word
aligned sentences, a bubble is a non-empty seg-
ment aligned with an empty segment of the other
sentence of the paraphrase, sharing a “strong” con-
text. In Figure 5, we show different examples of
bubbles.
the situation here in chicago with the workers
the situation ————in chicago with the workers
obama talks exclusively with tom brokaw on meet
obama talks with tom brokaw on meet
Ball and Arnaz were divorced in 1960
Ball and Arnaz ————divorced in 1960
america is in the exact same seat as sweigert and
america is in ——— —————same seat as sweigert and
after a while at the regents park gym, the president
after a while at ——— ——————— ————gym, the president
</bodyText>
<figureCaption confidence="0.996791">
Figure 5: Examples of Bubbles
</figureCaption>
<bodyText confidence="0.7938044">
To extract a bubble, left and right contexts of
equally aligned words must occur, and the proba-
bility of such extraction depends on the contexts
size as well as the size of the region aligned with
the empty space. The main idea is to eliminate
cases where the bubble middle sequence is too
large when compared to the size of left and right
contexts. More precisely, we use the condition in
7By ”aligned” we mean, from now on, word alignment
between paraphrase sentence pairs.
8There are other possible regions to explore, but due to
the complexity of this task, we decided to initially work only
with bubbles
will vote —— ——— ——————— ———— —— ————— ——friday .
———— vote on the amended bill as early as friday .
</bodyText>
<figureCaption confidence="0.997944">
Figure 6: Examples of Rejected Bubbles
</figureCaption>
<bodyText confidence="0.9844255">
Indeed, we favor examples with high common
contexts and few deleted words to enhance the in-
duction process.
So far, we only consider bubbles where the
middle region is aligned with a void segment
(X transf
−� 0). However, more general transforma-
tions will be investigated in the future. Indeed, any
</bodyText>
<equation confidence="0.90898525">
trans f
transformation X −� Y , where Y =� 0, having
Z(X) &gt; Z(Y ), may be a relevant compression ex-
ample.
</equation>
<bodyText confidence="0.999885272727273">
Following this methodology, we obtain a huge
set of examples, where relevant sentence transfor-
mations occur. To have an idea about the amount
of data we are working with, from a set of 30 days
web news stories (133.5 MB of raw text), we iden-
tified and extracted 596678 aligned paraphrases,
from which 143761 bubbles were obtained.
In the next section, we show how we explore
Inductive Logic Programming (ILP) techniques to
generalize regularities and find conditions to com-
press sentence segments.
</bodyText>
<sectionHeader confidence="0.98544" genericHeader="method">
4 The Induction of Compression Rules
</sectionHeader>
<bodyText confidence="0.9997764">
Many different algorithms exist to induce knowl-
edge from data. In this paper, we use Inductive
Logic Programming (ILP) (Muggleton, 1991) and
it was a choice based on a set of relevant fea-
tures like: the capacity to generate symbolic and
</bodyText>
<page confidence="0.778824">
18
</page>
<bodyText confidence="0.999971263157895">
relational knowledge; the possibility to securely
avoid negative instances; the ability to mix differ-
ent types of attribute and to have more control over
the theory search process.
Unlike (Clarke &amp; Lapata, 2006), we aim at
inducing human understandable knowledge, also
known as symbolic knowledge. For that pur-
pose, ILP satisfies perfectly this goal by produc-
ing clauses based on first order logic. Moreover,
most of the learning algorithms require a com-
plete definition and characterization of the feature
set, prior to the learning process, where any at-
tribute must be specified. This is a conceptual bot-
tleneck to many learning problems such as ours,
since we need to combine different types of at-
tributes i.e. lexical, morpho-syntactic and syntac-
tical. With ILP, we only need to define a set of pos-
sible features and the induction process will search
throughout this set.
</bodyText>
<subsectionHeader confidence="0.998761">
4.1 The Aleph System
</subsectionHeader>
<bodyText confidence="0.99999519047619">
The Aleph system(Srinivasan, 2000) is an empir-
ical ILP system, initially designed to be a pro-
totype for exploring ILP ideas. It has become a
quite mature ILP implementation, used in many
research projects, ranging form Biology to NLP. In
fact, Aleph is the successor of several and ”more
primitive” ILP systems, like: Progol (Muggleton,
1999), FOIL (Quinlan, 1990), and Indlog (Cama-
cho, 1994), among others, and may be appropri-
ately parametrized to emulate any of those older
systems.
One interesting advantage in Aleph is the possi-
bility to learn exclusively from positive instances,
contrarily to what is required by most learning sys-
tems. Moreover, there is theoretical research work
(Muggleton, 1996) demonstrating that the increase
in the learning error tend to be negligible with the
absence of negative examples, as the number of
learning instances increases. This is a relevant
issue, for many learning domains, and specially
ours, where negative examples are not available.
</bodyText>
<subsectionHeader confidence="0.997727">
4.2 Learning Instances
</subsectionHeader>
<bodyText confidence="0.999606083333333">
In our problem, we define predicates that charac-
terize possible features to be considered during the
induction process. Regarding the structure of our
learning instances (bubbles), we define predicates
which restrict left and right context sequences as
well as the aligned middle sequence. In particu-
lar, we limit the size of our context sequences to
a maximum of three words and, so far, only use
bubbles in which the middle sequence has a max-
imum length of three9 words. The notion of con-
texts from bubbles is clarified with the next exam-
ple.
</bodyText>
<equation confidence="0.999422">
L2 L1 X1 X2 X3 R1 R2 R3 R4
L2 L1 __ __ __ R1 R2 R3 R4
</equation>
<bodyText confidence="0.954331736842105">
For such a case, we consider [L1, L2] as the left
context, [R1, R2, R3] as the right context, and
[X1, X2, X3] as the aligned middle sequence.
Such an example is represented with a Prolog term
with arity 5 (bub/5) in the following manner:
bub(ID, t(3,0), [L1,L2],
[X1,X2,X3]---&gt;[],
[R1,R2,R3]).
The ID is the identifier of the sequence instance,
t/2 defines the “transformation dimension”, in
this case from 3 words to 0. The third and fifth
arguments are lists with the left and right con-
texts, respectively, and the fourth argument con-
tains the list with the elements deleted from the
middle sequence. It is important to point out that
every LZ, XZ and R, are structures with 3 elements
such as word/POS/Chunk. For example, the
word president would be represented by the
expanded structure president/nn/np.
</bodyText>
<subsectionHeader confidence="0.999291">
4.3 Feature Space
</subsectionHeader>
<bodyText confidence="0.999968904761905">
As mentioned previously, with an ILP system, and
in particular with Aleph, the set of attributes is
defined through a set of conditions, expressed in
the form of predicates. These predicates are the
building blocks that will be employed to construct
rules, during the induction process. Hence, our at-
tribute search space is defined using Prolog pred-
icates, which define the complete set of possibil-
ities for rule body construction. In our problem,
we let the induction engine seek generalization
conditions for the bubble main regions (left, mid-
dle, and right). Each condition may be from one
of the four types: dimensional, lexical, POS, and
chunk. Dimensional conditions simply express
the aligned sequence transformation dimensional-
ity. Lexical conditions impose a fixed position to
match a given word. The POS condition is similar
to the lexical one, but more general, as the position
must match a specific part-of-speech tag. Likely,
chunk conditions bind a region to be equal to a
particular chunk type. For example, by looking
</bodyText>
<footnote confidence="0.433366">
9They represent 83.47% from the total number of ex-
tracted bubbles.
</footnote>
<page confidence="0.905168">
19
</page>
<bodyText confidence="0.957925611111111">
at Figure 2, the attentive reader may have noticed
that these three conditions are present in rule 7. In
terms of Aleph declaration mode, these conditions
are defined as follows.
:- modeh(1,rule(+bub)).
:- modeb(1,transfdim(+bub,n(#nat,#nat))).
:- modeb(3,chunk(+bub,#side,#chk)).
:- modeb(*,inx(+bub,#side,#k,#tword)).
:- determination(rule/1,transfdim/2).
:- determination(rule/1,chunk/3).
:- determination(rule/1,inx/4).
The inx/4 predicate defines lexical and POS
type conditions, the chunk/3 predicate de-
fines chunking conditions and the transfdim/2
predicate defines the transformation dimension-
ality, which is in the form transfdim(N,0)
with N&gt;0, according to the kind of bubbles we are
working with.
</bodyText>
<subsectionHeader confidence="0.99739">
4.4 The Rule Value Function
</subsectionHeader>
<bodyText confidence="0.999994333333333">
The Aleph system implements many different
evaluation10 functions which guide the theory
search process, allowing the basic procedure for
theory construction to be altered. In order to bet-
ter fit to our problem, we define a new evaluation
function calculated as the geometrical mean be-
tween the coverage percentage and the rule size
value, as shown in Equation 11 where R is the can-
didate rule and Cov(R) is the proportion of posi-
tive instances covered by R and the LV (•) func-
tion defines the rule value in terms of its length,
returning a value in the [0, 1] interval.
</bodyText>
<equation confidence="0.9942705">
,1
V alue(R) = Cov(R) × LV (R) (11)
</equation>
<bodyText confidence="0.9990712">
The V alue(•) function guides the induction
process, by preferring not too general rules having
maximum possible coverage value. As shown in
Figure 7, the V alue(•) function gives preferences
to rules with 3, 4 and 5 literals.
</bodyText>
<sectionHeader confidence="0.999807" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.998452888888889">
The automatic evaluation of a system is always the
best way to do it, due to its objectivity and scal-
ability. However, in many cases it is unfeasible
for several practical reasons, like the unavailability
of data or the difficulty to prepare an appropriate
10In the Aleph terminology, this function is named as the
“cost” function, despite the fact that it really computes the
value in the sense that the grater the value, the more likely it
is to be chosen.
</bodyText>
<figure confidence="0.7531145">
1 2 3 4 5 6 7
no clauses
</figure>
<figureCaption confidence="0.998334">
Figure 7: Rule length value function
</figureCaption>
<bodyText confidence="0.999712846153846">
dataset. Some supervised learning approach use
manually labeled test sets to evaluated their sys-
tems. However, these are small test sets, for exam-
ple, (Knight &amp; Marcu, 2002) use a set of 1035 sen-
tences to train the system and only 32 sentences
to test it, which is a quite small test set. As a
consequence, it is also important to propose more
through evaluation. In order to assess as clearly
as possible the performance of our methodology
on large datasets, we propose a set of qualitative
and quantitative evaluations based on three differ-
ent measures: Utility, Ngram simplification and
Correctness.
</bodyText>
<subsectionHeader confidence="0.992364">
5.1 Evaluation
</subsectionHeader>
<bodyText confidence="0.9999864">
A relevant issue, not very commonly discussed, is
the Utility of a learned theory. In real life prob-
lems, people may be more interested in the vol-
ume of data processed than the quality of the re-
sults. Maybe, between a system which is 90%
precise and processes only 10% of data, and a sys-
tem with 70% precision, processing 50% of data,
the user would prefer the last one. The Utility
may be a stronger than the Recall measure, used
for the evaluation of supervised learning systems,
because the later measures how many instances
were well identified or processed from the test set
only, and the former takes into account the whole
universe. For example, in a sentence compres-
sion system, it is important to know how many
sentences would be compressed, from the whole
possible set of sentences encountered in electronic
news papers, or in classical literature books, or
both. This is what we mean here by Utility.
The Ngram-Simplification methodology is an
automatic extrinsic test, performed to perceive
how much a given sentence reduction ruleset
would simplify sentences in terms of syntactical
complexity. The answer is not obvious at first
sight, because even smaller sentences can contain
</bodyText>
<figure confidence="0.9948194">
100
90
80
value
70
60
50
40
60
40
30
20
10
0
25
20
90
50
10
20
</figure>
<bodyText confidence="0.997269857142857">
more improbable syntactical subsequences than
their uncompressed versions. To evaluate the syn-
tactical complexity of a sentence, we use a 4 −
gram model and compute a relative11 sequence
probability as defined in Equation 12 where W =
[t1, t2, ..., tm] is the sequence of part-of-speech
tags for a given sentence with size m.
</bodyText>
<equation confidence="0.95557">
” 1
P{tk  |tk−1, ..., tk−n} m (12)
</equation>
<bodyText confidence="0.985568763157895">
The third evaluation is qualitative. We measure
the quality of the learned rules when applied to
sentence reduction. The objective is to assess how
correct is the application of the reduction rules.
This evaluation was made through manual annota-
tion for a statistically representative random sam-
ple of compressed sentences. A human judged
the adequacy and Correctness of each compres-
sion rule to a given sentence segment, in a scale
from 1 to 5, where 1 means that it is absolutely in-
correct and inadequate, and 5 that the compression
rule fits perfectly to the situation (sentence) being
analyzed.
To perform our evaluation, a sample of 300 sen-
tences were randomly extracted, where at least one
compression rule had been applied. This eval-
uation set may be subdivided into three subsets,
where 100 instances came from rules with Z(X) =
1 (BD1), 100 from rules with Z(X) = 2 (BD2),
and the other 100 from rules with Z(X) = 3
(BD3). Another random sample, also with 100
cases has been extracted to evaluate our base-line
(BL) which consists in the direct application of
the bubble set to make compressions. This means
that no learning process is performed. Instead, we
store the complete bubble set as if they were rules
by themselves (in the same manner as (Le Nguyen
&amp; Ho, 2004) do).
Table 1 compiles the comparative results
for Correctness, Precision, Utility and Ngram-
simplification for all datasets. In particular,
Ngram-simplification in percentage is the pro-
portion of test cases where P{reduced( W�)} ≥
P{ W�}.
Table 1 provides evidence of the improvement
achieved with the induction rules, in comparison
with the base line, on each test parameter: Cor-
rectness, Utility and Ngram-simplification. Con-
</bodyText>
<table confidence="0.852567571428571">
11Because it is raised to the inverse power of m, which is
the number of words in the sentence.
Parameter BL BD1 BD2 BD3
Correctness: 2.93 3.56 4.03 4.01
Precision: 58.60% 71.20% 80.60% 80.20%
Utility: 8.65% 32.67% 85.72% 26.86%
NG-Simpl: 47.39% 89.33% 90.03% 89.23%
</table>
<tableCaption confidence="0.999971">
Table 1: Results with Four Evaluation Parameters.
</tableCaption>
<bodyText confidence="0.999976916666667">
sidering the three experiences, BD1, BD2, and
BD3, as a unique evaluation run, we obtained a
mean Correctness quality of 3.867 (i.e. 77.33%
Precision), a mean Utility of 48.45%, and a mean
Ngram-simplification equal to 89.53%, which are
significantly better than the base line.
Moreover, best results overall are obtained for
BD2 with 80.6% Precision, 85.72% Utility and
90.03% Ngram-simplification which means that
we can expect a reduction of two words with high
quality for a great number of sentences. In partic-
ular, Figure 2 shows examples of learned rules.
</bodyText>
<subsectionHeader confidence="0.997252">
5.2 Time Complexity
</subsectionHeader>
<bodyText confidence="0.999742545454545">
In the earlier12 days of ILP, the computation time
spent by their systems was a serious difficult ob-
stacle, disabling its implementation for real life
problems. However, nowadays these time ef-
ficiency issues have been overcome, opening a
wide range of application possibilities, for many
problems, from Biology to Natural Language Pro-
cessing. The graph in figure 8, shows that even
with considerable big datasets, our learning sys-
tem (based on Aleph) evidences acceptable feasi-
ble computation time.
</bodyText>
<figure confidence="0.9876787">
seconds
120
100
80
53
27
20
0
10 20 30 40 50 60
103 bubbles
</figure>
<figureCaption confidence="0.997519">
Figure 8: Time spent during the induction process,
</figureCaption>
<bodyText confidence="0.8364355">
for datasets with size expressed in thousands of
bubbles.
To give an idea about the size of an induced
rule set, and taking as an example the learned rules
</bodyText>
<figure confidence="0.9751273">
12In the 1990-2000 decade.
“P{ W� } = m−nY
k=n
140
60
40
12
0
120
0 0
</figure>
<page confidence="0.683122">
21
</page>
<bodyText confidence="0.99853">
with Z(X) = 2, these were learned from a dataset
containing 37271 t(2, 0) bubbles, and in the final
5806 sentence reduction rules were produced.
</bodyText>
<sectionHeader confidence="0.997476" genericHeader="conclusions">
6 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.99995928">
Sentence Compression is an active research topic,
where several relevant contributions have recently
been proposed. However, we believe that many
milestones still need to be reached. In this pa-
per, we propose a new framework in the form of
a pipeline, which processes huge sets of web news
articles and retrieves compression rules in an un-
supervised way. For that purpose, we extract and
align paraphrases, explore and select specific text
characteristics called bubbles and finally induce a
set of logical rules for sentence reduction in a real-
world environment. Although we have only con-
sidered bubbles having Z(X) ≤ 3, a sentence may
have a compression length greater than this value,
since several compression rules may be applied to
a single sentence.
Our results evidence good practical applicabil-
ity, both in terms of Utility, Precision and Ngram-
simplification. In particular, we assess results up
to 80.6% Precision, 85.72% Utility and 90.03%
Ngram-simplification for reduction rules of two
word length. Moreover, results were compared to
a base line set of rules produced without learning
and the difference reaches a maximum improve-
ment using Inductive Logic Programming of 22%.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.5418174">
This work was supported by the VIPACCESS
project - Ubiquitous Web Access for Visually Im-
paired People. Funding Agency: Fundac¸˜ao para
a Ciˆencia e a Tecnologia (Portugal). Reference:
PTDC/PLP/72142/2006.
</bodyText>
<sectionHeader confidence="0.948761" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999839460317461">
Barzilay R. and Lee L.. 2003. Learning to paraphrase:
An unsupervised approach using multiple-sequence
alignment. In HLT-NAACL 2003: Main Proceed-
ings, pages 16–23.
Camacho R. 1994. Learning stage transition rules with
Indlog. Gesellschaft f¨ur Mathematik und Datenver-
arbeitung MBH., Volume 237 of GMD- Studien, pp.
273-290.
Clarke J., and Lapata M. 2006. Constraint-based Sen-
tence Compression: An Integer Programming Ap-
proach. 21st International Conference on Compu-
tational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics.
Cordeiro J. and Dias G. and Cleuziou G. 2007. Bi-
ology Based Alignments of Paraphrases for Sen-
tence Compression. In Proceedings of the Workshop
on Textual Entailment and Paraphrasing (ACL-
PASCAL / ACL2007), Prague, Czech Republic.
Cordeiro J. and Dias G. and Brazdir P. October
2007. New Functions for Unsupervised Asymmet-
rical Paraphrase Detection. In Journal of Software.,
Volume:2, Issue:4, Page(s): 12-23. Academy Pub-
lisher. Finland. ISSN: 1796-217X.
Dolan W.B. and Quirck C. and Brockett C. 2004. Un-
supervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Pro-
ceedings of 20th International Conference on Com-
putational Linguistics (COLING 2004).
Knight K. and Marcu D. 2002. Summarization be-
yond sentence extraction: A probabilistic approach
to sentence compression. Artificial Intelligence,
139(1):91-107.
Muggleton S. 1991. Inductive Logic Programming.
New Generation Computing, 8 (4):295-318.
Muggleton S. 1996. Learning from positive data. Pro-
ceedings of the Sixth International Workshop on In-
ductive Logic Programming (ILP-96), LNAI 1314,
Berlin, 1996. Springer-Verlag.
Muggleton S. 1999. Inductive logic programming: Is-
sues, results and the challenge of learning language
in logic. Artificial Intelligence, 114 (1-2), 283?296.
Le Nguyen M., Horiguchi S., A. S., and Ho B. T. 2004.
Example-based sentence reduction using the hidden
markov model. ACM Transactions on Asian Lan-
guage Information Processing (TALIP), 3(2):146-
158.
Needleman SB, Wunsch CD. 1970. A general method
applicable to the search for similarities in the amino
acid sequence of two proteins. Journal of Molecular
Biology, 48 (3): 443–53.
Quinlan J. R. 1990. Learning Logical Deinitions from
Relations. Machine Learning., 5 (3), 239-266. 33,
39, 41.
Smith TF, Waterman MS. 1981. Identification of Com-
mon Molecular Subsequences. Journal of Molecu-
lar Biology, 147: 195–197.
Srinivasan A. 2000. The Aleph Manual, Technical
Report. Computing Laboratory, Oxford University,
UK.
Turner J, Charniak E. 2005. Supervised and Unsuper-
vised Learning for Sentence Compression. Proceed-
ings of the 43rd Annual Meeting of the ACL, pages
290-297.
</reference>
<page confidence="0.9456">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.363184">
<title confidence="0.966146">Unsupervised Induction of Sentence Compression Rules</title>
<affiliation confidence="0.889422">CLT and University of Beira</affiliation>
<email confidence="0.973078">jpaulo@di.ubi.pt</email>
<author confidence="0.958326">Ga¨el</author>
<affiliation confidence="0.995109">CLT and University of Beira</affiliation>
<email confidence="0.976657">ddg@di.ubi.pt</email>
<author confidence="0.918755">Pavel</author>
<affiliation confidence="0.999709">University of</affiliation>
<address confidence="0.594651">Porto,</address>
<email confidence="0.993946">pbrazdil@liaad.up.pt</email>
<abstract confidence="0.9991528">In this paper, we propose a new unsupervised approach to sentence compression based on shallow linguistic processing. For that purpose, paraphrase extraction and alignment is performed over web news stories extracted automatically from the web on a daily basis to provide structured data examples to the learning process. Compression rules are then learned through the application of Inductive Logic Programming techniques. Qualitative and quantitative evaluations suggests that this is a worth following approach, which might be even improved in the future.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In HLT-NAACL 2003: Main Proceedings,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="8560" citStr="Barzilay &amp; Lee, 2003" startWordPosition="1419" endWordPosition="1422">cts web news stories on a daily basis, and organized them into clusters, which are exclusively related to different and unique events, happening each day: ”a company acquisition”, ”a presidential speech”, ”a bomb attack”, etc. Usually, such clusters contain near 30 small or medium news articles, collected from different media sources. This environment proves to be very fruitful for paraphrase extraction, since we have many sentences conveying similar information yet written in a different form. A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay &amp; Lee, 2003; Dolan et al., 2004). However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan et al., 2004) and Word N-gram Overlap for (Barzilay &amp; Lee, 2003). Such pairs are useless for our purpose, since we aim to identify asymmetrical paraphrase pairs to be used for sentence compression rule induction, as explained in (Cordeiro et al., Oct 2007). There we proposed a new metric, the Sumo-Metric, specially designed for asymmetrical enta</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Barzilay R. and Lee L.. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In HLT-NAACL 2003: Main Proceedings, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Camacho</author>
</authors>
<title>Learning stage transition rules with Indlog.</title>
<date>1994</date>
<booktitle>Gesellschaft f¨ur Mathematik und Datenverarbeitung MBH., Volume 237 of GMD- Studien,</booktitle>
<pages>273--290</pages>
<contexts>
<context position="16578" citStr="Camacho, 1994" startWordPosition="2847" endWordPosition="2849">ine different types of attributes i.e. lexical, morpho-syntactic and syntactical. With ILP, we only need to define a set of possible features and the induction process will search throughout this set. 4.1 The Aleph System The Aleph system(Srinivasan, 2000) is an empirical ILP system, initially designed to be a prototype for exploring ILP ideas. It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP. In fact, Aleph is the successor of several and ”more primitive” ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems. One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning systems. Moreover, there is theoretical research work (Muggleton, 1996) demonstrating that the increase in the learning error tend to be negligible with the absence of negative examples, as the number of learning instances increases. This is a relevant issue, for many learning domains, and specially ours, where negative examples are not available. 4.2 Learn</context>
</contexts>
<marker>Camacho, 1994</marker>
<rawString>Camacho R. 1994. Learning stage transition rules with Indlog. Gesellschaft f¨ur Mathematik und Datenverarbeitung MBH., Volume 237 of GMD- Studien, pp. 273-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Constraint-based Sentence Compression: An Integer Programming Approach.</title>
<date>2006</date>
<booktitle>21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3065" citStr="Clarke &amp; Lapata, 2006" startWordPosition="471" endWordPosition="474"> ruleset, they proposed an improvement where a stochastic Hidden Markov Model is trained to help in the decision of which sequence of possible lexical reduction rules should be applied to a specific case. An unsupervised approach was included in the work of (Turner &amp; Charniak, 2005), where training data are automatically extracted from the Penn Treebank corpus, to fit a noisy channel model, similar to the one used by (Knight &amp; Marcu, 2002). Although it seems an interesting approach to provide new training instances, it still be dependent upon data manually labeled. More recently, the work of (Clarke &amp; Lapata, 2006) devise a different and quite curious approach, where the sentence compression task is defined as an optimization goal, from an Integer Programming problem. Several constraints are defined, according to language models, linguistic, and syntactical features. Although this is an unsupervised approach, without using any paralel corpus, it is completely knowledge driven, like a set of crafted rules and heuristics incorporated into a system to solve a certain problem. 1.2 Our Proposal In this paper, we propose a new approach to this research field, which follows an unsupervised methodology to learn</context>
<context position="15500" citStr="Clarke &amp; Lapata, 2006" startWordPosition="2668" endWordPosition="2671">we explore Inductive Logic Programming (ILP) techniques to generalize regularities and find conditions to compress sentence segments. 4 The Induction of Compression Rules Many different algorithms exist to induce knowledge from data. In this paper, we use Inductive Logic Programming (ILP) (Muggleton, 1991) and it was a choice based on a set of relevant features like: the capacity to generate symbolic and 18 relational knowledge; the possibility to securely avoid negative instances; the ability to mix different types of attribute and to have more control over the theory search process. Unlike (Clarke &amp; Lapata, 2006), we aim at inducing human understandable knowledge, also known as symbolic knowledge. For that purpose, ILP satisfies perfectly this goal by producing clauses based on first order logic. Moreover, most of the learning algorithms require a complete definition and characterization of the feature set, prior to the learning process, where any attribute must be specified. This is a conceptual bottleneck to many learning problems such as ours, since we need to combine different types of attributes i.e. lexical, morpho-syntactic and syntactical. With ILP, we only need to define a set of possible fea</context>
</contexts>
<marker>Clarke, Lapata, 2006</marker>
<rawString>Clarke J., and Lapata M. 2006. Constraint-based Sentence Compression: An Integer Programming Approach. 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cordeiro</author>
<author>G Dias</author>
<author>G Cleuziou</author>
</authors>
<title>Biology Based Alignments of Paraphrases for Sentence Compression.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Textual Entailment and Paraphrasing (ACLPASCAL / ACL2007),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="10621" citStr="Cordeiro et al., 2007" startWordPosition="1764" endWordPosition="1767">. (1) To the horror of their fans, Miss Ball and Arnaz were divorced in 1960. (2) Ball and Arnaz divorced in 1960. Figure 3: An Assymetrical Paraphrase 2.2 Paraphrase Alignment From a corpus of asymmetrical paraphrases, we then use biology-based gene alignment algorithms to align the words contained in each of the two sentences within each paraphrase. For that purpose, we implemented two well established algorithms, one identifying local alignments (Smith &amp; Waterman, 1981) and the other one computing global alignments (Needleman &amp; Wunsch, 1970). We also proposed a convenient dynamic strategy (Cordeiro et al., 2007), which chooses the best alignment algorithm to be applied to a specific case at runtime. The difference between local and global sequence alignments is illustrated below, where we use letters, instead of words, to better fit our paper space constraints. Suppose that we have the following two sequences: [D,H,M,S,T,P,R,Q,I,S] and [T,P,Q,I,S,D,H,S] a global alignment would produce the following pair. D H M S T P R Q I S _ _ _ _ _ _ _ T P _ Q I S D H S For the same two sequences, a local alignment strategy could generate two or more aligned subsequences as follows. S(Sa, Sb) = I 17 |D H M S ||T P</context>
</contexts>
<marker>Cordeiro, Dias, Cleuziou, 2007</marker>
<rawString>Cordeiro J. and Dias G. and Cleuziou G. 2007. Biology Based Alignments of Paraphrases for Sentence Compression. In Proceedings of the Workshop on Textual Entailment and Paraphrasing (ACLPASCAL / ACL2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cordeiro</author>
<author>G Dias</author>
<author>P Brazdir</author>
</authors>
<title>New Functions for Unsupervised Asymmetrical Paraphrase Detection.</title>
<date>2007</date>
<booktitle>In Journal of Software., Volume:2, Issue:4, Page(s): 12-23. Academy Publisher. Finland. ISSN:</booktitle>
<pages>1796--217</pages>
<contexts>
<context position="10621" citStr="Cordeiro et al., 2007" startWordPosition="1764" endWordPosition="1767">. (1) To the horror of their fans, Miss Ball and Arnaz were divorced in 1960. (2) Ball and Arnaz divorced in 1960. Figure 3: An Assymetrical Paraphrase 2.2 Paraphrase Alignment From a corpus of asymmetrical paraphrases, we then use biology-based gene alignment algorithms to align the words contained in each of the two sentences within each paraphrase. For that purpose, we implemented two well established algorithms, one identifying local alignments (Smith &amp; Waterman, 1981) and the other one computing global alignments (Needleman &amp; Wunsch, 1970). We also proposed a convenient dynamic strategy (Cordeiro et al., 2007), which chooses the best alignment algorithm to be applied to a specific case at runtime. The difference between local and global sequence alignments is illustrated below, where we use letters, instead of words, to better fit our paper space constraints. Suppose that we have the following two sequences: [D,H,M,S,T,P,R,Q,I,S] and [T,P,Q,I,S,D,H,S] a global alignment would produce the following pair. D H M S T P R Q I S _ _ _ _ _ _ _ T P _ Q I S D H S For the same two sequences, a local alignment strategy could generate two or more aligned subsequences as follows. S(Sa, Sb) = I 17 |D H M S ||T P</context>
</contexts>
<marker>Cordeiro, Dias, Brazdir, 2007</marker>
<rawString>Cordeiro J. and Dias G. and Brazdir P. October 2007. New Functions for Unsupervised Asymmetrical Paraphrase Detection. In Journal of Software., Volume:2, Issue:4, Page(s): 12-23. Academy Publisher. Finland. ISSN: 1796-217X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W B Dolan</author>
<author>C Quirck</author>
<author>C Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of 20th International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="8581" citStr="Dolan et al., 2004" startWordPosition="1423" endWordPosition="1426">n a daily basis, and organized them into clusters, which are exclusively related to different and unique events, happening each day: ”a company acquisition”, ”a presidential speech”, ”a bomb attack”, etc. Usually, such clusters contain near 30 small or medium news articles, collected from different media sources. This environment proves to be very fruitful for paraphrase extraction, since we have many sentences conveying similar information yet written in a different form. A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay &amp; Lee, 2003; Dolan et al., 2004). However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan et al., 2004) and Word N-gram Overlap for (Barzilay &amp; Lee, 2003). Such pairs are useless for our purpose, since we aim to identify asymmetrical paraphrase pairs to be used for sentence compression rule induction, as explained in (Cordeiro et al., Oct 2007). There we proposed a new metric, the Sumo-Metric, specially designed for asymmetrical entailed pairs identifica</context>
</contexts>
<marker>Dolan, Quirck, Brockett, 2004</marker>
<rawString>Dolan W.B. and Quirck C. and Brockett C. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of 20th International Conference on Computational Linguistics (COLING 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<pages>139--1</pages>
<contexts>
<context position="1242" citStr="Knight &amp; Marcu, 2002" startWordPosition="176" endWordPosition="179">data examples to the learning process. Compression rules are then learned through the application of Inductive Logic Programming techniques. Qualitative and quantitative evaluations suggests that this is a worth following approach, which might be even improved in the future. 1 Introduction Sentence compression, simplification or summarization has been an active research subject during this decade. A set of approaches involving machine learning algorithms and statistical models have been experimented and documented in the literature and several of these are described next. 1.1 Related Work In (Knight &amp; Marcu, 2002) two methods were proposed, one is a probabilistic model - the noisy channel model - where the probabilities for sentence reduction (P{Scompress|S)} 1) are estimated from a training set of 1035 (Sentence, Sentencecompress) pairs, manually crafted, while considering lexical and syntactical features. The other approach learns syntactic tree rewriting rules, defined through four operators: SHIFT, REDUCE DROP and ASSIGN. Sequences of these operators are learned from the training set, and each sequence defines a complete 1In the original paper the P(tIs) notation is used, where t is the sentence in</context>
<context position="2886" citStr="Knight &amp; Marcu, 2002" startWordPosition="442" endWordPosition="445">e, Sentencereduced) pair, selected from a news agency and manually tuned to obtain the training data. Due to complexity difficulties found for the application of this big lexical ruleset, they proposed an improvement where a stochastic Hidden Markov Model is trained to help in the decision of which sequence of possible lexical reduction rules should be applied to a specific case. An unsupervised approach was included in the work of (Turner &amp; Charniak, 2005), where training data are automatically extracted from the Penn Treebank corpus, to fit a noisy channel model, similar to the one used by (Knight &amp; Marcu, 2002). Although it seems an interesting approach to provide new training instances, it still be dependent upon data manually labeled. More recently, the work of (Clarke &amp; Lapata, 2006) devise a different and quite curious approach, where the sentence compression task is defined as an optimization goal, from an Integer Programming problem. Several constraints are defined, according to language models, linguistic, and syntactical features. Although this is an unsupervised approach, without using any paralel corpus, it is completely knowledge driven, like a set of crafted rules and heuristics incorpor</context>
<context position="21996" citStr="Knight &amp; Marcu, 2002" startWordPosition="3734" endWordPosition="3737"> to its objectivity and scalability. However, in many cases it is unfeasible for several practical reasons, like the unavailability of data or the difficulty to prepare an appropriate 10In the Aleph terminology, this function is named as the “cost” function, despite the fact that it really computes the value in the sense that the grater the value, the more likely it is to be chosen. 1 2 3 4 5 6 7 no clauses Figure 7: Rule length value function dataset. Some supervised learning approach use manually labeled test sets to evaluated their systems. However, these are small test sets, for example, (Knight &amp; Marcu, 2002) use a set of 1035 sentences to train the system and only 32 sentences to test it, which is a quite small test set. As a consequence, it is also important to propose more through evaluation. In order to assess as clearly as possible the performance of our methodology on large datasets, we propose a set of qualitative and quantitative evaluations based on three different measures: Utility, Ngram simplification and Correctness. 5.1 Evaluation A relevant issue, not very commonly discussed, is the Utility of a learned theory. In real life problems, people may be more interested in the volume of da</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Knight K. and Marcu D. 2002. Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1):91-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muggleton</author>
</authors>
<title>Inductive Logic Programming.</title>
<date>1991</date>
<journal>New Generation Computing,</journal>
<volume>8</volume>
<pages>4--295</pages>
<contexts>
<context position="15185" citStr="Muggleton, 1991" startWordPosition="2616" endWordPosition="2617">mples, where relevant sentence transformations occur. To have an idea about the amount of data we are working with, from a set of 30 days web news stories (133.5 MB of raw text), we identified and extracted 596678 aligned paraphrases, from which 143761 bubbles were obtained. In the next section, we show how we explore Inductive Logic Programming (ILP) techniques to generalize regularities and find conditions to compress sentence segments. 4 The Induction of Compression Rules Many different algorithms exist to induce knowledge from data. In this paper, we use Inductive Logic Programming (ILP) (Muggleton, 1991) and it was a choice based on a set of relevant features like: the capacity to generate symbolic and 18 relational knowledge; the possibility to securely avoid negative instances; the ability to mix different types of attribute and to have more control over the theory search process. Unlike (Clarke &amp; Lapata, 2006), we aim at inducing human understandable knowledge, also known as symbolic knowledge. For that purpose, ILP satisfies perfectly this goal by producing clauses based on first order logic. Moreover, most of the learning algorithms require a complete definition and characterization of t</context>
</contexts>
<marker>Muggleton, 1991</marker>
<rawString>Muggleton S. 1991. Inductive Logic Programming. New Generation Computing, 8 (4):295-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muggleton</author>
</authors>
<title>Learning from positive data.</title>
<date>1996</date>
<booktitle>Proceedings of the Sixth International Workshop on Inductive Logic Programming (ILP-96), LNAI 1314,</booktitle>
<publisher>Springer-Verlag.</publisher>
<location>Berlin,</location>
<contexts>
<context position="16890" citStr="Muggleton, 1996" startWordPosition="2896" endWordPosition="2897">a prototype for exploring ILP ideas. It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP. In fact, Aleph is the successor of several and ”more primitive” ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems. One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning systems. Moreover, there is theoretical research work (Muggleton, 1996) demonstrating that the increase in the learning error tend to be negligible with the absence of negative examples, as the number of learning instances increases. This is a relevant issue, for many learning domains, and specially ours, where negative examples are not available. 4.2 Learning Instances In our problem, we define predicates that characterize possible features to be considered during the induction process. Regarding the structure of our learning instances (bubbles), we define predicates which restrict left and right context sequences as well as the aligned middle sequence. In parti</context>
</contexts>
<marker>Muggleton, 1996</marker>
<rawString>Muggleton S. 1996. Learning from positive data. Proceedings of the Sixth International Workshop on Inductive Logic Programming (ILP-96), LNAI 1314, Berlin, 1996. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muggleton</author>
</authors>
<title>Inductive logic programming: Issues, results and the challenge of learning language in logic.</title>
<date>1999</date>
<journal>Artificial Intelligence,</journal>
<volume>114</volume>
<pages>1--2</pages>
<contexts>
<context position="16528" citStr="Muggleton, 1999" startWordPosition="2840" endWordPosition="2841">earning problems such as ours, since we need to combine different types of attributes i.e. lexical, morpho-syntactic and syntactical. With ILP, we only need to define a set of possible features and the induction process will search throughout this set. 4.1 The Aleph System The Aleph system(Srinivasan, 2000) is an empirical ILP system, initially designed to be a prototype for exploring ILP ideas. It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP. In fact, Aleph is the successor of several and ”more primitive” ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems. One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning systems. Moreover, there is theoretical research work (Muggleton, 1996) demonstrating that the increase in the learning error tend to be negligible with the absence of negative examples, as the number of learning instances increases. This is a relevant issue, for many learning domains, and specially ours, wh</context>
</contexts>
<marker>Muggleton, 1999</marker>
<rawString>Muggleton S. 1999. Inductive logic programming: Issues, results and the challenge of learning language in logic. Artificial Intelligence, 114 (1-2), 283?296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Le Nguyen</author>
<author>S Horiguchi</author>
<author>A S</author>
<author>B T Ho</author>
</authors>
<title>Example-based sentence reduction using the hidden markov model.</title>
<date>2004</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<pages>3--2</pages>
<marker>Le Nguyen, Horiguchi, S, Ho, 2004</marker>
<rawString>Le Nguyen M., Horiguchi S., A. S., and Ho B. T. 2004. Example-based sentence reduction using the hidden markov model. ACM Transactions on Asian Language Information Processing (TALIP), 3(2):146-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Needleman SB</author>
<author>Wunsch CD</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>Journal of Molecular Biology,</journal>
<volume>48</volume>
<issue>3</issue>
<pages>443--53</pages>
<marker>SB, CD, 1970</marker>
<rawString>Needleman SB, Wunsch CD. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48 (3): 443–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>Learning Logical Deinitions from Relations.</title>
<date>1990</date>
<journal>Machine Learning.,</journal>
<volume>5</volume>
<issue>3</issue>
<pages>239--266</pages>
<contexts>
<context position="16550" citStr="Quinlan, 1990" startWordPosition="2843" endWordPosition="2844"> ours, since we need to combine different types of attributes i.e. lexical, morpho-syntactic and syntactical. With ILP, we only need to define a set of possible features and the induction process will search throughout this set. 4.1 The Aleph System The Aleph system(Srinivasan, 2000) is an empirical ILP system, initially designed to be a prototype for exploring ILP ideas. It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP. In fact, Aleph is the successor of several and ”more primitive” ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems. One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning systems. Moreover, there is theoretical research work (Muggleton, 1996) demonstrating that the increase in the learning error tend to be negligible with the absence of negative examples, as the number of learning instances increases. This is a relevant issue, for many learning domains, and specially ours, where negative examples </context>
</contexts>
<marker>Quinlan, 1990</marker>
<rawString>Quinlan J. R. 1990. Learning Logical Deinitions from Relations. Machine Learning., 5 (3), 239-266. 33, 39, 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Smith TF</author>
<author>Waterman MS</author>
</authors>
<title>Identification of Common Molecular Subsequences.</title>
<date>1981</date>
<journal>Journal of Molecular Biology,</journal>
<volume>147</volume>
<pages>195--197</pages>
<marker>TF, MS, 1981</marker>
<rawString>Smith TF, Waterman MS. 1981. Identification of Common Molecular Subsequences. Journal of Molecular Biology, 147: 195–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Srinivasan</author>
</authors>
<title>The Aleph Manual, Technical Report. Computing Laboratory,</title>
<date>2000</date>
<location>Oxford University, UK.</location>
<contexts>
<context position="16220" citStr="Srinivasan, 2000" startWordPosition="2788" endWordPosition="2789">, ILP satisfies perfectly this goal by producing clauses based on first order logic. Moreover, most of the learning algorithms require a complete definition and characterization of the feature set, prior to the learning process, where any attribute must be specified. This is a conceptual bottleneck to many learning problems such as ours, since we need to combine different types of attributes i.e. lexical, morpho-syntactic and syntactical. With ILP, we only need to define a set of possible features and the induction process will search throughout this set. 4.1 The Aleph System The Aleph system(Srinivasan, 2000) is an empirical ILP system, initially designed to be a prototype for exploring ILP ideas. It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP. In fact, Aleph is the successor of several and ”more primitive” ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems. One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning s</context>
</contexts>
<marker>Srinivasan, 2000</marker>
<rawString>Srinivasan A. 2000. The Aleph Manual, Technical Report. Computing Laboratory, Oxford University, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Turner</author>
<author>E Charniak</author>
</authors>
<title>Supervised and Unsupervised Learning for Sentence Compression.</title>
<date>2005</date>
<booktitle>Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>290--297</pages>
<contexts>
<context position="2726" citStr="Turner &amp; Charniak, 2005" startWordPosition="414" endWordPosition="417">emplatetranslation learning, a method inherited from the machine translation field, which learns lexical transformation rules2, by observing a set of 1500 (Sentence, Sentencereduced) pair, selected from a news agency and manually tuned to obtain the training data. Due to complexity difficulties found for the application of this big lexical ruleset, they proposed an improvement where a stochastic Hidden Markov Model is trained to help in the decision of which sequence of possible lexical reduction rules should be applied to a specific case. An unsupervised approach was included in the work of (Turner &amp; Charniak, 2005), where training data are automatically extracted from the Penn Treebank corpus, to fit a noisy channel model, similar to the one used by (Knight &amp; Marcu, 2002). Although it seems an interesting approach to provide new training instances, it still be dependent upon data manually labeled. More recently, the work of (Clarke &amp; Lapata, 2006) devise a different and quite curious approach, where the sentence compression task is defined as an optimization goal, from an Integer Programming problem. Several constraints are defined, according to language models, linguistic, and syntactical features. Alt</context>
</contexts>
<marker>Turner, Charniak, 2005</marker>
<rawString>Turner J, Charniak E. 2005. Supervised and Unsupervised Learning for Sentence Compression. Proceedings of the 43rd Annual Meeting of the ACL, pages 290-297.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>