<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.984015">
Aiduti in Japanese Multi-party Design Conversations
</title>
<author confidence="0.997053">
Yasuhiro Katagiri
</author>
<affiliation confidence="0.998175">
Future University - Hakodate
</affiliation>
<address confidence="0.718894">
116-2 Kameda-Nakano Hakodate Hokkaido, Japan
</address>
<email confidence="0.999049">
katagiri@fun.ac.jp
</email>
<sectionHeader confidence="0.995652" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999650923076923">
Japanese backchannel utterances, aizuti, in
a multi-party design conversation were ex-
amined, and aizuti functions were analyzed
in comparison with its functions in two-
party dialogues. In addition to the two
major functions, signaling acknowledgment
and turn-management, it was argued that
aizuti in multi-party conversations are in-
volved in joint construction of design plans
through management of the floor structure,
and display of participants’ readiness to en-
gage in collaborative elaboration of jointly
constructed proposals.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997594117647">
Backchannel utterances are one of the representa-
tive phenomena characterizing conversational inter-
actions. We can find backchannel utterances in ev-
ery natural conversation in every culture. Differ-
ent languages have different repertoire of expres-
sions that work as backchannels. In terms of what
functions they serve in conversations, it has widely
been acknowledged that backchannels, by convey-
ing the hearer feedback to the speaker, serve to con-
tribute to informational coordination between con-
versational participants, through conversational flow
management in terms of both common grounding
and smooth turn-taking. It has also been acknowl-
edged, perhaps less explicitly, that backchannels
serve to contribute to affective coordination by pro-
moting rapport between conversational participants.
It is still unclear how these two contrasting views on
</bodyText>
<page confidence="0.957215">
9
</page>
<bodyText confidence="0.9998072">
backchannels can be integrated. How are the infor-
mational and the affective coordination functions of
backchannels inter-related? What factors determine
relative salience of these two functions in certain us-
age of backchannels? Are there any categories of
conversational interactions that promote one or the
other functions? Are there cultural differences in
backchannel usages?
We focus, in this paper, on the use of Japanese
backchannels, aiduti, in multi-party conversations.
Based on the analysis of how aiduti utterances are
employed in experimentally captured multi-party
design conversation data, we argue that aiduti ut-
terances in Japanese have, on top of the informa-
tional coordination functions of common-grounding
and turn-management, the function of expressing the
readiness, a positive attitude, on the part of a partic-
ipant to engage in the joint construction of an ongo-
ing proposal currently under discussion, which then
leads to affective coordination.
</bodyText>
<sectionHeader confidence="0.947063" genericHeader="method">
2 Backchannels in Dialogues
</sectionHeader>
<bodyText confidence="0.999905416666667">
Backchannel utterances were conceived initially
in two-party dialogues with one speaker and one
hearer. Schegloff (1982) picked up hearer’s short
utterances such as ’uh, huh’ produced in response
to the speaker’s main utterances, and character-
ized them as backchannels, whose functions are to
convey backward messages from the hearer to the
speaker indicating that the hearer is attending to, lis-
tening to, understanding, and expecting to continue
the production of the speaker’s main message.
Heritage (2006) provides a broader conception of
backchannels and lists the following four functions
</bodyText>
<note confidence="0.885819">
Proceedings of the Workshop on Embodied Language Processing, pages 9–16,
Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.993383">
Figure 2: Setting for multi-party design conversation
capture
Figure 1: Meeting archiver equipment MARC used
in data collection
</figureCaption>
<bodyText confidence="0.816825">
for backchannel utterances.
</bodyText>
<listItem confidence="0.998208428571428">
• Provide Acknowledgments to prior locutions
by the speaker
• Projection of further talk in turn taking
• Recipient epistemic states triggered by the
speaker’s message
• Recipient affiliative attitude, how the recipient
is aligned with speaker’s message
</listItem>
<bodyText confidence="0.98046975">
Maynard (1986) compared Japanese and Amer-
ican dialogues, and observed that Japanese dia-
logues have almost twice as much aizuti as Ameri-
can backchannel utterances. This observation sug-
gests that significance of backchannels and their
functions in conversational interactions may depend
on social groups, types of activities and other social
or task related parameters.
</bodyText>
<sectionHeader confidence="0.999776" genericHeader="method">
3 Multi-party Conversation
</sectionHeader>
<subsectionHeader confidence="0.99994">
3.1 Varieties of multi-party conversations
</subsectionHeader>
<bodyText confidence="0.99978075">
We will focus on aiduti utterances in Japanese multi-
party design conversations. In order to locate the
type of activity we’ve been working on within the
broad range of interaction activities collectively cat-
egorized as multi-party conversations, we first try to
list up potential parameters that might influence the
structure and organization of conversational interac-
tions.
</bodyText>
<subsectionHeader confidence="0.878125">
Number of participants
</subsectionHeader>
<bodyText confidence="0.999977">
We call a conversation between more than two
people a multi-party conversation. A conversation
between three people and a conversation between 10
people are not the same in their conversational orga-
nization. It has been observed (Fay et al., 2000) that
conversations with a small number of participants
tend to be homogeneous that contain a number of
equal status pairwise interactions, whereas conver-
sations with a large number of participants tend to
be more hierarchical with a central control person
working as a chairperson.
</bodyText>
<subsectionHeader confidence="0.906636">
Types of activities
</subsectionHeader>
<bodyText confidence="0.99631075">
Conversational interactions are often embedded in
larger activities, and the type of embedding activities
makes a difference in the organization of conversa-
tions.
</bodyText>
<listItem confidence="0.747361">
(a) Purpose
</listItem>
<bodyText confidence="0.988517285714286">
One-way information transfer in lectures and
joint problem solving in a group of people have
both fixed but different types of goals. When
people chat for socialization, having a conver-
sation itself becomes its own purpose. These
different types of goals could produce different
organizational structures in conversations.
</bodyText>
<listItem confidence="0.765997">
(b) Rigidity of purpose
</listItem>
<bodyText confidence="0.994577">
Even within joint problem solving activities,
</bodyText>
<page confidence="0.972361">
10
</page>
<subsectionHeader confidence="0.375315">
Sp Utterance Sp Utterance
</subsectionHeader>
<equation confidence="0.992675941176471">
D: B: (un)
D: C: (D )
D: : C: (laugh)
(I often think that even when you keep using the C:
same mobile carrier, if you could have one more
mail address,)
E: (un-un-un) (when I try to correspond by mail with elderly, eh,
with my parents)
D: E: (un-un)
(it would be nice) B: (un)
D: E: (un)
(with PC, any number of addresses) C: : :
F: (un-un) (parents cannot type)
E: : (aa-aa, hai-hai-hai-hai) B: (un)
D: E: (un)
(you can have) C:
F: (D ) (but, they can talk on the phone)
B: (un): B: (un)
C: (un) E: (un-un)
D: C: :
E: (un) (but, when you’d rather want to use mails, if possi-
ble)
D: E: (un-un-un)
(I would definitely want one) B: (un)
B: (un): C:
E: (D ) F: (un)
E: C: :
(You mean, multiple mail addresses, right?) C: :
D: (hai) (how about, with speech recognition)
C: (un): E: (aa) :
C: (that’s good)
(for elderly people) B: (un):
E: (un-un) C:
C: : (convert speech into text)
</equation>
<figureCaption confidence="0.998378">
Figure 3: Aiduti in design conversation
</figureCaption>
<bodyText confidence="0.999817384615385">
we can conceive of different degree of rigid-
ity of problem goals conversational participants
are working on. In one extreme lies a pursuit
of a fixed goal such as mathematical problem
solving, in which a problem with a clearly de-
termined answer is given to the group. In other
extreme lies a problem solving under a loosely
stated goal such as floor planning of an apart-
ment for the group, in which the only require-
ment is to reach an agreement, and factors to
consider must be made explicit in the course of
conversation. The design conversation we’ve
looked at belong to the latter category.
</bodyText>
<listItem confidence="0.643899">
(c) Reality
</listItem>
<bodyText confidence="0.98895025">
Every experimental data collection has to face
this problem. Whether or not and how much
the outcome of the conversation has real import
in participants’ life makes a big difference in
conversational organization.
(d) Use of objects
Use of physical objects, particularly informa-
tional artifact such as whiteboard and projec-
tors, changes the use pattern of multi-modal
signals: gaze, gestures and body postures, and
needs to be taken into account in experimental
data collection.
</bodyText>
<subsectionHeader confidence="0.873039">
Characteristics of participants
</subsectionHeader>
<bodyText confidence="0.914147833333333">
(a) Participant properties
Differences in capabilities such as in knowl-
edge and in expertise, and dispositional proper-
ties, such as preferences, beliefs, and personal-
ities of participants greatly contribute to shape
the interaction.
</bodyText>
<listItem confidence="0.938461">
(b) Participant roles
</listItem>
<page confidence="0.993912">
11
</page>
<table confidence="0.914352875">
Start -End Sp Utterances
243.1950-243.7450 F: are-wo
- (that)
244.2075-246.1200 F: tatoeba keitai-wo nakusita toki-no
sono
- (when you lose your mobile phone)
246.6300-247.9800 F: timei-tekina doai-wa
- (how fatal it will be)
248.2725-248.8850 F: nn daibu
- (big)
248.7550-249.7350 B: un:
249.3000-250.0200 E: un:
249.5150-249.8225 D: un:
250.1250-254.8225 F: un:are ikko otosityattara
ironna houmen-no raihu-rain-
ga soredakede tataretyautte iunoga
</table>
<tableCaption confidence="0.168162">
atte
</tableCaption>
<bodyText confidence="0.7186315">
- (if you lose one, your life line will
be cut out in a lot of ways)
</bodyText>
<figureCaption confidence="0.999483">
Figure 4: Aiduti overlap
</figureCaption>
<bodyText confidence="0.999569555555556">
Conversation setting often dictates certain role
assignment to each participant, which in turn
determines the shape of interactions that takes
place between people under those participant
roles. Instructor and follower in instruction giv-
ing tasks, and clerk and customer in commer-
cial transactions are typical examples. The role
of chairperson also is significant in determining
the structure of conversations.
</bodyText>
<listItem confidence="0.66122">
(c) Participant relationships
</listItem>
<bodyText confidence="0.997767142857143">
Age and social status often provide a fixed base
for dominance relationship among conversa-
tional participants. Affiliative familiarity be-
tween participants are less fixed but still stable
relationships. Sharing of opinions is temporary
and can change quite quickly during the course
of a conversation.
</bodyText>
<subsectionHeader confidence="0.999957">
3.2 Multi-party design conversation
</subsectionHeader>
<bodyText confidence="0.999587">
We have been collecting data on multi-party design
conversation in Japanese. Multi-party design con-
versation is a type of joint problem solving conversa-
tion, in which participants engage in a discussion to
come up with an agreement on the final design plan.
The design goal, however, is only partially specified,
and participants need to jointly decide on evaluative
criteria for the design goal during the course of the
discussion.
</bodyText>
<table confidence="0.998454830188679">
Start -End Sp Utterance
781.5050-781.6100 C:
781.7750-782.7050 C:
- (one more thing)
782.6300-782.8900 E:
782.9550-784.4925 C:
- (related to communication)
784.6050-784.7750 E:
784.6500-786.6450 C:
:
- (just a thought)
786.1925-786.6950 E:
787.3475-788.4875 C: : :
788.6125-789.9975 C: :
790.5375-790.6175 C: (W — )
790.7975-792.2575 C: :
792.6125-795.7250 C:
- (when you exchange mails, particu-
larly on mobile phones, people ex-
pect quicker responses)
. . .
830.4175-831.7750 C:
831.7125-832.0400 :
832.1475-833.1475 E: :
832.3675-833.3750 :
832.3875-834.4525
- (drive mode)
834.4450-835.5700 E: :
834.6325-834.9900
834.8000-836.3450 B:
- (on the mobile phone)
836.0075-837.5475 C:
- (Ah, I know drive mode)
837.4525-842.8250 B: (W — )
- (same as, when you make a call, it
says it’s on drive now)
- . . .
844.8375-846.2475
- (you get those responses)
845.1450-846.6375 E:
- (it seems rather simple to realize)
846.2325-846.3950
846.5650-846.7850 C:
846.5750-848.2600 D:
- (you know Yahoo messenger?)
847.5825-847.8575 B:
847.9050-848.5125 E: :
848.1400-848.6200 B: :
848.4450-849.5650 D: :
849.9125-851.3250 D:
- (you can see the situation of your
correspondent)
851.3600-851.8900 E: :
</table>
<figureCaption confidence="0.855452">
Figure 5: Floor structure
</figureCaption>
<page confidence="0.83591">
12
</page>
<table confidence="0.94664675">
Speaker Utterance Aiduti
A 158 3
B 426 179
C 420 125
D 346 138
E 612 343
F 206 69
Total 2,168 857
</table>
<tableCaption confidence="0.965398">
Table 1: Number of utterances and aiduti produced
in multi-party design conversation
</tableCaption>
<table confidence="0.9216985">
Japanese form sound translation
hai (yes)
un (yeah)
aa (ah)
ee (correct)
sou (I agree)
</table>
<tableCaption confidence="0.987967">
Table 2: Linguistic forms of aiduti
</tableCaption>
<bodyText confidence="0.971598476190476">
The condition of our data collection was as fol-
lows:
Number of participants: six for each session
Arrangement: face-to-face conversation
Task: Proposal for a new mobile phone business
Role: No pre-determined role was imposed
In order to minimize the intimidating effect of
a huge recording setup, we used a compact meet-
ing archiver equipment, MARC, currently under de-
velopment in AIST Japan (Asano and Ogata, 2006)
shown in Fig. 1. MARC is equipped with an ar-
ray of 6 cameras together with an array of 8 mi-
crophones, and it captures panoramic video with
up to 15 frames/sec. and speaker-separated speech
streams with 16kHz sampling rate. A meeting cap-
ture scene is shown in Fig. 2.
The data we examine in this paper consists of one
30 minutes conversation conducted by 5 males and
1 female. Even though we did not assign any roles, a
chairperson and a clerk were spontaneously elected
by the participants at the beginning of the session.
</bodyText>
<sectionHeader confidence="0.958803" genericHeader="method">
4 Aizuti in multi-party design conversation
</sectionHeader>
<subsectionHeader confidence="0.999175">
4.1 Aiduti types and amounts
</subsectionHeader>
<bodyText confidence="0.9999723125">
We first looked at how frequent people produce
aiduti in the conversation. Table 1 shows the number
of utterances and aiduti utterances for each of the six
speakers, both in terms of the number of inter-pausal
units (IPUs). Table 2 indicates expressions identified
as aiduti utterances. Positive responses to questions
and requests are not included in aiduti, even if they
share the surface forms of Table 2. Reduplicated
forms of each of the aiduti expressions in Table 2
are also frequently observed, and they were counted
as one aiduti occurences.
We can see that a sizable portion of utterances,
about 30% to 40%, were actually aiduti utterances
in our data. An example excerpt demonstrating the
abundance of aiduti is shown in Fig. 3, where aiduti
utterances are marked by bold characters.
</bodyText>
<subsectionHeader confidence="0.9657425">
4.2 Conversation flow management
Overlapping aiduti
</subsectionHeader>
<bodyText confidence="0.9999851">
One reason why multi-party conversation con-
tains a lot of aiduti is that there are more hearers,
potential backchannel producers. Fig. 4 shows an
example in which three hearers B,E, and D produced
aiduti almost simultaneously to the speaker F’s ut-
terance. The fact that these three aiduti were over-
lapping shows that they are independently directed
to the speaker F’s preceding utterance. This type of
aiduti response is expected to increase in numbers as
the number of conversation participants increases.
</bodyText>
<subsectionHeader confidence="0.815719">
Aiduti for turn-holding
</subsectionHeader>
<bodyText confidence="0.958684333333333">
In the same example in Fig. 4, the speaker F pro-
duced aiduti ‘un’ after all aiduti utterances by hear-
ers B, E, and D, and immediately before he con-
tinued his turn. This type of speaker aiduti can be
taken to serve the turn-holding function. It gives an
acknowledgment to all the acknowledgments from
hearers collectively and signals that the speaker is
going on producing his own message.
Aiduti for floor transition
A relatively clear structure was observed in the
conversation we analyzed. The conversation con-
sisted of a sequence of idea proposals produced by
</bodyText>
<page confidence="0.997825">
13
</page>
<table confidence="0.57142375">
Aiduti→Floor Num
Aiduti speaker becomes the next floor main speaker 53
non-Aiduti speaker becomes next floor main speaker 17
Total 70
</table>
<tableCaption confidence="0.995326">
Table 3: Aiduti and floor transition
</tableCaption>
<bodyText confidence="0.999883615384615">
different speakers. We identified a stretch of conver-
sation as a floor in which one main speaker makes
a proposal on his or her ideas. As long as the spe-
cific proposal is being discussed as the conversation
topic, other participants may contribute clarification
or elaboration utterances within the same floor. An
example of a sequence of floors is shown in Fig. 5.
C first talks about the difference in people’s expected
response between mobile mails and PC mails in the
first floor. B then brings about in the second floor
a suggestion on some functionality similar to drive
mode which indicates to the original sender that the
recipient is not available at the moment. D in the
third floor follows on by mentioning Yahoo messen-
ger. We extracted 71 floors total from the 30 minute
conversation data.
Table 3 indicates the relationship between the pro-
duction of aiduti in one floor and the claiming of
the main speaker-hood in the next floor. The table
shows that many of the main speaker of a floor had
produced aiduti as a non-main speaker in the preced-
ing floor. This suggests that aiduti utterances from
non-main speakers indicate their readiness to make
a positive contribution to the joint task, by taking the
next floor and by contributing a proposal for the task
when they find a suitable opportunity.
</bodyText>
<subsectionHeader confidence="0.998995">
4.3 Collaborative elaboration of proposals
</subsectionHeader>
<bodyText confidence="0.999706916666666">
When we take a closer look into floors, we find pos-
itive collaborative behaviors from non-main speaker
participants. Typical behaviors of non-main speaker
participants of a floor include giving aiduti, pro-
viding (positive) evaluations to the idea proposed,
and inserting clarification questions. On top of
these behaviors, it was often observed in a floor that
non-main speaker participants try to make positive
contributions to the idea currently on the table, by
adding new elements of ideas or providing concrete
ideas to part of the proposal that heretofore remained
vague at the time. We call these behaviors on the
</bodyText>
<table confidence="0.997259604166667">
Start -End Sp Utterance
505.2500-506.4500 D:
- (as an image)
505.4375-505.7225 E:
506.8000-508.1450 D: (W — )
- (this says three years from now)
508.6675-509.3500
509.4875-509.9375
509.5300-510.1400
510.3875-510.9250
510.4875-511.1200 B: :
510.5100-510.6650 D:
510.9125-511.5975
511.8375-512.2125
512.0075-512.1975 B:
512.1125-512.8725 D:
512.2650-512.8800 C: :
512.6075-513.2850 B: :
513.0050-514.0925 D: :
- (it would be really convenient to com-
bine PC with Skype)
513.3875-514.2525 E:
513.6325-514.1650 C:
- (good)
514.3150-515.2350 C: :
- (with Skype)
514.3725-515.5525 E:
514.5375-515.3200 B: :
- (good)
515.8950-516.0875 C:
516.2775-516.4825 C:
516.8400-517.8825 C:
- (you can call free)
517.8100-518.8125 B: (W — )
- (free call)
518.2200-520.8650 D:
- (frequency assignment problem will
somehow be solved)
518.2500-519.0475 C:
519.0500-519.9925
519.5150-520.6675
520.4400-521.6825 E:
520.6800-521.3675 B:
521.5100-522.3050 B:
521.8250-522.7875 E:
521.9025-522.9375 D:
- (if its available worldwide)
522.7975-523.0550 C:
</table>
<figureCaption confidence="0.981183">
Figure 6: Collaborative elaboration: Success
</figureCaption>
<page confidence="0.877087">
14
</page>
<figure confidence="0.953503976744186">
Start -End Sp Utterance
543.1750-544.3800 C: :
544.6725-548.2050 C: (W — )(W —
) (D
) :
:
- (this is closer to Google service)
546.8350-547.5825 E:
548.5725-551.8350 C: :
:
- (if we place data in the network
rather than on the terminal)
551.4175-552.3400 E:
551.7175-552.1175
552.4425-556.9450 : :
:
- (even when we lose your terminal,
if you setup so that other people can
not use, not access)
553.7150-554.2625 E:
554.3650-554.6675
556.2425-557.2450
556.7250-557.1150
557.5875-558.4275
- (nobody can get data from there)
. . .
567.2850-567.7400 B: :
567.6250-567.9725 E:
568.0075-568.8775 B:
569.0300-569.7200 B:
- (there might be backup)
569.7725-570.4025 E:
570.1050-570.7775 C: (W — )
- (well, backup)
570.2625-570.6350 D:
571.1225-572.4825
- (maybe backup is not such a good
idea)
571.3425-573.5925 :
:
- (backup leaves data on the terminal)
572.6925-573.2025 B:
- (right)
</figure>
<table confidence="0.990119857142857">
Condition Num
Floor with aiduti 67
Floor with no aiduti 4
Floor with Collab-Elab. 29
Floor with no Collab-Elab. 42
Aiduti speaker initiated Collab-Elab. 25
non-Aiduti speaker initiated Collab-Elab. 4
</table>
<tableCaption confidence="0.999941">
Table 4: Aiduti in Collaborative elaboration
</tableCaption>
<bodyText confidence="0.999895607142857">
part of non-main speaker participants ‘collaborative
elaboration.’ Collaborative elaboration can be a suc-
cess or a failure. Figures 6 and 7 show two con-
trasting examples. In the example in Fig. 6, non-
main speaker participants C and B successfully con-
tribute to the idea proposal by the main speaker D on
combining PC and Skype functionalities, by explic-
itly pointing out the concrete merit, e.g., free phone
call, as a support of the proposal. In the example in
Fig. 7, on the other hand, a non-main speaker par-
ticipant B first tried to make a contribution, the idea
of local data backup, to the proposal produced by
the main speaker C, storage of data in the network,
but gave up after a non-positive response from C and
retracted his additional proposal.
Table 4 shows the relationship between collab-
orative evaluation and aiduti utterances in a floor.
Aiduti utterances were observed in almost every
floor. Collaborative elaboration is also rather fre-
quent. It takes place in about 40% of all floors. Fi-
nally, the table shows that participants who perform
collaborative evaluation in a floor are likely to pro-
duce aiduti utterances in the same floor. This sug-
gests, again, that aiduti utterances from non-main
speaker participants of a floor indicate their readi-
ness to make a positive contribution to the joint task,
by improving on the proposal currently being dis-
cussed.
</bodyText>
<sectionHeader confidence="0.995582" genericHeader="evaluation">
5 Discussions
</sectionHeader>
<figureCaption confidence="0.998426">
Figure 7: Collaborative elaboration: failure
</figureCaption>
<subsectionHeader confidence="0.527059">
Frequency of aiduti utterances
</subsectionHeader>
<bodyText confidence="0.999970833333333">
We observed that multi-party conversations con-
tain a high rate (30∼40%) of aiduti utterances. a
great number of aiduti utterances were produced by
the chairperson among all the participants. Saft
(2006), based on the analysis of Japanese TV dis-
cussion programs, pointed out that chairperson pro-
</bodyText>
<page confidence="0.992437">
15
</page>
<bodyText confidence="0.980421652173913">
duces a large portion of aiduti among all the discus-
sion participants. These findings appear to confirm
the idea that aiduti utterances have functions to man-
age the flow of conversations, and chairpersons ex-
ploit these functions in discussion sessions. But, ex-
act conversation flow management function of aiduti
may not be unique. According to Saft (2006), the
chairperson in the particular TV discussion program
uses aiduti to claim their addressee-hood in order to
prevent the discussion from free-floating and out of
control. In our design conversation data, it appears
that the chairperson frequently inserts aiduti in or-
der to encourage other participants to engage in the
discussion and to make the session more lively.
Floor structure
It may not always be a good strategy for ev-
erybody to produce aiduti as acknowledgment in a
multi-party conversation, since with a lot of hearers
it can be a nuisance for the speaker to get too many
aiduti in every possible grounding point. It follows
that the fact that a certain participant produces aiduti
at a certain timing in a multi-party conversation can
have significance other than the grounding of the
message just produced. It is interesting to note that
even though at the level of turn-taking, an aiduti ut-
terance works as a continuer, a turn-yielding signal,
at the level of floor, aiduti utterances seem to indi-
cate positive involvement attitude of the participant
toward the joint problem solving activity.
Collaborative elaboration
We observed a number of instances of joint con-
struction of proposals through collaborative elabo-
ration in our design conversation data. It was also
observed that in most of the cases of collaborative
elaboration, aiduti utterances were accompanied by
participants engaging in collaborative elaboration.
These facts seem to imply that aiduti utterances both
signal and produce among conversation participants
an affiliative awareness toward joint construction of
the proposal for the problem at hand, through the
exchange of readiness signal, among all the group
members, toward making positive contributions to
the ongoing joint problem solving activity. We be-
lieve that these contribution readiness and affilia-
tive awareness are the basis of affective functions of
aiduti in Japanese conversations.
</bodyText>
<sectionHeader confidence="0.99959" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99998475">
An analysis of aiduti utterances, Japanese backchan-
nels, in a Japanese multi-party design conversation
was conducted. It was argued, based on the analysis,
that, in addition to the two major functions, signal-
ing acknowledgment and turn-management, aiduti
utterances in multi-party conversations are involved
in joint construction of design plans through man-
agement of the floor structure, and display of par-
ticipants’ readiness to engage in collaborative elab-
oration of jointly constructed proposals. It was also
suggested that these additional functions eventually
lead to affective functions of aiduti.
</bodyText>
<sectionHeader confidence="0.983481" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.950305">
The work reported in this paper was partially sup-
ported by Japan Society for the Promotion of
Science Grants-in-aid for Scientific Research (B)
18300052.
</bodyText>
<sectionHeader confidence="0.994916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998725782608695">
Futoshi Asano and Jun Ogata. 2006. Detection and sepa-
ration of speech events in meeting recordings. In Proc.
Interspeech, pages 2586–2589.
Nicholas Fay, Simon Garrod, and Jean Carletta. 2000.
Group discussion as interactive dialogue or as serial
monologue: The influence of group size. Psychologi-
cal Science, 11(6):487–492.
John Heritage. 2006. An overview of English backchan-
nels. International workshop on cross-cultural and
culture-specific aspects of conversational backchan-
nels and feedback, December.
Senko K. Maynard. 1986. On back-channel behavior in
Japanese and English casual conversation. Linguistics,
24:1079–1108.
Scott L. Saft. 2006. The moderator in control: Use
of names, the particle ne, and response tokens on a
Japanese discussion TV program. Research on Lan-
guage and Social Interaction, 39(2):155–193.
Emanuel A. Schegloff. 1982. Discourse as interactional
achievement: some uses of uh huh and other things
that come between sentences. In Deborah Tannen, ed-
itor, Analyzing Discourse, Text, and Talk, pages 71–93.
Georgetown University Press.
</reference>
<page confidence="0.998708">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.887976">
<title confidence="0.990298">Aiduti in Japanese Multi-party Design Conversations</title>
<author confidence="0.942334">Yasuhiro</author>
<affiliation confidence="0.998957">Future University -</affiliation>
<address confidence="0.977344">116-2 Kameda-Nakano Hakodate Hokkaido,</address>
<email confidence="0.996512">katagiri@fun.ac.jp</email>
<abstract confidence="0.997501785714286">Japanese backchannel utterances, aizuti, in a multi-party design conversation were examined, and aizuti functions were analyzed in comparison with its functions in twoparty dialogues. In addition to the two major functions, signaling acknowledgment and turn-management, it was argued that aizuti in multi-party conversations are involved in joint construction of design plans through management of the floor structure, and display of participants’ readiness to engage in collaborative elaboration of jointly constructed proposals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Futoshi Asano</author>
<author>Jun Ogata</author>
</authors>
<title>Detection and separation of speech events in meeting recordings.</title>
<date>2006</date>
<booktitle>In Proc. Interspeech,</booktitle>
<pages>2586--2589</pages>
<contexts>
<context position="11704" citStr="Asano and Ogata, 2006" startWordPosition="1791" endWordPosition="1794">Table 1: Number of utterances and aiduti produced in multi-party design conversation Japanese form sound translation hai (yes) un (yeah) aa (ah) ee (correct) sou (I agree) Table 2: Linguistic forms of aiduti The condition of our data collection was as follows: Number of participants: six for each session Arrangement: face-to-face conversation Task: Proposal for a new mobile phone business Role: No pre-determined role was imposed In order to minimize the intimidating effect of a huge recording setup, we used a compact meeting archiver equipment, MARC, currently under development in AIST Japan (Asano and Ogata, 2006) shown in Fig. 1. MARC is equipped with an array of 6 cameras together with an array of 8 microphones, and it captures panoramic video with up to 15 frames/sec. and speaker-separated speech streams with 16kHz sampling rate. A meeting capture scene is shown in Fig. 2. The data we examine in this paper consists of one 30 minutes conversation conducted by 5 males and 1 female. Even though we did not assign any roles, a chairperson and a clerk were spontaneously elected by the participants at the beginning of the session. 4 Aizuti in multi-party design conversation 4.1 Aiduti types and amounts We </context>
</contexts>
<marker>Asano, Ogata, 2006</marker>
<rawString>Futoshi Asano and Jun Ogata. 2006. Detection and separation of speech events in meeting recordings. In Proc. Interspeech, pages 2586–2589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Fay</author>
<author>Simon Garrod</author>
<author>Jean Carletta</author>
</authors>
<title>Group discussion as interactive dialogue or as serial monologue: The influence of group size.</title>
<date>2000</date>
<journal>Psychological Science,</journal>
<volume>11</volume>
<issue>6</issue>
<contexts>
<context position="4817" citStr="Fay et al., 2000" startWordPosition="690" endWordPosition="693">rances in Japanese multiparty design conversations. In order to locate the type of activity we’ve been working on within the broad range of interaction activities collectively categorized as multi-party conversations, we first try to list up potential parameters that might influence the structure and organization of conversational interactions. Number of participants We call a conversation between more than two people a multi-party conversation. A conversation between three people and a conversation between 10 people are not the same in their conversational organization. It has been observed (Fay et al., 2000) that conversations with a small number of participants tend to be homogeneous that contain a number of equal status pairwise interactions, whereas conversations with a large number of participants tend to be more hierarchical with a central control person working as a chairperson. Types of activities Conversational interactions are often embedded in larger activities, and the type of embedding activities makes a difference in the organization of conversations. (a) Purpose One-way information transfer in lectures and joint problem solving in a group of people have both fixed but different type</context>
</contexts>
<marker>Fay, Garrod, Carletta, 2000</marker>
<rawString>Nicholas Fay, Simon Garrod, and Jean Carletta. 2000. Group discussion as interactive dialogue or as serial monologue: The influence of group size. Psychological Science, 11(6):487–492.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Heritage</author>
</authors>
<title>An overview of English backchannels. International workshop on cross-cultural and culture-specific aspects of conversational backchannels and feedback,</title>
<date>2006</date>
<contexts>
<context position="3077" citStr="Heritage (2006)" startWordPosition="439" endWordPosition="440">posal currently under discussion, which then leads to affective coordination. 2 Backchannels in Dialogues Backchannel utterances were conceived initially in two-party dialogues with one speaker and one hearer. Schegloff (1982) picked up hearer’s short utterances such as ’uh, huh’ produced in response to the speaker’s main utterances, and characterized them as backchannels, whose functions are to convey backward messages from the hearer to the speaker indicating that the hearer is attending to, listening to, understanding, and expecting to continue the production of the speaker’s main message. Heritage (2006) provides a broader conception of backchannels and lists the following four functions Proceedings of the Workshop on Embodied Language Processing, pages 9–16, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics Figure 2: Setting for multi-party design conversation capture Figure 1: Meeting archiver equipment MARC used in data collection for backchannel utterances. • Provide Acknowledgments to prior locutions by the speaker • Projection of further talk in turn taking • Recipient epistemic states triggered by the speaker’s message • Recipient affiliative attit</context>
</contexts>
<marker>Heritage, 2006</marker>
<rawString>John Heritage. 2006. An overview of English backchannels. International workshop on cross-cultural and culture-specific aspects of conversational backchannels and feedback, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Senko K Maynard</author>
</authors>
<date>1986</date>
<booktitle>On back-channel behavior in Japanese and English casual conversation. Linguistics,</booktitle>
<pages>24--1079</pages>
<contexts>
<context position="3748" citStr="Maynard (1986)" startWordPosition="533" endWordPosition="534">the following four functions Proceedings of the Workshop on Embodied Language Processing, pages 9–16, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics Figure 2: Setting for multi-party design conversation capture Figure 1: Meeting archiver equipment MARC used in data collection for backchannel utterances. • Provide Acknowledgments to prior locutions by the speaker • Projection of further talk in turn taking • Recipient epistemic states triggered by the speaker’s message • Recipient affiliative attitude, how the recipient is aligned with speaker’s message Maynard (1986) compared Japanese and American dialogues, and observed that Japanese dialogues have almost twice as much aizuti as American backchannel utterances. This observation suggests that significance of backchannels and their functions in conversational interactions may depend on social groups, types of activities and other social or task related parameters. 3 Multi-party Conversation 3.1 Varieties of multi-party conversations We will focus on aiduti utterances in Japanese multiparty design conversations. In order to locate the type of activity we’ve been working on within the broad range of interact</context>
</contexts>
<marker>Maynard, 1986</marker>
<rawString>Senko K. Maynard. 1986. On back-channel behavior in Japanese and English casual conversation. Linguistics, 24:1079–1108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott L Saft</author>
</authors>
<title>The moderator in control: Use of names, the particle ne, and response tokens on a Japanese discussion TV program.</title>
<date>2006</date>
<journal>Research on Language and Social Interaction,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="20259" citStr="Saft (2006)" startWordPosition="3154" endWordPosition="3155"> collaborative evaluation in a floor are likely to produce aiduti utterances in the same floor. This suggests, again, that aiduti utterances from non-main speaker participants of a floor indicate their readiness to make a positive contribution to the joint task, by improving on the proposal currently being discussed. 5 Discussions Figure 7: Collaborative elaboration: failure Frequency of aiduti utterances We observed that multi-party conversations contain a high rate (30∼40%) of aiduti utterances. a great number of aiduti utterances were produced by the chairperson among all the participants. Saft (2006), based on the analysis of Japanese TV discussion programs, pointed out that chairperson pro15 duces a large portion of aiduti among all the discussion participants. These findings appear to confirm the idea that aiduti utterances have functions to manage the flow of conversations, and chairpersons exploit these functions in discussion sessions. But, exact conversation flow management function of aiduti may not be unique. According to Saft (2006), the chairperson in the particular TV discussion program uses aiduti to claim their addressee-hood in order to prevent the discussion from free-float</context>
</contexts>
<marker>Saft, 2006</marker>
<rawString>Scott L. Saft. 2006. The moderator in control: Use of names, the particle ne, and response tokens on a Japanese discussion TV program. Research on Language and Social Interaction, 39(2):155–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuel A Schegloff</author>
</authors>
<title>Discourse as interactional achievement: some uses of uh huh and other things that come between sentences.</title>
<date>1982</date>
<pages>71--93</pages>
<editor>In Deborah Tannen, editor, Analyzing Discourse, Text, and Talk,</editor>
<publisher>Georgetown University Press.</publisher>
<contexts>
<context position="2688" citStr="Schegloff (1982)" startWordPosition="379" endWordPosition="380">of how aiduti utterances are employed in experimentally captured multi-party design conversation data, we argue that aiduti utterances in Japanese have, on top of the informational coordination functions of common-grounding and turn-management, the function of expressing the readiness, a positive attitude, on the part of a participant to engage in the joint construction of an ongoing proposal currently under discussion, which then leads to affective coordination. 2 Backchannels in Dialogues Backchannel utterances were conceived initially in two-party dialogues with one speaker and one hearer. Schegloff (1982) picked up hearer’s short utterances such as ’uh, huh’ produced in response to the speaker’s main utterances, and characterized them as backchannels, whose functions are to convey backward messages from the hearer to the speaker indicating that the hearer is attending to, listening to, understanding, and expecting to continue the production of the speaker’s main message. Heritage (2006) provides a broader conception of backchannels and lists the following four functions Proceedings of the Workshop on Embodied Language Processing, pages 9–16, Prague, Czech Republic, June 28, 2007. c�2007 Associ</context>
</contexts>
<marker>Schegloff, 1982</marker>
<rawString>Emanuel A. Schegloff. 1982. Discourse as interactional achievement: some uses of uh huh and other things that come between sentences. In Deborah Tannen, editor, Analyzing Discourse, Text, and Talk, pages 71–93. Georgetown University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>