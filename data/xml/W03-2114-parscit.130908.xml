<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.970106">
Managing Dialogue Interaction: A Multi-Layered Approach
</title>
<author confidence="0.942589">
Oliver Lemon
</author>
<affiliation confidence="0.9629855">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.767223">
2 Buccleugh Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.981174">
olemon@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.4218896" genericHeader="abstract">
Lawrence Cavedon
CSLI
Stanford University
220 Panama St
Stanford, CA 94306, USA
</sectionHeader>
<email confidence="0.945143">
lcavedon@csli.stanford.edu
</email>
<author confidence="0.450459">
Barbara Kelly
</author>
<affiliation confidence="0.392657">
Department of Linguistics
</affiliation>
<sectionHeader confidence="0.555533" genericHeader="method">
UCSB
Santa Barbara
CA 93106-3100, USA
</sectionHeader>
<email confidence="0.833646">
bfk0@umail.ucsb.edu
</email>
<keyword confidence="0.8385575">
Keywords: dialogue management architecture, in-
teraction, communication channel management
</keyword>
<sectionHeader confidence="0.99497" genericHeader="method">
Abstract
</sectionHeader>
<bodyText confidence="0.999871272727273">
We present evidence for the importance
of low-level phenomena in dialogue in-
teraction and use this to motivate a
multi-layered approach to dialogue pro-
cessing. We describe an architecture
that separates content-level communica-
tive processes from interaction-level phe-
nomena (such as feedback, grounding,
turn-management), and provide details of
specific implementations of a number of
such phenomena.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="method">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999853653846154">
Real dialogue between human participants involves
phenomena that do not so much contribute to the
content of communication as relate directly to the
interactive process between the participants. This
includes turn management, providing feedback, ut-
terance fillers, error and false-start management, and
utterance timing.
Recent work on dialogue and natural language
processing in general has acknowledged the pres-
ence of such phenomena in natural speech, and in
some cases the importance of its role in dialogue in-
teraction. However, treatment of such phenomena
has generally been part of the standard processing
model; for example, some parsers are able to han-
dle fillers such as “um”, while recent versions of the
TRIPS system (Allen et al., 2001) uses incremental
parsing and other techniques to handle a range of re-
lated phenomena.
We believe that greater focus on “interaction
level” phenomena is appropriate and will lead to
benefits in building dialogue systems for more ro-
bust natural interaction. In this paper, we outline a
two-layer architecture for dialogue systems, where
one layer uses a range of “shallow” processing tech-
niques to maintain a smooth interaction between the
dialogue participants.
</bodyText>
<subsectionHeader confidence="0.987692">
1.1 Managing interaction
</subsectionHeader>
<bodyText confidence="0.999725574468086">
The inspiration for a clean separation into a two-
layer architecture comes from two sources. Clark
(1996) distinguishes between two separate commu-
nication tracks, which he calls communicative and
meta-communicative. These are simultaneously oc-
curring communications, the first dealing with the
information at hand, and the other relating to the
performance itself. Dialogue participants use what
Clark refers to as signals to refer to the performance
itself: e.g. timing, delays, re-phrasing, mistakes, re-
pairs, etc.1
A second motivation is work on architectures for
robots and autonomous agents embedded in com-
plex, dynamic, unpredictable environments. Sev-
eral researchers in this area have argued for multi-
layered architectures for agents that plan action se-
quences to achieve some goal or task, but need to
react quickly to change in the environment (e.g.
&apos;Clark’s distinction does not necessarily carry over directly
to the design of a dialogue system architecture, but it motivates
focus on the low-level communication channel.
(Firby, 1994; M¨uller, 1996)). In such architectures,
the role of the bottom layer is to monitor the envi-
ronment and initiate appropriate actions within the
broader context of the goal-directed plan, which is
provided by the higher layer of the architecture. The
layers operate independently and asynchronously,
but communicate as necessary: e.g. goals and plans
are passed down to the execution layer, while obser-
vations or problems (which may trigger replanning)
are passed up to the planning layer.
We view the process of natural interaction with
a dialogue participant as analogous to the interac-
tion with a dynamic environment: dialogue phenom-
ena arise which need to be negotiated (as a new
obstacle must be avoided by a robot). In the case
of a human user involved in activity-oriented dia-
logue, timeliness is particularly important in order
to keep the user engaged and focussed—otherwise,
performance of the joint activity may be adversely
affected. In particular, dialogic interaction is a con-
tinuous process which cannot be broken without the
risk of some breakdown: signal-level phenomena
must be handled as smoothly as possible, without
necessarily resorting to content-level processes, in
order to maintain a tight interaction between the par-
ticipants.
</bodyText>
<subsectionHeader confidence="0.995243">
1.2 A multi-layered architecture
</subsectionHeader>
<bodyText confidence="0.998277671052631">
Motivated partially by some of the same issues we
discuss here, Allen et al. (2001) describe a new ar-
chitecture for their TRIPS system that breaks dia-
logue management into multiple asynchronous com-
ponents. We concur with their concerns but focus on
a different architectural shift.
We outline below an architecture that sepa-
rates interaction-focussed techniques from context-
management and conversation planning. An initial
version of the architecture has been implemented at
the Center for the Study of Language and Informa-
tion (CSLI) at Stanford University.
This breakdown into separate architectural levels
is analogous to the multi-level agent/robot architec-
tures. However, many of the same motivations per-
tain, especially those related to design considera-
tions (e.g. separating different types of phenomena
into different layers) and performance (e.g. high-
level planning from low-level execution and mon-
itoring running in parallel2). Further, the manner
in which M¨uller and Firby’s systems handle reac-
tive tasks (e.g. obstacle avoidance, object tracking,
etc.) completely at the low-level whenever possible
reflects our view of how certain dialogue interaction
phenomena are best handled. Much like these sys-
tems, dialogue communicative goals are produced
at the higher level and imposed as constraints on
the lower-level. Environment-level processes fill in
the detail of these goals and handle contingencies
which may otherwise prevent the achievement of
these goals.
A number of interaction-management techniques
are present in the current implementation, including:
A back-up recognition pass, using statistical
processing to extend grammar-based coverage
and provide immediate user “help” feedback
for unrecognized utterances (Hockey et al.,
2003);
Turn management—timing of system output is
governed by monitoring the speech channel and
the (prioritized) agenda of speech outputs. If
the system need to take the turn, it grabs it using
only low-level processing;
Handling user barge-in—user speech interrupts
system output and automatically grabs the turn;
Immediate Grounding of recognized com-
mands (e.g. system says “OK” immediately af-
ter recognizing the user: “fly to the tower”);
NP selection — choosing anaphoric or salient
noun-phrases at the point of generation;
Incremental aggregation of system-generated
utterances — appropriately condensing and
forming elliptical system output at the point of
generation.
While this accounts for only a small number of
signals that arise during natural dialogue, the ar-
chitecture provides a framework for incorporat-
ing further techniques—in particular, using shallow
2Note: we are talking about very different parallel threads
here than those which occur in multi-modal fusion, such as oc-
curs in the SmartKom (Wahlster, 2002) system.
processing—for making use of such signals to pro-
vide more natural and robust interactions between
dialogue systems and human participants.
In the next section, we describe work from the lin-
guistic and psychology literature that demonstrates
the importance of asynchronous interaction-level
processing. In Section 3, we propose a specific ar-
chitecture that provides a framework for integrat-
ing various processes for channel-management. In
Sections 4 and 5, we describe specifics of the CSLI
implementation, outlining first the more abstract di-
alogue management layer, followed by techniques
employed at the interaction layer. In Section 6, we
discuss further possibilities and in Section 7 we con-
clude.
</bodyText>
<sectionHeader confidence="0.862824" genericHeader="method">
2 The Importance of Channel Phenomena
</sectionHeader>
<bodyText confidence="0.999964706666667">
The standard processing model for dialogue systems
involves a sequence of modules from speech recog-
nition to speech synthesis, as illustrated in Figure 1,
which essentially illustrates (a simplification of) the
original TRIPS architecture, as described in (Fergu-
son and Allen, 1998). Typically, each module is self-
contained and relatively independent of other mod-
ules.
Recent findings in the psycholinguistic literature
have suggested various shortcomings of this mod-
ular approach. For example, work on alignment
indicates that conversation participants’ processing
interacts on multiple levels, contravening the strict
modular model (Pickering and Garrod, 2003). This
is one of the considerations we address below, but
we are primarily concerned with other interaction-
level phenomena.
One of our prime motivations for an interaction
level processing layer is to ensure timely response
to interaction. Parsing and processing takes time—
this can be alleviated by incremental parsing tech-
niques, but meta-communication signals typically
do not need to be interpreted and processed to the
same extent as communicative utterances, and in-
stead require immediate attention that precludes full
processing.
For example, researchers have looked at the use
of um and uh in conversation and found that these
are often used as place-holders for a speaker who
wants to maintain their speaking turn (Clark and Fox
Tree, 2002). The detection of fillers such as these
generally acts to inhibit (to some extent) the listener
from interrupting or taking the turn from the current
speaker. Hence, not only should such discontinu-
ities not be ignored but they must also be processed
immediately in order to maintain the ongoing inter-
action.
Conversely, listeners also use what is known as
back-channel feedback to indicate to the speaker that
they are listening and paying attention. For En-
glish, back-channels include uh-huh, mhm and yeah.
Back-channels differ from other devices used to
keep a conversation flowing, such as repetitions and
collaborative finishes, in that they tend to be non-
specific to the current utterance. Moreover, back-
channel feedback is often produced without think-
ing, in response to simple prosodic clues such as a
speaker pause, a lowering of speaker pitch, or a rise
in speaker intonation (Ward and Tsukahara, 1999).
Most importantly, however, back-channel feed-
back is important to the speaker.3 Bavelas et al.
(2000) investigated how a speaker in a conversation
(in this case someone narrating a story) is affected
when listener responses are inhibited. They found
that speakers with distracted and unresponsive lis-
teners did not finish their stories effectively, measur-
ably faltering at what should have been the dramatic
ending. Speakers needed an interlocutor’s feedback
to be able to maintain fluency and continue the dia-
logue effectively. Bavelas et al also found that re-
sponse latency in one-on-one conversations is ex-
tremely short and may be simultaneous: listeners
can provide back-channels without fully listening to
the conversation partner and without being respon-
sible for taking up a speaking turn.
These results indicate that the nature of interac-
tion between participants is crucial to the collabora-
tive act of dialogue—signals and feedback that carry
effectively no communicative content are still im-
portant for keeping the interaction smooth and to en-
sure that the participants stay attentive and focussed
on the task at hand. When the dialogue task involves,
say, a human user being guided through a safety-
critical activity by an automated system, then such
issues are of particular importance.
</bodyText>
<footnote confidence="0.4416445">
3Allwood (1995) refers to such feedback morphemes as the
most important cohesion device in spoken language.
</footnote>
<figure confidence="0.99785525">
Problem-Solving
Manager
Discourse
context
Speech Output
Speech Recog
Speech Input
NL Parser
Dialogue
Manager
Speech Synth
Generation
</figure>
<figureCaption confidence="0.999981">
Figure 1: Traditional Dialogue System Architecture
</figureCaption>
<bodyText confidence="0.9999417">
Conversely, communicative behavior contains
signals regarding a participant’s attention, and in
particular may indicate a loss of focus. In tuto-
rial settings—one of the dialogue applications we
are specifically concerned with—this can be used
to determine students’ confidence in their responses.
For example, phenomena such as timing between re-
sponses, hesitance markers, and intonation can all
be implicit clues that a student is having a problem
(Graesser et al., 1995).
</bodyText>
<sectionHeader confidence="0.980959" genericHeader="method">
3 A Two-Level Architecture
</sectionHeader>
<bodyText confidence="0.99878256">
The traditional architecture for dialogue systems ba-
sically involves a linear approach to processing, as
illustrated in Figure 1. In this standard architecture,
modules tend to be self-contained and only loosely
dependent. Evidence outlined above, particularly
that related to alignment, suggests that this tightly
encapsulated approach will deal poorly with the in-
teractive nature of real dialogue. Allen et al’s (2001)
revised TRIPS architecture introduces a more non-
linear approach to dialogue processing, with asyn-
chronous processes managing interpretation, gener-
ation, and interface to behavioral aspects.
We augment the TRIPS approach by combining
multiple processes for interpreting utterances (e.g.
structured parsing versus statistical techniques) and
for generating responses (e.g. generation from se-
mantic representation versus template-based). More
fundamental to the architectural distinction we pro-
pose, the processing of an utterance and generat-
ing an appropriate response may proceed without
full processing by the Dialogue Management com-
ponent: information gleaned from an utterance will
always be passed up to the Dialogue Manager, but to
ensure timely response, an appropriate response may
be produced directly from a low-level component.
Other processes included at the interaction layer de-
tect non-communicative information, such as gaps
or delays in the user’s speech.
Figure 2 illustrates various aspects of the specific
two-level architecture we are developing. The lower
level interfaces directly with the user and, impor-
tantly, is driven by this interaction. For example the
low level includes a Turn Manager which manipu-
lates the speech channel to ensure that:
user inputs are respected without interruption
(except when necessary);
turn passes to the appropriate participant, based
on the highest priority Agenda item and the di-
alogue move that generated it;
generated outputs are natural and timely;
recognized user inputs are acknowledged
quickly using simple feedback utterances.
The upper level is responsible for modeling other
aspects of the conversational context, as well as
communicative goals and intentions. The con-
tent (i.e. logical forms) of user utterances are pro-
cessed using the dialogue model (e.g. updates and
adding nodes to the Dialogue Move Tree (Lemon et
al., 2002b)), and system utterances are constructed
which are in line with the system’s communicative
</bodyText>
<figureCaption confidence="0.971584">
Figure 2: System Architecture
</figureCaption>
<figure confidence="0.798699285714286">
Content layer:
- utterance planning
- communicative intentions
- grounding
- content management
- interaction with agent arch
Interaction layer
- timing
- form
- engagement
- acknowledgement
Attention
Monitor
Backup
Shallow
Processor
(Helper)
Context
Mgr
Speech channel
Speech
recogition
and
Parsing
Dialogue
Move
Tree
ack
Turn
Mgr
Conversation
Planner
TTS
Output
Agenda
Activity
Model
Generation
Module
Agent
- intentions
- goals
- plans
- observations
Generation:
- anaphora
- pronouns
- aggregation
- echoing
</figure>
<bodyText confidence="0.999271638888889">
goals and intentions, whether they be imparting in-
formation to the user or requesting clarification or
further information.
The higher level also interacts with the rest of the
agent architecture, mediated by an Activity Model
(i.e. a representation of the agent activities about
which dialogue may occur (Gruenstein, 2002)). The
agent may wish to communicate its own goals, the
progress of its activities, or report on any observa-
tions it makes regarding its environment.
As with multi-layered agent architectures, the
two levels operate semi-autonomously and asyn-
chronously: the lower level is driven by tight in-
teraction with the user, while the upper level is
driven by longer-range communicative goals from
its activities and responses to user utterances. How-
ever, various types of information exchange connect
the two levels. For instance, user utterances rec-
ognized at the lower level must clearly be passed
to the content-management level to be parsed and
then incorporated into the dialogue context, while
high-level communication goals must be passed to
the lower level’s Output Agenda for generation and
speech-synthesis.
The Output Agenda plays a crucial role in medi-
ating utterances to be communicated, whether they
be system-initiated or responses, and generated from
the planner or a low-level component. The Output
Agenda is a prioritized list, where an utterance’s pri-
ority is influenced by a number of factors, such as:
whether it is in response to an error or misunder-
standing (i.e. “Pardon”); the importance of the com-
municative content (i.e. an urgent observation); and
the dialogue move that generated it (e.g. answering a
question). The Agenda runs asynchronously, aggre-
gating multiple utterances when appropriate as well
as influencing speaker turn (see below).
Of perhaps greater interest, the interaction level
can be used to monitor user engagement and at-
tention in other ways — e.g. time between utter-
ances, speaking rate, use of speech fillers — to de-
tect potential problems as soon as possible, and to
provide early warning to the content layer that the
user may have, for example, misunderstood some
instruction. This can be used to generate a clarifi-
cation or grounding sub-dialogue, in order to estab-
lish mutual understanding before proceeding (thus
improving robustness of the system as a whole).
Conversely, expectations at the upper-layer can
influence processing at the interaction layer: for ex-
ample, open points of attachment on the Dialogue
Move Tree represent types of utterances the system
expects from the user, and these are used to prime
the recognition of incoming utterances for faster
processing, as well as influencing the turn.
In engineering terms, this division of labour is
attractive in that the clarity and modularity of dia-
logue management is enhanced. Rather than conflat-
ing, for example, turn-management with utterance
planning in a single generation component of a dia-
logue system, the separation into multiple levels of
processing allows different turn-taking and utterance
planning strategies to be developed independently,
and various combinations to be experimented with.
In the rest of the paper, we discuss our dialogue
management architecture and, in particular, the tech-
niques employed so far at each of the two levels de-
scribed here to enhance user experience and improve
overall system performance. The current implemen-
tation based on the above architecture is still being
refined; we focus on the features that have already
been implemented.
</bodyText>
<sectionHeader confidence="0.998305" genericHeader="method">
4 Top-Level Context Management
</sectionHeader>
<bodyText confidence="0.998597575757576">
The approach to dialogue modeling we have imple-
mented is based on the theory of dialogue games
(Carlson, 1983; Power, 1979), and, for task-oriented
dialogues, discourse segments (Grosz and Sidner,
1986). These accounts rely on the observation that
answers generally follow questions, commands are
usually acknowledged, and so on, so that dialogues
can be partially described as consisting of adjacency
pairs of such dialogue moves. The notion of “attach-
ment” of dialogue moves on a Dialogue Move Tree
(DMT) (Lemon et al., 2002b) embodies this idea.
An Activity Tree represents hierarchical and tem-
poral information about the task-state of the dia-
logue. Activities are the joint tasks managed by the
dialogue: e.g. booking a flight or moving a robot—
again, see (Lemon et al., 2002b) for details. Nodes
on the Activity Tree can be in various states (active,
complete, failed, ), and any change in the state of
a node (typically because of an action by the agent)
is placed onto the system’s Output Agenda for po-
tential verbal report to the user, via the low-level
message selection and generation module.
This level of the architecture is where conversa-
tion planning and generation of system-initiated top-
ics occur. Any planned communication (whether it
be system-initiated or in response to a user utter-
ance) is put on to the Output Agenda, where it is
scheduled for generation.4 Conversely, true ground-
ing — i.e. acknowledging that an utterance is un-
derstood within the context of the rest of the dia-
logue — only occurs after the utterance has been in-
terpreted with respect to the DMT. Since a simple
acknowledgment may already have been generated
</bodyText>
<tableCaption confidence="0.726526666666667">
4The order in which outputs are generated, or even whether
they end up generated at all, depends on the priority of the cor-
responding information as well other interactions with the user.
</tableCaption>
<bodyText confidence="0.999898529411765">
after recognition, output after interpretation is only
needed if a response is required (e.g. the user asked
a question), or if a problem is detected (e.g. an am-
biguity must be resolved).
Since system communication is planned here, this
layer is also the one that interacts with the rest of the
agent architecture: any goals, state-changes, or ob-
servations that the agent may wish to communicate
are added as communicative goals, typically via the
Activity Model. For command-and-control applica-
tions (e.g. guiding a robot or UAV), system-initiated
utterances tend to be fairly short and simple and
conversation-planning is minimal; however, for our
dialogue-enabled tutorial application (Clark et al.,
2001), conversation-planning is quite complex and
the system may generate multiple, relatively long ut-
terances on its own initiative.
</bodyText>
<sectionHeader confidence="0.985594" genericHeader="method">
5 Low-level Conversation Management:
Maintaining the Communication
Channel
</sectionHeader>
<bodyText confidence="0.999940846153846">
We currently employ a range of shallow processing
techniques to maintain a smooth interaction with the
human dialogue participant. By “shallow process-
ing” we mean processing that does not necessarily
result in or concern itself with the semantic repre-
sentation or pragmatic interpretation of the utterance
in the context of the dialogue. In particular, informa-
tion at this level is not processed in the context of the
Dialogue Move Tree or the Activity Tree.
In the following, we describe a number of the low-
level processing techniques currently implemented
in our system. Future work will address more of the
interaction phenomena described earlier.
</bodyText>
<subsectionHeader confidence="0.986257">
5.1 Case study 1: Helper Feedback
</subsectionHeader>
<bodyText confidence="0.999974939393939">
In cases where a user utterance is not recognized, the
input is passed to a statistical recognizer of wider
coverage. This recognizer is often able to detect
lexical items and grammatical structures in the in-
put that are not covered by the first (grammar-based)
recognizer. In these cases, the results of the second
recognition pass are used to inform the user of the
system’s shortcomings, for example: “The system
heard you say ‘Look around for a red car’, but the
system does not know the word ‘around’. You could
say ‘Look for a red car’ ”.
None of these utterances is planned or represented
at the top level of dialogue management. They are
produced simply to inform the user of a communi-
cation breakdown and to try to keep the communi-
cation flowing. If the user were to indulge in meta-
dialogue about the help message, then that message
would need to be represented in the high-level con-
text. However, we present the help message as being
generated by a different “helper” agent, which dis-
appears (from the GUI) as soon as the help message
is produced, thus discouraging the user from engag-
ing it in dialogue.
User tests have shown that the use of this low level
module (which can be installed independently of the
high-level dialogue manager) significantly improves
task completion (both percentage of tasks completed
and time taken). By the fifth task, 100% of users
with the helper completed the task as compared with
80% of those without, and those without the helper
took on average 53% longer to complete the tasks.
For full details of the evaluation see (Hockey et al.,
2003).
</bodyText>
<subsectionHeader confidence="0.993691">
5.2 Case study 2: Turn Taking
</subsectionHeader>
<bodyText confidence="0.99999105">
Here we use a turn-marker at the low-level of dia-
logue processing. The turn can be marked as user,
system or none, and is set in a variety of ways. If
the user begins to speak (start-of-speech signal is re-
ceived from the recognizer) the turn becomes user
and any system audio output is stopped. If the sys-
tem needs to take the turn (e.g. if it has urgent in-
formation it needs to communicate), but turn is set
to user, and the user is not speaking, the system will
output “Just a moment” and so take the turn before
generating its required utterance. Again, note that
this turn-grabbing utterance is not planned or repre-
sented at the top-level of dialogue moves. It does
not need to enter into such high-level plans or rep-
resentations because it is required only in order to
manipulate and maintain the channel, and does not
carry any content of its own.
The demonstration system displays a turn marker
on the GUI, allowing observers to monitor the
changing possession of the turn.
</bodyText>
<subsectionHeader confidence="0.979948">
5.3 Case study 3: Incremental aggregation
</subsectionHeader>
<bodyText confidence="0.997121784615385">
Aggregation (Appelt, 1985) combines and com-
presses utterances to make them more concise, avoid
repetitious language structure, and make the sys-
tem’s speech more natural and understandable over-
all. In our system, this process is carried out not
at the level of content planning, but at the lower-
level of processing, where content logical forms are
manipulated (possibly combined) and converted into
strings for speech synthesis. Indeed, it is impor-
tant that aggregation functions at this lower level,
because the process needs access to:
the message to be uttered (A),
what has just been said (B),
what is to be said next (C),
and the precise surface form of B is only represented
at the low-level. High-level processing only plans
the content of the utterance to be generated, and
passes it down, and so cannot determine the details
of the eventual surface form of the generated utter-
ance.
Aggregation techniques on a prewritten body of
text combine and compress sentences that have al-
ready been determined and ordered. In a complex
dialogue system however, aggregation should pro-
duce similarly natural output, but must function in-
crementally because utterances are generated on the
fly. In fact, when constructing an utterance we often
have no information about the utterances that will
follow it, and thus the best we can do is to com-
press it or “retro-aggregate” it with utterances that
preceded it (see the example below). Only occasion-
ally does the Output Agenda contain enough unsaid
utterances to perform reasonable “pre-aggregation”.
At the low-level of processing, the generator re-
ceives an item (on the Output Agenda) to be con-
verted into synthesized speech. This item consists
of a dialogue move type along with some content
(e.g. wh-answer, location(tower)).
Each dialogue move type (e.g. report, wh-
question, wh-answer) has its own aggregation rules,
stored in the class for that logical form (LF) type. In
each type, rules specify which other dialogue move
types can aggregate with it, and exactly how ag-
gregation works. The rules note identical portions
of LFs and unify them, and then combine the non-
identical portions appropriately.
For example, the LF that represents the phrase “I
will fly to the tower and I will land at the parking
lot”, will be converted to one representing “I will fly
to the tower and land at the parking lot” according
to the compression rules. Similarly, “I will fly to the
tower and fly to the hospital” gets converted to “I
will fly to the tower and the hospital”.
In contrast, the “retro-aggregation” rules result in
sequences of system utterances such as,
Sys: I have cancelled flying to the base
Sys: and the tower
Sys: and landing at the school
Again, this process happens only at the low-level
processing stage of content realization, and needs
no access to the high-level representations of di-
alogue structure, history, and plans. A separate
thread running in the Output Agenda component
asynchronously performs aggregation as needed and
appropriate.
</bodyText>
<subsectionHeader confidence="0.966819">
5.4 Case study 4: Choosing NPs
</subsectionHeader>
<bodyText confidence="0.999898333333333">
Another low-level process in utterance realization is
choosing appropriate NPs – anaphoric expressions
such as “it” or “there”, or NPs which “echo” those
already used by the human operator. Again, this rou-
tine does not need access to the high-level dialogue
management representations, but only to the list of
NPs employed in the dialogue thus far (the Salience
List).
Echoing is achieved by accessing the Salience
List whenever generating referential terms, and us-
ing whatever noun-phrase (if any) the user has pre-
viously employed to refer to the object in question.
Anaphoric phrases are generated whenever the ref-
erence object is the same as the one at the top of the
Salience List.
As in the case of aggregation, the top level content
generation algorithm does not manage the details of
utterance realization – this is better handled at the
instant that the content logical form is to be trans-
lated into a string for the speech synthesizer. Other-
wise the top level would have to replan utterances af-
ter every intervening dialogue move. This example
shows how respecting the multi-level architecture is
desirable from an engineering point of view.
</bodyText>
<sectionHeader confidence="0.882211" genericHeader="method">
6 Current Implementation and Further
Possibilities
</sectionHeader>
<bodyText confidence="0.999962902439024">
An initial version of the CSLI dialogue system based
on the described architecture has been implemented,
and is able to engage in conversations such as illus-
trated in Figure 3.
The system has been applied to both command-
and-control and tutorial applications; this is of inter-
est since the former generally involves user-initiated
conversations while in the latter, conversation tends
to be system-initiated. The Output Agenda me-
diates by handling both standard logical forms or
generation-templates.
Only a small number of the interaction-level phe-
nomena that arise in human-human dialogue have
been implemented, but we believe a number of them
could be treated within our framework. For in-
stance, processes at the lower level could detect mis-
communication and channel breakdown, and send a
request to the top level to replan the long-range dia-
logue strategy. This is particularly relevant in the tu-
torial setting, where low-level processes could detect
problems with user attention and responsiveness,
and prompt a switch to a different high-level strat-
egy. Particularly important for safety-critical appli-
cations, but of general use, would be low-level moni-
toring of channel noise and other environmental fac-
tors such as user gestures and gaze. Again, certain
combinations of these inputs would have high-level
consequences for interpretation and dialogue plan-
ning.
Recent work makes use of Icarus (Shapiro, 2001),
a reactive planning system that learns and adapts to
user behavior, to cover timing and realization of sys-
tem turns as well as handling delays in the user in-
put. In future, we anticipate that this will allow,
for instance, turn-taking facilities to be more eas-
ily adapted as personalities or situations require: for
example, after noticing a particular event the system
may be more likely to interrupt a speaker, or may
adapt to become less prone to interruption when in-
teracting with a speaker who responds poorly to sys-
tem barge-in.
</bodyText>
<sectionHeader confidence="0.998328" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9978475">
We have presented evidence from the psycholinguis-
tic literature that demonstrates the importance of
</bodyText>
<figureCaption confidence="0.989015">
Figure 3: Demonstration system, November 2002
</figureCaption>
<table confidence="0.72268196">
Utterance Dialogue Move
Operator (O): Fly around the school Command
Helper (H): I heard you say “Fly around the school” but the Helper feedback
system does not know the word “around”. You could say “fly
to the school”
O: Fly to the school Command
Robot (R): OK. Confirmation
O: Then pick up the medical supplies at the hospital Take turn, Command
R: OK. Wait a minute Confirmation, System grab turn
R: I am supposed to always fly high Report Global Constraint
R: Shall I fly to the hospital at low altitude anyway? Negotiate constraint relaxation, Re-
lease Turn
O: Yes. Do it anyway Yn-Answer
R: OK. Wait a minute Confirmation, System grab turn
R: There is afire at the tower Report observation
R: I am flying to the hospital Report Current Activity
O: Why? Why-question, Release Turn
R: Because I am picking up the medical sup Why-Answer, User barge-in
O: Stop that. Command (Barge-in)
R: OK. I have cancelled flying there Confirmation, Report Activity State,
Anaphoric NP
O: Fight the fire at the tower Command
R: OK. I am flying to the lake Confirmation, Report Activity State
O: Why are you doing that? Why-question, Release Turn
R: Because I am picking up water there. Why-Answer, Anaphoric NP
</table>
<bodyText confidence="0.999678434782609">
interaction-level phenomena in dialogue. Phenom-
ena such as fillers, timing, and feedback must be
dealt with properly and in a timely manner; other-
wise, the interaction and even the collaborative ac-
tivity being performed may be adversely affected.
Our approach is to cleanly separate the architec-
ture of dialogue systems to provide for an asyn-
chronous layer that is designed to handle interaction
signals, analogously to agent/robot architectures that
include a layer to manage interaction with a dynamic
environment. This allows processing outside the full
context of a dialogue history when required for pro-
cessing speed, while allowing the context to still in-
fluence such processes when able.
A system has been implemented based on this
architecture, containing a range of low-level pro-
cesses, which we have described here in some detail:
shallow-helper feedback; turn-management; aggre-
gation; NP selection. Current work is directed to-
wards incorporating techniques to manage further
phenomena—such as predictors of uncertainty and
loss of attention—in both command-and-control and
tutoring applications.
</bodyText>
<sectionHeader confidence="0.996548" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999940666666667">
This research was partially supported by the Wallen-
berg Foundation’s WITAS project, Link¨oping Uni-
versity, Sweden, and by grant number N00014-02-
1-0417 from the Department of the US Navy. The
dialogue system was implemented while the first au-
thor was employed at CSLI, Stanford University.
</bodyText>
<sectionHeader confidence="0.999265" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999940024096386">
James F. Allen, Bradford W. Miller, Eric K. Ringger, and
Teresa Sikorski. 1996. A robust system for natural
spoken dialogue. In Proceedings ofACL.
James Allen, George Ferguson, and Amanda Stent. 2001.
An architecture for more realistic conversational sys-
tems. In Proceedings of Intelligent User Interfaces
2001, Santa Fe, NM.
Jens Allwood. 1995. An activity based approach to prag-
matics. In Gothenburg Papers in Theoretical Linguis-
tics 76, Dept. of Linguistics, Uni. of G¨oteborg.
Douglas E. Appelt. 1985. Planning english referring ex-
pressions. Artificial Intelligence, 26(1):1 – 33.
J. B. Bavelas, L. Coates, and T. Johnson. 2000. Listeners
and co-narrators. Journal of Personality and Social
Psychology, 79:941–952.
Lauri Carlson. 1983. Dialogue Games: An Approach to
Discourse Analysis. D. Reidel.
Herbert H. Clark and Jean E. Fox Tree. 2002. Using uh
and um in spontaneous speaking. Cognition, 84:73–
111.
Brady Clark, John Fry, Matt Ginzton, Stanley Pe-
ters, Heather Pon-Barry, and Zachary Thomsen-Gray.
2001. Automated tutoring dialogues for training in
shipboard damage control. In Proceedings of SIGdial
2001.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
George Ferguson and James Allen. 1998. TRIPS: An in-
telligent integrated problem-solving assistant. In Pro-
ceedings 15th National Conference on Artificial Intel-
ligence (AAAI-98), pages 567–573, Madison, WI.
James Firby. 1994. Task networks for controlling con-
tinuous processes. In Proceedings 2nd Int’l Conf. on
AI Planning Systems, pages 49–54.
A. C. Graesser, N. K. Person, and J. P. Magliano. 1995.
Collaborative dialogue patterns in naturalistic one-to-
one tutoring. Applied Cognitive Psychology, 9:1–28.
Barbara Grosz and Candace Sidner. 1986. Attentions,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175–204.
Alexander H. Gruenstein. 2002. Conversational inter-
faces: A domain-independent architecture for task-
oriented dialogues. Masters thesis, Computer Science
Department, Stanford University.
Beth-Ann Hockey, Oliver Lemon, Ellen Campana, Laura
Hiatt, Gregory Aist, Jim Hieronymus, Alexander Gru-
enstein, and John Dowding. 2003. Targeted help for
spoken dialogue systems: intelligent feed back im-
proves naive users’ performance. In Proceedings Eu-
ropean Assoc. for Computational Linguistics (EACL
03).
Oliver Lemon, Alexander Gruenstein, Alexis Battle, and
Stanley Peters. 2002a. Multi-tasking and collabo-
rative activities in dialogue systems. In Proceedings
of 3rd SIGdial Workshop on Discourse and Dialogue,
pages 113 – 124, Philadelphia.
Oliver Lemon, Alexander Gruenstein, and Stanley Pe-
ters. 2002b. Collaborative activities and multi-tasking
in dialogue systems. Traitement Automatique des
Langues (TAL), 43(2):131 – 154. Special Issue on Di-
alogue.
Jorge P. M¨uller. 1996. The Design of IntelligentAgents—
A Layered Approach. Springer Verlag, Heidelberg,
Germany.
Martin Pickering and Simon Garrod. 2003. Toward a
mechanistic psychology of dialogue. Brain and Be-
havioral Science. to appear.
Richard Power. 1979. The organization of purposeful
dialogues. Linguistics, 17:107–152.
Daniel Shapiro. 2001. Value-driven agents. Ph.D. thesis,
Department of Management Science and Engineering,
Stanford University.
Jan van Kuppevelt, Ulrich Heid, and Hans Kamp. 2000.
Best practice in spoken language dialogue system en-
gineering. Natural Language Engineering, 6.
Wolfgang Wahlster. 2002. SmartKom: fusion and fission
of speech, gestures, and facial expressions. In Pro-
ceedings of the 1st International Workshop on Man-
Machine Symbiotic Systems, pages 213–225, Kyoto,
Japan.
N. Ward and W. Tsukahara. 1999. A responsive dialog
system. In Y. Wilks, editor, Machine Conversations,
pages 169–174. Kluwer.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.382637">
<title confidence="0.999799">Managing Dialogue Interaction: A Multi-Layered Approach</title>
<author confidence="0.985318">Oliver</author>
<affiliation confidence="0.986767">School of University of 2 Buccleugh</affiliation>
<address confidence="0.851713">Edinburgh EH8 9LW,</address>
<email confidence="0.997132">olemon@inf.ed.ac.uk</email>
<affiliation confidence="0.83146">Lawrence</affiliation>
<address confidence="0.900997333333333">Stanford 220 Panama Stanford, CA 94306,</address>
<email confidence="0.998621">lcavedon@csli.stanford.edu</email>
<author confidence="0.98058">Barbara</author>
<affiliation confidence="0.997307">Department of</affiliation>
<address confidence="0.983557">Santa CA 93106-3100,</address>
<email confidence="0.99859">bfk0@umail.ucsb.edu</email>
<keyword confidence="0.9301895">Keywords: dialogue management architecture, interaction, communication channel management</keyword>
<abstract confidence="0.9993465">We present evidence for the importance of low-level phenomena in dialogue interaction and use this to motivate a multi-layered approach to dialogue processing. We describe an architecture that separates content-level communicative processes from interaction-level phenomena (such as feedback, grounding, turn-management), and provide details of specific implementations of a number of such phenomena.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Bradford W Miller</author>
<author>Eric K Ringger</author>
<author>Teresa Sikorski</author>
</authors>
<title>A robust system for natural spoken dialogue.</title>
<date>1996</date>
<booktitle>In Proceedings ofACL.</booktitle>
<marker>Allen, Miller, Ringger, Sikorski, 1996</marker>
<rawString>James F. Allen, Bradford W. Miller, Eric K. Ringger, and Teresa Sikorski. 1996. A robust system for natural spoken dialogue. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>George Ferguson</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for more realistic conversational systems.</title>
<date>2001</date>
<booktitle>In Proceedings of Intelligent User Interfaces</booktitle>
<location>Santa Fe, NM.</location>
<contexts>
<context position="1644" citStr="Allen et al., 2001" startWordPosition="227" endWordPosition="230">te directly to the interactive process between the participants. This includes turn management, providing feedback, utterance fillers, error and false-start management, and utterance timing. Recent work on dialogue and natural language processing in general has acknowledged the presence of such phenomena in natural speech, and in some cases the importance of its role in dialogue interaction. However, treatment of such phenomena has generally been part of the standard processing model; for example, some parsers are able to handle fillers such as “um”, while recent versions of the TRIPS system (Allen et al., 2001) uses incremental parsing and other techniques to handle a range of related phenomena. We believe that greater focus on “interaction level” phenomena is appropriate and will lead to benefits in building dialogue systems for more robust natural interaction. In this paper, we outline a two-layer architecture for dialogue systems, where one layer uses a range of “shallow” processing techniques to maintain a smooth interaction between the dialogue participants. 1.1 Managing interaction The inspiration for a clean separation into a twolayer architecture comes from two sources. Clark (1996) distingu</context>
<context position="4545" citStr="Allen et al. (2001)" startWordPosition="672" endWordPosition="675">nvolved in activity-oriented dialogue, timeliness is particularly important in order to keep the user engaged and focussed—otherwise, performance of the joint activity may be adversely affected. In particular, dialogic interaction is a continuous process which cannot be broken without the risk of some breakdown: signal-level phenomena must be handled as smoothly as possible, without necessarily resorting to content-level processes, in order to maintain a tight interaction between the participants. 1.2 A multi-layered architecture Motivated partially by some of the same issues we discuss here, Allen et al. (2001) describe a new architecture for their TRIPS system that breaks dialogue management into multiple asynchronous components. We concur with their concerns but focus on a different architectural shift. We outline below an architecture that separates interaction-focussed techniques from contextmanagement and conversation planning. An initial version of the architecture has been implemented at the Center for the Study of Language and Information (CSLI) at Stanford University. This breakdown into separate architectural levels is analogous to the multi-level agent/robot architectures. However, many o</context>
</contexts>
<marker>Allen, Ferguson, Stent, 2001</marker>
<rawString>James Allen, George Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational systems. In Proceedings of Intelligent User Interfaces 2001, Santa Fe, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Allwood</author>
</authors>
<title>An activity based approach to pragmatics.</title>
<date>1995</date>
<booktitle>In Gothenburg Papers in Theoretical Linguistics 76,</booktitle>
<institution>Dept. of Linguistics, Uni. of G¨oteborg.</institution>
<contexts>
<context position="11630" citStr="Allwood (1995)" startWordPosition="1739" endWordPosition="1740">istening to the conversation partner and without being responsible for taking up a speaking turn. These results indicate that the nature of interaction between participants is crucial to the collaborative act of dialogue—signals and feedback that carry effectively no communicative content are still important for keeping the interaction smooth and to ensure that the participants stay attentive and focussed on the task at hand. When the dialogue task involves, say, a human user being guided through a safetycritical activity by an automated system, then such issues are of particular importance. 3Allwood (1995) refers to such feedback morphemes as the most important cohesion device in spoken language. Problem-Solving Manager Discourse context Speech Output Speech Recog Speech Input NL Parser Dialogue Manager Speech Synth Generation Figure 1: Traditional Dialogue System Architecture Conversely, communicative behavior contains signals regarding a participant’s attention, and in particular may indicate a loss of focus. In tutorial settings—one of the dialogue applications we are specifically concerned with—this can be used to determine students’ confidence in their responses. For example, phenomena suc</context>
</contexts>
<marker>Allwood, 1995</marker>
<rawString>Jens Allwood. 1995. An activity based approach to pragmatics. In Gothenburg Papers in Theoretical Linguistics 76, Dept. of Linguistics, Uni. of G¨oteborg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning english referring expressions.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="25002" citStr="Appelt, 1985" startWordPosition="3852" endWordPosition="3853">t speaking, the system will output “Just a moment” and so take the turn before generating its required utterance. Again, note that this turn-grabbing utterance is not planned or represented at the top-level of dialogue moves. It does not need to enter into such high-level plans or representations because it is required only in order to manipulate and maintain the channel, and does not carry any content of its own. The demonstration system displays a turn marker on the GUI, allowing observers to monitor the changing possession of the turn. 5.3 Case study 3: Incremental aggregation Aggregation (Appelt, 1985) combines and compresses utterances to make them more concise, avoid repetitious language structure, and make the system’s speech more natural and understandable overall. In our system, this process is carried out not at the level of content planning, but at the lowerlevel of processing, where content logical forms are manipulated (possibly combined) and converted into strings for speech synthesis. Indeed, it is important that aggregation functions at this lower level, because the process needs access to: the message to be uttered (A), what has just been said (B), what is to be said next (C), </context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning english referring expressions. Artificial Intelligence, 26(1):1 – 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Bavelas</author>
<author>L Coates</author>
<author>T Johnson</author>
</authors>
<title>Listeners and co-narrators.</title>
<date>2000</date>
<journal>Journal of Personality and Social Psychology,</journal>
<pages>79--941</pages>
<contexts>
<context position="10418" citStr="Bavelas et al. (2000)" startWordPosition="1548" endWordPosition="1551"> the speaker that they are listening and paying attention. For English, back-channels include uh-huh, mhm and yeah. Back-channels differ from other devices used to keep a conversation flowing, such as repetitions and collaborative finishes, in that they tend to be nonspecific to the current utterance. Moreover, backchannel feedback is often produced without thinking, in response to simple prosodic clues such as a speaker pause, a lowering of speaker pitch, or a rise in speaker intonation (Ward and Tsukahara, 1999). Most importantly, however, back-channel feedback is important to the speaker.3 Bavelas et al. (2000) investigated how a speaker in a conversation (in this case someone narrating a story) is affected when listener responses are inhibited. They found that speakers with distracted and unresponsive listeners did not finish their stories effectively, measurably faltering at what should have been the dramatic ending. Speakers needed an interlocutor’s feedback to be able to maintain fluency and continue the dialogue effectively. Bavelas et al also found that response latency in one-on-one conversations is extremely short and may be simultaneous: listeners can provide back-channels without fully lis</context>
</contexts>
<marker>Bavelas, Coates, Johnson, 2000</marker>
<rawString>J. B. Bavelas, L. Coates, and T. Johnson. 2000. Listeners and co-narrators. Journal of Personality and Social Psychology, 79:941–952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Carlson</author>
</authors>
<title>Dialogue Games: An Approach to Discourse Analysis.</title>
<date>1983</date>
<journal>D. Reidel.</journal>
<contexts>
<context position="19009" citStr="Carlson, 1983" startWordPosition="2854" endWordPosition="2855">ing strategies to be developed independently, and various combinations to be experimented with. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed so far at each of the two levels described here to enhance user experience and improve overall system performance. The current implementation based on the above architecture is still being refined; we focus on the features that have already been implemented. 4 Top-Level Context Management The approach to dialogue modeling we have implemented is based on the theory of dialogue games (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, discourse segments (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of adjacency pairs of such dialogue moves. The notion of “attachment” of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. An Activity Tree represents hierarchical and temporal information about the task-state of the dialogue. Activities are the joint tasks managed by the dialogue: </context>
</contexts>
<marker>Carlson, 1983</marker>
<rawString>Lauri Carlson. 1983. Dialogue Games: An Approach to Discourse Analysis. D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Jean E Fox Tree</author>
</authors>
<title>Using uh and um in spontaneous speaking.</title>
<date>2002</date>
<journal>Cognition,</journal>
<volume>84</volume>
<pages>111</pages>
<marker>Clark, Tree, 2002</marker>
<rawString>Herbert H. Clark and Jean E. Fox Tree. 2002. Using uh and um in spontaneous speaking. Cognition, 84:73– 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brady Clark</author>
<author>John Fry</author>
<author>Matt Ginzton</author>
<author>Stanley Peters</author>
<author>Heather Pon-Barry</author>
<author>Zachary Thomsen-Gray</author>
</authors>
<title>Automated tutoring dialogues for training in shipboard damage control.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGdial</booktitle>
<contexts>
<context position="21445" citStr="Clark et al., 2001" startWordPosition="3247" endWordPosition="3250">e.g. the user asked a question), or if a problem is detected (e.g. an ambiguity must be resolved). Since system communication is planned here, this layer is also the one that interacts with the rest of the agent architecture: any goals, state-changes, or observations that the agent may wish to communicate are added as communicative goals, typically via the Activity Model. For command-and-control applications (e.g. guiding a robot or UAV), system-initiated utterances tend to be fairly short and simple and conversation-planning is minimal; however, for our dialogue-enabled tutorial application (Clark et al., 2001), conversation-planning is quite complex and the system may generate multiple, relatively long utterances on its own initiative. 5 Low-level Conversation Management: Maintaining the Communication Channel We currently employ a range of shallow processing techniques to maintain a smooth interaction with the human dialogue participant. By “shallow processing” we mean processing that does not necessarily result in or concern itself with the semantic representation or pragmatic interpretation of the utterance in the context of the dialogue. In particular, information at this level is not processed </context>
</contexts>
<marker>Clark, Fry, Ginzton, Peters, Pon-Barry, Thomsen-Gray, 2001</marker>
<rawString>Brady Clark, John Fry, Matt Ginzton, Stanley Peters, Heather Pon-Barry, and Zachary Thomsen-Gray. 2001. Automated tutoring dialogues for training in shipboard damage control. In Proceedings of SIGdial 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2235" citStr="Clark (1996)" startWordPosition="320" endWordPosition="321"> (Allen et al., 2001) uses incremental parsing and other techniques to handle a range of related phenomena. We believe that greater focus on “interaction level” phenomena is appropriate and will lead to benefits in building dialogue systems for more robust natural interaction. In this paper, we outline a two-layer architecture for dialogue systems, where one layer uses a range of “shallow” processing techniques to maintain a smooth interaction between the dialogue participants. 1.1 Managing interaction The inspiration for a clean separation into a twolayer architecture comes from two sources. Clark (1996) distinguishes between two separate communication tracks, which he calls communicative and meta-communicative. These are simultaneously occurring communications, the first dealing with the information at hand, and the other relating to the performance itself. Dialogue participants use what Clark refers to as signals to refer to the performance itself: e.g. timing, delays, re-phrasing, mistakes, repairs, etc.1 A second motivation is work on architectures for robots and autonomous agents embedded in complex, dynamic, unpredictable environments. Several researchers in this area have argued for mu</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James Allen</author>
</authors>
<title>TRIPS: An intelligent integrated problem-solving assistant.</title>
<date>1998</date>
<booktitle>In Proceedings 15th National Conference on Artificial Intelligence (AAAI-98),</booktitle>
<pages>567--573</pages>
<location>Madison, WI.</location>
<contexts>
<context position="8274" citStr="Ferguson and Allen, 1998" startWordPosition="1216" endWordPosition="1220">ous processes for channel-management. In Sections 4 and 5, we describe specifics of the CSLI implementation, outlining first the more abstract dialogue management layer, followed by techniques employed at the interaction layer. In Section 6, we discuss further possibilities and in Section 7 we conclude. 2 The Importance of Channel Phenomena The standard processing model for dialogue systems involves a sequence of modules from speech recognition to speech synthesis, as illustrated in Figure 1, which essentially illustrates (a simplification of) the original TRIPS architecture, as described in (Ferguson and Allen, 1998). Typically, each module is selfcontained and relatively independent of other modules. Recent findings in the psycholinguistic literature have suggested various shortcomings of this modular approach. For example, work on alignment indicates that conversation participants’ processing interacts on multiple levels, contravening the strict modular model (Pickering and Garrod, 2003). This is one of the considerations we address below, but we are primarily concerned with other interactionlevel phenomena. One of our prime motivations for an interaction level processing layer is to ensure timely respo</context>
</contexts>
<marker>Ferguson, Allen, 1998</marker>
<rawString>George Ferguson and James Allen. 1998. TRIPS: An intelligent integrated problem-solving assistant. In Proceedings 15th National Conference on Artificial Intelligence (AAAI-98), pages 567–573, Madison, WI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Firby</author>
</authors>
<title>Task networks for controlling continuous processes.</title>
<date>1994</date>
<booktitle>In Proceedings 2nd Int’l Conf. on AI Planning Systems,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="3175" citStr="Firby, 1994" startWordPosition="460" endWordPosition="461"> the performance itself: e.g. timing, delays, re-phrasing, mistakes, repairs, etc.1 A second motivation is work on architectures for robots and autonomous agents embedded in complex, dynamic, unpredictable environments. Several researchers in this area have argued for multilayered architectures for agents that plan action sequences to achieve some goal or task, but need to react quickly to change in the environment (e.g. &apos;Clark’s distinction does not necessarily carry over directly to the design of a dialogue system architecture, but it motivates focus on the low-level communication channel. (Firby, 1994; M¨uller, 1996)). In such architectures, the role of the bottom layer is to monitor the environment and initiate appropriate actions within the broader context of the goal-directed plan, which is provided by the higher layer of the architecture. The layers operate independently and asynchronously, but communicate as necessary: e.g. goals and plans are passed down to the execution layer, while observations or problems (which may trigger replanning) are passed up to the planning layer. We view the process of natural interaction with a dialogue participant as analogous to the interaction with a </context>
</contexts>
<marker>Firby, 1994</marker>
<rawString>James Firby. 1994. Task networks for controlling continuous processes. In Proceedings 2nd Int’l Conf. on AI Planning Systems, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Graesser</author>
<author>N K Person</author>
<author>J P Magliano</author>
</authors>
<title>Collaborative dialogue patterns in naturalistic one-toone tutoring. Applied Cognitive Psychology,</title>
<date>1995</date>
<pages>9--1</pages>
<contexts>
<context position="12379" citStr="Graesser et al., 1995" startWordPosition="1844" endWordPosition="1847">context Speech Output Speech Recog Speech Input NL Parser Dialogue Manager Speech Synth Generation Figure 1: Traditional Dialogue System Architecture Conversely, communicative behavior contains signals regarding a participant’s attention, and in particular may indicate a loss of focus. In tutorial settings—one of the dialogue applications we are specifically concerned with—this can be used to determine students’ confidence in their responses. For example, phenomena such as timing between responses, hesitance markers, and intonation can all be implicit clues that a student is having a problem (Graesser et al., 1995). 3 A Two-Level Architecture The traditional architecture for dialogue systems basically involves a linear approach to processing, as illustrated in Figure 1. In this standard architecture, modules tend to be self-contained and only loosely dependent. Evidence outlined above, particularly that related to alignment, suggests that this tightly encapsulated approach will deal poorly with the interactive nature of real dialogue. Allen et al’s (2001) revised TRIPS architecture introduces a more nonlinear approach to dialogue processing, with asynchronous processes managing interpretation, generatio</context>
</contexts>
<marker>Graesser, Person, Magliano, 1995</marker>
<rawString>A. C. Graesser, N. K. Person, and J. P. Magliano. 1995. Collaborative dialogue patterns in naturalistic one-toone tutoring. Applied Cognitive Psychology, 9:1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<title>Attentions, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="19102" citStr="Grosz and Sidner, 1986" startWordPosition="2864" endWordPosition="2867">mented with. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed so far at each of the two levels described here to enhance user experience and improve overall system performance. The current implementation based on the above architecture is still being refined; we focus on the features that have already been implemented. 4 Top-Level Context Management The approach to dialogue modeling we have implemented is based on the theory of dialogue games (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, discourse segments (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of adjacency pairs of such dialogue moves. The notion of “attachment” of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. An Activity Tree represents hierarchical and temporal information about the task-state of the dialogue. Activities are the joint tasks managed by the dialogue: e.g. booking a flight or moving a robot— again, see (Lemon et al., 2002b) for details. Nodes </context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner. 1986. Attentions, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander H Gruenstein</author>
</authors>
<title>Conversational interfaces: A domain-independent architecture for taskoriented dialogues.</title>
<date>2002</date>
<tech>Masters thesis,</tech>
<institution>Computer Science Department, Stanford University.</institution>
<contexts>
<context position="15680" citStr="Gruenstein, 2002" startWordPosition="2331" endWordPosition="2332">allow Processor (Helper) Context Mgr Speech channel Speech recogition and Parsing Dialogue Move Tree ack Turn Mgr Conversation Planner TTS Output Agenda Activity Model Generation Module Agent - intentions - goals - plans - observations Generation: - anaphora - pronouns - aggregation - echoing goals and intentions, whether they be imparting information to the user or requesting clarification or further information. The higher level also interacts with the rest of the agent architecture, mediated by an Activity Model (i.e. a representation of the agent activities about which dialogue may occur (Gruenstein, 2002)). The agent may wish to communicate its own goals, the progress of its activities, or report on any observations it makes regarding its environment. As with multi-layered agent architectures, the two levels operate semi-autonomously and asynchronously: the lower level is driven by tight interaction with the user, while the upper level is driven by longer-range communicative goals from its activities and responses to user utterances. However, various types of information exchange connect the two levels. For instance, user utterances recognized at the lower level must clearly be passed to the c</context>
</contexts>
<marker>Gruenstein, 2002</marker>
<rawString>Alexander H. Gruenstein. 2002. Conversational interfaces: A domain-independent architecture for taskoriented dialogues. Masters thesis, Computer Science Department, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth-Ann Hockey</author>
<author>Oliver Lemon</author>
<author>Ellen Campana</author>
<author>Laura Hiatt</author>
<author>Gregory Aist</author>
<author>Jim Hieronymus</author>
<author>Alexander Gruenstein</author>
<author>John Dowding</author>
</authors>
<title>Targeted help for spoken dialogue systems: intelligent feed back improves naive users’ performance.</title>
<date>2003</date>
<booktitle>In Proceedings European Assoc. for Computational Linguistics (EACL 03).</booktitle>
<contexts>
<context position="6219" citStr="Hockey et al., 2003" startWordPosition="911" endWordPosition="914">certain dialogue interaction phenomena are best handled. Much like these systems, dialogue communicative goals are produced at the higher level and imposed as constraints on the lower-level. Environment-level processes fill in the detail of these goals and handle contingencies which may otherwise prevent the achievement of these goals. A number of interaction-management techniques are present in the current implementation, including: A back-up recognition pass, using statistical processing to extend grammar-based coverage and provide immediate user “help” feedback for unrecognized utterances (Hockey et al., 2003); Turn management—timing of system output is governed by monitoring the speech channel and the (prioritized) agenda of speech outputs. If the system need to take the turn, it grabs it using only low-level processing; Handling user barge-in—user speech interrupts system output and automatically grabs the turn; Immediate Grounding of recognized commands (e.g. system says “OK” immediately after recognizing the user: “fly to the tower”); NP selection — choosing anaphoric or salient noun-phrases at the point of generation; Incremental aggregation of system-generated utterances — appropriately conde</context>
<context position="23921" citStr="Hockey et al., 2003" startWordPosition="3658" endWordPosition="3661">t “helper” agent, which disappears (from the GUI) as soon as the help message is produced, thus discouraging the user from engaging it in dialogue. User tests have shown that the use of this low level module (which can be installed independently of the high-level dialogue manager) significantly improves task completion (both percentage of tasks completed and time taken). By the fifth task, 100% of users with the helper completed the task as compared with 80% of those without, and those without the helper took on average 53% longer to complete the tasks. For full details of the evaluation see (Hockey et al., 2003). 5.2 Case study 2: Turn Taking Here we use a turn-marker at the low-level of dialogue processing. The turn can be marked as user, system or none, and is set in a variety of ways. If the user begins to speak (start-of-speech signal is received from the recognizer) the turn becomes user and any system audio output is stopped. If the system needs to take the turn (e.g. if it has urgent information it needs to communicate), but turn is set to user, and the user is not speaking, the system will output “Just a moment” and so take the turn before generating its required utterance. Again, note that t</context>
</contexts>
<marker>Hockey, Lemon, Campana, Hiatt, Aist, Hieronymus, Gruenstein, Dowding, 2003</marker>
<rawString>Beth-Ann Hockey, Oliver Lemon, Ellen Campana, Laura Hiatt, Gregory Aist, Jim Hieronymus, Alexander Gruenstein, and John Dowding. 2003. Targeted help for spoken dialogue systems: intelligent feed back improves naive users’ performance. In Proceedings European Assoc. for Computational Linguistics (EACL 03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alexander Gruenstein</author>
<author>Alexis Battle</author>
<author>Stanley Peters</author>
</authors>
<title>Multi-tasking and collaborative activities in dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>113--124</pages>
<location>Philadelphia.</location>
<contexts>
<context position="14722" citStr="Lemon et al., 2002" startWordPosition="2188" endWordPosition="2191">uts are respected without interruption (except when necessary); turn passes to the appropriate participant, based on the highest priority Agenda item and the dialogue move that generated it; generated outputs are natural and timely; recognized user inputs are acknowledged quickly using simple feedback utterances. The upper level is responsible for modeling other aspects of the conversational context, as well as communicative goals and intentions. The content (i.e. logical forms) of user utterances are processed using the dialogue model (e.g. updates and adding nodes to the Dialogue Move Tree (Lemon et al., 2002b)), and system utterances are constructed which are in line with the system’s communicative Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Interaction layer - timing - form - engagement - acknowledgement Attention Monitor Backup Shallow Processor (Helper) Context Mgr Speech channel Speech recogition and Parsing Dialogue Move Tree ack Turn Mgr Conversation Planner TTS Output Agenda Activity Model Generation Module Agent - intentions - goals - plans - observations Generation: - anaphora </context>
<context position="19426" citStr="Lemon et al., 2002" startWordPosition="2916" endWordPosition="2919">we focus on the features that have already been implemented. 4 Top-Level Context Management The approach to dialogue modeling we have implemented is based on the theory of dialogue games (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, discourse segments (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of adjacency pairs of such dialogue moves. The notion of “attachment” of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. An Activity Tree represents hierarchical and temporal information about the task-state of the dialogue. Activities are the joint tasks managed by the dialogue: e.g. booking a flight or moving a robot— again, see (Lemon et al., 2002b) for details. Nodes on the Activity Tree can be in various states (active, complete, failed, ), and any change in the state of a node (typically because of an action by the agent) is placed onto the system’s Output Agenda for potential verbal report to the user, via the low-level message selection and generation module. This level of the arch</context>
</contexts>
<marker>Lemon, Gruenstein, Battle, Peters, 2002</marker>
<rawString>Oliver Lemon, Alexander Gruenstein, Alexis Battle, and Stanley Peters. 2002a. Multi-tasking and collaborative activities in dialogue systems. In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue, pages 113 – 124, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alexander Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Collaborative activities and multi-tasking in dialogue systems.</title>
<date>2002</date>
<booktitle>Traitement Automatique des Langues (TAL), 43(2):131 – 154. Special Issue on Dialogue.</booktitle>
<contexts>
<context position="14722" citStr="Lemon et al., 2002" startWordPosition="2188" endWordPosition="2191">uts are respected without interruption (except when necessary); turn passes to the appropriate participant, based on the highest priority Agenda item and the dialogue move that generated it; generated outputs are natural and timely; recognized user inputs are acknowledged quickly using simple feedback utterances. The upper level is responsible for modeling other aspects of the conversational context, as well as communicative goals and intentions. The content (i.e. logical forms) of user utterances are processed using the dialogue model (e.g. updates and adding nodes to the Dialogue Move Tree (Lemon et al., 2002b)), and system utterances are constructed which are in line with the system’s communicative Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Interaction layer - timing - form - engagement - acknowledgement Attention Monitor Backup Shallow Processor (Helper) Context Mgr Speech channel Speech recogition and Parsing Dialogue Move Tree ack Turn Mgr Conversation Planner TTS Output Agenda Activity Model Generation Module Agent - intentions - goals - plans - observations Generation: - anaphora </context>
<context position="19426" citStr="Lemon et al., 2002" startWordPosition="2916" endWordPosition="2919">we focus on the features that have already been implemented. 4 Top-Level Context Management The approach to dialogue modeling we have implemented is based on the theory of dialogue games (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, discourse segments (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of adjacency pairs of such dialogue moves. The notion of “attachment” of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. An Activity Tree represents hierarchical and temporal information about the task-state of the dialogue. Activities are the joint tasks managed by the dialogue: e.g. booking a flight or moving a robot— again, see (Lemon et al., 2002b) for details. Nodes on the Activity Tree can be in various states (active, complete, failed, ), and any change in the state of a node (typically because of an action by the agent) is placed onto the system’s Output Agenda for potential verbal report to the user, via the low-level message selection and generation module. This level of the arch</context>
</contexts>
<marker>Lemon, Gruenstein, Peters, 2002</marker>
<rawString>Oliver Lemon, Alexander Gruenstein, and Stanley Peters. 2002b. Collaborative activities and multi-tasking in dialogue systems. Traitement Automatique des Langues (TAL), 43(2):131 – 154. Special Issue on Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge P M¨uller</author>
</authors>
<title>The Design of IntelligentAgents— A Layered Approach.</title>
<date>1996</date>
<publisher>Springer Verlag,</publisher>
<location>Heidelberg, Germany.</location>
<marker>M¨uller, 1996</marker>
<rawString>Jorge P. M¨uller. 1996. The Design of IntelligentAgents— A Layered Approach. Springer Verlag, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Pickering</author>
<author>Simon Garrod</author>
</authors>
<title>Toward a mechanistic psychology of dialogue.</title>
<date>2003</date>
<journal>Brain and Behavioral Science.</journal>
<note>to appear.</note>
<contexts>
<context position="8654" citStr="Pickering and Garrod, 2003" startWordPosition="1268" endWordPosition="1271">ialogue systems involves a sequence of modules from speech recognition to speech synthesis, as illustrated in Figure 1, which essentially illustrates (a simplification of) the original TRIPS architecture, as described in (Ferguson and Allen, 1998). Typically, each module is selfcontained and relatively independent of other modules. Recent findings in the psycholinguistic literature have suggested various shortcomings of this modular approach. For example, work on alignment indicates that conversation participants’ processing interacts on multiple levels, contravening the strict modular model (Pickering and Garrod, 2003). This is one of the considerations we address below, but we are primarily concerned with other interactionlevel phenomena. One of our prime motivations for an interaction level processing layer is to ensure timely response to interaction. Parsing and processing takes time— this can be alleviated by incremental parsing techniques, but meta-communication signals typically do not need to be interpreted and processed to the same extent as communicative utterances, and instead require immediate attention that precludes full processing. For example, researchers have looked at the use of um and uh i</context>
</contexts>
<marker>Pickering, Garrod, 2003</marker>
<rawString>Martin Pickering and Simon Garrod. 2003. Toward a mechanistic psychology of dialogue. Brain and Behavioral Science. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Power</author>
</authors>
<title>The organization of purposeful dialogues.</title>
<date>1979</date>
<journal>Linguistics,</journal>
<pages>17--107</pages>
<contexts>
<context position="19023" citStr="Power, 1979" startWordPosition="2856" endWordPosition="2857">to be developed independently, and various combinations to be experimented with. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed so far at each of the two levels described here to enhance user experience and improve overall system performance. The current implementation based on the above architecture is still being refined; we focus on the features that have already been implemented. 4 Top-Level Context Management The approach to dialogue modeling we have implemented is based on the theory of dialogue games (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, discourse segments (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of adjacency pairs of such dialogue moves. The notion of “attachment” of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. An Activity Tree represents hierarchical and temporal information about the task-state of the dialogue. Activities are the joint tasks managed by the dialogue: e.g. booking a</context>
</contexts>
<marker>Power, 1979</marker>
<rawString>Richard Power. 1979. The organization of purposeful dialogues. Linguistics, 17:107–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Shapiro</author>
</authors>
<title>Value-driven agents.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Management Science and Engineering, Stanford University.</institution>
<contexts>
<context position="30625" citStr="Shapiro, 2001" startWordPosition="4763" endWordPosition="4764"> the top level to replan the long-range dialogue strategy. This is particularly relevant in the tutorial setting, where low-level processes could detect problems with user attention and responsiveness, and prompt a switch to a different high-level strategy. Particularly important for safety-critical applications, but of general use, would be low-level monitoring of channel noise and other environmental factors such as user gestures and gaze. Again, certain combinations of these inputs would have high-level consequences for interpretation and dialogue planning. Recent work makes use of Icarus (Shapiro, 2001), a reactive planning system that learns and adapts to user behavior, to cover timing and realization of system turns as well as handling delays in the user input. In future, we anticipate that this will allow, for instance, turn-taking facilities to be more easily adapted as personalities or situations require: for example, after noticing a particular event the system may be more likely to interrupt a speaker, or may adapt to become less prone to interruption when interacting with a speaker who responds poorly to system barge-in. 7 Conclusion We have presented evidence from the psycholinguist</context>
</contexts>
<marker>Shapiro, 2001</marker>
<rawString>Daniel Shapiro. 2001. Value-driven agents. Ph.D. thesis, Department of Management Science and Engineering, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan van Kuppevelt</author>
<author>Ulrich Heid</author>
<author>Hans Kamp</author>
</authors>
<title>Best practice in spoken language dialogue system engineering.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<marker>van Kuppevelt, Heid, Kamp, 2000</marker>
<rawString>Jan van Kuppevelt, Ulrich Heid, and Hans Kamp. 2000. Best practice in spoken language dialogue system engineering. Natural Language Engineering, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>SmartKom: fusion and fission of speech, gestures, and facial expressions.</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st International Workshop on ManMachine Symbiotic Systems,</booktitle>
<pages>213--225</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="7243" citStr="Wahlster, 2002" startWordPosition="1065" endWordPosition="1066">e user: “fly to the tower”); NP selection — choosing anaphoric or salient noun-phrases at the point of generation; Incremental aggregation of system-generated utterances — appropriately condensing and forming elliptical system output at the point of generation. While this accounts for only a small number of signals that arise during natural dialogue, the architecture provides a framework for incorporating further techniques—in particular, using shallow 2Note: we are talking about very different parallel threads here than those which occur in multi-modal fusion, such as occurs in the SmartKom (Wahlster, 2002) system. processing—for making use of such signals to provide more natural and robust interactions between dialogue systems and human participants. In the next section, we describe work from the linguistic and psychology literature that demonstrates the importance of asynchronous interaction-level processing. In Section 3, we propose a specific architecture that provides a framework for integrating various processes for channel-management. In Sections 4 and 5, we describe specifics of the CSLI implementation, outlining first the more abstract dialogue management layer, followed by techniques e</context>
</contexts>
<marker>Wahlster, 2002</marker>
<rawString>Wolfgang Wahlster. 2002. SmartKom: fusion and fission of speech, gestures, and facial expressions. In Proceedings of the 1st International Workshop on ManMachine Symbiotic Systems, pages 213–225, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ward</author>
<author>W Tsukahara</author>
</authors>
<title>A responsive dialog system.</title>
<date>1999</date>
<booktitle>Machine Conversations,</booktitle>
<pages>169--174</pages>
<editor>In Y. Wilks, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="10316" citStr="Ward and Tsukahara, 1999" startWordPosition="1533" endWordPosition="1536"> ongoing interaction. Conversely, listeners also use what is known as back-channel feedback to indicate to the speaker that they are listening and paying attention. For English, back-channels include uh-huh, mhm and yeah. Back-channels differ from other devices used to keep a conversation flowing, such as repetitions and collaborative finishes, in that they tend to be nonspecific to the current utterance. Moreover, backchannel feedback is often produced without thinking, in response to simple prosodic clues such as a speaker pause, a lowering of speaker pitch, or a rise in speaker intonation (Ward and Tsukahara, 1999). Most importantly, however, back-channel feedback is important to the speaker.3 Bavelas et al. (2000) investigated how a speaker in a conversation (in this case someone narrating a story) is affected when listener responses are inhibited. They found that speakers with distracted and unresponsive listeners did not finish their stories effectively, measurably faltering at what should have been the dramatic ending. Speakers needed an interlocutor’s feedback to be able to maintain fluency and continue the dialogue effectively. Bavelas et al also found that response latency in one-on-one conversat</context>
</contexts>
<marker>Ward, Tsukahara, 1999</marker>
<rawString>N. Ward and W. Tsukahara. 1999. A responsive dialog system. In Y. Wilks, editor, Machine Conversations, pages 169–174. Kluwer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>