<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001268">
<title confidence="0.999139">
Incorporating Contextual Cues in Trainable Models
for Coreference Resolution
</title>
<author confidence="0.996296">
Ryu Iida, Kentaro Inui, Hiroya Takamura and Yuji Matsumoto
</author>
<affiliation confidence="0.9987015">
Graduate School of Information Science,
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.941547">
8916-5 Takayama, Ikoma, Nara, 630-0192, Japan
</address>
<email confidence="0.999005">
fryu-i,inui,hiroya-tmatsuf@is.aist-nara.acjp
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999943461538461">
We propose a method that incorporates
various novel contextual cues into a ma-
chine learning for resolving coreference.
Distinct characteristics of our model are
(i) incorporating more linguistic fea-
tures capturing contextual information
that is more sophisticated than what is
offered in Centering Theory, and (ii) a
tournament model for selecting a ref-
erent. Our experiments show that this
model significantly outperforms earlier
machine learning approaches, such as
Soon et al. (2001).
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997103125">
Computational approaches to coreference resolu-
tion have been roughly evolving in two differ-
ent but complementary directions. One is theory-
oriented rule-based approaches and the other is
empirical corpus-based approaches.
In rule-based approaches (Mitkov, 1997; Bald-
win, 1995; Nakaiwa and Shirai, 1996; Okumura
and Tamura, 1996), efforts have been directed to
manual encoding of various linguistic cues into a
set of rule . Such cues include, for example, the
syntactic role of each target noun phrase, the ap-
pearance order of antecedent candidates, and the
semantic compatibility between an anaphor and a
candidate. Most rule-based approaches are also
influenced, to a greater or less extent, by the-
oretical linguistic work, such as Centering The-
ory (Grosz et al., 1995; Walker et al., 1994;
Kameyama, 1986) and the systemic theory (Hal-
liday and Hasan, 1976). The best-achieved per-
formance in MUC-7 I was around 70% precision
with 60% recall, which is still far from being sat-
isfactory for many practical applications. Worse
still, a rule set tuned for a particular domain is un-
likely to work equally for another domain due to
domain-dependent properties of coreference pat-
terns. Given these facts, further manual refine-
ments of rule-based models will be prohibitively
costly.
Corpus-based empirical approaches, such as
(Soon et al., 2001; Ng and Cardie, 2002), on
the other hand, are cost effective, while having
achieved a performance comparable to the best-
performing rule-based systems for the coreference
task test sets of MUC-6 and MUC-7. However,
they tend to lack an appropriate reference to the-
oretical linguistic work on coherence and coref-
erence. Given this background, one of the chal-
lenging issues we should explore next is to make a
good marriage between theoretical linguistic find-
ings and corpus-based empirical methods.
In this paper, we report our attempt to enhance
existing trainable coreference resolution models
by incorporating such theoretical findings as the
features utilized in Centering Theory. In Section 2,
we review the decision tree-based model proposed
by Soon et al. (2001) and one of its successors
devised by Ng and Cardie (2002), the latter of
which is referred to as the baseline model in our
</bodyText>
<footnote confidence="0.963917">
&apos;The Seventh Message Understanding Conference
(1998):
www.itl.nistgooaui/894.02/related _projects/muc/
</footnote>
<page confidence="0.998476">
23
</page>
<bodyText confidence="0.999702">
empirical evaluation. In Section 3, we discuss a
significant drawback of Ng and Cardie&apos;s model
and propose two solutions: (a) implementing the
centering factors as what we call centering fea-
tures, and (b) introducing a novel searching model,
which we call a tournament model. We then report
the results of our experiments on Japanese zero-
anaphora resolution in Section 4. We finally dis-
cuss remaining problems and future directions in
Section 5.
</bodyText>
<sectionHeader confidence="0.973533" genericHeader="method">
2 A baseline model
</sectionHeader>
<bodyText confidence="0.983850833333334">
Among previous machine learning approaches to
coreference resolution, it is probably reasonable
to take the work done by Soon et al. (2001) and
Ng and Cardie (2002) as our departing point be-
cause their models are reported to have reached a
level of performance comparable to state-of-the-
art knowledge-based systems.
Soon et al.&apos;s model is designed to operate by re-
casting anaphora resolution (i.e. detection of the
antecedent of a given anaphor) as a classification
task. Let us see Figure 1 in order to go into the de-
tail. The figure illustrates a situation where there
are eight noun phrases, NPi through NP8, which
precede the anaphoric noun phrase ANP in ques-
tion. NP2 and NP4, NP3 and NP5, and NP6 and
NP7 are coreferent respectively, and NP5 (and its
coreferent NP3) is the antecedent of ANP. Under
this situation, the model detects the antecedent by
answering a sequence of candidate-wise boolean
classification questions: whether or not NP is
ANP&apos;s antecedent for each i E {1, , 8}.
More precisely, for training, Soon et al.&apos;s model
creates a positive instance from an anaphor and
its closest antecedent (NP5-ANP) and a negative
instance from each of the intervening NPs paired
with the anaphor (NP6-ANP, NP7-ANP and NP8-
ANP). Analogously, given a target NP for resolu-
tion in the test phase (see the box &amp;quot;Resolution pro-
cess&amp;quot; in Figure 1), the model processes each of its
preceding NPs in the right-to-left order, answer-
ing a classification question of whether or not it is
coreferent, until a positive answer comes up. If all
the preceding NPs are classified in the negative,
the target NP is judged to be non-anaphoric. For
classifier induction, Soon et al. used the C5.0 de-
cision tree induction system, an updated version of
</bodyText>
<figureCaption confidence="0.994507">
Figure 1: Training example extraction in
candidate-wise classification models (Soon et al.,
2001; Ng and Cardie, 2002)
</figureCaption>
<bodyText confidence="0.99698351724138">
C4.5 (Quinlan, 1993), in their experiments with a
very limited feature set consisting of mere twelve
features.
Following Soon et al.&apos;s work, Ng and
Cardie (2002) improved upon the model by
(a) expanding the feature set, and (b) introducing
a new search algorithm that searches for the NP
with the highest coreference likelihood value. Let
us return to Figure 1 for the sake of explanation.
In this revised model, while training examples
are extracted in the same manner, antecedent
detection is done by selecting the highest scored
NP from the candidates NP1 to NP7. If no candi-
date is classified in the positive, the target noun
phrase is judged to be non-anaphoric. According
to Ng and Cardie (2002), their model outperforms
the original one, which has also been supported
by our experiment on Japanese zero-anaphora
resolution reported later. In the rest of the paper,
we thus refer to this revised model as the baseline
of our empirical evaluation.
Although we do not have the space to go into the
detail of the feature set used in Ng and Cardie&apos;s ex-
periments, it should be pointed out that their model
does not capture an important aspect of local con-
text that has been proved useful for coreference in-
terpretation in the literature of discourse analysis.
We elaborate this flaw and propose two solutions
in the next section.
</bodyText>
<figure confidence="0.998512628571428">
NP8
ANP
Hnegative
negative
NP5
NP6
ANP
NP7
ANP
NP6
---1[-coreferent
NP7
NP8
ANP
anaphor
beginning of document
Lsorefele■t
antecedent
Training examples
features class
positive
negative
Resolution process
features class
NP8 ANP negative
2. NP7 ANP negative
3. NP6 ANP 0 negative
4. NP5 ANP positive
•=&gt; NP5 is the antecedent
NPI I
NP2
NP3
NP4
NP5
coreferent
</figure>
<page confidence="0.932243">
24
</page>
<listItem confidence="0.78987525">
3 Incorporating of contextual cues
3.1 A flaw of the baseline model
Consider the following two discourses:
(1) a. Mary went to see John,.
b. He., was playing baseball.
(2) a. Tom, went to see John.
b. He., tried to explain what happened to him
yesterday.
</listItem>
<bodyText confidence="0.996714875">
In (1), the subject of sentence (b), He, refers to the
object of sentence (a), John. In (2), on the other
hand, it is not the case although He and John fills
the same syntactic role, respectively. An expla-
nation for this difference derived from Centering
Theory can be briefed as follows. In (2), Tom is
chosen to be the preferred antecedent of he be-
cause:
</bodyText>
<listItem confidence="0.996879">
(a) Tom, being the subject role filler, is the pre-
ferred center (i.e. the highest ranked entity of
the forward looking centers) assigned in (a),
(b) Tom is thus most likely to be the backward
looking center of (b), and
(c) if so is Tom, it must be realized as a pronoun.
</listItem>
<bodyText confidence="0.999950285714286">
In (1), on the other hand, Mary, the preferred cen-
ter, violates the gender constraint imposed by He,
and therefore the second ranked entity John is in-
terpreted as the antecedent.
The essence of the above explanation is that it
is derived from a model that takes into account
the preference between candidates. Whether or
not John is coreferent depends on the appearance
of other entities, such as Mary and Tom, in its lo-
cal context. This crucial property of local coher-
ence is, however, not properly captured in Ng and
Cardie&apos;s model because it views antecedent detec-
tion as a set of candidate-wise boolean classifica-
tion problems.
</bodyText>
<subsectionHeader confidence="0.998645">
3.2 Two solutions
</subsectionHeader>
<bodyText confidence="0.999971333333333">
Among various possibilities one may think of as
a solution to the problem argued above, we have
empirically examined two novel solutions.
</bodyText>
<subsubsectionHeader confidence="0.59763">
3.2.1 Centering features
</subsubsectionHeader>
<bodyText confidence="0.999996210526316">
A straightforward solution is to augment the
number of features that implement local contex-
tual factors. For example, one may introduce a
feature that indicates whether or not the antecedent
candidate in question is the present preferred cen-
ter. This feature can also be enhanced so that it can
indicate whether or not the candidate is ranked the
highest among the forward-looking centers while
satisfying gender and number constraints. Such
a feature would help the classification model to
distinguish the two Johns in the previous exam-
ples. Note that the computation of such features
requires the use of additional devices, such as a
list for storing forward-looking centers, which has
never been used in previous trainable models. We
refer to such features as centering features for cap-
turing centering state transitions. The centering
features we used in our experiments will be pre-
sented in the next section.
</bodyText>
<subsubsectionHeader confidence="0.665424">
3.2.2 The tournament model
</subsubsectionHeader>
<bodyText confidence="0.999842636363636">
Recall that what we wanted in John&apos;s exam-
ples was a model that compares the first John
with its opponent Mary and the second John with
Tom. Our second solution is to implement a pair-
wise comparison between two candidates in ref-
erence to ANP as a binary classification problem
(i.e. which candidate wins) and to conduct a tour-
nament to check against the candidate. A tour-
nament consists of a series of matches in which
candidates compete with each other and the one
that prevails through the final round is declared the
</bodyText>
<figure confidence="0.8766353">
beginning of document
coreferent NPI
NP2
antecedent— &gt; NP3 co referent
NP4
NP5
121
NP7
NP8
anaphor ANP
</figure>
<figureCaption confidence="0.99715">
Figure 2: The tournament model
</figureCaption>
<figure confidence="0.9880707">
Training examples
features class
NPI NP5
NP4 NP5 ANP
NP7 ANP
right
right
left
left
Resolution process
features class
UPI NP5 ANP
NP4 l.NP5 ANP
NP7 NP8 ANP
NP5 NP8 ANP
is the antecedent
right
left
right
right
</figure>
<page confidence="0.988206">
25
</page>
<bodyText confidence="0.998657290909091">
winner, namely, identified as the antecedent. We
call this new model the tournament model.
Observe the situation given in Figure 1 again,
which we have reillustrated here as Figure 2. Now,
due to the coreference chains, we have five can-
didates: NP1, NP4 (and its coreferent NP2), NP5
(NP3), NP7 (NP6) and NP8.
Let us first consider the training process . In
the tournament, the correct antecedent NP5 (NP3)
must prevail over any of the other four candidates.
We thus extract four training examples from the
present case as illustrated in the figure. The class
right denotes that the succeeding one of a given
pair of candidates prevails against (i.e. is more
likely to be the antecedent than) the preceding one.
Likewise, the class left denotes that the preced-
ing candidate prevails over the succeeding one.
Finally, we induce from a set of extracted train-
ing examples a pair-wise classifier that classifies a
given feature vector into either right or left.
In the test phase, the model conducts a tour-
nament for each given anaphor. In each tourna-
ment, it processes the antecedent candidates in the
right-to-left order. In the first round, the model
consults the trained classifier to judge which of
the right-most (closest th ANP) two candidates is
more likely to be the antecedent. Suppose anew
that we are trying to resolve the problem illustrated
in Figure 2. As shown in the &amp;quot;resolution process&amp;quot;
part of the figure, the first match is arranged be-
tween the right-most two candidates NP8 and NP7.
Here, we assume that NP8 wins as shown in the
figure. Then, each of the following matches is ar-
ranged in turn between the winner of the previ-
ous match and a right-most new challenger. In the
case shown in the figure, the second match is ar-
ranged between the current winner NP8 and the
right-most new challenger NP5. If NP5 wins, it
is next matched against all next challenger NP4.
This process is repeated until the left-most candi-
date participates. The model selects the candidate
that prevails through the final round as the answer.
The introduction of the pairwise classification
as above can incorporate the learning of centering
factors, such as the expected center order; for ex-
ample, the model may learn from Tom and John&apos;s
example that the subject role filler is preferred to
the object role filler. The tournament model can
also encode relational properties between candi-
dates into features. One may, for example, add
a feature that indicates the relative distance be-
tween a given candidate pair, expecting a tendency
that the succeeding candidate is more likely to win
when the relative distance between two candidates
is longer.
</bodyText>
<sectionHeader confidence="0.998823" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.997298111111111">
We made an empirical evaluation taking on
Japanese zero-anaphora resolution. Japanese
is characterized by an extensive use of zero-
pronouns, which behave like pronouns in English
texts. The resolution of zero-anaphora has been
receiving interest from an increasing number of
researchers (Kameyama, 1986; Nariyama, 2002;
Nakaiwa and Shirai, 1996; Seki et al., 2002; Ya-
mamoto and Sumita, 1998).
</bodyText>
<subsectionHeader confidence="0.883719">
4.1 Training and test sets
</subsectionHeader>
<bodyText confidence="0.9999802">
We extracted training and test data sets from a cor-
pus with GDA-tagged2 newspaper articles, which
is annotated with coreference relation tags as well
as various syntactic and semantic tags. The cor-
pus contains over 25,000 sentences with roughly
20,000 coreference tags annotated. In the ex-
periment, we preliminarily restricted our experi-
ments for resolving subject zero-anaphors, 2,155
instances in total, and conducted five-fold cross-
validation on that data set.
</bodyText>
<subsectionHeader confidence="0.967481">
4.2 Feature set
</subsectionHeader>
<bodyText confidence="0.998936833333333">
We used five types of features as summarized
in Table 1: (i) grammatical, (ii) semantic, (iii) po-
sitional, (iv) heuristic and (v) centering features.
The features of types (i) to (iv) are defined so as
to simulate Ng and Cardie&apos;s feature set, except the
following three features:
</bodyText>
<listItem confidence="0.972694833333333">
• LOG_LIKE: indicates the largest value
among the log-likelihood coefficients (Dun-
ning, 1993) of the pairs of a noun in the coref-
erence chain including the candidate and the
predicate of the anaphor. Those coefficients
are calculated with about ten millions of
</listItem>
<footnote confidence="0.69561825">
2The GDA (Global Document Annotation (Hasida,
2002)) tag set is designed to be a standard tag set which al-
lows machines to automatically recognize the semantic and
pragmatic structures of documents.
</footnote>
<page confidence="0.970502">
26
</page>
<table confidence="0.999365304347826">
Feature types Feature names Descriptions
Grammatical Pos The part-of-speech of NP i such as &apos;proper noun&apos; and `sahen noun&apos;.
DEFINITE Y if NP, is &apos;sore&apos;, &apos;soko&apos;, &apos;sono&apos;, &apos;sonna&apos;, etc; else N.
DEMONSTRATIVE Y if NPi is &apos;kore&apos;, &apos;soko&apos;, &apos;ano&apos;, &apos;asoko&apos;, etc; else N.
PARTICLE The case marker attached to NP, such as `wa-, &apos;pi&apos; and &apos;o&apos;.
Semantic NE Named entity class of NP,: PERSON, ORGANIZATION, LOCATION, ARTI-
FACT, DATE, TIME, MONEY, PERCENT or N/A.
EDR_HUMAN Y if NP i has the human attribute of EDR dictionary; else N.
SELECT_REST C if NP,-ANP pair satisfies the selectional restriction; else I.
LOG_LIKE Five degree of the log-like coefficient of the NP-ANP pair.
ANIMACY Y if NP i has the PERSON Or ORGANIZATION class; else N.
ANIMACY_COMP* N/31 if NP1 has ANIMACY feature and NP2 doesn&apos;t; else NP2 if the opposite
relation.
Positional SENTNUM_ANP Distance between NP, and ANP in terms of sentences.
SENTNUM_NPS* Distance between NP1 and NP2 in terms of sentences.
DEP_MAIN Y if NP, depends on the main clause; else N.
EMBEDDED Y if ATP i locates in an embedded clause; else N.
BEGINNING Y if NP, locates in the beginning of the sentence: else N.
Heuristic CHAIN_LENGTH Length of a cohesive chain of NP,
Centering SRL_ORDER The priority rank of NP i in SRL.
SRL_ORDER_COMP* NP1 if NPJ, is higher ranked than NP2 in SRL; else NP2
OA_REE Y if NP i is the subject of a subordinate clause of a particuler conjunctive type
and ANP is the subject of its matrix clause; else N.
</table>
<tableCaption confidence="0.883513111111111">
Table 1: Feature Set
ANP is an anaphor, and NP,E{1,2} is an antecedent candidate. The feature set contains relational and non-relational features.
Non-relational features test some property P of NP, under consideration and take on a value of YES or No depending on
whether P holds. Relational features test whether some property P holds for the NP1-NP2 or NP2-ANP pair under consideration
and indicates whether the pair is COMPATIBLE or INCOMPATIBLE w.r.t. P: a value of NOT APPLICABLE is used when property
P does not apply. Features with an asterisk are used only in the tournament model.
NOUN-VERB pairs extracted from other cor-
pora (Nikkei Shimbun, 1990-2000; Mainichi
Shimbun, 1991-1999).
</tableCaption>
<listItem confidence="0.934776142857143">
• SELECT_REST: indicates whether or not a
candidate satisfies selectional restrictions in
Nihongo Goi Taikei (Japanese Lexicon) (Ike-
hara, et al., 1997).
• CHAIN _LENGTH: indicates the number of all
the preceding nouns in the coreference chain
including the candidate.
</listItem>
<bodyText confidence="0.996136542857143">
We also introduce ANIMACY feature as in Ng&apos;s
feature set, because an animate noun tends to be
salient. ANIMACY indicates whether or not the
candidate is an animate noun. A noun is regarded
as animate if the noun is classified as PERSON or
ORGANIZATION by a named entity tagger or the
noun is included in PERSON or ORGANIZATION
class of Nihongo Goi Taikei (Ikehara, et al., 1997).
To define centering features, we adopted a
Japanese anaphora resolution model proposed
by Nariyama (2002) as the underlying the-
ory. Nariyama&apos;s method is an expansion of
Kameyama&apos;s work on the application of Centering
Theory to Japanese anaphora (Kameyama, 1986).
Nariyama expanded the original forward-looking
center list into Salience Reference List (SRL) in
order to take into account broader contextual in-
formation from preceding sentences. Analogous
to common centering models, in SRL, discourse
entities are stored in the salience order: TOPIC
(marked by wa-particle) &gt; SUBJ (ga) &gt; I_OBJ
(ni) &gt; D_OBJ (o) &gt; OTHERS. In the experiment,
we introduced two features, SRL_ORDER and
SRL_ORDER_COMP, to reflect the SRL-related
contextual factors. The definition of them is given
in Table 1. Nariyama&apos;s method is also devised to
deal with state transitions in complex sentences,
which was originally not handled in Kameyama&apos;s
model on Japanese. We partially implemented this
extension as another feature, GA_REF, expecting
the strong tendency of coreference that some con-
junctives convey.
In the experiment, all the features are automati-
cally computed with the help of the following NLP
systems: the Japanese morphological analyzer
</bodyText>
<page confidence="0.994479">
27
</page>
<table confidence="0.9863358">
ChaSen (Matsumoto, 2000), the Japanese depen- 1
dency structure analyzer CaboCha (Kudoh and 0.95 -
Matsumoto, 2000), and the named entity chunker 0.9
Yanee (Yamada, 2002). 0.85 -
4.3 Results 0.8 -
While Ng and Cardie used the C4.5 decision 0.75 -
tree induction system, we adopted Support Vec- 0.7 -
tor Machines (Vapnik, 1998) for classifier induc-
tion because of their state-of-the-art performance
and considerable generalization ability, which had
been proven for various NLP tasks.
0.65
0
0.1 0.2 0.3 0.4 0.5 0.6 0 7
Recall
</table>
<figureCaption confidence="0.995361">
Figure 3: Learning curves
</figureCaption>
<bodyText confidence="0.999234227272727">
BM: Baseline model, BM+CF: Baseline model using center-
ing features TM: Tournament model, TM+CF: Tournament
model using centering features
The results are shown in Figure 3. We can
see the positive effects for introducing the center-
ing features by comparing the learning curves of
BM±CF with BM, and TM+CF with TM. Like-
wise, the differences between BM and TM show
that the introduction of the tournament model sig-
nificantly improved the performance regardless of
the size of training data. That is to say, when the
tournament and centering features (TM+CF) are
incorporate, precision is always higher than with-
out, except for TM+CF in small data size. How-
ever, the improvement ratio of this model against
the data size is, in fact, the best of all, which sug-
gest that it will become the best method as the data
size increases.
One can also introduce the notion of decision
confidence into the tournament model. With a
good confidence measure, one can effectively im-
prove precision just by slightly sacrificing recall.
</bodyText>
<figureCaption confidence="0.845639">
Figure 4: Precision-recall curve obtained with the
tournament model
</figureCaption>
<bodyText confidence="0.999906857142857">
In case of the tournament model, the likelihood
(i.e. the degree of confidence) that the decision
for a match is correct can be heuristically esti-
mated by, for example, the absolute value of the
SVM classifier&apos;s discrimination function for the
corresponding classification problem. The likeli-
hood that the winner of a tournament is correct is
then given by the confidence value of the closest
match the winner have played. Given such a con-
fidence measure, one can obtain a recall-precision
curve by moving the threshold of confidence val-
ues. Working of this is shown in Figure 4, which
presents the recall-precision curve obtained by
testing this heuristic measure.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.9998550625">
There have been an increasing number of reports
on corpus-based empirical approaches to corefer-
ence resolution. For example, besides the mod-
els proposed by Soon et al. (2001) and Ng and
Cardie (2002), which we have referred to as the
baseline model, one can find a diversity of train-
able models for the resolution of pronouns (Ge
and Charniak, 1998), definite NPs (Aone and Ben-
nett, 1995; McCarthy and Lehnert, 1995; Strube
et al., 2002), and Japanese zero-pronouns (Ya-
mamoto and Sumita, 1998; Seki et al., 2002).
Surprisingly enough, however, very few of
these models has an explicit reference to such the-
oretical work as Centering Theory. In fact, none
of them incorporates a training feature that cap-
tures local context as well as the centering features
</bodyText>
<figure confidence="0.996598">
BM&apos;
-BM+CF
TM
--1M+CF
300 500 1000
training data size
Precision [%]
72
70
68
66
64
62
60
58
56
200
2000
</figure>
<page confidence="0.997304">
28
</page>
<bodyText confidence="0.999948625">
we proposed in this paper. Furthermore, the pre-
vious models are all designed to estimate for each
candidate how &amp;quot;likely&amp;quot; it is the coreferent with-
out referring to others. . The deficiency of such a
candidate-wise estimation model is just as we dis-
cussed in Section 3.1. The experimental results re-
ported above confirmed that our tournament model
has the potential for overcoming it.
</bodyText>
<sectionHeader confidence="0.949615" genericHeader="conclusions">
6 Summary and future work
</sectionHeader>
<bodyText confidence="0.999986470588235">
In this paper, we presented a trainable coreference
resolution model that is designed to incorporate
contextual cues by means of centering features and
a tournament-based search algorithm. These two
improvements worked effectively in our experi-
ments on Japanese zero-anaphora resolution.
As future work, we address three remaining is-
sues: (i) identification of relations between the
topics and the subtopics, (ii) analysis of complex
and quoted sentences and (iii) refinement of selec-
tional restrictions. With regard to (i), wa-marked
subtopics are often incorrectly selected because
the present model cannot capture topic-subtopic
structures. Our next step will be to encode such hi-
erarchical structure as a centering feature. Since a
topic-subtopic relation holds between two NPs, it
may be effective in the tournament model. As for
(ii), a half of zero-anaphors in GDA have the clos-
est antecedent in the same sentence because the
great majority of sentences in newspaper articles
are complex sentences. Thus, correct dependency
analysis of complex sentences is necessary. How-
ever, the dependency analyzer we used often make
errors with complex sentences. We hope for a
parallel progress of dependency structure analysis
and antecedent identification. Finally, we need to
make selectional restrictions more effective for re-
solving anaphora. We examined the misclassified
examples. Most errors are related to quoted sen-
tences, which are not dealt with under the frame-
work of the Centering. The corpus include many
tagging errors. Enhancing the quality of corpus as
well as the robustness of learning framework will
be also our next step.
</bodyText>
<sectionHeader confidence="0.992639" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999854142857143">
We thank Koiti Hasida (AIST) for allowing us
to use the GDA-tagged corpus, Hiroyasu Yamada
(JAIST) for his NE tagging tool YANEE, and Taku
Kudo (NAIST) for his Japanese dependency struc-
ture analyzer CaboCha and TinySVM. We also
thank Shigeko Nariyama (Melbourne University /
NAIST) for helpful comments on this work.
</bodyText>
<sectionHeader confidence="0.997638" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998793487179487">
C. Aone and S. W. Bennett. 1995. Evaluating auto-
mated and manual acquisition of anaphora resolu-
tion strategies. In Proceedings of 33th Annual Meet-
ing of the Association for Computational Linguis-
tics(ACL), 122-129.
B. Baldwin. 1995. CogNIAC: a discourse processing
engine. Ph.D. Thesis, Department of Computer and
Information Sciences, University of Pennsylvania.
T. Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Lin-
guistics, 19(1):61-74.
N. Ge, J. Hale, and E. Charniak. 1998. A statistical ap-
proach to anaphora resolution. In Proceedings of the
Sixth Workshop on Very Large Corpora, 161-170.
B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995.
Centering: a framework for modeling the local co-
herence of discourse. Computational Linguistics,
21(2):203-226.
M. Halliday and R. Hasan. 1976. Cohesion in English.
Longman.
K. Hasida. 2002. Global Document Annotation
(GDA). http://i-content.org/
K. Yamamoto and E. Sumita. 1998. Feasibility Study
for Ellipsis Resolution in Dialogues by Machine-
Learning Technique. In Proceedings of the 36th An-
nual Meeting of the Association for Computational
Linguistics and 17th International Conference on
Computational Linguistics
S. Ikehara, M. Miyazaki, A. Yokoo, S. Shirai, H.
Nakaiwa, K. Ogura, Y. Ooyama, and Y. Hayashi.
1997. Nihongo Goi Taikei - A Japanese Lexicon.
Iwanami Shoten. (In Japanese).
M. Kameyama. 1986. A property-sharing constraint in
centering. In Proceedings of the 24th Annual Meet-
ing of the Association fbr Computational Linguis-
tics, 200-206.
M. Kameyama. 1997. Intrasentential centering: a case
study. In Centering Theory in Discourse, chap. 6,
Oxford University Press.
</reference>
<page confidence="0.99939">
29
</page>
<bodyText confidence="0.8650395">
T. Kudoh and Y. Matsumoto. 2000. Japanese depen-
dency analysis based on Support Vector Machines.
In Proceedings of EMNLP/VLC2000.
K. Seki, A. Fujii, and T. Ishikawa. 2002. A proba-
bilistic method for analyzing Japanese anaphora in-
tegrating zero pronoun detection and resolution, In
Proceedings of the 19th International Conference on
Computational Linguistics, 911-917.
Mainichi Shimbunsha. 1991-1999. Mainichi Shimbun
CD-ROM.
</bodyText>
<reference confidence="0.999905571428571">
Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hi-
rano, H. Matsuda, K. Takaoka, and M. Asahara.
2000. Morphological Analysis System ChaSen ver-
sion 2.2.1 Manual.
J. F. McCarthy and W. G. Lehnert. 1995. In Proceed-
ings of the 14th International Joint Conference on
Artificial Intelligence.
R. Mitkov. 1997. Factors in anaphora resolution: they
are not the only things that matter. A case study
based on two different approaches. In Proceedings
of the ACL&apos;97/EACL&apos;97 Workshop on Operational
Factors in Practical, Robust Anaphora Resolution.
C. Milner, S. Rapp, and M. Strube. 2002. Applying
Co-Training to reference resolution. In Proceedings
of the 40th Annual Meeting of the Association fbr
Computational Linguistics, Proceedings of the Con-
ference (ACL 2002).
M. Murata, H. Isahara, and M. Nagao. 1999. Resolu-
tion of indirect anaphora in Japanese sentences using
examples &amp;quot;X no Y TY of X)&amp;quot;. In Proceedings of the
ACL&apos;99 Workshop on Coreference and Its Applica-
tions.
H. Nakaiwa and S. Shirai. 1996. Anaphora resolution
of Japanese zero pronouns with deictic reference. In
Proceedings of the 16th International Conference on
Computational Linguistics, 812-817.
S. Nariyama 2002. Grammar for ellipsis resolution in
Japanese. In Proceedings of the 9th International
Conference on Theoretical and Methodological Is-
sues in Machine Translation, 135-145.
V. Ng and C. Cardie. 2002. Improving machine learn-
ing approaches to coreference resolution. In Pro-
ceedings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics(ACL), 104-111.
Nikkei Shimbunsha. 1990-2000. Nikkei Shimbun CD-
ROM.
M. Okumura and K. Tamura. 1996. Zero pronoun
resolution in Japanese discourse based on centering
theory. In Proceedings of the 16th Annual Meet-
ing of the Association for Computational Linguis-
tics, 871-876.
J. R. Quinlan. 1993. C4.5: Programs for Machine
Learning. Morgan Kaufmann, San Mateo, CA.
W. M. Soon, H. T. Ng, and D. C. Y. Lim. 2001. A
machine learning approach to coreference resolu-
tion of noun phrases. Computational Linguistics,
27(4):521-544.
M. Strube, S. Rapp, and C. Muller. 2002. The influ-
ence if minimum edit distance on reference resolu-
tion. In Proceedings of the 2002 Conference on Em-
pirical Methods in Natural Language Processing.
V. Vapnik. 1998. Statistical Learning Theory. John
Wiley.
M. Walker, M. Iida, and S. Cote. 1994. Japanese dis-
course and the process of centering. Computational
Linguistics, 20(2): 193-233.
H. Yamada, T. Kudo, and Y. Matsumoto. 2002.
Japanese named entity extraction using Support Vec-
tor Machine. IPSJ Journal, Vol.43, No.1, (in
Japanese).
T. Yokoi. 1995. The EDR electric dictionary. Com-
munications of the ACM, Vol.38, No.11, November
1995, 42-44.
</reference>
<page confidence="0.998812">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.726277">
<title confidence="0.9995105">Incorporating Contextual Cues in Trainable for Coreference Resolution</title>
<author confidence="0.9901">Ryu Iida</author>
<author confidence="0.9901">Kentaro Inui</author>
<author confidence="0.9901">Hiroya Takamura</author>
<author confidence="0.9901">Yuji Matsumoto</author>
<affiliation confidence="0.9993345">Graduate School of Information Science, Nara Institute of Science and Technology</affiliation>
<address confidence="0.999652">8916-5 Takayama, Ikoma, Nara, 630-0192,</address>
<email confidence="0.99153">fryu-i,inui,hiroya-tmatsuf@is.aist-nara.acjp</email>
<abstract confidence="0.9812595">We propose a method that incorporates novel contextual cues into a machine learning for resolving coreference. Distinct characteristics of our model are (i) incorporating more linguistic features capturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Aone</author>
<author>S W Bennett</author>
</authors>
<title>Evaluating automated and manual acquisition of anaphora resolution strategies.</title>
<date>1995</date>
<booktitle>In Proceedings of 33th Annual Meeting of the Association for Computational Linguistics(ACL),</booktitle>
<pages>122--129</pages>
<contexts>
<context position="21714" citStr="Aone and Bennett, 1995" startWordPosition="3557" endWordPosition="3561"> measure, one can obtain a recall-precision curve by moving the threshold of confidence values. Working of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1M+CF 300 500 1000 training data size Precision [%] 72 70 68 66 64 62 60 58 56 200 2000 28 we proposed in this paper. Furthermore, the previous models are all designed to estimate for each candidate how &amp;quot;likely&amp;quot; it</context>
</contexts>
<marker>Aone, Bennett, 1995</marker>
<rawString>C. Aone and S. W. Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of 33th Annual Meeting of the Association for Computational Linguistics(ACL), 122-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Baldwin</author>
</authors>
<title>CogNIAC: a discourse processing engine.</title>
<date>1995</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Computer and Information Sciences, University of Pennsylvania.</institution>
<contexts>
<context position="1094" citStr="Baldwin, 1995" startWordPosition="146" endWordPosition="148"> incorporating more linguistic features capturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001). 1 Introduction Computational approaches to coreference resolution have been roughly evolving in two different but complementary directions. One is theoryoriented rule-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achie</context>
</contexts>
<marker>Baldwin, 1995</marker>
<rawString>B. Baldwin. 1995. CogNIAC: a discourse processing engine. Ph.D. Thesis, Department of Computer and Information Sciences, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="14593" citStr="Dunning, 1993" startWordPosition="2393" endWordPosition="2395">ughly 20,000 coreference tags annotated. In the experiment, we preliminarily restricted our experiments for resolving subject zero-anaphors, 2,155 instances in total, and conducted five-fold crossvalidation on that data set. 4.2 Feature set We used five types of features as summarized in Table 1: (i) grammatical, (ii) semantic, (iii) positional, (iv) heuristic and (v) centering features. The features of types (i) to (iv) are defined so as to simulate Ng and Cardie&apos;s feature set, except the following three features: • LOG_LIKE: indicates the largest value among the log-likelihood coefficients (Dunning, 1993) of the pairs of a noun in the coreference chain including the candidate and the predicate of the anaphor. Those coefficients are calculated with about ten millions of 2The GDA (Global Document Annotation (Hasida, 2002)) tag set is designed to be a standard tag set which allows machines to automatically recognize the semantic and pragmatic structures of documents. 26 Feature types Feature names Descriptions Grammatical Pos The part-of-speech of NP i such as &apos;proper noun&apos; and `sahen noun&apos;. DEFINITE Y if NP, is &apos;sore&apos;, &apos;soko&apos;, &apos;sono&apos;, &apos;sonna&apos;, etc; else N. DEMONSTRATIVE Y if NPi is &apos;kore&apos;, &apos;soko</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ge</author>
<author>J Hale</author>
<author>E Charniak</author>
</authors>
<title>A statistical approach to anaphora resolution.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>161--170</pages>
<marker>Ge, Hale, Charniak, 1998</marker>
<rawString>N. Ge, J. Hale, and E. Charniak. 1998. A statistical approach to anaphora resolution. In Proceedings of the Sixth Workshop on Very Large Corpora, 161-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering: a framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<contexts>
<context position="1589" citStr="Grosz et al., 1995" startWordPosition="226" endWordPosition="229">-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the </context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995. Centering: a framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203-226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Halliday</author>
<author>R Hasan</author>
</authors>
<date>1976</date>
<note>Cohesion in English. Longman.</note>
<contexts>
<context position="1678" citStr="Halliday and Hasan, 1976" startWordPosition="240" endWordPosition="244">d approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the other hand, are cost effective, while having achieved a performance comparable to the bes</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>M. Halliday and R. Hasan. 1976. Cohesion in English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hasida</author>
</authors>
<title>Global Document Annotation (GDA).</title>
<date>2002</date>
<note>http://i-content.org/</note>
<contexts>
<context position="14812" citStr="Hasida, 2002" startWordPosition="2430" endWordPosition="2431">set. 4.2 Feature set We used five types of features as summarized in Table 1: (i) grammatical, (ii) semantic, (iii) positional, (iv) heuristic and (v) centering features. The features of types (i) to (iv) are defined so as to simulate Ng and Cardie&apos;s feature set, except the following three features: • LOG_LIKE: indicates the largest value among the log-likelihood coefficients (Dunning, 1993) of the pairs of a noun in the coreference chain including the candidate and the predicate of the anaphor. Those coefficients are calculated with about ten millions of 2The GDA (Global Document Annotation (Hasida, 2002)) tag set is designed to be a standard tag set which allows machines to automatically recognize the semantic and pragmatic structures of documents. 26 Feature types Feature names Descriptions Grammatical Pos The part-of-speech of NP i such as &apos;proper noun&apos; and `sahen noun&apos;. DEFINITE Y if NP, is &apos;sore&apos;, &apos;soko&apos;, &apos;sono&apos;, &apos;sonna&apos;, etc; else N. DEMONSTRATIVE Y if NPi is &apos;kore&apos;, &apos;soko&apos;, &apos;ano&apos;, &apos;asoko&apos;, etc; else N. PARTICLE The case marker attached to NP, such as `wa-, &apos;pi&apos; and &apos;o&apos;. Semantic NE Named entity class of NP,: PERSON, ORGANIZATION, LOCATION, ARTIFACT, DATE, TIME, MONEY, PERCENT or N/A. ED</context>
</contexts>
<marker>Hasida, 2002</marker>
<rawString>K. Hasida. 2002. Global Document Annotation (GDA). http://i-content.org/</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamamoto</author>
<author>E Sumita</author>
</authors>
<title>Feasibility Study for Ellipsis Resolution in Dialogues by MachineLearning Technique.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</booktitle>
<contexts>
<context position="13711" citStr="Yamamoto and Sumita, 1998" startWordPosition="2253" endWordPosition="2257">ple, add a feature that indicates the relative distance between a given candidate pair, expecting a tendency that the succeeding candidate is more likely to win when the relative distance between two candidates is longer. 4 Experiments We made an empirical evaluation taking on Japanese zero-anaphora resolution. Japanese is characterized by an extensive use of zeropronouns, which behave like pronouns in English texts. The resolution of zero-anaphora has been receiving interest from an increasing number of researchers (Kameyama, 1986; Nariyama, 2002; Nakaiwa and Shirai, 1996; Seki et al., 2002; Yamamoto and Sumita, 1998). 4.1 Training and test sets We extracted training and test data sets from a corpus with GDA-tagged2 newspaper articles, which is annotated with coreference relation tags as well as various syntactic and semantic tags. The corpus contains over 25,000 sentences with roughly 20,000 coreference tags annotated. In the experiment, we preliminarily restricted our experiments for resolving subject zero-anaphors, 2,155 instances in total, and conducted five-fold crossvalidation on that data set. 4.2 Feature set We used five types of features as summarized in Table 1: (i) grammatical, (ii) semantic, (i</context>
<context position="21819" citStr="Yamamoto and Sumita, 1998" startWordPosition="3573" endWordPosition="3577">g of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1M+CF 300 500 1000 training data size Precision [%] 72 70 68 66 64 62 60 58 56 200 2000 28 we proposed in this paper. Furthermore, the previous models are all designed to estimate for each candidate how &amp;quot;likely&amp;quot; it is the coreferent without referring to others. . The deficiency of such a candidate-wise estimation mode</context>
</contexts>
<marker>Yamamoto, Sumita, 1998</marker>
<rawString>K. Yamamoto and E. Sumita. 1998. Feasibility Study for Ellipsis Resolution in Dialogues by MachineLearning Technique. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ikehara</author>
<author>M Miyazaki</author>
<author>A Yokoo</author>
<author>S Shirai</author>
<author>H Nakaiwa</author>
<author>K Ogura</author>
<author>Y Ooyama</author>
<author>Y Hayashi</author>
</authors>
<title>Nihongo Goi Taikei - A Japanese Lexicon. Iwanami Shoten. (In Japanese).</title>
<date>1997</date>
<contexts>
<context position="17280" citStr="Ikehara, et al., 1997" startWordPosition="2840" endWordPosition="2844">take on a value of YES or No depending on whether P holds. Relational features test whether some property P holds for the NP1-NP2 or NP2-ANP pair under consideration and indicates whether the pair is COMPATIBLE or INCOMPATIBLE w.r.t. P: a value of NOT APPLICABLE is used when property P does not apply. Features with an asterisk are used only in the tournament model. NOUN-VERB pairs extracted from other corpora (Nikkei Shimbun, 1990-2000; Mainichi Shimbun, 1991-1999). • SELECT_REST: indicates whether or not a candidate satisfies selectional restrictions in Nihongo Goi Taikei (Japanese Lexicon) (Ikehara, et al., 1997). • CHAIN _LENGTH: indicates the number of all the preceding nouns in the coreference chain including the candidate. We also introduce ANIMACY feature as in Ng&apos;s feature set, because an animate noun tends to be salient. ANIMACY indicates whether or not the candidate is an animate noun. A noun is regarded as animate if the noun is classified as PERSON or ORGANIZATION by a named entity tagger or the noun is included in PERSON or ORGANIZATION class of Nihongo Goi Taikei (Ikehara, et al., 1997). To define centering features, we adopted a Japanese anaphora resolution model proposed by Nariyama (200</context>
</contexts>
<marker>Ikehara, Miyazaki, Yokoo, Shirai, Nakaiwa, Ogura, Ooyama, Hayashi, 1997</marker>
<rawString>S. Ikehara, M. Miyazaki, A. Yokoo, S. Shirai, H. Nakaiwa, K. Ogura, Y. Ooyama, and Y. Hayashi. 1997. Nihongo Goi Taikei - A Japanese Lexicon. Iwanami Shoten. (In Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>A property-sharing constraint in centering.</title>
<date>1986</date>
<booktitle>In Proceedings of the 24th Annual Meeting of the Association fbr Computational Linguistics,</booktitle>
<pages>200--206</pages>
<contexts>
<context position="1627" citStr="Kameyama, 1986" startWordPosition="234" endWordPosition="235">cal corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the other hand, are cost effective, while </context>
<context position="13622" citStr="Kameyama, 1986" startWordPosition="2241" endWordPosition="2242">ode relational properties between candidates into features. One may, for example, add a feature that indicates the relative distance between a given candidate pair, expecting a tendency that the succeeding candidate is more likely to win when the relative distance between two candidates is longer. 4 Experiments We made an empirical evaluation taking on Japanese zero-anaphora resolution. Japanese is characterized by an extensive use of zeropronouns, which behave like pronouns in English texts. The resolution of zero-anaphora has been receiving interest from an increasing number of researchers (Kameyama, 1986; Nariyama, 2002; Nakaiwa and Shirai, 1996; Seki et al., 2002; Yamamoto and Sumita, 1998). 4.1 Training and test sets We extracted training and test data sets from a corpus with GDA-tagged2 newspaper articles, which is annotated with coreference relation tags as well as various syntactic and semantic tags. The corpus contains over 25,000 sentences with roughly 20,000 coreference tags annotated. In the experiment, we preliminarily restricted our experiments for resolving subject zero-anaphors, 2,155 instances in total, and conducted five-fold crossvalidation on that data set. 4.2 Feature set We</context>
<context position="18038" citStr="Kameyama, 1986" startWordPosition="2967" endWordPosition="2968">feature as in Ng&apos;s feature set, because an animate noun tends to be salient. ANIMACY indicates whether or not the candidate is an animate noun. A noun is regarded as animate if the noun is classified as PERSON or ORGANIZATION by a named entity tagger or the noun is included in PERSON or ORGANIZATION class of Nihongo Goi Taikei (Ikehara, et al., 1997). To define centering features, we adopted a Japanese anaphora resolution model proposed by Nariyama (2002) as the underlying theory. Nariyama&apos;s method is an expansion of Kameyama&apos;s work on the application of Centering Theory to Japanese anaphora (Kameyama, 1986). Nariyama expanded the original forward-looking center list into Salience Reference List (SRL) in order to take into account broader contextual information from preceding sentences. Analogous to common centering models, in SRL, discourse entities are stored in the salience order: TOPIC (marked by wa-particle) &gt; SUBJ (ga) &gt; I_OBJ (ni) &gt; D_OBJ (o) &gt; OTHERS. In the experiment, we introduced two features, SRL_ORDER and SRL_ORDER_COMP, to reflect the SRL-related contextual factors. The definition of them is given in Table 1. Nariyama&apos;s method is also devised to deal with state transitions in compl</context>
</contexts>
<marker>Kameyama, 1986</marker>
<rawString>M. Kameyama. 1986. A property-sharing constraint in centering. In Proceedings of the 24th Annual Meeting of the Association fbr Computational Linguistics, 200-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>Intrasentential centering: a case study.</title>
<date>1997</date>
<booktitle>In Centering Theory in Discourse, chap. 6,</booktitle>
<publisher>University Press.</publisher>
<location>Oxford</location>
<marker>Kameyama, 1997</marker>
<rawString>M. Kameyama. 1997. Intrasentential centering: a case study. In Centering Theory in Discourse, chap. 6, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>A Kitauchi</author>
<author>T Yamashita</author>
<author>Y Hirano</author>
<author>H Matsuda</author>
<author>K Takaoka</author>
<author>M Asahara</author>
</authors>
<title>Morphological Analysis System ChaSen version</title>
<date>2000</date>
<tech>2.2.1 Manual.</tech>
<marker>Matsumoto, Kitauchi, Yamashita, Hirano, Matsuda, Takaoka, Asahara, 2000</marker>
<rawString>Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hirano, H. Matsuda, K. Takaoka, and M. Asahara. 2000. Morphological Analysis System ChaSen version 2.2.1 Manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F McCarthy</author>
<author>W G Lehnert</author>
</authors>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="21742" citStr="McCarthy and Lehnert, 1995" startWordPosition="3562" endWordPosition="3565"> a recall-precision curve by moving the threshold of confidence values. Working of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1M+CF 300 500 1000 training data size Precision [%] 72 70 68 66 64 62 60 58 56 200 2000 28 we proposed in this paper. Furthermore, the previous models are all designed to estimate for each candidate how &amp;quot;likely&amp;quot; it is the coreferent without r</context>
</contexts>
<marker>McCarthy, Lehnert, 1995</marker>
<rawString>J. F. McCarthy and W. G. Lehnert. 1995. In Proceedings of the 14th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Factors in anaphora resolution: they are not the only things that matter. A case study based on two different approaches.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Operational Factors in Practical, Robust Anaphora Resolution.</booktitle>
<contexts>
<context position="1079" citStr="Mitkov, 1997" startWordPosition="144" endWordPosition="145"> model are (i) incorporating more linguistic features capturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001). 1 Introduction Computational approaches to coreference resolution have been roughly evolving in two different but complementary directions. One is theoryoriented rule-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976).</context>
</contexts>
<marker>Mitkov, 1997</marker>
<rawString>R. Mitkov. 1997. Factors in anaphora resolution: they are not the only things that matter. A case study based on two different approaches. In Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Operational Factors in Practical, Robust Anaphora Resolution.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Milner</author>
<author>S Rapp</author>
<author>M Strube</author>
</authors>
<title>Applying Co-Training to reference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association fbr Computational Linguistics, Proceedings of the Conference (ACL</booktitle>
<marker>Milner, Rapp, Strube, 2002</marker>
<rawString>C. Milner, S. Rapp, and M. Strube. 2002. Applying Co-Training to reference resolution. In Proceedings of the 40th Annual Meeting of the Association fbr Computational Linguistics, Proceedings of the Conference (ACL 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Murata</author>
<author>H Isahara</author>
<author>M Nagao</author>
</authors>
<title>Resolution of indirect anaphora in Japanese sentences using examples &amp;quot;X no Y TY of X)&amp;quot;.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL&apos;99 Workshop on Coreference and Its Applications.</booktitle>
<marker>Murata, Isahara, Nagao, 1999</marker>
<rawString>M. Murata, H. Isahara, and M. Nagao. 1999. Resolution of indirect anaphora in Japanese sentences using examples &amp;quot;X no Y TY of X)&amp;quot;. In Proceedings of the ACL&apos;99 Workshop on Coreference and Its Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakaiwa</author>
<author>S Shirai</author>
</authors>
<title>Anaphora resolution of Japanese zero pronouns with deictic reference.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>812--817</pages>
<contexts>
<context position="1120" citStr="Nakaiwa and Shirai, 1996" startWordPosition="149" endWordPosition="152">more linguistic features capturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001). 1 Introduction Computational approaches to coreference resolution have been roughly evolving in two different but complementary directions. One is theoryoriented rule-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I</context>
<context position="13664" citStr="Nakaiwa and Shirai, 1996" startWordPosition="2245" endWordPosition="2248">n candidates into features. One may, for example, add a feature that indicates the relative distance between a given candidate pair, expecting a tendency that the succeeding candidate is more likely to win when the relative distance between two candidates is longer. 4 Experiments We made an empirical evaluation taking on Japanese zero-anaphora resolution. Japanese is characterized by an extensive use of zeropronouns, which behave like pronouns in English texts. The resolution of zero-anaphora has been receiving interest from an increasing number of researchers (Kameyama, 1986; Nariyama, 2002; Nakaiwa and Shirai, 1996; Seki et al., 2002; Yamamoto and Sumita, 1998). 4.1 Training and test sets We extracted training and test data sets from a corpus with GDA-tagged2 newspaper articles, which is annotated with coreference relation tags as well as various syntactic and semantic tags. The corpus contains over 25,000 sentences with roughly 20,000 coreference tags annotated. In the experiment, we preliminarily restricted our experiments for resolving subject zero-anaphors, 2,155 instances in total, and conducted five-fold crossvalidation on that data set. 4.2 Feature set We used five types of features as summarized</context>
</contexts>
<marker>Nakaiwa, Shirai, 1996</marker>
<rawString>H. Nakaiwa and S. Shirai. 1996. Anaphora resolution of Japanese zero pronouns with deictic reference. In Proceedings of the 16th International Conference on Computational Linguistics, 812-817.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nariyama</author>
</authors>
<title>Grammar for ellipsis resolution in Japanese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>135--145</pages>
<contexts>
<context position="13638" citStr="Nariyama, 2002" startWordPosition="2243" endWordPosition="2244">roperties between candidates into features. One may, for example, add a feature that indicates the relative distance between a given candidate pair, expecting a tendency that the succeeding candidate is more likely to win when the relative distance between two candidates is longer. 4 Experiments We made an empirical evaluation taking on Japanese zero-anaphora resolution. Japanese is characterized by an extensive use of zeropronouns, which behave like pronouns in English texts. The resolution of zero-anaphora has been receiving interest from an increasing number of researchers (Kameyama, 1986; Nariyama, 2002; Nakaiwa and Shirai, 1996; Seki et al., 2002; Yamamoto and Sumita, 1998). 4.1 Training and test sets We extracted training and test data sets from a corpus with GDA-tagged2 newspaper articles, which is annotated with coreference relation tags as well as various syntactic and semantic tags. The corpus contains over 25,000 sentences with roughly 20,000 coreference tags annotated. In the experiment, we preliminarily restricted our experiments for resolving subject zero-anaphors, 2,155 instances in total, and conducted five-fold crossvalidation on that data set. 4.2 Feature set We used five types</context>
<context position="17882" citStr="Nariyama (2002)" startWordPosition="2943" endWordPosition="2944">et al., 1997). • CHAIN _LENGTH: indicates the number of all the preceding nouns in the coreference chain including the candidate. We also introduce ANIMACY feature as in Ng&apos;s feature set, because an animate noun tends to be salient. ANIMACY indicates whether or not the candidate is an animate noun. A noun is regarded as animate if the noun is classified as PERSON or ORGANIZATION by a named entity tagger or the noun is included in PERSON or ORGANIZATION class of Nihongo Goi Taikei (Ikehara, et al., 1997). To define centering features, we adopted a Japanese anaphora resolution model proposed by Nariyama (2002) as the underlying theory. Nariyama&apos;s method is an expansion of Kameyama&apos;s work on the application of Centering Theory to Japanese anaphora (Kameyama, 1986). Nariyama expanded the original forward-looking center list into Salience Reference List (SRL) in order to take into account broader contextual information from preceding sentences. Analogous to common centering models, in SRL, discourse entities are stored in the salience order: TOPIC (marked by wa-particle) &gt; SUBJ (ga) &gt; I_OBJ (ni) &gt; D_OBJ (o) &gt; OTHERS. In the experiment, we introduced two features, SRL_ORDER and SRL_ORDER_COMP, to refle</context>
</contexts>
<marker>Nariyama, 2002</marker>
<rawString>S. Nariyama 2002. Grammar for ellipsis resolution in Japanese. In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation, 135-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics(ACL),</booktitle>
<pages>104--111</pages>
<contexts>
<context position="2180" citStr="Ng and Cardie, 2002" startWordPosition="321" endWordPosition="324">ng Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the other hand, are cost effective, while having achieved a performance comparable to the bestperforming rule-based systems for the coreference task test sets of MUC-6 and MUC-7. However, they tend to lack an appropriate reference to theoretical linguistic work on coherence and coreference. Given this background, one of the challenging issues we should explore next is to make a good marriage between theoretical linguistic findings and corpus-based empirical methods. In this paper, we report our attempt to enhance existing trainable coreference resolution models by incorporating such theor</context>
<context position="3785" citStr="Ng and Cardie (2002)" startWordPosition="573" endWordPosition="576"> evaluation. In Section 3, we discuss a significant drawback of Ng and Cardie&apos;s model and propose two solutions: (a) implementing the centering factors as what we call centering features, and (b) introducing a novel searching model, which we call a tournament model. We then report the results of our experiments on Japanese zeroanaphora resolution in Section 4. We finally discuss remaining problems and future directions in Section 5. 2 A baseline model Among previous machine learning approaches to coreference resolution, it is probably reasonable to take the work done by Soon et al. (2001) and Ng and Cardie (2002) as our departing point because their models are reported to have reached a level of performance comparable to state-of-theart knowledge-based systems. Soon et al.&apos;s model is designed to operate by recasting anaphora resolution (i.e. detection of the antecedent of a given anaphor) as a classification task. Let us see Figure 1 in order to go into the detail. The figure illustrates a situation where there are eight noun phrases, NPi through NP8, which precede the anaphoric noun phrase ANP in question. NP2 and NP4, NP3 and NP5, and NP6 and NP7 are coreferent respectively, and NP5 (and its corefer</context>
<context position="5475" citStr="Ng and Cardie, 2002" startWordPosition="857" endWordPosition="860">. Analogously, given a target NP for resolution in the test phase (see the box &amp;quot;Resolution process&amp;quot; in Figure 1), the model processes each of its preceding NPs in the right-to-left order, answering a classification question of whether or not it is coreferent, until a positive answer comes up. If all the preceding NPs are classified in the negative, the target NP is judged to be non-anaphoric. For classifier induction, Soon et al. used the C5.0 decision tree induction system, an updated version of Figure 1: Training example extraction in candidate-wise classification models (Soon et al., 2001; Ng and Cardie, 2002) C4.5 (Quinlan, 1993), in their experiments with a very limited feature set consisting of mere twelve features. Following Soon et al.&apos;s work, Ng and Cardie (2002) improved upon the model by (a) expanding the feature set, and (b) introducing a new search algorithm that searches for the NP with the highest coreference likelihood value. Let us return to Figure 1 for the sake of explanation. In this revised model, while training examples are extracted in the same manner, antecedent detection is done by selecting the highest scored NP from the candidates NP1 to NP7. If no candidate is classified in</context>
<context position="21526" citStr="Ng and Cardie (2002)" startWordPosition="3524" endWordPosition="3527">assification problem. The likelihood that the winner of a tournament is correct is then given by the confidence value of the closest match the winner have played. Given such a confidence measure, one can obtain a recall-precision curve by moving the threshold of confidence values. Working of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1M+CF 300 500 1000 trainin</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>V. Ng and C. Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics(ACL), 104-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikkei Shimbunsha</author>
</authors>
<date>1990</date>
<institution>Nikkei Shimbun CDROM.</institution>
<marker>Shimbunsha, 1990</marker>
<rawString>Nikkei Shimbunsha. 1990-2000. Nikkei Shimbun CDROM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Okumura</author>
<author>K Tamura</author>
</authors>
<title>Zero pronoun resolution in Japanese discourse based on centering theory.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>871--876</pages>
<contexts>
<context position="1147" citStr="Okumura and Tamura, 1996" startWordPosition="153" endWordPosition="156">apturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001). 1 Introduction Computational approaches to coreference resolution have been roughly evolving in two different but complementary directions. One is theoryoriented rule-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision w</context>
</contexts>
<marker>Okumura, Tamura, 1996</marker>
<rawString>M. Okumura and K. Tamura. 1996. Zero pronoun resolution in Japanese discourse based on centering theory. In Proceedings of the 16th Annual Meeting of the Association for Computational Linguistics, 871-876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="5496" citStr="Quinlan, 1993" startWordPosition="862" endWordPosition="863">et NP for resolution in the test phase (see the box &amp;quot;Resolution process&amp;quot; in Figure 1), the model processes each of its preceding NPs in the right-to-left order, answering a classification question of whether or not it is coreferent, until a positive answer comes up. If all the preceding NPs are classified in the negative, the target NP is judged to be non-anaphoric. For classifier induction, Soon et al. used the C5.0 decision tree induction system, an updated version of Figure 1: Training example extraction in candidate-wise classification models (Soon et al., 2001; Ng and Cardie, 2002) C4.5 (Quinlan, 1993), in their experiments with a very limited feature set consisting of mere twelve features. Following Soon et al.&apos;s work, Ng and Cardie (2002) improved upon the model by (a) expanding the feature set, and (b) introducing a new search algorithm that searches for the NP with the highest coreference likelihood value. Let us return to Figure 1 for the sake of explanation. In this revised model, while training examples are extracted in the same manner, antecedent detection is done by selecting the highest scored NP from the candidates NP1 to NP7. If no candidate is classified in the positive, the ta</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>J. R. Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Soon</author>
<author>H T Ng</author>
<author>D C Y Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--4</pages>
<contexts>
<context position="803" citStr="Soon et al. (2001)" startWordPosition="105" endWordPosition="108">itute of Science and Technology 8916-5 Takayama, Ikoma, Nara, 630-0192, Japan fryu-i,inui,hiroya-tmatsuf@is.aist-nara.acjp Abstract We propose a method that incorporates various novel contextual cues into a machine learning for resolving coreference. Distinct characteristics of our model are (i) incorporating more linguistic features capturing contextual information that is more sophisticated than what is offered in Centering Theory, and (ii) a tournament model for selecting a referent. Our experiments show that this model significantly outperforms earlier machine learning approaches, such as Soon et al. (2001). 1 Introduction Computational approaches to coreference resolution have been roughly evolving in two different but complementary directions. One is theoryoriented rule-based approaches and the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility bet</context>
<context position="2158" citStr="Soon et al., 2001" startWordPosition="317" endWordPosition="320">rk, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the other hand, are cost effective, while having achieved a performance comparable to the bestperforming rule-based systems for the coreference task test sets of MUC-6 and MUC-7. However, they tend to lack an appropriate reference to theoretical linguistic work on coherence and coreference. Given this background, one of the challenging issues we should explore next is to make a good marriage between theoretical linguistic findings and corpus-based empirical methods. In this paper, we report our attempt to enhance existing trainable coreference resolution models by in</context>
<context position="3760" citStr="Soon et al. (2001)" startWordPosition="568" endWordPosition="571">jects/muc/ 23 empirical evaluation. In Section 3, we discuss a significant drawback of Ng and Cardie&apos;s model and propose two solutions: (a) implementing the centering factors as what we call centering features, and (b) introducing a novel searching model, which we call a tournament model. We then report the results of our experiments on Japanese zeroanaphora resolution in Section 4. We finally discuss remaining problems and future directions in Section 5. 2 A baseline model Among previous machine learning approaches to coreference resolution, it is probably reasonable to take the work done by Soon et al. (2001) and Ng and Cardie (2002) as our departing point because their models are reported to have reached a level of performance comparable to state-of-theart knowledge-based systems. Soon et al.&apos;s model is designed to operate by recasting anaphora resolution (i.e. detection of the antecedent of a given anaphor) as a classification task. Let us see Figure 1 in order to go into the detail. The figure illustrates a situation where there are eight noun phrases, NPi through NP8, which precede the anaphoric noun phrase ANP in question. NP2 and NP4, NP3 and NP5, and NP6 and NP7 are coreferent respectively,</context>
<context position="5453" citStr="Soon et al., 2001" startWordPosition="853" endWordPosition="856">7-ANP and NP8- ANP). Analogously, given a target NP for resolution in the test phase (see the box &amp;quot;Resolution process&amp;quot; in Figure 1), the model processes each of its preceding NPs in the right-to-left order, answering a classification question of whether or not it is coreferent, until a positive answer comes up. If all the preceding NPs are classified in the negative, the target NP is judged to be non-anaphoric. For classifier induction, Soon et al. used the C5.0 decision tree induction system, an updated version of Figure 1: Training example extraction in candidate-wise classification models (Soon et al., 2001; Ng and Cardie, 2002) C4.5 (Quinlan, 1993), in their experiments with a very limited feature set consisting of mere twelve features. Following Soon et al.&apos;s work, Ng and Cardie (2002) improved upon the model by (a) expanding the feature set, and (b) introducing a new search algorithm that searches for the NP with the highest coreference likelihood value. Let us return to Figure 1 for the sake of explanation. In this revised model, while training examples are extracted in the same manner, antecedent detection is done by selecting the highest scored NP from the candidates NP1 to NP7. If no cand</context>
<context position="21501" citStr="Soon et al. (2001)" startWordPosition="3519" endWordPosition="3522">or the corresponding classification problem. The likelihood that the winner of a tournament is correct is then given by the confidence value of the closest match the winner have played. Given such a confidence measure, one can obtain a recall-precision curve by moving the threshold of confidence values. Working of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>W. M. Soon, H. T. Ng, and D. C. Y. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S Rapp</author>
<author>C Muller</author>
</authors>
<title>The influence if minimum edit distance on reference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="21764" citStr="Strube et al., 2002" startWordPosition="3566" endWordPosition="3569"> moving the threshold of confidence values. Working of this is shown in Figure 4, which presents the recall-precision curve obtained by testing this heuristic measure. 5 Related work There have been an increasing number of reports on corpus-based empirical approaches to coreference resolution. For example, besides the models proposed by Soon et al. (2001) and Ng and Cardie (2002), which we have referred to as the baseline model, one can find a diversity of trainable models for the resolution of pronouns (Ge and Charniak, 1998), definite NPs (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Strube et al., 2002), and Japanese zero-pronouns (Yamamoto and Sumita, 1998; Seki et al., 2002). Surprisingly enough, however, very few of these models has an explicit reference to such theoretical work as Centering Theory. In fact, none of them incorporates a training feature that captures local context as well as the centering features BM&apos; -BM+CF TM --1M+CF 300 500 1000 training data size Precision [%] 72 70 68 66 64 62 60 58 56 200 2000 28 we proposed in this paper. Furthermore, the previous models are all designed to estimate for each candidate how &amp;quot;likely&amp;quot; it is the coreferent without referring to others. . </context>
</contexts>
<marker>Strube, Rapp, Muller, 2002</marker>
<rawString>M. Strube, S. Rapp, and C. Muller. 2002. The influence if minimum edit distance on reference resolution. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley.</publisher>
<contexts>
<context position="19335" citStr="Vapnik, 1998" startWordPosition="3168" endWordPosition="3169">artially implemented this extension as another feature, GA_REF, expecting the strong tendency of coreference that some conjunctives convey. In the experiment, all the features are automatically computed with the help of the following NLP systems: the Japanese morphological analyzer 27 ChaSen (Matsumoto, 2000), the Japanese depen- 1 dency structure analyzer CaboCha (Kudoh and 0.95 - Matsumoto, 2000), and the named entity chunker 0.9 Yanee (Yamada, 2002). 0.85 - 4.3 Results 0.8 - While Ng and Cardie used the C4.5 decision 0.75 - tree induction system, we adopted Support Vec- 0.7 - tor Machines (Vapnik, 1998) for classifier induction because of their state-of-the-art performance and considerable generalization ability, which had been proven for various NLP tasks. 0.65 0 0.1 0.2 0.3 0.4 0.5 0.6 0 7 Recall Figure 3: Learning curves BM: Baseline model, BM+CF: Baseline model using centering features TM: Tournament model, TM+CF: Tournament model using centering features The results are shown in Figure 3. We can see the positive effects for introducing the centering features by comparing the learning curves of BM±CF with BM, and TM+CF with TM. Likewise, the differences between BM and TM show that the in</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. Vapnik. 1998. Statistical Learning Theory. John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>M Iida</author>
<author>S Cote</author>
</authors>
<title>Japanese discourse and the process of centering.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<pages>193--233</pages>
<contexts>
<context position="1610" citStr="Walker et al., 1994" startWordPosition="230" endWordPosition="233">d the other is empirical corpus-based approaches. In rule-based approaches (Mitkov, 1997; Baldwin, 1995; Nakaiwa and Shirai, 1996; Okumura and Tamura, 1996), efforts have been directed to manual encoding of various linguistic cues into a set of rule . Such cues include, for example, the syntactic role of each target noun phrase, the appearance order of antecedent candidates, and the semantic compatibility between an anaphor and a candidate. Most rule-based approaches are also influenced, to a greater or less extent, by theoretical linguistic work, such as Centering Theory (Grosz et al., 1995; Walker et al., 1994; Kameyama, 1986) and the systemic theory (Halliday and Hasan, 1976). The best-achieved performance in MUC-7 I was around 70% precision with 60% recall, which is still far from being satisfactory for many practical applications. Worse still, a rule set tuned for a particular domain is unlikely to work equally for another domain due to domain-dependent properties of coreference patterns. Given these facts, further manual refinements of rule-based models will be prohibitively costly. Corpus-based empirical approaches, such as (Soon et al., 2001; Ng and Cardie, 2002), on the other hand, are cost </context>
</contexts>
<marker>Walker, Iida, Cote, 1994</marker>
<rawString>M. Walker, M. Iida, and S. Cote. 1994. Japanese discourse and the process of centering. Computational Linguistics, 20(2): 193-233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Japanese named entity extraction using Support Vector Machine.</title>
<date>2002</date>
<journal>IPSJ Journal,</journal>
<location>Vol.43, No.1, (in Japanese).</location>
<marker>Yamada, Kudo, Matsumoto, 2002</marker>
<rawString>H. Yamada, T. Kudo, and Y. Matsumoto. 2002. Japanese named entity extraction using Support Vector Machine. IPSJ Journal, Vol.43, No.1, (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Yokoi</author>
</authors>
<title>The EDR electric dictionary.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<pages>42--44</pages>
<marker>Yokoi, 1995</marker>
<rawString>T. Yokoi. 1995. The EDR electric dictionary. Communications of the ACM, Vol.38, No.11, November 1995, 42-44.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>