<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005290">
<title confidence="0.99908">
A Portable Algorithm for Mapping Bitext Correspondence
</title>
<author confidence="0.984241">
I. Dan Melamed
</author>
<affiliation confidence="0.9983055">
Dept. of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.762584">
Philadelphia, PA, 19104, U.S.A.
</address>
<email confidence="0.999499">
melamed@unagi.cis.upenn.edu
</email>
<sectionHeader confidence="0.997398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999857529411765">
The first step in most empirical work in
multilingual NLP is to construct maps of
the correspondence between texts and their
translations (bitext maps). The Smooth
Injective Map Recognizer (SIMR) algo-
rithm presented here is a generic pattern
recognition algorithm that is particularly
well-suited to mapping bitext correspon-
dence. SIMR is faster and significantly
more accurate than other algorithms in the
literature. The algorithm is robust enough
to use on noisy texts, such as those result-
ing from OCR input, and on translations
that are not very literal. SIMR encap-
sulates its language-specific heuristics, so
that it can be ported to any language pair
with a minimal effort.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999636886363636">
Texts that are available in two languages (bitexts)
are immensely valuable for many natural language
processing applicationsl Bitexts are the raw ma-
terial from which translation models are built. In
addition to their use in machine translation (Sato
&amp; Nagao, 1990; Brown et al., 1993; Melamed,
1997), translation models can be applied to machine-
assisted translation (Sato, 1992; Foster et al., 1996),
cross-lingual information retrieval (SIGIR, 1996),
and gisting of World Wide Web pages (Resnik,
1997). Bitexts also play a role in less auto-
mated applications such as concordancing for bilin-
gual lexicography (Catizone et al., 1993; Gale &amp;
Church, 1991b), computer-assisted language learn-
ing, and tools for translators (e.g. (Macklovitch,
&amp;quot;Multitexts&amp;quot; in more than two languages are even
more valuable, but they are much more rare.
1995; Melamed, 1996b). However, bitexts are of lit-
tle use without an automatic method for construct-
ing bitext maps.
Bitext maps identify corresponding text units be-
tween the two halves of a bitext. The ideal bitext
mapping algorithm should be fast and accurate, use
little memory and degrade gracefully when faced
with translation irregularities like omissions and in
versions. It should be applicable to any text genre
in any pair of languages.
The Smooth Injective Map Recognizer (SIMR) al-
gorithm presented in this paper is a bitext mapping
algorithm that advances the state of the art on these
criteria. The evaluation in Section 5 shows that
SIMR&apos;s error rates are lower than those of other
bitext mapping algorithms by an order of magni-
tude. At the same time, its expected running time
and memory requirements are linear in the size of the
input, better than any other published algorithm.
The paper begins by laying down SIMR&apos;s geomet-
ric foundations and describing the algorithm. Then,
Section 4 explains how to port SIMR to arbitrary
language pairs with minimal effort, without rely-
ing on genre-specific information such as sentence
boundaries. The last section offers some insights
about the optimal level of text analysis for mapping
bitext correspondence.
</bodyText>
<sectionHeader confidence="0.955047" genericHeader="method">
2 Bitext Geometry
</sectionHeader>
<bodyText confidence="0.999931636363636">
A bitext (Harris, 1988) comprises two versions of
a text, such as a text in two different languages.
Translators create a bitext each time they trans-
late a text. Each bitext defines a rectangular
bitext space, as illustrated in Figure 1. The width
and height of the rectangle are the lengths of the
two component texts, in characters. The lower left
corner of the rectangle is the origin of the bitext
space and represents the two texts&apos; beginnings. The
upper right corner is the terminus and represents
the texts&apos; ends. The line between the origin and the
</bodyText>
<page confidence="0.996741">
305
</page>
<figure confidence="0.553734">
terminus
</figure>
<figureCaption confidence="0.999751">
Figure 1: a bitext space
</figureCaption>
<bodyText confidence="0.999652833333334">
terminus is the main diagonal. The slope of the
main diagonal is the bitext slope.
Each bitext space contains a number of true
points of correspondence (TPCs), other than
the origin and the terminus. For example, if a token
at position p on the x-axis and a token at position
q on the y-axis are translations of each other, then
the coordinate (p, q) in the bitext space is a TPC2.
TPCs also exist at corresponding boundaries of text
units such as sentences, paragraphs, and chapters.
Groups of TPCs with a roughly linear arrangement
in the bitext space are called chains.
Bitext maps are 1-to-1 functions in bitext
spaces. A complete set of TPCs for a particular
bitext is called a true bitext map (TBM). The
purpose of a bitext mapping algorithm is to pro-
duce bitext maps that are the best possible approx-
imations of each bitext&apos;s TBM.
</bodyText>
<sectionHeader confidence="0.997866" genericHeader="method">
3 SIMR
</sectionHeader>
<bodyText confidence="0.999261828571428">
SIMR builds bitext maps one chain at a time. The
search for each chain alternates between a genera-
tion phase and a recognition phase. The genera-
tion phase begins in a small rectangular region of
the bitext space, whose diagonal is parallel to the
main diagonal. Within this search rectangle, SIMR
generates all the points of correspondence that sat-
isfy the supplied matching predicate, as explained
in Section 3.1. In the recognition phase, SIMR
calls the chain recognition heuristic to find suitable
chains among the generated points. If no suitable
chains are found, the search rectangle is proportion-
ally expanded and the generation-recognition cycle
&apos;Since distances in the bitext space are measured in
characters, the position of a token is defined as the mean
position of its characters.
is repeated. The rectangle keeps expanding until at
least one acceptable chain is found. If more than
one chain is found in the same cycle, SIMR accepts
the one whose points are least dispersed around its
least-squares line. Each time SIMR accepts a chain,
it selects another region of the bitext space to search
for the next chain.
SIMR employs a simple heuristic to select regions
of the bitext space to search. To a first approxima-
tion, TBMs are monotonically increasing functions.
This means that if SIMR finds one chain, it should
look for others either above and to the right or below
and to the left of the one it has just found. All SIMR
needs is a place to start the trace. A good place to
start is at the beginning: Since the origin of the
bitext space is always a TPC, the first search rect-
angle is anchored at the origin. Subsequent search
rectangles are anchored at the top right corner of
the previously found chain, as shown in Figure 2.
</bodyText>
<listItem confidence="0.728896333333333">
• ous chain
•▪ • • •
.• prey
</listItem>
<figureCaption confidence="0.99369975">
Figure 2: SIMR &apos;s &amp;quot;expanding rectangle&amp;quot; search
strategy. The search rectangle is anchored at the top
right corner of the previously found chain. Its diag-
onal remains parallel to the main diagonal.
</figureCaption>
<bodyText confidence="0.999929111111111">
The expanding-rectangle search strategy makes
SIMR robust in the face of TBM discontinuities.
Figure 2 shows a segment of the TBM that contains
a vertical gap (an omission in the text on the x-axis).
As the search rectangle grows, it will eventually in-
tersect with the TBM, even if the discontinuity is
quite large (Melamed, 1996b). The noise filter de-
scribed in Section 3.3 prevents SIMR from being led
astray by false points of correspondence.
</bodyText>
<subsectionHeader confidence="0.998889">
3.1 Point Generation
</subsectionHeader>
<bodyText confidence="0.9979988">
SIMR generates candidate points of correspondence
in the search rectangle using one of its matching
predicates. A matching predicate is a heuristic
for deciding whether a given pair of tokens are likely
to be&apos;mutual translations. Two kinds of information
</bodyText>
<figure confidence="0.9925304">
x = character position in text 1
next
TPC chain
• discovered TPC
O undiscovered TPC
• noise
main
diagonal
search
frontier
</figure>
<page confidence="0.996749">
306
</page>
<bodyText confidence="0.996163">
that a matching predicate can rely on most often are
cognates and translation lexicons.
Two tokens in a bitext are cognates if they have
the same meaning and similar spellings. In the non-
technical Canadian Hansards (parliamentary debate
transcripts available in English and in French), cog-
nates can be found for roughly one quarter of all
text tokens (Melamed, 1995). Even distantly related
languages like English and Czech will share a large
number of cognates in the form of proper nouns.
Cognates are more common in bitexts from more
similar language pairs, and from text genres where
more word borrowing occurs, such as technical texts.
When dealing with language pairs that have dissim-
ilar alphabets, the matching predicate can employ
phonetic cognates (Melamed, 1996a). When one
or both of the languages involved is written in pic-
tographs, cognates can still be found among punc-
tuation and digit strings. However, cognates of this
last kind are usually too sparse to suffice by them-
selves.
When the matching predicate cannot generate
enough candidate correspondence points based on
cognates, its signal can be strengthened by a trans-
lation lexicon. Translation lexicons can be ex-
tracted from machine-readable bilingual dictionaries
(MRBDs), in the rare cases where MRBDs are avail-
able. In other cases, they can be constructed auto-
matically or semi-automatically using any of several
methods (Fung, 1995; Melamed, 1996c; Resnik Sz
Melamed, 1997). Since the matching predicate need
not be perfectly accurate, the translation lexicons
need not be either.
Matching predicates can take advantage of other
information, besides cognates and translation lexi-
cons can also be used. For example, a list of faux
amis is a useful complement to a cognate matching
strategy (Macklovitch, 1995). A stop list of function
words is also helpful. Function words are translated
inconsistently and make unreliable points of corre-
spondence (Melamed, 1996a).
</bodyText>
<subsectionHeader confidence="0.999832">
3.2 Point Selection
</subsectionHeader>
<bodyText confidence="0.999980333333333">
As illustrated in Figure 2, even short sequences of
TPCs form characteristic patterns. Most chains of
TPCs have the following properties:
</bodyText>
<listItem confidence="0.990036833333333">
• Linearity: TPCs tend to line up straight.
• Low Variance of Slope: The slope of a TPC
chain is rarely much different from the bitext
slope.
• Injectivity: No two points in a chain of TPCs
can have the same x— or y—co-ordinates.
</listItem>
<bodyText confidence="0.991358952380953">
SIMR&apos;s chain recognition heuristic exploits these
properties to decide which chains in the search rect-
angle might be TPC chains.
The heuristic involves three parameters: chain
size, maximum point dispersal and maximum
angle deviation. A chain&apos;s size is simply the num-
ber of points it contains. The heuristic considers
only chains of exactly the specified size whose points
are injective. The linearity of the these chains is
tested by measuring the root mean squared distance
of the chain&apos;s points from the chain&apos;s least-squares
line. If this distance exceeds the maximum point
dispersal threshold, the chain is rejected. Next, the
angle of each chain&apos;s least-squares line is compared
to the arctangent of the bitext slope. If the differ-
ence exceeds the maximum angle deviation thresh-
old, the chain is rejected. These filters can be effi-
ciently combined so that SIMR&apos;s expected running
time and memory requirements are linear in the size
of the input bitext (Melamed, 1996a).
The chain recognition heuristic pays no attention
to whether chains are monotonic. Non-monotonic
TPC chains are quite common, because even lan-
guages with similar syntax like French and English
have well-known differences in word order. For ex-
ample, English (adjective, noun) pairs usually corre-
spond to French (noun, adjective) pairs. Such inver-
sions result in TPCs arranged like the middle two
points in the &amp;quot;previous chain&amp;quot; of Figure 2. SIMR
has no problem accepting the inverted points.
If the order of words in a certain text passage is
radically altered during translation, SIMR will sim-
ply ignore the words that &amp;quot;move too much&amp;quot; and con-
struct chains out of those that remain more station-
ary. The maximum point dispersal parameter lim-
its the width of accepted chains, but nothing lim-
its their length. In practice, the chain recognition
heuristic often accepts chains that span several sen-
tences. The ability to analyze non-monotonic points
of correspondence over variable-size areas of bitext
space makes SIMR robust enough to use on transla-
tions that are not very literal.
</bodyText>
<subsectionHeader confidence="0.999321">
3.3 Noise Filter
</subsectionHeader>
<bodyText confidence="0.999258">
Points of correspondence among frequent token
types often line up in rows and columns, as illus-
trated in Figure 3. Token types like the English
article &amp;quot;a&amp;quot; can produce one or more correspondence
points for almost every sentence in the opposite text.
Only one point of correspondence in each row and
column can be correct; the rest are noise. A noise fil-
ter can make it easier for SIMR to find TPC chains.
Other bitext mapping algorithms mitigate this
source of noise either by assigning lower weights to
</bodyText>
<page confidence="0.959971">
307
</page>
<figure confidence="0.998097230769231">
a • • • •
a •
a • • • •
a
a
a
a •
a a
French text
false
chain
anchor
off track&apos;
</figure>
<figureCaption confidence="0.995621833333333">
Figure 4: SIMR&apos;s noise filter ensures that TPCs
are much more dense than false points of correspon-
dence. A good signal-to-noise ratio prevents SIMR
from getting lost.
Figure 3: Frequent tokens cause false points of cor-
respondence that line up in rows and columns.
</figureCaption>
<bodyText confidence="0.999837447368421">
correspondence points associated with frequent to-
ken types (Church, 1993) or by deleting frequent to-
ken types from the bitext altogether (Dagan et al.,
1993). However, a token type that is relatively fre-
quent overall can be rare in some parts of the text.
In those parts, the token type can provide valuable
clues to correspondence. On the other hand, many
tokens of a relatively rare type can be concentrated
in a short segment of the text, resulting in many
false correspondence points. The varying concentra-
tion of identical tokens suggests that more localized
noise filters would be more effective. SIMR&apos;s local-
ized search strategy provides a vehicle for a localized
noise filter.
The filter is based on the maximum point am-
biguity level parameter. For each point p = (x, y),
let X be the number of points in column x within
the search rectangle, and let Y be the number of
points in row y within the search rectangle. Then
the ambiguity level of p is X + Y - 2. In partic-
ular, if p is the only point in its row and column,
then its ambiguity level is zero. The chain recogni-
tion heuristic ignores points whose ambiguity level is
too high. What makes this a localized filter is that
only points within the search rectangle count toward
each other&apos;s ambiguity level. The ambiguity level of
a given point can change when the search rectangle
expands or moves.
The noise filter ensures that false points of corre-
spondence are very sparse, as illustrated in Figure 4.
Even if one chain of false points of correspondence
slips by the chain recognition heuristic, the expand-
ing rectangle will find its way back to the TBM be-
fore the chain recognition heuristic accepts another
chain. If the matching predicate generates a reason-
ably strong signal then the signal-to-noise ratio will
be high and SIMR will not get lost, even though it
is a greedy algorithm with no ability to look ahead.
</bodyText>
<sectionHeader confidence="0.635215" genericHeader="method">
4 Porting to New Language Pairs
</sectionHeader>
<bodyText confidence="0.8366015">
SIMR can be ported to a new language pair in three
steps.
</bodyText>
<subsectionHeader confidence="0.964403">
4.1 Step 1: Construct Matching Predicate
</subsectionHeader>
<bodyText confidence="0.999754">
The original SIMR implementation for
French/English included matching predicates that
could use cognates and/or translation lexicons. For
language pairs in which lexical cognates are frequent,
a cognate-based matching predicate should suffice.
In other cases, a &amp;quot;seed&amp;quot; translation lexicon may be
used to boost the number of candidate points pro-
duced in the generation phase of the search. The
SIMR implementation for Spanish/English uses only
cognates. For Korean/English, SIMR takes advan-
tage of punctuation and number cognates but sup-
plements them with a small translation lexicon.
</bodyText>
<subsectionHeader confidence="0.98521">
4.2 Step 2: Construct Axis Generators
</subsectionHeader>
<bodyText confidence="0.999801727272727">
In order for SIMR to generate candidate points of
correspondence, it needs to know what token pairs
correspond to co-ordinates in the search rectangle.
It is the axis generator&apos;s job to map the two halves
of the bitext to positions on the x- and y-axes of
the bitext space, before SIMR starts searching for
chains. This mapping should be done with the
matching predicate in mind.
If the matching predicate uses cognates, then ev-
ery word that might have a cognate in the other
half of the bitext should be assigned its own axis
</bodyText>
<page confidence="0.995335">
308
</page>
<bodyText confidence="0.99997925">
position. This rule applies to punctuation and num-
bers as well as to &amp;quot;lexical&amp;quot; cognates. In the case of-
lexical cognates, the axis generator typically needs
to invoke a language-specific tokenization program
to identify words in the text. Writing such a pro-
gram may constitute a significant part of the port-
ing effort, if no such program is available in advance.
The effort may be lessened, however, by the realiza-
tion that it is acceptable for the tokenization pro-
gram to overgenerate just as it is acceptable for the
matching predicate. For example, when tokenizing
German text, it is not necessary for the tokenizer
to know which words are compounds. A word that
has another word as a substring should result in one
axis position for the substring and one for the su-
perstring.
When lexical cognates are not being used, the axis
generator only needs to identify punctuation, num-
bers, and those character strings in the text which
also appear on the relevant side of the translation
lexicon&apos;. It would be pointless to plot other words
on the axes because the matching predicate could
never match them anyway. Therefore, for languages
like Chinese and Japanese, which are written with-
out spaces between words, tokenization boils down
to string matching. In this manner, SIMR circum-
vents the difficult problem of word identification in
these languages.
</bodyText>
<subsectionHeader confidence="0.984763">
4.3 Step 3: Re-optimize Parameters
</subsectionHeader>
<bodyText confidence="0.978230216216216">
The last step in the porting process is to re-optimize
SIMR&apos;s numerical parameters. The four parameters
described in Section 3 interact in complicated ways,
and it is impossible to find a good parameter set
analytically. It is easier to optimize these parameters
empirically, using simulated annealing (Vidal, 1993).
Simulated annealing requires an objective func-
tion to optimize. The objective function for bitext
mapping should measure the difference between the
TBM and maps produced with the current parame-
ter set. In geometric terms, the difference is a dis-
tance. The TBM consists of a set of TPCs. The
error between a bitext map and each TPC can be
defined as the horizontal distance, the vertical dis-
tance, or the distance perpendicular to the main di-
agonal. The first two alternatives would minimize
the error with respect to only one language or the
other. The perpendicular distance is a more robust
average. In order to penalize large errors more heav-
ily, root mean squared (RMS) distance is minimized
instead of mean distance.
3Multi-word expressions in the translation lexicon are
treated just like any other character string.
The most tedious part of the porting process is the
construction of TBMs against which SIMR&apos;s param-
eters can be optimized and tested. The easiest way
to construct these gold standards is to extract them
from pairs of hand-aligned text segments: The final
character positions of each segment in an aligned
pair are the co-ordinates of a TPC. Over the course
of two porting efforts, I have develojted and refined
tools and methods that allow a bilingual annota-
tor to construct the required TBMs very efficiently
from a raw bitext. For example, a tool originally de-
signed for automatic detection of omissions in trans-
lations (Melamed, 1996b) was adopted to detect mis-
alignments.
</bodyText>
<subsectionHeader confidence="0.995337">
4.4 Porting Experience Summary
</subsectionHeader>
<bodyText confidence="0.999965857142857">
Table 1 summarizes the amount of time invested
in each new language pair. The estimated times
for building axis generators do not include the time
spent to build the English axis generator, which was
part of the original implementation. Axis generators
need to be built only once per language, rather than
once per language pair.
</bodyText>
<sectionHeader confidence="0.99223" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999950827586207">
SIMR was evaluated on hand-aligned bitexts of vari-
ous genres in three language pairs. None of these test
bitexts were used anywhere in the training or port-
ing procedures. Each test bitext was converted to a
set of TPCs by noting the pair of character positions
at the end of each aligned pair of text segments. The
test metric was the root mean squared distance, in
characters, between each TPC and the interpolated
bitext map produced by SIMR, where the distance
was measured perpendicular to the main diagonal.
The results are presented in Table 2.
The French/English part of the evaluation was
performed on bitexts from the publicly available
BAF corpus created at CITI (Simard (gz Plamon-
don, 1996). SIMR&apos;s error distribution on the &amp;quot;parlia-
mentary debates&amp;quot; bitext in this collection is given in
Table 3. This distribution can be compared to error
distributions reported in (Church, 1993) and in (Da-
gan et al., 1993). SIMR&apos;s RMS error on this bitext
was 5.7 characters. Church&apos;s char_align algorithm
(Church, 1993) is the only algorithm that does not
use sentence boundary information for which com-
parable results have been reported. char_align&apos;s
RMS error on this bitext was 57 characters, exactly
ten times higher.
Two teams of researchers have reported results
on the same &amp;quot;parliamentary debates&amp;quot; bitext for al-
gorithms that map correspondence at the sentence
level (Gale &amp; Church, 1991a; Simard et al., 1992).
</bodyText>
<page confidence="0.999349">
309
</page>
<tableCaption confidence="0.999877">
Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs.
</tableCaption>
<table confidence="0.98949">
language pair main informant for estimated time estimated time number of
matching predicate spent to build spent on segments
new axis generator hand-alignment aligned
Spanish/English lexical cognates 8 h 5 h 1338
Korean/English translation lexicon 6 h 12 h 1224
</table>
<tableCaption confidence="0.972057">
Table 2: SIMR accuracy on different text genres in three language pairs.
</tableCaption>
<table confidence="0.986310727272727">
language number of genre number of RMS Error
pair training TPCs test TPCs in characters
French / English 598 parliamentary debates 7123 5.7
CITI technical reports 365, 305, 176 4.4, 2.6, 9.9
other technical reports 561, 1393 20.6, 14.2
court transcripts 1377 3.9
U.N. annual report 2049 12.36
I.L.O. report 7129 6.42
Spanish / English 562 software manuals 376, 151, 100, 349 4.7, 1.3, 6.6, 4.9
Korean / English 615 military manuals 40, 88, 186, 299 2.6, 7.1, 25, 7.8
military messages 192 0.53
</table>
<tableCaption confidence="0.919624833333333">
Both of these algorithms use sentence boundary
information. Melamed (1996a) showed that sen-
tence boundary information can be used to convert
Table 3: SIMR&apos;s error distribution on the SIMR&apos;s output into sentence alignments that are
French/English &amp;quot;parliamentary debates&amp;quot; bitext. more accurate than those obtained by either of the
other two approaches.
</tableCaption>
<bodyText confidence="0.998926909090909">
The test bitexts in the other two language pairs
were created when SIMR was being ported to those
languages. The Spanish/English bitexts were drawn
from the on-line Sun MicroSystems Solaris An-
swerBooks. The Korean/English bitexts were pro-
vided and hand-aligned by Young-Suk Lee of MIT&apos;s
Lincoln Laboratories. Although it is not possible
to compare SIMR&apos;s performance on these language
pairs to the performance of other algorithms, Table 2
shows that the performance on other language pairs
is no worse than performance on French/English.
</bodyText>
<sectionHeader confidence="0.669566" genericHeader="method">
6 Which Text Units to Map?
</sectionHeader>
<tableCaption confidence="0.757716636363637">
Early bitext mapping algorithms focused on sen-
tences (Kay &amp; Roscheisen, 1993; Debili &amp; Sam-
mouda, 1992). Although sentence maps do not have
sufficient resolution for some important bitext appli-
cations (Melamed, 1996b; Macklovitch, 1995), sen-
tences were an easy starting point, because their
order rarely changes during translation. Therefore,
sentence mapping algorithms need not worry about
crossing correspondences. In 1991, two teams of re-
searchers independently discovered that sentences
can be accurately aligned by matching sequences
</tableCaption>
<figure confidence="0.9251655">
number of error range fraction of
test points in characters test points
1 -101 .0001
2 -80 to -70 .0003
1 -70 to -60 .0001
5 -60 to -50 .0007
4 -50 to -40 .0006
6 -40 to -30 .0008
9 -30 to -20 .0013
29 -20 to -10 .0041
3057 -10 to 0 .4292
3902 0 to 10 .5478
43 10 to 20 .0060
28 20 to 30 .0039
17 30 to 40 .0024
5 40 to 50 .0007
8 50 to 60 .0011
1 60 to 70 .0001
1 70 to 80 .0001
1 80 to 90 .0001
1 90 to 100 .0001
1 110 to 120 .0001
1 185 .0001
7123 1.000
</figure>
<page confidence="0.995636">
310
</page>
<bodyText confidence="0.99997468292683">
with similar lengths (Gale &amp; Church, 1991a; Brown
et al., 1991).
Soon thereafter, Church (1993) found that bitext
mapping at the sentence level is not an option for
noisy bitexts found in the real world. Sentences
are often difficult to detect, especially where punc-
tuation is missing due to OCR errors. More im-
portantly, bitexts often contain lists, tables, titles,
footnotes, citations and/or mark-up codes that foil
sentence alignment methods. Church&apos;s solution was
to look at the smallest of text units — characters
— and to use digital signal processing techniques
to grapple with the much larger number of text
units that might match between the two halves of
a bitext. Characters match across languages only to
the extent that they participate in cognates. Thus,
Church&apos;s method is only applicable to language pairs
with similar alphabets.
The main insight of the present work is that words
are a happy medium-sized text unit at which to map
bitext correspondence. By situating word positions
in a bitext space, the geometric heuristics of sen-
tence alignment algorithms can be exploited equally
well at the word level. The cognate heuristic of
the character-based algorithms works better at the
word level, because cognateness can be defined more
precisely in terms of words, e.g. using the Longest
Common Subsequence Ratio (Melamed, 1995). Sev-
eral other matching heuristics can only be applied
at the word level, including the localized noise filter
in Section 3.3, lists of stop words and lists of faux
amis (Macklovitch, 1995). Most importantly, trans-
lation lexicons can only be used at the word level.
SIMR can employ a small hand-constructed transla-
tion lexicon to map bitexts in any pair of languages,
even when the cognate heuristic is not applicable and
sentences cannot be found. The particular combina-
tion of heuristics described in Section 3 can certainly
be improved on, but research into better bitext map-
ping algorithms is likely to be most fruitfull at the
word level.
</bodyText>
<sectionHeader confidence="0.996951" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999860391304348">
The Smooth Injective Map Recognizer (SIMR)
bitext mapping algorithm advances the state of the
art on several frontiers. It is significantly more ac-
curate than other algorithms in the literature. Its
expected running time and memory requirements
are linear in the size of the input, which makes
it the algorithm of choice for very large bitexts.
It is not fazed by word order differences. It does
not rely on pre-segmented input and is portable to
any pair of languages with a minimal effort. These
features make SIMR the mostly widely applicable
bitext mapping algorithm to date.
SIMR opens up several new avenues of research.
One important application of bitext maps is the con-
struction of translation lexicons (Dagan et al., 1993)
and, as discussed, translation lexicons are an impor-
tant information source for bitext mapping. It is
likely that the accuracy of both kinds of algorithms
can be improved by alternating between the two on
the same bitext. There are also plans to build an
automatic bitext locating spider for the World Wide
Web, so that SIMR can be applied to more new lan-
guage pairs and bitext genres.
</bodyText>
<sectionHeader confidence="0.989966" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999565625">
SIMR was ported to Spanish/English while I was
visiting Sun MicroSystems Laboratories. Thanks
to Gary Adams, Cookie Callahan, Bob Kuhns and
Philip Resnik for their help with that project.
Thanks also to Philip Resnik for writing the Spanish
tokenizer, and hand-aligning the Spanish/English
training bitexts. Porting SIMR to Korean/English
would not have been possible without Young-Suk
Lee of MIT&apos;s Lincoln Laboratories, who provided the
seed translation lexicon, and aligned all the training
and test bitexts. This paper was much improved
by helpful comments from Mitch Marcus, Adwait
Ratnaparkhi, Bonnie Webber and three anonymous
reviewers. This research was supported by an equip-
ment grant from Sun MicroSystems and by ARPA
Contract #N66001-94C-6043.
</bodyText>
<sectionHeader confidence="0.997297" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998720277777778">
P. F. Brown, J. C. Lai &amp; R. L. Mercer, &amp;quot;Aligning
Sentences in Parallel Corpora,&amp;quot; Proceedings of the
29th Annual Meeting of the Association for Com-
putational Linguistics, Berkeley, CA, 1991.
P. F. Brown, S. Della Pietra, V. Della Pietra,
R. Mercer, &amp;quot;The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation&amp;quot;, Com-
putational Linguistics 19:2, 1993.
R. Catizone, G. Russell &amp; S. Warwick &amp;quot;Deriving
Translation Data from Bilingual Texts,&amp;quot; Proceed-
ings of the First International Lexical Acquisition
Workshop, Detroit, MI, 1993.
S. Chen, &amp;quot;Aligning Sentences in Bilingual Corpora
Using Lexical Information,&amp;quot; Proceedings of the
31st Annual Meeting of the Association for Com-
putational Linguistics, Columbus, OH, 1993.
K. W. Church, &amp;quot;Char_align: A Program for Align-
ing Parallel Texts at the Character Level,&amp;quot; Pro-
</reference>
<page confidence="0.984714">
311
</page>
<reference confidence="0.999714556818182">
ceedings of the 31st Annual Meeting of the Asso-
ciation for Computational Linguistics, Columbus,
OH, 1993.
I. Dagan, K. Church, &amp; W. Gale, &amp;quot;Robust Word
Alignment for Machine Aided Translation,&amp;quot; Pro-
ceedings of the Workshop on Very Large Corpora:
Academic and Industrial Perspectives, Columbus,
OH, 1993.
F. Debili &amp; E. Sammouda &amp;quot;Appariement des Phrases
de Textes Bilingues,&amp;quot; Proceedings of the 14th
International Conference on Computational Lin-
guistics, Nantes, France, 1992.
G. Foster, P. Isabelle &amp; P. Plamondon, &amp;quot;Word Com-
pletion: A First Step Toward Target-Text Medi-
ated IMT,&amp;quot; Proceedings of the 16th International
Conference on Computational Linguistics, Copen-
hagen, Denmark, 1996.
P. Fung, &amp;quot;Compiling Bilingual Lexicon Entries from
a Non-Parallel English-Chinese Corpus,&amp;quot; Proceed-
ings of the Third Workshop on Very Large Cor-
pora, Boston, MA, 1995.
W. Gale &amp; K. W. Church, &amp;quot;A Program for Aligning
Sentences in Bilingual Corpora,&amp;quot; Proceedings of
the 29th Annual Meeting of the Association for
Computational Linguistics, Berkeley, CA, 1991a.
W. Gale &amp; K. W. Church, &amp;quot;Identifying Word Corre-
spondences in Parallel Texts,&amp;quot; Proceedings of the
DARPA SNL Workshop, 1991b.
B. Harris, &apos;Bi-Text, a New Concept in Translation
Theory,&amp;quot; Language Monthly #54, 1988.
M. Kay &amp; M. Roscheisen &amp;quot;Text-Translation Align-
ment,&amp;quot; Computational Linguistics 19:1, 1993.
E. Macklovitch, &amp;quot;Peut-on verifier automatiquement
la coherence terminologique?&amp;quot; Proceedings of the
IV&amp;quot; Journees scientifiques, Lexicommatique et
Dictionnairiques, organized by AUPELF-UREF,
Lyon, France, 1995.
I. D. Melamed &amp;quot;Automatic Evaluation and Uniform
Filter Cascades for Inducing N-best Translation
Lexicons,&amp;quot; Proceedings of the Third Workshop on
Very Large Corpora, Boston, MA, 1995.
I. D. Melamed, &amp;quot;A Geometric Approach to Mapping
Bitext Correspondence,&amp;quot; Proceedings of the First
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP&apos;96), Philadelphia, PA,
1996a.
I. D. Melamed &amp;quot;Automatic Detection of Omissions
in Translations,&amp;quot; Proceedings of the 16th Interna-
tional Conference on Computational Linguistics,
Copenhagen, Denmark, 1996b.
I. D. Melamed, &amp;quot;Automatic Construction of Clean
Broad-Coverage Translation Lexicons,&amp;quot; Proceed-
ings of the Conference of the Association for
Machine Translation in the Americas, Montreal,
Canada, 1996c.
I. D. Melamed, &amp;quot;A Word-to-Word Model of Transla-
tional Equivalence,&amp;quot; Proceedings of the 35th Con-
ference of the Association for Computational Lin-
guistics, Madrid, Spain, 1997. (in this volume)
P. Resnik &amp; I. D. Melamed, &amp;quot;Semi-Automatic Acqui-
sition of Domain-Specific Translation Lexicons,&amp;quot;
Proceedings of the 7th ACL Conference on Ap-
plied Natural Language Processing, Washington,
DC, 1997.
P. Resnik, &amp;quot;Evaluating Multilingual Gisting of Web
Pages,&amp;quot; UMIACS-TR-97-39, University of Mary-
land, 1997.
S. Sato &amp; M. Nagao, &amp;quot;Toward Memory-Based Trans-
lation,&amp;quot; Proceedings of the 13th International
Conference on Computational Linguistics, 1990.
S. Sato, &amp;quot;CTM: An Example-Based Translation
Aid System,&amp;quot; Proceedings of the 14th Interna-
tional Conference on Computational Linguistics,
Nantes, France, 1992.
SIGIR Workshop on Cross-linguistic Multilingual
Information Retrieval, Zurich, 1996.
M. Simard, G. F. Foster &amp; P. Isabelle, &amp;quot;Using Cog-
nates to Align Sentences in Bilingual Corpora,&amp;quot;
in Proceedings of the Fourth International Con-
ference on Theoretical and Methodological Issues
in Machine Translation, Montreal, Canada, 1992.
M. Simard &amp; P. Plamondon, &amp;quot;Bilingual Sentence
Alignment: Balancing Robustness and Accuracy,&amp;quot;
Proceedings of the Conference of the Association
for Machine Translation in the Americas, Mon-
treal, Canada, 1996.
R. V. V. Vidal, Applied Simulated Annealing,
Springer-Verlag, Heidelberg, Germany, 1993.
</reference>
<page confidence="0.998666">
312
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.983330">
<title confidence="0.999277">A Portable Algorithm for Mapping Bitext Correspondence</title>
<author confidence="0.999888">I Dan Melamed</author>
<affiliation confidence="0.999904">Dept. of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.997749">Philadelphia, PA, 19104, U.S.A.</address>
<email confidence="0.999817">melamed@unagi.cis.upenn.edu</email>
<abstract confidence="0.999253777777778">The first step in most empirical work in multilingual NLP is to construct maps of the correspondence between texts and their maps). Smooth Injective Map Recognizer (SIMR) algorithm presented here is a generic pattern recognition algorithm that is particularly well-suited to mapping bitext correspondence. SIMR is faster and significantly more accurate than other algorithms in the literature. The algorithm is robust enough to use on noisy texts, such as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora,&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Berkeley, CA,</location>
<contexts>
<context position="23568" citStr="Brown et al., 1991" startWordPosition="3924" endWordPosition="3927">rchers independently discovered that sentences can be accurately aligned by matching sequences number of error range fraction of test points in characters test points 1 -101 .0001 2 -80 to -70 .0003 1 -70 to -60 .0001 5 -60 to -50 .0007 4 -50 to -40 .0006 6 -40 to -30 .0008 9 -30 to -20 .0013 29 -20 to -10 .0041 3057 -10 to 0 .4292 3902 0 to 10 .5478 43 10 to 20 .0060 28 20 to 30 .0039 17 30 to 40 .0024 5 40 to 50 .0007 8 50 to 60 .0011 1 60 to 70 .0001 1 70 to 80 .0001 1 80 to 90 .0001 1 90 to 100 .0001 1 110 to 120 .0001 1 185 .0001 7123 1.000 310 with similar lengths (Gale &amp; Church, 1991a; Brown et al., 1991). Soon thereafter, Church (1993) found that bitext mapping at the sentence level is not an option for noisy bitexts found in the real world. Sentences are often difficult to detect, especially where punctuation is missing due to OCR errors. More importantly, bitexts often contain lists, tables, titles, footnotes, citations and/or mark-up codes that foil sentence alignment methods. Church&apos;s solution was to look at the smallest of text units — characters — and to use digital signal processing techniques to grapple with the much larger number of text units that might match between the two halves </context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>P. F. Brown, J. C. Lai &amp; R. L. Mercer, &amp;quot;Aligning Sentences in Parallel Corpora,&amp;quot; Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, CA, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation&amp;quot;,</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context position="1187" citStr="Brown et al., 1993" startWordPosition="176" endWordPosition="179">ly more accurate than other algorithms in the literature. The algorithm is robust enough to use on noisy texts, such as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of litt</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. Della Pietra, V. Della Pietra, R. Mercer, &amp;quot;The Mathematics of Statistical Machine Translation: Parameter Estimation&amp;quot;, Computational Linguistics 19:2, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Catizone</author>
<author>G Russell</author>
<author>S Warwick</author>
</authors>
<title>Deriving Translation Data from Bilingual Texts,&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the First International Lexical Acquisition Workshop,</booktitle>
<location>Detroit, MI,</location>
<contexts>
<context position="1535" citStr="Catizone et al., 1993" startWordPosition="228" endWordPosition="231"> are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in versions. It should be applicab</context>
</contexts>
<marker>Catizone, Russell, Warwick, 1993</marker>
<rawString>R. Catizone, G. Russell &amp; S. Warwick &amp;quot;Deriving Translation Data from Bilingual Texts,&amp;quot; Proceedings of the First International Lexical Acquisition Workshop, Detroit, MI, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chen</author>
</authors>
<title>Aligning Sentences in Bilingual Corpora Using Lexical Information,&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Columbus, OH,</location>
<marker>Chen, 1993</marker>
<rawString>S. Chen, &amp;quot;Aligning Sentences in Bilingual Corpora Using Lexical Information,&amp;quot; Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, Columbus, OH, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>Char_align: A Program for Aligning Parallel Texts at the Character Level,&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Columbus, OH,</location>
<contexts>
<context position="12607" citStr="Church, 1993" startWordPosition="2082" endWordPosition="2083"> correct; the rest are noise. A noise filter can make it easier for SIMR to find TPC chains. Other bitext mapping algorithms mitigate this source of noise either by assigning lower weights to 307 a • • • • a • a • • • • a a a a • a a French text false chain anchor off track&apos; Figure 4: SIMR&apos;s noise filter ensures that TPCs are much more dense than false points of correspondence. A good signal-to-noise ratio prevents SIMR from getting lost. Figure 3: Frequent tokens cause false points of correspondence that line up in rows and columns. correspondence points associated with frequent token types (Church, 1993) or by deleting frequent token types from the bitext altogether (Dagan et al., 1993). However, a token type that is relatively frequent overall can be rare in some parts of the text. In those parts, the token type can provide valuable clues to correspondence. On the other hand, many tokens of a relatively rare type can be concentrated in a short segment of the text, resulting in many false correspondence points. The varying concentration of identical tokens suggests that more localized noise filters would be more effective. SIMR&apos;s localized search strategy provides a vehicle for a localized no</context>
<context position="20169" citStr="Church, 1993" startWordPosition="3350" endWordPosition="3351">ch aligned pair of text segments. The test metric was the root mean squared distance, in characters, between each TPC and the interpolated bitext map produced by SIMR, where the distance was measured perpendicular to the main diagonal. The results are presented in Table 2. The French/English part of the evaluation was performed on bitexts from the publicly available BAF corpus created at CITI (Simard (gz Plamondon, 1996). SIMR&apos;s error distribution on the &amp;quot;parliamentary debates&amp;quot; bitext in this collection is given in Table 3. This distribution can be compared to error distributions reported in (Church, 1993) and in (Dagan et al., 1993). SIMR&apos;s RMS error on this bitext was 5.7 characters. Church&apos;s char_align algorithm (Church, 1993) is the only algorithm that does not use sentence boundary information for which comparable results have been reported. char_align&apos;s RMS error on this bitext was 57 characters, exactly ten times higher. Two teams of researchers have reported results on the same &amp;quot;parliamentary debates&amp;quot; bitext for algorithms that map correspondence at the sentence level (Gale &amp; Church, 1991a; Simard et al., 1992). 309 Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs. language </context>
<context position="23600" citStr="Church (1993)" startWordPosition="3930" endWordPosition="3931">entences can be accurately aligned by matching sequences number of error range fraction of test points in characters test points 1 -101 .0001 2 -80 to -70 .0003 1 -70 to -60 .0001 5 -60 to -50 .0007 4 -50 to -40 .0006 6 -40 to -30 .0008 9 -30 to -20 .0013 29 -20 to -10 .0041 3057 -10 to 0 .4292 3902 0 to 10 .5478 43 10 to 20 .0060 28 20 to 30 .0039 17 30 to 40 .0024 5 40 to 50 .0007 8 50 to 60 .0011 1 60 to 70 .0001 1 70 to 80 .0001 1 80 to 90 .0001 1 90 to 100 .0001 1 110 to 120 .0001 1 185 .0001 7123 1.000 310 with similar lengths (Gale &amp; Church, 1991a; Brown et al., 1991). Soon thereafter, Church (1993) found that bitext mapping at the sentence level is not an option for noisy bitexts found in the real world. Sentences are often difficult to detect, especially where punctuation is missing due to OCR errors. More importantly, bitexts often contain lists, tables, titles, footnotes, citations and/or mark-up codes that foil sentence alignment methods. Church&apos;s solution was to look at the smallest of text units — characters — and to use digital signal processing techniques to grapple with the much larger number of text units that might match between the two halves of a bitext. Characters match ac</context>
</contexts>
<marker>Church, 1993</marker>
<rawString>K. W. Church, &amp;quot;Char_align: A Program for Aligning Parallel Texts at the Character Level,&amp;quot; Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, Columbus, OH, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>K Church</author>
<author>W Gale</author>
</authors>
<title>Robust Word Alignment for Machine Aided Translation,&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<location>Columbus, OH,</location>
<contexts>
<context position="12691" citStr="Dagan et al., 1993" startWordPosition="2095" endWordPosition="2098">nd TPC chains. Other bitext mapping algorithms mitigate this source of noise either by assigning lower weights to 307 a • • • • a • a • • • • a a a a • a a French text false chain anchor off track&apos; Figure 4: SIMR&apos;s noise filter ensures that TPCs are much more dense than false points of correspondence. A good signal-to-noise ratio prevents SIMR from getting lost. Figure 3: Frequent tokens cause false points of correspondence that line up in rows and columns. correspondence points associated with frequent token types (Church, 1993) or by deleting frequent token types from the bitext altogether (Dagan et al., 1993). However, a token type that is relatively frequent overall can be rare in some parts of the text. In those parts, the token type can provide valuable clues to correspondence. On the other hand, many tokens of a relatively rare type can be concentrated in a short segment of the text, resulting in many false correspondence points. The varying concentration of identical tokens suggests that more localized noise filters would be more effective. SIMR&apos;s localized search strategy provides a vehicle for a localized noise filter. The filter is based on the maximum point ambiguity level parameter. For </context>
<context position="20197" citStr="Dagan et al., 1993" startWordPosition="3354" endWordPosition="3358">t segments. The test metric was the root mean squared distance, in characters, between each TPC and the interpolated bitext map produced by SIMR, where the distance was measured perpendicular to the main diagonal. The results are presented in Table 2. The French/English part of the evaluation was performed on bitexts from the publicly available BAF corpus created at CITI (Simard (gz Plamondon, 1996). SIMR&apos;s error distribution on the &amp;quot;parliamentary debates&amp;quot; bitext in this collection is given in Table 3. This distribution can be compared to error distributions reported in (Church, 1993) and in (Dagan et al., 1993). SIMR&apos;s RMS error on this bitext was 5.7 characters. Church&apos;s char_align algorithm (Church, 1993) is the only algorithm that does not use sentence boundary information for which comparable results have been reported. char_align&apos;s RMS error on this bitext was 57 characters, exactly ten times higher. Two teams of researchers have reported results on the same &amp;quot;parliamentary debates&amp;quot; bitext for algorithms that map correspondence at the sentence level (Gale &amp; Church, 1991a; Simard et al., 1992). 309 Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs. language pair main informant for esti</context>
<context position="26241" citStr="Dagan et al., 1993" startWordPosition="4360" endWordPosition="4363">tiers. It is significantly more accurate than other algorithms in the literature. Its expected running time and memory requirements are linear in the size of the input, which makes it the algorithm of choice for very large bitexts. It is not fazed by word order differences. It does not rely on pre-segmented input and is portable to any pair of languages with a minimal effort. These features make SIMR the mostly widely applicable bitext mapping algorithm to date. SIMR opens up several new avenues of research. One important application of bitext maps is the construction of translation lexicons (Dagan et al., 1993) and, as discussed, translation lexicons are an important information source for bitext mapping. It is likely that the accuracy of both kinds of algorithms can be improved by alternating between the two on the same bitext. There are also plans to build an automatic bitext locating spider for the World Wide Web, so that SIMR can be applied to more new language pairs and bitext genres. Acknowledgements SIMR was ported to Spanish/English while I was visiting Sun MicroSystems Laboratories. Thanks to Gary Adams, Cookie Callahan, Bob Kuhns and Philip Resnik for their help with that project. Thanks a</context>
</contexts>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>I. Dagan, K. Church, &amp; W. Gale, &amp;quot;Robust Word Alignment for Machine Aided Translation,&amp;quot; Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, Columbus, OH, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Debili</author>
<author>E</author>
</authors>
<title>Sammouda &amp;quot;Appariement des Phrases de Textes Bilingues,&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics,</booktitle>
<location>Nantes,</location>
<marker>Debili, E, 1992</marker>
<rawString>F. Debili &amp; E. Sammouda &amp;quot;Appariement des Phrases de Textes Bilingues,&amp;quot; Proceedings of the 14th International Conference on Computational Linguistics, Nantes, France, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Word Completion: A First Step Toward Target-Text Mediated IMT,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<location>Copenhagen,</location>
<contexts>
<context position="1303" citStr="Foster et al., 1996" startWordPosition="193" endWordPosition="196">ch as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units betwe</context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1996</marker>
<rawString>G. Foster, P. Isabelle &amp; P. Plamondon, &amp;quot;Word Completion: A First Step Toward Target-Text Mediated IMT,&amp;quot; Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen, Denmark, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>Compiling Bilingual Lexicon Entries from a Non-Parallel English-Chinese Corpus,&amp;quot;</title>
<date>1995</date>
<booktitle>Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<location>Boston, MA,</location>
<contexts>
<context position="8689" citStr="Fung, 1995" startWordPosition="1430" endWordPosition="1431">e languages involved is written in pictographs, cognates can still be found among punctuation and digit strings. However, cognates of this last kind are usually too sparse to suffice by themselves. When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a translation lexicon. Translation lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in the rare cases where MRBDs are available. In other cases, they can be constructed automatically or semi-automatically using any of several methods (Fung, 1995; Melamed, 1996c; Resnik Sz Melamed, 1997). Since the matching predicate need not be perfectly accurate, the translation lexicons need not be either. Matching predicates can take advantage of other information, besides cognates and translation lexicons can also be used. For example, a list of faux amis is a useful complement to a cognate matching strategy (Macklovitch, 1995). A stop list of function words is also helpful. Function words are translated inconsistently and make unreliable points of correspondence (Melamed, 1996a). 3.2 Point Selection As illustrated in Figure 2, even short sequenc</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>P. Fung, &amp;quot;Compiling Bilingual Lexicon Entries from a Non-Parallel English-Chinese Corpus,&amp;quot; Proceedings of the Third Workshop on Very Large Corpora, Boston, MA, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora,&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Berkeley, CA,</location>
<contexts>
<context position="1556" citStr="Gale &amp; Church, 1991" startWordPosition="232" endWordPosition="235">anguages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in versions. It should be applicable to any text genre </context>
<context position="20669" citStr="Gale &amp; Church, 1991" startWordPosition="3428" endWordPosition="3431">his collection is given in Table 3. This distribution can be compared to error distributions reported in (Church, 1993) and in (Dagan et al., 1993). SIMR&apos;s RMS error on this bitext was 5.7 characters. Church&apos;s char_align algorithm (Church, 1993) is the only algorithm that does not use sentence boundary information for which comparable results have been reported. char_align&apos;s RMS error on this bitext was 57 characters, exactly ten times higher. Two teams of researchers have reported results on the same &amp;quot;parliamentary debates&amp;quot; bitext for algorithms that map correspondence at the sentence level (Gale &amp; Church, 1991a; Simard et al., 1992). 309 Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs. language pair main informant for estimated time estimated time number of matching predicate spent to build spent on segments new axis generator hand-alignment aligned Spanish/English lexical cognates 8 h 5 h 1338 Korean/English translation lexicon 6 h 12 h 1224 Table 2: SIMR accuracy on different text genres in three language pairs. language number of genre number of RMS Error pair training TPCs test TPCs in characters French / English 598 parliamentary debates 7123 5.7 CITI technical reports 365, 305, 1</context>
<context position="23546" citStr="Gale &amp; Church, 1991" startWordPosition="3920" endWordPosition="3923">91, two teams of researchers independently discovered that sentences can be accurately aligned by matching sequences number of error range fraction of test points in characters test points 1 -101 .0001 2 -80 to -70 .0003 1 -70 to -60 .0001 5 -60 to -50 .0007 4 -50 to -40 .0006 6 -40 to -30 .0008 9 -30 to -20 .0013 29 -20 to -10 .0041 3057 -10 to 0 .4292 3902 0 to 10 .5478 43 10 to 20 .0060 28 20 to 30 .0039 17 30 to 40 .0024 5 40 to 50 .0007 8 50 to 60 .0011 1 60 to 70 .0001 1 70 to 80 .0001 1 80 to 90 .0001 1 90 to 100 .0001 1 110 to 120 .0001 1 185 .0001 7123 1.000 310 with similar lengths (Gale &amp; Church, 1991a; Brown et al., 1991). Soon thereafter, Church (1993) found that bitext mapping at the sentence level is not an option for noisy bitexts found in the real world. Sentences are often difficult to detect, especially where punctuation is missing due to OCR errors. More importantly, bitexts often contain lists, tables, titles, footnotes, citations and/or mark-up codes that foil sentence alignment methods. Church&apos;s solution was to look at the smallest of text units — characters — and to use digital signal processing techniques to grapple with the much larger number of text units that might match b</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W. Gale &amp; K. W. Church, &amp;quot;A Program for Aligning Sentences in Bilingual Corpora,&amp;quot; Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, CA, 1991a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
</authors>
<title>Identifying Word Correspondences in Parallel Texts,&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the DARPA SNL Workshop,</booktitle>
<contexts>
<context position="1556" citStr="Gale &amp; Church, 1991" startWordPosition="232" endWordPosition="235">anguages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in versions. It should be applicable to any text genre </context>
<context position="20669" citStr="Gale &amp; Church, 1991" startWordPosition="3428" endWordPosition="3431">his collection is given in Table 3. This distribution can be compared to error distributions reported in (Church, 1993) and in (Dagan et al., 1993). SIMR&apos;s RMS error on this bitext was 5.7 characters. Church&apos;s char_align algorithm (Church, 1993) is the only algorithm that does not use sentence boundary information for which comparable results have been reported. char_align&apos;s RMS error on this bitext was 57 characters, exactly ten times higher. Two teams of researchers have reported results on the same &amp;quot;parliamentary debates&amp;quot; bitext for algorithms that map correspondence at the sentence level (Gale &amp; Church, 1991a; Simard et al., 1992). 309 Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs. language pair main informant for estimated time estimated time number of matching predicate spent to build spent on segments new axis generator hand-alignment aligned Spanish/English lexical cognates 8 h 5 h 1338 Korean/English translation lexicon 6 h 12 h 1224 Table 2: SIMR accuracy on different text genres in three language pairs. language number of genre number of RMS Error pair training TPCs test TPCs in characters French / English 598 parliamentary debates 7123 5.7 CITI technical reports 365, 305, 1</context>
<context position="23546" citStr="Gale &amp; Church, 1991" startWordPosition="3920" endWordPosition="3923">91, two teams of researchers independently discovered that sentences can be accurately aligned by matching sequences number of error range fraction of test points in characters test points 1 -101 .0001 2 -80 to -70 .0003 1 -70 to -60 .0001 5 -60 to -50 .0007 4 -50 to -40 .0006 6 -40 to -30 .0008 9 -30 to -20 .0013 29 -20 to -10 .0041 3057 -10 to 0 .4292 3902 0 to 10 .5478 43 10 to 20 .0060 28 20 to 30 .0039 17 30 to 40 .0024 5 40 to 50 .0007 8 50 to 60 .0011 1 60 to 70 .0001 1 70 to 80 .0001 1 80 to 90 .0001 1 90 to 100 .0001 1 110 to 120 .0001 1 185 .0001 7123 1.000 310 with similar lengths (Gale &amp; Church, 1991a; Brown et al., 1991). Soon thereafter, Church (1993) found that bitext mapping at the sentence level is not an option for noisy bitexts found in the real world. Sentences are often difficult to detect, especially where punctuation is missing due to OCR errors. More importantly, bitexts often contain lists, tables, titles, footnotes, citations and/or mark-up codes that foil sentence alignment methods. Church&apos;s solution was to look at the smallest of text units — characters — and to use digital signal processing techniques to grapple with the much larger number of text units that might match b</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W. Gale &amp; K. W. Church, &amp;quot;Identifying Word Correspondences in Parallel Texts,&amp;quot; Proceedings of the DARPA SNL Workshop, 1991b.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Harris</author>
</authors>
<title>Bi-Text, a New Concept in Translation Theory,&amp;quot;</title>
<date>1988</date>
<journal>Language Monthly</journal>
<volume>54</volume>
<contexts>
<context position="3043" citStr="Harris, 1988" startWordPosition="472" endWordPosition="473"> bitext mapping algorithms by an order of magnitude. At the same time, its expected running time and memory requirements are linear in the size of the input, better than any other published algorithm. The paper begins by laying down SIMR&apos;s geometric foundations and describing the algorithm. Then, Section 4 explains how to port SIMR to arbitrary language pairs with minimal effort, without relying on genre-specific information such as sentence boundaries. The last section offers some insights about the optimal level of text analysis for mapping bitext correspondence. 2 Bitext Geometry A bitext (Harris, 1988) comprises two versions of a text, such as a text in two different languages. Translators create a bitext each time they translate a text. Each bitext defines a rectangular bitext space, as illustrated in Figure 1. The width and height of the rectangle are the lengths of the two component texts, in characters. The lower left corner of the rectangle is the origin of the bitext space and represents the two texts&apos; beginnings. The upper right corner is the terminus and represents the texts&apos; ends. The line between the origin and the 305 terminus Figure 1: a bitext space terminus is the main diagona</context>
</contexts>
<marker>Harris, 1988</marker>
<rawString>B. Harris, &apos;Bi-Text, a New Concept in Translation Theory,&amp;quot; Language Monthly #54, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M</author>
</authors>
<title>Roscheisen &amp;quot;Text-Translation Alignment,&amp;quot;</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<marker>Kay, M, 1993</marker>
<rawString>M. Kay &amp; M. Roscheisen &amp;quot;Text-Translation Alignment,&amp;quot; Computational Linguistics 19:1, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Macklovitch</author>
</authors>
<title>Peut-on verifier automatiquement la coherence terminologique?&amp;quot;</title>
<date>1995</date>
<booktitle>Proceedings of the IV&amp;quot; Journees scientifiques, Lexicommatique et Dictionnairiques, organized by AUPELF-UREF,</booktitle>
<location>Lyon, France,</location>
<contexts>
<context position="9066" citStr="Macklovitch, 1995" startWordPosition="1488" endWordPosition="1489">lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in the rare cases where MRBDs are available. In other cases, they can be constructed automatically or semi-automatically using any of several methods (Fung, 1995; Melamed, 1996c; Resnik Sz Melamed, 1997). Since the matching predicate need not be perfectly accurate, the translation lexicons need not be either. Matching predicates can take advantage of other information, besides cognates and translation lexicons can also be used. For example, a list of faux amis is a useful complement to a cognate matching strategy (Macklovitch, 1995). A stop list of function words is also helpful. Function words are translated inconsistently and make unreliable points of correspondence (Melamed, 1996a). 3.2 Point Selection As illustrated in Figure 2, even short sequences of TPCs form characteristic patterns. Most chains of TPCs have the following properties: • Linearity: TPCs tend to line up straight. • Low Variance of Slope: The slope of a TPC chain is rarely much different from the bitext slope. • Injectivity: No two points in a chain of TPCs can have the same x— or y—co-ordinates. SIMR&apos;s chain recognition heuristic exploits these prope</context>
<context position="22740" citStr="Macklovitch, 1995" startWordPosition="3757" endWordPosition="3758">Solaris AnswerBooks. The Korean/English bitexts were provided and hand-aligned by Young-Suk Lee of MIT&apos;s Lincoln Laboratories. Although it is not possible to compare SIMR&apos;s performance on these language pairs to the performance of other algorithms, Table 2 shows that the performance on other language pairs is no worse than performance on French/English. 6 Which Text Units to Map? Early bitext mapping algorithms focused on sentences (Kay &amp; Roscheisen, 1993; Debili &amp; Sammouda, 1992). Although sentence maps do not have sufficient resolution for some important bitext applications (Melamed, 1996b; Macklovitch, 1995), sentences were an easy starting point, because their order rarely changes during translation. Therefore, sentence mapping algorithms need not worry about crossing correspondences. In 1991, two teams of researchers independently discovered that sentences can be accurately aligned by matching sequences number of error range fraction of test points in characters test points 1 -101 .0001 2 -80 to -70 .0003 1 -70 to -60 .0001 5 -60 to -50 .0007 4 -50 to -40 .0006 6 -40 to -30 .0008 9 -30 to -20 .0013 29 -20 to -10 .0041 3057 -10 to 0 .4292 3902 0 to 10 .5478 43 10 to 20 .0060 28 20 to 30 .0039 17</context>
<context position="25041" citStr="Macklovitch, 1995" startWordPosition="4163" endWordPosition="4164">ized text unit at which to map bitext correspondence. By situating word positions in a bitext space, the geometric heuristics of sentence alignment algorithms can be exploited equally well at the word level. The cognate heuristic of the character-based algorithms works better at the word level, because cognateness can be defined more precisely in terms of words, e.g. using the Longest Common Subsequence Ratio (Melamed, 1995). Several other matching heuristics can only be applied at the word level, including the localized noise filter in Section 3.3, lists of stop words and lists of faux amis (Macklovitch, 1995). Most importantly, translation lexicons can only be used at the word level. SIMR can employ a small hand-constructed translation lexicon to map bitexts in any pair of languages, even when the cognate heuristic is not applicable and sentences cannot be found. The particular combination of heuristics described in Section 3 can certainly be improved on, but research into better bitext mapping algorithms is likely to be most fruitfull at the word level. 7 Conclusion The Smooth Injective Map Recognizer (SIMR) bitext mapping algorithm advances the state of the art on several frontiers. It is signif</context>
</contexts>
<marker>Macklovitch, 1995</marker>
<rawString>E. Macklovitch, &amp;quot;Peut-on verifier automatiquement la coherence terminologique?&amp;quot; Proceedings of the IV&amp;quot; Journees scientifiques, Lexicommatique et Dictionnairiques, organized by AUPELF-UREF, Lyon, France, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Automatic Evaluation and Uniform Filter Cascades for Inducing N-best Translation Lexicons,&amp;quot;</title>
<date>1995</date>
<booktitle>Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<location>Boston, MA,</location>
<contexts>
<context position="7647" citStr="Melamed, 1995" startWordPosition="1266" endWordPosition="1267">is a heuristic for deciding whether a given pair of tokens are likely to be&apos;mutual translations. Two kinds of information x = character position in text 1 next TPC chain • discovered TPC O undiscovered TPC • noise main diagonal search frontier 306 that a matching predicate can rely on most often are cognates and translation lexicons. Two tokens in a bitext are cognates if they have the same meaning and similar spellings. In the nontechnical Canadian Hansards (parliamentary debate transcripts available in English and in French), cognates can be found for roughly one quarter of all text tokens (Melamed, 1995). Even distantly related languages like English and Czech will share a large number of cognates in the form of proper nouns. Cognates are more common in bitexts from more similar language pairs, and from text genres where more word borrowing occurs, such as technical texts. When dealing with language pairs that have dissimilar alphabets, the matching predicate can employ phonetic cognates (Melamed, 1996a). When one or both of the languages involved is written in pictographs, cognates can still be found among punctuation and digit strings. However, cognates of this last kind are usually too spa</context>
<context position="24851" citStr="Melamed, 1995" startWordPosition="4131" endWordPosition="4132">t they participate in cognates. Thus, Church&apos;s method is only applicable to language pairs with similar alphabets. The main insight of the present work is that words are a happy medium-sized text unit at which to map bitext correspondence. By situating word positions in a bitext space, the geometric heuristics of sentence alignment algorithms can be exploited equally well at the word level. The cognate heuristic of the character-based algorithms works better at the word level, because cognateness can be defined more precisely in terms of words, e.g. using the Longest Common Subsequence Ratio (Melamed, 1995). Several other matching heuristics can only be applied at the word level, including the localized noise filter in Section 3.3, lists of stop words and lists of faux amis (Macklovitch, 1995). Most importantly, translation lexicons can only be used at the word level. SIMR can employ a small hand-constructed translation lexicon to map bitexts in any pair of languages, even when the cognate heuristic is not applicable and sentences cannot be found. The particular combination of heuristics described in Section 3 can certainly be improved on, but research into better bitext mapping algorithms is li</context>
</contexts>
<marker>Melamed, 1995</marker>
<rawString>I. D. Melamed &amp;quot;Automatic Evaluation and Uniform Filter Cascades for Inducing N-best Translation Lexicons,&amp;quot; Proceedings of the Third Workshop on Very Large Corpora, Boston, MA, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>A Geometric Approach to Mapping Bitext Correspondence,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the First Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;96),</booktitle>
<location>Philadelphia, PA,</location>
<contexts>
<context position="1755" citStr="Melamed, 1996" startWordPosition="263" endWordPosition="264">ation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in versions. It should be applicable to any text genre in any pair of languages. The Smooth Injective Map Recognizer (SIMR) algorithm presented in this paper is a bitext mapping algorithm that advances the state of the art on these criteria. The evaluati</context>
<context position="6762" citStr="Melamed, 1996" startWordPosition="1122" endWordPosition="1123">rner of the previously found chain, as shown in Figure 2. • ous chain •▪ • • • .• prey Figure 2: SIMR &apos;s &amp;quot;expanding rectangle&amp;quot; search strategy. The search rectangle is anchored at the top right corner of the previously found chain. Its diagonal remains parallel to the main diagonal. The expanding-rectangle search strategy makes SIMR robust in the face of TBM discontinuities. Figure 2 shows a segment of the TBM that contains a vertical gap (an omission in the text on the x-axis). As the search rectangle grows, it will eventually intersect with the TBM, even if the discontinuity is quite large (Melamed, 1996b). The noise filter described in Section 3.3 prevents SIMR from being led astray by false points of correspondence. 3.1 Point Generation SIMR generates candidate points of correspondence in the search rectangle using one of its matching predicates. A matching predicate is a heuristic for deciding whether a given pair of tokens are likely to be&apos;mutual translations. Two kinds of information x = character position in text 1 next TPC chain • discovered TPC O undiscovered TPC • noise main diagonal search frontier 306 that a matching predicate can rely on most often are cognates and translation lex</context>
<context position="8053" citStr="Melamed, 1996" startWordPosition="1330" endWordPosition="1331">imilar spellings. In the nontechnical Canadian Hansards (parliamentary debate transcripts available in English and in French), cognates can be found for roughly one quarter of all text tokens (Melamed, 1995). Even distantly related languages like English and Czech will share a large number of cognates in the form of proper nouns. Cognates are more common in bitexts from more similar language pairs, and from text genres where more word borrowing occurs, such as technical texts. When dealing with language pairs that have dissimilar alphabets, the matching predicate can employ phonetic cognates (Melamed, 1996a). When one or both of the languages involved is written in pictographs, cognates can still be found among punctuation and digit strings. However, cognates of this last kind are usually too sparse to suffice by themselves. When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a translation lexicon. Translation lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in the rare cases where MRBDs are available. In other cases, they can be constructed automatically or semi-automatically usin</context>
<context position="10583" citStr="Melamed, 1996" startWordPosition="1735" endWordPosition="1736"> whose points are injective. The linearity of the these chains is tested by measuring the root mean squared distance of the chain&apos;s points from the chain&apos;s least-squares line. If this distance exceeds the maximum point dispersal threshold, the chain is rejected. Next, the angle of each chain&apos;s least-squares line is compared to the arctangent of the bitext slope. If the difference exceeds the maximum angle deviation threshold, the chain is rejected. These filters can be efficiently combined so that SIMR&apos;s expected running time and memory requirements are linear in the size of the input bitext (Melamed, 1996a). The chain recognition heuristic pays no attention to whether chains are monotonic. Non-monotonic TPC chains are quite common, because even languages with similar syntax like French and English have well-known differences in word order. For example, English (adjective, noun) pairs usually correspond to French (noun, adjective) pairs. Such inversions result in TPCs arranged like the middle two points in the &amp;quot;previous chain&amp;quot; of Figure 2. SIMR has no problem accepting the inverted points. If the order of words in a certain text passage is radically altered during translation, SIMR will simply </context>
<context position="18865" citStr="Melamed, 1996" startWordPosition="3135" endWordPosition="3136">f the porting process is the construction of TBMs against which SIMR&apos;s parameters can be optimized and tested. The easiest way to construct these gold standards is to extract them from pairs of hand-aligned text segments: The final character positions of each segment in an aligned pair are the co-ordinates of a TPC. Over the course of two porting efforts, I have develojted and refined tools and methods that allow a bilingual annotator to construct the required TBMs very efficiently from a raw bitext. For example, a tool originally designed for automatic detection of omissions in translations (Melamed, 1996b) was adopted to detect misalignments. 4.4 Porting Experience Summary Table 1 summarizes the amount of time invested in each new language pair. The estimated times for building axis generators do not include the time spent to build the English axis generator, which was part of the original implementation. Axis generators need to be built only once per language, rather than once per language pair. 5 Evaluation SIMR was evaluated on hand-aligned bitexts of various genres in three language pairs. None of these test bitexts were used anywhere in the training or porting procedures. Each test bitex</context>
<context position="21662" citStr="Melamed (1996" startWordPosition="3592" endWordPosition="3593">ifferent text genres in three language pairs. language number of genre number of RMS Error pair training TPCs test TPCs in characters French / English 598 parliamentary debates 7123 5.7 CITI technical reports 365, 305, 176 4.4, 2.6, 9.9 other technical reports 561, 1393 20.6, 14.2 court transcripts 1377 3.9 U.N. annual report 2049 12.36 I.L.O. report 7129 6.42 Spanish / English 562 software manuals 376, 151, 100, 349 4.7, 1.3, 6.6, 4.9 Korean / English 615 military manuals 40, 88, 186, 299 2.6, 7.1, 25, 7.8 military messages 192 0.53 Both of these algorithms use sentence boundary information. Melamed (1996a) showed that sentence boundary information can be used to convert Table 3: SIMR&apos;s error distribution on the SIMR&apos;s output into sentence alignments that are French/English &amp;quot;parliamentary debates&amp;quot; bitext. more accurate than those obtained by either of the other two approaches. The test bitexts in the other two language pairs were created when SIMR was being ported to those languages. The Spanish/English bitexts were drawn from the on-line Sun MicroSystems Solaris AnswerBooks. The Korean/English bitexts were provided and hand-aligned by Young-Suk Lee of MIT&apos;s Lincoln Laboratories. Although it i</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>I. D. Melamed, &amp;quot;A Geometric Approach to Mapping Bitext Correspondence,&amp;quot; Proceedings of the First Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;96), Philadelphia, PA, 1996a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D</author>
</authors>
<title>Melamed &amp;quot;Automatic Detection of Omissions in Translations,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<location>Copenhagen, Denmark,</location>
<marker>D, 1996</marker>
<rawString>I. D. Melamed &amp;quot;Automatic Detection of Omissions in Translations,&amp;quot; Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen, Denmark, 1996b.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Automatic Construction of Clean Broad-Coverage Translation Lexicons,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="1755" citStr="Melamed, 1996" startWordPosition="263" endWordPosition="264">ation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use little memory and degrade gracefully when faced with translation irregularities like omissions and in versions. It should be applicable to any text genre in any pair of languages. The Smooth Injective Map Recognizer (SIMR) algorithm presented in this paper is a bitext mapping algorithm that advances the state of the art on these criteria. The evaluati</context>
<context position="6762" citStr="Melamed, 1996" startWordPosition="1122" endWordPosition="1123">rner of the previously found chain, as shown in Figure 2. • ous chain •▪ • • • .• prey Figure 2: SIMR &apos;s &amp;quot;expanding rectangle&amp;quot; search strategy. The search rectangle is anchored at the top right corner of the previously found chain. Its diagonal remains parallel to the main diagonal. The expanding-rectangle search strategy makes SIMR robust in the face of TBM discontinuities. Figure 2 shows a segment of the TBM that contains a vertical gap (an omission in the text on the x-axis). As the search rectangle grows, it will eventually intersect with the TBM, even if the discontinuity is quite large (Melamed, 1996b). The noise filter described in Section 3.3 prevents SIMR from being led astray by false points of correspondence. 3.1 Point Generation SIMR generates candidate points of correspondence in the search rectangle using one of its matching predicates. A matching predicate is a heuristic for deciding whether a given pair of tokens are likely to be&apos;mutual translations. Two kinds of information x = character position in text 1 next TPC chain • discovered TPC O undiscovered TPC • noise main diagonal search frontier 306 that a matching predicate can rely on most often are cognates and translation lex</context>
<context position="8053" citStr="Melamed, 1996" startWordPosition="1330" endWordPosition="1331">imilar spellings. In the nontechnical Canadian Hansards (parliamentary debate transcripts available in English and in French), cognates can be found for roughly one quarter of all text tokens (Melamed, 1995). Even distantly related languages like English and Czech will share a large number of cognates in the form of proper nouns. Cognates are more common in bitexts from more similar language pairs, and from text genres where more word borrowing occurs, such as technical texts. When dealing with language pairs that have dissimilar alphabets, the matching predicate can employ phonetic cognates (Melamed, 1996a). When one or both of the languages involved is written in pictographs, cognates can still be found among punctuation and digit strings. However, cognates of this last kind are usually too sparse to suffice by themselves. When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a translation lexicon. Translation lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in the rare cases where MRBDs are available. In other cases, they can be constructed automatically or semi-automatically usin</context>
<context position="10583" citStr="Melamed, 1996" startWordPosition="1735" endWordPosition="1736"> whose points are injective. The linearity of the these chains is tested by measuring the root mean squared distance of the chain&apos;s points from the chain&apos;s least-squares line. If this distance exceeds the maximum point dispersal threshold, the chain is rejected. Next, the angle of each chain&apos;s least-squares line is compared to the arctangent of the bitext slope. If the difference exceeds the maximum angle deviation threshold, the chain is rejected. These filters can be efficiently combined so that SIMR&apos;s expected running time and memory requirements are linear in the size of the input bitext (Melamed, 1996a). The chain recognition heuristic pays no attention to whether chains are monotonic. Non-monotonic TPC chains are quite common, because even languages with similar syntax like French and English have well-known differences in word order. For example, English (adjective, noun) pairs usually correspond to French (noun, adjective) pairs. Such inversions result in TPCs arranged like the middle two points in the &amp;quot;previous chain&amp;quot; of Figure 2. SIMR has no problem accepting the inverted points. If the order of words in a certain text passage is radically altered during translation, SIMR will simply </context>
<context position="18865" citStr="Melamed, 1996" startWordPosition="3135" endWordPosition="3136">f the porting process is the construction of TBMs against which SIMR&apos;s parameters can be optimized and tested. The easiest way to construct these gold standards is to extract them from pairs of hand-aligned text segments: The final character positions of each segment in an aligned pair are the co-ordinates of a TPC. Over the course of two porting efforts, I have develojted and refined tools and methods that allow a bilingual annotator to construct the required TBMs very efficiently from a raw bitext. For example, a tool originally designed for automatic detection of omissions in translations (Melamed, 1996b) was adopted to detect misalignments. 4.4 Porting Experience Summary Table 1 summarizes the amount of time invested in each new language pair. The estimated times for building axis generators do not include the time spent to build the English axis generator, which was part of the original implementation. Axis generators need to be built only once per language, rather than once per language pair. 5 Evaluation SIMR was evaluated on hand-aligned bitexts of various genres in three language pairs. None of these test bitexts were used anywhere in the training or porting procedures. Each test bitex</context>
<context position="21662" citStr="Melamed (1996" startWordPosition="3592" endWordPosition="3593">ifferent text genres in three language pairs. language number of genre number of RMS Error pair training TPCs test TPCs in characters French / English 598 parliamentary debates 7123 5.7 CITI technical reports 365, 305, 176 4.4, 2.6, 9.9 other technical reports 561, 1393 20.6, 14.2 court transcripts 1377 3.9 U.N. annual report 2049 12.36 I.L.O. report 7129 6.42 Spanish / English 562 software manuals 376, 151, 100, 349 4.7, 1.3, 6.6, 4.9 Korean / English 615 military manuals 40, 88, 186, 299 2.6, 7.1, 25, 7.8 military messages 192 0.53 Both of these algorithms use sentence boundary information. Melamed (1996a) showed that sentence boundary information can be used to convert Table 3: SIMR&apos;s error distribution on the SIMR&apos;s output into sentence alignments that are French/English &amp;quot;parliamentary debates&amp;quot; bitext. more accurate than those obtained by either of the other two approaches. The test bitexts in the other two language pairs were created when SIMR was being ported to those languages. The Spanish/English bitexts were drawn from the on-line Sun MicroSystems Solaris AnswerBooks. The Korean/English bitexts were provided and hand-aligned by Young-Suk Lee of MIT&apos;s Lincoln Laboratories. Although it i</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>I. D. Melamed, &amp;quot;Automatic Construction of Clean Broad-Coverage Translation Lexicons,&amp;quot; Proceedings of the Conference of the Association for Machine Translation in the Americas, Montreal, Canada, 1996c.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>A Word-to-Word Model of Translational Equivalence,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of the 35th Conference of the Association for Computational Linguistics,</booktitle>
<location>Madrid,</location>
<note>(in this volume)</note>
<contexts>
<context position="1203" citStr="Melamed, 1997" startWordPosition="180" endWordPosition="181">n other algorithms in the literature. The algorithm is robust enough to use on noisy texts, such as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without a</context>
<context position="8731" citStr="Melamed, 1997" startWordPosition="1436" endWordPosition="1437">tographs, cognates can still be found among punctuation and digit strings. However, cognates of this last kind are usually too sparse to suffice by themselves. When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a translation lexicon. Translation lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in the rare cases where MRBDs are available. In other cases, they can be constructed automatically or semi-automatically using any of several methods (Fung, 1995; Melamed, 1996c; Resnik Sz Melamed, 1997). Since the matching predicate need not be perfectly accurate, the translation lexicons need not be either. Matching predicates can take advantage of other information, besides cognates and translation lexicons can also be used. For example, a list of faux amis is a useful complement to a cognate matching strategy (Macklovitch, 1995). A stop list of function words is also helpful. Function words are translated inconsistently and make unreliable points of correspondence (Melamed, 1996a). 3.2 Point Selection As illustrated in Figure 2, even short sequences of TPCs form characteristic patterns. M</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. D. Melamed, &amp;quot;A Word-to-Word Model of Translational Equivalence,&amp;quot; Proceedings of the 35th Conference of the Association for Computational Linguistics, Madrid, Spain, 1997. (in this volume)</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>I D Melamed</author>
</authors>
<title>Semi-Automatic Acquisition of Domain-Specific Translation Lexicons,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of the 7th ACL Conference on Applied Natural Language Processing,</booktitle>
<location>Washington, DC,</location>
<marker>Resnik, Melamed, 1997</marker>
<rawString>P. Resnik &amp; I. D. Melamed, &amp;quot;Semi-Automatic Acquisition of Domain-Specific Translation Lexicons,&amp;quot; Proceedings of the 7th ACL Conference on Applied Natural Language Processing, Washington, DC, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Evaluating Multilingual Gisting of Web Pages,&amp;quot;</title>
<date>1997</date>
<pages>97--39</pages>
<institution>University of Maryland,</institution>
<contexts>
<context position="1406" citStr="Resnik, 1997" startWordPosition="209" endWordPosition="210">guage-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify corresponding text units between the two halves of a bitext. The ideal bitext mapping algorithm should be fast and accurate, use litt</context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>P. Resnik, &amp;quot;Evaluating Multilingual Gisting of Web Pages,&amp;quot; UMIACS-TR-97-39, University of Maryland, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
<author>M Nagao</author>
</authors>
<title>Toward Memory-Based Translation,&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<contexts>
<context position="1167" citStr="Sato &amp; Nagao, 1990" startWordPosition="172" endWordPosition="175">ster and significantly more accurate than other algorithms in the literature. The algorithm is robust enough to use on noisy texts, such as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However,</context>
</contexts>
<marker>Sato, Nagao, 1990</marker>
<rawString>S. Sato &amp; M. Nagao, &amp;quot;Toward Memory-Based Translation,&amp;quot; Proceedings of the 13th International Conference on Computational Linguistics, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
</authors>
<title>CTM: An Example-Based Translation Aid System,&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics,</booktitle>
<location>Nantes,</location>
<contexts>
<context position="1281" citStr="Sato, 1992" startWordPosition="191" endWordPosition="192">sy texts, such as those resulting from OCR input, and on translations that are not very literal. SIMR encapsulates its language-specific heuristics, so that it can be ported to any language pair with a minimal effort. 1 Introduction Texts that are available in two languages (bitexts) are immensely valuable for many natural language processing applicationsl Bitexts are the raw material from which translation models are built. In addition to their use in machine translation (Sato &amp; Nagao, 1990; Brown et al., 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al., 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997). Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography (Catizone et al., 1993; Gale &amp; Church, 1991b), computer-assisted language learning, and tools for translators (e.g. (Macklovitch, &amp;quot;Multitexts&amp;quot; in more than two languages are even more valuable, but they are much more rare. 1995; Melamed, 1996b). However, bitexts are of little use without an automatic method for constructing bitext maps. Bitext maps identify correspo</context>
</contexts>
<marker>Sato, 1992</marker>
<rawString>S. Sato, &amp;quot;CTM: An Example-Based Translation Aid System,&amp;quot; Proceedings of the 14th International Conference on Computational Linguistics, Nantes, France, 1992.</rawString>
</citation>
<citation valid="true">
<date>1996</date>
<booktitle>SIGIR Workshop on Cross-linguistic Multilingual Information Retrieval,</booktitle>
<location>Zurich,</location>
<marker>1996</marker>
<rawString>SIGIR Workshop on Cross-linguistic Multilingual Information Retrieval, Zurich, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G F Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora,&amp;quot;</title>
<date>1992</date>
<booktitle>in Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="20692" citStr="Simard et al., 1992" startWordPosition="3432" endWordPosition="3435">n in Table 3. This distribution can be compared to error distributions reported in (Church, 1993) and in (Dagan et al., 1993). SIMR&apos;s RMS error on this bitext was 5.7 characters. Church&apos;s char_align algorithm (Church, 1993) is the only algorithm that does not use sentence boundary information for which comparable results have been reported. char_align&apos;s RMS error on this bitext was 57 characters, exactly ten times higher. Two teams of researchers have reported results on the same &amp;quot;parliamentary debates&amp;quot; bitext for algorithms that map correspondence at the sentence level (Gale &amp; Church, 1991a; Simard et al., 1992). 309 Table 1: Time spent in constructing two &amp;quot; old standard&amp;quot; TBMs. language pair main informant for estimated time estimated time number of matching predicate spent to build spent on segments new axis generator hand-alignment aligned Spanish/English lexical cognates 8 h 5 h 1338 Korean/English translation lexicon 6 h 12 h 1224 Table 2: SIMR accuracy on different text genres in three language pairs. language number of genre number of RMS Error pair training TPCs test TPCs in characters French / English 598 parliamentary debates 7123 5.7 CITI technical reports 365, 305, 176 4.4, 2.6, 9.9 other </context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>M. Simard, G. F. Foster &amp; P. Isabelle, &amp;quot;Using Cognates to Align Sentences in Bilingual Corpora,&amp;quot; in Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation, Montreal, Canada, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>P Plamondon</author>
</authors>
<title>Bilingual Sentence Alignment: Balancing Robustness and Accuracy,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>Montreal, Canada,</location>
<marker>Simard, Plamondon, 1996</marker>
<rawString>M. Simard &amp; P. Plamondon, &amp;quot;Bilingual Sentence Alignment: Balancing Robustness and Accuracy,&amp;quot; Proceedings of the Conference of the Association for Machine Translation in the Americas, Montreal, Canada, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R V V Vidal</author>
</authors>
<title>Applied Simulated Annealing,</title>
<date>1993</date>
<publisher>Springer-Verlag,</publisher>
<location>Heidelberg, Germany,</location>
<contexts>
<context position="17404" citStr="Vidal, 1993" startWordPosition="2892" endWordPosition="2893"> match them anyway. Therefore, for languages like Chinese and Japanese, which are written without spaces between words, tokenization boils down to string matching. In this manner, SIMR circumvents the difficult problem of word identification in these languages. 4.3 Step 3: Re-optimize Parameters The last step in the porting process is to re-optimize SIMR&apos;s numerical parameters. The four parameters described in Section 3 interact in complicated ways, and it is impossible to find a good parameter set analytically. It is easier to optimize these parameters empirically, using simulated annealing (Vidal, 1993). Simulated annealing requires an objective function to optimize. The objective function for bitext mapping should measure the difference between the TBM and maps produced with the current parameter set. In geometric terms, the difference is a distance. The TBM consists of a set of TPCs. The error between a bitext map and each TPC can be defined as the horizontal distance, the vertical distance, or the distance perpendicular to the main diagonal. The first two alternatives would minimize the error with respect to only one language or the other. The perpendicular distance is a more robust avera</context>
</contexts>
<marker>Vidal, 1993</marker>
<rawString>R. V. V. Vidal, Applied Simulated Annealing, Springer-Verlag, Heidelberg, Germany, 1993.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>