<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000087">
<title confidence="0.991434">
An Efficient Dynamic Oracle for Unrestricted Non-Projective Parsing
</title>
<author confidence="0.951174">
Carlos G´omez-Rodriguez
</author>
<affiliation confidence="0.680682">
Departamento de Computaci´on
Universidade da Coru˜na
Campus de Elvi˜na, s/n
15071 A Coru˜na, Spain
</affiliation>
<email confidence="0.993324">
carlos.gomez@udc.es
</email>
<sectionHeader confidence="0.997302" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992">
We define a dynamic oracle for the Cov-
ington non-projective dependency parser.
This is not only the first dynamic oracle
that supports arbitrary non-projectivity,
but also considerably more efficient
(O(n)) than the only existing oracle with
restricted non-projectivity support. Ex-
periments show that training with the dy-
namic oracle significantly improves pars-
ing accuracy over the static oracle baseline
on a wide range of treebanks.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954555555556">
Greedy transition-based dependency parsers build
analyses for sentences incrementally by following
a sequence of transitions defined by an automaton,
using a scoring model to choose the best trans-
ition to take at each state (Nivre, 2008). While
this kind of parsers have become very popular,
as they achieve competitive accuracy with espe-
cially fast parsing times; their raw accuracy is still
behind that of slower alternatives like transition-
based parsers that use beam search (Zhang and
Nivre, 2011; Choi and McCallum, 2013). For this
reason, a current research challenge is to improve
the accuracy of greedy transition-based parsers as
much as possible without sacrificing efficiency.
A relevant recent advance in this direction is
the introduction of dynamic oracles (Goldberg and
Nivre, 2012), an improvement in the training pro-
cedure of greedy parsers that can boost their ac-
curacy without any impact on parsing speed. An
oracle is a training component that selects the best
transition(s) to take at a given configuration, us-
ing knowledge about the gold tree. Traditionally,
transition-based parsers were trained to follow a
so-called static oracle, which is only defined on
the configurations of a canonical computation that
generates the gold tree, returning the next trans-
ition in said computation. In contrast, dynamic
</bodyText>
<note confidence="0.9415942">
Daniel Fern´andez-Gonz´alez
Departamento de Inform´atica
Universidade de Vigo
Campus As Lagoas, s/n
32004 Ourense, Spain
</note>
<email confidence="0.950665">
danifg@uvigo.es
</email>
<bodyText confidence="0.999815097560976">
oracles are non-deterministic (not limited to one
sequence, but supporting all the possible computa-
tions leading to the gold tree), and complete (also
defined for configurations where the gold tree is
unreachable, choosing the transition(s) that lead to
a tree with minimum error). This extra robustness
in training provides higher parsing accuracy.
However, defining a usable dynamic oracle for
a given parser is non-trivial in general, due to
the need of calculating the loss of each configura-
tion, i.e., the minimum Hamming loss to the gold
tree from a tree reachable from that configuration.
While it is always easy to do this in exponential
time by simulating all possible computations in
the algorithm to obtain all reachable trees, it is
not always clear how to achieve this calculation
in polynomial time. At the moment, this prob-
lem has been solved for several projective pars-
ers exploiting either arc-decomposability (Gold-
berg and Nivre, 2013) or tabularization of compu-
tations (Goldberg et al., 2014). However, for pars-
ers that can handle crossing arcs, the only known
dynamic oracle (G´omez-Rodr´ıguez et al., 2014)
has been defined for a variant of the parser by At-
tardi (2006) that supports a restricted set of non-
projective trees. To our knowledge, no dynamic
oracles are known for any transition-based parser
that can handle unrestricted non-projectivity.
In this paper, we define such an oracle for
the Covington non-projective parser (Covington,
2001; Nivre, 2008), which can handle arbitrary
non-projective dependency trees. As this al-
gorithm is not arc-decomposable and its tabular-
ization is NP-hard (Neuhaus and Br¨oker, 1997),
we do not use the existing techniques to define
dynamic oracles, but a reasoning specific to this
parser. It is worth noting that, apart from being the
first dynamic oracle supporting unrestricted non-
projectivity, our oracle is very efficient, solving the
loss calculation in O(n). In contrast, the restricted
non-projective oracle of G´omez-Rodriguez et al.
</bodyText>
<page confidence="0.920449">
256
</page>
<bodyText confidence="0.835817111111111">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 256–261,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
(2014) has O(n8) time complexity.
The rest of the paper is organized as follows:
after a quick outline of Covington’s parser in
Sect. 2, we present the oracle and prove its cor-
rectness in Sect. 3. Experiments are reported in
Sect. 4, and Sect. 5 contains concluding remarks.
</bodyText>
<sectionHeader confidence="0.988041" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.97100298245614">
We will define a dynamic oracle for the non-
projective parser originally defined by Covington
(2001), and implemented by Nivre (2008) under
the transition-based parsing framework. For space
reasons, we only sketch the parser very briefly, and
refer to the above reference for more details.
Parser configurations are of the form c =
(A1, A2, B, A), where A1 and A2 are lists of par-
tially processed words, B is another list (called the
buffer) with currently unprocessed words, and A is
the set of dependencies built so far. Suppose that
we parse a string w1 · · · wn, whose word occur-
rences will be identified with their indices 1 · · · n
for simplicity. Then, the parser starts at an initial
configuration cs(w1 ... wn) = ([], [], [1... n], 0),
and executes transitions chosen from those in Fig-
ure 1 until a terminal configuration of the form
{(A1, A2, [], A) E C1 is reached, and the sen-
tence’s parse tree is obtained from A.1
The transition semantics is very simple, mirror-
ing the double nested loop traversing word pairs in
the formulation by Covington (2001). When the
algorithm is in a configuration (A1Ii, A2, jIB, A),
we will say that it is considering the focus words
i and j, located at the end of the first list and at the
beginning of the buffer. A decision is then made
about whether these two words should be linked
with a rightward arc i —* j (Right-Arc transition),
a leftward arc i +— j (Left-Arc transition) or not
linked (No-Arc transition). The first two choices
will be unavailable in configurations where the
newly-created arc would violate the single-head
constraint (a node cannot have more than one in-
coming arc) or the acyclicity constraint (cycles
are not allowed). In any of these three transitions,
i is then moved to the second list to make i−1 and
j the focus words for the next step. Alternatively,
we can choose to read a new word from the string
with a Shift transition, so that the focus words in
1The arcs in A form a forest, but we convert it to a tree by
linking any node without a head as a dependent of an artifi-
cial node at position 0 that acts as a dummy root. From now
on, when we refer to some dependency graph as a tree, we
assume that this transformation is being implicitly made.
the resulting configuration will be j and j + 1.
The result is a parser that can generate any pos-
sible dependency tree for the input, and runs in
quadratic worst-case time. Although in theory this
complexity can seem like a drawback compared to
linear-time transition-based parsers (e.g. (Nivre,
2003; G´omez-Rodr´ıguez and Nivre, 2013)), it has
been shown by Volokh and Neumann (2012) to ac-
tually outperform linear algorithms in practice, as
it allows for relevant optimizations in feature ex-
traction that cannot be implemented in other pars-
ers. In fact, one of the fastest dependency parsers
to date uses this algorithm (Volokh, 2013).
</bodyText>
<sectionHeader confidence="0.963574" genericHeader="method">
3 The oracle
</sectionHeader>
<bodyText confidence="0.999765461538461">
As sketched in Sect. 1, a dynamic oracle is a train-
ing component that, given a configuration c and
a gold tree tG, provides the set of transitions that
are applicable in c and lead to trees with minimum
Hamming loss with respect to tG. The Hamming
loss between a tree t and tG, written G(t, tG), is
the number of nodes that have a different head in t
than in tG. Following Goldberg and Nivre (2013),
we say that a set of arcs A is reachable from con-
figuration c, written c A, if there is some (pos-
sibly empty) path of transitions from c to some
configuration c&apos; = (A1, A2, B, A&apos;), with A C_ A&apos;.
Then, we can define the loss of a configuration as
</bodyText>
<equation confidence="0.985871">
e(c) = min
t|c t
</equation>
<bodyText confidence="0.9986815">
and the set of transitions that must be returned by
a correct dynamic oracle is then
</bodyText>
<equation confidence="0.649652">
od(c, tG) = Iτ I e(c) − e(τ(c)) = 01,
</equation>
<bodyText confidence="0.810970444444445">
i.e., the transitions that do not increase configur-
ation loss, and hence lead to the best parse (in
terms of loss) reachable from c. Therefore, imple-
menting a dynamic oracle reduces to computing
the loss e(c) for each configuration c.
Goldberg and Nivre (2013) show that the calcu-
lation of the loss is easy for parsers that are arc-
decomposable, i.e., those where for every config-
uration c and arc set A that is tree-compatible (i.e.
that can be a part of a well-formed parse2), c A
is entailed by c (i —* j) for every i —* j E A.
That is, if each arc in a tree-compatible set is indi-
vidually reachable from configuration c, then that
2In the cited paper, tree-compatibility required projectiv-
ity, as the authors were dealing with projective parsers. In
our case, since the parser is non-projective, tree-compatibility
only consists of the single-head and acyclicity constraints.
G(t, tG),
</bodyText>
<page confidence="0.909516">
257
</page>
<construct confidence="0.741153">
Shift: hA1, A2, j|B, Ai ⇒ hA1 · A2|j, [], B, Ai
No-Arc: hA1|i, A2, B, Ai ⇒ hA1, i|A2, B, Ai
Left-Arc: hA1|i, A2, j|B, Ai ⇒ hA1, i|A2, j|B, A ∪ {j → i}i
</construct>
<equation confidence="0.697044666666667">
only if �k  |k --+ i E A (single-head) and i --+∗ j E� A (acyclicity).
Right-Arc: hA1|i, A2, j|B, Ai ⇒ hA1, i|A2, j|B, A ∪ {i → j}i
only if �k  |k --+ j E A (single-head) and j --+∗ i E� A (acyclicity).
</equation>
<figureCaption confidence="0.908402333333333">
Figure 1: Transitions of the Covington non-projective dependency parser.
Figure 2: An example of non-arc-decomposability
of the Covington parser: graphical representation
</figureCaption>
<bodyText confidence="0.981128397260274">
of configuration c = h[1, 2], [], [3, 4], A = {1 →
2}i. The solid arc corresponds to the arc set A,
and the circled indexes mark the focus words. The
dashed arcs represent the gold tree tG.
set of arcs is reachable from c. If this holds, then
computing the loss of a configuration c reduces to
determining and counting the gold arcs that are not
reachable from c, which is easy in most parsers.
Unfortunately, the Covington parser is not arc-
decomposable. This can be seen in the example of
Figure 2: while any of the gold arcs 2→3, 3→4,
4→1 can be reachable individually from the depic-
ted configuration, they are not jointly reachable as
they form a cycle with the already-built arc 1→2.
Thus, the configuration has only one individually
unreachable arc (0→2), but its loss is 2.
However, it is worth noting that non-arc-
decomposability in the parser is exclusively due
to cycles. If a set of individually reachable arcs do
not form a cycle together with already-built arcs,
then we can show that the set will be reachable.
This idea is the basis for an expression to compute
loss based on counting individually unreachable
arcs, and then correcting for the effect of cycles:
Theorem 1 Let c = hA1, A2, B, Ai be a config-
uration of the Covington parser, and tG the set of
arcs of a gold tree. We call I(c, tG) = {x → y ∈
tG  |c -_� (x → y)} the set of individually reach-
able arcs of tG; note that this set may overlap A.
Conversely, we call U(c, tG) = tG \ I(c, tG) the
set of individually unreachable arcs of tG from c.
Finally, let n,(G) denote the number of cycles in
a graph G.
Then E(c) = |U(c, tG) |+ n,(A ∪ I(c, tG)). ✷
We now sketch the proof. To prove Theorem 1,
it is enough to show that (1) there is at least one
tree reachable from c with exactly that Hamming
loss to tG, and (2) there are no trees reachable from
c with a smaller loss. To this end, we will use some
properties of the graph A∪I(c, tG). First, we note
that no node in this graph has in-degree greater
than 1. In particular, each node except for the
dummy root has exactly one head, either explicit
or (if no head has been assigned in A or in the gold
tree) the dummy root. No node has more than one
head: a node cannot have two heads in A because
the parser transitions enforce the single-head con-
straint, it cannot have two heads in I(c, tG) be-
cause tG must satisfy this constraint as well, and it
cannot have one head in A and another in I(c, tG)
because the corresponding arc in I(c, tG) would
be unreachable due to the single-head constraint.
This, in turn, implies that the graph A∪I(c, tG)
has no overlapping cycles, as overlapping cycles
can only appear in graphs with in-degree greater
than 1. This is the key property enabling us to
exactly calculate loss using the number of cycles.
To show (1), consider the graph A ∪ I(c, tG).
In each of its cycles, there is at least one arc
that belongs to I(c, tG), as A must satisfy the
acyclicity constraint. We arbitrarily choose one
such arc from each cycle, and remove it from
the graph. Note that this results in removing ex-
actly n,(A ∪ I(c, tG)) arcs, as we have shown
that the cycles in A ∪ I(c, tG) are disjoint. We
call the resulting graph B(c, tG). As it has max-
imum in-degree 1 and it is acyclic (because we
have broken all the cycles), B(c, tG) is a tree, mod-
ulo our standard assumption that headless nodes
are assumed to be linked to the dummy root.
This tree B(c, tG) is reachable from c and has
loss E(c) = |U(c, tG) |+ n,(A ∪ I(c, tG)). Reach-
ability is shown by building a sequence of trans-
</bodyText>
<equation confidence="0.653384">
0 1 2 3 4
</equation>
<page confidence="0.981821">
258
</page>
<bodyText confidence="0.99825492">
itions that will visit the pairs of words corres-
ponding to remaining arcs in order, and inter-
calating the corresponding Left-Arc or Right-Arc
transitions, which cannot violate the acyclicity or
single-head constraints. The term U(c, tG) in the
loss stems from the fact that A U I(c, tG) can-
not contain arcs in U(c, tG), and the term n,(A U
I(c, tG)) from not including the n,(A U I(c, tG))
arcs that we discarded to break cycles.
Finally, from these observations, it is easy to
see that B(c, tG) has the best loss among reach-
able trees, and thus prove (2): the arcs in U(c, tG)
are always unreachable by definition, and for each
cycle in n,(A U I(c, tG)), the acyclicity con-
straint forces us to miss at least one arc. As
the cycles are disjoint, this means that we neces-
sarily miss at least n,(A U I(c, tG)) arcs, hence
|U(c, tG) |+ n,(A U I(c, tG)) is indeed the min-
imum loss among reachable trees. ❑
Thus, to calculate the loss of a configuration c,
we only need to compute both of the terms in The-
orem 1. For the first term, note that if c has focus
words i and j (i.e., c = (λ,|i, λ2, j|B, A)), then
an arc x —* y is in U(c, tG) if it is not in A, and at
least one of the following holds:
</bodyText>
<listItem confidence="0.990936923076923">
• j &gt; max(x, y), as in this case we have read
too far in the string and will not be able to get
x and y as focus words,
• j = max(x, y) ∧ i &lt; min(x, y), as in this
case we have max(x, y) as the right focus
word but the left focus word is to the left of
min(x, y), and we cannot move it back,
• there is some z =� 0, z =� x such that z —* y E
A, as in this case the single-head constraint
prevents us from creating x —* y,
• x and y are on the same weakly connected
component of A, as in this case the acyclicity
constraint will not let us create x —* y.
</listItem>
<bodyText confidence="0.994646066666667">
All of these arcs can be trivially enumerated in
O(n) time (in fact, they can be updated in O(1)
if we start from the configuration that preceded c).
The second term of the loss, n,(AUI(c, tG)), can
be computed by obtaining I(c, tG) as tG\U(c, tG)
to then apply a standard cycle-finding algorithm
(Tarjan, 1972) which, for a graph with maximum
in-degree 1, runs in O(n) time.
Algorithm 1 presents the resulting loss cal-
culation algorithm in pseudocode form, where
COUNTCYCLES is a function that counts the num-
ber of cycles in the given graph in linear time as
mentioned above. Note that the for loop runs in
Algorithm 1 Computation of the loss of a config-
uration.
</bodyText>
<listItem confidence="0.886553416666667">
1: function LOSS(c = (λ,|i, λ2, j|B, A), tG)
2: U +— 0 &gt; Variable U is for U(c, tG)
3: for each x —* y E (tG \ A) do
4: left +— min(x, y)
5: right +— max(x, y)
6: if j &gt; right V
7: (j = right ∧ i &lt; left) V
8: (]z &gt; 0,z =�x : z —* y E A)V
9: WEAKLYCONNECTED(A, x, y) then
10: U+—uU{x—*y}
11: I +— tG \ U &gt; Variable I is for I(c, tG)
12: return |U |+ COUNTCYCLES(A U I)
</listItem>
<bodyText confidence="0.993515481481482">
linear time: the condition on line 8 can be com-
puted in constant time by recovering the head of
y. The call to WEAKLYCONNECTED in line 9
finds out whether the two given nodes are weakly
connected in A, and can also be resolved in
O(1), by querying the disjoint set data structure
that implementations of the Covington algorithm
commonly use for the parser’s acyclicity checks
(Nivre, 2008).
It is worth noting that the linear-time com-
plexity can also be achieved by a standalone im-
plementation of the loss calculation algorithm,
without recurse to the parser’s auxiliary data struc-
tures (although this is dubiously practical). To
do so, we can implement WEAKLYCONNECTED
so that the first call computes the connected com-
ponents of A in linear time (Hopcroft and Tarjan,
1973) and subsequent calls use this information to
find out if two nodes are weakly connected in con-
stant time.
On the other hand, a more efficient implementa-
tion than the one shown in Algorithm 1 (which we
chose for clarity) can be achieved by more tightly
coupling the oracle to the parser, as the relevant
sets of arcs associated with a configuration can be
obtained incrementally from those of the previous
configuration.
</bodyText>
<sectionHeader confidence="0.999454" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999207833333333">
To evaluate the performance of our approach, we
conduct experiments on both static and dynamic
Covington non-projective oracles. Concretely, we
train an averaged perceptron model for 15 itera-
tions on nine datasets from the CoNLL-X shared
task (Buchholz and Marsi, 2006) and all data-
</bodyText>
<page confidence="0.994887">
259
</page>
<table confidence="0.993810111111111">
Unigrams
L0w; L0p; L0wp; L0l; L0hw; L0hp; L0hl; L0l0w; L0l0p;
L0l0l; L0r0w; L0r0p; L0r0l; L0h2w; L0h2p; L0h2l; L0lw;
L0lp; L0ll; L0rw; L0rp; L0rl; L0wd; L0pd;
L0wvr; L0pvr; L0wvl; L0pvl; L0wsl; L0psl; L0wsr;
L0psr; L1w; L1p; L1wp; R0w; R0p; R0wp; R0l0w;
R0l0p; R0l0l; R0lw; R0lp; R0ll; R0wd; R0pd; R0wvl;
R0pvl;R0wsl; R0psl; R1w; R1p; R1wp; R2w; R2p;
R2wp; CLw; CLp; CLwp; CRw; CRp; CRwp;
Pairs
L0wp+R0wp; L0wp+R0w; L0w+R0wp; L0wp+R0p;
L0p+R0wp; L0w+R0w; L0p+R0p;R0p+R1p;
L0w+R0wd; L0p+R0pd;
Triples
R0p+R1p+R2p; L0p+R0p+R1p; L0hp+L0p+R0p;
L0p+L0l0p+R0p; L0p+L0r0p+R0p; L0p+R0p+R0l0p;
L0p+L0l0p+L0lp; L0p+L0r0p+L0rp;
L0p+L0hp+L0h2p; R0p+R0l0p+R0lp;
</table>
<tableCaption confidence="0.999448">
Table 1: Feature templates. L0 and R0 denote
</tableCaption>
<bodyText confidence="0.9991294375">
the left and right focus words; L1, L2,... are the
words to the left of L0 and R1, R2,... those to the
right of R0. Xih means the head of Xi, Xih2 the
grandparent, Xil and Xil, the farthest and closest
left dependents, and Xir and Xir, the farthest and
closest right dependents, respectively. CL and
CR are the first and last words between L0 and R0
whose head is not in the interval [L0, R0]. Finally,
w stands for word form; p for PoS tag; l for de-
pendency label; d is the distance between L0 and
R0; vl, vr are the left/right valencies (number of
left/right dependents); and sl, sr the left/right label
sets (dependency labels of left/right dependents).
sets from the CoNLL-XI shared task (Nivre et al.,
2007). We use the same feature templates for all
languages, which result from adapting the features
described by Zhang and Nivre (2011) to the data
structures of the Covington non-projective parser,
and are listed in detail in Table 1.
Table 2 reports the accuracy obtained by the
Covington non-projective parser with both or-
acles. As we can see, the dynamic oracle imple-
mented in the Covington algorithm improves over
the accuracy of the static version on all datasets
except Japanese and Swedish, and most improve-
ments are statistically significant at the .05 level.3
In addition, the Covington dynamic oracle
achieves a greater average improvement in ac-
curacy than the Attardi dynamic oracle (G´omez-
Rodr´ıguez et al., 2014) over their respective static
versions. Concretely, the Attardi oracle accom-
plishes an average improvement of 0.52 percent-
</bodyText>
<footnote confidence="0.9881965">
3Note that the loss of accuracy in Japanese and Swedish
is not statistically significant.
</footnote>
<table confidence="0.999886227272727">
Language s-Covington d-Covington
UAS LAS UAS LAS
Arabic 80.03 71.32 81.47* 72.77*
Basque 75.76 69.70 76.49* 70.27*
Catalan 88.66 83.92 89.28 84.26
Chinese 83.94 79.59 84.68* 80.16*
Czech 77.38 71.21 78.58* 72.59*
English 84.64 83.72 86.14* 84.96*
Greek 79.33 72.65 80.52* 73.67*
Hungarian 77.70 74.32 78.22 74.61
Italian 83.39 79.66 83.66 79.91
Turkish 82.14 76.00 82.38 76.15
Bulgarian 87.68 84.55 88.48* 85.32*
Danish 84.07 79.99 84.98* 80.85*
Dutch 80.28 77.55 81.17* 78.54*
German 86.12 83.93 87.47* 85.15*
Japanese 93.92 92.51 93.79 92.42
Portuguese 85.70 82.78 86.23 83.27
Slovene 75.31 68.97 76.76* 70.35*
Spanish 78.82 75.84 79.87* 76.97*
Swedish 86.78 81.29 86.66 81.21
Average 82.72 78.39 83.52 79.13
</table>
<tableCaption confidence="0.99582">
Table 2: Parsing accuracy (UAS and LAS, in-
</tableCaption>
<bodyText confidence="0.905571">
cluding punctuation) of Covington non-projective
parser with static (s-Covington) and dynamic (d-
Covington) oracles on CoNLL-XI (first block) and
CoNLL-X (second block) datasets. For each lan-
guage, we run five experiments with the same
setup but different seeds and report the averaged
accuracy. Best results for each language are shown
in boldface. Statistically significant improvements
(α = .05) (Yeh, 2000) are marked with ∗.
age points in UAS and 0.71 in LAS, while our ap-
proach achieves 0.80 in UAS and 0.74 in LAS.
</bodyText>
<sectionHeader confidence="0.998925" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999957727272727">
We have defined the first dynamic oracle for
a transition-based parser supporting unrestricted
non-projectivity. The oracle is very efficient, com-
puting loss in O(n), compared to O(n8) for the
only previously known dynamic oracle with sup-
port for a subset of non-projective trees (G´omez-
Rodr´ıguez et al., 2014).
Experiments on the treebanks from the CoNLL-
X and CoNLL-XI shared tasks show that the dy-
namic oracle significantly improves accuracy on
many languages over a static oracle baseline.
</bodyText>
<sectionHeader confidence="0.998033" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9961924">
Research partially funded by the Spanish Min-
istry of Economy and Competitiveness/ERDF
(grants FFI2014-51978-C2-1-R, FFI2014-51978-
C2-2-R), Ministry of Education (FPU grant pro-
gram) and Xunta de Galicia (grant R2014/034).
</bodyText>
<page confidence="0.99203">
260
</page>
<sectionHeader confidence="0.996029" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998656831460674">
Giuseppe Attardi. 2006. Experiments with a multil-
anguage non-projective dependency parser. In Pro-
ceedings of the 10th Conference on Computational
Natural Language Learning (CoNLL-X), pages 166–
170, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of the 10th Conference on Computa-
tional Natural Language Learning (CoNLL), pages
149–164.
Jinho D. Choi and Andrew McCallum. 2013.
Transition-based dependency parsing with selec-
tional branching. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1052–
1062, Sofia, Bulgaria.
Michael A. Covington. 2001. A fundamental al-
gorithm for dependency parsing. In Proceedings of
the 39th Annual ACM Southeast Conference, pages
95–102, New York, NY, USA. ACM.
Yoav Goldberg and Joakim Nivre. 2012. A dynamic
oracle for arc-eager dependency parsing. In Pro-
ceedings of COLING 2012, pages 959–976, Mum-
bai, India, December. Association for Computa-
tional Linguistics.
Yoav Goldberg and Joakim Nivre. 2013. Training
deterministic parsers with non-deterministic oracles.
Transactions of the Association for Computational
Linguistics, 1:403–414.
Yoav Goldberg, Francesco Sartorio, and Giorgio Satta.
2014. A tabular method for dynamic oracles in
transition-based parsing. Transactions of the Asso-
ciation for Computational Linguistics, 2:119–130.
Carlos G´omez-Rodr´ıguez and Joakim Nivre. 2013.
Divisible transition systems and multiplanar de-
pendency parsing. Computational Linguistics,
39(4):799–845.
Carlos G´omez-Rodr´ıguez, Francesco Sartorio, and
Giorgio Satta. 2014. A polynomial-time dy-
namic oracle for non-projective dependency pars-
ing. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 917–927. Association for Compu-
tational Linguistics.
John Hopcroft and Robert Endre Tarjan. 1973. Al-
gorithm 447: Efficient algorithms for graph manip-
ulation. Commun. ACM, 16(6):372–378, June.
Peter Neuhaus and Norbert Br¨oker. 1997. The com-
plexity of recognition of linguistically adequate de-
pendency grammars. In Proceedings of the 35th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL) and the 8th Conference of
the European Chapter of the Association for Com-
putational Linguistics (EACL), pages 337–343.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
915–932, June.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of the
8th International Workshop on Parsing Technologies
(IWPT 03), pages 149–160. ACL/SIGPARSE.
Joakim Nivre. 2008. Algorithms for Deterministic In-
cremental Dependency Parsing. Computational Lin-
guistics, 34(4):513–553.
Robert Endre Tarjan. 1972. Depth-first search and lin-
ear graph algorithms. SIAM J. Comput., 1(2):146–
160.
Alexander Volokh and G¨unter Neumann. 2012. De-
pendency parsing with efficient feature extraction.
In Birte Glimm and Antonio Kr¨uger, editors, KI,
volume 7526 of Lecture Notes in Computer Science,
pages 253–256. Springer.
Alexander Volokh. 2013. Performance-Oriented De-
pendency Parsing. Doctoral dissertation, Saarland
University, Saarbr¨ucken, Germany.
Alexander Yeh. 2000. More accurate tests for the stat-
istical significance of result differences. In Proceed-
ings of the 18th International Conference on Com-
putational Linguistics (COLING), pages 947–953.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers - Volume 2, pages
188–193.
</reference>
<page confidence="0.997817">
261
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.211816">
<title confidence="0.999788">An Efficient Dynamic Oracle for Unrestricted Non-Projective Parsing</title>
<author confidence="0.483506">Carlos</author>
<abstract confidence="0.952527294117647">Departamento de da de A carlos.gomez@udc.es Abstract We define a dynamic oracle for the Covington non-projective dependency parser. This is not only the first dynamic oracle that supports arbitrary non-projectivity, but also considerably more efficient than the only existing oracle with restricted non-projectivity support. Experiments show that training with the dynamic oracle significantly improves parsing accuracy over the static oracle baseline on a wide range of treebanks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Giuseppe Attardi</author>
</authors>
<title>Experiments with a multilanguage non-projective dependency parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>166--170</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3327" citStr="Attardi (2006)" startWordPosition="505" endWordPosition="507">that configuration. While it is always easy to do this in exponential time by simulating all possible computations in the algorithm to obtain all reachable trees, it is not always clear how to achieve this calculation in polynomial time. At the moment, this problem has been solved for several projective parsers exploiting either arc-decomposability (Goldberg and Nivre, 2013) or tabularization of computations (Goldberg et al., 2014). However, for parsers that can handle crossing arcs, the only known dynamic oracle (G´omez-Rodr´ıguez et al., 2014) has been defined for a variant of the parser by Attardi (2006) that supports a restricted set of nonprojective trees. To our knowledge, no dynamic oracles are known for any transition-based parser that can handle unrestricted non-projectivity. In this paper, we define such an oracle for the Covington non-projective parser (Covington, 2001; Nivre, 2008), which can handle arbitrary non-projective dependency trees. As this algorithm is not arc-decomposable and its tabularization is NP-hard (Neuhaus and Br¨oker, 1997), we do not use the existing techniques to define dynamic oracles, but a reasoning specific to this parser. It is worth noting that, apart from</context>
</contexts>
<marker>Attardi, 2006</marker>
<rawString>Giuseppe Attardi. 2006. Experiments with a multilanguage non-projective dependency parser. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), pages 166– 170, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLLX shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="17596" citStr="Buchholz and Marsi, 2006" startWordPosition="3154" endWordPosition="3157">connected in constant time. On the other hand, a more efficient implementation than the one shown in Algorithm 1 (which we chose for clarity) can be achieved by more tightly coupling the oracle to the parser, as the relevant sets of arcs associated with a configuration can be obtained incrementally from those of the previous configuration. 4 Experiments To evaluate the performance of our approach, we conduct experiments on both static and dynamic Covington non-projective oracles. Concretely, we train an averaged perceptron model for 15 iterations on nine datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006) and all data259 Unigrams L0w; L0p; L0wp; L0l; L0hw; L0hp; L0hl; L0l0w; L0l0p; L0l0l; L0r0w; L0r0p; L0r0l; L0h2w; L0h2p; L0h2l; L0lw; L0lp; L0ll; L0rw; L0rp; L0rl; L0wd; L0pd; L0wvr; L0pvr; L0wvl; L0pvl; L0wsl; L0psl; L0wsr; L0psr; L1w; L1p; L1wp; R0w; R0p; R0wp; R0l0w; R0l0p; R0l0l; R0lw; R0lp; R0ll; R0wd; R0pd; R0wvl; R0pvl;R0wsl; R0psl; R1w; R1p; R1wp; R2w; R2p; R2wp; CLw; CLp; CLwp; CRw; CRp; CRwp; Pairs L0wp+R0wp; L0wp+R0w; L0w+R0wp; L0wp+R0p; L0p+R0wp; L0w+R0w; L0p+R0p;R0p+R1p; L0w+R0wd; L0p+R0pd; Triples R0p+R1p+R2p; L0p+R0p+R1p; L0hp+L0p+R0p; L0p+L0l0p+R0p; L0p+L0r0p+R0p; L0p+R0p+R0l0p</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLLX shared task on multilingual dependency parsing. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
<author>Andrew McCallum</author>
</authors>
<title>Transition-based dependency parsing with selectional branching.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1052--1062</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1197" citStr="Choi and McCallum, 2013" startWordPosition="171" endWordPosition="174">ves parsing accuracy over the static oracle baseline on a wide range of treebanks. 1 Introduction Greedy transition-based dependency parsers build analyses for sentences incrementally by following a sequence of transitions defined by an automaton, using a scoring model to choose the best transition to take at each state (Nivre, 2008). While this kind of parsers have become very popular, as they achieve competitive accuracy with especially fast parsing times; their raw accuracy is still behind that of slower alternatives like transitionbased parsers that use beam search (Zhang and Nivre, 2011; Choi and McCallum, 2013). For this reason, a current research challenge is to improve the accuracy of greedy transition-based parsers as much as possible without sacrificing efficiency. A relevant recent advance in this direction is the introduction of dynamic oracles (Goldberg and Nivre, 2012), an improvement in the training procedure of greedy parsers that can boost their accuracy without any impact on parsing speed. An oracle is a training component that selects the best transition(s) to take at a given configuration, using knowledge about the gold tree. Traditionally, transition-based parsers were trained to foll</context>
</contexts>
<marker>Choi, McCallum, 2013</marker>
<rawString>Jinho D. Choi and Andrew McCallum. 2013. Transition-based dependency parsing with selectional branching. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1052– 1062, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>A fundamental algorithm for dependency parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual ACM Southeast Conference,</booktitle>
<pages>95--102</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3605" citStr="Covington, 2001" startWordPosition="547" endWordPosition="548">lved for several projective parsers exploiting either arc-decomposability (Goldberg and Nivre, 2013) or tabularization of computations (Goldberg et al., 2014). However, for parsers that can handle crossing arcs, the only known dynamic oracle (G´omez-Rodr´ıguez et al., 2014) has been defined for a variant of the parser by Attardi (2006) that supports a restricted set of nonprojective trees. To our knowledge, no dynamic oracles are known for any transition-based parser that can handle unrestricted non-projectivity. In this paper, we define such an oracle for the Covington non-projective parser (Covington, 2001; Nivre, 2008), which can handle arbitrary non-projective dependency trees. As this algorithm is not arc-decomposable and its tabularization is NP-hard (Neuhaus and Br¨oker, 1997), we do not use the existing techniques to define dynamic oracles, but a reasoning specific to this parser. It is worth noting that, apart from being the first dynamic oracle supporting unrestricted nonprojectivity, our oracle is very efficient, solving the loss calculation in O(n). In contrast, the restricted non-projective oracle of G´omez-Rodriguez et al. 256 Proceedings of the 53rd Annual Meeting of the Associatio</context>
<context position="5777" citStr="Covington (2001)" startWordPosition="905" endWordPosition="906"> currently unprocessed words, and A is the set of dependencies built so far. Suppose that we parse a string w1 · · · wn, whose word occurrences will be identified with their indices 1 · · · n for simplicity. Then, the parser starts at an initial configuration cs(w1 ... wn) = ([], [], [1... n], 0), and executes transitions chosen from those in Figure 1 until a terminal configuration of the form {(A1, A2, [], A) E C1 is reached, and the sentence’s parse tree is obtained from A.1 The transition semantics is very simple, mirroring the double nested loop traversing word pairs in the formulation by Covington (2001). When the algorithm is in a configuration (A1Ii, A2, jIB, A), we will say that it is considering the focus words i and j, located at the end of the first list and at the beginning of the buffer. A decision is then made about whether these two words should be linked with a rightward arc i —* j (Right-Arc transition), a leftward arc i +— j (Left-Arc transition) or not linked (No-Arc transition). The first two choices will be unavailable in configurations where the newly-created arc would violate the single-head constraint (a node cannot have more than one incoming arc) or the acyclicity constra</context>
</contexts>
<marker>Covington, 2001</marker>
<rawString>Michael A. Covington. 2001. A fundamental algorithm for dependency parsing. In Proceedings of the 39th Annual ACM Southeast Conference, pages 95–102, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Joakim Nivre</author>
</authors>
<title>A dynamic oracle for arc-eager dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>959--976</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="1468" citStr="Goldberg and Nivre, 2012" startWordPosition="211" endWordPosition="214">to choose the best transition to take at each state (Nivre, 2008). While this kind of parsers have become very popular, as they achieve competitive accuracy with especially fast parsing times; their raw accuracy is still behind that of slower alternatives like transitionbased parsers that use beam search (Zhang and Nivre, 2011; Choi and McCallum, 2013). For this reason, a current research challenge is to improve the accuracy of greedy transition-based parsers as much as possible without sacrificing efficiency. A relevant recent advance in this direction is the introduction of dynamic oracles (Goldberg and Nivre, 2012), an improvement in the training procedure of greedy parsers that can boost their accuracy without any impact on parsing speed. An oracle is a training component that selects the best transition(s) to take at a given configuration, using knowledge about the gold tree. Traditionally, transition-based parsers were trained to follow a so-called static oracle, which is only defined on the configurations of a canonical computation that generates the gold tree, returning the next transition in said computation. In contrast, dynamic Daniel Fern´andez-Gonz´alez Departamento de Inform´atica Universidad</context>
</contexts>
<marker>Goldberg, Nivre, 2012</marker>
<rawString>Yoav Goldberg and Joakim Nivre. 2012. A dynamic oracle for arc-eager dependency parsing. In Proceedings of COLING 2012, pages 959–976, Mumbai, India, December. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Joakim Nivre</author>
</authors>
<title>Training deterministic parsers with non-deterministic oracles.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--403</pages>
<contexts>
<context position="3090" citStr="Goldberg and Nivre, 2013" startWordPosition="463" endWordPosition="467">her parsing accuracy. However, defining a usable dynamic oracle for a given parser is non-trivial in general, due to the need of calculating the loss of each configuration, i.e., the minimum Hamming loss to the gold tree from a tree reachable from that configuration. While it is always easy to do this in exponential time by simulating all possible computations in the algorithm to obtain all reachable trees, it is not always clear how to achieve this calculation in polynomial time. At the moment, this problem has been solved for several projective parsers exploiting either arc-decomposability (Goldberg and Nivre, 2013) or tabularization of computations (Goldberg et al., 2014). However, for parsers that can handle crossing arcs, the only known dynamic oracle (G´omez-Rodr´ıguez et al., 2014) has been defined for a variant of the parser by Attardi (2006) that supports a restricted set of nonprojective trees. To our knowledge, no dynamic oracles are known for any transition-based parser that can handle unrestricted non-projectivity. In this paper, we define such an oracle for the Covington non-projective parser (Covington, 2001; Nivre, 2008), which can handle arbitrary non-projective dependency trees. As this a</context>
<context position="7990" citStr="Goldberg and Nivre (2013)" startWordPosition="1305" endWordPosition="1308">ms in practice, as it allows for relevant optimizations in feature extraction that cannot be implemented in other parsers. In fact, one of the fastest dependency parsers to date uses this algorithm (Volokh, 2013). 3 The oracle As sketched in Sect. 1, a dynamic oracle is a training component that, given a configuration c and a gold tree tG, provides the set of transitions that are applicable in c and lead to trees with minimum Hamming loss with respect to tG. The Hamming loss between a tree t and tG, written G(t, tG), is the number of nodes that have a different head in t than in tG. Following Goldberg and Nivre (2013), we say that a set of arcs A is reachable from configuration c, written c A, if there is some (possibly empty) path of transitions from c to some configuration c&apos; = (A1, A2, B, A&apos;), with A C_ A&apos;. Then, we can define the loss of a configuration as e(c) = min t|c t and the set of transitions that must be returned by a correct dynamic oracle is then od(c, tG) = Iτ I e(c) − e(τ(c)) = 01, i.e., the transitions that do not increase configuration loss, and hence lead to the best parse (in terms of loss) reachable from c. Therefore, implementing a dynamic oracle reduces to computing the loss e(c) for</context>
</contexts>
<marker>Goldberg, Nivre, 2013</marker>
<rawString>Yoav Goldberg and Joakim Nivre. 2013. Training deterministic parsers with non-deterministic oracles. Transactions of the Association for Computational Linguistics, 1:403–414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Francesco Sartorio</author>
<author>Giorgio Satta</author>
</authors>
<title>A tabular method for dynamic oracles in transition-based parsing.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>2--119</pages>
<contexts>
<context position="3148" citStr="Goldberg et al., 2014" startWordPosition="473" endWordPosition="476">le for a given parser is non-trivial in general, due to the need of calculating the loss of each configuration, i.e., the minimum Hamming loss to the gold tree from a tree reachable from that configuration. While it is always easy to do this in exponential time by simulating all possible computations in the algorithm to obtain all reachable trees, it is not always clear how to achieve this calculation in polynomial time. At the moment, this problem has been solved for several projective parsers exploiting either arc-decomposability (Goldberg and Nivre, 2013) or tabularization of computations (Goldberg et al., 2014). However, for parsers that can handle crossing arcs, the only known dynamic oracle (G´omez-Rodr´ıguez et al., 2014) has been defined for a variant of the parser by Attardi (2006) that supports a restricted set of nonprojective trees. To our knowledge, no dynamic oracles are known for any transition-based parser that can handle unrestricted non-projectivity. In this paper, we define such an oracle for the Covington non-projective parser (Covington, 2001; Nivre, 2008), which can handle arbitrary non-projective dependency trees. As this algorithm is not arc-decomposable and its tabularization is</context>
</contexts>
<marker>Goldberg, Sartorio, Satta, 2014</marker>
<rawString>Yoav Goldberg, Francesco Sartorio, and Giorgio Satta. 2014. A tabular method for dynamic oracles in transition-based parsing. Transactions of the Association for Computational Linguistics, 2:119–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Joakim Nivre</author>
</authors>
<title>Divisible transition systems and multiplanar dependency parsing.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>4</issue>
<marker>G´omez-Rodr´ıguez, Nivre, 2013</marker>
<rawString>Carlos G´omez-Rodr´ıguez and Joakim Nivre. 2013. Divisible transition systems and multiplanar dependency parsing. Computational Linguistics, 39(4):799–845.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Francesco Sartorio</author>
<author>Giorgio Satta</author>
</authors>
<title>A polynomial-time dynamic oracle for non-projective dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>917--927</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>G´omez-Rodr´ıguez, Sartorio, Satta, 2014</marker>
<rawString>Carlos G´omez-Rodr´ıguez, Francesco Sartorio, and Giorgio Satta. 2014. A polynomial-time dynamic oracle for non-projective dependency parsing. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 917–927. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hopcroft</author>
<author>Robert Endre Tarjan</author>
</authors>
<title>Algorithm 447: Efficient algorithms for graph manipulation.</title>
<date>1973</date>
<journal>Commun. ACM,</journal>
<volume>16</volume>
<issue>6</issue>
<contexts>
<context position="16892" citStr="Hopcroft and Tarjan, 1973" startWordPosition="3039" endWordPosition="3042">hether the two given nodes are weakly connected in A, and can also be resolved in O(1), by querying the disjoint set data structure that implementations of the Covington algorithm commonly use for the parser’s acyclicity checks (Nivre, 2008). It is worth noting that the linear-time complexity can also be achieved by a standalone implementation of the loss calculation algorithm, without recurse to the parser’s auxiliary data structures (although this is dubiously practical). To do so, we can implement WEAKLYCONNECTED so that the first call computes the connected components of A in linear time (Hopcroft and Tarjan, 1973) and subsequent calls use this information to find out if two nodes are weakly connected in constant time. On the other hand, a more efficient implementation than the one shown in Algorithm 1 (which we chose for clarity) can be achieved by more tightly coupling the oracle to the parser, as the relevant sets of arcs associated with a configuration can be obtained incrementally from those of the previous configuration. 4 Experiments To evaluate the performance of our approach, we conduct experiments on both static and dynamic Covington non-projective oracles. Concretely, we train an averaged per</context>
</contexts>
<marker>Hopcroft, Tarjan, 1973</marker>
<rawString>John Hopcroft and Robert Endre Tarjan. 1973. Algorithm 447: Efficient algorithms for graph manipulation. Commun. ACM, 16(6):372–378, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Neuhaus</author>
<author>Norbert Br¨oker</author>
</authors>
<title>The complexity of recognition of linguistically adequate dependency grammars.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL) and the 8th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>337--343</pages>
<marker>Neuhaus, Br¨oker, 1997</marker>
<rawString>Peter Neuhaus and Norbert Br¨oker. 1997. The complexity of recognition of linguistically adequate dependency grammars. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL) and the 8th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 337–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007,</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03),</booktitle>
<pages>149--160</pages>
<publisher>ACL/SIGPARSE.</publisher>
<contexts>
<context position="7241" citStr="Nivre, 2003" startWordPosition="1173" endWordPosition="1174"> focus words in 1The arcs in A form a forest, but we convert it to a tree by linking any node without a head as a dependent of an artificial node at position 0 that acts as a dummy root. From now on, when we refer to some dependency graph as a tree, we assume that this transformation is being implicitly made. the resulting configuration will be j and j + 1. The result is a parser that can generate any possible dependency tree for the input, and runs in quadratic worst-case time. Although in theory this complexity can seem like a drawback compared to linear-time transition-based parsers (e.g. (Nivre, 2003; G´omez-Rodr´ıguez and Nivre, 2013)), it has been shown by Volokh and Neumann (2012) to actually outperform linear algorithms in practice, as it allows for relevant optimizations in feature extraction that cannot be implemented in other parsers. In fact, one of the fastest dependency parsers to date uses this algorithm (Volokh, 2013). 3 The oracle As sketched in Sect. 1, a dynamic oracle is a training component that, given a configuration c and a gold tree tG, provides the set of transitions that are applicable in c and lead to trees with minimum Hamming loss with respect to tG. The Hamming l</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03), pages 149–160. ACL/SIGPARSE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for Deterministic Incremental Dependency Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="908" citStr="Nivre, 2008" startWordPosition="127" endWordPosition="128">r. This is not only the first dynamic oracle that supports arbitrary non-projectivity, but also considerably more efficient (O(n)) than the only existing oracle with restricted non-projectivity support. Experiments show that training with the dynamic oracle significantly improves parsing accuracy over the static oracle baseline on a wide range of treebanks. 1 Introduction Greedy transition-based dependency parsers build analyses for sentences incrementally by following a sequence of transitions defined by an automaton, using a scoring model to choose the best transition to take at each state (Nivre, 2008). While this kind of parsers have become very popular, as they achieve competitive accuracy with especially fast parsing times; their raw accuracy is still behind that of slower alternatives like transitionbased parsers that use beam search (Zhang and Nivre, 2011; Choi and McCallum, 2013). For this reason, a current research challenge is to improve the accuracy of greedy transition-based parsers as much as possible without sacrificing efficiency. A relevant recent advance in this direction is the introduction of dynamic oracles (Goldberg and Nivre, 2012), an improvement in the training procedu</context>
<context position="3619" citStr="Nivre, 2008" startWordPosition="549" endWordPosition="550">projective parsers exploiting either arc-decomposability (Goldberg and Nivre, 2013) or tabularization of computations (Goldberg et al., 2014). However, for parsers that can handle crossing arcs, the only known dynamic oracle (G´omez-Rodr´ıguez et al., 2014) has been defined for a variant of the parser by Attardi (2006) that supports a restricted set of nonprojective trees. To our knowledge, no dynamic oracles are known for any transition-based parser that can handle unrestricted non-projectivity. In this paper, we define such an oracle for the Covington non-projective parser (Covington, 2001; Nivre, 2008), which can handle arbitrary non-projective dependency trees. As this algorithm is not arc-decomposable and its tabularization is NP-hard (Neuhaus and Br¨oker, 1997), we do not use the existing techniques to define dynamic oracles, but a reasoning specific to this parser. It is worth noting that, apart from being the first dynamic oracle supporting unrestricted nonprojectivity, our oracle is very efficient, solving the loss calculation in O(n). In contrast, the restricted non-projective oracle of G´omez-Rodriguez et al. 256 Proceedings of the 53rd Annual Meeting of the Association for Computat</context>
<context position="4848" citStr="Nivre (2008)" startWordPosition="736" endWordPosition="737"> and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 256–261, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics (2014) has O(n8) time complexity. The rest of the paper is organized as follows: after a quick outline of Covington’s parser in Sect. 2, we present the oracle and prove its correctness in Sect. 3. Experiments are reported in Sect. 4, and Sect. 5 contains concluding remarks. 2 Preliminaries We will define a dynamic oracle for the nonprojective parser originally defined by Covington (2001), and implemented by Nivre (2008) under the transition-based parsing framework. For space reasons, we only sketch the parser very briefly, and refer to the above reference for more details. Parser configurations are of the form c = (A1, A2, B, A), where A1 and A2 are lists of partially processed words, B is another list (called the buffer) with currently unprocessed words, and A is the set of dependencies built so far. Suppose that we parse a string w1 · · · wn, whose word occurrences will be identified with their indices 1 · · · n for simplicity. Then, the parser starts at an initial configuration cs(w1 ... wn) = ([], [], [1</context>
<context position="16507" citStr="Nivre, 2008" startWordPosition="2978" endWordPosition="2979">t +— max(x, y) 6: if j &gt; right V 7: (j = right ∧ i &lt; left) V 8: (]z &gt; 0,z =�x : z —* y E A)V 9: WEAKLYCONNECTED(A, x, y) then 10: U+—uU{x—*y} 11: I +— tG \ U &gt; Variable I is for I(c, tG) 12: return |U |+ COUNTCYCLES(A U I) linear time: the condition on line 8 can be computed in constant time by recovering the head of y. The call to WEAKLYCONNECTED in line 9 finds out whether the two given nodes are weakly connected in A, and can also be resolved in O(1), by querying the disjoint set data structure that implementations of the Covington algorithm commonly use for the parser’s acyclicity checks (Nivre, 2008). It is worth noting that the linear-time complexity can also be achieved by a standalone implementation of the loss calculation algorithm, without recurse to the parser’s auxiliary data structures (although this is dubiously practical). To do so, we can implement WEAKLYCONNECTED so that the first call computes the connected components of A in linear time (Hopcroft and Tarjan, 1973) and subsequent calls use this information to find out if two nodes are weakly connected in constant time. On the other hand, a more efficient implementation than the one shown in Algorithm 1 (which we chose for cla</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for Deterministic Incremental Dependency Parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Endre Tarjan</author>
</authors>
<title>Depth-first search and linear graph algorithms.</title>
<date>1972</date>
<journal>SIAM J. Comput.,</journal>
<volume>1</volume>
<issue>2</issue>
<pages>160</pages>
<contexts>
<context position="15397" citStr="Tarjan, 1972" startWordPosition="2753" endWordPosition="2754"> min(x, y), and we cannot move it back, • there is some z =� 0, z =� x such that z —* y E A, as in this case the single-head constraint prevents us from creating x —* y, • x and y are on the same weakly connected component of A, as in this case the acyclicity constraint will not let us create x —* y. All of these arcs can be trivially enumerated in O(n) time (in fact, they can be updated in O(1) if we start from the configuration that preceded c). The second term of the loss, n,(AUI(c, tG)), can be computed by obtaining I(c, tG) as tG\U(c, tG) to then apply a standard cycle-finding algorithm (Tarjan, 1972) which, for a graph with maximum in-degree 1, runs in O(n) time. Algorithm 1 presents the resulting loss calculation algorithm in pseudocode form, where COUNTCYCLES is a function that counts the number of cycles in the given graph in linear time as mentioned above. Note that the for loop runs in Algorithm 1 Computation of the loss of a configuration. 1: function LOSS(c = (λ,|i, λ2, j|B, A), tG) 2: U +— 0 &gt; Variable U is for U(c, tG) 3: for each x —* y E (tG \ A) do 4: left +— min(x, y) 5: right +— max(x, y) 6: if j &gt; right V 7: (j = right ∧ i &lt; left) V 8: (]z &gt; 0,z =�x : z —* y E A)V 9: WEAKLY</context>
</contexts>
<marker>Tarjan, 1972</marker>
<rawString>Robert Endre Tarjan. 1972. Depth-first search and linear graph algorithms. SIAM J. Comput., 1(2):146– 160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Volokh</author>
<author>G¨unter Neumann</author>
</authors>
<title>Dependency parsing with efficient feature extraction.</title>
<date>2012</date>
<booktitle>In Birte Glimm and</booktitle>
<volume>7526</volume>
<pages>253--256</pages>
<editor>Antonio Kr¨uger, editors, KI,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="7326" citStr="Volokh and Neumann (2012)" startWordPosition="1184" endWordPosition="1187">ee by linking any node without a head as a dependent of an artificial node at position 0 that acts as a dummy root. From now on, when we refer to some dependency graph as a tree, we assume that this transformation is being implicitly made. the resulting configuration will be j and j + 1. The result is a parser that can generate any possible dependency tree for the input, and runs in quadratic worst-case time. Although in theory this complexity can seem like a drawback compared to linear-time transition-based parsers (e.g. (Nivre, 2003; G´omez-Rodr´ıguez and Nivre, 2013)), it has been shown by Volokh and Neumann (2012) to actually outperform linear algorithms in practice, as it allows for relevant optimizations in feature extraction that cannot be implemented in other parsers. In fact, one of the fastest dependency parsers to date uses this algorithm (Volokh, 2013). 3 The oracle As sketched in Sect. 1, a dynamic oracle is a training component that, given a configuration c and a gold tree tG, provides the set of transitions that are applicable in c and lead to trees with minimum Hamming loss with respect to tG. The Hamming loss between a tree t and tG, written G(t, tG), is the number of nodes that have a dif</context>
</contexts>
<marker>Volokh, Neumann, 2012</marker>
<rawString>Alexander Volokh and G¨unter Neumann. 2012. Dependency parsing with efficient feature extraction. In Birte Glimm and Antonio Kr¨uger, editors, KI, volume 7526 of Lecture Notes in Computer Science, pages 253–256. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Volokh</author>
</authors>
<title>Performance-Oriented Dependency Parsing. Doctoral dissertation,</title>
<date>2013</date>
<institution>Saarland University,</institution>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="7577" citStr="Volokh, 2013" startWordPosition="1227" endWordPosition="1228">tion will be j and j + 1. The result is a parser that can generate any possible dependency tree for the input, and runs in quadratic worst-case time. Although in theory this complexity can seem like a drawback compared to linear-time transition-based parsers (e.g. (Nivre, 2003; G´omez-Rodr´ıguez and Nivre, 2013)), it has been shown by Volokh and Neumann (2012) to actually outperform linear algorithms in practice, as it allows for relevant optimizations in feature extraction that cannot be implemented in other parsers. In fact, one of the fastest dependency parsers to date uses this algorithm (Volokh, 2013). 3 The oracle As sketched in Sect. 1, a dynamic oracle is a training component that, given a configuration c and a gold tree tG, provides the set of transitions that are applicable in c and lead to trees with minimum Hamming loss with respect to tG. The Hamming loss between a tree t and tG, written G(t, tG), is the number of nodes that have a different head in t than in tG. Following Goldberg and Nivre (2013), we say that a set of arcs A is reachable from configuration c, written c A, if there is some (possibly empty) path of transitions from c to some configuration c&apos; = (A1, A2, B, A&apos;), with</context>
</contexts>
<marker>Volokh, 2013</marker>
<rawString>Alexander Volokh. 2013. Performance-Oriented Dependency Parsing. Doctoral dissertation, Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>947--953</pages>
<contexts>
<context position="21114" citStr="Yeh, 2000" startWordPosition="3704" endWordPosition="3705">se 85.70 82.78 86.23 83.27 Slovene 75.31 68.97 76.76* 70.35* Spanish 78.82 75.84 79.87* 76.97* Swedish 86.78 81.29 86.66 81.21 Average 82.72 78.39 83.52 79.13 Table 2: Parsing accuracy (UAS and LAS, including punctuation) of Covington non-projective parser with static (s-Covington) and dynamic (dCovington) oracles on CoNLL-XI (first block) and CoNLL-X (second block) datasets. For each language, we run five experiments with the same setup but different seeds and report the averaged accuracy. Best results for each language are shown in boldface. Statistically significant improvements (α = .05) (Yeh, 2000) are marked with ∗. age points in UAS and 0.71 in LAS, while our approach achieves 0.80 in UAS and 0.74 in LAS. 5 Conclusion We have defined the first dynamic oracle for a transition-based parser supporting unrestricted non-projectivity. The oracle is very efficient, computing loss in O(n), compared to O(n8) for the only previously known dynamic oracle with support for a subset of non-projective trees (G´omezRodr´ıguez et al., 2014). Experiments on the treebanks from the CoNLLX and CoNLL-XI shared tasks show that the dynamic oracle significantly improves accuracy on many languages over a stati</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the 18th International Conference on Computational Linguistics (COLING), pages 947–953.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<volume>2</volume>
<pages>188--193</pages>
<contexts>
<context position="1171" citStr="Zhang and Nivre, 2011" startWordPosition="167" endWordPosition="170">cle significantly improves parsing accuracy over the static oracle baseline on a wide range of treebanks. 1 Introduction Greedy transition-based dependency parsers build analyses for sentences incrementally by following a sequence of transitions defined by an automaton, using a scoring model to choose the best transition to take at each state (Nivre, 2008). While this kind of parsers have become very popular, as they achieve competitive accuracy with especially fast parsing times; their raw accuracy is still behind that of slower alternatives like transitionbased parsers that use beam search (Zhang and Nivre, 2011; Choi and McCallum, 2013). For this reason, a current research challenge is to improve the accuracy of greedy transition-based parsers as much as possible without sacrificing efficiency. A relevant recent advance in this direction is the introduction of dynamic oracles (Goldberg and Nivre, 2012), an improvement in the training procedure of greedy parsers that can boost their accuracy without any impact on parsing speed. An oracle is a training component that selects the best transition(s) to take at a given configuration, using knowledge about the gold tree. Traditionally, transition-based pa</context>
<context position="19149" citStr="Zhang and Nivre (2011)" startWordPosition="3401" endWordPosition="3404">nd Xir and Xir, the farthest and closest right dependents, respectively. CL and CR are the first and last words between L0 and R0 whose head is not in the interval [L0, R0]. Finally, w stands for word form; p for PoS tag; l for dependency label; d is the distance between L0 and R0; vl, vr are the left/right valencies (number of left/right dependents); and sl, sr the left/right label sets (dependency labels of left/right dependents). sets from the CoNLL-XI shared task (Nivre et al., 2007). We use the same feature templates for all languages, which result from adapting the features described by Zhang and Nivre (2011) to the data structures of the Covington non-projective parser, and are listed in detail in Table 1. Table 2 reports the accuracy obtained by the Covington non-projective parser with both oracles. As we can see, the dynamic oracle implemented in the Covington algorithm improves over the accuracy of the static version on all datasets except Japanese and Swedish, and most improvements are statistically significant at the .05 level.3 In addition, the Covington dynamic oracle achieves a greater average improvement in accuracy than the Attardi dynamic oracle (G´omezRodr´ıguez et al., 2014) over the</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, pages 188–193.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>