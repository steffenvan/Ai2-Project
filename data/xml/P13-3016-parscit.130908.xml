<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007266">
<title confidence="0.9971665">
Detecting Chronic Critics Based on
Sentiment Polarity and User’s Behavior in Social Media
</title>
<author confidence="0.84373">
Sho Takase† Akiko Murakami‡ Miki Enoki‡ Naoaki Okazaki† Kentaro Inui†
</author>
<affiliation confidence="0.729283">
Tohoku University† IBM Research - Tokyo‡
</affiliation>
<email confidence="0.877593">
{takase, okazaki, inui}@ecei.tohoku.ac.jp
{akikom, enomiki}@jp.ibm.com
</email>
<sectionHeader confidence="0.993824" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999519">
There are some chronic critics who al-
ways complain about the entity in social
media. We are working to automatically
detect these chronic critics to prevent the
spread of bad rumors about the reputation
of the entity. In social media, most com-
ments are informal, and, there are sarcas-
tic and incomplete contexts. This means
that it is difficult for current NLP technol-
ogy such as opinion mining to recognize
the complaints. As an alternative approach
for social media, we can assume that users
who share the same opinions will link to
each other. Thus, we propose a method
that combines opinion mining with graph
analysis for the connections between users
to identify the chronic critics. Our ex-
perimental results show that the proposed
method outperforms analysis based only
on opinion mining techniques.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999926827586207">
On a social media website, there may be millions
of users and large numbers of comments. The
comments in social media are related to the real
world in such fields as marketing and politics. An-
alyzing comments in social media has been shown
to be effective in predicting the behaviors of stock
markets and of voters in elections (Bollen et al.,
2011; Tumasjan et al., 2010; O’Connor et al.,
2010). Because of their effects on the real world,
some complaints may harm the reputation of a cor-
poration or an individual and cause serious dam-
age. Consider a comment such as “Working for
Company A is really awful” as an example. The
complaint gives viewers a negative impression of
Company A and can increase the number of people
who think the company is bad.
Some complaints are expressed by a specific
user who is always criticizing a specific target en-
tity (in this example, Company A). We call this
user a chronic critic of that entity, a person who
is deliberately trying to harm the reputation of the
entity. That is, a chronic critic is trying to run a
negative campaign against the entity. If the entity
is aware of its own chronic critics, then it is able
to take prompt action to stop the malicious com-
plaints. When the complaints are false, the entity
can use that defense. In contrast, if the chronic
critics are justified, then the entity should address
the concerns to limit the damage. Hence, to han-
dle malicious rumors, it is important to detect the
chronic critics.
However, it is generally quite difficult for a
computer to detect a chronic critic’s comments,
since especially the comments in social media are
often quite informal. In addition, there are com-
plexities such as sarcasm and incomplete contexts.
For example, if Company A has been involved in a
widely recognized fiasco, then some chronic crit-
ics might sarcastically write “good job” or “won-
derful” about Company A. They are using posi-
tive words, but in the context they are effectively
criticizing Company A. Some chronic critics bash
a target entity solely with sarcasm, so they dam-
age the target with positive words. It is exceed-
ingly difficult to directly detect these chronic crit-
ics based on their comments. In an example of
an incomplete context, if one author starts an ex-
change with a comment such as “The new prod-
uct from Company A is difficult to use” and an-
other user responds with something like “Fool”,
we cannot easily recognize the meaning of this
comment as related to “Company A being foolish
because the product really is difficult to use” or
whether “the user is the fool because the product
is easy for other people to use”. To find chronic
critics for a given entity, we need to identify the
actual target of the complaints. Take the comment
“Company B is much worse than Company A” for
</bodyText>
<page confidence="0.975919">
110
</page>
<note confidence="0.896023">
Proceedings of the ACL Student Research Workshop, pages 110–116,
</note>
<page confidence="0.429266">
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</page>
<bodyText confidence="0.991771542857143">
example. This comment is probably complaining
about Company B but not Company A. In contrast,
most of the previous work on sentiment analysis
in social media does not consider these kinds of
problems (Barbosa and Feng, 2010; Davidov et
al., 2010; Speriosu et al., 2011).
Switching to the behavior of each user, in so-
cial media we often see that users who have sim-
ilar ideas will tend to cooperate with each other.
In fact, previous work suggests that users who
have the same opinions tend to create links to each
other (Conover et al., 2011b; Yang et al., 2012).
Because chronic critics share the purpose of at-
tacking some target’s reputation, they may also
decide to cooperate. For this reason, to detect
chronic critics, we believe that information about
the connections among users will be effective.
In this paper, we present a method that com-
bines opinion mining based on NLP and graph
analysis of the connections among users to rec-
ognize the chronic critics. In the experiments, we
demonstrate the difficulty in detecting chronic crit-
ics by analyzing only the individual comments. In
addition, we investigate the effectiveness of using
the connections between users, i.e., using the pro-
posed method. For our experiments, we used Twit-
ter, a popular social media service. In particular,
we focus on Japanese comments on Twitter.
This paper is organized as follows. Section 2
reviews related work. Section 3 presents the pro-
posed method which applies the opinion mining
and graph analysis. Section 4 demonstrates the ef-
fectiveness of the proposed method and discusses
the experimental results. Section 5 concludes this
paper.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999957020408164">
In recent years, an interest in opinion mining in
online communities has emerged (Conover et al.,
2011a; O’Connor et al., 2010; Speriosu et al.,
2011; Murakami and Raymond, 2010; Barbosa
and Feng, 2010; Davidov et al., 2010). O’Connor
et al. (2010), Barbosa and Feng (2010), Davidov
et al. (2010), and Speriosu et al. (2011) proposed
methods to predict a sentiment polarity (i.e., pos-
itive or negative) of a comment in social media.
O’Connor et al. (2010) studied a subjectivity lexi-
con. Barbosa and Feng (2010) and Davidov et al.
(2010) used machine learning approaches. Spe-
riosu et al. (2011) introduced connections between
words, emoticons, tags, n-grams, comments and
users. These studies did not identify the target of
the polarized sentiment of each comment.
Conover et al. (2011a) proposed a method that
predicts the political polarity of a social media
user based on the connections between users and
tags. They demonstrated that label propagation
on the graph representing the connections between
users is effective. However, this method is not
guaranteed to obtain the optimal solution. In con-
trast, our research uses graph analysis that con-
verges on the optimal solution.
Murakami and Raymond (2010) proposed a
method that uses the connections between users
to predict each user’s opinion, i.e., support or op-
pose a topic in online debates. They analyzed
the content of the discussions to infer the connec-
tions. However, in social media, it is difficult to in-
fer connections based on content because of such
complexities as incomplete contexts. To address
these problem, we analyzed the behavior of the
users to predict the connections between users.
Our task is similar to spammer detection (Wang,
2010; Yang et al., 2012). Wang (2010) pro-
posed a method using a classifier to detect spam-
mers. They used the content in the comments
and the number of linked users as features. Yang
et al. (2012) analyzed spammer communities and
demonstrated that spammers closely link to each
other in social media. They also proposed a
method that extracts spammers using the connec-
tions between users. While Wang (2010) and Yang
et al. (2012) required manually annotated data for
training or as seeds, we extract the seeds for the
graph analysis automatically through opinion min-
ing.
</bodyText>
<sectionHeader confidence="0.991035" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.997758071428571">
Figure 1 presents an overview of the proposed
method. The proposed method has two phases,
opinion mining and graph analysis. First, we ex-
tract a few chronic critics by analyzing the opin-
ions of many users referencing the target entity.
For the opinion mining, we are initially looking
for users who strongly criticize the target entity. In
Figure 1, given Company A as a target entity, we
find users “b” and “e” since they said “Working
for Company A is really awful” and “This product
from Company A is useless”. However, we may
miss the other chronic critics since they used sar-
casm and incomplete contexts.
Next, we find the users who are linked to the
</bodyText>
<page confidence="0.993806">
111
</page>
<note confidence="0.279577">
The graph based on a relationship of agreements Results of the graph analysis
</note>
<figureCaption confidence="0.999784">
Figure 1: Overview of proposed method
</figureCaption>
<figure confidence="0.998862584905661">
Company A is a bad company.
A new product of Company A is difficult to use.
a
b
c
d
Fiasco of Company A occurs almost every day.
The product from Company A is difficult to use.
Company B is much worse than Company A.
This product from Company A is useless.
A product of Company A is wonderful.
Why do people praise Company A?
Company A, good job!
g
e
f
Company A always makes shitty produces.
Working for Company A is really awful.
The attitude of Company A is perfect.
I use only products of Company A.
I like products of Company A.
Company A is very very nice.
Opinion
Making
graph
mining
b
e
An account of
x a target entity
Chronic critics extracted by the opinion mining
Company A always makes shitty produces.
Working for Company A is really awful.
A product of Company A is useless.
Comments in social media
b
c
a
e
d
f
g
Graph
analysis
x x
b
c
a
e
d
g
f
Chronic critics
</figure>
<bodyText confidence="0.998964083333333">
chronic critics that were detected through opinion
mining. We built a graph in which the users are
represented by nodes and the links between the
users are represented by edges.We recognize ad-
ditional chronic critics based on the graph anal-
ysis. In the example of Figure 1, we find more
chronic critics not recognized by the opinion min-
ing, such as “a” and “c”, because they are linked
to the chronic critics “b” and “e”. In this section,
we explain the opinion mining and graph analysis.
Since a comment in Twitter is called a tweet, we
use the term tweet below.
</bodyText>
<subsectionHeader confidence="0.999072">
3.1 Opinion Mining
</subsectionHeader>
<bodyText confidence="0.999885">
As defined in Section 1, we defined a user who
frequently criticizes a target entity as a chronic
critic. Therefore, we classify the tweets of each
user into critical or non-critical and label any users
who complain about the target entity many times
as chronic critics. Because we want to investi-
gate the opinions of each user in public, we an-
alyze public tweets, excluding the private conver-
sations between users. In Twitter, this means we
ignore a reply that is a response to a specific user
named username (written in the format “@user-
name response”) and QT that is a mention in a
quoted tweet from username (written in the format
“mention RT @username: quoted tweet”).
We assume a phrase representing negative po-
larity or profanity to be critical phrases. The pro-
posed method determines whether a tweet com-
plains about the target entity by investigating a
critical phrase and the target of the phrase.
Note that a negative polarity is represented by
declinable words or substantives. We used the
sentiment analyzer created by Kanayama and Na-
sukawa (2012) to detect a phrase representing neg-
</bodyText>
<figure confidence="0.7474695">
A4±0 TpI-I *�!M 000
Working for Company A is really awful.
</figure>
<figureCaption confidence="0.999691">
Figure 2: Example of critic tweet
</figureCaption>
<bodyText confidence="0.989868793103448">
ative polarity by using declinable words. We used
the lexicon collected by Higashiyama et al. (2008)
to find negative polarity in substantives. For de-
tecting profanity, we use a profane lexicon col-
lected by Ogino et al. (2012).
The sentiment analyzer can find not only senti-
ment phrases but the targets of the phrases based
on syntactic parsing and the case frames&apos;. How-
ever, because there are many informal tweets and
because most users omit the grammatical case in
tweets, the sentiment analyzer often fails to cap-
ture any target. To address this problem, in ad-
dition to a target extracted by the sentiment ana-
lyzer, we obtain a target based on the dependency
tree. We extract nouns in parent and child phrases
within distance 2 from a critical phrase in the de-
pendency tree.
Figure 2 shows an example of a Japanese tweet
criticizing Company A and its English translation.
The Japanese tweet is split into phrase-like units
(bunsetsu). Each English phrase is linked to the
corresponding bunsetsu by a dotted line. The de-
pendency relationships among the bunsetsu are ex-
pressed by the arrows. In the tweet, the black-
edged phrase “awful” is a critical phrase. We ex-
tract the nouns in “Working for” and “Company
A is” as targets of the critical phrase since these
&apos;A case frame is a list which represents grammatical cases
of a predicate.
</bodyText>
<page confidence="0.993013">
112
</page>
<bodyText confidence="0.9959283">
phrases are parents within distance 2 of the criti-
cal phrase. Therefore, we decide that the tweet is
criticizing Company A.
Since a chronic critic frequently complains
about the target entity, we can predict that most
of the tweets written by a chronic critic of the tar-
get entity will be critical tweets. Therefore, we
can calculate a ratio of critical tweets for all of the
tweets about the target entity. We score the user ui
with equation (1).
</bodyText>
<equation confidence="0.8232615">
ni (1)
Ni
</equation>
<bodyText confidence="0.999745">
Ni is the number of all tweets about the target en-
tity and ni is the number of critical tweets about
the entity by that user 2. We extract the top M
users based on scorei as chronic critics.
</bodyText>
<subsectionHeader confidence="0.998547">
3.2 Graph Analysis
</subsectionHeader>
<bodyText confidence="0.999536">
In social media, it is often very difficult to deter-
mine whether a tweet is critical since many tweets
include sarcasm or incomplete contexts. The opin-
ion mining may miss numerous complaints with
sarcasm or incomplete contexts. To resolve this
problem, we apply user behaviors. In social me-
dia, we assume that users having the same opinion
interact with each other in order to demonstrate the
correctness of their opinion. In particular, since
the purpose of chronic critics is to spread the bad
reputation, we assume that they want to assist each
other. We supplement the opinion mining by a
graph analysis using this assumption. Thus, we
make a graph representing connections among the
users and use label propagation on the graph based
on the results of the opinion mining as the seeds.
In addition, we believe that a user will try to
spread user matching opinions. This implies that a
user who spreads the opinion of another of agrees
with the author of that opinion. In Twitter, a user
can spread an opinion as an RT, which is a repost-
ing of a tweet by a username (written in the format
“RT @username: tweet”). Conover et al. (2011b)
demonstrated that they can make a graph repre-
senting the connections among users who support
each others opinions by using RTs. Hence, an RT
expresses a relationship of endorsement. We also
created a graph based on this feature.
Our graph has m users (U = Ju1,..., um}) as
nodes, where ui connects with uj via an edge that
</bodyText>
<footnote confidence="0.8709125">
2The formula (1) assigns a high score to a user if the user
only produces one or two tweets about the target entity and
those tweets are negative. To prevent this, we disregard the
users whose the number of tweets are fewer than 5.
</footnote>
<bodyText confidence="0.999956">
has weight wij (0 &lt; wij &lt; 1) and wij corresponds
to the degree to which ui supports uj. We calcu-
late wij by using Equation (2).
</bodyText>
<equation confidence="0.9636345">
wij = 1 rij rji (2)
2 (Ri + Rj
</equation>
<bodyText confidence="0.998452538461538">
rij is the total RT tweets of uj by ui and Ri is the
number of RTs by ui. Therefore, the more ui and
uj RT each other, the more weight wij is close to
1. In contrast, if ui and uj rarely RT each other, the
value of wij will approach 0. In addition, this wij
definition is symmetric means (i.e., wij = wji).
We find more new chronic critics by label prop-
agation on the graph. We use the chronic critics
obtained by the opinion mining as seeds. It is as-
sumed that a user who supports the target entity is
not a chronic critic. Using this knowledge, we use
the account of the target entity as a seed.
The label propagation assigns a confidence
score c = (c1, ..., cm) to each node U =
u1, ..., um, where the score is a real number be-
tween −1 and 1. A score close to 1 indicates
that we are very confident that the node (user) is
a chronic critic. A score close to −1 indicates that
we are sure that the node is not a chronic critic. In
addition, the scores of seeds are fixed and cannot
be changed. The scores of chronic critics obtained
by the opinion mining are 1 and the score of the
target entity is set to −1. To formulate the label
propagation as an optimization problem, we used
the loss function proposed by Zhu et al. (2003),
because wij &gt; 0 for all i, j.
</bodyText>
<equation confidence="0.634309">
wij(ci − cj)2 (3)
</equation>
<bodyText confidence="0.9999092">
To minimize E(c), ci is close to cj when wij
is greater than 0. That is, if the users support
each other, the scores of the users are close to
each other. Thus, by minimizing E(c), we as-
sign the confidence scores considering the results
of the opinion mining and agreement relationships
among the users. We find the users that have
scores greater than the threshold.
We believe that if the distance between users on
the graph is large, then users slightly support each
other. However, we can assign a score of 1 to each
node in any subgraph that has chronic critics ex-
tracted by the opinion mining to minimize E(c)
if the subgraph does not include the account of
the target entity, no matter how far away a node
</bodyText>
<equation confidence="0.96951375">
scorei =
1 �
E(c) = 2
i,j
</equation>
<page confidence="0.999323">
113
</page>
<tableCaption confidence="0.999773">
Table 1: Properties of the experimental datasets
</tableCaption>
<table confidence="0.984688333333333">
Target entity Tweets Critics Kappa
Company A 35,807 112 0.81
Politician A 45,378 254 1.0
</table>
<bodyText confidence="0.999702454545455">
is from the seeds. To avoid this problem, Yin and
Tan (2011) introduced a neutral fact, which de-
creases each confidence score by considering the
distance from the seeds. The neutral fact has a
fixed confidence score 0 and connects with all of
the nodes except the seeds. Suppose u1 is the neu-
tral fact, Ul = {u2, ..., ul} is the set of seeds and
Ut = {ul+1, ..., um} is the set of all nodes except
seeds. To assign the weight of the edge between
u1 and other nodes considering the degrees of the
nodes, we calculate the weight by as:
</bodyText>
<equation confidence="0.999393">
� (4)
0 i = 1, ..., l
w1z = µ � ��1 |wz� |i = l + 1, ..., m
</equation>
<bodyText confidence="0.999897">
where µ is a small constant. Thus, the weight is
proportional to the total weight of the edges from
each node.
</bodyText>
<sectionHeader confidence="0.999866" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998705">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.99996280952381">
For our experiment, we gathered tweets by using
the Twitter search API. The twitter search API re-
turns the tweets that contain an input query. We
used the name of a target entity, words related to
the entity3, and the account name of the entity as
queries. In this research, there were two target
entities, Company A and Politician A. We found
many critical tweets about these target entities.
The entities have their own accounts in Twitter.
We collected the Japanese tweets for one month.
We want to extract the users who frequently ex-
press a public opinion related to a target entity.
For this reason, we eliminated users whose the
number of tweets except conversation (i.e., reply,
QT, RT) are fewer than 5. In addition, to elimi-
nate bots that automatically post specific tweets,
we eliminated users whose conversational tweets
were fewer than 2. We selected some of the re-
maining users for the experiment. To satisfy our
definition, a chronic critic must tweet about the
target entity many times. Therefore, we focused
</bodyText>
<footnote confidence="0.987692666666667">
3We manually prepared the words that have a correlation
with the entity. In this paper, we only used the name of the
political party of Politician A as the related word.
</footnote>
<bodyText confidence="0.999986685714286">
on the top 300 users based on the number of tweets
as our experimental users. Table 1 shows the total
numbers of tweets by the top 300 users, excluding
the account of the target entity.
We created an evaluation set by manually di-
viding the experimental users into chronic critics
and regular users. A chronic critic actively com-
plained and tried to harm the reputation of the
target entity. We also regarded a user who fre-
quently reposted a critic’s tweets and unfavorable
news about the target entity as a chronic critic. For
the experimental users tweeting about Company A,
we asked two human annotators to judge whether
a user was a chronic critic based on one month of
tweets. The Cohen’s kappa value was 0.81 which
inter-annotator agreement was good. We selected
the arbitrarily annotating by one of the annotators
as our evaluation set. Table 1 expresses the num-
ber of chronic critics for each target entity in the
evaluation set. For the experimental users tweet-
ing about Politician A, we randomly extracted 50
users randomly to calculate Cohen’s kappa, which
is displayed in Table 1.
We evaluated the effects of combining the opin-
ion mining with the graph analysis. We compared
opinion mining (OM), graph analysis (GA), and
the combination of opinion mining and graph anal-
ysis (our proposed method). GA randomly se-
lected M users from experimental users as seeds
and takes the average of the results obtained by
performing label propagation three times. The
number of chronic critics extracted by the opinion
mining (i.e., the valuable M) was set to 30. The
parameter µ, that we use to calculate the weight of
the edges connected to neutral fact, was set to 0.1.
</bodyText>
<subsectionHeader confidence="0.758776">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.9998365">
Figure 3 represents the precision and recall of each
method for each target entity. In OM, we varied
the threshold from 0 to 0.2 in increments of 0.02
and accepted a user with a score over the threshold
as a chronic critic. In GA, we varied the threshold
from 0.35 to 0.8 in increments of 0.05.
In Figure 3, the results for Company A and
Politician A are quite different, though there are
some similar characteristics. Figure 3 shows that
OM achieved high precision but it was difficult to
improve the recall. In contrast, GA easily achieved
high recall. The proposed method achieved high
precision similar to OM and high recall. In
other words, the proposed method found many
</bodyText>
<page confidence="0.994262">
114
</page>
<figure confidence="0.999796107142857">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
(a) Company A
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
(b) Politician A
OM
GA
The proposed method
OM
GA
The proposed method
Precision 0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
0.45
0.4
0.35
Precision 1
0.95
0.9
0.85
0.8
</figure>
<figureCaption confidence="0.99981">
Figure 3: Precision and recall of each method for each target entity
</figureCaption>
<tableCaption confidence="0.994922">
Table 2: Users connected with the target entity
</tableCaption>
<table confidence="0.990806">
Target entity Users Non-critics
Company A 45 39
Politician A 74 35
</table>
<bodyText confidence="0.999757111111111">
chronic critics while retaining high precision of
OM. Therefore, the combination of the opinion
mining and the graph analysis improved the per-
formance of recognizing the chronic critics.
Figure 3 shows that the recall of OM was low,
which means that OM missed some of the critical
tweets. In this paper, we used domain-independent
lexicons to detect the critical phrases. Therefore,
OM failed to find domain-dependent critic phrases
such as slang words. In addition, some chronic
critics do not express criticism clearly in their own
tweets. To spread the bad reputation, they refer-
ence only a title and link to a webpage that criti-
cizes the target entity such as:
This shows the reality of Company A.
Why do you buy products from this
company? http://xxx
We believe that is often done because each tweet is
limited to 140 characters. It is difficult to classify
the tweet as a complaint based only on its content.
However, the proposed method recognized most
chronic critics that complain with these methods
based on the GA.
It cannot reasonably be assumed that a user
who supports the account of the target entity is a
chronic critic. For this reason, in the graph analy-
sis, we used the entity’s account to recognize non-
critics. We believe that using the account corrects
for mistakes in selecting the seed chronic critics.
Table 2 shows the number of users connected with
the account. Table 2 also shows the number of
non-critics among the users. As seen in Table 2,
many non-critics were connected with the account.
Especially for Politician A, most of the non-critics
in the evaluation set were connected with the ac-
count. Therefore, incorporating the account into
the graph analysis can correct for errors in the
seeding of chronic critics. However, some chronic
critics were connected with the target’s account
and reposted tweets from the account. We noticed
that they mentioned their negative opinions about
the content of such a tweet immediately after re-
posting that tweet. Hence, we need to analyze the
contexts before and after each RT.
For Politician A, Table 1 shows that most of the
users in the evaluation set criticized the politician.
We were able to find most of the chronic critics
by extracting the users linked to each other. How-
ever, for Company A, the precision of GA was low.
This means we need high accuracy in selecting the
seeds to correctly capture chronic critics. Because
we used the users extracted by the opinion mining
as the seeds, the proposed method outperformed
OM and GA.
</bodyText>
<sectionHeader confidence="0.998935" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999772">
In this paper, we proposed a method that uses not
only opinion mining but graph analysis of the con-
nections between users to detect chronic critics.
In our experiments, we found that the proposed
method outperformed each technique.
In our study, we used two entities. To im-
prove reliability, we should study more entities.
We used a relationship between users that support
each other. However, we suspect that the rela-
tionship includes adversaries. We hope to address
these topics in the future.
</bodyText>
<page confidence="0.998669">
115
</page>
<sectionHeader confidence="0.998331" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998232">
This research was partly supported by JSPS KAK-
ENHI Grant Numbers 23240018. The authors
would like to acknowledge Hiroshi Kanayama and
Shiho Ogino in IBM Research-Tokyo for provid-
ing their tools for our experiments.
</bodyText>
<sectionHeader confidence="0.999181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999214875">
Luciano Barbosa and Junlan Feng. 2010. Robust Sen-
timent Detection on Twitter from Biased and Noisy
Data. In Proceedings of the 23rd International Con-
ference on Computational Linguistics, pages 36–44.
Johan Bollen, Huina Mao, and Xiao-Jun Zeng. 2011.
Twitter mood predicts the stock market. Journal of
Computational Science, 2(1):1–8.
Michael D. Conover, Bruno Gonc¸alves, Jacob
Ratkiewicz, Alessandro Flammini, and Filippo
Menczer. 2011a. Predicting the Political Alignment
of Twitter Users. In Proceedings of the 3rd IEEE
Conference on Social Computing, pages 192–199.
Michael D. Conover, Jacob Ratkiewicz, Matthew Fran-
cisco, Bruno Gonc¸alves, Alessandro Flammini, and
Filippo Menczer. 2011b. Political Polarization on
Twitter. In Proceeding of the 5th International AAAI
Conference on Weblogs and Social Media, pages
89–96.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced Sentiment Learning Using Twitter Hash-
tags and Smileys. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics,
pages 241–249.
Masahiko Higashiyama, Kentaro Inui, and Yuji Mat-
sumoto. 2008. Learning Polarity of Nouns by Se-
lectional Preferences of Predicates (in Japanese). In
Proceedings of the 14th Annual Meeting of The As-
sociation for Natural Language Processing, pages
584–587.
Hiroshi Kanayama and Tetsuya Nasukawa. 2012. Un-
supervised Lexicon Induction for Clause-Level De-
tection of Evaluations. Natural Language Engineer-
ing, 18(1):83–107.
Akiko Murakami and Rudy Raymond. 2010. Support
or Oppose? Classifying Positions in Online Debates
from Reply Activities and Opinion Expressions. In
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 869–875, Beijing,
China.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R. Routledge, and Noah A. Smith. 2010.
From Tweets to Polls: Linking Text Sentiment to
Public Opinion Time Series. In Proceedings of the
4h International AAAI Conference on Weblogs and
Social Media, pages 122–129.
Shiho Ogino, Tetsuya Nasukawa, Hiroshi Kanayama,
and Miki Enoki. 2012. Knowledge Discovery Us-
ing Swearwords (in Japanese). In Proceedings of the
8th Annual Meeting of The Association for Natural
Language Processing, pages 58–61.
Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Ja-
son Baldridge. 2011. Twitter Polarity Classification
with Label Propagation over Lexical Links and the
Follower Graph. In Proceedings of the 1st workshop
on Unsupervised Learning in NLP, pages 53–63.
Andranik Tumasjan, Timm O. Sprenger, Philipp G.
Sandner, and Isabell M. Welpe. 2010. Predicting
Elections with Twitter: What 140 Characters Reveal
about Political Sentiment. In Proceedings of the 4th
International AAAI Conference on Weblogs and So-
cial Media, pages 178–185.
Alex Hai Wang. 2010. Don’t Follow Me - Spam De-
tection in Twitter. In Proceedings of the 5th Inter-
national Conference on Security and Cryptography,
pages 142–151.
Chao Yang, Robert Harkreader, Jialong Zhang, Seung-
won Shin, and Guofei Gu. 2012. Analyzing Spam-
mers’ Social Networks for Fun and Profit: A Case
Study of Cyber Criminal Ecosystem on Twitter. In
Proceedings of the 21st international conference on
World Wide Web, pages 71–80.
Xiaoxin Yin and Wenzhao Tan. 2011. Semi-
Supervised Truth Discovery. In Proceedings of the
20th international conference on World Wide Web,
pages 217–226.
Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.
2003. Semi-Supervised Learning Using Gaussian
Fields and Harmonic Functions. In Proceedings
of the 20th International Conference on Machine
Learning, pages 912–919.
</reference>
<page confidence="0.999021">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.259370">
<title confidence="0.961186">Detecting Chronic Critics Based</title>
<affiliation confidence="0.560455">Sentiment Polarity and User’s Behavior in Social Media Research -</affiliation>
<address confidence="0.500301">okazaki,</address>
<abstract confidence="0.999782095238095">There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our experimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust Sentiment Detection on Twitter from Biased and Noisy Data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>36--44</pages>
<contexts>
<context position="4261" citStr="Barbosa and Feng, 2010" startWordPosition="713" endWordPosition="716">whether “the user is the fool because the product is easy for other people to use”. To find chronic critics for a given entity, we need to identify the actual target of the complaints. Take the comment “Company B is much worse than Company A” for 110 Proceedings of the ACL Student Research Workshop, pages 110–116, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics example. This comment is probably complaining about Company B but not Company A. In contrast, most of the previous work on sentiment analysis in social media does not consider these kinds of problems (Barbosa and Feng, 2010; Davidov et al., 2010; Speriosu et al., 2011). Switching to the behavior of each user, in social media we often see that users who have similar ideas will tend to cooperate with each other. In fact, previous work suggests that users who have the same opinions tend to create links to each other (Conover et al., 2011b; Yang et al., 2012). Because chronic critics share the purpose of attacking some target’s reputation, they may also decide to cooperate. For this reason, to detect chronic critics, we believe that information about the connections among users will be effective. In this paper, we p</context>
<context position="5883" citStr="Barbosa and Feng, 2010" startWordPosition="981" endWordPosition="984">ts, we used Twitter, a popular social media service. In particular, we focus on Japanese comments on Twitter. This paper is organized as follows. Section 2 reviews related work. Section 3 presents the proposed method which applies the opinion mining and graph analysis. Section 4 demonstrates the effectiveness of the proposed method and discusses the experimental results. Section 5 concludes this paper. 2 Related Work In recent years, an interest in opinion mining in online communities has emerged (Conover et al., 2011a; O’Connor et al., 2010; Speriosu et al., 2011; Murakami and Raymond, 2010; Barbosa and Feng, 2010; Davidov et al., 2010). O’Connor et al. (2010), Barbosa and Feng (2010), Davidov et al. (2010), and Speriosu et al. (2011) proposed methods to predict a sentiment polarity (i.e., positive or negative) of a comment in social media. O’Connor et al. (2010) studied a subjectivity lexicon. Barbosa and Feng (2010) and Davidov et al. (2010) used machine learning approaches. Speriosu et al. (2011) introduced connections between words, emoticons, tags, n-grams, comments and users. These studies did not identify the target of the polarized sentiment of each comment. Conover et al. (2011a) proposed a me</context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2010. Robust Sentiment Detection on Twitter from Biased and Noisy Data. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 36–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
<author>Huina Mao</author>
<author>Xiao-Jun Zeng</author>
</authors>
<title>Twitter mood predicts the stock market.</title>
<date>2011</date>
<journal>Journal of Computational Science,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1450" citStr="Bollen et al., 2011" startWordPosition="228" endWordPosition="231">s, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our experimental results show that the proposed method outperforms analysis based only on opinion mining techniques. 1 Introduction On a social media website, there may be millions of users and large numbers of comments. The comments in social media are related to the real world in such fields as marketing and politics. Analyzing comments in social media has been shown to be effective in predicting the behaviors of stock markets and of voters in elections (Bollen et al., 2011; Tumasjan et al., 2010; O’Connor et al., 2010). Because of their effects on the real world, some complaints may harm the reputation of a corporation or an individual and cause serious damage. Consider a comment such as “Working for Company A is really awful” as an example. The complaint gives viewers a negative impression of Company A and can increase the number of people who think the company is bad. Some complaints are expressed by a specific user who is always criticizing a specific target entity (in this example, Company A). We call this user a chronic critic of that entity, a person who </context>
</contexts>
<marker>Bollen, Mao, Zeng, 2011</marker>
<rawString>Johan Bollen, Huina Mao, and Xiao-Jun Zeng. 2011. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael D Conover</author>
<author>Bruno Gonc¸alves</author>
<author>Jacob Ratkiewicz</author>
<author>Alessandro Flammini</author>
<author>Filippo Menczer</author>
</authors>
<title>Predicting the Political Alignment of Twitter Users.</title>
<date>2011</date>
<booktitle>In Proceedings of the 3rd IEEE Conference on Social Computing,</booktitle>
<pages>192--199</pages>
<marker>Conover, Gonc¸alves, Ratkiewicz, Flammini, Menczer, 2011</marker>
<rawString>Michael D. Conover, Bruno Gonc¸alves, Jacob Ratkiewicz, Alessandro Flammini, and Filippo Menczer. 2011a. Predicting the Political Alignment of Twitter Users. In Proceedings of the 3rd IEEE Conference on Social Computing, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael D Conover</author>
<author>Jacob Ratkiewicz</author>
<author>Matthew Francisco</author>
<author>Bruno Gonc¸alves</author>
<author>Alessandro Flammini</author>
<author>Filippo Menczer</author>
</authors>
<title>Political Polarization on Twitter.</title>
<date>2011</date>
<booktitle>In Proceeding of the 5th International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>89--96</pages>
<marker>Conover, Ratkiewicz, Francisco, Gonc¸alves, Flammini, Menczer, 2011</marker>
<rawString>Michael D. Conover, Jacob Ratkiewicz, Matthew Francisco, Bruno Gonc¸alves, Alessandro Flammini, and Filippo Menczer. 2011b. Political Polarization on Twitter. In Proceeding of the 5th International AAAI Conference on Weblogs and Social Media, pages 89–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Enhanced Sentiment Learning Using Twitter Hashtags and Smileys.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>241--249</pages>
<contexts>
<context position="4283" citStr="Davidov et al., 2010" startWordPosition="717" endWordPosition="720"> fool because the product is easy for other people to use”. To find chronic critics for a given entity, we need to identify the actual target of the complaints. Take the comment “Company B is much worse than Company A” for 110 Proceedings of the ACL Student Research Workshop, pages 110–116, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics example. This comment is probably complaining about Company B but not Company A. In contrast, most of the previous work on sentiment analysis in social media does not consider these kinds of problems (Barbosa and Feng, 2010; Davidov et al., 2010; Speriosu et al., 2011). Switching to the behavior of each user, in social media we often see that users who have similar ideas will tend to cooperate with each other. In fact, previous work suggests that users who have the same opinions tend to create links to each other (Conover et al., 2011b; Yang et al., 2012). Because chronic critics share the purpose of attacking some target’s reputation, they may also decide to cooperate. For this reason, to detect chronic critics, we believe that information about the connections among users will be effective. In this paper, we present a method that c</context>
<context position="5906" citStr="Davidov et al., 2010" startWordPosition="985" endWordPosition="988">opular social media service. In particular, we focus on Japanese comments on Twitter. This paper is organized as follows. Section 2 reviews related work. Section 3 presents the proposed method which applies the opinion mining and graph analysis. Section 4 demonstrates the effectiveness of the proposed method and discusses the experimental results. Section 5 concludes this paper. 2 Related Work In recent years, an interest in opinion mining in online communities has emerged (Conover et al., 2011a; O’Connor et al., 2010; Speriosu et al., 2011; Murakami and Raymond, 2010; Barbosa and Feng, 2010; Davidov et al., 2010). O’Connor et al. (2010), Barbosa and Feng (2010), Davidov et al. (2010), and Speriosu et al. (2011) proposed methods to predict a sentiment polarity (i.e., positive or negative) of a comment in social media. O’Connor et al. (2010) studied a subjectivity lexicon. Barbosa and Feng (2010) and Davidov et al. (2010) used machine learning approaches. Speriosu et al. (2011) introduced connections between words, emoticons, tags, n-grams, comments and users. These studies did not identify the target of the polarized sentiment of each comment. Conover et al. (2011a) proposed a method that predicts the </context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Enhanced Sentiment Learning Using Twitter Hashtags and Smileys. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 241–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahiko Higashiyama</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Learning Polarity of Nouns by Selectional Preferences of Predicates (in Japanese).</title>
<date>2008</date>
<booktitle>In Proceedings of the 14th Annual Meeting of The Association for Natural Language Processing,</booktitle>
<pages>584--587</pages>
<contexts>
<context position="11504" citStr="Higashiyama et al. (2008)" startWordPosition="1956" endWordPosition="1959">d tweet”). We assume a phrase representing negative polarity or profanity to be critical phrases. The proposed method determines whether a tweet complains about the target entity by investigating a critical phrase and the target of the phrase. Note that a negative polarity is represented by declinable words or substantives. We used the sentiment analyzer created by Kanayama and Nasukawa (2012) to detect a phrase representing negA4±0 TpI-I *�!M 000 Working for Company A is really awful. Figure 2: Example of critic tweet ative polarity by using declinable words. We used the lexicon collected by Higashiyama et al. (2008) to find negative polarity in substantives. For detecting profanity, we use a profane lexicon collected by Ogino et al. (2012). The sentiment analyzer can find not only sentiment phrases but the targets of the phrases based on syntactic parsing and the case frames&apos;. However, because there are many informal tweets and because most users omit the grammatical case in tweets, the sentiment analyzer often fails to capture any target. To address this problem, in addition to a target extracted by the sentiment analyzer, we obtain a target based on the dependency tree. We extract nouns in parent and c</context>
</contexts>
<marker>Higashiyama, Inui, Matsumoto, 2008</marker>
<rawString>Masahiko Higashiyama, Kentaro Inui, and Yuji Matsumoto. 2008. Learning Polarity of Nouns by Selectional Preferences of Predicates (in Japanese). In Proceedings of the 14th Annual Meeting of The Association for Natural Language Processing, pages 584–587.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Unsupervised Lexicon Induction for Clause-Level Detection of Evaluations.</title>
<date>2012</date>
<journal>Natural Language Engineering,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="11275" citStr="Kanayama and Nasukawa (2012)" startWordPosition="1916" endWordPosition="1920">s means we ignore a reply that is a response to a specific user named username (written in the format “@username response”) and QT that is a mention in a quoted tweet from username (written in the format “mention RT @username: quoted tweet”). We assume a phrase representing negative polarity or profanity to be critical phrases. The proposed method determines whether a tweet complains about the target entity by investigating a critical phrase and the target of the phrase. Note that a negative polarity is represented by declinable words or substantives. We used the sentiment analyzer created by Kanayama and Nasukawa (2012) to detect a phrase representing negA4±0 TpI-I *�!M 000 Working for Company A is really awful. Figure 2: Example of critic tweet ative polarity by using declinable words. We used the lexicon collected by Higashiyama et al. (2008) to find negative polarity in substantives. For detecting profanity, we use a profane lexicon collected by Ogino et al. (2012). The sentiment analyzer can find not only sentiment phrases but the targets of the phrases based on syntactic parsing and the case frames&apos;. However, because there are many informal tweets and because most users omit the grammatical case in twee</context>
</contexts>
<marker>Kanayama, Nasukawa, 2012</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2012. Unsupervised Lexicon Induction for Clause-Level Detection of Evaluations. Natural Language Engineering, 18(1):83–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akiko Murakami</author>
<author>Rudy Raymond</author>
</authors>
<title>Support or Oppose? Classifying Positions in Online Debates from Reply Activities and Opinion Expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>869--875</pages>
<location>Beijing, China.</location>
<contexts>
<context position="5859" citStr="Murakami and Raymond, 2010" startWordPosition="977" endWordPosition="980">ed method. For our experiments, we used Twitter, a popular social media service. In particular, we focus on Japanese comments on Twitter. This paper is organized as follows. Section 2 reviews related work. Section 3 presents the proposed method which applies the opinion mining and graph analysis. Section 4 demonstrates the effectiveness of the proposed method and discusses the experimental results. Section 5 concludes this paper. 2 Related Work In recent years, an interest in opinion mining in online communities has emerged (Conover et al., 2011a; O’Connor et al., 2010; Speriosu et al., 2011; Murakami and Raymond, 2010; Barbosa and Feng, 2010; Davidov et al., 2010). O’Connor et al. (2010), Barbosa and Feng (2010), Davidov et al. (2010), and Speriosu et al. (2011) proposed methods to predict a sentiment polarity (i.e., positive or negative) of a comment in social media. O’Connor et al. (2010) studied a subjectivity lexicon. Barbosa and Feng (2010) and Davidov et al. (2010) used machine learning approaches. Speriosu et al. (2011) introduced connections between words, emoticons, tags, n-grams, comments and users. These studies did not identify the target of the polarized sentiment of each comment. Conover et a</context>
</contexts>
<marker>Murakami, Raymond, 2010</marker>
<rawString>Akiko Murakami and Rudy Raymond. 2010. Support or Oppose? Classifying Positions in Online Debates from Reply Activities and Opinion Expressions. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 869–875, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series.</title>
<date>2010</date>
<booktitle>In Proceedings of the 4h International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>122--129</pages>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series. In Proceedings of the 4h International AAAI Conference on Weblogs and Social Media, pages 122–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiho Ogino</author>
<author>Tetsuya Nasukawa</author>
<author>Hiroshi Kanayama</author>
<author>Miki Enoki</author>
</authors>
<title>Knowledge Discovery Using Swearwords (in Japanese).</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th Annual Meeting of The Association for Natural Language Processing,</booktitle>
<pages>58--61</pages>
<contexts>
<context position="11630" citStr="Ogino et al. (2012)" startWordPosition="1978" endWordPosition="1981">ther a tweet complains about the target entity by investigating a critical phrase and the target of the phrase. Note that a negative polarity is represented by declinable words or substantives. We used the sentiment analyzer created by Kanayama and Nasukawa (2012) to detect a phrase representing negA4±0 TpI-I *�!M 000 Working for Company A is really awful. Figure 2: Example of critic tweet ative polarity by using declinable words. We used the lexicon collected by Higashiyama et al. (2008) to find negative polarity in substantives. For detecting profanity, we use a profane lexicon collected by Ogino et al. (2012). The sentiment analyzer can find not only sentiment phrases but the targets of the phrases based on syntactic parsing and the case frames&apos;. However, because there are many informal tweets and because most users omit the grammatical case in tweets, the sentiment analyzer often fails to capture any target. To address this problem, in addition to a target extracted by the sentiment analyzer, we obtain a target based on the dependency tree. We extract nouns in parent and child phrases within distance 2 from a critical phrase in the dependency tree. Figure 2 shows an example of a Japanese tweet cr</context>
</contexts>
<marker>Ogino, Nasukawa, Kanayama, Enoki, 2012</marker>
<rawString>Shiho Ogino, Tetsuya Nasukawa, Hiroshi Kanayama, and Miki Enoki. 2012. Knowledge Discovery Using Swearwords (in Japanese). In Proceedings of the 8th Annual Meeting of The Association for Natural Language Processing, pages 58–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Speriosu</author>
<author>Nikita Sudan</author>
<author>Sid Upadhyay</author>
<author>Jason Baldridge</author>
</authors>
<title>Twitter Polarity Classification with Label Propagation over Lexical Links and the Follower Graph.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st workshop on Unsupervised Learning in NLP,</booktitle>
<pages>53--63</pages>
<contexts>
<context position="4307" citStr="Speriosu et al., 2011" startWordPosition="721" endWordPosition="724">uct is easy for other people to use”. To find chronic critics for a given entity, we need to identify the actual target of the complaints. Take the comment “Company B is much worse than Company A” for 110 Proceedings of the ACL Student Research Workshop, pages 110–116, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics example. This comment is probably complaining about Company B but not Company A. In contrast, most of the previous work on sentiment analysis in social media does not consider these kinds of problems (Barbosa and Feng, 2010; Davidov et al., 2010; Speriosu et al., 2011). Switching to the behavior of each user, in social media we often see that users who have similar ideas will tend to cooperate with each other. In fact, previous work suggests that users who have the same opinions tend to create links to each other (Conover et al., 2011b; Yang et al., 2012). Because chronic critics share the purpose of attacking some target’s reputation, they may also decide to cooperate. For this reason, to detect chronic critics, we believe that information about the connections among users will be effective. In this paper, we present a method that combines opinion mining b</context>
<context position="5831" citStr="Speriosu et al., 2011" startWordPosition="973" endWordPosition="976"> i.e., using the proposed method. For our experiments, we used Twitter, a popular social media service. In particular, we focus on Japanese comments on Twitter. This paper is organized as follows. Section 2 reviews related work. Section 3 presents the proposed method which applies the opinion mining and graph analysis. Section 4 demonstrates the effectiveness of the proposed method and discusses the experimental results. Section 5 concludes this paper. 2 Related Work In recent years, an interest in opinion mining in online communities has emerged (Conover et al., 2011a; O’Connor et al., 2010; Speriosu et al., 2011; Murakami and Raymond, 2010; Barbosa and Feng, 2010; Davidov et al., 2010). O’Connor et al. (2010), Barbosa and Feng (2010), Davidov et al. (2010), and Speriosu et al. (2011) proposed methods to predict a sentiment polarity (i.e., positive or negative) of a comment in social media. O’Connor et al. (2010) studied a subjectivity lexicon. Barbosa and Feng (2010) and Davidov et al. (2010) used machine learning approaches. Speriosu et al. (2011) introduced connections between words, emoticons, tags, n-grams, comments and users. These studies did not identify the target of the polarized sentiment o</context>
</contexts>
<marker>Speriosu, Sudan, Upadhyay, Baldridge, 2011</marker>
<rawString>Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Jason Baldridge. 2011. Twitter Polarity Classification with Label Propagation over Lexical Links and the Follower Graph. In Proceedings of the 1st workshop on Unsupervised Learning in NLP, pages 53–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andranik Tumasjan</author>
<author>Timm O Sprenger</author>
<author>Philipp G Sandner</author>
<author>Isabell M Welpe</author>
</authors>
<title>Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="1473" citStr="Tumasjan et al., 2010" startWordPosition="232" endWordPosition="235">d that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our experimental results show that the proposed method outperforms analysis based only on opinion mining techniques. 1 Introduction On a social media website, there may be millions of users and large numbers of comments. The comments in social media are related to the real world in such fields as marketing and politics. Analyzing comments in social media has been shown to be effective in predicting the behaviors of stock markets and of voters in elections (Bollen et al., 2011; Tumasjan et al., 2010; O’Connor et al., 2010). Because of their effects on the real world, some complaints may harm the reputation of a corporation or an individual and cause serious damage. Consider a comment such as “Working for Company A is really awful” as an example. The complaint gives viewers a negative impression of Company A and can increase the number of people who think the company is bad. Some complaints are expressed by a specific user who is always criticizing a specific target entity (in this example, Company A). We call this user a chronic critic of that entity, a person who is deliberately trying </context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Andranik Tumasjan, Timm O. Sprenger, Philipp G. Sandner, and Isabell M. Welpe. 2010. Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment. In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media, pages 178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Hai Wang</author>
</authors>
<title>Don’t Follow Me - Spam Detection in Twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Conference on Security and Cryptography,</booktitle>
<pages>142--151</pages>
<contexts>
<context position="7396" citStr="Wang, 2010" startWordPosition="1226" endWordPosition="1227">rast, our research uses graph analysis that converges on the optimal solution. Murakami and Raymond (2010) proposed a method that uses the connections between users to predict each user’s opinion, i.e., support or oppose a topic in online debates. They analyzed the content of the discussions to infer the connections. However, in social media, it is difficult to infer connections based on content because of such complexities as incomplete contexts. To address these problem, we analyzed the behavior of the users to predict the connections between users. Our task is similar to spammer detection (Wang, 2010; Yang et al., 2012). Wang (2010) proposed a method using a classifier to detect spammers. They used the content in the comments and the number of linked users as features. Yang et al. (2012) analyzed spammer communities and demonstrated that spammers closely link to each other in social media. They also proposed a method that extracts spammers using the connections between users. While Wang (2010) and Yang et al. (2012) required manually annotated data for training or as seeds, we extract the seeds for the graph analysis automatically through opinion mining. 3 Proposed Method Figure 1 present</context>
</contexts>
<marker>Wang, 2010</marker>
<rawString>Alex Hai Wang. 2010. Don’t Follow Me - Spam Detection in Twitter. In Proceedings of the 5th International Conference on Security and Cryptography, pages 142–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Yang</author>
<author>Robert Harkreader</author>
<author>Jialong Zhang</author>
<author>Seungwon Shin</author>
<author>Guofei Gu</author>
</authors>
<title>Analyzing Spammers’ Social Networks for Fun and Profit: A Case Study of Cyber Criminal Ecosystem on Twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>71--80</pages>
<contexts>
<context position="4599" citStr="Yang et al., 2012" startWordPosition="776" endWordPosition="779">9 2013. c�2013 Association for Computational Linguistics example. This comment is probably complaining about Company B but not Company A. In contrast, most of the previous work on sentiment analysis in social media does not consider these kinds of problems (Barbosa and Feng, 2010; Davidov et al., 2010; Speriosu et al., 2011). Switching to the behavior of each user, in social media we often see that users who have similar ideas will tend to cooperate with each other. In fact, previous work suggests that users who have the same opinions tend to create links to each other (Conover et al., 2011b; Yang et al., 2012). Because chronic critics share the purpose of attacking some target’s reputation, they may also decide to cooperate. For this reason, to detect chronic critics, we believe that information about the connections among users will be effective. In this paper, we present a method that combines opinion mining based on NLP and graph analysis of the connections among users to recognize the chronic critics. In the experiments, we demonstrate the difficulty in detecting chronic critics by analyzing only the individual comments. In addition, we investigate the effectiveness of using the connections bet</context>
<context position="7416" citStr="Yang et al., 2012" startWordPosition="1228" endWordPosition="1231">search uses graph analysis that converges on the optimal solution. Murakami and Raymond (2010) proposed a method that uses the connections between users to predict each user’s opinion, i.e., support or oppose a topic in online debates. They analyzed the content of the discussions to infer the connections. However, in social media, it is difficult to infer connections based on content because of such complexities as incomplete contexts. To address these problem, we analyzed the behavior of the users to predict the connections between users. Our task is similar to spammer detection (Wang, 2010; Yang et al., 2012). Wang (2010) proposed a method using a classifier to detect spammers. They used the content in the comments and the number of linked users as features. Yang et al. (2012) analyzed spammer communities and demonstrated that spammers closely link to each other in social media. They also proposed a method that extracts spammers using the connections between users. While Wang (2010) and Yang et al. (2012) required manually annotated data for training or as seeds, we extract the seeds for the graph analysis automatically through opinion mining. 3 Proposed Method Figure 1 presents an overview of the</context>
</contexts>
<marker>Yang, Harkreader, Zhang, Shin, Gu, 2012</marker>
<rawString>Chao Yang, Robert Harkreader, Jialong Zhang, Seungwon Shin, and Guofei Gu. 2012. Analyzing Spammers’ Social Networks for Fun and Profit: A Case Study of Cyber Criminal Ecosystem on Twitter. In Proceedings of the 21st international conference on World Wide Web, pages 71–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoxin Yin</author>
<author>Wenzhao Tan</author>
</authors>
<title>SemiSupervised Truth Discovery.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference on World Wide Web,</booktitle>
<pages>217--226</pages>
<contexts>
<context position="17486" citStr="Yin and Tan (2011)" startWordPosition="3065" endWordPosition="3068">that have scores greater than the threshold. We believe that if the distance between users on the graph is large, then users slightly support each other. However, we can assign a score of 1 to each node in any subgraph that has chronic critics extracted by the opinion mining to minimize E(c) if the subgraph does not include the account of the target entity, no matter how far away a node scorei = 1 � E(c) = 2 i,j 113 Table 1: Properties of the experimental datasets Target entity Tweets Critics Kappa Company A 35,807 112 0.81 Politician A 45,378 254 1.0 is from the seeds. To avoid this problem, Yin and Tan (2011) introduced a neutral fact, which decreases each confidence score by considering the distance from the seeds. The neutral fact has a fixed confidence score 0 and connects with all of the nodes except the seeds. Suppose u1 is the neutral fact, Ul = {u2, ..., ul} is the set of seeds and Ut = {ul+1, ..., um} is the set of all nodes except seeds. To assign the weight of the edge between u1 and other nodes considering the degrees of the nodes, we calculate the weight by as: � (4) 0 i = 1, ..., l w1z = µ � ��1 |wz� |i = l + 1, ..., m where µ is a small constant. Thus, the weight is proportional to t</context>
</contexts>
<marker>Yin, Tan, 2011</marker>
<rawString>Xiaoxin Yin and Wenzhao Tan. 2011. SemiSupervised Truth Discovery. In Proceedings of the 20th international conference on World Wide Web, pages 217–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
<author>John Lafferty</author>
</authors>
<title>Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th International Conference on Machine Learning,</booktitle>
<pages>912--919</pages>
<contexts>
<context position="16496" citStr="Zhu et al. (2003)" startWordPosition="2879" endWordPosition="2882">gation assigns a confidence score c = (c1, ..., cm) to each node U = u1, ..., um, where the score is a real number between −1 and 1. A score close to 1 indicates that we are very confident that the node (user) is a chronic critic. A score close to −1 indicates that we are sure that the node is not a chronic critic. In addition, the scores of seeds are fixed and cannot be changed. The scores of chronic critics obtained by the opinion mining are 1 and the score of the target entity is set to −1. To formulate the label propagation as an optimization problem, we used the loss function proposed by Zhu et al. (2003), because wij &gt; 0 for all i, j. wij(ci − cj)2 (3) To minimize E(c), ci is close to cj when wij is greater than 0. That is, if the users support each other, the scores of the users are close to each other. Thus, by minimizing E(c), we assign the confidence scores considering the results of the opinion mining and agreement relationships among the users. We find the users that have scores greater than the threshold. We believe that if the distance between users on the graph is large, then users slightly support each other. However, we can assign a score of 1 to each node in any subgraph that has </context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. 2003. Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. In Proceedings of the 20th International Conference on Machine Learning, pages 912–919.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>