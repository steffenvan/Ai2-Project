<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999089">
Building A Large Chinese Corpus
Annotated With Semantic Dependency
</title>
<author confidence="0.968878">
LI Mingqin
</author>
<affiliation confidence="0.804904666666667">
Department of Electronic Engineering,
Tsinghua University,
Beijing 100084, China
</affiliation>
<email confidence="0.8177605">
lmq@thsp.ee.tsinghua
.edu.cn
</email>
<author confidence="0.577723">
LI Juanzi
</author>
<affiliation confidence="0.69562175">
Department of Computer Science
and Technology,
Tsinghua University,
Beijing 100084, China
</affiliation>
<email confidence="0.779861">
ljz@thsp.ee.tsinghu
a.edu.cn
</email>
<author confidence="0.452428">
DONG Zhendong
</author>
<affiliation confidence="0.497589">
Research Centre of Computer &amp;
Language Engineering,
Chinese Academy of Sciences,
</affiliation>
<address confidence="0.707778">
Beijing, 100084,China
</address>
<email confidence="0.993895">
dzd@keenage.com
</email>
<author confidence="0.99103">
WANG Zuoying
</author>
<affiliation confidence="0.907148666666667">
Department of Electronic Engineering,
Tsinghua University,
Beijing 100084, China
</affiliation>
<email confidence="0.982048">
wzy-dee@tsinghua.edu.cn
</email>
<author confidence="0.982459">
LU Dajin
</author>
<affiliation confidence="0.906583333333333">
Department of Electronic Engineering,
Tsinghua University,
Beijing 100084, China
</affiliation>
<email confidence="0.988308">
ludj@mail.tsinghua.edu.cn
</email>
<sectionHeader confidence="0.994175" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823142857143">
At present most of corpora are annotated
mainly with syntactic knowledge. In this
paper, we attempt to build a large corpus
and annotate semantic knowledge with
dependency grammar. We believe that
words are the basic units of semantics,
and the structure and meaning of a
sentence consist mainly of a series of
semantic dependencies between
individual words. A 1,000,000-word-
scale corpus annotated with semantic
dependency has been built. Compared
with syntactic knowledge, semantic
knowledge is more difficult to annotate,
for ambiguity problem is more serious. In
the paper, the strategy to improve
consistency is addressed, and congruence
is defined to measure the consistency of
tagged corpus.. Finally, we will compare
our corpus with other well-known
corpora.
</bodyText>
<sectionHeader confidence="0.998559" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991897260274">
As basic research tools for investigators in natural
language processing, large annotated corpora play
an important role in investigating diverse lan-
guage phenomena, building statistical language
models, evaluating and comparing kinds of pars-
ing models. At present most of corpora are anno-
tated mainly with syntactic knowledge, though
some function tags are added to annotate semantic
knowledge. For example, the Penn Treebank
(Marcus et al., 1993) was annotated with skeletal
syntactic structure, and many syntactic parsers
were evaluated and compared on the corpus. For
Chinese, some corpora annotated with phrase
structure also have been built, for instance the
Penn Chinese Treebank (Xia et al., 2000) and Sina
Corpus (Huang and Chen, 1992). A syntactic an-
notation scheme based on dependency was pro-
posed by (Lai and Huang, 2000), and a small
corpus was built for testing. However, very lim-
ited work has been done with annotation semantic
knowledge in all languages. From 1999, Berkeley
started FrameNet project (Baker et al., 1998),
which produced the frame-semantic descriptions
of several thousand English lexical items and
backed up these description with semantically an-
notated attestations from contemporary English
corpus. Although few corpora annotated with se-
mantic knowledge are available now, there are
some valuable lexical databases describing the
lexical semantics in dictionary form, for example
English WordNet (Miller et al., 1993) and Chinese
HowNet (Dong and Dong, 2001).
For Chinese, many attentions have been natu-
rally paid to researches on semantics, because
Chinese is a meaning-combined language, its syn-
tax is very flexible, and semantic rules are more
stable than syntactic rules. For instance, in Chi-
nese it is very pervasive that more than one part-of
-speeches a word has, and a word does not have
tense or voice flectional transition under different
tenses or voices. Nevertheless, no large Chinese
corpus annotated with semantic knowledge has
ever been built at present. In Semantic Depend-
ency Net (SDN), we try to describe deeper seman-
tic dependency relationship between individual
words and represent the meaning and structure of
a sentence by these dependencies.
Compared with syntactic corpus, it is more dif-
ficult to build a semantic corpus, for the granular-
ity of semantic knowledge is smaller, and
behaviors of different words differ more greatly.
Furthermore, ambiguity in semantics is commoner.
Different people may have different opinions on
understanding the same word in the same sentence,
and even the same people may have different
opinions on understanding the same word in dif-
ferent occasions. In this paper, we emphatically
discuss the strategy to improve the consistency of
Semantic Dependency Net.
The paper is organized as follows. The tagging
scheme is discussed in Section 2, which describes
the semantic dependency grammar and the tag set
of semantic relations. In section 3, we describe the
tagging task. First, we briefly introduce the text of
this corpus, which has been tagged with semantic
classes. Second, we describe the strategy to im-
prove consistency during tagging and checking.
At last, congruence is defined to measure the con-
sistency of tagged corpus. In Section 4, we briefly
introduce some of the works on the corpus, and
indicate the directions that the project is likely to
take in the future. Finally, we compare SDN cor-
pus with some other well-known corpora.
</bodyText>
<figureCaption confidence="0.722544666666667">
Figure 1: A sample sentence from the corpus. (a) The sentence tagged with semantic classes; (b) The sen-
tence annotated with semantic dependency; (c) The semantic dependency tree of the sentence, headwords
are linked with bold lines, and modifier words are linked with arrow lines.
</figureCaption>
<figure confidence="0.409638">
S
</figure>
<sectionHeader confidence="0.7881655" genericHeader="method">
2 The tagging scheme of semantic depend-
ency
</sectionHeader>
<subsectionHeader confidence="0.998994">
2.1 Semantic dependency grammar
</subsectionHeader>
<bodyText confidence="0.999931125">
Like Word grammar (Hudson, 1998), We believe
that words are the basic units of semantics, and
the structure and meaning of a sentence consist
mainly of semantic dependencies between indi-
vidual words. So a sentence could be annotated
with a series of semantic dependency relations (Li
Juanzi and Wang, 2002). Let S be a sentence
composed of words tagged with semantic classes,
</bodyText>
<equation confidence="0.986464875">
= &lt; w s &gt; &lt; w s &gt; &lt; wn s n
{ 1, 1 , 2, 2 , ,
, &gt;}
list of semantic dependency relations is defined as:
SRL = SR
{ (1 ), ( 2 ), , (
SR SR n
,
</equation>
<bodyText confidence="0.987688895833334">
where SR(i) = (hi,ri) . SR stands for ‘ semantic
relation’. SR(i) = (hi , r i ) states that the hi -th
word is the headword to the i-th word with seman-
tic relation ri. If the word j is the root, SR (j) is
defined to be (-1, “kernel word”).
For example, a sample sentence from the cor-
pus is shown in Figure 1 (a). The semantic de-
pendency relation list and semantic dependency
tree are shown in Figure 1 (b) and (c) respectively.
More samples will be seen in Appendix A.
In semantic dependency grammar, the head-
word of sentence represents the main meaning of
the whole sentence, and the headword of constitu-
ent represents the main meaning of the constituent.
In a compound constituent, the headword inherits
the headword of the head sub-constituent, and
headwords of other sub-constituents are dependent
on that headword. We select the word that can
represent the meaning of the constituent to the
most extent as headword. For example, the verb is
the headword of verb phrase, the object is the
headword of preposition phrase, and the location
noun is the headword of the location phrase.
At the same time, semantic dependency rela-
tions do not damage the phrase structure, that is,
all words in the same phrase are in the same sub-
tree whose root is the headword of the phrase.
Therefore, when tagging dependency relations,
semantic and syntactic restrictions are both taken
into account. The structures of dependency tree
are mainly determined by syntactic restrictions,
and the semantic relations are mainly determined
by semantic restrictions. For example, in Figure 1
the phrase “”( of his invention pro-
duction) modifies the phrase “” (popu-
larization and application) in syntax, so the word
“” (popularization) governs the word “”
(production). However, the production is the con-
tent of the action popularization in semantics, so
the relation between them is “content”.
Our tagging scheme is more concise compared
with phrase structure grammar, in which the
boundaries of all phrases have to be marked and
the corresponding labels have to be tagged. In the
semantic dependency grammar, phrases are im-
plicit, but play no part in grammar. More empha-
sis is paid to the syntactic and semantic functions
of the word, especially of the headword.
</bodyText>
<subsectionHeader confidence="0.99237">
2.2 The dependency relation tag set
</subsectionHeader>
<bodyText confidence="0.999990375">
The dependency relation tag set mainly consists of
three kinds of relations: semantic relations, syn-
tactic relations and special relations. Semantics is
the main content of this corpus, so semantic rela-
tions are in the majority, and syntactic relations
are used to annotate the special structures that do
not have exact sense in terms of semantics. In ad-
dition, there are two special relations: “kernel
word” is to indicate the headword of a sentence,
and “failure” is to indicate the word that cannot be
annotated with dependency relations because the
sentence is not completed.
The selections of semantic relations were re-
ferred to HowNet (Dong and Dong, 2001).
HowNet is a lexical database, which describes the
relations among words and concepts as a network.
In HowNet, senventy-six semantic relations are
defined to describe all relations among various
concepts, and most of them describe the semantic
relations between action and other concepts. With
these semantic relations, necessary role frame is
further defined. The roles in the necessary role
frame must take part in the action in real word,
while these roles may not appear in the same sen-
tence. Hong Kong Technology University has
successfully tagged a news corpus with the neces-
sary role frame (Yan and Tan, 1999), which
shows that these roles can describe all semantic
phenomena in real texts.
In order to make tagging task easier and the
corpus more suitable for statistical learning, we
have pared down some relations in HowNet and
</bodyText>
<equation confidence="0.962991">
. A
) }
</equation>
<bodyText confidence="0.936344214285714">
got fifty-nine semantic relations. Some HowNet
relations seldom occurred in the corpus, and their
semantic functions are somewhat similar, so they
are merged. Some relations are ambiguous, for
example “degree” and “range”. In order to im-
prove the consistency, we also merge these two
relations.
Semantic relations can describe the relations
between notional words, but they cannot annotate
function words in some special phrase structures.
So nine syntactic relations are added.
The tag set is listed in table 1. Full definition
of each dependency relation can be seen in (Li
Mingqin et al., 2002).
</bodyText>
<table confidence="0.996026555555555">
Semantic
Relations
59
Syntacitc “ ”
Relations
9
Special
relaions
2
</table>
<tableCaption confidence="0.999933">
Table 1: The dependency relation tag set.
</tableCaption>
<sectionHeader confidence="0.950458" genericHeader="method">
3 The tagging and checking of semantic
dependency relations
</sectionHeader>
<subsectionHeader confidence="0.999954">
3.1 Texts of corpus
</subsectionHeader>
<bodyText confidence="0.998063444444445">
A part of Tsinghua Corpus (Zhang, 1999) anno-
tated with semantic classes was selected as raw
data of our corpus. The texts of Tsinghua corpus
come from the news of People’s Daily. The se-
lected part consists of about 1,000,000 words, ap-
proximately 1,500,000 Chinese characters. Its
domain covers the politics, economy, science,
sports, etc. The proportion of different domains is
shown in figure 2.
</bodyText>
<figureCaption confidence="0.7742315">
Figure 2: The proportion of texts of different do-
mains
Because Chinese is not written with word de-
limiters, first the text was segmented into words
</figureCaption>
<bodyText confidence="0.999862941176471">
according to the lexicon of 100,000 words. Then
each word was tagged with semantic class, whose
definition follows Tongyici Cilin (Dictionary of
Synonymous Words) (Mei et al., 1983).The seman-
tic classes are organized as a tree, which has three
levels. The first level contains 18 classes, the sec-
ond level contains 101 classes, and the third level
contains 1434 classes. These hierarchical semantic
classes are helpful to express the superordinate and
subordinate information among words.
All the text in Tsinghua Corpus was seg-
mented, tagged and checked manually. Since the
corpus was built in 1998, it has been used for sev-
eral years in the researches on automatic sense tag-
ging and class-based language model. Now, the
accuracy of tagging system has reached to 92.7%
(Zhang, 1999).
</bodyText>
<subsectionHeader confidence="0.999118">
3.2 Tagging tools
</subsectionHeader>
<bodyText confidence="0.998732571428571">
A computer-aided tagging tool was developed to
assist annotators in tagging semantic dependency
relations. To tag a word, annotator only need to
select its headword and their relation by clicking
mouse. After a sentence has been tagged, the cor-
responding semantic dependency tree will be dis-
played to help annotators check the sentence
structure.
Two additional functions are also provided in
the tool: dependency grammar checking and on-
line reference of HowNet. Dependency grammar
checking guarantees that the tagged sentence con-
forms to four axioms of dependency grammar
(Robinson, 1970):
</bodyText>
<listItem confidence="0.986152111111111">
(a) One and only one element is independent;
(b) All others depend directly on some ele-
ment;
(c) No element depends directly on more than
one other
(d) If A depends directly on B and some ele-
ment C intervenes between them (in linear or-
der of string), then C depends directly on A or
B or some other intervening element.
</listItem>
<bodyText confidence="0.999818814814815">
During annotating procedure, the tool checks
whether the tagged relation conforms to depend-
ency grammar, and prompts the grammar errors in
time.
On-line HowNet reference facilitates looking
up semantic knowledge and helps to ensure the
consistency of tagging. Semantic knowledge is
more difficult to grasp than syntactic knowledge.
Even for annotators majored in linguistics, it is too
difficult to grasp all semantic relations of words
only after a short-term training. And different opin-
ions about relations will lead to the inconsistency.
However, HowNet defines the necessary role
frame for verbs frequently used in real world, and
these roles can be mapped to our semantic relations,
so HowNet has set up a detail annotating manual
for us. For example, in HowNet the role frame of
the verb “” (pay attention to) is defined as
{experiencer, target, cause}. With basic semantic
knowledge, annotators can easily identify the rela-
tion between “” (doctor) and “” (pay at-
tention to) as “experiencer”, and the relation
between “” (popularization) and “” (pay
attention to) as “target”. We integrated the on-line
reference of HowNet to the tool, which has been
proved in practice to be very helpful in improving
the consistency and speed of tagging.
</bodyText>
<subsectionHeader confidence="0.999204">
3.3 Checking
</subsectionHeader>
<bodyText confidence="0.995614">
Our work is the first attempt to annotate semantic
dependency relations on a large corpus, and no
prior knowledge is available, so the whole corpus
is tagged manually. But in checking procedure we
have learned some experience and knowledge,
which should be used as possible as we can. So we
adopt two checking modes. In the first mode—
manual checking, checkers correct all errors by
hand; in second mode—semiautomatic checking,
computer-aided checking tool automatically
searches for the errors and then human checkers
correct them, and it means checkers need to read
only about 1/3 or less questionable sentences.
In semiautomatic checking, all the files are
scanned automatically to search for three kinds of
errors:
</bodyText>
<listItem confidence="0.935418411764706">
1. To check whether the semantic relations
conform to the necessary role frame defined
by HowNet.
2. To check whether the relations conform to
error rules. Some errors frequently occurred
during manual checking. For example, the re-
lation between words “/”(again) and a
verb must be “frequency”, but in incorrect
sentences it was tagged otherwise. We sum-
marized these errors, and wrote them as rules.
3. To check whether the score of semantic
dependency model (equation 1) is below some
threshold. A simple semantic dependency
model was built on the corpus. Although the
score of tagged sentence cannot be the crite-
rion of correctness, at least it can show the
consistency of a kind of sentences.
</listItem>
<equation confidence="0.994923">
n
P(T) = ∏P(wk,h(wk),rk) (1)
k=1
</equation>
<bodyText confidence="0.999991938775511">
where n is the length of the sentence, wk is the
k-th word in the sentence, h(wk) is the headword
to wk with semantic relation rk .
The semiautomatic checking interface could
prompt some possible errors, but the necessary role
frames defined by HowNet may be not complete,
the error rules may be not restrict, and the score of
semantic structure model may be not credible. The
prompted errors may be false, so the decision
whether the error is true and how to correct it must
be made by human checkers. This is the reason
why it is called semiautomatic checking.
The checking procedure consisted of five
rounds of selective manual checking and a round
of semiautomatic checking. In tagging procedure,
we dispatched the raw files to annotators in a
group of 10 files. In a round of selective manual
checking, one file in every group was selected to
check. All corrections were recorded by the check-
ing interface, and the reasons for corrections were
explained by the checker. If too many error sen-
tences occurred in the selected file, all files in this
group needed correcting by original annotators
after referring to the corrected sentences and their
explanations.
After four rounds of selective manual check-
ing, most of errors have been corrected, but there
were still some files that have not been checked or
corrected. We semi-automatically checked all files.
Finally, the fifth round of manual checking was
taken.
Fourteen graduate studentstook part in anno-
tating, most of them are majored in linguistics.
Seven excellent students were elected for checking
among annotators, and they were not allowed to
check their own files. According to our statistics,
the average speed to annotate by hand is about 1.15
hours per 100 sentences; the average speed to
check by hand is about 0.25 hours per 100 sen-
tences; and the speed to check half automatically is
about 0.08 hours per 100 sentences. In manual
checking procedure, there were 50% of all files
that were manually checked, 75.45% that were
turned to the original annotator to correct. (When
counting the files corrected by original annotators,
if the same group of files were corrected in two
rounds, we count them as two groups.) And all
files were checked in semiautomatic checking pro-
cedure.
</bodyText>
<subsectionHeader confidence="0.993155">
3.4 Congruence
</subsectionHeader>
<bodyText confidence="0.999974178571428">
Under the given annotating manual, consistency is
an important criterion to evaluate the corpus. If
tagged sentence is independently checked and
passed by several experts, the annotation may be
credible; otherwise, if some experts do not agree to
the annotation, it may be not credible enough. If
several experts evaluate tagged sentences inde-
pendently, the inter-checker agreement is defined
as the measure of consistency.
Relation Congruence (RCn) and Sentence
Congruence (SCn) are defined. RCn is the number
of relations for which n judges agreed, divided by
the total number of relations, in which n can be 1,
2, 3. SCn is the number of sentences for which n
judges agreed, divided by the total number of sen-
tences, in which n can be 1, 2, 3. For example, if
three experts take part in evaluating, RC3 is the
percentage of the annotated relation that all three
experts are agree to one annotation, and SC1 is the
percentage of the annotated sentence for which all
three judges’ opinions are different from one an-
other.
Before checking, 500 sentences were evalu-
ated by three experts. After checking, 1,400 sen-
tences were evaluated by three experts. In order to
balance the coverage and workload of evaluation,
another 4,900 sentences were evaluated by two
experts. The congruency is shown in table 2.
</bodyText>
<table confidence="0.9978925">
RC3 RC2 RC1
Unchecked(500) 90.78% 8.65% 0.57%
Checked(1400) 96.24% 3.64% 0.12%
Checked(4900) 97.56% 2.44%
SC3 SC2 SC1
Unchecked(500) 69.20% 23.00% 7.80%
Checked(1400) 83.43% 14.07% 2.50%
Checked(4900) 89.10% 10.90%
</table>
<tableCaption confidence="0.8219285">
Table 2: the congruency of data before and after
checking
</tableCaption>
<bodyText confidence="0.976106">
The results show that the quality of corpus is
improved greatly after checking, and high rela-
tion/sentence congruency of 96.24%/83.43%
among three experts was satisfactory.
</bodyText>
<sectionHeader confidence="0.470449" genericHeader="method">
4 Future works
References
</sectionHeader>
<bodyText confidence="0.970624708333333">
Collin F. Baker, Charles J. Fillmore, John B. Lowe.
1998. The Berkeley FrameNet Project, Proceedings
of the COLING-ACL, Montreal, Canada.
Although the tagging task is completed, much fur-
ther work will be needed. A user-friendly, interac-
tive interface for corpus investigation is needed to
search the example sentences and to maintain the
tagged data. Inconsistencies still exist in the corpus,
and it may become more apparent with time. How
to reduce inconsistencies is a challenging problem.
The role frame of verbs can to be extracted from
the corpus, which could be integrated with
HowNet to build a larger database. The correlation
frame of nouns, which can represent the order of
modifier phrases, can be extracted, too.
More statistical researches could be carried
out on the corpus. Researches on Chinese informa-
tion structure have been carried out on the corpus
(You et al., 2002). Auto-tagging the semantic de-
pendency structure of this kind is under going. And
we hope the SDN corpus could be exploited in
more areas: speech recognition, natural language
understanding, machine translation, information
extraction, and so on.
</bodyText>
<sectionHeader confidence="0.935794" genericHeader="method">
5 Comparison with other corpora
</sectionHeader>
<bodyText confidence="0.9019295">
Our Corpus is compared with other famous cor-
pora for English and Chinese in table 3.
</bodyText>
<table confidence="0.999147142857143">
Corpus Languge Content Scale Institution
SDN Chinese Semantic 1,000,000 Tsinghua
dependency words
FrameNet English Frame 250,000 Berkeley
Semantics sentences
TreeBank(C) Chinese Phrase 500,000 UPenn
structure words
</table>
<tableCaption confidence="0.999971">
Table 3: Comparison with other corpora
</tableCaption>
<bodyText confidence="0.946908461538461">
The FrameNet is annotated with semantic
knowledge, which emphasizes on describing the
frame and scene of several thousands verbs. They
first build a frame database, which contains de-
scriptions of each frame of the verbs, and then an-
notated example sentences of these frames. Unlike
FrameNet, we first annotated semantic dependency
relations of sentences according to HowNet, and
hope to extract frames from the corpus later. Fra-
meNet only described the frame of verbs, while
from Semantic Dependency Net the correlation
frame of nouns and verbs could be automatically
learned by machine.
</bodyText>
<reference confidence="0.903291727272727">
Zhendong Dong and Qiang Dong. 2001. Construction of
a Knowledge System and its Impact on Chinese Re-
search, Contemporary Linguistics, 3: 33-44, Beijing.
Chu-Ren Huang and Keh-jiann Chen. 1992. A Chinese
Corpus for Linguistics Research. In the Proceedings
of the COLING. 1214-1217. Nantes, France
Richard Hudson. 1998. Word Grammars, Dependency
and Valency, An International Handbook of Con-
temporary Research. Edited by Vilmos Agel,
Ludwig M. Eichinger, etc. Berlin, Walter de Gruyter.
Tom B. Y. Lai and Changning Huang. 2000. Depend-
ency-based syntactic analysis of Chinese and Anno-
tation of Parsed Corpus. The 38th Annual Meeting of
the Association for Computational Linguistics, Hong
Kong.
Juanzi Li and Zuoying Wang. 2002. Chinese Statistcal
Parser Based on Semantic Dependecies, Tsinghua
Science and Technology, 7(6): 591-595.
Mingqin Li, Fang You, Juanzi Li, Zuoying Wang. 2002.
Manual of Tagging Semantic Dependency (third
Version), Technical Report, Tsinghua University,
Department of Electronic Engineering.
Mitchell P. Marcus, Beatrice Santorini, Mary Ann Mar-
cinkiewicz. 1993. Building a large annotated corpus
of English: The Penn Treebank. Computational Lin-
guistics, 19(2): 313-330.
Jiaju Mei, Yiming Zhu and YunQi Gao, Yin Hongxiang,
Edited. 1983. Tongyici Cilin (Dictionary of
Synonymous Words), Shanghai Cishu Publisher.
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1993. In-
troduction to WordNet: An On-line Lexical Database,
Five papers on WordNet, CSL Report 43, Cognitive
Science Laboratory. Princeton University.
Jane J. Robinson. 1970. Dependency Structures and
Transformation Rules. Lanuage, 46: 259-285.
Fei Xia, Martha Palmer, Nianwen Xue, Mary Ellen
Okurowski, John Kovarik, Fu-Dong Chiou, Shizhe
Huang, Tony Kroch, and Mitch Marcus. 2000. Pro-
ceedings of the second International Conference on
Language Resources and Evaluation (LREC 2000),
Athens, Greece.
Guowei Yan and Huimin Tan. 1999. Corpus Annotating
Mannual Based on HowNet (Jiyu ZhiWang de
Yuliao Biaozhu Shouce), Technical Report, the De-
partment of computer science, Hong Kong Univer-
sity of Sience of Techonolgy.
http://www.keenage.com
Fang You, Juanzi Li and Zuoying Wang. 2002. An ap-
proach Based HowNet for Extracting Chinese Mes-
sage Structure, Computer Engineering and
Applications, 38: 56-58.
Jianping Zhang. 1999. A Study of Language Model and
Understanding Algorithm for Large Vocabulary
Spontaneous Speech Recognition. Doctor Disserta-
tion, The Department of Electronic Engineering,
Tsinghua University, Beijing.
Appendix A. samples from corpus
Sentence 1:
01/Scope
1-1-1 /Kernel word
23/Restrictive
38/Restrictive
4 3 /‘De’ dependency
56/Descriptive
68/Restrictive
</reference>
<footnote confidence="0.736927533333333">
7 6 /‘De’ dependency
81/Content
Sentence 2:
0 1 /Preposition
1 4 /Location
2 4 /Correlative
3 4 /Comment
4 -1-1 /Kernel word
5 6 /Restrictive
6 11 /Restrictive
7 8 /Preposition
8 9 /LocationIni
9 11 /Patient
10 9 � � /‘De’ dependency
11 4 /Content
</footnote>
<figure confidence="0.9714925">
Sentence 3:
0 2 /Agent
1 2 /Comment
2 -1-1 /Kernel word
3 4 /Modifier
4 18/Restrictive
5 4 /Appositive
6 11 /Quantity
7 6 /Connection
8 6 /Connection
9 6 /Connection
10 6 /Connection
11 18/Quantity
12 18/Relevant
13 15 /Restrictive
14 15 /Restrictive
15 12 /Isa
16 12 � � /‘De’ dependency
17 18/Modifier
182 /Patient
Sentence 4:
0 -1-1 /Kernel word
1 2 /Comment
2 0 /Content
3 8 /Experiencer
4 6 /Restrictive
5 6 /Restrictive
6 3 /Target
7 3 � � /‘De’ dependency
8 9/Restrictive
92 /Possession
Sentence 5:
</figure>
<footnote confidence="0.98813225">
0 6 /Preposition
1 6 /Relevant
2 1 /Contrast
3 1 /Coordination
4 3 /Contrast
5 1 � � /‘De’ dependency
6 -1-1 /Kernel word
7 6 /LocationPreposition
</footnote>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.052879">
<title confidence="0.930626">Building A Large Chinese Annotated With Semantic Dependency</title>
<author confidence="0.962968">LI Mingqin</author>
<affiliation confidence="0.867772">Department of Electronic Tsinghua</affiliation>
<address confidence="0.993543">Beijing 100084, China</address>
<email confidence="0.953861">.edu.cn</email>
<author confidence="0.987235">LI Juanzi</author>
<affiliation confidence="0.933987666666667">Department of Computer and Tsinghua</affiliation>
<address confidence="0.973243">Beijing 100084, China</address>
<email confidence="0.698717">ljz@thsp.ee.tsinghua.edu.cn</email>
<author confidence="0.872855">DONG Zhendong</author>
<affiliation confidence="0.747737333333333">Research Centre of Computer Language Chinese Academy of</affiliation>
<address confidence="0.934123">Beijing, 100084,China</address>
<email confidence="0.998743">dzd@keenage.com</email>
<author confidence="0.997941">WANG Zuoying</author>
<affiliation confidence="0.9997765">Department of Electronic Engineering, Tsinghua University,</affiliation>
<address confidence="0.999064">Beijing 100084, China</address>
<email confidence="0.92748">wzy-dee@tsinghua.edu.cn</email>
<author confidence="0.984109">LU Dajin</author>
<affiliation confidence="0.8687445">Department of Electronic Tsinghua</affiliation>
<address confidence="0.994091">Beijing 100084, China</address>
<email confidence="0.990847">ludj@mail.tsinghua.edu.cn</email>
<abstract confidence="0.993444136363637">At present most of corpora are annotated mainly with syntactic knowledge. In this paper, we attempt to build a large corpus and annotate semantic knowledge with dependency grammar. We believe that words are the basic units of semantics, and the structure and meaning of a sentence consist mainly of a series of semantic dependencies individual words. A 1,000,000-wordscale corpus annotated with semantic dependency has been built. Compared with syntactic knowledge, semantic knowledge is more difficult to annotate, for ambiguity problem is more serious. In the paper, the strategy to improve consistency is addressed, and congruence is defined to measure the consistency of tagged corpus.. Finally, we will compare our corpus with other well-known corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
</authors>
<date>2001</date>
<booktitle>Construction of a Knowledge System and its Impact on Chinese Research, Contemporary Linguistics,</booktitle>
<volume>3</volume>
<pages>33--44</pages>
<location>Beijing.</location>
<contexts>
<context position="2967" citStr="Dong and Dong, 2001" startWordPosition="417" endWordPosition="420">ng. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (Miller et al., 1993) and Chinese HowNet (Dong and Dong, 2001). For Chinese, many attentions have been naturally paid to researches on semantics, because Chinese is a meaning-combined language, its syntax is very flexible, and semantic rules are more stable than syntactic rules. For instance, in Chinese it is very pervasive that more than one part-of -speeches a word has, and a word does not have tense or voice flectional transition under different tenses or voices. Nevertheless, no large Chinese corpus annotated with semantic knowledge has ever been built at present. In Semantic Dependency Net (SDN), we try to describe deeper semantic dependency relatio</context>
<context position="8725" citStr="Dong and Dong, 2001" startWordPosition="1392" endWordPosition="1395">sists of three kinds of relations: semantic relations, syntactic relations and special relations. Semantics is the main content of this corpus, so semantic relations are in the majority, and syntactic relations are used to annotate the special structures that do not have exact sense in terms of semantics. In addition, there are two special relations: “kernel word” is to indicate the headword of a sentence, and “failure” is to indicate the word that cannot be annotated with dependency relations because the sentence is not completed. The selections of semantic relations were referred to HowNet (Dong and Dong, 2001). HowNet is a lexical database, which describes the relations among words and concepts as a network. In HowNet, senventy-six semantic relations are defined to describe all relations among various concepts, and most of them describe the semantic relations between action and other concepts. With these semantic relations, necessary role frame is further defined. The roles in the necessary role frame must take part in the action in real word, while these roles may not appear in the same sentence. Hong Kong Technology University has successfully tagged a news corpus with the necessary role frame (Y</context>
</contexts>
<marker>Dong, Dong, 2001</marker>
<rawString>Zhendong Dong and Qiang Dong. 2001. Construction of a Knowledge System and its Impact on Chinese Research, Contemporary Linguistics, 3: 33-44, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chu-Ren Huang</author>
<author>Keh-jiann Chen</author>
</authors>
<title>A Chinese Corpus for Linguistics Research.</title>
<date>1992</date>
<booktitle>In the Proceedings of the COLING.</booktitle>
<pages>1214--1217</pages>
<location>Nantes, France</location>
<contexts>
<context position="2218" citStr="Huang and Chen, 1992" startWordPosition="304" endWordPosition="307"> investigating diverse language phenomena, building statistical language models, evaluating and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical data</context>
</contexts>
<marker>Huang, Chen, 1992</marker>
<rawString>Chu-Ren Huang and Keh-jiann Chen. 1992. A Chinese Corpus for Linguistics Research. In the Proceedings of the COLING. 1214-1217. Nantes, France</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Hudson</author>
</authors>
<title>Word Grammars, Dependency and Valency, An International Handbook of Contemporary Research. Edited by Vilmos</title>
<date>1998</date>
<contexts>
<context position="5301" citStr="Hudson, 1998" startWordPosition="796" endWordPosition="797"> corpus. In Section 4, we briefly introduce some of the works on the corpus, and indicate the directions that the project is likely to take in the future. Finally, we compare SDN corpus with some other well-known corpora. Figure 1: A sample sentence from the corpus. (a) The sentence tagged with semantic classes; (b) The sentence annotated with semantic dependency; (c) The semantic dependency tree of the sentence, headwords are linked with bold lines, and modifier words are linked with arrow lines. S 2 The tagging scheme of semantic dependency 2.1 Semantic dependency grammar Like Word grammar (Hudson, 1998), We believe that words are the basic units of semantics, and the structure and meaning of a sentence consist mainly of semantic dependencies between individual words. So a sentence could be annotated with a series of semantic dependency relations (Li Juanzi and Wang, 2002). Let S be a sentence composed of words tagged with semantic classes, = &lt; w s &gt; &lt; w s &gt; &lt; wn s n { 1, 1 , 2, 2 , , , &gt;} list of semantic dependency relations is defined as: SRL = SR { (1 ), ( 2 ), , ( SR SR n , where SR(i) = (hi,ri) . SR stands for ‘ semantic relation’. SR(i) = (hi , r i ) states that the hi -th word is the </context>
</contexts>
<marker>Hudson, 1998</marker>
<rawString>Richard Hudson. 1998. Word Grammars, Dependency and Valency, An International Handbook of Contemporary Research. Edited by Vilmos Agel, Ludwig M. Eichinger, etc. Berlin, Walter de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom B Y Lai</author>
<author>Changning Huang</author>
</authors>
<title>Dependency-based syntactic analysis of Chinese and Annotation of Parsed Corpus.</title>
<date>2000</date>
<booktitle>The 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Hong Kong.</location>
<contexts>
<context position="2307" citStr="Lai and Huang, 2000" startWordPosition="320" endWordPosition="323">g and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (M</context>
</contexts>
<marker>Lai, Huang, 2000</marker>
<rawString>Tom B. Y. Lai and Changning Huang. 2000. Dependency-based syntactic analysis of Chinese and Annotation of Parsed Corpus. The 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juanzi Li</author>
<author>Zuoying Wang</author>
</authors>
<date>2002</date>
<booktitle>Chinese Statistcal Parser Based on Semantic Dependecies, Tsinghua Science and Technology,</booktitle>
<volume>7</volume>
<issue>6</issue>
<pages>591--595</pages>
<marker>Li, Wang, 2002</marker>
<rawString>Juanzi Li and Zuoying Wang. 2002. Chinese Statistcal Parser Based on Semantic Dependecies, Tsinghua Science and Technology, 7(6): 591-595.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingqin Li</author>
<author>Fang You</author>
<author>Juanzi Li</author>
<author>Zuoying Wang</author>
</authors>
<title>Manual of Tagging Semantic Dependency (third Version),</title>
<date>2002</date>
<tech>Technical Report,</tech>
<institution>Tsinghua University, Department of Electronic Engineering.</institution>
<marker>Li, You, Li, Wang, 2002</marker>
<rawString>Mingqin Li, Fang You, Juanzi Li, Zuoying Wang. 2002. Manual of Tagging Semantic Dependency (third Version), Technical Report, Tsinghua University, Department of Electronic Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="1922" citStr="Marcus et al., 1993" startWordPosition="258" endWordPosition="261">ncy is addressed, and congruence is defined to measure the consistency of tagged corpus.. Finally, we will compare our corpus with other well-known corpora. 1 Introduction As basic research tools for investigators in natural language processing, large annotated corpora play an important role in investigating diverse language phenomena, building statistical language models, evaluating and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which prod</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2): 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiaju Mei</author>
</authors>
<title>Yiming Zhu and YunQi Gao, Yin Hongxiang, Edited.</title>
<date>1983</date>
<publisher>Cishu Publisher.</publisher>
<location>Shanghai</location>
<marker>Mei, 1983</marker>
<rawString>Jiaju Mei, Yiming Zhu and YunQi Gao, Yin Hongxiang, Edited. 1983. Tongyici Cilin (Dictionary of Synonymous Words), Shanghai Cishu Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>Introduction to WordNet: An On-line Lexical Database, Five papers on WordNet,</title>
<date>1993</date>
<tech>CSL Report 43,</tech>
<institution>Cognitive Science Laboratory. Princeton University.</institution>
<contexts>
<context position="2926" citStr="Miller et al., 1993" startWordPosition="410" endWordPosition="413">), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (Miller et al., 1993) and Chinese HowNet (Dong and Dong, 2001). For Chinese, many attentions have been naturally paid to researches on semantics, because Chinese is a meaning-combined language, its syntax is very flexible, and semantic rules are more stable than syntactic rules. For instance, in Chinese it is very pervasive that more than one part-of -speeches a word has, and a word does not have tense or voice flectional transition under different tenses or voices. Nevertheless, no large Chinese corpus annotated with semantic knowledge has ever been built at present. In Semantic Dependency Net (SDN), we try to de</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1993</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. 1993. Introduction to WordNet: An On-line Lexical Database, Five papers on WordNet, CSL Report 43, Cognitive Science Laboratory. Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane J Robinson</author>
</authors>
<title>Dependency Structures and Transformation Rules.</title>
<date>1970</date>
<journal>Lanuage,</journal>
<volume>46</volume>
<pages>259--285</pages>
<contexts>
<context position="12297" citStr="Robinson, 1970" startWordPosition="1971" endWordPosition="1972"> 1999). 3.2 Tagging tools A computer-aided tagging tool was developed to assist annotators in tagging semantic dependency relations. To tag a word, annotator only need to select its headword and their relation by clicking mouse. After a sentence has been tagged, the corresponding semantic dependency tree will be displayed to help annotators check the sentence structure. Two additional functions are also provided in the tool: dependency grammar checking and online reference of HowNet. Dependency grammar checking guarantees that the tagged sentence conforms to four axioms of dependency grammar (Robinson, 1970): (a) One and only one element is independent; (b) All others depend directly on some element; (c) No element depends directly on more than one other (d) If A depends directly on B and some element C intervenes between them (in linear order of string), then C depends directly on A or B or some other intervening element. During annotating procedure, the tool checks whether the tagged relation conforms to dependency grammar, and prompts the grammar errors in time. On-line HowNet reference facilitates looking up semantic knowledge and helps to ensure the consistency of tagging. Semantic knowledge</context>
</contexts>
<marker>Robinson, 1970</marker>
<rawString>Jane J. Robinson. 1970. Dependency Structures and Transformation Rules. Lanuage, 46: 259-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
<author>Mary Ellen Okurowski</author>
<author>John Kovarik</author>
<author>Fu-Dong Chiou</author>
<author>Shizhe Huang</author>
<author>Tony Kroch</author>
<author>Mitch Marcus</author>
</authors>
<date>2000</date>
<booktitle>Proceedings of the second International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="2179" citStr="Xia et al., 2000" startWordPosition="297" endWordPosition="300">d corpora play an important role in investigating diverse language phenomena, building statistical language models, evaluating and comparing kinds of parsing models. At present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge. For example, the Penn Treebank (Marcus et al., 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus. For Chinese, some corpora annotated with phrase structure also have been built, for instance the Penn Chinese Treebank (Xia et al., 2000) and Sina Corpus (Huang and Chen, 1992). A syntactic annotation scheme based on dependency was proposed by (Lai and Huang, 2000), and a small corpus was built for testing. However, very limited work has been done with annotation semantic knowledge in all languages. From 1999, Berkeley started FrameNet project (Baker et al., 1998), which produced the frame-semantic descriptions of several thousand English lexical items and backed up these description with semantically annotated attestations from contemporary English corpus. Although few corpora annotated with semantic knowledge are available no</context>
</contexts>
<marker>Xia, Palmer, Xue, Okurowski, Kovarik, Chiou, Huang, Kroch, Marcus, 2000</marker>
<rawString>Fei Xia, Martha Palmer, Nianwen Xue, Mary Ellen Okurowski, John Kovarik, Fu-Dong Chiou, Shizhe Huang, Tony Kroch, and Mitch Marcus. 2000. Proceedings of the second International Conference on Language Resources and Evaluation (LREC 2000), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guowei Yan</author>
<author>Huimin Tan</author>
</authors>
<title>Corpus Annotating Mannual Based on HowNet (Jiyu ZhiWang de Yuliao Biaozhu Shouce),</title>
<date>1999</date>
<tech>Technical Report, the</tech>
<institution>Department of computer science, Hong Kong University of Sience of Techonolgy.</institution>
<note>http://www.keenage.com</note>
<contexts>
<context position="9342" citStr="Yan and Tan, 1999" startWordPosition="1492" endWordPosition="1495">). HowNet is a lexical database, which describes the relations among words and concepts as a network. In HowNet, senventy-six semantic relations are defined to describe all relations among various concepts, and most of them describe the semantic relations between action and other concepts. With these semantic relations, necessary role frame is further defined. The roles in the necessary role frame must take part in the action in real word, while these roles may not appear in the same sentence. Hong Kong Technology University has successfully tagged a news corpus with the necessary role frame (Yan and Tan, 1999), which shows that these roles can describe all semantic phenomena in real texts. In order to make tagging task easier and the corpus more suitable for statistical learning, we have pared down some relations in HowNet and . A ) } got fifty-nine semantic relations. Some HowNet relations seldom occurred in the corpus, and their semantic functions are somewhat similar, so they are merged. Some relations are ambiguous, for example “degree” and “range”. In order to improve the consistency, we also merge these two relations. Semantic relations can describe the relations between notional words, but t</context>
</contexts>
<marker>Yan, Tan, 1999</marker>
<rawString>Guowei Yan and Huimin Tan. 1999. Corpus Annotating Mannual Based on HowNet (Jiyu ZhiWang de Yuliao Biaozhu Shouce), Technical Report, the Department of computer science, Hong Kong University of Sience of Techonolgy. http://www.keenage.com</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang You</author>
<author>Juanzi Li</author>
<author>Zuoying Wang</author>
</authors>
<title>An approach Based HowNet for Extracting Chinese Message Structure,</title>
<date>2002</date>
<journal>Computer Engineering and Applications,</journal>
<volume>38</volume>
<pages>56--58</pages>
<contexts>
<context position="20258" citStr="You et al., 2002" startWordPosition="3276" endWordPosition="3279">tion is needed to search the example sentences and to maintain the tagged data. Inconsistencies still exist in the corpus, and it may become more apparent with time. How to reduce inconsistencies is a challenging problem. The role frame of verbs can to be extracted from the corpus, which could be integrated with HowNet to build a larger database. The correlation frame of nouns, which can represent the order of modifier phrases, can be extracted, too. More statistical researches could be carried out on the corpus. Researches on Chinese information structure have been carried out on the corpus (You et al., 2002). Auto-tagging the semantic dependency structure of this kind is under going. And we hope the SDN corpus could be exploited in more areas: speech recognition, natural language understanding, machine translation, information extraction, and so on. 5 Comparison with other corpora Our Corpus is compared with other famous corpora for English and Chinese in table 3. Corpus Languge Content Scale Institution SDN Chinese Semantic 1,000,000 Tsinghua dependency words FrameNet English Frame 250,000 Berkeley Semantics sentences TreeBank(C) Chinese Phrase 500,000 UPenn structure words Table 3: Comparison w</context>
</contexts>
<marker>You, Li, Wang, 2002</marker>
<rawString>Fang You, Juanzi Li and Zuoying Wang. 2002. An approach Based HowNet for Extracting Chinese Message Structure, Computer Engineering and Applications, 38: 56-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianping Zhang</author>
</authors>
<title>A Study of Language Model and Understanding Algorithm for Large Vocabulary Spontaneous Speech Recognition.</title>
<date>1999</date>
<institution>Doctor Dissertation, The Department of Electronic Engineering, Tsinghua University,</institution>
<location>Beijing.</location>
<contexts>
<context position="10399" citStr="Zhang, 1999" startWordPosition="1667" endWordPosition="1668">range”. In order to improve the consistency, we also merge these two relations. Semantic relations can describe the relations between notional words, but they cannot annotate function words in some special phrase structures. So nine syntactic relations are added. The tag set is listed in table 1. Full definition of each dependency relation can be seen in (Li Mingqin et al., 2002). Semantic Relations 59 Syntacitc “ ” Relations 9 Special relaions 2 Table 1: The dependency relation tag set. 3 The tagging and checking of semantic dependency relations 3.1 Texts of corpus A part of Tsinghua Corpus (Zhang, 1999) annotated with semantic classes was selected as raw data of our corpus. The texts of Tsinghua corpus come from the news of People’s Daily. The selected part consists of about 1,000,000 words, approximately 1,500,000 Chinese characters. Its domain covers the politics, economy, science, sports, etc. The proportion of different domains is shown in figure 2. Figure 2: The proportion of texts of different domains Because Chinese is not written with word delimiters, first the text was segmented into words according to the lexicon of 100,000 words. Then each word was tagged with semantic class, whos</context>
<context position="11688" citStr="Zhang, 1999" startWordPosition="1878" endWordPosition="1879">al., 1983).The semantic classes are organized as a tree, which has three levels. The first level contains 18 classes, the second level contains 101 classes, and the third level contains 1434 classes. These hierarchical semantic classes are helpful to express the superordinate and subordinate information among words. All the text in Tsinghua Corpus was segmented, tagged and checked manually. Since the corpus was built in 1998, it has been used for several years in the researches on automatic sense tagging and class-based language model. Now, the accuracy of tagging system has reached to 92.7% (Zhang, 1999). 3.2 Tagging tools A computer-aided tagging tool was developed to assist annotators in tagging semantic dependency relations. To tag a word, annotator only need to select its headword and their relation by clicking mouse. After a sentence has been tagged, the corresponding semantic dependency tree will be displayed to help annotators check the sentence structure. Two additional functions are also provided in the tool: dependency grammar checking and online reference of HowNet. Dependency grammar checking guarantees that the tagged sentence conforms to four axioms of dependency grammar (Robins</context>
</contexts>
<marker>Zhang, 1999</marker>
<rawString>Jianping Zhang. 1999. A Study of Language Model and Understanding Algorithm for Large Vocabulary Spontaneous Speech Recognition. Doctor Dissertation, The Department of Electronic Engineering, Tsinghua University, Beijing.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Appendix</author>
</authors>
<title>samples from corpus Sentence 1: 01/Scope</title>
<marker>Appendix, </marker>
<rawString>Appendix A. samples from corpus Sentence 1: 01/Scope</rawString>
</citation>
<citation valid="false">
<pages>1--1</pages>
<note>Kernel word 23/Restrictive 38/Restrictive</note>
<marker></marker>
<rawString>1-1-1 /Kernel word 23/Restrictive 38/Restrictive</rawString>
</citation>
<citation valid="false">
<volume>4</volume>
<note>De’ dependency 56/Descriptive 68/Restrictive</note>
<marker></marker>
<rawString>4 3 /‘De’ dependency 56/Descriptive 68/Restrictive</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>