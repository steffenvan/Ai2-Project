<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.979602">
Graph Based Semi-Supervised Approach for Information Extraction
</title>
<author confidence="0.896998">
Hany Hassan Ahmed Hassan Sara Noeman
</author>
<affiliation confidence="0.869565">
IBM Cairo Technology Development Center
</affiliation>
<address confidence="0.8222935">
Giza, Egypt
P.O. Box 166 Al-Ahram
</address>
<email confidence="0.972833">
hanyh@eg.ibm.com hasanah@eg.ibm.com noemans@eg.ibm.com
</email>
<sectionHeader confidence="0.983577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997436">
Classification techniques deploy supervised
labeled instances to train classifiers for
various classification problems. However
labeled instances are limited, expensive,
and time consuming to obtain, due to the
need of experienced human annotators.
Meanwhile large amount of unlabeled data
is usually easy to obtain. Semi-supervised
learning addresses the problem of utilizing
unlabeled data along with supervised la-
beled data, to build better classifiers. In
this paper we introduce a semi-supervised
approach based on mutual reinforcement in
graphs to obtain more labeled data to en-
hance the classifier accuracy. The approach
has been used to supplement a maximum
entropy model for semi-supervised training
of the ACE Relation Detection and Charac-
terization (RDC) task. ACE RDC is con-
sidered a hard task in information
extraction due to lack of large amounts of
training data and inconsistencies in the
available data. The proposed approach pro-
vides 10% relative improvement over the
state of the art supervised baseline system.
</bodyText>
<sectionHeader confidence="0.992543" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999722">
Classification techniques use labeled data to train
classifiers for various classification problems. Yet
they often face a shortage of labeled training data.
Labeled instances are often difficult, expensive,
</bodyText>
<page confidence="0.350544">
9
</page>
<bodyText confidence="0.999897085714286">
and /or time consuming to obtain. Meanwhile large
numbers of unlabeled instances are often available.
Semi-supervised learning addresses the problem of
how unlabeled data can be usefully employed,
along with labeled data, to build better classifiers.
In this paper we propose a semi-supervised ap-
proach for acquiring more training instances simi-
lar to some labeled instances. The approach
depends on constructing generalized extraction
patterns, which could match many instances, and
deploying graph based mutual reinforcement to
weight the importance of these patterns. The mu-
tual reinforcement is used to automatically identify
the most informative patterns; where patterns that
match many instances tend to be correct. Similarly,
instances matched by many patterns also tend to be
correct. The labeled instances should have more
effect in the mutual reinforcement weighting proc-
ess. The problem can therefore be seen as hubs
(instances) and authorities (patterns) problem
which can be solved using the Hypertext Induced
Topic Selection (HITS) algorithm (Kleinberg,
1998 ).
HITS is an algorithmic formulation of the notion
of authority in web pages link analysis, based on a
relationship between a set of relevant “authorita-
tive pages” and a set of “hub pages”. The HITS
algorithm benefits from the following observation:
when a page (hub) links to another page (author-
ity), the former confers authority over the latter.
By analogy to the authoritative web pages prob-
lem, we could represent the patterns as authorities
and instances as hubs, and use mutual reinforce-
ment between patterns and instances to weight the
most authoritative patterns. Instances from unsu-
</bodyText>
<note confidence="0.516823">
Workshop on TextGraphs, at HLT-NAACL 2006, pages 9–16,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999543727272727">
pervised data matched with the highly weighted
patterns are then used in retraining the system.
The paper proceeds as follows: in Section 2 we
discuss previous work followed by a brief defini-
tion of our general notation in Section 3. A detailed
description of the proposed approach then follows
in Section 4. Section 5 discusses the application of
the proposed approach to the problem of detecting
semantic relations from text. Section 6 discusses
experimental results while the conclusion is pre-
sented in Section 7.
</bodyText>
<sectionHeader confidence="0.988909" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999884541666667">
(Blum and Mitchell, 1998) proposed an approach
based on co-training that uses unlabeled data in a
particular setting. They exploit the fact that, for
some problems, each example can be described by
multiple representations. They develop a boosting
scheme which exploits conditional independence
between these representations.
(Blum and Chawla, 2001) proposed a general
approach utilizing unlabeled data by constructing a
graph on all the data points based on distance rela-
tionships among examples, and then to use the
known labels to perform a graph partitioning using
the minimum cut that agrees with the labeled data.
(Zhu et al., 2003) extended this approach by pro-
posing a cut based on the assumption that labels
are generated according to a Markov Random
Field on the graph , (Joachims, 2003) presented an
algorithm based on spectral graph partitioning.
(Blum et al., 2004) extended the min-cut approach
by adding randomness to the graph structure, their
algorithm addresses several shortcomings of the
basic mincut approach, yet it may not help in cases
where the graph does not have small cuts for a
given classification problem.
</bodyText>
<sectionHeader confidence="0.991336" genericHeader="method">
3 Background
</sectionHeader>
<bodyText confidence="0.99983347826087">
In graph theory, a graph is a set of objects called
vertices joined by links called edges. A bipartite
graph, also called a bigraph, is a special graph
where the set of vertices can be divided into two
disjoint sets with no two vertices of the same set
sharing an edge.
The Hypertext Induced Topic Selection (HITS)
algorithm is an algorithm for rating, and therefore
ranking, web pages. The HITS algorithm makes
use of the following observation: when a page
(hub) links to another page (authority), the former
confers authority over the latter. HITS uses two
values for each page, the &amp;quot;authority value&amp;quot; and the
&amp;quot;hub value&amp;quot;. &amp;quot;Authority value&amp;quot; and &amp;quot;hub value&amp;quot; are
defined in terms of one another in a mutual recur-
sion. An authority value is computed as the sum of
the scaled hub values that point to that authority. A
hub value is the sum of the scaled authority values
of the authorities it points to.
A template, as we define for this work, is a se-
quence of generic forms that could generalize over
the given training instance. An example template
is:
</bodyText>
<equation confidence="0.882305">
COUNTRY NOUN PHRASE PERSON
_
VERB_PHRASE
</equation>
<bodyText confidence="0.971051166666667">
This template could represent the sentence:
“American vice President Al Gore visited ...”.
This template is derived from the representation of
the Named Entity tags, Part-of-Speech (POS) tags
and semantic tags. The choice of the template rep-
resentation here is for illustration purpose only;
any combination of tags, representations and tag-
ging styles might be used.
A pattern is more specific than a template. A
pattern specifies the role played by the tags (first
entity, second entity, or relation). An example of a
pattern is:
</bodyText>
<equation confidence="0.997794">
COUNTRY(E2) NOUN_PHRASE(R) PERSON(E1)
VERB_PHRASE
</equation>
<bodyText confidence="0.957812363636364">
This pattern indicates that the word(s) with the
tag COUNTRY in the sentence represents the sec-
ond entity (Entity 2) in the relation, while the
word(s) tagged PERSON represents the first entity
(Entity 1) in this relation. Finally, the word(s) with
the tag NOUN_PHRASE represents the relation
between the two previous entities.
A tuple, in our notation during this paper, is the
result of the application of a pattern to unstructured
text. In the above example, one result of applying
the pattern to some raw text is the following tuple:
</bodyText>
<table confidence="0.450255333333333">
Entity 1: Al Gore
Entity 2: United States
Relation: vice President
</table>
<sectionHeader confidence="0.942034" genericHeader="method">
4 The Approach
</sectionHeader>
<bodyText confidence="0.999849">
The semi-supervised graph-based approach we
propose depends on the construction of generalized
extraction patterns that could match many training
instances. The patterns are then weighted accord-
ing to their importance by deploying graph based
</bodyText>
<page confidence="0.823462">
10
</page>
<bodyText confidence="0.9998832">
mutual reinforcement techniques. Patterns derived
from the supervised training instances should have
a superior effect in the reinforcement weighting
process. This duality in patterns and tuples relation
could be stated that patterns could match different
tuples, and tuples in turn could be matched by dif-
ferent patterns. The proposed approach is com-
posed of two main steps namely, pattern extraction
and pattern weighting or induction. Both steps are
detailed in the next subsections.
</bodyText>
<subsectionHeader confidence="0.99931">
4.1 Patterns Extraction
</subsectionHeader>
<bodyText confidence="0.9995755">
As shown in Figure 1, several syntactic, lexical,
and semantic analyzers could be applied to the
training instances. The resulting analyses could be
employed in the construction of extraction pat-
terns. Any extraction pattern could match different
relations and hence could produce several tuples.
As an example let’s consider the pattern depicted
in figure 1:
</bodyText>
<figureCaption confidence="0.769773">
Figure 1: An example of a pattern and its possible
tuples.
</figureCaption>
<equation confidence="0.574839272727273">
PEOPLE_Inhabitant(E2) NOUN_PHRASE(R)
PERSON(E1) VERB_PHRASE
This pattern could extract the tuple:
Entity 1: Al Gore
Entity 2: American
Relation: vice President
Another tuple that could be extracted by the same
pattern is:
Entity 1: Berlusconi
Entity 2: Italian
Relation: Prime Minister
</equation>
<bodyText confidence="0.999846666666667">
On the other hand, many other patterns could ex-
tract the same information in the tuple from differ-
ent contexts. It is worth mentioning that the
proposed approach is general enough to accommo-
date any pattern design; the introduced pattern de-
sign is for illustration purposes only.
To further increase the number of patterns that
could match a single tuple, the tuple space might
be reduced i.e. by grouping tuples conveying the
same information content together into a single
tuple. This will be detailed further in the experi-
mental setup section.
</bodyText>
<subsectionHeader confidence="0.987299">
4.2 Pattern Induction
</subsectionHeader>
<bodyText confidence="0.999986">
The inherent duality in the patterns and tuples rela-
tion suggests that the problem could be interpreted
as a hub authority problem. This problem could be
solved by applying the HITS algorithm to itera-
tively assign authority and hub scores to patterns
and tuples respectively.
</bodyText>
<subsectionHeader confidence="0.859018">
Patterns Tuples
</subsectionHeader>
<figureCaption confidence="0.8420705">
Figure 2: A bipartite graph representing patterns
and tuples
</figureCaption>
<bodyText confidence="0.999018571428571">
Patterns and tuples are represented by a bipartite
graph as illustrated in figure 2. Each pattern or tu-
ple is represented by a node in the graph. Edges
represent matching between patterns and tuples.
The pattern induction problem can be formu-
lated as follows: Given a very large set of data D
containing a large set of patterns P which match a
</bodyText>
<figure confidence="0.76672735">
American vice President Al Gore said today...
PEOPLE_Inhabitant NOUN_PHRASE PERSON
VERB_PHRASE
Word: American
Entity: PEOPLE
POS : ADJ
Sem: Inhabitant
American vice Presi-
dent Al Gore said
today...
Word: vice president
Entity:
POS: NOUN_PHRASE
Sem:
Italian Prime Minister
Berlusconi visited.....
Word: Al Gore
Entity: PERSON
POS:
Sem:
Entity 1: Al Gore
Entity 2: American
Relation: vice President
Entity 1: Berlusconi
Entity 2: Italian
Relation: prime minister
P
P
P
P
T
T
T
T
P T
P
T
P
T
11
</figure>
<bodyText confidence="0.99976245">
large set of tuples T, the problem is to identify P ,
the set of patterns that match the set of the most
~
correct tuplesT . The intuition is that the tuples
matched by many different patterns tend to be cor-
rect and the patterns matching many different tu-
ples tend to be good patterns. In other words; we
want to choose, among the large space of patterns
in the data, the most informative, highest confi-
dence patterns that could identify correct tuples;
i.e. choosing the most “authoritative” patterns in
analogy with the hub authority problem. However,
both P ~ andT~ are unknown. The induction process
proceeds as follows: each pattern p in P is associ-
ated with a numerical authority weight av which
expresses how many tuples match that pattern.
Similarly, each tuple t in T has a numerical hub
weight ht which expresses how many patterns were
matched by this tuple. The weights are calculated
iteratively as follows:
</bodyText>
<equation confidence="0.993722947368421">
( 1) ( ) ( ) ( )
h u
( )
i + i
= � =
T p
a p (1)
u 1 i
H ( )
h t
( 1) ( ) ( ) ( )
a u
+ = P t ( )
i
i (2)
� =
u 1 ( )
i
A
</equation>
<bodyText confidence="0.990312833333333">
where T(p) is the set of tuples matched by p, P(t) is
the set of patterns matching t, a (i+1) ( p) is the au-
thoritative weight of pattern p at iteration (i + 1) ,
and h(i+1)( t) is the hub weight of tuple t at itera-
tion (i + 1) . H(i) and A(i) are normalization fac-
tors defined as:
</bodyText>
<equation confidence="0.997869153846154">
( ) =  ||
P T p
( )
H i h i u
( )
� = � = ( ) (3)
p 1 u 1
A i ( )
( ) =  ||
� = � = a i u
v 1 u 1
T P t
( ) ( ) (4)
</equation>
<bodyText confidence="0.999392461538462">
Patterns with weights lower than a predefined
threshold are rejected, and examples associated
with highly ranked patterns are then used in unsu-
pervised training.
It is worth mentioning that both T and P contain
supervised and unsupervised examples, however
the proposed method could assign weights to the
correct examples (tuples and patterns) in a com-
pletely unsupervised setup. For semi-supervised
data some supervised examples are provided,
which are associated in turn with tuples and pat-
terns.
We adopt the HITS extension introduced in
(White and Smyth, 2003) to extend HITS with Pri-
ors. By analogy, we handle the supervised exam-
ples as priors to the HITS induction algorithm.
A prior probabilities vector pr ={pr1, . . . , prn}
is defined such that the probabilities sum to 1,
where prv denotes the relative importance (or
“prior bias”) we attach to node v. A pattern Pi is
assigned a prior pri=1/n if pattern Pi matches a
supervised tuple, otherwise pri is set to zero, n is
the total number of patterns that have a supervised
match. We also define a “back probability” �, 0
1 which determines how often we bias the su-
pervised nodes:
</bodyText>
<equation confidence="0.999200458333333">
( ) ( ) ( ) ( )
( )
i
�
( 1)
+ �
i = − ~T = p h u
a p 1 β � � + β *pr (5)
u 1 i p
H( )
� �
h t
( 1)
i �
+ 1 β � � +
( ) ( ) ( ) ( )
= − � P = t a u
�
� A �
u 1 ( )
( )
i
i β * pr (6)
t
</equation>
<bodyText confidence="0.998356555555555">
where T(p) is the set of tuples matched by p , P(t)
is the set of patterns matching t, and H(i) and A(i)
are normalization factors defined as in equations
(3) and (4)
Thus each node in the graph (pattern or tuple) has
an associated prior weight depending on its super-
vised data. The induction process proceeds to itera-
tively assign weights to the patterns and tuples. In
the current work we used β = 0. 5 .
</bodyText>
<sectionHeader confidence="0.998094" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.7193655">
5.1 ACE Relation Detection and Characteri-
zation
</subsectionHeader>
<bodyText confidence="0.999887571428571">
In this section, we describe Automatic Content
Extraction (ACE). ACE is an evaluation conducted
by NIST to measure Entity Detection and Tracking
(EDT) and Relation Detection and Characteriza-
tion (RDC). The EDT task is concerned with the
detection of mentions of entities, and grouping
them together by identifying their coreference. The
RDC task detects relations between entities identi-
fied by the EDT task. We choose the RDC task to
show the performance of the graph based semi-
supervised information extraction approach we
propose. To this end we need to introduce the no-
tion of mentions and entities. Mentions are any
instances of textual references to objects like peo-
</bodyText>
<page confidence="0.687772">
12
</page>
<bodyText confidence="0.99307075">
ple, organizations, geo-political entities (countries,
cities ...etc), locations, or facilities. On the other
hand, entities are objects containing all mentions to
the same object.
</bodyText>
<table confidence="0.999939458333333">
Type Subtype Number of
Instances
ART User-Owner 331
Inventor
Other
DISC DISC 143
EMP-ORG Employ-Exec 1673
Employ-Staff
Employ-Undetermined
Member-of-Group
Subsidiary
Other
Other-AFF Ethnic 153
Ideology
Other
GPE-AFF Citizen-Resident 695
Based-in
Other
PER-SOC Business 358
Family
Other
PHYS Located 1411
Near
Part-Whole
</table>
<tableCaption confidence="0.999735">
Table 1. Types and subtypes of ACE relations
</tableCaption>
<bodyText confidence="0.986567333333333">
Table 1 lists the types and subtypes of relations
for the ACE RDC task. Here, we present an exam-
ple for those relations:
Spain’s Interior Minister an-
nounced this evening the ar-
rest of separatist
organization Eta’s presumed
leader Ignacio Garcia Ar-
regui. Arregui, who is con-
sidered to be the Eta
organization’s top man, was
arrested at 17h45 Greenwich.
The Spanish judiciary sus-
pects Arregui of ordering a
failed attack on King Juan
Carlos in 1995.
In this fragment, all the underlined phrases are
mentions to Eta organization, or to “Garcia Ar-
regui”. There is a management relation between
leader which references to “Garcia Arregui” and
Eta.
</bodyText>
<subsectionHeader confidence="0.998735">
5.2 Baseline System
</subsectionHeader>
<bodyText confidence="0.999920470588235">
The base line system uses a Maximum Entropy
model that combines diverse lexical, syntactic and
semantic features derived from text, like the sys-
tem described in (Nanda, 2004). The system was
trained on the ACE training data provided by LDC.
The training set contained 145K words, and 4764
instances of relations, the number of instances cor-
responding to each relation is shown in Table 1.
The test set contained around 41K words, and
1097 instances of relations. The system was evalu-
ated using standard ACE evaluation procedure.
ACE evaluation procedure assigns the system an
ACE value for each relation type and a total ACE
value. The ACE value is a standard NIST metric
for evaluating relation extraction. The reader is
referred to the ACE web site (ACE, 2004) for more
details.
</bodyText>
<subsectionHeader confidence="0.986253">
5.3 Pattern Construction
</subsectionHeader>
<bodyText confidence="0.949076222222222">
We used the baseline system described in the pre-
vious section to label a large amount of unsuper-
vised data. The data comes from LDC English
Gigaword corpus, Agence France Press English
Service (AFE). The data contains around 3M
words, from which 80K instances of relations have
been extracted.
We start by extracting a set of patterns that rep-
resent the supervised and unsupervised data. We
consider each relation type separately and extract a
pattern for each instance in the selected relation.
The pattern we used consists of a mix between the
part of speech (POS) tags and the mention tags for
the words in the training instance. We use the men-
tion tag, if it exists; otherwise we use the part of
speech tag. An example of a pattern is:
Text: Eta’s presumed leader
Arregui ...
</bodyText>
<equation confidence="0.915483">
Pos: NNP POS JJ NN NNP
Mention: ORG 0 0 0 PERSON
Pattern: ORG(E2) POS JJ NN(R)
PERSON(E1)
</equation>
<page confidence="0.6213">
13
</page>
<subsectionHeader confidence="0.981774">
5.4 Tuples Clustering
</subsectionHeader>
<bodyText confidence="0.999995476190476">
As discussed in the previous section, the tuple
space should be reduced to allow more matching
between pattern-tuple pairs. This space reduction
could be accomplished by seeking a tuple similar-
ity measure, and constructing a weighted undi-
rected graph of tuples. Two tuples are linked with
an edge if their similarity measure exceeds a cer-
tain threshold. Graph clustering algorithms could
be deployed to partition the graph into a set of ho-
mogeneous communities or clusters. To reduce the
space of tuples, we seek a matching criterion that
group similar tuples together. Using WordNet, we
can measure the semantic similarity or relatedness
between a pair of concepts (or word senses), and
by extension, between a pair of sentences. We use
the similarity measure described in (Wu and
Palmer, 1994) which finds the path length to the
root node from the least common subsumer (LCS)
of the two word senses which is the most specific
word sense they share as an ancestor. The similar-
ity score of two tuples, ST, is calculated as follows:.
</bodyText>
<equation confidence="0.968526">
ST = SE1 + SE (9)
2 2
2
</equation>
<bodyText confidence="0.999941166666667">
where SE1, and SE2 are the similarity scores of the
first entities in the two tuples, and their second en-
titles respectively.
The tuple matching procedure assigns a similarity
measure to each pair of tuples in the dataset. Using
this measure we can construct an undirected graph
G. The vertices of G are the tuples. Two vertices
are connected with an edge if the similarity meas-
ure between their underlying tuples exceeds a cer-
tain threshold. It was noticed that the constructed
graph consists of a set of semi isolated groups as
shown in figure 3. Those groups have a very large
number of inter-group edges and meanwhile a
rather small number of intra-group edges. This im-
plies that using a graph clustering algorithm would
eliminate those weak intra-group edges and pro-
duce separate groups or clusters representing simi-
lar tuples. We used Markov Cluster Algorithm
(MCL) for graph clustering (Dongen, 2000). MCL
is a fast and scalable unsupervised cluster algo-
rithm for graphs based on simulation of stochastic
flow.
A bipartite graph of patterns and tuple clusters is
constructed. Weights are assigned to patterns and
tuple clusters by iteratively applying the HITS with
Priors’ algorithm. Instances associated with highly
ranked patterns are then added to the training data
and the model is retrained. Samples of some highly
ranked patterns and corresponding matching text
are introduced in Table 2.
</bodyText>
<subsectionHeader confidence="0.880037">
Before Clustering After Clustering
</subsectionHeader>
<figureCaption confidence="0.8170645">
Figure 3: Applying Clustering Algorithms to Tuple
graph
</figureCaption>
<table confidence="0.999762705882353">
Pattern Matches
GPE PERSON Zimbabwean President
PERSON PERSON Robert Mugabe
GPE POS PERSON Zimbabwe &apos;s President
PERSON Robert Mugabe
GPE JJ PERSON American diplomatic per-
sonnel
PERSON IN JJ GPE candidates for local gov-
ernment
ORGANIZATION Airways spokesman
PERSON
ORGANIZATION Ajax players
PERSON
PERSON IN DT JJ chairman of the opposition
ORGANIZATION parties
ORGANIZATION parties chairmans
PERSON
</table>
<tableCaption confidence="0.997886">
Table 2: Examples of patterns with high weights
</tableCaption>
<sectionHeader confidence="0.991687" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999993923076923">
We train several models like the one described in
section 5.2 on different training data sets. In all
experiments, we use both the LDC ACE training
data and the labeled unsupervised data induced
with the graph based approach we propose. We use
the ACE evaluation procedure and ACE test cor-
pus, provided by LDC, to evaluate all models.
We incrementally added labeled unsupervised
data to the training data to determine the amount of
data after which degradation in the system per-
formance occurs. We sought this degradation point
separately for each relation type. Figure 4 shows
the effect of adding labeled unsupervised data on
</bodyText>
<equation confidence="0.9997026">
T
T T
T
T
T
T
T
T
T
T
T
T
T
T T
T
T T
T
T
T
T
T
T
T
T
T
</equation>
<page confidence="0.567942">
14
</page>
<bodyText confidence="0.973502025">
the ACE value for each relation separately. We
notice from figure 4 and table 1 that relations with
a small number of training instances had a higher
gain in performance compared to relations with a
large number of training instances. This implies
that the proposed approach achieves significant
improvement when the number of labeled training
instances is small but representative.
Figure 4: The effect of adding labeled unsuper-
vised data on the ACE value for each relation. The
average number of relations per document is 4.
From figure 4, we determined the number of
training instances resulting in the maximum boost
in performance for each relation. We added the
training instances corresponding to the maximum
boost in performance for all relations to the super-
vised training data and trained a new model on
them. Figure 5 compares the ACE values for each
relation in the base line model and the final model
The total system ACE value has been improved
by 10% over the supervised baseline system. All
relation types, except the DSC relation, had sig-
nificant improvement ranging from 7% to 30%
over the baseline supervised system. The DISC
relation type had a small degradation; noting that it
already has a low ACE value with the baseline sys-
tem. We think this is due to the fact that the DISC
relation has few and inconsistent examples in the
supervised data set.
To assess the usefulness of the smoothing
method employing WordNet distance, we repeated
the experiment on EMP-ORG relation without it.
We found out that it contributed to almost 30% of
the total achieved improvement. We also repeated
the experiment but with considering hub scores
instead of authority scores. We added the examples
associated with highly ranked tuples to the training
set. We noticed that using hub scores yielded very
little variation in the ACE value (i.e. 0.1 point for
EMP-ORG relation).
</bodyText>
<figureCaption confidence="0.8567095">
Figure 5: A comparison of base line ACE values,
and final ACE values for each relation.
</figureCaption>
<bodyText confidence="0.999808944444445">
To evaluate the quality and representativeness of
the labeled unsupervised data, acquired using the
proposed approach, we study the effect of replac-
ing supervised data with unsupervised data while
holding the amount of training data fixed. Several
systems have been built using mixture of the su-
pervised and the unsupervised data. In Figure 6,
the dotted line shows the degradation in the system
performance when using a reduced amount of su-
pervised training data only, while the solid line
shows the effect of replacing supervised training
data with unsupervised labeled data on the system
performance. We notice from Figure 6 that the un-
supervised data could replace more than 50% of
the supervised data without any degradation in the
system performance. This is an indication that the
induced unsupervised data is good for training the
classifier.
</bodyText>
<figureCaption confidence="0.987355">
Figure 6: The effect of removing portions of the
supervised data on the ACE value. And the effect
</figureCaption>
<figure confidence="0.997611958333334">
.
ACE Value
40
20
60
50
30
10
0
0 50 100 200 300 400 500
Number of Added Documents
EMP-ORG
PER-SOC
ART
OTHER-
AFF
PHYS
GPE-AFF
ACE Value
BaseLine
Final Model
50
40
30
20
10
0
ART
36.7
39.6
DISC
4.2
6
EMP-
ORG
33.1
35.8
GPE-
AFF
22.3
24.7
OTHE
R-AFF
23.6
30.8
PER-
SOC
42.2
46.6
PHYS TOTAL
26.4
28.2
30.5
33.5
34
33
ACE Value
32
31
30
29
28
27
26
0% 25% 50% 75% Unsupervised
100% 75% 50% 25% Supervised
Percentage of Unsupervised/Supervised
Data
Sup + Unsup
Data
Sup Data Only
15
</figure>
<bodyText confidence="0.8576755">
of replacing portions of the supervised data with
labeled training data.
</bodyText>
<sectionHeader confidence="0.995626" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99998925">
We introduce a general framework for semi-
supervised learning based on mutual reinforcement
in graphs. We construct generalized extraction pat-
terns and deploy graph based mutual reinforcement
to automatically identify the most informative pat-
terns. We provide motivation for our approach
from a graph theory and graph link analysis per-
spective.
We present experimental results supporting the
applicability of the proposed approach to ACE Re-
lation Detection and Characterization (RDC) task,
demonstrating its applicability to hard information
extraction problems. Our approach achieves a sig-
nificant improvement over the base line supervised
system especially when the number of labeled in-
stances is small.
</bodyText>
<sectionHeader confidence="0.997022" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999986666666667">
We would like to thank Nanda Kambhatla for pro-
viding the ACE baseline system. We would also
like to thank Salim Roukos for several invaluable
suggestions and guidance. Finally we would like to
thank the anonymous reviewers for their construc-
tive criticism and helpful comments.
</bodyText>
<sectionHeader confidence="0.99402" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999872609375">
ACE. 2004. The NIST ACE evaluation website.
http://www.nist.gov/speech/tests/ace/
Avrim Blum, and Tom Mitchell. 1998. Combining La-
beled and Unlabeled data with Co-training. Proceed-
ings of the 11th Annual Conference on
Computational Learning Theory.
Avrim Blum and Shuchi Chawla. 2001. Learning From
Labeled and Unlabeled Data Using Graph Mincuts.
Proceedings of International Conference on Machine
Learning (ICML).
Avrim Blum, John Lafferty, Mugizi Rwebangira, and
Rajashekar Reddy. 2004. Semi-supervised Learning
Using Randomized Mincuts. Proceedings of the In-
ternational Conference on Machine Learning
(ICML).
Stijn van Dongen. 2000. A Cluster Algorithm for
Graphs. Technical Report INS-R0010, National Re-
search Institute for Mathematics and Computer Sci-
ence in the Netherlands.
Stijn van Dongen. 2000. Graph Clustering by Flow
Simulation. PhD thesis, University of Utrecht
Radu Florian, Hany Hassan, Hongyan Jing, Nanda
Kambhatla, Xiaqiang Luo, Nicolas Nicolov, and
Salim Roukos. 2004. A Statistical Model for multi-
lingual entity detection and tracking. Proceedings of
the Human Language Technologies Conference
(HLT-NAACL’04).
Dayne Freitag, and Nicholas Kushmerick. 2000.
Boosted wrapper induction. The 14th European Con-
ference on Artificial Intelligence Workshop on Ma-
chine Learning for Information Extraction
Taher Haveliwala. 2002. Topic-sensitive PageRank.
Proceedings of the 11th International World Wide
Web Conference
Thorsten Joachims. 2003. Transductive Learning via
Spectral Graph Partitioning. Proceedings of the In-
ternational Conference on Machine Learning
(ICML).
John Kleinberg. 1998. Authoritative Sources in a Hy-
perlinked Environment. Proceedings of the. 9th
ACM-SIAM Symposium on Discrete Algorithms.
Nanda Kambhatla. 2004. Combining Lexical, Syntactic,
and Semantic Features with Maximum Entropy Mod-
els for Information Extraction. Proceedings of the
42nd Annual Meeting of the Association for Compu-
tational Linguistics
Ted Pedersen, Siddharth Patwardhan, and Jason Mich-
elizzi, 2004, WordNet::Similarity - Measuring the
Relatedness of Concepts. Proceedings of Fifth An-
nual Meeting of the North American Chapter of the
Association for Computational Linguistics (NAACL-
2004)
Scott White, and Padhraic Smyth. 2003. Algorithms for
Discoveing Relative Importance in Graphs. Proceed-
ings of Ninth ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining.
Zhibiao Wu, and Martha Palmer. 1994. Verb semantics
and lexical selection. Proceedings of the 32nd An-
nual Meeting of the Association for Computational
Linguistics.
Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.
2003. Semi-supervised Learning using Gaussian
Fields and Harmonic Functions. Proceedings of the
20th International Conference on Machine Learning.
</reference>
<page confidence="0.907141">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.920942">
<title confidence="0.999799">Graph Based Semi-Supervised Approach for Information Extraction</title>
<author confidence="0.998849">Hany Hassan Ahmed Hassan Sara Noeman</author>
<affiliation confidence="0.997971">IBM Cairo Technology Development</affiliation>
<address confidence="0.9656885">Giza, Egypt P.O. Box 166 Al-Ahram</address>
<email confidence="0.994794">hanyh@eg.ibm.comhasanah@eg.ibm.comnoemans@eg.ibm.com</email>
<abstract confidence="0.999782538461538">Classification techniques deploy supervised labeled instances to train classifiers for various classification problems. However labeled instances are limited, expensive, and time consuming to obtain, due to the need of experienced human annotators. Meanwhile large amount of unlabeled data is usually easy to obtain. Semi-supervised learning addresses the problem of utilizing unlabeled data along with supervised labeled data, to build better classifiers. In this paper we introduce a semi-supervised approach based on mutual reinforcement in graphs to obtain more labeled data to enhance the classifier accuracy. The approach has been used to supplement a maximum entropy model for semi-supervised training of the ACE Relation Detection and Characterization (RDC) task. ACE RDC is considered a hard task in information extraction due to lack of large amounts of training data and inconsistencies in the available data. The proposed approach provides 10% relative improvement over the state of the art supervised baseline system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ACE</author>
</authors>
<title>The NIST ACE evaluation website. http://www.nist.gov/speech/tests/ace/</title>
<date>2004</date>
<contexts>
<context position="16373" citStr="ACE, 2004" startWordPosition="2772" endWordPosition="2773">ribed in (Nanda, 2004). The system was trained on the ACE training data provided by LDC. The training set contained 145K words, and 4764 instances of relations, the number of instances corresponding to each relation is shown in Table 1. The test set contained around 41K words, and 1097 instances of relations. The system was evaluated using standard ACE evaluation procedure. ACE evaluation procedure assigns the system an ACE value for each relation type and a total ACE value. The ACE value is a standard NIST metric for evaluating relation extraction. The reader is referred to the ACE web site (ACE, 2004) for more details. 5.3 Pattern Construction We used the baseline system described in the previous section to label a large amount of unsupervised data. The data comes from LDC English Gigaword corpus, Agence France Press English Service (AFE). The data contains around 3M words, from which 80K instances of relations have been extracted. We start by extracting a set of patterns that represent the supervised and unsupervised data. We consider each relation type separately and extract a pattern for each instance in the selected relation. The pattern we used consists of a mix between the part of sp</context>
</contexts>
<marker>ACE, 2004</marker>
<rawString>ACE. 2004. The NIST ACE evaluation website. http://www.nist.gov/speech/tests/ace/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining Labeled and Unlabeled data with Co-training.</title>
<date>1998</date>
<booktitle>Proceedings of the 11th Annual Conference on Computational Learning Theory.</booktitle>
<contexts>
<context position="3849" citStr="Blum and Mitchell, 1998" startWordPosition="572" endWordPosition="575">City, June 2006. c�2006 Association for Computational Linguistics pervised data matched with the highly weighted patterns are then used in retraining the system. The paper proceeds as follows: in Section 2 we discuss previous work followed by a brief definition of our general notation in Section 3. A detailed description of the proposed approach then follows in Section 4. Section 5 discusses the application of the proposed approach to the problem of detecting semantic relations from text. Section 6 discusses experimental results while the conclusion is presented in Section 7. 2 Previous Work (Blum and Mitchell, 1998) proposed an approach based on co-training that uses unlabeled data in a particular setting. They exploit the fact that, for some problems, each example can be described by multiple representations. They develop a boosting scheme which exploits conditional independence between these representations. (Blum and Chawla, 2001) proposed a general approach utilizing unlabeled data by constructing a graph on all the data points based on distance relationships among examples, and then to use the known labels to perform a graph partitioning using the minimum cut that agrees with the labeled data. (Zhu </context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum, and Tom Mitchell. 1998. Combining Labeled and Unlabeled data with Co-training. Proceedings of the 11th Annual Conference on Computational Learning Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Shuchi Chawla</author>
</authors>
<title>Learning From Labeled and Unlabeled Data Using Graph Mincuts.</title>
<date>2001</date>
<booktitle>Proceedings of International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4173" citStr="Blum and Chawla, 2001" startWordPosition="618" endWordPosition="621">the proposed approach then follows in Section 4. Section 5 discusses the application of the proposed approach to the problem of detecting semantic relations from text. Section 6 discusses experimental results while the conclusion is presented in Section 7. 2 Previous Work (Blum and Mitchell, 1998) proposed an approach based on co-training that uses unlabeled data in a particular setting. They exploit the fact that, for some problems, each example can be described by multiple representations. They develop a boosting scheme which exploits conditional independence between these representations. (Blum and Chawla, 2001) proposed a general approach utilizing unlabeled data by constructing a graph on all the data points based on distance relationships among examples, and then to use the known labels to perform a graph partitioning using the minimum cut that agrees with the labeled data. (Zhu et al., 2003) extended this approach by proposing a cut based on the assumption that labels are generated according to a Markov Random Field on the graph , (Joachims, 2003) presented an algorithm based on spectral graph partitioning. (Blum et al., 2004) extended the min-cut approach by adding randomness to the graph struct</context>
</contexts>
<marker>Blum, Chawla, 2001</marker>
<rawString>Avrim Blum and Shuchi Chawla. 2001. Learning From Labeled and Unlabeled Data Using Graph Mincuts. Proceedings of International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>John Lafferty</author>
<author>Mugizi Rwebangira</author>
<author>Rajashekar Reddy</author>
</authors>
<title>Semi-supervised Learning Using Randomized Mincuts.</title>
<date>2004</date>
<booktitle>Proceedings of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4702" citStr="Blum et al., 2004" startWordPosition="707" endWordPosition="710"> exploits conditional independence between these representations. (Blum and Chawla, 2001) proposed a general approach utilizing unlabeled data by constructing a graph on all the data points based on distance relationships among examples, and then to use the known labels to perform a graph partitioning using the minimum cut that agrees with the labeled data. (Zhu et al., 2003) extended this approach by proposing a cut based on the assumption that labels are generated according to a Markov Random Field on the graph , (Joachims, 2003) presented an algorithm based on spectral graph partitioning. (Blum et al., 2004) extended the min-cut approach by adding randomness to the graph structure, their algorithm addresses several shortcomings of the basic mincut approach, yet it may not help in cases where the graph does not have small cuts for a given classification problem. 3 Background In graph theory, a graph is a set of objects called vertices joined by links called edges. A bipartite graph, also called a bigraph, is a special graph where the set of vertices can be divided into two disjoint sets with no two vertices of the same set sharing an edge. The Hypertext Induced Topic Selection (HITS) algorithm is </context>
</contexts>
<marker>Blum, Lafferty, Rwebangira, Reddy, 2004</marker>
<rawString>Avrim Blum, John Lafferty, Mugizi Rwebangira, and Rajashekar Reddy. 2004. Semi-supervised Learning Using Randomized Mincuts. Proceedings of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stijn van Dongen</author>
</authors>
<title>A Cluster Algorithm for Graphs.</title>
<date>2000</date>
<tech>Technical Report INS-R0010,</tech>
<institution>National Research Institute for Mathematics and Computer Science</institution>
<note>in the Netherlands.</note>
<marker>van Dongen, 2000</marker>
<rawString>Stijn van Dongen. 2000. A Cluster Algorithm for Graphs. Technical Report INS-R0010, National Research Institute for Mathematics and Computer Science in the Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stijn van Dongen</author>
</authors>
<title>Graph Clustering by Flow Simulation.</title>
<date>2000</date>
<tech>PhD thesis,</tech>
<institution>University of Utrecht</institution>
<marker>van Dongen, 2000</marker>
<rawString>Stijn van Dongen. 2000. Graph Clustering by Flow Simulation. PhD thesis, University of Utrecht</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Hany Hassan</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Xiaqiang Luo</author>
<author>Nicolas Nicolov</author>
<author>Salim Roukos</author>
</authors>
<title>A Statistical Model for multilingual entity detection and tracking.</title>
<date>2004</date>
<booktitle>Proceedings of the Human Language Technologies Conference (HLT-NAACL’04).</booktitle>
<marker>Florian, Hassan, Jing, Kambhatla, Luo, Nicolov, Roukos, 2004</marker>
<rawString>Radu Florian, Hany Hassan, Hongyan Jing, Nanda Kambhatla, Xiaqiang Luo, Nicolas Nicolov, and Salim Roukos. 2004. A Statistical Model for multilingual entity detection and tracking. Proceedings of the Human Language Technologies Conference (HLT-NAACL’04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
<author>Nicholas Kushmerick</author>
</authors>
<title>Boosted wrapper induction.</title>
<date>2000</date>
<booktitle>The 14th European Conference on Artificial Intelligence Workshop on Machine Learning for Information Extraction</booktitle>
<marker>Freitag, Kushmerick, 2000</marker>
<rawString>Dayne Freitag, and Nicholas Kushmerick. 2000. Boosted wrapper induction. The 14th European Conference on Artificial Intelligence Workshop on Machine Learning for Information Extraction</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher Haveliwala</author>
</authors>
<title>Topic-sensitive PageRank.</title>
<date>2002</date>
<booktitle>Proceedings of the 11th International World Wide Web Conference</booktitle>
<marker>Haveliwala, 2002</marker>
<rawString>Taher Haveliwala. 2002. Topic-sensitive PageRank. Proceedings of the 11th International World Wide Web Conference</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive Learning via Spectral Graph Partitioning.</title>
<date>2003</date>
<booktitle>Proceedings of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4621" citStr="Joachims, 2003" startWordPosition="697" endWordPosition="698">be described by multiple representations. They develop a boosting scheme which exploits conditional independence between these representations. (Blum and Chawla, 2001) proposed a general approach utilizing unlabeled data by constructing a graph on all the data points based on distance relationships among examples, and then to use the known labels to perform a graph partitioning using the minimum cut that agrees with the labeled data. (Zhu et al., 2003) extended this approach by proposing a cut based on the assumption that labels are generated according to a Markov Random Field on the graph , (Joachims, 2003) presented an algorithm based on spectral graph partitioning. (Blum et al., 2004) extended the min-cut approach by adding randomness to the graph structure, their algorithm addresses several shortcomings of the basic mincut approach, yet it may not help in cases where the graph does not have small cuts for a given classification problem. 3 Background In graph theory, a graph is a set of objects called vertices joined by links called edges. A bipartite graph, also called a bigraph, is a special graph where the set of vertices can be divided into two disjoint sets with no two vertices of the sam</context>
</contexts>
<marker>Joachims, 2003</marker>
<rawString>Thorsten Joachims. 2003. Transductive Learning via Spectral Graph Partitioning. Proceedings of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kleinberg</author>
</authors>
<title>Authoritative Sources in a Hyperlinked Environment.</title>
<date>1998</date>
<booktitle>Proceedings of the. 9th ACM-SIAM Symposium on Discrete Algorithms.</booktitle>
<contexts>
<context position="2567" citStr="Kleinberg, 1998" startWordPosition="368" endWordPosition="369"> match many instances, and deploying graph based mutual reinforcement to weight the importance of these patterns. The mutual reinforcement is used to automatically identify the most informative patterns; where patterns that match many instances tend to be correct. Similarly, instances matched by many patterns also tend to be correct. The labeled instances should have more effect in the mutual reinforcement weighting process. The problem can therefore be seen as hubs (instances) and authorities (patterns) problem which can be solved using the Hypertext Induced Topic Selection (HITS) algorithm (Kleinberg, 1998 ). HITS is an algorithmic formulation of the notion of authority in web pages link analysis, based on a relationship between a set of relevant “authoritative pages” and a set of “hub pages”. The HITS algorithm benefits from the following observation: when a page (hub) links to another page (authority), the former confers authority over the latter. By analogy to the authoritative web pages problem, we could represent the patterns as authorities and instances as hubs, and use mutual reinforcement between patterns and instances to weight the most authoritative patterns. Instances from unsuWorksh</context>
</contexts>
<marker>Kleinberg, 1998</marker>
<rawString>John Kleinberg. 1998. Authoritative Sources in a Hyperlinked Environment. Proceedings of the. 9th ACM-SIAM Symposium on Discrete Algorithms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanda Kambhatla</author>
</authors>
<title>Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Information Extraction.</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics</booktitle>
<marker>Kambhatla, 2004</marker>
<rawString>Nanda Kambhatla. 2004. Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Information Extraction. Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity - Measuring the Relatedness of Concepts.</title>
<date>2004</date>
<booktitle>Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL2004)</booktitle>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi, 2004, WordNet::Similarity - Measuring the Relatedness of Concepts. Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL2004)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott White</author>
<author>Padhraic Smyth</author>
</authors>
<title>Algorithms for Discoveing Relative Importance in Graphs.</title>
<date>2003</date>
<booktitle>Proceedings of Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="12489" citStr="White and Smyth, 2003" startWordPosition="2067" endWordPosition="2070"> A i ( ) ( ) = || � = � = a i u v 1 u 1 T P t ( ) ( ) (4) Patterns with weights lower than a predefined threshold are rejected, and examples associated with highly ranked patterns are then used in unsupervised training. It is worth mentioning that both T and P contain supervised and unsupervised examples, however the proposed method could assign weights to the correct examples (tuples and patterns) in a completely unsupervised setup. For semi-supervised data some supervised examples are provided, which are associated in turn with tuples and patterns. We adopt the HITS extension introduced in (White and Smyth, 2003) to extend HITS with Priors. By analogy, we handle the supervised examples as priors to the HITS induction algorithm. A prior probabilities vector pr ={pr1, . . . , prn} is defined such that the probabilities sum to 1, where prv denotes the relative importance (or “prior bias”) we attach to node v. A pattern Pi is assigned a prior pri=1/n if pattern Pi matches a supervised tuple, otherwise pri is set to zero, n is the total number of patterns that have a supervised match. We also define a “back probability” �, 0 1 which determines how often we bias the supervised nodes: ( ) ( ) ( ) ( ) ( ) i �</context>
</contexts>
<marker>White, Smyth, 2003</marker>
<rawString>Scott White, and Padhraic Smyth. 2003. Algorithms for Discoveing Relative Importance in Graphs. Proceedings of Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18107" citStr="Wu and Palmer, 1994" startWordPosition="3064" endWordPosition="3067">ng a tuple similarity measure, and constructing a weighted undirected graph of tuples. Two tuples are linked with an edge if their similarity measure exceeds a certain threshold. Graph clustering algorithms could be deployed to partition the graph into a set of homogeneous communities or clusters. To reduce the space of tuples, we seek a matching criterion that group similar tuples together. Using WordNet, we can measure the semantic similarity or relatedness between a pair of concepts (or word senses), and by extension, between a pair of sentences. We use the similarity measure described in (Wu and Palmer, 1994) which finds the path length to the root node from the least common subsumer (LCS) of the two word senses which is the most specific word sense they share as an ancestor. The similarity score of two tuples, ST, is calculated as follows:. ST = SE1 + SE (9) 2 2 2 where SE1, and SE2 are the similarity scores of the first entities in the two tuples, and their second entitles respectively. The tuple matching procedure assigns a similarity measure to each pair of tuples in the dataset. Using this measure we can construct an undirected graph G. The vertices of G are the tuples. Two vertices are conne</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu, and Martha Palmer. 1994. Verb semantics and lexical selection. Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
<author>John Lafferty</author>
</authors>
<title>Semi-supervised Learning using Gaussian Fields and Harmonic Functions.</title>
<date>2003</date>
<booktitle>Proceedings of the 20th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="4462" citStr="Zhu et al., 2003" startWordPosition="667" endWordPosition="670">998) proposed an approach based on co-training that uses unlabeled data in a particular setting. They exploit the fact that, for some problems, each example can be described by multiple representations. They develop a boosting scheme which exploits conditional independence between these representations. (Blum and Chawla, 2001) proposed a general approach utilizing unlabeled data by constructing a graph on all the data points based on distance relationships among examples, and then to use the known labels to perform a graph partitioning using the minimum cut that agrees with the labeled data. (Zhu et al., 2003) extended this approach by proposing a cut based on the assumption that labels are generated according to a Markov Random Field on the graph , (Joachims, 2003) presented an algorithm based on spectral graph partitioning. (Blum et al., 2004) extended the min-cut approach by adding randomness to the graph structure, their algorithm addresses several shortcomings of the basic mincut approach, yet it may not help in cases where the graph does not have small cuts for a given classification problem. 3 Background In graph theory, a graph is a set of objects called vertices joined by links called edge</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. 2003. Semi-supervised Learning using Gaussian Fields and Harmonic Functions. Proceedings of the 20th International Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>