<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000484">
<title confidence="0.996454">
Natural Logic for Textual Inference
</title>
<author confidence="0.998999">
Bill MacCartney Christopher D. Manning
</author>
<affiliation confidence="0.999472">
Stanford University Stanford University
</affiliation>
<email confidence="0.996936">
wcmac@cs.stanford.edu manning@cs.stanford.edu
</email>
<sectionHeader confidence="0.993849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999876043478261">
This paper presents the first use of a com-
putational model of natural logic—a sys-
tem of logical inference which operates
over natural language—for textual infer-
ence. Most current approaches to the PAS-
CAL RTE textual inference task achieve ro-
bustness by sacrificing semantic precision;
while broadly effective, they are easily con-
founded by ubiquitous inferences involving
monotonicity. At the other extreme, systems
which rely on first-order logic and theorem
proving are precise, but excessively brittle.
This work aims at a middle way. Our system
finds a low-cost edit sequence which trans-
forms the premise into the hypothesis; learns
to classify entailment relations across atomic
edits; and composes atomic entailments into
a top-level entailment judgment. We pro-
vide the first reported results for any system
on the FraCaS test suite. We also evaluate
on RTE3 data, and show that hybridizing an
existing RTE system with our natural logic
system yields significant performance gains.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.97765296">
The last five years have seen a surge of interest in
the problem of textual inference, that is, automat-
ically determining whether a natural-language hy-
pothesis can be inferred from a given premise. A
broad spectrum of approaches have been explored,
ranging from shallow-but-robust to deep-but-brittle.
Up to now, the most successful approaches have
used fairly impoverished semantic representations,
relying on measures of lexical or semantic overlap
(Jijkoun and de Rijke, 2005), pattern-based relation
extraction (Romano et al., 2006), or approximate
matching of predicate-argument structure (Hickl et
al., 2006). Such methods, while robust and broadly
effective, are imprecise, and are easily confounded
by ubiquituous inferences involving monotonicity,
particularly in negative polarity contexts, as in:
P: No case of indigenously acquired rabies
infection has been confirmed in the past 2 years.
H: No rabies cases have been confirmed.
Because it drops important qualifiers in a negative
context, the hypothesis does not follow; yet both the
lexical content and the predicate-argument structure
of the hypothesis closely match the premise.
At the other extreme, textual inference can be ap-
proached as deduction, building on work in formal
computational semantics to translate sentences into
first-order logic (FOL), and then applying a theo-
rem prover or a model builder (Akhmatova, 2005;
Fowler et al., 2005). However, such approaches
tend to founder on the difficulty of accurately trans-
lating natural language in FOL—tricky issues in-
clude idioms, intensionality and propositional at-
titudes, modalities, temporal and causal relations,
certain quantifiers, and so on. FOL-based systems
that have attained high precision (Bos and Markert,
2006) have done so at the cost of very poor recall.
In this work, we explore a different point on the
spectrum, by developing a computational model of
natural logic, that is, a logic whose vehicle of in-
ference is natural language.&apos; Natural logic eschews
logical notation and model theory. Its proofs pro-
ceed by incremental edits to expressions of natural
language, and its inference rules specify conditions
under which semantic expansions or contractions
preserve truth. It thus permits us to do precise rea-
soning about monotonicity, while sidestepping the
difficulties of translating sentences into FOL.
It should be emphasized that there are many
&apos;Natural logic should not be confused with natural deduc-
tion, a proof system for first-order logic.
</bodyText>
<page confidence="0.980207">
193
</page>
<note confidence="0.78632">
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 193–200,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999779428571429">
important kinds of inference which are not ad-
dressed by a natural logic system, including tem-
poral reasoning, causal reasoning (Khan sold nu-
clear plans ==&gt;. Khan possessed nuclear plans), para-
phrase (McEwan flew to Rome ==&gt;. McEwan took a
flight to Rome), relation extraction (Bill Gates and
his wife, Melinda... ==&gt;. Melinda Gates is married
to Bill Gates), etc. Moreover, a natural logic sys-
tem will struggle with inferences requiring model-
building or deep proof search, which are more suit-
able for formal deduction systems. However, the ap-
plicability of natural logic is broader than it might at
first appear, and a natural logic system can be de-
signed to integrate with other kinds of reasoners.
</bodyText>
<sectionHeader confidence="0.879904" genericHeader="method">
2 Foundations of natural logic
</sectionHeader>
<bodyText confidence="0.999950980769231">
Natural logic aims to explain inferences involving
monotonicity, in which the concepts or constraints
expressed are expanded or contracted. Consider, for
example, the sentence Every meal without wine is a
terrible crime. Some semantic elements can be ex-
panded (but not contracted) salva veritate, and are
therefore said to have positive polarity: wine may be
broadened to drink, terrible crime may be relaxed to
crime, or every may be weakened to some. Other el-
ements can only be contracted (not expanded) salva
veritate, and thus have negative polarity: meal can
be narrowed to dinner. The monotonicity calcu-
lus developed in (S´anchez Valencia, 1991) explains
these polarity effects by (1) defining an entailment
relation over multifarious expressions of natural lan-
guage, (2) defining monotonicity properties of se-
mantic functions, and finally (3) specifying how
monotonicities combine during Fregean composi-
tion of semantic functions.
The entailment relation. Most work in textual
inference reflects a simple concept of entailment:
one sentence entails another, or does not. In nat-
ural logic, however, entailment is a semantic con-
tainment relation (analogous to the set containment
relation C_) over expressions of all types, including
words and phrases as well as sentences. We define
the entailment relation C recursively over the se-
mantic types familiar from Montague semantics. If
c and d are of type t (truth values), then c C d iff
c —* d. If c and d are of type a (entities), then c C d
iff c = d. Finally, if c and d are of functional type
(a,0), then c C d iff for all a E a, c(a) C d(a).
Otherwise, if c C= d and d C= c, we write c # d.
Using these formal definitions, we can establish
entailment relations between common nouns (pen-
guin C bird), common and proper adjectives (tiny C
small, French C European), transitive and intransi-
tive verbs (kick C strike, hover C fly), temporal and
locative modifiers (this morning C today, in Beijing
C in China), connectives (and C or), and quanti-
fiers (everyone C someone, all C most C some).2
Among noun phrases, we have everyone C Einstein
C some physicist. Finally, observe that dropping a
modifier generally yields entailment (eat quickly C
eat) though this heuristic can be violated, e.g., by
operator adjectives (fake vaccine C= vaccine).
Monotonicity. Under the Fregean hypothesis, the
meaning of a compound expression is the result of
function application. In semantics as in mathemat-
ics, we can describe a function as upward mono-
tone if “larger” inputs yield larger outputs. Formally,
given a function f of functional type (a, 0):
</bodyText>
<listItem confidence="0.998470666666667">
• f is upward-monotone (T) iff for all x, y E a,
x C y entails f(x) C f(y).
• f is downward-monotone (1) iff for all x, y E
a, x C y entails f(y) C f(x).
• f is non-monotone (=T1) iff it is neither upward-
nor downward-monotone.
</listItem>
<bodyText confidence="0.831324952380952">
Most linguistic expressions may be regarded as
upward-monotone semantic functions. Thus tango
in Paris C dance in France, since tango C
dance and in Paris C in France. However, a
number of important linguistic constructions are
downward-monotone, including negation (not), re-
strictive quantifiers (no, few, at most n), restrictive
verbs (lack, fail, prohibit), certain adverbs (without,
except), the antecedent of a conditional, and so on.
We thus have didn’t dance C didn’t tango, few ath-
letes C few sprinters, lack weapons C lack guns,
2The entailment relations among quantifiers may be coun-
terintuitive to those prone to what Peter Geach called “quantifi-
catious thinking”, who might consider someone “smaller” than
everyone. But in the theory of generalized quantifiers, the deno-
tation of a quantified noun phrase is the set of predicates which
it satisfies, and the predicates satisfied by everyone are a subset
of those satisfied by someone. Note also that logicians will deny
that the universal entails the existential: `dx P(x) 74 3x P(x).
However, most people are happy to infer someone is hungry
from everyone is hungry.
</bodyText>
<page confidence="0.997912">
194
</page>
<bodyText confidence="0.9971014">
without clothes C without pants, and If stocks rise,
we win C If stocks soar, we win. Finally, a few
expressions must be considered non-monotone, in-
cluding superlative adjectives and quantifiers such
as most. Thus prettiest butterfly # prettiest insect
and most boats # most vehicles. Note that certain
generalized quantifiers must be treated as binary
functions having different monotonicities in differ-
ent arguments. Thus every is downward-monotone
in its first argument (every fish swims C every shark
swims) but upward-monotone in its second argument
(every shark swims C every shark moves).
Composition of monotonicity. Finally, we must
specify how monotonicities combine during Fregean
composition of semantic functions. In S´anchez Va-
lencia’s marking algorithm, we represent each input
expression as a parse in the Lambek categorial gram-
mar. We then (1) mark leaf nodes with appropriate
lexical monotonicity values, (2) project monotonic-
ities to internal nodes representing function applica-
tions, and finally (3) compose monotonicities along
the path from the root to each leaf in order to deter-
mine effective polarities. The composition of mono-
tonicities is straightforward. Suppose h = f o g. If
either f or g is non-monotone, then so is h. Other-
wise, if the monotonicities of f and g are the same,
then h is upward-monotone; if they are different,
then h is downward-monotone. (Thus, wine has pos-
itive polarity in no meal without wine because it falls
under two downward-monotone operators.)
</bodyText>
<sectionHeader confidence="0.959975" genericHeader="method">
3 The NatLog System
</sectionHeader>
<bodyText confidence="0.9990376">
Our natural logic system, dubbed the NatLog sys-
tem, has a three-stage architecture similar to those
in (Marsi and Krahmer, 2005; MacCartney et al.,
2006), comprising (1) linguistic pre-preprocessing,
(2) alignment, and (3) entailment classification.
</bodyText>
<subsectionHeader confidence="0.998332">
3.1 Linguistic pre-processing
</subsectionHeader>
<bodyText confidence="0.999881">
Relative to other textual inference systems, the Nat-
Log system does comparatively little linguistic pre-
processing. We rely on the Stanford parser (Klein
and Manning, 2003), a Treebank-trained statistical
parser, for tokenization, part-of-speech tagging, and
phrase-structure parsing. By far the most impor-
tant analysis performed at this stage is monotonicity
marking, in which we compute the effective mono-
</bodyText>
<construct confidence="0.9105573">
unary operator: without
pattern: IN &lt; /-[Ww]ithout\$/
argument 1: monotonicity 1 on dominating PP
pattern: __ &gt; PP=proj
binary operator: most
pattern: JJS &lt; /-[Mm]ost\$/ !&gt; QP
argument 1: monotonicity X on dominating NP
pattern: __ &gt;+(NP) (NP=proj !&gt; NP)
argument 2: monotonicity I on dominating S
pattern: __ &gt;+(/.*/) (S=proj !&gt; S)
</construct>
<figureCaption confidence="0.9696265">
Figure 1: Two examples of monotonicity operator
definitions. The patterns employ Tregex syntax.
</figureCaption>
<bodyText confidence="0.999978954545455">
tonicity for each token span in each input sentence.
For this, we use an adaptation of the marking algo-
rithm of S´anchez Valencia (section 2); however, our
choice of a Treebank-trained parser (driven by the
goal of broad coverage) requires us to modify the
algorithm substantially. Unlike the categorial gram-
mar parses assumed by S´anchez Valencia, the nest-
ing of constituents in phrase-structure parses does
not always correspond to the composition of seman-
tic functions, which introduces a number of com-
plications. We define a list of downward-monotone
and non-monotone expressions, and for each item
we specify its arity and a Tregex pattern (Levy and
Andrew, 2006) which permits us to identify its oc-
currences. We also specify, for each argument, both
the monotonicity and another Tregex pattern which
helps us to determine the sentence span over which
the monotonicity is projected. (Figure 1 shows
some example definitions.) The marking process
computes these projections, performs monotonicity
composition where needed, and marks each token
span with its final effective monotonicity.
</bodyText>
<subsectionHeader confidence="0.999279">
3.2 Alignment
</subsectionHeader>
<bodyText confidence="0.999769636363636">
The second stage of processing establishes an align-
ment between the premise and the hypothesis. While
there are many notions of alignment, in this work we
have chosen to represent alignments as sequences of
atomic edits over spans of word tokens. We define
four types of atomic edits: deletion of a span from
the premise, insertion of a span into the hypothesis,
substitution of a hypothesis span for a premise span,
and advance over a span without modification. Each
atomic edit is parameterized by the token indices at
which it operates. As an example, the first problem
</bodyText>
<page confidence="0.994904">
195
</page>
<bodyText confidence="0.999901825">
in table 3 may be aligned using following edits:
An Irishman =#. An Irishman ADV
won =#. won ADV
a =#. the SUB
Nobel prize =#. Nobel prize ADV
=#. for literature INS
. =#. . ADV
Clearly, this representation imposes certain lim-
itations: there is no atomic edit type representing
the movement of a token span from one sentence
location to another (instead a combination of dele-
tion and insertion must be used), and there can be no
alignments to non-contiguous sets of tokens. How-
ever, the span edit representation also offers impor-
tant benefits. First, there is always a well-defined
sequence of intermediate forms through which the
sentence progresses during editing, which is impor-
tant for the computation of monotonicity features.
Second, given a cost function over edits, it is possi-
ble to construct an efficient dynamic program to find
the lowest-cost edit sequence between any pair of
sentences, using a straightforward extension of the
Levenshtein string-edit algorithm.
For this purpose, we have designed a cost function
which prefers edits which operate on longer spans;
penalizes edits operating on spans which are not
parse-tree constituents; imposes nomimal cost on
substitutions of words having the same lemma; and
imposes little cost on certain “light” edits, involving
prepositions, articles, auxiliaries, etc. When applied
to problems like those in the FraCaS test suite (sec-
tion 4), this cost model gives intuitively pleasing re-
sults. However, because our focus in this work is on
entailment, we have not devoted much energy to op-
timizing our alignment model, and will not discuss it
further. (For the RTE experiments described in sec-
tion 5, we use alignments derived from an indepen-
dent RTE system. Translating those alignments into
the span edit representation requires relaxing some
of its constraints, as we’ll explain.)
</bodyText>
<subsectionHeader confidence="0.99326">
3.3 Entailment classification
</subsectionHeader>
<bodyText confidence="0.999837166666667">
The edit sequence obtained during the alignment
stage effectively decomposes the global entailment
problem into a sequence of atomic entailment prob-
lems, one for each atomic edit. In the final stage, we
train a model for atomic entailment classification,
and predict an entailment relation for each atomic
</bodyText>
<table confidence="0.743485666666667">
relation symbol in terms of C FraCaS RTE
equivalent p = h p C h, h C p yes yes
forward p E h p C h, h C= p yes yes
reverse p �] h h C p, p C= h unk no
independent p # h p C= h, h C= p unk no
exclusive p  |h p C -h no no
</table>
<tableCaption confidence="0.687299333333333">
Table 1: The five elementary entailment relations.
The last two columns indicate correspondences to
FraCaS and RTE answers; see sections 4 and 5.
</tableCaption>
<bodyText confidence="0.994419435897436">
edit. We then compose our atomic entailment pre-
dictions to produce a global entailment prediction.
The atomic entailment model uses a classifier to
predict one of five elementary entailment relations
(table 1) for each atomic edit. This model uses a
feature representation designed to capture character-
istics of the edit pertinent to a natural logic analysis:
the type of the edit (DEL, INS, or SUB), the effec-
tive monotonicity at the affected token span (T, 1, or
X), and various lexical features of the affected to-
kens. In the case of a SUB edit, the lexical features
help to indicate whether the substitution constitutes
a semantic expansion, contraction, equivalence, or
exclusion, using WordNet-derived measures of syn-
onymy, hyponymy, and antonymy, and a measure
of lemma similarity based on Levenshtein string-
edit distance. In addition, for edits of all types, we
have found it useful to generate a “light edit” fea-
ture indicating whether the affected tokens belong to
categories which are usually negligible for inferen-
tial purposes, including prepositions, articles, auxil-
iaries, and punctuation.
The entailment model uses a decision tree clas-
sifier, trained on a small data set of 69 problems
custom-designed to exercise diverse regions of the
feature space.3 From these examples, the decision
tree effectively learns such heuristics as deletion in
an upward-monotone context yields C, substitution
of a hypernym in a downward-monotone context
yields ::1, and substitution of an antonym yields 1.
To produce a top-level entailment judgment, the
atomic entailment predictions associated with each
3Thus, in using learning, we are not trying to estimate statis-
tical properties of some natural distribution of data. Rather, the
learning framework provides (1) a modular way to add features
which may impact the entailment decision, (2) a principled way
to combine evidence from diverse features, such as real-valued
lexical features, and (3) a convenient way to verify the proper
functioning of the system.
</bodyText>
<page confidence="0.990269">
196
</page>
<table confidence="0.778197166666667">
atomic edit: SUB(a, the)
features:
type: SUB, monotonicity: ↑, isLightEdit: true,
wnSyno: 0.0, wnHypo: 0.0, wnAnto: 0.0, lemmaSim: 0.0
predicted entailment relation: =
atomic edit: INS(for literature)
features:
type: INS, monotonicity: ↑, isLightEdit: false
predicted entailment relation: —1
top-level inference:
composition of entailment relations: = ◦ ⇒
mapping to FraCaS answer: �] ⇒ unk
</table>
<figureCaption confidence="0.8700265">
Figure 2: The operation of the entailment model on
FraCaS problem 33 (see table 3).
</figureCaption>
<table confidence="0.997343833333333">
§ Category Count % Acc.
1 Quantifiers 44 84.09
2 Plurals 24 41.67
3 Anaphora 6 50.00
4 Ellipsis 25 28.00
5 Adjectives 15 60.00
6 Comparatives 16 68.75
7 Temporal 36 61.11
8 Verbs 8 62.50
9 Attitudes 9 55.56
Applicable sections: 1, 5, 6 75 76.00
All sections 183 59.56
</table>
<tableCaption confidence="0.890419666666667">
Table 2: NatLog’s accuracy on the FraCaS test suite,
by section. We exclude degenerate problems and
multiple-premise problems; see text.
</tableCaption>
<bodyText confidence="0.618917166666667">
edit are composed in a fairly obvious way. If r is any
entailment relation, then = ◦ r ≡ r, but # ◦ r ≡ #.
C and � are transitive, but C ◦ � ≡ #, and so on.
Compositions are commutative and associative.
Figure 2 shows an example of the operation of the
entailment model.
</bodyText>
<sectionHeader confidence="0.890681" genericHeader="method">
4 Experiments with the FraCaS test suite
</sectionHeader>
<bodyText confidence="0.970861555555556">
The FraCaS test suite (Cooper et al., 1996) was de-
veloped as part of a collaborative research effort in
computational semantics. It contains 346 inference
problems reminiscent of a textbook on formal se-
mantics. In the authors’ view, “inferencing tasks
[are] the best way of testing an NLP system’s se-
mantic capacity.” Yet, to our knowledge, this work
is the first to present a quantitative system evaluation
using FraCaS.4
The problems are divided into nine sections, each
focused on a category of semantic phenomena, such
as quantifiers or anaphora (see table 2). Each prob-
lem consists of one or more premise sentences, fol-
lowed by a one-sentence question. For this project,
the questions were converted into declarative hy-
potheses. Each problem also has an answer, which
(usually) takes one of three values: yes (the hypoth-
esis can be inferred from the premise(s)), no (the
negation of the hypothesis can be inferred), or unk
(neither the hypothesis nor its negation can be in-
ferred). Some examples are shown in table 3.
4Indeed, our first step was to put the FraCaS data into
machine-readable form, which we make publicly available at
http://nlp.stanford.edu/∼wcmac/downloads/fracas.xml.
Not all of the 346 problems were used in this
work. First, 12 of the problems were excluded
because they are degenerate, lacking either a hy-
pothesis or a well-defined answer. Second, an
additional 151 problems (about 45% of the to-
tal) were excluded because they involve multiple
premises. While many of the multiple-premise prob-
lems should be feasible for NatLog in the future,
such inferences require search, and for now we have
chosen to sidestep this complexity.
Finally, it should be noted that several sections of
the test suite involve semantic phenomena, such as
ellipsis, which the NatLog system makes no attempt
to model. While we report results for these sections,
we do not expect performance to be good, and in
development we have concentrated on the sections
where we expect NatLog to have relevant expertise.
In table 2, results for these sections are aggregated
under the label “applicable sections”.
Results are shown in table 2. On the “applica-
ble” sections, performance is good. (Not supris-
ingly, we make little headway with, e.g., ellipsis.)
Of course, this does not constitute a proper evalua-
tion on unseen test data—but on the other hand, the
system was never trained on the FraCaS problems,
and has had no opportunity to learn biases implicit
in the data.5 Our main goal in testing on FraCaS is
to evaluate the representational and inferential ade-
quacy of our model of natural logic, and from that
perspective, the strong performance in quantifiers,
</bodyText>
<footnote confidence="0.996522">
5This also explains why NatLog’s performance on some
FraCaS sections falls below that of a baseline most-common-
label classifier.
</footnote>
<page confidence="0.98994">
197
</page>
<table confidence="0.960283166666667">
§ ID Premise(s) Hypothesis Ans
1 33 An Irishman won a Nobel prize. An Irishman won the Nobel prize for literature. unk
1 38 No delegate finished the report. Some delegate finished the report on time. no
2 99 Clients at the demonstration were all impressed by the sys- Smith was impressed by the system’s perfor- yes
tem’s performance. Smith was a client at the demonstration. mance.
9 335 Smith believed that ITEL had won the contract in 1992. ITEL won the contract in 1992. unk
</table>
<tableCaption confidence="0.986137">
Table 3: Illustrative examples from the FraCaS test suite
</tableCaption>
<table confidence="0.974498166666667">
guess
answer yes unk no total
yes 62 40 – 102
unk 15 45 – 60
no 6 13 2 21
total 90 91 2 183
</table>
<tableCaption confidence="0.9999">
Table 4: Confusions on FraCaS data (all sections)
</tableCaption>
<bodyText confidence="0.999406130434783">
adjectives, and comparatives is satisfying.
The confusion matrix shown in table 4 is instruc-
tive. By far the largest category of confusions com-
prise problems where we guess unk when the cor-
rect answer is yes. This reflects both the bias to-
ward yes in the FraCaS data, and the system’s ten-
dency to predict unk (entailment relation #) when
confused: given the composition rules for entail-
ment relations, the system can predict yes only if all
atomic-level predictions are either C or =. On the
other hand, there are a number of problems where
we predict yes mistakenly. Several of these errors
arise in a series of problems in §5 which concern
operator adjectives such as former. The entailment
model wrongly assumes that such modifiers, like any
others, can safely be deleted in upward-monotone
contexts, but in fact former student V� student. If
the feature set used by the entailment model were
extended to represent occurrences of operator adjec-
tives, and if appropriate examples were included in
the training data, our accuracy in §5—and the av-
erage accuracy for the “applicable” sections—could
easily be boosted over 80%.
</bodyText>
<sectionHeader confidence="0.973076" genericHeader="method">
5 Experiments with RTE data
</sectionHeader>
<bodyText confidence="0.9998926">
Textual inference problems from the PASCAL RTE
Challenge (Dagan et al., 2005) differ from FraCaS
problems in several important ways. (See table 5
for examples.) Instead of textbook examples of se-
mantic phenomena, RTE problems are more natural-
seeming, with premises collected “in the wild” from
newswire text. The premises are much longer, aver-
aging 35 words (vs. 11 words for FraCaS). Also, the
RTE task aims at a binary classification: the RTE no
answer combines the no and unk answers in FraCaS.
Due to the character of RTE problems, we do not
expect NatLog to be a good general-purpose solu-
tion to solving RTE problems. First, most RTE prob-
lems depend on forms of inference, such as para-
phrase, temporal reasoning, or relation extraction,
which NatLog is not designed to address. Second,
in most RTE problems, the edit distance between
premise and hypothesis is relatively large. More
atomic edits means a greater chance that prediction
errors made by the atomic entailment model will
propagate, via entailment composition, to the sys-
tem’s final output. Rather, in applying NatLog to
RTE, we hope to make reliable predictions on a sub-
set of RTE problems, trading recall for precision. If
we succeed, then we may be able to hybridize with a
broad-coverage RTE system to obtain better results
than either system individually—the same strategy
that was adopted by (Bos and Markert, 2006) for
their FOL-based system.
For this purpose, we have chosen to use the Stan-
ford RTE system described in (de Marneffe et al.,
2006). In applying NatLog to RTE problems, we use
alignments from the Stanford system as input to our
entailment model. A Stanford alignment is a map
from hypothesis words to premise words. When we
translate such alignments into the NatLog represen-
tation described in section 3, each pair of aligned
words generates a substitution edit (or, if the words
are identical, an advance edit). Unaligned premise
words yield deletion edits, while unaligned hypothe-
sis words yield insertion edits. Where possible, con-
tiguous sequences of word-level edits are then col-
lected into equivalent span edits. While the result
of this translation method cannot be interpreted as a
conventional edit script (there is no well-defined or-
</bodyText>
<page confidence="0.993844">
198
</page>
<table confidence="0.9985116">
ID Premise(s) Hypothesis Answer
518 The French railway company SNCF is cooperating in The French railway company is called SNCF. yes
the project.
601 NUCOR has pioneered a giant mini-mill in which steel Nucor has pioneered the first mini-mill. no
is poured into continuous casting machines.
</table>
<tableCaption confidence="0.968766">
Table 5: Illustrative examples from the RTE3 test suite
</tableCaption>
<table confidence="0.995022666666666">
RTE3 Development Set (800 problems)
System % yes precision recall accuracy
Stanford 50.25 68.66 66.99 67.25
NatLog 18.00 76.39 26.70 58.00
Hybrid, bal. 50.00 69.75 67.72 68.25
Hybrid, opt. 55.13 69.16 74.03 69.63
RTE3 Test Set (800 problems)
System % yes precision recall accuracy
Stanford 50.00 61.75 60.24 60.50
NatLog 23.88 68.06 31.71 57.38
Hybrid, bal. 50.00 64.50 62.93 63.25
Hybrid, opt. 54.13 63.74 67.32 63.62
</table>
<tableCaption confidence="0.981918">
Table 6: Performance on the RTE3 development and
</tableCaption>
<bodyText confidence="0.997391660377358">
test sets. % yes indicates the proportion of yes pre-
dictions made by the system. Precision and recall
are shown for the yes label.
dering of edits, and multiple edits can operate on the
same input spans), we find that this poses no great
impediment to subsequent processing by the entail-
ment model.
Table 6 shows the performance of the NatLog
system on RTE3 data. Relative to the Stanford
RTE system, NatLog achieves high precision on its
yes predictions—about 76% on the development set,
and 68% on the test set—suggesting that hybridizing
may be effective. For comparison, the FOL-based
system reported in (Bos and Markert, 2006) attained
a similarly high precision of 76% on RTE2 prob-
lems, but was able to make a positive prediction in
only about 4% of cases. NatLog makes positive pre-
dictions far more often—at a rate of 18% on the de-
velopment set, and 24% on the test set.
The Stanford RTE system makes yes/no predic-
tions by thresholding a real-valued inference score.
To construct a hybrid system, we adjust the Stan-
ford inference scores by +x or −x, depending on
whether NatLog predicts yes or no/unk. We choose
the value of x by optimizing development set accu-
racy, while adjusting the threshold to generate bal-
anced predictions (that is, equal numbers of yes and
no predictions). As an additional experiment, we
fix x at this value and then adjust the threshold to
optimize development set accuracy, resulting in an
excess of yes predictions. (Since this optimization
is based solely on development data, its use on test
data is fully legitimate.) Results for these two cases
are shown in table 6. The parameters tuned on devel-
opment data were found to yield good performance
on test data. The optimized hybrid system attained
an absolute accuracy gain of 3.12% over the Stan-
ford system, corresponding to an extra 25 problems
answered correctly. This result is statistically signif-
icant (p &lt; 0.01, McNemar’s test, 2-tailed).
However, the gain cannot be attributed to Nat-
Log’s success in handling the kind of inferences
about monotonicity which are the staple of natural
logic. Indeed, such inferences are quite rare in the
RTE data. Rather, NatLog seems to have gained
primarily by being more precise. In some cases,
this precision works against it: NatLog answers no
to problem 518 (table 5) because it cannot account
for the insertion of called in the hypothesis. On
the other hand, it correctly rejects the hypothesis in
problem 601 because it cannot account for the inser-
tion of first, whereas the less-precise Stanford sys-
tem was happy to allow it.
</bodyText>
<sectionHeader confidence="0.999979" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999977727272727">
While the roots of natural logic can be traced back
to Aristotle’s syllogisms, the modern conception of
natural logic began with George Lakoff, who pro-
posed “a logic for natural language” which could
“characterize all the valid inferences that can be
made in natural language” (Lakoff, 1970). The
study of natural logic was formalized by Johan van
Benthem, who crucially connected it with catego-
rial grammar (van Benthem, 1986), and later was
brought to fruition by Victor S´anchez Valencia, who
first gave a precise definition of a calculus of mono-
</bodyText>
<page confidence="0.996527">
199
</page>
<bodyText confidence="0.999848944444444">
tonicity (S´anchez Valencia, 1991). A small current
of theoretical work has continued up to the present,
for example (Zamansky et al., 2006).
There has been surprisingly little work on build-
ing computational models of natural logic. (Fyo-
dorov et al., 2003) describes a Prolog implementa-
tion for a small fragment of English, based on a cat-
egorial grammar parser.6 In an unpublished draft,
(van Eijck, 2005) describes a preliminary implemen-
tation in Haskell.
Doing inference with representations close to nat-
ural language has also been advocated by Jerry
Hobbs, as in (Hobbs, 1985).
To our knowledge, the FraCaS results reported
here represent the first such evaluation. (Sukkarieh,
2003) describes applying a deductive system to
some FraCaS inferences, but does not perform a
complete evaluation or report quantitative results.
</bodyText>
<sectionHeader confidence="0.999283" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999614666666667">
Our NatLog implementation of natural logic suc-
cessfully handles a broad range of inferences involv-
ing monotonicity, as demonstrated on the FraCaS
test suite. While a post-hoc analysis of performance
on the RTE3 Challenge suggests that monotonicity-
related inferences have limited applicability in RTE
data, the greater precision of the NatLog system nev-
ertheless significantly improved the performance of
a hybrid RTE system. An area for future work is
further consideration of what kinds of inference are
prevalent and important in prominent computational
linguistic applications.
Acknowledgements The authors wish to thank
Marie-Catherine de Marneffe and the anonymous
reviewers for their helpful comments on an earlier
draft of this paper. This work was supported in part
by ARDA’s Advanced Question Answering for In-
telligence (AQUAINT) Program.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992777558823529">
Elena Akhmatova. 2005. Textual entailment resolution via
atomic propositions. In Proc. of the PASCAL RTE Challenge
Workshop.
Johan Bos and Katja Markert. 2006. When logical inference
helps determining textual entailment (and when it doesn’t).
In Proc. of the 2nd PASCAL RTE Challenge Workshop.
6Available at http://yeda.cs.technion.ac.il/∼yaroslav/oc/
Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Jo-
han Van Genabith, Jan Jaspars, Hans Kamp, David Milward,
Manfred Pinkal, Massimo Poesio, and Steve Pulman. 1996.
Using the framework. Technical Report LRE 62-051 D-16,
The FraCaS Consortium.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The
PASCAL Recognising Textual Entailment Challenge. In
Proc. of the PASCAL RTE Challenge Workshop.
Marie-Catherine de Marneffe, Bill MacCartney, Trond
Grenager, Daniel Cer, Anna Rafferty, and Christopher D.
Manning. 2006. Learning to distinguish valid textual entail-
ments. In Proc. of the 2nd PASCAL RTE Challenge Work-
shop.
Abraham Fowler, Bob Hauser, Daniel Hodges, Ian Niles,
Adrian Novischi, and Jens Stephan. 2005. Applying CO-
GEX to recognize textual entailment. In Proc. of the PAS-
CAL RTE Challenge Workshop.
Yaroslav Fyodorov, Yoad Winter, and Nissim Francez. 2003.
Order-based inference in natural logic. Logic Journal of the
IGPL, 11(4):385–416.
Andrew Hickl, John Williams, Jeremy Bensley, Kirk Roberts,
Bryan Rink, and Ying Shi. 2006. Recognizing textual en-
tailment with LCC’s GROUNDHOG system. In Proc. of the
2nd PASCAL RTE Challenge Workshop.
Jerry R. Hobbs. 1985. Ontological promiscuity. In Proc. of
ACL-85, pages 61–69.
Valentin Jijkoun and Maarten de Rijke. 2005. Recognizing
textual entailment using lexical similarity. In Proc. of the
PASCAL RTE Challenge Workshop.
Dan Klein and Christopher D. Manning. 2003. Accurate unlex-
icalized parsing. In Proc. of ACL-03.
George Lakoff. 1970. Linguistics and natural logic. Synthese,
22:151–271.
Roger Levy and Galen Andrew. 2006. Tregex and Tsurgeon:
tools for querying and manipulating tree data structures. In
Proc. of LREC-06.
Bill MacCartney, Trond Grenager, Marie-Catherine de Marn-
effe, Daniel Cer, and Christopher D. Manning. 2006. Learn-
ing to recognize features of valid textual entailments. In
Proc. of HLT-NAACL-06.
Erwin Marsi and Emiel Krahmer. 2005. Classification of se-
mantic relations by humans and machines. In Proc. of the
ACL 2005 Workshop on Empirical Modeling of Semantic
Equivalence and Entailment.
Lorenza Romano, Milen Kouylekov, Idan Szpektor, Ido Da-
gan, and Alberto Lavelli. 2006. Investigating a generic
paraphrase-based approach for relation extraction. In Proc.
of EACL-06.
Victor S´anchez Valencia. 1991. Studies on Natural Logic and
Categorial Grammar. Ph.D. thesis, Univ. of Amsterdam.
Jana Z. Sukkarieh. 2003. An expressive efficient representation:
Bridging a gap between NLP and KR. In Proc. of the 7th
Int’l Conf. on Knowledge-Based Intelligent Information and
Engineering Systems.
Johan van Benthem. 1986. Essays in logical semantics. Reidel,
Dordrecht.
Jan van Eijck. 2005. Natural logic for natural language. http:
//homepages.cwi.nl/�jve/papers/05/nlnl/NLNL.pdf.
Anna Zamansky, Nissim Francez, and Yoad Winter. 2006. A
‘natural logic’ inference system using the Lambek calculus.
Journal of Logic, Language and Information, 15:273–295.
</reference>
<page confidence="0.996669">
200
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.986519">
<title confidence="0.994983">Natural Logic for Textual Inference</title>
<author confidence="0.999755">Bill MacCartney Christopher D Manning</author>
<affiliation confidence="0.999953">Stanford University Stanford University</affiliation>
<email confidence="0.999622">wcmac@cs.stanford.edumanning@cs.stanford.edu</email>
<abstract confidence="0.999658291666666">This paper presents the first use of a commodel of system of logical inference which operates over natural language—for textual inference. Most current approaches to the PAS- CAL RTE textual inference task achieve robustness by sacrificing semantic precision; while broadly effective, they are easily confounded by ubiquitous inferences involving monotonicity. At the other extreme, systems which rely on first-order logic and theorem proving are precise, but excessively brittle. This work aims at a middle way. Our system finds a low-cost edit sequence which transforms the premise into the hypothesis; learns to classify entailment relations across atomic edits; and composes atomic entailments into a top-level entailment judgment. We provide the first reported results for any system on the FraCaS test suite. We also evaluate on RTE3 data, and show that hybridizing an existing RTE system with our natural logic system yields significant performance gains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Elena Akhmatova</author>
</authors>
<title>Textual entailment resolution via atomic propositions.</title>
<date>2005</date>
<booktitle>In Proc. of the PASCAL RTE Challenge Workshop.</booktitle>
<contexts>
<context position="2564" citStr="Akhmatova, 2005" startWordPosition="376" endWordPosition="377">ative polarity contexts, as in: P: No case of indigenously acquired rabies infection has been confirmed in the past 2 years. H: No rabies cases have been confirmed. Because it drops important qualifiers in a negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the premise. At the other extreme, textual inference can be approached as deduction, building on work in formal computational semantics to translate sentences into first-order logic (FOL), and then applying a theorem prover or a model builder (Akhmatova, 2005; Fowler et al., 2005). However, such approaches tend to founder on the difficulty of accurately translating natural language in FOL—tricky issues include idioms, intensionality and propositional attitudes, modalities, temporal and causal relations, certain quantifiers, and so on. FOL-based systems that have attained high precision (Bos and Markert, 2006) have done so at the cost of very poor recall. In this work, we explore a different point on the spectrum, by developing a computational model of natural logic, that is, a logic whose vehicle of inference is natural language.&apos; Natural logic es</context>
</contexts>
<marker>Akhmatova, 2005</marker>
<rawString>Elena Akhmatova. 2005. Textual entailment resolution via atomic propositions. In Proc. of the PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>When logical inference helps determining textual entailment (and when it doesn’t).</title>
<date>2006</date>
<booktitle>In Proc. of the 2nd PASCAL RTE Challenge Workshop. 6Available</booktitle>
<note>at http://yeda.cs.technion.ac.il/∼yaroslav/oc/</note>
<contexts>
<context position="2921" citStr="Bos and Markert, 2006" startWordPosition="425" endWordPosition="428">match the premise. At the other extreme, textual inference can be approached as deduction, building on work in formal computational semantics to translate sentences into first-order logic (FOL), and then applying a theorem prover or a model builder (Akhmatova, 2005; Fowler et al., 2005). However, such approaches tend to founder on the difficulty of accurately translating natural language in FOL—tricky issues include idioms, intensionality and propositional attitudes, modalities, temporal and causal relations, certain quantifiers, and so on. FOL-based systems that have attained high precision (Bos and Markert, 2006) have done so at the cost of very poor recall. In this work, we explore a different point on the spectrum, by developing a computational model of natural logic, that is, a logic whose vehicle of inference is natural language.&apos; Natural logic eschews logical notation and model theory. Its proofs proceed by incremental edits to expressions of natural language, and its inference rules specify conditions under which semantic expansions or contractions preserve truth. It thus permits us to do precise reasoning about monotonicity, while sidestepping the difficulties of translating sentences into FOL.</context>
<context position="24593" citStr="Bos and Markert, 2006" startWordPosition="3983" endWordPosition="3986">igned to address. Second, in most RTE problems, the edit distance between premise and hypothesis is relatively large. More atomic edits means a greater chance that prediction errors made by the atomic entailment model will propagate, via entailment composition, to the system’s final output. Rather, in applying NatLog to RTE, we hope to make reliable predictions on a subset of RTE problems, trading recall for precision. If we succeed, then we may be able to hybridize with a broad-coverage RTE system to obtain better results than either system individually—the same strategy that was adopted by (Bos and Markert, 2006) for their FOL-based system. For this purpose, we have chosen to use the Stanford RTE system described in (de Marneffe et al., 2006). In applying NatLog to RTE problems, we use alignments from the Stanford system as input to our entailment model. A Stanford alignment is a map from hypothesis words to premise words. When we translate such alignments into the NatLog representation described in section 3, each pair of aligned words generates a substitution edit (or, if the words are identical, an advance edit). Unaligned premise words yield deletion edits, while unaligned hypothesis words yield i</context>
<context position="26887" citStr="Bos and Markert, 2006" startWordPosition="4356" endWordPosition="4359">. % yes indicates the proportion of yes predictions made by the system. Precision and recall are shown for the yes label. dering of edits, and multiple edits can operate on the same input spans), we find that this poses no great impediment to subsequent processing by the entailment model. Table 6 shows the performance of the NatLog system on RTE3 data. Relative to the Stanford RTE system, NatLog achieves high precision on its yes predictions—about 76% on the development set, and 68% on the test set—suggesting that hybridizing may be effective. For comparison, the FOL-based system reported in (Bos and Markert, 2006) attained a similarly high precision of 76% on RTE2 problems, but was able to make a positive prediction in only about 4% of cases. NatLog makes positive predictions far more often—at a rate of 18% on the development set, and 24% on the test set. The Stanford RTE system makes yes/no predictions by thresholding a real-valued inference score. To construct a hybrid system, we adjust the Stanford inference scores by +x or −x, depending on whether NatLog predicts yes or no/unk. We choose the value of x by optimizing development set accuracy, while adjusting the threshold to generate balanced predic</context>
</contexts>
<marker>Bos, Markert, 2006</marker>
<rawString>Johan Bos and Katja Markert. 2006. When logical inference helps determining textual entailment (and when it doesn’t). In Proc. of the 2nd PASCAL RTE Challenge Workshop. 6Available at http://yeda.cs.technion.ac.il/∼yaroslav/oc/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
<author>Dick Crouch</author>
<author>Jan Van Eijck</author>
<author>Chris Fox</author>
<author>Johan Van Genabith</author>
<author>Jan Jaspars</author>
<author>Hans Kamp</author>
<author>David Milward</author>
<author>Manfred Pinkal</author>
<author>Massimo Poesio</author>
<author>Steve Pulman</author>
</authors>
<title>Using the framework.</title>
<date>1996</date>
<tech>Technical Report LRE 62-051 D-16, The FraCaS Consortium.</tech>
<marker>Cooper, Crouch, Van Eijck, Fox, Van Genabith, Jaspars, Kamp, Milward, Pinkal, Poesio, Pulman, 1996</marker>
<rawString>Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, and Steve Pulman. 1996. Using the framework. Technical Report LRE 62-051 D-16, The FraCaS Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL Recognising Textual Entailment Challenge.</title>
<date>2005</date>
<booktitle>In Proc. of the PASCAL RTE Challenge Workshop.</booktitle>
<contexts>
<context position="23283" citStr="Dagan et al., 2005" startWordPosition="3765" endWordPosition="3768"> problems in §5 which concern operator adjectives such as former. The entailment model wrongly assumes that such modifiers, like any others, can safely be deleted in upward-monotone contexts, but in fact former student V� student. If the feature set used by the entailment model were extended to represent occurrences of operator adjectives, and if appropriate examples were included in the training data, our accuracy in §5—and the average accuracy for the “applicable” sections—could easily be boosted over 80%. 5 Experiments with RTE data Textual inference problems from the PASCAL RTE Challenge (Dagan et al., 2005) differ from FraCaS problems in several important ways. (See table 5 for examples.) Instead of textbook examples of semantic phenomena, RTE problems are more naturalseeming, with premises collected “in the wild” from newswire text. The premises are much longer, averaging 35 words (vs. 11 words for FraCaS). Also, the RTE task aims at a binary classification: the RTE no answer combines the no and unk answers in FraCaS. Due to the character of RTE problems, we do not expect NatLog to be a good general-purpose solution to solving RTE problems. First, most RTE problems depend on forms of inference,</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The PASCAL Recognising Textual Entailment Challenge. In Proc. of the PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Trond Grenager</author>
<author>Daniel Cer</author>
<author>Anna Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Learning to distinguish valid textual entailments.</title>
<date>2006</date>
<booktitle>In Proc. of the 2nd PASCAL RTE Challenge Workshop.</booktitle>
<marker>de Marneffe, MacCartney, Grenager, Cer, Rafferty, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, Trond Grenager, Daniel Cer, Anna Rafferty, and Christopher D. Manning. 2006. Learning to distinguish valid textual entailments. In Proc. of the 2nd PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Fowler</author>
<author>Bob Hauser</author>
<author>Daniel Hodges</author>
<author>Ian Niles</author>
<author>Adrian Novischi</author>
<author>Jens Stephan</author>
</authors>
<title>Applying COGEX to recognize textual entailment.</title>
<date>2005</date>
<booktitle>In Proc. of the PASCAL RTE Challenge Workshop.</booktitle>
<contexts>
<context position="2586" citStr="Fowler et al., 2005" startWordPosition="378" endWordPosition="381">ntexts, as in: P: No case of indigenously acquired rabies infection has been confirmed in the past 2 years. H: No rabies cases have been confirmed. Because it drops important qualifiers in a negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the premise. At the other extreme, textual inference can be approached as deduction, building on work in formal computational semantics to translate sentences into first-order logic (FOL), and then applying a theorem prover or a model builder (Akhmatova, 2005; Fowler et al., 2005). However, such approaches tend to founder on the difficulty of accurately translating natural language in FOL—tricky issues include idioms, intensionality and propositional attitudes, modalities, temporal and causal relations, certain quantifiers, and so on. FOL-based systems that have attained high precision (Bos and Markert, 2006) have done so at the cost of very poor recall. In this work, we explore a different point on the spectrum, by developing a computational model of natural logic, that is, a logic whose vehicle of inference is natural language.&apos; Natural logic eschews logical notation</context>
</contexts>
<marker>Fowler, Hauser, Hodges, Niles, Novischi, Stephan, 2005</marker>
<rawString>Abraham Fowler, Bob Hauser, Daniel Hodges, Ian Niles, Adrian Novischi, and Jens Stephan. 2005. Applying COGEX to recognize textual entailment. In Proc. of the PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaroslav Fyodorov</author>
<author>Yoad Winter</author>
<author>Nissim Francez</author>
</authors>
<title>Order-based inference in natural logic.</title>
<date>2003</date>
<journal>Logic Journal of the IGPL,</journal>
<volume>11</volume>
<issue>4</issue>
<contexts>
<context position="29643" citStr="Fyodorov et al., 2003" startWordPosition="4819" endWordPosition="4823"> which could “characterize all the valid inferences that can be made in natural language” (Lakoff, 1970). The study of natural logic was formalized by Johan van Benthem, who crucially connected it with categorial grammar (van Benthem, 1986), and later was brought to fruition by Victor S´anchez Valencia, who first gave a precise definition of a calculus of mono199 tonicity (S´anchez Valencia, 1991). A small current of theoretical work has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a categorial grammar parser.6 In an unpublished draft, (van Eijck, 2005) describes a preliminary implementation in Haskell. Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985). To our knowledge, the FraCaS results reported here represent the first such evaluation. (Sukkarieh, 2003) describes applying a deductive system to some FraCaS inferences, but does not perform a complete evaluation or report quantitative results. 7 Conclusion Our NatLog imple</context>
</contexts>
<marker>Fyodorov, Winter, Francez, 2003</marker>
<rawString>Yaroslav Fyodorov, Yoad Winter, and Nissim Francez. 2003. Order-based inference in natural logic. Logic Journal of the IGPL, 11(4):385–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hickl</author>
<author>John Williams</author>
<author>Jeremy Bensley</author>
<author>Kirk Roberts</author>
<author>Bryan Rink</author>
<author>Ying Shi</author>
</authors>
<title>Recognizing textual entailment with LCC’s GROUNDHOG system.</title>
<date>2006</date>
<booktitle>In Proc. of the 2nd PASCAL RTE Challenge Workshop.</booktitle>
<contexts>
<context position="1787" citStr="Hickl et al., 2006" startWordPosition="257" endWordPosition="260">tion The last five years have seen a surge of interest in the problem of textual inference, that is, automatically determining whether a natural-language hypothesis can be inferred from a given premise. A broad spectrum of approaches have been explored, ranging from shallow-but-robust to deep-but-brittle. Up to now, the most successful approaches have used fairly impoverished semantic representations, relying on measures of lexical or semantic overlap (Jijkoun and de Rijke, 2005), pattern-based relation extraction (Romano et al., 2006), or approximate matching of predicate-argument structure (Hickl et al., 2006). Such methods, while robust and broadly effective, are imprecise, and are easily confounded by ubiquituous inferences involving monotonicity, particularly in negative polarity contexts, as in: P: No case of indigenously acquired rabies infection has been confirmed in the past 2 years. H: No rabies cases have been confirmed. Because it drops important qualifiers in a negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the premise. At the other extreme, textual inference can be approached as deductio</context>
</contexts>
<marker>Hickl, Williams, Bensley, Roberts, Rink, Shi, 2006</marker>
<rawString>Andrew Hickl, John Williams, Jeremy Bensley, Kirk Roberts, Bryan Rink, and Ying Shi. 2006. Recognizing textual entailment with LCC’s GROUNDHOG system. In Proc. of the 2nd PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Ontological promiscuity.</title>
<date>1985</date>
<booktitle>In Proc. of ACL-85,</booktitle>
<pages>61--69</pages>
<contexts>
<context position="29966" citStr="Hobbs, 1985" startWordPosition="4874" endWordPosition="4875">inition of a calculus of mono199 tonicity (S´anchez Valencia, 1991). A small current of theoretical work has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a categorial grammar parser.6 In an unpublished draft, (van Eijck, 2005) describes a preliminary implementation in Haskell. Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985). To our knowledge, the FraCaS results reported here represent the first such evaluation. (Sukkarieh, 2003) describes applying a deductive system to some FraCaS inferences, but does not perform a complete evaluation or report quantitative results. 7 Conclusion Our NatLog implementation of natural logic successfully handles a broad range of inferences involving monotonicity, as demonstrated on the FraCaS test suite. While a post-hoc analysis of performance on the RTE3 Challenge suggests that monotonicityrelated inferences have limited applicability in RTE data, the greater precision of the NatL</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry R. Hobbs. 1985. Ontological promiscuity. In Proc. of ACL-85, pages 61–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
</authors>
<title>Recognizing textual entailment using lexical similarity.</title>
<date>2005</date>
<booktitle>In Proc. of the PASCAL RTE Challenge Workshop.</booktitle>
<marker>Jijkoun, de Rijke, 2005</marker>
<rawString>Valentin Jijkoun and Maarten de Rijke. 2005. Recognizing textual entailment using lexical similarity. In Proc. of the PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proc. of ACL-03.</booktitle>
<contexts>
<context position="10480" citStr="Klein and Manning, 2003" startWordPosition="1655" endWordPosition="1658">fferent, then h is downward-monotone. (Thus, wine has positive polarity in no meal without wine because it falls under two downward-monotone operators.) 3 The NatLog System Our natural logic system, dubbed the NatLog system, has a three-stage architecture similar to those in (Marsi and Krahmer, 2005; MacCartney et al., 2006), comprising (1) linguistic pre-preprocessing, (2) alignment, and (3) entailment classification. 3.1 Linguistic pre-processing Relative to other textual inference systems, the NatLog system does comparatively little linguistic preprocessing. We rely on the Stanford parser (Klein and Manning, 2003), a Treebank-trained statistical parser, for tokenization, part-of-speech tagging, and phrase-structure parsing. By far the most important analysis performed at this stage is monotonicity marking, in which we compute the effective monounary operator: without pattern: IN &lt; /-[Ww]ithout\$/ argument 1: monotonicity 1 on dominating PP pattern: __ &gt; PP=proj binary operator: most pattern: JJS &lt; /-[Mm]ost\$/ !&gt; QP argument 1: monotonicity X on dominating NP pattern: __ &gt;+(NP) (NP=proj !&gt; NP) argument 2: monotonicity I on dominating S pattern: __ &gt;+(/.*/) (S=proj !&gt; S) Figure 1: Two examples of monoto</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proc. of ACL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<date>1970</date>
<booktitle>Linguistics and natural logic. Synthese,</booktitle>
<pages>22--151</pages>
<contexts>
<context position="29125" citStr="Lakoff, 1970" startWordPosition="4737" endWordPosition="4738">t: NatLog answers no to problem 518 (table 5) because it cannot account for the insertion of called in the hypothesis. On the other hand, it correctly rejects the hypothesis in problem 601 because it cannot account for the insertion of first, whereas the less-precise Stanford system was happy to allow it. 6 Related work While the roots of natural logic can be traced back to Aristotle’s syllogisms, the modern conception of natural logic began with George Lakoff, who proposed “a logic for natural language” which could “characterize all the valid inferences that can be made in natural language” (Lakoff, 1970). The study of natural logic was formalized by Johan van Benthem, who crucially connected it with categorial grammar (van Benthem, 1986), and later was brought to fruition by Victor S´anchez Valencia, who first gave a precise definition of a calculus of mono199 tonicity (S´anchez Valencia, 1991). A small current of theoretical work has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a cat</context>
</contexts>
<marker>Lakoff, 1970</marker>
<rawString>George Lakoff. 1970. Linguistics and natural logic. Synthese, 22:151–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Galen Andrew</author>
</authors>
<title>Tregex and Tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In Proc. of LREC-06.</booktitle>
<contexts>
<context position="11812" citStr="Levy and Andrew, 2006" startWordPosition="1860" endWordPosition="1863">tence. For this, we use an adaptation of the marking algorithm of S´anchez Valencia (section 2); however, our choice of a Treebank-trained parser (driven by the goal of broad coverage) requires us to modify the algorithm substantially. Unlike the categorial grammar parses assumed by S´anchez Valencia, the nesting of constituents in phrase-structure parses does not always correspond to the composition of semantic functions, which introduces a number of complications. We define a list of downward-monotone and non-monotone expressions, and for each item we specify its arity and a Tregex pattern (Levy and Andrew, 2006) which permits us to identify its occurrences. We also specify, for each argument, both the monotonicity and another Tregex pattern which helps us to determine the sentence span over which the monotonicity is projected. (Figure 1 shows some example definitions.) The marking process computes these projections, performs monotonicity composition where needed, and marks each token span with its final effective monotonicity. 3.2 Alignment The second stage of processing establishes an alignment between the premise and the hypothesis. While there are many notions of alignment, in this work we have ch</context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>Roger Levy and Galen Andrew. 2006. Tregex and Tsurgeon: tools for querying and manipulating tree data structures. In Proc. of LREC-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Trond Grenager</author>
<author>Marie-Catherine de Marneffe</author>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
</authors>
<title>Learning to recognize features of valid textual entailments.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL-06.</booktitle>
<marker>MacCartney, Grenager, de Marneffe, Cer, Manning, 2006</marker>
<rawString>Bill MacCartney, Trond Grenager, Marie-Catherine de Marneffe, Daniel Cer, and Christopher D. Manning. 2006. Learning to recognize features of valid textual entailments. In Proc. of HLT-NAACL-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
</authors>
<title>Classification of semantic relations by humans and machines.</title>
<date>2005</date>
<booktitle>In Proc. of the ACL 2005 Workshop on Empirical Modeling of Semantic Equivalence and Entailment.</booktitle>
<contexts>
<context position="10156" citStr="Marsi and Krahmer, 2005" startWordPosition="1612" endWordPosition="1615">e monotonicities along the path from the root to each leaf in order to determine effective polarities. The composition of monotonicities is straightforward. Suppose h = f o g. If either f or g is non-monotone, then so is h. Otherwise, if the monotonicities of f and g are the same, then h is upward-monotone; if they are different, then h is downward-monotone. (Thus, wine has positive polarity in no meal without wine because it falls under two downward-monotone operators.) 3 The NatLog System Our natural logic system, dubbed the NatLog system, has a three-stage architecture similar to those in (Marsi and Krahmer, 2005; MacCartney et al., 2006), comprising (1) linguistic pre-preprocessing, (2) alignment, and (3) entailment classification. 3.1 Linguistic pre-processing Relative to other textual inference systems, the NatLog system does comparatively little linguistic preprocessing. We rely on the Stanford parser (Klein and Manning, 2003), a Treebank-trained statistical parser, for tokenization, part-of-speech tagging, and phrase-structure parsing. By far the most important analysis performed at this stage is monotonicity marking, in which we compute the effective monounary operator: without pattern: IN &lt; /-[</context>
</contexts>
<marker>Marsi, Krahmer, 2005</marker>
<rawString>Erwin Marsi and Emiel Krahmer. 2005. Classification of semantic relations by humans and machines. In Proc. of the ACL 2005 Workshop on Empirical Modeling of Semantic Equivalence and Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorenza Romano</author>
<author>Milen Kouylekov</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Alberto Lavelli</author>
</authors>
<title>Investigating a generic paraphrase-based approach for relation extraction.</title>
<date>2006</date>
<booktitle>In Proc. of EACL-06.</booktitle>
<contexts>
<context position="1709" citStr="Romano et al., 2006" startWordPosition="247" endWordPosition="250"> with our natural logic system yields significant performance gains. 1 Introduction The last five years have seen a surge of interest in the problem of textual inference, that is, automatically determining whether a natural-language hypothesis can be inferred from a given premise. A broad spectrum of approaches have been explored, ranging from shallow-but-robust to deep-but-brittle. Up to now, the most successful approaches have used fairly impoverished semantic representations, relying on measures of lexical or semantic overlap (Jijkoun and de Rijke, 2005), pattern-based relation extraction (Romano et al., 2006), or approximate matching of predicate-argument structure (Hickl et al., 2006). Such methods, while robust and broadly effective, are imprecise, and are easily confounded by ubiquituous inferences involving monotonicity, particularly in negative polarity contexts, as in: P: No case of indigenously acquired rabies infection has been confirmed in the past 2 years. H: No rabies cases have been confirmed. Because it drops important qualifiers in a negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the </context>
</contexts>
<marker>Romano, Kouylekov, Szpektor, Dagan, Lavelli, 2006</marker>
<rawString>Lorenza Romano, Milen Kouylekov, Idan Szpektor, Ido Dagan, and Alberto Lavelli. 2006. Investigating a generic paraphrase-based approach for relation extraction. In Proc. of EACL-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor S´anchez Valencia</author>
</authors>
<date>1991</date>
<booktitle>Studies on Natural Logic and Categorial Grammar. Ph.D. thesis,</booktitle>
<institution>Univ. of Amsterdam.</institution>
<contexts>
<context position="5203" citStr="Valencia, 1991" startWordPosition="791" endWordPosition="792">nces involving monotonicity, in which the concepts or constraints expressed are expanded or contracted. Consider, for example, the sentence Every meal without wine is a terrible crime. Some semantic elements can be expanded (but not contracted) salva veritate, and are therefore said to have positive polarity: wine may be broadened to drink, terrible crime may be relaxed to crime, or every may be weakened to some. Other elements can only be contracted (not expanded) salva veritate, and thus have negative polarity: meal can be narrowed to dinner. The monotonicity calculus developed in (S´anchez Valencia, 1991) explains these polarity effects by (1) defining an entailment relation over multifarious expressions of natural language, (2) defining monotonicity properties of semantic functions, and finally (3) specifying how monotonicities combine during Fregean composition of semantic functions. The entailment relation. Most work in textual inference reflects a simple concept of entailment: one sentence entails another, or does not. In natural logic, however, entailment is a semantic containment relation (analogous to the set containment relation C_) over expressions of all types, including words and ph</context>
<context position="29421" citStr="Valencia, 1991" startWordPosition="4785" endWordPosition="4786">to allow it. 6 Related work While the roots of natural logic can be traced back to Aristotle’s syllogisms, the modern conception of natural logic began with George Lakoff, who proposed “a logic for natural language” which could “characterize all the valid inferences that can be made in natural language” (Lakoff, 1970). The study of natural logic was formalized by Johan van Benthem, who crucially connected it with categorial grammar (van Benthem, 1986), and later was brought to fruition by Victor S´anchez Valencia, who first gave a precise definition of a calculus of mono199 tonicity (S´anchez Valencia, 1991). A small current of theoretical work has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a categorial grammar parser.6 In an unpublished draft, (van Eijck, 2005) describes a preliminary implementation in Haskell. Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985). To our knowledge, the FraCaS results reported here re</context>
</contexts>
<marker>Valencia, 1991</marker>
<rawString>Victor S´anchez Valencia. 1991. Studies on Natural Logic and Categorial Grammar. Ph.D. thesis, Univ. of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jana Z Sukkarieh</author>
</authors>
<title>An expressive efficient representation: Bridging a gap between NLP and KR.</title>
<date>2003</date>
<booktitle>In Proc. of the 7th Int’l Conf. on Knowledge-Based Intelligent Information and Engineering Systems.</booktitle>
<contexts>
<context position="30073" citStr="Sukkarieh, 2003" startWordPosition="4889" endWordPosition="4890">k has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a categorial grammar parser.6 In an unpublished draft, (van Eijck, 2005) describes a preliminary implementation in Haskell. Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985). To our knowledge, the FraCaS results reported here represent the first such evaluation. (Sukkarieh, 2003) describes applying a deductive system to some FraCaS inferences, but does not perform a complete evaluation or report quantitative results. 7 Conclusion Our NatLog implementation of natural logic successfully handles a broad range of inferences involving monotonicity, as demonstrated on the FraCaS test suite. While a post-hoc analysis of performance on the RTE3 Challenge suggests that monotonicityrelated inferences have limited applicability in RTE data, the greater precision of the NatLog system nevertheless significantly improved the performance of a hybrid RTE system. An area for future wo</context>
</contexts>
<marker>Sukkarieh, 2003</marker>
<rawString>Jana Z. Sukkarieh. 2003. An expressive efficient representation: Bridging a gap between NLP and KR. In Proc. of the 7th Int’l Conf. on Knowledge-Based Intelligent Information and Engineering Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan van Benthem</author>
</authors>
<title>Essays in logical semantics.</title>
<date>1986</date>
<location>Reidel, Dordrecht.</location>
<marker>van Benthem, 1986</marker>
<rawString>Johan van Benthem. 1986. Essays in logical semantics. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan van Eijck</author>
</authors>
<title>Natural logic for natural language. http:</title>
<date>2005</date>
<pages>05</pages>
<marker>van Eijck, 2005</marker>
<rawString>Jan van Eijck. 2005. Natural logic for natural language. http: //homepages.cwi.nl/�jve/papers/05/nlnl/NLNL.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Zamansky</author>
<author>Nissim Francez</author>
<author>Yoad Winter</author>
</authors>
<title>A ‘natural logic’ inference system using the Lambek calculus.</title>
<date>2006</date>
<journal>Journal of Logic, Language and Information,</journal>
<pages>15--273</pages>
<contexts>
<context position="29527" citStr="Zamansky et al., 2006" startWordPosition="4801" endWordPosition="4804">ogisms, the modern conception of natural logic began with George Lakoff, who proposed “a logic for natural language” which could “characterize all the valid inferences that can be made in natural language” (Lakoff, 1970). The study of natural logic was formalized by Johan van Benthem, who crucially connected it with categorial grammar (van Benthem, 1986), and later was brought to fruition by Victor S´anchez Valencia, who first gave a precise definition of a calculus of mono199 tonicity (S´anchez Valencia, 1991). A small current of theoretical work has continued up to the present, for example (Zamansky et al., 2006). There has been surprisingly little work on building computational models of natural logic. (Fyodorov et al., 2003) describes a Prolog implementation for a small fragment of English, based on a categorial grammar parser.6 In an unpublished draft, (van Eijck, 2005) describes a preliminary implementation in Haskell. Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985). To our knowledge, the FraCaS results reported here represent the first such evaluation. (Sukkarieh, 2003) describes applying a deductive system to some FraCaS </context>
</contexts>
<marker>Zamansky, Francez, Winter, 2006</marker>
<rawString>Anna Zamansky, Nissim Francez, and Yoad Winter. 2006. A ‘natural logic’ inference system using the Lambek calculus. Journal of Logic, Language and Information, 15:273–295.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>