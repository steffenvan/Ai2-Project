<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000079">
<title confidence="0.999408">
A More Precise Analysis of Punctuation for
Broad-Coverage Surface Realization with CCG
</title>
<author confidence="0.994763">
Michael White and Rajakrishnan Rajkumar
</author>
<affiliation confidence="0.9944795">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.928599">
Columbus, OH, USA
</address>
<email confidence="0.999822">
{mwhite,raja}@ling.osu.edu
</email>
<sectionHeader confidence="0.998606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967826086957">
This paper describes a more precise anal-
ysis of punctuation for a bi-directional,
broad coverage English grammar extracted
from the CCGbank (Hockenmaier and
Steedman, 2007). We discuss various ap-
proaches which have been proposed in
the literature to constrain overgeneration
with punctuation, and illustrate how as-
pects of Briscoe’s (1994) influential ap-
proach, which relies on syntactic features
to constrain the appearance of balanced
and unbalanced commas and dashes to ap-
propriate sentential contexts, is unattrac-
tive for CCG. As an interim solution
to constrain overgeneration, we propose
a rule-based filter which bars illicit se-
quences of punctuation and cases of im-
properly unbalanced apposition. Using
the OpenCCG toolkit, we demonstrate
that our punctuation-augmented grammar
yields substantial increases in surface re-
alization coverage and quality, helping to
achieve state-of-the-art BLEU scores.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999728375">
In his pioneering monograph, Nunberg (1990) ar-
gues that punctuation is a systematic module of the
grammar of written text and is governed by princi-
ples and constraints like other sub-systems such as
syntax or phonology. Since then, others including
Briscoe (1994) and Doran (1998) have explored
ways of including rules and representations for
punctuation marks in broad coverage grammars. In
</bodyText>
<footnote confidence="0.90298575">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999885736842105">
computational systems, punctuation provides dis-
ambiguation cues which can help parsers arrive at
the correct parse. From a natural language gener-
ation standpoint, text without punctuation can be
difficult to comprehend, or even misleading.
In this paper, we describe a more precise analy-
sis of punctuation for a bi-directional, broad cover-
age English grammar extracted from the CCGbank
(Hockenmaier and Steedman, 2007). In contrast to
previous work, which has been primarily oriented
towards parsing, our goal has been to develop an
analysis of punctuation that is well suited for both
parsing and surface realization. In addition, while
Briscoe and Doran have simply included punctu-
ation rules in their manually written grammars,
our approach has been to revise the CCGbank it-
self with punctuation categories and more precise
linguistic analyses, and then to extract a grammar
from the enhanced corpus.
In developing our analysis, we illustrate how as-
pects of Briscoe’s (1994) approach, which relies
on syntactic features to constrain the appearance
of balanced and unbalanced commas and dashes to
appropriate sentential contexts, is unattractive for
CCG, with its more flexible handling of word or-
der. Consequently, as an interim solution, we have
chosen to identify and filter undesirable configu-
rations when scoring alternative realizations. We
also point to other ways in which punctuation con-
straints could be incorporated into the grammar,
for exploration in future work.
Using the OpenCCG toolkit, we demonstrate
that our punctuation-enhanced grammar yields
substantial increases in surface realization quality,
helping to achieve state-of-the-art BLEU scores.
We use non-blind testing to evaluate the efficacy
of the grammar, and blind-testing to evaluate its
performance on unseen data. The baseline models
</bodyText>
<page confidence="0.991795">
17
</page>
<note confidence="0.849221">
Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 17–24
Manchester, August 2008
</note>
<bodyText confidence="0.999406583333333">
are (1) a grammar which has lexicalized punctu-
ation categories only for conjunction and apposi-
tion, and (2) one which has punctuation categories
corresponding to the existing treatment of punctua-
tion in the corpus. Non-blind testing results shown
a nearly 9-point increase in BLEU scores com-
pared to the best baseline model using oracle n-
grams, as well as a 40% increase in exact matches.
Blind testing results show a more than 5.5-point
increase in BLEU scores, contributing to an all-
sentences score of 0.7323 on Section 23 with over
96% coverage.
</bodyText>
<sectionHeader confidence="0.986702" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999864891891892">
CCG (Steedman, 2000) is a unification-based cat-
egorial grammar formalism which is defined al-
most entirely in terms of lexical entries that encode
sub-categorization information as well as syntactic
feature information (e.g. number and agreement).
Complementing function application as the stan-
dard means of combining a head with its argument,
type-raising and composition support transparent
analyses for a wide range of phenomena, includ-
ing right-node raising and long distance dependen-
cies. Semantic composition happens in parallel
with syntactic composition, which makes it attrac-
tive for generation.
OpenCCG is a parsing/generation library which
works by combining lexical categories for words
using CCG rules and multi-modal extensions on
rules (Baldridge, 2002) to produce derivations.
Surface realization is the process by which logical
forms are transduced to strings. OpenCCG uses
a hybrid symbolic-statistical chart realizer (White,
2006) which takes logical forms as input and pro-
duces sentences by using CCG combinators to
combine signs. Alternative realizations are ranked
using integrated n-gram scoring.
To illustrate the input to OpenCCG, consider
the semantic dependency graph in Figure 1. In
the graph, each node has a lexical predication
(e.g. make.03) and a set of semantic features (e.g.
(NUM)sg); nodes are connected via dependency
relations (e.g. (ARG0)). Internally, such graphs
are represented using Hybrid Logic Dependency
Semantics (HLDS), a dependency-based approach
to representing linguistic meaning (Baldridge and
Kruijff, 2002). In HLDS, each semantic head (cor-
responding to a node in the graph) is associated
with a nominal that identifies its discourse referent,
and relations between heads and their dependents
</bodyText>
<figureCaption confidence="0.698985">
Figure 1: Semantic dependency graph from the
</figureCaption>
<bodyText confidence="0.538689666666667">
CCGbank for He has a point he wants to make
[. . . ]
are modeled as modal relations.
</bodyText>
<sectionHeader confidence="0.98843" genericHeader="method">
3 The need for an OpenCCG analysis of
punctuation
</sectionHeader>
<bodyText confidence="0.999562761904762">
The linguistic analysis aims to make a broad cover-
age OpenCCG grammar extracted from the CCG-
bank (White et al., 2007) more precise by adding
lexicalized punctuation categories to deal with
constructions involving punctuation. The origi-
nal CCGbank corpus does not have lexical cate-
gories for punctuation; instead, punctuation marks
carry categories derived from their part of speech
tags and form part of a binary rule. It is as-
sumed that there are no dependencies between
words and punctuation marks and that the re-
sult of punctuation rules is the same as the non-
punctuation category. OpenCCG does not support
non-combinatory binary rules, as they can be re-
placed by equivalent lexicalized categories with
application-only slashes. For example, a binary
rule of the form , s ⇒ s can be replaced by the
equivalent category s(l)/*s(l) for the comma. In
fact, this would work reasonably well for parsing,
but is inadequate for generation. To illustrate, con-
sider (1):
</bodyText>
<listItem confidence="0.796672">
(1) Despite recent declines in yields, in-
</listItem>
<bodyText confidence="0.921991">
vestors continue to pour cash into
money funds. (wsj 0004.10)
A comma category like the one shown above
would end up overgenerating, as sentences and
</bodyText>
<figure confidence="0.99778708">
he
&lt;Arg1&gt;
P1
point
h2
&lt;NUM&gt;sg
&lt;Det&gt;
have.03
&lt;TENSE&gt;pres
&lt;Arg0&gt;
&lt;GenRel&gt;
h1
&lt;Arg1&gt;
want.01
a1
a
W1
&lt;TENSE&gt;pres
&lt;Arg0&gt;
&lt;Arg1&gt;
h3
he
M1
make.03
&lt;Arg0&gt;
</figure>
<page confidence="0.993245">
18
</page>
<bodyText confidence="0.999844">
sentential complements would be generated with
a comma preceding them. Also, the result of the
above function application rule could act as its own
argument, producing a string of commas. More
generally, binary rules miss out on many linguis-
tic generalizations, such as the presence of manda-
tory balancing marks in sentence-medial comma
or dash adjuncts.
The literature discusses various means to ad-
dress the issue of overgeneration: absorption rules
(Nunberg, 1990), syntactic features (Doran, 1998)
and (Briscoe, 1994) and semantic features (White,
2006). Section 5 explains these approaches in de-
tail, and considers a possible system of syntactic
features for a multi-modal CCG grammar imple-
mentation. We show how such a system is inade-
quate to constrain all possible cases of overgener-
ation, motivating our decision to employ semantic
features in our bi-directional grammar.
</bodyText>
<sectionHeader confidence="0.7828745" genericHeader="method">
4 Integrating an analysis of punctuation
into the grammar
</sectionHeader>
<bodyText confidence="0.999978642857143">
As our starting point, we used an XML repre-
sentation of an enhanced version of the CCGbank
with Propbank roles projected onto it (Boxwell and
White, 2008). Contexts and constructions in which
punctuation marks occur were isolated and the cor-
pus was then restructured by inserting new cate-
gories and modified derivations using XSL trans-
forms. In many cases this also involved modify-
ing the gold standard derivations substantially and
adding semantic representations to syntactic cat-
egories using logical form templates. Currently,
the algorithm succeeds in creating logical forms
for 98.01% of the sentences in the development
section (Sect. 00) of the converted CCGbank, and
96.46% of the sentences in the test section (Sect.
23). Of these, 92.10% of the development LFs
are semantic dependency graphs with a single root,
while 92.12% of the test LFs have a single root.
The remaining cases, with multiple roots, are miss-
ing one or more dependencies required to form a
fully connected graph. These missing dependen-
cies usually reflect inadequacies in the current log-
ical form templates. In Section 00, 89 punctuation
categories were created (66 commas, 14 dashes
and 3 each for the rest) out of 54 classes of binary
rules (37 comma, 8 dash, 3 apiece of colon, paren-
thesis and dots). Three high frequency comma cat-
egories are explained below.
</bodyText>
<subsectionHeader confidence="0.998229">
4.1 Sentential Adjuncts
</subsectionHeader>
<bodyText confidence="0.98198453125">
The comma in example (1) has been analysed
as selecting a sentential modifier to its left,
Despite recent declines in yields, to result in a
sentential modifier which then selects the rest of
the sentence. This results in the following lexical
category and semantics for the comma category:
(2) , `s(1)iced=X1,mod=M/s(1)\*(s(1)/s(1))
: @m(hEMPH-INTROi+)
Syntactic categories and their semantics are linked
by index variables in the feature structures of cat-
egories. Index variables for semantic heads (e.g.
X1) are conventionally named X plus the number
of the feature structure. To support modifier modi-
fiers, as in (2), semantic heads of modifiers are also
made available through a modifier index feature,
with a variable conventionally named M.1 Here,
the effect of combining the comma with the phrase
headed by despite is to add the hEMPH-INTROi+
feature to the despite-phrase’s semantics. Follow-
ing (Bayraktar et al., 1998), this feature indicates
that the comma has the discourse function of em-
phasizing an introductory clause or phrase. Dur-
ing realization, the feature triggers the look-up of
the category in (2), and prevents the re-application
of the category to its own output (as the feature
should only be realized once).
The category in (2) illustrates our approach,
which is to assign to every punctuation mark (other
than balancing marks) a category whose LF in-
cludes a feature or relation which represents its
discourse semantic function in broad-brush terms
such as emphasis, elaboration and apposition.
</bodyText>
<subsectionHeader confidence="0.999566">
4.2 Verbs of reported speech
</subsectionHeader>
<bodyText confidence="0.994827333333333">
In (3), the comma which follows Neverthless and
sets off the phrase headed by said has the category
in (4):
</bodyText>
<listItem confidence="0.999325428571429">
(3) Nevertheless, said Brenda Malizia Ne-
gus, editor of Money Fund Report,
yields may blip up again before they
blip down because of recent rises in
short-term interest rates. (wsj 0004.8)
(4) , ` s(2)/s(2)/*punct[,]/*(s(1)dcl\s(2) dcl)
: @X2(hELABRELi ∧ X1)
</listItem>
<footnote confidence="0.9676345">
1A limited form of default unification is used in the im-
plementation to keep multiple modifiers from conflicting. As
the names of index variables are entirely predictable, they are
suppressed in the remainder of the paper.
</footnote>
<page confidence="0.998776">
19
</page>
<bodyText confidence="0.99999028">
In the genre of newswire text, this construction
occurs frequently with verbs of reported speech.
The CCGbank derivation of (3) assigns the cate-
gory s(1)dcl\s(2)dcl to the phrase headed by said,
the same category that is used when the phrase
follows the missing sentential complement. The
comma category in (4) selects for this category
and a balancing comma and then converts it to
a pre-sentential modifier, s(2)/s(2). Semantically,
an elaboration relation is added between the main
clause and the reported speech phrase.
Category (4) overgenerates to some extent in
that it will allow a comma at the beginning of the
sentence. To prevent this, an alternative would be
to make the comma explicitly select for lexical ma-
terial to its left (in this case for the category of Nev-
erthless). Another possibility would be to follow
Doran (1998) in analyzing the above construction
by using the verb itself to select for the comma.
However, since our method involves changing the
gold standard derivations, and since making the
verb select extra commas or having the comma se-
lect leftward material would entail substantial fur-
ther changes to the derivations, we have opted to
go with (4), balancing adequacy and convenience.
</bodyText>
<subsectionHeader confidence="0.996108">
4.3 NP appositives
</subsectionHeader>
<bodyText confidence="0.999759571428571">
Neither the Penn Tree Bank nor the CCGbank
distinguishes between NP appositives and NP
conjunctions. We wrote a set of simple heuristic
rules to enforce this distinction, which is vital
to generation. Appositives can occur sentence
medially or finally. The conventions of writing
mandate that sentence medial appositives should
be balanced—i.e., the appositive NP should
be surrounded by commas or dashes on both
sides—while sentence final appositives should
be unbalanced—i.e., they should only have one
preceding comma or dash. The categories and
semantics for unbalanced and balanced appositive
commas are, respectively:
</bodyText>
<equation confidence="0.975217">
(5) a. , np(1)\np(1)/*np(3)
: @xl((APPOSREL) n X3)
b. , np(1)\np(1)/*punct[,]/*np(3)
: @xl((APPOSREL) n X3)
</equation>
<bodyText confidence="0.999696">
Here, the unbalanced appositive has a category
where the comma selects as argument the apposi-
tive NP and converts it to a nominal modifier. For
balanced appositives, the comma selects the ap-
positive NP and the balancing comma to form a
nominal modifier (examples are given in the next
section).
</bodyText>
<sectionHeader confidence="0.9194015" genericHeader="method">
5 Constraining overgeneration in
bi-directional grammars
</sectionHeader>
<bodyText confidence="0.998393769230769">
A complex issue that arises in the design of bi-
directional grammars is ensuring the proper pre-
sentation of punctuation. Among other things, this
involves the task of ensuring the correct realization
of commas introducing noun phrase appositives—
in our case, choosing when to use (5a) vs. (5b). In
this section, we consider and ultimately reject a so-
lution that follows Briscoe (1994) in using syntac-
tic features. As an alternative, interim solution, we
then describe a rule-based filter which bars illicit
punctuation sequences and improperly unbalanced
apposition. The paradigm below helps illustrate
the issues:
</bodyText>
<listItem confidence="0.9997225">
(6) John, CEO of ABC, loves Mary.
(7) * John, CEO of ABC loves Mary.
(8) Mary loves John, CEO of ABC.
(9) * Mary loves John, CEO of ABC,.
(10) Mary loves John, CEO of ABC, madly.
(11) * Mary loves John, CEO of ABC madly.
</listItem>
<subsectionHeader confidence="0.99144">
5.1 Absorption vs. syntactic features
</subsectionHeader>
<bodyText confidence="0.999935136363637">
Nunberg (1990) argues that text adjuncts intro-
duced by punctuation marks have an underlying
representation where these adjuncts have marks on
either side. They attain their surface form when
a set of presentation rules are applied. This ap-
proach ensures that all sentence medial cases like
(6) and (10) above are generated correctly, while
unacceptable examples (7) and (11) would not be
generated at all. Example (8) would at first be
generated as (9): to deal with such sentences,
where two points happen to coincide, Nunberg
posits an implicit point which is absorbed by the
adjacent point. Absorption occurs according to
the “strength” of the two points. Strength is de-
termined according to the Point Absorption Hi-
erarchy, which ranks commas lower than dashes,
semi-colons, colons and periods. As White (1995)
observes, from a generation-only perspective, it
makes sense to generate text adjuncts which are
always balanced and post-process the output to
delete lower ranked points, as absorption uses rel-
atively simple rules that operate independently of
</bodyText>
<page confidence="0.987596">
20
</page>
<bodyText confidence="0.999952777777778">
the hierarchy of the constituents. However, us-
ing this approach for parsing would involve a pre-
processing step which inserts commas into possi-
ble edges of possible constituents, as described in
(Forst and Kaplan, 2006). To avoid this consider-
able complication, Briscoe (1994) has argued for
developing declarative approaches involving syn-
tactic features, with no deletions or insertions of
punctuation marks.
</bodyText>
<subsectionHeader confidence="0.945725">
5.2 Features for punctuation in CCG?
</subsectionHeader>
<bodyText confidence="0.999854666666666">
Unfortunately, the feature-based approach appears
to be inadequate for dealing with the class of ex-
amples presented above in CCG. This approach in-
volves the incorporation of syntactic features for
punctuation into atomic categories so that certain
combinations are blocked. To ensure proper ap-
positive balancing sentence finally, the rightmost
element in the sentence should transmit a relevant
feature to the clause level, which the sentence-final
period can then check for the presence of right-
edge punctuation. Possible categories for a tran-
sitive verb and the full stop appear below:
</bodyText>
<listItem confidence="0.596174333333333">
(12) loves ` s(1)bal=BAL,end=PE\np(2)bal=+
/np(3)bal=BAL,end=PE
(13) . ` sent\*send=nil
</listItem>
<bodyText confidence="0.9480618">
Here the feature variables BAL and PE of the right-
most argument of the verb would unify with the
corresponding result category feature values to re-
alize the main clauses of (8) and (9) with the fol-
lowing feature values:
</bodyText>
<listItem confidence="0.91401625">
(14) Mary loves John, CEO of ABC `
s(1)bal=−,end=nil
(15) Mary loves John, CEO of ABC, `
s(1)bal=+,end=comma
</listItem>
<bodyText confidence="0.999920333333333">
Thus, in (15), the sentence-final period would not
combine with s(1)bal=+,end=comma and the deriva-
tion would be blocked.2
</bodyText>
<subsectionHeader confidence="0.656329">
5.2.1 Issue: Extraction cases
</subsectionHeader>
<bodyText confidence="0.997701333333333">
The solution sketched above is not adequate to
deal with extraction involving ditransitive verbs in
cases like (16) and (17):
</bodyText>
<footnote confidence="0.990907333333333">
2It is worth noting than an n-gram scorer would highly
disprefer example (9), as a comma period sequence would not
be attested in the training data. However, an n-gram model
cannot be relied upon to eliminate examples like (11), which
would likely be favored as they are shorter than their balanced
counterparts.
</footnote>
<listItem confidence="0.99410175">
(16) Mary loves a book that John gave Bill,
his brother.
(17) * Mary loves a book that John gave Bill,
his brother,.
</listItem>
<bodyText confidence="0.999887181818182">
As Figure 2 shows, an unacceptable case like (17)
is not blocked. Even when the sentence final NP is
balanced, the end=comma value is not propagated
to the root level. This is because the end feature
for the relative clause should depend on the first
(indirect) object of gave, rather than the second
(direct) object as in a full ditransitive clause. A
possible solution would be to introduce more fea-
tures which record the presence of punctuation in
the leftward and rightward arguments of complex
categories; this would be rather baroque, however.
</bodyText>
<subsubsectionHeader confidence="0.945846">
5.2.2 Issue: Crossing composition
</subsubsectionHeader>
<bodyText confidence="0.995821">
Another issue is how crossing composition, used
with adverbs in heavy NP shift contructions, inter-
acts with appositives, as in the following examples:
</bodyText>
<listItem confidence="0.9881575">
(18) Mary loves madly John, CEO of ABC.
(19) * Mary loves madly John, CEO of ABC,.
</listItem>
<bodyText confidence="0.999592">
For examples (10) and (11), which do not involve
crossing composition, the category for the adverb
should be the one in (20):
</bodyText>
<listItem confidence="0.783317">
(20) madly ` s(1)end=nil\np(2)\
(s(1)bal=+\np(2))
</listItem>
<bodyText confidence="0.9918494375">
Here the bal=+ feature on the argument of the ad-
verb madly ensures that the direct object of the
verb is balanced, as in (10); otherwise, the deriva-
tion fails, as in (11). Irrespective of the value
of the end feature of the argument, the result of
the adverb has the feature end=nil as the post-
modifier is lexical material which occurs after the
VP. With crossing composition, however, category
(20) would licence an erroneous derivation for ex-
ample (19), as the end=nil feature on the result of
the adverb category would prevent the percolation
of the end feature at the edge of the phrase to the
clausal root, as Figure 3 shows.
To block such derivations, one might consider
giving the adverb another category for use with
crossing composition:
</bodyText>
<listItem confidence="0.602608">
(21) madly ` s(1)\np(2)\x(s(1)\np(2))
</listItem>
<bodyText confidence="0.999302">
The use of the non-associative, permutative modal-
ity × on the main slash allows the crossing com-
position rule to be applied, and feature inheritance
</bodyText>
<page confidence="0.997125">
21
</page>
<figure confidence="0.632794833333333">
that John gave Bill, his brother,
(nend=PE\n)/(send=PE/np) np send=PE\np/npend=PE/np npend=comma
&gt;T &gt;
s/(s\np) send=PE\np/npend=PE
send=PE/npend=PE
nend=PE \n
</figure>
<figureCaption confidence="0.901409">
Figure 2: Object extraction
</figureCaption>
<figure confidence="0.99577575">
Mary loves madly John, CEO, .
np send=PE\np/npend=PE s 1end=nil\np 1\(s 1bal=+\np 1) npbal=+,end=comma sent\?send=nil
&gt;B
&gt;
&lt;B×
send=nil\np/npend=PE
send=nil\np
send=nil
sent
&gt;
&lt;
&lt;
</figure>
<figureCaption confidence="0.999963">
Figure 3: Crossing composition
</figureCaption>
<bodyText confidence="0.99875095">
ensures that the end feature from the verb loves
is also copied over. Thus, in example (19), the
punctuation at the edge of the phrase would be
percolated to the clausal root, where the sentence-
final period would block the derivation. However,
in the slash modality inheritance hierarchy pro-
posed by Baldridge (2002), the × modality inher-
its the properties of function application. Conse-
quently, this category could also lead to the erro-
neous derivation of example (11). In such a deriva-
tion, category (21) will not require the direct ob-
ject to have a balanced appositive; meanwhile, the
end=nil feature on the direct object will propagate
to the clausal root, where it will happily combine
with the category for the full stop. Finally, having
two distinct categories for the adverb would off-
set the advantage of multi-modal categorial gram-
mar in dealing with word order variation, where it
is possible to use one category in situations where
otherwise several categories would be required.
</bodyText>
<subsectionHeader confidence="0.9828535">
5.3 A rule-based filter to constrain
overgeneration
</subsectionHeader>
<bodyText confidence="0.999961272727273">
For the reasons discussed in the preceding section,
we decided not to use syntactic features to con-
strain overgeneration. Instead, we have employed
semantic features in the logical form together with
a rule-based filter, as an interim solution. Dur-
ing realization, the generated output is examined
and fragments where two marks appear in a row
are eliminated. Additionally, to handle improp-
erly unbalanced punctuation, we modified the re-
sult categories of unbalanced appositive commas
and dashes to include a feature marking unbal-
</bodyText>
<equation confidence="0.8149545">
anced punctuation, as follows:
(22) , �- np(1)unbal=comma\*np(1)/*np(2)
</equation>
<bodyText confidence="0.999932">
Then, during realization, a filter on derivations
looks for categories such as npunbal=comma, and
checks to make sure this NP is followed by a an-
other punctuation mark in the string. We report on
the effects of the filter in our results section.
</bodyText>
<sectionHeader confidence="0.997093" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.998085333333333">
We extracted a grammar from the restructured cor-
pus and created testbeds of logical forms under the
following conditions:
</bodyText>
<listItem confidence="0.864271833333333">
1. Baseline 1: A CCGbank version which has no
lexicalized categories corresponding to any
of the punctuation marks except sentence fi-
nal marks and commas which conjoin ele-
ments or introduce NP appositives. Conjunc-
tion and apposition are frequent in the corpus
and if excluded, logical forms for many sen-
tences are not produced, weakening the base-
line considerably.
2. Baseline 2: A CCGbank version where
all punctuation marks (except conjunc-
tion/apposition commas and sentence-final
marks, which have proper categories) have
lexicalized MMCCG categories with no se-
mantics, corresponding to binary rules in the
original CCGbank.
3. The CCGbank augmented with punctuation
categories.
</listItem>
<page confidence="0.993696">
22
</page>
<bodyText confidence="0.962748142857143">
Testing was done under four conditions:
1. Non-blind testing with oracle n-gram scoring.
This condition tests the grammar most di-
rectly, as it avoids the issue of lexical smooth-
ing and keeps the combinatorial search man-
ageable. A grammar extracted from the de-
velopment section (Section 00) of the CCG-
bank was applied to the LF testbed of that
section, using oracle n-gram scoring (along
with FLMs, see next) to generate the sen-
tences back. For each logical form, the gener-
ated output sentence was compared with the
actual gold standard sentence corresponding
to that logical form.
2. Blind testing with factored language mod-
els (FLM) and lexical smoothing, following
(White et al., 2007). Blind testing naturally
provides a more realistic test of performance
on unseen data. Here logical forms of Sec-
tions 00 and 23 were created using gram-
mars of those sections respectively and then
a grammar was extracted from the standard
training sections (02-21). This grammar was
used to generate from the LFs of the develop-
ment and test sections; for space reasons, we
only report the results on the test section.
3. Blind testing with hypertagging. Hypertag-
ging (Espinosa et al., 2008) is supertagging
for surface realization; it improves realizer
speed and coverage with large grammars by
predicting lexical category assignments with
a maximum entropy model.
4. The punctuation-enhanced grammars were
tested in the three conditions above with and
without the balanced punctuation filter.
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.999740909090909">
Non-blind testing results in Table 1 indicate that
both exact match figures as well BLEU scores in-
crease substantially in comparison to the baselines
when a punctuation augmented grammar is used.
The difference is especially notable when oracle
n-gram scoring is used. The punctuation filter im-
proves performance as exact matches increase by
1.66% and BLEU scores also show a slight in-
crease. Complete realizations are slightly worse
for the augmented grammar than Baseline 1, but
the coverage of the baseline grammar is lower.
</bodyText>
<tableCaption confidence="0.996897">
Table 1: Non-blind testing on Section 00 (Gram-
</tableCaption>
<table confidence="0.9648307">
mar coverage: Baseline 1, 95.8%; Baseline 2,
95.03%; Punct grammar, 98.0%)
N-grams Grammar Exact Complete BLEU
Oracle Baseline 1 35.8% 86.2% 0.8613
Baseline 2 39.10% 53.58% 0.8053
Punct 75.9% 85.3% 0.9503
FLM w/o Baseline 1 17.7% 83.0% 0.7293
filter Baseline 2 5.72% 4.18% 0.4470
Punct 29.7% 80.6% 0.7984
FLM w/ filt. Punct 31.3% 80.6% 0.8062
</table>
<tableCaption confidence="0.828762">
Table 2: Blind testing on Section 23 with FLM
</tableCaption>
<table confidence="0.920132">
(Grammar coverage: Baseline 1, 94.8%; Base-
line 2, 95.06%; Punct grammar, 96.5%)
Hyp., Filt. Grammar Exact Complete BLEU
no, w/o Baseline 1 11.1% 46.4% 0.6297
Baseline 2 2.97% 3.97% 0.3104
Punct 18.0% 43.2% 0.6815
no, w/ Punct 19.3% 43.3% 0.6868
yes, w/o Punct 20.4% 61.5% 0.7270
yes, w/ Punct 21.6% 61.5% 0.7323
</table>
<bodyText confidence="0.999057428571429">
Blind testing results shown in Table 2 also demon-
strate that the augmented grammar does better than
the baseline in terms of BLEU scores and ex-
act matches, with the hypertagger further boosting
BLEU scores and the number of complete realiza-
tions. The use of the filter yields a further 1.2–
1.3% increase in exact match figures as well as a
half a BLEU point improvement; a planned col-
lection of human judgments may reveal that these
improvements are more meaningful than the scores
would indicate.
Baseline 2, which models all punctuation, per-
forms very badly with FLM scoring though it does
better than the minimal punctuation Baseline 1
with oracle scoring. The main reason for this is
that, without any semantic or syntactic features to
constrain punctuation categories, they tend to re-
apply to their own output, clogging up the chart.
This results in a low number of complete realiza-
tions as well as exact matches.
While direct comparisons cannot really be made
across grammar frameworks, as inputs vary in
their semantic depth and specificity, we observe
that our all-sentences BLEU score of 0.7323 ex-
ceeds that of Hogan et al. (2007), who report a
top score of 0.6882 including special treatment of
multi-word units (though their coverage is near
100%). Nakanishi et al. (2005) and Langkilde-
</bodyText>
<page confidence="0.991559">
23
</page>
<bodyText confidence="0.964594333333333">
Geary (2002) report scores several points higher,
though the former is limited to sentences of length
20 or less, and the latter’s coverage is much lower.
</bodyText>
<sectionHeader confidence="0.895563" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.993033625">
Espinosa, Dominic, Michael White, and Dennis Mehay.
2008. Hypertagging: Supertagging for surface real-
ization with CCG. In Proc. ACL-08:HLT. To appear.
Forst, Martin and Ronald M. Kaplan. 2006. The im-
portance of precise tokenizing for deep grammars.
In Proc. LREC-06.
We have shown that incorporating a more pre-
cise analysis of punctuation into a broad-coverage
reversible grammar extracted from the CCGbank
yields substantial increases in the number of ex-
act matches and BLEU scores when performing
surface realization with OpenCCG, contributing to
state-of-the-art results. Our discussion has also
highlighted the inadequacy of using syntactic fea-
tures to control punctuation placement in CCG,
leading us to develop a filter to ensure appro-
priately balanced commas and dashes. In fu-
ture work, we plan to investigate a more satisfac-
tory grammatical treatment involving constraints
in independent orthographic derivations, perhaps
along the lines of the autonomous prosodic deriva-
tions which Steedman and Prevost (1994) discuss.
An evaluation of parsing side performance is also
planned.
</bodyText>
<sectionHeader confidence="0.999074" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99999">
We thank the anonymous reviewers, Detmar Meur-
ers and the Clippers and Synners groups at OSU
for helpful comments and discussion.
</bodyText>
<sectionHeader confidence="0.999553" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999748653846154">
Baldridge, Jason and Geert-Jan Kruijff. 2002. Cou-
pling CCG and Hybrid Logic Dependency Seman-
tics. In Proc. ACL-02.
Baldridge, Jason. 2002. Lexically Specified Deriva-
tional Control in Combinatory Categorial Grammar.
Ph.D. thesis, University of Edinburgh.
Bayraktar, Murat, Bilge Say, and Varol Akman. 1998.
An Analysis of English Punctuation: The Special
Case of Comma. International Journal of Corpus
Linguistics, 3(1):33–58.
Boxwell, Stephen and Michael White. 2008. Pro-
jecting Propbank roles onto the CCGbank. In Proc.
LREC-08. To appear.
Briscoe, Ted. 1994. Parsing (with) punctuation. Tech-
nical report, Xerox, Grenoble, France.
Doran, Christine. 1998. Incorporating Punctuation
into the Sentence Grammar: A Lexicalized Tree Ad-
joining Grammar Perspective. Ph.D. thesis, Univer-
sity of Pennsylvania.
Hockenmaier, Julia and Mark Steedman. 2007. CCG-
bank: A Corpus of CCG Derivations and Depen-
dency Structures Extracted from the Penn Treebank.
Computational Linguistics, 33(3):355–396.
Hogan, Deirdre, Conor Cafferkey, Aoife Cahill, and
Josef van Genabith. 2007. Exploiting multi-word
units in history-based probabilistic generation. In
Proc. EMNLP-CoNLL-07.
Langkilde-Geary, Irene. 2002. An empirical veri-
fication of coverage and correctness for a general-
purpose sentence generator. In Proc. INLG-02.
Nakanishi, Hiroko, Yusuke Miyao, and Jun’ichi Tsujii.
2005. Probabilistic methods for disambiguation of
an HPSG-based chart generator. In Proc. IWPT-05.
Nunberg, Geoffrey. 1990. The Linguistics of Punctua-
tion. CSLI Publications, Stanford, CA.
Steedman, Mark and S. Prevost. 1994. Specifying in-
tonation from context for speech synthesis. Speech
Communication, 15(1–2):139–153.
Steedman, Mark. 2000. The syntactic process. MIT
Press, Cambridge, MA, USA.
White, Michael, Rajakrishnan Rajkumar, and Scott
Martin. 2007. Towards broad coverage surface re-
alization with CCG. In Proc. of the Workshop on
Using Corpora for NLG: Language Generation and
Machine Translation (UCNLG+MT).
White, Michael. 1995. Presenting punctuation. In Pro-
ceedings of the Fifth European Workshop on Natural
Language Generation, pages 107–125.
White, Michael. 2006. Efficient realization of coordi-
nate structures in combinatory categorial grammar.
Research on Language and Computation, 4(1):39–
75.
</reference>
<page confidence="0.999135">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.855074">
<title confidence="0.982327">A More Precise Analysis of Punctuation Broad-Coverage Surface Realization with CCG</title>
<author confidence="0.957493">White</author>
<affiliation confidence="0.971329">Department of The Ohio State</affiliation>
<address confidence="0.965836">Columbus, OH,</address>
<abstract confidence="0.999248">This paper describes a more precise analysis of punctuation for a bi-directional, broad coverage English grammar extracted from the CCGbank (Hockenmaier and Steedman, 2007). We discuss various approaches which have been proposed in the literature to constrain overgeneration with punctuation, and illustrate how aspects of Briscoe’s (1994) influential approach, which relies on syntactic features to constrain the appearance of balanced and unbalanced commas and dashes to appropriate sentential contexts, is unattractive for CCG. As an interim solution to constrain overgeneration, we propose a rule-based filter which bars illicit sequences of punctuation and cases of improperly unbalanced apposition. Using the OpenCCG toolkit, we demonstrate that our punctuation-augmented grammar yields substantial increases in surface realization coverage and quality, helping to achieve state-of-the-art BLEU scores.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Geert-Jan Kruijff</author>
</authors>
<title>Coupling CCG and Hybrid Logic Dependency Semantics. In</title>
<date>2002</date>
<booktitle>Proc. ACL-02.</booktitle>
<contexts>
<context position="5787" citStr="Baldridge and Kruijff, 2002" startWordPosition="841" endWordPosition="844">zer (White, 2006) which takes logical forms as input and produces sentences by using CCG combinators to combine signs. Alternative realizations are ranked using integrated n-gram scoring. To illustrate the input to OpenCCG, consider the semantic dependency graph in Figure 1. In the graph, each node has a lexical predication (e.g. make.03) and a set of semantic features (e.g. (NUM)sg); nodes are connected via dependency relations (e.g. (ARG0)). Internally, such graphs are represented using Hybrid Logic Dependency Semantics (HLDS), a dependency-based approach to representing linguistic meaning (Baldridge and Kruijff, 2002). In HLDS, each semantic head (corresponding to a node in the graph) is associated with a nominal that identifies its discourse referent, and relations between heads and their dependents Figure 1: Semantic dependency graph from the CCGbank for He has a point he wants to make [. . . ] are modeled as modal relations. 3 The need for an OpenCCG analysis of punctuation The linguistic analysis aims to make a broad coverage OpenCCG grammar extracted from the CCGbank (White et al., 2007) more precise by adding lexicalized punctuation categories to deal with constructions involving punctuation. The ori</context>
</contexts>
<marker>Baldridge, Kruijff, 2002</marker>
<rawString>Baldridge, Jason and Geert-Jan Kruijff. 2002. Coupling CCG and Hybrid Logic Dependency Semantics. In Proc. ACL-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>Lexically Specified Derivational Control in Combinatory Categorial Grammar.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="4995" citStr="Baldridge, 2002" startWordPosition="730" endWordPosition="731">ategorization information as well as syntactic feature information (e.g. number and agreement). Complementing function application as the standard means of combining a head with its argument, type-raising and composition support transparent analyses for a wide range of phenomena, including right-node raising and long distance dependencies. Semantic composition happens in parallel with syntactic composition, which makes it attractive for generation. OpenCCG is a parsing/generation library which works by combining lexical categories for words using CCG rules and multi-modal extensions on rules (Baldridge, 2002) to produce derivations. Surface realization is the process by which logical forms are transduced to strings. OpenCCG uses a hybrid symbolic-statistical chart realizer (White, 2006) which takes logical forms as input and produces sentences by using CCG combinators to combine signs. Alternative realizations are ranked using integrated n-gram scoring. To illustrate the input to OpenCCG, consider the semantic dependency graph in Figure 1. In the graph, each node has a lexical predication (e.g. make.03) and a set of semantic features (e.g. (NUM)sg); nodes are connected via dependency relations (e.</context>
<context position="20968" citStr="Baldridge (2002)" startWordPosition="3277" endWordPosition="3278">T &gt; s/(s\np) send=PE\np/npend=PE send=PE/npend=PE nend=PE \n Figure 2: Object extraction Mary loves madly John, CEO, . np send=PE\np/npend=PE s 1end=nil\np 1\(s 1bal=+\np 1) npbal=+,end=comma sent\?send=nil &gt;B &gt; &lt;B× send=nil\np/npend=PE send=nil\np send=nil sent &gt; &lt; &lt; Figure 3: Crossing composition ensures that the end feature from the verb loves is also copied over. Thus, in example (19), the punctuation at the edge of the phrase would be percolated to the clausal root, where the sentencefinal period would block the derivation. However, in the slash modality inheritance hierarchy proposed by Baldridge (2002), the × modality inherits the properties of function application. Consequently, this category could also lead to the erroneous derivation of example (11). In such a derivation, category (21) will not require the direct object to have a balanced appositive; meanwhile, the end=nil feature on the direct object will propagate to the clausal root, where it will happily combine with the category for the full stop. Finally, having two distinct categories for the adverb would offset the advantage of multi-modal categorial grammar in dealing with word order variation, where it is possible to use one ca</context>
</contexts>
<marker>Baldridge, 2002</marker>
<rawString>Baldridge, Jason. 2002. Lexically Specified Derivational Control in Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murat Bayraktar</author>
<author>Bilge Say</author>
<author>Varol Akman</author>
</authors>
<title>An Analysis of English Punctuation: The Special Case of Comma.</title>
<date>1998</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="10692" citStr="Bayraktar et al., 1998" startWordPosition="1633" endWordPosition="1636">d=X1,mod=M/s(1)\*(s(1)/s(1)) : @m(hEMPH-INTROi+) Syntactic categories and their semantics are linked by index variables in the feature structures of categories. Index variables for semantic heads (e.g. X1) are conventionally named X plus the number of the feature structure. To support modifier modifiers, as in (2), semantic heads of modifiers are also made available through a modifier index feature, with a variable conventionally named M.1 Here, the effect of combining the comma with the phrase headed by despite is to add the hEMPH-INTROi+ feature to the despite-phrase’s semantics. Following (Bayraktar et al., 1998), this feature indicates that the comma has the discourse function of emphasizing an introductory clause or phrase. During realization, the feature triggers the look-up of the category in (2), and prevents the re-application of the category to its own output (as the feature should only be realized once). The category in (2) illustrates our approach, which is to assign to every punctuation mark (other than balancing marks) a category whose LF includes a feature or relation which represents its discourse semantic function in broad-brush terms such as emphasis, elaboration and apposition. 4.2 Ver</context>
</contexts>
<marker>Bayraktar, Say, Akman, 1998</marker>
<rawString>Bayraktar, Murat, Bilge Say, and Varol Akman. 1998. An Analysis of English Punctuation: The Special Case of Comma. International Journal of Corpus Linguistics, 3(1):33–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Boxwell</author>
<author>Michael White</author>
</authors>
<title>Projecting Propbank roles onto the CCGbank.</title>
<date>2008</date>
<booktitle>In Proc. LREC-08.</booktitle>
<note>To appear.</note>
<contexts>
<context position="8552" citStr="Boxwell and White, 2008" startWordPosition="1293" endWordPosition="1296"> syntactic features (Doran, 1998) and (Briscoe, 1994) and semantic features (White, 2006). Section 5 explains these approaches in detail, and considers a possible system of syntactic features for a multi-modal CCG grammar implementation. We show how such a system is inadequate to constrain all possible cases of overgeneration, motivating our decision to employ semantic features in our bi-directional grammar. 4 Integrating an analysis of punctuation into the grammar As our starting point, we used an XML representation of an enhanced version of the CCGbank with Propbank roles projected onto it (Boxwell and White, 2008). Contexts and constructions in which punctuation marks occur were isolated and the corpus was then restructured by inserting new categories and modified derivations using XSL transforms. In many cases this also involved modifying the gold standard derivations substantially and adding semantic representations to syntactic categories using logical form templates. Currently, the algorithm succeeds in creating logical forms for 98.01% of the sentences in the development section (Sect. 00) of the converted CCGbank, and 96.46% of the sentences in the test section (Sect. 23). Of these, 92.10% of the</context>
</contexts>
<marker>Boxwell, White, 2008</marker>
<rawString>Boxwell, Stephen and Michael White. 2008. Projecting Propbank roles onto the CCGbank. In Proc. LREC-08. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
</authors>
<title>Parsing (with) punctuation.</title>
<date>1994</date>
<tech>Technical report,</tech>
<location>Xerox, Grenoble, France.</location>
<contexts>
<context position="1420" citStr="Briscoe (1994)" startWordPosition="202" endWordPosition="203">neration, we propose a rule-based filter which bars illicit sequences of punctuation and cases of improperly unbalanced apposition. Using the OpenCCG toolkit, we demonstrate that our punctuation-augmented grammar yields substantial increases in surface realization coverage and quality, helping to achieve state-of-the-art BLEU scores. 1 Introduction In his pioneering monograph, Nunberg (1990) argues that punctuation is a systematic module of the grammar of written text and is governed by principles and constraints like other sub-systems such as syntax or phonology. Since then, others including Briscoe (1994) and Doran (1998) have explored ways of including rules and representations for punctuation marks in broad coverage grammars. In © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. computational systems, punctuation provides disambiguation cues which can help parsers arrive at the correct parse. From a natural language generation standpoint, text without punctuation can be difficult to comprehend, or even misleading. In this paper, we describe a more precise analysis of</context>
<context position="7981" citStr="Briscoe, 1994" startWordPosition="1203" endWordPosition="1204">Arg0&gt; &lt;GenRel&gt; h1 &lt;Arg1&gt; want.01 a1 a W1 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;Arg1&gt; h3 he M1 make.03 &lt;Arg0&gt; 18 sentential complements would be generated with a comma preceding them. Also, the result of the above function application rule could act as its own argument, producing a string of commas. More generally, binary rules miss out on many linguistic generalizations, such as the presence of mandatory balancing marks in sentence-medial comma or dash adjuncts. The literature discusses various means to address the issue of overgeneration: absorption rules (Nunberg, 1990), syntactic features (Doran, 1998) and (Briscoe, 1994) and semantic features (White, 2006). Section 5 explains these approaches in detail, and considers a possible system of syntactic features for a multi-modal CCG grammar implementation. We show how such a system is inadequate to constrain all possible cases of overgeneration, motivating our decision to employ semantic features in our bi-directional grammar. 4 Integrating an analysis of punctuation into the grammar As our starting point, we used an XML representation of an enhanced version of the CCGbank with Propbank roles projected onto it (Boxwell and White, 2008). Contexts and constructions </context>
<context position="14612" citStr="Briscoe (1994)" startWordPosition="2258" endWordPosition="2259">nominal modifier. For balanced appositives, the comma selects the appositive NP and the balancing comma to form a nominal modifier (examples are given in the next section). 5 Constraining overgeneration in bi-directional grammars A complex issue that arises in the design of bidirectional grammars is ensuring the proper presentation of punctuation. Among other things, this involves the task of ensuring the correct realization of commas introducing noun phrase appositives— in our case, choosing when to use (5a) vs. (5b). In this section, we consider and ultimately reject a solution that follows Briscoe (1994) in using syntactic features. As an alternative, interim solution, we then describe a rule-based filter which bars illicit punctuation sequences and improperly unbalanced apposition. The paradigm below helps illustrate the issues: (6) John, CEO of ABC, loves Mary. (7) * John, CEO of ABC loves Mary. (8) Mary loves John, CEO of ABC. (9) * Mary loves John, CEO of ABC,. (10) Mary loves John, CEO of ABC, madly. (11) * Mary loves John, CEO of ABC madly. 5.1 Absorption vs. syntactic features Nunberg (1990) argues that text adjuncts introduced by punctuation marks have an underlying representation whe</context>
<context position="16439" citStr="Briscoe (1994)" startWordPosition="2553" endWordPosition="2554">hy, which ranks commas lower than dashes, semi-colons, colons and periods. As White (1995) observes, from a generation-only perspective, it makes sense to generate text adjuncts which are always balanced and post-process the output to delete lower ranked points, as absorption uses relatively simple rules that operate independently of 20 the hierarchy of the constituents. However, using this approach for parsing would involve a preprocessing step which inserts commas into possible edges of possible constituents, as described in (Forst and Kaplan, 2006). To avoid this considerable complication, Briscoe (1994) has argued for developing declarative approaches involving syntactic features, with no deletions or insertions of punctuation marks. 5.2 Features for punctuation in CCG? Unfortunately, the feature-based approach appears to be inadequate for dealing with the class of examples presented above in CCG. This approach involves the incorporation of syntactic features for punctuation into atomic categories so that certain combinations are blocked. To ensure proper appositive balancing sentence finally, the rightmost element in the sentence should transmit a relevant feature to the clause level, which</context>
</contexts>
<marker>Briscoe, 1994</marker>
<rawString>Briscoe, Ted. 1994. Parsing (with) punctuation. Technical report, Xerox, Grenoble, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine Doran</author>
</authors>
<title>Incorporating Punctuation into the Sentence Grammar: A Lexicalized Tree Adjoining Grammar Perspective.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1437" citStr="Doran (1998)" startWordPosition="205" endWordPosition="206">e a rule-based filter which bars illicit sequences of punctuation and cases of improperly unbalanced apposition. Using the OpenCCG toolkit, we demonstrate that our punctuation-augmented grammar yields substantial increases in surface realization coverage and quality, helping to achieve state-of-the-art BLEU scores. 1 Introduction In his pioneering monograph, Nunberg (1990) argues that punctuation is a systematic module of the grammar of written text and is governed by principles and constraints like other sub-systems such as syntax or phonology. Since then, others including Briscoe (1994) and Doran (1998) have explored ways of including rules and representations for punctuation marks in broad coverage grammars. In © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. computational systems, punctuation provides disambiguation cues which can help parsers arrive at the correct parse. From a natural language generation standpoint, text without punctuation can be difficult to comprehend, or even misleading. In this paper, we describe a more precise analysis of punctuation for </context>
<context position="7961" citStr="Doran, 1998" startWordPosition="1200" endWordPosition="1201">e.03 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;GenRel&gt; h1 &lt;Arg1&gt; want.01 a1 a W1 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;Arg1&gt; h3 he M1 make.03 &lt;Arg0&gt; 18 sentential complements would be generated with a comma preceding them. Also, the result of the above function application rule could act as its own argument, producing a string of commas. More generally, binary rules miss out on many linguistic generalizations, such as the presence of mandatory balancing marks in sentence-medial comma or dash adjuncts. The literature discusses various means to address the issue of overgeneration: absorption rules (Nunberg, 1990), syntactic features (Doran, 1998) and (Briscoe, 1994) and semantic features (White, 2006). Section 5 explains these approaches in detail, and considers a possible system of syntactic features for a multi-modal CCG grammar implementation. We show how such a system is inadequate to constrain all possible cases of overgeneration, motivating our decision to employ semantic features in our bi-directional grammar. 4 Integrating an analysis of punctuation into the grammar As our starting point, we used an XML representation of an enhanced version of the CCGbank with Propbank roles projected onto it (Boxwell and White, 2008). Context</context>
<context position="12745" citStr="Doran (1998)" startWordPosition="1969" endWordPosition="1970">hen the phrase follows the missing sentential complement. The comma category in (4) selects for this category and a balancing comma and then converts it to a pre-sentential modifier, s(2)/s(2). Semantically, an elaboration relation is added between the main clause and the reported speech phrase. Category (4) overgenerates to some extent in that it will allow a comma at the beginning of the sentence. To prevent this, an alternative would be to make the comma explicitly select for lexical material to its left (in this case for the category of Neverthless). Another possibility would be to follow Doran (1998) in analyzing the above construction by using the verb itself to select for the comma. However, since our method involves changing the gold standard derivations, and since making the verb select extra commas or having the comma select leftward material would entail substantial further changes to the derivations, we have opted to go with (4), balancing adequacy and convenience. 4.3 NP appositives Neither the Penn Tree Bank nor the CCGbank distinguishes between NP appositives and NP conjunctions. We wrote a set of simple heuristic rules to enforce this distinction, which is vital to generation. </context>
</contexts>
<marker>Doran, 1998</marker>
<rawString>Doran, Christine. 1998. Incorporating Punctuation into the Sentence Grammar: A Lexicalized Tree Adjoining Grammar Perspective. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="2145" citStr="Hockenmaier and Steedman, 2007" startWordPosition="298" endWordPosition="301">rks in broad coverage grammars. In © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. computational systems, punctuation provides disambiguation cues which can help parsers arrive at the correct parse. From a natural language generation standpoint, text without punctuation can be difficult to comprehend, or even misleading. In this paper, we describe a more precise analysis of punctuation for a bi-directional, broad coverage English grammar extracted from the CCGbank (Hockenmaier and Steedman, 2007). In contrast to previous work, which has been primarily oriented towards parsing, our goal has been to develop an analysis of punctuation that is well suited for both parsing and surface realization. In addition, while Briscoe and Doran have simply included punctuation rules in their manually written grammars, our approach has been to revise the CCGbank itself with punctuation categories and more precise linguistic analyses, and then to extract a grammar from the enhanced corpus. In developing our analysis, we illustrate how aspects of Briscoe’s (1994) approach, which relies on syntactic feat</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Hockenmaier, Julia and Mark Steedman. 2007. CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank. Computational Linguistics, 33(3):355–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deirdre Hogan</author>
<author>Conor Cafferkey</author>
<author>Aoife Cahill</author>
<author>Josef van Genabith</author>
</authors>
<title>Exploiting multi-word units in history-based probabilistic generation.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP-CoNLL-07.</booktitle>
<marker>Hogan, Cafferkey, Cahill, van Genabith, 2007</marker>
<rawString>Hogan, Deirdre, Conor Cafferkey, Aoife Cahill, and Josef van Genabith. 2007. Exploiting multi-word units in history-based probabilistic generation. In Proc. EMNLP-CoNLL-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a generalpurpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proc. INLG-02.</booktitle>
<marker>Langkilde-Geary, 2002</marker>
<rawString>Langkilde-Geary, Irene. 2002. An empirical verification of coverage and correctness for a generalpurpose sentence generator. In Proc. INLG-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroko Nakanishi</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Probabilistic methods for disambiguation of an HPSG-based chart generator.</title>
<date>2005</date>
<booktitle>In Proc. IWPT-05.</booktitle>
<contexts>
<context position="27413" citStr="Nakanishi et al. (2005)" startWordPosition="4315" endWordPosition="4318">The main reason for this is that, without any semantic or syntactic features to constrain punctuation categories, they tend to reapply to their own output, clogging up the chart. This results in a low number of complete realizations as well as exact matches. While direct comparisons cannot really be made across grammar frameworks, as inputs vary in their semantic depth and specificity, we observe that our all-sentences BLEU score of 0.7323 exceeds that of Hogan et al. (2007), who report a top score of 0.6882 including special treatment of multi-word units (though their coverage is near 100%). Nakanishi et al. (2005) and Langkilde23 Geary (2002) report scores several points higher, though the former is limited to sentences of length 20 or less, and the latter’s coverage is much lower. 8 Conclusion Espinosa, Dominic, Michael White, and Dennis Mehay. 2008. Hypertagging: Supertagging for surface realization with CCG. In Proc. ACL-08:HLT. To appear. Forst, Martin and Ronald M. Kaplan. 2006. The importance of precise tokenizing for deep grammars. In Proc. LREC-06. We have shown that incorporating a more precise analysis of punctuation into a broad-coverage reversible grammar extracted from the CCGbank yields s</context>
</contexts>
<marker>Nakanishi, Miyao, Tsujii, 2005</marker>
<rawString>Nakanishi, Hiroko, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic methods for disambiguation of an HPSG-based chart generator. In Proc. IWPT-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
</authors>
<title>The Linguistics of Punctuation.</title>
<date>1990</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="1200" citStr="Nunberg (1990)" startWordPosition="166" endWordPosition="167">pproach, which relies on syntactic features to constrain the appearance of balanced and unbalanced commas and dashes to appropriate sentential contexts, is unattractive for CCG. As an interim solution to constrain overgeneration, we propose a rule-based filter which bars illicit sequences of punctuation and cases of improperly unbalanced apposition. Using the OpenCCG toolkit, we demonstrate that our punctuation-augmented grammar yields substantial increases in surface realization coverage and quality, helping to achieve state-of-the-art BLEU scores. 1 Introduction In his pioneering monograph, Nunberg (1990) argues that punctuation is a systematic module of the grammar of written text and is governed by principles and constraints like other sub-systems such as syntax or phonology. Since then, others including Briscoe (1994) and Doran (1998) have explored ways of including rules and representations for punctuation marks in broad coverage grammars. In © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. computational systems, punctuation provides disambiguation cues which can</context>
<context position="7927" citStr="Nunberg, 1990" startWordPosition="1196" endWordPosition="1197">&lt;Arg1&gt; P1 point h2 &lt;NUM&gt;sg &lt;Det&gt; have.03 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;GenRel&gt; h1 &lt;Arg1&gt; want.01 a1 a W1 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;Arg1&gt; h3 he M1 make.03 &lt;Arg0&gt; 18 sentential complements would be generated with a comma preceding them. Also, the result of the above function application rule could act as its own argument, producing a string of commas. More generally, binary rules miss out on many linguistic generalizations, such as the presence of mandatory balancing marks in sentence-medial comma or dash adjuncts. The literature discusses various means to address the issue of overgeneration: absorption rules (Nunberg, 1990), syntactic features (Doran, 1998) and (Briscoe, 1994) and semantic features (White, 2006). Section 5 explains these approaches in detail, and considers a possible system of syntactic features for a multi-modal CCG grammar implementation. We show how such a system is inadequate to constrain all possible cases of overgeneration, motivating our decision to employ semantic features in our bi-directional grammar. 4 Integrating an analysis of punctuation into the grammar As our starting point, we used an XML representation of an enhanced version of the CCGbank with Propbank roles projected onto it </context>
<context position="15116" citStr="Nunberg (1990)" startWordPosition="2344" endWordPosition="2345">o use (5a) vs. (5b). In this section, we consider and ultimately reject a solution that follows Briscoe (1994) in using syntactic features. As an alternative, interim solution, we then describe a rule-based filter which bars illicit punctuation sequences and improperly unbalanced apposition. The paradigm below helps illustrate the issues: (6) John, CEO of ABC, loves Mary. (7) * John, CEO of ABC loves Mary. (8) Mary loves John, CEO of ABC. (9) * Mary loves John, CEO of ABC,. (10) Mary loves John, CEO of ABC, madly. (11) * Mary loves John, CEO of ABC madly. 5.1 Absorption vs. syntactic features Nunberg (1990) argues that text adjuncts introduced by punctuation marks have an underlying representation where these adjuncts have marks on either side. They attain their surface form when a set of presentation rules are applied. This approach ensures that all sentence medial cases like (6) and (10) above are generated correctly, while unacceptable examples (7) and (11) would not be generated at all. Example (8) would at first be generated as (9): to deal with such sentences, where two points happen to coincide, Nunberg posits an implicit point which is absorbed by the adjacent point. Absorption occurs ac</context>
</contexts>
<marker>Nunberg, 1990</marker>
<rawString>Nunberg, Geoffrey. 1990. The Linguistics of Punctuation. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>S Prevost</author>
</authors>
<title>Specifying intonation from context for speech synthesis.</title>
<date>1994</date>
<journal>Speech Communication,</journal>
<pages>15--1</pages>
<marker>Steedman, Prevost, 1994</marker>
<rawString>Steedman, Mark and S. Prevost. 1994. Specifying intonation from context for speech synthesis. Speech Communication, 15(1–2):139–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The syntactic process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="4248" citStr="Steedman, 2000" startWordPosition="624" endWordPosition="625">es 17–24 Manchester, August 2008 are (1) a grammar which has lexicalized punctuation categories only for conjunction and apposition, and (2) one which has punctuation categories corresponding to the existing treatment of punctuation in the corpus. Non-blind testing results shown a nearly 9-point increase in BLEU scores compared to the best baseline model using oracle ngrams, as well as a 40% increase in exact matches. Blind testing results show a more than 5.5-point increase in BLEU scores, contributing to an allsentences score of 0.7323 on Section 23 with over 96% coverage. 2 Background CCG (Steedman, 2000) is a unification-based categorial grammar formalism which is defined almost entirely in terms of lexical entries that encode sub-categorization information as well as syntactic feature information (e.g. number and agreement). Complementing function application as the standard means of combining a head with its argument, type-raising and composition support transparent analyses for a wide range of phenomena, including right-node raising and long distance dependencies. Semantic composition happens in parallel with syntactic composition, which makes it attractive for generation. OpenCCG is a par</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000. The syntactic process. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
<author>Rajakrishnan Rajkumar</author>
<author>Scott Martin</author>
</authors>
<title>Towards broad coverage surface realization with CCG.</title>
<date>2007</date>
<booktitle>In Proc. of the Workshop on Using Corpora for NLG: Language Generation and Machine Translation (UCNLG+MT).</booktitle>
<contexts>
<context position="6271" citStr="White et al., 2007" startWordPosition="927" endWordPosition="930"> Hybrid Logic Dependency Semantics (HLDS), a dependency-based approach to representing linguistic meaning (Baldridge and Kruijff, 2002). In HLDS, each semantic head (corresponding to a node in the graph) is associated with a nominal that identifies its discourse referent, and relations between heads and their dependents Figure 1: Semantic dependency graph from the CCGbank for He has a point he wants to make [. . . ] are modeled as modal relations. 3 The need for an OpenCCG analysis of punctuation The linguistic analysis aims to make a broad coverage OpenCCG grammar extracted from the CCGbank (White et al., 2007) more precise by adding lexicalized punctuation categories to deal with constructions involving punctuation. The original CCGbank corpus does not have lexical categories for punctuation; instead, punctuation marks carry categories derived from their part of speech tags and form part of a binary rule. It is assumed that there are no dependencies between words and punctuation marks and that the result of punctuation rules is the same as the nonpunctuation category. OpenCCG does not support non-combinatory binary rules, as they can be replaced by equivalent lexicalized categories with application</context>
<context position="24050" citStr="White et al., 2007" startWordPosition="3765" endWordPosition="3768">acle n-gram scoring. This condition tests the grammar most directly, as it avoids the issue of lexical smoothing and keeps the combinatorial search manageable. A grammar extracted from the development section (Section 00) of the CCGbank was applied to the LF testbed of that section, using oracle n-gram scoring (along with FLMs, see next) to generate the sentences back. For each logical form, the generated output sentence was compared with the actual gold standard sentence corresponding to that logical form. 2. Blind testing with factored language models (FLM) and lexical smoothing, following (White et al., 2007). Blind testing naturally provides a more realistic test of performance on unseen data. Here logical forms of Sections 00 and 23 were created using grammars of those sections respectively and then a grammar was extracted from the standard training sections (02-21). This grammar was used to generate from the LFs of the development and test sections; for space reasons, we only report the results on the test section. 3. Blind testing with hypertagging. Hypertagging (Espinosa et al., 2008) is supertagging for surface realization; it improves realizer speed and coverage with large grammars by predi</context>
</contexts>
<marker>White, Rajkumar, Martin, 2007</marker>
<rawString>White, Michael, Rajakrishnan Rajkumar, and Scott Martin. 2007. Towards broad coverage surface realization with CCG. In Proc. of the Workshop on Using Corpora for NLG: Language Generation and Machine Translation (UCNLG+MT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Presenting punctuation.</title>
<date>1995</date>
<booktitle>In Proceedings of the Fifth European Workshop on Natural Language Generation,</booktitle>
<pages>107--125</pages>
<contexts>
<context position="15915" citStr="White (1995)" startWordPosition="2473" endWordPosition="2474">resentation rules are applied. This approach ensures that all sentence medial cases like (6) and (10) above are generated correctly, while unacceptable examples (7) and (11) would not be generated at all. Example (8) would at first be generated as (9): to deal with such sentences, where two points happen to coincide, Nunberg posits an implicit point which is absorbed by the adjacent point. Absorption occurs according to the “strength” of the two points. Strength is determined according to the Point Absorption Hierarchy, which ranks commas lower than dashes, semi-colons, colons and periods. As White (1995) observes, from a generation-only perspective, it makes sense to generate text adjuncts which are always balanced and post-process the output to delete lower ranked points, as absorption uses relatively simple rules that operate independently of 20 the hierarchy of the constituents. However, using this approach for parsing would involve a preprocessing step which inserts commas into possible edges of possible constituents, as described in (Forst and Kaplan, 2006). To avoid this considerable complication, Briscoe (1994) has argued for developing declarative approaches involving syntactic featur</context>
</contexts>
<marker>White, 1995</marker>
<rawString>White, Michael. 1995. Presenting punctuation. In Proceedings of the Fifth European Workshop on Natural Language Generation, pages 107–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Efficient realization of coordinate structures in combinatory categorial grammar.</title>
<date>2006</date>
<journal>Research on Language and Computation,</journal>
<volume>4</volume>
<issue>1</issue>
<pages>75</pages>
<contexts>
<context position="5176" citStr="White, 2006" startWordPosition="755" endWordPosition="756">ument, type-raising and composition support transparent analyses for a wide range of phenomena, including right-node raising and long distance dependencies. Semantic composition happens in parallel with syntactic composition, which makes it attractive for generation. OpenCCG is a parsing/generation library which works by combining lexical categories for words using CCG rules and multi-modal extensions on rules (Baldridge, 2002) to produce derivations. Surface realization is the process by which logical forms are transduced to strings. OpenCCG uses a hybrid symbolic-statistical chart realizer (White, 2006) which takes logical forms as input and produces sentences by using CCG combinators to combine signs. Alternative realizations are ranked using integrated n-gram scoring. To illustrate the input to OpenCCG, consider the semantic dependency graph in Figure 1. In the graph, each node has a lexical predication (e.g. make.03) and a set of semantic features (e.g. (NUM)sg); nodes are connected via dependency relations (e.g. (ARG0)). Internally, such graphs are represented using Hybrid Logic Dependency Semantics (HLDS), a dependency-based approach to representing linguistic meaning (Baldridge and Kru</context>
<context position="8017" citStr="White, 2006" startWordPosition="1208" endWordPosition="1209">W1 &lt;TENSE&gt;pres &lt;Arg0&gt; &lt;Arg1&gt; h3 he M1 make.03 &lt;Arg0&gt; 18 sentential complements would be generated with a comma preceding them. Also, the result of the above function application rule could act as its own argument, producing a string of commas. More generally, binary rules miss out on many linguistic generalizations, such as the presence of mandatory balancing marks in sentence-medial comma or dash adjuncts. The literature discusses various means to address the issue of overgeneration: absorption rules (Nunberg, 1990), syntactic features (Doran, 1998) and (Briscoe, 1994) and semantic features (White, 2006). Section 5 explains these approaches in detail, and considers a possible system of syntactic features for a multi-modal CCG grammar implementation. We show how such a system is inadequate to constrain all possible cases of overgeneration, motivating our decision to employ semantic features in our bi-directional grammar. 4 Integrating an analysis of punctuation into the grammar As our starting point, we used an XML representation of an enhanced version of the CCGbank with Propbank roles projected onto it (Boxwell and White, 2008). Contexts and constructions in which punctuation marks occur wer</context>
</contexts>
<marker>White, 2006</marker>
<rawString>White, Michael. 2006. Efficient realization of coordinate structures in combinatory categorial grammar. Research on Language and Computation, 4(1):39– 75.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>