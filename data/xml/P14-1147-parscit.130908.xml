<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000232">
<title confidence="0.971336">
Towards a General Rule for Identifying Deceptive Opinion Spam
</title>
<author confidence="0.99944">
Jiwei Li&apos;, Myle Ott&apos;, Claire Cardie&apos;, Eduard Hovy&apos;
</author>
<affiliation confidence="0.9995945">
&apos;Language Technology Institute, Carnegie Mellon University, Pittsburgh, P.A. 15213, USA
&apos;Department of Computer Science, Cornell University, Ithaca, N.Y., 14853, USA
</affiliation>
<email confidence="0.956696">
bdlijiwei@gmail.com, myleott@cs.cornell.edu
cardie@cs.cornell.edu, ehovy@andrew.cmu.edu
</email>
<sectionHeader confidence="0.99353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993372">
Consumers’ purchase decisions are in-
creasingly influenced by user-generated
online reviews. Accordingly, there has
been growing concern about the poten-
tial for posting deceptive opinion spam—
fictitious reviews that have been deliber-
ately written to sound authentic, to de-
ceive the reader. In this paper, we ex-
plore generalized approaches for identify-
ing online deceptive opinion spam based
on a new gold standard dataset, which is
comprised of data from three different do-
mains (i.e. Hotel, Restaurant, Doctor),
each of which contains three types of re-
views, i.e. customer generated truthful re-
views, Turker generated deceptive reviews
and employee (domain-expert) generated
deceptive reviews. Our approach tries to
capture the general difference of language
usage between deceptive and truthful re-
views, which we hope will help customers
when making purchase decisions and re-
view portal operators, such as TripAdvisor
or Yelp, investigate possible fraudulent ac-
tivity on their sites.1
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999751111111111">
Consumers increasingly rely on user-generated
online reviews when making purchase deci-
sion (Cone, 2011; Ipsos, 2012). Unfortunately,
the ease of posting content to the Web, poten-
tially anonymously, creates opportunities and in-
centives for unscrupulous businesses to post de-
ceptive opinion spam—fictitious reviews that are
deliberately written to sound authentic, in order to
deceive the reader.2 Accordingly, there appears
</bodyText>
<footnote confidence="0.755818666666667">
1Dataset available by request from the first author.
2Manipulating online reviews may also have legal conse-
quences. For example, the Federal Trade Commission (FTC)
</footnote>
<bodyText confidence="0.998976189189189">
to be widespread and growing concern among
both businesses and the public about this poten-
tial abuse (Meyer, 2009; Miller, 2009; Streitfeld,
2012; Topping, 2010; Ott, 2013).
Existing approaches for spam detection are usu-
ally focused on developing supervised learning-
based algorithms to help users identify decep-
tive opinion spam, which are highly dependent
upon high-quality gold-standard labeled data (Jin-
dal and Liu, 2008; Jindal et al., 2010; Lim et al.,
2010; Wang et al., 2011; Wu et al., 2010). Stud-
ies in the literature rely on a couple of approaches
for obtaining labeled data, which usually fall into
two categories. The first relies on the judge-
ments of human annotators (Jindal et al., 2010;
Mukherjee et al., 2012). However, recent stud-
ies show that deceptive opinion spam is not eas-
ily identified by human readers (Ott et al., 2011).
An alternative approach, as introduced by Ott et
al. (2011), crowdsourced deceptive reviews using
Amazon Mechanical Turk.3 A couple of follow-up
works have been introduced based on Ott et al.’s
dataset, including estimating prevalence of decep-
tion in online reviews (Ott et al., 2012), identifica-
tion of negative deceptive opinion spam (Ott et al.,
2013), and identifying manipulated offerings (Li
et al., 2013b).
Despite the advantages of soliciting deceptive
gold-standard material from Turkers (it is easy,
large-scale, and affordable), it is unclear whether
Turkers are representative of the general popula-
tion that generate fake reviews, or in other words,
Ott et al.’s data set may correspond to only one
type of online deceptive opinion spam — fake re-
views generated by people who have never been
to offerings or experienced the entities. Specifi-
cally, according to their findings (Ott et al., 2011;
</bodyText>
<footnote confidence="0.99882375">
has updated their guidelines on the use of endorsements and
testimonials in advertising to suggest that posting deceptive
reviews may be unlawful in the United States (FTC, 2009).
3http://www.mturk.com
</footnote>
<page confidence="0.835794">
1566
</page>
<note confidence="0.84274">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1566–1576,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.998467106382979">
Li et al., 2013a), truthful hotel reviews encode
more spatial details, characterized by terms such
as “bathroom” and “location”, while deceptive re-
views talk about general concepts such as why or
with whom they went to the hotel. However, a
hotel can instead solicit fake reviews from their
employees or customers who possess substantial
domain knowledge to write fake reviews and en-
code more spatial details in their lies. Indeed,
cases have been reported where hotel owners bribe
guests in return for good reviews on TripAdvi-
sor4, or companies ordered employees to pretend
they were satisfied customers and write glowing
reviews of its face-lift procedure on Web sites.5
The domain knowledge possessed by domain ex-
perts enables them to craft reviews that are much
more difficult for classifiers to detect, compared to
the crowdsourced fake reviews.
Additionally, existing supervised algorithms in
the literature are usually narrowed to one spe-
cific domain and heavily rely on domain-specific
vocabulary. For example, classifiers assign high
weights to domain-specific terms such as “hotel”,
“rooms”, or even the name of the hotels such as
“Hilton” when trained on reviews on hotels. It
is unclear whether these classifiers will perform
well at detecting deception in other domains, e.g.,
Restaurant or Doctor reviews. Even in a single do-
main, e.g., Hotel, classifiers trained from reviews
of one city (e.g., Chicago) may not be effective if
directly applied to reviews from other cities (e.g.,
New York City) (Li et al., 2013b). In the exam-
ples in Table 1, we trained a linear SVM clas-
sifier on Ott’s Chicago-hotel dataset on unigram
features and tested it on a couple of different do-
mains (the details of data acquisition are illustrated
in Section 3). Good performance is obtained on
Chicago-hotel reviews (Ott et al., 2011), but not as
good on New York City ones. The performance is
reasonable in Restaurant reviews due to the many
shared properties among restaurants and hotels,
but suffers in Doctor settings.
In this paper, we try to obtain a deeper under-
standing of the general nature of deceptive opin-
ion spam. One contribution of the work presented
here is the creation of the cross-domain (i.e., Ho-
tel, Restaurant and Doctor) gold-standard dataset.
</bodyText>
<footnote confidence="0.995649">
4http://www.dailymail.co.uk/travel/article-
2013391/Tripadvisor-Hotel-owners-bribe-guests-return-
good-reviews.html
5http://www.nytimes.com/2009/07/15/
technology/internet/15lift.html?_r=0
</footnote>
<table confidence="0.99951575">
Accuracy Precision Recall F1
NYC-Hotel 0.799 0.794 0.758 0.766
Chicago-Restaurant 0.785 0.813 0.742 0.778
Doctor 0.550 0.537 0.725 0.617
</table>
<tableCaption confidence="0.999394">
Table 1: SVM performance on datasets for a clas-
</tableCaption>
<bodyText confidence="0.986351051282051">
sifier trained on Chicago hotel review based on
Unigram feature.
In contrast to existing work (Ott et al., 2011; Li et
al., 2013b), our new gold standard includes three
types of reviews: domain expert deceptive opinion
spam (Employee), crowdsourced deceptive opin-
ion spam (Turker), and truthful Customer reviews
(Customer). In addition, some of domains contain
both positive (P) and negative (N) reviews.6
To explore the general rule of deceptive opinion
spam, we extended SAGE Model (Eisenstein et
al., 2011), a bayesian generative approach that can
capture the multiple generative facets (i.e., decep-
tive vs truthful, positive vs negative, experienced
vs non-experienced, hotel vs restaurant vs doctor)
in the text collection. We find that more general
features, such as LIWC and POS, are more robust
when modeled using SAGE, compared with just
bag-of-words.
We additionally make theoretical contributions
that may shed light on a longstanding debate in the
literature about deception. For example, in con-
trast to existing findings that highlight the lack of
spatial detail in deceptive reviews (Ott et al., 2011;
Li et al., 2013b), we find that a lack of spatial de-
tail may not be a universal cue to deception, since
it does not apply to fake reviews written by domain
experts. Instead, our finding suggest that other lin-
guistic features may offer more robust cues to de-
ceptive opinion spam, such as overly highlighted
sentiment in the review or the overuse of first-
person singular pronouns.
The rest of this paper is organized as follows.
In Section 2, we briefly go over related work. We
describe the creation of our data set in Section 3
and present our model in Section 4. Experimental
results are shown in Section 5. We present anal-
ysis of general cues to deception in Section 6 and
conclude this paper in Section 7.
</bodyText>
<footnote confidence="0.9985226">
6For example, a hotel manager could hire people to write
positive reviews to increase the reputation of his own hotel
or post negative ones to degrade his competitors. Identify-
ing positive/negative opinion spam is explored in (Ott et al.,
2011; Ott et al., 2013)
</footnote>
<page confidence="0.996798">
1567
</page>
<sectionHeader confidence="0.999655" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999945727272727">
Spam has been historically studied in the contexts
of Web text (Gy¨ongyi et al., 2004; Ntoulas et al.,
2006) or email (Drucker et al., 1999). Recently
there has been increasing concern about deceptive
opinion spam (Jindal and Liu, 2008; Ott et al.,
2011; Wu et al., 2010; Mukherjee et al., 2013b;
Wang et al., 2012).
Jindal and Liu (2008) first studied the deceptive
opinion problem and trained models using features
based on the review text, reviewer, and product
to identify duplicate opinions, i.e., opinions that
appear more than once in the corpus with simi-
lar contexts. Wu et al. (2010) propose an alter-
native strategy to detect deceptive opinion spam
in the absence of a gold standard. Yoo and Gret-
zel (2009) gathered 40 truthful and 42 deceptive
hotel reviews and manually compare the linguis-
tic differences between them. Ott et al. created
a gold-standard collection by employing Turkers
to write fake reviews, and follow-up research was
based on their data (Ott et al., 2012; Ott et al.,
2013; Li et al., 2013b; Feng and Hirst, 2013). For
example, Song et al. (2012) looked into syntactic
features from Context Free Grammar parse trees
to improve the classifier performance. A step fur-
ther, Feng and Hirst (2013) make use of degree
of compatibility between the personal experiment
and a collection of reference reviews about the
same product rather than simple textual features.
In addition to exploring text or linguistic fea-
tures in deception, some existing work looks
into customers’ behavior to identify deception
(Mukherjee et al., 2013a). For example, Mukher-
jee et al. (2011; 2012) delved into group behavior
to identify group of reviewers who work collabo-
ratively to write fake reviews. Qian and Liu (2013)
identified multiple user IDs that are generated by
the same author, as these authors are more likely
to generate deceptive reviews.
In the psychological literature, researchers have
looked into possible linguistic cues to deception
(Newman et al., 2003), such as decreased spatial
detail, which is consistent with theories of reality
monitoring (Johnson and Raye, 1981), increased
negative emotion terms (Newman et al., 2003), or
the writing style difference between informative
(truthful) and imaginative (deceptive) writings in
(Rayson et al., 2001). The former typically con-
sists of more nouns, adjectives, prepositions, de-
terminers, and coordinating conjunctions, while
the latter consists of more verbs, adverbs, pro-
nouns, and pre-determiners.
SAGE (Sparse Additive Generative Model):
SAGE is an generative bayesian approach in-
troduced by Eisenstein et al. (2011), which
can be viewed as an combination of topic mod-
els (Blei et al., 2003) and generalized additive
models (Hastie and Tibshirani, 1990). Unlike
other derivatives of topic models, SAGE drops
the Dirichlet-multinomial assumption and adopts
a Laplacian prior, triggering sparsity in topic-word
distribution. The reason why SAGE is tailored for
our task is that SAGE constructs multi-faceted la-
tent variable models by simply adding together the
component vectors rather than incorporating mul-
tiple switching latent variables in multiple facets.
</bodyText>
<sectionHeader confidence="0.996431" genericHeader="method">
3 Dataset Construction
</sectionHeader>
<bodyText confidence="0.99943675">
In this section, we report our efforts to gather gold-
standard opinion spam datasets. Our datasets con-
tain the following domains, namely Hotel, Restau-
rant, and Doctor.
</bodyText>
<subsectionHeader confidence="0.996225">
3.1 Turker set, using Mechanical Turk
</subsectionHeader>
<bodyText confidence="0.994479888888889">
Crowdsourcing services such as AMT greatly fa-
cilitate large-scale data annotation and collection
efforts. Anyone with basic programming skills can
create Human Intelligence Tasks (HITs) and ac-
cess a marketplace of anonymous online workers
(Turkers) willing to complete the tasks. We bor-
rowed some rules used by Ott et al. to create their
dataset, such as restricting task to Turkers located
in the United States, and who maintain an approval
rating of at least 90%.
Hotel-Turker : We directly borrowed datasets
from Ott7 and Li.8
Restaurant-Turker : We gathered 20 positive
(P) deceptive reviews for each of 10 of the most
popular restaurants in Chicago, for a total of 200
positive deceptive restaurant reviews.
Doctor-Turker : We gathered a total number of
200 positive reviews from Turkers.
</bodyText>
<subsectionHeader confidence="0.99583">
3.2 Employee set, by domain experts
</subsectionHeader>
<bodyText confidence="0.999971">
We seek deceptive opinion spam written by people
with expert-level domain knowledge. It is not ap-
propriate to use crowdsourcing to obtain this data,
</bodyText>
<footnote confidence="0.990521666666667">
7http://myleott.com/op_spam/
8http://www.cs.cmu.edu/˜jiweil/html/
four_city.html
</footnote>
<page confidence="0.941006">
1568
</page>
<table confidence="0.99917325">
Turker Expert Customer
Hotel (P/N) 400/400 140/140 400/400
Restaurant (P/N) 200/0 120/0 200/200
Doctor (P/N) 200/0 32/0 200/0
</table>
<tableCaption confidence="0.990626">
Table 2: Statistics for our dataset.
</tableCaption>
<bodyText confidence="0.999920823529412">
so instead we solicit reviews written by employees
in each domain.
Hotel-Employee: We asked two hotel employ-
ees from each of seven hotels (14 employees to-
tal) each to write 10 deceptive positive-sentiment
reviews of their own hotel, and 10 deceptive
negative-sentiment reviews of their biggest local
competitor’s hotel. In total, we obtained 280 de-
ceptive reviews of 14 hotels, including a balanced
mix of positive- and negative-sentiment reviews.
Restaurant-Employee: We asked employees
from selected restaurants (a waiter/waitress or
cook) to each write positive-sentiment reviews of
their restaurant.
Doctor-Employee: We asked real doctors to
write positive fake reviews about themselves. In
total we obtained 32 reviews from 15 doctors.
</bodyText>
<subsectionHeader confidence="0.99968">
3.3 Customer set from Actual Customers
</subsectionHeader>
<bodyText confidence="0.9998956">
Hotel-Customer: We borrowed from Ott et al.’s
dataset.
Restaurant/Doctor-Customer: We solicited
data by matching a set of truthful reviews as Ott
et al. did in collecting truthful hotel reviews.
</bodyText>
<subsectionHeader confidence="0.918438">
3.4 Summary for Data Creation
</subsectionHeader>
<bodyText confidence="0.9999363">
Statistics for our data set is presented in Table 2.
Due to the difficulty in obtaining gold-standard
data in the literature, there is no doubt that our data
set is not perfect. Some parts are missing, some
are unbalanced, participants in the survey may not
be representative of the general population. How-
ever, as far as we know, this is the most compre-
hensive dataset for deceptive opinion spam so far,
and may to some extent shed insights on the nature
of online deception.
</bodyText>
<sectionHeader confidence="0.997657" genericHeader="method">
4 Feature-based Additive Model
</sectionHeader>
<bodyText confidence="0.985098142857143">
In this section, we briefly describe our model.
Since mathematics are not the main theme of this
paper, we omit the exact details for inference,
which can be found in (Eisenstein et al., 2011).
Before describing the model in detail, we note
the following advantages of the SAGE model, and
our reasons for using it in this paper:
1. the “additive” nature of SAGE allows a better
understanding of which features contribute
most to each type of deceptive review and
how much each such feature contributes to
the final decision jointly. If we instead use
SVM, for example, we would have to train
classifiers one by one (due to the distinct fea-
tures from different sources) to draw con-
clusions regarding the differences between
Turker vs Expert vs truthful reviews, positive
expert vs negative expert reviews, or reviews
from different domains. This would not only
become intractable, but would make the con-
clusions less clear.
</bodyText>
<listItem confidence="0.986612">
2. For cross-domain classification task, standard
machine learning approaches may suffer due
to domain-specific properties (See Section
5.2).
</listItem>
<subsectionHeader confidence="0.996704">
4.1 Model
</subsectionHeader>
<bodyText confidence="0.997552">
In SAGE, each term w is drawn from a distribution
</bodyText>
<equation confidence="0.94743925">
proportional to exp(m(w) + 77(T)(w) yd+ 77(A)(w)
zn +
77yd,zn ), where m(w) is the observed background
(I)(w)
</equation>
<bodyText confidence="0.954709">
term frequency, 77yd, 77zn and 77yd,zn denote the log
frequency deviation representing topic zn, facet
yd, and the second-order interaction part respec-
tively. Superscripts T, A and I respectively denote
the index of the topic, facet, and second-order in-
teraction. In our task, we adapt the SAGE model
as follows:
Y = {ySentiment E {positive, negative},
yDomain E {hotel, restaurant, doctor},
ySource E {employee, turker, customer}}
We model three 77’s, one for each type of y. Let
i, j, k denote the index of the different types of y,
so that each term w is drawn as follows:
</bodyText>
<equation confidence="0.989168333333334">
P(w|i, j, k) a exp(m(w) + 77(i)(w)
ySentiment
+77(j)(w)
yDomain + 77(k)(
w)tee + higher order)
ur
</equation>
<bodyText confidence="0.99980425">
where the higher order parts denote the interac-
tions between different facets.
In our approach each document-level feature f
is drawn from the following distribution:
</bodyText>
<equation confidence="0.990616833333333">
P(f|i, j, k) ∝ exp(m(f)+ η(i)(f)
ySentiment + η(j)(f)
yDomain
(1)
+ η(k)(f)
yScource + higher order)
</equation>
<page confidence="0.903611">
1569
</page>
<bodyText confidence="0.9997225">
where m(f) can be interpreted as the background
value of feature f. For each review d, the proba-
bility that it is drawn from facets with index i, j, k
is as follows:
</bodyText>
<equation confidence="0.909242666666667">
P(d|i, j, k) = P(f|i, j, k)
11 11 P(w|i, j, k) (2)
f∈d w∈d
</equation>
<bodyText confidence="0.916135">
In the training process, parameters η(w)
</bodyText>
<equation confidence="0.557353">
y and η(f)
y
</equation>
<bodyText confidence="0.99964425">
are to be learned by maximizing the posterior
distribution following the original SAGE training
procedure. For prediction, we estimate ySource for
each document given all or part of η(w)
</bodyText>
<equation confidence="0.876213">
y and η(f)
y
as follows:
ySource =
argmax P(d|y�Source, ySentiment, yDomain),
y� Source
</equation>
<bodyText confidence="0.999992875">
where we assume ySentiment and yDomain are
given for each document d. Note that we as-
sume conditional independence between features
and words given y, similar to other topic mod-
els (Blei et al., 2003). Notably, our revised SAGE
model degenerates into a model similar to Gen-
eralized Additive Model (Hastie and Tibshirani,
1990) when word features are not considered.
</bodyText>
<sectionHeader confidence="0.99952" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999957333333333">
In this section, we report our experimental results.
We first restrict experiments to the within-domain
task and see what features most characterize the
deceptive reviews, and how. We later extend it to
cross domains to explore a more general classifier
of deceptive opinion spam.
</bodyText>
<subsectionHeader confidence="0.532978">
5.1 Intra-Domain Classification
</subsectionHeader>
<bodyText confidence="0.9909457">
We explore the effect of both domain experts
and crowdsourcing workers on intra-domain de-
ception. Specifically, we reframe it as a intra-
domain multi-class classification task, where
given the labeled training data from one domain,
we learn a classifier to classify reviews accord-
ing to their source, i.e., Employee, Turker and
Customer. Since the machine learning classi-
fier is trained and tested within the same domain,
(j)(m and (i)(f) are not considered here.
</bodyText>
<subsubsectionHeader confidence="0.567122">
ηyDoain %Domain
</subsubsectionHeader>
<bodyText confidence="0.999982282051282">
We use a One-Versus-Rest (OvR) scheme, in
which we train m classifiers using SAGE, such
that each classifier fi, for i ∈ [1, m], is trained to
distinguish between class i on the one hand, and
all classes except i on the other. To make an m-
way decision, we then choose the class c with the
most confident prediction. OvR approaches have
been shown to produce state-of-art performance
compared to other multi-class approaches such as
Multinomial Naive Bayes or One-Versus-One clas-
sification scheme. We train the OvR classifier on
three sets of features, LIWC, Unigram, and POS.9
Multi-class classification results are given at Ta-
ble 3. We report both OvR performance and the
performance of three One-versus-One binary clas-
sifiers, trained to distinguish between each pair
of classes. In particular, the three-class classifier
is around 65% accurate at distinguishing between
Employee, Customer, and Turker for each of the
domains using Unigram, significantly higher than
random guess. We also observe that each of the
three One-versus-One binary classifications per-
forms significantly better than chance, suggesting
that Employee, Customer, and Turker are in fact
three different classes. In particular, the two-class
classifier is around 0.76 accurate in distinguish-
ing between Turker and Employee reviews, de-
spite both kinds of reviews being deceptive opin-
ion spam.
Best performance is achieved on Unigram fea-
tures, constantly outperforming LIWC and POS
features in both three-class and two-class settings
in the hotel domain. Similar results are observed
for restaurant and doctor domains and details are
excluded for brevity. This suggests that a universal
set of keyword-based deception cues (e.g., LIWC)
is not the best approach for Intra-Domain Classifi-
cation. Similar results were also reported in previ-
ous work (Ott et al., 2012; Ott, 2013).
</bodyText>
<subsectionHeader confidence="0.976174">
5.2 Cross-domain Classification
</subsectionHeader>
<bodyText confidence="0.999921666666667">
In this subsection, we frame our problem as a
domain adaptation task (Pan and Yang, 2010).
Again, we explore 3 feature sets: LIWC, Uni-
gram and POS. We train a classifier on hotel re-
views, and evaluate the performance on other do-
mains. For simplicity, we focus on truthful (Cus-
tomer) versus deceptive (Turker) binary classifi-
cation rather than a multi-class classification.
We report results from SAGE and SVM10 in Ta-
ble 4. We first observe that classifiers trained on
hotel reviews apply well in the restaurant domain,
which is reasonable due to the many shared prop-
</bodyText>
<footnote confidence="0.976116">
9Part-of-speech tags were assigned based on Stan-
ford Parser http://nlp.stanford.edu/software/
lex-parser.shtml
10We use SVMlight (Joachims, 1999) to train our linear
SVM classifiers
</footnote>
<page confidence="0.94474">
1570
</page>
<table confidence="0.999988">
Domain Setting Features Customer Employee Turker
A P R P R P R
Unigram 0.664 0.678 0.669 0.589 0.610 0.641 0.582
Three-Class LIWC 0.602 0.617 0.613 0.541 0.598 0.590 0.511
POS 0.517 0.532 0.669 0.481 0.479 0.482 0.416
Unigram 0.818 0.812 0.840 - - 0.820 0.809
Customer vs Turker LIWC 0.764 0.774 0.771 - - 0.723 0.749
Hotel POS 0.729 0.748 0.692 - - 0.707 0.759
Unigram 0.799 0.832 0.784 0.804 0.820 - -
Customer vs Employee LIWC 0.732 0.746 0.751 0.714 0.722 - -
POS 0.728 0.713 0.742 0.707 0.754 - -
Unigram 0.762 - - 0.786 0.806 0.826 0.794
Employee vs Turker LIWC 0.720 - - 0.728 0.726 0.698 0.739
POS 0.701 - - 0.688 0.710 0.701 0.697
Three-Class 0.647 0.692 0.725 0.625 0.648 0.686 0.702
Restaurant Customer vs Turker Unigram 0.817 0.842 0.816 - - 0.804 0.812
Customer vs Employee 0.785 0.790 0.814 0.769 0.826 - -
Employee vs Turker 0.774 - - 0.784 0.804 0.802 0.763
Doctor Customer vs Turker 0.745 0.772 0.701 - - 0.752 0.718
</table>
<tableCaption confidence="0.982981">
Table 3: Within-domain multi-class classifier performance.
</tableCaption>
<table confidence="0.999820363636364">
Model Features Domain A P R F1 Domain A P R F1
SVM Unigram Restaurant 0.785 0.813 0.742 0.778 Doctor 0.550 0.537 0.725 0.617
LIWC
POS
Restaurant 0.745 0.692 0.840 0.759 Doctor 0.521 0.512 0.965 0.669
Restaurant 0.735 0.697 0.815 0.751 Doctor 0.540 0.521 0.975 0.679
SAGE Unigram Restaurant 0.770 0.793 0.750 0.784 Doctor 0.520 0.547 0.705 0.616
LIWC
POS
Restaurant 0.742 0.728 0.749 0.738 Doctor 0.647 0.650 0.608 0.628
Restaurant 0.746 0.732 0.687 0.701 Doctor 0.634 0.623 0.682 0.651
</table>
<tableCaption confidence="0.999872">
Table 4: Classifier performance in cross-domain adaptation.
</tableCaption>
<bodyText confidence="0.999044714285715">
erties among restaurants and hotels. Among three
types of features, Unigram still performs best.
POS and LIWC features are also robust across do-
mains.
In the doctor domain, we observe that models
trained on Unigram features from the hotels do-
main do not generalize well to doctor reviews, and
the performance is a little bit better than random
guess with only 0.55 accuracy. For SVM, models
trained on POS and LIWC features achieve even
lower accuracy than Unigram. POS and LIWC
features obtain around 0.5 precision and 1.0 re-
call, indicating that all doctor reviews are classi-
fied as deceptive by the classifier. One plausible
explanation could be doctor reviews generally en-
code some type of positive-weighted (deceptive)
features more than hotel reviews and these types
of features dominate the decision making proce-
dures, leading all reviews to be classified as de-
ceptive.
Tables 5 and 6 give the top weighted LIWC and
POS features. We observe that many features are
indeed shared among doctor and hotel domains.
Notably, POS features are more robust than LIWC
as more shared features are observed. As domain
specific properties will be considered in the in-
teraction art LIWC and pOS ) of the addi-
p (ηdomain domain
</bodyText>
<table confidence="0.999281533333333">
LIWC (hotel) LIWC (doctor)
deceptive truthful deceptive truthful
i AllPct Sixletters present
family number past AllPct
pronoun hear work social
Sixletters we health shehe
see space i number
posemo dash friend time
certain human posemo we
leisure exclusive feel you
future past perceptual negemo
perceptual home leisure Period
feel otherpunct insight relativ
comma negemo comma ingest
cause dash future money
</table>
<tableCaption confidence="0.994698">
Table 5: Top weighted LIWC features for Turker
</tableCaption>
<bodyText confidence="0.884725833333333">
vs Customer in Doctor and Hotel reviews. Blue
denotes shared positive (deceptive) features and
red denotes negative (truthful) features.
tive model, SAGE achieve much better results than
SVM, and is around 0.65 accurate in the cross-
domain task.
</bodyText>
<sectionHeader confidence="0.96526" genericHeader="method">
6 General Linguistic Cues of Deceptive
Opinion Spam
</sectionHeader>
<bodyText confidence="0.998608333333333">
In this section, we examine a number of general
POS and LIWC features that may shed light on
a general rule for identifying deceptive opinion
</bodyText>
<page confidence="0.995173">
1571
</page>
<figureCaption confidence="0.9946245">
Figure 1: Visualization of the q for POS features: Horizontal axes correspond to the values q and are
NORMALIZED from the log-frequency function.
</figureCaption>
<table confidence="0.999802166666667">
POS (hotel) POS (doctor)
deceptive truthful deceptive truthful
PRP$ CD VBD CD
PRP RRB NNP VBZ
VB LRB VB VBP
TO CC TO FW
NNP NNS VBG RRB
VBG RP PRP$ LRB
MD VBN JJS RB
VBP IN JJ LS
RB EX WRB PDT
JJS VBZ PRP VBN
</table>
<tableCaption confidence="0.986093">
Table 6: Top weighted POS features for Turker vs
</tableCaption>
<bodyText confidence="0.957019928571428">
Customer in Doctor and Hotel reviews. Blue de-
notes shared positive (deceptive) features and red
denotes negative (truthful) features.
spam. Our modified SAGE model provides us
with a tailored tool for this analysis. Specifically,
each feature f is associated with a background
value mf. For each facet A, qfA, presents the facet-
specific preference value for feature f. Note that
sentiments are separated into positive and negative
dimensions, which is necessary because hotel em-
ployee authors wrote positive-sentiment reviews
when reviewing their own hotels, and negative-
sentiment reviews when reviewing their competi-
tors’ hotels.
</bodyText>
<subsectionHeader confidence="0.996473">
6.1 POS features
</subsectionHeader>
<bodyText confidence="0.999968666666667">
Early findings in the literature (Rayson et al.,
2001; Buller and Burgoon, 1996; Biber et al.,
1999) found that informative (truthful) writings
typically consist of more nouns, adjectives, prepo-
sitions, determiners, and coordinating conjunc-
tions, while imaginative (deceptive) writing con-
sist of more verbs, adverbs, pronouns, and pre-
determiners (with a few exceptions). Our find-
ings with POS features are largely in agreement
with these findings when distinguishing between
Turker and Customer reviews, but are violated in
the Employee set.
We present the eight types of POS features in
Figure 1, namely, N (Noun), JJ (Adjective), IN
(Preposition or subordinating conjunction) and DT
(Determiner), V (Verb), RB (Adverb), PRP (Pro-
nouns, both personal and possessive) and PDT
(Pre-Determiner).
From Figures 1(a)(b)(e)(f), we observe that with
the exception of PDT, the word frequency of
which is too small to draw a conclusion, Turker
and Customer reviews exhibit linguistic patterns in
agreement with previous findings in the literature,
where truthful reviews (Customer) tend to include
more N, JJ, IN and DT, while deceptive writings
tend to encode more V, RB and PRP.
However, in the case of the Employee-Positive
dataset, which is equally deceptive, most of these
rules are violated. Notably, reviews from the
Employee-Positive set did not encode fewer N, JJ
and DT terms, as expected (see Figures 1(a)(c)).
Instead, they encode even more N, JJ and DT
vocabularies than truthful reviews from the Cus-
tomer reviews. Also, fewer V and RB are found
in Employee-Positive reviews compared with Cus-
tomer reviews (see Figures 1(e)(g)).
One explanation for these observations is that
informative (truthful) writing tends to be more in-
troductory and descriptive, encoding more con-
crete details, when compared with imaginary writ-
ings. As domain experts possess considerable
knowledge of their own offerings, they highlight
</bodyText>
<page confidence="0.995932">
1572
</page>
<figureCaption confidence="0.998317">
Figure 2: Visualization of the q for LIWC features: Horizontal axes correspond to the values q and are
normalized from the log-frequency function.
</figureCaption>
<bodyText confidence="0.999987769230769">
the details and their lies may be even more in-
formative and descriptive than those generated by
real customers! This explains why Employee-
Positive contains more N, IN and DT. Meanwhile,
as domain experts are engaged more in talking
about the details, they inevitably overlook other
information, possibly leading to fewer V and RB.
For Employee-Positive reviews, shown in Fig-
ures 1(d)(h), it turns out that domain experts do
not compensate for their lack of prior experience
when writing negative reviews for competitors’ of-
ferings, as we will see again with LIWC features
in the next subsection.
</bodyText>
<subsectionHeader confidence="0.99917">
6.2 LIWC features
</subsectionHeader>
<bodyText confidence="0.998686487804878">
We explore 3 LIWC categories (from left to right
in subfigures of Figure 2): sentiment (neg emo and
pos emo), spatial detail (space), and first-person
singular pronouns (first-person).
Space: Note that spatial details are more spe-
cific in the Hotel and Restaurant domains,
which is reflected in the high positive value of
Hotel,space (see Figure 2(g)) and negative value
qdomain
ofqDoctor,space
domain (see Figure 2(h)). It illustrates how
domain-specific details can be predictive of decep-
tive text. Similarly predictive LIWC features are
home for the Hotel domain, ingest for the Restau-
rant domain, and health and body for the Doctor
domain.
In Figure 2(i)(j)(k)(l), we can easily see that
both actual customers and domain experts encode
more spatial details in their reviews (positive value
of q), which is in agreement with our expectation.
This further demonstrates that a lack of spatial de-
tails would not be a general cue for deception.
Moreover, it appears that general domain expertise
does not compensate for the lack of prior experi-
ence when writing deceptive negative reviews for
competitors’ hotels, as demonstrated by the lack
of spatial details in the negative-sentiment reviews
by employees shown in Figure 2(k).
Sentiment: According to our findings, the pres-
ence of sentiment is a general cue to deceptive
opinion spam, as observed when comparing Fig-
ure 2(b) to Figure 2(c) and (d). Participants, both
Employees and Turkers, tend to exaggerate senti-
ment, and include more sentiment-related vocabu-
laries in their lies. In other words, positive decep-
tive reviews were generally more positive and neg-
ative deceptive reviews were more negative in sen-
timent when compared with the truthful reviews
generated by actual customers. A similar pattern
can also be observed when comparing Figure 2(i)
to Figure 2(j).
</bodyText>
<page confidence="0.97842">
1573
</page>
<subsubsectionHeader confidence="0.345695">
First-Person Singular Pronouns: The litera-
</subsubsectionHeader>
<bodyText confidence="0.9999497">
ture also associates deception with decreased us-
age of first-person singular pronouns, an effect at-
tributed to psychological distancing, whereby de-
ceivers talk less about themselves due either to a
lack of personal experience, or to detach them-
selves from the lie (Newman et al., 2003; Zhou
et al., 2004; Buller et al., 1996; Knapp and Co-
maden, 1979). However, according to our find-
ings, we find the opposite to hold. Increased first
person singular is an apparent indicator of decep-
tion, when comparing Figure 2(b) to 2(c) and 2(e).
We suspect that this relates to an effect observed
in previous studies of deception, where liars inad-
vertently undermine their lies by overemphasizing
aspects of their deception that they believe reflect
credibility (Bond and DePaulo, 2006; DePaulo et
al., 2003). One interpretation for this phenomenon
would be that deceivers try to overemphasize their
physical presence because they believe that this in-
creases their credibility.
</bodyText>
<sectionHeader confidence="0.986038" genericHeader="conclusions">
7 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.99998755882353">
In this work, we have developed a multi-domain
large-scale dataset containing gold-standard de-
ceptive opinion spam. It includes reviews of Ho-
tels, Restaurants and Doctors, generated through
crowdsourcing and domain experts. We study this
data using SAGE, which enables us to make ob-
servations about the respects in which truthful and
deceptive text differs. Our model includes sev-
eral domain-independent features that shed light
on these differences, which further allows us to
formulate some general rules for recognizing de-
ceptive opinion spam.
We also acknowledge several important caveats
to this work. By soliciting fake reviews from par-
ticipants, including crowd workers and domain
experts, we have found that is possible to de-
tect fake reviews with above-chance accuracy, and
have used our models to explore several psycho-
logical theories of deception. However, it is still
very difficult to estimate the practical impact of
such methods, as it is very challenging to obtain
gold-standard data in the real world. Moreover,
by soliciting deceptive opinion spam in an arti-
ficial environment, we are endorsing the decep-
tion, which may influence the cues that we ob-
serve (Feeley and others, 1998; Frank and Ekman,
1997; Newman et al., 2003; Ott, 2013). Finally, it
may be possible to train people to tell more con-
vincing lies. Many of the characteristics regard-
ing fake review generation might be overcome by
well-trained fake review writers, which would re-
sults in opinion spam that is harder for detect. Fu-
ture work may wish to consider some of these ad-
ditional challenges.
</bodyText>
<sectionHeader confidence="0.995567" genericHeader="acknowledgments">
8 Acknowledgement
</sectionHeader>
<bodyText confidence="0.99992">
We thank Wenjie Li and Xun Wang for useful dis-
cussions and suggestions. This work was sup-
ported in part by National Science Foundation
Grant BCS-0904822, a DARPA Deft grant, as well
as a gift from Google. We also thank the ACL re-
viewers for their helpful comments and advice.
</bodyText>
<sectionHeader confidence="0.998936" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997686090909091">
Douglas Biber, Stig Johansson, Geoffrey Leech, Su-
san Conrad, Edward Finegan, and Randolph Quirk.
1999. Longman grammar of spoken and written En-
glish, volume 2. MIT Press.
David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. the Journal of machine
Learning research, 3:993–1022.
Charles Bond and Bella DePaulo. 2006. Accuracy of
deception judgments. Personality and Social Psy-
chology Review, 10(3):214–234.
David B Buller and Judee K Burgoon. 1996. Inter-
personal deception theory. Communication theory,
6(3):203–242.
David B Buller, Judee K Burgoon, Aileen Buslig, and
James Roiger. 1996. Testing interpersonal decep-
tion theory: The language of interpersonal decep-
tion. Communication theory, 6(3):268–289.
Paul-Alexandru Chirita, J¨org Diederich, and Wolfgang
Nejdl. 2005. Mailrank: using ranking for spam
detection. In Proceedings of the 14th ACM inter-
national conference on Information and knowledge
management, pages 373–380. ACM.
Cone. 2011. 2011 Online Influence Trend Tracker.
http://www.coneinc.com/negative-reviews-online-
reverse-purchase-decisions, August.
Bella DePaulo, James Lindsay, Brian Malone, Laura
Muhlenbruck, Kelly Charlton, and Harris Cooper.
2003. Cues to deception. Psychological bulletin,
129(1):74.
Harris Drucker, Donghui Wu, and Vladimir Vapnik.
1999. Support vector machines for spam catego-
rization. Neural Networks, IEEE Transactions on,
10(5):1048–1054.
</reference>
<page confidence="0.953607">
1574
</page>
<reference confidence="0.993374082568807">
Jacob Eisenstein, Amr Ahmed, and Eric P Xing. 2011.
Sparse additive generative models of text. In Pro-
ceedings of the 28th International Conference on
Machine Learning (ICML-11), pages 1041–1048.
Thomas Feeley. 1998. The behavioral correlates of
sanctioned and unsanctioned deceptive communica-
tion. Journal of Nonverbal Behavior, 22(3):189–
204.
Vanessa Feng and Graeme Hirst. 2013. Detecting de-
ceptive opinions with profile compatibility. In Pro-
ceedings of the 6th International Joint Conference
on Natural Language Processing, Nagoya, Japan,
pages 14–18.
Song Feng, Ritwik Banerjee, and Yejin Choi. 2012.
Syntactic stylometry for deception detection. In
Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics: Short
Papers-Volume 2, pages 171–175. Association for
Computational Linguistics.
Mark Frank and Paul Ekman. 1997. The ability to de-
tect deceit generalizes across different types of high-
stake lies. Journal ofpersonality and social psychol-
ogy, 72(6):1429.
Zolt´an Gy¨ongyi, Hector Garcia-Molina, and Jan Ped-
ersen. 2004. Combating web spam with trustrank.
In Proceedings of the Thirtieth international con-
ference on Very large data bases-Volume 30, pages
576–587. VLDB Endowment.
Trevor J Hastie and Robert J Tibshirani. 1990. Gener-
alized additive models, volume 43. CRC Press.
Ipsos. 2012. Socialogue: Five Stars? Thumbs Up? A+
or Just Average? http://www.ipsos-na.com/news-
polls/pressrelease.aspx?id=5929.
Nitin Jindal and Bing Liu. 2008. Opinion spam and
analysis. In Proceedings of the international con-
ference on Web search and web data mining, pages
219–230. ACM.
Nitin Jindal, Bing Liu, and Ee-Peng Lim. 2010. Find-
ing unusual review patterns using unexpected rules.
In Proceedings of the 19th ACM international con-
ference on Information and knowledge management,
pages 1549–1552. ACM.
Thorsten Joachims. 1999. Making large scale svm
learning practical.
Marcia K Johnson and Carol L Raye. 1981. Reality
monitoring. Psychological review, 88(1):67.
Mark Knapp and Mark Comaden. 1979. Telling it like
it isn’t: A review of theory and research on decep-
tive communications. Human Communication Re-
search, 5(3):270–285.
Jiwei Li, Claire Cardie, and Sujian Li. 2013a. Top-
icspam: a topic-model-based approach for spam de-
tection. In Proceedings of the 51th Annual Meeting
of the Association for Computational Linguis-tics.
Jiwei Li, Myle Ott, and Claire Cardie. 2013b. Iden-
tifying manipulated offerings on review portals. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, Seattle,
Wash, pages 18–21.
Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu,
and Hady Wirawan Lauw. 2010. Detecting prod-
uct review spammers using rating behaviors. In Pro-
ceedings of the 19th ACM international conference
on Information and knowledge management, pages
939–948. ACM.
Juan Martinez-Romo and Lourdes Araujo. 2009. Web
spam identification through language model analy-
sis. In Proceedings of the 5th International Work-
shop on Adversarial Information Retrieval on the
Web, pages 21–28. ACM.
David Meyer. 2009. Fake reviews prompt belkin apol-
ogy.
Claire Miller. 2009. Company settles case of reviews
it faked. New York Times.
Arjun Mukherjee, Bing Liu, Junhui Wang, Natalie
Glance, and Nitin Jindal. 2011. Detecting group
review spam. In Proceedings of the 20th interna-
tional conference companion on World wide web,
pages 93–94. ACM.
Arjun Mukherjee, Bing Liu, and Natalie Glance. 2012.
Spotting fake reviewer groups in consumer reviews.
In Proceedings of the 21st international conference
on World Wide Web, pages 191–200. ACM.
Arjun Mukherjee, Abhinav Kumar, Bing Liu, Junhui
Wang, Meichun Hsu, Malu Castellanos, and Riddhi-
man Ghosh. 2013a. Spotting opinion spammers us-
ing behavioral footprints. In Proceedings of the 19th
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 632–640.
ACM.
Arjun Mukherjee, Vivek Venkataraman, Bing Liu, and
Natalie Glance. 2013b. What yelp fake review fil-
ter might be doing. In Seventh International AAAI
Conference on Weblogs and Social Media.
Matthew L Newman, James W Pennebaker, Diane S
Berry, and Jane M Richards. 2003. Lying words:
Predicting deception from linguistic styles. Person-
ality and social psychology bulletin, 29(5):665–675.
Alexandros Ntoulas, Marc Najork, Mark Manasse, and
Dennis Fetterly. 2006. Detecting spam web pages
through content analysis. In Proceedings of the 15th
international conference on World Wide Web, pages
83–92. ACM.
Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T.
Hancock. 2011. Finding deceptive opinion spam
by any stretch of the imagination. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 309–319.
</reference>
<page confidence="0.784344">
1575
</page>
<reference confidence="0.999719">
Myle Ott, Claire Cardie, and Jeff Hancock. 2012. Esti-
mating the prevalence of deception in online review
communities. In Proceedings of the 21st interna-
tional conference on World Wide Web, pages 201–
210. ACM.
Myle Ott, Claire Cardie, and Jeffrey T. Hancock. 2013.
Negative deceptive opinion spam. In Proceedings of
the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Short Papers, At-
lanta, Georgia, USA, June. Association for Compu-
tational Linguistics.
Myle Ott. 2013. Computational lingustic models of
deceptive opinion spam. PHD, thesis.
Sinno Pan and Qiang Yang. 2010. A survey on transfer
learning. Knowledge and Data Engineering, IEEE
Transactions on, 22(10):1345–1359.
Tieyun Qian and Bing Liu. 2013. Identifying multiple
userids of the same author. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, Seattle, Wash, pages 18–21.
Paul Rayson, Andrew Wilson, and Geoffrey Leech.
2001. Grammatical word class variation within
the british national corpus sampler. Language and
Computers, 36(1):295–306.
David Streitfeld. 2012. For 2 a star, an online retailer
gets 5-star product reviews. New York Times., 26.
Alexandra Topping. 2010. Historian orlando figes
agrees to pay damages for fake reviews. The
Guardian., 16.
Guan Wang, Sihong Xie, Bing Liu, and Philip Yu.
2011. Review graph based online store review
spammer detection. In Data Mining (ICDM),
2011 IEEE 11th International Conference on, pages
1242–1247. IEEE.
Guan Wang, Sihong Xie, Bing Liu, and Philip Yu.
2012. Identify online store review spammers via so-
cial review graph. ACM Transactions on Intelligent
Systems and Technology (TIST), 3(4):61.
Guangyu Wu, Derek Greene, Barry Smyth, and P´adraig
Cunningham. 2010. Distortion as a validation cri-
terion in the identification of suspicious reviews. In
Proceedings of the First Workshop on Social Media
Analytics, pages 10–13. ACM.
Kyung-Hyan Yoo and Ulrike Gretzel. 2009. Com-
parison of deceptive and truthful travel reviews.
In Information and communication technologies in
tourism 2009, pages 37–47. Springer.
Lina Zhou, Judee K Burgoon, Douglas P Twitchell,
Tiantian Qin, and Jay F Nunamaker Jr. 2004. A
comparison of classification methods for predict-
ing deception in computer-mediated communica-
tion. Journal of Management Information Systems,
20(4):139–166.
</reference>
<page confidence="0.99254">
1576
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.183489">
<title confidence="0.999661">Towards a General Rule for Identifying Deceptive Opinion Spam</title>
<author confidence="0.816986">Myle Claire Eduard</author>
<address confidence="0.6357425">Technology Institute, Carnegie Mellon University, Pittsburgh, P.A. 15213, of Computer Science, Cornell University, Ithaca, N.Y., 14853,</address>
<email confidence="0.9602865">bdlijiwei@gmail.com,cardie@cs.cornell.edu,ehovy@andrew.cmu.edu</email>
<abstract confidence="0.984186423076923">Consumers’ purchase decisions are increasingly influenced by user-generated online reviews. Accordingly, there has been growing concern about the potential for posting deceptive opinion spam— fictitious reviews that have been deliberately written to sound authentic, to deceive the reader. In this paper, we explore generalized approaches for identifying online deceptive opinion spam based on a new gold standard dataset, which is comprised of data from three different domains (i.e. Hotel, Restaurant, Doctor), each of which contains three types of rei.e. generated truthful regenerated deceptive reviews (domain-expert) generated Our approach tries to capture the general difference of language usage between deceptive and truthful reviews, which we hope will help customers when making purchase decisions and review portal operators, such as TripAdvisor or Yelp, investigate possible fraudulent acon their</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
<author>Stig Johansson</author>
<author>Geoffrey Leech</author>
<author>Susan Conrad</author>
<author>Edward Finegan</author>
<author>Randolph Quirk</author>
</authors>
<title>Longman grammar of spoken and written English,</title>
<date>1999</date>
<volume>2</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="26317" citStr="Biber et al., 1999" startWordPosition="4166" endWordPosition="4169">res. spam. Our modified SAGE model provides us with a tailored tool for this analysis. Specifically, each feature f is associated with a background value mf. For each facet A, qfA, presents the facetspecific preference value for feature f. Note that sentiments are separated into positive and negative dimensions, which is necessary because hotel employee authors wrote positive-sentiment reviews when reviewing their own hotels, and negativesentiment reviews when reviewing their competitors’ hotels. 6.1 POS features Early findings in the literature (Rayson et al., 2001; Buller and Burgoon, 1996; Biber et al., 1999) found that informative (truthful) writings typically consist of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while imaginative (deceptive) writing consist of more verbs, adverbs, pronouns, and predeterminers (with a few exceptions). Our findings with POS features are largely in agreement with these findings when distinguishing between Turker and Customer reviews, but are violated in the Employee set. We present the eight types of POS features in Figure 1, namely, N (Noun), JJ (Adjective), IN (Preposition or subordinating conjunction) and DT (Determiner), V</context>
</contexts>
<marker>Biber, Johansson, Leech, Conrad, Finegan, Quirk, 1999</marker>
<rawString>Douglas Biber, Stig Johansson, Geoffrey Leech, Susan Conrad, Edward Finegan, and Randolph Quirk. 1999. Longman grammar of spoken and written English, volume 2. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="11529" citStr="Blei et al., 2003" startWordPosition="1783" endWordPosition="1786"> reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstein et al. (2011), which can be viewed as an combination of topic models (Blei et al., 2003) and generalized additive models (Hastie and Tibshirani, 1990). Unlike other derivatives of topic models, SAGE drops the Dirichlet-multinomial assumption and adopts a Laplacian prior, triggering sparsity in topic-word distribution. The reason why SAGE is tailored for our task is that SAGE constructs multi-faceted latent variable models by simply adding together the component vectors rather than incorporating multiple switching latent variables in multiple facets. 3 Dataset Construction In this section, we report our efforts to gather goldstandard opinion spam datasets. Our datasets contain the</context>
<context position="17902" citStr="Blei et al., 2003" startWordPosition="2803" endWordPosition="2806"> index i, j, k is as follows: P(d|i, j, k) = P(f|i, j, k) 11 11 P(w|i, j, k) (2) f∈d w∈d In the training process, parameters η(w) y and η(f) y are to be learned by maximizing the posterior distribution following the original SAGE training procedure. For prediction, we estimate ySource for each document given all or part of η(w) y and η(f) y as follows: ySource = argmax P(d|y�Source, ySentiment, yDomain), y� Source where we assume ySentiment and yDomain are given for each document d. Note that we assume conditional independence between features and words given y, similar to other topic models (Blei et al., 2003). Notably, our revised SAGE model degenerates into a model similar to Generalized Additive Model (Hastie and Tibshirani, 1990) when word features are not considered. 5 Experiments In this section, we report our experimental results. We first restrict experiments to the within-domain task and see what features most characterize the deceptive reviews, and how. We later extend it to cross domains to explore a more general classifier of deceptive opinion spam. 5.1 Intra-Domain Classification We explore the effect of both domain experts and crowdsourcing workers on intra-domain deception. Specifica</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Michael Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Bond</author>
<author>Bella DePaulo</author>
</authors>
<title>Accuracy of deception judgments.</title>
<date>2006</date>
<journal>Personality and Social Psychology Review,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="31542" citStr="Bond and DePaulo, 2006" startWordPosition="4989" endWordPosition="4992">ers talk less about themselves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize their physical presence because they believe that this increases their credibility. 7 Conclusion and Discussion In this work, we have developed a multi-domain large-scale dataset containing gold-standard deceptive opinion spam. It includes reviews of Hotels, Restaurants and Doctors, generated through crowdsourcing and domain experts. We study this data using SAGE, which enables us to make observations about the respects in which truthful and deceptive text differs. Our model includes se</context>
</contexts>
<marker>Bond, DePaulo, 2006</marker>
<rawString>Charles Bond and Bella DePaulo. 2006. Accuracy of deception judgments. Personality and Social Psychology Review, 10(3):214–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David B Buller</author>
<author>Judee K Burgoon</author>
</authors>
<date>1996</date>
<booktitle>Interpersonal deception theory. Communication theory,</booktitle>
<pages>6--3</pages>
<contexts>
<context position="26296" citStr="Buller and Burgoon, 1996" startWordPosition="4162" endWordPosition="4165"> negative (truthful) features. spam. Our modified SAGE model provides us with a tailored tool for this analysis. Specifically, each feature f is associated with a background value mf. For each facet A, qfA, presents the facetspecific preference value for feature f. Note that sentiments are separated into positive and negative dimensions, which is necessary because hotel employee authors wrote positive-sentiment reviews when reviewing their own hotels, and negativesentiment reviews when reviewing their competitors’ hotels. 6.1 POS features Early findings in the literature (Rayson et al., 2001; Buller and Burgoon, 1996; Biber et al., 1999) found that informative (truthful) writings typically consist of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while imaginative (deceptive) writing consist of more verbs, adverbs, pronouns, and predeterminers (with a few exceptions). Our findings with POS features are largely in agreement with these findings when distinguishing between Turker and Customer reviews, but are violated in the Employee set. We present the eight types of POS features in Figure 1, namely, N (Noun), JJ (Adjective), IN (Preposition or subordinating conjunction) a</context>
</contexts>
<marker>Buller, Burgoon, 1996</marker>
<rawString>David B Buller and Judee K Burgoon. 1996. Interpersonal deception theory. Communication theory, 6(3):203–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David B Buller</author>
<author>Judee K Burgoon</author>
<author>Aileen Buslig</author>
<author>James Roiger</author>
</authors>
<title>Testing interpersonal deception theory: The language of interpersonal deception.</title>
<date>1996</date>
<journal>Communication theory,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="31093" citStr="Buller et al., 1996" startWordPosition="4917" endWordPosition="4920">ws were generally more positive and negative deceptive reviews were more negative in sentiment when compared with the truthful reviews generated by actual customers. A similar pattern can also be observed when comparing Figure 2(i) to Figure 2(j). 1573 First-Person Singular Pronouns: The literature also associates deception with decreased usage of first-person singular pronouns, an effect attributed to psychological distancing, whereby deceivers talk less about themselves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize their physical presence because they belie</context>
</contexts>
<marker>Buller, Burgoon, Buslig, Roiger, 1996</marker>
<rawString>David B Buller, Judee K Burgoon, Aileen Buslig, and James Roiger. 1996. Testing interpersonal deception theory: The language of interpersonal deception. Communication theory, 6(3):268–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul-Alexandru Chirita</author>
<author>J¨org Diederich</author>
<author>Wolfgang Nejdl</author>
</authors>
<title>Mailrank: using ranking for spam detection.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM international conference on Information and knowledge management,</booktitle>
<pages>373--380</pages>
<publisher>ACM.</publisher>
<marker>Chirita, Diederich, Nejdl, 2005</marker>
<rawString>Paul-Alexandru Chirita, J¨org Diederich, and Wolfgang Nejdl. 2005. Mailrank: using ranking for spam detection. In Proceedings of the 14th ACM international conference on Information and knowledge management, pages 373–380. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cone</author>
</authors>
<title>Online Influence Trend Tracker.</title>
<date>2011</date>
<location>http://www.coneinc.com/negative-reviews-onlinereverse-purchase-decisions,</location>
<contexts>
<context position="1480" citStr="Cone, 2011" startWordPosition="204" endWordPosition="205">staurant, Doctor), each of which contains three types of reviews, i.e. customer generated truthful reviews, Turker generated deceptive reviews and employee (domain-expert) generated deceptive reviews. Our approach tries to capture the general difference of language usage between deceptive and truthful reviews, which we hope will help customers when making purchase decisions and review portal operators, such as TripAdvisor or Yelp, investigate possible fraudulent activity on their sites.1 1 Introduction Consumers increasingly rely on user-generated online reviews when making purchase decision (Cone, 2011; Ipsos, 2012). Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; </context>
</contexts>
<marker>Cone, 2011</marker>
<rawString>Cone. 2011. 2011 Online Influence Trend Tracker. http://www.coneinc.com/negative-reviews-onlinereverse-purchase-decisions, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bella DePaulo</author>
<author>James Lindsay</author>
<author>Brian Malone</author>
<author>Laura Muhlenbruck</author>
<author>Kelly Charlton</author>
<author>Harris Cooper</author>
</authors>
<title>Cues to deception. Psychological bulletin,</title>
<date>2003</date>
<pages>129--1</pages>
<contexts>
<context position="31565" citStr="DePaulo et al., 2003" startWordPosition="4993" endWordPosition="4996">selves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize their physical presence because they believe that this increases their credibility. 7 Conclusion and Discussion In this work, we have developed a multi-domain large-scale dataset containing gold-standard deceptive opinion spam. It includes reviews of Hotels, Restaurants and Doctors, generated through crowdsourcing and domain experts. We study this data using SAGE, which enables us to make observations about the respects in which truthful and deceptive text differs. Our model includes several domain-independen</context>
</contexts>
<marker>DePaulo, Lindsay, Malone, Muhlenbruck, Charlton, Cooper, 2003</marker>
<rawString>Bella DePaulo, James Lindsay, Brian Malone, Laura Muhlenbruck, Kelly Charlton, and Harris Cooper. 2003. Cues to deception. Psychological bulletin, 129(1):74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harris Drucker</author>
<author>Donghui Wu</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support vector machines for spam categorization. Neural Networks,</title>
<date>1999</date>
<journal>IEEE Transactions on,</journal>
<volume>10</volume>
<issue>5</issue>
<contexts>
<context position="9002" citStr="Drucker et al., 1999" startWordPosition="1383" endWordPosition="1386">set in Section 3 and present our model in Section 4. Experimental results are shown in Section 5. We present analysis of general cues to deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and</context>
</contexts>
<marker>Drucker, Wu, Vapnik, 1999</marker>
<rawString>Harris Drucker, Donghui Wu, and Vladimir Vapnik. 1999. Support vector machines for spam categorization. Neural Networks, IEEE Transactions on, 10(5):1048–1054.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>Sparse additive generative models of text.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th International Conference on Machine Learning (ICML-11),</booktitle>
<pages>1041--1048</pages>
<contexts>
<context position="7263" citStr="Eisenstein et al., 2011" startWordPosition="1087" endWordPosition="1090">o-Restaurant 0.785 0.813 0.742 0.778 Doctor 0.550 0.537 0.725 0.617 Table 1: SVM performance on datasets for a classifier trained on Chicago hotel review based on Unigram feature. In contrast to existing work (Ott et al., 2011; Li et al., 2013b), our new gold standard includes three types of reviews: domain expert deceptive opinion spam (Employee), crowdsourced deceptive opinion spam (Turker), and truthful Customer reviews (Customer). In addition, some of domains contain both positive (P) and negative (N) reviews.6 To explore the general rule of deceptive opinion spam, we extended SAGE Model (Eisenstein et al., 2011), a bayesian generative approach that can capture the multiple generative facets (i.e., deceptive vs truthful, positive vs negative, experienced vs non-experienced, hotel vs restaurant vs doctor) in the text collection. We find that more general features, such as LIWC and POS, are more robust when modeled using SAGE, compared with just bag-of-words. We additionally make theoretical contributions that may shed light on a longstanding debate in the literature about deception. For example, in contrast to existing findings that highlight the lack of spatial detail in deceptive reviews (Ott et al.,</context>
<context position="11454" citStr="Eisenstein et al. (2011)" startWordPosition="1768" endWordPosition="1771">l., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstein et al. (2011), which can be viewed as an combination of topic models (Blei et al., 2003) and generalized additive models (Hastie and Tibshirani, 1990). Unlike other derivatives of topic models, SAGE drops the Dirichlet-multinomial assumption and adopts a Laplacian prior, triggering sparsity in topic-word distribution. The reason why SAGE is tailored for our task is that SAGE constructs multi-faceted latent variable models by simply adding together the component vectors rather than incorporating multiple switching latent variables in multiple facets. 3 Dataset Construction In this section, we report our eff</context>
<context position="15158" citStr="Eisenstein et al., 2011" startWordPosition="2340" endWordPosition="2343">n obtaining gold-standard data in the literature, there is no doubt that our data set is not perfect. Some parts are missing, some are unbalanced, participants in the survey may not be representative of the general population. However, as far as we know, this is the most comprehensive dataset for deceptive opinion spam so far, and may to some extent shed insights on the nature of online deception. 4 Feature-based Additive Model In this section, we briefly describe our model. Since mathematics are not the main theme of this paper, we omit the exact details for inference, which can be found in (Eisenstein et al., 2011). Before describing the model in detail, we note the following advantages of the SAGE model, and our reasons for using it in this paper: 1. the “additive” nature of SAGE allows a better understanding of which features contribute most to each type of deceptive review and how much each such feature contributes to the final decision jointly. If we instead use SVM, for example, we would have to train classifiers one by one (due to the distinct features from different sources) to draw conclusions regarding the differences between Turker vs Expert vs truthful reviews, positive expert vs negative exp</context>
</contexts>
<marker>Eisenstein, Ahmed, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Amr Ahmed, and Eric P Xing. 2011. Sparse additive generative models of text. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 1041–1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Feeley</author>
</authors>
<title>The behavioral correlates of sanctioned and unsanctioned deceptive communication.</title>
<date>1998</date>
<journal>Journal of Nonverbal Behavior,</journal>
<volume>22</volume>
<issue>3</issue>
<pages>204</pages>
<marker>Feeley, 1998</marker>
<rawString>Thomas Feeley. 1998. The behavioral correlates of sanctioned and unsanctioned deceptive communication. Journal of Nonverbal Behavior, 22(3):189– 204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Feng</author>
<author>Graeme Hirst</author>
</authors>
<title>Detecting deceptive opinions with profile compatibility.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Natural Language Processing,</booktitle>
<pages>14--18</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="9905" citStr="Feng and Hirst, 2013" startWordPosition="1535" endWordPosition="1538"> on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group </context>
</contexts>
<marker>Feng, Hirst, 2013</marker>
<rawString>Vanessa Feng and Graeme Hirst. 2013. Detecting deceptive opinions with profile compatibility. In Proceedings of the 6th International Joint Conference on Natural Language Processing, Nagoya, Japan, pages 14–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Ritwik Banerjee</author>
<author>Yejin Choi</author>
</authors>
<title>Syntactic stylometry for deception detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2,</booktitle>
<pages>171--175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Feng, Banerjee, Choi, 2012</marker>
<rawString>Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic stylometry for deception detection. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 171–175. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Frank</author>
<author>Paul Ekman</author>
</authors>
<title>The ability to detect deceit generalizes across different types of highstake lies. Journal ofpersonality and social psychology,</title>
<date>1997</date>
<pages>72--6</pages>
<contexts>
<context position="32984" citStr="Frank and Ekman, 1997" startWordPosition="5213" endWordPosition="5216"> work. By soliciting fake reviews from participants, including crowd workers and domain experts, we have found that is possible to detect fake reviews with above-chance accuracy, and have used our models to explore several psychological theories of deception. However, it is still very difficult to estimate the practical impact of such methods, as it is very challenging to obtain gold-standard data in the real world. Moreover, by soliciting deceptive opinion spam in an artificial environment, we are endorsing the deception, which may influence the cues that we observe (Feeley and others, 1998; Frank and Ekman, 1997; Newman et al., 2003; Ott, 2013). Finally, it may be possible to train people to tell more convincing lies. Many of the characteristics regarding fake review generation might be overcome by well-trained fake review writers, which would results in opinion spam that is harder for detect. Future work may wish to consider some of these additional challenges. 8 Acknowledgement We thank Wenjie Li and Xun Wang for useful discussions and suggestions. This work was supported in part by National Science Foundation Grant BCS-0904822, a DARPA Deft grant, as well as a gift from Google. We also thank the A</context>
</contexts>
<marker>Frank, Ekman, 1997</marker>
<rawString>Mark Frank and Paul Ekman. 1997. The ability to detect deceit generalizes across different types of highstake lies. Journal ofpersonality and social psychology, 72(6):1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zolt´an Gy¨ongyi</author>
<author>Hector Garcia-Molina</author>
<author>Jan Pedersen</author>
</authors>
<title>Combating web spam with trustrank.</title>
<date>2004</date>
<booktitle>In Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,</booktitle>
<pages>576--587</pages>
<publisher>VLDB Endowment.</publisher>
<marker>Gy¨ongyi, Garcia-Molina, Pedersen, 2004</marker>
<rawString>Zolt´an Gy¨ongyi, Hector Garcia-Molina, and Jan Pedersen. 2004. Combating web spam with trustrank. In Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, pages 576–587. VLDB Endowment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor J Hastie</author>
<author>Robert J Tibshirani</author>
</authors>
<title>Generalized additive models, volume 43.</title>
<date>1990</date>
<publisher>CRC Press.</publisher>
<contexts>
<context position="11591" citStr="Hastie and Tibshirani, 1990" startWordPosition="1791" endWordPosition="1794">sed negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstein et al. (2011), which can be viewed as an combination of topic models (Blei et al., 2003) and generalized additive models (Hastie and Tibshirani, 1990). Unlike other derivatives of topic models, SAGE drops the Dirichlet-multinomial assumption and adopts a Laplacian prior, triggering sparsity in topic-word distribution. The reason why SAGE is tailored for our task is that SAGE constructs multi-faceted latent variable models by simply adding together the component vectors rather than incorporating multiple switching latent variables in multiple facets. 3 Dataset Construction In this section, we report our efforts to gather goldstandard opinion spam datasets. Our datasets contain the following domains, namely Hotel, Restaurant, and Doctor. 3.1 </context>
<context position="18028" citStr="Hastie and Tibshirani, 1990" startWordPosition="2822" endWordPosition="2825">rameters η(w) y and η(f) y are to be learned by maximizing the posterior distribution following the original SAGE training procedure. For prediction, we estimate ySource for each document given all or part of η(w) y and η(f) y as follows: ySource = argmax P(d|y�Source, ySentiment, yDomain), y� Source where we assume ySentiment and yDomain are given for each document d. Note that we assume conditional independence between features and words given y, similar to other topic models (Blei et al., 2003). Notably, our revised SAGE model degenerates into a model similar to Generalized Additive Model (Hastie and Tibshirani, 1990) when word features are not considered. 5 Experiments In this section, we report our experimental results. We first restrict experiments to the within-domain task and see what features most characterize the deceptive reviews, and how. We later extend it to cross domains to explore a more general classifier of deceptive opinion spam. 5.1 Intra-Domain Classification We explore the effect of both domain experts and crowdsourcing workers on intra-domain deception. Specifically, we reframe it as a intradomain multi-class classification task, where given the labeled training data from one domain, we</context>
</contexts>
<marker>Hastie, Tibshirani, 1990</marker>
<rawString>Trevor J Hastie and Robert J Tibshirani. 1990. Generalized additive models, volume 43. CRC Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ipsos</author>
</authors>
<title>Socialogue: Five Stars? Thumbs Up? A+ or Just Average?</title>
<date>2012</date>
<contexts>
<context position="1494" citStr="Ipsos, 2012" startWordPosition="206" endWordPosition="207">ctor), each of which contains three types of reviews, i.e. customer generated truthful reviews, Turker generated deceptive reviews and employee (domain-expert) generated deceptive reviews. Our approach tries to capture the general difference of language usage between deceptive and truthful reviews, which we hope will help customers when making purchase decisions and review portal operators, such as TripAdvisor or Yelp, investigate possible fraudulent activity on their sites.1 1 Introduction Consumers increasingly rely on user-generated online reviews when making purchase decision (Cone, 2011; Ipsos, 2012). Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; </context>
</contexts>
<marker>Ipsos, 2012</marker>
<rawString>Ipsos. 2012. Socialogue: Five Stars? Thumbs Up? A+ or Just Average? http://www.ipsos-na.com/newspolls/pressrelease.aspx?id=5929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Opinion spam and analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the international conference on Web search and web data mining,</booktitle>
<pages>219--230</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2388" citStr="Jindal and Liu, 2008" startWordPosition="334" endWordPosition="338">der.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced base</context>
<context position="9097" citStr="Jindal and Liu, 2008" startWordPosition="1397" endWordPosition="1400">. We present analysis of general cues to deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott e</context>
</contexts>
<marker>Jindal, Liu, 2008</marker>
<rawString>Nitin Jindal and Bing Liu. 2008. Opinion spam and analysis. In Proceedings of the international conference on Web search and web data mining, pages 219–230. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
<author>Ee-Peng Lim</author>
</authors>
<title>Finding unusual review patterns using unexpected rules.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management,</booktitle>
<pages>1549--1552</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2409" citStr="Jindal et al., 2010" startWordPosition="339" endWordPosition="342">re appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dat</context>
</contexts>
<marker>Jindal, Liu, Lim, 2010</marker>
<rawString>Nitin Jindal, Bing Liu, and Ee-Peng Lim. 2010. Finding unusual review patterns using unexpected rules. In Proceedings of the 19th ACM international conference on Information and knowledge management, pages 1549–1552. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large scale svm learning practical.</title>
<date>1999</date>
<contexts>
<context position="21466" citStr="Joachims, 1999" startWordPosition="3359" endWordPosition="3360">, we explore 3 feature sets: LIWC, Unigram and POS. We train a classifier on hotel reviews, and evaluate the performance on other domains. For simplicity, we focus on truthful (Customer) versus deceptive (Turker) binary classification rather than a multi-class classification. We report results from SAGE and SVM10 in Table 4. We first observe that classifiers trained on hotel reviews apply well in the restaurant domain, which is reasonable due to the many shared prop9Part-of-speech tags were assigned based on Stanford Parser http://nlp.stanford.edu/software/ lex-parser.shtml 10We use SVMlight (Joachims, 1999) to train our linear SVM classifiers 1570 Domain Setting Features Customer Employee Turker A P R P R P R Unigram 0.664 0.678 0.669 0.589 0.610 0.641 0.582 Three-Class LIWC 0.602 0.617 0.613 0.541 0.598 0.590 0.511 POS 0.517 0.532 0.669 0.481 0.479 0.482 0.416 Unigram 0.818 0.812 0.840 - - 0.820 0.809 Customer vs Turker LIWC 0.764 0.774 0.771 - - 0.723 0.749 Hotel POS 0.729 0.748 0.692 - - 0.707 0.759 Unigram 0.799 0.832 0.784 0.804 0.820 - - Customer vs Employee LIWC 0.732 0.746 0.751 0.714 0.722 - - POS 0.728 0.713 0.742 0.707 0.754 - - Unigram 0.762 - - 0.786 0.806 0.826 0.794 Employee vs Tu</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large scale svm learning practical.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcia K Johnson</author>
<author>Carol L Raye</author>
</authors>
<date>1981</date>
<booktitle>Reality monitoring. Psychological review,</booktitle>
<pages>88--1</pages>
<contexts>
<context position="10955" citStr="Johnson and Raye, 1981" startWordPosition="1698" endWordPosition="1701">work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstein et al. (2011), which can be viewed as an combination of topic models (Blei et al., 2003) and generalized additive </context>
</contexts>
<marker>Johnson, Raye, 1981</marker>
<rawString>Marcia K Johnson and Carol L Raye. 1981. Reality monitoring. Psychological review, 88(1):67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Knapp</author>
<author>Mark Comaden</author>
</authors>
<title>Telling it like it isn’t: A review of theory and research on deceptive communications.</title>
<date>1979</date>
<journal>Human Communication Research,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="31119" citStr="Knapp and Comaden, 1979" startWordPosition="4921" endWordPosition="4925">e positive and negative deceptive reviews were more negative in sentiment when compared with the truthful reviews generated by actual customers. A similar pattern can also be observed when comparing Figure 2(i) to Figure 2(j). 1573 First-Person Singular Pronouns: The literature also associates deception with decreased usage of first-person singular pronouns, an effect attributed to psychological distancing, whereby deceivers talk less about themselves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize their physical presence because they believe that this increases the</context>
</contexts>
<marker>Knapp, Comaden, 1979</marker>
<rawString>Mark Knapp and Mark Comaden. 1979. Telling it like it isn’t: A review of theory and research on deceptive communications. Human Communication Research, 5(3):270–285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Claire Cardie</author>
<author>Sujian Li</author>
</authors>
<title>Topicspam: a topic-model-based approach for spam detection.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguis-tics.</booktitle>
<contexts>
<context position="3222" citStr="Li et al., 2013" startWordPosition="474" endWordPosition="477"> on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the general population that generate fake reviews, or in other words, Ott et al.’s data set may correspond to only one type of online deceptive opinion spam — fake reviews generated by people who have never been to offerings or experienced the entities. Specifically, according to their findings (Ott et al., 2011; has updated their guidelines on the use of endorsements and testimonials in advertising to suggest that</context>
<context position="5651" citStr="Li et al., 2013" startWordPosition="851" endWordPosition="854">e are usually narrowed to one specific domain and heavily rely on domain-specific vocabulary. For example, classifiers assign high weights to domain-specific terms such as “hotel”, “rooms”, or even the name of the hotels such as “Hilton” when trained on reviews on hotels. It is unclear whether these classifiers will perform well at detecting deception in other domains, e.g., Restaurant or Doctor reviews. Even in a single domain, e.g., Hotel, classifiers trained from reviews of one city (e.g., Chicago) may not be effective if directly applied to reviews from other cities (e.g., New York City) (Li et al., 2013b). In the examples in Table 1, we trained a linear SVM classifier on Ott’s Chicago-hotel dataset on unigram features and tested it on a couple of different domains (the details of data acquisition are illustrated in Section 3). Good performance is obtained on Chicago-hotel reviews (Ott et al., 2011), but not as good on New York City ones. The performance is reasonable in Restaurant reviews due to the many shared properties among restaurants and hotels, but suffers in Doctor settings. In this paper, we try to obtain a deeper understanding of the general nature of deceptive opinion spam. One co</context>
<context position="6882" citStr="Li et al., 2013" startWordPosition="1031" endWordPosition="1034">e work presented here is the creation of the cross-domain (i.e., Hotel, Restaurant and Doctor) gold-standard dataset. 4http://www.dailymail.co.uk/travel/article2013391/Tripadvisor-Hotel-owners-bribe-guests-returngood-reviews.html 5http://www.nytimes.com/2009/07/15/ technology/internet/15lift.html?_r=0 Accuracy Precision Recall F1 NYC-Hotel 0.799 0.794 0.758 0.766 Chicago-Restaurant 0.785 0.813 0.742 0.778 Doctor 0.550 0.537 0.725 0.617 Table 1: SVM performance on datasets for a classifier trained on Chicago hotel review based on Unigram feature. In contrast to existing work (Ott et al., 2011; Li et al., 2013b), our new gold standard includes three types of reviews: domain expert deceptive opinion spam (Employee), crowdsourced deceptive opinion spam (Turker), and truthful Customer reviews (Customer). In addition, some of domains contain both positive (P) and negative (N) reviews.6 To explore the general rule of deceptive opinion spam, we extended SAGE Model (Eisenstein et al., 2011), a bayesian generative approach that can capture the multiple generative facets (i.e., deceptive vs truthful, positive vs negative, experienced vs non-experienced, hotel vs restaurant vs doctor) in the text collection.</context>
<context position="9881" citStr="Li et al., 2013" startWordPosition="1531" endWordPosition="1534">ing features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group beh</context>
</contexts>
<marker>Li, Cardie, Li, 2013</marker>
<rawString>Jiwei Li, Claire Cardie, and Sujian Li. 2013a. Topicspam: a topic-model-based approach for spam detection. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguis-tics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying manipulated offerings on review portals.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>18--21</pages>
<location>Seattle, Wash,</location>
<contexts>
<context position="3222" citStr="Li et al., 2013" startWordPosition="474" endWordPosition="477"> on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the general population that generate fake reviews, or in other words, Ott et al.’s data set may correspond to only one type of online deceptive opinion spam — fake reviews generated by people who have never been to offerings or experienced the entities. Specifically, according to their findings (Ott et al., 2011; has updated their guidelines on the use of endorsements and testimonials in advertising to suggest that</context>
<context position="5651" citStr="Li et al., 2013" startWordPosition="851" endWordPosition="854">e are usually narrowed to one specific domain and heavily rely on domain-specific vocabulary. For example, classifiers assign high weights to domain-specific terms such as “hotel”, “rooms”, or even the name of the hotels such as “Hilton” when trained on reviews on hotels. It is unclear whether these classifiers will perform well at detecting deception in other domains, e.g., Restaurant or Doctor reviews. Even in a single domain, e.g., Hotel, classifiers trained from reviews of one city (e.g., Chicago) may not be effective if directly applied to reviews from other cities (e.g., New York City) (Li et al., 2013b). In the examples in Table 1, we trained a linear SVM classifier on Ott’s Chicago-hotel dataset on unigram features and tested it on a couple of different domains (the details of data acquisition are illustrated in Section 3). Good performance is obtained on Chicago-hotel reviews (Ott et al., 2011), but not as good on New York City ones. The performance is reasonable in Restaurant reviews due to the many shared properties among restaurants and hotels, but suffers in Doctor settings. In this paper, we try to obtain a deeper understanding of the general nature of deceptive opinion spam. One co</context>
<context position="6882" citStr="Li et al., 2013" startWordPosition="1031" endWordPosition="1034">e work presented here is the creation of the cross-domain (i.e., Hotel, Restaurant and Doctor) gold-standard dataset. 4http://www.dailymail.co.uk/travel/article2013391/Tripadvisor-Hotel-owners-bribe-guests-returngood-reviews.html 5http://www.nytimes.com/2009/07/15/ technology/internet/15lift.html?_r=0 Accuracy Precision Recall F1 NYC-Hotel 0.799 0.794 0.758 0.766 Chicago-Restaurant 0.785 0.813 0.742 0.778 Doctor 0.550 0.537 0.725 0.617 Table 1: SVM performance on datasets for a classifier trained on Chicago hotel review based on Unigram feature. In contrast to existing work (Ott et al., 2011; Li et al., 2013b), our new gold standard includes three types of reviews: domain expert deceptive opinion spam (Employee), crowdsourced deceptive opinion spam (Turker), and truthful Customer reviews (Customer). In addition, some of domains contain both positive (P) and negative (N) reviews.6 To explore the general rule of deceptive opinion spam, we extended SAGE Model (Eisenstein et al., 2011), a bayesian generative approach that can capture the multiple generative facets (i.e., deceptive vs truthful, positive vs negative, experienced vs non-experienced, hotel vs restaurant vs doctor) in the text collection.</context>
<context position="9881" citStr="Li et al., 2013" startWordPosition="1531" endWordPosition="1534">ing features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group beh</context>
</contexts>
<marker>Li, Ott, Cardie, 2013</marker>
<rawString>Jiwei Li, Myle Ott, and Claire Cardie. 2013b. Identifying manipulated offerings on review portals. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Wash, pages 18–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ee-Peng Lim</author>
<author>Viet-An Nguyen</author>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
<author>Hady Wirawan Lauw</author>
</authors>
<title>Detecting product review spammers using rating behaviors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management,</booktitle>
<pages>939--948</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2427" citStr="Lim et al., 2010" startWordPosition="343" endWordPosition="346">vailable by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including es</context>
</contexts>
<marker>Lim, Nguyen, Jindal, Liu, Lauw, 2010</marker>
<rawString>Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu, and Hady Wirawan Lauw. 2010. Detecting product review spammers using rating behaviors. In Proceedings of the 19th ACM international conference on Information and knowledge management, pages 939–948. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juan Martinez-Romo</author>
<author>Lourdes Araujo</author>
</authors>
<title>Web spam identification through language model analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web,</booktitle>
<pages>21--28</pages>
<publisher>ACM.</publisher>
<marker>Martinez-Romo, Araujo, 2009</marker>
<rawString>Juan Martinez-Romo and Lourdes Araujo. 2009. Web spam identification through language model analysis. In Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web, pages 21–28. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Meyer</author>
</authors>
<title>Fake reviews prompt belkin apology.</title>
<date>2009</date>
<contexts>
<context position="2078" citStr="Meyer, 2009" startWordPosition="292" endWordPosition="293">n (Cone, 2011; Ipsos, 2012). Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee </context>
</contexts>
<marker>Meyer, 2009</marker>
<rawString>David Meyer. 2009. Fake reviews prompt belkin apology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Miller</author>
</authors>
<title>Company settles case of reviews it faked.</title>
<date>2009</date>
<location>New York Times.</location>
<contexts>
<context position="2092" citStr="Miller, 2009" startWordPosition="294" endWordPosition="295">; Ipsos, 2012). Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012).</context>
</contexts>
<marker>Miller, 2009</marker>
<rawString>Claire Miller. 2009. Company settles case of reviews it faked. New York Times.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Junhui Wang</author>
<author>Natalie Glance</author>
<author>Nitin Jindal</author>
</authors>
<title>Detecting group review spam.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference companion on World wide web,</booktitle>
<pages>93--94</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="10452" citStr="Mukherjee et al. (2011" startWordPosition="1620" endWordPosition="1624">Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between</context>
</contexts>
<marker>Mukherjee, Liu, Wang, Glance, Jindal, 2011</marker>
<rawString>Arjun Mukherjee, Bing Liu, Junhui Wang, Natalie Glance, and Nitin Jindal. 2011. Detecting group review spam. In Proceedings of the 20th international conference companion on World wide web, pages 93–94. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Natalie Glance</author>
</authors>
<title>Spotting fake reviewer groups in consumer reviews.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>191--200</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2691" citStr="Mukherjee et al., 2012" startWordPosition="390" endWordPosition="393">eyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard mate</context>
</contexts>
<marker>Mukherjee, Liu, Glance, 2012</marker>
<rawString>Arjun Mukherjee, Bing Liu, and Natalie Glance. 2012. Spotting fake reviewer groups in consumer reviews. In Proceedings of the 21st international conference on World Wide Web, pages 191–200. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Abhinav Kumar</author>
<author>Bing Liu</author>
<author>Junhui Wang</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Spotting opinion spammers using behavioral footprints.</title>
<date>2013</date>
<booktitle>In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>632--640</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9156" citStr="Mukherjee et al., 2013" startWordPosition="1409" endWordPosition="1412">tion 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turke</context>
<context position="10413" citStr="Mukherjee et al., 2013" startWordPosition="1614" endWordPosition="1617">w-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), </context>
</contexts>
<marker>Mukherjee, Kumar, Liu, Wang, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Arjun Mukherjee, Abhinav Kumar, Bing Liu, Junhui Wang, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013a. Spotting opinion spammers using behavioral footprints. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 632–640. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Vivek Venkataraman</author>
<author>Bing Liu</author>
<author>Natalie Glance</author>
</authors>
<title>What yelp fake review filter might be doing.</title>
<date>2013</date>
<booktitle>In Seventh International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="9156" citStr="Mukherjee et al., 2013" startWordPosition="1409" endWordPosition="1412">tion 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turke</context>
<context position="10413" citStr="Mukherjee et al., 2013" startWordPosition="1614" endWordPosition="1617">w-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), </context>
</contexts>
<marker>Mukherjee, Venkataraman, Liu, Glance, 2013</marker>
<rawString>Arjun Mukherjee, Vivek Venkataraman, Bing Liu, and Natalie Glance. 2013b. What yelp fake review filter might be doing. In Seventh International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew L Newman</author>
<author>James W Pennebaker</author>
<author>Diane S Berry</author>
<author>Jane M Richards</author>
</authors>
<title>Lying words: Predicting deception from linguistic styles. Personality and social psychology bulletin,</title>
<date>2003</date>
<pages>29--5</pages>
<contexts>
<context position="10839" citStr="Newman et al., 2003" startWordPosition="1681" endWordPosition="1684">r than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstei</context>
<context position="31053" citStr="Newman et al., 2003" startWordPosition="4909" endWordPosition="4912">In other words, positive deceptive reviews were generally more positive and negative deceptive reviews were more negative in sentiment when compared with the truthful reviews generated by actual customers. A similar pattern can also be observed when comparing Figure 2(i) to Figure 2(j). 1573 First-Person Singular Pronouns: The literature also associates deception with decreased usage of first-person singular pronouns, an effect attributed to psychological distancing, whereby deceivers talk less about themselves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize th</context>
<context position="33005" citStr="Newman et al., 2003" startWordPosition="5217" endWordPosition="5220">ke reviews from participants, including crowd workers and domain experts, we have found that is possible to detect fake reviews with above-chance accuracy, and have used our models to explore several psychological theories of deception. However, it is still very difficult to estimate the practical impact of such methods, as it is very challenging to obtain gold-standard data in the real world. Moreover, by soliciting deceptive opinion spam in an artificial environment, we are endorsing the deception, which may influence the cues that we observe (Feeley and others, 1998; Frank and Ekman, 1997; Newman et al., 2003; Ott, 2013). Finally, it may be possible to train people to tell more convincing lies. Many of the characteristics regarding fake review generation might be overcome by well-trained fake review writers, which would results in opinion spam that is harder for detect. Future work may wish to consider some of these additional challenges. 8 Acknowledgement We thank Wenjie Li and Xun Wang for useful discussions and suggestions. This work was supported in part by National Science Foundation Grant BCS-0904822, a DARPA Deft grant, as well as a gift from Google. We also thank the ACL reviewers for thei</context>
</contexts>
<marker>Newman, Pennebaker, Berry, Richards, 2003</marker>
<rawString>Matthew L Newman, James W Pennebaker, Diane S Berry, and Jane M Richards. 2003. Lying words: Predicting deception from linguistic styles. Personality and social psychology bulletin, 29(5):665–675.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandros Ntoulas</author>
<author>Marc Najork</author>
<author>Mark Manasse</author>
<author>Dennis Fetterly</author>
</authors>
<title>Detecting spam web pages through content analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>83--92</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="8970" citStr="Ntoulas et al., 2006" startWordPosition="1377" endWordPosition="1380">scribe the creation of our data set in Section 3 and present our model in Section 4. Experimental results are shown in Section 5. We present analysis of general cues to deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel</context>
</contexts>
<marker>Ntoulas, Najork, Manasse, Fetterly, 2006</marker>
<rawString>Alexandros Ntoulas, Marc Najork, Mark Manasse, and Dennis Fetterly. 2006. Detecting spam web pages through content analysis. In Proceedings of the 15th international conference on World Wide Web, pages 83–92. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>Finding deceptive opinion spam by any stretch of the imagination.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>309--319</pages>
<contexts>
<context position="2810" citStr="Ott et al., 2011" startWordPosition="411" endWordPosition="414">used on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the ge</context>
<context position="5952" citStr="Ott et al., 2011" startWordPosition="903" endWordPosition="906">e classifiers will perform well at detecting deception in other domains, e.g., Restaurant or Doctor reviews. Even in a single domain, e.g., Hotel, classifiers trained from reviews of one city (e.g., Chicago) may not be effective if directly applied to reviews from other cities (e.g., New York City) (Li et al., 2013b). In the examples in Table 1, we trained a linear SVM classifier on Ott’s Chicago-hotel dataset on unigram features and tested it on a couple of different domains (the details of data acquisition are illustrated in Section 3). Good performance is obtained on Chicago-hotel reviews (Ott et al., 2011), but not as good on New York City ones. The performance is reasonable in Restaurant reviews due to the many shared properties among restaurants and hotels, but suffers in Doctor settings. In this paper, we try to obtain a deeper understanding of the general nature of deceptive opinion spam. One contribution of the work presented here is the creation of the cross-domain (i.e., Hotel, Restaurant and Doctor) gold-standard dataset. 4http://www.dailymail.co.uk/travel/article2013391/Tripadvisor-Hotel-owners-bribe-guests-returngood-reviews.html 5http://www.nytimes.com/2009/07/15/ technology/internet</context>
<context position="7868" citStr="Ott et al., 2011" startWordPosition="1180" endWordPosition="1183"> al., 2011), a bayesian generative approach that can capture the multiple generative facets (i.e., deceptive vs truthful, positive vs negative, experienced vs non-experienced, hotel vs restaurant vs doctor) in the text collection. We find that more general features, such as LIWC and POS, are more robust when modeled using SAGE, compared with just bag-of-words. We additionally make theoretical contributions that may shed light on a longstanding debate in the literature about deception. For example, in contrast to existing findings that highlight the lack of spatial detail in deceptive reviews (Ott et al., 2011; Li et al., 2013b), we find that a lack of spatial detail may not be a universal cue to deception, since it does not apply to fake reviews written by domain experts. Instead, our finding suggest that other linguistic features may offer more robust cues to deceptive opinion spam, such as overly highlighted sentiment in the review or the overuse of firstperson singular pronouns. The rest of this paper is organized as follows. In Section 2, we briefly go over related work. We describe the creation of our data set in Section 3 and present our model in Section 4. Experimental results are shown in </context>
<context position="9115" citStr="Ott et al., 2011" startWordPosition="1401" endWordPosition="1404">of general cues to deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a go</context>
</contexts>
<marker>Ott, Choi, Cardie, Hancock, 2011</marker>
<rawString>Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T. Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 309–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Jeff Hancock</author>
</authors>
<title>Estimating the prevalence of deception in online review communities.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>201--210</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3096" citStr="Ott et al., 2012" startWordPosition="455" endWordPosition="458">e literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the general population that generate fake reviews, or in other words, Ott et al.’s data set may correspond to only one type of online deceptive opinion spam — fake reviews generated by people who have never been to offerings or experienced the entities. Specifically, according to their findi</context>
<context position="9846" citStr="Ott et al., 2012" startWordPosition="1523" endWordPosition="1526">pinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al.</context>
<context position="20709" citStr="Ott et al., 2012" startWordPosition="3239" endWordPosition="3242">ssifier is around 0.76 accurate in distinguishing between Turker and Employee reviews, despite both kinds of reviews being deceptive opinion spam. Best performance is achieved on Unigram features, constantly outperforming LIWC and POS features in both three-class and two-class settings in the hotel domain. Similar results are observed for restaurant and doctor domains and details are excluded for brevity. This suggests that a universal set of keyword-based deception cues (e.g., LIWC) is not the best approach for Intra-Domain Classification. Similar results were also reported in previous work (Ott et al., 2012; Ott, 2013). 5.2 Cross-domain Classification In this subsection, we frame our problem as a domain adaptation task (Pan and Yang, 2010). Again, we explore 3 feature sets: LIWC, Unigram and POS. We train a classifier on hotel reviews, and evaluate the performance on other domains. For simplicity, we focus on truthful (Customer) versus deceptive (Turker) binary classification rather than a multi-class classification. We report results from SAGE and SVM10 in Table 4. We first observe that classifiers trained on hotel reviews apply well in the restaurant domain, which is reasonable due to the many</context>
</contexts>
<marker>Ott, Cardie, Hancock, 2012</marker>
<rawString>Myle Ott, Claire Cardie, and Jeff Hancock. 2012. Estimating the prevalence of deception in online review communities. In Proceedings of the 21st international conference on World Wide Web, pages 201– 210. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>Negative deceptive opinion spam.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Short Papers,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="3166" citStr="Ott et al., 2013" startWordPosition="466" endWordPosition="469">, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in online reviews (Ott et al., 2012), identification of negative deceptive opinion spam (Ott et al., 2013), and identifying manipulated offerings (Li et al., 2013b). Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the general population that generate fake reviews, or in other words, Ott et al.’s data set may correspond to only one type of online deceptive opinion spam — fake reviews generated by people who have never been to offerings or experienced the entities. Specifically, according to their findings (Ott et al., 2011; has updated their guidelines on the use of endo</context>
<context position="8841" citStr="Ott et al., 2013" startWordPosition="1354" endWordPosition="1357">erson singular pronouns. The rest of this paper is organized as follows. In Section 2, we briefly go over related work. We describe the creation of our data set in Section 3 and present our model in Section 4. Experimental results are shown in Section 5. We present analysis of general cues to deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu </context>
</contexts>
<marker>Ott, Cardie, Hancock, 2013</marker>
<rawString>Myle Ott, Claire Cardie, and Jeffrey T. Hancock. 2013. Negative deceptive opinion spam. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Short Papers, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
</authors>
<title>Computational lingustic models of deceptive opinion spam.</title>
<date>2013</date>
<tech>PHD, thesis.</tech>
<contexts>
<context position="2137" citStr="Ott, 2013" startWordPosition="300" endWordPosition="301">ing content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive </context>
<context position="20721" citStr="Ott, 2013" startWordPosition="3243" endWordPosition="3244">0.76 accurate in distinguishing between Turker and Employee reviews, despite both kinds of reviews being deceptive opinion spam. Best performance is achieved on Unigram features, constantly outperforming LIWC and POS features in both three-class and two-class settings in the hotel domain. Similar results are observed for restaurant and doctor domains and details are excluded for brevity. This suggests that a universal set of keyword-based deception cues (e.g., LIWC) is not the best approach for Intra-Domain Classification. Similar results were also reported in previous work (Ott et al., 2012; Ott, 2013). 5.2 Cross-domain Classification In this subsection, we frame our problem as a domain adaptation task (Pan and Yang, 2010). Again, we explore 3 feature sets: LIWC, Unigram and POS. We train a classifier on hotel reviews, and evaluate the performance on other domains. For simplicity, we focus on truthful (Customer) versus deceptive (Turker) binary classification rather than a multi-class classification. We report results from SAGE and SVM10 in Table 4. We first observe that classifiers trained on hotel reviews apply well in the restaurant domain, which is reasonable due to the many shared prop</context>
<context position="33017" citStr="Ott, 2013" startWordPosition="5221" endWordPosition="5222">cipants, including crowd workers and domain experts, we have found that is possible to detect fake reviews with above-chance accuracy, and have used our models to explore several psychological theories of deception. However, it is still very difficult to estimate the practical impact of such methods, as it is very challenging to obtain gold-standard data in the real world. Moreover, by soliciting deceptive opinion spam in an artificial environment, we are endorsing the deception, which may influence the cues that we observe (Feeley and others, 1998; Frank and Ekman, 1997; Newman et al., 2003; Ott, 2013). Finally, it may be possible to train people to tell more convincing lies. Many of the characteristics regarding fake review generation might be overcome by well-trained fake review writers, which would results in opinion spam that is harder for detect. Future work may wish to consider some of these additional challenges. 8 Acknowledgement We thank Wenjie Li and Xun Wang for useful discussions and suggestions. This work was supported in part by National Science Foundation Grant BCS-0904822, a DARPA Deft grant, as well as a gift from Google. We also thank the ACL reviewers for their helpful co</context>
</contexts>
<marker>Ott, 2013</marker>
<rawString>Myle Ott. 2013. Computational lingustic models of deceptive opinion spam. PHD, thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Pan</author>
<author>Qiang Yang</author>
</authors>
<title>A survey on transfer learning.</title>
<date>2010</date>
<journal>Knowledge and Data Engineering, IEEE Transactions on,</journal>
<volume>22</volume>
<issue>10</issue>
<contexts>
<context position="20844" citStr="Pan and Yang, 2010" startWordPosition="3260" endWordPosition="3263"> opinion spam. Best performance is achieved on Unigram features, constantly outperforming LIWC and POS features in both three-class and two-class settings in the hotel domain. Similar results are observed for restaurant and doctor domains and details are excluded for brevity. This suggests that a universal set of keyword-based deception cues (e.g., LIWC) is not the best approach for Intra-Domain Classification. Similar results were also reported in previous work (Ott et al., 2012; Ott, 2013). 5.2 Cross-domain Classification In this subsection, we frame our problem as a domain adaptation task (Pan and Yang, 2010). Again, we explore 3 feature sets: LIWC, Unigram and POS. We train a classifier on hotel reviews, and evaluate the performance on other domains. For simplicity, we focus on truthful (Customer) versus deceptive (Turker) binary classification rather than a multi-class classification. We report results from SAGE and SVM10 in Table 4. We first observe that classifiers trained on hotel reviews apply well in the restaurant domain, which is reasonable due to the many shared prop9Part-of-speech tags were assigned based on Stanford Parser http://nlp.stanford.edu/software/ lex-parser.shtml 10We use SVM</context>
</contexts>
<marker>Pan, Yang, 2010</marker>
<rawString>Sinno Pan and Qiang Yang. 2010. A survey on transfer learning. Knowledge and Data Engineering, IEEE Transactions on, 22(10):1345–1359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tieyun Qian</author>
<author>Bing Liu</author>
</authors>
<title>Identifying multiple userids of the same author.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>18--21</pages>
<location>Seattle, Wash,</location>
<contexts>
<context position="10585" citStr="Qian and Liu (2013)" startWordPosition="1643" endWordPosition="1646">res from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features. In addition to exploring text or linguistic features in deception, some existing work looks into customers’ behavior to identify deception (Mukherjee et al., 2013a). For example, Mukherjee et al. (2011; 2012) delved into group behavior to identify group of reviewers who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, a</context>
</contexts>
<marker>Qian, Liu, 2013</marker>
<rawString>Tieyun Qian and Bing Liu. 2013. Identifying multiple userids of the same author. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Wash, pages 18–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Rayson</author>
<author>Andrew Wilson</author>
<author>Geoffrey Leech</author>
</authors>
<title>Grammatical word class variation within the british national corpus sampler.</title>
<date>2001</date>
<journal>Language and Computers,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="11137" citStr="Rayson et al., 2001" startWordPosition="1723" endWordPosition="1726"> who work collaboratively to write fake reviews. Qian and Liu (2013) identified multiple user IDs that are generated by the same author, as these authors are more likely to generate deceptive reviews. In the psychological literature, researchers have looked into possible linguistic cues to deception (Newman et al., 2003), such as decreased spatial detail, which is consistent with theories of reality monitoring (Johnson and Raye, 1981), increased negative emotion terms (Newman et al., 2003), or the writing style difference between informative (truthful) and imaginative (deceptive) writings in (Rayson et al., 2001). The former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs, adverbs, pronouns, and pre-determiners. SAGE (Sparse Additive Generative Model): SAGE is an generative bayesian approach introduced by Eisenstein et al. (2011), which can be viewed as an combination of topic models (Blei et al., 2003) and generalized additive models (Hastie and Tibshirani, 1990). Unlike other derivatives of topic models, SAGE drops the Dirichlet-multinomial assumption and adopts a Laplacian prior, triggering sparsity in t</context>
<context position="26270" citStr="Rayson et al., 2001" startWordPosition="4158" endWordPosition="4161">tures and red denotes negative (truthful) features. spam. Our modified SAGE model provides us with a tailored tool for this analysis. Specifically, each feature f is associated with a background value mf. For each facet A, qfA, presents the facetspecific preference value for feature f. Note that sentiments are separated into positive and negative dimensions, which is necessary because hotel employee authors wrote positive-sentiment reviews when reviewing their own hotels, and negativesentiment reviews when reviewing their competitors’ hotels. 6.1 POS features Early findings in the literature (Rayson et al., 2001; Buller and Burgoon, 1996; Biber et al., 1999) found that informative (truthful) writings typically consist of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while imaginative (deceptive) writing consist of more verbs, adverbs, pronouns, and predeterminers (with a few exceptions). Our findings with POS features are largely in agreement with these findings when distinguishing between Turker and Customer reviews, but are violated in the Employee set. We present the eight types of POS features in Figure 1, namely, N (Noun), JJ (Adjective), IN (Preposition or su</context>
</contexts>
<marker>Rayson, Wilson, Leech, 2001</marker>
<rawString>Paul Rayson, Andrew Wilson, and Geoffrey Leech. 2001. Grammatical word class variation within the british national corpus sampler. Language and Computers, 36(1):295–306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Streitfeld</author>
</authors>
<title>For 2 a star, an online retailer gets 5-star product reviews.</title>
<date>2012</date>
<location>New York Times.,</location>
<contexts>
<context position="2110" citStr="Streitfeld, 2012" startWordPosition="296" endWordPosition="297">. Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent s</context>
</contexts>
<marker>Streitfeld, 2012</marker>
<rawString>David Streitfeld. 2012. For 2 a star, an online retailer gets 5-star product reviews. New York Times., 26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Topping</author>
</authors>
<title>Historian orlando figes agrees to pay damages for fake reviews.</title>
<date>2010</date>
<journal>The Guardian.,</journal>
<volume>16</volume>
<contexts>
<context position="2125" citStr="Topping, 2010" startWordPosition="298" endWordPosition="299">he ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam—fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.2 Accordingly, there appears 1Dataset available by request from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show tha</context>
</contexts>
<marker>Topping, 2010</marker>
<rawString>Alexandra Topping. 2010. Historian orlando figes agrees to pay damages for fake reviews. The Guardian., 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guan Wang</author>
<author>Sihong Xie</author>
<author>Bing Liu</author>
<author>Philip Yu</author>
</authors>
<title>Review graph based online store review spammer detection.</title>
<date>2011</date>
<booktitle>In Data Mining (ICDM), 2011 IEEE 11th International Conference on,</booktitle>
<pages>1242--1247</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2446" citStr="Wang et al., 2011" startWordPosition="347" endWordPosition="350">t from the first author. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence</context>
</contexts>
<marker>Wang, Xie, Liu, Yu, 2011</marker>
<rawString>Guan Wang, Sihong Xie, Bing Liu, and Philip Yu. 2011. Review graph based online store review spammer detection. In Data Mining (ICDM), 2011 IEEE 11th International Conference on, pages 1242–1247. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guan Wang</author>
<author>Sihong Xie</author>
<author>Bing Liu</author>
<author>Philip Yu</author>
</authors>
<title>Identify online store review spammers via social review graph.</title>
<date>2012</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>3--4</pages>
<contexts>
<context position="9177" citStr="Wang et al., 2012" startWordPosition="1413" endWordPosition="1416">paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake revi</context>
</contexts>
<marker>Wang, Xie, Liu, Yu, 2012</marker>
<rawString>Guan Wang, Sihong Xie, Bing Liu, and Philip Yu. 2012. Identify online store review spammers via social review graph. ACM Transactions on Intelligent Systems and Technology (TIST), 3(4):61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangyu Wu</author>
<author>Derek Greene</author>
<author>Barry Smyth</author>
<author>P´adraig Cunningham</author>
</authors>
<title>Distortion as a validation criterion in the identification of suspicious reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Workshop on Social Media Analytics,</booktitle>
<pages>10--13</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2464" citStr="Wu et al., 2010" startWordPosition="351" endWordPosition="354">thor. 2Manipulating online reviews may also have legal consequences. For example, the Federal Trade Commission (FTC) to be widespread and growing concern among both businesses and the public about this potential abuse (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010; Ott, 2013). Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data (Jindal and Liu, 2008; Jindal et al., 2010; Lim et al., 2010; Wang et al., 2011; Wu et al., 2010). Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories. The first relies on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012). However, recent studies show that deceptive opinion spam is not easily identified by human readers (Ott et al., 2011). An alternative approach, as introduced by Ott et al. (2011), crowdsourced deceptive reviews using Amazon Mechanical Turk.3 A couple of follow-up works have been introduced based on Ott et al.’s dataset, including estimating prevalence of deception in o</context>
<context position="9132" citStr="Wu et al., 2010" startWordPosition="1405" endWordPosition="1408"> deception in Section 6 and conclude this paper in Section 7. 6For example, a hotel manager could hire people to write positive reviews to increase the reputation of his own hotel or post negative ones to degrade his competitors. Identifying positive/negative opinion spam is explored in (Ott et al., 2011; Ott et al., 2013) 1567 2 Related Work Spam has been historically studied in the contexts of Web text (Gy¨ongyi et al., 2004; Ntoulas et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard colle</context>
</contexts>
<marker>Wu, Greene, Smyth, Cunningham, 2010</marker>
<rawString>Guangyu Wu, Derek Greene, Barry Smyth, and P´adraig Cunningham. 2010. Distortion as a validation criterion in the identification of suspicious reviews. In Proceedings of the First Workshop on Social Media Analytics, pages 10–13. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyung-Hyan Yoo</author>
<author>Ulrike Gretzel</author>
</authors>
<title>Comparison of deceptive and truthful travel reviews. In Information and communication technologies in tourism</title>
<date>2009</date>
<pages>37--47</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="9577" citStr="Yoo and Gretzel (2009)" startWordPosition="1479" endWordPosition="1483">s et al., 2006) or email (Drucker et al., 1999). Recently there has been increasing concern about deceptive opinion spam (Jindal and Liu, 2008; Ott et al., 2011; Wu et al., 2010; Mukherjee et al., 2013b; Wang et al., 2012). Jindal and Liu (2008) first studied the deceptive opinion problem and trained models using features based on the review text, reviewer, and product to identify duplicate opinions, i.e., opinions that appear more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them. Ott et al. created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of refe</context>
</contexts>
<marker>Yoo, Gretzel, 2009</marker>
<rawString>Kyung-Hyan Yoo and Ulrike Gretzel. 2009. Comparison of deceptive and truthful travel reviews. In Information and communication technologies in tourism 2009, pages 37–47. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lina Zhou</author>
<author>Judee K Burgoon</author>
<author>Douglas P Twitchell</author>
<author>Tiantian Qin</author>
<author>Jay F Nunamaker Jr</author>
</authors>
<title>A comparison of classification methods for predicting deception in computer-mediated communication.</title>
<date>2004</date>
<journal>Journal of Management Information Systems,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="31072" citStr="Zhou et al., 2004" startWordPosition="4913" endWordPosition="4916">ive deceptive reviews were generally more positive and negative deceptive reviews were more negative in sentiment when compared with the truthful reviews generated by actual customers. A similar pattern can also be observed when comparing Figure 2(i) to Figure 2(j). 1573 First-Person Singular Pronouns: The literature also associates deception with decreased usage of first-person singular pronouns, an effect attributed to psychological distancing, whereby deceivers talk less about themselves due either to a lack of personal experience, or to detach themselves from the lie (Newman et al., 2003; Zhou et al., 2004; Buller et al., 1996; Knapp and Comaden, 1979). However, according to our findings, we find the opposite to hold. Increased first person singular is an apparent indicator of deception, when comparing Figure 2(b) to 2(c) and 2(e). We suspect that this relates to an effect observed in previous studies of deception, where liars inadvertently undermine their lies by overemphasizing aspects of their deception that they believe reflect credibility (Bond and DePaulo, 2006; DePaulo et al., 2003). One interpretation for this phenomenon would be that deceivers try to overemphasize their physical presen</context>
</contexts>
<marker>Zhou, Burgoon, Twitchell, Qin, Jr, 2004</marker>
<rawString>Lina Zhou, Judee K Burgoon, Douglas P Twitchell, Tiantian Qin, and Jay F Nunamaker Jr. 2004. A comparison of classification methods for predicting deception in computer-mediated communication. Journal of Management Information Systems, 20(4):139–166.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>