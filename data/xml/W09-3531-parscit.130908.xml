<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004290">
<title confidence="0.9974395">
Bridging Languages
by SuperSense Entity Tagging
</title>
<author confidence="0.994173">
Davide Picca and Alfio Massimiliano Gliozzo* and Simone Campora**
</author>
<affiliation confidence="0.971574">
University of Lausanne, CH 1015-Lausanne-Switzerland
*Semantic Technology Lab (STLab - ISTC - CNR), Via Nomentana 56-0016, Rome, Italy
**Ecole Polytechnique Federale de Lausanne (EPFL)
</affiliation>
<email confidence="0.994986">
davide.picca@unil.ch, alfio.gliozzo@istc.cnr.it, simone.campora@gmail.com
</email>
<sectionHeader confidence="0.993874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988620689655">
This paper explores a very basic linguis-
tic phenomenon in multilingualism: the
lexicalizations of entities are very often
identical within different languages while
concepts are usually lexicalized differ-
ently. Since entities are commonly re-
ferred to by proper names in natural lan-
guage, we measured their distribution in
the lexical overlap of the terminologies ex-
tracted from comparable corpora. Results
show that the lexical overlap is mostly
composed by unambiguous words, which
can be regarded as anchors to bridge lan-
guages: most of terms having the same
spelling refer exactly to the same entities.
Thanks to this important feature of Named
Entities, we developed a multilingual su-
per sense tagging system capable to distin-
guish between concepts and individuals.
Individuals adopted for training have been
extracted both by YAGO and by a heuristic
procedure. The general F1 of the English
tagger is over 76%, which is in line with
the state of the art on super sense tagging
while augmenting the number of classes.
Performances for Italian are slightly lower,
while ensuring a reasonable accuracy level
which is capable to show effective results
for knowledge acquisition.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999419510204082">
The Semantic Web paradigm is often required
to provide a structured view of the unstructured
information expressed in texts (Buitelaar et al.,
2005; Cimiano, 2006). Semantic technology re-
quires abundance of such kind of knowledge in
order to cover the web scale in almost any lan-
guage. Natural Language Processing (NLP) has
been adopted with the purpose of knowledge ac-
quisition, and in particular for ontology learn-
ing and information extraction. Structured infor-
mation in ontologies is often expressed by tax-
onomies of concepts, and then populated by in-
stances.
Nonetheless, automatically distinguish con-
cepts from entities in taxonomies is not an easy
task, especially as far as the problem of acquiring
such knowledge from texts is concerned (Zirn et
al., 2008; Picca and Popescu, 2007; Miller and
Hristea, 2006). First of all because such a dis-
tinction is quite vague. From a description log-
ics perspective, that is incidently widely adopted
in ontology engineering, instances are the leaves
of any taxonomy as they cannot be further sub-
categorized and populated by other instances. For
example,“Bill Clinton” is clearly an individual,
since it is instance of many concepts, such as per-
son or president, but at the same time it is a non
sense describing individuals belonging to the class
Bill Clinton.
In order to tackle this issue, we aim to provide
empirical evidence to a very basic linguistic phe-
nomenon in multilingualism, which allows the ex-
ploitation of comparable corpora for bilingual lex-
ical acquisition. It consists on the fact that the lexi-
calizations of entities is very often identical within
different languages while concepts are usually lex-
icalized differently (de Pablo et al., 2006). The
existence of this phenomenon is quite intuitive and
can be easily justified by considering entities as of-
ten referred to by means of ostensive acts (i.e. the
act of nominating objects by indicating them), per-
formed in presentia during every day life. Since
entities are usually referred to using proper names
in natural language, we measured their distribu-
tion in the lexical overlap of the terminologies ex-
tracted from comparable corpora in two different
sample languages (i.e. Italian and English).
Named Entities are instances of particular con-
cepts (such as person or location) and are referred
</bodyText>
<page confidence="0.983413">
136
</page>
<note confidence="0.9837835">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 136–142,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.998380333333333">
to by proper names. Named Entity Recognition
(NER) is a basic task in NLP that has the in-
tent of automatically recognizing Named Entities.
Incidentally, NER systems can be a useful step
for broad-coverage ontology engineering but they
have two main limitations:
</bodyText>
<listItem confidence="0.914758625">
• Traditional categories (e.g., person, location,
and organization) are too few and generic. It
is quite evident that taxonomies require more
categories than the three mentioned above.
• Even though NER systems are supposed to
recognize individuals, very often they also re-
turns common names and no clear distinction
with concepts is made.
</listItem>
<bodyText confidence="0.9989352">
A Super Sense Tagger (SST) (Ciaramita and
Johnson, 2003) is an extended NER system that
uses the wider set of categories composed by the
41 most general concepts defined by WordNet.
WordNet has been organized according to psy-
cholinguistic theories on the principles governing
lexical memory (Beckwith et al., 1991). Thus the
broadest WordNet’s categories can serve as basis
for a set of categories which exhaustively covers,
at least as a first approximation, all possible con-
cepts occurring in a sentence.
The aim of this paper is to develop and explore
the property of instances being lexicalized identi-
cally in different languages in order to produce a
SST having the following two features:
</bodyText>
<listItem confidence="0.98389475">
• Make explicit distinction between instances
and concepts.
• Analyze the terminology of different lan-
guages adopting a common category set.
</listItem>
<bodyText confidence="0.999938517241379">
Nevertheless, the first point demands to face
with the vague distinction between concepts and
individuals belonging to those concepts. So one
of the main issues explored in this paper is the au-
tomatic tagging of which categories clearly have
this distinction.
The paper is organized as follows. In Section
2 we describe the multilingual SST, an Italian ex-
tension of the English SST that we exploited in
Section 3 to show that the lexical overlap between
languages is mostly composed by unambiguous
words, which can be also regarded as anchors to
bridge the two languages. Most of terms having
the same spelling in the two languages exactly re-
fer to the same entities. We measured those oc-
currencies with respect to all different ontologi-
cal types identified by our tagging device, observ-
ing that most of the overlapped terms are proper
names of persons, organization, locations and ar-
tifact, while the remaining ontological types are
mostly lexicalized by common nouns and have a
quite empty overlap. This confirms our claim that
entities of tangible types are always lexicalized by
the same terms.
In Section 4 we extended the SuperSense Tag-
ger in order to distinguish instances from individ-
uals, while Section 5 is about evaluation. Finally
Section 6 concludes the paper proposing new di-
rections for future investigation.
</bodyText>
<sectionHeader confidence="0.961876" genericHeader="method">
2 Multilingual Supersense Tagging
</sectionHeader>
<bodyText confidence="0.999920333333333">
SuperSense Tagging is the problem to identify
terms in texts, assigning a “supersense” category
(e.g. person, act) to their senses within their
context and apply it to recognize concepts and in-
stances in large scale textual collections of texts.
An example of tagging is provided here:
</bodyText>
<figure confidence="0.4769805">
GunsB−noun.group andI−noun.group
RosesI−noun.group playsB−verb.communication
</figure>
<figureCaption confidence="0.229523">
aty they stadiumB−noun.location
</figureCaption>
<bodyText confidence="0.999932590909091">
These categories are extracted from WordNet.
WordNet (Fellbaum, 1998) defines 45 lexicogra-
pher’s categories, also called supersenses (Cia-
ramita and Johnson, 2003). They are used by lex-
icographers to provide an initial broad classifica-
tion for the lexicon entries 1.
Although simplistic in many ways, the super-
sense ontology has several attractive features for
NLP purposes. First of all, concepts are easily rec-
ognizable, however very general. Secondly, the
small number of classes makes the implementa-
tion of state of the art methods possible (e.g. se-
quence taggers) to annotate text with supersenses.
Finally, similar word senses tend to be merged to-
gether reducing ambiguity. This technology has
been also adopted for Ontology Learning (Picca et
al., 2007), as the top level WordNet supersenses
cover almost any high level ontological type of
interest in ontology design. Compared to other
semantic tagsets, supersenses have the advantage
of being designed to cover all possible open class
words. Thus, in principle there is a supersense cat-
</bodyText>
<footnote confidence="0.565936">
1We have used the WordNet version 2.0 for all the exper-
iments in the paper.
</footnote>
<page confidence="0.993239">
137
</page>
<bodyText confidence="0.99943">
egory for each word, known or novel. Addition-
ally, no distinction is made between proper and
common nouns, whereas standard NER systems
tends to be biased towards the former.
Following the procedure described in (Picca et
al., 2008), we developed a multilingual SST work-
ing on both Italian and English languages by train-
ing the same system on MultiSemcor (Bentivogli
et al., 2004), a parallel English/Italian corpus com-
posed of 116 texts which are the translation of
their corresponding English texts in SemCor. This
resource has been developed by manually trans-
lating the English texts to Italian. Then, the so
generated parallel corpus has been automatically
aligned at the Word Level. Finally, sense labels
have been automatically transferred from the En-
glish words to their Italian translations.
The sense labels adopted in the Italian part of
MultiSemCor (Bentivogli et al., 2004) have been
extracted by Multi WordNet 2. It is a multilingual
computational lexicon, conceived to be strictly
aligned with the Princeton WordNet. The avail-
able languages are Italian, Spanish, Hebrew and
Romanian. In our experiment we used the En-
glish and the Italian components. The last version
of the Italian WordNet contains around 58,000
Italian word senses and 41,500 lemmas organized
into 32,700 synsets aligned with WordNet English
synsets. The Italian synsets are created in cor-
respondence with the Princeton WordNet synsets
whenever possible, and the semantic relations are
ported from the corresponding English synsets.
This implies that the synset index structure is the
same for the two languages.
The full alignment between the English and the
Italian WordNet is guaranteed by the fact that both
resources adopts the same synset IDs to refer to
concepts. This nice feature has allowed us to in-
fer the correct super-sense for each Italian sense
by simply looking at the English structure. In this
way, we assign exactly the same ontological types
to both Italian and English terms, thus obtaining an
Italian corpus tagged by its supersenses as shown
below:
</bodyText>
<figure confidence="0.623246333333333">
Iy GunsB−noun.group andI−noun.group
RosesI−noun.group suonanoB−verb.communication
alloy stadioB−noun.location
</figure>
<footnote confidence="0.995022">
2Available at http://multi WordNet.itc.it.
</footnote>
<sectionHeader confidence="0.8857745" genericHeader="method">
3 Lexical Overlap in Comparable
Corpora
</sectionHeader>
<bodyText confidence="0.999813142857143">
Comparable corpora are collections of texts in dif-
ferent languages that regard similar topics (e.g.
a collection of news published by press agencies
in the same period). More restrictive require-
ments are expected for parallel corpora (i.e. cor-
pora composed of texts which are mutual transla-
tions), while the class of the multilingual corpora
(i.e. collection of texts expressed in different lan-
guages without any additional requirement) is the
more general. Obviously parallel corpora are also
comparable, while comparable corpora are also
multilingual.
In comparable corpora, most of the individu-
als preserve the same spelling across different lan-
guages, while most concepts are translated differ-
ently. The analysis of the acquired terms for differ-
ent ontological types shows a huge percentage of
overlapped Named Entities. For our experiments,
we assumed that the distinction between common
names and proper names reflect as well the dif-
ference between concepts and entities in a formal
ontology. Since proper names are recognized by
the PoS tagger with relatively high precision, we
interpreted occurrences of proper names in the ac-
quired terminology as an evidence for detecting
entities.
The Leipzig Corpora Collection (Quasthoff,
2006) presents corpora in different languages us-
ing the same format and comparable sources. The
corpora are identical in format and similar in size
and content. They contain randomly selected sen-
tences in the language of the corpus. For the ex-
periments reported in this paper, we used the Ital-
ian and the English part composed by 300,000
sentences. As shown in Figure 1 and in Figure
2, Named Entities are mostly concentrated into
tangible types: Groups (organizations), Locations,
Persons and Artifacts.
The results analysis is more impressive. Figure
3 shows that the lexical overlap (i.e. the subset
of terms in common between English and Italian)
is composed almost exclusively by entities (i.e.
proper nouns). Instead if we take a look at Figure
4, we can observe that concepts are generally not
shared, having an average percentage lower than
0.1%, independently of the ontological type. We
can also observe the predictable result that onto-
logical categories denoting material objects (i.e.
persons, locations and groups, artifacts) still have
</bodyText>
<page confidence="0.994073">
138
</page>
<figureCaption confidence="0.98908225">
Figure 1: Distribution of discovered entity types
in English
Figure 2: Distribution of discovered entity types
in Italian
</figureCaption>
<bodyText confidence="0.9809845">
greater percentage of shared entities.
This is in line with the common practice of
training NER on these categories. Examples of
shared terms (entities) in concrete categories are:
</bodyText>
<listItem confidence="0.9983986">
• noun.group: e.g. NATO, Boeing, NASA;
• noun.location: e.g. Canada, Austria, Hous-
ton;
• noun.person: e.g. Romano Prodi, Blair,
Kofi Annan.
</listItem>
<bodyText confidence="0.5104015">
Incidentally, exceptions can be found to our
hypothesis (i.e. some concept is also shared).
</bodyText>
<figureCaption confidence="0.999512333333333">
Figure 3: Shared Named Entities in both lan-
guages
Figure 4: Shared Concepts in both languages
</figureCaption>
<bodyText confidence="0.999704769230769">
Examples are terms belonging to the supersense
noun.object such as Radio and Computer.
Anyhow, being them ported from one language
to another, they generally do not cause problems,
since they tend to share the same meaning. In our
experiments (i.e. in the sample we manually ana-
lyzed), we did not find any false friend, suggesting
that the impact of those words is relatively small,
in spite of the fact that it is very often overempha-
sized.
Inversely, many abstract types (e.g.
noun.possession and noun.feeling) do not
share terminology at all.
</bodyText>
<sectionHeader confidence="0.958684" genericHeader="method">
4 Distinguishing entities from concepts
</sectionHeader>
<bodyText confidence="0.999815083333333">
Successively, we subdivided each category into
two sub-categories for both languages, Instance
and Concept so that now the term “president” is
tagged as noun.person Concept and the term “Bill
Clinton” as noun.person Instance. In order to au-
tomate this task and create a reliable training set,
we adopted the following strategy.
We used the concept/instances distinction pro-
vided by YAGO (Suchanek et al., 2007b). YAGO
is a huge semantic knowledge base developed by
the Max-Plack-Institute of Saarbrcken. YAGO
knows over 1.7 million entities (like persons,
organizations, cities, etc.). YAGO, exploits
Wikipedia’s info-boxes and category pages. Info-
boxes are standardized tables that contain basic in-
formation about the entity described in the article
(Suchanek et al., 2007a). For our purposes it is
fundamental that YAGO’s components are repre-
sented as entities. In our experiment we exploit
entities as proper names and we use only YAGO
entity database containing named entities.
For each term belonging to one of the concrete
categories, we check if it appears in YAGO en-
tity dataset, otherwise, if the term is not found in
</bodyText>
<page confidence="0.997885">
139
</page>
<bodyText confidence="0.988189">
YAGO, it has to satisfy all the following condi-
tions to be tagged as Instance:
</bodyText>
<listItem confidence="0.9897172">
• The part of speech of the term belongs to
one of the noun categories as “NN”, “NNS”,
“NNP” or “NNPS”.
• The first letter of the term is a capital letter.
• The term does not come after a full stop.
</listItem>
<bodyText confidence="0.9758154">
Upon a total of 12817 instances, almost 4 have
been found in YAGO, 3413 have been found using
the heuristic strategy and the rest have been classi-
fied as concepts. If we take the previous example,
the new output has now this form:
</bodyText>
<figure confidence="0.964998636363636">
• GunsB−noun.group_Instance
andI−noun.group_Instance
RosesI−noun.group_Instance
playsB−verb.communication atO theO
stadiumB−noun.location_Concept
or
• GunsB−noun.group_Instance
andI−noun.group_Instance
RosesI−noun.group_Instance
suonanoB−verb.communication alloO
stadioB−noun.location_Concept
</figure>
<bodyText confidence="0.999703533333333">
Afterwards, we trained the SST engine. It im-
plements a Hidden Markov Model, trained with
the perceptron algorithm introduced in (Collins,
2002) and it achieves a recall of 77.71% and
a precision of 76.65% . Perception sequence
learning provides an excellent trade-off accu-
racy/performance, sometimes outperforming more
complex models such as Conditional Random
Fields (Nguyen and Guo, 2007). We optimized the
required parameters by adopting a cross validation
technique. As for the settings developed by (Cia-
ramita and Johnson, 2003), the best results have
been obtained by setting 50 trials and 10 epochs to
train the perceptron algorithm. The basic feature
set used for the training process, includes:
</bodyText>
<listItem confidence="0.999728833333333">
• word = lower-cased form of each token for
the current position i and in addition for i-1
and i+1
• sh = shape of the token as a simple regular
expression-like representation
• pos = POS of i, i-1 and i+1
</listItem>
<table confidence="0.999825777777778">
Category Recall Prec. F1
noun.artifact Concept 0.72 0.73 0.73
noun.artifact Instance 0.59 0.64 0.62
noun.group Concept 0.72 0.73 0.73
noun.group Instance 0.68 0.70 0.69
noun.location Concept 0.68 0.65 0.66
noun.location Instance 0.75 0.80 0.77
noun.person Concept 0.83 0.80 0.82
noun.person Instance 0.92 0.88 0.90
</table>
<tableCaption confidence="0.923193">
Table 1: Recall, precision and F1 for each category
for English
</tableCaption>
<listItem confidence="0.991281444444444">
• sb= bi- and tri-grams of characters of the suf-
fix of word i
• pr= bi- and tri-grams of characters of the pre-
fix of word i
• rp = coarse relative position of word i,
rp=begin if i = 0, rp=end if i = —sentence—-
1, sb=mid otherwise
• kf = constant features on each token for reg-
ularization purposes
</listItem>
<bodyText confidence="0.999972">
Finally, we trained the SST engine in the Italian
corpus generated so far, and we evaluated the su-
per sense tagging accuracy by adopting the same
evaluation method as described in (Ciaramita and
Johnson, 2003), obtaining F1 close to 0.70. How-
ever quite lower than the English F1, this result is
in line with the claim, since the Italian corpus is
smaller and lower in quality.
</bodyText>
<sectionHeader confidence="0.827343" genericHeader="method">
5 SST Performance and Evaluation
</sectionHeader>
<bodyText confidence="0.999380941176471">
We evaluated the performances of the SST gen-
erated so far by adopting a n-fold cross valida-
tion strategy on the Semcor adopted for training.
Results for the chosen categories are illustrated
in Table 1 and Table 2, reporting precision, re-
call and F1 for any Supersense. If we cast a
deeper glance at the tables, we can clearly no-
tice that for some category the F1 is exception-
ally high. Some of those best categorized cat-
egories are really essential for ontology learn-
ing. For example, important labels as noun.person
or noun.group achieve results among the 70%.
For some categories we have found a F1 over
0.80% as noun.person Instance (F1 0.90% ) or
noun.person Concept (F1 0.85% )
On the other hand, the Italian tagger achieved
lower performances if compared with the English.
</bodyText>
<page confidence="0.989982">
140
</page>
<table confidence="0.999946888888889">
Category Recall Prec. F1
noun.artifact Concept 0.64 0.63 0.63
noun.artifact Instance 0.66 0.67 0.66
noun.group Concept 0.61 0.65 0.63
noun.group Instance 0.66 0.66 0.66
noun.location Concept 0.55 0.53 0.54
noun.location Instance 0.56 0.76 0.64
noun.person Concept 0.81 0.76 0.78
noun.person Instance 0.88 0.81 0.85
</table>
<tableCaption confidence="0.939457">
Table 2: Recall, precision and F1 for each category
for Italian
</tableCaption>
<bodyText confidence="0.999743052631579">
It can be explained by (i) the lower quality of the
training resource, (ii) the lower quantity of training
data and (iii) the unavailability of the first sense
info.
Regarding the first point, it is worthwhile to re-
mark that even if the quality of transfer developed
by (Bentivogli et al., 2004) is high, many incor-
rect sense transfers (around 14%) can be found.
Because of that our work suffers of the same in-
herited faults by the automatic alignment. For in-
stance, we report here the most relevant errors we
faced with during the preprocessing step. One of
the main errors that has badly influenced the train-
ing set especially for multiword recognition is the
case in which the translation equivalent is indeed a
cross-language synonym of the source expression
but not a lexical unit. It occurs when a language
expresses a concept with a lexical unit whereas the
other language expresses the same concept with a
free combination of words (for instance occhiali
da sole annotated with the sense of sunglasses).
Regarding the second problem, we noticed
that the quantity of sense labeled words adopted
for English is higher than 200,000, whereas the
amount of Italian tokens adopted is around 92,000.
Therefore, the amount of Italian training data
is sensibly lower, explaining the lower perfor-
mances.
Moreover, the italian SST lacks in one of the
most important feature used for the English SST,
first sense heuristics. In fact, for the Italian lan-
guage, the first sense baseline cannot be estimated
by simply looking at the first sense in WordNet,
since the order of the Italian WordNet does not re-
flect the frequency of senses. Therefore, we did
not estimate this baseline for the Italian SST, in
contrast to what has been done for the English
SST.
</bodyText>
<sectionHeader confidence="0.988886" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999990975609756">
In this work, we presented an empirical investiga-
tion about the role of Named Entities in compara-
ble corpora, showing that they largely contribute
in finding bridges between languages since they
tend to refer to the same entities. This feature
allows us to discover bridges among languages
by simply looking for common Named Entities in
corpora that are generally not parallels since such
terms are usually associated to the same objects
in the external world. We demonstrated that most
terms in the lexical overlap between languages are
entities, and we showed that they belong to few
fundamentals categories (including persons, loca-
tions and groups).
A predominant amount of entities in the lexi-
cal overlap could be conceived as a support to our
claim that Named Entities can be used to bridge
the languages, since they preserve meaning and
provide a set of highly accurate anchors to bridge
languages in multilingual knowledge bases. Those
anchors can be used as a set of seeds to boost fur-
ther statistical or logical lexical acquisition pro-
cesses. In addition, the impact of false friends re-
vealed to be less problematic than expected.
We trained a multilingual super sense tagger
on the Italian and English language and we in-
troduced the distinction between concept and in-
stance in a subset of its target classes, where our
investigation suggested to look for concrete types.
The resulting tagger largely extend the capabilities
of the state of art supersense technology, by pro-
viding a multilingual tool which can be effectively
used for multilingual knowledge induction.
For the future, we are going to further explore
the direction of multilingual knowledge induction,
exploiting the tagger developed so far for ontology
engineering and knowledge retrieval. In addition,
we plan to leverage more on the lexical overlap
property analyzed in this paper, for example to de-
velop unsupervised super sense taggers for all lan-
guages where annotated corpora are not available.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999487">
Alfio Massimiliano Gliozzo has been supported by
the BONy project, financed by the Education and
culture DG of the EU, grant agreement N 135263-
2007-IT-KA3-KA3MP, under the Lifelong Learn-
ing Programme 2007 managed by EACEA.
</bodyText>
<page confidence="0.997915">
141
</page>
<sectionHeader confidence="0.99589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998366">
R. Beckwith, C. Fellbaum, D. Gross, and G. Miller.
1991. 9. wordnet: A lexical database organized on
psycholinguistic principles. Lexicons: Using On-
Line Resources to Build a Lexicon, pages 211–232,
Jan.
L. Bentivogli, P. Forner, and E. Pianta. 2004. Evalu-
ating cross-language annotation transfer in the mul-
tisemcor corpus. In COLING ’04: Proceedings of
the 20th international conference on Computational
Linguistics, page 364, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
P. Buitelaar, P. Cimiano, and B. Magnini. 2005. On-
tology learning from texts: methods, evaluation and
applications. IOS Press.
M. Ciaramita and M. Johnson. 2003. Supersense tag-
ging of unknown nouns in wordnet. In Proceedings
of EMNLP-03, pages 168–175, Sapporo, Japan.
P. Cimiano. 2006. Ontology Learning and Popula-
tion from Text: Algorithms, Evaluation and Appli-
cations. Springer-Verlag New York, Inc., Secaucus,
NJ, USA.
M. Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of EMNLP-02.
C. de Pablo, J.L. Mart´ınez, and P. Mart´ınez. 2006.
Named entity processing for cross-lingual and mul-
tilingual ir applications. In proceedings of the SI-
GIR2006 workshop on New Directions In Multilin-
gual Information Access.
C. Fellbaum. 1998. WordNet. An Electronic Lexical
Database. MIT Press.
G. A. Miller and F. Hristea. 2006. Wordnet nouns:
Classes and instances. Computational Linguistics,
32(1):1–3.
N. Nguyen and Y. Guo. 2007. Comparison of se-
quence labeling algorithms and extensions. In Pro-
ceedings of ICML 2007, pages 681–688.
D. Picca and A. Popescu. 2007. Using wikipedia and
supersense tagging for semi-automatic complex tax-
onomy construction. In proceedings RANLP.
D. Picca, A. Gliozzo, and M. Ciaramita. 2007. Se-
mantic domains and supersens tagging for domain-
specific ontology learning. In proceedings RIAO
2007.
D. Picca, A. M. Gliozzo, and M. Ciaramita. 2008.
Supersense tagger for italian. In proceedings of
the sixth international conference on Language Re-
sources and Evaluation (LREC 2008).
C. B. Quasthoff, U. M. Richter. 2006. Corpus portal
for search in monolingual corpora,. In Proceedings
of the fifth international conference on Language
Resources and Evaluation, LREC, pages pp. 1799–
1802.
F. Suchanek, G. Kasneci, and G. Weikum. 2007a.
Yago: A large ontology from wikipedia and word-
net. Technical Report.
F. M. Suchanek, G. Kasneci, and G. Weikum. 2007b.
Yago: a core of semantic knowledge. In WWW ’07:
Proceedings of the 16th international conference on
World Wide Web, pages 697–706, New York, NY,
USA. ACM Press.
C. Zirn, V. Nastase, and M. Strube. 2008. Distinguish-
ing between instances and classes in the wikipedia
taxonomy. Lecture notes in computer science, Jan.
</reference>
<page confidence="0.997714">
142
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.359713">
<title confidence="0.910205">Bridging Languages by SuperSense Entity Tagging</title>
<author confidence="0.990315">Picca Massimiliano Gliozzo</author>
<affiliation confidence="0.731229">University of Lausanne, CH *Semantic Technology Lab (STLab - ISTC - CNR), Via Nomentana 56-0016, Rome, **Ecole Polytechnique Federale de Lausanne</affiliation>
<email confidence="0.999281">davide.picca@unil.ch,alfio.gliozzo@istc.cnr.it,simone.campora@gmail.com</email>
<abstract confidence="0.9987689">This paper explores a very basic linguistic phenomenon in multilingualism: the lexicalizations of entities are very often identical within different languages while concepts are usually lexicalized differently. Since entities are commonly referred to by proper names in natural language, we measured their distribution in the lexical overlap of the terminologies extracted from comparable corpora. Results show that the lexical overlap is mostly composed by unambiguous words, which can be regarded as anchors to bridge languages: most of terms having the same spelling refer exactly to the same entities. Thanks to this important feature of Named Entities, we developed a multilingual super sense tagging system capable to distinguish between concepts and individuals. Individuals adopted for training have been extracted both by YAGO and by a heuristic procedure. The general F1 of the English tagger is over 76%, which is in line with the state of the art on super sense tagging while augmenting the number of classes. Performances for Italian are slightly lower, while ensuring a reasonable accuracy level which is capable to show effective results for knowledge acquisition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>G Miller</author>
</authors>
<title>9. wordnet: A lexical database organized on psycholinguistic principles. Lexicons: Using OnLine Resources to Build a Lexicon,</title>
<date>1991</date>
<pages>211--232</pages>
<contexts>
<context position="4945" citStr="Beckwith et al., 1991" startWordPosition="766" endWordPosition="769">person, location, and organization) are too few and generic. It is quite evident that taxonomies require more categories than the three mentioned above. • Even though NER systems are supposed to recognize individuals, very often they also returns common names and no clear distinction with concepts is made. A Super Sense Tagger (SST) (Ciaramita and Johnson, 2003) is an extended NER system that uses the wider set of categories composed by the 41 most general concepts defined by WordNet. WordNet has been organized according to psycholinguistic theories on the principles governing lexical memory (Beckwith et al., 1991). Thus the broadest WordNet’s categories can serve as basis for a set of categories which exhaustively covers, at least as a first approximation, all possible concepts occurring in a sentence. The aim of this paper is to develop and explore the property of instances being lexicalized identically in different languages in order to produce a SST having the following two features: • Make explicit distinction between instances and concepts. • Analyze the terminology of different languages adopting a common category set. Nevertheless, the first point demands to face with the vague distinction betwe</context>
</contexts>
<marker>Beckwith, Fellbaum, Gross, Miller, 1991</marker>
<rawString>R. Beckwith, C. Fellbaum, D. Gross, and G. Miller. 1991. 9. wordnet: A lexical database organized on psycholinguistic principles. Lexicons: Using OnLine Resources to Build a Lexicon, pages 211–232, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bentivogli</author>
<author>P Forner</author>
<author>E Pianta</author>
</authors>
<title>Evaluating cross-language annotation transfer in the multisemcor corpus.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>364</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="8724" citStr="Bentivogli et al., 2004" startWordPosition="1367" endWordPosition="1370">red to other semantic tagsets, supersenses have the advantage of being designed to cover all possible open class words. Thus, in principle there is a supersense cat1We have used the WordNet version 2.0 for all the experiments in the paper. 137 egory for each word, known or novel. Additionally, no distinction is made between proper and common nouns, whereas standard NER systems tends to be biased towards the former. Following the procedure described in (Picca et al., 2008), we developed a multilingual SST working on both Italian and English languages by training the same system on MultiSemcor (Bentivogli et al., 2004), a parallel English/Italian corpus composed of 116 texts which are the translation of their corresponding English texts in SemCor. This resource has been developed by manually translating the English texts to Italian. Then, the so generated parallel corpus has been automatically aligned at the Word Level. Finally, sense labels have been automatically transferred from the English words to their Italian translations. The sense labels adopted in the Italian part of MultiSemCor (Bentivogli et al., 2004) have been extracted by Multi WordNet 2. It is a multilingual computational lexicon, conceived </context>
<context position="19486" citStr="Bentivogli et al., 2004" startWordPosition="3072" endWordPosition="3075">4 0.63 0.63 noun.artifact Instance 0.66 0.67 0.66 noun.group Concept 0.61 0.65 0.63 noun.group Instance 0.66 0.66 0.66 noun.location Concept 0.55 0.53 0.54 noun.location Instance 0.56 0.76 0.64 noun.person Concept 0.81 0.76 0.78 noun.person Instance 0.88 0.81 0.85 Table 2: Recall, precision and F1 for each category for Italian It can be explained by (i) the lower quality of the training resource, (ii) the lower quantity of training data and (iii) the unavailability of the first sense info. Regarding the first point, it is worthwhile to remark that even if the quality of transfer developed by (Bentivogli et al., 2004) is high, many incorrect sense transfers (around 14%) can be found. Because of that our work suffers of the same inherited faults by the automatic alignment. For instance, we report here the most relevant errors we faced with during the preprocessing step. One of the main errors that has badly influenced the training set especially for multiword recognition is the case in which the translation equivalent is indeed a cross-language synonym of the source expression but not a lexical unit. It occurs when a language expresses a concept with a lexical unit whereas the other language expresses the s</context>
</contexts>
<marker>Bentivogli, Forner, Pianta, 2004</marker>
<rawString>L. Bentivogli, P. Forner, and E. Pianta. 2004. Evaluating cross-language annotation transfer in the multisemcor corpus. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics, page 364, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>P Cimiano</author>
<author>B Magnini</author>
</authors>
<title>Ontology learning from texts: methods, evaluation and applications.</title>
<date>2005</date>
<publisher>IOS Press.</publisher>
<contexts>
<context position="1724" citStr="Buitelaar et al., 2005" startWordPosition="250" endWordPosition="253"> to distinguish between concepts and individuals. Individuals adopted for training have been extracted both by YAGO and by a heuristic procedure. The general F1 of the English tagger is over 76%, which is in line with the state of the art on super sense tagging while augmenting the number of classes. Performances for Italian are slightly lower, while ensuring a reasonable accuracy level which is capable to show effective results for knowledge acquisition. 1 Introduction The Semantic Web paradigm is often required to provide a structured view of the unstructured information expressed in texts (Buitelaar et al., 2005; Cimiano, 2006). Semantic technology requires abundance of such kind of knowledge in order to cover the web scale in almost any language. Natural Language Processing (NLP) has been adopted with the purpose of knowledge acquisition, and in particular for ontology learning and information extraction. Structured information in ontologies is often expressed by taxonomies of concepts, and then populated by instances. Nonetheless, automatically distinguish concepts from entities in taxonomies is not an easy task, especially as far as the problem of acquiring such knowledge from texts is concerned (</context>
</contexts>
<marker>Buitelaar, Cimiano, Magnini, 2005</marker>
<rawString>P. Buitelaar, P. Cimiano, and B. Magnini. 2005. Ontology learning from texts: methods, evaluation and applications. IOS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ciaramita</author>
<author>M Johnson</author>
</authors>
<title>Supersense tagging of unknown nouns in wordnet.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP-03,</booktitle>
<pages>168--175</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="4687" citStr="Ciaramita and Johnson, 2003" startWordPosition="725" endWordPosition="728">ty Recognition (NER) is a basic task in NLP that has the intent of automatically recognizing Named Entities. Incidentally, NER systems can be a useful step for broad-coverage ontology engineering but they have two main limitations: • Traditional categories (e.g., person, location, and organization) are too few and generic. It is quite evident that taxonomies require more categories than the three mentioned above. • Even though NER systems are supposed to recognize individuals, very often they also returns common names and no clear distinction with concepts is made. A Super Sense Tagger (SST) (Ciaramita and Johnson, 2003) is an extended NER system that uses the wider set of categories composed by the 41 most general concepts defined by WordNet. WordNet has been organized according to psycholinguistic theories on the principles governing lexical memory (Beckwith et al., 1991). Thus the broadest WordNet’s categories can serve as basis for a set of categories which exhaustively covers, at least as a first approximation, all possible concepts occurring in a sentence. The aim of this paper is to develop and explore the property of instances being lexicalized identically in different languages in order to produce a </context>
<context position="7382" citStr="Ciaramita and Johnson, 2003" startWordPosition="1146" endWordPosition="1150">directions for future investigation. 2 Multilingual Supersense Tagging SuperSense Tagging is the problem to identify terms in texts, assigning a “supersense” category (e.g. person, act) to their senses within their context and apply it to recognize concepts and instances in large scale textual collections of texts. An example of tagging is provided here: GunsB−noun.group andI−noun.group RosesI−noun.group playsB−verb.communication aty they stadiumB−noun.location These categories are extracted from WordNet. WordNet (Fellbaum, 1998) defines 45 lexicographer’s categories, also called supersenses (Ciaramita and Johnson, 2003). They are used by lexicographers to provide an initial broad classification for the lexicon entries 1. Although simplistic in many ways, the supersense ontology has several attractive features for NLP purposes. First of all, concepts are easily recognizable, however very general. Secondly, the small number of classes makes the implementation of state of the art methods possible (e.g. sequence taggers) to annotate text with supersenses. Finally, similar word senses tend to be merged together reducing ambiguity. This technology has been also adopted for Ontology Learning (Picca et al., 2007), a</context>
<context position="16563" citStr="Ciaramita and Johnson, 2003" startWordPosition="2570" endWordPosition="2574">nce RosesI−noun.group_Instance suonanoB−verb.communication alloO stadioB−noun.location_Concept Afterwards, we trained the SST engine. It implements a Hidden Markov Model, trained with the perceptron algorithm introduced in (Collins, 2002) and it achieves a recall of 77.71% and a precision of 76.65% . Perception sequence learning provides an excellent trade-off accuracy/performance, sometimes outperforming more complex models such as Conditional Random Fields (Nguyen and Guo, 2007). We optimized the required parameters by adopting a cross validation technique. As for the settings developed by (Ciaramita and Johnson, 2003), the best results have been obtained by setting 50 trials and 10 epochs to train the perceptron algorithm. The basic feature set used for the training process, includes: • word = lower-cased form of each token for the current position i and in addition for i-1 and i+1 • sh = shape of the token as a simple regular expression-like representation • pos = POS of i, i-1 and i+1 Category Recall Prec. F1 noun.artifact Concept 0.72 0.73 0.73 noun.artifact Instance 0.59 0.64 0.62 noun.group Concept 0.72 0.73 0.73 noun.group Instance 0.68 0.70 0.69 noun.location Concept 0.68 0.65 0.66 noun.location Ins</context>
<context position="17827" citStr="Ciaramita and Johnson, 2003" startWordPosition="2793" endWordPosition="2796">cept 0.83 0.80 0.82 noun.person Instance 0.92 0.88 0.90 Table 1: Recall, precision and F1 for each category for English • sb= bi- and tri-grams of characters of the suffix of word i • pr= bi- and tri-grams of characters of the prefix of word i • rp = coarse relative position of word i, rp=begin if i = 0, rp=end if i = —sentence—- 1, sb=mid otherwise • kf = constant features on each token for regularization purposes Finally, we trained the SST engine in the Italian corpus generated so far, and we evaluated the super sense tagging accuracy by adopting the same evaluation method as described in (Ciaramita and Johnson, 2003), obtaining F1 close to 0.70. However quite lower than the English F1, this result is in line with the claim, since the Italian corpus is smaller and lower in quality. 5 SST Performance and Evaluation We evaluated the performances of the SST generated so far by adopting a n-fold cross validation strategy on the Semcor adopted for training. Results for the chosen categories are illustrated in Table 1 and Table 2, reporting precision, recall and F1 for any Supersense. If we cast a deeper glance at the tables, we can clearly notice that for some category the F1 is exceptionally high. Some of thos</context>
</contexts>
<marker>Ciaramita, Johnson, 2003</marker>
<rawString>M. Ciaramita and M. Johnson. 2003. Supersense tagging of unknown nouns in wordnet. In Proceedings of EMNLP-03, pages 168–175, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
</authors>
<title>Ontology Learning and Population from Text: Algorithms, Evaluation and Applications.</title>
<date>2006</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc., Secaucus, NJ, USA.</location>
<contexts>
<context position="1740" citStr="Cimiano, 2006" startWordPosition="254" endWordPosition="255">concepts and individuals. Individuals adopted for training have been extracted both by YAGO and by a heuristic procedure. The general F1 of the English tagger is over 76%, which is in line with the state of the art on super sense tagging while augmenting the number of classes. Performances for Italian are slightly lower, while ensuring a reasonable accuracy level which is capable to show effective results for knowledge acquisition. 1 Introduction The Semantic Web paradigm is often required to provide a structured view of the unstructured information expressed in texts (Buitelaar et al., 2005; Cimiano, 2006). Semantic technology requires abundance of such kind of knowledge in order to cover the web scale in almost any language. Natural Language Processing (NLP) has been adopted with the purpose of knowledge acquisition, and in particular for ontology learning and information extraction. Structured information in ontologies is often expressed by taxonomies of concepts, and then populated by instances. Nonetheless, automatically distinguish concepts from entities in taxonomies is not an easy task, especially as far as the problem of acquiring such knowledge from texts is concerned (Zirn et al., 200</context>
</contexts>
<marker>Cimiano, 2006</marker>
<rawString>P. Cimiano. 2006. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications. Springer-Verlag New York, Inc., Secaucus, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-02.</booktitle>
<contexts>
<context position="16173" citStr="Collins, 2002" startWordPosition="2515" endWordPosition="2516">ound in YAGO, 3413 have been found using the heuristic strategy and the rest have been classified as concepts. If we take the previous example, the new output has now this form: • GunsB−noun.group_Instance andI−noun.group_Instance RosesI−noun.group_Instance playsB−verb.communication atO theO stadiumB−noun.location_Concept or • GunsB−noun.group_Instance andI−noun.group_Instance RosesI−noun.group_Instance suonanoB−verb.communication alloO stadioB−noun.location_Concept Afterwards, we trained the SST engine. It implements a Hidden Markov Model, trained with the perceptron algorithm introduced in (Collins, 2002) and it achieves a recall of 77.71% and a precision of 76.65% . Perception sequence learning provides an excellent trade-off accuracy/performance, sometimes outperforming more complex models such as Conditional Random Fields (Nguyen and Guo, 2007). We optimized the required parameters by adopting a cross validation technique. As for the settings developed by (Ciaramita and Johnson, 2003), the best results have been obtained by setting 50 trials and 10 epochs to train the perceptron algorithm. The basic feature set used for the training process, includes: • word = lower-cased form of each token</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of EMNLP-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C de Pablo</author>
<author>J L Mart´ınez</author>
<author>P Mart´ınez</author>
</authors>
<title>Named entity processing for cross-lingual and multilingual ir applications.</title>
<date>2006</date>
<booktitle>In proceedings of the SIGIR2006 workshop on New Directions In Multilingual Information Access.</booktitle>
<marker>de Pablo, Mart´ınez, Mart´ınez, 2006</marker>
<rawString>C. de Pablo, J.L. Mart´ınez, and P. Mart´ınez. 2006. Named entity processing for cross-lingual and multilingual ir applications. In proceedings of the SIGIR2006 workshop on New Directions In Multilingual Information Access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7289" citStr="Fellbaum, 1998" startWordPosition="1136" endWordPosition="1137">tion 5 is about evaluation. Finally Section 6 concludes the paper proposing new directions for future investigation. 2 Multilingual Supersense Tagging SuperSense Tagging is the problem to identify terms in texts, assigning a “supersense” category (e.g. person, act) to their senses within their context and apply it to recognize concepts and instances in large scale textual collections of texts. An example of tagging is provided here: GunsB−noun.group andI−noun.group RosesI−noun.group playsB−verb.communication aty they stadiumB−noun.location These categories are extracted from WordNet. WordNet (Fellbaum, 1998) defines 45 lexicographer’s categories, also called supersenses (Ciaramita and Johnson, 2003). They are used by lexicographers to provide an initial broad classification for the lexicon entries 1. Although simplistic in many ways, the supersense ontology has several attractive features for NLP purposes. First of all, concepts are easily recognizable, however very general. Secondly, the small number of classes makes the implementation of state of the art methods possible (e.g. sequence taggers) to annotate text with supersenses. Finally, similar word senses tend to be merged together reducing a</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet. An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>F Hristea</author>
</authors>
<title>Wordnet nouns: Classes and instances.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="2393" citStr="Miller and Hristea, 2006" startWordPosition="357" endWordPosition="360">es abundance of such kind of knowledge in order to cover the web scale in almost any language. Natural Language Processing (NLP) has been adopted with the purpose of knowledge acquisition, and in particular for ontology learning and information extraction. Structured information in ontologies is often expressed by taxonomies of concepts, and then populated by instances. Nonetheless, automatically distinguish concepts from entities in taxonomies is not an easy task, especially as far as the problem of acquiring such knowledge from texts is concerned (Zirn et al., 2008; Picca and Popescu, 2007; Miller and Hristea, 2006). First of all because such a distinction is quite vague. From a description logics perspective, that is incidently widely adopted in ontology engineering, instances are the leaves of any taxonomy as they cannot be further subcategorized and populated by other instances. For example,“Bill Clinton” is clearly an individual, since it is instance of many concepts, such as person or president, but at the same time it is a non sense describing individuals belonging to the class Bill Clinton. In order to tackle this issue, we aim to provide empirical evidence to a very basic linguistic phenomenon in</context>
</contexts>
<marker>Miller, Hristea, 2006</marker>
<rawString>G. A. Miller and F. Hristea. 2006. Wordnet nouns: Classes and instances. Computational Linguistics, 32(1):1–3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Nguyen</author>
<author>Y Guo</author>
</authors>
<title>Comparison of sequence labeling algorithms and extensions.</title>
<date>2007</date>
<booktitle>In Proceedings of ICML</booktitle>
<pages>681--688</pages>
<contexts>
<context position="16420" citStr="Nguyen and Guo, 2007" startWordPosition="2549" endWordPosition="2552">un.group_Instance playsB−verb.communication atO theO stadiumB−noun.location_Concept or • GunsB−noun.group_Instance andI−noun.group_Instance RosesI−noun.group_Instance suonanoB−verb.communication alloO stadioB−noun.location_Concept Afterwards, we trained the SST engine. It implements a Hidden Markov Model, trained with the perceptron algorithm introduced in (Collins, 2002) and it achieves a recall of 77.71% and a precision of 76.65% . Perception sequence learning provides an excellent trade-off accuracy/performance, sometimes outperforming more complex models such as Conditional Random Fields (Nguyen and Guo, 2007). We optimized the required parameters by adopting a cross validation technique. As for the settings developed by (Ciaramita and Johnson, 2003), the best results have been obtained by setting 50 trials and 10 epochs to train the perceptron algorithm. The basic feature set used for the training process, includes: • word = lower-cased form of each token for the current position i and in addition for i-1 and i+1 • sh = shape of the token as a simple regular expression-like representation • pos = POS of i, i-1 and i+1 Category Recall Prec. F1 noun.artifact Concept 0.72 0.73 0.73 noun.artifact Inst</context>
</contexts>
<marker>Nguyen, Guo, 2007</marker>
<rawString>N. Nguyen and Y. Guo. 2007. Comparison of sequence labeling algorithms and extensions. In Proceedings of ICML 2007, pages 681–688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Picca</author>
<author>A Popescu</author>
</authors>
<title>Using wikipedia and supersense tagging for semi-automatic complex taxonomy construction.</title>
<date>2007</date>
<booktitle>In proceedings RANLP.</booktitle>
<contexts>
<context position="2366" citStr="Picca and Popescu, 2007" startWordPosition="353" endWordPosition="356">emantic technology requires abundance of such kind of knowledge in order to cover the web scale in almost any language. Natural Language Processing (NLP) has been adopted with the purpose of knowledge acquisition, and in particular for ontology learning and information extraction. Structured information in ontologies is often expressed by taxonomies of concepts, and then populated by instances. Nonetheless, automatically distinguish concepts from entities in taxonomies is not an easy task, especially as far as the problem of acquiring such knowledge from texts is concerned (Zirn et al., 2008; Picca and Popescu, 2007; Miller and Hristea, 2006). First of all because such a distinction is quite vague. From a description logics perspective, that is incidently widely adopted in ontology engineering, instances are the leaves of any taxonomy as they cannot be further subcategorized and populated by other instances. For example,“Bill Clinton” is clearly an individual, since it is instance of many concepts, such as person or president, but at the same time it is a non sense describing individuals belonging to the class Bill Clinton. In order to tackle this issue, we aim to provide empirical evidence to a very bas</context>
</contexts>
<marker>Picca, Popescu, 2007</marker>
<rawString>D. Picca and A. Popescu. 2007. Using wikipedia and supersense tagging for semi-automatic complex taxonomy construction. In proceedings RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Picca</author>
<author>A Gliozzo</author>
<author>M Ciaramita</author>
</authors>
<title>Semantic domains and supersens tagging for domainspecific ontology learning.</title>
<date>2007</date>
<booktitle>In proceedings RIAO</booktitle>
<contexts>
<context position="7979" citStr="Picca et al., 2007" startWordPosition="1243" endWordPosition="1246">ita and Johnson, 2003). They are used by lexicographers to provide an initial broad classification for the lexicon entries 1. Although simplistic in many ways, the supersense ontology has several attractive features for NLP purposes. First of all, concepts are easily recognizable, however very general. Secondly, the small number of classes makes the implementation of state of the art methods possible (e.g. sequence taggers) to annotate text with supersenses. Finally, similar word senses tend to be merged together reducing ambiguity. This technology has been also adopted for Ontology Learning (Picca et al., 2007), as the top level WordNet supersenses cover almost any high level ontological type of interest in ontology design. Compared to other semantic tagsets, supersenses have the advantage of being designed to cover all possible open class words. Thus, in principle there is a supersense cat1We have used the WordNet version 2.0 for all the experiments in the paper. 137 egory for each word, known or novel. Additionally, no distinction is made between proper and common nouns, whereas standard NER systems tends to be biased towards the former. Following the procedure described in (Picca et al., 2008), w</context>
</contexts>
<marker>Picca, Gliozzo, Ciaramita, 2007</marker>
<rawString>D. Picca, A. Gliozzo, and M. Ciaramita. 2007. Semantic domains and supersens tagging for domainspecific ontology learning. In proceedings RIAO 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Picca</author>
<author>A M Gliozzo</author>
<author>M Ciaramita</author>
</authors>
<title>Supersense tagger for italian.</title>
<date>2008</date>
<booktitle>In proceedings of the sixth international conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="8576" citStr="Picca et al., 2008" startWordPosition="1342" endWordPosition="1345">g (Picca et al., 2007), as the top level WordNet supersenses cover almost any high level ontological type of interest in ontology design. Compared to other semantic tagsets, supersenses have the advantage of being designed to cover all possible open class words. Thus, in principle there is a supersense cat1We have used the WordNet version 2.0 for all the experiments in the paper. 137 egory for each word, known or novel. Additionally, no distinction is made between proper and common nouns, whereas standard NER systems tends to be biased towards the former. Following the procedure described in (Picca et al., 2008), we developed a multilingual SST working on both Italian and English languages by training the same system on MultiSemcor (Bentivogli et al., 2004), a parallel English/Italian corpus composed of 116 texts which are the translation of their corresponding English texts in SemCor. This resource has been developed by manually translating the English texts to Italian. Then, the so generated parallel corpus has been automatically aligned at the Word Level. Finally, sense labels have been automatically transferred from the English words to their Italian translations. The sense labels adopted in the </context>
</contexts>
<marker>Picca, Gliozzo, Ciaramita, 2008</marker>
<rawString>D. Picca, A. M. Gliozzo, and M. Ciaramita. 2008. Supersense tagger for italian. In proceedings of the sixth international conference on Language Resources and Evaluation (LREC 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C B Quasthoff</author>
<author>U M Richter</author>
</authors>
<title>Corpus portal for search in monolingual corpora,.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth international conference on Language Resources and Evaluation, LREC,</booktitle>
<pages>1799--1802</pages>
<marker>Quasthoff, Richter, 2006</marker>
<rawString>C. B. Quasthoff, U. M. Richter. 2006. Corpus portal for search in monolingual corpora,. In Proceedings of the fifth international conference on Language Resources and Evaluation, LREC, pages pp. 1799– 1802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: A large ontology from wikipedia and wordnet.</title>
<date>2007</date>
<tech>Technical Report.</tech>
<contexts>
<context position="14505" citStr="Suchanek et al., 2007" startWordPosition="2261" endWordPosition="2264">y small, in spite of the fact that it is very often overemphasized. Inversely, many abstract types (e.g. noun.possession and noun.feeling) do not share terminology at all. 4 Distinguishing entities from concepts Successively, we subdivided each category into two sub-categories for both languages, Instance and Concept so that now the term “president” is tagged as noun.person Concept and the term “Bill Clinton” as noun.person Instance. In order to automate this task and create a reliable training set, we adopted the following strategy. We used the concept/instances distinction provided by YAGO (Suchanek et al., 2007b). YAGO is a huge semantic knowledge base developed by the Max-Plack-Institute of Saarbrcken. YAGO knows over 1.7 million entities (like persons, organizations, cities, etc.). YAGO, exploits Wikipedia’s info-boxes and category pages. Infoboxes are standardized tables that contain basic information about the entity described in the article (Suchanek et al., 2007a). For our purposes it is fundamental that YAGO’s components are represented as entities. In our experiment we exploit entities as proper names and we use only YAGO entity database containing named entities. For each term belonging to </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>F. Suchanek, G. Kasneci, and G. Weikum. 2007a. Yago: A large ontology from wikipedia and wordnet. Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="14505" citStr="Suchanek et al., 2007" startWordPosition="2261" endWordPosition="2264">y small, in spite of the fact that it is very often overemphasized. Inversely, many abstract types (e.g. noun.possession and noun.feeling) do not share terminology at all. 4 Distinguishing entities from concepts Successively, we subdivided each category into two sub-categories for both languages, Instance and Concept so that now the term “president” is tagged as noun.person Concept and the term “Bill Clinton” as noun.person Instance. In order to automate this task and create a reliable training set, we adopted the following strategy. We used the concept/instances distinction provided by YAGO (Suchanek et al., 2007b). YAGO is a huge semantic knowledge base developed by the Max-Plack-Institute of Saarbrcken. YAGO knows over 1.7 million entities (like persons, organizations, cities, etc.). YAGO, exploits Wikipedia’s info-boxes and category pages. Infoboxes are standardized tables that contain basic information about the entity described in the article (Suchanek et al., 2007a). For our purposes it is fundamental that YAGO’s components are represented as entities. In our experiment we exploit entities as proper names and we use only YAGO entity database containing named entities. For each term belonging to </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>F. M. Suchanek, G. Kasneci, and G. Weikum. 2007b. Yago: a core of semantic knowledge. In WWW ’07: Proceedings of the 16th international conference on World Wide Web, pages 697–706, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zirn</author>
<author>V Nastase</author>
<author>M Strube</author>
</authors>
<title>Distinguishing between instances and classes in the wikipedia taxonomy. Lecture notes in computer science,</title>
<date>2008</date>
<contexts>
<context position="2341" citStr="Zirn et al., 2008" startWordPosition="349" endWordPosition="352">; Cimiano, 2006). Semantic technology requires abundance of such kind of knowledge in order to cover the web scale in almost any language. Natural Language Processing (NLP) has been adopted with the purpose of knowledge acquisition, and in particular for ontology learning and information extraction. Structured information in ontologies is often expressed by taxonomies of concepts, and then populated by instances. Nonetheless, automatically distinguish concepts from entities in taxonomies is not an easy task, especially as far as the problem of acquiring such knowledge from texts is concerned (Zirn et al., 2008; Picca and Popescu, 2007; Miller and Hristea, 2006). First of all because such a distinction is quite vague. From a description logics perspective, that is incidently widely adopted in ontology engineering, instances are the leaves of any taxonomy as they cannot be further subcategorized and populated by other instances. For example,“Bill Clinton” is clearly an individual, since it is instance of many concepts, such as person or president, but at the same time it is a non sense describing individuals belonging to the class Bill Clinton. In order to tackle this issue, we aim to provide empiric</context>
</contexts>
<marker>Zirn, Nastase, Strube, 2008</marker>
<rawString>C. Zirn, V. Nastase, and M. Strube. 2008. Distinguishing between instances and classes in the wikipedia taxonomy. Lecture notes in computer science, Jan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>