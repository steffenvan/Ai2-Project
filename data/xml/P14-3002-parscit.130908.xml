<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002331">
<title confidence="0.984965">
Extracting Temporal and Causal Relations between Events
</title>
<author confidence="0.881957">
Paramita Mirza
</author>
<affiliation confidence="0.905672">
Fondazione Bruno Kessler
University of Trento
</affiliation>
<address confidence="0.606358">
Trento, Italy
</address>
<email confidence="0.997598">
paramita@fbk.eu
</email>
<sectionHeader confidence="0.993867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961105263158">
A notably challenging problem related to
event processing is recognizing the rela-
tions holding between events in a text, in
particular temporal and causal relations.
While there has been some research on
temporal relations, the aspect of causality
between events from a Natural Language
Processing (NLP) perspective has hardly
been touched. We propose an annotation
scheme to cover different types of causality
between events, techniques for extracting
such relations and an investigation into the
connection between temporal and causal re-
lations. In this thesis work we aim to focus
especially on the latter, because causality
is presumed to have a temporal constraint.
We conjecture that injecting this presump-
tion may be beneficial for the recognition
of both temporal and causal relations.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999704">
With the rapid growth of information available on
the world wide web, especially in the form of un-
structured and natural texts, information extraction
(IE) becomes one of the most prominent fields in
NLP research. IE aims to provide ways to automat-
ically extract the available information and store
them in a structured representation of knowledge.
The stored knowledge can then be useful for many
NLP applications, such as question answering, tex-
tual entailment, summarization, and focused infor-
mation retrieval systems.
There are several subtasks within information
extraction related to the type of knowledge one
wishes to extract from the text, event extraction be-
ing one of them. Event extraction is considered to
be a non-trivial task, due to the fact that mentions
of an event in text could be highly varied in terms
of sentence construction, and that the attributes de-
scribing an event are usually mentioned in several
sentences. However, the most challenging problem
in the context of event extraction is identifying the
relationship between events.
Events are usually anchored to temporal expres-
sions. The temporal attribute of an event can be
used to determine the temporal relationship be-
tween events. This information can be useful for
the ordering of event sequence in a timeline, e.g.
for the better presentation of news or history texts.
Moreover, in multi-document summarization of
news articles, the relative order of events is impor-
tant to merge and present information from multi-
ple sources correctly.
A more complex type of relationship between
events is causality. Identifying the causal relation
between events is an important step in predicting
occurrence of future events, and can be very ben-
eficial in risk analysis as well as decision making
support.
There is an overlap between causal and tem-
poral relations, since by the definition of causal-
ity, the first event (cause) must happen BEFORE
the second event (effect). We claim that a system
for extracting both temporal and causal relations,
may benefit from integrating this presumption. The
main focus of this research work will be (i) investi-
gating ways to utilize this presumption in building
an integrated event relation extraction system, in
addition to (ii) exploring ways to develop a robust
extraction component for each type of relations
(temporal and causal).
</bodyText>
<sectionHeader confidence="0.989163" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999866875">
In NLP, the definition of an event can be varied de-
pending on the target application. In topic detection
and tracking (Allan, 2002), the term event is used
interchangeably with topic, which describes some-
thing that happens and is usually used to identify a
cluster of documents, e.g. Olympics, wars. On the
other hand, information extraction provides finer
granularity of event definitions, in which events
</bodyText>
<page confidence="0.985423">
10
</page>
<note confidence="0.853041">
Proceedings of the ACL 2014 Student Research Workshop, pages 10–17,
</note>
<affiliation confidence="0.275011">
Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.999202456521739">
are entities that happen/occur within the scope of a
document.
There are several annotation frameworks for
events and temporal expressions that can be viewed
as event models,1 TimeML (Pustejovsky et al.,
2003b) and ACE (Consortium, 2005) being the
prominent ones.
Both TimeML and ACE define an event as
something that happens/occurs or a state that
holds true, which can be expressed by a verb,
a noun, an adjective, as well as a nominaliza-
tion either from verbs or adjectives. Consider
the following passage annotated with events and
temporal expressions (TIMEX). “A Philippine
volcano, dormant EVENT for six centuries TIMEX,
exploded EVENT last Monday TIMEX. During the
eruption EVENT, lava, rocks and red-hot ash are
spewed EVENT onto surrounding villages. The
explosion EVENT claimed EVENT at least 30 lives.”
The most important attribute of TimeML that
differs from ACE is the separation of the repre-
sentation of events and temporal expressions from
the anchoring or ordering dependencies. Instead
of treating a temporal expression as an event ar-
gument, TimeML introduces temporal link annota-
tions to establish dependencies (temporal relations)
between events and temporal expressions (Puste-
jovsky et al., 2003b). This annotation is important
in (i) anchoring an event to a temporal expression
(event time-stamping) and (ii) determining the tem-
poral order between events. This distinctive feature
of TimeML becomes our main consideration in
choosing the event model for our research.
Moreover, TimeML is the annotation framework
used in TempEval-32, the most recent shared task
on temporal and event processing. The ultimate
goal of this evaluation campaign is the automatic
identification of temporal expressions, events, and
temporal relations within a text (UzZaman et al.,
2012).
The main tasks defined in TempEval-3 include:
the automatic extraction of TimeML entities, i.e.
temporal expressions and events, and the end-to-
end automatic extraction of both TimeML enti-
ties and temporal links/relations. The result of
TempEval-3 reported by UzZaman et al. (2013)
</bodyText>
<footnote confidence="0.998148571428571">
1There are other event models based on web ontology
(RDFS+OWL) such as LODE (Shaw et al., 2009), SEM (van
Hage et al., 2011) and DOLCE (Gangemi et al., 2002), which
encode knowledge about events as triples. Such models can
be seen as ways to store the extracted knowledge to perform
the reasoning on.
2http://www.cs.york.ac.uk/semeval-2013/task1/
</footnote>
<bodyText confidence="0.9996683">
shows that even though the performances of sys-
tems for extracting TimeML entities are quite good
(&gt;80% F-score), the overall performance of end-
to-end event extraction systems suffers from the
low performance of the temporal relation extrac-
tion system. The state-of-the-art performance on
the temporal relation extraction task yields only
around 36% F-score. This becomes the main rea-
son of focusing our research on the extraction of
event relations.
</bodyText>
<sectionHeader confidence="0.994817" genericHeader="method">
3 Research Problem
</sectionHeader>
<bodyText confidence="0.9939773">
We consider two types of event relations to be ex-
tracted from text, which are temporal relations and
causal relations. Causal relations are related to
temporal relations since there is a temporal con-
straint in causality, i.e. the cause must precede the
effect. Considering this presumption, and the as-
sumption that there are good enough systems to
extract temporal expressions and events, we define
two main problems that will be addressed in this
research work:
</bodyText>
<listItem confidence="0.865701">
1. Given a text annotated with entities (temporal
expressions and events), how to automatically
extract temporal and causal relations between
them.
2. Given the temporal constraint of causality,
how to utilize the interaction between tempo-
ral relations and causal relations for building
an integrated event relation extraction system
for both types of relations.
</listItem>
<sectionHeader confidence="0.994442" genericHeader="method">
4 Research Methodology
</sectionHeader>
<bodyText confidence="0.999977571428571">
There are several aspects of the mentioned prob-
lems that will become our guidelines in continuing
our research in this topic. The following sections
will give a more detailed description of these as-
pects including the arising challenges, some pre-
liminary results to address the challenges and our
future research directions.
</bodyText>
<subsectionHeader confidence="0.992616">
4.1 Temporal Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999784142857143">
As previously mentioned, we consider the TimeML
annotation framework because it explicitly encodes
the temporal links between entities (events and tem-
poral expressions) in a text. In TimeML, each tem-
poral link has a temporal relation type assigned to
it. There are 14 types of temporal relations speci-
fied in TimeML version 1.2.1 (Saur´ı et al., 2006),
</bodyText>
<page confidence="0.998543">
11
</page>
<bodyText confidence="0.926703">
which are defined based on Allen’s interval algebra
(Allen, 1983), as illustrated in Table 1.
</bodyText>
<figure confidence="0.9988456">
a |——— |a is BEFORE b
b |——— |b is AFTER a
a |——— |a is IBEFORE b
b |——— |b is IAFTER a
a |—— |a BEGINS b
b |———— |b is BEGUN BY a
a|—— |a ENDS b
b |———— |bis ENDED BY a
a |—— |a is DURING b
b   ||b is DURING INV a
a   ||a INCLUDES b
b|—— |b IS INCLUDED in a
a |——— |a is SIMULTANEOUS with b
b |———|
a |——— |b a is IDENTITY with b
</figure>
<tableCaption confidence="0.989687">
Table 1: Temporal relations in TimeML annotation
</tableCaption>
<bodyText confidence="0.999944904761905">
Recalling the low performances of currently
available systems on the temporal relation extrac-
tion task, including the state-of-the-art systems ac-
cording to TempEval-3, it is still insufficient to use
the existing temporal relation extraction systems
to support real world applications, such as creat-
ing event timelines and temporally-based question
answering. Therefore, as the first step we take as
an objective finding ways to improve the current
state-of-the-art performance on temporal relation
extraction task.
The common approach towards temporal rela-
tion extraction is dividing the task into two sub-
tasks: identifying the pairs of entities having a tem-
poral link and determining the relation types. The
problem of identifying the entity pairs is usually
simplified. In TempEval-3, the possible pairs of
entities that can have a temporal link are defined as
(i) main events of consecutive sentences, (ii) pairs
of events in the same sentence, (iii) an event and a
time expression in the same sentence, and (iv) an
event and the document creation time (UzZaman
et al., 2013). The problem of determining the label
of a given temporal link is usually regarded as a
classification problem. Given an ordered pair of
entities (e1, e2) that could be either event-event,
event-timex or timex-timex pair, the classifier has
to assign a certain label representing the temporal
relation type.
We focus on the latter subtask of classifying
temporal relation types, assuming that the links
between events and time expressions are already
established. Several recent works have tried to ad-
dress this complex multi-class classification task
by using sophisticated features based on deep pars-
ing, semantic role labelling and discourse parsing
(D’Souza and Ng, 2013; Laokulrat et al., 2013). In
Mirza and Tonelli (2014) we have shown that a sim-
pler approach, based on lexico-syntactic features,
can achieve comparable results.
A classification model is trained for each cate-
gory of entity pair, i.e. event-event, event-timex
and timex-timex, as suggested in several previous
works (Mani et al., 2006; Chambers, 2013). How-
ever, because there are very few examples of timex-
timex pairs in the training corpus, it is not possible
to train a classifier for these particular pairs. More-
over, they only add up to 3.2% of the total number
of extracted entity pairs; therefore, we decided to
disregard these pairs.
We follow the guidelines and the dataset pro-
vided by the organizers of TempEval-3 so that we
can compare our system with other systems partici-
pating in the challenge. The TBAQ-cleaned corpus
is the training set provided for the task, consisting
of the TimeBank (Pustejovsky et al., 2003a) and
the AQUAINT corpora. It contains around 100K
words in total, with 11K words annotated as events
(UzZaman et al., 2013).
Simple Feature Set. We implement a number of
features including the commonly used ones (UzZa-
man et al., 2013), which take into account morpho-
syntactic information on events and time expres-
sions, their textual context and their attributes.
Other features rely on semantic information such
as typical event durations and explicit temporal
connective types. However, we avoid complex pro-
cessing of data. Such semantic information is based
on external lists of lexical items and on the output
of the addDiscourse tagger (Pitler and Nenkova,
2009). We build our classification models using the
Support Vector Machine (SVM) implementation
provided by YamCha3.
We perform feature engineering in order to se-
lect from our initial set of features only those that
improve the accuracy of the classifiers. This allows
us to select the best classification models for both
event-event pairs and event-timex pairs.
Inverse Relations and Closure. Motivated by the
finding of Mani et al. (2006) that bootstrapping the
training data through a temporal closure method
results in quite significant improvements, we in-
vestigate the effect of enriching the training data
with inverse relations and closure-based inferred
</bodyText>
<footnote confidence="0.965396">
3http://chasen.org/∼taku/software/yamcha/
</footnote>
<page confidence="0.996476">
12
</page>
<bodyText confidence="0.998296545454545">
relations.
However, we adopt a simpler approach to obtain
the closure graph of temporal relations, by applying
the transitive closure only within the same relation
type, e.g. e1 BEFORE e2 ∧ e2 BEFORE e3 → e1
BEFORE e3. It produces only a subset of the rela-
tions produced by the temporal closure (Verhagen,
2005; Gerevini et al., 1995). The problem of find-
ing the transitive closure of a directed acyclic graph
can be reduced to a boolean matrix multiplication
(Fischer and Meyer, 1971).
</bodyText>
<table confidence="0.99986975">
Training data event-event event-timex
TBAQ 48.28% 73.82%
TBAQ-I 47.77% 74.45%
TBAQ-IC 46.39% 74.45%
</table>
<tableCaption confidence="0.916007">
Table 2: Classifier accuracies with different
</tableCaption>
<bodyText confidence="0.951347911764706">
training data: TBAQ (TimeBank+AQUAINT),
TBAQ-I (TBAQ+inverse relations) and TBAQ-IC
(TBAQ+inverse relations+transitive closure).
Evaluation and Analysis. Our test data is the
newly annotated TempEval-3-platinum evaluation
corpus provided by TempEval-3 organizers, so that
we can compare our system with other systems
participating in the task. First, to investigate the
effect of enriching the training data with inverse
relations and transitive closure, we evaluate the sys-
tem performance trained with different datasets, as
shown in Table 2. A randomization test between
the best performing classifier and the others shows
that by extending the training data with inverse
relations and transitive closure, the improvement
are not significant. Applying inverse relations and
transitive closure extends the number of training in-
stances but makes the already skewed dataset more
imbalanced, thus it does not result in a significant
improvement.
We then train our classifiers for event-event pairs
and event-timex pairs by exploiting the best feature
combination and using the best reported dataset
for each classifier as the training data. The two
classifiers are part of our temporal classification
system called TRelPro.
Compared with the performances of other sys-
tems participating in TempEval-3 reported in UzZa-
man et al. (2013), TRelPro is the best performing
system both in terms of precision and of recall.
The result of our system using simpler features
confirms the finding reported in UzZaman et al.
(2013), that a system using basic morpho-syntactic
features is hard to beat with systems using more
</bodyText>
<table confidence="0.976202111111111">
complex semantic features, if not used properly.
System F1 Precision Recall
TRelPro 58.48% 58.80% 58.17%
UTTime-1, 4 56.45% 55.58% 57.35%
UTTime-3, 5 54.70% 53.85% 55.58%
UTTime-2 54.26% 53.20% 55.36%
NavyTime-1 46.83% 46.59% 47.07%
NavyTime-2 43.92% 43.65% 44.20%
JU-CSE 34.77% 35.07% 34.48%
</table>
<tableCaption confidence="0.9295945">
Table 3: TempEval-3 evaluation on the classifica-
tion of temporal relation types
</tableCaption>
<subsectionHeader confidence="0.976007">
4.2 Causal Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999986305555556">
Unlike the temporal order that has a clear defini-
tion, there is no consensus in the NLP community
on how to define causality. Causality is not a lin-
guistic notion, meaning that although language can
be used to express causality, causality exists as
a psychological tool for understanding the world
independently of language (van de Koot and Neele-
man, 2012). There have been several attempts in
the psychology field to model causality, including
the counterfactual model (Lewis, 1973), proba-
bilistic contrast model (Cheng and Novick, 1991;
Cheng and Novick, 1992) and the dynamics model
(Wolff and Song, 2003; Wolff et al., 2005; Wolff,
2007), which is based on Talmy’s force dynamic
account of causality (Talmy, 1985; Talmy, 1988).
In information extraction, modelling causality
is only the first step in order to have guidelines
to recognize causal relations in a text. In order
to have an automatic extraction system for causal
relations (particularly using a data-driven approach)
and most importantly to evaluate the performance
of the developed extraction system, it is important
that a language resource annotated with causality
is available.
Even though there are several corpora anno-
tated with causality, e.g. Penn Discourse Tree-
bank (PDTB) (Prasad et al., 2007) and PropBank
(Palmer et al., 2005),4 we are not aware of any
standard benchmarking corpus for evaluating event
causality extraction, as it is available for temporal
relations in TimeML. This motivates us to create
a language resource annotated with both temporal
and causal relations in a unified annotation scheme,
for the main purpose of investigating the interac-
tion between both types of relations. It becomes
the objective of the second stage of our research, in
</bodyText>
<footnote confidence="0.994114666666667">
4PDTB annotates causality between related clauses, while
PropBank annotates causality between a verb and its cause
clause.
</footnote>
<page confidence="0.999533">
13
</page>
<bodyText confidence="0.999951738095238">
addition to building an automatic extraction system
for event causality using the developed corpus.
In Mirza et al. (2014) we have proposed annota-
tion guidelines for causality between events, based
on the TimeML definition of events, which consid-
ers all types of actions (punctual and durative) and
states as events. Parallel to the &lt;TLINK&gt; tag in
TimeML for temporal relations, we introduced the
&lt;CLINK&gt; tag to signify a causal link. We also
introduced the notion of causal signals through the
&lt;C-SIGNAL&gt; tag, parallel to the &lt;SIGNAL&gt; tag
in TimeML indicating temporal cues.
C-SIGNAL. C-SIGNAL is used to mark-up textual
elements signalling the presence of causal relations,
which include all causal uses of: prepositions (e.g.
because of, as a result of, due to), conjunctions
(e.g. because, since, so that), adverbial connectors
(e.g. so, therefore, thus) and clause-integrated ex-
pressions (e.g. the reason why, the result is, that is
why).
CLINK. A CLINK is a directional relation where
the causing event is the source (indicated with S
in the examples) and the caused event is the target
(indicated with T). The annotation of CLINKs also
includes the c-signalID attribute, with the value of
the ID of C-SIGNAL marking the causal relation
(if available).
Wolff (2007) has shown that the dynamics model
covers three main types of causal concepts, i.e.
CAUSE, ENABLE and PREVENT. The model has
been tested by linking it with natural language,
Wolff and Song (2003) show that the three causal
concepts can be lexicalized as verbs : (i) CAUSE-
type verbs, e.g. cause, prompt, force; (ii) ENABLE-
type verbs, e.g. allow, enable, help; and (iii)
PREVENT-type verbs, e.g. block, prevent, restrain.
Its connection with natural language becomes the
main reason of basing our annotation guidelines
for causality on the dynamics model.
We limit the annotation of CLINKs to the pres-
ence of an explicit causal construction linking two
events, which can be one of the following cases:
</bodyText>
<listItem confidence="0.984621944444444">
1. Expressions containing affect verbs (affect,
influence, determine, change), e.g. Ogun ACN
crisis S influences the launch T of the All Pro-
gressive Congress.
2. Expressions containing link verbs (link, lead,
depend on), e.g. An earthquake T in North
America was linked to a tsunami S in Japan.
3. Basic construction of causative verbs, e.g.
The purchase S caused the creation T of the
current building.
4. Periphrastic construction of causative
verbs, e.g. The blast S caused the boat to
heel T violently, where the causative verb
(caused) takes an embedded verb (heel) ex-
pressing a particular result.
5. Expressions containing causative conjunc-
tions and prepositions, which are annotated
as C-SIGNALs.
</listItem>
<bodyText confidence="0.995094">
Note that for causative verbs we consider sets of
verbs from all types of causal concepts including
CAUSE-type, ENABLE-type and PREVENT-type
verbs.
</bodyText>
<subsectionHeader confidence="0.650914">
Manual Annotation of Event Causality. Having
</subsectionHeader>
<bodyText confidence="0.9999671875">
the annotation guidelines, we are about to complete
the annotation of event causality. We have anno-
tated a subset of training corpus from TempEval-3
used in the temporal relation extraction, i.e. Time-
Bank. The agreement reached by two annotators on
a subset of 5 documents is 0.844 Dice’s coefficient
on C-SIGNALs (micro-average over markables)
and 0.73 on CLINKs.
After completing causality annotation, the next
step will be to build an automatic extraction system
for causal relations. We will consider to use a su-
pervised learning approach, as well as the similar
features employed for temporal relation classifica-
tion task, in addition to lexical information (e.g.
WordNet (Fellbaum, 1998), VerbOcean (Chklovski
and Pantel, 2004)) and the existing causal signals.
</bodyText>
<subsectionHeader confidence="0.973569">
4.3 Integrated Event Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999908117647059">
During the last stage of our research work, we will
investigate the interaction between temporal and
causal relations, given the temporal constraint of
causality. The ultimate goal is to build an integrated
event relation extraction system, that is capable of
automatically extracting both temporal and causal
relations from text.
Few works have investigated the interaction be-
tween these two types of relations. The corpus
analysis conducted by Bethard et al. (2008) shows
that although it is expected that almost every causal
relation would have an underlying before relation,
in reality, 32% of causal relations in the corpus are
not accompanied by underlying before relations.
One of the possible causes is that the considered
event pairs are conjoined event pairs under the am-
biguous and conjunctive.
</bodyText>
<page confidence="0.997762">
14
</page>
<bodyText confidence="0.999981155172414">
Consider the sentence “The walls were
shaking T because of the earthquake S.” Looking
at the explicit causal mark because, there is a causal
relation between the events shaking and earthquake.
However, according to Allen’s interval algebra or
the TimeML annotation framework we cannot say
that event earthquake occurred BEFORE the event
shaking, because both events happen almost at
the same time (could be SIMULTANOUS), and in
both frameworks there is no overlap in BEFORE
relations. During our manual annotation process,
we encountered the case where the cause event
happens after the effect, as in “Some analysts
questioned T how much of an impact the retirement
package will have, because few jobs will end S
up being eliminated.” Further investigations are
needed to address this issue.
Rink et al. (2010) makes use of manually anno-
tated temporal relation types as a feature to build
a classification model for causal relations between
events. This results in 57.9% of F1-Score, 15% im-
provement of performance in comparison with the
system without the additional feature of temporal
relations. The significant increase of performance
proves that the temporal relations between causal
events have a significant role in discovering causal
relations. On the other hand, a brief analysis into
our preliminary result on temporal relation extrac-
tion shows that there is a possibility to employ
causality to improve the temporal relation classifi-
cation of event-event pairs, specifically to reduce
the number of false positives and false negatives of
BEFORE and AFTER relations scored by the sys-
tem. Our hypothesis is that temporal and causal
relations can be of mutual benefit to the extraction
of each other.
Taking into account different classification
frameworks and possible configurations for the in-
tegrated system, for example, cascading the tempo-
ral and causal relation extraction systems, or one
system for both relation types in one pass, we will
explore the possibilities and evaluate their perfor-
mances. Furthermore, there is a possibility to ex-
ploit a global optimization algorithm, as explored
by Chambers and Jurafsky (2008) and Do et al.
(2012), to improve the performance of a pairwise
classification system.
One possible classification algorithm under our
considerations, which can be used for extracting
both temporal and causal relations in one pass,
is General Conditional Random Fields (CRFs).
General CRFs allow us to train a classification
model with arbitrary graphical structure, e.g. a
two-dimensional CRF can be used to perform both
noun phrase chunking and PoS tagging at the same
time. And its skip-chain mechanism allows us to
create a chain of entity pairs, which may improve
the classification performance.
</bodyText>
<sectionHeader confidence="0.993505" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999966171428571">
Event extraction has become one of the most in-
vestigated tasks of information extraction, since
it is the key to many applications in natural lan-
guage processing such as personalized news sys-
tems, question answering and document summa-
rization. The extraction of relations that hold be-
tween events is one of the subtasks within event ex-
traction gaining more attention in the recent years,
given the beneficial and promising applications.
We have presented a research plan covering the
topic of automatic extraction of two event relation
types, i.e. temporal and causal relations, from natu-
ral language texts. While there has been a clearly
defined framework for temporal relation extraction
task, namely TempEval-3, there is none for causal
relation extraction. Furthermore, since causality
has a temporal constraint, we are interested in in-
vestigating the interaction between temporal and
causal relations, in the context of events.
We propose a three-stage approach to cover this
research topic. The first stage includes improv-
ing the state-of-the-art performance on temporal
relation extraction. During the second stage we
propose an annotation scheme to create a corpus
for causal relations, based on the established anno-
tation framework for events and temporal relations,
namely TimeML. The created language resource
will then be used to build the automatic extraction
system for causal relations, and also to provide
the benchmarking evaluation corpus. Finally, the
last stage includes investigating the interaction be-
tween temporal and causal relations, in order to
build an integrated system for event relation ex-
traction, which is the ultimate goal of this research
work.
</bodyText>
<sectionHeader confidence="0.998088" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.6474512">
The research leading to this paper was partially
supported by the European Union’s 7th Frame-
work Programme via the NewsReader Project (ICT-
316404). We also thank Google for travel and
conference support for this paper.
</bodyText>
<page confidence="0.997149">
15
</page>
<sectionHeader confidence="0.989627" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999531385321101">
James Allan, editor. 2002. Topic Detection and
Tracking: Event-based Information Organization.
Kluwer Academic Publishers, Norwell, MA, USA.
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Commun. ACM, 26(11):832–
843, November.
Steven Bethard, William Corvey, Sara Klingenstein,
and James H. Martin. 2008. Building a corpus
of temporal-causal structure. In Proceedings of
the Sixth International Conference on Language Re-
sources and Evaluation (LREC’08), Marrakech, Mo-
rocco, May. European Language Resources Associ-
ation (ELRA).
Nathanael Chambers and Dan Jurafsky. 2008. Jointly
combining implicit constraints improves temporal
ordering. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’08, pages 698–706, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Nate Chambers. 2013. Navytime: Event and time or-
dering from raw text. In Second Joint Conference
on Lexical and Computational Semantics (*SEM),
Volume 2: Proceedings of the Seventh International
Workshop on Semantic Evaluation (SemEval 2013),
pages 73–77, Atlanta, Georgia, USA, June. Associa-
tion for Computational Linguistics.
Patricia W. Cheng and Laura R. Novick. 1991. Causes
versus enabling conditions. Cognition, 40(1-2):83 –
120.
Patricia W. Cheng and Laura R. Novick. 1992. Co-
variation in natural causal induction. Psychological
Review, 99(2):365–382.
Timothy Chklovski and Patrick Pantel. 2004. Ver-
bocean: Mining the web for fine-grained semantic
verb relations. In Dekang Lin and Dekai Wu, ed-
itors, Proceedings of EMNLP 2004, pages 33–40,
Barcelona, Spain, July. Association for Computa-
tional Linguistics.
Linguistic Data Consortium, 2005. ACE (Automatic
Content Extraction) English Annotation Guidelines
for Events.
Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint
inference for event timeline construction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, EMNLP-
CoNLL ’12, pages 677–687, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Jennifer D’Souza and Vincent Ng. 2013. Classifying
temporal relations with rich linguistic knowledge.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 918–927.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Michael J. Fischer and Albert R. Meyer. 1971.
Boolean matrix multiplication and transitive closure.
In SWAT (FOCS), pages 129–131. IEEE Computer
Society.
Aldo Gangemi, Nicola Guarino, Claudio Masolo,
Alessandro Oltramari, and Luc Schneider. 2002.
Sweetening ontologies with dolce. In Proceedings
of the 13th International Conference on Knowledge
Engineering and Knowledge Management. Ontolo-
gies and the Semantic Web, EKAW ’02, pages 166–
181, London, UK, UK. Springer-Verlag.
Alfonso Gerevini, Lenhart Schubert, and Stephanie
Schaeffer. 1995. The temporal reasoning tools time-
graph i-ii. International Journal of Artificial Intelli-
gence Tools, 4(1-2):281–299.
Natsuda Laokulrat, Makoto Miwa, Yoshimasa Tsu-
ruoka, and Takashi Chikayama. 2013. Uttime: Tem-
poral relation classification using deep syntactic fea-
tures. In Second Joint Conference on Lexical and
Computational Semantics (*SEM), Volume 2: Pro-
ceedings of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013), pages 88–92,
Atlanta, Georgia, USA, June. Association for Com-
putational Linguistics.
David Lewis. 1973. Causation. The Journal of Philos-
ophy, 70(17):pp. 556–567.
Inderjeet Mani, Marc Verhagen, Ben Wellner,
Chong Min Lee, and James Pustejovsky. 2006. Ma-
chine learning of temporal relations. In Proceedings
of the 21st International Conference on Compu-
tational Linguistics and the 44th Annual Meeting
of the Association for Computational Linguistics,
ACL-44, pages 753–760, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Paramita Mirza and Sara Tonelli. 2014. Classifying
temporal relations with simple features. In Proceed-
ings of the 14th Conference of the European Chapter
of the Association for Computational Linguistics.
Paramita Mirza, Rachele Sprugnoli, Sara Tonelli, and
Manuela Speranza. 2014. Annotating causality in
the tempeval-3 corpus. In Proceedings of the EACL-
2014 Workshop on Computational Approaches to
Causality in Language (CAtoCL).
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated corpus
of semantic roles. Comput. Linguist., 31(1):71–106,
March.
Emily Pitler and Ani Nenkova. 2009. Using syn-
tax to disambiguate explicit discourse connectives
in text. In Proceedings of the ACL-IJCNLP 2009
Conference Short Papers, ACLShort ’09, pages 13–
16, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
</reference>
<page confidence="0.970997">
16
</page>
<reference confidence="0.999875823529412">
Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee, Aravind Joshi, Livio Robaldo, and Bonnie L
Webber. 2007. The penn discourse treebank 2.0 an-
notation manual. Technical report.
J. Pustejovsky, P. Hanks, R. Sauri, A. See,
R. Gaizauskas, A. Setzer, D. Radev, B. Sund-
heim, D. Day, L. Ferro, et al. 2003a. The timebank
corpus. In Corpus Linguistics, volume 2003,
page 40.
James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, and Gra-
ham Katz. 2003b. Timeml: Robust specification of
event and temporal expressions in text. In Proceed-
ings of the Fifth International Workshop on Compu-
tational Semantics (IWCS-5).
Bryan Rink, Cosmin Adrian Bejan, and Sanda M.
Harabagiu. 2010. Learning textual graph patterns
to detect causal event relations. In FLAIRS Confer-
ence.
Roser Saur´ı, Jessica Littman, Robert Gaizauskas, An-
drea Setzer, and James Pustejovsky, 2006. TimeML
Annotation Guidelines, Version 1.2.1.
Ryan Shaw, Rapha¨el Troncy, and Lynda Hardman.
2009. Lode: Linking open descriptions of events.
In Proceedings of the 4th Asian Conference on The
Semantic Web, ASWC ’09, pages 153–167, Berlin,
Heidelberg. Springer-Verlag.
Leonard Talmy. 1985. Force dynamics in lan-
guage and thought. Chicago Linguistic Society,
21:293337.
Leonard Talmy. 1988. Force dynamics in language
and cognition. Cognitive Science, 12(1):49–100.
Naushad UzZaman, Hector Llorens, James F. Allen,
Leon Derczynski, Marc Verhagen, and James Puste-
jovsky. 2012. Tempeval-3: Evaluating events,
time expressions, and temporal relations. CoRR,
abs/1206.5333.
Naushad UzZaman, Hector Llorens, Leon Derczyn-
ski, James Allen, Marc Verhagen, and James Puste-
jovsky. 2013. Semeval-2013 task 1: Tempeval-3:
Evaluating time expressions, events, and temporal
relations. In Proceedings of the Seventh Interna-
tional Workshop on Semantic Evaluation, SemEval
’13, pages 1–9, Atlanta, Georgia, USA, June. Asso-
ciation for Computational Linguistics.
H van de Koot and A Neeleman, 2012. The Theta Sys-
tem: Argument Structure at the Interface, chapter
The Linguistic Expression of Causation, pages 20 –
51. Oxford University Press: Oxford.
Willem Robert van Hage, V´eronique Malais´e, Roxane
Segers, Laura Hollink, and Guus Schreiber. 2011.
Design and use of the simple event model (sem).
Journal of Web Semantics, 9(2):128–136.
Marc Verhagen. 2005. Temporal closure in an annota-
tion environment. Language Resources and Evalua-
tion, 39(2-3):211–241.
Phillip Wolff and Grace Song. 2003. Models of cau-
sation and the semantics of causal verbs. Cognitive
Psychology, 47(3):276 – 332.
Phillip Wolff, Bianca Klettke, Tatyana Ventura, and
Grace Song, 2005. Categorization inside and out-
side the laboratory: Essays in honor of Douglas L.
Medin. APA decade of behavior series, chapter Ex-
pressing Causation in English and Other Languages,
pages 29–48. Washington, DC, US: American Psy-
chological Association, xx, 316 pp.
Phillip Wolff. 2007. Representing causation. Journal
of Experiment Psychology: General, 136:82–111.
</reference>
<page confidence="0.999409">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.452619">
<title confidence="0.920845">Extracting Temporal and Causal Relations between Events Paramita</title>
<author confidence="0.974541">Fondazione Bruno</author>
<affiliation confidence="0.776972">University of Trento,</affiliation>
<email confidence="0.997717">paramita@fbk.eu</email>
<abstract confidence="0.9990709">A notably challenging problem related to event processing is recognizing the relations holding between events in a text, in particular temporal and causal relations. While there has been some research on temporal relations, the aspect of causality between events from a Natural Language Processing (NLP) perspective has hardly been touched. We propose an annotation scheme to cover different types of causality between events, techniques for extracting such relations and an investigation into the connection between temporal and causal relations. In this thesis work we aim to focus especially on the latter, because causality is presumed to have a temporal constraint. We conjecture that injecting this presumption may be beneficial for the recognition of both temporal and causal relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Topic Detection and Tracking: Event-based Information Organization.</title>
<date>2002</date>
<editor>James Allan, editor.</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Norwell, MA, USA.</location>
<marker>2002</marker>
<rawString>James Allan, editor. 2002. Topic Detection and Tracking: Event-based Information Organization. Kluwer Academic Publishers, Norwell, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Commun. ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<pages>843</pages>
<contexts>
<context position="8409" citStr="Allen, 1983" startWordPosition="1298" endWordPosition="1299">etailed description of these aspects including the arising challenges, some preliminary results to address the challenges and our future research directions. 4.1 Temporal Relation Extraction As previously mentioned, we consider the TimeML annotation framework because it explicitly encodes the temporal links between entities (events and temporal expressions) in a text. In TimeML, each temporal link has a temporal relation type assigned to it. There are 14 types of temporal relations specified in TimeML version 1.2.1 (Saur´ı et al., 2006), 11 which are defined based on Allen’s interval algebra (Allen, 1983), as illustrated in Table 1. a |——— |a is BEFORE b b |——— |b is AFTER a a |——— |a is IBEFORE b b |——— |b is IAFTER a a |—— |a BEGINS b b |———— |b is BEGUN BY a a|—— |a ENDS b b |———— |bis ENDED BY a a |—— |a is DURING b b ||b is DURING INV a a ||a INCLUDES b b|—— |b IS INCLUDED in a a |——— |a is SIMULTANEOUS with b b |———| a |——— |b a is IDENTITY with b Table 1: Temporal relations in TimeML annotation Recalling the low performances of currently available systems on the temporal relation extraction task, including the state-of-the-art systems according to TempEval-3, it is still insufficient to</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Commun. ACM, 26(11):832– 843, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>William Corvey</author>
<author>Sara Klingenstein</author>
<author>James H Martin</author>
</authors>
<title>Building a corpus of temporal-causal structure.</title>
<date>2008</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="21521" citStr="Bethard et al. (2008)" startWordPosition="3366" endWordPosition="3369">rmation (e.g. WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004)) and the existing causal signals. 4.3 Integrated Event Relation Extraction During the last stage of our research work, we will investigate the interaction between temporal and causal relations, given the temporal constraint of causality. The ultimate goal is to build an integrated event relation extraction system, that is capable of automatically extracting both temporal and causal relations from text. Few works have investigated the interaction between these two types of relations. The corpus analysis conducted by Bethard et al. (2008) shows that although it is expected that almost every causal relation would have an underlying before relation, in reality, 32% of causal relations in the corpus are not accompanied by underlying before relations. One of the possible causes is that the considered event pairs are conjoined event pairs under the ambiguous and conjunctive. 14 Consider the sentence “The walls were shaking T because of the earthquake S.” Looking at the explicit causal mark because, there is a causal relation between the events shaking and earthquake. However, according to Allen’s interval algebra or the TimeML anno</context>
</contexts>
<marker>Bethard, Corvey, Klingenstein, Martin, 2008</marker>
<rawString>Steven Bethard, William Corvey, Sara Klingenstein, and James H. Martin. 2008. Building a corpus of temporal-causal structure. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), Marrakech, Morocco, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Jointly combining implicit constraints improves temporal ordering.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>698--706</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="24000" citStr="Chambers and Jurafsky (2008)" startWordPosition="3756" endWordPosition="3759"> false positives and false negatives of BEFORE and AFTER relations scored by the system. Our hypothesis is that temporal and causal relations can be of mutual benefit to the extraction of each other. Taking into account different classification frameworks and possible configurations for the integrated system, for example, cascading the temporal and causal relation extraction systems, or one system for both relation types in one pass, we will explore the possibilities and evaluate their performances. Furthermore, there is a possibility to exploit a global optimization algorithm, as explored by Chambers and Jurafsky (2008) and Do et al. (2012), to improve the performance of a pairwise classification system. One possible classification algorithm under our considerations, which can be used for extracting both temporal and causal relations in one pass, is General Conditional Random Fields (CRFs). General CRFs allow us to train a classification model with arbitrary graphical structure, e.g. a two-dimensional CRF can be used to perform both noun phrase chunking and PoS tagging at the same time. And its skip-chain mechanism allows us to create a chain of entity pairs, which may improve the classification performance.</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 698–706, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nate Chambers</author>
</authors>
<title>Navytime: Event and time ordering from raw text.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>73--77</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="10919" citStr="Chambers, 2013" startWordPosition="1720" endWordPosition="1721"> events and time expressions are already established. Several recent works have tried to address this complex multi-class classification task by using sophisticated features based on deep parsing, semantic role labelling and discourse parsing (D’Souza and Ng, 2013; Laokulrat et al., 2013). In Mirza and Tonelli (2014) we have shown that a simpler approach, based on lexico-syntactic features, can achieve comparable results. A classification model is trained for each category of entity pair, i.e. event-event, event-timex and timex-timex, as suggested in several previous works (Mani et al., 2006; Chambers, 2013). However, because there are very few examples of timextimex pairs in the training corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disregard these pairs. We follow the guidelines and the dataset provided by the organizers of TempEval-3 so that we can compare our system with other systems participating in the challenge. The TBAQ-cleaned corpus is the training set provided for the task, consisting of the TimeBank (Pustejovsky et al., 2003a) and the AQUAINT corpo</context>
</contexts>
<marker>Chambers, 2013</marker>
<rawString>Nate Chambers. 2013. Navytime: Event and time ordering from raw text. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 73–77, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patricia W Cheng</author>
<author>Laura R Novick</author>
</authors>
<title>Causes versus enabling conditions.</title>
<date>1991</date>
<journal>Cognition,</journal>
<pages>40--1</pages>
<contexts>
<context position="16049" citStr="Cheng and Novick, 1991" startWordPosition="2508" endWordPosition="2511">tion on the classification of temporal relation types 4.2 Causal Relation Extraction Unlike the temporal order that has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is</context>
</contexts>
<marker>Cheng, Novick, 1991</marker>
<rawString>Patricia W. Cheng and Laura R. Novick. 1991. Causes versus enabling conditions. Cognition, 40(1-2):83 – 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patricia W Cheng</author>
<author>Laura R Novick</author>
</authors>
<title>Covariation in natural causal induction.</title>
<date>1992</date>
<journal>Psychological Review,</journal>
<volume>99</volume>
<issue>2</issue>
<contexts>
<context position="16074" citStr="Cheng and Novick, 1992" startWordPosition="2512" endWordPosition="2515">on of temporal relation types 4.2 Causal Relation Extraction Unlike the temporal order that has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though t</context>
</contexts>
<marker>Cheng, Novick, 1992</marker>
<rawString>Patricia W. Cheng and Laura R. Novick. 1992. Covariation in natural causal induction. Psychological Review, 99(2):365–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>Verbocean: Mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>33--40</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="20978" citStr="Chklovski and Pantel, 2004" startWordPosition="3285" endWordPosition="3288"> subset of training corpus from TempEval-3 used in the temporal relation extraction, i.e. TimeBank. The agreement reached by two annotators on a subset of 5 documents is 0.844 Dice’s coefficient on C-SIGNALs (micro-average over markables) and 0.73 on CLINKs. After completing causality annotation, the next step will be to build an automatic extraction system for causal relations. We will consider to use a supervised learning approach, as well as the similar features employed for temporal relation classification task, in addition to lexical information (e.g. WordNet (Fellbaum, 1998), VerbOcean (Chklovski and Pantel, 2004)) and the existing causal signals. 4.3 Integrated Event Relation Extraction During the last stage of our research work, we will investigate the interaction between temporal and causal relations, given the temporal constraint of causality. The ultimate goal is to build an integrated event relation extraction system, that is capable of automatically extracting both temporal and causal relations from text. Few works have investigated the interaction between these two types of relations. The corpus analysis conducted by Bethard et al. (2008) shows that although it is expected that almost every cau</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. Verbocean: Mining the web for fine-grained semantic verb relations. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 33–40, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linguistic Data Consortium</author>
</authors>
<date>2005</date>
<journal>ACE (Automatic Content Extraction) English Annotation Guidelines for Events.</journal>
<contexts>
<context position="4132" citStr="Consortium, 2005" startWordPosition="639" endWordPosition="640"> describes something that happens and is usually used to identify a cluster of documents, e.g. Olympics, wars. On the other hand, information extraction provides finer granularity of event definitions, in which events 10 Proceedings of the ACL 2014 Student Research Workshop, pages 10–17, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics are entities that happen/occur within the scope of a document. There are several annotation frameworks for events and temporal expressions that can be viewed as event models,1 TimeML (Pustejovsky et al., 2003b) and ACE (Consortium, 2005) being the prominent ones. Both TimeML and ACE define an event as something that happens/occurs or a state that holds true, which can be expressed by a verb, a noun, an adjective, as well as a nominalization either from verbs or adjectives. Consider the following passage annotated with events and temporal expressions (TIMEX). “A Philippine volcano, dormant EVENT for six centuries TIMEX, exploded EVENT last Monday TIMEX. During the eruption EVENT, lava, rocks and red-hot ash are spewed EVENT onto surrounding villages. The explosion EVENT claimed EVENT at least 30 lives.” The most important attr</context>
</contexts>
<marker>Consortium, 2005</marker>
<rawString>Linguistic Data Consortium, 2005. ACE (Automatic Content Extraction) English Annotation Guidelines for Events.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Xuan Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint inference for event timeline construction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLPCoNLL ’12,</booktitle>
<pages>677--687</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="24021" citStr="Do et al. (2012)" startWordPosition="3761" endWordPosition="3764">ves of BEFORE and AFTER relations scored by the system. Our hypothesis is that temporal and causal relations can be of mutual benefit to the extraction of each other. Taking into account different classification frameworks and possible configurations for the integrated system, for example, cascading the temporal and causal relation extraction systems, or one system for both relation types in one pass, we will explore the possibilities and evaluate their performances. Furthermore, there is a possibility to exploit a global optimization algorithm, as explored by Chambers and Jurafsky (2008) and Do et al. (2012), to improve the performance of a pairwise classification system. One possible classification algorithm under our considerations, which can be used for extracting both temporal and causal relations in one pass, is General Conditional Random Fields (CRFs). General CRFs allow us to train a classification model with arbitrary graphical structure, e.g. a two-dimensional CRF can be used to perform both noun phrase chunking and PoS tagging at the same time. And its skip-chain mechanism allows us to create a chain of entity pairs, which may improve the classification performance. 5 Conclusion Event e</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint inference for event timeline construction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLPCoNLL ’12, pages 677–687, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer D’Souza</author>
<author>Vincent Ng</author>
</authors>
<title>Classifying temporal relations with rich linguistic knowledge.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>918--927</pages>
<marker>D’Souza, Ng, 2013</marker>
<rawString>Jennifer D’Souza and Vincent Ng. 2013. Classifying temporal relations with rich linguistic knowledge. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 918–927.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Fischer</author>
<author>Albert R Meyer</author>
</authors>
<title>Boolean matrix multiplication and transitive closure.</title>
<date>1971</date>
<booktitle>In SWAT (FOCS),</booktitle>
<pages>129--131</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="13351" citStr="Fischer and Meyer, 1971" startWordPosition="2107" endWordPosition="2110">e the effect of enriching the training data with inverse relations and closure-based inferred 3http://chasen.org/∼taku/software/yamcha/ 12 relations. However, we adopt a simpler approach to obtain the closure graph of temporal relations, by applying the transitive closure only within the same relation type, e.g. e1 BEFORE e2 ∧ e2 BEFORE e3 → e1 BEFORE e3. It produces only a subset of the relations produced by the temporal closure (Verhagen, 2005; Gerevini et al., 1995). The problem of finding the transitive closure of a directed acyclic graph can be reduced to a boolean matrix multiplication (Fischer and Meyer, 1971). Training data event-event event-timex TBAQ 48.28% 73.82% TBAQ-I 47.77% 74.45% TBAQ-IC 46.39% 74.45% Table 2: Classifier accuracies with different training data: TBAQ (TimeBank+AQUAINT), TBAQ-I (TBAQ+inverse relations) and TBAQ-IC (TBAQ+inverse relations+transitive closure). Evaluation and Analysis. Our test data is the newly annotated TempEval-3-platinum evaluation corpus provided by TempEval-3 organizers, so that we can compare our system with other systems participating in the task. First, to investigate the effect of enriching the training data with inverse relations and transitive closur</context>
</contexts>
<marker>Fischer, Meyer, 1971</marker>
<rawString>Michael J. Fischer and Albert R. Meyer. 1971. Boolean matrix multiplication and transitive closure. In SWAT (FOCS), pages 129–131. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldo Gangemi</author>
<author>Nicola Guarino</author>
<author>Claudio Masolo</author>
<author>Alessandro Oltramari</author>
<author>Luc Schneider</author>
</authors>
<title>Sweetening ontologies with dolce.</title>
<date>2002</date>
<booktitle>In Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management. Ontologies and the Semantic Web, EKAW ’02,</booktitle>
<pages>166--181</pages>
<publisher>UK. Springer-Verlag.</publisher>
<location>London, UK,</location>
<contexts>
<context position="6122" citStr="Gangemi et al., 2002" startWordPosition="945" endWordPosition="948">rocessing. The ultimate goal of this evaluation campaign is the automatic identification of temporal expressions, events, and temporal relations within a text (UzZaman et al., 2012). The main tasks defined in TempEval-3 include: the automatic extraction of TimeML entities, i.e. temporal expressions and events, and the end-toend automatic extraction of both TimeML entities and temporal links/relations. The result of TempEval-3 reported by UzZaman et al. (2013) 1There are other event models based on web ontology (RDFS+OWL) such as LODE (Shaw et al., 2009), SEM (van Hage et al., 2011) and DOLCE (Gangemi et al., 2002), which encode knowledge about events as triples. Such models can be seen as ways to store the extracted knowledge to perform the reasoning on. 2http://www.cs.york.ac.uk/semeval-2013/task1/ shows that even though the performances of systems for extracting TimeML entities are quite good (&gt;80% F-score), the overall performance of endto-end event extraction systems suffers from the low performance of the temporal relation extraction system. The state-of-the-art performance on the temporal relation extraction task yields only around 36% F-score. This becomes the main reason of focusing our researc</context>
</contexts>
<marker>Gangemi, Guarino, Masolo, Oltramari, Schneider, 2002</marker>
<rawString>Aldo Gangemi, Nicola Guarino, Claudio Masolo, Alessandro Oltramari, and Luc Schneider. 2002. Sweetening ontologies with dolce. In Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management. Ontologies and the Semantic Web, EKAW ’02, pages 166– 181, London, UK, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfonso Gerevini</author>
<author>Lenhart Schubert</author>
<author>Stephanie Schaeffer</author>
</authors>
<title>The temporal reasoning tools timegraph i-ii.</title>
<date>1995</date>
<journal>International Journal of Artificial Intelligence Tools,</journal>
<pages>4--1</pages>
<contexts>
<context position="13200" citStr="Gerevini et al., 1995" startWordPosition="2082" endWordPosition="2085">of Mani et al. (2006) that bootstrapping the training data through a temporal closure method results in quite significant improvements, we investigate the effect of enriching the training data with inverse relations and closure-based inferred 3http://chasen.org/∼taku/software/yamcha/ 12 relations. However, we adopt a simpler approach to obtain the closure graph of temporal relations, by applying the transitive closure only within the same relation type, e.g. e1 BEFORE e2 ∧ e2 BEFORE e3 → e1 BEFORE e3. It produces only a subset of the relations produced by the temporal closure (Verhagen, 2005; Gerevini et al., 1995). The problem of finding the transitive closure of a directed acyclic graph can be reduced to a boolean matrix multiplication (Fischer and Meyer, 1971). Training data event-event event-timex TBAQ 48.28% 73.82% TBAQ-I 47.77% 74.45% TBAQ-IC 46.39% 74.45% Table 2: Classifier accuracies with different training data: TBAQ (TimeBank+AQUAINT), TBAQ-I (TBAQ+inverse relations) and TBAQ-IC (TBAQ+inverse relations+transitive closure). Evaluation and Analysis. Our test data is the newly annotated TempEval-3-platinum evaluation corpus provided by TempEval-3 organizers, so that we can compare our system wit</context>
</contexts>
<marker>Gerevini, Schubert, Schaeffer, 1995</marker>
<rawString>Alfonso Gerevini, Lenhart Schubert, and Stephanie Schaeffer. 1995. The temporal reasoning tools timegraph i-ii. International Journal of Artificial Intelligence Tools, 4(1-2):281–299.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Natsuda Laokulrat</author>
<author>Makoto Miwa</author>
<author>Yoshimasa Tsuruoka</author>
<author>Takashi Chikayama</author>
</authors>
<title>Uttime: Temporal relation classification using deep syntactic features.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>88--92</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="10593" citStr="Laokulrat et al., 2013" startWordPosition="1668" endWordPosition="1671">garded as a classification problem. Given an ordered pair of entities (e1, e2) that could be either event-event, event-timex or timex-timex pair, the classifier has to assign a certain label representing the temporal relation type. We focus on the latter subtask of classifying temporal relation types, assuming that the links between events and time expressions are already established. Several recent works have tried to address this complex multi-class classification task by using sophisticated features based on deep parsing, semantic role labelling and discourse parsing (D’Souza and Ng, 2013; Laokulrat et al., 2013). In Mirza and Tonelli (2014) we have shown that a simpler approach, based on lexico-syntactic features, can achieve comparable results. A classification model is trained for each category of entity pair, i.e. event-event, event-timex and timex-timex, as suggested in several previous works (Mani et al., 2006; Chambers, 2013). However, because there are very few examples of timextimex pairs in the training corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disrega</context>
</contexts>
<marker>Laokulrat, Miwa, Tsuruoka, Chikayama, 2013</marker>
<rawString>Natsuda Laokulrat, Makoto Miwa, Yoshimasa Tsuruoka, and Takashi Chikayama. 2013. Uttime: Temporal relation classification using deep syntactic features. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 88–92, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Lewis</author>
</authors>
<date>1973</date>
<journal>Causation. The Journal of Philosophy,</journal>
<volume>70</volume>
<issue>17</issue>
<pages>556--567</pages>
<contexts>
<context position="15995" citStr="Lewis, 1973" startWordPosition="2502" endWordPosition="2503">77% 35.07% 34.48% Table 3: TempEval-3 evaluation on the classification of temporal relation types 4.2 Causal Relation Extraction Unlike the temporal order that has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is importan</context>
</contexts>
<marker>Lewis, 1973</marker>
<rawString>David Lewis. 1973. Causation. The Journal of Philosophy, 70(17):pp. 556–567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, ACL-44,</booktitle>
<pages>753--760</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10902" citStr="Mani et al., 2006" startWordPosition="1716" endWordPosition="1719">t the links between events and time expressions are already established. Several recent works have tried to address this complex multi-class classification task by using sophisticated features based on deep parsing, semantic role labelling and discourse parsing (D’Souza and Ng, 2013; Laokulrat et al., 2013). In Mirza and Tonelli (2014) we have shown that a simpler approach, based on lexico-syntactic features, can achieve comparable results. A classification model is trained for each category of entity pair, i.e. event-event, event-timex and timex-timex, as suggested in several previous works (Mani et al., 2006; Chambers, 2013). However, because there are very few examples of timextimex pairs in the training corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disregard these pairs. We follow the guidelines and the dataset provided by the organizers of TempEval-3 so that we can compare our system with other systems participating in the challenge. The TBAQ-cleaned corpus is the training set provided for the task, consisting of the TimeBank (Pustejovsky et al., 2003a) and </context>
<context position="12599" citStr="Mani et al. (2006)" startWordPosition="1991" endWordPosition="1994">ver, we avoid complex processing of data. Such semantic information is based on external lists of lexical items and on the output of the addDiscourse tagger (Pitler and Nenkova, 2009). We build our classification models using the Support Vector Machine (SVM) implementation provided by YamCha3. We perform feature engineering in order to select from our initial set of features only those that improve the accuracy of the classifiers. This allows us to select the best classification models for both event-event pairs and event-timex pairs. Inverse Relations and Closure. Motivated by the finding of Mani et al. (2006) that bootstrapping the training data through a temporal closure method results in quite significant improvements, we investigate the effect of enriching the training data with inverse relations and closure-based inferred 3http://chasen.org/∼taku/software/yamcha/ 12 relations. However, we adopt a simpler approach to obtain the closure graph of temporal relations, by applying the transitive closure only within the same relation type, e.g. e1 BEFORE e2 ∧ e2 BEFORE e3 → e1 BEFORE e3. It produces only a subset of the relations produced by the temporal closure (Verhagen, 2005; Gerevini et al., 1995</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, ACL-44, pages 753–760, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramita Mirza</author>
<author>Sara Tonelli</author>
</authors>
<title>Classifying temporal relations with simple features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10622" citStr="Mirza and Tonelli (2014)" startWordPosition="1673" endWordPosition="1676">roblem. Given an ordered pair of entities (e1, e2) that could be either event-event, event-timex or timex-timex pair, the classifier has to assign a certain label representing the temporal relation type. We focus on the latter subtask of classifying temporal relation types, assuming that the links between events and time expressions are already established. Several recent works have tried to address this complex multi-class classification task by using sophisticated features based on deep parsing, semantic role labelling and discourse parsing (D’Souza and Ng, 2013; Laokulrat et al., 2013). In Mirza and Tonelli (2014) we have shown that a simpler approach, based on lexico-syntactic features, can achieve comparable results. A classification model is trained for each category of entity pair, i.e. event-event, event-timex and timex-timex, as suggested in several previous works (Mani et al., 2006; Chambers, 2013). However, because there are very few examples of timextimex pairs in the training corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disregard these pairs. We follow the</context>
</contexts>
<marker>Mirza, Tonelli, 2014</marker>
<rawString>Paramita Mirza and Sara Tonelli. 2014. Classifying temporal relations with simple features. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramita Mirza</author>
<author>Rachele Sprugnoli</author>
<author>Sara Tonelli</author>
<author>Manuela Speranza</author>
</authors>
<title>Annotating causality in the tempeval-3 corpus.</title>
<date>2014</date>
<booktitle>In Proceedings of the EACL2014 Workshop on Computational Approaches to Causality in Language (CAtoCL).</booktitle>
<contexts>
<context position="17499" citStr="Mirza et al. (2014)" startWordPosition="2734" endWordPosition="2737">luating event causality extraction, as it is available for temporal relations in TimeML. This motivates us to create a language resource annotated with both temporal and causal relations in a unified annotation scheme, for the main purpose of investigating the interaction between both types of relations. It becomes the objective of the second stage of our research, in 4PDTB annotates causality between related clauses, while PropBank annotates causality between a verb and its cause clause. 13 addition to building an automatic extraction system for event causality using the developed corpus. In Mirza et al. (2014) we have proposed annotation guidelines for causality between events, based on the TimeML definition of events, which considers all types of actions (punctual and durative) and states as events. Parallel to the &lt;TLINK&gt; tag in TimeML for temporal relations, we introduced the &lt;CLINK&gt; tag to signify a causal link. We also introduced the notion of causal signals through the &lt;C-SIGNAL&gt; tag, parallel to the &lt;SIGNAL&gt; tag in TimeML indicating temporal cues. C-SIGNAL. C-SIGNAL is used to mark-up textual elements signalling the presence of causal relations, which include all causal uses of: prepositions</context>
</contexts>
<marker>Mirza, Sprugnoli, Tonelli, Speranza, 2014</marker>
<rawString>Paramita Mirza, Rachele Sprugnoli, Sara Tonelli, and Manuela Speranza. 2014. Annotating causality in the tempeval-3 corpus. In Proceedings of the EACL2014 Workshop on Computational Approaches to Causality in Language (CAtoCL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Comput. Linguist.,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="16817" citStr="Palmer et al., 2005" startWordPosition="2628" endWordPosition="2631">count of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Discourse Treebank (PDTB) (Prasad et al., 2007) and PropBank (Palmer et al., 2005),4 we are not aware of any standard benchmarking corpus for evaluating event causality extraction, as it is available for temporal relations in TimeML. This motivates us to create a language resource annotated with both temporal and causal relations in a unified annotation scheme, for the main purpose of investigating the interaction between both types of relations. It becomes the objective of the second stage of our research, in 4PDTB annotates causality between related clauses, while PropBank annotates causality between a verb and its cause clause. 13 addition to building an automatic extrac</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Comput. Linguist., 31(1):71–106, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Using syntax to disambiguate explicit discourse connectives in text.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09,</booktitle>
<pages>13--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12164" citStr="Pitler and Nenkova, 2009" startWordPosition="1923" endWordPosition="1926">nd 100K words in total, with 11K words annotated as events (UzZaman et al., 2013). Simple Feature Set. We implement a number of features including the commonly used ones (UzZaman et al., 2013), which take into account morphosyntactic information on events and time expressions, their textual context and their attributes. Other features rely on semantic information such as typical event durations and explicit temporal connective types. However, we avoid complex processing of data. Such semantic information is based on external lists of lexical items and on the output of the addDiscourse tagger (Pitler and Nenkova, 2009). We build our classification models using the Support Vector Machine (SVM) implementation provided by YamCha3. We perform feature engineering in order to select from our initial set of features only those that improve the accuracy of the classifiers. This allows us to select the best classification models for both event-event pairs and event-timex pairs. Inverse Relations and Closure. Motivated by the finding of Mani et al. (2006) that bootstrapping the training data through a temporal closure method results in quite significant improvements, we investigate the effect of enriching the trainin</context>
</contexts>
<marker>Pitler, Nenkova, 2009</marker>
<rawString>Emily Pitler and Ani Nenkova. 2009. Using syntax to disambiguate explicit discourse connectives in text. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09, pages 13– 16, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Eleni Miltsakaki</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Aravind Joshi</author>
<author>Livio Robaldo</author>
<author>Bonnie L Webber</author>
</authors>
<title>The penn discourse treebank 2.0 annotation manual.</title>
<date>2007</date>
<tech>Technical report.</tech>
<contexts>
<context position="16782" citStr="Prasad et al., 2007" startWordPosition="2622" endWordPosition="2625">s based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Discourse Treebank (PDTB) (Prasad et al., 2007) and PropBank (Palmer et al., 2005),4 we are not aware of any standard benchmarking corpus for evaluating event causality extraction, as it is available for temporal relations in TimeML. This motivates us to create a language resource annotated with both temporal and causal relations in a unified annotation scheme, for the main purpose of investigating the interaction between both types of relations. It becomes the objective of the second stage of our research, in 4PDTB annotates causality between related clauses, while PropBank annotates causality between a verb and its cause clause. 13 addit</context>
</contexts>
<marker>Prasad, Miltsakaki, Dinesh, Lee, Joshi, Robaldo, Webber, 2007</marker>
<rawString>Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan Lee, Aravind Joshi, Livio Robaldo, and Bonnie L Webber. 2007. The penn discourse treebank 2.0 annotation manual. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Hanks</author>
<author>R Sauri</author>
<author>A See</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>D Radev</author>
<author>B Sundheim</author>
<author>D Day</author>
<author>L Ferro</author>
</authors>
<date>2003</date>
<note>The timebank</note>
<contexts>
<context position="4103" citStr="Pustejovsky et al., 2003" startWordPosition="633" endWordPosition="636">ed interchangeably with topic, which describes something that happens and is usually used to identify a cluster of documents, e.g. Olympics, wars. On the other hand, information extraction provides finer granularity of event definitions, in which events 10 Proceedings of the ACL 2014 Student Research Workshop, pages 10–17, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics are entities that happen/occur within the scope of a document. There are several annotation frameworks for events and temporal expressions that can be viewed as event models,1 TimeML (Pustejovsky et al., 2003b) and ACE (Consortium, 2005) being the prominent ones. Both TimeML and ACE define an event as something that happens/occurs or a state that holds true, which can be expressed by a verb, a noun, an adjective, as well as a nominalization either from verbs or adjectives. Consider the following passage annotated with events and temporal expressions (TIMEX). “A Philippine volcano, dormant EVENT for six centuries TIMEX, exploded EVENT last Monday TIMEX. During the eruption EVENT, lava, rocks and red-hot ash are spewed EVENT onto surrounding villages. The explosion EVENT claimed EVENT at least 30 li</context>
<context position="11495" citStr="Pustejovsky et al., 2003" startWordPosition="1817" endWordPosition="1820">evious works (Mani et al., 2006; Chambers, 2013). However, because there are very few examples of timextimex pairs in the training corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disregard these pairs. We follow the guidelines and the dataset provided by the organizers of TempEval-3 so that we can compare our system with other systems participating in the challenge. The TBAQ-cleaned corpus is the training set provided for the task, consisting of the TimeBank (Pustejovsky et al., 2003a) and the AQUAINT corpora. It contains around 100K words in total, with 11K words annotated as events (UzZaman et al., 2013). Simple Feature Set. We implement a number of features including the commonly used ones (UzZaman et al., 2013), which take into account morphosyntactic information on events and time expressions, their textual context and their attributes. Other features rely on semantic information such as typical event durations and explicit temporal connective types. However, we avoid complex processing of data. Such semantic information is based on external lists of lexical items an</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, 2003</marker>
<rawString>J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro, et al. 2003a. The timebank</rawString>
</citation>
<citation valid="true">
<authors>
<author>corpus</author>
</authors>
<date>2003</date>
<booktitle>In Corpus Linguistics,</booktitle>
<volume>volume</volume>
<pages>40</pages>
<marker>corpus, 2003</marker>
<rawString>corpus. In Corpus Linguistics, volume 2003, page 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>Timeml: Robust specification of event and temporal expressions in text.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fifth International Workshop on Computational Semantics (IWCS-5).</booktitle>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003b. Timeml: Robust specification of event and temporal expressions in text. In Proceedings of the Fifth International Workshop on Computational Semantics (IWCS-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Rink</author>
<author>Cosmin Adrian Bejan</author>
<author>Sanda M Harabagiu</author>
</authors>
<title>Learning textual graph patterns to detect causal event relations.</title>
<date>2010</date>
<booktitle>In FLAIRS Conference.</booktitle>
<contexts>
<context position="22673" citStr="Rink et al. (2010)" startWordPosition="3551" endWordPosition="3554"> However, according to Allen’s interval algebra or the TimeML annotation framework we cannot say that event earthquake occurred BEFORE the event shaking, because both events happen almost at the same time (could be SIMULTANOUS), and in both frameworks there is no overlap in BEFORE relations. During our manual annotation process, we encountered the case where the cause event happens after the effect, as in “Some analysts questioned T how much of an impact the retirement package will have, because few jobs will end S up being eliminated.” Further investigations are needed to address this issue. Rink et al. (2010) makes use of manually annotated temporal relation types as a feature to build a classification model for causal relations between events. This results in 57.9% of F1-Score, 15% improvement of performance in comparison with the system without the additional feature of temporal relations. The significant increase of performance proves that the temporal relations between causal events have a significant role in discovering causal relations. On the other hand, a brief analysis into our preliminary result on temporal relation extraction shows that there is a possibility to employ causality to impr</context>
</contexts>
<marker>Rink, Bejan, Harabagiu, 2010</marker>
<rawString>Bryan Rink, Cosmin Adrian Bejan, and Sanda M. Harabagiu. 2010. Learning textual graph patterns to detect causal event relations. In FLAIRS Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Saur´ı</author>
<author>Jessica Littman</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>James Pustejovsky</author>
</authors>
<date>2006</date>
<journal>TimeML Annotation Guidelines, Version</journal>
<volume>1</volume>
<marker>Saur´ı, Littman, Gaizauskas, Setzer, Pustejovsky, 2006</marker>
<rawString>Roser Saur´ı, Jessica Littman, Robert Gaizauskas, Andrea Setzer, and James Pustejovsky, 2006. TimeML Annotation Guidelines, Version 1.2.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Shaw</author>
<author>Rapha¨el Troncy</author>
<author>Lynda Hardman</author>
</authors>
<title>Lode: Linking open descriptions of events.</title>
<date>2009</date>
<booktitle>In Proceedings of the 4th Asian Conference on The Semantic Web, ASWC ’09,</booktitle>
<pages>153--167</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Shaw, Rapha¨el Troncy, Hardman, 2009</marker>
<rawString>Ryan Shaw, Rapha¨el Troncy, and Lynda Hardman. 2009. Lode: Linking open descriptions of events. In Proceedings of the 4th Asian Conference on The Semantic Web, ASWC ’09, pages 153–167, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Force dynamics in language and thought.</title>
<date>1985</date>
<pages>21--293337</pages>
<publisher>Chicago Linguistic Society,</publisher>
<contexts>
<context position="16228" citStr="Talmy, 1985" startWordPosition="2540" endWordPosition="2541">to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Discourse Treebank (PDTB) (Prasad et al., 2007) and PropBank (Palmer et al., 2005),4 we are n</context>
</contexts>
<marker>Talmy, 1985</marker>
<rawString>Leonard Talmy. 1985. Force dynamics in language and thought. Chicago Linguistic Society, 21:293337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Force dynamics in language and cognition.</title>
<date>1988</date>
<journal>Cognitive Science,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="16242" citStr="Talmy, 1988" startWordPosition="2542" endWordPosition="2543">sality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Discourse Treebank (PDTB) (Prasad et al., 2007) and PropBank (Palmer et al., 2005),4 we are not aware of an</context>
</contexts>
<marker>Talmy, 1988</marker>
<rawString>Leonard Talmy. 1988. Force dynamics in language and cognition. Cognitive Science, 12(1):49–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>James F Allen</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>Tempeval-3: Evaluating events, time expressions, and temporal relations.</title>
<date>2012</date>
<location>CoRR, abs/1206.5333.</location>
<contexts>
<context position="5682" citStr="UzZaman et al., 2012" startWordPosition="874" endWordPosition="877">nd temporal expressions (Pustejovsky et al., 2003b). This annotation is important in (i) anchoring an event to a temporal expression (event time-stamping) and (ii) determining the temporal order between events. This distinctive feature of TimeML becomes our main consideration in choosing the event model for our research. Moreover, TimeML is the annotation framework used in TempEval-32, the most recent shared task on temporal and event processing. The ultimate goal of this evaluation campaign is the automatic identification of temporal expressions, events, and temporal relations within a text (UzZaman et al., 2012). The main tasks defined in TempEval-3 include: the automatic extraction of TimeML entities, i.e. temporal expressions and events, and the end-toend automatic extraction of both TimeML entities and temporal links/relations. The result of TempEval-3 reported by UzZaman et al. (2013) 1There are other event models based on web ontology (RDFS+OWL) such as LODE (Shaw et al., 2009), SEM (van Hage et al., 2011) and DOLCE (Gangemi et al., 2002), which encode knowledge about events as triples. Such models can be seen as ways to store the extracted knowledge to perform the reasoning on. 2http://www.cs.y</context>
</contexts>
<marker>UzZaman, Llorens, Allen, Derczynski, Verhagen, Pustejovsky, 2012</marker>
<rawString>Naushad UzZaman, Hector Llorens, James F. Allen, Leon Derczynski, Marc Verhagen, and James Pustejovsky. 2012. Tempeval-3: Evaluating events, time expressions, and temporal relations. CoRR, abs/1206.5333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>James Allen</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="5964" citStr="UzZaman et al. (2013)" startWordPosition="916" endWordPosition="919">oosing the event model for our research. Moreover, TimeML is the annotation framework used in TempEval-32, the most recent shared task on temporal and event processing. The ultimate goal of this evaluation campaign is the automatic identification of temporal expressions, events, and temporal relations within a text (UzZaman et al., 2012). The main tasks defined in TempEval-3 include: the automatic extraction of TimeML entities, i.e. temporal expressions and events, and the end-toend automatic extraction of both TimeML entities and temporal links/relations. The result of TempEval-3 reported by UzZaman et al. (2013) 1There are other event models based on web ontology (RDFS+OWL) such as LODE (Shaw et al., 2009), SEM (van Hage et al., 2011) and DOLCE (Gangemi et al., 2002), which encode knowledge about events as triples. Such models can be seen as ways to store the extracted knowledge to perform the reasoning on. 2http://www.cs.york.ac.uk/semeval-2013/task1/ shows that even though the performances of systems for extracting TimeML entities are quite good (&gt;80% F-score), the overall performance of endto-end event extraction systems suffers from the low performance of the temporal relation extraction system. </context>
<context position="9893" citStr="UzZaman et al., 2013" startWordPosition="1561" endWordPosition="1564">the-art performance on temporal relation extraction task. The common approach towards temporal relation extraction is dividing the task into two subtasks: identifying the pairs of entities having a temporal link and determining the relation types. The problem of identifying the entity pairs is usually simplified. In TempEval-3, the possible pairs of entities that can have a temporal link are defined as (i) main events of consecutive sentences, (ii) pairs of events in the same sentence, (iii) an event and a time expression in the same sentence, and (iv) an event and the document creation time (UzZaman et al., 2013). The problem of determining the label of a given temporal link is usually regarded as a classification problem. Given an ordered pair of entities (e1, e2) that could be either event-event, event-timex or timex-timex pair, the classifier has to assign a certain label representing the temporal relation type. We focus on the latter subtask of classifying temporal relation types, assuming that the links between events and time expressions are already established. Several recent works have tried to address this complex multi-class classification task by using sophisticated features based on deep p</context>
<context position="11620" citStr="UzZaman et al., 2013" startWordPosition="1838" endWordPosition="1841">ng corpus, it is not possible to train a classifier for these particular pairs. Moreover, they only add up to 3.2% of the total number of extracted entity pairs; therefore, we decided to disregard these pairs. We follow the guidelines and the dataset provided by the organizers of TempEval-3 so that we can compare our system with other systems participating in the challenge. The TBAQ-cleaned corpus is the training set provided for the task, consisting of the TimeBank (Pustejovsky et al., 2003a) and the AQUAINT corpora. It contains around 100K words in total, with 11K words annotated as events (UzZaman et al., 2013). Simple Feature Set. We implement a number of features including the commonly used ones (UzZaman et al., 2013), which take into account morphosyntactic information on events and time expressions, their textual context and their attributes. Other features rely on semantic information such as typical event durations and explicit temporal connective types. However, we avoid complex processing of data. Such semantic information is based on external lists of lexical items and on the output of the addDiscourse tagger (Pitler and Nenkova, 2009). We build our classification models using the Support V</context>
<context position="14830" citStr="UzZaman et al. (2013)" startWordPosition="2318" endWordPosition="2322">e improvement are not significant. Applying inverse relations and transitive closure extends the number of training instances but makes the already skewed dataset more imbalanced, thus it does not result in a significant improvement. We then train our classifiers for event-event pairs and event-timex pairs by exploiting the best feature combination and using the best reported dataset for each classifier as the training data. The two classifiers are part of our temporal classification system called TRelPro. Compared with the performances of other systems participating in TempEval-3 reported in UzZaman et al. (2013), TRelPro is the best performing system both in terms of precision and of recall. The result of our system using simpler features confirms the finding reported in UzZaman et al. (2013), that a system using basic morpho-syntactic features is hard to beat with systems using more complex semantic features, if not used properly. System F1 Precision Recall TRelPro 58.48% 58.80% 58.17% UTTime-1, 4 56.45% 55.58% 57.35% UTTime-3, 5 54.70% 53.85% 55.58% UTTime-2 54.26% 53.20% 55.36% NavyTime-1 46.83% 46.59% 47.07% NavyTime-2 43.92% 43.65% 44.20% JU-CSE 34.77% 35.07% 34.48% Table 3: TempEval-3 evaluatio</context>
</contexts>
<marker>UzZaman, Llorens, Derczynski, Allen, Verhagen, Pustejovsky, 2013</marker>
<rawString>Naushad UzZaman, Hector Llorens, Leon Derczynski, James Allen, Marc Verhagen, and James Pustejovsky. 2013. Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations. In Proceedings of the Seventh International Workshop on Semantic Evaluation, SemEval ’13, pages 1–9, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van de Koot</author>
<author>A Neeleman</author>
</authors>
<title>The Theta System: Argument Structure at the Interface, chapter The Linguistic Expression of Causation,</title>
<date>2012</date>
<pages>20--51</pages>
<publisher>Oxford University Press: Oxford.</publisher>
<marker>van de Koot, Neeleman, 2012</marker>
<rawString>H van de Koot and A Neeleman, 2012. The Theta System: Argument Structure at the Interface, chapter The Linguistic Expression of Causation, pages 20 – 51. Oxford University Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willem Robert van Hage</author>
<author>V´eronique Malais´e</author>
<author>Roxane Segers</author>
<author>Laura Hollink</author>
<author>Guus Schreiber</author>
</authors>
<title>Design and use of the simple event model (sem).</title>
<date>2011</date>
<journal>Journal of Web Semantics,</journal>
<volume>9</volume>
<issue>2</issue>
<marker>van Hage, Malais´e, Segers, Hollink, Schreiber, 2011</marker>
<rawString>Willem Robert van Hage, V´eronique Malais´e, Roxane Segers, Laura Hollink, and Guus Schreiber. 2011. Design and use of the simple event model (sem). Journal of Web Semantics, 9(2):128–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
</authors>
<title>Temporal closure in an annotation environment. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="13176" citStr="Verhagen, 2005" startWordPosition="2080" endWordPosition="2081"> by the finding of Mani et al. (2006) that bootstrapping the training data through a temporal closure method results in quite significant improvements, we investigate the effect of enriching the training data with inverse relations and closure-based inferred 3http://chasen.org/∼taku/software/yamcha/ 12 relations. However, we adopt a simpler approach to obtain the closure graph of temporal relations, by applying the transitive closure only within the same relation type, e.g. e1 BEFORE e2 ∧ e2 BEFORE e3 → e1 BEFORE e3. It produces only a subset of the relations produced by the temporal closure (Verhagen, 2005; Gerevini et al., 1995). The problem of finding the transitive closure of a directed acyclic graph can be reduced to a boolean matrix multiplication (Fischer and Meyer, 1971). Training data event-event event-timex TBAQ 48.28% 73.82% TBAQ-I 47.77% 74.45% TBAQ-IC 46.39% 74.45% Table 2: Classifier accuracies with different training data: TBAQ (TimeBank+AQUAINT), TBAQ-I (TBAQ+inverse relations) and TBAQ-IC (TBAQ+inverse relations+transitive closure). Evaluation and Analysis. Our test data is the newly annotated TempEval-3-platinum evaluation corpus provided by TempEval-3 organizers, so that we ca</context>
</contexts>
<marker>Verhagen, 2005</marker>
<rawString>Marc Verhagen. 2005. Temporal closure in an annotation environment. Language Resources and Evaluation, 39(2-3):211–241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip Wolff</author>
<author>Grace Song</author>
</authors>
<title>Models of causation and the semantics of causal verbs.</title>
<date>2003</date>
<journal>Cognitive Psychology,</journal>
<volume>47</volume>
<issue>3</issue>
<pages>332</pages>
<contexts>
<context position="16119" citStr="Wolff and Song, 2003" startWordPosition="2520" endWordPosition="2523">n Extraction Unlike the temporal order that has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causa</context>
<context position="18843" citStr="Wolff and Song (2003)" startWordPosition="2951" endWordPosition="2954">refore, thus) and clause-integrated expressions (e.g. the reason why, the result is, that is why). CLINK. A CLINK is a directional relation where the causing event is the source (indicated with S in the examples) and the caused event is the target (indicated with T). The annotation of CLINKs also includes the c-signalID attribute, with the value of the ID of C-SIGNAL marking the causal relation (if available). Wolff (2007) has shown that the dynamics model covers three main types of causal concepts, i.e. CAUSE, ENABLE and PREVENT. The model has been tested by linking it with natural language, Wolff and Song (2003) show that the three causal concepts can be lexicalized as verbs : (i) CAUSEtype verbs, e.g. cause, prompt, force; (ii) ENABLEtype verbs, e.g. allow, enable, help; and (iii) PREVENT-type verbs, e.g. block, prevent, restrain. Its connection with natural language becomes the main reason of basing our annotation guidelines for causality on the dynamics model. We limit the annotation of CLINKs to the presence of an explicit causal construction linking two events, which can be one of the following cases: 1. Expressions containing affect verbs (affect, influence, determine, change), e.g. Ogun ACN cr</context>
</contexts>
<marker>Wolff, Song, 2003</marker>
<rawString>Phillip Wolff and Grace Song. 2003. Models of causation and the semantics of causal verbs. Cognitive Psychology, 47(3):276 – 332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip Wolff</author>
<author>Bianca Klettke</author>
<author>Tatyana Ventura</author>
<author>Grace Song</author>
</authors>
<title>Categorization inside and outside the laboratory: Essays in honor of</title>
<date>2005</date>
<journal>Association,</journal>
<booktitle>in English and Other Languages,</booktitle>
<volume>316</volume>
<pages>29--48</pages>
<publisher>American Psychological</publisher>
<location>Washington, DC, US:</location>
<contexts>
<context position="16139" citStr="Wolff et al., 2005" startWordPosition="2524" endWordPosition="2527">e temporal order that has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Disc</context>
</contexts>
<marker>Wolff, Klettke, Ventura, Song, 2005</marker>
<rawString>Phillip Wolff, Bianca Klettke, Tatyana Ventura, and Grace Song, 2005. Categorization inside and outside the laboratory: Essays in honor of Douglas L. Medin. APA decade of behavior series, chapter Expressing Causation in English and Other Languages, pages 29–48. Washington, DC, US: American Psychological Association, xx, 316 pp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip Wolff</author>
</authors>
<title>Representing causation.</title>
<date>2007</date>
<journal>Journal of Experiment Psychology: General,</journal>
<pages>136--82</pages>
<contexts>
<context position="16153" citStr="Wolff, 2007" startWordPosition="2528" endWordPosition="2529">t has a clear definition, there is no consensus in the NLP community on how to define causality. Causality is not a linguistic notion, meaning that although language can be used to express causality, causality exists as a psychological tool for understanding the world independently of language (van de Koot and Neeleman, 2012). There have been several attempts in the psychology field to model causality, including the counterfactual model (Lewis, 1973), probabilistic contrast model (Cheng and Novick, 1991; Cheng and Novick, 1992) and the dynamics model (Wolff and Song, 2003; Wolff et al., 2005; Wolff, 2007), which is based on Talmy’s force dynamic account of causality (Talmy, 1985; Talmy, 1988). In information extraction, modelling causality is only the first step in order to have guidelines to recognize causal relations in a text. In order to have an automatic extraction system for causal relations (particularly using a data-driven approach) and most importantly to evaluate the performance of the developed extraction system, it is important that a language resource annotated with causality is available. Even though there are several corpora annotated with causality, e.g. Penn Discourse Treebank</context>
<context position="18648" citStr="Wolff (2007)" startWordPosition="2920" endWordPosition="2921">ausal relations, which include all causal uses of: prepositions (e.g. because of, as a result of, due to), conjunctions (e.g. because, since, so that), adverbial connectors (e.g. so, therefore, thus) and clause-integrated expressions (e.g. the reason why, the result is, that is why). CLINK. A CLINK is a directional relation where the causing event is the source (indicated with S in the examples) and the caused event is the target (indicated with T). The annotation of CLINKs also includes the c-signalID attribute, with the value of the ID of C-SIGNAL marking the causal relation (if available). Wolff (2007) has shown that the dynamics model covers three main types of causal concepts, i.e. CAUSE, ENABLE and PREVENT. The model has been tested by linking it with natural language, Wolff and Song (2003) show that the three causal concepts can be lexicalized as verbs : (i) CAUSEtype verbs, e.g. cause, prompt, force; (ii) ENABLEtype verbs, e.g. allow, enable, help; and (iii) PREVENT-type verbs, e.g. block, prevent, restrain. Its connection with natural language becomes the main reason of basing our annotation guidelines for causality on the dynamics model. We limit the annotation of CLINKs to the prese</context>
</contexts>
<marker>Wolff, 2007</marker>
<rawString>Phillip Wolff. 2007. Representing causation. Journal of Experiment Psychology: General, 136:82–111.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>