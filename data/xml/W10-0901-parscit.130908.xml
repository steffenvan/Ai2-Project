<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.972769">
Machine Reading as a Process of Partial Question-Answering
</title>
<author confidence="0.662397">
Peter Clark and Phil Harrison
</author>
<affiliation confidence="0.67533">
Boeing Research &amp; Technology
The Boeing Company, PO Box 3707, Seattle, WA 98124, USA
</affiliation>
<email confidence="0.967853">
{peter.e.clark,philip.harrison}@boeing.com
</email>
<sectionHeader confidence="0.994849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999886962962963">
This paper explores the close relationship be-
tween question answering and machine read-
ing, and how the active use of reasoning to
answer (and in the process, disambiguate)
questions can also be applied to reading de-
clarative texts, where a substantial proportion
of the text’s contents is already known to (rep-
resented in) the system. In question answer-
ing, a question may be ambiguous, and it may
only be in the process of trying to answer it
that the &amp;quot;right&amp;quot; way to disambiguate it be-
comes apparent. Similarly in machine reading,
a text may be ambiguous, and may require
some process to relate it to what is already
known. Our conjecture in this paper is that
these two processes are similar, and that we
can modify a question answering tool to help
&amp;quot;read&amp;quot; new text that augments existing system
knowledge. Specifically, interpreting a new
text T can be recast as trying to answer, or
partially answer, the question &amp;quot;Is it true that
T?&amp;quot;, resulting in both appropriate disambigua-
tion and connection of T to existing knowl-
edge. Some preliminary investigation suggests
this might be useful for proposing knowledge
base extensions, extracted from text, to a
knowledge engineer.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999770857142857">
Machine reading is not just a task of language
processing, but an active interplay between knowl-
edge and language; Prior knowledge should guide
interpretation of new text, and new interpretations
should augment that prior knowledge. Such inter-
action is essential if ambiguities in language are to
be resolved &amp;quot;correctly&amp;quot; (with respect to what is
</bodyText>
<page confidence="0.845761">
1
</page>
<bodyText confidence="0.999944513513513">
known), and if the resulting interpretations are to
be integrated with existing knowledge. The main
insight of this paper is that this interaction is simi-
lar to that required for knowledge-based question
answering, which also requires searching a knowl-
edge base (KB) for a valid interpretation of the
question. In our earlier work on question answer-
ing (Clark and Harrison, 2010), we found that
some disambiguation decisions for question inter-
pretation could be deferred, to be resolved during
question answering, guided by what was found in
the KB. In this paper, we show how a similar ap-
proach can be applied to interpreting declarative
text, so that a similar interplay between language
and knowledge is achieved.
&amp;quot;Machine reading&amp;quot; itself is a loosely-defined no-
tion, ranging from extracting selective facts to con-
structing complex, inference-supporting
representations of text. One approach for selective
extraction is the use of semantic templates
(&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots)
and constraints on objects playing those roles (fill-
ers) to be expected in text, and might be filled by
methods ranging from simply skimming text, e.g.,
FRUMP (DeJong, 1979), to full language process-
ing, e.g., (Dahlgren et al., 1991). Other work has
looked at techniques for learning phrasal patterns
likely to contain slot fillers (Riloff, 1996; Sekine,
2006) or contain information semantically similar
to a set of seed examples (Carlson et al, 2009).
At the other end of the spectrum, some systems
attempt a full understanding of text, i.e., have the
ambitious goal of building a complete representa-
tion of the text&apos;s contents (e.g., Zadrozny 1991,
Hobbs et al, 1993). A common thread of these ap-
proaches is to search a space of alternative disam-
biguations and elaborations and select the most
</bodyText>
<note confidence="0.984542">
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999872375">
&amp;quot;coherent&amp;quot;, based on criteria such as maximizing
coreference, minimizing redundancy, and avoiding
contradictions. For example, Mulkar et al (2007)
search for a set of abductive inferences on the
(logical form of the) text that minimizes cost
(maximizes coherence) of the result, where an ab-
ductive inference might be a word sense or
coreference decision with an associated cost. Simi-
larly, Zadrozny and Jensen (1991) search a space
of disambiguations when interpreting paragraphs
by elaborating each alternative (using dictionary
definitions) and selecting the most coherent based
on similar criteria. Work on model building is in-
spiring but also challenging due to the lack of con-
straint on the final models (even with substantial
domain knowledge) and the difficulty of quantify-
ing &amp;quot;coherence&amp;quot;.
Our work falls somewhere between these two. We
do not use templates for new knowledge, but rather
use inference at run-time to identify what is known
and thus what to expect that the text might be say-
ing. However, unlike full model building ap-
proaches, we assume that the majority of what is
being read is already known (represented) in the
KB, and thus the reading task is primarily one of
recognizing that knowledge in the text, and extend-
ing it with any new facts that are encountered. We
might term this a &amp;quot;model extension&amp;quot; approach; it
corresponds to Feigenbaum&apos;s (2003) challenge of,
given the representation of a book, have a machine
read a second book (about the same topic) and in-
tegrate the new knowledge contained in that text.
</bodyText>
<sectionHeader confidence="0.975218" genericHeader="method">
2 The Problem
</sectionHeader>
<bodyText confidence="0.99989425">
Our work is in the context of cell biology, where
we have a moderately sized1, hand-built knowl-
edge base available containing formal representa-
tions of biological structures and processes
expressed in first-order logic. Our goal is to take
paragraphs of text about a topic partially covered
by the KB, and identify facts which are already
known, facts which are new, and the connections
</bodyText>
<footnote confidence="0.950034285714286">
1 Specifically, it has detailed representations of entities and
processes related to cell division, DNA replication, and pro-
tein synthesis, containing approximately 250 domain-specific
concepts (built on top of a pre-existing library of approxi-
mately 500 domain-general concepts), 120 relations (binary
predicates), and approximately 2000 axioms, built as part of
Project Halo (Gunning et al., 2010).
</footnote>
<bodyText confidence="0.5203">
Topic: prophase
</bodyText>
<subsectionHeader confidence="0.777382">
Input Paragraph:
</subsectionHeader>
<bodyText confidence="0.9985405">
In the cytoplasm, the mitotic spindle, consisting of
microtubules and other proteins, forms between the
two pairs of centrioles as they migrate to opposite
poles of the cell.
</bodyText>
<listItem confidence="0.754973428571429">
Output Axioms: (expressed in English)
In all prophase events:
a. The mitotic spindle has parts the microtubule
and the protein.
b. The mitotic spindle is created between the
centrioles in the cytoplasm.
c. The centrioles move to the poles.
</listItem>
<figureCaption confidence="0.979995">
Figure 1: The system’s behavior, showing known
</figureCaption>
<bodyText confidence="0.9647813125">
(normal font) and new (bold) facts identified
from the text. Note that the output is not just a
simple recitation of the input, but a mixture of
known and new axioms for the KB.
between the two. An example of the system’s out-
put is shown in Figure 1. In the Output Axioms in
that Figure, the normal font shows facts that the
system has recognized as already known in the
KB, while bold font shows new knowledge. It is
important to note that the output facts are not just a
simple recitation of the input, but have been inter-
preted in the context of the KB. For example in the
input paragraph:
&amp;quot;the mitotic spindle, consisting of microtubules&amp;quot;
has not been interpreted as describing some “con-
sisting” event, but recognized (via use of para-
phrases, described later) as referring to the has-
part(mitotic-spindle01,microtubules01) element in
the representation of prophase in the KB, i.e., de-
noting a &amp;quot;has part&amp;quot; relationship ((a) in Figure 1).
Similarly,
&amp;quot;the spindle forms&amp;quot;
has not been interpreted as an organizing event
(“form a team”) nor as the spindle doing the form-
ing (“the spindle forms something”), but instead
been recognized as the result(create01,mitotic-
spindle01) element in the representation of pro-
phase in the KB, i.e., &amp;quot;forms&amp;quot; has been interpreted
as this particular creation event in the representa-
tion of prophase (b in Figure 1). Doing this re-
quires not just careful language processing; it
requires querying the knowledge base to see/infer
</bodyText>
<page confidence="0.988239">
2
</page>
<bodyText confidence="0.990494833333333">
what is already known, and using this to guide the
interpretation.
This process is similar to that needed for question-
answering. Consider giving a question form of
(part of) the earlier paragraph to a question-
answering system:
</bodyText>
<listItem confidence="0.8292445">
(1) Is it true that the mitotic spindle consists of
microtubules?
</listItem>
<bodyText confidence="0.999960714285714">
Again, the phrase &amp;quot;consists of&amp;quot; is ambiguous, and
may mean different things in different contexts.
However, in the context of question-answering,
there is a natural approach to disambiguating this:
as the user is asking about what is in the KB, then
a natural approach is to query the KB for relation-
ships that hold between the mitotic spindle and
microtubules, and see if any are a plausible inter-
pretation of &amp;quot;consists of&amp;quot;. If there is one, then it is
likely to be the interpretation that the user intended
(assuming the user is not being deliberately ob-
scure; we call this a &amp;quot;benevolent user&amp;quot; assump-
tion). If this happens, then the question-answering
system can answer &amp;quot;yes&amp;quot;; but more importantly
from a machine reading point of view, the system
has also correctly disambiguated the original ques-
tion and located the facts it mentions in the knowl-
edge base as side-effects. It is this process that we
want to apply to interpreting declarative texts, with
the change that unproven parts should be treated as
new assertions, rather than failed queries.
</bodyText>
<sectionHeader confidence="0.995567" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999646821428572">
Based on these observations, our approach is to
interpret a new text T by treating it as a question to
the KB asking whether the facts in T are already
known. By attempting to answer this question, the
system resolves ambiguity for the known facts
(namely, the resolution that leads to them being
recognized is preferred). For new facts, the system
falls back on more traditional NLP modules, fil-
tered by coarser-grained type constraints. In addi-
tion, the identification of known facts in the KB
and the connection between the old facts and the
new facts provides anchor points for the new facts
to be connected to.
To implement this approach, we have used three
important features of our question-answering sys-
tem, here reapplied to the task of text interpreta-
tion:
a. The use of a large database of paraphrases to
explore alternative phrasings (hence alternative
interpretations) of text;
b. Deferring word sense and semantic role com-
mitment during initial language processing, to
be resolved later based on what is found in the
KB;
c. The use of standard disambiguation techniques
to process new facts not located in the KB.
We now summarize these three features, then pre-
sent the complete algorithm.
</bodyText>
<subsectionHeader confidence="0.995492">
3.1 Paraphrases
</subsectionHeader>
<bodyText confidence="0.999927">
A relatively recent advance in NLP has been the
automatic construction of paraphrase databases
(containing phrasal patterns with approximately
equivalent meaning), built by finding phrases that
occur in distributionally similar contexts (e.g.,
Dras et al, 2005). To date, paraphrase databases
have primarily been exploited for recognizing tex-
tual entailment (e.g., Bentivogli et al., 2009). In
our work, we take them in a new direction and ex-
ploit them for language interpretation.
We use the DIRT paraphrase database (Lin and
Pantel, 2001a,b), containing approximately 12 mil-
lion automatically learned rules of the form:
</bodyText>
<equation confidence="0.556439">
IF X relation Y THEN X relation&apos; Y
</equation>
<bodyText confidence="0.980972285714286">
where relation is a path in the dependency tree be-
tween constitutents X and Y, or equivalently (as
we use later) a chain of clauses:
{p0(x0,x1), w1(x1), ...pn-1(x n-1,xn)}
where pi is the syntactic relation between (non-
prepositional) constituents xi and xi+1, and wi is the
word used for xi. An example from DIRT is:
</bodyText>
<equation confidence="0.911916">
IF X is found in Y THEN X is inside Y
</equation>
<bodyText confidence="0.958663833333333">
The condition “X is found in Y” can be expressed
as the clause chain:
{ object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) }
We use DIRT to explore alternative interpretations
of the text, singling out those that help identify the
facts in the text that are already known in the KB.
</bodyText>
<subsectionHeader confidence="0.99746">
3.2 Deferred Sense Commitment
</subsectionHeader>
<bodyText confidence="0.9990605">
Two common challenges for NLP are word sense
disambiguation (WSD) and semantic role labeling
</bodyText>
<page confidence="0.978426">
3
</page>
<bodyText confidence="0.998194895522388">
(SRL). While there are a number of existing tools 4 Algorithm and Implementation
for performing these tasks based on the linguistic 4.1 Topics and Participants
context (e.g., Toutanova et al., 2008, Erk and Pado,
2006), their performance is only moderate (e.g.,
Agirre et al, 2007). The problem is accentuated
when trying to disambiguate in a way consistent
with a particular KB, because there is often a de-
gree of subjectivity in how the knowledge engineer
chose to represent the world in that KB (e.g.,
whether some object is the &amp;quot;agent&amp;quot; or &amp;quot;instrument&amp;quot;
or &amp;quot;site&amp;quot; of an activity is to a degree a matter of
viewpoint). Trying to create a WSD or SRL mod-
ule that reliably mimics the knowledge engineer’s
decision procedure is difficult.
To address this, we defer WSD and SRL commit-
ment during the initial text processing. Instead,
these ambiguities are resolved during the subse-
quent stage of querying the KB to see if (some in-
terpretion of) the text is already known. One can
view this as a trivial form of preserving under-
specification (eg. Pinkal, 1999) in the initial lan-
guage processing, where the words themselves
denote their possible meanings.
3.3 Interpretation of New Knowledge
Given some text, our system attempts to disam-
biguate it by searching for (some interpretation of)
its statements in the KB. However, this will only
disambiguate statements of facts that are already
known. For new facts, we fall back on traditional
disambiguation methods, using a set of approxi-
mately 100 hand-built rules for semantic role label-
ling, and word sense disambiguation preferences
taken from WordNet sense frequency statistics and
from the KB. In addition, we use a simple filter to
discard apparently irrelevant/nonsensical assertions
by discarding those that use concepts unrelated to
the domain. These are defined as those with words
whose preferred WordNet sense falls under one of
a small number of hand-selected &amp;quot;non-biological&amp;quot;
synsets (namely human_activity#n#1, mental_ob-
ject#n#1, artifact#n#1, instrumentation#n#1, psy-
chological_feature#n#1, device#n#1). One might
also be able to use a KB-guided approach to dis-
ambiguation similar to that described for known
facts, by (for example) looking for generalizations
of (interpretations of) new facts in the knowledge
base. This is a direction for future exploration.
4
For now, we assume that all knowledge in the KB
can be represented by “forall...exists...” state-
ments, i.e., statements of the form:
b&apos;x isa(x,C) --+3y1..yn p1(v1,v2), ..., pq(vr,vs) [1]
(We will later discuss how this assumption can be
relaxed). pi are predicates in the KB’s ontology and
each vi is either a variable vE{x,y1,...,yn} or a
symbol in the KB’s ontology. We say clauses
pi(vj,vk) are about concept C, and that C is the topic
of the clauses. We also say that any instance yi that
is in some (possibly indirect) relationship to x is a
participant in the representation of instance x of C.
Thus all the yi in [1] are participants, plus there
may be additional participants implied by other
axioms. For some given instance X0 of C, we can
identify all the participants in the representation of
X0 by forward chaining from isa(X0,C) and col-
lecting all the instances connected via some chain
of predicates to X0. We encode this using a par-
</bodyText>
<table confidence="0.960001217391304">
ticipant(x,yi) relation2. As this computation is po-
tentially unbounded, we use a depth bound to
heuristically limit this computation.
4.2 Initial Language Processing
Assume the system has a paragraph of text about a
topic, and that it has identified what that topic is3.
For example, consider that the topic is prophase (a
step in cell division), and the paragraph is the sin-
gle sentence:
T: The mitotic spindle consists of hollow micro-
tubules.
Text is parsed using a broad coverage, phrase
structure parser (Harrison and Maxwell, 1986),
followed by coreference resolution, producing a
&amp;quot;syntactic&amp;quot; logical form, here:
LF: &amp;quot;mitotic-spindle&amp;quot;(s), &amp;quot;consist&amp;quot;(c), &amp;quot;hollow&amp;quot;(h),
&amp;quot;microtubule&amp;quot;(m), subject(c,s), &amp;quot;of&amp;quot;(c,m),
modifier(m,h).
2 We can formalize this by adding participant(x,yi) to the con-
clusion in [1] for all yi, plus an axiom that participant is transi-
tive.
3 E.g., via some topic classification algorithm. For our experi-
ments here, we manually declare the topic.
</table>
<subsectionHeader confidence="0.955896">
4.3 Semantic Interpretation
</subsectionHeader>
<bodyText confidence="0.999701777777778">
To interpret T the system then tries to answer, or
partially answer, the corresponding question:
T: Is it true that the mitotic spindle consists of hol-
low microtubules?
Note that this question is in the context of the topic
(prophase), and thus the mentioned objects are im-
plicitly participants in prophase. To do this, the
system proceeds as follows, using a deductive rea-
soning engine operating over the KB:
</bodyText>
<listItem confidence="0.967601">
(a) setup: create an instance X0 of the topic, i.e.,
assert isa(X0,topic) in the KB, then find its
participants { y  |participant(X0,y) }. Next,
bind one of the variables in the LF to a partici-
pant that the variable&apos;s word might denote.
(b) query: for each clause in the LF with at least
one bound variable, iteratively query the KB to
see if some interpretation of those clauses are
provable i.e., already known.
</listItem>
<bodyText confidence="0.986965444444444">
In this example, for setup (a) the system first cre-
ates an instance X0 of prophase, i.e., asserts
isa(X0,Prophase) in the KB, then finds its partici-
pants Y0,...,Yn by querying for participant(X0,y).
The participants Y0,Y1,... will be instances of ob-
jects and events known (in the KB) to be present in
prophase, e.g., instances of Move, Centrosome,
Elongate, Mitotic-Spindle, etc. The system then
instantiates a variable in the LF, e.g., s in &amp;quot;mitotic-
spindle&amp;quot;(s) with a participant that &amp;quot;mitotic spindle&amp;quot;
might refer to, e.g., Y4, if Y4 is an instance of Mi-
totic-Spindle. The resulting LF looks:
LF:&amp;quot;mitotic-spindle&amp;quot;(Y4),&amp;quot;consist&amp;quot;(c),&amp;quot;hollow&amp;quot;(h),
&amp;quot;microtubule&amp;quot;(m), subject(c,Y4), &amp;quot;of&amp;quot;(c,m),
modifier(m,h).
For querying (b), the system uses the algorithm as
follows (on the next page):
(Graphical depiction of) (part of) the representation of Prophase:
</bodyText>
<figure confidence="0.514827">
destination
</figure>
<figureCaption confidence="0.939597">
Figure 2: The path found through the search space for an interpretation of the example sentence. (a) setup
(b) paraphrase substitution (c) interpretation of {subject-of(Y4,p),“part”(p),“of”(p,m)} as has-part(Y4,m),
preferred as it is provable from the KB, resulting in m=Y7 (d) interpretation of new knowledge (standard
WSD and SRL tools).
</figureCaption>
<figure confidence="0.885768179487179">
Y0:Move
Y3:Elongate
object
Y6:Create
...
Y2:Eukaryotic-Cell
has-part has-region
Y5:Pole
has-part
Y8:Hollow
Y1:Centrosome
Y4:Mitotic-Spindle
Y7:Microtubule
shape
...
LF interpretation: Recognized Old Knowledge New Knowledge
&amp;quot;mitotic-spindle&amp;quot;(s), &amp;quot;consist&amp;quot;(c), &amp;quot;hollow&amp;quot;(h), &amp;quot;microtubule&amp;quot;(m), subject(c,s), &amp;quot;of&amp;quot;(c,m), modifier(m,h).
isa(Y4,Mitotic-Spindle), &amp;quot;consist&amp;quot;(c), &amp;quot;hollow&amp;quot;(h), &amp;quot;microtubule&amp;quot;(m), subject(c,Y4), &amp;quot;of&amp;quot;(c,m), modifier(m,h)
isa(Y4,Mitotic-Spindle), “part&amp;quot;(p), &amp;quot;hollow&amp;quot;(h), &amp;quot;microtubule&amp;quot;(m), subject(p,Y4), &amp;quot;of&amp;quot;(p,m), modifier(m,h).
isa(Y4,Mitotic-Spindle), &amp;quot;hollow&amp;quot;(h), isa(Y7,Microtubule), has-part(Y4,Y7), modifier(Y7,h).
isa(Y4,Mitotic-Spindle), isa(Y8,Hollow), isa(Y7,Microtubule), has-part(Y4,Y7), shape(Y7,Y8).
X0:Prophase
subevent
object
5
repeat
select a clause chain Cu of “syntactic” clauses
in the LF with at least 1 bound variable
Cu = {p(x,y)} or {w(x)} or
{p1(x,z), w(z), p2(z,y)}
select some interpretation C of Cu where:
C is a possible interpretation of Cu
or C&apos;u is a possible paraphrase for Cu and
C is a possible interpretation of C&apos;u
try prove C[bindings] --+ new-bindings
If success:
replace Cu with C
add new-bindings to bindings
until
</figure>
<bodyText confidence="0.905851">
as many clauses proved as possible
where:
</bodyText>
<listItem confidence="0.983982">
• A syntactic clause is a clause whose predicate
is a word or syntactic role (subject, object,
modifier, etc.) All clauses in the initial LF are
syntactic clauses.
• A clause chain is a set of &amp;quot;syntactic&amp;quot; clauses in
the LF of the form {p(x,y)} or {w(x)} or
{p1(x,z), w(z), p2(z,y)}, where pi, w are words
or syntactic roles (subject, modifier, etc).
• A possible paraphrase is a possible substitu-
tion of one syntactic clause chain with another,
listed in the DIRT paraphrase database.
• A possible interpretation of the singleton syn-
tactic clause chain {w(x)} is isa(x,class),
where class is a possible sense of word w.
• A possible interpretation of a syntactic clause
</listItem>
<bodyText confidence="0.98825952631579">
chain {p(x,y)} or {p1(x,z),w(z),p2(z,y)} is
r(x,y), where r is a semantic relation corre-
sponding to syntactic relation p (e.g., &amp;quot;in&amp;quot;(x,y)
--+ is-inside(x,y)) or word w (e.g., {subject-
of(e,h), &amp;quot;have&amp;quot;(h), &amp;quot;of&amp;quot;(h,n)} --+ has-part(e,n)).
Possible word-to-class and word-to-predicate map-
pings are specified in the KB.
As there are several points of non-determinism in
the algorithm, including the setup (e.g., which
clauses to select, which interpretation to explore),
it is a search process. Our current implementation
uses most-instantiated-first query ordering plus
breadth-first search, although other implementa-
tions could traverse the space in other ways.
Figure 2 illustrates this procedure for the example
sentence. The procedure iteratively replaces syn-
tactic clauses with semantic clauses that corre-
spond to an interpretation that is provable from the
KB. If all the clauses are proved, then the original
text T is redundant; there exists an interpretation
under which it can be proved from the KB, and we
assume under the benevolent user assumption that
this is the interpretation that the user intended.
If some syntactic clauses remain unproved, then
they correspond to new knowledge, and a standard
NLP pipeline is then used to interpret them. In this
example (Figure 2), the &amp;quot;hollow&amp;quot; modifier to the
microtubule Y7 was unproved, and was subse-
quently interpreted by the NLP pipeline as the
shape of the microtubule. This new clause is con-
verted into a (potential) addition to the KB by
identifying an axiom that concluded one of the
known connected facts (here, has-part(Y4,Y7)),
and then proposing the new clause as an additional
conclusion of that axiom. If there are no connected
clauses, it is instead proposed as a new axiom
about prophase. The user can verify/reject that
proposal as he/she desires.
</bodyText>
<sectionHeader confidence="0.995098" genericHeader="method">
5 Illustration
</sectionHeader>
<bodyText confidence="0.999808615384615">
An illustration of the system’s typical processing
of a paragraph is shown in Figure 3. As in Figure
1, normal font shows facts recognized as already
known, and bold shows new knowledge. Again
note that the output facts are not a simple recitation
of the input, but have been interpreted with respect
to the KB. For example, in (e), Create is the pre-
ferred interpretation of &amp;quot;form&amp;quot;, and in (d), has-part
is the preferred interpretation of &amp;quot;consisting of&amp;quot;, as
these result in the interpretation being provable
from the KB. Also note that new knowledge is an-
chored to old, e.g., in (d), proteins are posited as an
additional part of the mitotic spindle participant of
prophase.
There are several errors and meaningless state-
ments in the output also. For example, &amp;quot;something
signals&amp;quot; is not particularly helpful, and &amp;quot;the chro-
mosome moves&amp;quot; is, although biologically correct, a
misinterpretation of the original English &amp;quot;the
chromosome is seen as...&amp;quot;, with Move being a pos-
sible interpretation of &amp;quot;see&amp;quot; (as in &amp;quot;I&apos;ll see you to
the door&amp;quot;). In addition some sentences were mis-
parsed or unparsed, and some interpretations were
discarded as they involved non-biological con-
cepts. Many representational issues have been
skirted also, discussed shortly.
</bodyText>
<page confidence="0.997241">
6
</page>
<bodyText confidence="0.723776">
Topic: prophase
</bodyText>
<subsectionHeader confidence="0.626808">
Input Paragraph:4
</subsectionHeader>
<bodyText confidence="0.953972058823529">
During prophase, chromosomes become visible,
the nucleolus disappears, the mitotic spindle forms,
and the nuclear envelope disappears. Chromo-
somes become more coiled and can be viewed un-
der a light microscope. Each duplicated
chromosome is seen as a pair of sister chromatids
joined by the duplicated but unseparated centro-
mere. The nucleolus disappears during prophase.
In the cytoplasm, the mitotic spindle, consisting of
microtubules and other proteins, forms between the
two pairs of centrioles as they migrate to opposite
poles of the cell. The nuclear envelope disappears
at the end of prophase. This signals the beginning
of the substage called prometaphase.
Output Axioms: (expressed in English)
In all prophase events:
d. The chromosome moves.
</bodyText>
<listItem confidence="0.826449727272727">
e. The chromatids are attached by the centro-
mere.
f. The nucleolus disappears during the pro-
phase.
g. The mitotic spindle has parts the microtubule
and the protein.
h. The mitotic spindle is created between the
centrioles in the cytoplasm.
i. The centrioles move to the poles.
j. The nuclear envelope disappears at the end.
k. Something signals.
</listItem>
<figureCaption confidence="0.997964">
Figure 3: Illustration of the System’s Behavior
</figureCaption>
<sectionHeader confidence="0.873804" genericHeader="method">
6 Preliminary Evaluation
</sectionHeader>
<bodyText confidence="0.960665076923077">
To make a preliminary assessment of how much
useful information the system is producing, we
conducted a small study. 10 paragraphs about pro-
phase (from different Web sources) were run
through the system (110 sentences in total). The
system extracted 114 statements of which 23
(20%) were interpreted as fully known (i.e., al-
ready in the KB), 27 (24%) as partially new
knowledge, and 64 (56%) as completely new
knowledge. The extracted statements were then
scored by a biologist as one of:
c = correct; useful knowledge that should be in
the KB
</bodyText>
<footnote confidence="0.847596">
4 From http://www.phschool.com/science/biology_place/ bio-
coach/mitosisisg/prophase.html
</footnote>
<bodyText confidence="0.9743495">
q = questionable; not useful knowledge (mean-
ingless, overly general, vague)
i = incorrect
The results are shown in Table 1.
</bodyText>
<table confidence="0.999322428571429">
Fully Statements Fully
known that are: new
Mixture of
known &amp; new
Correct 22 19 25
Questionable 1 8 38
Incorrect 0 0 1
</table>
<tableCaption confidence="0.9214685">
Table 1: Correctness of axioms proposed by the
system.
</tableCaption>
<bodyText confidence="0.999705769230769">
For the statements that mix old and new knowl-
edge, 70% were judged correct, and for completely
new statements, 39% were judged correct.5 This
suggests the system is at least producing some use-
ful suggestions, and for the statements that mix old
and new knowledge, has identified the connection
points in the KB for the new facts. Although this
level of accuracy is too low for automation, it sug-
gests the system might be a useful tool for helping
a knowledge engineer check that he/she has fully
encoded the contents of a passage when building
the KB, and performing those approved additions
automatically.
</bodyText>
<sectionHeader confidence="0.995518" genericHeader="discussions">
7 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.9986641">
We have described a method for reading &amp;quot;at the
fringe&amp;quot; of what is known, leveraging existing
knowledge to help in the reading process by treat-
ing text interpretation as partial question answer-
ing. This approach is appropriate for situations in
which a reasonable proportion of the text&apos;s content
is already known to (represented in) the KB. Our
evaluation suggests that the approach has merit, at
least as an interactive knowledge acquisition tool.
As we have suggested, existing knowledge can
help guide and anchor interpretation, but to what
extent might it stifle the system from learning
genuinely new knowledge? At present, our system
is unable to extend its own ontology (it can only
learns axioms expressed using its existing ontol-
ogy), and thus will skim over unrecognized words
5 For the 1 statement already fully known but judged as ques-
tionable, the score appears to be due to poor rendering in Eng-
lish, the axiom being rendered as &amp;quot;The membrane break
down.&amp;quot; rather than &amp;quot;The membrane breaks down.&amp;quot;.
</bodyText>
<page confidence="0.997709">
7
</page>
<bodyText confidence="0.999908828571428">
even if those words reflect something new (with
respect to the KB) and important about the domain.
The system is thus biased towards texts about con-
cepts that it has at least heard of before (even if it
knows little about them), expecting small, incre-
mental additions of knowledge, rather than work-
ing hard to untangle information about completely
novel topics. It can learn about concepts it has al-
ready heard of, but not, at present, learn new con-
cepts. While it would be simple to modify the
system to treat any new word as a new concept,
this may potentially overwhelm the system, and so
such extensions would need to be made carefully.
This is an area for future work.
How large must the starting KB be? Although it
can be missing (possibly many) axioms, we implic-
itly assume that at least the basic ontology and the
mapping from words to concepts is reasonably
complete (for the types of texts being considered),
i.e., there is a good &amp;quot;skeleton&amp;quot; KB to add axioms
to. Thus, methodologically, a first step for using
our system would be to create the initial ontology
and lexical mappings, e.g., via corpus analysis or
using an ontology learning tool (Gomez-Perez and
Manzano-Macho, 2003). Beyond that, the more
axioms the starting KB has the better, as each
axiom can potentially guide the interpretation of a
new sentence. In the limiting case, where there are
no axioms (only the ontology and lexical map-
pings), our system&apos;s behavior reverts to that of a
normal, pipelined NLP interpreter (with the normal
associated problems).
This work is still preliminary, and there are nu-
merous other issues and limitations that need to be
addressed also. Three notable issues are as follows:
</bodyText>
<listItem confidence="0.818602">
• Syntactic ambiguity: While we defer WSD
</listItem>
<bodyText confidence="0.9240036">
and SRL commitment, our system is eagerly
committing to a single parse during initial lan-
guage processing, and that parse may be
wrong. An obvious extension is to similarly
defer some syntactic commitments until se-
mantic interpretation, for example using an
underspecified or packed logical form (e.g.,
Bobrow et al, 2005) or exploring alternative
parses.
• Interpretation of new knowledge: While our
approach leverages the KB to interpret state-
ments about known facts, and thus help find
the anchor points for new facts, those state-
ments of new facts are still interpreted using a
traditional pipelined approach, with all its as-
sociated brittlenesses (as evidenced in the last
column in Table 1). Creative ways for using
the KB to similarly help guide new fact inter-
pretation are needed, for example searching the
KB for generalizations or variants of those
facts, and then preferring the interpretations
they suggest.
• Representational adequacy: Our work so far
has assumed a simple, deductive representa-
tional framework of individual objects and
events, and correspondingly assumes the same
individuality in language. However the world,
and language used to describe it, often goes
beyond this to include a miriad of representa-
tionally difficult phenomena (sets, pairs, ag-
gregates, conditionality, plausibility,
constraints, etc.). Our system largely skips
over such aspects, as it is unable to represent
them.
Despite these limitations, the picture of text inter-
pretation as partial question-answering appears to
be a useful one, as it suggests a means by which
language and knowledge can be connected. We are
optimistic that it can be further developed and im-
proved for better machine reading in the future.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997">
We are grateful to Vulcan Inc. who partially sup-
ported this work through Project Halo.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999779933333333">
Agirre, E., Marquez, L., Wicentowski, R., Eds., 2007.
Proceedings of the 4th International Workshop on
Semantic Evaluations (SemEval), ACL, Prague,
Czech Republic.
Bentivogli, L., Dagan, I., Dang, Hoa, Giampiccolo, D.,
Magnini, B. 2009. The Fifth PASCAL Recognizing
Textual Entailment Challenge. In Proc Text Analysis
Conference (TAC’09).
Bobrow, D. G., Condoravdi, Crouch, R. Kaplan, R.
Karttunen, L., King, L.T.H., de Paiva, V., Zaenen, A.
2005. A Basic Logic for Textual Inference. In Pro-
ceedings of the AAAI Workshop on Inference for Tex-
tual Question Answering, Pittsburgh, PA.
Carlson, A., Betteridge, J., Hruschka, E., Mitchell, T.
2009. Coupling Semi-Supervised Learning of Cate-
</reference>
<page confidence="0.976572">
8
</page>
<reference confidence="0.99890175">
gories and Relations. Proceedings of the NAACL
HLT 2009 Workshop on Semi-supervised Learning
for Natural Language Processing.
Clark, P., Harrison, P. 2010. Exploiting Paraphraes and
Deferred Sense Commitment to Interpret Questions
more Reliably. (Submitted).
Dahlgren, K., Lord, C., Wada, H., McDowell, J., Sabler,
E. 1991. ITP: Description of the interpretext system
as used for MUC-3. In Proc 3rd Message Under-
standing Conference (MUC-3), pp163-170.
DeJong, G. 1979. Prediction and Substantiation: Two
processes that comprise understanding. IJCAI’79,
pp217-222.
Dras, M., Yamamoto, K. (Eds). 2005. Proc 3rd Interna-
tionl Workshop of Paraphrasing. South Korea.
Erk, K., Pado, S. 2006. Shalmaneser – a flexible toolbox
for semantic role assignment. Proc LREC 2006,
Genoa, Italy.
Feigenbaum, E. 2003. Some Challenges and Grand
Challenges for Computational Intelligence. Journal
of ACM, 50 (1), pp 32-40.
Gomez-Perez, A., Manzano-Macho, D. 2003. &amp;quot;A Survey
of Ontology Learning Methods and Techniques&amp;quot;,
Technical Report, Univ Politecnica de Madrid (On-
toWeb Deliverable 1.5, http://www.sti-innsbruck.at/
fileadmin/documents/deliverables/Ontoweb/D1.5.pdf
)
Gunning, D., Greaves, M., Chaudhri, V. et al. 2010.
Project Halo Update – Progress Towards Digital Ar-
istotle (Submitted).
Harrison, P., Maxwell, M. 1986. A New Implementa-
tion of GPSG. In Proc. 6th Canadian Conf on AI.
Hobb, J., Stickel, M., Appelt, D., Martin, P. 1993. Inter-
pretation as Abudction. In Artificial Intelligence 63
(1-2), pp 69-142.
Lin, D. and Pantel, P. 2001a. Discovery of Inference
Rules for Question Answering. Natural Language
Engineering 7 (4) pp 343-360.
Lin, D. and Pantel, P. 2001b. Discovery of Inference
Rules in Text. Proc ACM SIGKDD Conf on Know-
eldge Discovery and Data Mining.
Mulkar, R., Hobbs, J. Hovy, E. 2007. Learning to Read
Syntactically Complex Biology Texts. In Proc 8th
International Symposium on Logical Formalizations
of Commonsense Reasoning (AAAI Spring Sympo-
sium).
Pinkal, M. 1999. On Semantic Underspecification. In
Bunt, H./Muskens, R. (Eds.). Proceedings of the 2nd
International Workshop on Compuational Linguistics
(IWCS 2).
Riloff, E. 1996. Automatically Generating Extraction
Patterns from Untagged Text. Proc AAAI’96.
Sekine, S. 2006. On-Demand Information Extraction.
Proc. COLING-ACL.
Toutanova, K., Haghighi, A., Manning, C. 2008. A
Global Joint Model for Semantic Role Labeling.
Computational Linguistics, 34 (2).
Zadrozny, W., Jensen, K. 1991. Semantics of Para-
graphs. in Computational Linguistics 17 (2) pp171-
209.
</reference>
<page confidence="0.997084">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.592568">
<title confidence="0.999846">Machine Reading as a Process of Partial Question-Answering</title>
<author confidence="0.932771">Peter Clark</author>
<author confidence="0.932771">Phil</author>
<affiliation confidence="0.934709">Boeing Research &amp;</affiliation>
<address confidence="0.638874">The Boeing Company, PO Box 3707, Seattle, WA 98124,</address>
<email confidence="0.999497">peter.e.clark@boeing.com</email>
<email confidence="0.999497">philip.harrison@boeing.com</email>
<abstract confidence="0.999639">This paper explores the close relationship between question answering and machine reading, and how the active use of reasoning to answer (and in the process, disambiguate) questions can also be applied to reading declarative texts, where a substantial proportion of the text’s contents is already known to (represented in) the system. In question answering, a question may be ambiguous, and it may only be in the process of trying to answer it that the &amp;quot;right&amp;quot; way to disambiguate it becomes apparent. Similarly in machine reading, a text may be ambiguous, and may require some process to relate it to what is already known. Our conjecture in this paper is that these two processes are similar, and that we can modify a question answering tool to help &amp;quot;read&amp;quot; new text that augments existing system knowledge. Specifically, interpreting a new text T can be recast as trying to answer, or partially answer, the question &amp;quot;Is it true that T?&amp;quot;, resulting in both appropriate disambiguation and connection of T to existing knowledge. Some preliminary investigation suggests this might be useful for proposing knowledge base extensions, extracted from text, to a knowledge engineer.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>L Marquez</author>
<author>R Wicentowski</author>
<author>Eds</author>
</authors>
<date>2007</date>
<booktitle>Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval), ACL,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="12342" citStr="Agirre et al, 2007" startWordPosition="2003" endWordPosition="2006">clause chain: { object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) } We use DIRT to explore alternative interpretations of the text, singling out those that help identify the facts in the text that are already known in the KB. 3.2 Deferred Sense Commitment Two common challenges for NLP are word sense disambiguation (WSD) and semantic role labeling 3 (SRL). While there are a number of existing tools 4 Algorithm and Implementation for performing these tasks based on the linguistic 4.1 Topics and Participants context (e.g., Toutanova et al., 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al, 2007). The problem is accentuated when trying to disambiguate in a way consistent with a particular KB, because there is often a degree of subjectivity in how the knowledge engineer chose to represent the world in that KB (e.g., whether some object is the &amp;quot;agent&amp;quot; or &amp;quot;instrument&amp;quot; or &amp;quot;site&amp;quot; of an activity is to a degree a matter of viewpoint). Trying to create a WSD or SRL module that reliably mimics the knowledge engineer’s decision procedure is difficult. To address this, we defer WSD and SRL commitment during the initial text processing. Instead, these ambiguities are resolved during the subsequen</context>
</contexts>
<marker>Agirre, Marquez, Wicentowski, Eds, 2007</marker>
<rawString>Agirre, E., Marquez, L., Wicentowski, R., Eds., 2007. Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval), ACL, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bentivogli</author>
<author>I Dagan</author>
<author>Hoa Dang</author>
<author>D Giampiccolo</author>
<author>B Magnini</author>
</authors>
<title>The Fifth PASCAL Recognizing Textual Entailment Challenge.</title>
<date>2009</date>
<booktitle>In Proc Text Analysis Conference (TAC’09).</booktitle>
<contexts>
<context position="11044" citStr="Bentivogli et al., 2009" startWordPosition="1780" endWordPosition="1783"> resolved later based on what is found in the KB; c. The use of standard disambiguation techniques to process new facts not located in the KB. We now summarize these three features, then present the complete algorithm. 3.1 Paraphrases A relatively recent advance in NLP has been the automatic construction of paraphrase databases (containing phrasal patterns with approximately equivalent meaning), built by finding phrases that occur in distributionally similar contexts (e.g., Dras et al, 2005). To date, paraphrase databases have primarily been exploited for recognizing textual entailment (e.g., Bentivogli et al., 2009). In our work, we take them in a new direction and exploit them for language interpretation. We use the DIRT paraphrase database (Lin and Pantel, 2001a,b), containing approximately 12 million automatically learned rules of the form: IF X relation Y THEN X relation&apos; Y where relation is a path in the dependency tree between constitutents X and Y, or equivalently (as we use later) a chain of clauses: {p0(x0,x1), w1(x1), ...pn-1(x n-1,xn)} where pi is the syntactic relation between (nonprepositional) constituents xi and xi+1, and wi is the word used for xi. An example from DIRT is: IF X is found i</context>
</contexts>
<marker>Bentivogli, Dagan, Dang, Giampiccolo, Magnini, 2009</marker>
<rawString>Bentivogli, L., Dagan, I., Dang, Hoa, Giampiccolo, D., Magnini, B. 2009. The Fifth PASCAL Recognizing Textual Entailment Challenge. In Proc Text Analysis Conference (TAC’09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>Crouch Condoravdi</author>
<author>R Kaplan</author>
<author>R Karttunen</author>
<author>L King</author>
<author>L T H de Paiva</author>
<author>V Zaenen</author>
<author>A</author>
</authors>
<title>A Basic Logic for Textual Inference.</title>
<date>2005</date>
<booktitle>In Proceedings of the AAAI Workshop on Inference for Textual Question Answering,</booktitle>
<location>Pittsburgh, PA.</location>
<marker>Bobrow, Condoravdi, Kaplan, Karttunen, King, de Paiva, Zaenen, A, 2005</marker>
<rawString>Bobrow, D. G., Condoravdi, Crouch, R. Kaplan, R. Karttunen, L., King, L.T.H., de Paiva, V., Zaenen, A. 2005. A Basic Logic for Textual Inference. In Proceedings of the AAAI Workshop on Inference for Textual Question Answering, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>J Betteridge</author>
<author>E Hruschka</author>
<author>T Mitchell</author>
</authors>
<title>Coupling Semi-Supervised Learning of Categories and Relations.</title>
<date>2009</date>
<booktitle>Proceedings of the NAACL HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing.</booktitle>
<contexts>
<context position="3226" citStr="Carlson et al, 2009" startWordPosition="509" endWordPosition="512">ence-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP (DeJong, 1979), to full language processing, e.g., (Dahlgren et al., 1991). Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (Riloff, 1996; Sekine, 2006) or contain information semantically similar to a set of seed examples (Carlson et al, 2009). At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics &amp;quot;coherent&amp;quot;, based on criteria such as max</context>
</contexts>
<marker>Carlson, Betteridge, Hruschka, Mitchell, 2009</marker>
<rawString>Carlson, A., Betteridge, J., Hruschka, E., Mitchell, T. 2009. Coupling Semi-Supervised Learning of Categories and Relations. Proceedings of the NAACL HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clark</author>
<author>P Harrison</author>
</authors>
<title>Exploiting Paraphraes and Deferred Sense Commitment to Interpret Questions more Reliably.</title>
<date>2010</date>
<publisher>(Submitted).</publisher>
<contexts>
<context position="2144" citStr="Clark and Harrison, 2010" startWordPosition="340" endWordPosition="343">nd language; Prior knowledge should guide interpretation of new text, and new interpretations should augment that prior knowledge. Such interaction is essential if ambiguities in language are to be resolved &amp;quot;correctly&amp;quot; (with respect to what is 1 known), and if the resulting interpretations are to be integrated with existing knowledge. The main insight of this paper is that this interaction is similar to that required for knowledge-based question answering, which also requires searching a knowledge base (KB) for a valid interpretation of the question. In our earlier work on question answering (Clark and Harrison, 2010), we found that some disambiguation decisions for question interpretation could be deferred, to be resolved during question answering, guided by what was found in the KB. In this paper, we show how a similar approach can be applied to interpreting declarative text, so that a similar interplay between language and knowledge is achieved. &amp;quot;Machine reading&amp;quot; itself is a loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to p</context>
</contexts>
<marker>Clark, Harrison, 2010</marker>
<rawString>Clark, P., Harrison, P. 2010. Exploiting Paraphraes and Deferred Sense Commitment to Interpret Questions more Reliably. (Submitted).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Dahlgren</author>
<author>C Lord</author>
<author>H Wada</author>
<author>J McDowell</author>
<author>E Sabler</author>
</authors>
<title>ITP: Description of the interpretext system as used for MUC-3.</title>
<date>1991</date>
<booktitle>In Proc 3rd Message Understanding Conference (MUC-3),</booktitle>
<pages>163--170</pages>
<contexts>
<context position="3007" citStr="Dahlgren et al., 1991" startWordPosition="475" endWordPosition="478">reting declarative text, so that a similar interplay between language and knowledge is achieved. &amp;quot;Machine reading&amp;quot; itself is a loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP (DeJong, 1979), to full language processing, e.g., (Dahlgren et al., 1991). Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (Riloff, 1996; Sekine, 2006) or contain information semantically similar to a set of seed examples (Carlson et al, 2009). At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most Proceedings of the NAACL HLT 2010 Fi</context>
</contexts>
<marker>Dahlgren, Lord, Wada, McDowell, Sabler, 1991</marker>
<rawString>Dahlgren, K., Lord, C., Wada, H., McDowell, J., Sabler, E. 1991. ITP: Description of the interpretext system as used for MUC-3. In Proc 3rd Message Understanding Conference (MUC-3), pp163-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G DeJong</author>
</authors>
<title>Prediction and Substantiation: Two processes that comprise understanding.</title>
<date>1979</date>
<booktitle>IJCAI’79,</booktitle>
<pages>217--222</pages>
<contexts>
<context position="2947" citStr="DeJong, 1979" startWordPosition="467" endWordPosition="468">how how a similar approach can be applied to interpreting declarative text, so that a similar interplay between language and knowledge is achieved. &amp;quot;Machine reading&amp;quot; itself is a loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP (DeJong, 1979), to full language processing, e.g., (Dahlgren et al., 1991). Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (Riloff, 1996; Sekine, 2006) or contain information semantically similar to a set of seed examples (Carlson et al, 2009). At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborati</context>
</contexts>
<marker>DeJong, 1979</marker>
<rawString>DeJong, G. 1979. Prediction and Substantiation: Two processes that comprise understanding. IJCAI’79, pp217-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dras</author>
<author>K Yamamoto</author>
</authors>
<date>2005</date>
<booktitle>Proc 3rd Internationl Workshop of Paraphrasing. South</booktitle>
<marker>Dras, Yamamoto, 2005</marker>
<rawString>Dras, M., Yamamoto, K. (Eds). 2005. Proc 3rd Internationl Workshop of Paraphrasing. South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pado</author>
</authors>
<title>Shalmaneser – a flexible toolbox for semantic role assignment.</title>
<date>2006</date>
<booktitle>Proc LREC</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="12279" citStr="Erk and Pado, 2006" startWordPosition="1993" endWordPosition="1996">side Y The condition “X is found in Y” can be expressed as the clause chain: { object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) } We use DIRT to explore alternative interpretations of the text, singling out those that help identify the facts in the text that are already known in the KB. 3.2 Deferred Sense Commitment Two common challenges for NLP are word sense disambiguation (WSD) and semantic role labeling 3 (SRL). While there are a number of existing tools 4 Algorithm and Implementation for performing these tasks based on the linguistic 4.1 Topics and Participants context (e.g., Toutanova et al., 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al, 2007). The problem is accentuated when trying to disambiguate in a way consistent with a particular KB, because there is often a degree of subjectivity in how the knowledge engineer chose to represent the world in that KB (e.g., whether some object is the &amp;quot;agent&amp;quot; or &amp;quot;instrument&amp;quot; or &amp;quot;site&amp;quot; of an activity is to a degree a matter of viewpoint). Trying to create a WSD or SRL module that reliably mimics the knowledge engineer’s decision procedure is difficult. To address this, we defer WSD and SRL commitment during the initial text processin</context>
</contexts>
<marker>Erk, Pado, 2006</marker>
<rawString>Erk, K., Pado, S. 2006. Shalmaneser – a flexible toolbox for semantic role assignment. Proc LREC 2006, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Feigenbaum</author>
</authors>
<title>Some Challenges and Grand Challenges for Computational Intelligence.</title>
<date>2003</date>
<journal>Journal of ACM,</journal>
<volume>50</volume>
<issue>1</issue>
<pages>32--40</pages>
<marker>Feigenbaum, 2003</marker>
<rawString>Feigenbaum, E. 2003. Some Challenges and Grand Challenges for Computational Intelligence. Journal of ACM, 50 (1), pp 32-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gomez-Perez</author>
<author>D Manzano-Macho</author>
</authors>
<title>A Survey of Ontology Learning Methods and Techniques&amp;quot;,</title>
<date>2003</date>
<booktitle>Univ Politecnica de Madrid (OntoWeb Deliverable 1.5, http://www.sti-innsbruck.at/ fileadmin/documents/deliverables/Ontoweb/D1.5.pdf )</booktitle>
<tech>Technical Report,</tech>
<contexts>
<context position="28294" citStr="Gomez-Perez and Manzano-Macho, 2003" startWordPosition="4517" endWordPosition="4520">ntially overwhelm the system, and so such extensions would need to be made carefully. This is an area for future work. How large must the starting KB be? Although it can be missing (possibly many) axioms, we implicitly assume that at least the basic ontology and the mapping from words to concepts is reasonably complete (for the types of texts being considered), i.e., there is a good &amp;quot;skeleton&amp;quot; KB to add axioms to. Thus, methodologically, a first step for using our system would be to create the initial ontology and lexical mappings, e.g., via corpus analysis or using an ontology learning tool (Gomez-Perez and Manzano-Macho, 2003). Beyond that, the more axioms the starting KB has the better, as each axiom can potentially guide the interpretation of a new sentence. In the limiting case, where there are no axioms (only the ontology and lexical mappings), our system&apos;s behavior reverts to that of a normal, pipelined NLP interpreter (with the normal associated problems). This work is still preliminary, and there are numerous other issues and limitations that need to be addressed also. Three notable issues are as follows: • Syntactic ambiguity: While we defer WSD and SRL commitment, our system is eagerly committing to a sing</context>
</contexts>
<marker>Gomez-Perez, Manzano-Macho, 2003</marker>
<rawString>Gomez-Perez, A., Manzano-Macho, D. 2003. &amp;quot;A Survey of Ontology Learning Methods and Techniques&amp;quot;, Technical Report, Univ Politecnica de Madrid (OntoWeb Deliverable 1.5, http://www.sti-innsbruck.at/ fileadmin/documents/deliverables/Ontoweb/D1.5.pdf )</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gunning</author>
<author>M Greaves</author>
<author>V Chaudhri</author>
</authors>
<date>2010</date>
<booktitle>Project Halo Update – Progress Towards Digital Aristotle (Submitted).</booktitle>
<contexts>
<context position="6121" citStr="Gunning et al., 2010" startWordPosition="970" endWordPosition="973">ructures and processes expressed in first-order logic. Our goal is to take paragraphs of text about a topic partially covered by the KB, and identify facts which are already known, facts which are new, and the connections 1 Specifically, it has detailed representations of entities and processes related to cell division, DNA replication, and protein synthesis, containing approximately 250 domain-specific concepts (built on top of a pre-existing library of approximately 500 domain-general concepts), 120 relations (binary predicates), and approximately 2000 axioms, built as part of Project Halo (Gunning et al., 2010). Topic: prophase Input Paragraph: In the cytoplasm, the mitotic spindle, consisting of microtubules and other proteins, forms between the two pairs of centrioles as they migrate to opposite poles of the cell. Output Axioms: (expressed in English) In all prophase events: a. The mitotic spindle has parts the microtubule and the protein. b. The mitotic spindle is created between the centrioles in the cytoplasm. c. The centrioles move to the poles. Figure 1: The system’s behavior, showing known (normal font) and new (bold) facts identified from the text. Note that the output is not just a simple </context>
</contexts>
<marker>Gunning, Greaves, Chaudhri, 2010</marker>
<rawString>Gunning, D., Greaves, M., Chaudhri, V. et al. 2010. Project Halo Update – Progress Towards Digital Aristotle (Submitted).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Harrison</author>
<author>M Maxwell</author>
</authors>
<title>A New Implementation of GPSG.</title>
<date>1986</date>
<booktitle>In Proc. 6th Canadian Conf on AI.</booktitle>
<contexts>
<context position="15868" citStr="Harrison and Maxwell, 1986" startWordPosition="2578" endWordPosition="2581"> all the instances connected via some chain of predicates to X0. We encode this using a participant(x,yi) relation2. As this computation is potentially unbounded, we use a depth bound to heuristically limit this computation. 4.2 Initial Language Processing Assume the system has a paragraph of text about a topic, and that it has identified what that topic is3. For example, consider that the topic is prophase (a step in cell division), and the paragraph is the single sentence: T: The mitotic spindle consists of hollow microtubules. Text is parsed using a broad coverage, phrase structure parser (Harrison and Maxwell, 1986), followed by coreference resolution, producing a &amp;quot;syntactic&amp;quot; logical form, here: LF: &amp;quot;mitotic-spindle&amp;quot;(s), &amp;quot;consist&amp;quot;(c), &amp;quot;hollow&amp;quot;(h), &amp;quot;microtubule&amp;quot;(m), subject(c,s), &amp;quot;of&amp;quot;(c,m), modifier(m,h). 2 We can formalize this by adding participant(x,yi) to the conclusion in [1] for all yi, plus an axiom that participant is transitive. 3 E.g., via some topic classification algorithm. For our experiments here, we manually declare the topic. 4.3 Semantic Interpretation To interpret T the system then tries to answer, or partially answer, the corresponding question: T: Is it true that the mitotic spindle co</context>
</contexts>
<marker>Harrison, Maxwell, 1986</marker>
<rawString>Harrison, P., Maxwell, M. 1986. A New Implementation of GPSG. In Proc. 6th Canadian Conf on AI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobb</author>
<author>M Stickel</author>
<author>D Appelt</author>
<author>P Martin</author>
</authors>
<title>Interpretation as Abudction.</title>
<date>1993</date>
<journal>In Artificial Intelligence</journal>
<volume>63</volume>
<pages>1--2</pages>
<marker>Hobb, Stickel, Appelt, Martin, 1993</marker>
<rawString>Hobb, J., Stickel, M., Appelt, D., Martin, P. 1993. Interpretation as Abudction. In Artificial Intelligence 63 (1-2), pp 69-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2001</date>
<journal>Natural Language Engineering</journal>
<volume>7</volume>
<issue>4</issue>
<pages>343--360</pages>
<contexts>
<context position="11194" citStr="Lin and Pantel, 2001" startWordPosition="1807" endWordPosition="1810">arize these three features, then present the complete algorithm. 3.1 Paraphrases A relatively recent advance in NLP has been the automatic construction of paraphrase databases (containing phrasal patterns with approximately equivalent meaning), built by finding phrases that occur in distributionally similar contexts (e.g., Dras et al, 2005). To date, paraphrase databases have primarily been exploited for recognizing textual entailment (e.g., Bentivogli et al., 2009). In our work, we take them in a new direction and exploit them for language interpretation. We use the DIRT paraphrase database (Lin and Pantel, 2001a,b), containing approximately 12 million automatically learned rules of the form: IF X relation Y THEN X relation&apos; Y where relation is a path in the dependency tree between constitutents X and Y, or equivalently (as we use later) a chain of clauses: {p0(x0,x1), w1(x1), ...pn-1(x n-1,xn)} where pi is the syntactic relation between (nonprepositional) constituents xi and xi+1, and wi is the word used for xi. An example from DIRT is: IF X is found in Y THEN X is inside Y The condition “X is found in Y” can be expressed as the clause chain: { object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) } We use DIRT to e</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Lin, D. and Pantel, P. 2001a. Discovery of Inference Rules for Question Answering. Natural Language Engineering 7 (4) pp 343-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<date>2001</date>
<booktitle>Discovery of Inference Rules in Text. Proc ACM SIGKDD Conf on Knoweldge Discovery and Data Mining.</booktitle>
<contexts>
<context position="11194" citStr="Lin and Pantel, 2001" startWordPosition="1807" endWordPosition="1810">arize these three features, then present the complete algorithm. 3.1 Paraphrases A relatively recent advance in NLP has been the automatic construction of paraphrase databases (containing phrasal patterns with approximately equivalent meaning), built by finding phrases that occur in distributionally similar contexts (e.g., Dras et al, 2005). To date, paraphrase databases have primarily been exploited for recognizing textual entailment (e.g., Bentivogli et al., 2009). In our work, we take them in a new direction and exploit them for language interpretation. We use the DIRT paraphrase database (Lin and Pantel, 2001a,b), containing approximately 12 million automatically learned rules of the form: IF X relation Y THEN X relation&apos; Y where relation is a path in the dependency tree between constitutents X and Y, or equivalently (as we use later) a chain of clauses: {p0(x0,x1), w1(x1), ...pn-1(x n-1,xn)} where pi is the syntactic relation between (nonprepositional) constituents xi and xi+1, and wi is the word used for xi. An example from DIRT is: IF X is found in Y THEN X is inside Y The condition “X is found in Y” can be expressed as the clause chain: { object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) } We use DIRT to e</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Lin, D. and Pantel, P. 2001b. Discovery of Inference Rules in Text. Proc ACM SIGKDD Conf on Knoweldge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mulkar</author>
<author>J Hovy Hobbs</author>
<author>E</author>
</authors>
<title>Learning to Read Syntactically Complex Biology Texts. In</title>
<date>2007</date>
<booktitle>Proc 8th International Symposium on Logical Formalizations of Commonsense Reasoning</booktitle>
<publisher>(AAAI Spring Symposium).</publisher>
<contexts>
<context position="3931" citStr="Mulkar et al (2007)" startWordPosition="616" endWordPosition="619"> i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics &amp;quot;coherent&amp;quot;, based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions. For example, Mulkar et al (2007) search for a set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be a word sense or coreference decision with an associated cost. Similarly, Zadrozny and Jensen (1991) search a space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria. Work on model building is inspiring but also challenging due to the lack of constraint on the final models (even with substantial domain knowled</context>
</contexts>
<marker>Mulkar, Hobbs, E, 2007</marker>
<rawString>Mulkar, R., Hobbs, J. Hovy, E. 2007. Learning to Read Syntactically Complex Biology Texts. In Proc 8th International Symposium on Logical Formalizations of Commonsense Reasoning (AAAI Spring Symposium).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pinkal</author>
</authors>
<title>On Semantic Underspecification.</title>
<date>1999</date>
<booktitle>In Bunt, H./Muskens, R. (Eds.). Proceedings of the 2nd International Workshop on Compuational Linguistics (IWCS 2).</booktitle>
<contexts>
<context position="13116" citStr="Pinkal, 1999" startWordPosition="2140" endWordPosition="2141">wledge engineer chose to represent the world in that KB (e.g., whether some object is the &amp;quot;agent&amp;quot; or &amp;quot;instrument&amp;quot; or &amp;quot;site&amp;quot; of an activity is to a degree a matter of viewpoint). Trying to create a WSD or SRL module that reliably mimics the knowledge engineer’s decision procedure is difficult. To address this, we defer WSD and SRL commitment during the initial text processing. Instead, these ambiguities are resolved during the subsequent stage of querying the KB to see if (some interpretion of) the text is already known. One can view this as a trivial form of preserving underspecification (eg. Pinkal, 1999) in the initial language processing, where the words themselves denote their possible meanings. 3.3 Interpretation of New Knowledge Given some text, our system attempts to disambiguate it by searching for (some interpretation of) its statements in the KB. However, this will only disambiguate statements of facts that are already known. For new facts, we fall back on traditional disambiguation methods, using a set of approximately 100 hand-built rules for semantic role labelling, and word sense disambiguation preferences taken from WordNet sense frequency statistics and from the KB. In addition,</context>
</contexts>
<marker>Pinkal, 1999</marker>
<rawString>Pinkal, M. 1999. On Semantic Underspecification. In Bunt, H./Muskens, R. (Eds.). Proceedings of the 2nd International Workshop on Compuational Linguistics (IWCS 2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text.</title>
<date>1996</date>
<booktitle>Proc AAAI’96.</booktitle>
<contexts>
<context position="3119" citStr="Riloff, 1996" startWordPosition="494" endWordPosition="495">is a loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP (DeJong, 1979), to full language processing, e.g., (Dahlgren et al., 1991). Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (Riloff, 1996; Sekine, 2006) or contain information semantically similar to a set of seed examples (Carlson et al, 2009). At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9, Los Angeles, Califo</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Riloff, E. 1996. Automatically Generating Extraction Patterns from Untagged Text. Proc AAAI’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
</authors>
<title>On-Demand Information Extraction.</title>
<date>2006</date>
<booktitle>Proc. COLING-ACL.</booktitle>
<contexts>
<context position="3134" citStr="Sekine, 2006" startWordPosition="496" endWordPosition="497">efined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text. One approach for selective extraction is the use of semantic templates (&amp;quot;scripts&amp;quot;, &amp;quot;frames&amp;quot;) to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP (DeJong, 1979), to full language processing, e.g., (Dahlgren et al., 1991). Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers (Riloff, 1996; Sekine, 2006) or contain information semantically similar to a set of seed examples (Carlson et al, 2009). At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text&apos;s contents (e.g., Zadrozny 1991, Hobbs et al, 1993). A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9, Los Angeles, California, June 2010</context>
</contexts>
<marker>Sekine, 2006</marker>
<rawString>Sekine, S. 2006. On-Demand Information Extraction. Proc. COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>A Haghighi</author>
<author>C Manning</author>
</authors>
<title>A Global Joint Model for Semantic Role Labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="12258" citStr="Toutanova et al., 2008" startWordPosition="1989" endWordPosition="1992"> found in Y THEN X is inside Y The condition “X is found in Y” can be expressed as the clause chain: { object-of(x,f), &amp;quot;find&amp;quot;(f), &amp;quot;in&amp;quot;(f,y) } We use DIRT to explore alternative interpretations of the text, singling out those that help identify the facts in the text that are already known in the KB. 3.2 Deferred Sense Commitment Two common challenges for NLP are word sense disambiguation (WSD) and semantic role labeling 3 (SRL). While there are a number of existing tools 4 Algorithm and Implementation for performing these tasks based on the linguistic 4.1 Topics and Participants context (e.g., Toutanova et al., 2008, Erk and Pado, 2006), their performance is only moderate (e.g., Agirre et al, 2007). The problem is accentuated when trying to disambiguate in a way consistent with a particular KB, because there is often a degree of subjectivity in how the knowledge engineer chose to represent the world in that KB (e.g., whether some object is the &amp;quot;agent&amp;quot; or &amp;quot;instrument&amp;quot; or &amp;quot;site&amp;quot; of an activity is to a degree a matter of viewpoint). Trying to create a WSD or SRL module that reliably mimics the knowledge engineer’s decision procedure is difficult. To address this, we defer WSD and SRL commitment during the i</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2008</marker>
<rawString>Toutanova, K., Haghighi, A., Manning, C. 2008. A Global Joint Model for Semantic Role Labeling. Computational Linguistics, 34 (2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zadrozny</author>
<author>K Jensen</author>
</authors>
<title>Semantics of Paragraphs.</title>
<date>1991</date>
<journal>in Computational Linguistics</journal>
<volume>17</volume>
<issue>2</issue>
<pages>171--209</pages>
<contexts>
<context position="4201" citStr="Zadrozny and Jensen (1991)" startWordPosition="661" endWordPosition="664">eedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics &amp;quot;coherent&amp;quot;, based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions. For example, Mulkar et al (2007) search for a set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be a word sense or coreference decision with an associated cost. Similarly, Zadrozny and Jensen (1991) search a space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria. Work on model building is inspiring but also challenging due to the lack of constraint on the final models (even with substantial domain knowledge) and the difficulty of quantifying &amp;quot;coherence&amp;quot;. Our work falls somewhere between these two. We do not use templates for new knowledge, but rather use inference at run-time to identify what is known and thus what to expect that the text might be saying. However, unlik</context>
</contexts>
<marker>Zadrozny, Jensen, 1991</marker>
<rawString>Zadrozny, W., Jensen, K. 1991. Semantics of Paragraphs. in Computational Linguistics 17 (2) pp171-209.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>