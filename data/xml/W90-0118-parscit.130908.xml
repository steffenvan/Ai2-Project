<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.066681">
<title confidence="0.977396">
Reassessing Rhetorical Abstractions and Planning Mechanisms&apos;
</title>
<author confidence="0.99818">
Daniel D. Suthers
</author>
<affiliation confidence="0.909414666666667">
Department of Computer and Information Science
University of Massachusetts
Amherst, Massachusetts 01003
</affiliation>
<email confidence="0.987927">
suthers@cs.umass.edu
</email>
<sectionHeader confidence="0.997223" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998763">
The utility of rhetorical abstractions and certain text
planning mechanisms were assessed from the stand-
point of accounting for how an explainer chooses and
structures content under multiple perspectives to meet
knowledge communication goals. This paper discusses
ways in which they were found to be inadequate, ar-
gues for greater emphasis on an epistemological level of
analysis, and proposes a mixed architecture matching
computational mechanisms to the explanation planning
subtasks they are suited for.
</bodyText>
<sectionHeader confidence="0.97549" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.995376156862745">
Our research is concerned with explanation in its
broad sense, as &amp;quot;the act or process of making plain
or comprehensible; elucidation; clarification&amp;quot; (Ameri-
can Heritage Dictionary). In many physical science do-
mains, an explanation can be based on a variety of mod-
els of the phenomenon being explained. These models
differ on the type of properties and relationships em-
phasized; what ontology is used and whether the phe-
nomenon is described at a macroscopic, microscopic, or
atomic granularity; what factors are ignored or assumed
to be constant; the use of general statements vs. con-
crete examples; and in general on what concepts func-
tion as primitives, providing the basis for understand-
ing the topic phenomenon. Selection of an appropriate
model of the topic is an important aspect of content
selection which impacts on the interlocutor&apos;s compre-
hension of the explanation and on its appropriateness
for his or her purposes. We use the term perspective
to refer to an abstract characterization of the kind of
knowledge provided by a class of models. Our notion
of perspective is a composite of distinctions made by
Falkenhainer &amp; Forbus (submitted), Stevens &amp; Collins
(1980) Stevens &amp; Steinberg (1981) and White &amp; Fred-
eriksen (1989).
Copyright @ 1990, Daniel D. Suthers Permission granted to
copy for non-profit academic purposes.
Most existing work in explanation and text planning
has been directed at other problems, and hence has
utilized single-perspective knowledge bases to simplify
the research. (Notable exceptions include McCoy, 1989
and McKeown et al. 1985.) A number of such re-
search efforts emphasize rhetorical abstractions for the
analysis of natural explanations and for expressing a
theory of explanation (Hovy, 1988; Mann &amp; Thomp-
son, 1986; Maybury, 1988; McKeown, 1985; Moore,
1989). A variety of mechanisms for selecting and or-
ganizing the content of explanations have also been ex-
plored. This includes schema filling (McKeown 1985)
and structure matching (Hovy 1988), graph traversal
algorithms (Paris &amp; McKeown 1986), and top-down ex-
pansion planning (Cawsey, 1989; Moore, 1989).
Our own work on choosing explanatory content from
multiple-perspective knowledge bases has uncovered
some limitations of rhetorical abstractions, and led us
to question previous applications of the computational
mechanisms listed above. The purpose of this paper is
to present our perception of the roles and limitations of
these items, and suggest some alternatives. (We do not
emphasize our work on perspective and content organi-
zation here: see Suthers &amp; Woolf, 1990.) We begin with
an example, used to illustrate some of the problems.
</bodyText>
<subsectionHeader confidence="0.92475">
An Example
</subsectionHeader>
<bodyText confidence="0.999944375">
The following example explanation will be used to
illustrate our points. The domain is elementary elec-
tricity. We emphasize the communication of an under-
standing of concepts such as &amp;quot;charge&amp;quot;, &amp;quot;current&amp;quot;, and
&amp;quot;capacitance&amp;quot; within the context of qualitative reason-
ing about the behavior of simple circuits and their com-
ponents. The explanation is an edited version of a hu-
man protocol.
</bodyText>
<footnote confidence="0.769331666666667">
Ql: How does a capacitor store charge?
El: A capacitor
E2: can be thought of as two flat metallic plates
</footnote>
<page confidence="0.991404">
137
</page>
<figure confidence="0.994632375">
IAir Background
lAirConstituency
1,4KAttril&lt;tive?
1,4r Conclusion?
Cause-Effect I
1
I,,,Illustration
2 3 4 5 6 7 8 9
</figure>
<figureCaption confidence="0.999898">
Figure 1: One possible RST analysis (partial)
</figureCaption>
<bodyText confidence="0.995921055555556">
E3: situated close to each other and parallel to each
other,
E4: with air in between.
ES: If you connect a capacitor to a battery,
E6: as follows:
point out some features of interest. For example, we
note that the explanation starts with Background ma-
terial (El-E4) before proceeding to the primary expla-
nation (E5-E9). The Background relation in this case
describes the high level organization of the explanation.
The question is how this relation should be manifest in
the mechanism for generating the explanation. Also of
interest are the explainer&apos;s determination that a process
account of how the capacitor carries out its function is
appropriate; use of an abstract structural model of the
capacitor, simplified to what is needed to support the
process account; and use of a concrete situation for the
enablement condition of the process.
</bodyText>
<subsectionHeader confidence="0.989205">
Problems with Rhetorical Abstractions
</subsectionHeader>
<bodyText confidence="0.991940535714286">
El: then positive charge builds up on one plate and neg-
ative charge on the other,
E8: until the voltage across the capacitor is equal to the
voltage of the battery.
E9: The charge stays there when you disconnect the bat-
tery.
One possible rhetorical analysis of the first explana-
tion, using relations from McKeown (1985) and Mann &amp;
Thompson (1986), is given in Figure 1. (Whether or not
this is an optimal analysis is not the point; rather we are
concerned with the role of rhetorical abstractions and
various characterizations of the content planning task
in accounting for the explanation.) The analysis does
Rhetorical relations were an important development
in explanation research, since they provided a first pass
at abstractions for a general description of explanatory
structure, and in bringing various roles of the parts
of explanation into the foreground, pointed out phe-
nomena in need of further study. They are also useful
via their &amp;quot;relational propositions&amp;quot; (Mann &amp; Thomp-
son 1983), for conveying propositional information im-
plicitly in the structure of the text, hence reducing its
length and redundancy. However, we claim that rhetor-
ical abstractions fail to make the necessary distinctions
for further advances in a theoretical understanding of
explanation.
Potpourri. Rhetorical abstractions are descriptive of
explanatory tent, i.e. the end product of some expla-
</bodyText>
<page confidence="0.997435">
138
</page>
<bodyText confidence="0.995214237288136">
nation generation process, and so describe with one de-
vice structure due to a variety of distinct knowledge
sources bearing on such a process. These knowledge
sources operate on different levels of information, and
hence need to be separated in a theory of explanation
generation. For example, (drawing on relations in McK-
eown, 1985 and Mann &amp; Thompson, 1986) some corre-
spond directly to the fundamental structure of domain
objects and processes (e.g. Constituency and Causal-
ity), while others are about derived relations between
concepts which may vary according to the context (e.g.
Comparison). Relations such as Amplification, Back-
ground, Evidence, and Illustration are primarily about
relationships between propositions which arise in part
out of consideration of what the interlocutor knows and
needs to know to better grasp a point. Illocutionary
acts are involved in the relations as well (most blatantly,
Concession; others are not themselves illocutionary acts
but only make sense in the context of certain such acts).
Finally, relations such as Topic and Conclusion appear
to be due to conventions governing writing style which
direct focus of attention. Grosz &amp; Sidner (1986) made
similar criticisms from the standpoint of characterizing
discourse coherence. They suggested that each rhetori-
cal relation combines domain information with certain
general relations between propositions, between actions,
and between intentions.
Implicit Features Unaccounted For. Rhetorical
abstractions are also inappropriate for a theory of con-
tent selection because, in describing the final text, they
fail to identify important relations between the chosen
content and external material, such as what is known
about the user, or information left out of the explana-
tion. For example, E5-E6 is more specific than is neces-
sary and includes a concrete example. A more general
and accurate way to state the condition for initiation of
the charging process would be &amp;quot;If a voltage is applied
to the plates ...&amp;quot;. However, the explainer has opted to
replace this with one of the many particular configura-
tions which meet the condition. A rhetorical analysis
of the text cannot even, tell us that this has happened,
let alone why, because it does not describe relations be-
tween the contents of the text and what is not included,
viz., other models of the process being described. It can
only report that an illustration is being used. Another
example is provided by E9. Retention of charge when
the voltage is removed is what is meant by &amp;quot;storage&amp;quot; in
this case, so the fact expressed in E9 is essential to an-
swering the question. Rhetorically, we can only identify
relationships E9 has to the rest of the text, e.g. that it is
a Conclusion. This does not illuminate the relationship
between its content and the goal of the explanation.
Epistemological Analysis. The success of an expla-
nation is primarily a function of choice and organiza-
tion of knowledge. Hence, to account for how these
choices further knowledge communication goals, one
must examine explanation in part from an epistemo-
logical standpoint. Such an analysis examines how ex-
planations are guided by:
</bodyText>
<listItem confidence="0.980904666666667">
• the types of knowledge in a given domain, and its
logical and etiological structure (Rissland, 1978);
• the types of knowledge which, in principle, could
fulfill a given request for information;
• the role of an individual&apos;s knowledge in under-
standing new concepts and situations, and hence
in understanding a given explanation (Paris, 1987);
and
• the ways in which individuals are willing or able
to undertake conceptual change (Goldstein, 1979;
Hewson, 1981; White &amp; Frederiksen, 1989; van-
Lehn, 1987).
</listItem>
<bodyText confidence="0.999626857142857">
As discussed in Suthers (1989), most previous work has
offered solutions to the subproblems of explanation in
the form of mechanisms and data structures which are
in part the result of, rather than the expression of, epis-
temological considerations. Epistemological problems
have been avoided through direct selection of content
based on well-formulated queries; the simplicity of the
knowledge bases used, which only permit one way of
discussing each topic; and through implicit conflation
of epistemological constraints on organization of the ex-
planation with those of rhetorical and linguistic origin.
A major goal of our research (Suthers &amp; Woolf, 1990)
is an explicit theory of the epistemological structure of
the activity of explaining.
</bodyText>
<subsectionHeader confidence="0.994615">
Roles of Computational Mechanisms
</subsectionHeader>
<bodyText confidence="0.999977357142857">
In this section we illustrate how inclusion of back-
ground material and the use of multiple perspectives
pose problems for various mechanisms in the literature,
and suggest a mixed architecture solution.
Structure Matching. By &amp;quot;structure matching&amp;quot; we
mean methods where abstract descriptions of the struc-
ture of explanations are matched to a collection of
propositions (or other content to be expressed) in order
to organize this material. This includes bottom-up com-
position of structural units (Ilovy, 1988) and schema
filling (McKeown, 1985). We question their adequacy
for accounting for the prerequisite structure of expla-
nations, such as the Background relation of the exam-
ple. In our view, the explanation is organized this way
</bodyText>
<page confidence="0.995476">
139
</page>
<bodyText confidence="0.999982165048544">
because the explainer recognized in his process model
(expressed in E5-E9) concepts the interlocutor may not
be familiar with (the parts of a capacitor), and then
added material prerequisite to understanding the pro-
cess explanation (the structural description expressed in
E1-E4). The background material is not automatically
part of the relevant knowledge pool for this question,
and structure matching methods leave choice of con-
tent and perspective to other mechanisms. Suppose,
then, that some other mechanism accounts for inclu-
sion of the background in the pool. It is included as
background by virtue of relationships between the inter-
locutor&apos;s assumed knowledge state and the conceptual-
izations contained in the first attempt at a knowledge
pool. Pattern matching techniques which are ignorant
of such relationships and see only the composite pool
would be unable to identify the part of the knowledge
pool which plays the role of &amp;quot;background&amp;quot;, and account
for placement of background before primary material.
Graph Traversal. These are algorithms for selec-
tively following links in a knowledge base, with the path
so traced out providing the content and structure of
the explanation (Paris &amp; McKeown 1986). Such meth-
ods model how an explanation exploits the structure of
knowledge. They implicitly embody the heuristic that
it will be easier for the interlocutor to reconstruct the
knowledge if it is presented such that each unit is in-
troduced in relation to the previous unit. For example,
parts of an object are introduced in relation to con-
taining or adjacent parts, and process descriptions or-
ganized to follow temporal and causal relations in the
forward direction. However, graph traversal is limited
to modeling local organization, or global organization
which is a composite of local choices. Traversal meth-
ods don&apos;t naturally extend to global organization which
occurs at a higher level of abstraction than the links
followed, e.g. the presentation of a coherent structural
model before a process account begins.
Top-Down Goal Expansion. Top-down expansion
of a discourse goal (Cawsey, 1989; Moore, 1989) is a
stronger candidate for a uniform mechanism for expla-
nation, integrating content selection and structuring.
The background problem can be handled with precon-
ditions on plan operators, as Cawsey does. It simplifies
modeling explanations such as our example if one can
specify the kind of background knowledge required in
preconditions at the highest level of plan operators. To
illustrate, consider a rhetorical plan operator which con-
tains an optional satellite for Background but does not
specify what constitutes background knowledge. Ex-
pansion of the satellite would have to be predicated on
a comparison of the content selected by expansion of
the nucleus with the user model. This decision could
not be made at the time the operator is selected by the
planning system, since the knowledge pool for the nu-
cleus would not have been selected yet. Instead, one
would have to place the satellite decision on hold, ex-
pand the nucleus, collect together the knowledge se-
lected at the leaves of its expansion, and perform the
comparison before deciding on the satellite. (One could
make the decisions concerning the need for background
locally to each leaf, avoiding the need for a high level
decision depending on knowledge selected at many lo-
calities. But then one could not model the structure of
explanations such as this one, where the need for prereq-
uisite material is anticipated and provided in advance
as a coherent model, rather than as an interruption to
the flow of the process description.) Then, if it was
decided that some background was required, expansion
of the satellite would have to occur under a binding of
some variable in the satellite to the concepts for which
background is required.
With regards to perspective, some problems emerge.
Content selection in top-down expansion can be influ-
enced by the current perspective if some mechanism for
sharing perspective decisions across the expansion tree
is provided. However, neither the choice of perspec-
tive nor the actual mechanism by which it influences
content selection are modeled appropriately by top-
down expansion. Choice of perspective tries to balance
the (sometimes conflicting) constraints of adequacy and
comprehensibility. Adequacy constraints come from ex-
amination of the informative goals (McKeown et al.
1985). Comprehensibility requires answering the ques-
tion: given the concepts which have been used in the
dialogue so far, and/or which the explainer has evidence
the interlocutor is familiar with, what other concepts
are also likely to be familiar? This suggests a strength-
of-association mechanism (McCoy 1989), which we com-
ment on further in the next section. As Hovy (1990)
points out, top-down planning is prescriptive, and does
not handle conflicting goals easily. The influence of per-
spective on content selection involves what Hovy calls
restrictive planning: some perspective goals, once gen-
erated, remain active throughout a span of discourse,
and operate as preferences applied to choice points in
content selection. They cannot be erased once satisfied,
and they may change dynamically. Finally, McDonald
&amp; Pustejovsky (1985) point out that a uniform mecha-
nism may not be desirable, as it incorrectly implies that
all information is equally available during each point of
the text planning process. A principled match of dis-
tinct computational mechanisms to each subtask of the
</bodyText>
<equation confidence="0.969786454545455">
1 4 0
(Query) --&gt; Identify
V
Refine
V
Retrieve
V
Modify
1
V
Order --&gt; (Realize)
</equation>
<figureCaption confidence="0.996299">
Figure 2: Content planning tasks
</figureCaption>
<bodyText confidence="0.999275942528736">
explanation planning task is one way to express one&apos;s
theory of what kind of process explanation is. For these
reasons, we postulate a separate level of planning for co-
ordinating perspective decisions.
A Mixed Architecture. In our current approach,
planning occurs at two granularities: selection and re-
trieval of coherent packages of knowledge similar to
Suthers&apos; (1988a,b) &amp;quot;views&amp;quot; or Souther, Acker, Lester,
&amp; Porter&apos;s (1989) &amp;quot;viewpoints&amp;quot;; and editing and order-
ing the propositions and examples which make up these
views. Planning at the granularity of views is concerned
with purely epistemological constraints on identification
of appropriate content, including choice of perspective
and prerequisite explanations. At the finer granular-
ity, further epistemological constraints governing the
comprehensibility of the explanation are applied, and
rhetorical and linguistic constraints play a role as well.
The question at hand is: what sort of task is content
planning? We postulate several, and comment on possi-
ble computational mechanisms for each. Figure 2 gives
the rough relationships between the different tasks. The
process is reminiscent of case-based design, where one
identifies and refines design specifications, and retrieves
and reconfigures a previous solution to fit the circum-
stances.
An explainer must first identify at least some of its
goals. These are of two types, as discussed above: pre-
scriptive informative goals, and restrictive goals such as
comprehensibility. We mentioned that the latter sug-
gests a concept association mechanism. This could be
done by activating weighted links between concepts, or
though intermediate frames of attribute weights, as in
McCoy (1989). However, one would have to install a po-
tentially combinatorial number of associations between
concepts. Because we wish to make an epistemological
theory explicit and implement it with an abstract inter-
face to the knowledge base, we are investigating use of
a mechanism akin to prototype induction, to generate
an abstract description of the desired perspective from
the user model and dialogue history.
At the view granularity, content selection may be seen
as refinement of explanatory goals into a specification
of the appropriate addition to the relevant knowledge
pool. This refinement includes consideration of what
type of knowledge, in principle, could fulfill the infor-
mative goal; of the concepts the interlocutor is likely to
understand; and of the models which have already been
shared in the dialogue. We are attempting to treat this
refinement task as top-down planning, though our work
has not progressed far enough to comment further on
this.
Retrieval requires a knowledge-base specific mech-
anism: its only theoretical importance to us is that it
correctly operationalize the dimensions used to describe
the desired view (Suthers 1988a,b). We are examining
a variant of compositional modeling (Falkenhainer &amp;
Forbus, submitted) for this purpose.
Once a knowledge pool is available, some data driven
activities occur at a finer granularity, resulting in mod-
ification of the relevant knowledge pool. This includes
filtering activities, such as removing particular proposi-
tions likely to be familiar to the interlocutor; and aug-
menting activities, such as illustrating abstract state-
ments with examples. These are opportunistic planning
tasks, that can be approached with critics which match
to the knowledge pool and user model, and specify re-
placements or deletions to be made. As shown in fig-
ure 2, data driven operators may also reinvoke content
planning at the refinement level to access material in
a different type of model. For example, we have seen
how process propositions may involve use of structural
concepts the interlocutor is not likely to understand,
causing the explainer to plan a prerequisite explana-
tion. An explicit record of the prerequisite relations
between views is created, important for ordering the
explanation.
Ordering is sensitive to prerequisite and illustration
links installed by the modification processes. Hence fig-
ure 2 should not be interpreted as a claim that order-
ing considerations do not arise during content selection.
The ordering task involves two kinds of processes. One
embodies epistemological constraints by exploiting ex-
isting structure in the knowledge pool. As discussed
previously, techniques for traversing links in the knowl-
edge pool apply here. The result will likely be a par-
tial ordering. Further ordering requires imposition of
structure for rhetorical, linguistic, and pictorial reasons
</bodyText>
<page confidence="0.996608">
141
</page>
<bodyText confidence="0.998505">
during realization (generation of text and graphics).
Matching of rhetorical patterns to the knowledge pool
may be more appropriate at this later stage.
In summary, we have argued for a mixed architec-
ture matching prescriptive, restrictive, and opportunis-
tic mechanisms to explanation subtasks. Coordination
of these diverse processes may, at the implementation
level, require an agenda control mechanism as in Niren-
burg, Lesser, &amp; Nyberg (1989).
</bodyText>
<sectionHeader confidence="0.688165" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999981208333333">
Single-perspective knowledge bases, i.e. those which
provide only a single conceptual basis for a given de-
scription or explanation, have dominated existing work
in planning expository text. This research has over-
emphasized rhetorical abstractions as the basis for the-
ories of content planning, and used computational for-
malisms such as top-down goal expansion, traversal al-
gorithms, and opportunistic structure matching which,
taken alone, fail to fully account for the search for ap-
propriate conceptualizations during content selection.
We suggest a greater emphasis on epistemological ab-
stractions, and viewing content selection in terms of
identification, refinement, retrieval, modification, and
ordering tasks. Rhetorical abstractions retain a place
in initial analyses of explanations, to point out features
in need of further study, and in the later stages of text
planning, to further constrain a partial ordering of con-
tent and implicitly convey content via textual structure.
Finally, the devices of top-down goal expansion, traver-
sal algorithms, and structure matching retain potential
utility for high level content planning, exploiting the
structure of knowledge when ordering an explanation,
and further ordering an explanation on a rhetorical ba-
sis, respectively.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999195">
The author has been supported by the National Sci-
ence Foundation under grant number MDR 8751362,
and by Apple Computer, Inc., Cupertino, CA. Par-
tial support was also received from the Office of Naval
Research under a University Research Initiative Grant,
contract no. N00014-86-K-0764. Thanks are due to my
advisors, Edwina Rissland and Beverly Woolf; to Klaus
Schultz for his expert explanations; to Matthew Cornell
for assistance with the research, and to the reviewers for
comments.
</bodyText>
<sectionHeader confidence="0.998692" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984115711538462">
Cawsey, A. (1989). Generating Explanatory Discourse:
A Plan-Based, Interactive Approach. Ph.D. Disserta-
tion, University of Edinburgh.
Falkenhainer &amp; Forbus (submitted). Compositional
Modeling: Finding the right model for the job. Sub-
mitted to Artificial Intelligence.
Goldstein, I. (1979). The genetic graph: a representa-
tion for the evolution of procedural knowledge. Inter-
national Journal of Man-Machine Studies, vol. 11, pp.
51-77.
Grosz, B. J. &amp; Sidner, C. L. (1986). Attention, in-
tention, and the structure of discourse. Computational
Linguistics, vol. 12, no. 3, pp. 175-204.
Hewson, P. W. (1981). A conceptual change approach
to learning science. European Journal of Science Edu-
cation, vol. 3, no. 4, pp. 383-396.
Hovy, E. H. (1988). Planning coherent multisentential
text. Proc. 26th Meeting of the A CL, Buffalo, New
York; Reprinted as ISI/RS-88-208, Information Sci-
ences Institute, Marina del Rey, California.
Hovy, E. H. (1990). Pragmatics and natural language
generation. Artificial Intelligence, vol. 43, no. 2, pp.
153-197.
Mann, W. C., &amp; Thompson, S. A. (1983). Relational
Propositions in Discourse. ISI/RR-83-115, Information
Sciences Institute, University of Southern California,
Marina del Rey, California.
Mann, W. C., &amp; Thompson, S. A. (1986). Rhetor-
ical structure theory: Description and construction of
text structures; Proceedings of the NATO Advanced Re-
search Workshop on Natural Language Generation, Ni-
jmegen, The Netherlands, August 19-23, 1986.
Maybury, M. (1988). Explanation rhetoric: The rhetor-
ical progression of justifications. Proc. AAAI-88 Work-
shop on Explanation, St. Paul, August 22, 1988, pp.
16-20.
McCoy, K. F. (1989). Generating context-sensitive re-
sponses to object-related misconceptions. Artificial In-
telligence, vol. 41, no. 2, pp. 157-195.
McDonald, D. D. &amp; Pustejovsky, J. D. (1985).
Description-directed natural language generation.
Proc. 9th Int. Joint Conf. on Artificial Intelligence,
Los Angeles, August 18-23, 1985, pp. 799-805.
McKeown, K. R. (1985). Discourse strategies for gen-
erating natural language text. Artificial Intelligence,
vol. 27, no. 1, pp. 1-41.
McKeown, K. It., Wish, M., St Matthews, K.
(1985). Tailoring explanations for the user. Proc. 9th
Int. Joint Conf. on Artificial Intelligence, Los Ange-
les, August 18-23, 1985, pp. 794-798.
Moore, J. D. (1989). A Reactive Approach to Expla-
nation in Expert and Advice-giving Systems. Ph.D.
</reference>
<affiliation confidence="0.768726">
Dissertation, University of California, Los Angeles.
</affiliation>
<page confidence="0.994079">
142
</page>
<reference confidence="0.999781018867924">
Nirenburg, S., Lesser, V., &amp; Nyberg, E. (1989).
Controlling a language generation planner. Proc. 11th
Int. Joint Conf. on Artificial Intelligence, Detroit,
pp. 1524-1530.
Paris, C. L. (1987). Combining discourse strategies to
generate descriptions to users along a Naive/Expert
spectrum. Proc. 10th Int. Joint Conf. on Artificial
Intelligence, August 1987, Milan, Italy, pp. 626-632.
Paris, C. L. &amp; McKeown, K. R. (1986). Discourse
strategies for describing complex physical objects; Pro-
ceedings of the NATO Advanced Research Workshop on
Natural Language Generation, Nijmegen, The Nether-
lands, August 19-23, 1986. Also published by Martinus
Nijhoff, Dordrecht, 1987.
Rissland, E. L. (1978). (Formerly Michener.) Under-
standing Understanding Mathematics. Cognitive Sci-
ence, vol. 2, no. 4.
Souther, A. Acker, L., Lester, J., &amp; Porter, B.
(1989). Using view types to generate explanations in
intelligent tutoring systems. Proc. Cognitive Science
Conf., Montreal, 1989.
Stevens, A. L. &amp; Collins, A. (1980). Multiple con-
ceptual models of a complex system. In R. E. Snow, P.
Federico, and W. E. Montague (Eds.), Aptitude, Learn-
ing, and Instruction (Vol. 2). Hillsdale, NJ: Erlbaum,
1980. pp. 177-197.
Stevens, A. L. &amp; Steinberg, C. (1981). A typology of
explanations and its application to intelligent computer
aided instruction. Report No. 4626, Bolt Beranek and
Newman Inc., Cambridge, MA.
Suthers, D. D. (1988a). Providing multiple views of
reasoning for explanation. Proc. Int. Conf. on In-
telligent Tutoring Systems, Montreal, June 1988, pp.
435-442.
Suthers, D. D. (1988b). Providing multiple views for
explanation. Proc. AAAI-88 Workshop on Explana-
tion, St. Paul, August 22, 1988, pp. 12-15.
Suthers, D. D. (1989). Perspectives in Explanation;
COINS Technical Report 89-24, Computer and Infor-
mation Science, University of Massachusetts, Amherst.
Suthers, D. D., &amp; Woolf, B. P. (1990). Account-
ing for the Epistemological Structure of Explanation.
Spring Symposium on Knowledge Based Environments
for Learning and Teaching, March 27-29, Stanford.
Available as COINS Technical Report 90-36, Computer
and Information Science, University of Massachusetts,
Amherst.
vanLehn, K. (1987). Learning one subprocedure per
lesson. Artificial Intelligence, vol. 31, no. 1, pp. 1-40.
White, B. Y. &amp; Frederiksen, J. R. (1990). Causal
Model Progressions as a Foundation for Intelligent
Learning Environments. Artificial Intelligence, vol.
42, no. 1, pp. 99-157.
</reference>
<page confidence="0.999132">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.989506">
<title confidence="0.999843">Reassessing Rhetorical Abstractions and Planning Mechanisms&apos;</title>
<author confidence="0.9999">Daniel D Suthers</author>
<affiliation confidence="0.999841">Department of Computer and Information University of</affiliation>
<address confidence="0.999103">Amherst, Massachusetts 01003</address>
<email confidence="0.999866">suthers@cs.umass.edu</email>
<abstract confidence="0.999184818181818">The utility of rhetorical abstractions and certain text planning mechanisms were assessed from the standpoint of accounting for how an explainer chooses and structures content under multiple perspectives to meet knowledge communication goals. This paper discusses ways in which they were found to be inadequate, argues for greater emphasis on an epistemological level of analysis, and proposes a mixed architecture matching computational mechanisms to the explanation planning subtasks they are suited for.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Cawsey</author>
</authors>
<title>Generating Explanatory Discourse: A Plan-Based, Interactive Approach.</title>
<date>1989</date>
<tech>Ph.D. Dissertation,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="2818" citStr="Cawsey, 1989" startWordPosition="424" endWordPosition="425">bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to present our perception of the roles and limitations of these items, and suggest some alternatives. (We do not emphasize our work on perspective and content organization here: see Suthers &amp; Woolf, 1990.) We begin with an example, used to illustrate some of the problems. An Example The following example explanation </context>
<context position="13589" citStr="Cawsey, 1989" startWordPosition="2122" endWordPosition="2123">le, parts of an object are introduced in relation to containing or adjacent parts, and process descriptions organized to follow temporal and causal relations in the forward direction. However, graph traversal is limited to modeling local organization, or global organization which is a composite of local choices. Traversal methods don&apos;t naturally extend to global organization which occurs at a higher level of abstraction than the links followed, e.g. the presentation of a coherent structural model before a process account begins. Top-Down Goal Expansion. Top-down expansion of a discourse goal (Cawsey, 1989; Moore, 1989) is a stronger candidate for a uniform mechanism for explanation, integrating content selection and structuring. The background problem can be handled with preconditions on plan operators, as Cawsey does. It simplifies modeling explanations such as our example if one can specify the kind of background knowledge required in preconditions at the highest level of plan operators. To illustrate, consider a rhetorical plan operator which contains an optional satellite for Background but does not specify what constitutes background knowledge. Expansion of the satellite would have to be </context>
</contexts>
<marker>Cawsey, 1989</marker>
<rawString>Cawsey, A. (1989). Generating Explanatory Discourse: A Plan-Based, Interactive Approach. Ph.D. Dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Falkenhainer</author>
<author>Forbus</author>
</authors>
<title>Compositional Modeling: Finding the right model for the job. Submitted to Artificial Intelligence.</title>
<marker>Falkenhainer, Forbus, </marker>
<rawString>Falkenhainer &amp; Forbus (submitted). Compositional Modeling: Finding the right model for the job. Submitted to Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Goldstein</author>
</authors>
<title>The genetic graph: a representation for the evolution of procedural knowledge.</title>
<date>1979</date>
<journal>International Journal of Man-Machine Studies,</journal>
<volume>11</volume>
<pages>51--77</pages>
<contexts>
<context position="9907" citStr="Goldstein, 1979" startWordPosition="1554" endWordPosition="1555">ther knowledge communication goals, one must examine explanation in part from an epistemological standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of discussing each topic; and through implicit conflation of epistemological constraints on organization of t</context>
</contexts>
<marker>Goldstein, 1979</marker>
<rawString>Goldstein, I. (1979). The genetic graph: a representation for the evolution of procedural knowledge. International Journal of Man-Machine Studies, vol. 11, pp. 51-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intention, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<pages>175--204</pages>
<contexts>
<context position="7492" citStr="Grosz &amp; Sidner (1986)" startWordPosition="1161" endWordPosition="1164"> the context (e.g. Comparison). Relations such as Amplification, Background, Evidence, and Illustration are primarily about relationships between propositions which arise in part out of consideration of what the interlocutor knows and needs to know to better grasp a point. Illocutionary acts are involved in the relations as well (most blatantly, Concession; others are not themselves illocutionary acts but only make sense in the context of certain such acts). Finally, relations such as Topic and Conclusion appear to be due to conventions governing writing style which direct focus of attention. Grosz &amp; Sidner (1986) made similar criticisms from the standpoint of characterizing discourse coherence. They suggested that each rhetorical relation combines domain information with certain general relations between propositions, between actions, and between intentions. Implicit Features Unaccounted For. Rhetorical abstractions are also inappropriate for a theory of content selection because, in describing the final text, they fail to identify important relations between the chosen content and external material, such as what is known about the user, or information left out of the explanation. For example, E5-E6 i</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. J. &amp; Sidner, C. L. (1986). Attention, intention, and the structure of discourse. Computational Linguistics, vol. 12, no. 3, pp. 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Hewson</author>
</authors>
<title>A conceptual change approach to learning science.</title>
<date>1981</date>
<journal>European Journal of Science Education,</journal>
<volume>3</volume>
<pages>383--396</pages>
<contexts>
<context position="9921" citStr="Hewson, 1981" startWordPosition="1556" endWordPosition="1557">mmunication goals, one must examine explanation in part from an epistemological standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of discussing each topic; and through implicit conflation of epistemological constraints on organization of the explanation</context>
</contexts>
<marker>Hewson, 1981</marker>
<rawString>Hewson, P. W. (1981). A conceptual change approach to learning science. European Journal of Science Education, vol. 3, no. 4, pp. 383-396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Planning coherent multisentential text.</title>
<date>1988</date>
<booktitle>Proc. 26th Meeting of the A CL,</booktitle>
<pages>88--208</pages>
<institution>Information Sciences Institute, Marina del Rey,</institution>
<location>Buffalo, New York; Reprinted as</location>
<contexts>
<context position="2467" citStr="Hovy, 1988" startWordPosition="370" endWordPosition="371">iner &amp; Forbus (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed abo</context>
</contexts>
<marker>Hovy, 1988</marker>
<rawString>Hovy, E. H. (1988). Planning coherent multisentential text. Proc. 26th Meeting of the A CL, Buffalo, New York; Reprinted as ISI/RS-88-208, Information Sciences Institute, Marina del Rey, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Pragmatics and natural language generation.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<volume>43</volume>
<pages>153--197</pages>
<contexts>
<context position="16271" citStr="Hovy (1990)" startWordPosition="2550" endWordPosition="2551">d appropriately by topdown expansion. Choice of perspective tries to balance the (sometimes conflicting) constraints of adequacy and comprehensibility. Adequacy constraints come from examination of the informative goals (McKeown et al. 1985). Comprehensibility requires answering the question: given the concepts which have been used in the dialogue so far, and/or which the explainer has evidence the interlocutor is familiar with, what other concepts are also likely to be familiar? This suggests a strengthof-association mechanism (McCoy 1989), which we comment on further in the next section. As Hovy (1990) points out, top-down planning is prescriptive, and does not handle conflicting goals easily. The influence of perspective on content selection involves what Hovy calls restrictive planning: some perspective goals, once generated, remain active throughout a span of discourse, and operate as preferences applied to choice points in content selection. They cannot be erased once satisfied, and they may change dynamically. Finally, McDonald &amp; Pustejovsky (1985) point out that a uniform mechanism may not be desirable, as it incorrectly implies that all information is equally available during each po</context>
</contexts>
<marker>Hovy, 1990</marker>
<rawString>Hovy, E. H. (1990). Pragmatics and natural language generation. Artificial Intelligence, vol. 43, no. 2, pp. 153-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Relational Propositions in Discourse.</title>
<date>1983</date>
<tech>ISI/RR-83-115,</tech>
<institution>Information Sciences Institute, University of Southern California, Marina del Rey,</institution>
<location>California.</location>
<contexts>
<context position="5915" citStr="Mann &amp; Thompson 1983" startWordPosition="920" endWordPosition="924">hether or not this is an optimal analysis is not the point; rather we are concerned with the role of rhetorical abstractions and various characterizations of the content planning task in accounting for the explanation.) The analysis does Rhetorical relations were an important development in explanation research, since they provided a first pass at abstractions for a general description of explanatory structure, and in bringing various roles of the parts of explanation into the foreground, pointed out phenomena in need of further study. They are also useful via their &amp;quot;relational propositions&amp;quot; (Mann &amp; Thompson 1983), for conveying propositional information implicitly in the structure of the text, hence reducing its length and redundancy. However, we claim that rhetorical abstractions fail to make the necessary distinctions for further advances in a theoretical understanding of explanation. Potpourri. Rhetorical abstractions are descriptive of explanatory tent, i.e. the end product of some expla138 nation generation process, and so describe with one device structure due to a variety of distinct knowledge sources bearing on such a process. These knowledge sources operate on different levels of information,</context>
</contexts>
<marker>Mann, Thompson, 1983</marker>
<rawString>Mann, W. C., &amp; Thompson, S. A. (1983). Relational Propositions in Discourse. ISI/RR-83-115, Information Sciences Institute, University of Southern California, Marina del Rey, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical structure theory: Description and construction of text structures;</title>
<date>1986</date>
<booktitle>Proceedings of the NATO Advanced Research Workshop on Natural Language Generation,</booktitle>
<location>Nijmegen, The Netherlands,</location>
<contexts>
<context position="2490" citStr="Mann &amp; Thompson, 1986" startWordPosition="372" endWordPosition="376">s (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this</context>
<context position="5268" citStr="Mann &amp; Thompson (1986)" startWordPosition="819" endWordPosition="822">itor carries out its function is appropriate; use of an abstract structural model of the capacitor, simplified to what is needed to support the process account; and use of a concrete situation for the enablement condition of the process. Problems with Rhetorical Abstractions El: then positive charge builds up on one plate and negative charge on the other, E8: until the voltage across the capacitor is equal to the voltage of the battery. E9: The charge stays there when you disconnect the battery. One possible rhetorical analysis of the first explanation, using relations from McKeown (1985) and Mann &amp; Thompson (1986), is given in Figure 1. (Whether or not this is an optimal analysis is not the point; rather we are concerned with the role of rhetorical abstractions and various characterizations of the content planning task in accounting for the explanation.) The analysis does Rhetorical relations were an important development in explanation research, since they provided a first pass at abstractions for a general description of explanatory structure, and in bringing various roles of the parts of explanation into the foreground, pointed out phenomena in need of further study. They are also useful via their &amp;quot;</context>
<context position="6664" citStr="Mann &amp; Thompson, 1986" startWordPosition="1036" endWordPosition="1039">wever, we claim that rhetorical abstractions fail to make the necessary distinctions for further advances in a theoretical understanding of explanation. Potpourri. Rhetorical abstractions are descriptive of explanatory tent, i.e. the end product of some expla138 nation generation process, and so describe with one device structure due to a variety of distinct knowledge sources bearing on such a process. These knowledge sources operate on different levels of information, and hence need to be separated in a theory of explanation generation. For example, (drawing on relations in McKeown, 1985 and Mann &amp; Thompson, 1986) some correspond directly to the fundamental structure of domain objects and processes (e.g. Constituency and Causality), while others are about derived relations between concepts which may vary according to the context (e.g. Comparison). Relations such as Amplification, Background, Evidence, and Illustration are primarily about relationships between propositions which arise in part out of consideration of what the interlocutor knows and needs to know to better grasp a point. Illocutionary acts are involved in the relations as well (most blatantly, Concession; others are not themselves illocut</context>
</contexts>
<marker>Mann, Thompson, 1986</marker>
<rawString>Mann, W. C., &amp; Thompson, S. A. (1986). Rhetorical structure theory: Description and construction of text structures; Proceedings of the NATO Advanced Research Workshop on Natural Language Generation, Nijmegen, The Netherlands, August 19-23, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Maybury</author>
</authors>
<title>Explanation rhetoric: The rhetorical progression of justifications.</title>
<date>1988</date>
<booktitle>Proc. AAAI-88 Workshop on Explanation, St. Paul,</booktitle>
<pages>16--20</pages>
<contexts>
<context position="2505" citStr="Maybury, 1988" startWordPosition="377" endWordPosition="378">&amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to pr</context>
</contexts>
<marker>Maybury, 1988</marker>
<rawString>Maybury, M. (1988). Explanation rhetoric: The rhetorical progression of justifications. Proc. AAAI-88 Workshop on Explanation, St. Paul, August 22, 1988, pp. 16-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K F McCoy</author>
</authors>
<title>Generating context-sensitive responses to object-related misconceptions.</title>
<date>1989</date>
<journal>Artificial Intelligence,</journal>
<volume>41</volume>
<pages>157--195</pages>
<contexts>
<context position="2277" citStr="McCoy, 1989" startWordPosition="340" endWordPosition="341">the term perspective to refer to an abstract characterization of the kind of knowledge provided by a class of models. Our notion of perspective is a composite of distinctions made by Falkenhainer &amp; Forbus (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory conten</context>
<context position="16206" citStr="McCoy 1989" startWordPosition="2537" endWordPosition="2538">ual mechanism by which it influences content selection are modeled appropriately by topdown expansion. Choice of perspective tries to balance the (sometimes conflicting) constraints of adequacy and comprehensibility. Adequacy constraints come from examination of the informative goals (McKeown et al. 1985). Comprehensibility requires answering the question: given the concepts which have been used in the dialogue so far, and/or which the explainer has evidence the interlocutor is familiar with, what other concepts are also likely to be familiar? This suggests a strengthof-association mechanism (McCoy 1989), which we comment on further in the next section. As Hovy (1990) points out, top-down planning is prescriptive, and does not handle conflicting goals easily. The influence of perspective on content selection involves what Hovy calls restrictive planning: some perspective goals, once generated, remain active throughout a span of discourse, and operate as preferences applied to choice points in content selection. They cannot be erased once satisfied, and they may change dynamically. Finally, McDonald &amp; Pustejovsky (1985) point out that a uniform mechanism may not be desirable, as it incorrectly</context>
<context position="18793" citStr="McCoy (1989)" startWordPosition="2932" endWordPosition="2933">onships between the different tasks. The process is reminiscent of case-based design, where one identifies and refines design specifications, and retrieves and reconfigures a previous solution to fit the circumstances. An explainer must first identify at least some of its goals. These are of two types, as discussed above: prescriptive informative goals, and restrictive goals such as comprehensibility. We mentioned that the latter suggests a concept association mechanism. This could be done by activating weighted links between concepts, or though intermediate frames of attribute weights, as in McCoy (1989). However, one would have to install a potentially combinatorial number of associations between concepts. Because we wish to make an epistemological theory explicit and implement it with an abstract interface to the knowledge base, we are investigating use of a mechanism akin to prototype induction, to generate an abstract description of the desired perspective from the user model and dialogue history. At the view granularity, content selection may be seen as refinement of explanatory goals into a specification of the appropriate addition to the relevant knowledge pool. This refinement include</context>
</contexts>
<marker>McCoy, 1989</marker>
<rawString>McCoy, K. F. (1989). Generating context-sensitive responses to object-related misconceptions. Artificial Intelligence, vol. 41, no. 2, pp. 157-195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D McDonald</author>
<author>J D Pustejovsky</author>
</authors>
<title>Description-directed natural language generation.</title>
<date>1985</date>
<booktitle>Proc. 9th Int. Joint Conf. on Artificial Intelligence,</booktitle>
<pages>799--805</pages>
<location>Los Angeles,</location>
<contexts>
<context position="16731" citStr="McDonald &amp; Pustejovsky (1985)" startWordPosition="2615" endWordPosition="2618">r concepts are also likely to be familiar? This suggests a strengthof-association mechanism (McCoy 1989), which we comment on further in the next section. As Hovy (1990) points out, top-down planning is prescriptive, and does not handle conflicting goals easily. The influence of perspective on content selection involves what Hovy calls restrictive planning: some perspective goals, once generated, remain active throughout a span of discourse, and operate as preferences applied to choice points in content selection. They cannot be erased once satisfied, and they may change dynamically. Finally, McDonald &amp; Pustejovsky (1985) point out that a uniform mechanism may not be desirable, as it incorrectly implies that all information is equally available during each point of the text planning process. A principled match of distinct computational mechanisms to each subtask of the 1 4 0 (Query) --&gt; Identify V Refine V Retrieve V Modify 1 V Order --&gt; (Realize) Figure 2: Content planning tasks explanation planning task is one way to express one&apos;s theory of what kind of process explanation is. For these reasons, we postulate a separate level of planning for coordinating perspective decisions. A Mixed Architecture. In our cur</context>
</contexts>
<marker>McDonald, Pustejovsky, 1985</marker>
<rawString>McDonald, D. D. &amp; Pustejovsky, J. D. (1985). Description-directed natural language generation. Proc. 9th Int. Joint Conf. on Artificial Intelligence, Los Angeles, August 18-23, 1985, pp. 799-805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
</authors>
<title>Discourse strategies for generating natural language text.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<volume>27</volume>
<pages>1--41</pages>
<contexts>
<context position="2520" citStr="McKeown, 1985" startWordPosition="379" endWordPosition="380">) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to present our perce</context>
<context position="5241" citStr="McKeown (1985)" startWordPosition="816" endWordPosition="817">nt of how the capacitor carries out its function is appropriate; use of an abstract structural model of the capacitor, simplified to what is needed to support the process account; and use of a concrete situation for the enablement condition of the process. Problems with Rhetorical Abstractions El: then positive charge builds up on one plate and negative charge on the other, E8: until the voltage across the capacitor is equal to the voltage of the battery. E9: The charge stays there when you disconnect the battery. One possible rhetorical analysis of the first explanation, using relations from McKeown (1985) and Mann &amp; Thompson (1986), is given in Figure 1. (Whether or not this is an optimal analysis is not the point; rather we are concerned with the role of rhetorical abstractions and various characterizations of the content planning task in accounting for the explanation.) The analysis does Rhetorical relations were an important development in explanation research, since they provided a first pass at abstractions for a general description of explanatory structure, and in bringing various roles of the parts of explanation into the foreground, pointed out phenomena in need of further study. They </context>
<context position="6637" citStr="McKeown, 1985" startWordPosition="1032" endWordPosition="1034">and redundancy. However, we claim that rhetorical abstractions fail to make the necessary distinctions for further advances in a theoretical understanding of explanation. Potpourri. Rhetorical abstractions are descriptive of explanatory tent, i.e. the end product of some expla138 nation generation process, and so describe with one device structure due to a variety of distinct knowledge sources bearing on such a process. These knowledge sources operate on different levels of information, and hence need to be separated in a theory of explanation generation. For example, (drawing on relations in McKeown, 1985 and Mann &amp; Thompson, 1986) some correspond directly to the fundamental structure of domain objects and processes (e.g. Constituency and Causality), while others are about derived relations between concepts which may vary according to the context (e.g. Comparison). Relations such as Amplification, Background, Evidence, and Illustration are primarily about relationships between propositions which arise in part out of consideration of what the interlocutor knows and needs to know to better grasp a point. Illocutionary acts are involved in the relations as well (most blatantly, Concession; others</context>
<context position="11286" citStr="McKeown, 1985" startWordPosition="1761" endWordPosition="1762">cture of the activity of explaining. Roles of Computational Mechanisms In this section we illustrate how inclusion of background material and the use of multiple perspectives pose problems for various mechanisms in the literature, and suggest a mixed architecture solution. Structure Matching. By &amp;quot;structure matching&amp;quot; we mean methods where abstract descriptions of the structure of explanations are matched to a collection of propositions (or other content to be expressed) in order to organize this material. This includes bottom-up composition of structural units (Ilovy, 1988) and schema filling (McKeown, 1985). We question their adequacy for accounting for the prerequisite structure of explanations, such as the Background relation of the example. In our view, the explanation is organized this way 139 because the explainer recognized in his process model (expressed in E5-E9) concepts the interlocutor may not be familiar with (the parts of a capacitor), and then added material prerequisite to understanding the process explanation (the structural description expressed in E1-E4). The background material is not automatically part of the relevant knowledge pool for this question, and structure matching m</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>McKeown, K. R. (1985). Discourse strategies for generating natural language text. Artificial Intelligence, vol. 27, no. 1, pp. 1-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K It McKeown</author>
<author>M Wish</author>
<author>St Matthews</author>
<author>K</author>
</authors>
<title>Tailoring explanations for the user.</title>
<date>1985</date>
<booktitle>Proc. 9th Int. Joint Conf. on Artificial Intelligence,</booktitle>
<pages>794--798</pages>
<location>Los Angeles,</location>
<contexts>
<context position="2301" citStr="McKeown et al. 1985" startWordPosition="343" endWordPosition="346">tive to refer to an abstract characterization of the kind of knowledge provided by a class of models. Our notion of perspective is a composite of distinctions made by Falkenhainer &amp; Forbus (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspect</context>
<context position="15901" citStr="McKeown et al. 1985" startWordPosition="2489" endWordPosition="2492">or which background is required. With regards to perspective, some problems emerge. Content selection in top-down expansion can be influenced by the current perspective if some mechanism for sharing perspective decisions across the expansion tree is provided. However, neither the choice of perspective nor the actual mechanism by which it influences content selection are modeled appropriately by topdown expansion. Choice of perspective tries to balance the (sometimes conflicting) constraints of adequacy and comprehensibility. Adequacy constraints come from examination of the informative goals (McKeown et al. 1985). Comprehensibility requires answering the question: given the concepts which have been used in the dialogue so far, and/or which the explainer has evidence the interlocutor is familiar with, what other concepts are also likely to be familiar? This suggests a strengthof-association mechanism (McCoy 1989), which we comment on further in the next section. As Hovy (1990) points out, top-down planning is prescriptive, and does not handle conflicting goals easily. The influence of perspective on content selection involves what Hovy calls restrictive planning: some perspective goals, once generated,</context>
</contexts>
<marker>McKeown, Wish, Matthews, K, 1985</marker>
<rawString>McKeown, K. It., Wish, M., St Matthews, K. (1985). Tailoring explanations for the user. Proc. 9th Int. Joint Conf. on Artificial Intelligence, Los Angeles, August 18-23, 1985, pp. 794-798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
</authors>
<title>A Reactive Approach to Explanation in Expert and Advice-giving Systems.</title>
<date>1989</date>
<publisher>Ph.D.</publisher>
<contexts>
<context position="2534" citStr="Moore, 1989" startWordPosition="381" endWordPosition="382">inberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to present our perception of the r</context>
<context position="13603" citStr="Moore, 1989" startWordPosition="2124" endWordPosition="2125">n object are introduced in relation to containing or adjacent parts, and process descriptions organized to follow temporal and causal relations in the forward direction. However, graph traversal is limited to modeling local organization, or global organization which is a composite of local choices. Traversal methods don&apos;t naturally extend to global organization which occurs at a higher level of abstraction than the links followed, e.g. the presentation of a coherent structural model before a process account begins. Top-Down Goal Expansion. Top-down expansion of a discourse goal (Cawsey, 1989; Moore, 1989) is a stronger candidate for a uniform mechanism for explanation, integrating content selection and structuring. The background problem can be handled with preconditions on plan operators, as Cawsey does. It simplifies modeling explanations such as our example if one can specify the kind of background knowledge required in preconditions at the highest level of plan operators. To illustrate, consider a rhetorical plan operator which contains an optional satellite for Background but does not specify what constitutes background knowledge. Expansion of the satellite would have to be predicated on </context>
</contexts>
<marker>Moore, 1989</marker>
<rawString>Moore, J. D. (1989). A Reactive Approach to Explanation in Expert and Advice-giving Systems. Ph.D.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nirenburg</author>
<author>V Lesser</author>
<author>E Nyberg</author>
</authors>
<title>Controlling a language generation planner.</title>
<date>1989</date>
<booktitle>Proc. 11th Int. Joint Conf. on Artificial Intelligence,</booktitle>
<pages>1524--1530</pages>
<location>Detroit,</location>
<marker>Nirenburg, Lesser, Nyberg, 1989</marker>
<rawString>Nirenburg, S., Lesser, V., &amp; Nyberg, E. (1989). Controlling a language generation planner. Proc. 11th Int. Joint Conf. on Artificial Intelligence, Detroit, pp. 1524-1530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Paris</author>
</authors>
<title>Combining discourse strategies to generate descriptions to users along a Naive/Expert spectrum.</title>
<date>1987</date>
<booktitle>Proc. 10th Int. Joint Conf. on Artificial Intelligence,</booktitle>
<pages>626--632</pages>
<location>Milan, Italy,</location>
<contexts>
<context position="9802" citStr="Paris, 1987" startWordPosition="1537" endWordPosition="1538">marily a function of choice and organization of knowledge. Hence, to account for how these choices further knowledge communication goals, one must examine explanation in part from an epistemological standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of d</context>
</contexts>
<marker>Paris, 1987</marker>
<rawString>Paris, C. L. (1987). Combining discourse strategies to generate descriptions to users along a Naive/Expert spectrum. Proc. 10th Int. Joint Conf. on Artificial Intelligence, August 1987, Milan, Italy, pp. 626-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Paris</author>
<author>K R McKeown</author>
</authors>
<title>Discourse strategies for describing complex physical objects;</title>
<date>1986</date>
<booktitle>Proceedings of the NATO Advanced Research Workshop on Natural Language Generation,</booktitle>
<location>Nijmegen, The Netherlands,</location>
<contexts>
<context position="2771" citStr="Paris &amp; McKeown 1986" startWordPosition="415" endWordPosition="418">ms, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989). A variety of mechanisms for selecting and organizing the content of explanations have also been explored. This includes schema filling (McKeown 1985) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to present our perception of the roles and limitations of these items, and suggest some alternatives. (We do not emphasize our work on perspective and content organization here: see Suthers &amp; Woolf, 1990.) We begin with an example, used to illustrate some of the problems</context>
<context position="12694" citStr="Paris &amp; McKeown 1986" startWordPosition="1979" endWordPosition="1982">ound by virtue of relationships between the interlocutor&apos;s assumed knowledge state and the conceptualizations contained in the first attempt at a knowledge pool. Pattern matching techniques which are ignorant of such relationships and see only the composite pool would be unable to identify the part of the knowledge pool which plays the role of &amp;quot;background&amp;quot;, and account for placement of background before primary material. Graph Traversal. These are algorithms for selectively following links in a knowledge base, with the path so traced out providing the content and structure of the explanation (Paris &amp; McKeown 1986). Such methods model how an explanation exploits the structure of knowledge. They implicitly embody the heuristic that it will be easier for the interlocutor to reconstruct the knowledge if it is presented such that each unit is introduced in relation to the previous unit. For example, parts of an object are introduced in relation to containing or adjacent parts, and process descriptions organized to follow temporal and causal relations in the forward direction. However, graph traversal is limited to modeling local organization, or global organization which is a composite of local choices. Tra</context>
</contexts>
<marker>Paris, McKeown, 1986</marker>
<rawString>Paris, C. L. &amp; McKeown, K. R. (1986). Discourse strategies for describing complex physical objects; Proceedings of the NATO Advanced Research Workshop on Natural Language Generation, Nijmegen, The Netherlands, August 19-23, 1986. Also published by Martinus Nijhoff, Dordrecht, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E L Rissland</author>
</authors>
<date>1978</date>
<journal>(Formerly Michener.) Understanding Understanding Mathematics. Cognitive Science,</journal>
<volume>2</volume>
<contexts>
<context position="9561" citStr="Rissland, 1978" startWordPosition="1499" endWordPosition="1500">y identify relationships E9 has to the rest of the text, e.g. that it is a Conclusion. This does not illuminate the relationship between its content and the goal of the explanation. Epistemological Analysis. The success of an explanation is primarily a function of choice and organization of knowledge. Hence, to account for how these choices further knowledge communication goals, one must examine explanation in part from an epistemological standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather th</context>
</contexts>
<marker>Rissland, 1978</marker>
<rawString>Rissland, E. L. (1978). (Formerly Michener.) Understanding Understanding Mathematics. Cognitive Science, vol. 2, no. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Acker Souther</author>
<author>L Lester</author>
<author>J</author>
<author>B Porter</author>
</authors>
<title>Using view types to generate explanations in intelligent tutoring systems.</title>
<date>1989</date>
<booktitle>Proc. Cognitive Science Conf.,</booktitle>
<location>Montreal,</location>
<marker>Souther, Lester, J, Porter, 1989</marker>
<rawString>Souther, A. Acker, L., Lester, J., &amp; Porter, B. (1989). Using view types to generate explanations in intelligent tutoring systems. Proc. Cognitive Science Conf., Montreal, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Stevens</author>
<author>A Collins</author>
</authors>
<title>Multiple conceptual models of a complex system. In</title>
<date>1980</date>
<journal>Montague (Eds.), Aptitude, Learning, and Instruction</journal>
<volume>2</volume>
<pages>177--197</pages>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ:</location>
<contexts>
<context position="1908" citStr="Stevens &amp; Collins (1980)" startWordPosition="284" endWordPosition="287">e of general statements vs. concrete examples; and in general on what concepts function as primitives, providing the basis for understanding the topic phenomenon. Selection of an appropriate model of the topic is an important aspect of content selection which impacts on the interlocutor&apos;s comprehension of the explanation and on its appropriateness for his or her purposes. We use the term perspective to refer to an abstract characterization of the kind of knowledge provided by a class of models. Our notion of perspective is a composite of distinctions made by Falkenhainer &amp; Forbus (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; M</context>
</contexts>
<marker>Stevens, Collins, 1980</marker>
<rawString>Stevens, A. L. &amp; Collins, A. (1980). Multiple conceptual models of a complex system. In R. E. Snow, P. Federico, and W. E. Montague (Eds.), Aptitude, Learning, and Instruction (Vol. 2). Hillsdale, NJ: Erlbaum, 1980. pp. 177-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Stevens</author>
<author>C Steinberg</author>
</authors>
<title>A typology of explanations and its application to intelligent computer aided instruction.</title>
<date>1981</date>
<tech>Report No. 4626,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="1935" citStr="Stevens &amp; Steinberg (1981)" startWordPosition="288" endWordPosition="291">s. concrete examples; and in general on what concepts function as primitives, providing the basis for understanding the topic phenomenon. Selection of an appropriate model of the topic is an important aspect of content selection which impacts on the interlocutor&apos;s comprehension of the explanation and on its appropriateness for his or her purposes. We use the term perspective to refer to an abstract characterization of the kind of knowledge provided by a class of models. Our notion of perspective is a composite of distinctions made by Falkenhainer &amp; Forbus (submitted), Stevens &amp; Collins (1980) Stevens &amp; Steinberg (1981) and White &amp; Frederiksen (1989). Copyright @ 1990, Daniel D. Suthers Permission granted to copy for non-profit academic purposes. Most existing work in explanation and text planning has been directed at other problems, and hence has utilized single-perspective knowledge bases to simplify the research. (Notable exceptions include McCoy, 1989 and McKeown et al. 1985.) A number of such research efforts emphasize rhetorical abstractions for the analysis of natural explanations and for expressing a theory of explanation (Hovy, 1988; Mann &amp; Thompson, 1986; Maybury, 1988; McKeown, 1985; Moore, 1989).</context>
</contexts>
<marker>Stevens, Steinberg, 1981</marker>
<rawString>Stevens, A. L. &amp; Steinberg, C. (1981). A typology of explanations and its application to intelligent computer aided instruction. Report No. 4626, Bolt Beranek and Newman Inc., Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Suthers</author>
</authors>
<title>Providing multiple views of reasoning for explanation.</title>
<date>1988</date>
<booktitle>Proc. Int. Conf. on Intelligent Tutoring Systems,</booktitle>
<pages>435--442</pages>
<location>Montreal,</location>
<contexts>
<context position="19946" citStr="Suthers 1988" startWordPosition="3111" endWordPosition="3112">ion to the relevant knowledge pool. This refinement includes consideration of what type of knowledge, in principle, could fulfill the informative goal; of the concepts the interlocutor is likely to understand; and of the models which have already been shared in the dialogue. We are attempting to treat this refinement task as top-down planning, though our work has not progressed far enough to comment further on this. Retrieval requires a knowledge-base specific mechanism: its only theoretical importance to us is that it correctly operationalize the dimensions used to describe the desired view (Suthers 1988a,b). We are examining a variant of compositional modeling (Falkenhainer &amp; Forbus, submitted) for this purpose. Once a knowledge pool is available, some data driven activities occur at a finer granularity, resulting in modification of the relevant knowledge pool. This includes filtering activities, such as removing particular propositions likely to be familiar to the interlocutor; and augmenting activities, such as illustrating abstract statements with examples. These are opportunistic planning tasks, that can be approached with critics which match to the knowledge pool and user model, and spe</context>
</contexts>
<marker>Suthers, 1988</marker>
<rawString>Suthers, D. D. (1988a). Providing multiple views of reasoning for explanation. Proc. Int. Conf. on Intelligent Tutoring Systems, Montreal, June 1988, pp. 435-442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Suthers</author>
</authors>
<title>Providing multiple views for explanation.</title>
<date>1988</date>
<booktitle>Proc. AAAI-88 Workshop on Explanation, St. Paul,</booktitle>
<pages>12--15</pages>
<contexts>
<context position="19946" citStr="Suthers 1988" startWordPosition="3111" endWordPosition="3112">ion to the relevant knowledge pool. This refinement includes consideration of what type of knowledge, in principle, could fulfill the informative goal; of the concepts the interlocutor is likely to understand; and of the models which have already been shared in the dialogue. We are attempting to treat this refinement task as top-down planning, though our work has not progressed far enough to comment further on this. Retrieval requires a knowledge-base specific mechanism: its only theoretical importance to us is that it correctly operationalize the dimensions used to describe the desired view (Suthers 1988a,b). We are examining a variant of compositional modeling (Falkenhainer &amp; Forbus, submitted) for this purpose. Once a knowledge pool is available, some data driven activities occur at a finer granularity, resulting in modification of the relevant knowledge pool. This includes filtering activities, such as removing particular propositions likely to be familiar to the interlocutor; and augmenting activities, such as illustrating abstract statements with examples. These are opportunistic planning tasks, that can be approached with critics which match to the knowledge pool and user model, and spe</context>
</contexts>
<marker>Suthers, 1988</marker>
<rawString>Suthers, D. D. (1988b). Providing multiple views for explanation. Proc. AAAI-88 Workshop on Explanation, St. Paul, August 22, 1988, pp. 12-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Suthers</author>
</authors>
<title>Perspectives in Explanation;</title>
<date>1989</date>
<tech>COINS Technical Report 89-24,</tech>
<institution>Computer and Information Science, University of Massachusetts,</institution>
<location>Amherst.</location>
<contexts>
<context position="9996" citStr="Suthers (1989)" startWordPosition="1568" endWordPosition="1569">ogical standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of discussing each topic; and through implicit conflation of epistemological constraints on organization of the explanation with those of rhetorical and linguistic origin. A major goal of our resear</context>
</contexts>
<marker>Suthers, 1989</marker>
<rawString>Suthers, D. D. (1989). Perspectives in Explanation; COINS Technical Report 89-24, Computer and Information Science, University of Massachusetts, Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Suthers</author>
<author>B P Woolf</author>
</authors>
<title>Accounting for the Epistemological Structure of Explanation. Spring Symposium on Knowledge Based Environments for Learning and Teaching,</title>
<date>1990</date>
<tech>Technical Report 90-36,</tech>
<institution>Computer and Information Science, University of Massachusetts,</institution>
<location>Amherst.</location>
<contexts>
<context position="3303" citStr="Suthers &amp; Woolf, 1990" startWordPosition="495" endWordPosition="498">85) and structure matching (Hovy 1988), graph traversal algorithms (Paris &amp; McKeown 1986), and top-down expansion planning (Cawsey, 1989; Moore, 1989). Our own work on choosing explanatory content from multiple-perspective knowledge bases has uncovered some limitations of rhetorical abstractions, and led us to question previous applications of the computational mechanisms listed above. The purpose of this paper is to present our perception of the roles and limitations of these items, and suggest some alternatives. (We do not emphasize our work on perspective and content organization here: see Suthers &amp; Woolf, 1990.) We begin with an example, used to illustrate some of the problems. An Example The following example explanation will be used to illustrate our points. The domain is elementary electricity. We emphasize the communication of an understanding of concepts such as &amp;quot;charge&amp;quot;, &amp;quot;current&amp;quot;, and &amp;quot;capacitance&amp;quot; within the context of qualitative reasoning about the behavior of simple circuits and their components. The explanation is an edited version of a human protocol. Ql: How does a capacitor store charge? El: A capacitor E2: can be thought of as two flat metallic plates 137 IAir Background lAirConstit</context>
<context position="10622" citStr="Suthers &amp; Woolf, 1990" startWordPosition="1660" endWordPosition="1663">st previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of discussing each topic; and through implicit conflation of epistemological constraints on organization of the explanation with those of rhetorical and linguistic origin. A major goal of our research (Suthers &amp; Woolf, 1990) is an explicit theory of the epistemological structure of the activity of explaining. Roles of Computational Mechanisms In this section we illustrate how inclusion of background material and the use of multiple perspectives pose problems for various mechanisms in the literature, and suggest a mixed architecture solution. Structure Matching. By &amp;quot;structure matching&amp;quot; we mean methods where abstract descriptions of the structure of explanations are matched to a collection of propositions (or other content to be expressed) in order to organize this material. This includes bottom-up composition of s</context>
</contexts>
<marker>Suthers, Woolf, 1990</marker>
<rawString>Suthers, D. D., &amp; Woolf, B. P. (1990). Accounting for the Epistemological Structure of Explanation. Spring Symposium on Knowledge Based Environments for Learning and Teaching, March 27-29, Stanford. Available as COINS Technical Report 90-36, Computer and Information Science, University of Massachusetts, Amherst.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K vanLehn</author>
</authors>
<title>Learning one subprocedure per lesson.</title>
<date>1987</date>
<journal>Artificial Intelligence,</journal>
<volume>31</volume>
<pages>1--40</pages>
<contexts>
<context position="9964" citStr="vanLehn, 1987" startWordPosition="1562" endWordPosition="1564">nation in part from an epistemological standpoint. Such an analysis examines how explanations are guided by: • the types of knowledge in a given domain, and its logical and etiological structure (Rissland, 1978); • the types of knowledge which, in principle, could fulfill a given request for information; • the role of an individual&apos;s knowledge in understanding new concepts and situations, and hence in understanding a given explanation (Paris, 1987); and • the ways in which individuals are willing or able to undertake conceptual change (Goldstein, 1979; Hewson, 1981; White &amp; Frederiksen, 1989; vanLehn, 1987). As discussed in Suthers (1989), most previous work has offered solutions to the subproblems of explanation in the form of mechanisms and data structures which are in part the result of, rather than the expression of, epistemological considerations. Epistemological problems have been avoided through direct selection of content based on well-formulated queries; the simplicity of the knowledge bases used, which only permit one way of discussing each topic; and through implicit conflation of epistemological constraints on organization of the explanation with those of rhetorical and linguistic or</context>
</contexts>
<marker>vanLehn, 1987</marker>
<rawString>vanLehn, K. (1987). Learning one subprocedure per lesson. Artificial Intelligence, vol. 31, no. 1, pp. 1-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Y White</author>
<author>J R Frederiksen</author>
</authors>
<title>Causal Model Progressions as a Foundation for Intelligent Learning Environments.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<volume>42</volume>
<pages>99--157</pages>
<marker>White, Frederiksen, 1990</marker>
<rawString>White, B. Y. &amp; Frederiksen, J. R. (1990). Causal Model Progressions as a Foundation for Intelligent Learning Environments. Artificial Intelligence, vol. 42, no. 1, pp. 99-157.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>