<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.940986">
Japanese Morphological Analyzer using Word Co-occurrence
JTAG
</title>
<author confidence="0.400639">
Takeshi FUCHI
</author>
<affiliation confidence="0.193939">
NTT Information and Communication
</affiliation>
<address confidence="0.353631">
Systems Laboratories
Hilcari-no-oka 1-1
Yokosuka 239-0847, Japan,
</address>
<email confidence="0.928407">
fuchi@isl.ntt.co.jp
</email>
<note confidence="0.813114">
Shinichiro TAKAGI
</note>
<sectionHeader confidence="0.553508" genericHeader="abstract">
NTT Information and Communication Systems
Laboratories
</sectionHeader>
<address confidence="0.4444375">
Hikari-no-oka 1-1
Yokosuka 239-0847, Japan,
</address>
<email confidence="0.901247">
takagi@nttnly.isl.ntt.co.jp
</email>
<sectionHeader confidence="0.993093" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.9998678">
We developed a Japanese morphological
analyzer that uses the co-occurrence of
words to select the correct sequence of
words in an unsegmented Japanese sentence.
The co-occurrence information can be
obtained from cases where the system
incorrectly analyzes sentences. As the
amount of information increases, the
accuracy of the system increases with a
small risk of degradation. Experimental
results show that the proposed system
assigns the correct phonological
representations to unsegmented Japanese
sentences more precisely than do other
popular systems.
</bodyText>
<sectionHeader confidence="0.960898" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999367142857143">
In natural language processing for Japanese text,
morphological analysis is very important.
Currently, there are two main methods for
automatic part-of-speech tagging, namely, corpus-
based and rule-based methods. The corpus-based
method is popular for European languages.
Samuelsson and Voutilainen (1997), however,
show significantly higher achievement of a rule-
based tagger than that of statistical taggers for
English text. On the other hand, most Japanese
taggers&apos; are rule-based. In previous Japanese
taggers, it was difficult to increase the accuracy of
the analysis. Takeuchi and Matsumoto (1995)
combined a rule-based and a corpus-based method,
</bodyText>
<sectionHeader confidence="0.274981" genericHeader="method">
1 In this paper, a tagger is identical to a
morphological analyzer.
</sectionHeader>
<bodyText confidence="0.999950461538462">
resulting in a marginal increase in the accuracy of
their taggers. However, this increase is still
insufficient. The source of the trouble is the
difficulty in adjusting the grammar and parameters.
Our tagger is also rule-based. By using the co-
occurrence of words, it reduces the difficulty and
generates a continuous increase in its accuracy.
The proposed system analyzes unsegmented
Japanese sentences and segments them into words.
Each word has a part-of-speech and phonological
representation. Our tagger has the co-occurrence
information of words in its dictionary. The
information can be adjusted concretely by hand in
each case of incorrect analysis. Concrete
adjustment is different from detailed adjustment. It
must be easy to understand for people who make
adjustments to the system. The effect of one
adjustment is concrete but small. Therefore, much
manual work is needed. However, the work is so
simple and easy.
Section 1 shows the drawbacks to previous
systems. Section 2 describes the outline of the
proposed system. In Section 3, the accuracy of the
system is compared with that of others. In addition,
we show the change in the accuracy while the
system is being adjusted.
</bodyText>
<sectionHeader confidence="0.9650015" genericHeader="method">
1 Previous Japanese Morphological
Analyzers
</sectionHeader>
<bodyText confidence="0.9949774">
Most Japanese morphological analyzers use
linguistic grammar, generate possible sequences of
words from an input string, and select a sequence.
The following are methods for selecting the
sequence:
</bodyText>
<listItem confidence="0.995231">
• Choose the sequence that has a longer word on
the right-hand side. (right longest match
principle)
</listItem>
<page confidence="0.957782">
409
</page>
<listItem confidence="0.9979916">
• Choose the sequence that has a longer word on
the left-hand side. (left longest match
principle)
• Choose the sequence that has the least number
of phrases. (least number of phrases
principle)
• Choose the sequence that has the least
connective-cost of words. (least connective-
cost principle)
• Use pattern matching of words and/or parts-of-
speech to specify the priority of sequences.
• Choose the sequence that contains modifiers
and modifiees.
• Choose the sequence that contains words used
frequently.
</listItem>
<bodyText confidence="0.998126404761905">
In practice, combinations of the above methods
are used.
Using these methods, many Japanese
morphological analyzers have been created.
However, the accuracy cannot increase
continuously in spite of careful manual
adjustments and statistical adjustments. The cause
of incorrect analyses is not only unregistered
words, in fact, many sentences are analyzed
incorrectly even though there is a sufficient
vocabulary for the sentences in their dictionaries.
In this case, the system generates a correct
sequence but does not select it. Parameters such as
the priorities of words and connective-costs
between parts-of-speech, can be adjusted so that
the correct sequence is selected. However, this
adjustment often causes incorrect side effects and
the system analyzes other sentences incorrectly
that have already been analyzed correctly. This
phenomenon is called &apos;degrading&apos;.
In addition to parameter adjustment, parts-of-
speech may need to be expanded. Both operations
are almost impossible to complete by people who
are not very familiar with the system. If the
system uses a complex algorithm to select a
sequence of words, even the system developer can
hardly grasp the behaviour of the system.
These operations begin to become more than
what a few experts can handle because
vocabularies in the systems are big. Even to add
an unregistered word to a dictionary, operators
must have good knowledge of parts-of-speech, the
priorities of words, and word classification for
modifiers and modifiees. In this situation, it is
difficult to increase the number of operators. This
is situation with previous analyzers.
Unfortunately, current statistical taggers cannot
avoid this situation. The tuning of the systems is
very subtle. It is hard to predict the effect of
parameter tuning of the systems. To avoid this
situation, our tagger uses the co-occurrence of
words whose effect is easy to understand.
</bodyText>
<sectionHeader confidence="0.499989" genericHeader="method">
2 Overview of our system
</sectionHeader>
<bodyText confidence="0.9980752">
We developed the Japanese morphological
analyzer, JTAG, paying attention to simple
algorithm, straightforward adjustment, and
flexible grammar.
The features of JTAG are the followings.
</bodyText>
<listItem confidence="0.986407">
• An attribute value is an atom.
</listItem>
<bodyText confidence="0.986873">
In our system, each word has several attribute
values. An attribute value is limited so as not to
have structure. Giving an attribute value to words
is equivalent to naming the words as a group.
</bodyText>
<listItem confidence="0.990389">
• New attribute values can be introduced easily.
</listItem>
<bodyText confidence="0.99008425">
An attribute value is a simple character string.
When a new attribute value is required, the user
writes a new string in the attribute field of a record
in a dictionary.
</bodyText>
<listItem confidence="0.999158666666667">
• The number of attribute values is unlimited.
• A part-of-speech is a kind of attribute value.
• Grammar is a set of connection rules.
</listItem>
<bodyText confidence="0.998057454545455">
Grammar is implemented with connection rules
between attribute values. List 1 is an example2.
One connection rule is written in one line. The
fields are separated by commas. Attribute values
of a word on the left are written in the first field.
Attribute values of a word on the right are written
in the second field. In the last field, the cost3 of the
rule is written. Attribute values are separated by
colons. A minus sign `-&apos; means negation.
For example, the first rule shows that a word
with &apos;Noun&apos; can be followed by a word with
</bodyText>
<table confidence="0.8669875">
Noun, Case:ConVerb, 50
Noun:Name, Posffix:Noun, 100
Noun:-Name, Postfix:Noun, 90
Copula:de, VerbStem:Lde, 50
</table>
<tableCaption confidence="0.410999">
List 1: Connection rules.
</tableCaption>
<footnote confidence="0.9388754">
2 Actual rules use Japanese characters.
3 The cost figures were intuitively determined. The
grammar is used mainly to generate possible sequences
of words, so the determination of the cost figures was
not very subtle. The precise selection of the correct
</footnote>
<page confidence="0.982593">
410
</page>
<table confidence="0.999360416666667">
JTAG JUMAN CHASEN
Vocabulary 350K 710K 115K
Standard Words 11809 9830 9901
Output Words 11855 9864 9948
Segmentation 98.9% I 99.3% 98.9% I 99.3% 98.5% I 98.9%
Segmentation &amp; 98.8% I 99.2% 98.3% I 98.7% 97.6% I 98.1%
Part-of-Speech
Segmentation &amp; 98.8% I 99.2% 98.2% I 98.6% 97.5% I 97.9%
Phoneme
Segmentation &amp; 98.7% 199.1% 98.0% 198.3% 97.1% 197.6%
Phoneme &amp;
Part-of-Speech
</table>
<tableCaption confidence="0.999018">
Table Accuracy per word (precision 1recall)
</tableCaption>
<bodyText confidence="0.986939">
&apos;Case&apos; and &apos;ConVerb&apos;. The cost of the rule is 50.
The second rule shows that a word with &apos;Noun&apos;
and &apos;Name&apos; can be followed by a word with
&apos;Postfix&apos; and &apos;Noun&apos;. The cost is 100. The third
rule shows that a word that has &apos;Noun&apos; and does
not have &apos;Name&apos; can be followed by a word with
&apos;Postfix&apos; and &apos;Noun&apos;. The cost is 90.
Only the word &amp;quot;C&amp;quot; has the combination of
&apos;Copula&apos; and &apos;de&apos;, so the fourth rule is specific to
</bodyText>
<listItem confidence="0.626217">
• The co-occurrence of words.
</listItem>
<bodyText confidence="0.999782">
In our system, the sequence of words that
includes the maximum number of co-occurrence
of words is selected. Table I shows examples of
records in a dictionary.
&apos;11&apos; means &apos;amount&apos;, &apos;frame&apos;, &apos;forehead&apos; or a
human name `Gaku&apos;. In the co-occurrence field,
words are presented directly. If there are no co-
occurrence words in a sentence that includes &apos;11&apos;,
&apos;amount&apos; is selected because its cost is the
smallest. If lik—(picture) is in the sentence,
&apos;frame&apos; is selected.
</bodyText>
<listItem confidence="0.593073">
• Selection Algorithm
</listItem>
<bodyText confidence="0.996225444444444">
JTAG selects the correct sequence of words
using connective-cost, the number of co-
occurrences, the priority of words, and the length
of words. The precise description of the algolitlun
is shown in the Appendix.
This algolitlun is too simple to analyze
Japanese sentences perfectly. However, it is
sufficient in practice.
sequence is done by the co-occurrence of words.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.9979975">
In this section, Japanese morphological
anayzers are evaluated using the following:
</bodyText>
<listItem confidence="0.999624666666667">
• Segmentation
• Part-of-speech tagging
• Phonological representation
</listItem>
<bodyText confidence="0.980668285714286">
JTAG, is compared with JUMAN4 and
CHASEN5. A single &amp;quot;correct analysis&amp;quot; is
meaningless because these taggers use different
parts-of-speech, grammars, and segmentation
policies. We checked the outputs of each and
selected the incorrect analyses that the grammar
maker of each system must not expect.
</bodyText>
<subsectionHeader confidence="0.992698">
3.1 Comparison
</subsectionHeader>
<bodyText confidence="0.99969">
To make the output of each system comparable,
we reduce them to 21 parts-of-speech and 14 verb-
inflection-types. In addition, we assume that the
part-of-speech of unrecognized words is Noun.
The segmentation policies are not unified.
Therefore, the number of words in sentences is
different from each other.
Table II shows the system accuracy. We used
500 sentences6 (19,519 characters) in the EDIU
corpus. For segmentation, the accuracy of JTAG is
</bodyText>
<figure confidence="0.70827375">
4 JUMAN Version 3.4.
http://www-nagao.kuee.kyoto-u.ac.jp/index-e.html
5 CHASEN Version 1.5.1.
http://cactus.aist-nara.ac.jp/lab/n1t/chasen.html
</figure>
<footnote confidence="0.9691552">
6 The sentences do not include Arabic numerals
because JUMAN and CHASEN do not assign
phonological representation to them.
7Japan Electronic Dictionary Research Institute.
http://www.iijnet.or.jp/ecir/
</footnote>
<page confidence="0.992682">
411
</page>
<table confidence="0.998353333333333">
JTAG JUMAN CHASEN
Conversion Ratio 88.5% 71.7% 72.3%
Processing Time 86sec 576sec 335sec
</table>
<tableCaption confidence="0.941515333333333">
Table HI: Correct phonological representation
per sentence. Average 38 characters in one
sentence. Sun Ultra-1 170Mhz.
</tableCaption>
<bodyText confidence="0.999634736842105">
the same as that of JUMAN. Table II shows that
JTAG assigns the correct phonological
representations to unsegmented Japanese
sentences more precisely than do the other
systems.
Table DI shows the ratio of sentences that are
converted to the correct phonological
representation where segmentation errors are
ignored. 80,000 sentences8 (3,038,713 characters,
no Arabic numerals) were used in the EDR corpus.
The average number of characters in one sentence
is 38. JTAG converts 88.5% of sentences correctly.
The ratio is much higher than that of the other
systems.
Table Ill also shows the processing time of
each system. JTAG analyzes Japanese text more
than do four times faster than the other taggers.
The simplicity of the JTAG selection algorithm
contributes to the fast processing speed.
</bodyText>
<subsectionHeader confidence="0.996578">
3.2 Adjustment Process
</subsectionHeader>
<bodyText confidence="0.999709466666667">
To show the adjustablity of JTAG, we tuned it
for a specific set of 10,000 sentences9. The
average number of words in a sentence is 21.
Graph 1 shows the transition of the number of
sentences converted correctly to their
phonological representation. We finished the
adjustment when the system could no longer be
tuned in the framework of JTAG. The last
accuracy rating (99.8% per sentence) shows the
maximum ability of JTAG.
The feature of each phase of the adjustment is
described below.
Phase I . In this phase, the grammar of JTAG was
changed. New attribute values were introduced
and the costs of connection rules were changed.
</bodyText>
<figureCaption confidence="0.389620125">
8 In the EDR corpus, 2.3% of sentences have errors
and 1.5% of sentences have phonological
representation inconsistencies. In this case, the
sentences are not revised.
9 311,330 characters without Arabic numerals.
Average 31 characters per sentence. In this case, we
fixed all errors of the sentences and the inconsistency
of their phonological representation.
</figureCaption>
<table confidence="0.966702857142857">
I II
. .•
orrec
975
.
IIIIIIIIIIIIIIIIPY
9555
1111111Pr_ o a 1 I
Mr&amp;quot;—
Fr/
L 111111111.11.111
111.111111111111111111.11111111111
0 50 100 150 200
Duration of Adjustment (hour)
</table>
<tableCaption confidence="0.494201">
Graph 1: Transition of the number of
sentences correctly converted to
phonological representation.
</tableCaption>
<bodyText confidence="0.996453291666667">
These adjustments caused large occurrences of
degradation in our tagger.
Phase II. The grammar was almost fixed. One of
the authors added unregistered words to the
dictionaries, changed the costs of registered words,
and supplied the information of the co-occurrence
of words. The changes in the costs of words
caused a small degree of degradation.
Phase Ill. In this phase, all unrecognized words
were registered together. The unrecognized words
were extracted automatically and checked
manually. The time taken for this phase is the
duration of the checking.
Phase N. Mainly, co-occurrence information was
supplied. This phase caused some degradation, but
these instances were very small.
Graph 1 shows that JTAG converts 91.9% of
open sentences to the correct phonological
representation, and 99.8% of closed sentences.
Without the co-occurrence information, the ratio is
97.5%. Therefore, the co-occurrence information
corrects 2.3% of the sentences. Without new
registered words, the ratio is 95.6%, so
unrecognized words caused an error in 4.2% of the
</bodyText>
<table confidence="0.978143333333333">
Sentences Errors
Unrecognized Words 4.2% 52%
Co-occurrence 2.3% 28%
Others 1.6% 20%
Total 8.1% 100%
cI
</table>
<tableCaption confidence="0.9994">
Table IV: Causes of errors.
</tableCaption>
<figure confidence="0.999232533333333">
t0000
9900
9800
9700
9600
9500
9400
9300
9200
9100
9000
onversions
urrence
onal words
justment
</figure>
<page confidence="0.995183">
412
</page>
<bodyText confidence="0.9967205">
sentences. Table IV shows the percentages of the
causes.
</bodyText>
<sectionHeader confidence="0.836422" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999970166666667">
We developed a Japanese morphological
analyzer that analyzes unsegmented Japanese
sentences more precisely than other popular
analyzers. Our system uses the co-occurrence of
words to select the correct sequence of words. The
efficiency of the co-occurrence information was
shown through experimental results. The precision
of our current tagger is 98.7% and the recall is
99.1%. The accuracy of the tagger can be
expected to increase because the risk of
degradation is small when using the co-occurrence
information.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997859510204081">
Yoshimura K, Hitaka T. and Yoshida S. (1983)
Morphological Analysis of Non-marked-off Japanese
Sentences by the Least BUNSETSU&apos; s Number
Method. Trans. IPSJ, Vol.24, No.1, pp.40-46. (in
Japanese)
Miyazaki M. and Ooyama Y. (1986) Linguistic Method
for a Japanese Text to Speech System. Trans. IPSJ,
Vol.27, No.11, pp.1053-1059. (in Japanese)
Hisamitsu T. and Nitta Y. (1990) Morphological
Analysis by Minimum Connective-Cost Method.
SIGNLC 90-8, lEICE, pp.17-24. (in Japanese)
Brill E. (1992) A simple rule-based part of speech
tagger. Procs. Of 3rd Conference on Applied Naural
Language Processing, ACL.
Maruyama M. and Ogino S. (1994) Japanese
Morphological Analysis Based on Regular Grammar.
Trans. IPSJ, Vol.35, No.7, pp.1293-1299. (in
Japanese)
Nagata M. (1994) A Stochastic Japanese
Morphological Analyzer Using a Forward-DP
Backward-A* N-Best Search Algorithm.
Computational Linguistics, COLING, pp.201-207.
Fuchi T. and Yonezawa M. (1995) A Morpheme
Grammar for Japanese Morphological Analyzers.
Journal of Natural Language Processing, The
Association for Natural Language Processing, Vo12,
No.4, pp.37-65.
Pierre C. and Tapanainen P. (1995) Tagging French —
comparing a statical and a constraint-based method.
Procs. Of 7th Conference of the European Chapter of
the ACL, ACL, pp.149-156.
Takeuchi K. and Matsumoto Y. (1995) HMM
Parameter Learning for Japanese Morphological
Analyzer. Procs. Of 10th Pacific Asia Conference
Language, Information and Computation, pp.163-
172.
Voutilainen A. (1995) A syntax-based part of speech
analyser. Procs. Of 7th Conference of the European
Chapter of the Association for Computational
Linguistics, ACL, pp.157-164.
Matsuoka K., Talceishi E. and Asano H. (1996) Natural
Language Processing in a Japanese Text-To-Speech
System for Written-style Texts. Procs. Of r IEEE
Workshop On Interactive Voice Technology For
Telecommunications Applications, IEEE, pp.33-36.
Samuelsson C. and Voutilainen A. (1997) Comparing a
Linguistic and a Stochastic Tagger. Procs. Of 35th
Annual Meeting of the Association for
Computational Linguistics, ACL.
</reference>
<sectionHeader confidence="0.721529" genericHeader="references">
Appendix
</sectionHeader>
<reference confidence="0.992504433962264">
ELEMENT selection(SET sequences)
ELEMENT selected;
int best_total_connective_cost MAX_INT;
int best_number_of_cooc -1;
int best_total_word_cost -1;
int best_number_of_2character_word •■ -1;
foreach s (sequences) [
s.total_connective_cost
▪ sum_of_connective_cost(s);
if (best_total_connective_cost
&gt; s.total_connective_cost) (
best_total_connective_cost
- $.total_connective_cost;
selected - s; ))
foreach s (sequences) [
if (s.total_connective_cost
- best_total_connective_cost
&gt; PRUNE_RANGE) (
sequcences.delete(s); ))
foreach s (sequences) [
s.number_of_cooc
▪ count_cooccurence_of_words(s);
if (best_number_of_cooc
&lt; s.number_of_cooc)
best_number_of_cooc
- s.number_of_cooc;
selected s; ))
foreach s (sequences) [
if (s.number_of_cooc
&lt; best_number_of_cooc)
sequcences.delete(s); ))
foreach s (sequences) [
s.total_word_cost
▪ sum_of_word_cost(s);
if (best_total_word_cost
&gt; s.total_word_cost)
best_total_word_cost
- s.total_word_cost;
selected - s; 11
foreach s (sequences) (
if (s.total_word_cost
&gt; best_total_word_cost)
sequcences.delete(s); ))
foreach s (sequences) [
s.number_of_2character_word
- count_2character_word(5);
if (best_number_of_2character_word
&lt; s.number_of_2character_word)
best_number_of_2character_word
▪ s.number_of_2character_word;
selected - s; 1)
return selected;
1
</reference>
<page confidence="0.998988">
413
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.281529">
<title confidence="0.8363722">Japanese Morphological Analyzer using Word Co-occurrence JTAG Takeshi FUCHI NTT Information and Communication Systems Laboratories</title>
<address confidence="0.723086">Hilcari-no-oka 1-1 Yokosuka 239-0847, Japan,</address>
<email confidence="0.991132">fuchi@isl.ntt.co.jp</email>
<author confidence="0.9366">Shinichiro TAKAGI</author>
<affiliation confidence="0.9236535">NTT Information and Communication Systems Laboratories</affiliation>
<address confidence="0.934803">Hikari-no-oka 1-1 Yokosuka 239-0847, Japan,</address>
<email confidence="0.993874">takagi@nttnly.isl.ntt.co.jp</email>
<abstract confidence="0.9995866875">We developed a Japanese morphological analyzer that uses the co-occurrence of words to select the correct sequence of words in an unsegmented Japanese sentence. The co-occurrence information can be obtained from cases where the system incorrectly analyzes sentences. As the amount of information increases, the accuracy of the system increases with a small risk of degradation. Experimental results show that the proposed system assigns the correct phonological representations to unsegmented Japanese sentences more precisely than do other popular systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Yoshimura</author>
<author>T Hitaka</author>
<author>S Yoshida</author>
</authors>
<title>Morphological Analysis of Non-marked-off Japanese Sentences by the Least BUNSETSU&apos;</title>
<date>1983</date>
<journal>s Number Method. Trans. IPSJ,</journal>
<volume>24</volume>
<pages>40--46</pages>
<note>(in Japanese)</note>
<marker>Yoshimura, Hitaka, Yoshida, 1983</marker>
<rawString>Yoshimura K, Hitaka T. and Yoshida S. (1983) Morphological Analysis of Non-marked-off Japanese Sentences by the Least BUNSETSU&apos; s Number Method. Trans. IPSJ, Vol.24, No.1, pp.40-46. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Miyazaki</author>
<author>Y Ooyama</author>
</authors>
<title>Linguistic Method for a Japanese Text to Speech System.</title>
<date>1986</date>
<journal>Trans. IPSJ,</journal>
<volume>27</volume>
<pages>1053--1059</pages>
<note>(in Japanese)</note>
<marker>Miyazaki, Ooyama, 1986</marker>
<rawString>Miyazaki M. and Ooyama Y. (1986) Linguistic Method for a Japanese Text to Speech System. Trans. IPSJ, Vol.27, No.11, pp.1053-1059. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hisamitsu</author>
<author>Y Nitta</author>
</authors>
<title>Morphological Analysis by Minimum Connective-Cost Method.</title>
<date>1990</date>
<journal>SIGNLC</journal>
<pages>90--8</pages>
<note>(in Japanese)</note>
<marker>Hisamitsu, Nitta, 1990</marker>
<rawString>Hisamitsu T. and Nitta Y. (1990) Morphological Analysis by Minimum Connective-Cost Method. SIGNLC 90-8, lEICE, pp.17-24. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>Procs. Of 3rd Conference on Applied Naural Language Processing,</booktitle>
<publisher>ACL.</publisher>
<marker>Brill, 1992</marker>
<rawString>Brill E. (1992) A simple rule-based part of speech tagger. Procs. Of 3rd Conference on Applied Naural Language Processing, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Maruyama</author>
<author>S Ogino</author>
</authors>
<title>Japanese Morphological Analysis Based on Regular Grammar.</title>
<date>1994</date>
<journal>Trans. IPSJ,</journal>
<volume>35</volume>
<pages>1293--1299</pages>
<note>(in Japanese)</note>
<marker>Maruyama, Ogino, 1994</marker>
<rawString>Maruyama M. and Ogino S. (1994) Japanese Morphological Analysis Based on Regular Grammar. Trans. IPSJ, Vol.35, No.7, pp.1293-1299. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
</authors>
<title>A Stochastic Japanese Morphological Analyzer Using a Forward-DP Backward-A* N-Best Search Algorithm.</title>
<date>1994</date>
<booktitle>Computational Linguistics, COLING,</booktitle>
<pages>201--207</pages>
<marker>Nagata, 1994</marker>
<rawString>Nagata M. (1994) A Stochastic Japanese Morphological Analyzer Using a Forward-DP Backward-A* N-Best Search Algorithm. Computational Linguistics, COLING, pp.201-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Fuchi</author>
<author>M Yonezawa</author>
</authors>
<title>A Morpheme Grammar for Japanese Morphological Analyzers.</title>
<date>1995</date>
<journal>Journal of Natural Language Processing, The Association for Natural Language Processing,</journal>
<volume>12</volume>
<pages>37--65</pages>
<marker>Fuchi, Yonezawa, 1995</marker>
<rawString>Fuchi T. and Yonezawa M. (1995) A Morpheme Grammar for Japanese Morphological Analyzers. Journal of Natural Language Processing, The Association for Natural Language Processing, Vo12, No.4, pp.37-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pierre</author>
<author>P Tapanainen</author>
</authors>
<title>Tagging French — comparing a statical and a constraint-based method.</title>
<date>1995</date>
<booktitle>Procs. Of 7th Conference of the European Chapter of the ACL, ACL,</booktitle>
<pages>149--156</pages>
<marker>Pierre, Tapanainen, 1995</marker>
<rawString>Pierre C. and Tapanainen P. (1995) Tagging French — comparing a statical and a constraint-based method. Procs. Of 7th Conference of the European Chapter of the ACL, ACL, pp.149-156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeuchi</author>
<author>Y Matsumoto</author>
</authors>
<title>HMM Parameter Learning for Japanese Morphological Analyzer.</title>
<date>1995</date>
<booktitle>Procs. Of 10th Pacific Asia Conference Language, Information and Computation,</booktitle>
<pages>163--172</pages>
<contexts>
<context position="1523" citStr="Takeuchi and Matsumoto (1995)" startWordPosition="197" endWordPosition="200">ular systems. Introduction In natural language processing for Japanese text, morphological analysis is very important. Currently, there are two main methods for automatic part-of-speech tagging, namely, corpusbased and rule-based methods. The corpus-based method is popular for European languages. Samuelsson and Voutilainen (1997), however, show significantly higher achievement of a rulebased tagger than that of statistical taggers for English text. On the other hand, most Japanese taggers&apos; are rule-based. In previous Japanese taggers, it was difficult to increase the accuracy of the analysis. Takeuchi and Matsumoto (1995) combined a rule-based and a corpus-based method, 1 In this paper, a tagger is identical to a morphological analyzer. resulting in a marginal increase in the accuracy of their taggers. However, this increase is still insufficient. The source of the trouble is the difficulty in adjusting the grammar and parameters. Our tagger is also rule-based. By using the cooccurrence of words, it reduces the difficulty and generates a continuous increase in its accuracy. The proposed system analyzes unsegmented Japanese sentences and segments them into words. Each word has a part-of-speech and phonological </context>
</contexts>
<marker>Takeuchi, Matsumoto, 1995</marker>
<rawString>Takeuchi K. and Matsumoto Y. (1995) HMM Parameter Learning for Japanese Morphological Analyzer. Procs. Of 10th Pacific Asia Conference Language, Information and Computation, pp.163-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>A syntax-based part of speech analyser.</title>
<date>1995</date>
<booktitle>Procs. Of 7th Conference of the European Chapter of the Association for Computational Linguistics, ACL,</booktitle>
<pages>157--164</pages>
<marker>Voutilainen, 1995</marker>
<rawString>Voutilainen A. (1995) A syntax-based part of speech analyser. Procs. Of 7th Conference of the European Chapter of the Association for Computational Linguistics, ACL, pp.157-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Matsuoka</author>
<author>E Talceishi</author>
<author>H Asano</author>
</authors>
<title>Natural Language Processing in a Japanese Text-To-Speech System for Written-style Texts.</title>
<date>1996</date>
<booktitle>Procs. Of r IEEE Workshop On Interactive Voice Technology For Telecommunications Applications, IEEE,</booktitle>
<pages>33--36</pages>
<marker>Matsuoka, Talceishi, Asano, 1996</marker>
<rawString>Matsuoka K., Talceishi E. and Asano H. (1996) Natural Language Processing in a Japanese Text-To-Speech System for Written-style Texts. Procs. Of r IEEE Workshop On Interactive Voice Technology For Telecommunications Applications, IEEE, pp.33-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
<author>A Voutilainen</author>
</authors>
<title>Comparing a Linguistic and a Stochastic Tagger.</title>
<date>1997</date>
<booktitle>Procs. Of 35th Annual Meeting of the Association for Computational Linguistics, ACL.</booktitle>
<contexts>
<context position="1225" citStr="Samuelsson and Voutilainen (1997)" startWordPosition="152" endWordPosition="155">ctly analyzes sentences. As the amount of information increases, the accuracy of the system increases with a small risk of degradation. Experimental results show that the proposed system assigns the correct phonological representations to unsegmented Japanese sentences more precisely than do other popular systems. Introduction In natural language processing for Japanese text, morphological analysis is very important. Currently, there are two main methods for automatic part-of-speech tagging, namely, corpusbased and rule-based methods. The corpus-based method is popular for European languages. Samuelsson and Voutilainen (1997), however, show significantly higher achievement of a rulebased tagger than that of statistical taggers for English text. On the other hand, most Japanese taggers&apos; are rule-based. In previous Japanese taggers, it was difficult to increase the accuracy of the analysis. Takeuchi and Matsumoto (1995) combined a rule-based and a corpus-based method, 1 In this paper, a tagger is identical to a morphological analyzer. resulting in a marginal increase in the accuracy of their taggers. However, this increase is still insufficient. The source of the trouble is the difficulty in adjusting the grammar an</context>
</contexts>
<marker>Samuelsson, Voutilainen, 1997</marker>
<rawString>Samuelsson C. and Voutilainen A. (1997) Comparing a Linguistic and a Stochastic Tagger. Procs. Of 35th Annual Meeting of the Association for Computational Linguistics, ACL.</rawString>
</citation>
<citation valid="false">
<title>ELEMENT selection(SET sequences) ELEMENT selected; int best_total_connective_cost MAX_INT; int best_number_of_cooc -1; int best_total_word_cost -1; int best_number_of_2character_word •■ -1; foreach s (sequences) [ s.total_connective_cost ▪ sum_of_connective_cost(s); if (best_total_connective_cost &gt; s.total_connective_cost) ( best_total_connective_cost - $.total_connective_cost; selected - s; )) foreach s (sequences) [ if (s.total_connective_cost - best_total_connective_cost &gt; PRUNE_RANGE) ( sequcences.delete(s); )) foreach s (sequences) [ s.number_of_cooc ▪ count_cooccurence_of_words(s); if (best_number_of_cooc &lt; s.number_of_cooc) best_number_of_cooc - s.number_of_cooc; selected s; )) foreach s (sequences) [ if (s.number_of_cooc &lt; best_number_of_cooc) sequcences.delete(s); )) foreach s (sequences) [ s.total_word_cost ▪ sum_of_word_cost(s); if (best_total_word_cost &gt; s.total_word_cost) best_total_word_cost - s.total_word_cost; selected - s; 11 foreach s (sequences) ( if (s.total_word_cost &gt; best_total_word_cost) sequcences.delete(s); )) foreach s (sequences)</title>
<note>s.number_of_2character_word</note>
<marker></marker>
<rawString>ELEMENT selection(SET sequences) ELEMENT selected; int best_total_connective_cost MAX_INT; int best_number_of_cooc -1; int best_total_word_cost -1; int best_number_of_2character_word •■ -1; foreach s (sequences) [ s.total_connective_cost ▪ sum_of_connective_cost(s); if (best_total_connective_cost &gt; s.total_connective_cost) ( best_total_connective_cost - $.total_connective_cost; selected - s; )) foreach s (sequences) [ if (s.total_connective_cost - best_total_connective_cost &gt; PRUNE_RANGE) ( sequcences.delete(s); )) foreach s (sequences) [ s.number_of_cooc ▪ count_cooccurence_of_words(s); if (best_number_of_cooc &lt; s.number_of_cooc) best_number_of_cooc - s.number_of_cooc; selected s; )) foreach s (sequences) [ if (s.number_of_cooc &lt; best_number_of_cooc) sequcences.delete(s); )) foreach s (sequences) [ s.total_word_cost ▪ sum_of_word_cost(s); if (best_total_word_cost &gt; s.total_word_cost) best_total_word_cost - s.total_word_cost; selected - s; 11 foreach s (sequences) ( if (s.total_word_cost &gt; best_total_word_cost) sequcences.delete(s); )) foreach s (sequences) [ s.number_of_2character_word</rawString>
</citation>
<citation valid="false">
<booktitle>count_2character_word(5); if (best_number_of_2character_word &lt; s.number_of_2character_word) best_number_of_2character_word</booktitle>
<marker></marker>
<rawString>- count_2character_word(5); if (best_number_of_2character_word &lt; s.number_of_2character_word) best_number_of_2character_word</rawString>
</citation>
<citation valid="false">
<title>s.number_of_2character_word; selected - s; 1) return selected; 1</title>
<marker></marker>
<rawString>▪ s.number_of_2character_word; selected - s; 1) return selected; 1</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>