<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9975105">
The Interactive Navigation to the Stored Q&amp;A data using Simple
Questions
</title>
<author confidence="0.816194">
Kunio MATSUI Hozumi TANAKA
</author>
<affiliation confidence="0.763963">
Fujitsu Laboratories Ltd. Tokyo Institute of Technology
</affiliation>
<email confidence="0.9092">
matsui . kunio@jp . fuj itsu . com tanaka@cs.titech.ac.jp
</email>
<sectionHeader confidence="0.993091" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999504166666667">
As an effort aimed at designing a system
to save operator work at Call Centers, this
research suggests directing users to Q&amp;A
data stored in the call center by using
naturally expressed questions (simple
questions) received from users as a trig-
ger. And, based on actual data, this re-
search effort closely examines difference
in accuracy when selecting methods for
key terms, and the difference in accuracy
when case elements are omitted. Our ef-
forts showed that the term that limits or
extends the heads of the sentence greatly
influences the search accuracy. Accord-
ingly, this paper presents an interactive
navigation method for supplementing a
term in accordance with a rule and im-
proves its effectiveness.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999449">
Call Centers, which provide answers on prod-
uct usage directly to consumers, are a rapidly
growing part of customer service. However, due
to the furious rate at which new products are be-
ing developed and introduced to the market, an
ever-increasing knowledge base is required to
effectively respond to user questions. This is
making it extremely difficult for call center op-
erators to give precise answers to complicated
questions in a timely manner. Because of the
stressful nature of this job, the stability of the
workforce at Call Centers is decreasing and corn-
panies are facing an increasing number of prob-
lems in retaining a sufficient number of skilled
operators, due to such costs as personnel ex-
penses and employee training.
In an effort to design a system to assist Call
Center operators, this report suggests an interac-
tive navigation method that will channel callers
to Q&amp;A data stored in the Call Center database
by using naturally expressed questions and natu-
ral sentences (hereinafter, simple questions). We
believe that these simple questions can provide
reliable indicators into the situation confronting
the user and can be used as a trigger. In this pa-
per we will also examine the difference in the
precision of creating methods for simple ques-
tions, the difference in the precision of selecting
methods for key terms, and the difference in the
precision when case elements are omitted.
</bodyText>
<sectionHeader confidence="0.997992" genericHeader="introduction">
2 Related Research
</sectionHeader>
<bodyText confidence="0.999932066666667">
While the ideal solution to the problem would
be a computer that could answer user questions
automatically, no such system is currently avail-
able and it is not clear as to when such a system
will appear in the future.
As a research of dialogue, ELIZA
(Weizenbaum, 1966) is very famous but it is not
developed for the purpose of user solution. Also
the interactive information retrieval system
(Oddy, 1977) is designed to give alternatives to
the user, but it is difficult to reflect the user inten-
tion.
As a research of Q&amp;A system, a helpdesk sys-
tem for software products (Kurohashi et al, 2000)
is now working on research based on FAQ Finder
</bodyText>
<page confidence="0.997202">
79
</page>
<bodyText confidence="0.999846577777778">
(Bruke, 1997), but it is still confined to a limited
field.
At the same time, however, a method that uses
previously stored question and answer data to
provide responses to user questions is available.
This method utilizes several approaches. One
approach is a system where the operator mediates
user inquiries and uses the system as a resource
for finding the answer to the question. In this
case, system integrity is not a requirement be-
cause of the human mediation. And some are
effectively working in the sense of assisting op-
erators even though they may be imperfect.
Alternatively, in some systems, the computer
responds directly to the users. An example of
such systems would be a system (Harabagiu,
2001) where a search question is replaced by cre-
ating a precise search query that may be used for
QA task of TREC, and in another system(Robin,
1997) a planning question is replaced to clarify
its goal by applying the world model and the user
model in a limited world.
The problem with the former is that the ques-
tion itself is not realistic and storing all the Q&amp;A
data costs a great deal. The problem with the lat-
ter is that creating the models costs too much for
adopting to the rapidly changing real-world situa-
tions.
In yet another method, the stored Q&amp;A data
are utilized as FAQ to allow users to perform
keyword search. However, a log survey of some
internet search engine shows that 90% of users
enter just one keyword for the first search step
(Harada, 1997). This means it is hard to say that
users are sufficiently utilizing this method as a
search query even though there may be potential
demands.
In light of the situation described above, the
research effort described in this paper works at
the method of solving user questions by generat-
ing a query that extracts effective constituent
elements of simple questions and navigates the
user to the stored Q&amp;A, using &amp;quot;simple questions&amp;quot;
that conform to the user&apos;s situation and that indi-
cate the expression of natural questions.
</bodyText>
<sectionHeader confidence="0.958027" genericHeader="method">
3 Data and Evaluation Method
</sectionHeader>
<subsectionHeader confidence="0.954707">
3.1 Q&amp;A at Call Center
</subsectionHeader>
<bodyText confidence="0.989942642857143">
In this experiment, a group of records describ-
ing questions solved by operators at Call Center
through telephone responses were divided into
questions (&lt;subject&gt;) and answers (&lt;solution&gt;),
and were used as an analysis target. An actual
example is shown in Example 1.
The question and answer are not an exact dia-
logue record between the user and operator. It is
considered that they actually began from an ex-
pression of a simple user situation or intention,
and that the outcome derived from several dia-
logues between user and operator is summarized
later. Data stored at Call Center are usually
summarized in many cases.
</bodyText>
<figure confidence="0.626747875">
&lt;qaid&gt;354&lt;/qaid&gt;
&lt;subject&gt;
I want to record and reproduce audio using the audio re—
corder with USB connection, Roland AUDIO CANVAS UA-
100. Please let me know connection method of putting the
audio outputs of PC together.
&lt;/subject&gt;
&lt;solution&gt;
</figure>
<bodyText confidence="0.97157725">
For the audio recording and reproduction using Roland
AUDIO CANVAS UA-100, audio recording without getting
influence of the noise as AD/DA conversion can be sepa—
rated from the main body of PC (the sound card).
</bodyText>
<listItem confidence="0.931485307692308">
•Operating Procedure
1. PC is connected with the terminal USB of UA-100.
(Recording and reproduction of WAV files)
2. The terminal LINE OUT of the sound board on the PC
is connected with the terminal INPUT of UA-100. (Music CD
reproduction and reproduction of MIDI files that use sound
board or soft MIDI sound source)
3. The terminal OUTPUT of UA-100 is connected to an
external speaker.
4. In addition, audio recording can be done by connecting
the mike and the recording machine (MD and cassette, etc.)
with UA-100.
&lt;/solution&gt;
</listItem>
<bodyText confidence="0.973275928571429">
Example 1 Sample Q&amp;A at Call Center
To begin analysis of the stored data, we first
conducted research on the constituent elements of
questions. As the research viewpoint, 300 arbi-
trarily extracted questions were categorized into
three types (Phenomenon, Denial, and Intention)
as situation explanation, and nine question types
(What, How, Method, Which, Why, Where, Re-
quest, Possibility, and YIN), which were counted
respectively. As the result below shows, the ma-
jority of questions consist of question sentences
that can be expressed as situation explanation and
question type. The majority consists of situation
explanation and question type.
</bodyText>
<footnote confidence="0.524571666666667">
- Situation Explanation
Phenomenon (154)
Denial (92)
</footnote>
<page confidence="0.774445">
80
</page>
<equation confidence="0.6033874">
Intention (28)
- Question Type
What (12), How (24), Method (20), Which (7),
Why (17), Where (2), Request (47),
Possibility (18), Y/N (21)
</equation>
<bodyText confidence="0.999019333333333">
Such explanations and questions were not
complete in the beginning. Instead, they were
considered to have started with an expression of
simple situation or question derived by the opera-
tors based on the dialogues with the users which
were later summarized.
</bodyText>
<subsectionHeader confidence="0.999995">
3.2 Setting of Goal
</subsectionHeader>
<bodyText confidence="0.989769642857143">
As previously described, when users call a
Call Center, the process starts with simple ques-
tions in many cases consisting of situation expla-
nations and conditions that are not complicated.
Operators then ask the users for various details in
order to lead them to the right answers. To per-
form the same type of navigation with a com-
puter, it is first necessary to receive simple
questions from users, and then to try to match
those questions with stored questions by supple-
menting necessary conditions through interactive
dialogues between the computer and the user, and
then to lead the user to the right answer. (Figure
1)
</bodyText>
<figureCaption confidence="0.985591">
Figure 1 Image of the System Realization
</figureCaption>
<bodyText confidence="0.999991333333333">
In this experiment, we set a target for analysis
on which points, and in what way, simple ques-
tions are matched with stored questions. Addi-
tionally, in an effort to find out what types of
dialogues should be conducted for simple ques-
tions input by users, we looked to determine what
kind of constituent elements in simple questions
are effective for assisting matching.
For this, we decided the goal would be to first
create simple question sentences that are not in
the record, and then create a search query that
best matches the stored questions.
</bodyText>
<subsectionHeader confidence="0.999968">
3.3 Creation of Simple Questions
</subsectionHeader>
<bodyText confidence="0.999246769230769">
We created simple questions by reading
through the stored questions and using various
user questions that can be analyzed as simple
structure questions.
In order to avoid being too dependent upon
creator&apos;s habits, here we tried, to the greatest de-
gree possible, to create natural questions by indi-
cating two methods and having plurality of
persons involved in the work.
Two guidelines of creation are listed below:
- First guideline: &amp;quot;Natural and simple expressions
where nature of the question is very easily rec-
ognizable from the sentence alone.&amp;quot;(Ex. 2)
</bodyText>
<figure confidence="0.803868473684211">
&lt;simple_q&gt;
&lt;sq&gt;I want to know the connection method to put audio
outputs together. &lt;/sq&gt;
&lt;sq&gt;I want to record and reproduce audio.&lt;/sq&gt;
&lt;sq&gt;I want to record and reproduce audio with ROLAND
AUDIO CANVAS UA-100.&lt;/sq&gt;
&lt;sq&gt;I want to connect audio outputs all together.&lt;/sq&gt;
&lt;/simple_q&gt;
Example 2 Simple Question of Free Description
- Second Guideline: &amp;quot;Render the stored questions
into several constituent elements making each
element a simple question.&amp;quot;(Ex. 3)
&lt;simple_q&gt;
&lt;sq&gt;I want to record and reproduce audio. &lt;/sq&gt;
&lt;sq&gt;I want to use an audio recorder with USB connec—
tion.&lt;/sq&gt;
&lt;sq&gt;Please let me know how to connect it with PC.&lt;/sq&gt;
&lt;/simple_q&gt;
Example 3 Simple Question of Constituent Elements
</figure>
<subsectionHeader confidence="0.987073">
3.4 Retrieval Tool
</subsectionHeader>
<bodyText confidence="0.992592833333334">
As a retrieval tool, the preceding sentence
search engine (Matsui et al, 2000), which we
have developed, was used to retrieve the ques-
tions rendered from simple questions. Simple
questions for the query were morphologically
analyzed by JUMAN (Kurohashi and Nagao,
1999) to select key terms to be used for retrieval.
Selection of key terms is shown below.
[Basis of selection of key terms used for re-
trieval]
After the morphological analysis of simple
questions, key terms are set so that they can be
selected by the following part of speech.
{Noun, Undefmed Word, Adjective, Verb, Adverb}
Additionally, it can be selected from the level
that expresses the head of case frame. For this,
division and connection are defined as below, so
that case frames are expressed. The charge parti-
</bodyText>
<table confidence="0.854717">
User Stored Stored
Simple Questions Questions Answers
Possibility of dialogues for the matching process
</table>
<page confidence="0.996369">
81
</page>
<bodyText confidence="0.970785571428571">
cle and the case-marking particle, etc. at the level
of the morphological analysis are recognized as
divider, as the sentences are simple.
TF/IDF(Term Frequency and Inverted Document
Frequency) was used to put the retrieval output in
order of relevance.
Divider: Divides the unity of each case frame.
</bodyText>
<equation confidence="0.8951638">
: 73(ga), (wo), --C;(de), ri(wa),
(mo), &amp;quot;Punctuation&amp;quot;
Connector : Expands the range of each case frame.
(7) (no), &amp;quot;Noun Connection&amp;quot;
Nouns : Noun, Undefined Word
</equation>
<bodyText confidence="0.988193583333333">
Using the defmition of these connectors and
dividers, the levels of the key terms were defined
as follows. The levels were defined for the pur-
pose of determining whether interactive key
terms supplementation was necessary.
Level 1: Only the term immediately preceding a di-
vider
Level 2 : All terms that are connected by a connector
preceding a divider.
Level 3 : All terms
By selecting a speech part and level, key term
assignment becomes possible as described below.
</bodyText>
<equation confidence="0.733881">
Example 4 Output of morphological analyzer and the divid-
ers
[Sample sentence]
t&apos;Elq&apos;Watit-e#1-4.i.Prit-g-ZA75q)75NGtsi,N.
(rusubandenwadebangouwotsuuchisaseruhouhougawa—
karanai.)
</equation>
<bodyText confidence="0.931356588235294">
[Output of morphological analyzer]
rusuban / denwa / de / bangou / wo / tsuuchi / sase
/ ru / houhou / g / waka / ra / nai I.
( I don&apos;t know how to have the number displayed on
the display screen of the answering machine.)
The dividers were underlined in the above-
mentioned of morphological analyzer output. In
this example, the following terms can be assigned
at each level.
Level 1 : 1%* 1-0 (denwa), (bangou),
(houhou), 7 11 &apos;(nai)
Level 2: Level 1 + g&apos;41---1-(rusuban)
Level 3 : Level 2 + AMtsuuchi),
(waka)
Questions that have accumulated were pre-
registered as features of n-gram when the indexes
were made. The general weighting method of
</bodyText>
<subsectionHeader confidence="0.866047">
3.5 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.99992225">
Since its aim is to navigate to the accumulated
questions, measuring the recall ratio and the rele-
vance ratio used in a general retrieval was not
considered a valid alternative. Hence, evaluation
was conducted based on the order in which the
ranking was done with the retrieval tool.
Relative evaluation was done according to the
number of first places.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.777417333333333">
The experiments were conducted by the fol-
lowing methods.
[Methods]
- Ranking search was conducted on simple ques-
tions as queries and accumulated questions as
targeted information.
- Ranking search was conducted on question and
answer pairs, with a combination of plural, sim-
ple questions designated as queries.
- Number of queries: 300 Queries, made as sim-
ple questions were randomly extracted from
38,000 accumulated questions.
</bodyText>
<listItem confidence="0.866422875">
- Number of accumulated questions: 38,000.
[Conditions]
- Difference by basis of selection of key terms
- Difference by excluding case elements
- Supplement of term to simple question
- Retrieval method: The morpheme was analyzed
with JUMAN. With a noun, a verb, an adjective,
an undefined word, the prefix, the suffix, and
the adverb assigned as key terms, retrieval was
conducted as follows
LI -one: a single, simple question and the key terms of level I.
Ll-all: plural simple questions and the key terms of level I.
L2-one: a single, simple question and the key terms of level 2.
L2-all: plural simple questions and the key terms of level 2.
L3-one: a single, simple question and the key terms of level 3.
L3-all: plural simple questions and the key terms of level 3.
</listItem>
<bodyText confidence="0.974289">
Next, the retrieval type, without the &amp;quot;case ele-
ment&amp;quot; delimited by a divider, was made for the
level 3 key terms, and retrieval was conducted as
follows.
one-ga: a key term excluding &amp;quot;ga&amp;quot; case with a single, sim-
ple question
</bodyText>
<page confidence="0.996834">
82
</page>
<tableCaption confidence="0.912087111111111">
all-ga: a key term excluding &amp;quot;go&amp;quot; case with plural, simple
questions
one-wo: a key term excluding &amp;quot;wo&amp;quot; case with a single,
simple question
all-wo: a key term excluding &amp;quot;wo&amp;quot; case with plural, sim-
ple questions
one-de: a key term excluding &amp;quot;de&amp;quot; case with a single, sim-
ple question
all-de: a key term excluding &amp;quot;de&amp;quot; case with plural, simple
questions
one-wamo: a key term excluding &amp;quot;wa&amp;quot; case and &amp;quot;mo&amp;quot; case
with a single, simple question
all-wamo: a key term excluding &amp;quot;wa&amp;quot; case and &amp;quot;mo&amp;quot; case
with plural, simple questions
one-nie: a key term excluding &amp;quot;ni&amp;quot; case and &amp;quot;e&amp;quot; case with
a single, simple question
all-nie: a key term excluding &amp;quot;ni&amp;quot; case and &amp;quot;e&amp;quot; case with
plural, simple questions
</tableCaption>
<sectionHeader confidence="0.513427" genericHeader="method">
5 Arguments on the composition of sim-
ple questions
</sectionHeader>
<subsectionHeader confidence="0.662316">
5.1 Difference in method of making sim-
ple questions
</subsectionHeader>
<bodyText confidence="0.9999486">
Simple questions were made using two guide-
lines. Along with its comparison, the difference
between a retrieval type made only from a single,
simple question and a retrieval type made by us-
ing the logical sum of plural, simple questions
are shown below. Table 1 shows the retrieval
output using simple questions made by the first
guideline (hereafter, sqf), and Table 2 shows the
retrieval output using simple questions made by
the second guideline (hereafter, sqc).
</bodyText>
<tableCaption confidence="0.997365">
Table 1 Retrieval outøut using the 1st guideline s
</tableCaption>
<table confidence="0.999885">
Ranking L3-one L3-one L3-all L3-all
1st 414 53.6% 232 77.3%
2nd-10th 184 23.8% 44 14.7%
below 11th 175 22.6% 24 8.0%
773 100.0% 300 100.0%
</table>
<tableCaption confidence="0.965223">
Table 2 Retrieval outøut using the 2nd guideline s c
</tableCaption>
<table confidence="0.9911238">
Ranking L3-one L3-one L3-all L3-all
1st 248 49.7% 223 74.3%
2nd-10th 115 23.0% 51 17.0%
below 11th 136 27.3% 26 8.7%
499 100.0% 300 100.0%
</table>
<bodyText confidence="0.99994878125">
From the results of Table 1 and Table 2, it is
clear that retrieval using combined plural, simple
questions yields a higher ratio of first place in the
retrieval order than retrieval by a single, simple
question. Since both outputs were 24-25%
higher, it is understood that, from the viewpoint
of retrieval, a simple question does not increase
noise, but rather, proves itself to be an effective
key term. In other words, a single, simple ques-
tion alone cannot easily navigate users to the
original question, it requires supplementary in-
formation.
In addition, the retrieval outputs by different
guideline of constructing simple questions
showed that the first guideline gave higher ratios
of first place by about 3-4% in both single and
plural questions. This is because there seemed to
be a tendency for ... to satisfy the accumulated
original questions even though simple questions
were freely described in the first guideline. Ex-
ample 5 are samples of simple questions that led
to the retrieval output in which the simple ques-
tion made by the second guideline was signifi-
cantly worse than the simple question made by
the first guideline
In &lt;qaid&gt;769 of example 5, &amp;quot;sold at distribu-
tion outlet&amp;quot; is the important key term, and in
&lt;qaid&gt;1510, &amp;quot;built-in fax modem&amp;quot; is the impor-
tant key term. As described later in the method
of selecting the key term in which similar results
are seen, an important key term for retrieval is
included in words and phrases that modify nouns.
</bodyText>
<figure confidence="0.9244336">
&lt;qaid&gt;769&lt;/qaid&gt;
&lt;subject&gt;
FM—TOWNS FRESH) WINDOWS95 bought in a distribution
outlet cannot be installed. Why?
&lt;/subject&gt;
&lt;sqf&gt;&gt; WINDOWS95 bought in a distribution outlet cannot be
installed &lt;/sqf&gt;—&gt;1 st rank
&lt;sqc&gt;&gt; WINDOWS95 on the market cannot be installed .&lt;/sq
c&gt;—&gt;271et rank
&lt;qaid&gt;1510&lt;/qaid&gt;
</figure>
<bodyText confidence="0.672815714285714">
&lt;subject&gt; The following errors occur when dialed to the
Internet with the modem by using dial—up networking at the
connection destination. Show what to do. Also, show how to
turn off the power supply of the built—in fax modem in soft—
ware.
&lt;/subject&gt;
&lt;sqf&gt;&gt; 1 want to know software—wise the method of turning
off the power supply of the built—in fax modem.&lt;/sqf&gt; —&gt;lst
rank
&lt;sqc&gt; Cannot dial—up—connect with the modem. &lt;/sqc&gt;
—*29th rank
Example 5 Difference between sqf and sqc
5.2 Difference by basis of selection of
key terms
</bodyText>
<page confidence="0.995347">
83
</page>
<bodyText confidence="0.999692357142857">
Table 3 shows the retrieval output with
change in the selection criterion of the key terms
for the above-mentioned sqf. Likewise, the re-
trieval output with a change in the selection crite-
rion of the key terms for sqc is shown in Table 4.
What can be said about both sqf and sqc is,
Level 1 that selects only a term just before a di-
vider has lower ratio of first place by more than
30 points compared with Level 2 (terms con-
nected by connectors) and level 3 (all terms). In
the Japanese language, a term preceding a parti-
cle usually becomes a head, which indicates that
a head alone is not sufficient as a key term for
retrieval.
</bodyText>
<tableCaption confidence="0.97964">
Table 3 Difference by basis of selection of key terms s
</tableCaption>
<table confidence="0.9999532">
Ranking Li-one L2-one L3-one Li-all L2-all L3-all
1st 15.7% 47.2% 53.6% 34.7% 69.0% 77.3%
2nd-10th 21.1% 24.6% 23.8% 25.3% 19.3% 14.7%
below 11th 63.3% 28.2% 22.6% 40.0% 11.7% 8.0%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<tableCaption confidence="0.917794">
Table 4 Difference by basis of selection of key terms
</tableCaption>
<table confidence="0.930657">
sac
Ranking L1-one L2-one L3-one Li-all L2-all L3-all
1st 15.2% 41.1% 49.7% 32.7% 64.0% 74.3%
2nd-10th 22.4% 24.2% 23.0% 28.7% 21.3% 17.0%
below 1 1 th 62.3% 34.7% 27.3% 38.7% 14.7% 8.7%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<subsectionHeader confidence="0.7241435">
5.3 Difference by excluding case ele-
ments
</subsectionHeader>
<bodyText confidence="0.9999">
Table 5 shows the effect of the removal of the
case element in a single, simple question for sqf,
and Table 6, the effect of the removal of the case
element in plural, simple questions for sqf. Like-
wise, Table 7 shows the effect of the removal of
the case element in a single, simple question for
sqc, and Table 8, the effect of the removal of the
case element in plural, simple questions for sqc.
The effect is most remarkable when &amp;quot;ga&amp;quot; case
element or &amp;quot;wo&amp;quot; case element is removed for
both single and plural questions: both ratios of
first places have decreased by more than 15
points. In addition, the ratio of first places has
decreased by 6-7 points in &amp;quot;ni, e&amp;quot; case element.
However, for sqc, there is little change in &amp;quot;de&amp;quot;
case element as the situation differs between sqf
and sqc. This is due to the difference in writing a
simple question.
</bodyText>
<tableCaption confidence="0.907535">
Table 5 Effect of the removal of the case element in a
single, simple question (sqf)
</tableCaption>
<table confidence="0.9998706">
Ranking L3-one one-ga one-wo one-de one-hie one-warr
1st 53.6% 37.8% 35.8% 47.9% 47.3% 52.3%
2nd-10th 23.8% 19.5% 20.2% 25.1% 23.3% 23.9%
below 11th 22.6% 42.7% 44.0% 27.0% 29.4% 23.8%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<tableCaption confidence="0.989042">
Table 6 Effect of the removal of the case element in plura ,
simple uuestions s
</tableCaption>
<table confidence="0.9999372">
Ranking L3-all all-ga all-wo all-de all-nie all-wamo
1st 77.3% 63.7% 61.7% 71.3% 70.0% 76.0%
2nd-10th 14.7% 17.7% 20.0% 18.0% 17.0% 16.0%
below 11th 8.0% 18.7% 18.3% 10.7% 13.0% 8.0%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<tableCaption confidence="0.9445155">
Table 7 Effect of the removal of the case element in a
single, simple question (sqc)
</tableCaption>
<table confidence="0.9999444">
Ranking L3-one one-ga one-wo one-de one-hie one-wan
1st 49.7% 34.7% 36.5% 46.3% 41.5% 45.7%
2nd-10th 23.0% 19.6% 20.4% 23.0% 22.2% 23.2%
below 11th 27.3% 45.7% 43.1% 30.7% 36.3% 31.1%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<tableCaption confidence="0.994454">
Table 8 Effect of the removal of the case element in plura ,
simple uuestions s c
</tableCaption>
<table confidence="0.9997956">
Ranking L3-all all-ga all-wo all-de all-nie all-wamo
1st 74.3% 55.3% 58.0% 70.3% 63.3% 69.3%
2nd-10th 17.0% 19.7% 20.7% 18.3% 21.0% 18.3%
below 1 1 th 8.7% 25.0% 21.3% 11.3% 15.7% 12.3%
100.0% 100.0% 100.0% 100.0% 100.0% 100.0%
</table>
<sectionHeader confidence="0.9628385" genericHeader="method">
6 Discussion concerning interactive navi-
gating
</sectionHeader>
<subsectionHeader confidence="0.972614">
6.1 Strategy of supplement of interactive
term
</subsectionHeader>
<bodyText confidence="0.999991105263158">
It remains in about 50 percent in a single, sim-
ple question though the nearly 80 percent of
questions can be navigated by combining two or
more single, simple questions. It is important to
determine whether it is possible to navigate to
supplement a term very appropriate to surround-
ings of a head as being from the discussion about
Chapter 5 in order to improve the search preci-
sion.
It is necessary to decide which term in the
simple questions attention should be focused on,
and whether to limit the term or to provide it in
detail. What query the system makes becomes
the strategy of the term supplement.
Consequently, to examine whether the kind of
the noun relates as a clue that decides whether to
limit the term, or to make it in detail, about
38,000 accumulated questions were analyzed.
We then counted the number of the questions in
</bodyText>
<page confidence="0.995906">
84
</page>
<bodyText confidence="0.993337333333333">
which the modification by &amp;quot;no&amp;quot; appears five
times or more.
Tables 9-11 show the example of typical
phrases, the total frequency, and the ratio. Table
9 shows the relation between &amp;quot;sahen&amp;quot; noun
(Japanese verbal noun) and &amp;quot;no&amp;quot;. Table 10 shows
the relation between the common noun and &amp;quot;no&amp;quot;.
Table 11 shows the relation between the proper
noun and &amp;quot;no&amp;quot;
</bodyText>
<tableCaption confidence="0.999433">
Table 9: Relation between &amp;quot;sahen&amp;quot; noun and &amp;quot;no&amp;quot;
</tableCaption>
<table confidence="0.999006">
Term Freqency modify with -no- modified by &amp;quot;no&amp;quot;
set up 722 32 690
display 166 9 157
install 158 16 142
update 144 4 140
connect 119 18 101
Total 5107 862 4245
Ratio 16.9% 83.1%
</table>
<tableCaption confidence="0.996621">
Table 10: Relation between common noun and &amp;quot;no&amp;quot;
</tableCaption>
<table confidence="0.999243125">
Term Freqency modify with &amp;quot;no&amp;quot; modified by &amp;quot;no&amp;quot;
file 262 132 130
data 182 75 107
hard disk 121 85 36
PC 107 77 30
program 96 47 49
Total 14181 6362 7819
Ratio 44.9% 55.1%
</table>
<tableCaption confidence="0.994405">
Table 11: Relation between oroner noun and &amp;quot;no&amp;quot;
</tableCaption>
<table confidence="0.9987455">
Term Freqency modify with -no- modified by &amp;quot;no-
Windows95 180 149 20
Windows98 85 76 9
Windows 65 61 4
Word 37 35 2
Fujitsu 36 35 1
Total 1567 1405 162
Ratio 88.9% 11.1%
</table>
<subsectionHeader confidence="0.9556525">
6.2 Supplement of term to simple ques-
tions
</subsectionHeader>
<bodyText confidence="0.999799">
The following four rules, that decide which
term in the simple questions attention is to be
focused on, and how to limit it or make it in de-
tail, can be derived in consideration of the above
analysis.
</bodyText>
<listItem confidence="0.909952857142857">
(1) Focus attention to the term that becomes a
head of the case frame in the order of the case
frame that influences the search precision.
(&amp;quot;ga&amp;quot; &gt; &amp;quot;wo&amp;quot; &gt; &amp;quot;ni/e&amp;quot; &gt; &amp;quot;wa/mo&amp;quot; &gt; &amp;quot;de&amp;quot; as
the result of Table 7 and 8)
(2) Focus attention to the term of &amp;quot;A&amp;quot; when the
term that becomes a head contains the connec-
tor and is shape of &amp;quot;B of A&amp;quot; (because B has
already been limited).
(3) Supplement the term that limits the &amp;quot;sahen&amp;quot;
noun if the term that is focused attention is a
&amp;quot;sahen&amp;quot; noun (as the result of Table 9).
(4) Supplement the term that defines the proper
noun in detail if the term under intense con-
</listItem>
<bodyText confidence="0.98651465">
sideration is a proper noun (as the result of
Table 11).
By using these rules, the term under intense
consideration and the response of system accord-
ing to the following procedures, and determine if
the term should be supplemented.
[Procedure of supplement of term]
(a) When the case frame divided by divider ex-
cept &amp;quot;Punctuation&amp;quot; is plural, rule (1) is applied.
(b) Table 12 shows that the response of the sys-
tem changes depending on the presence of the
existence of the connector &amp;quot;no&amp;quot; and the kind
of the noun before and behind. The upper row
shows the number of the applied rule. The
lower shows the response of the system. The
sign &amp;quot;1&amp;quot; shows that either possibility exists.
Moreover, as a heuristics, &amp;quot;Donna (Which)&amp;quot; is
used for the limitation of the &amp;quot;sahen&amp;quot; noun,
and &amp;quot;Narmo (What)&amp;quot; is used for the limitation
of the common noun.
</bodyText>
<tableCaption confidence="0.998872">
Table 12: Term in &apos;B of A&amp;quot; that is focused attention
</tableCaption>
<table confidence="0.9938135">
ANB Sahen Common Proper
Sahen Noun (2)(3) (2)(3) (2)(3)(4)
[-Donna- AJ r-Donna-A] I—Donna-AI (&amp;quot;Conna&amp;quot;AJ I
rErno Nani-J
Common Noun x (2)(3) (2) (2)(4)
r&amp;quot;Nani no&amp;quot;A1 I r&amp;quot;Nani no-AI I ni noAJ 1-&amp;quot;Naini no-AI
(A-no Nani-J 1-Donna-BJ I 1-13-no Nani-J
Proper Noun (2)(3)(4) (2)(4) (2)(4)
„ I-A-no Nani-J I 1-A&amp;quot;no Nani&amp;quot;J I r B&amp;quot;no Nani&amp;quot;J
(A&amp;quot;no Nae &amp;quot;j I--Donna-13_1 r-Nani no-Aj
</table>
<figure confidence="0.802994375">
&lt;qiad&gt;351&lt;/qaid&gt;
&lt;sqc&gt; Should I set CRT? &lt;/sqc&gt;.
&lt;sqc-new&gt; Should I set CRT for FMV-5133T3? &lt;sqc-
new&gt;
&lt;qald&gt;384&lt;/qaid&gt;
&lt;sqc&gt; The error occurs in &amp;quot;FUDEMAME.” &lt;/sqc&gt;
&lt;src-new&gt; The error occurs in the address list of
&amp;quot;FUDEMAME.&amp;quot; &lt;sqc-new&gt;
</figure>
<figureCaption confidence="0.878199">
Example 6: Examples of new simple questions
</figureCaption>
<bodyText confidence="0.999918">
At this time, the example of supplementing the
term is shown in example 6. (parts enclosed with
&lt;sqc-new&gt; are new simple questions).
The simple questions, which were low in rank
when searched by the simple questions of sqc
shown in Table 2, were reviewed along this flow.
</bodyText>
<page confidence="0.999867">
85
</page>
<tableCaption confidence="0.998029">
Table 13: Search result by this new sim le auestion (sac-new
</tableCaption>
<table confidence="0.996799142857143">
RankingiCondition by original simple questions by new simple questions
L3—one L3—all L3—one L3—all
Num. Rate Num. Rate Num. Rate Num. Rate
1st 248 49.7% 223 74.3% 346 69.3% 269 89.7%
2nd-10th 115 23.0% 51 17.0% 109 21.8% 24 8.0%
below 11th 136 27.3% 26 8.7% 44 8.8% 7 2.3%
499 100% 300 100% 499 100% 300 100%
</table>
<bodyText confidence="0.999886375">
Then, one term was added to the original sim-
ple question, and we experimented to determine
how much the search precision had improved.
Table 13 shows the comparison result. In Table
13, the ratio that wins the first place rose to about
20% in case of a single question and to about
15% in case of plural questions respectively. As
a result, the precision improvement of confirmed.
</bodyText>
<sectionHeader confidence="0.999777" genericHeader="method">
7 Future Work
</sectionHeader>
<bodyText confidence="0.941853">
The future works are shown below.
</bodyText>
<listItem confidence="0.854361">
(1) Absorption of difference of phrasing
</listItem>
<bodyText confidence="0.987617">
One of the causes of inability to navigate is a
mismatch of terms by the difference of nota-
tion or expression. To correct this, the search
by ontology is needed.
(2) Dealing with compound clause and embedded
clause
It is necessary to deal with compound clauses,
and embedded clauses, even though all the
simple questions used in this research were
simple sentences.
(3) Verification by mass data and real data
This time only the amount of about 10% of
those simple questions made were targeted
due to the limit of processing time. It is nec-
essary to put out the result of no bias by all
simple questions. Moreover, it is necessary to
obtain the first question that a user asks on an
actual scene, and to verify it by real data
though simple questions were made this time.
</bodyText>
<sectionHeader confidence="0.998288" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999992666666667">
In this experiment, a method was considered,
in which the expression of a simple doubt was
replaced with a simple question, and then previ-
ously recorded question and answer was retrieved.
We now understood that the terms that limited a
head or made it in detail were required when
navigating to the solution that the user is seeking.
And it was proposed how to draw out those terms
interactively, and its effectiveness was proven.
</bodyText>
<sectionHeader confidence="0.97299" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9927925">
We would like to express our sincere gratitude
to Dr. Takenobu Tokunaga, Tokyo Institute of
Technology, Ms. Minako Hashimoto in Fujitsu
Ltd. and everybody in Document Laboratory of
Fujitsu Laboratories Ltd, for their continuing
assistance and guidance.
</bodyText>
<sectionHeader confidence="0.998623" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9989475">
Weizenbaum, J. 1966, ELIZA —A computer program
for the study of natural language communication
between man and machine. Communications of the
ACM, 9(1) 36-45
R.N.Oddy, 1977. Information Retrieval through
Man-Machine Dialogue, The Journal of Documen-
tation, Vol.33, Number 1
Sadao Kurohashi and Wataru Higasa. 2000. Dia-
logue Helpsystem based on Flexible Matching of
User Query with Natural Language Knowledge
Base, In Proceedings of 1st ACL SIGdial Work-
shop on Discourse and Dialogue, pp.141-149
Robin D. Bruke. 1977, Question Answering from Fre-
quently-Asked Question Files: Experiences with
the FAQ Finder System, Technical Report TR-97-
05
Sanda M. Harabagiu. 2001, Just-In-Time Question
Answering, NLPRS-2001, pp. 27-34
Allen J.F. 1983. Recognizing Intentions from Natural
Language Utterances in Computational Models of
Discourse, MIT Press, pp.107-166
Harada, Shimizu 1997, Utilization of User Log on the
WWW Search Engine, IPSJ, 97-DPS-81, pp.61-66
Kunio Matsui, Isao Namba, Nobuyuki Igata. 2000,
Full-text Search Engine, The Technology of Infor-
mation and Science, Vol.50 No.1, (2000-1)
Sadao Kurohashi, Makoto Nagao. 1999. JUMAN ver-
sion 3.61(Manual), Kyoto University
</reference>
<page confidence="0.998563">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.662741">
<title confidence="0.9989475">The Interactive Navigation to the Stored Q&amp;A data using Simple Questions</title>
<author confidence="0.954004">Kunio MATSUI Hozumi TANAKA</author>
<affiliation confidence="0.780722">Fujitsu Laboratories Ltd. Tokyo Institute of Technology</affiliation>
<email confidence="0.869529">.kunio@jp.fujitsu.com</email>
<abstract confidence="0.99883">As an effort aimed at designing a system to save operator work at Call Centers, this research suggests directing users to Q&amp;A data stored in the call center by using naturally expressed questions (simple questions) received from users as a trigger. And, based on actual data, this research effort closely examines difference in accuracy when selecting methods for key terms, and the difference in accuracy when case elements are omitted. Our efforts showed that the term that limits or extends the heads of the sentence greatly influences the search accuracy. Accordingly, this paper presents an interactive navigation method for supplementing a term in accordance with a rule and improves its effectiveness.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Weizenbaum</author>
</authors>
<title>ELIZA —A computer program for the study of natural language communication between man and machine.</title>
<date>1966</date>
<journal>Communications of the ACM,</journal>
<volume>9</volume>
<issue>1</issue>
<pages>36--45</pages>
<contexts>
<context position="2640" citStr="Weizenbaum, 1966" startWordPosition="430" endWordPosition="431">le indicators into the situation confronting the user and can be used as a trigger. In this paper we will also examine the difference in the precision of creating methods for simple questions, the difference in the precision of selecting methods for key terms, and the difference in the precision when case elements are omitted. 2 Related Research While the ideal solution to the problem would be a computer that could answer user questions automatically, no such system is currently available and it is not clear as to when such a system will appear in the future. As a research of dialogue, ELIZA (Weizenbaum, 1966) is very famous but it is not developed for the purpose of user solution. Also the interactive information retrieval system (Oddy, 1977) is designed to give alternatives to the user, but it is difficult to reflect the user intention. As a research of Q&amp;A system, a helpdesk system for software products (Kurohashi et al, 2000) is now working on research based on FAQ Finder 79 (Bruke, 1997), but it is still confined to a limited field. At the same time, however, a method that uses previously stored question and answer data to provide responses to user questions is available. This method utilizes </context>
</contexts>
<marker>Weizenbaum, 1966</marker>
<rawString>Weizenbaum, J. 1966, ELIZA —A computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1) 36-45</rawString>
</citation>
<citation valid="true">
<authors>
<author>R N Oddy</author>
</authors>
<title>Information Retrieval through Man-Machine Dialogue,</title>
<date>1977</date>
<journal>The Journal of Documentation, Vol.33, Number</journal>
<volume>1</volume>
<contexts>
<context position="2776" citStr="Oddy, 1977" startWordPosition="452" endWordPosition="453">recision of creating methods for simple questions, the difference in the precision of selecting methods for key terms, and the difference in the precision when case elements are omitted. 2 Related Research While the ideal solution to the problem would be a computer that could answer user questions automatically, no such system is currently available and it is not clear as to when such a system will appear in the future. As a research of dialogue, ELIZA (Weizenbaum, 1966) is very famous but it is not developed for the purpose of user solution. Also the interactive information retrieval system (Oddy, 1977) is designed to give alternatives to the user, but it is difficult to reflect the user intention. As a research of Q&amp;A system, a helpdesk system for software products (Kurohashi et al, 2000) is now working on research based on FAQ Finder 79 (Bruke, 1997), but it is still confined to a limited field. At the same time, however, a method that uses previously stored question and answer data to provide responses to user questions is available. This method utilizes several approaches. One approach is a system where the operator mediates user inquiries and uses the system as a resource for finding th</context>
</contexts>
<marker>Oddy, 1977</marker>
<rawString>R.N.Oddy, 1977. Information Retrieval through Man-Machine Dialogue, The Journal of Documentation, Vol.33, Number 1</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Wataru Higasa</author>
</authors>
<title>Dialogue Helpsystem based on Flexible Matching of User Query with Natural Language Knowledge Base,</title>
<date>2000</date>
<booktitle>In Proceedings of 1st ACL SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>141--149</pages>
<marker>Kurohashi, Higasa, 2000</marker>
<rawString>Sadao Kurohashi and Wataru Higasa. 2000. Dialogue Helpsystem based on Flexible Matching of User Query with Natural Language Knowledge Base, In Proceedings of 1st ACL SIGdial Workshop on Discourse and Dialogue, pp.141-149</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin D Bruke</author>
</authors>
<title>Question Answering from Frequently-Asked Question Files: Experiences with the FAQ Finder System,</title>
<date>1977</date>
<tech>Technical Report TR-97-05</tech>
<marker>Bruke, 1977</marker>
<rawString>Robin D. Bruke. 1977, Question Answering from Frequently-Asked Question Files: Experiences with the FAQ Finder System, Technical Report TR-97-05</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
</authors>
<date>2001</date>
<booktitle>Just-In-Time Question Answering, NLPRS-2001,</booktitle>
<pages>27--34</pages>
<contexts>
<context position="3729" citStr="Harabagiu, 2001" startWordPosition="616" endWordPosition="617">that uses previously stored question and answer data to provide responses to user questions is available. This method utilizes several approaches. One approach is a system where the operator mediates user inquiries and uses the system as a resource for finding the answer to the question. In this case, system integrity is not a requirement because of the human mediation. And some are effectively working in the sense of assisting operators even though they may be imperfect. Alternatively, in some systems, the computer responds directly to the users. An example of such systems would be a system (Harabagiu, 2001) where a search question is replaced by creating a precise search query that may be used for QA task of TREC, and in another system(Robin, 1997) a planning question is replaced to clarify its goal by applying the world model and the user model in a limited world. The problem with the former is that the question itself is not realistic and storing all the Q&amp;A data costs a great deal. The problem with the latter is that creating the models costs too much for adopting to the rapidly changing real-world situations. In yet another method, the stored Q&amp;A data are utilized as FAQ to allow users to pe</context>
</contexts>
<marker>Harabagiu, 2001</marker>
<rawString>Sanda M. Harabagiu. 2001, Just-In-Time Question Answering, NLPRS-2001, pp. 27-34</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Recognizing Intentions from Natural Language Utterances in Computational Models of Discourse,</title>
<date>1983</date>
<pages>107--166</pages>
<publisher>MIT Press,</publisher>
<marker>Allen, 1983</marker>
<rawString>Allen J.F. 1983. Recognizing Intentions from Natural Language Utterances in Computational Models of Discourse, MIT Press, pp.107-166</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shimizu Harada</author>
</authors>
<date>1997</date>
<booktitle>Utilization of User Log on the WWW Search Engine, IPSJ, 97-DPS-81,</booktitle>
<pages>61--66</pages>
<contexts>
<context position="4491" citStr="Harada, 1997" startWordPosition="756" endWordPosition="757">anning question is replaced to clarify its goal by applying the world model and the user model in a limited world. The problem with the former is that the question itself is not realistic and storing all the Q&amp;A data costs a great deal. The problem with the latter is that creating the models costs too much for adopting to the rapidly changing real-world situations. In yet another method, the stored Q&amp;A data are utilized as FAQ to allow users to perform keyword search. However, a log survey of some internet search engine shows that 90% of users enter just one keyword for the first search step (Harada, 1997). This means it is hard to say that users are sufficiently utilizing this method as a search query even though there may be potential demands. In light of the situation described above, the research effort described in this paper works at the method of solving user questions by generating a query that extracts effective constituent elements of simple questions and navigates the user to the stored Q&amp;A, using &amp;quot;simple questions&amp;quot; that conform to the user&apos;s situation and that indicate the expression of natural questions. 3 Data and Evaluation Method 3.1 Q&amp;A at Call Center In this experiment, a grou</context>
</contexts>
<marker>Harada, 1997</marker>
<rawString>Harada, Shimizu 1997, Utilization of User Log on the WWW Search Engine, IPSJ, 97-DPS-81, pp.61-66</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kunio Matsui</author>
</authors>
<title>Isao Namba, Nobuyuki Igata.</title>
<date>2000</date>
<booktitle>The Technology of Information and Science, Vol.50 No.1,</booktitle>
<pages>2000--1</pages>
<marker>Matsui, 2000</marker>
<rawString>Kunio Matsui, Isao Namba, Nobuyuki Igata. 2000, Full-text Search Engine, The Technology of Information and Science, Vol.50 No.1, (2000-1)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>JUMAN version 3.61(Manual),</title>
<date>1999</date>
<institution>Kyoto University</institution>
<contexts>
<context position="10579" citStr="Kurohashi and Nagao, 1999" startWordPosition="1741" endWordPosition="1744">stored questions into several constituent elements making each element a simple question.&amp;quot;(Ex. 3) &lt;simple_q&gt; &lt;sq&gt;I want to record and reproduce audio. &lt;/sq&gt; &lt;sq&gt;I want to use an audio recorder with USB connec— tion.&lt;/sq&gt; &lt;sq&gt;Please let me know how to connect it with PC.&lt;/sq&gt; &lt;/simple_q&gt; Example 3 Simple Question of Constituent Elements 3.4 Retrieval Tool As a retrieval tool, the preceding sentence search engine (Matsui et al, 2000), which we have developed, was used to retrieve the questions rendered from simple questions. Simple questions for the query were morphologically analyzed by JUMAN (Kurohashi and Nagao, 1999) to select key terms to be used for retrieval. Selection of key terms is shown below. [Basis of selection of key terms used for retrieval] After the morphological analysis of simple questions, key terms are set so that they can be selected by the following part of speech. {Noun, Undefmed Word, Adjective, Verb, Adverb} Additionally, it can be selected from the level that expresses the head of case frame. For this, division and connection are defined as below, so that case frames are expressed. The charge partiUser Stored Stored Simple Questions Questions Answers Possibility of dialogues for the</context>
</contexts>
<marker>Kurohashi, Nagao, 1999</marker>
<rawString>Sadao Kurohashi, Makoto Nagao. 1999. JUMAN version 3.61(Manual), Kyoto University</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>