<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.054501">
<title confidence="0.922859">
CRF tagging for head recognition based on Stanford parser
</title>
<author confidence="0.973795">
Yong Cheng, Chengjie Sun, Bingquan Liu, Lei Lin
</author>
<affiliation confidence="0.967326">
Harbin Institute of Technology
</affiliation>
<email confidence="0.981476">
{ycheng, cjsun, linl,liubq}@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.997332" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99977025">
Chinese parsing has received more and
more attention, and in this paper, we use
toolkit to perform parsing on the data of
Tsinghua Chinese Treebank (TCT) used in
CIPS, and we use Conditional Random
Fields (CRFs) to train specific model for the
head recognition. At last, we compare
different results on different POS results.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997669583333333">
In the past decade, Chinese parsing has
received more and more attention, it is the
core of Chinese information processing
technology, and it is also the cornerstone for
deep understanding of Chinese.
Parsing is to identify automatically
syntactic units in the sentence and give the
relationship between these units. It is based
on a given grammar. The results of parsing
are usually structured syntax tree. For
example, the parsing result of sentence &amp;quot;rP
qk�KNNV is as following.
</bodyText>
<equation confidence="0.968645">
(ROOT
(dj (nS rPQ)
(vp (v ;9)
(np
(np (m &apos;) (n .VQN))
(n QjE)))))
</equation>
<bodyText confidence="0.999961823529411">
With the development of Chinese
economy, Chinese information processing
has become a worldwide hot spot, and
parsing is an essential task. However,
parsing is a recognized research problem,
and it is so difficult to meet the urgent needs
of industrial applications in accuracy,
robustness, speed. So the study of Chinese
grammar and syntax analysis algorithm are
still the focus of Chinese information
processing.
In all the parsing technology research,
English parsing research is the most in-depth,
and there are three main aspects of research
in statistical parsing, they are parsing model,
parsing algorithm, and corpus construction.
As for the parsing model, currently there are
four commonly used parsing models, PCFG
model [1], the model based on historical,
Hierarchical model of progressive, head-
driven model [2].
Since parsing is mostly a data driven
process, its performance is determined by
the amount of data in a Treebank on which a
parser is trained. Much more data for
English than for any other languages have
been available so far. Thus most researches
on parsing are concentrated on English. It is
unrealistic to directly apply any existing
parser trained on an English Treebank for
Chinese sentences. But the methodology is,
without doubt, highly applicable. Even for
those corpora with special format and
information integrated some modification
and enhancement on a well-performed parser
to fit the special structure for the data could
help to obtain a good performance.
This paper presents our solution for the
shared Task 2 of CIPS2010-Chinese Parsing.
We exploit an existing powerful parser,
Stanford parser, which has showed its
effectiveness on English, with necessary
modifications for parsing Chinese for the
shared task. Since the corpus used in CIPS is
from TCT, and the sentence contains the
head-word information, but for the Stanford
parser, it can&apos;t recognize the head
constituents. So we apply a sequence tagging
method to label head constituents based on
the data extracted from the TCT corpus, In
section 2 and section 3, we will present the
</bodyText>
<tableCaption confidence="0.999355">
Table 1. Training data with different formats
</tableCaption>
<table confidence="0.99898875">
1.(ROOT (np-0-2 (n 货币学派) (cC 及其) (np-
0-1 (n 政策 ) (n 主
张) ) ) )
2.(ROOT (vp-1 (pp-1 (p
对) (np-0-2 (np-1 (n 金
Parsing model 融) (n 政策) ) (cC 以
及 ) (np-2 (a 类 似 )
(uJDE 的) (np-1 (n 宏
观) (np-1 (n 经济) (n 政
策) ) ) ) ) ) (vp-1 (d 必
须) (vp-1 (d 重新) (v 估
价) ) ) ) )
1. 中国/nS 传统/a 医
学/n
2.中国/nS 是/vC 多/a
民族/n 国家/n ,/wP
POS model 中华/nR 民族/n 是/vC
50/m 多/m 个/qN
民族/n 的/uJDE 总称
/n 。/wE
Head-recognition a O n np 0
n a O np 1
model nS O np np 0
np nS O np 1
</table>
<bodyText confidence="0.997908933333333">
details of our approach, and In section 4, we
present the details of experiment.
these parsers to Tsinghua Chinese Treebank
(TCT) used in CIP, we firstly transform the
TCT training data into UPenn format. Then,
some slight modifications have been made to
the three parsers. So that they could fulfill
the needs in our task.
In our work, we use Stanford parser to
train our model by change the training data
to three parts with different formats, one for
training parsing model, one for training POS
model, and the last for training head-
recognition model. Table 1 shows the three
different forms.
</bodyText>
<sectionHeader confidence="0.992778" genericHeader="method">
3 Head recognition
</sectionHeader>
<bodyText confidence="0.999973411764706">
Head recognition is to find the head
word in a clause, for example, &apos;np-1&apos; express
that in the clause, the word with index &apos;1&apos; is
the key word.
To recognize the head constituents, and
extra step is needed since Stanford parsing
could not provide a straight forward way for
this. Consider that head constituents are
always determined by their syntactic symbol
and their neighbors, whose order and
relations strongly affects the head labeling.
Like chunking [9], it is natural to apply a
sequence labeling strategy to tackle this
problem. We adopt the linear-chain CRF
[10], one of the most successful sequence
labeling framework so far, for the head
recognition is this stage.
</bodyText>
<sectionHeader confidence="0.982158" genericHeader="method">
2 Parsing
</sectionHeader>
<bodyText confidence="0.9999552">
Since English parsing has made many
achievements, so we investigated some
statistical parsing models designed for
English. There are three open source
constituent parsers, Stanford parser [3],
Berkeley parser [4] and Bikel&apos;s parser [5].
Bikel&apos;s parser is an implementation of
Collins&apos; head-driven statistical model [6].
The Stanford parser is based on the factored
model described in [7]. Berkeley parser is
based on unlexicalized parsing model, as
described in [8].
All the three parsers are claimed to be
multilingual parsers but only accept training
data in UPenn Treebank format. To adapt
</bodyText>
<sectionHeader confidence="0.997871" genericHeader="conclusions">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.977722">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999964111111111">
The training data is from Tsinghua
Chinese Treebank (TCT), and our task is to
perform full parsing on them. There are
37218 lines in official released training data,
As the Table 1 show; we change the data
into three parts for different models.
The testing data doesn’t contain POS
labels, and there are 1000 lines in official
released testing data.
</bodyText>
<tableCaption confidence="0.941641">
Table 2. Different POS tagging results
</tableCaption>
<figure confidence="0.975118333333333">
original new
pos accuracy 80.40 94.82
number of word statistics number
&lt; 1 160
2 50834
3 12592
4 56
5 664
&gt;5 360
</figure>
<bodyText confidence="0.998486588235294">
And for head-word recognition, since the
adjacent clause has little effect on the
recognition of head-word, so we set the
clause as the smallest unit. We chose CRF to
train our model. However, for getting the
proper format of data for training in CRF,
We have to do further processing on the data.
As the table 3 shows, the final data set word
as the unit.
For example, the line &apos;n O np vp 1’, the
meaning from beginning to end is POS or
clause mark of current word or clause, POS
or clause mark of previous word, POS or
clause mark of latter word, the clause mark
of current word, and the last mean that if
current word or clause is headword 1
represents YES, 0 represents NO.
</bodyText>
<subsectionHeader confidence="0.890473">
4.4 Result and Conclusion
</subsectionHeader>
<bodyText confidence="0.909186875">
As we mention before, in evaluation, we
didn&apos;t train specific POS tagging model, So
we re-train our pos model, and the new
results is shown in table 6, it can be seen that,
with the increase of POS result, there is a
corresponding increase in the overall results.
Table 5. Performance of head recognition and
the template for model training
</bodyText>
<figure confidence="0.9992038">
Boundary + 70.58
Constituent
Boundary + 66.97
Constituent + Head
U00:%x[0,0]
U01:%x[-1,0]
U02:%x[1,0]
template U04:%x[0,0]/%x[-1,0]
U05:%x[0,0]/%x[1,0]
U06:%x[-1,0]/%x[1,0]
</figure>
<tableCaption confidence="0.872457">
Table 4. Statistics the frequency of the words in
each clause
</tableCaption>
<subsectionHeader confidence="0.8733825">
4.2 Models training
4.2.1 Parsing model training
</subsectionHeader>
<bodyText confidence="0.9994492">
As for training parsing model with
Stanford parser, since there are little
parameters need to set, so we directly use the
Stanford parser to train a model without any
parameter setting.
</bodyText>
<subsubsectionHeader confidence="0.803921">
4.2.2 POS model training
</subsubsectionHeader>
<bodyText confidence="0.999993529411765">
In this session of the evaluation, POS
tagging is no longer as a separate task, so we
have to train our own POS tagging model. In
the evaluation process, we didn&apos;t fully
consider the POS tagging results&apos; impact on
the overall results, so we didn&apos;t train the POS
model specially, we directly use the POS
function in Stanford parser toolkit. This has
led to relatively poor results in POS tagging,
and it also affects the overall parsing result.
After the evaluation, we train a specific
model to improve the POS tagging results.
As the table 1 shows, we extract training
data from the original corpus and adopt the
linear-chain CRF to train a POS tagging
model. Table 2 shows the original POS
tagging results and new results.
</bodyText>
<subsectionHeader confidence="0.644408">
4.2.3 Head recognition model training
</subsectionHeader>
<bodyText confidence="0.9879965">
As the table 1 shows, we extract specific
training data from original corpus.
</bodyText>
<tableCaption confidence="0.822353">
Table 3. Training data formats for Head-
recognition
</tableCaption>
<table confidence="0.977281111111111">
original corpus 1.[vp-0 减少/v [np-1
财政/n 收入/n ] ]
temp corpus 1.[np-1 财政/n 收入
/n ] [np-1
2.[vp-0 减少/v ]
财政/n 收入/n ]
final corpus n O n np 0
n n O np 1
v O np vp 1
np v O vp 0
labeling sequence data. In Proceedings of
ICML 2001, pages 282-289, Williams College,
Williamstown, MA, USA.
Table 6. Overall results on different POS results
POS Boundary +
Constituent
original 80.40 67.00
new 94.82 74.28
</table>
<bodyText confidence="0.9988565">
Through our evaluation results, we can
see that it is not appropriate to directly use
English parser toolkit to process Chinese.
And it is urgent to development parsing
model based on the characteristics of
Chinese.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999345">
[1] T. L. Booth and R. A. Thompson. Applying
Probability Measures to Abstract Languages.
IEEE Transactions on Computers, 1973, C-
22(5):422-450.
[2] M. Collins. Three Generative, Lexicalised
Models for Statistical Parsing. In Proceedings
of the 35th annual meeting of the association
for computational linguistics.
[3] http://nlp.stanford.edu/software/lex-parser.html
[4] http://code.google.com/p/berkeleyparser
[5] http://www.cis.upenn.edu/~dbikel/download
[6] Michael Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis.
University of Pennsylvania.
[7] Dan Klein and Christopher D. Manning
Accurate unlixicalized parsing. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics.
[8] S Petrov and D Klein. Improved inference for
unlexicalized parsing. In Proceedings of
NAACL HLT 2007.
[9] Fei Sha and Fernando Pereira. 2003. Shallow
parsing with conditional random fields. In
Proceedings of HLT-NAACL 2003, pages
213-220, Edmonton. Canada.
[10] John Lafferty. Andrew McCallum. And
Fernando Pereira. 2001. Conditional random
fields: Probabilistic models for segmenting and
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.722276">
<title confidence="0.824913">CRF tagging for head recognition based on Stanford parser</title>
<author confidence="0.992442">Yong Cheng</author>
<author confidence="0.992442">Chengjie Sun</author>
<author confidence="0.992442">Bingquan Liu</author>
<author confidence="0.992442">Lei</author>
<affiliation confidence="0.995597">Harbin Institute of</affiliation>
<email confidence="0.90298">ycheng@insun.hit.edu.cn</email>
<email confidence="0.90298">cjsun@insun.hit.edu.cn</email>
<email confidence="0.90298">linl@insun.hit.edu.cn</email>
<email confidence="0.90298">liubq@insun.hit.edu.cn</email>
<abstract confidence="0.995015">Chinese parsing has received more and more attention, and in this paper, we use toolkit to perform parsing on the data of Tsinghua Chinese Treebank (TCT) used in CIPS, and we use Conditional Random Fields (CRFs) to train specific model for the head recognition. At last, we compare different results on different POS results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T L Booth</author>
<author>R A Thompson</author>
</authors>
<title>Applying Probability Measures to Abstract Languages.</title>
<date>1973</date>
<journal>IEEE Transactions on Computers,</journal>
<pages>22--5</pages>
<contexts>
<context position="1812" citStr="[1]" startWordPosition="284" endWordPosition="284">al task. However, parsing is a recognized research problem, and it is so difficult to meet the urgent needs of industrial applications in accuracy, robustness, speed. So the study of Chinese grammar and syntax analysis algorithm are still the focus of Chinese information processing. In all the parsing technology research, English parsing research is the most in-depth, and there are three main aspects of research in statistical parsing, they are parsing model, parsing algorithm, and corpus construction. As for the parsing model, currently there are four commonly used parsing models, PCFG model [1], the model based on historical, Hierarchical model of progressive, headdriven model [2]. Since parsing is mostly a data driven process, its performance is determined by the amount of data in a Treebank on which a parser is trained. Much more data for English than for any other languages have been available so far. Thus most researches on parsing are concentrated on English. It is unrealistic to directly apply any existing parser trained on an English Treebank for Chinese sentences. But the methodology is, without doubt, highly applicable. Even for those corpora with special format and informa</context>
<context position="7210" citStr="[1,0]" startWordPosition="1234" endWordPosition="1234">r word, the clause mark of current word, and the last mean that if current word or clause is headword 1 represents YES, 0 represents NO. 4.4 Result and Conclusion As we mention before, in evaluation, we didn&apos;t train specific POS tagging model, So we re-train our pos model, and the new results is shown in table 6, it can be seen that, with the increase of POS result, there is a corresponding increase in the overall results. Table 5. Performance of head recognition and the template for model training Boundary + 70.58 Constituent Boundary + 66.97 Constituent + Head U00:%x[0,0] U01:%x[-1,0] U02:%x[1,0] template U04:%x[0,0]/%x[-1,0] U05:%x[0,0]/%x[1,0] U06:%x[-1,0]/%x[1,0] Table 4. Statistics the frequency of the words in each clause 4.2 Models training 4.2.1 Parsing model training As for training parsing model with Stanford parser, since there are little parameters need to set, so we directly use the Stanford parser to train a model without any parameter setting. 4.2.2 POS model training In this session of the evaluation, POS tagging is no longer as a separate task, so we have to train our own POS tagging model. In the evaluation process, we didn&apos;t fully consider the POS tagging results&apos; im</context>
</contexts>
<marker>[1]</marker>
<rawString>T. L. Booth and R. A. Thompson. Applying Probability Measures to Abstract Languages. IEEE Transactions on Computers, 1973, C22(5):422-450.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Collins</author>
</authors>
<title>Three Generative, Lexicalised Models for Statistical Parsing.</title>
<booktitle>In Proceedings of the 35th annual</booktitle>
<contexts>
<context position="1900" citStr="[2]" startWordPosition="297" endWordPosition="297">et the urgent needs of industrial applications in accuracy, robustness, speed. So the study of Chinese grammar and syntax analysis algorithm are still the focus of Chinese information processing. In all the parsing technology research, English parsing research is the most in-depth, and there are three main aspects of research in statistical parsing, they are parsing model, parsing algorithm, and corpus construction. As for the parsing model, currently there are four commonly used parsing models, PCFG model [1], the model based on historical, Hierarchical model of progressive, headdriven model [2]. Since parsing is mostly a data driven process, its performance is determined by the amount of data in a Treebank on which a parser is trained. Much more data for English than for any other languages have been available so far. Thus most researches on parsing are concentrated on English. It is unrealistic to directly apply any existing parser trained on an English Treebank for Chinese sentences. But the methodology is, without doubt, highly applicable. Even for those corpora with special format and information integrated some modification and enhancement on a well-performed parser to fit the </context>
</contexts>
<marker>[2]</marker>
<rawString>M. Collins. Three Generative, Lexicalised Models for Statistical Parsing. In Proceedings of the 35th annual meeting of the association for computational linguistics.</rawString>
</citation>
<citation valid="false">
<note>http://nlp.stanford.edu/software/lex-parser.html</note>
<contexts>
<context position="5138" citStr="[3]" startWordPosition="871" endWordPosition="871">his. Consider that head constituents are always determined by their syntactic symbol and their neighbors, whose order and relations strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Tab</context>
</contexts>
<marker>[3]</marker>
<rawString>http://nlp.stanford.edu/software/lex-parser.html</rawString>
</citation>
<citation valid="false">
<note>http://code.google.com/p/berkeleyparser</note>
<contexts>
<context position="5159" citStr="[4]" startWordPosition="874" endWordPosition="874">ad constituents are always determined by their syntactic symbol and their neighbors, whose order and relations strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Table 1 show; we change </context>
</contexts>
<marker>[4]</marker>
<rawString>http://code.google.com/p/berkeleyparser</rawString>
</citation>
<citation valid="false">
<note>http://www.cis.upenn.edu/~dbikel/download</note>
<contexts>
<context position="5182" citStr="[5]" startWordPosition="878" endWordPosition="878">ays determined by their syntactic symbol and their neighbors, whose order and relations strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Table 1 show; we change the data into three par</context>
</contexts>
<marker>[5]</marker>
<rawString>http://www.cis.upenn.edu/~dbikel/download</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis.</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="5265" citStr="[6]" startWordPosition="889" endWordPosition="889">ions strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Table 1 show; we change the data into three parts for different models. The testing data doesn’t contain POS labels, and there are</context>
</contexts>
<marker>[6]</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis. University of Pennsylvania.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dan Klein</author>
<author>D Christopher</author>
</authors>
<title>Manning Accurate unlixicalized parsing.</title>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5334" citStr="[7]" startWordPosition="901" endWordPosition="901">ural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Table 1 show; we change the data into three parts for different models. The testing data doesn’t contain POS labels, and there are 1000 lines in official released testing data. Table 2. Different POS</context>
</contexts>
<marker>[7]</marker>
<rawString>Dan Klein and Christopher D. Manning Accurate unlixicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT</booktitle>
<contexts>
<context position="5412" citStr="[8]" startWordPosition="913" endWordPosition="913">e linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three parsers are claimed to be multilingual parsers but only accept training data in UPenn Treebank format. To adapt 4 Experiment 4.1 Data The training data is from Tsinghua Chinese Treebank (TCT), and our task is to perform full parsing on them. There are 37218 lines in official released training data, As the Table 1 show; we change the data into three parts for different models. The testing data doesn’t contain POS labels, and there are 1000 lines in official released testing data. Table 2. Different POS tagging results original new pos accuracy 80.40 94.82 number of word statisti</context>
</contexts>
<marker>[8]</marker>
<rawString>S Petrov and D Klein. Improved inference for unlexicalized parsing. In Proceedings of NAACL HLT 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Sha</author>
<author>Fernando Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL 2003,</booktitle>
<pages>213--220</pages>
<location>Edmonton. Canada.</location>
<contexts>
<context position="4720" citStr="[9]" startWordPosition="806" endWordPosition="806">model, one for training POS model, and the last for training headrecognition model. Table 1 shows the three different forms. 3 Head recognition Head recognition is to find the head word in a clause, for example, &apos;np-1&apos; express that in the clause, the word with index &apos;1&apos; is the key word. To recognize the head constituents, and extra step is needed since Stanford parsing could not provide a straight forward way for this. Consider that head constituents are always determined by their syntactic symbol and their neighbors, whose order and relations strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model de</context>
</contexts>
<marker>[9]</marker>
<rawString>Fei Sha and Fernando Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of HLT-NAACL 2003, pages 213-220, Edmonton. Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>And Fernando Pereira.</title>
<date>2001</date>
<contexts>
<context position="4832" citStr="[10]" startWordPosition="825" endWordPosition="825">ferent forms. 3 Head recognition Head recognition is to find the head word in a clause, for example, &apos;np-1&apos; express that in the clause, the word with index &apos;1&apos; is the key word. To recognize the head constituents, and extra step is needed since Stanford parsing could not provide a straight forward way for this. Consider that head constituents are always determined by their syntactic symbol and their neighbors, whose order and relations strongly affects the head labeling. Like chunking [9], it is natural to apply a sequence labeling strategy to tackle this problem. We adopt the linear-chain CRF [10], one of the most successful sequence labeling framework so far, for the head recognition is this stage. 2 Parsing Since English parsing has made many achievements, so we investigated some statistical parsing models designed for English. There are three open source constituent parsers, Stanford parser [3], Berkeley parser [4] and Bikel&apos;s parser [5]. Bikel&apos;s parser is an implementation of Collins&apos; head-driven statistical model [6]. The Stanford parser is based on the factored model described in [7]. Berkeley parser is based on unlexicalized parsing model, as described in [8]. All the three pars</context>
</contexts>
<marker>[10]</marker>
<rawString>John Lafferty. Andrew McCallum. And Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>