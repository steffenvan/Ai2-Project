<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000025">
<title confidence="0.96691">
Joint Morphological and Syntactic Analysis for Richly Inflected Languages
</title>
<author confidence="0.997602">
Bernd Bohnet* Joakim Nivre* Igor Boguslavsky` Rich´ard Farkas* Filip Ginter† Jan Hajiˇc$
</author>
<affiliation confidence="0.981557142857143">
*University of Birmingham, School of Computer Science
*Uppsala University, Department of Linguistics and Philology
*Universidad Polit´ecnica de Madrid, Departamento de Inteligencia Artificial
&apos;Russian Academy of Sciences, Institute for Information Transmission Problems
*University of Szeged, Institute of Informatics
†University of Turku, Department of Information Technology
$Charles University in Prague, Institute of Formal and Applied Linguistics
</affiliation>
<sectionHeader confidence="0.987962" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994587">
Joint morphological and syntactic analysis has
been proposed as a way of improving parsing
accuracy for richly inflected languages. Start-
ing from a transition-based model for joint
part-of-speech tagging and dependency pars-
ing, we explore different ways of integrating
morphological features into the model. We
also investigate the use of rule-based mor-
phological analyzers to provide hard or soft
lexical constraints and the use of word clus-
ters to tackle the sparsity of lexical features.
Evaluation on five morphologically rich lan-
guages (Czech, Finnish, German, Hungarian,
and Russian) shows consistent improvements
in both morphological and syntactic accuracy
for joint prediction over a pipeline model, with
further improvements thanks to lexical con-
straints and word clusters. The final results
improve the state of the art in dependency
parsing for all languages.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999744533333333">
Syntactic parsing of natural language has witnessed
a tremendous development during the last twenty
years, especially through the use of statistical mod-
els for robust and accurate broad-coverage parsing.
However, as statistical parsing techniques have been
applied to more and more languages, it has also
been observed that typological differences between
languages lead to new challenges. In particular, it
has been found over and over again that languages
exhibiting rich morphological structure, often to-
gether with a relatively free word order, usually ob-
tain lower parsing accuracy, especially in compar-
ison to English. One striking demonstration of this
tendency can be found in the CoNLL shared tasks on
multilingual dependency parsing, organized in 2006
and 2007, where richly inflected languages clustered
at the lower end of the scale with respect to pars-
ing accuracy (Buchholz and Marsi, 2006; Nivre et
al., 2007). These and similar observations have led
to an increased interest in the special challenges
posed by parsing morphologically rich languages,
as evidenced most clearly by a new series of work-
shops devoted to this topic (Tsarfaty et al., 2010), as
well as a special issue in Computational Linguistics
(Tsarfaty et al., 2013) and a shared task on parsing
morphologically rich languages.1
One hypothesized explanation for the lower pars-
ing accuracy observed for richly inflected languages
is the strict separation of morphological and syn-
tactic analysis assumed in many parsing frame-
works (Tsarfaty et al., 2010; Tsarfaty et al., 2013).
This is true in particular for data-driven dependency
parsers, which tend to assume that all morphological
disambiguation has been performed before syntactic
analysis begins. However, as argued by Lee et al.
(2011), in morphologically rich languages there is
often considerable interaction between morphology
and syntax, such that neither can be disambiguated
without the other. Lee et al. (2011) go on to show
that a discriminative model for joint morphological
disambiguation and dependency parsing gives con-
sistent improvements in morphological and syntac-
tic accuracy, compared to a pipeline model, for An-
cient Greek, Czech, Hungarian and Latin. Simi-
larly, Bohnet and Nivre (2012) propose a model for
</bodyText>
<footnote confidence="0.991291">
1See https://sites.google.com/site/spmrl2013/home/sharedtask.
</footnote>
<page confidence="0.963433">
415
</page>
<bodyText confidence="0.978234053571429">
Transactions of the Association for Computational Linguistics, 1 (2013) 415–428. Action Editor: Brian Roark.
Submitted 7/2013; Revised 9/2013; Published 10/2013. c�2013 Association for Computational Linguistics.
joint part-of-speech tagging and dependency parsing
and report improved accuracy for Czech and Ger-
man (but also for Chinese and English), although in
this case the joint model is limited to basic part-of-
speech tags and does not involve the full complex
of morphological features. An integrated approach
to morphological and syntactic analysis can also
be found in grammar-based dependency parsers,
such as the ETAP-3 linguistic processor (Apresian
et al., 2003), where morphological disambiguation
is mostly carried out together with syntactic anal-
ysis. Finally, it is worth noting that joint models
of morphology and syntax have been more popu-
lar in constituency-based statistical parsing (Cowan
and Collins, 2005; Tsarfaty, 2006; Cohen and Smith,
2007; Goldberg and Tsarfaty, 2008).
Another hypothesis from the literature is that the
high type-token ratio resulting from large morpho-
logical paradigms leads to data sparseness when es-
timating the parameters of a statistical parsing model
(Tsarfaty et al., 2010; Tsarfaty et al., 2013). In par-
ticular, for many words in the language, only a sub-
set of its morphological forms will be observed at
training time. This suggests that using rule-based
morphological analyzers or other lexical resources
may be a viable strategy to improve coverage and
performance. Thus, Goldberg and Elhadad (2013)
show that integrating an external wide-coverage lex-
icon with a treebank-trained PCFG parser improves
parsing accuracy for Modern Hebrew, which is in
line with earlier studies of part-of-speech tagging for
morphologically rich languages (Hajiˇc, 2000). The
sparsity of lexical features can also be tackled by the
use of distributional word clusters as pioneered by
Koo et al. (2008).
In this paper, we present a transition-based model
that jointly predicts complex morphological repre-
sentations and dependency relations, generalizing
the approach of Bohnet and Nivre (2012) to include
the full range of morphological information. We
start by investigating different ways of integrating
morphological features into the model, go on to ex-
amine the effect of using rule-based morphological
analyzers to derive hard or soft constraints on the
morphological analysis, and finally add word clus-
ter features to combat lexical sparsity. We evalu-
ate our methods on data from Czech, Finnish, Ger-
man, Hungarian, and Russian, five morphologically
rich languages representing three different language
groups. The experiments show that joint prediction
of morphology and syntax, rule-based morpholog-
ical analyzers, and word clusters all contribute to
improved parsing accuracy, leading to new state-of-
the-art results for all languages.
</bodyText>
<sectionHeader confidence="0.980352" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.999856333333333">
In this section, we define target representations and
evaluation metrics (2.1), and describe our transition-
based parsing framework, consisting of an abstract
transition system (2.2), a feature-based scoring func-
tion (2.3), and algorithms for decoding (2.4) and
learning (2.5).
</bodyText>
<subsectionHeader confidence="0.96085">
2.1 Representations and Metrics
</subsectionHeader>
<bodyText confidence="0.995789451612903">
We take an unlabeled dependency tree for a sentence
x = w1, ... , wn to be a directed tree T = (Vx, A),
where Vx = {0, 1, ..., n}, A C_ Vx x Vx+, and 0 is
the root of the tree (K¨ubler et al., 2009). The set Vx
of nodes is the set of positive integers up to and in-
cluding n, each corresponding to the linear position
of a word in the sentence, plus an extra artificial root
node 0. We use Vx+ to denote Vx −{0}. The set A of
arcs is a set of pairs (i, j), where i is the head node
and j is the dependent node.
To this basic representation of syntactic structure
we add four labeling functions for part-of-speech
tags, morphological features, lemmas, and depen-
dency relations. The function 7r : Vx+ -+ P maps
each node in Vx+ to a part-of-speech tag in the set
P; the function p : Vx+ -+ M maps each node to a
morphological description in the set M; the function
λ : Vx+ -+ Z∗ maps each node in Vx+ to a lemma
(a string over some character set Z); and the func-
tion 6 : A -+ D maps each arc to a dependency
label in the set D. The exact nature of P, M and D
depends on the data sets used, but normally P and
D only contain atomic labels while the members of
M are sets of atomic features encoding properties
like number, case, tense, etc. For lemmas, we do not
assume that there is a fixed lexicon but allow any
character string as a legal value.
We define our target representation for a sentence
x = w1, ... , wn as a quintuple F = (A, 7r, p, λ, 6)
such that (Vx, A) is an unlabeled dependency tree;
7r, p and λ label the nodes with part-of-speech tags,
</bodyText>
<page confidence="0.994754">
416
</page>
<subsectionHeader confidence="0.354033">
Transition Condition
</subsectionHeader>
<equation confidence="0.974395">
LEFT-ARCd ([σ|i, j], B, Γ) ==&gt; ([σ|j], B, Γ[(j, i)EA, δ(j, i)=d]) i =7� 0
RIGHT-ARCd ([σ|i, j], B, Γ) ==&gt; ([σ|i], B, Γ[(i, j)EA, δ(i, j)=d])
SHIFTp,m,l (σ, [i|β],Γ) ==&gt; ([σ|i], β,Γ[π(i)=p,µ(i)=m,λ(i)=l])
SWAP ([σ|i, j],β, Γ) ==&gt; ([σ|j], [i|β], Γ) 0 &lt; i &lt; j
</equation>
<figureCaption confidence="0.956694333333333">
Figure 1: Transitions for joint morphological and syntactic analysis. The stack Σ is represented as a list with its head
to the right (and tail σ) and the buffer B as a list with its head to the left (and tail β). The notation Γ[q1, ... , q,..] is
used to denote an MS-parse that is exactly like Γ except that ql, ... , q,,,, hold true.
</figureCaption>
<bodyText confidence="0.999513166666667">
morphological features and lemmas; and δ labels the
arcs with dependency relations. For convenience,
we refer to this type of structure as a morphosyn-
tactic parse (or MS-parse, for short). The follow-
ing evaluation metrics are used to score an MS-parse
with respect to a gold standard:
</bodyText>
<listItem confidence="0.936402947368421">
1. POS: The percentage of nodes in Vx+ that have
the correct part-of-speech tag.
2. MOR: The percentage of nodes in Vx+ that have
the correct morphological description; if the
description is set-valued, all members of the set
must match exactly.
3. LEM: The percentage of nodes in Vx+ that have
the correct lemma.
4. UAS: The percentage of nodes in Vx+ that have
the correct incoming arc.
5. LAS: The percentage of nodes in Vx+ that have
the correct incoming arc with the correct label.
6. PM: The percentage of nodes in Vx+ that have
the correct part-of-speech tag and the correct
morphological description.
7. PMD: The percentage of nodes in Vx+ that have
the correct part-of-speech tag, the correct mor-
phological description, and the correct incom-
ing arc with the correct label.
</listItem>
<bodyText confidence="0.92148375">
The POS, UAS and LAS metrics are standard in the
dependency parsing literature; the additional met-
rics will provide us with a more fine-grained pic-
ture of the (joint) morphological and syntactic accu-
racy. All evaluation scores are computed over all to-
kens, including punctuation. We test statistical sig-
nificance primarily for the PMD metric, using a two-
tailed paired t-test.
</bodyText>
<subsectionHeader confidence="0.999686">
2.2 Transition System
</subsectionHeader>
<bodyText confidence="0.999631657142857">
A transition system for dependency parsing is a
quadruple S = (C, T, cs, Ct), where C is a set
of configurations, T is a set of transitions, each of
which is a (partial) function t : C -+ C, cs is an ini-
tialization function, mapping a sentence x to a con-
figuration c E C, and Ct C_ C is a set of terminal
configurations. A transition sequence for a sentence
x in S is a sequence of configuration-transition pairs
C0,m = [(c0, t0), (c1, t1), ... , (cm, tm)] where c0 =
cs(x), tm(cm) E Ct, and ti(ci) = ci+1(0 &lt; i &lt; m).
In our model for joint prediction of part-of-speech
tags, morphological features and dependency trees,
the set C of configurations consists of all triples
c = (Σ, B, Γ) such that Σ (the stack) and B
(the buffer) are disjoint sublists of the nodes Vx
of some sentence x, and Γ = (A, π, µ, λ, δ) is
an MS-parse for x. We take the initial config-
uration for a sentence x = w1, ... , wn to be
cs(x) = ([0], [1, ... , n], (�, L, L, L, L)), where
L is the function that is undefined for all argu-
ments, and we take the set Ct of terminal config-
urations to be the set of all configurations of the
form c = ([0], [ ], Γ) (for any Γ). The MS-parse de-
fined for x by c = (Σ, B, (A, π, µ, λ, δ)) is Γc =
(A, π, µ, λ, δ), and the MS-parse defined for x by a
complete transition sequence C0,m is Γt.(c.).
The set T of transitions is shown in Figure 1. It
is based on the system of Nivre (2009), where a de-
pendency tree is built by repeated applications of the
LEFT-ARCd and RIGHT-ARCd transitions, which
add an arc (with some label d E D) between the
two topmost nodes on the stack (with the leftmost
or rightmost node as the dependent, respectively).
The SHIFT transition is used to move nodes from the
buffer to the stack, and the SWAP transition is used
</bodyText>
<page confidence="0.996966">
417
</page>
<bodyText confidence="0.999884928571429">
to permute nodes in order to allow non-projective
dependencies. Bohnet and Nivre (2012) modified
this system by replacing the simple SHIFT transition
by SHIFTp, which not only moves a node from the
buffer to the stack but also assigns it a part-of-speech
tag p, turning it into a system for joint part-of-speech
tagging and dependency parsing.2 Here we add two
additional parameters m and l to the SHIFT transi-
tion, so that a node moved from the buffer to the
stack is assigned not only a tag p but also a morpho-
logical description m and a lemma l. In this way,
we get a joint model for the prediction of part-of-
speech tags, morphological features, lemmas, and
dependency trees.
</bodyText>
<subsectionHeader confidence="0.998621">
2.3 Scoring
</subsectionHeader>
<bodyText confidence="0.99922225">
In transition-based parsing, we score parses in an in-
direct fashion by scoring transition sequences. In
general, we assume that the score function s factors
by configuration-transition pairs:
</bodyText>
<equation confidence="0.994087">
m
s(x, C0,m) = E s(x, ci, ti) (1)
i=0
</equation>
<bodyText confidence="0.9997348">
Moreover, when using structured learning, as first
proposed for transition-based parsing by Zhang and
Clark (2008), we assume that the score is given by a
linear model whose feature representations decom-
pose in the same way:
</bodyText>
<equation confidence="0.99798425">
s(x, C0,m) = f(x, C0,m) · w (2)
m
E f(x, ci, ti) · w
i=0
</equation>
<bodyText confidence="0.998548125">
Here, f(x, c, t) is a high-dimensional feature vec-
tor, where each component fi(x, c, t) is a nonneg-
ative numerical feature (usually binary), and w is
a weight vector of the same dimensionality, where
each component wi is the real-valued weight of the
feature fi(x, c, t). The choice of features to include
in f(x, c, t) is discussed separately for each instanti-
ation of the model in Sections 4–6.
</bodyText>
<footnote confidence="0.8583955">
2Hatori et al. (2011) previously made the same modifica-
tion to the arc-standard system (Nivre, 2004), without the SWAP
transition. Similarly, Titov and Henderson (2007) added a word
parameter to the SHIFT transition to get a joint model of word
strings and dependency trees. A similar model was considered
but finally not used by Gesmundo et al. (2009).
</footnote>
<subsectionHeader confidence="0.996735">
2.4 Decoding
</subsectionHeader>
<bodyText confidence="0.999992028571429">
Exact decoding for transition-based parsing is hard
in general.3 Early transition-based parsers mostly
relied on greedy, deterministic decoding, which
makes for very efficient parsing (Yamada and Mat-
sumoto, 2003; Nivre, 2003), but research has shown
that accuracy can be improved by using beam search
instead (Zhang and Clark, 2008; Zhang and Nivre,
2012). While still not exact, beam search decoders
explore a larger part of the search space than greedy
parsers, which is likely to be especially important
for joint models, where the search space is larger
than for plain dependency parsing without morphol-
ogy (even more so with the SWAP transition for non-
projectivity). Figure 2 outlines the beam search al-
gorithm used for decoding with our model. Differ-
ent instantiations of the model will require slightly
different implementations of the permissibility con-
dition invoked in line 8, which can be used to filter
out labels that are improbable or incompatible with
an external lexicon, and the pruning step performed
in line 13, where there may be a need to balance the
amount of morphological and syntactic variation in
the beam. Both these aspects will be discussed in
depth in Sections 4–6.
Although the worst-case running time with con-
stant beam size is quadratic in sentence length, the
observed running time is linear for natural language
data sets, due to the sparsity of non-projective de-
pendencies (Nivre, 2009). The running time is also
linear in |D |+ |P x M|, which means that joint pre-
diction only gives a linear increase in running time,
often quite marginal because |D |&gt; |P x M|. This
assumes that the lemma is predicted deterministi-
cally given a tag and a morphological description, an
assumption that is enforced in all our experiments.
</bodyText>
<subsectionHeader confidence="0.996698">
2.5 Learning
</subsectionHeader>
<bodyText confidence="0.9995022">
In order to learn a weight vector w from a training
set of sentences with gold parses, we use a variant
of the structured perceptron, introduced by Collins
(2002) and first used for transition-based parsing by
Zhang and Clark (2008). We initialize all weights
</bodyText>
<footnote confidence="0.456942">
3While there exist exact dynamic programming algorithms
for projective transition systems (Huang and Sagae, 2010;
Kuhlmann et al., 2011) and even for restricted non-projective
systems (Cohen et al., 2011), parsing is intractable for systems
like ours that permit arbitrary non-projective trees.
</footnote>
<page confidence="0.980536">
418
</page>
<figure confidence="0.9932935">
PARSE(x, w)
1 h0.c cs(x)
2 h0.s 0.0
3 h0.f 10.01dim(w)
4 BEAM [h0]
5 while ]h E BEAM: h.c E� Ct
6 TMP [ ]
7 foreach h E BEAM
8 foreach t E T : PERMISSIBLE(h.c, t)
9 h.f h.f + f(x, h.c, t)
10 h.s h.s + f(x, h.c, t) · w
11 h.c t(h.c)
12 TMP INSERT(h, TMP)
13 BEAM PRUNE(TMP)
14 h∗ TOP(BEAM)
15 return rh∗
</figure>
<figureCaption confidence="0.9957404">
Figure 2: Beam search algorithm for finding the best MS-
parse for input sentence x with weight vector w. The
symbols h.c, h.s and h.f denote, respectively, the con-
figuration, score and feature vector of a hypothesis h; r,
denotes the MS-parse defined by c.
</figureCaption>
<bodyText confidence="0.9991875">
to 0.0, make N iterations over the training data and
update the weight vector for every sentence x where
the transition sequence C0,m corresponding to the
gold parse is different from the highest scoring tran-
sition sequence C∗0,m,.4 More precisely, we use the
passive-aggressive update of Crammer et al. (2006).
We also use the early update strategy found benefi-
cial for parsing in several previous studies (Collins
and Roark, 2004; Zhang and Clark, 2008; Huang
and Sagae, 2010). This means that, at learning
time, we terminate the beam search as soon as the
hypothesis corresponding to the gold parse is pruned
from the beam and then update with respect to the
partial transition sequences constructed up to that
point. Finally, we use the standard technique of av-
eraging over all weight vectors seen in training, as
originally proposed by Collins (2002).
4Note that there may be more than one transition sequence
corresponding to the gold parse, in which case we pick the
canonical transition sequence that processes all left-dependents
before right-dependents and applies the lazy swapping strategy
of Nivre et al. (2009).
</bodyText>
<sectionHeader confidence="0.809184" genericHeader="method">
3 Data Sets and Resources
</sectionHeader>
<bodyText confidence="0.999954902439025">
Throughout the paper, we experiment with data from
five languages: Czech, Finnish, German, Hungarian,
and Russian. For each language, we use a morpho-
logically and syntactically annotated corpus (tree-
bank), divided into a training set, a development set
and a test set. In addition, we use a lexicon gen-
erated by a rule-based morphological analyzer, and
distributional word clusters derived from a large un-
labeled corpus. Below we describe the specific re-
sources used for each language. Table 1 provides
descriptive statistics about the resources.
Czech For training and test we use the Prague De-
pendency Treebank (Hajiˇc et al., 2001; B¨ohmov´a et
al., 2003), Version 2.5, converted to the format used
in the CoNLL 2009 shared task (Hajiˇc et al., 2009).
The morphological lexicon comes from Hajiˇc and
Hladk´a (1998),5 and word clusters are derived from
a large web corpus (Spoustov´a and Spousta, 2012).
Finnish The training set is from the Turku Depen-
dency Treebank (Haverinen et al., 2013), and the test
set is the hidden test set maintained by the treebank
developers. It is worth noting that, while the entire
treebank has manually validated syntactic annota-
tion, the morphological annotation is automatic ex-
cept for a subset of 1204 tokens in the test set, which
will be used to estimate the POS, MOR, LEM, PM
and PMD scores. The estimated accuracy of the
automatic annotation is 97.3% POS and 94.8% PM
(Haverinen et al., 2013). Also, because of the lim-
ited amount of data, we do not use a development
set for Finnish but instead use cross-validation on
the training set when tuning parameters. We use the
open-source morphological analyzer OMorFi (Piri-
nen, 2011) and word clusters derived from the entire
Finnish Wikipedia.6
German Training and test sets are from the Tiger
Treebank (Brants et al., 2002) in the improved de-
pendency conversion by Seeker et al. (2010). We
use the SMOR morphological analyzer (Schmid et
al., 2004), but because the tags and morphological
features in the lexicon are not the same as in the
</bodyText>
<footnote confidence="0.999956333333333">
5Downloaded from the http://lindat.cz repository as resource
PID http://hdl.handle.net/11858/00-097C-0000-0015-A780-9.
6Downloaded in March 2012.
</footnote>
<page confidence="0.993016">
419
</page>
<table confidence="0.999686142857143">
Treebank Morphology Clusters
Train Dev Test P M D Forms Lemmas Tokens Types
Czech 652,544 87,988 70,348 12 1851 49 98,360 42,058 628,332,859 477,185
Finnish 183,118 – 21,211 12 1917 47 57,127 25,280 50,207,300 257,984
German 648,296 32,065 31,692 54 257 43 76,729 55,220 1,327,701,182 1,621,083
Hungarian 1,101,871 210,068 171,466 22 1105 33 151,971 71,263 200,249,814 538,138
Russian 575,400 72,893 71,664 14 454 78 97,905 35,039 195,897,041 639,446
</table>
<tableCaption confidence="0.973027666666667">
Table 1: Statistics about data sets and resources used in the experiments. Treebank: number of tokens in data sets;
number of labels in label sets. Morphology: number of word forms and lemmas in treebank covered by morphological
analyzer. Clusters: number of tokens and types in unlabeled corpus.
</tableCaption>
<bodyText confidence="0.99975055">
treebank annotation we have to rely on a heuristic
mapping between the two. Word clusters are derived
from the so-called Huge German Corpus.7
Hungarian For training and test we use the
Szeged Dependency Treebank (Farkas et al., 2012).
We use a finite-state morphological analyzer con-
structed from the morphdb.hu lexical resource (Tr´on
et al., 2006), and word clusters come from the Hun-
garian National Corpus (V´aradi, 2002).
Russian Parsers are trained and tested on data
from the SynTagRus Treebank (Boguslavsky et al.,
2000; Boguslavsky et al., 2002). The morpholog-
ical analyzer is a module of the ETAP-3 linguistic
processor (Apresian et al., 2003) with a dictionary
comprising more than 130,000 lexemes (Iomdin and
Sizov, 2008). Word clusters have been produced on
the basis of an unlabeled corpus of Russian com-
piled by the Russian Language Institute of the Rus-
sian Academy of Sciences and tokenized by the
ETAP-3 analyzer.
</bodyText>
<sectionHeader confidence="0.862928" genericHeader="method">
4 Joint Morphology and Syntax
</sectionHeader>
<bodyText confidence="0.999922636363636">
We start by exploring different ways of integrating
morphology and syntax in a data-driven setting, that
is, where our only knowledge source is the anno-
tated training corpus. At both learning and parsing
time, we preprocess sentences using a tagger that as-
signs (up to) kp part-of-speech tags and km morpho-
logical descriptions and a lemmatizer that assigns
a single best lemma to each word. Complex mor-
phological descriptions consisting of several atomic
features are predicted as a whole, both in prepro-
cessing and in parsing. Although it would be pos-
</bodyText>
<footnote confidence="0.89001">
7See http://www.ims.uni-stuttgart.de/forschung/ressourcen/
korpora/hgc.html.
</footnote>
<bodyText confidence="0.874878705882353">
sible to predict each atomic morphological feature
separately, we believe this would increase the risk
of creating inconsistent morphological descriptions.
As preprocessors, we use the tagger and lemmatizer
included in the MATE tools8 trained on the same
annotated training set, using 10-fold jack-knifing to
get predictions for the training set itself. The tag-
ger is a greedy left-to-right tagger trained with the
same passive-aggressive online learning as the pars-
ing system, which is run twice over the input to make
more effective use of contextual features. The tagger
scores are not properly normalized but tend to be in
the [0,1] range for both part-of-speech tags and mor-
phological descriptions. In this setting, we consider
four different models for deriving a full MS-parse:
1. In the PIPELINE model, we set kp = km = 1,
which means that the SHIFT transition always
selects the 1-best tag, morphological descrip-
tion and lemma for each word. We use a beam
size of 40 and prune by simply keeping the 40
highest scoring hypotheses at each step. As the
name suggests, this is equivalent to a standard
pipeline with no joint prediction.
2. The SIMPLETAG model replicates the model of
Bohnet and Nivre (2012) with kp = 2, km = 1,
and a score threshold for tags of 0.25, meaning
that the second best tag is only considered if
its score is less than 0.25 below that of the best
tag. We use two-step beam pruning, where we
first extract the 40 highest scoring hypotheses
with distinct dependency trees and then add the
8 highest scoring remaining hypotheses (nor-
mally morphological variants of hypotheses al-
ready included) for a total beam size of 48. This
</bodyText>
<footnote confidence="0.997793">
8Available at https://code.google.com/p/mate-tools/.
</footnote>
<page confidence="0.995578">
420
</page>
<bodyText confidence="0.9825255">
model performs joint tagging and parsing but
relies on 1-best morphological features.
</bodyText>
<listItem confidence="0.8516754">
3. The COMPLEXTAG model is like SIMPLETAG
except that we let tags represent the concate-
nation of ordinary tags and morphological de-
scriptions (and retrain the preprocessing tagger
on this representation). This model performs
joint morphological and syntactic analysis as
joint tagging and parsing with a fine-grained
tag set.
4. The JOINT model has kp = km = 2, meaning
that the tag and the morphological description
can be selected independently by the parser.
For morphological descriptions, we use a score
threshold of 0.1. For beam pruning, we gener-
alize the previous method by first extracting the
40 highest-scoring hypotheses with distinct de-
</listItem>
<bodyText confidence="0.979355567567568">
pendency trees. For each of these, we then find
the highest-scoring hypothesis with the same
dependency tree but different tags or morpho-
logical features, storing these in two temporary
lists TMPp, for hypotheses that differ with re-
spect to tags, and TMPm, for hypotheses that
differ only with respect to morphological fea-
tures. Finally, we extract the 8 highest-scoring
hypotheses from each of TMPp and TMPm and
add them to the beam for a total beam size
of 56. This model performs joint prediction
of part-of-speech tags, morphological descrip-
tions and dependency relations (but still relies
on 1-best lemmas, like all the other models.)
The procedures for beam pruning may appear both
complex and ad hoc, especially for the JOINT model,
but are motivated by the need to achieve a balance
between morphological and syntactic ambiguity in
the set of hypotheses maintained. As explained by
Bohnet and Nivre (2012), just maintaining a single
beam does not give enough variety in the beam. The
method used for the JOINT model is one way of gen-
eralizing this technique to a fully joint model, but
other strategies are certainly conceivable.
Another point that may be surprising is the choice
to keep kp and km as low as 2, which is fairly close to
a pipeline model. Bohnet and Nivre (2012) experi-
mented with higher values for the tag threshold but
found no improvement in accuracy, and our own pre-
liminary experiments confirmed this trend for mor-
phological descriptions. In Section 7, we present an
empirical analysis that gives further support for this
choice, at least for the languages considered in this
paper. Note also that the choice is not motivated by
efficiency concerns, since increasing the values of kp
and km has only a marginal effect on running time,
as explained in Section 2.4. Finally, the choice not
to consider k-best lemmas is dictated by the fact that
our lemmatizer only provides a 1-best analysis.
For the first three models, we use the same fea-
ture representations as Bohnet and Nivre (2012),9
consisting of their adaptation of the features used
by Zhang and Nivre (2011), the graph completion
features of Bohnet and Kuhn (2012), and the spe-
cial features over k-best tags introduced specifi-
cally for joint tagging and parsing by Bohnet and
Nivre (2012). For the JOINT model, we simply add
features over the k-best morphological descriptions
analogous to the features over k-best tags.10
Experimental results for these four models can be
found in Table 2. From the PIPELINE results, we
see that the 1-best accuracy of the preprocessing tag-
ger ranges from 95.0 (Finnish) to 99.2 (Czech) for
POS, and from 89.4 (Finnish) to 96.5 (Hungarian)
for MOR. The lemmatizer does a good job for four
of the languages (93.9–97.9) but has really poor per-
formance on Finnish (73.7). With respect to syn-
tactic accuracy, the PIPELINE system achieves LAS
ranging from 79.9 (Finnish) to 91.8 (German) and
UAS ranging from 84.4 to 93.7. It is interesting
to note that the highest PMD score, which requires
both morphology and syntax to be completely cor-
rect, is observed for Hungarian (86.2).
Turning to the results for SIMPLETAG, we note
that our results are consistent with those reported
by Bohnet and Nivre (2012), with small but con-
sistent improvements in POS and UAS/LAS (and
in the compound metrics PM and PMD) for most
languages. However, the improvement in the PMD
score is statistically significant only for Hungarian
and Russian (p &lt; 0.01). By contrast, the results for
COMPLEXTAG confirm our hypothesis that merging
tags and morphological descriptions into a single tag
is not an effective way to do joint morphological and
</bodyText>
<footnote confidence="0.998158333333333">
9See http://stp.lingfil.uu.se/∼nivre/exp/emnlp12.html.
10A complete description of our feature representations is
available at http://stp.lingfil.uu.se/∼nivre/exp/tacl13.html.
</footnote>
<page confidence="0.977789">
421
</page>
<table confidence="0.99993418367347">
Czech POS MOR LEM UAS LAS PM PMD
PIPELINE 99.2 93.2 95.5 88.5 83.1 93.0 78.4
SIMPLETAG 99.2 93.2 95.5 88.5 83.2 93.1 78.4
COMPLEXTAG 98.8 93.3 95.5 87.1 81.2 93.3 77.3
JOINT 99.2 93.7 95.5 88.7 83.3 93.7 79.2
LEXHARD 99.3 93.0 94.3 88.7 83.4 92.9 78.3
LEXSOFT 99.4 94.5 95.9 88.8 83.5 94.4 79.8
CLUSTER 99.4 94.6 96.0 89.0 83.7 94.5 80.0
ORACLE 99.8 97.0 – 92.7 89.9 94.1 84.7
GOLD – – – 89.3 84.5 – –
Finnish POS MOR LEM UAS LAS PM PMD
PIPELINE 95.0 89.4 73.7 84.4 79.9 88.8 71.5
SIMPLETAG 95.6 89.4 73.7 84.8 80.5 89.0 73.0
COMPLEXTAG 93.0 84.9 73.7 80.1 74.5 84.7 65.3
JOINT 95.4 89.2 73.7 84.8 80.6 89.1 72.6
LEXHARD 95.8 91.6 93.4 86.1 82.5 91.1 75.9
LEXSOFT 95.5 91.9 93.0 86.0 82.3 91.6 75.7
CLUSTER 95.7 92.0 94.4 86.6 83.1 91.4 75.8
ORACLE 98.0 94.8 – 91.3 89.4 91.8 83.1
German POS MOR LEM UAS LAS PM PMD
PIPELINE 97.6 90.0 97.9 93.7 91.8 89.1 82.9
SIMPLETAG 98.0 90.0 97.9 93.8 91.9 89.1 83.0
COMPLEXTAG 97.3 87.6 97.9 92.3 90.1 86.9 79.7
JOINT 98.1 90.8 97.9 93.9 92.0 90.0 83.9
LEXHARD 97.0 65.6 97.9 93.7 92.0 64.6 61.3
LEXSOFT 98.4 91.9 97.9 94.0 92.1 91.2 85.1
CLUSTER 98.4 92.5 97.9 94.1 92.4 91.7 85.9
ORACLE 99.6 96.3 – 96.3 95.9 91.9 88.8
GOLD – – – 94.2 92.7 – –
Hungarian POS MOR LEM UAS LAS PM PMD
PIPELINE 97.6 96.5 93.9 91.0 88.4 96.1 86.2
SIMPLETAG 97.8 96.5 93.9 91.3 88.8 96.1 86.6
COMPLEXTAG 97.5 90.9 93.9 90.6 87.7 90.9 81.2
JOINT 97.8 96.4 93.7 91.3 88.9 96.2 86.7
LEXHARD 98.5 97.3 99.0 91.5 89.1 97.1 87.4
LEXSOFT 98.5 97.6 99.0 91.4 89.1 97.4 87.7
CLUSTER 98.5 97.6 99.0 91.7 89.3 97.4 88.0
ORACLE 99.7 99.3 – 94.6 93.3 97.6 91.7
GOLD – – – 91.9 89.8 – –
Russian POS MOR LEM UAS LAS PM PMD
PIPELINE 98.4 94.0 96.1 92.6 87.4 92.6 82.7
SIMPLETAG 98.5 94.0 96.1 92.6 87.5 92.6 82.9
COMPLEXTAG 97.9 91.4 96.1 91.2 85.1 90.8 79.0
JOINT 98.5 94.4 96.1 92.8 87.6 92.8 83.5
LEXHARD 98.9 95.1 94.0 93.0 88.0 94.5 84.1
LEXSOFT 98.8 95.7 96.5 92.9 87.7 95.1 84.5
CLUSTER 98.8 95.7 96.6 93.0 87.9 95.7 84.7
ORACLE 99.9 98.6 – 95.5 92.9 95.2 89.0
GOLD – – – 94.0 89.1 – –
</table>
<tableCaption confidence="0.93567075">
Table 2: Test set results for all models. ORACLE = ora-
cle scores for LEXSOFT; GOLD = accuracy for PIPELINE
with gold POS, MOR, LEM. Bold marks best result per
column and language (excluding ORACLE and GOLD).
</tableCaption>
<bodyText confidence="0.999961171428571">
syntactic analysis. Here, we see a significant drop
in most scores for all languages, but in particular in
the accuracy of morphological descriptions (MOR),
where the score drops by 5.6 percentage points for
Hungarian, 4.5 for Finnish, 2.6 for Russian, and 2.4
for German. The only exception is Czech, where
MOR and PM actually improve slightly, but this
comes at the expense of a substantial drop in depen-
dency accuracy. In any case, the decrease in PMD is
highly significant for all languages (p &lt; 0.01).
Finally, we see that the JOINT model, where
tags and morphological descriptions are predicted
separately during the parsing process, gives sig-
nificant improvements in MOR accuracy compared
to the PIPELINE and SIMPLETAG models for Ger-
man (+0.8), Czech (+0.5), and Russian (+0.4), with
marginal improvements also in the syntactic UAS
and LAS scores. For Finnish and Hungarian, on
the other hand, there is actually a small drop in ac-
curacy (and for Finnish also a drop in POS accu-
racy compared to SIMPLETAG). Interestingly, how-
ever, for both these languages there is nevertheless
a small improvement in the joint PM score, indicat-
ing that the JOINT model in general does a better
job at selecting a valid complete morphological de-
scription than the SIMPLETAG model. Since Finnish
and Hungarian are the most morphologically com-
plex languages, it is likely that the lack of a strong
positive effect is due in part to sparse data, espe-
cially for Finnish where the training set is small. As
we shall see in the next section, this problem can be
partly overcome through the use of external lexical
resources. Still, the improvement in the PMD score
over the other three models is highly significant for
all languages except Finnish (p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.992708" genericHeader="method">
5 Lexical Constraints
</sectionHeader>
<bodyText confidence="0.8780323">
Our starting point in this section is the JOINT model,
which gave the best overall accuracy score (PMD)
for all languages except Finnish. To this model we
now add constraints derived from a morphological
lexicon that maps each word form to a set of pos-
sible tags, morphological descriptions and lemmas.
We explore two different ways of integrating these
constraints:
1. In the LEXHARD model, we use the lexicon to
derive hard constraints and filter out tags and
</bodyText>
<page confidence="0.997494">
422
</page>
<bodyText confidence="0.999921448717949">
morphological descriptions that are not in the
lexicon. More precisely, for word forms that
are covered by the lexicon, we let the prepro-
cessing tagger select the kp best tags and km
best morphological descriptions that are in the
lexicon. We do this both during training and
parsing, and we use exactly the same features
and beam handling as for the JOINT model in
the previous section.
2. In the LEXSOFT model, we instead use soft
lexical constraints by adding features that en-
code whether a tag or morphological descrip-
tion is in the lexicon or not. Again, we add
these features both to the preprocessing tagger
and to the joint parser, which otherwise remain
exactly as before.
One additional modification that we make for both
the LEXHARD and the LEXSOFT model is to com-
pletely rely on the external lexicon for the predic-
tion of lemmas. After the parser has selected a tag
and morphological description for a word, we sim-
ply predict the corresponding lemma from the lexi-
con, breaking ties arbitrarily in the very few cases
where the word form, tag and morphological de-
scription do not determine a unique lemma, and
leaving the lemma empty for word forms that are not
contained in the lexicon. This means that, in con-
trast to the purely data-driven models, the lexicon-
enriched models predict the complete morphological
analysis jointly with parsing (with the lemma being
derived deterministically from the tag and the mor-
phological description). We make an exception only
for German, where the lexicon provides lemmas that
would require further disambiguation and where we
therefore continue to use the data-driven lemmatizer.
As can be seen in Table 2, the results for the LEX-
HARD model are somewhat mixed. For Finnish, we
see a dramatic improvement of the LEM score (from
73.7 to 93.4), indicating that the rule-based morpho-
logical analyzer is vastly superior to the data-driven
lemmatizer for Finnish. There is also a very nice
boost to the MOR score (+2.2) and a smaller im-
provement on POS (+0.4). These improvements also
lead to higher syntactic accuracy, with LAS increas-
ing from 80.6 to 82.5 and UAS from 84.8 to 86.1.
For Hungarian, we have nice improvements of the
LEM score (+5.3), the MOR score (+0.9) and the
POS score (+0.7), but only small improvements in
LAS/UAS. For Russian, we observe improvements
in POS and MOR, a small drop in LEM, and again
minor improvements in UAS/LAS. For Czech and
German, finally, we see a drop in MOR (and in LEM
for Czech and POS for German), while UAS/LAS is
largely unaffected. For German, this result can prob-
ably be explained largely by the fact that the mor-
phological descriptions in the lexicon are not fully
compatible with those in the treebank, as explained
in Section 3. Similarly, for Czech, we think the drop
in the LEM score is due to discrepancies caused by
updates in the dictionary version released in 2013,
deviating from the previously published treebank.
In general, the LEXSOFT model performs consid-
erably better, achieving the best results so far for
most languages and metrics. The only clear ex-
ception is Finnish, where it performs slightly worse
than LEXHARD (but better than all the other mod-
els). In addition, there is a marginal drop in POS
and LAS/UAS for Russian and in UAS for Hungar-
ian (but again only compared to LEXHARD). The
results are particularly striking for German, where
the soft lexical constraints are clearly beneficial (es-
pecially for the MOR score) despite not being quite
compatible with the morphological descriptions in
the training set. In terms of statistical signifance,
LEXSOFT outperforms the JOINT model with re-
spect to the PMD score for all languages (p &lt; 0.01).
It is also significantly better than LEXHARD for all
languages except Finnish (p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.992671" genericHeader="method">
6 Word Clusters
</sectionHeader>
<bodyText confidence="0.999948083333333">
Finally, we add word cluster features to the best
model for each language (LEXHARD for Finnish,
LEXSOFT for the others).11 We use Brown clus-
ters (Brown et al., 1992), with 800 clusters for all
languages, and we use the same feature represen-
tation as Bohnet and Nivre (2012). The results in
Table 2 show small but consistent improvements
in almost all metrics for all languages, confirming
the benefit of cluster features for morphologically
rich languages. It is worth noting that we see the
biggest improvement for Finnish, the language with
the smallest training set and therefore most likely to
</bodyText>
<footnote confidence="0.639473">
11The best model was selected according to results on the dev
set (cross-validation on the training set for Finnish).
</footnote>
<page confidence="0.998815">
423
</page>
<bodyText confidence="0.999888090909091">
suffer from sparse data, where the syntactic accu-
racy improves substantially (LAS +0.6, UAS +0.5)
and lemmatization even more (LEM +1.0). We also
see a nice improvement in morphological accuracy
for German (MOR +0.6, PM +0.5), which may be
related to the lack of a compatible morphological
analyzer for this language or simply to the fact that
the clusters are derived from a much larger corpus
for German than for the other languages. The PMD
improvement is statistically significant for all lan-
guages except Finnish (p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.996994" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.990487814814815">
The experimental results generally support the con-
clusion that joint prediction of morphology and syn-
tax, where morphology includes rich morphologi-
cal features as well as basic part-of-speech tags, im-
proves both morphological and syntactic accuracy.
The effect is especially clear on the joint evalua-
tion metrics PM and PMD, which indicates that the
joint model produces more internally consistent rep-
resentations. However, we also see evidence that
the joint model may suffer from data sparsity, as in
the case of Finnish, where a model that only pre-
dicts part-of-speech tags jointly with dependency
relations achieve better accuracy on some metrics.
However, even in this case, the joint model has the
best results on the joint evaluation metrics.
The second conclusion that can be drawn from the
experiments is that the use of an external lexicon is
an effective way of mitigating the sparse data prob-
lem and thereby improving accuracy. In general,
however, it is more effective to add the lexical con-
straints in the form of features, or soft constraints,
than to apply them as hard constraints and discard all
analyses that are not licensed by the lexicon. In par-
ticular, this is a useful strategy when the lexical re-
source is not completely compatible with the annota-
tion in the training set, as seen in the case of German
and (to a lesser extent) Czech. The only exception to
this generalization is again Finnish, where the hard
constraint model works marginally better (except for
the MOR and PM metrics), which may again indi-
cate that the training set is too small to make opti-
mal use of the additional features. Still, the soft con-
straint model improves substantially over the models
without lexical resources also for Finnish.
Finally, our experiments confirm that features
based on distributional word clusters have a positive
impact on syntactic accuracy, but little or no impact
on morphological accuracy. This is consistent with
previous findings in the literature, mainly from En-
glish (Koo et al., 2008; Sagae and Gordon, 2009),
and it is interesting to see that it holds also for richly
inflected languages and when added on top of fea-
tures derived from external lexical resources.
One issue worth discussing is the choice to allow
the joint model to consider at most 2 tags and 2 mor-
phological descriptions per word, which may seem
overly restrictive and very close to a pipeline model.
As already mentioned, this was motivated by the re-
sults of Bohnet and Nivre (2012), which explored
higher values without seeing any improvements, as
well as by our own preliminary experiments. In an
attempt to shed further light on this issue, we com-
puted oracle scores for the LEXSOFT model, which
uses soft lexical constraints but no cluster features.
The oracle scores for POS and MOR tell us how of-
ten the correct analysis is actually included in the
input to the joint model, while the oracle scores for
UAS and LAS reports the score of the best depen-
dency tree present in the beam at termination. The
results, reported in Table 2, show that the oracle
scores are very high, especially for part-of-speech
tags (98.0–99.9) but also for morphological descrip-
tions (94.8–99.3). Hence, very few correct analyses
are pruned away when setting the kp and km param-
eters to 2, and increasing the search space further is
therefore unlikely to improve accuracy.
For further analysis, Table 2 reports the UAS/LAS
scores of the PIPELINE system when given gold
standard tags, morphological descriptions and lem-
mas as input.12 Viewing this as an upper bound
on improvements in parsing accuracy for the joint
models, and comparing with the LEXSOFT model,
which like PIPELINE does not use cluster features,
we see that joint prediction with (soft) lexical con-
straints gives an average error reduction of about
40% for UAS and about 32% for LAS, which is
substantial especially given that the error reduction
in the PM score (compared to the perfect morphol-
ogy underlyling the GOLD scores) is only about
12Finnish had to be excluded because gold standard morpho-
logical annotation exists only for a small subset of the treebank.
</bodyText>
<page confidence="0.998015">
424
</page>
<bodyText confidence="0.963134901408451">
27.5%. It is also worth pointing out that these im-
provements come at a very modest cost in computa-
tional efficiency, as the run times for the LEXSOFT
model are on average only 15% higher than for the
PIPELINE model, despite having a 40% larger beam
size.13 Interestingly, however, for all languages the
LAS/UAS scores are actually higher for ORACLE
than for GOLD, indicating that the LEXSOFT model
has in its final beam dependency trees that are better
than the 1-best trees predicted with perfect morpho-
logical input and suggesting that there is room for
further improvement of the scoring model.
The final results obtained with joint prediction of
morphology and syntax, external lexical constraints,
and cluster features represent a new state of the art
for syntactic dependency parsing for all five lan-
guages. For Czech, the best previous UAS on the
standard train-test split of the PDT is 87.32, re-
ported by Koo et al. (2010) with a parser using
non-projective head automata and dual decomposi-
tion, while the best LAS is 78.82 LAS from Nilsson
et al. (2006), using a greedy arc-eager transition-
based system with pseudo-projective parsing. Our
best results are 1.7 percentage points better for UAS
(89.0) and almost 5 percentage points better for LAS
(83.7).14 For Finnish, the only previous results are
from Haverinen et al. (2013), who achieve 81.01
LAS and 84.97 UAS with the graph-based parser
of Bohnet (2010). We get substantial improvements
with 83.1 LAS and 86.6 UAS. We also improve
slightly over their best POS score, obtained with the
HunPos tagger (Hal´acsy et al., 2007) together with
the OMorFi analyzer (95.7 vs. 95.4). For German,
the best previous results on the same train-test split
are from Seeker and Kuhn (2012), using the graph-
based parser of Bohnet (2010) in a pipeline archi-
tecture. With the same evaluation setup as in this
paper, they achieve 91.50 LAS and 93.48 UAS –
13LEXSOFT averages 0.132 ms per sentence on an Intel i7-
3930K processor with 6 cores, against 0.112 ms for PIPELINE.
14It is worth noting that there are a number of more recent
parsing results for Czech, but they all use a different test set (and
often a different training set), usually from one of the CoNLL
shared tasks in 2006 (Buchholz and Marsi, 2006), 2007 (Nivre
et al., 2007) and 2009 (Hajiˇc et al., 2009). For the 2009 data set,
the best results are 83.73 LAS and 88.82 UAS from Bohnet and
Nivre (2012), who use the SIMPLETAG model but with a beam
size of 80. In our setup, we outperform this model by 0.5 points
in both LAS and UAS.
in the original paper, they only report results with-
out punctuation – to be compared with 92.4 LAS
and 94.1 UAS for our best model.15 In addition,
our POS score of 98.4 is the highest reported for a
tagger trained only on the Tiger Treebank, outper-
forming the previous best from Bohnet and Nivre
(2012) by 0.3 percentage points. The only previ-
ous results on Hungarian using the same version of
the treebank are from Farkas et al. (2012), who re-
port 87.2 LAS and 90.1 UAS for the graph-based
parser of Bohnet (2010). Our best results improve
labeled accuracy by 2.1 points (89.3 LAS) and un-
labeled accuracy by 1.6 points (91.7 UAS), which is
again quite substantial. For Russian, Boguslavsky et
al. (2011) report 86.0 LAS and 90.0 UAS using the
rule-based ETAP-3 parser with an added statistical
model and joint morphological and syntactic disam-
biguation. The scores are not strictly comparable,
because we use a more recent version of the Syn-
TagRus treebank (May 2013 vs. April 2011), but our
results nevertheless show substantial improvements,
in particular for UAS (93.0) but also for LAS (88.0).
</bodyText>
<sectionHeader confidence="0.973963" genericHeader="conclusions">
8 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999977076923077">
We have presented the first system that performs
full morphological disambiguation and labeled non-
projective dependency parsing in a joint model, and
we have demonstrated its usefulness for parsing
richly inflected languages. A thorough empirical
investigation of joint prediction models, rule-based
lexical constraints, and distributional word clusters
has shown substantial improvements in accuracy for
five languages. In the future, we hope to conduct a
detailed error analysis for all languages, which may
give us more insight about the benefits of different
components and hopefully pave the way for further
improvements.
</bodyText>
<sectionHeader confidence="0.9975" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.872252875">
Work partly funded by the projects LM2010013 and
LH12093 of the MEYS of the Czech Republic and the
National Excellence Program of the State of Hungary
(T ´AMOP 4.2.4. A/2-11-1-2012-0001).
15As in the case of Czech, there are many recent results for
German based on the CoNLL 2009 data sets, but the previous
best is with the SIMPLETAG model of Bohnet and Nivre (2012),
which we outperform by 0.5/0.3 points in LAS/UAS.
</bodyText>
<page confidence="0.998616">
425
</page>
<sectionHeader confidence="0.990328" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996176361904762">
Ju. Apresian, I. Boguslavsky, L. Iomdin, A. Lazursky,
V. Sannikov, V. Sizov, and L. Tsinman. 2003. ETAP-3
linguistic processor: A full-fledged NLP implementa-
tion of the MTT. In Proceedings of the First Inter-
national Conference on Meaning-Text Theory, pages
279–288.
Igor Boguslavsky, Svetlana Grigorieva, Nikolai Grig-
oriev, Leonid Kreidlin, and Nadezhda Frid. 2000.
Dependency treebank for Russian: Concept, tools,
types of information. In Proceedings of the 18th In-
ternational Conference on Computational Linguistics
(COLING), pages 987–991.
Igor Boguslavsky, Ivan Chardin, Svetlana Grigorieva,
Nikolai Grigoriev, Leonid Iomdin, Leonid Kreidlin,
and Nadezhda Frid. 2002. Development of a depen-
dency treebank for Russian and its possible applica-
tions in NLP. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC), pages 852–856.
Igor Boguslavsky, Leonid Iomdin, Victor Sizov, Leonid
Tsinman, and Vadim Petrochenkov. 2011. Rule-based
dependency parser refined by empirical and corpus
statistics. In Proceedings of the International Confer-
ence on Dependency Linguistics, pages 318–327.
Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora
Hladk´a. 2003. The Prague Dependency Treebank: A
three-level annotation scenario. In Anne Abeill´e, ed-
itor, Treebanks: Building and Using Parsed Corpora,
pages 103–127. Kluwer.
Bernd Bohnet and Jonas Kuhn. 2012. The best of
both worlds – a graph-based completion model for
transition-based parsers. In Proceedings of the 13th
Conference of the European Chpater of the Associa-
tion for Computational Linguistics (EACL), pages 77–
87.
Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Proceed-
ings of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning (EMNLP-CoNLL),
pages 1455–1465.
Bernd Bohnet. 2010. Top accuracy and fast dependency
parsing is not a contradiction. In Proceedings of the
23rd International Conference on Computational Lin-
guistics (COLING), pages 89–97.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang
Lezius, and George Smith. 2002. TIGER treebank.
In Proceedings of the 1st Workshop on Treebanks and
Linguistic Theories (TLT), pages 24–42.
Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza,
Jennifer C. Lai, and Robert L. Mercer. 1992. Class-
based n-gram models of natural language. Computa-
tional Linguistics, 18:467–479.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of the 10th Conference on Computational
Natural Language Learning (CoNLL), pages 149–164.
Shay B. Cohen and Noah A. Smith. 2007. Joint morpho-
logical and syntactic disambiguation. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
208–217.
Shay B. Cohen, Carlos G´omez-Rodr´ıguez, and Giorgio
Satta. 2011. Exact inference for generative probabilis-
tic non-projective dependency parsing. In Proceedings
of the 2011 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1234–1245.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceed-
ings of the 42nd Annual Meeting of the Association for
Computational Linguistics (ACL), pages 112–119.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1–8.
Brooke Cowan and Michael Collins. 2005. Morphology
and reranking for the statistical parsing of spanish. In
Proceedings of the Human Language Technology Con-
ference and the Conference on Empirical Methods in
Natural Language Processing (HLT/EMNLP), pages
795–802.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research, 7:551–585.
Rich´ard Farkas, Veronika Vincze, and Helmut Schmid.
2012. Dependency parsing of hungarian: Baseline re-
sults and challenges. In Proceedings of the 13th Con-
ference of the European Chpater of the Association for
Computational Linguistics (EACL), pages 55–65.
Andrea Gesmundo, James Henderson, Paola Merlo, and
Ivan Titov. 2009. A latent variable model of syn-
chronous syntactic-semantic parsing for multiple lan-
guages. In Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learning
(CoNLL 2009): Shared Task, pages 37–42.
Yoav Goldberg and Michael Elhadad. 2013. Word seg-
mentation, unknown-word resolution, and morpholog-
ical agreement in a hebrew parsing system. Computa-
tional Linguistics, 39:121–160.
Yoav Goldberg and Reut Tsarfaty. 2008. A single gener-
ative model for joint morphological segmentation and
</reference>
<page confidence="0.995264">
426
</page>
<reference confidence="0.999338076190476">
syntactic parsing. In Proceedings of the 46th Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 371–379.
Jan Hajiˇc and Barbora Hladk´a. 1998. Tagging Inflective
Languages: Prediction of Morphological Categories
for a Rich, Structured Tagset. In Proceedings of the
36th Annual Meeting of the Association for Compu-
tational Linguistics (ACL) and the 17th International
Conference on Computational Linguistics (COLING),
pages 483–490.
Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevov´a,
Eva Hajiˇcov´a, Petr Sgall, and Petr Pajas. 2001. Prague
Dependency Treebank 1.0. LDC, 2001T10.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The conll-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL): Shared Task, pages 1–18.
Jan Hajiˇc. 2000. Morphological tagging: Data vs. dic-
tionaries. In Proceedings of the First Meeting of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL), pages 94–101.
P´eter Hal´acsy, Andr´as Kornai, and Csaba Oravecz. 2007.
HunPos – an open source trigram tagger. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics: Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 209–
212.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun’ichi Tsujii. 2011. Incremental joint pos tagging
and dependency parsing in chinese. In Proceedings
of 5th International Joint Conference on Natural Lan-
guage Processing, pages 1216–1224.
Katri Haverinen, Jenna Nyblom, Timo Viljanen,
Veronika Laippala, Samuel Kohonen, Anna Missil¨a,
Stina Ojala, Tapio Salakoski, and Filip Ginter. 2013.
Building the essential resources for Finnish: the Turku
Dependency Treebank. Language Resources and
Evaluation.
Liang Huang and Kenji Sagae. 2010. Dynamic program-
ming for linear-time incremental parsing. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 1077–1086.
Leonid Iomdin and Viktor Sizov. 2008. Lexicographer’s
companion: A user-friendly software system for en-
larging and updating high-profile computerized bilin-
gual dictionaries. In Lexicographic Tools and Tech-
niques. MONDILEX First Open Workshop, pages 42–
54.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings of the 46th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 595–603.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decompo-
sition for parsing with non-projective head automata.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1288–1298.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Morgan and Claypool.
Marco Kuhlmann, Carlos G´omez-Rodr´ıguez, and Gior-
gio Satta. 2011. Dynamic programming algorithms
for transition-based dependency parsers. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 673–682.
John Lee, Jason Naradowsky, and David A. Smith. 2011.
A discriminative model for joint morphological disam-
biguation and dependency parsing. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 885–894.
Jens Nilsson, Joakim Nivre, and Johan Hall. 2006.
Graph transformations in data-driven dependency
parsing. In Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th An-
nual Meeting of the Association for Computational
Linguistics, pages 257–264.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of the CoNLL Shared Task of
EMNLP-CoNLL 2007, pages 915–932.
Joakim Nivre, Marco Kuhlmann, and Johan Hall. 2009.
An improved oracle for dependency parsing with
online reordering. In Proceedings of the 11th
International Conference on Parsing Technologies
(IWPT’09), pages 73–76.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of the
8th International Workshop on Parsing Technologies
(IWPT), pages 149–160.
Joakim Nivre. 2004. Incrementality in deterministic de-
pendency parsing. In Proceedings of the Workshop on
Incremental Parsing: Bringing Engineering and Cog-
nition Together (ACL), pages 50–57.
Joakim Nivre. 2009. Non-projective dependency parsing
in expected linear time. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP (ACL-IJCNLP), pages
351–359.
</reference>
<page confidence="0.980765">
427
</page>
<reference confidence="0.999811815789474">
Tommi A. Pirinen. 2011. Modularisation of finnish
finite-state language description – towards wide col-
laboration in open source development of a morpho-
logical analyser. In Proceedings of the 18th Nordic
Conference of Computational Linguistics (NODAL-
IDA), pages 299–302.
Kenji Sagae and Andrew S. Gordon. 2009. Clustering
words by syntactic similarity improves dependency
parsing of predicate-argument structures. In Proceed-
ings of the 11th International Conference on Parsing
Technologies (IWPT), pages 192–201.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
SMOR: A German computational morphology cover-
ing derivation, composition and inflection. In Pro-
ceedings of the 4th International Conference on Lan-
guage Resources and Evaluation (LREC), pages 1263–
1266.
Wolfgang Seeker and Jonas Kuhn. 2012. Making el-
lipses explicit in dependency conversion for a ger-
man treebank. In Proceedings of the 8th International
Conference on Language Resources and Evaluation
(LREC), pages 3132–3139.
Wolfgang Seeker, Bernd Bohnet, Lilja Øvrelid, and Jonas
Kuhn. 2010. Informed ways of improving data-driven
dependency parsing for german. In Coling 2010:
Posters, pages 1122–1130.
Johanka Spoustov´a and Miroslav Spousta. 2012. A high-
quality web corpus of czech. In Proceedings of the 8th
International Conference on Language Resources and
Evaluation (LREC 2012), pages 311–315.
Ivan Titov and James Henderson. 2007. A latent variable
model for generative dependency parsing. In Proceed-
ings of the 10th International Conference on Parsing
Technologies (IWPT), pages 144–155.
Viktor Tr´on, P´eter Hal´acsy, P´eter Rebrus, Andr´as Rung,
Eszter Simon, and P´eter Vajda. 2006. Morphdb.hu:
Hungarian lexical database and morphological gram-
mar. In Proceedings of the 5th International Confer-
ence on Language Resources and Evaluation (LREC),
pages 1670–1673.
Reut Tsarfaty, Djam´e Seddah, Yoav Goldberg, San-
dra Kuebler, Yannick Versley, Marie Candito, Jen-
nifer Foster, Ines Rehbein, and Lamia Tounsi. 2010.
Statistical parsing of morphologically rich languages
(spmrl) what, how and whither. In Proceedings of the
NAACL HLT 2010 First Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 1–12.
Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and Joakim
Nivre. 2013. Parsing morphologicall rich languages:
Introduction to the special issue. Computational Lin-
guistics, 39:15–22.
Reut Tsarfaty. 2006. Integrated morphological and syn-
tactic disambiguation for modern hebrew. In Pro-
ceedings of the COLING/ACL 2006 Student Research
Workshop, pages 49–54.
Tam´as V´aradi. 2002. The hungarian national corpus.
In Proceedings of the 3rd International Conference on
Language Resources and Evaluation (LREC), pages
385–389.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statisti-
cal dependency analysis with support vector machines.
In Proceedings of the 8th International Workshop on
Parsing Technologies (IWPT), pages 195–206.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 562–571.
Yue Zhang and Joakim Nivre. 2011. Transition-based
parsing with rich non-local features. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics (ACL).
Yue Zhang and Joakim Nivre. 2012. Analyzing the ef-
fect of global learning and beam-search on transition-
based dependency parsing. In Proceedings of COL-
ING 2012: Posters, pages 1391–1400.
</reference>
<page confidence="0.998346">
428
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.140800">
<title confidence="0.812294">Joint Morphological and Syntactic Analysis for Richly Inflected Languages</title>
<affiliation confidence="0.831828">of Birmingham, School of Computer *Uppsala University, Department of Linguistics and Polit´ecnica de Madrid, Departamento de Inteligencia Academy of Sciences, Institute for Information Transmission</affiliation>
<note confidence="0.600307">of Szeged, Institute of of Turku, Department of Information University in Prague, Institute of Formal and Applied Linguistics</note>
<abstract confidence="0.998507428571428">Joint morphological and syntactic analysis has been proposed as a way of improving parsing accuracy for richly inflected languages. Starting from a transition-based model for joint part-of-speech tagging and dependency parsing, we explore different ways of integrating morphological features into the model. We also investigate the use of rule-based morphological analyzers to provide hard or soft lexical constraints and the use of word clusters to tackle the sparsity of lexical features. Evaluation on five morphologically rich languages (Czech, Finnish, German, Hungarian, and Russian) shows consistent improvements in both morphological and syntactic accuracy for joint prediction over a pipeline model, with further improvements thanks to lexical constraints and word clusters. The final results improve the state of the art in dependency parsing for all languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Boguslavsky Apresian</author>
<author>L Iomdin</author>
<author>A Lazursky</author>
<author>V Sannikov</author>
<author>V Sizov</author>
<author>L Tsinman</author>
</authors>
<title>ETAP-3 linguistic processor: A full-fledged NLP implementation of the MTT.</title>
<date>2003</date>
<booktitle>In Proceedings of the First International Conference on Meaning-Text Theory,</booktitle>
<pages>279--288</pages>
<contexts>
<context position="4512" citStr="Apresian et al., 2003" startWordPosition="650" endWordPosition="653">inguistics, 1 (2013) 415–428. Action Editor: Brian Roark. Submitted 7/2013; Revised 9/2013; Published 10/2013. c�2013 Association for Computational Linguistics. joint part-of-speech tagging and dependency parsing and report improved accuracy for Czech and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many</context>
<context position="22020" citStr="Apresian et al., 2003" startWordPosition="3658" endWordPosition="3661"> rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training corpus. At both learning and parsing time, we preprocess sentences using a tagger that assigns (up to) kp part-of-speech tags</context>
</contexts>
<marker>Apresian, Iomdin, Lazursky, Sannikov, Sizov, Tsinman, 2003</marker>
<rawString>Ju. Apresian, I. Boguslavsky, L. Iomdin, A. Lazursky, V. Sannikov, V. Sizov, and L. Tsinman. 2003. ETAP-3 linguistic processor: A full-fledged NLP implementation of the MTT. In Proceedings of the First International Conference on Meaning-Text Theory, pages 279–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Boguslavsky</author>
<author>Svetlana Grigorieva</author>
<author>Nikolai Grigoriev</author>
<author>Leonid Kreidlin</author>
<author>Nadezhda Frid</author>
</authors>
<title>Dependency treebank for Russian: Concept, tools, types of information.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>987--991</pages>
<contexts>
<context position="21894" citStr="Boguslavsky et al., 2000" startWordPosition="3638" endWordPosition="3641">bank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training</context>
</contexts>
<marker>Boguslavsky, Grigorieva, Grigoriev, Kreidlin, Frid, 2000</marker>
<rawString>Igor Boguslavsky, Svetlana Grigorieva, Nikolai Grigoriev, Leonid Kreidlin, and Nadezhda Frid. 2000. Dependency treebank for Russian: Concept, tools, types of information. In Proceedings of the 18th International Conference on Computational Linguistics (COLING), pages 987–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Boguslavsky</author>
<author>Ivan Chardin</author>
<author>Svetlana Grigorieva</author>
<author>Nikolai Grigoriev</author>
<author>Leonid Iomdin</author>
<author>Leonid Kreidlin</author>
<author>Nadezhda Frid</author>
</authors>
<title>Development of a dependency treebank for Russian and its possible applications in NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>852--856</pages>
<contexts>
<context position="21921" citStr="Boguslavsky et al., 2002" startWordPosition="3642" endWordPosition="3645">cal analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training corpus. At both learning a</context>
</contexts>
<marker>Boguslavsky, Chardin, Grigorieva, Grigoriev, Iomdin, Kreidlin, Frid, 2002</marker>
<rawString>Igor Boguslavsky, Ivan Chardin, Svetlana Grigorieva, Nikolai Grigoriev, Leonid Iomdin, Leonid Kreidlin, and Nadezhda Frid. 2002. Development of a dependency treebank for Russian and its possible applications in NLP. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC), pages 852–856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Boguslavsky</author>
<author>Leonid Iomdin</author>
<author>Victor Sizov</author>
<author>Leonid Tsinman</author>
<author>Vadim Petrochenkov</author>
</authors>
<title>Rule-based dependency parser refined by empirical and corpus statistics.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Dependency Linguistics,</booktitle>
<pages>318--327</pages>
<contexts>
<context position="46068" citStr="Boguslavsky et al. (2011)" startWordPosition="7737" endWordPosition="7740">pared with 92.4 LAS and 94.1 UAS for our best model.15 In addition, our POS score of 98.4 is the highest reported for a tagger trained only on the Tiger Treebank, outperforming the previous best from Bohnet and Nivre (2012) by 0.3 percentage points. The only previous results on Hungarian using the same version of the treebank are from Farkas et al. (2012), who report 87.2 LAS and 90.1 UAS for the graph-based parser of Bohnet (2010). Our best results improve labeled accuracy by 2.1 points (89.3 LAS) and unlabeled accuracy by 1.6 points (91.7 UAS), which is again quite substantial. For Russian, Boguslavsky et al. (2011) report 86.0 LAS and 90.0 UAS using the rule-based ETAP-3 parser with an added statistical model and joint morphological and syntactic disambiguation. The scores are not strictly comparable, because we use a more recent version of the SynTagRus treebank (May 2013 vs. April 2011), but our results nevertheless show substantial improvements, in particular for UAS (93.0) but also for LAS (88.0). 8 Concluding Remarks We have presented the first system that performs full morphological disambiguation and labeled nonprojective dependency parsing in a joint model, and we have demonstrated its usefulnes</context>
</contexts>
<marker>Boguslavsky, Iomdin, Sizov, Tsinman, Petrochenkov, 2011</marker>
<rawString>Igor Boguslavsky, Leonid Iomdin, Victor Sizov, Leonid Tsinman, and Vadim Petrochenkov. 2011. Rule-based dependency parser refined by empirical and corpus statistics. In Proceedings of the International Conference on Dependency Linguistics, pages 318–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The Prague Dependency Treebank: A three-level annotation scenario.</title>
<date>2003</date>
<pages>103--127</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2003</marker>
<rawString>Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora Hladk´a. 2003. The Prague Dependency Treebank: A three-level annotation scenario. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, pages 103–127. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Jonas Kuhn</author>
</authors>
<title>The best of both worlds – a graph-based completion model for transition-based parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chpater of the Association for Computational Linguistics (EACL),</booktitle>
<pages>77--87</pages>
<contexts>
<context position="27558" citStr="Bohnet and Kuhn (2012)" startWordPosition="4565" endWordPosition="4568">ther support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the JOINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the PIPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a good job for four of the languages (93.9–97.9) but has real</context>
</contexts>
<marker>Bohnet, Kuhn, 2012</marker>
<rawString>Bernd Bohnet and Jonas Kuhn. 2012. The best of both worlds – a graph-based completion model for transition-based parsers. In Proceedings of the 13th Conference of the European Chpater of the Association for Computational Linguistics (EACL), pages 77– 87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Joakim Nivre</author>
</authors>
<title>A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1455--1465</pages>
<contexts>
<context position="3752" citStr="Bohnet and Nivre (2012)" startWordPosition="547" endWordPosition="550">s, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computational Linguistics, 1 (2013) 415–428. Action Editor: Brian Roark. Submitted 7/2013; Revised 9/2013; Published 10/2013. c�2013 Association for Computational Linguistics. joint part-of-speech tagging and dependency parsing and report improved accuracy for Czech and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approac</context>
<context position="5967" citStr="Bohnet and Nivre (2012)" startWordPosition="869" endWordPosition="872">and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range of morphological information. We start by investigating different ways of integrating morphological features into the model, go on to examine the effect of using rule-based morphological analyzers to derive hard or soft constraints on the morphological analysis, and finally add word cluster features to combat lexical sparsity. We evaluate our methods on data from Czech, Finnish, German, Hungarian, and Russian, five morphologically rich languages representing three different language groups. The experiments show that joint prediction of morphology and syntax, rule-bas</context>
<context position="12522" citStr="Bohnet and Nivre (2012)" startWordPosition="2079" endWordPosition="2082">d the MS-parse defined for x by a complete transition sequence C0,m is Γt.(c.). The set T of transitions is shown in Figure 1. It is based on the system of Nivre (2009), where a dependency tree is built by repeated applications of the LEFT-ARCd and RIGHT-ARCd transitions, which add an arc (with some label d E D) between the two topmost nodes on the stack (with the leftmost or rightmost node as the dependent, respectively). The SHIFT transition is used to move nodes from the buffer to the stack, and the SWAP transition is used 417 to permute nodes in order to allow non-projective dependencies. Bohnet and Nivre (2012) modified this system by replacing the simple SHIFT transition by SHIFTp, which not only moves a node from the buffer to the stack but also assigns it a part-of-speech tag p, turning it into a system for joint part-of-speech tagging and dependency parsing.2 Here we add two additional parameters m and l to the SHIFT transition, so that a node moved from the buffer to the stack is assigned not only a tag p but also a morphological description m and a lemma l. In this way, we get a joint model for the prediction of part-ofspeech tags, morphological features, lemmas, and dependency trees. 2.3 Scor</context>
<context position="24169" citStr="Bohnet and Nivre (2012)" startWordPosition="4003" endWordPosition="4006">properly normalized but tend to be in the [0,1] range for both part-of-speech tags and morphological descriptions. In this setting, we consider four different models for deriving a full MS-parse: 1. In the PIPELINE model, we set kp = km = 1, which means that the SHIFT transition always selects the 1-best tag, morphological description and lemma for each word. We use a beam size of 40 and prune by simply keeping the 40 highest scoring hypotheses at each step. As the name suggests, this is equivalent to a standard pipeline with no joint prediction. 2. The SIMPLETAG model replicates the model of Bohnet and Nivre (2012) with kp = 2, km = 1, and a score threshold for tags of 0.25, meaning that the second best tag is only considered if its score is less than 0.25 below that of the best tag. We use two-step beam pruning, where we first extract the 40 highest scoring hypotheses with distinct dependency trees and then add the 8 highest scoring remaining hypotheses (normally morphological variants of hypotheses already included) for a total beam size of 48. This 8Available at https://code.google.com/p/mate-tools/. 420 model performs joint tagging and parsing but relies on 1-best morphological features. 3. The COMP</context>
<context position="26320" citStr="Bohnet and Nivre (2012)" startWordPosition="4352" endWordPosition="4355">ith respect to morphological features. Finally, we extract the 8 highest-scoring hypotheses from each of TMPp and TMPm and add them to the beam for a total beam size of 56. This model performs joint prediction of part-of-speech tags, morphological descriptions and dependency relations (but still relies on 1-best lemmas, like all the other models.) The procedures for beam pruning may appear both complex and ad hoc, especially for the JOINT model, but are motivated by the need to achieve a balance between morphological and syntactic ambiguity in the set of hypotheses maintained. As explained by Bohnet and Nivre (2012), just maintaining a single beam does not give enough variety in the beam. The method used for the JOINT model is one way of generalizing this technique to a fully joint model, but other strategies are certainly conceivable. Another point that may be surprising is the choice to keep kp and km as low as 2, which is fairly close to a pipeline model. Bohnet and Nivre (2012) experimented with higher values for the tag threshold but found no improvement in accuracy, and our own preliminary experiments confirmed this trend for morphological descriptions. In Section 7, we present an empirical analysi</context>
<context position="27682" citStr="Bohnet and Nivre (2012)" startWordPosition="4586" endWordPosition="4589">ed by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the JOINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the PIPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a good job for four of the languages (93.9–97.9) but has really poor performance on Finnish (73.7). With respect to syntactic accuracy, the PIPELINE system achieves LAS ranging from 79.</context>
<context position="37705" citStr="Bohnet and Nivre (2012)" startWordPosition="6321" endWordPosition="6324"> for the MOR score) despite not being quite compatible with the morphological descriptions in the training set. In terms of statistical signifance, LEXSOFT outperforms the JOINT model with respect to the PMD score for all languages (p &lt; 0.01). It is also significantly better than LEXHARD for all languages except Finnish (p &lt; 0.01). 6 Word Clusters Finally, we add word cluster features to the best model for each language (LEXHARD for Finnish, LEXSOFT for the others).11 We use Brown clusters (Brown et al., 1992), with 800 clusters for all languages, and we use the same feature representation as Bohnet and Nivre (2012). The results in Table 2 show small but consistent improvements in almost all metrics for all languages, confirming the benefit of cluster features for morphologically rich languages. It is worth noting that we see the biggest improvement for Finnish, the language with the smallest training set and therefore most likely to 11The best model was selected according to results on the dev set (cross-validation on the training set for Finnish). 423 suffer from sparse data, where the syntactic accuracy improves substantially (LAS +0.6, UAS +0.5) and lemmatization even more (LEM +1.0). We also see a n</context>
<context position="41181" citStr="Bohnet and Nivre (2012)" startWordPosition="6898" endWordPosition="6901">acy, but little or no impact on morphological accuracy. This is consistent with previous findings in the literature, mainly from English (Koo et al., 2008; Sagae and Gordon, 2009), and it is interesting to see that it holds also for richly inflected languages and when added on top of features derived from external lexical resources. One issue worth discussing is the choice to allow the joint model to consider at most 2 tags and 2 morphological descriptions per word, which may seem overly restrictive and very close to a pipeline model. As already mentioned, this was motivated by the results of Bohnet and Nivre (2012), which explored higher values without seeing any improvements, as well as by our own preliminary experiments. In an attempt to shed further light on this issue, we computed oracle scores for the LEXSOFT model, which uses soft lexical constraints but no cluster features. The oracle scores for POS and MOR tell us how often the correct analysis is actually included in the input to the joint model, while the oracle scores for UAS and LAS reports the score of the best dependency tree present in the beam at termination. The results, reported in Table 2, show that the oracle scores are very high, es</context>
<context position="45232" citStr="Bohnet and Nivre (2012)" startWordPosition="7585" endWordPosition="7588">peline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13LEXSOFT averages 0.132 ms per sentence on an Intel i7- 3930K processor with 6 cores, against 0.112 ms for PIPELINE. 14It is worth noting that there are a number of more recent parsing results for Czech, but they all use a different test set (and often a different training set), usually from one of the CoNLL shared tasks in 2006 (Buchholz and Marsi, 2006), 2007 (Nivre et al., 2007) and 2009 (Hajiˇc et al., 2009). For the 2009 data set, the best results are 83.73 LAS and 88.82 UAS from Bohnet and Nivre (2012), who use the SIMPLETAG model but with a beam size of 80. In our setup, we outperform this model by 0.5 points in both LAS and UAS. in the original paper, they only report results without punctuation – to be compared with 92.4 LAS and 94.1 UAS for our best model.15 In addition, our POS score of 98.4 is the highest reported for a tagger trained only on the Tiger Treebank, outperforming the previous best from Bohnet and Nivre (2012) by 0.3 percentage points. The only previous results on Hungarian using the same version of the treebank are from Farkas et al. (2012), who report 87.2 LAS and 90.1 U</context>
</contexts>
<marker>Bohnet, Nivre, 2012</marker>
<rawString>Bernd Bohnet and Joakim Nivre. 2012. A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1455–1465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>89--97</pages>
<contexts>
<context position="44236" citStr="Bohnet (2010)" startWordPosition="7410" endWordPosition="7411">nguages. For Czech, the best previous UAS on the standard train-test split of the PDT is 87.32, reported by Koo et al. (2010) with a parser using non-projective head automata and dual decomposition, while the best LAS is 78.82 LAS from Nilsson et al. (2006), using a greedy arc-eager transitionbased system with pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score, obtained with the HunPos tagger (Hal´acsy et al., 2007) together with the OMorFi analyzer (95.7 vs. 95.4). For German, the best previous results on the same train-test split are from Seeker and Kuhn (2012), using the graphbased parser of Bohnet (2010) in a pipeline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13LEXSOFT averages 0.132 ms per sentence on an Intel i7- 3930K processor with 6 cores, against 0.112 ms for PIPELINE. </context>
<context position="45878" citStr="Bohnet (2010)" startWordPosition="7708" endWordPosition="7709"> with a beam size of 80. In our setup, we outperform this model by 0.5 points in both LAS and UAS. in the original paper, they only report results without punctuation – to be compared with 92.4 LAS and 94.1 UAS for our best model.15 In addition, our POS score of 98.4 is the highest reported for a tagger trained only on the Tiger Treebank, outperforming the previous best from Bohnet and Nivre (2012) by 0.3 percentage points. The only previous results on Hungarian using the same version of the treebank are from Farkas et al. (2012), who report 87.2 LAS and 90.1 UAS for the graph-based parser of Bohnet (2010). Our best results improve labeled accuracy by 2.1 points (89.3 LAS) and unlabeled accuracy by 1.6 points (91.7 UAS), which is again quite substantial. For Russian, Boguslavsky et al. (2011) report 86.0 LAS and 90.0 UAS using the rule-based ETAP-3 parser with an added statistical model and joint morphological and syntactic disambiguation. The scores are not strictly comparable, because we use a more recent version of the SynTagRus treebank (May 2013 vs. April 2011), but our results nevertheless show substantial improvements, in particular for UAS (93.0) but also for LAS (88.0). 8 Concluding Re</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), pages 89–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>24--42</pages>
<contexts>
<context position="20254" citStr="Brants et al., 2002" startWordPosition="3388" endWordPosition="3391">tation is automatic except for a subset of 1204 tokens in the test set, which will be used to estimate the POS, MOR, LEM, PM and PMD scores. The estimated accuracy of the automatic annotation is 97.3% POS and 94.8% PM (Haverinen et al., 2013). Also, because of the limited amount of data, we do not use a development set for Finnish but instead use cross-validation on the training set when tuning parameters. We use the open-source morphological analyzer OMorFi (Pirinen, 2011) and word clusters derived from the entire Finnish Wikipedia.6 German Training and test sets are from the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion by Seeker et al. (2010). We use the SMOR morphological analyzer (Schmid et al., 2004), but because the tags and morphological features in the lexicon are not the same as in the 5Downloaded from the http://lindat.cz repository as resource PID http://hdl.handle.net/11858/00-097C-0000-0015-A780-9. 6Downloaded in March 2012. 419 Treebank Morphology Clusters Train Dev Test P M D Forms Lemmas Tokens Types Czech 652,544 87,988 70,348 12 1851 49 98,360 42,058 628,332,859 477,185 Finnish 183,118 – 21,211 12 1917 47 57,127 25,280 50,207,300 257,984 German 648,296 3</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. TIGER treebank. In Proceedings of the 1st Workshop on Treebanks and Linguistic Theories (TLT), pages 24–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V deSouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--467</pages>
<contexts>
<context position="37597" citStr="Brown et al., 1992" startWordPosition="6302" endWordPosition="6305"> particularly striking for German, where the soft lexical constraints are clearly beneficial (especially for the MOR score) despite not being quite compatible with the morphological descriptions in the training set. In terms of statistical signifance, LEXSOFT outperforms the JOINT model with respect to the PMD score for all languages (p &lt; 0.01). It is also significantly better than LEXHARD for all languages except Finnish (p &lt; 0.01). 6 Word Clusters Finally, we add word cluster features to the best model for each language (LEXHARD for Finnish, LEXSOFT for the others).11 We use Brown clusters (Brown et al., 1992), with 800 clusters for all languages, and we use the same feature representation as Bohnet and Nivre (2012). The results in Table 2 show small but consistent improvements in almost all metrics for all languages, confirming the benefit of cluster features for morphologically rich languages. It is worth noting that we see the biggest improvement for Finnish, the language with the smallest training set and therefore most likely to 11The best model was selected according to results on the dev set (cross-validation on the training set for Finnish). 423 suffer from sparse data, where the syntactic </context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Classbased n-gram models of natural language. Computational Linguistics, 18:467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="2414" citStr="Buchholz and Marsi, 2006" startWordPosition="342" endWordPosition="345">re languages, it has also been observed that typological differences between languages lead to new challenges. In particular, it has been found over and over again that languages exhibiting rich morphological structure, often together with a relatively free word order, usually obtain lower parsing accuracy, especially in comparison to English. One striking demonstration of this tendency can be found in the CoNLL shared tasks on multilingual dependency parsing, organized in 2006 and 2007, where richly inflected languages clustered at the lower end of the scale with respect to parsing accuracy (Buchholz and Marsi, 2006; Nivre et al., 2007). These and similar observations have led to an increased interest in the special challenges posed by parsing morphologically rich languages, as evidenced most clearly by a new series of workshops devoted to this topic (Tsarfaty et al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing fram</context>
<context position="45076" citStr="Buchholz and Marsi, 2006" startWordPosition="7555" endWordPosition="7558">5.4). For German, the best previous results on the same train-test split are from Seeker and Kuhn (2012), using the graphbased parser of Bohnet (2010) in a pipeline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13LEXSOFT averages 0.132 ms per sentence on an Intel i7- 3930K processor with 6 cores, against 0.112 ms for PIPELINE. 14It is worth noting that there are a number of more recent parsing results for Czech, but they all use a different test set (and often a different training set), usually from one of the CoNLL shared tasks in 2006 (Buchholz and Marsi, 2006), 2007 (Nivre et al., 2007) and 2009 (Hajiˇc et al., 2009). For the 2009 data set, the best results are 83.73 LAS and 88.82 UAS from Bohnet and Nivre (2012), who use the SIMPLETAG model but with a beam size of 80. In our setup, we outperform this model by 0.5 points in both LAS and UAS. in the original paper, they only report results without punctuation – to be compared with 92.4 LAS and 94.1 UAS for our best model.15 In addition, our POS score of 98.4 is the highest reported for a tagger trained only on the Tiger Treebank, outperforming the previous best from Bohnet and Nivre (2012) by 0.3 pe</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Joint morphological and syntactic disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>208--217</pages>
<contexts>
<context position="4804" citStr="Cohen and Smith, 2007" startWordPosition="693" endWordPosition="696">ish), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that</context>
</contexts>
<marker>Cohen, Smith, 2007</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2007. Joint morphological and syntactic disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 208–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Giorgio Satta</author>
</authors>
<title>Exact inference for generative probabilistic non-projective dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1234--1245</pages>
<marker>Cohen, G´omez-Rodr´ıguez, Satta, 2011</marker>
<rawString>Shay B. Cohen, Carlos G´omez-Rodr´ıguez, and Giorgio Satta. 2011. Exact inference for generative probabilistic non-projective dependency parsing. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1234–1245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>112--119</pages>
<contexts>
<context position="17721" citStr="Collins and Roark, 2004" startWordPosition="2972" endWordPosition="2975"> input sentence x with weight vector w. The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; r, denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring transition sequence C∗0,m,.4 More precisely, we use the passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dep</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 112–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--8</pages>
<contexts>
<context position="16334" citStr="Collins (2002)" startWordPosition="2731" endWordPosition="2732"> linear for natural language data sets, due to the sparsity of non-projective dependencies (Nivre, 2009). The running time is also linear in |D |+ |P x M|, which means that joint prediction only gives a linear increase in running time, often quite marginal because |D |&gt; |P x M|. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. 418 PARSE(x, w) 1 h0.c cs(x) 2 h0.s 0.0 3 h0.f 10.01dim(w) 4 BEAM [h0] 5 while ]h E BEAM: h.c E� Ct 6 TMP [ ] 7 foreach h E BEAM 8 foreach t E T : PERMISSIBLE(h.c, t) 9 h.f h.f + f(x, h.c, t) 10 h.s h.s + f(</context>
<context position="18145" citStr="Collins (2002)" startWordPosition="3045" endWordPosition="3046">cisely, we use the passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-dependents and applies the lazy swapping strategy of Nivre et al. (2009). 3 Data Sets and Resources Throughout the paper, we experiment with data from five languages: Czech, Finnish, German, Hungarian, and Russian. For each language, we use a morphologically and syntactically annotated corpus (treebank), divided into a training set, a development set and a test set. In addition, we use a lexicon gene</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brooke Cowan</author>
<author>Michael Collins</author>
</authors>
<title>Morphology and reranking for the statistical parsing of spanish.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>795--802</pages>
<contexts>
<context position="4765" citStr="Cowan and Collins, 2005" startWordPosition="687" endWordPosition="690">and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus</context>
</contexts>
<marker>Cowan, Collins, 2005</marker>
<rawString>Brooke Cowan and Michael Collins. 2005. Morphology and reranking for the statistical parsing of spanish. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 795–802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="17600" citStr="Crammer et al. (2006)" startWordPosition="2952" endWordPosition="2955"> TMP) 13 BEAM PRUNE(TMP) 14 h∗ TOP(BEAM) 15 return rh∗ Figure 2: Beam search algorithm for finding the best MSparse for input sentence x with weight vector w. The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; r, denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring transition sequence C∗0,m,.4 More precisely, we use the passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequ</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Helmut Schmid</author>
</authors>
<title>Dependency parsing of hungarian: Baseline results and challenges.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chpater of the Association for Computational Linguistics (EACL),</booktitle>
<pages>55--65</pages>
<contexts>
<context position="21601" citStr="Farkas et al., 2012" startWordPosition="3593" endWordPosition="3596">249,814 538,138 Russian 575,400 72,893 71,664 14 454 78 97,905 35,039 195,897,041 639,446 Table 1: Statistics about data sets and resources used in the experiments. Treebank: number of tokens in data sets; number of labels in label sets. Morphology: number of word forms and lemmas in treebank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Rus</context>
<context position="45800" citStr="Farkas et al. (2012)" startWordPosition="7691" endWordPosition="7694">83.73 LAS and 88.82 UAS from Bohnet and Nivre (2012), who use the SIMPLETAG model but with a beam size of 80. In our setup, we outperform this model by 0.5 points in both LAS and UAS. in the original paper, they only report results without punctuation – to be compared with 92.4 LAS and 94.1 UAS for our best model.15 In addition, our POS score of 98.4 is the highest reported for a tagger trained only on the Tiger Treebank, outperforming the previous best from Bohnet and Nivre (2012) by 0.3 percentage points. The only previous results on Hungarian using the same version of the treebank are from Farkas et al. (2012), who report 87.2 LAS and 90.1 UAS for the graph-based parser of Bohnet (2010). Our best results improve labeled accuracy by 2.1 points (89.3 LAS) and unlabeled accuracy by 1.6 points (91.7 UAS), which is again quite substantial. For Russian, Boguslavsky et al. (2011) report 86.0 LAS and 90.0 UAS using the rule-based ETAP-3 parser with an added statistical model and joint morphological and syntactic disambiguation. The scores are not strictly comparable, because we use a more recent version of the SynTagRus treebank (May 2013 vs. April 2011), but our results nevertheless show substantial impro</context>
</contexts>
<marker>Farkas, Vincze, Schmid, 2012</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, and Helmut Schmid. 2012. Dependency parsing of hungarian: Baseline results and challenges. In Proceedings of the 13th Conference of the European Chpater of the Association for Computational Linguistics (EACL), pages 55–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Gesmundo</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Ivan Titov</author>
</authors>
<title>A latent variable model of synchronous syntactic-semantic parsing for multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>37--42</pages>
<contexts>
<context position="14387" citStr="Gesmundo et al. (2009)" startWordPosition="2407" endWordPosition="2410">ally binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi(x, c, t). The choice of features to include in f(x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency p</context>
</contexts>
<marker>Gesmundo, Henderson, Merlo, Titov, 2009</marker>
<rawString>Andrea Gesmundo, James Henderson, Paola Merlo, and Ivan Titov. 2009. A latent variable model of synchronous syntactic-semantic parsing for multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 37–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Word segmentation, unknown-word resolution, and morphological agreement in a hebrew parsing system.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<pages>39--121</pages>
<contexts>
<context position="5394" citStr="Goldberg and Elhadad (2013)" startWordPosition="785" endWordPosition="788">Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range </context>
</contexts>
<marker>Goldberg, Elhadad, 2013</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2013. Word segmentation, unknown-word resolution, and morphological agreement in a hebrew parsing system. Computational Linguistics, 39:121–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
</authors>
<title>A single generative model for joint morphological segmentation and syntactic parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>371--379</pages>
<contexts>
<context position="4834" citStr="Goldberg and Tsarfaty, 2008" startWordPosition="697" endWordPosition="700">case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-</context>
</contexts>
<marker>Goldberg, Tsarfaty, 2008</marker>
<rawString>Yoav Goldberg and Reut Tsarfaty. 2008. A single generative model for joint morphological segmentation and syntactic parsing. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), pages 371–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Barbora Hladk´a</author>
</authors>
<title>Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL) and the 17th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>483--490</pages>
<marker>Hajiˇc, Hladk´a, 1998</marker>
<rawString>Jan Hajiˇc and Barbora Hladk´a. 1998. Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL) and the 17th International Conference on Computational Linguistics (COLING), pages 483–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Barbora Vidova Hladka, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, and Petr Pajas.</title>
<date>2001</date>
<marker>Hajiˇc, 2001</marker>
<rawString>Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, and Petr Pajas. 2001. Prague Dependency Treebank 1.0. LDC, 2001T10.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The conll2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task,</booktitle>
<pages>1--18</pages>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The conll2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Morphological tagging: Data vs. dictionaries.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>94--101</pages>
<marker>Hajiˇc, 2000</marker>
<rawString>Jan Hajiˇc. 2000. Morphological tagging: Data vs. dictionaries. In Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 94–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P´eter Hal´acsy</author>
<author>Andr´as Kornai</author>
<author>Csaba Oravecz</author>
</authors>
<title>HunPos – an open source trigram tagger.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics: Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>209--212</pages>
<marker>Hal´acsy, Kornai, Oravecz, 2007</marker>
<rawString>P´eter Hal´acsy, Andr´as Kornai, and Csaba Oravecz. 2007. HunPos – an open source trigram tagger. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics: Companion Volume Proceedings of the Demo and Poster Sessions, pages 209– 212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Hatori</author>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Incremental joint pos tagging and dependency parsing in chinese.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1216--1224</pages>
<contexts>
<context position="14056" citStr="Hatori et al. (2011)" startWordPosition="2353" endWordPosition="2356"> parsing by Zhang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m) = f(x, C0,m) · w (2) m E f(x, ci, ti) · w i=0 Here, f(x, c, t) is a high-dimensional feature vector, where each component fi(x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi(x, c, t). The choice of features to include in f(x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that</context>
</contexts>
<marker>Hatori, Matsuzaki, Miyao, Tsujii, 2011</marker>
<rawString>Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2011. Incremental joint pos tagging and dependency parsing in chinese. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1216–1224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katri Haverinen</author>
<author>Jenna Nyblom</author>
</authors>
<title>Timo Viljanen, Veronika Laippala, Samuel Kohonen,</title>
<date>2013</date>
<location>Anna Missil¨a, Stina Ojala, Tapio</location>
<marker>Haverinen, Nyblom, 2013</marker>
<rawString>Katri Haverinen, Jenna Nyblom, Timo Viljanen, Veronika Laippala, Samuel Kohonen, Anna Missil¨a, Stina Ojala, Tapio Salakoski, and Filip Ginter. 2013. Building the essential resources for Finnish: the Turku Dependency Treebank. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1077--1086</pages>
<contexts>
<context position="16544" citStr="Huang and Sagae, 2010" startWordPosition="2759" endWordPosition="2762">linear increase in running time, often quite marginal because |D |&gt; |P x M|. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. 418 PARSE(x, w) 1 h0.c cs(x) 2 h0.s 0.0 3 h0.f 10.01dim(w) 4 BEAM [h0] 5 while ]h E BEAM: h.c E� Ct 6 TMP [ ] 7 foreach h E BEAM 8 foreach t E T : PERMISSIBLE(h.c, t) 9 h.f h.f + f(x, h.c, t) 10 h.s h.s + f(x, h.c, t) · w 11 h.c t(h.c) 12 TMP INSERT(h, TMP) 13 BEAM PRUNE(TMP) 14 h∗ TOP(BEAM) 15 return rh∗ Figure 2: Beam search algorithm for finding the best MSparse for input sentence x with weight vector w. The sy</context>
<context position="17768" citStr="Huang and Sagae, 2010" startWordPosition="2980" endWordPosition="2983">ols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; r, denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring transition sequence C∗0,m,.4 More precisely, we use the passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-dependents and applies the</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1077–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Iomdin</author>
<author>Viktor Sizov</author>
</authors>
<title>Lexicographer’s companion: A user-friendly software system for enlarging and updating high-profile computerized bilingual dictionaries.</title>
<date>2008</date>
<booktitle>In Lexicographic Tools and Techniques. MONDILEX First Open Workshop,</booktitle>
<pages>42--54</pages>
<contexts>
<context position="22100" citStr="Iomdin and Sizov, 2008" startWordPosition="3670" endWordPosition="3673">e so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training corpus. At both learning and parsing time, we preprocess sentences using a tagger that assigns (up to) kp part-of-speech tags and km morphological descriptions and a lemmatizer that assigns a single best l</context>
</contexts>
<marker>Iomdin, Sizov, 2008</marker>
<rawString>Leonid Iomdin and Viktor Sizov. 2008. Lexicographer’s companion: A user-friendly software system for enlarging and updating high-profile computerized bilingual dictionaries. In Lexicographic Tools and Techniques. MONDILEX First Open Workshop, pages 42– 54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>595--603</pages>
<contexts>
<context position="5776" citStr="Koo et al. (2008)" startWordPosition="843" endWordPosition="846">rphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range of morphological information. We start by investigating different ways of integrating morphological features into the model, go on to examine the effect of using rule-based morphological analyzers to derive hard or soft constraints on the morphological analysis, and finally add word cluster features to combat lexical sparsity. We evaluate our methods on data from Czech, Finnish, </context>
<context position="40712" citStr="Koo et al., 2008" startWordPosition="6815" endWordPosition="6818"> is again Finnish, where the hard constraint model works marginally better (except for the MOR and PM metrics), which may again indicate that the training set is too small to make optimal use of the additional features. Still, the soft constraint model improves substantially over the models without lexical resources also for Finnish. Finally, our experiments confirm that features based on distributional word clusters have a positive impact on syntactic accuracy, but little or no impact on morphological accuracy. This is consistent with previous findings in the literature, mainly from English (Koo et al., 2008; Sagae and Gordon, 2009), and it is interesting to see that it holds also for richly inflected languages and when added on top of features derived from external lexical resources. One issue worth discussing is the choice to allow the joint model to consider at most 2 tags and 2 morphological descriptions per word, which may seem overly restrictive and very close to a pipeline model. As already mentioned, this was motivated by the results of Bohnet and Nivre (2012), which explored higher values without seeing any improvements, as well as by our own preliminary experiments. In an attempt to she</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), pages 595–603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1288--1298</pages>
<contexts>
<context position="43748" citStr="Koo et al. (2010)" startWordPosition="7329" endWordPosition="7332">ores are actually higher for ORACLE than for GOLD, indicating that the LEXSOFT model has in its final beam dependency trees that are better than the 1-best trees predicted with perfect morphological input and suggesting that there is room for further improvement of the scoring model. The final results obtained with joint prediction of morphology and syntax, external lexical constraints, and cluster features represent a new state of the art for syntactic dependency parsing for all five languages. For Czech, the best previous UAS on the standard train-test split of the PDT is 87.32, reported by Koo et al. (2010) with a parser using non-projective head automata and dual decomposition, while the best LAS is 78.82 LAS from Nilsson et al. (2006), using a greedy arc-eager transitionbased system with pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1288–1298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing.</title>
<date>2009</date>
<publisher>Morgan</publisher>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. Morgan and Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Giorgio Satta</author>
</authors>
<title>Dynamic programming algorithms for transition-based dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>673--682</pages>
<marker>Kuhlmann, G´omez-Rodr´ıguez, Satta, 2011</marker>
<rawString>Marco Kuhlmann, Carlos G´omez-Rodr´ıguez, and Giorgio Satta. 2011. Dynamic programming algorithms for transition-based dependency parsers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 673–682.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
</authors>
<title>A discriminative model for joint morphological disambiguation and dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>885--894</pages>
<contexts>
<context position="3283" citStr="Lee et al. (2011)" startWordPosition="477" endWordPosition="480"> al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing frameworks (Tsarfaty et al., 2010; Tsarfaty et al., 2013). This is true in particular for data-driven dependency parsers, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computat</context>
</contexts>
<marker>Lee, Naradowsky, Smith, 2011</marker>
<rawString>John Lee, Jason Naradowsky, and David A. Smith. 2011. A discriminative model for joint morphological disambiguation and dependency parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 885–894.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
</authors>
<title>Graph transformations in data-driven dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>257--264</pages>
<contexts>
<context position="43880" citStr="Nilsson et al. (2006)" startWordPosition="7352" endWordPosition="7355"> are better than the 1-best trees predicted with perfect morphological input and suggesting that there is room for further improvement of the scoring model. The final results obtained with joint prediction of morphology and syntax, external lexical constraints, and cluster features represent a new state of the art for syntactic dependency parsing for all five languages. For Czech, the best previous UAS on the standard train-test split of the PDT is 87.32, reported by Koo et al. (2010) with a parser using non-projective head automata and dual decomposition, while the best LAS is 78.82 LAS from Nilsson et al. (2006), using a greedy arc-eager transitionbased system with pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score, obtained with the HunPos tagger (Hal´acsy et al., 2007) together with the OMorFi analyzer (95.7 vs. 95.4). For German, the best pr</context>
</contexts>
<marker>Nilsson, Nivre, Hall, 2006</marker>
<rawString>Jens Nilsson, Joakim Nivre, and Johan Hall. 2006. Graph transformations in data-driven dependency parsing. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 257–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Marco Kuhlmann</author>
<author>Johan Hall</author>
</authors>
<title>An improved oracle for dependency parsing with online reordering.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>73--76</pages>
<contexts>
<context position="18414" citStr="Nivre et al. (2009)" startWordPosition="3084" endWordPosition="3087">ing time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-dependents and applies the lazy swapping strategy of Nivre et al. (2009). 3 Data Sets and Resources Throughout the paper, we experiment with data from five languages: Czech, Finnish, German, Hungarian, and Russian. For each language, we use a morphologically and syntactically annotated corpus (treebank), divided into a training set, a development set and a test set. In addition, we use a lexicon generated by a rule-based morphological analyzer, and distributional word clusters derived from a large unlabeled corpus. Below we describe the specific resources used for each language. Table 1 provides descriptive statistics about the resources. Czech For training and te</context>
</contexts>
<marker>Nivre, Kuhlmann, Hall, 2009</marker>
<rawString>Joakim Nivre, Marco Kuhlmann, and Johan Hall. 2009. An improved oracle for dependency parsing with online reordering. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 73–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>149--160</pages>
<contexts>
<context position="14627" citStr="Nivre, 2003" startWordPosition="2442" endWordPosition="2443">el in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the SWAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different imple</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Incrementality in deterministic dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together (ACL),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="14135" citStr="Nivre, 2004" startWordPosition="2367" endWordPosition="2368"> whose feature representations decompose in the same way: s(x, C0,m) = f(x, C0,m) · w (2) m E f(x, ci, ti) · w i=0 Here, f(x, c, t) is a high-dimensional feature vector, where each component fi(x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi(x, c, t). The choice of features to include in f(x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; </context>
</contexts>
<marker>Nivre, 2004</marker>
<rawString>Joakim Nivre. 2004. Incrementality in deterministic dependency parsing. In Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together (ACL), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Non-projective dependency parsing in expected linear time.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP),</booktitle>
<pages>351--359</pages>
<contexts>
<context position="12067" citStr="Nivre (2009)" startWordPosition="2003" endWordPosition="2004">e x, and Γ = (A, π, µ, λ, δ) is an MS-parse for x. We take the initial configuration for a sentence x = w1, ... , wn to be cs(x) = ([0], [1, ... , n], (�, L, L, L, L)), where L is the function that is undefined for all arguments, and we take the set Ct of terminal configurations to be the set of all configurations of the form c = ([0], [ ], Γ) (for any Γ). The MS-parse defined for x by c = (Σ, B, (A, π, µ, λ, δ)) is Γc = (A, π, µ, λ, δ), and the MS-parse defined for x by a complete transition sequence C0,m is Γt.(c.). The set T of transitions is shown in Figure 1. It is based on the system of Nivre (2009), where a dependency tree is built by repeated applications of the LEFT-ARCd and RIGHT-ARCd transitions, which add an arc (with some label d E D) between the two topmost nodes on the stack (with the leftmost or rightmost node as the dependent, respectively). The SHIFT transition is used to move nodes from the buffer to the stack, and the SWAP transition is used 417 to permute nodes in order to allow non-projective dependencies. Bohnet and Nivre (2012) modified this system by replacing the simple SHIFT transition by SHIFTp, which not only moves a node from the buffer to the stack but also assig</context>
<context position="15824" citStr="Nivre, 2009" startWordPosition="2640" endWordPosition="2641">different implementations of the permissibility condition invoked in line 8, which can be used to filter out labels that are improbable or incompatible with an external lexicon, and the pruning step performed in line 13, where there may be a need to balance the amount of morphological and syntactic variation in the beam. Both these aspects will be discussed in depth in Sections 4–6. Although the worst-case running time with constant beam size is quadratic in sentence length, the observed running time is linear for natural language data sets, due to the sparsity of non-projective dependencies (Nivre, 2009). The running time is also linear in |D |+ |P x M|, which means that joint prediction only gives a linear increase in running time, often quite marginal because |D |&gt; |P x M|. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all </context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Non-projective dependency parsing in expected linear time. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP), pages 351–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommi A Pirinen</author>
</authors>
<title>Modularisation of finnish finite-state language description – towards wide collaboration in open source development of a morphological analyser.</title>
<date>2011</date>
<booktitle>In Proceedings of the 18th Nordic Conference of Computational Linguistics (NODALIDA),</booktitle>
<pages>299--302</pages>
<contexts>
<context position="20112" citStr="Pirinen, 2011" startWordPosition="3366" endWordPosition="3368">ebank developers. It is worth noting that, while the entire treebank has manually validated syntactic annotation, the morphological annotation is automatic except for a subset of 1204 tokens in the test set, which will be used to estimate the POS, MOR, LEM, PM and PMD scores. The estimated accuracy of the automatic annotation is 97.3% POS and 94.8% PM (Haverinen et al., 2013). Also, because of the limited amount of data, we do not use a development set for Finnish but instead use cross-validation on the training set when tuning parameters. We use the open-source morphological analyzer OMorFi (Pirinen, 2011) and word clusters derived from the entire Finnish Wikipedia.6 German Training and test sets are from the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion by Seeker et al. (2010). We use the SMOR morphological analyzer (Schmid et al., 2004), but because the tags and morphological features in the lexicon are not the same as in the 5Downloaded from the http://lindat.cz repository as resource PID http://hdl.handle.net/11858/00-097C-0000-0015-A780-9. 6Downloaded in March 2012. 419 Treebank Morphology Clusters Train Dev Test P M D Forms Lemmas Tokens Types Czech 652,544 87</context>
</contexts>
<marker>Pirinen, 2011</marker>
<rawString>Tommi A. Pirinen. 2011. Modularisation of finnish finite-state language description – towards wide collaboration in open source development of a morphological analyser. In Proceedings of the 18th Nordic Conference of Computational Linguistics (NODALIDA), pages 299–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Andrew S Gordon</author>
</authors>
<title>Clustering words by syntactic similarity improves dependency parsing of predicate-argument structures.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT),</booktitle>
<pages>192--201</pages>
<contexts>
<context position="40737" citStr="Sagae and Gordon, 2009" startWordPosition="6819" endWordPosition="6822"> where the hard constraint model works marginally better (except for the MOR and PM metrics), which may again indicate that the training set is too small to make optimal use of the additional features. Still, the soft constraint model improves substantially over the models without lexical resources also for Finnish. Finally, our experiments confirm that features based on distributional word clusters have a positive impact on syntactic accuracy, but little or no impact on morphological accuracy. This is consistent with previous findings in the literature, mainly from English (Koo et al., 2008; Sagae and Gordon, 2009), and it is interesting to see that it holds also for richly inflected languages and when added on top of features derived from external lexical resources. One issue worth discussing is the choice to allow the joint model to consider at most 2 tags and 2 morphological descriptions per word, which may seem overly restrictive and very close to a pipeline model. As already mentioned, this was motivated by the results of Bohnet and Nivre (2012), which explored higher values without seeing any improvements, as well as by our own preliminary experiments. In an attempt to shed further light on this i</context>
</contexts>
<marker>Sagae, Gordon, 2009</marker>
<rawString>Kenji Sagae and Andrew S. Gordon. 2009. Clustering words by syntactic similarity improves dependency parsing of predicate-argument structures. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 192–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Arne Fitschen</author>
<author>Ulrich Heid</author>
</authors>
<title>SMOR: A German computational morphology covering derivation, composition and inflection.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1263--1266</pages>
<contexts>
<context position="20378" citStr="Schmid et al., 2004" startWordPosition="3409" endWordPosition="3412"> and PMD scores. The estimated accuracy of the automatic annotation is 97.3% POS and 94.8% PM (Haverinen et al., 2013). Also, because of the limited amount of data, we do not use a development set for Finnish but instead use cross-validation on the training set when tuning parameters. We use the open-source morphological analyzer OMorFi (Pirinen, 2011) and word clusters derived from the entire Finnish Wikipedia.6 German Training and test sets are from the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion by Seeker et al. (2010). We use the SMOR morphological analyzer (Schmid et al., 2004), but because the tags and morphological features in the lexicon are not the same as in the 5Downloaded from the http://lindat.cz repository as resource PID http://hdl.handle.net/11858/00-097C-0000-0015-A780-9. 6Downloaded in March 2012. 419 Treebank Morphology Clusters Train Dev Test P M D Forms Lemmas Tokens Types Czech 652,544 87,988 70,348 12 1851 49 98,360 42,058 628,332,859 477,185 Finnish 183,118 – 21,211 12 1917 47 57,127 25,280 50,207,300 257,984 German 648,296 32,065 31,692 54 257 43 76,729 55,220 1,327,701,182 1,621,083 Hungarian 1,101,871 210,068 171,466 22 1105 33 151,971 71,263 2</context>
</contexts>
<marker>Schmid, Fitschen, Heid, 2004</marker>
<rawString>Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004. SMOR: A German computational morphology covering derivation, composition and inflection. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC), pages 1263– 1266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Seeker</author>
<author>Jonas Kuhn</author>
</authors>
<title>Making ellipses explicit in dependency conversion for a german treebank.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>3132--3139</pages>
<contexts>
<context position="44555" citStr="Seeker and Kuhn (2012)" startWordPosition="7461" endWordPosition="7464">h pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score, obtained with the HunPos tagger (Hal´acsy et al., 2007) together with the OMorFi analyzer (95.7 vs. 95.4). For German, the best previous results on the same train-test split are from Seeker and Kuhn (2012), using the graphbased parser of Bohnet (2010) in a pipeline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13LEXSOFT averages 0.132 ms per sentence on an Intel i7- 3930K processor with 6 cores, against 0.112 ms for PIPELINE. 14It is worth noting that there are a number of more recent parsing results for Czech, but they all use a different test set (and often a different training set), usually from one of the CoNLL shared tasks in 2006 (Buchholz and Marsi, 2006), 2007 (Nivre et al., 2007) and 2009 (Hajiˇc et al., 2009). For the 2009 data s</context>
</contexts>
<marker>Seeker, Kuhn, 2012</marker>
<rawString>Wolfgang Seeker and Jonas Kuhn. 2012. Making ellipses explicit in dependency conversion for a german treebank. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC), pages 3132–3139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Seeker</author>
<author>Bernd Bohnet</author>
<author>Lilja Øvrelid</author>
<author>Jonas Kuhn</author>
</authors>
<title>Informed ways of improving data-driven dependency parsing for german. In Coling 2010: Posters,</title>
<date>2010</date>
<pages>1122--1130</pages>
<contexts>
<context position="20316" citStr="Seeker et al. (2010)" startWordPosition="3399" endWordPosition="3402">test set, which will be used to estimate the POS, MOR, LEM, PM and PMD scores. The estimated accuracy of the automatic annotation is 97.3% POS and 94.8% PM (Haverinen et al., 2013). Also, because of the limited amount of data, we do not use a development set for Finnish but instead use cross-validation on the training set when tuning parameters. We use the open-source morphological analyzer OMorFi (Pirinen, 2011) and word clusters derived from the entire Finnish Wikipedia.6 German Training and test sets are from the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion by Seeker et al. (2010). We use the SMOR morphological analyzer (Schmid et al., 2004), but because the tags and morphological features in the lexicon are not the same as in the 5Downloaded from the http://lindat.cz repository as resource PID http://hdl.handle.net/11858/00-097C-0000-0015-A780-9. 6Downloaded in March 2012. 419 Treebank Morphology Clusters Train Dev Test P M D Forms Lemmas Tokens Types Czech 652,544 87,988 70,348 12 1851 49 98,360 42,058 628,332,859 477,185 Finnish 183,118 – 21,211 12 1917 47 57,127 25,280 50,207,300 257,984 German 648,296 32,065 31,692 54 257 43 76,729 55,220 1,327,701,182 1,621,083 H</context>
</contexts>
<marker>Seeker, Bohnet, Øvrelid, Kuhn, 2010</marker>
<rawString>Wolfgang Seeker, Bernd Bohnet, Lilja Øvrelid, and Jonas Kuhn. 2010. Informed ways of improving data-driven dependency parsing for german. In Coling 2010: Posters, pages 1122–1130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanka Spoustov´a</author>
<author>Miroslav Spousta</author>
</authors>
<title>A highquality web corpus of czech.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>311--315</pages>
<marker>Spoustov´a, Spousta, 2012</marker>
<rawString>Johanka Spoustov´a and Miroslav Spousta. 2012. A highquality web corpus of czech. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012), pages 311–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>A latent variable model for generative dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies (IWPT),</booktitle>
<pages>144--155</pages>
<contexts>
<context position="14203" citStr="Titov and Henderson (2007)" startWordPosition="2374" endWordPosition="2377">ay: s(x, C0,m) = f(x, C0,m) · w (2) m E f(x, ci, ti) · w i=0 Here, f(x, c, t) is a high-dimensional feature vector, where each component fi(x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi(x, c, t). The choice of features to include in f(x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders </context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>Ivan Titov and James Henderson. 2007. A latent variable model for generative dependency parsing. In Proceedings of the 10th International Conference on Parsing Technologies (IWPT), pages 144–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viktor Tr´on</author>
<author>P´eter Hal´acsy</author>
<author>P´eter Rebrus</author>
<author>Andr´as Rung</author>
<author>Eszter Simon</author>
<author>P´eter Vajda</author>
</authors>
<title>Morphdb.hu: Hungarian lexical database and morphological grammar.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1670--1673</pages>
<marker>Tr´on, Hal´acsy, Rebrus, Rung, Simon, Vajda, 2006</marker>
<rawString>Viktor Tr´on, P´eter Hal´acsy, P´eter Rebrus, Andr´as Rung, Eszter Simon, and P´eter Vajda. 2006. Morphdb.hu: Hungarian lexical database and morphological grammar. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), pages 1670–1673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djam´e Seddah</author>
<author>Yoav Goldberg</author>
<author>Sandra Kuebler</author>
<author>Yannick Versley</author>
<author>Marie Candito</author>
<author>Jennifer Foster</author>
<author>Ines Rehbein</author>
<author>Lamia Tounsi</author>
</authors>
<title>Statistical parsing of morphologically rich languages (spmrl) what, how and whither.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="2677" citStr="Tsarfaty et al., 2010" startWordPosition="385" endWordPosition="388">der, usually obtain lower parsing accuracy, especially in comparison to English. One striking demonstration of this tendency can be found in the CoNLL shared tasks on multilingual dependency parsing, organized in 2006 and 2007, where richly inflected languages clustered at the lower end of the scale with respect to parsing accuracy (Buchholz and Marsi, 2006; Nivre et al., 2007). These and similar observations have led to an increased interest in the special challenges posed by parsing morphologically rich languages, as evidenced most clearly by a new series of workshops devoted to this topic (Tsarfaty et al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing frameworks (Tsarfaty et al., 2010; Tsarfaty et al., 2013). This is true in particular for data-driven dependency parsers, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. </context>
<context position="5063" citStr="Tsarfaty et al., 2010" startWordPosition="732" endWordPosition="735">rsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of </context>
</contexts>
<marker>Tsarfaty, Seddah, Goldberg, Kuebler, Versley, Candito, Foster, Rehbein, Tounsi, 2010</marker>
<rawString>Reut Tsarfaty, Djam´e Seddah, Yoav Goldberg, Sandra Kuebler, Yannick Versley, Marie Candito, Jennifer Foster, Ines Rehbein, and Lamia Tounsi. 2010. Statistical parsing of morphologically rich languages (spmrl) what, how and whither. In Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djam´e Seddah</author>
<author>Sandra K¨ubler</author>
<author>Joakim Nivre</author>
</authors>
<title>Parsing morphologicall rich languages: Introduction to the special issue.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<pages>39--15</pages>
<marker>Tsarfaty, Seddah, K¨ubler, Nivre, 2013</marker>
<rawString>Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and Joakim Nivre. 2013. Parsing morphologicall rich languages: Introduction to the special issue. Computational Linguistics, 39:15–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
</authors>
<title>Integrated morphological and syntactic disambiguation for modern hebrew.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Student Research Workshop,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="4781" citStr="Tsarfaty, 2006" startWordPosition="691" endWordPosition="692">Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and E</context>
</contexts>
<marker>Tsarfaty, 2006</marker>
<rawString>Reut Tsarfaty. 2006. Integrated morphological and syntactic disambiguation for modern hebrew. In Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tam´as V´aradi</author>
</authors>
<title>The hungarian national corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>385--389</pages>
<marker>V´aradi, 2002</marker>
<rawString>Tam´as V´aradi. 2002. The hungarian national corpus. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC), pages 385–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>195--206</pages>
<contexts>
<context position="14613" citStr="Yamada and Matsumoto, 2003" startWordPosition="2437" endWordPosition="2441">ach instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the SWAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly d</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>562--571</pages>
<contexts>
<context position="13470" citStr="Zhang and Clark (2008)" startWordPosition="2242" endWordPosition="2245">n, so that a node moved from the buffer to the stack is assigned not only a tag p but also a morphological description m and a lemma l. In this way, we get a joint model for the prediction of part-ofspeech tags, morphological features, lemmas, and dependency trees. 2.3 Scoring In transition-based parsing, we score parses in an indirect fashion by scoring transition sequences. In general, we assume that the score function s factors by configuration-transition pairs: m s(x, C0,m) = E s(x, ci, ti) (1) i=0 Moreover, when using structured learning, as first proposed for transition-based parsing by Zhang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m) = f(x, C0,m) · w (2) m E f(x, ci, ti) · w i=0 Here, f(x, c, t) is a high-dimensional feature vector, where each component fi(x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi(x, c, t). The choice of features to include in f(x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2Hatori et al. (2011) previously ma</context>
<context position="14733" citStr="Zhang and Clark, 2008" startWordPosition="2458" endWordPosition="2461">rd system (Nivre, 2004), without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the SWAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different implementations of the permissibility condition invoked in line 8, which can be used to filter out labels that </context>
<context position="16404" citStr="Zhang and Clark (2008)" startWordPosition="2740" endWordPosition="2743"> non-projective dependencies (Nivre, 2009). The running time is also linear in |D |+ |P x M|, which means that joint prediction only gives a linear increase in running time, often quite marginal because |D |&gt; |P x M|. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. 418 PARSE(x, w) 1 h0.c cs(x) 2 h0.s 0.0 3 h0.f 10.01dim(w) 4 BEAM [h0] 5 while ]h E BEAM: h.c E� Ct 6 TMP [ ] 7 foreach h E BEAM 8 foreach t E T : PERMISSIBLE(h.c, t) 9 h.f h.f + f(x, h.c, t) 10 h.s h.s + f(x, h.c, t) · w 11 h.c t(h.c) 12 TMP INSERT(h, TMP) 13 BEAM PRUNE(TMP) </context>
<context position="17744" citStr="Zhang and Clark, 2008" startWordPosition="2976" endWordPosition="2979">ight vector w. The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; r, denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring transition sequence C∗0,m,.4 More precisely, we use the passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-de</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 562–571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="27501" citStr="Zhang and Nivre (2011)" startWordPosition="4556" endWordPosition="4559">ection 7, we present an empirical analysis that gives further support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the JOINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the PIPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a go</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Analyzing the effect of global learning and beam-search on transitionbased dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012: Posters,</booktitle>
<pages>1391--1400</pages>
<contexts>
<context position="14757" citStr="Zhang and Nivre, 2012" startWordPosition="2462" endWordPosition="2465">, without the SWAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the SHIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the SWAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different implementations of the permissibility condition invoked in line 8, which can be used to filter out labels that are improbable or incomp</context>
</contexts>
<marker>Zhang, Nivre, 2012</marker>
<rawString>Yue Zhang and Joakim Nivre. 2012. Analyzing the effect of global learning and beam-search on transitionbased dependency parsing. In Proceedings of COLING 2012: Posters, pages 1391–1400.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>