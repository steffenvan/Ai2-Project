<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.89529">
The Impact of Z_score on Twitter Sentiment Analysis
</title>
<author confidence="0.802962">
Hussam Hamdan*,**,***
</author>
<bodyText confidence="0.19888315">
*LSIS
Aix-Marseille Université CNRS
Av. Esc. Normandie Niemen,
13397 Marseille Cedex 20,
France
hussam.hamdan@lsis.org
Patrice Bellot*,**
**OpenEdition
Aix-Marseille Université CNRS
3 pl. V. Hugo, case n°86
13331 Marseille Cedex 3,
France
patrice.bellot@lsis.org
Frederic Béchet***
***LIF
Aix-Marseille Université CNRS
Avenue de Luminy
13288 Marseille Cedex 9,
France
frederic.bechet@lif.univ-mrs.fr
</bodyText>
<sectionHeader confidence="0.985927" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999876928571429">
Twitter has become more and more an im-
portant resource of user-generated data. Sen-
timent Analysis in Twitter is interesting for
many applications and objectives. In this pa-
per, we propose to exploit some features
which can be useful for this task; the main
contribution is the use of Z-scores as features
for sentiment classification in addition to
pre-polarity and POS tags features. Our ex-
periments have been evaluated using the test
data provided by SemEval 2013 and 2014.
The evaluation demonstrates that Z_scores
features can significantly improve the predic-
tion performance.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999898333333333">
The interactive Web has changed the relation
between the users and the web. Users have be-
come an important source of content. They ex-
press their opinion towards different issues. The-
se opinions are important for others who are in-
terested in understanding users’ interests such as
buyers, sellers and producers.
Twitter is one of the most important platforms in
which the users express their opinions. Many
works have exploited this media for predicting
valuable issues depending on Sentiment Analysis
(SA). The authors in (Asur and Huberman 2010)
predicted the box-office revenues of movies in
advance of their releases using the tweets talking
about them. In (Bae and Lee 2012) Sentiment
</bodyText>
<footnote confidence="0.7159996">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers
and proceedings footer are added by the organisers.
Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.971642775">
Analysis has been used to study the impact of 13
twitter accounts of famous persons on their fol-
lowers and also for forecasting the interesting
tweets which are more probably to be reposted
by the followers (Naveed, Gottron et al. 2011).
Sentiment Analysis can be done in different lev-
els; Document level; Sentence level; Clause level
or Aspect-Based level. SA in Twitter can be seen
as a sentence level task, but some limitations
should be considered in such sentences. The size
of tweets is limited to 140 characters, informal
language, emotion icons and non-standard ex-
pressions are commonly used, and many spelling
errors can be found due to the absence of cor-
rectness verification.
Three different approaches can be identified in
the literature of Sentiment Analysis in Twitter,
the first approach is lexicon based, using specific
types of lexicons to derive the polarity of a text,
this approach suffers from the limited size of lex-
icon and requires human expertise to build man-
ual lexicon (Joshi, Balamurali et al. 2011), in the
other hand the automatic lexicons are not so effi-
cient. The second one is machine learning ap-
proach which uses annotated texts with a given
labels to learn a classification model, an early
work was done on a movie review dataset (Pang,
Lee et al. 2002). Both lexicon and machine learn-
ing approaches can be combined to achieve a
better performance (Khuc, Shivade et al. 2012).
These two approaches are used for SA task but
the third one is specific for Twitter or social con-
tent, the social approach exploits social network
properties and data for enhancing the accuracy of
the classification (Speriosu, Sudan et al. 2011).
In this paper, we exploit machine learning al-
gorithm with the aid of some features:
• The original Terms: the terms represent-
ing the tweet after the tokenization and
stemming;
</bodyText>
<page confidence="0.993231">
636
</page>
<note confidence="0.627196">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 636–641,
Dublin, Ireland, August 23-24, 2014.
</note>
<listItem confidence="0.962183111111111">
• Pre-polarity features: the number of neg-
ative, positive and neutral words extract-
ed from two sentiment lexicons;
• POS tags: the number of adjectives, con-
nectors, verbs, nouns, adverbs in the
tweet;
• Z-score: The numbers of terms having Z-
score value more than three for each
class positive, negative and neutral.
</listItem>
<bodyText confidence="0.999973538461538">
We extended the original terms with these last
features. We also constructed a dictionary for the
abbreviations and the slang words used in Twit-
ter in order to overcome the ambiguity of the
tweets. We tested the performance of every pos-
sible combination of these features.
The rest of this paper is organized as follows.
Section 2 outlines previous work that focused on
sentiment analysis in Twitter. Section 3 presents
the Z_score features and the others which we
used for training a classifier. Our experiments are
described in section 4, conclusion and future
work is presented in section 5.
</bodyText>
<sectionHeader confidence="0.999029" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999990225806452">
We can identify three main approaches for sen-
timent analysis in Twitter. The lexicon based
approaches which depend on sentiment lexicons
containing positive, negative and neutral words
or expressions; they calculate the polarity ac-
cording to the number of common opinionated
words between the lexicons and the text. Many
dictionaries have been created manually such as
ANEW (Affective Norms for English Words) or
automatically such as SentiWordNet
(Baccianella, Esuli et al. 2010). Four lexicon dic-
tionaries were used to overcome the lack of
words in each one (Joshi, Balamurali et al. 2011;
Mukherjee, Malu et al. 2012). Automatically
construction of a Twitter lexicon was imple-
mented by (Khuc, Shivade et al. 2012).
Machine learning approaches were employed
from annotated tweets by using Naive Bayes,
Maximum Entropy MaxEnt and Support Vector
Machines (SVM). The authors (Go, Bhayani et
al. 2009) reported that SVM outperforms other
classifiers. They tried a unigram and a bigram
model in conjunction with parts-of-speech (POS)
features; they noted that the unigram model out-
performs all other models when using SVM and
that POS features decrease the quality of results.
The authors in (Kouloumpis, Wilson et al. 2011)
found that N-gram with lexicon features and mi-
cro-blogging features are useful but POS features
are not. In contrast, in (Pak and Paroubek 2010)
they reported that POS and bigrams both help. In
(Barbosa and Feng 2010) the authors proposed
the use of syntax features of tweets like retweet,
hashtags, link, punctuation and exclamation
marks in conjunction with features like prior po-
larity of words and POS tags, in (Agarwal, Xie et
al. 2011) this approach was extended by using
real valued prior polarity and by combining prior
polarity with POS. Authors in (Saif, He et al.
2012) proposed to use the semantic features,
therefore they extracted the named entities in the
tweets. Authors in (Hamdan, Béchet et al. 2013)
used the concepts extracted from DBpedia and
the adjectives from WordNet, they reported that
the DBpedia concepts are useful with Naïve-
Bayes classifier but less useful with SVM.
The third main approach takes into account
the influence of users on their followers and the
relation between the users and the tweets they
wrote. It assumes that using the Twitter follower
graph might improve the polarity classification.
In (Speriosu, Sudan et al. 2011) they demonstrat-
ed that using label propagation with Twitter fol-
lower graph improves the polarity classification.
In (Tan, Lee et al. 2011) they employed social
relation for user-level sentiment analysis. In (Hu,
Tang et al. 2013) a Sociological Approach to
handling the Noisy and short Text (SANT) for
supervised sentiment classification is used; they
reported that social theories such as Sentiment
Consistency and Emotional Contagion could be
helpful for sentiment analysis.
</bodyText>
<sectionHeader confidence="0.991443" genericHeader="method">
3 Feature Selection
</sectionHeader>
<bodyText confidence="0.975157421052632">
We used different types of features in order to
improve the accuracy of sentiment classification.
- Bag of words (Terms)
The most commonly used features in text analy-
sis are the bag of words which represent a text as
unordered set of words or terms. It assumes that
words are independent from each other and also
disregards their order of appearance. We
stemmed the words using Porter Stemmer and
used them as a baseline features.
- Z_score Features (Z)
We suggest using a new type of features for Sen-
timent Analysis, Z_score can distinguish the im-
portance of each term in each class. We compute
the number of terms having Z_score more than
three for each class over each tweet. We assume
that the term frequencies follow the multinomial
distribution. Thus, Z_score can be seen as a
standardization of the term. We compute the
</bodyText>
<page confidence="0.992788">
637
</page>
<bodyText confidence="0.99855">
Z_score for each term ti in a class Cj (tij) by cal-
culating its term relative frequency tfrij in a par-
ticular class Cj, as well as the mean (meani)
which is the term probability over the whole cor-
pus multiplied by nj the number of terms in the
class Cj, and standard deviation (sdi) of term ti
according to the underlying corpus (see Eq.
(1,2)).
</bodyText>
<equation confidence="0.9956542">
tfrij-mean;
Zscore(tij) _ sdi Eq. (1)
_ tfrij-nj*p(ti)
Zscore(tij) Eq. (2)
�n�*p(t�)*(��p(t�))
</equation>
<bodyText confidence="0.999563954545454">
The term which has salient frequency in a class
in compassion to others will have a salient
Z_score. Z_score was exploited for SA by
(Zubaryeva and Savoy 2010) , they choose a
threshold (&gt;2) for selecting the number of terms
having Z_score more than the threshold, then
they used a logistic regression for combining
these scores. We use Z_scores as added features
for classification because the tweet is too short,
therefore many tweets does not have any words
with salient Z_score. The three following figures
1,2,3 show the distribution of Z_score over each
class, we remark that the majority of terms has
Z_score between -1.5 and 2.5 in each class and
the rest are either vey frequent (&gt;2.5) or very rare
(&lt;-1.5). It should indicate that negative value
means that the term is not frequent in this class in
comparison with its frequencies in other classes.
Table1 demonstrates the first ten terms having
the highest Z_scores in each class. We have test-
ed to use different values for the threshold, the
best results was obtained when the threshold is 3.
</bodyText>
<table confidence="0.999720727272727">
positive Z_score negative Z_score Neutra Z_score
Love 14.31 Not 13.99 Httpbit 6.44
Good 14.01 Fuck 12.97 Httpfb 4.56
Happy 12.30 Don’t 10.97 Httpbnd 3.78
Great 11.10 Shit 8.99 Intern 3.58
Excite 10.35 Bad 8.40 Nov 3.45
Best 9.24 Hate 8.29 Httpdlvr 3.40
Thank 9.21 Sad 8.28 Open 3.30
Hope 8.24 Sorry 8.11 Live 3.28
Cant 8.10 Cancel 7.53 Cloud 3.28
Wait 8.05 stupid 6.83 begin 3.17
</table>
<tableCaption confidence="0.6628525">
Table1. The first ten terms having the highest Z_score in
each class
</tableCaption>
<sectionHeader confidence="0.469634" genericHeader="method">
- Sentiment Lexicon Features (POL)
</sectionHeader>
<bodyText confidence="0.999001">
We used two sentiment lexicons, MPQA Subjec-
tivity Lexicon(Wilson, Wiebe et al. 2005) and
Bing Liu&apos;s Opinion Lexicon which is created by
(Hu and Liu 2004) and augmented in many latter
works. We extract the number of positive, nega-
tive and neutral words in tweets according to the-
se lexicons. Bing Liu&apos;s lexicon only contains
negative and positive annotation but Subjectivity
contains negative, positive and neutral.
</bodyText>
<listItem confidence="0.306706">
- Part Of Speech (POS)
</listItem>
<bodyText confidence="0.99990325">
We annotate each word in the tweet by its POS
tag, and then we compute the number of adjec-
tives, verbs, nouns, adverbs and connectors in
each tweet.
</bodyText>
<sectionHeader confidence="0.999722" genericHeader="method">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.99841">
4.1 Data collection
</subsectionHeader>
<bodyText confidence="0.999957571428572">
We used the data set provided in SemEval 2013
and 2014 for subtask B of sentiment analysis in
Twitter(Rosenthal, Ritter et al. 2014) (Wilson,
Kozareva et al. 2013). The participants were
provided with training tweets annotated as posi-
tive, negative or neutral. We downloaded these
tweets using a given script. Among 9646 tweets,
we could only download 8498 of them because
of protected profiles and deleted tweets. Then,
we used the development set containing 1654
tweets for evaluating our methods. We combined
the development set with training set and built a
new model which predicted the labels of the test
set 2013 and 2014.
</bodyText>
<sectionHeader confidence="0.697386" genericHeader="method">
4.2 Experiments
</sectionHeader>
<subsectionHeader confidence="0.692185">
Official Results
</subsectionHeader>
<bodyText confidence="0.999964416666667">
The results of our system submitted for
SemEval evaluation gave 46.38%, 52.02% for
test set 2013 and 2014 respectively. It should
mention that these results are not correct because
of a software bug discovered after the submis-
sion deadline, therefore the correct results is
demonstrated as non-official results. In fact the
previous results are the output of our classifier
which is trained by all the features in section 3,
but because of index shifting error the test set
was represented by all the features except the
terms.
</bodyText>
<sectionHeader confidence="0.81537" genericHeader="method">
Non-official Results
</sectionHeader>
<bodyText confidence="0.999969166666667">
We have done various experiments using the
features presented in Section 3 with Multinomial
Naïve-Bayes model. We firstly constructed fea-
ture vector of tweet terms which gave 49%, 46%
for test set 2013, 2014 respectively. Then, we
augmented this original vector by the Z_score
</bodyText>
<page confidence="0.99759">
638
</page>
<bodyText confidence="0.999707166666667">
features which improve the performance by 6.5%
and 10.9%, then by pre-polarity features which
also improve the f-measure by 4%, 6%, but the
extending with POS tags decreases the f-
measure. We also test all combinations with the-
se previous features, Table2 demonstrates the
results of each combination, we remark that POS
tags are not useful over all the experiments, the
best result is obtained by combining Z_score and
pre-polarity features. We find that Z_score fea-
tures improve significantly the f-measure and
they are better than pre-polarity features.
</bodyText>
<table confidence="0.9990073">
Features F-measure
2013 2014
Terms 49.42 46.31
Terms+Z 55.90 57.28
Terms+POS 43.45 41.14
Terms+POL 53.53 52.73
Terms+Z+POS 52.59 54.43
Terms+Z+POL 58.34 59.38
Terms+POS+POL 48.42 50.03
Terms+Z+POS+POL 55.35 58.58
</table>
<tableCaption confidence="0.933134">
Table 2. Average f-measures for positive and negative clas-
ses of SemEval2013 and 2014 test sets.
</tableCaption>
<bodyText confidence="0.997783375">
We repeated all previous experiments after using
a twitter dictionary where we extend the tweet by
the expressions related to each emotion icons or
abbreviations in tweets. The results in Table3
demonstrate that using that dictionary improves
the f-measure over all the experiments, the best
results obtained also by combining Z_scores and
pre-polarity features.
</bodyText>
<table confidence="0.998535">
Features F-measure
2013 2014
Terms 50.15 48.56
Terms+Z 57.17 58.37
Terms+POS 44.07 42.64
Terms+POL 54.72 54.53
Terms+Z+POS 53.20 56.47
Terms+Z+POL 59.66 61.07
Terms+POS+POL 48.97 51.90
Terms+Z+POS+POL 55.83 60.22
</table>
<tableCaption confidence="0.9603735">
Table 3. Average f-measures for positive and negative clas-
ses of SemEval2013 and 2014 test sets after using a twitter
</tableCaption>
<bodyText confidence="0.537064">
dictionary.
</bodyText>
<sectionHeader confidence="0.994201" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99883425">
In this paper we tested the impact of using
Twitter Dictionary, Sentiment Lexicons, Z_score
features and POS tags for the sentiment classifi-
cation of tweets. We extended the feature vector
of tweets by all these features; we have proposed
new type of features Z_score and demonstrated
that they can improve the performance.
We think that Z_score can be used in different
ways for improving the Sentiment Analysis, we
are going to test it in another type of corpus and
using other methods in order to combine these
features.
</bodyText>
<sectionHeader confidence="0.771527" genericHeader="references">
Reference
</sectionHeader>
<subsectionHeader confidence="0.370737">
Apoorv Agarwal,Boyi Xie,Ilia Vovsha,Owen
Rambow and Rebecca Passonneau (2011).
Sentiment analysis of Twitter data.
Proceedings of the Workshop on Languages
</subsectionHeader>
<figureCaption confidence="0.999893333333333">
Figure 1 Z_score distribution in positive class
Figure 3 Z_score distribution in negative class
Figure 2 Z_score distribution in neutral class
</figureCaption>
<page confidence="0.99408">
639
</page>
<table confidence="0.744893444444444">
in Social Media. Portland, Oregon,
Association for Computational Linguistics:
30-38.
Sitaram Asur and Bernardo A. Huberman (2010).
Predicting the Future with Social Media.
Proceedings of the 2010 IEEE/WIC/ACM
International Conference on Web
Intelligence and Intelligent Agent
Technology - Volume 01, IEEE Computer
Society: 492-499.
Stefano Baccianella,Andrea Esuli and Fabrizio
Sebastiani (2010). SentiWordNet 3.0: An
Enhanced Lexical Resource for Sentiment
Analysis and Opinion Mining. Proceedings
of the Seventh Conference on International
Language Resources and Evaluation
(LREC&apos;10), European Language Resources
Association (ELRA).
</table>
<reference confidence="0.998402128712871">
Younggue Bae and Hongchul Lee (2012). &amp;quot;Sentiment
analysis of twitter audiences: Measuring the
positive or negative influence of popular
twitterers.&amp;quot; J. Am. Soc. Inf. Sci. Technol.
63(12): 2521-2535.
Luciano Barbosa and Junlan Feng (2010). Robust
sentiment detection on Twitter from biased
and noisy data. Proceedings of the 23rd
International Conference on Computational
Linguistics: Posters. Beijing, China,
Association for Computational Linguistics:
36-44.
Alec Go,Richa Bhayani and Lei Huang Twitter
Sentiment Classification using Distant
Supervision.
Hussam Hamdan,Frederic Béchet and Patrice Bellot
(2013). Experiments with DBpedia,
WordNet and SentiWordNet as resources for
sentiment analysis in micro-blogging.
Proceedings of the Seventh International
Workshop on Semantic Evaluation (SemEval
2013), Atlanta, Georgia, USA.
Minqing Hu and Bing Liu (2004). Mining and
summarizing customer reviews. Proceedings
of the tenth ACM SIGKDD international
conference on Knowledge discovery and
data mining. Seattle, WA, USA, ACM: 168-
177.
Xia Hu,Lei Tang,Jiliang Tang and Huan Liu (2013).
Exploiting social relations for sentiment
analysis in microblogging. Proceedings of
the sixth ACM international conference on
Web search and data mining. Rome, Italy,
ACM: 537-546.
Aditya Joshi,A. R. Balamurali,Pushpak Bhattacharyya
and Rajat Mohanty (2011). C-Feel-It: a
sentiment analyzer for micro-blogs.
Proceedings of the 49th Annual Meeting of
the Association for Computational
Linguistics: Human Language Technologies:
Systems Demonstrations. Portland, Oregon,
Association for Computational Linguistics:
127-132.
Vinh Ngoc Khuc,Chaitanya Shivade,Rajiv Ramnath
and Jay Ramanathan (2012). Towards
building large-scale distributed systems for
twitter sentiment analysis. Proceedings of the
27th Annual ACM Symposium on Applied
Computing. Trento, Italy, ACM: 459-464.
E. Kouloumpis,T. Wilson and J. Moore (2011).
Twitter Sentiment Analysis: The Good the
Bad and the OMG! Fifth International AAAI
Conference on Weblogs and Social Media.
Subhabrata Mukherjee,Akshat Malu,Balamurali A.R.
and Pushpak Bhattacharyya (2012). TwiSent:
a multistage system for analyzing sentiment
in twitter. Proceedings of the 21st ACM
international conference on Information and
knowledge management. Maui, Hawaii,
USA, ACM: 2531-2534.
Nasir Naveed,Thomas Gottron,J\&apos;Er\^Ome Kunegis
and Arifah Che Alhadi (2011). Bad News
Travels Fast: A Content-based Analysis of
Interestingness on Twitter. Proc. Web
Science Conf.
Alexander Pak and Patrick Paroubek (2010). Twitter
as a Corpus for Sentiment Analysis and
Opinion Mining. Proceedings of the Seventh
conference on International Language
Resources and Evaluation (LREC&apos;10),
Valletta, Malta, European Language
Resources Association (ELRA).
Bo Pang,Lillian Lee and Shivakumar Vaithyanathan
(2002). Thumbs up?: sentiment classification
using machine learning techniques.
Proceedings of the ACL-02 conference on
Empirical methods in natural language
processing - Volume 10, Association for
Computational Linguistics: 79-86.
Sara Rosenthal,Alan Ritter,Veselin Stoyanov and
Preslav Nakov (2014). &amp;quot;SemEval-2014 Task
9: Sentiment Analysis in Twitter.&amp;quot; In
Proceedings of the Eighth International
Workshop on Semantic Evaluation
(SemEval&apos;14).August 23-24, Dublin, Ireland.
Hassan Saif,Yulan He and Harith Alani (2012).
Semantic sentiment analysis of twitter.
Proceedings of the 11th international
conference on The Semantic Web - Volume
Part I. Boston, MA, Springer-Verlag: 508-
524.
Michael Speriosu,Nikita Sudan,Sid Upadhyay and
Jason Baldridge (2011). Twitter polarity
classification with label propagation over
lexical links and the follower graph.
Proceedings of the First Workshop on
Unsupervised Learning in NLP. Edinburgh,
Scotland, Association for Computational
Linguistics: 53-63.
Chenhao Tan,Lillian Lee,Jie Tang,Long Jiang,Ming
Zhou and Ping Li (2011). User-level
</reference>
<page confidence="0.971653">
640
</page>
<reference confidence="0.999508071428571">
sentiment analysis incorporating social
networks. Proceedings of the 17th ACM
SIGKDD international conference on
Knowledge discovery and data mining. San
Diego, California, USA, ACM: 1397-1405.
Theresa Wilson,Zornitsa Kozareva,Preslav
Nakov,Alan Ritter,Sara Rosenthal and
Veselin Stoyanov (2013). &amp;quot;SemEval-2013
Task 2: Sentiment Analysis in Twitter.&amp;quot;
Proceedings of the 7th International
Workshop on Semantic Evaluation.
Association for Computational Linguistics.
Theresa Wilson,Janyce Wiebe and Paul Hoffmann
(2005). Recognizing contextual polarity in
phrase-level sentiment analysis. Proceedings
of the conference on Human Language
Technology and Empirical Methods in
Natural Language Processing. Vancouver,
British Columbia, Canada, Association for
Computational Linguistics: 347-354.
Olena Zubaryeva and Jacques Savoy (2010). &amp;quot;Opinion
Detection by Combining Machine Learning
&amp; Linguistic Tools.&amp;quot; In Proceedings of the
8th NTCIR, Workshop Meeting on
Evaluation of Information Access
Technologies: InformationRetrieval,
Question Answering and Cross-Lingual
Information Access.
</reference>
<page confidence="0.998325">
641
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.096796">
<title confidence="0.979695333333333">The Impact of Z_score on Twitter Sentiment Analysis Hussam Aix-Marseille Université</title>
<author confidence="0.957429">Esc Normandie</author>
<address confidence="0.917697">13397 Marseille Cedex</address>
<email confidence="0.952471">hussam.hamdan@lsis.org</email>
<author confidence="0.888224">Patrice Bellot</author>
<affiliation confidence="0.3832785">OpenEdition Aix-Marseille Université CNRS</affiliation>
<address confidence="0.512420666666667">3 pl. V. Hugo, case n°86 13331 Marseille Cedex 3, France</address>
<email confidence="0.957418">patrice.bellot@lsis.org</email>
<author confidence="0.918385">Frederic</author>
<affiliation confidence="0.908017">Aix-Marseille Université Avenue de</affiliation>
<address confidence="0.98183">13288 Marseille Cedex</address>
<email confidence="0.994318">frederic.bechet@lif.univ-mrs.fr</email>
<abstract confidence="0.997956333333333">Twitter has become more and more an important resource of user-generated data. Sentiment Analysis in Twitter is interesting for many applications and objectives. In this paper, we propose to exploit some features which can be useful for this task; the main contribution is the use of Z-scores as features for sentiment classification in addition to pre-polarity and POS tags features. Our experiments have been evaluated using the test data provided by SemEval 2013 and 2014. The evaluation demonstrates that Z_scores features can significantly improve the prediction performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Younggue Bae</author>
<author>Hongchul Lee</author>
</authors>
<title>Sentiment analysis of twitter audiences: Measuring the positive or negative influence of popular twitterers.&amp;quot;</title>
<date>2012</date>
<journal>J. Am. Soc. Inf. Sci. Technol.</journal>
<volume>63</volume>
<issue>12</issue>
<pages>2521--2535</pages>
<contexts>
<context position="1757" citStr="Bae and Lee 2012" startWordPosition="258" endWordPosition="261">s and the web. Users have become an important source of content. They express their opinion towards different issues. These opinions are important for others who are interested in understanding users’ interests such as buyers, sellers and producers. Twitter is one of the most important platforms in which the users express their opinions. Many works have exploited this media for predicting valuable issues depending on Sentiment Analysis (SA). The authors in (Asur and Huberman 2010) predicted the box-office revenues of movies in advance of their releases using the tweets talking about them. In (Bae and Lee 2012) Sentiment This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ Analysis has been used to study the impact of 13 twitter accounts of famous persons on their followers and also for forecasting the interesting tweets which are more probably to be reposted by the followers (Naveed, Gottron et al. 2011). Sentiment Analysis can be done in different levels; Document level; Sentence level; Clause level or Aspect-Based level. SA in Twitter can b</context>
</contexts>
<marker>Bae, Lee, 2012</marker>
<rawString>Younggue Bae and Hongchul Lee (2012). &amp;quot;Sentiment analysis of twitter audiences: Measuring the positive or negative influence of popular twitterers.&amp;quot; J. Am. Soc. Inf. Sci. Technol. 63(12): 2521-2535.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust sentiment detection on Twitter from biased and noisy data.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Beijing, China, Association for Computational Linguistics:</booktitle>
<pages>36--44</pages>
<contexts>
<context position="6322" citStr="Barbosa and Feng 2010" startWordPosition="995" endWordPosition="998">py MaxEnt and Support Vector Machines (SVM). The authors (Go, Bhayani et al. 2009) reported that SVM outperforms other classifiers. They tried a unigram and a bigram model in conjunction with parts-of-speech (POS) features; they noted that the unigram model outperforms all other models when using SVM and that POS features decrease the quality of results. The authors in (Kouloumpis, Wilson et al. 2011) found that N-gram with lexicon features and micro-blogging features are useful but POS features are not. In contrast, in (Pak and Paroubek 2010) they reported that POS and bigrams both help. In (Barbosa and Feng 2010) the authors proposed the use of syntax features of tweets like retweet, hashtags, link, punctuation and exclamation marks in conjunction with features like prior polarity of words and POS tags, in (Agarwal, Xie et al. 2011) this approach was extended by using real valued prior polarity and by combining prior polarity with POS. Authors in (Saif, He et al. 2012) proposed to use the semantic features, therefore they extracted the named entities in the tweets. Authors in (Hamdan, Béchet et al. 2013) used the concepts extracted from DBpedia and the adjectives from WordNet, they reported that the D</context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng (2010). Robust sentiment detection on Twitter from biased and noisy data. Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Beijing, China, Association for Computational Linguistics: 36-44.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Alec Go</author>
<author>Richa</author>
</authors>
<title>Bhayani and Lei Huang Twitter Sentiment Classification using Distant Supervision.</title>
<marker>Go, Richa, </marker>
<rawString>Alec Go,Richa Bhayani and Lei Huang Twitter Sentiment Classification using Distant Supervision.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hussam Hamdan</author>
<author>Frederic Béchet</author>
<author>Patrice Bellot</author>
</authors>
<title>Experiments with DBpedia, WordNet and SentiWordNet as resources for sentiment analysis in micro-blogging.</title>
<date>2013</date>
<booktitle>Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013),</booktitle>
<location>Atlanta, Georgia, USA.</location>
<marker>Hamdan, Béchet, Bellot, 2013</marker>
<rawString>Hussam Hamdan,Frederic Béchet and Patrice Bellot (2013). Experiments with DBpedia, WordNet and SentiWordNet as resources for sentiment analysis in micro-blogging. Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining.</booktitle>
<pages>168--177</pages>
<location>Seattle, WA, USA, ACM:</location>
<contexts>
<context position="10735" citStr="Hu and Liu 2004" startWordPosition="1736" endWordPosition="1739">tive Z_score Neutra Z_score Love 14.31 Not 13.99 Httpbit 6.44 Good 14.01 Fuck 12.97 Httpfb 4.56 Happy 12.30 Don’t 10.97 Httpbnd 3.78 Great 11.10 Shit 8.99 Intern 3.58 Excite 10.35 Bad 8.40 Nov 3.45 Best 9.24 Hate 8.29 Httpdlvr 3.40 Thank 9.21 Sad 8.28 Open 3.30 Hope 8.24 Sorry 8.11 Live 3.28 Cant 8.10 Cancel 7.53 Cloud 3.28 Wait 8.05 stupid 6.83 begin 3.17 Table1. The first ten terms having the highest Z_score in each class - Sentiment Lexicon Features (POL) We used two sentiment lexicons, MPQA Subjectivity Lexicon(Wilson, Wiebe et al. 2005) and Bing Liu&apos;s Opinion Lexicon which is created by (Hu and Liu 2004) and augmented in many latter works. We extract the number of positive, negative and neutral words in tweets according to these lexicons. Bing Liu&apos;s lexicon only contains negative and positive annotation but Subjectivity contains negative, positive and neutral. - Part Of Speech (POS) We annotate each word in the tweet by its POS tag, and then we compute the number of adjectives, verbs, nouns, adverbs and connectors in each tweet. 4 Evaluation 4.1 Data collection We used the data set provided in SemEval 2013 and 2014 for subtask B of sentiment analysis in Twitter(Rosenthal, Ritter et al. 2014) </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu (2004). Mining and summarizing customer reviews. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. Seattle, WA, USA, ACM: 168-177.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Xia Hu</author>
<author>Lei</author>
</authors>
<title>Tang,Jiliang Tang and Huan Liu (2013). Exploiting social relations for sentiment analysis in microblogging.</title>
<booktitle>Proceedings of the sixth ACM international conference on Web search and data mining.</booktitle>
<pages>537--546</pages>
<location>Rome, Italy, ACM:</location>
<marker>Hu, Lei, </marker>
<rawString>Xia Hu,Lei Tang,Jiliang Tang and Huan Liu (2013). Exploiting social relations for sentiment analysis in microblogging. Proceedings of the sixth ACM international conference on Web search and data mining. Rome, Italy, ACM: 537-546.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Aditya Joshi</author>
<author>A R</author>
</authors>
<title>Balamurali,Pushpak Bhattacharyya and Rajat Mohanty (2011). C-Feel-It: a sentiment analyzer for micro-blogs.</title>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Systems Demonstrations. Portland, Oregon, Association for Computational Linguistics:</booktitle>
<pages>127--132</pages>
<marker>Joshi, R, </marker>
<rawString>Aditya Joshi,A. R. Balamurali,Pushpak Bhattacharyya and Rajat Mohanty (2011). C-Feel-It: a sentiment analyzer for micro-blogs. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Systems Demonstrations. Portland, Oregon, Association for Computational Linguistics: 127-132.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Vinh Ngoc</author>
</authors>
<title>Khuc,Chaitanya Shivade,Rajiv Ramnath and Jay Ramanathan (2012). Towards building large-scale distributed systems for twitter sentiment analysis.</title>
<booktitle>Proceedings of the 27th Annual ACM Symposium on Applied Computing.</booktitle>
<pages>459--464</pages>
<location>Trento, Italy, ACM:</location>
<marker>Ngoc, </marker>
<rawString>Vinh Ngoc Khuc,Chaitanya Shivade,Rajiv Ramnath and Jay Ramanathan (2012). Towards building large-scale distributed systems for twitter sentiment analysis. Proceedings of the 27th Annual ACM Symposium on Applied Computing. Trento, Italy, ACM: 459-464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kouloumpis</author>
<author>T Wilson</author>
<author>J Moore</author>
</authors>
<title>Twitter Sentiment Analysis: The Good the Bad and the OMG!</title>
<date>2011</date>
<booktitle>Fifth International AAAI Conference on Weblogs and Social Media.</booktitle>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>E. Kouloumpis,T. Wilson and J. Moore (2011). Twitter Sentiment Analysis: The Good the Bad and the OMG! Fifth International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Subhabrata Mukherjee</author>
<author>Akshat Malu</author>
<author>A R Balamurali</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>TwiSent: a multistage system for analyzing sentiment in twitter.</title>
<date>2012</date>
<booktitle>Proceedings of the 21st ACM international conference on Information and knowledge management. Maui,</booktitle>
<pages>2531--2534</pages>
<location>Hawaii, USA, ACM:</location>
<marker>Mukherjee, Malu, Balamurali, Bhattacharyya, 2012</marker>
<rawString>Subhabrata Mukherjee,Akshat Malu,Balamurali A.R. and Pushpak Bhattacharyya (2012). TwiSent: a multistage system for analyzing sentiment in twitter. Proceedings of the 21st ACM international conference on Information and knowledge management. Maui, Hawaii, USA, ACM: 2531-2534.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nasir Naveed</author>
<author>Thomas</author>
</authors>
<title>Gottron,J\&apos;Er\^Ome Kunegis and Arifah Che Alhadi (2011). Bad News Travels Fast: A Content-based Analysis of Interestingness on Twitter.</title>
<booktitle>Proc. Web Science Conf.</booktitle>
<marker>Naveed, Thomas, </marker>
<rawString>Nasir Naveed,Thomas Gottron,J\&apos;Er\^Ome Kunegis and Arifah Che Alhadi (2011). Bad News Travels Fast: A Content-based Analysis of Interestingness on Twitter. Proc. Web Science Conf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a Corpus for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC&apos;10),</booktitle>
<location>Valletta, Malta,</location>
<contexts>
<context position="6249" citStr="Pak and Paroubek 2010" startWordPosition="982" endWordPosition="985">s were employed from annotated tweets by using Naive Bayes, Maximum Entropy MaxEnt and Support Vector Machines (SVM). The authors (Go, Bhayani et al. 2009) reported that SVM outperforms other classifiers. They tried a unigram and a bigram model in conjunction with parts-of-speech (POS) features; they noted that the unigram model outperforms all other models when using SVM and that POS features decrease the quality of results. The authors in (Kouloumpis, Wilson et al. 2011) found that N-gram with lexicon features and micro-blogging features are useful but POS features are not. In contrast, in (Pak and Paroubek 2010) they reported that POS and bigrams both help. In (Barbosa and Feng 2010) the authors proposed the use of syntax features of tweets like retweet, hashtags, link, punctuation and exclamation marks in conjunction with features like prior polarity of words and POS tags, in (Agarwal, Xie et al. 2011) this approach was extended by using real valued prior polarity and by combining prior polarity with POS. Authors in (Saif, He et al. 2012) proposed to use the semantic features, therefore they extracted the named entities in the tweets. Authors in (Hamdan, Béchet et al. 2013) used the concepts extract</context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek (2010). Twitter as a Corpus for Sentiment Analysis and Opinion Mining. Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC&apos;10), Valletta, Malta, European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, Association for Computational Linguistics:</booktitle>
<pages>79--86</pages>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang,Lillian Lee and Shivakumar Vaithyanathan (2002). Thumbs up?: sentiment classification using machine learning techniques. Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, Association for Computational Linguistics: 79-86.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sara Rosenthal</author>
<author>Alan</author>
</authors>
<title>Ritter,Veselin Stoyanov and Preslav Nakov (2014). &amp;quot;SemEval-2014 Task 9: Sentiment Analysis in Twitter.&amp;quot;</title>
<booktitle>In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval&apos;14).August 23-24,</booktitle>
<location>Dublin, Ireland.</location>
<marker>Rosenthal, Alan, </marker>
<rawString>Sara Rosenthal,Alan Ritter,Veselin Stoyanov and Preslav Nakov (2014). &amp;quot;SemEval-2014 Task 9: Sentiment Analysis in Twitter.&amp;quot; In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval&apos;14).August 23-24, Dublin, Ireland.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hassan Saif</author>
<author>Yulan</author>
</authors>
<title>He and Harith Alani (2012). Semantic sentiment analysis of twitter.</title>
<booktitle>Proceedings of the 11th international conference on The Semantic Web - Volume Part I.</booktitle>
<pages>508--524</pages>
<publisher>Springer-Verlag:</publisher>
<location>Boston, MA,</location>
<marker>Saif, Yulan, </marker>
<rawString>Hassan Saif,Yulan He and Harith Alani (2012). Semantic sentiment analysis of twitter. Proceedings of the 11th international conference on The Semantic Web - Volume Part I. Boston, MA, Springer-Verlag: 508-524.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Speriosu</author>
<author>Nikita Sudan</author>
<author>Sid Upadhyay</author>
<author>Jason Baldridge</author>
</authors>
<title>Twitter polarity classification with label propagation over lexical links and the follower graph.</title>
<date>2011</date>
<booktitle>Proceedings of the First Workshop on Unsupervised Learning in NLP. Edinburgh, Scotland, Association for Computational Linguistics:</booktitle>
<pages>53--63</pages>
<marker>Speriosu, Sudan, Upadhyay, Baldridge, 2011</marker>
<rawString>Michael Speriosu,Nikita Sudan,Sid Upadhyay and Jason Baldridge (2011). Twitter polarity classification with label propagation over lexical links and the follower graph. Proceedings of the First Workshop on Unsupervised Learning in NLP. Edinburgh, Scotland, Association for Computational Linguistics: 53-63.</rawString>
</citation>
<citation valid="false">
<title>Chenhao Tan,Lillian Lee,Jie Tang,Long Jiang,Ming Zhou and Ping Li (2011). User-level sentiment analysis incorporating social networks.</title>
<booktitle>Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining.</booktitle>
<pages>1397--1405</pages>
<location>San Diego, California, USA, ACM:</location>
<marker></marker>
<rawString>Chenhao Tan,Lillian Lee,Jie Tang,Long Jiang,Ming Zhou and Ping Li (2011). User-level sentiment analysis incorporating social networks. Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. San Diego, California, USA, ACM: 1397-1405.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa</author>
</authors>
<title>Kozareva,Preslav Nakov,Alan Ritter,Sara Rosenthal and Veselin Stoyanov (2013). &amp;quot;SemEval-2013 Task 2: Sentiment Analysis in Twitter.&amp;quot;</title>
<booktitle>Proceedings of the 7th International Workshop on Semantic Evaluation. Association for Computational Linguistics.</booktitle>
<marker>Wilson, Zornitsa, </marker>
<rawString>Theresa Wilson,Zornitsa Kozareva,Preslav Nakov,Alan Ritter,Sara Rosenthal and Veselin Stoyanov (2013). &amp;quot;SemEval-2013 Task 2: Sentiment Analysis in Twitter.&amp;quot; Proceedings of the 7th International Workshop on Semantic Evaluation. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Vancouver, British Columbia, Canada, Association for Computational Linguistics:</booktitle>
<pages>347--354</pages>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson,Janyce Wiebe and Paul Hoffmann (2005). Recognizing contextual polarity in phrase-level sentiment analysis. Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Vancouver, British Columbia, Canada, Association for Computational Linguistics: 347-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Zubaryeva</author>
<author>Jacques Savoy</author>
</authors>
<title>Opinion Detection by Combining Machine Learning &amp; Linguistic Tools.&amp;quot;</title>
<date>2010</date>
<booktitle>In Proceedings of the 8th NTCIR, Workshop Meeting on Evaluation of Information Access Technologies: InformationRetrieval, Question Answering and Cross-Lingual Information Access.</booktitle>
<contexts>
<context position="9202" citStr="Zubaryeva and Savoy 2010" startWordPosition="1475" endWordPosition="1478">term. We compute the 637 Z_score for each term ti in a class Cj (tij) by calculating its term relative frequency tfrij in a particular class Cj, as well as the mean (meani) which is the term probability over the whole corpus multiplied by nj the number of terms in the class Cj, and standard deviation (sdi) of term ti according to the underlying corpus (see Eq. (1,2)). tfrij-mean; Zscore(tij) _ sdi Eq. (1) _ tfrij-nj*p(ti) Zscore(tij) Eq. (2) �n�*p(t�)*(��p(t�)) The term which has salient frequency in a class in compassion to others will have a salient Z_score. Z_score was exploited for SA by (Zubaryeva and Savoy 2010) , they choose a threshold (&gt;2) for selecting the number of terms having Z_score more than the threshold, then they used a logistic regression for combining these scores. We use Z_scores as added features for classification because the tweet is too short, therefore many tweets does not have any words with salient Z_score. The three following figures 1,2,3 show the distribution of Z_score over each class, we remark that the majority of terms has Z_score between -1.5 and 2.5 in each class and the rest are either vey frequent (&gt;2.5) or very rare (&lt;-1.5). It should indicate that negative value mea</context>
</contexts>
<marker>Zubaryeva, Savoy, 2010</marker>
<rawString>Olena Zubaryeva and Jacques Savoy (2010). &amp;quot;Opinion Detection by Combining Machine Learning &amp; Linguistic Tools.&amp;quot; In Proceedings of the 8th NTCIR, Workshop Meeting on Evaluation of Information Access Technologies: InformationRetrieval, Question Answering and Cross-Lingual Information Access.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>