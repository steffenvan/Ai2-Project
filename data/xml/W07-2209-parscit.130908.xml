<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000468">
<title confidence="0.992358">
Ambiguity Resolution by Reordering Rules in Text Containing Errors
</title>
<author confidence="0.984986">
Sylvana Sofkova Hashemi
</author>
<affiliation confidence="0.993636">
Department of Linguistics, Gšteborg University
</affiliation>
<address confidence="0.940254">
Box 200, SE-405 30 Gšteborg, SWEDEN
</address>
<email confidence="0.995683">
sylvana@ling.gu.se
</email>
<sectionHeader confidence="0.995541" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999342">
Writing aids such as spelling and grammar
checkers are often based on texts by adult writ-
ers and are not sufficiently targeted to support
children in their writing process. This paper
reports on the development of a writing tool
based on a corpus of Swedish text written by
children and on the parsing methods developed
to handle text containing errors. The system
uses finite state techniques for finding gram-
mar errors without actually specifying the error.
The ‘broadness’ of the grammar and the lexical
ambiguity in words, necessary for parsing text
containing errors, also yields ambiguous and/or
alternative phrase annotations. We block some
of the (erroneous) alternative parses by the or-
der in which phrase segments are selected,
which causes bleeding of some rules and more
‘correct’ parsing results are achieved. The
technique shows good coverage results for
agreement and verb selection phenomena.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972807692308">
Writing on a computer in school often involves
making a fair copy from a handwritten draft. Al-
though a computer is an excellent means for the
writing process, especially the linguistic tools are
not used adequately. Spelling and grammar correc-
tors are in general developed for and adapted to
adult writers and have difficulties to support chil-
dren in their writing development and give no
space for acquisition or training. Errors in texts
written by school children are more frequent and
the distribution of the error types is different from
adult writers.
This paper reports on the development of a finite
state system for finding grammar errors, called Fi-
niteCheck, based on a corpus of Swedish text writ-
ten by school children. The system applies descrip-
tions of correct language use in the detection proc-
ess of grammatical violations and contains no rules
describing the nature of the erroneous segments the
system searches for. The approach (following
Karttunen et al., 1996) for finding errors involves
developing automata that represent two ‘positive’
grammars with varying degree of detail and then
subtracting the detailed one from the general one.
The difference between the automata corresponds
to a grammar for errors.
</bodyText>
<sectionHeader confidence="0.992169" genericHeader="method">
2 Grammar Checkers
</sectionHeader>
<subsectionHeader confidence="0.978977">
2.1 Current Systems
</subsectionHeader>
<bodyText confidence="0.998146052631579">
Whereas spelling checkers are standard in most
word processors, grammar checking is a rather re-
cent technology, especially for Swedish. Different
methods and techniques have been applied to han-
dle nonsense words and thus operate on isolated
words as most spelling correctors do. Both statisti-
cal and rule-based methods and also algorithms
that to some extent take into consideration the sur-
rounding context (i.e. context-sensitive errors) or
how a word is pronounced have been used for
spelling correction (cf. Kukich, 1992).
Grammar checkers involve techniques and solve
problems above the single word level and require
syntactic, semantic or even discourse analysis (see
Section 2.2). Grammar checking techniques started
to develop first in the 1980’s with products mainly
for English (see Jensen et al, 1993; Vernon, 2000)
but also for other languages, e.g. French (Chanod,
1996), Dutch (Vosse, 1994), Czech (Kirschner,
</bodyText>
<page confidence="0.992403">
69
</page>
<note confidence="0.9242535">
Proceedings of the 10th Conference on Parsing Technologies, pages 69–79,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.990597545454545">
1994), Spanish and Greek (Bustamente and Le—n,
1996). Computer-based grammar checking for
Swedish is fairly recent and has primarily focused
on the needs of adult writers. The first product re-
lease of such a writing aid was in November 1998
with the tool GrammatiÞx (Arppe, 2000; Birn,
2000), now part of the Swedish Microsoft Office
2000. Two other research groups developed
grammar checking prototypes: Granska (Knutsson,
2001; Domeij, 2003) and Scarrie (SŒgvall Hein,
1999).
</bodyText>
<subsectionHeader confidence="0.995399">
2.2 Methods and Techniques
</subsectionHeader>
<bodyText confidence="0.999881104477612">
Many of the grammar checking systems are com-
mercial products and technical documentation is
often minimal or even absent. Critique (known
until 1984 as Epistle) is an exception, a system
developed in collaboration with IBM within the
Programming Language for Natural Language
Processing (PLNLP) project (Jensen et al., 1993).
This tool is based on a parser using Augmented
Phrase Structure Grammar (ACFG) and produces
a complete analysis for all sentences (even un-
grammatical) by application of relaxation rules
when parsing fails on the first try or parse fitting
procedure identifying the head and its constituents
(Heidorn, 1993; Jensen et al., 1993). This approach
of providing analysis of all sentences had influ-
enced other grammar formalisms such as Con-
straint Grammar (Karlsson et al., 1995) or Func-
tional Dependency Grammar (JŠrvinen and Ta-
panainen, 1998). The methods of rule relaxation
and parse fitting had an impact on the development
of other grammar checking systems.
The three Swedish tools use different technol-
ogy to analyze unrestricted text and detect gram-
mar errors. The lexical analysis in Grammatifix is
based on the morphological analyzer SWETWOL,
designed according to the principles of two-level
morphology (Karlsson, 1992). The part-of-speech
assignment applies the Swedish Constraint Gram-
mar (SWECG), a surface-syntactic parser applying
context-sensitive disambiguation rules (Birn,
1998). Errors are detected by partial parsing and
relaxation on rules, regarding certain word se-
quences as phrases despite grammar errors in them.
Granska combines probabilistic and rule-based
methods, where specific error rules (around 600)
and local applied rules detect ungrammaticalities in
free text. The lexical analyzer applies Hidden
Markov Models and a rule matching system analy-
ses the tagged text searching for grammatical vio-
lations defined in the detection rules and produces
error description and a correction suggestion for
the error (Carlberger &amp; Kann, 1999).
The grammar checker in Scarrie is based on a
previously developed parser, the Uppsala Chart
Parser (UCP), a procedural, bottom-up parser, ap-
plying a longest path strategy (SŒgvall Hein,
1983). The parsing strategy of erroneous input is
based on constraint relaxation and application of
local error rules. The grammar is in other words
underspecified to a certain level, allowing feature
violations and parsing of ungrammatical word se-
quences (Wedbjer Rambell, 1999).
The Swedish approaches to detection of gram-
mar errors vary from chart-based methods in Scar-
rie, application of constraint grammars in Gram-
matifix, to a combination of probabilistic and rule-
based methods in Granska. Scarrie and Granska
identify erroneous patterns by partial analysis,
whereas Grammatifix produces full analysis for
both grammatical and ungrammatical sentences.
All the tools define (wholly or to some extent) ex-
plicit error rules describing the nature of the error
they search for. In the process of error detection
they either proceed sentence by sentence, requiring
recognition of sentence boundaries, or they rely in
their rules on for instance capitalization conven-
tions.
</bodyText>
<subsectionHeader confidence="0.969471">
2.3 Error Coverage
</subsectionHeader>
<bodyText confidence="0.9999509">
Current grammar checking systems are restricted
to a small set of all possible writing errors, con-
cerning mostly syntactic analysis. The choice of
what types of errors are detected in the Swedish
tools is based on analysis of errors in writing of
certain groups of writers (e.g. professional writers,
writers at work). The coverage of error types is
very similar between the systems, including errors
in noun phrase agreement and agreement in predi-
cative complement, pronoun case after preposition,
word order, errors in verbs, etc.
Observations with children writing on a com-
puter in school (HŒrd af Segerstad &amp; Sofkova
Hashemi, 2006; Sofkova Hashemi, forthcoming)
and performance tests of the Swedish tools on texts
written by school children (Sofkova Hashemi,
2003) show that grammar checkers do not suffi-
ciently support school children in their writing de-
velopment. The grammatical mistakes found in
texts written by children display different fre-
</bodyText>
<page confidence="0.996147">
70
</page>
<bodyText confidence="0.9992533125">
quency and distribution than in adults and the text
structure as whole is different. Main clauses are
often joined together without conjunctions and
punctuation marks often delimit larger textual units
than syntactic sentences. Sentence boundaries and
capitalization are something the Swedish tools rely
on in their detection process, which may have im-
pact on the coverage results. Although the systems
cover many of the types of errors found in school
texts, they detect around 12% of all writing errors
(Sofkova Hashemi, 2003) (see Section 6). Per-
formance on text data such as newspaper texts and
student compositions evaluated within the frames
of the separate projects shows a much higher cov-
erage of error detection on average 58% (Birn,
2000; Knutsson, 2001; SŒgvall Hein et al., 1999).
</bodyText>
<sectionHeader confidence="0.996985" genericHeader="method">
3 The Training Data
</sectionHeader>
<subsectionHeader confidence="0.999825">
3.1 The Child Data Corpus
</subsectionHeader>
<bodyText confidence="0.999996923076923">
FiniteCheck, the grammar error detector reported
in this paper, is based on a corpus of Swedish text
written by school children. This Child Data corpus
of 29 812 words (3 373 word types) is composed
of computer written and hand written essays writ-
ten by children between 9 and 13 years of age. In
general, the text structure of the compositions re-
veals clearly the influence of spoken language and
performance difficulties in spelling, segmentation
of words, the use of capitals and punctuation, with
fairly wide variation both by individual and age. In
total, 260 instances of grammatical errors were
found in 134 narratives.
</bodyText>
<subsectionHeader confidence="0.999847">
3.2 The Error Types
</subsectionHeader>
<bodyText confidence="0.9168719">
The most frequent grammatical violation concerns
the omission of Þnite verb inflection (42% of all
errors), i.e. when the main finite verb in a clause
lacks the appropriate present or past tense endings:
(1) PŒ natten *vakna jag av att brandlarmet tjšt
in the-night wake[untensed] I from that fire-
alarm howled
– In the night I woke up from that the fire-
alarm went off.
The correct form of the verb vakna ‘wake’ should
be in the past tense, i.e. vaknade ‘woke’. This type
of error arises from the fact that the writing is
highly influenced by spoken language. In spoken
Swedish regular weak verbs in the past tense often
lack the appropriate ending and the spoken form
then coincides with the infinitive (and for some
verbs also imperative) form of the verb.
Other frequent grammar problems concern extra
inserted or missing words in sentences (22%), here
the preposition i ‘in’ is missing:
</bodyText>
<listItem confidence="0.657199">
(2) Gunnar var pŒ semester *_ norge och Œkte
skidor.
</listItem>
<bodyText confidence="0.993160625">
Gunnar was on vacation _ Norway and went
skis
– Gunnar was on vacation in Norway and
skied.
word choice errors (11%), here the verb att vara
lika ‘to be alike’ requires the particle till ‘to’ in
combination with the noun phrase sŠttet ‘the-
manner’ and not pŒ ‘on’ as the writer uses:
</bodyText>
<listItem confidence="0.974202666666667">
(3) vi var vŠldigt lika *pŒ sŠttet
we were very like on the-manner
– We were very alike in the manners.
errors in noun phrase agreement (6%), here the
correct form of the noun phrase requires the noun
to be definite as in den nŠrmsta handduken ‘the
nearest towel’:
(4) jag tar den nŠrmsta *handduk och slŠnger
den i vasken
</listItem>
<bodyText confidence="0.984341285714286">
I take the[def] nearest[def] towel [indef] and
throw it in the sink
– I take the nearest towel and throw it into the
sink.
errors in verb chains (3%), here the auxiliary verb
should be followed by an infinitive, ska bli ‘will
become’, but in this case the present tense is used:
</bodyText>
<listItem confidence="0.863069">
(5) Men kom ihŒg att det inte ska *blir nŒgon
riktig brand.
</listItem>
<bodyText confidence="0.967038">
but remember that it not will becomes[pres]
some real fire
– But remember that there will not be a real
fire.
Other grammar errors occurred less than ten times
in the whole corpus, including reference errors,
agreement between subject and predicative com-
</bodyText>
<page confidence="0.992229">
71
</page>
<bodyText confidence="0.978539611111111">
plement, definiteness in single nouns, pronoun
form, errors in infinitive phrases, word order.
Punctuation problems are also included in the
analyses. In general, the use of punctuation varies
from no usage at all (mostly among the youngest
children) to rather sparse marking. In the following
example the main clauses are joined together and
the boundary between the sentences is not marked:
(6) nasse blev arg han gick och la sig med dom
andra syskonen.
nasse became angry he went and lay himself
with the other siblings
– Nasse got angry. He went and lay down
with the other siblings.
The finite verb problem, verb form in verb chains
and infinitive phrases and agreement problems in
noun phrase are the four types of errors detected by
the current system, FiniteCheck.
</bodyText>
<sectionHeader confidence="0.952227" genericHeader="method">
4 System architecture
</sectionHeader>
<bodyText confidence="0.993748964285714">
The framework for detection of grammar errors in
FiniteCheck is built as a network of finite state
transducers compiled from regular expressions in-
cluding operators defined in the Xerox Finite State
Tool (XFST) (Karttunen et al., 1997). Each
automaton in the network composes with the result
of previous application and in principle all the
automata can be composed into a single transducer.
There are in general two types of transducers in
use: one that annotates text in order to select cer-
tain segments and one that redefines or refines ear-
lier decisions. Annotations of any kind are handled
by transducers defined as finite state markers that
add reserved symbols into text and mark out syn-
tactical segments, grammar errors, or other patterns
aimed at selections. Finite state filters are used for
refinement and/or revision of earlier decisions.
The system runs under UNIX in a simple Emacs
environment used for testing and development of
finite state grammars. The environment shows the
results of an XFST-process run on the current
Emacs buffer in a separate buffer. An XFST-mode
allows for menus to be used and recompile files in
the system.
The sequenced finite state transducers of
FiniteCheck are divided in four main modules:
the lexicon lookup, the grammar, the parser and
the error finder – see Figure 1.
</bodyText>
<figure confidence="0.617122">
text input
</figure>
<figureCaption confidence="0.999803">
Figure 1: The system architecture
</figureCaption>
<subsectionHeader confidence="0.996735">
4.1 The Lexicon Lookup
</subsectionHeader>
<bodyText confidence="0.99988904">
The lexicon of around 160, 000 word forms, is
built as a finite state transducer, using the Xerox
tool Finite State Lexicon Compiler (Karttunen,
1993). The lexicon is composed from two re-
sources and takes a string and maps inflected sur-
face form to a tag containing part-of-speech and
feature information, e. g. applying the transducer to
the string kvinna ‘woman’ will return [nn utr sin
ind nom]. The morphosyntactic tags follow di-
rectly the relevant string or token. More than one
tag can be attached to a string, since no contextual
information is taken into account. The morphosyn-
tactic information in the tags is further used in the
grammars of the system. The set of tags follows
the Stockholm-UmeŒ Corpus project conventions
(Ejerhed et al, 1992), including 23 category classes
and 29 feature classes that were extended with 3
additional categories. Below is an example of a
lookup on the example sentence in (5):
(7) Men[kn] kom[qmvb prt akt][vb prt akt]
ihŒg[ab][pl] att[sn][ie] det[pn neu sin def
sub/obj] [dt neu sin def] inte[ab] ska[vb prs
akt][mvb prs akt] blir[vb prs akt] nŒgon[dt utr
sin ind][pn utr sin ind sub/obj] riktig[jj pos utr
sin ind nom] brand[nn utr sin ind nom]
</bodyText>
<page confidence="0.990221">
72
</page>
<subsectionHeader confidence="0.981558">
4.2 The Grammar
</subsectionHeader>
<bodyText confidence="0.983005263157895">
The grammar module includes two grammar sets
with (positive) rules reflecting the grammatical
structure of Swedish, differing in the level of de-
tail. The broad grammar is especially designed to
handle text with ungrammaticalities and the lin-
guistic descriptions are less accurate accepting
both valid and invalid patterns. The narrow
gramar is fine and accurate and accepts only the
grammatical segments. For example, the regular
expression in (8) belongs to the broad grammar set
and recognizes potential verb clusters (VC) (both
grammatical and ungrammatical) as a pattern con-
sisting of a sequence of two or three verbs in com-
bination with (zero or more) adverbs:
(8) define VC [Verb Adv* Verb (Verb)];
This automaton accepts all the verb cluster exam-
ples in (9), including the ungrammatical instance
(9c) (marked by an asterisk ‘*’), where a finite
verb follows a (finite) auxiliary verb.
</bodyText>
<listItem confidence="0.969035333333333">
(9) a. kan inte springa ‘can not run’
b. skulle ha sprungit ‘would have run [sup]’
c. *ska blir ‘will be [pres]’
</listItem>
<bodyText confidence="0.993491857142857">
Corresponding rules in the narrow grammar set
represented by the regular expressions in (10) take
into account the internal structure of a verb cluster
and define the grammar of modal auxiliary verbs
(Mod) followed by (zero or more) adverb(s), and
either a verb in infinitive form (VerbInf) as in
(10a), or a temporal verb in infinitive (PerfInf) and
a verb in supine form (VerbSup), as in (10b).
These rules thus accept only the grammatical seg-
ments in (9) and will not include example (9c). The
actual grammar of grammatical verb clusters is a
little bit more complex.
(10) a. define VC1 [Mod Adv* VerbInf];
b. define VC2 [Mod Adv* PerfInf VerbSup];
</bodyText>
<subsectionHeader confidence="0.999422">
4.3 The parser
</subsectionHeader>
<bodyText confidence="0.9999901875">
The various kinds of constituents are marked out in
a text using a lexical-prefix-first method, i.e. pars-
ing first from left margin of a phrase to the head
and then extending the phrase by adding on com-
plements. The actual parsing (based on the broad
grammar definitions) is incremental in a similar
fashion as the methods described in Ait-Mohtar
and Chanod (1997), where the output from one
layer serves as input to the next, building on the
segments. The system recognizes the head phrases
in certain order in the first phase (verbal head,
prepositional head, adjective phrase) and then ap-
plies the second phase in the reverse order and ex-
tends the phrases with complements (noun phrase,
prepositional phrase, verb phrase). The parsing
method is described in detail in Section 5.
</bodyText>
<subsectionHeader confidence="0.876334">
4.4 Error Detection
</subsectionHeader>
<bodyText confidence="0.999910529411765">
The error finder is a separate module in the system,
which means that the grammar and parser could
potentially be used directly in a different applica-
tion. The nets of this module correspond to the dif-
ference between the two grammars, broad and nar-
row.
By subtracting the narrow grammar from the
broad grammar we create machines that will find
ungrammatical phrases in a text. For example, the
regular expression in (11) identifies verb clusters
that violate the narrow grammar of modal verb
clusters (VC1 or VC2, defined in (10)) by subtract-
ing these rules from the more general (overgenerat-
ing) rule in the broad grammar (VC, defined in (8))
within the boundaries of a verb cluster (‘&lt;vc&gt;’,
‘&lt;/vc&gt;’), that have been previously marked out in
the parsing stage.
</bodyText>
<listItem confidence="0.7116045">
(11) define VCerror [ &amp;quot;&lt;vc&gt;&amp;quot; [VC - [VC1 |
VC2]] &amp;quot;&lt;/vc&gt;&amp;quot; ];
</listItem>
<bodyText confidence="0.996254">
By application of a marking transducer in (12), the
found error segment is annotated directly in the
text as in example (13).
</bodyText>
<listItem confidence="0.959605142857143">
(12) define markVCerror [VCerror -&gt;
&amp;quot;&lt;Error verb after Vaux&gt;&amp;quot; ... &amp;quot;&lt;/Error&gt;&amp;quot;];
(13) Men &lt;vp&gt; &lt;vpHead&gt; kom ihŒg &lt;/vpHead&gt;
&lt;/vp&gt; att &lt;np&gt; det &lt;/np&gt; &lt;vp&gt; &lt;vpHead&gt; inte
&lt;Error verb after Vaux&gt; &lt;vc&gt; ska blir &lt;/vc&gt;
&lt;/Error&gt; &lt;/vpHead&gt; &lt;np&gt; nŒgon &lt;ap&gt; riktig
&lt;/ap&gt; brand &lt;/np&gt; &lt;/vp&gt;
</listItem>
<page confidence="0.999017">
73
</page>
<sectionHeader confidence="0.998275" genericHeader="method">
5 Parsing
</sectionHeader>
<subsectionHeader confidence="0.999898">
5.1 Parsing procedure
</subsectionHeader>
<bodyText confidence="0.980222428571429">
The rules of the (underspecified) broad grammar
are used to mark syntactic patterns in a text. A par-
tial, lexical-prefix-first, longest-match, incremental
strategy is used for parsing. The parsing procedure
is partial in the sense that only portions of text are
recognized and no full parse is provided for. Pat-
terns not recognized by the rules of the (broad)
grammar remain unchanged. The maximal in-
stances of a particular phrase are selected by appli-
cation of the left-to-right-longest-match replace-
ment operator.
The segments are built on in cascades in the
sense that first the heads are recognized, starting
from the left-most edge to the head (so called lexi-
cal-prefix) and then the segments are expanded in
the next level by addition of complement con-
stituents. The regular expressions in (14) compose
the marking transducers of separate segments into
a three step process.
(14) define parse1[markVPhead .o.
markPPhead .o. AP];
define parse2 [markNP];
define parse3 [markPP .o. markVP];
First the verbal heads, prepositional heads and
adjective phrases are recognized by composition in
that order (parse1). This output serves then as in-
put to the next level, where the adjective phrases
are extended and noun phrases are recognized and
marked (parse2). This output in turn serves as in-
put to the last level, where the whole prepositional
phrases and verb phrases are recognized in that
order (parse3). During and after this parsing anno-
tation, some phrase types are further expanded
with post-modifiers, split segments are joined and
empty results are removed.
The ‘broadness’ of the grammar and the lexical
ambiguity in words, necessary for parsing text con-
taining errors, also yields ambiguous and/or alter-
native phrase annotations. We block some of the
(erroneous) alternative parses by the order in
which phrase segments are selected, which causes
bleeding of some rules (i.e. the parsing order de-
stroys application of another parsing rules; a fea-
ture mostly used of the ordering of phonological
rules) and more ‘correct’ parsing results are
achieved. The order in which the labels are in-
serted into the string influences the segmentation
of patterns into phrases. Further ambiguity resolu-
tion is provided for by filtering automata.
</bodyText>
<subsectionHeader confidence="0.997331">
5.2 The Heuristics of Parsing Order
</subsectionHeader>
<bodyText confidence="0.999424125">
Reordering rules used in parsing allows us to re-
solve certain ambiguities. For example, marking
verbal heads before noun phrases will prefer a verb
phrase interpretation of a string over a noun phrase
interpretation and avoid merging constituents of
verbal heads into noun phrases and yielding noun
phrases with too-wide range.
For instance, marking first the sentence in (15)
for noun phrases will interpret the pronoun De
‘they’ as a determiner and the verb sŒg ‘saw’, that
is exactly as in English homonymous with the
noun ‘saw’, as a noun and merges these two con-
stituents to a noun phrase as shown in (16). De sŒg
will subsequently be marked as ungrammatical,
since a number feature mismatch occurs between
the plural De ‘they’ and singular sŒg ‘saw’.
</bodyText>
<listItem confidence="0.99945175">
(15) De sŒg ledsna ut
they looked sad out
- They seemed sad.
(16) &lt;np&gt;De sŒg &lt;/np&gt; &lt;np&gt;ledsna &lt;/np&gt; ut .
</listItem>
<bodyText confidence="0.984533">
Composing the marking transducers by first mark-
ing the verbal head and then the noun phrase will
instead yield the more correct parse. Although the
alternative of the verb being parsed as verbal head
or a noun remains (i.e. sŒg ‘saw’ is still tagged as a
noun in a noun phrase), the pronoun De ‘they’ is
now marked correctly as a separate noun phrase
and not merged together with the main verb into a
noun phrase:
</bodyText>
<listItem confidence="0.969816">
(17) &lt;np&gt; De &lt;/np&gt; &lt;vpHead&gt; &lt;np&gt; sŒg &lt;/np&gt;
&lt;/vpHead&gt; &lt;np&gt; ledsna &lt;/np&gt; ut .
</listItem>
<bodyText confidence="0.9996595">
The output at this stage is then further refined
and/or revised by application of filtering transduc-
ers. Earlier parsing decisions depending on lexical
ambiguity are resolved (e.g. adjectives parsed as
verbs) and phrases extended (e.g. with postnominal
modifiers). Other structural ambiguities, such as
verb coordinations or clausal modifiers on nouns,
are also taken care of.
</bodyText>
<page confidence="0.996763">
74
</page>
<bodyText confidence="0.9999325">
This ordering strategy is not absolute however,
since the opposite scenario is possible where pars-
ing noun phrases before verbal heads is more suit-
able, as for instance in example (18) below, where
the string det šppna fšnstret ‘the open window’
will be split in three separate noun phrase segments
when applying the order of parsing verbal heads
before noun phrases, due the homonymity between
an adjective and an infinitive or imperative verb
form (19).
</bodyText>
<listItem confidence="0.987846">
(18) han tittade genom det šppna fšnstret
he looked through the open window
- He looked through the open window
(19) &lt;np&gt; han &lt;/np&gt;&lt;vpHead&gt; tittade &lt;/vpHead&gt;
genom &lt;np&gt; det &lt;/np&gt; &lt;vpHead&gt; &lt;np&gt;
šppna &lt;/np&gt; &lt;/vpHead&gt; &lt;np&gt; fšnstret &lt;/np&gt;
</listItem>
<bodyText confidence="0.999914666666667">
We analyzed the ambiguity frequency in the Child
Data corpus and found that occurrences of nouns
recognized as verbs are more frequent than the op-
posite. On this ground, we chose the strategy of
marking verbal heads before marking noun
phrases. In the case of the opposite scenario, the
false parsing can be revised and corrected by an
additional filter (see Section 5.3).
A similar problem occurs with homonymous
prepositions and nouns. For instance, the string vid
is ambiguous between an adjective (‘wide’) and a
preposition (‘by’) as shown in example (20) and
influences the order of marking prepositional heads
and noun phrases. Parsing prepositional heads be-
fore noun phrases is more suitable for preposition
occurrences as shown in (22) in order to prevent
the preposition from being merged as part of a
noun phrase, as in (21):
</bodyText>
<listItem confidence="0.98163825">
(20) Jag satte mig vid bordet
I sat me by the-table
– I sat down at the table.
(21) &lt;np&gt; Jag &lt;/np&gt; satte &lt;np&gt; mig &lt;/np&gt; &lt;np&gt;
&lt;ppHead&gt; vid &lt;/ppHead&gt; bordet &lt;/np&gt;
(22) &lt;np&gt; Jag &lt;/np&gt; satte &lt;np&gt; mig &lt;/np&gt;
&lt;ppHead&gt; &lt;np&gt; vid &lt;/np&gt; &lt;/ppHead&gt; &lt;np&gt;
bordet &lt;/np&gt;
</listItem>
<subsectionHeader confidence="0.984299">
5.3 Further Ambiguity Resolution
</subsectionHeader>
<bodyText confidence="0.9998805">
Nouns, adjectives and pronouns are homonymous
with verbs and might then be interpreted by the
parser as verbal heads. Adjectives homonymous
with prepositions can be analyzed as prepositional
heads. These parsing decisions can be redefined at
a later stage by application of filtering transducers.
As exemplified in (19) above, the consequence
of parsing verbal heads before noun phrases may
yield noun phrases that are split into parts, due to
the fact that adjectives are interpreted as verbs. The
filtering transducer in (23) adjusts such segments
and removes the erroneous (inner) syntactic tags
(i.e. replaces them with the empty string ‘0’) so
that only the outer noun phrase markers remain and
converts the split phrase in to one noun phrase
yielding (24).
</bodyText>
<listItem confidence="0.516134">
(23) define adjustNPAdj [
&amp;quot;&lt;/np&gt;&lt;vpHead&gt;&lt;np&gt;&amp;quot; -&gt; 0  ||Det _ APPhr
&amp;quot;&lt;/np&gt;&lt;/vpHead&gt;&amp;quot; NPPhr,,
&amp;quot;&lt;/np&gt;&lt;/vpHead&gt;&lt;np&gt;&amp;quot; -&gt; 0  ||Det
&amp;quot;&lt;/np&gt;&lt;vpHead&gt;&lt;np&gt;&amp;quot; APPhr _ ];
(24) &lt;np&gt; han &lt;/np&gt; &lt;vpHead&gt; tittade &lt;/vpHead&gt;
genom &lt;np&gt; det šppna fšnstret &lt;/np&gt;
</listItem>
<bodyText confidence="0.999943285714286">
The regular expression consists of two replacement
rules that apply in parallel. They are constrained by
the surrounding context of a preceding determiner
(Det) and a subsequent adjective phrase (APPhr)
and a noun phrase (NPPhr) in the first rule, and a
preceding determiner and an adjective phrase in
the second rule.
</bodyText>
<subsectionHeader confidence="0.999862">
5.4 Parsing Expansion and Adjustment
</subsectionHeader>
<bodyText confidence="0.999964153846154">
The text is now annotated with syntactic tags and
some of the segments have to be further expanded
with postnominal attributes and coordinations. In
the current system, partitive prepositional phrases
are the only postnominal attributes taken care of.
The reason is that grammatical errors were found
in these constructions.
By application of the filtering transducer in (25)
the example text in (26) with the partitive noun
phrase en av dom gamla husen ‘one of the old
houses’ split into a noun phrase followed by a
prepositional head that includes the partitive
preposition av ‘of’ and yet another noun phrase
</bodyText>
<page confidence="0.997255">
75
</page>
<bodyText confidence="0.9996316">
grammar errors, working mostly with the errors
and not paying much attention to the text as a
whole. The second phase involved blocking of the
resultant false alarms found in the first stage.
In Table 1 we show the final results of error de-
tection in the training corpus of Child Data. There
were altogether 15 agreement errors in noun
phrase, 110 errors in the form of finite verb, 7 er-
rors in the verb form after an auxiliary verb and 4
errors in verbs after infinitive marker.
</bodyText>
<table confidence="0.99623">
Error type No. CA FA R P F
Errors
Agreement in 15 15 62 100% 19% 33%
NP 110 96 126 87% 43% 58%
Finite verb 7 6 47 86% 11% 20%
form 4 4 0 100% 100% 100%
Verb form
after aux. verb
Verb form
after inf. mar-
ker
Total 136 121 235 89% 34% 49%
</table>
<bodyText confidence="0.996044714285714">
from the parsing stage (27) is merged to form a
single noun phrase, as shown in (28). This automa-
ton removes the redundant inner syntactic markers
by application of two replacement rules, con-
strained by the right or left context. The replace-
ment occurs simultaneously by application of par-
allel replacement.
</bodyText>
<figure confidence="0.885227142857143">
(25) define adjustNPPart [
&amp;quot;&lt;/np&gt;&lt;ppHead&gt;&amp;quot; -&gt; 0  ||_ PPart
&amp;quot;&lt;/ppHead&gt;&lt;np&gt;&amp;quot;,,
&amp;quot;&lt;/ppHead&gt;&lt;np&gt;&amp;quot; -&gt; 0 ||
&amp;quot;&lt;/np&gt;&lt;ppHead&gt;&amp;quot; PPart _ ];
(26) Virginia hade šppnat en tygaffŠr i en av
dom gamla husen.
</figure>
<bodyText confidence="0.92659625">
Virginia had opened a fabric-store in one
of the old houses[def].
- Virginia had opened a fabric-store in one
of the old houses.
</bodyText>
<listItem confidence="0.975553666666667">
(27) &lt;np&gt; Virginia &lt;/np&gt; &lt;vp&gt;&lt;vpHead&gt; &lt;vc&gt;
hade šppnat &lt;/vc&gt; &lt;/vpHead&gt; &lt;np&gt; en tyg-
affŠr &lt;/np&gt; i &lt;np&gt; en &lt;/np&gt; &lt;ppHead&gt; av
&lt;/ppHead&gt; &lt;np&gt; dom &lt;ap&gt; gamla &lt;/ap&gt;
husen &lt;/np&gt; .
(28) &lt;np&gt; Virginia &lt;/np&gt; &lt;vp&gt; &lt;vpHead&gt; &lt;vc&gt;
hade šppnat &lt;/vc&gt; &lt;/vpHead&gt; &lt;np&gt; en tyg-
affŠr &lt;/np&gt; i &lt;NPPart&gt; en av dom &lt;ap&gt; gamla
&lt;/ap&gt; husen &lt;/np&gt;
</listItem>
<bodyText confidence="0.999791">
Other filtering transducers are used for refining the
parsing result and eliminate incomplete parsing
decisions such as prepositional heads without a
following noun phrase.
</bodyText>
<sectionHeader confidence="0.975766" genericHeader="method">
6 The System Performance
</sectionHeader>
<subsectionHeader confidence="0.983396">
6.1 Result on Child Data
</subsectionHeader>
<bodyText confidence="0.9999945">
The implemented error detector, FiniteCheck, can-
not at present be considered as a fully developed
grammar checking tool, but still even with its re-
stricted lexicon and small grammar the results are
promising. So far the technique was used to detect
agreement errors in noun phrases, selection of
finite and non-finite verb forms in main and subor-
dinate clauses and infinitival complements. The
implementation proceeded in two steps. In the first
phase we devoted all effort to detection of the
</bodyText>
<tableCaption confidence="0.923301">
Table 1. Performance of FiniteCheck on Child Data:
correct alarms (CA), false alarms (FA), recall (R), pre-
cision (P), F-value (F).
</tableCaption>
<bodyText confidence="0.999948666666667">
FiniteCheck detected all the agreement errors in
noun phrases and all erroneous verb forms after an
infinitive marker, only a portion of other errors in
verb form was missed. The precision of the system
is rather low, primarily due the ambiguity of the
texts and the number of alarms marking other er-
rors such as segmentation or spelling errors. This
side-effect is difficult to eliminate totally and gives
rather rise to new questions of how to handle also
these types of writing problems that concern spell-
ing rather than grammar.
The three Swedish grammar checkers mentioned
above in Section 2: GrammatiÞx, Granska and
Scarrie, have been tested on the Child Data. The
result of their performance is shown in Figure 2,
below, together with the results of FiniteCheck.
These three tools are designed to detect errors in
text different from the nature of the Child Data and
thus not surprisingly the accuracy rates are in over-
all low. The total recall rate for the four error types
covered by FiniteCheck is between 9% and 21% in
these three tools and precision varies between 16%
to 35%. Errors in noun phrases seem to be better
covered than verb errors.
</bodyText>
<page confidence="0.945473">
76
</page>
<bodyText confidence="0.9999757">
In the case of GrammatiÞx, errors in verbs are not
covered at all. Half of the noun phrase errors were
identified and only five errors in the finite verb
form. Granska covered all four error types and de-
tected at most half of the errors for three of these
types. However, only seven instances of errors in
finite verb form were identified. Scarrie had diffi-
culties with errors in verb form after infinitive
marker that were not detected at all. Errors in noun
phrase were the best detected type.
</bodyText>
<figureCaption confidence="0.998591">
Figure 2: Performance of All Systems on Child Data
</figureCaption>
<bodyText confidence="0.999776285714286">
The detection performance of these three tools on
Child Data is in general half that good in compari-
son to our detector and the fact that the error type
with worst coverage (finite verbs) is the one most
frequent among children indicates clearly the need
for specialized grammar checking tools for chil-
dren.
</bodyText>
<subsectionHeader confidence="0.995352">
6.2 Result on Text Written by Adult
</subsectionHeader>
<bodyText confidence="0.999864583333333">
The current system was also tested on a text of
1 070 words written by an adult, one of the demon-
stration texts used by Granska. The performance of
FiniteCheck on this text is presented in Table 2.
We found 17 noun phrase agreement errors, 5 er-
rors in the form of finite verb and 1 error in the
verbform after an auxiliary verb in the text. Fi-
niteCheck found all the verb form errors and most
of the agreement errors, ending in a recall value of
87%. False alarms occurred also only in the
agreement errors, resulting in a precision rate of
71% and an F-value of 78%.
</bodyText>
<table confidence="0.8943549">
Error type No. CA FA R P F
Errors
Agreement 17 14 6 82% 70% 76%
in NP
Finite verb 5 5 1 100% 83% 91%
form
Verb form 1 1 1 100% 50% 67%
after aux.
verb
Total 23 20 8 87% 71% 78%
</table>
<tableCaption confidence="0.981396666666667">
Table 2. Performance of FiniteCheck on Text Written
by Adult: correct alarms (CA), false alarms (FA), recall
(R), precision (P), F-value (F).
</tableCaption>
<bodyText confidence="0.9998230625">
The three Swedish grammar checkers were also
tested on this adult text, that reflects more the text
type these tools are designed for. The results pre-
sented in Figure 3 show an average recall rate of
52% for the three Swedish grammar checkers, Fi-
niteCheck scored 87%. These tools had difficulties
to detect the verb form errors, whereas most of the
errors in noun phrase agreement were found. The
opposite scenario applies for precision, where Fi-
niteCheck had slightly worse rate (71%) than
Grammatifix and Granska, which had a precision
above 90%. Scarrie’s precision was 65%. In the
combined measure of recall and precision (F-
value) our system obtained 78%, which is slightly
better in comparison to the other tools that had
70% or less in F-value.
</bodyText>
<figureCaption confidence="0.8924705">
Figure 3: Performance of All Systems on Text Written
by Adult
</figureCaption>
<page confidence="0.992679">
77
</page>
<reference confidence="0.9996915">
GACL’98, Workshop on ‘Processing of Dependency-
Based Grammars’, pages 1–10. Universite de Mont-
real, Canada.
Karlsson, F. (1992). SWETWOL: Comprehensive mor-
phological analyzer for Swedish. Nordic Journal of
Linguistics, 15:1–45.
Karlsson, F., Voutilainen, A., HeikkilŠ, J., and Anttila,
A. (1995). Constraint Grammar: a language-
independent system for parsing unrestricted text.
Mouton de Gruyter, Berlin.
Karttunen, L. (1993) Finite State Lexicon Compiler.
Technical Report ISTL-NLTT-1993-04-02, Xerox
Palo Alto Research Center, Palo Alto, California.
Karttunen, L., Chanod, J., Grefenstette, G. and Schiller,
A. (1996) Regular Expressions for Language Engi-
neering, In Natural Language Engineering 2 (4) 305-
328.
Karttunen, L., Ga‡l, T. and Kempe, A. (1997) Xerox
Finite State Tool. Xerox Research Centre Europe,
Kirschner, Z. (1994) CZECKER -a Maquette Grammar-
Checker for Czech. In The Prague Bulletin of
Mathematical Linguistics 62, Praha: Universita Kar-
lova.
Knutsson, O. (2001). Automatisk sprŒkgranskning av
svensk text. Licentiatavhandling, KTH, Institutionen
fšr numerisk analys och datalogi, Stockholm.
Kukich, K. (1992) Techniques for Automatically Cor-
recting Words in Text. ACM Computing Surveys,
Vol. 24, No. 4: 377 - 439.
Sofkova Hashemi, S. (2003) Automatic Detection of
Grammar Errors in Primary School Children&apos;s Texts.
A Finite State Approach. Doctoral dissertation. Goth-
enburg Monographs in Linguistics 24. Department of
Linguistics, Gšteborg University.
Sofkova Hashemi, S. (forthcoming) The role of writing
aid in the text production of school children. De-
partment of Linguistics, Gšteborg University
SŒgvall Hein, A. (1983). A Parser for Swedish. Status
Report for SveUcp. (UCDLR-83-2). Uppsala Univer-
sity, Department of Linguistics. February 1983.
SŒgvall Hein, A. (1999) A grammar checking module
for Swedish. Report from the Scarrie-project: DEL
6.6.3, June 1999, Dept. of Linguistics, Uppsala Uni-
versity.
SŒgvall Hein, A., Olsson, L.-G., Dahlqvist, B., and
Mats, E. (1999). Evaluation report for the Swedish
prototype. In SŒgvall Hein, A. (ed.) Reports from the
SCARRIE project, Deliverable 8.1.3, June 1999.
Uppsala University, Department of Linguistics.
Vernon, A. (2000) Computerized grammar checkers
2000: Capabilities, limitations, and pedagogical pos-
sibilities. Computers and Composition 17, 329-349.
Vosse, T. G. (1994) The Word Connection. Grammar-
based Spelling Error Correction in Dutch. Enschede:
Neslia Paniculata.
Wedbjer Rambell, O. (1999). Swedish phrase constitu-
ent rules. A formalism for the expression of local er-
ror rules for Swedish. In SŒgvall Hein, A. (ed.) Re-
ports from the SCARRIE project. Uppsala University,
Department of Linguistics.
</reference>
<page confidence="0.999032">
79
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.911720">
<title confidence="0.999883">Ambiguity Resolution by Reordering Rules in Text Containing Errors</title>
<author confidence="0.997931">Sylvana Sofkova</author>
<affiliation confidence="0.992722">Department of Linguistics, Gšteborg</affiliation>
<address confidence="0.948373">Box 200, SE-405 30 Gšteborg,</address>
<email confidence="0.953417">sylvana@ling.gu.se</email>
<abstract confidence="0.999355571428571">Writing aids such as spelling and grammar checkers are often based on texts by adult writers and are not sufficiently targeted to support children in their writing process. This paper reports on the development of a writing tool based on a corpus of Swedish text written by children and on the parsing methods developed to handle text containing errors. The system uses finite state techniques for finding grammar errors without actually specifying the error. The ‘broadness’ of the grammar and the lexical ambiguity in words, necessary for parsing text containing errors, also yields ambiguous and/or alternative phrase annotations. We block some of the (erroneous) alternative parses by the order in which phrase segments are selected, which causes bleeding of some rules and more ‘correct’ parsing results are achieved. The technique shows good coverage results for agreement and verb selection phenomena.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>GACL’98</author>
</authors>
<title>Workshop on ‘Processing of DependencyBased Grammars’,</title>
<pages>1--10</pages>
<institution>Universite de Montreal, Canada.</institution>
<marker>GACL’98, </marker>
<rawString>GACL’98, Workshop on ‘Processing of DependencyBased Grammars’, pages 1–10. Universite de Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
</authors>
<title>SWETWOL: Comprehensive morphological analyzer for Swedish.</title>
<date>1992</date>
<journal>Nordic Journal of Linguistics,</journal>
<pages>15--1</pages>
<contexts>
<context position="5232" citStr="Karlsson, 1992" startWordPosition="803" endWordPosition="804">Jensen et al., 1993). This approach of providing analysis of all sentences had influenced other grammar formalisms such as Constraint Grammar (Karlsson et al., 1995) or Functional Dependency Grammar (JŠrvinen and Tapanainen, 1998). The methods of rule relaxation and parse fitting had an impact on the development of other grammar checking systems. The three Swedish tools use different technology to analyze unrestricted text and detect grammar errors. The lexical analysis in Grammatifix is based on the morphological analyzer SWETWOL, designed according to the principles of two-level morphology (Karlsson, 1992). The part-of-speech assignment applies the Swedish Constraint Grammar (SWECG), a surface-syntactic parser applying context-sensitive disambiguation rules (Birn, 1998). Errors are detected by partial parsing and relaxation on rules, regarding certain word sequences as phrases despite grammar errors in them. Granska combines probabilistic and rule-based methods, where specific error rules (around 600) and local applied rules detect ungrammaticalities in free text. The lexical analyzer applies Hidden Markov Models and a rule matching system analyses the tagged text searching for grammatical viol</context>
</contexts>
<marker>Karlsson, 1992</marker>
<rawString>Karlsson, F. (1992). SWETWOL: Comprehensive morphological analyzer for Swedish. Nordic Journal of Linguistics, 15:1–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
<author>A Voutilainen</author>
<author>J HeikkilŠ</author>
<author>A Anttila</author>
</authors>
<title>Constraint Grammar: a languageindependent system for parsing unrestricted text. Mouton de Gruyter,</title>
<date>1995</date>
<location>Berlin.</location>
<contexts>
<context position="4782" citStr="Karlsson et al., 1995" startWordPosition="733" endWordPosition="736">, a system developed in collaboration with IBM within the Programming Language for Natural Language Processing (PLNLP) project (Jensen et al., 1993). This tool is based on a parser using Augmented Phrase Structure Grammar (ACFG) and produces a complete analysis for all sentences (even ungrammatical) by application of relaxation rules when parsing fails on the first try or parse fitting procedure identifying the head and its constituents (Heidorn, 1993; Jensen et al., 1993). This approach of providing analysis of all sentences had influenced other grammar formalisms such as Constraint Grammar (Karlsson et al., 1995) or Functional Dependency Grammar (JŠrvinen and Tapanainen, 1998). The methods of rule relaxation and parse fitting had an impact on the development of other grammar checking systems. The three Swedish tools use different technology to analyze unrestricted text and detect grammar errors. The lexical analysis in Grammatifix is based on the morphological analyzer SWETWOL, designed according to the principles of two-level morphology (Karlsson, 1992). The part-of-speech assignment applies the Swedish Constraint Grammar (SWECG), a surface-syntactic parser applying context-sensitive disambiguation r</context>
</contexts>
<marker>Karlsson, Voutilainen, HeikkilŠ, Anttila, 1995</marker>
<rawString>Karlsson, F., Voutilainen, A., HeikkilŠ, J., and Anttila, A. (1995). Constraint Grammar: a languageindependent system for parsing unrestricted text. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Finite State Lexicon Compiler.</title>
<date>1993</date>
<tech>Technical Report ISTL-NLTT-1993-04-02,</tech>
<institution>Xerox Palo Alto Research Center,</institution>
<location>Palo Alto, California.</location>
<contexts>
<context position="14065" citStr="Karttunen, 1993" startWordPosition="2246" endWordPosition="2247">ing and development of finite state grammars. The environment shows the results of an XFST-process run on the current Emacs buffer in a separate buffer. An XFST-mode allows for menus to be used and recompile files in the system. The sequenced finite state transducers of FiniteCheck are divided in four main modules: the lexicon lookup, the grammar, the parser and the error finder – see Figure 1. text input Figure 1: The system architecture 4.1 The Lexicon Lookup The lexicon of around 160, 000 word forms, is built as a finite state transducer, using the Xerox tool Finite State Lexicon Compiler (Karttunen, 1993). The lexicon is composed from two resources and takes a string and maps inflected surface form to a tag containing part-of-speech and feature information, e. g. applying the transducer to the string kvinna ‘woman’ will return [nn utr sin ind nom]. The morphosyntactic tags follow directly the relevant string or token. More than one tag can be attached to a string, since no contextual information is taken into account. The morphosyntactic information in the tags is further used in the grammars of the system. The set of tags follows the Stockholm-UmeŒ Corpus project conventions (Ejerhed et al, 1</context>
</contexts>
<marker>Karttunen, 1993</marker>
<rawString>Karttunen, L. (1993) Finite State Lexicon Compiler. Technical Report ISTL-NLTT-1993-04-02, Xerox Palo Alto Research Center, Palo Alto, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
<author>J Chanod</author>
<author>G Grefenstette</author>
<author>A Schiller</author>
</authors>
<title>Regular Expressions for Language Engineering,</title>
<date>1996</date>
<journal>In Natural Language Engineering</journal>
<volume>2</volume>
<issue>4</issue>
<pages>305--328</pages>
<contexts>
<context position="2106" citStr="Karttunen et al., 1996" startWordPosition="327" endWordPosition="330">writing development and give no space for acquisition or training. Errors in texts written by school children are more frequent and the distribution of the error types is different from adult writers. This paper reports on the development of a finite state system for finding grammar errors, called FiniteCheck, based on a corpus of Swedish text written by school children. The system applies descriptions of correct language use in the detection process of grammatical violations and contains no rules describing the nature of the erroneous segments the system searches for. The approach (following Karttunen et al., 1996) for finding errors involves developing automata that represent two ‘positive’ grammars with varying degree of detail and then subtracting the detailed one from the general one. The difference between the automata corresponds to a grammar for errors. 2 Grammar Checkers 2.1 Current Systems Whereas spelling checkers are standard in most word processors, grammar checking is a rather recent technology, especially for Swedish. Different methods and techniques have been applied to handle nonsense words and thus operate on isolated words as most spelling correctors do. Both statistical and rule-based</context>
</contexts>
<marker>Karttunen, Chanod, Grefenstette, Schiller, 1996</marker>
<rawString>Karttunen, L., Chanod, J., Grefenstette, G. and Schiller, A. (1996) Regular Expressions for Language Engineering, In Natural Language Engineering 2 (4) 305-328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
<author>T Ga‡l</author>
<author>A Kempe</author>
</authors>
<title>Xerox Finite State Tool. Xerox Research Centre Europe,</title>
<date>1997</date>
<marker>Karttunen, Ga‡l, Kempe, 1997</marker>
<rawString>Karttunen, L., Ga‡l, T. and Kempe, A. (1997) Xerox Finite State Tool. Xerox Research Centre Europe,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Kirschner</author>
</authors>
<title>CZECKER -a Maquette GrammarChecker for Czech.</title>
<date>1994</date>
<booktitle>In The Prague Bulletin of Mathematical Linguistics 62,</booktitle>
<location>Praha: Universita Karlova.</location>
<marker>Kirschner, 1994</marker>
<rawString>Kirschner, Z. (1994) CZECKER -a Maquette GrammarChecker for Czech. In The Prague Bulletin of Mathematical Linguistics 62, Praha: Universita Karlova.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Knutsson</author>
</authors>
<title>Automatisk sprŒkgranskning av svensk text. Licentiatavhandling, KTH, Institutionen fšr numerisk analys och datalogi,</title>
<date>2001</date>
<location>Stockholm.</location>
<contexts>
<context position="3907" citStr="Knutsson, 2001" startWordPosition="600" endWordPosition="601"> 1994), Czech (Kirschner, 69 Proceedings of the 10th Conference on Parsing Technologies, pages 69–79, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics 1994), Spanish and Greek (Bustamente and Le—n, 1996). Computer-based grammar checking for Swedish is fairly recent and has primarily focused on the needs of adult writers. The first product release of such a writing aid was in November 1998 with the tool GrammatiÞx (Arppe, 2000; Birn, 2000), now part of the Swedish Microsoft Office 2000. Two other research groups developed grammar checking prototypes: Granska (Knutsson, 2001; Domeij, 2003) and Scarrie (SŒgvall Hein, 1999). 2.2 Methods and Techniques Many of the grammar checking systems are commercial products and technical documentation is often minimal or even absent. Critique (known until 1984 as Epistle) is an exception, a system developed in collaboration with IBM within the Programming Language for Natural Language Processing (PLNLP) project (Jensen et al., 1993). This tool is based on a parser using Augmented Phrase Structure Grammar (ACFG) and produces a complete analysis for all sentences (even ungrammatical) by application of relaxation rules when parsin</context>
<context position="8865" citStr="Knutsson, 2001" startWordPosition="1357" endWordPosition="1358">punctuation marks often delimit larger textual units than syntactic sentences. Sentence boundaries and capitalization are something the Swedish tools rely on in their detection process, which may have impact on the coverage results. Although the systems cover many of the types of errors found in school texts, they detect around 12% of all writing errors (Sofkova Hashemi, 2003) (see Section 6). Performance on text data such as newspaper texts and student compositions evaluated within the frames of the separate projects shows a much higher coverage of error detection on average 58% (Birn, 2000; Knutsson, 2001; SŒgvall Hein et al., 1999). 3 The Training Data 3.1 The Child Data Corpus FiniteCheck, the grammar error detector reported in this paper, is based on a corpus of Swedish text written by school children. This Child Data corpus of 29 812 words (3 373 word types) is composed of computer written and hand written essays written by children between 9 and 13 years of age. In general, the text structure of the compositions reveals clearly the influence of spoken language and performance difficulties in spelling, segmentation of words, the use of capitals and punctuation, with fairly wide variation b</context>
</contexts>
<marker>Knutsson, 2001</marker>
<rawString>Knutsson, O. (2001). Automatisk sprŒkgranskning av svensk text. Licentiatavhandling, KTH, Institutionen fšr numerisk analys och datalogi, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for Automatically Correcting Words in Text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<pages>377--439</pages>
<contexts>
<context position="2920" citStr="Kukich, 1992" startWordPosition="453" endWordPosition="454">the automata corresponds to a grammar for errors. 2 Grammar Checkers 2.1 Current Systems Whereas spelling checkers are standard in most word processors, grammar checking is a rather recent technology, especially for Swedish. Different methods and techniques have been applied to handle nonsense words and thus operate on isolated words as most spelling correctors do. Both statistical and rule-based methods and also algorithms that to some extent take into consideration the surrounding context (i.e. context-sensitive errors) or how a word is pronounced have been used for spelling correction (cf. Kukich, 1992). Grammar checkers involve techniques and solve problems above the single word level and require syntactic, semantic or even discourse analysis (see Section 2.2). Grammar checking techniques started to develop first in the 1980’s with products mainly for English (see Jensen et al, 1993; Vernon, 2000) but also for other languages, e.g. French (Chanod, 1996), Dutch (Vosse, 1994), Czech (Kirschner, 69 Proceedings of the 10th Conference on Parsing Technologies, pages 69–79, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics 1994), Spanish and Greek (Bustamente and </context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Kukich, K. (1992) Techniques for Automatically Correcting Words in Text. ACM Computing Surveys, Vol. 24, No. 4: 377 - 439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sofkova Hashemi</author>
<author>S</author>
</authors>
<title>Automatic Detection of Grammar Errors in Primary School Children&apos;s Texts. A Finite State Approach. Doctoral dissertation. Gothenburg Monographs in Linguistics 24.</title>
<date>2003</date>
<institution>Department of Linguistics, Gšteborg University.</institution>
<marker>Hashemi, S, 2003</marker>
<rawString>Sofkova Hashemi, S. (2003) Automatic Detection of Grammar Errors in Primary School Children&apos;s Texts. A Finite State Approach. Doctoral dissertation. Gothenburg Monographs in Linguistics 24. Department of Linguistics, Gšteborg University.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sofkova Hashemi</author>
<author>S</author>
</authors>
<title>(forthcoming) The role of writing aid in the text production of school children.</title>
<institution>Department of Linguistics, Gšteborg University</institution>
<marker>Hashemi, S, </marker>
<rawString>Sofkova Hashemi, S. (forthcoming) The role of writing aid in the text production of school children. Department of Linguistics, Gšteborg University</rawString>
</citation>
<citation valid="true">
<authors>
<author>SŒgvall Hein</author>
<author>A</author>
</authors>
<title>A Parser for Swedish.</title>
<date>1983</date>
<tech>Status Report for SveUcp. (UCDLR-83-2).</tech>
<institution>Uppsala University, Department of Linguistics.</institution>
<marker>Hein, A, 1983</marker>
<rawString>SŒgvall Hein, A. (1983). A Parser for Swedish. Status Report for SveUcp. (UCDLR-83-2). Uppsala University, Department of Linguistics. February 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SŒgvall Hein</author>
<author>A</author>
</authors>
<title>A grammar checking module for Swedish. Report from the Scarrie-project: DEL 6.6.3,</title>
<date>1999</date>
<institution>Dept. of Linguistics, Uppsala University.</institution>
<marker>Hein, A, 1999</marker>
<rawString>SŒgvall Hein, A. (1999) A grammar checking module for Swedish. Report from the Scarrie-project: DEL 6.6.3, June 1999, Dept. of Linguistics, Uppsala University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SŒgvall Hein</author>
<author>A Olsson</author>
<author>L-G Dahlqvist</author>
<author>B</author>
<author>E Mats</author>
</authors>
<title>Evaluation report for the Swedish prototype.</title>
<date>1999</date>
<booktitle>In SŒgvall Hein, A. (ed.) Reports from the SCARRIE project, Deliverable 8.1.3,</booktitle>
<institution>Uppsala University, Department of Linguistics.</institution>
<contexts>
<context position="8893" citStr="Hein et al., 1999" startWordPosition="1360" endWordPosition="1363">delimit larger textual units than syntactic sentences. Sentence boundaries and capitalization are something the Swedish tools rely on in their detection process, which may have impact on the coverage results. Although the systems cover many of the types of errors found in school texts, they detect around 12% of all writing errors (Sofkova Hashemi, 2003) (see Section 6). Performance on text data such as newspaper texts and student compositions evaluated within the frames of the separate projects shows a much higher coverage of error detection on average 58% (Birn, 2000; Knutsson, 2001; SŒgvall Hein et al., 1999). 3 The Training Data 3.1 The Child Data Corpus FiniteCheck, the grammar error detector reported in this paper, is based on a corpus of Swedish text written by school children. This Child Data corpus of 29 812 words (3 373 word types) is composed of computer written and hand written essays written by children between 9 and 13 years of age. In general, the text structure of the compositions reveals clearly the influence of spoken language and performance difficulties in spelling, segmentation of words, the use of capitals and punctuation, with fairly wide variation both by individual and age. I</context>
</contexts>
<marker>Hein, Olsson, Dahlqvist, B, Mats, 1999</marker>
<rawString>SŒgvall Hein, A., Olsson, L.-G., Dahlqvist, B., and Mats, E. (1999). Evaluation report for the Swedish prototype. In SŒgvall Hein, A. (ed.) Reports from the SCARRIE project, Deliverable 8.1.3, June 1999. Uppsala University, Department of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vernon</author>
</authors>
<title>Computerized grammar checkers 2000: Capabilities, limitations, and pedagogical possibilities.</title>
<date>2000</date>
<journal>Computers and Composition</journal>
<volume>17</volume>
<pages>329--349</pages>
<contexts>
<context position="3221" citStr="Vernon, 2000" startWordPosition="498" endWordPosition="499">and thus operate on isolated words as most spelling correctors do. Both statistical and rule-based methods and also algorithms that to some extent take into consideration the surrounding context (i.e. context-sensitive errors) or how a word is pronounced have been used for spelling correction (cf. Kukich, 1992). Grammar checkers involve techniques and solve problems above the single word level and require syntactic, semantic or even discourse analysis (see Section 2.2). Grammar checking techniques started to develop first in the 1980’s with products mainly for English (see Jensen et al, 1993; Vernon, 2000) but also for other languages, e.g. French (Chanod, 1996), Dutch (Vosse, 1994), Czech (Kirschner, 69 Proceedings of the 10th Conference on Parsing Technologies, pages 69–79, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics 1994), Spanish and Greek (Bustamente and Le—n, 1996). Computer-based grammar checking for Swedish is fairly recent and has primarily focused on the needs of adult writers. The first product release of such a writing aid was in November 1998 with the tool GrammatiÞx (Arppe, 2000; Birn, 2000), now part of the Swedish Microsoft Office 2000. Tw</context>
</contexts>
<marker>Vernon, 2000</marker>
<rawString>Vernon, A. (2000) Computerized grammar checkers 2000: Capabilities, limitations, and pedagogical possibilities. Computers and Composition 17, 329-349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G Vosse</author>
</authors>
<title>The Word Connection. Grammarbased Spelling Error Correction in Dutch. Enschede: Neslia Paniculata.</title>
<date>1994</date>
<contexts>
<context position="3299" citStr="Vosse, 1994" startWordPosition="510" endWordPosition="511">ical and rule-based methods and also algorithms that to some extent take into consideration the surrounding context (i.e. context-sensitive errors) or how a word is pronounced have been used for spelling correction (cf. Kukich, 1992). Grammar checkers involve techniques and solve problems above the single word level and require syntactic, semantic or even discourse analysis (see Section 2.2). Grammar checking techniques started to develop first in the 1980’s with products mainly for English (see Jensen et al, 1993; Vernon, 2000) but also for other languages, e.g. French (Chanod, 1996), Dutch (Vosse, 1994), Czech (Kirschner, 69 Proceedings of the 10th Conference on Parsing Technologies, pages 69–79, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics 1994), Spanish and Greek (Bustamente and Le—n, 1996). Computer-based grammar checking for Swedish is fairly recent and has primarily focused on the needs of adult writers. The first product release of such a writing aid was in November 1998 with the tool GrammatiÞx (Arppe, 2000; Birn, 2000), now part of the Swedish Microsoft Office 2000. Two other research groups developed grammar checking prototypes: Granska (Knutss</context>
</contexts>
<marker>Vosse, 1994</marker>
<rawString>Vosse, T. G. (1994) The Word Connection. Grammarbased Spelling Error Correction in Dutch. Enschede: Neslia Paniculata.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wedbjer Rambell</author>
<author>O</author>
</authors>
<title>Swedish phrase constituent rules. A formalism for the expression of local error rules for Swedish. In</title>
<date>1999</date>
<booktitle>Reports from the SCARRIE project.</booktitle>
<editor>SŒgvall Hein, A. (ed.)</editor>
<institution>Uppsala University, Department of Linguistics.</institution>
<marker>Rambell, O, 1999</marker>
<rawString>Wedbjer Rambell, O. (1999). Swedish phrase constituent rules. A formalism for the expression of local error rules for Swedish. In SŒgvall Hein, A. (ed.) Reports from the SCARRIE project. Uppsala University, Department of Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>