<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000930">
<title confidence="0.9983185">
Improving Named Entity Recognition in Tweets via Detecting
Non-Standard Words
</title>
<author confidence="0.999759">
Chen Li and Yang Liu
</author>
<affiliation confidence="0.855811">
Computer Science Department, The University of Texas at Dallas
Richardson, Texas 75080, USA
</affiliation>
<email confidence="0.998954">
{chenli,yangl@hlt.utdallas.edu}
</email>
<sectionHeader confidence="0.99739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999884892857143">
Most previous work of text normalization
on informal text made a strong assumption
that the system has already known which
tokens are non-standard words (NSW) and
thus need normalization. However, this is
not realistic. In this paper, we propose
a method for NSW detection. In addi-
tion to the information based on the dic-
tionary, e.g., whether a word is out-of-
vocabulary (OOV), we leverage novel in-
formation derived from the normalization
results for OOV words to help make deci-
sions. Second, this paper investigates two
methods using NSW detection results for
named entity recognition (NER) in social
media data. One adopts a pipeline strat-
egy, and the other uses a joint decoding
fashion. We also create a new data set
with newly added normalization annota-
tion beyond the existing named entity la-
bels. This is the first data set with such
annotation and we release it for research
purpose. Our experiment results demon-
strate the effectiveness of our NSW detec-
tion method and the benefit of NSW detec-
tion for NER. Our proposed methods per-
form better than the state-of-the-art NER
system.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998898">
Short text messages or comments from social me-
dia websites such as Facebook and Twitter have
become one of the most popular communication
forms in recent years. However, abbreviations,
misspelled words and many other non-standard
words are very common in short texts for vari-
ous reasons (e.g., length limitation, need to con-
vey much information, writing style). They post
problems to many NLP techniques in this domain.
There are many ways to improve language pro-
cessing performance on the social media data. One
is to leverage normalization techniques to auto-
matically convert the non-standard words into the
corresponding standard words (Aw et al., 2006;
Cook and Stevenson, 2009; Pennell and Liu, 2011;
Liu et al., 2012a; Li and Liu, 2014; Sonmez and
Ozgur, 2014). Intuitively this will ease subsequent
language processing modules. For example, if
‘2mr’ is converted to ‘tomorrow’, a text-to-speech
system will know how to pronounce it, a part-of-
speech (POS) tagger can label it correctly, and an
information extraction system can identify it as a
time expression. This normalization task has re-
ceived an increasing attention in social media lan-
guage processing.
However, most of previous work on normaliza-
tion assumed that they already knew which tokens
are NSW that need normalization. Then differ-
ent methods are applied only to these tokens. To
our knowledge, Han and Baldwin (2011) is the
only previous work which made a pilot research on
NSW detection. One straight forward method to
do this is to use a dictionary to classify a token into
in-vocabulary (IV) words and out-of-vocabulary
(OOV) words, and just treat all the OOV words as
NSW. The shortcoming of this method is obvious.
For example, tokens like ‘iPhone’, ‘PES’(a game
name) and ‘Xbox’ will be considered as NSW,
however, these words do not need normalization.
Han and Baldwin (2011) called these OOV words
correct-OOV, and named those OOV words that
do need normalization as ill-OOV. We will follow
their naming convention and use these two terms
in our study. In this paper, we propose two meth-
ods to classify tokens in informal text into three
classes: IV, correct-OOV, and ill-OOV. In the fol-
lowing, we call this task the NSW detection task,
and these three labels NSW labels or classes. The
novelty of our work is that we incorporate a to-
ken’s normalization information to assist this clas-
</bodyText>
<page confidence="0.971775">
929
</page>
<note confidence="0.977937666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 929–938,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999466">
sification process. Our experiment results demon-
strate that our proposed system gives a signifi-
cant performance improvement on NSW detection
compared with the dictionary baseline system.
On the other hand, the impact of normalization
or NSW detection on NER has not been well stud-
ied in social media domain. In this paper, we pro-
pose two methods to incorporate the NSW detec-
tion information: one is a pipeline system that just
uses the predicted NSW labels as additional fea-
tures in an NER system; the other one uses joint
decoding, where we can simultaneously decide a
token’s NSW and NER labels. Our experiment re-
sults show that our proposed joint decoding per-
forms better than the pipeline method, and it out-
performs the state-of-the-art NER system.
Our contributions in this paper are as follows:
(1) We proposed a NSW detection model by lever-
aging normalization information of the OOV to-
kens. (2) We created a data set with new NSW
and normalization information, in addition to the
existing NER labels. (3) It is the first time to our
knowledge that an effective and joint approach is
proposed to combine the NSW detection and NER
techniques to improve the performance of these
two tasks at the same time on social media data.
(4) We demonstrate the effectiveness of our pro-
posed method. Our proposed NER system outper-
forms the state-of-the-art system.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999977197183099">
There has been a surge of interest in lexical nor-
malization with the advent of social media data.
Lots of approaches have been developed for this
task, from using edit distance (Damerau, 1964;
Levenshtein, 1966), to the noisy channel model
(Cook and Stevenson, 2009; Pennell and Liu,
2010; Liu et al., 2012a) and machine transla-
tion method (Aw et al., 2006; Pennell and Liu,
2011; Li and Liu, 2012b; Li and Liu, 2012a).
Normalization performance on some benchmark
data has been improved a lot. Currently, unsuper-
vised models are widely used to extract latent rela-
tionship between non-standard words and correct
words from a huge corpus. Hassan and Menezes
(2013) applied the random walk algorithm on a
contextual similarity bipartite graph, constructed
from n-gram sequences on a large unlabeled text
corpus to build relation between non-standard to-
kens and correct words. Yang and Eisenstein
(2013) presented a unified unsupervised statistical
model, in which the relationship between the stan-
dard and non-standard words is characterized by
a log-linear model, permitting the use of arbitrary
features. Chrupała (2014) proposed a text normal-
ization model based on learning edit operations
from labeled data while incorporating features in-
duced from unlabeled data via recurrent network
derived character-level neural text embeddings.
These studies only focused on how to normal-
ize a given ill-OOV word and did not address the
problem of detecting an ill-OOV word. Han and
Baldwin (2011) is the only previous study that
conducted the detection work. For any OOV word,
they replaced it with its possible correct candi-
date, then if the possible candidate together with
OOV’s original context adheres to the knowledge
they learned from large formal corpora, the re-
placement could be considered as a better choice
and that OOV token is classified as ill-OOV. In this
paper, we propose a different method for NSW
detection. Similar to (Han and Baldwin, 2011),
we also use normalization information for OOV
words, but we use a feature based learning ap-
proach.
In order to improve robustness of NLP mod-
ules in social media domain, some works chose
to design specific linguistic information. For ex-
ample, by designing or annotating POS, chunking
and capitalized information on tweets, (Ritter et
al., 2011) proposed a system which reduced the
POS tagging error by 41% compared with Stan-
ford POS Tagger, and by 50% in NER compared
with the baseline systems. Gimpel et al. (2011)
created a specific set of POS tags for twitter data.
With this tag set and word cluster information ex-
tracted from a huge Twitter corpus, their proposed
system obtained significant improvement on POS
tagging accuracy in Twitter data.
At the same time, increasing research work has
been done to integrate lexical normalization into
the NLP tasks in social media data. Kaji and Kit-
suregawa (2014) combined lexical normalization,
word segmentation and POS tagging on Japanese
microblog. They used rich character-level and
word-level features from the state-of-the-art mod-
els of joint word segmentation and POS tagging
in Japanese (Kudo et al., 2004; Neubig et al.,
2011). Their model can also be trained on a par-
tially annotated corpus. Li and Liu (2015) con-
ducted a similar research on joint POS tagging
and text normalization for English. Wang and Kan
</bodyText>
<page confidence="0.993562">
930
</page>
<bodyText confidence="0.999970142857143">
(2013) proposed a method of joint ill-OOV word
recognition and word segmentation in Chinese Mi-
croblog. But with their method, ill-OOV words
are merely recognized and not normalized. There-
fore, they did not investigate how to exploit the
information that may be derived from normaliza-
tion to increase word segmentation accuracy. Liu
et al. (2012b) studied the problem of named entity
normalization (NEN) for tweets. They proposed a
novel graphical model to simultaneously conduct
NER and NEN on multiple tweets. Although this
work involved text normalization, it only focused
on the NER task, and there was no reported re-
sult for normalization. On Turkish tweets, Ku-
cuk and Steinberger (2014) adapted NER rules
and resources to better fit Twitter language by re-
laxing its capitalization constraint, expanding its
lexical resources based on diacritics, and using a
normalization scheme on tweets. These showed
positive effect on the overall NER performance.
Rangarajan Sridhar et al. (2014) decoupled the
SMS translation task into normalization followed
by translation. They exploited bi-text resources,
and presented a normalization approach using dis-
tributed representation of words learned through
neural networks.
In this study, we propose new methods to ef-
fectively integrate information of OOV words and
their normalization for the NER task. In particu-
lar, by adopting joint decoding for both NSW de-
tection and NER, we are able to outperform state-
of-the-art results for both tasks. This is the first
study that systematically evaluates the effect of
OOV words and normalization on NER in social
media data.
</bodyText>
<sectionHeader confidence="0.998948" genericHeader="method">
3 Proposed Method
</sectionHeader>
<subsectionHeader confidence="0.999152">
3.1 NSW Detection Methods
</subsectionHeader>
<bodyText confidence="0.999965145454546">
The task of NSW detection is to find those words
that indeed need normalization. Note that in
this study we only consider single-token ill-OOV
words (both before and after normalization). For
example, we would consider snds (sounds) as ill-
OOV, but not smh (shaking my head).
For a data set, our annotation process is as fol-
lows. We first manually label whether a token is
ill-OOV and if so its corresponding standard word.
We only consider tokens consisting of alphanu-
meric characters. Then based on a dictionary, the
tokes that are not labeled as ill-OOV can be cat-
egorized into IV and OOV words. These OOV
words will be considered as correct-OOV. There-
fore all the tokens will have these three labels: IV,
ill-OOV, and correct-OOV.
Throughout this paper, we use GNU spell dic-
tionary (v0.60.6.1) to determine whether a token is
OOV.1 Twitter mentions (e.g., @twitter), hashtags
and urls are excluded from consideration for OOV.
Dictionary lookup of Internet slang2 is performed
to filter those ill-OOV words whose correct forms
are not single words.
We propose two methods for NSW detection.
The first one is a two-step method, where we first
label a token as IV or OOV based on the given
dictionary and some filter rules, then a statistical
classifier is applied on those OOV tokens to fur-
ther decide their classes: ill-OOV or correct-OOV.
We use a maximum entropy classifier for this. The
second model directly does 3-way classification to
predict a token’s label to be IV, correct-OOV, or
ill-OOV. We use a CRF model in this method.3
Table 1 shows the features used in these two
methods. The first dictionary feature is not appli-
cable for the two-step method because all the in-
stances in that process have the same feature value
‘OOV’. However, this dictionary feature is an im-
portant feature for the 3-way classification model
– a token with a feature value ‘IV’ has a very high
probability of being ‘IV’. Lexical features focus
on a token’s surface information to judge whether
it is a regular English word or not. It is because
most of correct-OOV words (e.g., location and
person names) are still some regular words, com-
plying with the general rules of word formation.
For example, features 5-8 consider English word
formation rules that at least one vowel character
is needed for a correct word4. Feature 9 consid-
ers that a correct English word does not contain
more than three consecutive same character. The
character level language model used in Feature 10
is trained from a dictionary. A higher probability
may indicate that it is a correct word.
The motivation for the normalization features is
</bodyText>
<footnote confidence="0.994025666666667">
1We remove all the one-character tokens, except a and I.
25452 items are collected from http://www.noslang.com.
3We can also use a maximum entropy classifier to imple-
</footnote>
<bodyText confidence="0.907026142857143">
ment this model. Our experiments showed that using CRFs
has slightly better results. But the main reason we adopt
CRFs is because we use CRFs for NER, therefore we can
easily integrate the two models in joint decoding in Section
3.2 for NER and NSW detection. We do not use CRFs in
the two-step system because the labeling is performed on a
subset of the words, not the entire sequence.
</bodyText>
<footnote confidence="0.7356935">
4Although some exceptions exist, this rule applies to most
words.
</footnote>
<page confidence="0.98556">
931
</page>
<figure confidence="0.7292186">
Dictionary Feature
1. is token categorized as IV or OOV by the
given dictionary (Only used in 3-way classifi-
cation)
Lexical Features
</figure>
<listItem confidence="0.78096075">
2. word identity
3. whether token’s first character is capitalized
4. token’s length
5. how many vowel character chunks does this
token have
6. how many consonant character chunks does
this token have
7. the length of longest consecutive vowel
character chunk
8. the length of longest consecutive consonant
character chunk
9. whether this token contains more than 3 con-
</listItem>
<bodyText confidence="0.993141181818182">
secutive same character
10. character level probability of this token
based on a character level language model
Normalization Features
11. whether each individual candidate list has
any candidates for this token
12. how many candidates each individual can-
didate list has
13. whether each individual list’s top 10 candi-
dates contain this token itself
14. the max number of lists that have the same
top one candidate
15. the similarity value between each in-
dividual normalization system’s first candi-
date w and this token t, calculated by
longest common string(w,t)
length(t)
16. the similarity value between each in-
dividual normalization system’s first candi-
date w and this token t, calculated by
longest common sequence(w,t)
length(t)
</bodyText>
<tableCaption confidence="0.98618">
Table 1: Features used in NSW detection system.
</tableCaption>
<bodyText confidence="0.99996575">
to leverage the normalization result of an OOV to-
ken to help its classification. Before we describe
the reason why normalization information could
benefit this task, we first introduce the normal-
ization system we used. We apply a state-of-the-
art normalization system proposed by (Li and Liu,
2014). Briefly, in this normalization system there
are three supervised and two unsupervised sub-
systems for each OOV token, resulting in six can-
didate lists (one system provides two lists). Then
a maximum entropy reranking model is adopted
to combine and rerank these candidate lists, using
a rich set of features. Please refer to (Li and Liu,
2014) for more details. By analyzing each individ-
ual system, we find that for ill-OOV words most
normalization systems can generate many candi-
dates, which may contain a correct candidate; for
correct-OOV words, many normalization systems
have few candidates or may not provide any can-
didates. For example, only two of the six lists have
candidates for the token Newsfeed and Metropcs.
Therefore, we believe the patterns of these normal-
ization results contain useful information to clas-
sify OOVs. Note that this kind of feature is only
applicable for those tokens that are judged as OOV
by the given dictionary (normalization is done on
these OOV words). The bottom of Table 1 shows
the normalization features we designed.
</bodyText>
<subsectionHeader confidence="0.549943">
3.2 NER Methods
</subsectionHeader>
<bodyText confidence="0.99997846875">
The NER task we study in this paper is just about
segmenting named entities, without identifying
their types (e.g., person, location, organization).
Following most previous work, we model it as a
sequence-labeling task and use the BIO encoding
method (each word either begins, is inside, or out-
side of a named entity).
Intuitively, NSW detection has an impact on
NER, because many named entities may have the
correct-OOV label. Therefore, we investigate if
we can leverage NSW label information for NER.
First, we adopt a pipeline method, where we first
perform NSW detection and the results are used
as features in the NER system. Table 2 shows the
features we designed. One thing worth mentioning
is that the POS tags we used are from (Gimpel et
al., 2011). This POS tag set consists of 25 coarse-
grained tags designed for social media text. We
use CRFs for this NER system.
The above method simply incorporates a to-
ken’s predicted NSW label as features in the NER
model. Obviously it has an unavoidable limitation
– the errors from the NSW detection model would
affect the downstream NER process. Therefore we
propose a second method, a joint decoding process
to determine a token’s NSW and NER label at the
same time. The 3-way classification method for
NSW detection and the above NER system both
use CRFs. The decoding process for these two
tasks is performed separately, using their corre-
sponding trained models. The motivation of our
proposed joint decoding process is to combine the
</bodyText>
<page confidence="0.987777">
932
</page>
<bodyText confidence="0.999292857142857">
two processes together, therefore we can avoid the
error propagation in the pipeline system, and allow
the two models to benefit from each other.
Part (A) and (B) of Figure 1 show the trellis for
decoding word sequence ‘Messi is well-known’ in
the NER and NSW detection systems respectively.
As shown in (A), every black box with dashed line
is a hidden state (possible BIO tag) for the corre-
sponding token. Two sources of information are
used in decoding. One is the label transition prob-
ability p(yi|yj), from the trained model, where yi
and yj are two BIO tags. The other is p(yi|ti),
where yi is a BIO label for token ti. Similarly,
during decoding in NSW detection, we need the
</bodyText>
<table confidence="0.999696620689655">
Basic Features
1. Lexical features (word n-gram):
Unigram: Wi(i = 0)
Bigram: WiWi+1(i = −2, −1, 0,1)
Trigram: Wi−1WiWi+1(i = −2, −1, 0,1)
2. POS features (POS n-gram):
Unigram: Pi(i = 0)
Bigram: PiPi+1(i = −2, −1, 0,1)
Trigram: Pi−1PiPi+1(i = −2, −1, 0,1)
3. Token’s capitalization information:
Trigram: Ci−1CiCi+1(i = 0) (Ci = 1 means
this token’s first character is capitalized.)
Additional Features by Incorporating Pre-
dicted NSW Label
4. Token’s dictionary categorization label:
Unigram: Di(i = 0)
Bigram: DiDi+1(i = −2, −1, 0,1)
Trigram: Di−1DiDi+1(i = −2, −1, 0,1)
5. Token’s predicted NSW label:
Unigram: Li(i = 0)
Bigram: LiLi+1(i = −2, −1, 0,1)
Trigram: Li−1LiLi+1(i = −2, −1, 0,1)
6. Compound features using lexical and NSW
labels: WiDi, WiLi, WiDiLi(i = 0)
7. Compound features using POS and NSW
labels: PiDi, PiLi, PiDiLi(i = 0)
8. Compound features using word, POS, and
NSW labels:
WiPiDiLi(i = 0)
</table>
<tableCaption confidence="0.983515">
Table 2: Features used in the NER System. W
</tableCaption>
<bodyText confidence="0.989023263157895">
and P represent word and POS. D and L represent
labels classified by the dictionary and 3-way NSW
detection system. Subscripts i, i − 1 and i + 1
indicate the word position. For example, when i
equals to -1, i + 1 means the current word.
probability of p(oi|oj) and p(oi|ti). The only dif-
ference is that oi is a NSW label. Part (C) of Figure
1 shows the trellis used in our proposed joint de-
coding approach for NSW detection and NER. In
this figure, three places are worth pointing out: (1)
the label is a combination of NSW and NER la-
bels, and thus there are nine in total; (2) the label
transition probability is a linear sum of the previ-
ous two transition probabilities: p(yi oi|yj oj) =
p(yi|yj) + Q * p(oi|oj), where yi and yj are BIO
tags and oi and oj are NSW tags; (3) similarly,
p(yi oi|ti) equals to p(yi|ti) + α * p(oi|ti). Please
note all these probabilities are log probabilities
and they are trained separately from each system.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="method">
4 Data and Experiment
</sectionHeader>
<subsectionHeader confidence="0.999812">
4.1 Data Set and Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999913121212121">
The NSW detection model is trained using the data
released by (Li and Liu, 2014). It has 2,577 Twit-
ter messages (selected from the Edinburgh Twit-
ter corpus (Petrovic et al., 2010)), in which there
are 2,333 unique pairs of NSW and their standard
words. This data is used for training the different
normalization models. We labeled this data set us-
ing the given dictionary for NSW detection. 4,121
tokens are labeled as ill-OOV, 1,455 as correct-
OOV, and the rest 33,740 tokens are IV words.
We have two test sets for evaluating the NSW
detection system. One is from (Han and Baldwin,
2011), which includes 549 tweets. Each tweet
contains at least one ill-OOV and the correspond-
ing correct word. We call it Test set 1 in the fol-
lowing. The other is from (Li and Liu, 2015), who
further processed the tweets data from (Owoputi
et al., 2013). Briefly, Owoputi et al. (2013) re-
leased 2,347 tweets with their designed POS tags
for social media text, and then Li and Liu (2015)
further annotated this data with normalization in-
formation for each token. The released data by (Li
and Liu, 2015) contains 798 tweets with ill-OOV.
We use these 798 tweets as the second data set for
NSW detection, and call it Test set 2 in the follow-
ing. In addition, we use all of these 2,347 tweets
to train a POS model which then is used to predict
tokens’ POS tags for NER (see Section 3.2 about
the POS tags). The CRF model is implemented us-
ing the pocket-CRF toolkit5. The SRILM toolkit
(Stolcke, 2002) is used to build the character-level
language model (LM) for generating the LM fea-
tures in NSW detection system.
</bodyText>
<footnote confidence="0.973889">
5http://sourceforge.net/projects/pocket-crf-1/
</footnote>
<page confidence="0.997413">
933
</page>
<figureCaption confidence="0.99979">
Figure 1: Trellis Viterbi decoding for different systems.
</figureCaption>
<figure confidence="0.9995829">
p(I|B)+ β * p(IVIill-OOV)
.
.
.
well-known
.
.
.
.
.
.
Messi
is
(C)
(A)
(B)
p(B|B)+ β * p(IVIIV)
p(B|B)+ β * p(ill-OOVIIV)
B_IV
p(B|Messi)+ α* p(IV|Messi)
p(B|is)+ α* p(correct-OOV|is)
B_ill-OOV
I_IV
p(I|B)+ β * p(IVIIV)
I_IV
B_correct-OOV
B_ill-OOV
I_IV
B_IV
B_correct-OOV
p(B|well-known)+
α* p(ill-OOV|well-known)
B_IV
B_correct-OOV
B_ill-OOV
p(IV|IV)
p(B|B)
IV
B
B
IV
B
p(IV|Messi) p(correct-OOV|IV)
p(I|B)
p(B|Messi)
correct-OOV
I
I
I
p(O|B)
p(ill-OOV|IV)
p(I|Messi)
Ill-OOV
O
O
O
p(Ill-OOV|Messi)
p(O|Messi)
well-known
is
is
Messi
well-known
Messi
correct-OOV
p(correct-OOV|Messi)
Ill-OOV
IV
correct-OOV
Ill-OOV
</figure>
<bodyText confidence="0.999632428571428">
The data with the NER labels are from (Ritter
et al., 2011) who annotated 2,396 tweets (34K to-
kens) with named entities, but there is no infor-
mation on the tweets’ ill-OOV words. In order to
evaluate the impact of ill-OOV on NER, we ask six
annotators to annotate the ill-OOV words and the
corresponding standard words in this data. There
are only 1,012 sentences with ill-OOV words. We
use all the sentences (2,396) for the NER exper-
iments. This data set,6 to our knowledge, is the
first one having both ill-OOV and NER annotation
in social media domain. For joint decoding, the
parameters α and β are empirically set as 0.95 and
0.5.
</bodyText>
<subsectionHeader confidence="0.8749705">
4.2 Experiment Results
4.2.1 NSW Detection Results
</subsectionHeader>
<bodyText confidence="0.999944384615385">
For NSW detection, we compared our two pro-
posed systems on the two test sets described
above, and also conducted different experiments to
investigate the effectiveness of different features.
We use the categorization of words by the dictio-
nary as the baseline for this task. Table 3 shows the
results for three NSW detection systems. We use
Recall, Precision and F value for the ill-OOV class
as the evaluation metrics. The Dictionary base-
line can only recognize the token as IV and OOV,
and thus label all the OOV words as ill-OOV. Both
the two-step and the 3-way classification meth-
ods in Table 3 leverage all the features described
</bodyText>
<footnote confidence="0.925997">
6http://www.hlt.utdallas.edu/∼chenli/normalization ner
</footnote>
<bodyText confidence="0.999975193548387">
in Table 1. First note because of the property of
the two-step method (it further divides the OOV
words from the dictionary-based method into ill-
OOV and correct-OOV), the upper bound of its
recall is the recall of the dictionary based method.
We can see that in Test set 1, both the two-step and
the 3-way classification methods have a significant
improvement compared to the Dictionary method.
However, in Test set 2, the two-step method per-
forms much worse than that of the 3-way classifi-
cation method, although it outperforms the dictio-
nary method. This can be attributed to the charac-
teristics of that data set and also the system’s upper
bounded recall. We will provide a more detailed
analysis in the following feature analysis part.
Table 4 and 5 show the performance of the two
systems on the two test sets with different features.
Note that the dictionary feature is not applicable to
the two-step method, and the results for the two-
step method using dictionary feature (feature 1,
first line in the tables) are the same as the dictio-
nary baseline in Table 3. From these two tables,
we can see that: (1) For both systems, normaliza-
tion features (11-16) and lexical features (2-10)
both perform better than the dictionary feature. (2)
In general, the combination of any two kinds of
features has better performance than any one fea-
ture type. Using all the features (results shown in
Table 3) yields the best performance, which signif-
icantly improves the performance compared with
the baseline. (3) There are some differences across
</bodyText>
<page confidence="0.996301">
934
</page>
<bodyText confidence="0.99947908">
the two data sets in terms of the feature effective-
ness on the two methods. On Test set 2, when
lexical features are combined with other features
(forth and fifth line of Table 5), the 3-way classifi-
cation method significantly outperforms the two-
step method. It is because this data set has a
large number of ill-OOV words that are dictionary
words. For example, token ‘its’ appears 31 times
as ill-OOV, ‘ya’ 13 times, and ‘bro’ 10 times. Such
ill-OOV words occur more than two hundred times
in total. Since these tokens are included in the dic-
tionary, they are already classified as IV by the
dictionary, and their label will not change in the
second step. This is also the reason why in Table
3, the performance of 3-way classification is sig-
nificantly better than that of the two-step method
using all the features. However, we also find that
when we only use lexical features (2∼10), the two
methods have similar performance on Test set 2,
but the two-step method has much better perfor-
mance than the 3-way classifier method on Test
set 1. We believe this shows that lexical features
themselves are not reliable for the NSW detection
task, and other information such as normalization
features may be more stable.
</bodyText>
<table confidence="0.999635166666667">
Test Set 1 Test Set 2
System
R P F R P F
Dictionary 88.73 72.35 79.71 67.87 69.59 68.72
Two-step 81.66 88.74 85.05 57.60 90.04 70.26
3-way 87.63 83.49 85.51 73.53 90.42 81.10
</table>
<tableCaption confidence="0.975367">
Table 3: NSW detection results.
</tableCaption>
<table confidence="0.99996625">
Features Two-Step 3-way Classification
R P F R P F
1 88.73 72.35 79.71 87.13 70.04 77.66
2∼10 87.21 77.44 82.04 82.59 67.49 74.28
11∼16 86.45 78.77 82.43 91.75 74.97 82.51
1∼10 76.78 92.87 84.07 77.12 93.09 84.36
2∼16 81.16 89.02 84.90 87.13 86.54 85.30
1,11∼16 78.30 91.00 84.17 78.55 93.77 85.48
</table>
<tableCaption confidence="0.999998666666667">
Table 4: Feature impact on NSW detection on Test
Set 1. The feature number corresponds to that in
Table 1.
</tableCaption>
<subsectionHeader confidence="0.503461">
4.2.2 NER Results
</subsectionHeader>
<bodyText confidence="0.9989432">
For the NER task, in order to make a fair compari-
son with (Ritter et al., 2011), we conducted 4-fold
cross validation experiments as they did. First we
present the result on the NSW detection task on
this date set when using our proposed joint de-
</bodyText>
<table confidence="0.99989975">
Features Two-Step 3-way Classification
R P F R P F
1 67.86 69.59 68.72 66.45 64.27 65.34
2∼10 64.33 79.52 71.12 69.56 76.26 72.76
11∼16 53.78 91.34 67.70 54.35 91.42 68.17
1∼10 63.12 81.53 71.16 78.41 81.65 80.00
2∼16 56.40 89.02 69.06 72.32 90.28 80.31
1,11∼16 56.40 92.35 70.03 56.68 92.81 70.38
</table>
<tableCaption confidence="0.997769">
Table 5: Feature impact on NSW detection on Test
Set 2.
</tableCaption>
<bodyText confidence="0.937504742857143">
coding method integrating NER and NSW. This
is done using the 1,012 sentences that contain ill-
OOV words. Table 6 shows such results on the
NER data described in Section 4.1. The 3-way
classification method for NSW detection is used
as a baseline here. It is the same model as used
in the previous section, and applied to the entire
NER data. For each cross validation experiment
of the joint decoding method, the NSW detection
model is kept the same (from 3-way classifica-
tion method), but NER model is tested on 1/4 of
the data and trained from the remaining 3/4 of the
data. From the Table 6, we can see that joint de-
coding yields some marginal improvement for the
NSW detection task.
System R P F
3-way classification 58.65 72.83 64.97
Joint decoding w all features 59.53 72.96 65.56
Table 6: NSW detection results on the data from
(Ritter et al., 2011) with our new NSW annotation.
In the following, we will focus on the impact
of NSW detection on NER. Table 7 shows the
NER performance from different systems on the
data with NER and NSW labels. From this table,
we can see that when using our pipeline system,
adding NSW label features has a significant im-
provement compared to the basic features. The F
value of 67.4% when using all the features is even
higher than the state-of-the-art performance from
(Ritter et al., 2011). Please note that Ritter et al.
(2011) used much more information than us for
this task, such as dictionaries including a set of
type lists gathered from Freebase, brown clusters,
and outputs of their specifically designed chunk
and capitalization labels components7. Then they
</bodyText>
<footnote confidence="0.998894666666667">
7The chunk and capitalization components are specially
created by them for social media domain data. Then they
created a data set to train these models.
</footnote>
<page confidence="0.996776">
935
</page>
<bodyText confidence="0.999068">
improved their baseline performance from 65% to
the reported best one at 67%. However, we only
added our predicted NSW labels and related fea-
tures, and we already achieved similar or slightly
better results. Using joint decoding can further
boost the performance to 69%.
</bodyText>
<table confidence="0.9989372">
System R P F
Pipeline w basic features 55.85 74.33 63.76
Pipeline w all features 60.00 77.09 67.40
Joint decoding w all features 73.56 65.02 69.00
(Ritter et al., 2011) 73.00 61.00 67.00
</table>
<tableCaption confidence="0.98119">
Table 7: NER results from different systems on
</tableCaption>
<bodyText confidence="0.9608425">
data from (Ritter et al., 2011).
Table 8 shows the impact of different features.
This analysis is based on the pipeline system.
First, we can see that adding feature 4 and 5 (Uni-,
Bi- and Tri-gram of the dictionary and predicted
NSW labels) yields the most improvement com-
pared with other features, and between these two
kinds of features, using predicted NSW labels is
better than the dictionary labels. It also shows the
effectiveness of our NSW detection system. Sec-
ond, comparing adding feature 6 and 7, it shows
that combination of word/POS and its dictionary
or NSW label is not as good as only considering
the label’s n-gram. We also explored various other
n-gram features, but did not find any that outper-
formed feature 4 or 5. Another finding is that the
POS related features are not as good as that of
words.
</bodyText>
<table confidence="0.999363285714286">
Features R P F
Basic 55.85 74.33 63.76
Basic + 4 57.71 75.04 65.23
Basic + 5 57.47 75.87 65.37
Basic + 6 56.53 74.20 64.12
Basic + 7 56.13 74.66 64.06
Basic + 8 57.14 74.55 64.66
</table>
<tableCaption confidence="0.963076666666667">
Table 8: Pipeline NER performance using differ-
ent features. The feature number corresponds to
that in Table 2.
</tableCaption>
<subsubsectionHeader confidence="0.59691">
4.2.3 Error Analysis
</subsubsectionHeader>
<bodyText confidence="0.999959322580645">
A detailed error analysis further shows what im-
provement our proposed method makes and what
errors it is still making. For example, for the
tweet ‘Watching the VMA pre-show again ...’, the
token VMA is annotated as B-tvshow in NER la-
bels. Without using predicted NSW labels, the
baseline system labels this token as O (outside of
named entity). However, after using the NSW pre-
dicted label correct-OOV and related features, the
pipeline NER system predicts its label as B. We
noticed that joint decoding can solve some com-
plicated cases that are hard for the pipeline sys-
tem, especially for some OOVs, or when there are
consecutive named entity tokens. For example, in
a tweet, ‘Let’s hope the Serie A continues to be
on the tv schedule next week’, Seria A is a proper
noun (meaning Italian soccer league). The anno-
tation for Seria and A is correct-OOV/B and IV/I.
We find the joint decoding system successfully la-
bels A as I after Seria is labeled as B. However, the
pipeline system labels A as O even it correctly la-
bels Seria. Take another example, in a tweet ‘I was
gonna buy a Zune HD ...’, Zune HD is consecutive
named entities. The pipeline system recognized
Zune as correct-OOV and HD as ill-OOV, then
labeled both them as O. But the joint decoding
system identified HD as correct-OOV and labeled
‘Zune HD’ as B and I. These changes may have
happened because of adjusting the transition prob-
ability and observation probability during Viterbi
decoding.
</bodyText>
<sectionHeader confidence="0.997485" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999913285714286">
In this paper, we proposed an approach to detect
NSW. This makes the lexical normalization task
as a complete applicable process. The proposed
NSW detection system leveraged normalization
information of an OOV and other useful lexical
information. Our experimental results show both
kinds of information can help improve the predic-
tion performance on two different data sets. Fur-
thermore, we applied the predicted labels as ad-
ditional information for the NER task. In this
task, we proposed a novel joint decoding approach
to label every token’s NSW and NER label in a
tweet at the same time. Again, experimental re-
sults demonstrate that the NSW label has a sig-
nificant impact on NER performance and our pro-
posed method improves performance on both tasks
and outperforms the best previous results in NER.
In future work, we propose to pursue a number
of directions. First, we plan to consider how to
conduct NSW detection and normalization at the
same time. Second, we like to try a joint method to
</bodyText>
<page confidence="0.99503">
936
</page>
<bodyText confidence="0.9999244">
simultaneously train the NSW detection and NER
models, rather than just combining models in de-
coding. Third, we want to investigate the impact of
NSW and normalization on other NLP tasks such
as parsing in social media data.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999939375">
We thank the anonymous reviewers for their de-
tailed and insightful comments on earlier drafts
of this paper. The work is partially supported by
DARPA Contract No. FA8750-13-2-0041. Any
opinions, findings, and conclusions or recommen-
dations expressed are those of the authors and do
not necessarily reflect the views of the funding
agencies.
</bodyText>
<sectionHeader confidence="0.999676" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999762705882353">
Aiti Aw, Min Zhang, Juan Xiao, Jian Su, and Jian Su.
2006. A phrase-based statistical model for sms text
normalization. In Processing of COLING/ACL.
Grzegorz Chrupała. 2014. Normalizing tweets with
edit scripts and recurrent neural embeddings. In
Proceedings of ACL.
Paul Cook and Suzanne Stevenson. 2009. An unsu-
pervised model for text message normalization. In
Proceedings of NAACL.
Fred J Damerau. 1964. A technique for computer de-
tection and correction of spelling errors. Communi-
cations of the ACM, 7(3):171–176.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of ACL.
Bo Han and Timothy Baldwin. 2011. Lexical normali-
sation of short text messages: Makn sens a #twitter.
In Proceeding of ACL.
Hany Hassan and Arul Menezes. 2013. Social text
normalization using contextual graph random walks.
In Proceedings of ACL.
Nobuhiro Kaji and Masaru Kitsuregawa. 2014. Accu-
rate word segmentation and pos tagging for Japanese
microblogs: Corpus annotation and joint model-
ing with lexical normalization. In Proceedings of
EMNLP.
Dilek Kucuk and Ralf Steinberger. 2014. Experi-
ments to improve named entity recognition on turk-
ish tweets. In Proceedings of Workshop on Lan-
guage Analysis for Social Media (LASM) on EACL.
Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.
2004. Applying conditional random fields to
Japanese morphological analysis. In Proceedings of
EMNLP.
Vladimir I Levenshtein. 1966. Binary codes capable
of correcting deletions, insertions and reversals. In
Soviet physics doklady, volume 10, page 707.
Chen Li and Yang Liu. 2012a. Improving text nor-
malization using character-blocks based models and
system combination. In Proceedings of COLING
2012.
Chen Li and Yang Liu. 2012b. Normalization of text
messages using character- and phone-based machine
translation approaches. In Proceedings of 13th In-
terspeech.
Chen Li and Yang Liu. 2014. Improving text normal-
ization via unsupervised model and discriminative
reranking. In Proceedings of ACL.
Chen Li and Yang Liu. 2015. Joint POS tagging and
text normalization for informal text. In Proceedings
of IJCAI.
Fei Liu, Fuliang Weng, and Xiao Jiang. 2012a. A
broad-coverage normalization system for social me-
dia language. In Proceedings of ACL.
Xiaohua Liu, Ming Zhou, Xiangyang Zhou,
Zhongyang Fu, and Furu Wei. 2012b. Joint
inference of named entity recognition and normal-
ization for tweets. In Proceedings of ACL.
Graham Neubig, Yosuke Nakata, and Shinsuke Mori.
2011. Pointwise prediction for robust, adaptable
Japanese morphological analysis. In Proceedings of
ACL.
Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A.
Smith. 2013. Improved part-of-speech tagging for
online conversational text with word clusters. In
Proceedings of NAACL.
Deana Pennell and Yang Liu. 2010. Normalization of
text messages for text-to-speech. In ICASSP.
Deana Pennell and Yang Liu. 2011. A character-level
machine translation approach for normalization of
sms abbreviations. In Proceedings of IJCNLP.
Sasa Petrovic, Miles Osborne, and Victor Lavrenko.
2010. The Edinburgh twitter corpus. In Proceed-
ings of NAACL.
Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas
Bangalore, and Ron Shacham. 2014. A framework
for translating SMS messages. In Proceedings of
COLING.
Alan Ritter, Sam Clark, and Oren Etzioni. 2011.
Named entity recognition in tweets: an experimental
study. In Proceedings of EMNLP.
</reference>
<page confidence="0.975598">
937
</page>
<reference confidence="0.998431">
Cagil Sonmez and Arzucan Ozgur. 2014. A graph-
based approach for contextual text normalization. In
Proceedings of EMNLP.
Andreas Stolcke. 2002. SRILM-an extensible lan-
guage modeling toolkit. In Proceedings Interna-
tional Conference on Spoken Language Processing.
Aobo Wang and Min-Yen Kan. 2013. Mining informal
language from Chinese microtext: Joint word recog-
nition and segmentation. In Proceedings of ACL.
Yi Yang and Jacob Eisenstein. 2013. A log-linear
model for unsupervised text normalization. In Pro-
ceedings of EMNLP.
</reference>
<page confidence="0.997447">
938
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929405">
<title confidence="0.9954335">Improving Named Entity Recognition in Tweets via Non-Standard Words</title>
<author confidence="0.986054">Li</author>
<affiliation confidence="0.996395">Computer Science Department, The University of Texas at</affiliation>
<address confidence="0.988375">Richardson, Texas 75080,</address>
<abstract confidence="0.998701551724138">Most previous work of text normalization on informal text made a strong assumption that the system has already known which tokens are non-standard words (NSW) and thus need normalization. However, this is not realistic. In this paper, we propose a method for NSW detection. In addition to the information based on the dictionary, e.g., whether a word is out-ofvocabulary (OOV), we leverage novel information derived from the normalization results for OOV words to help make decisions. Second, this paper investigates two methods using NSW detection results for named entity recognition (NER) in social media data. One adopts a pipeline strategy, and the other uses a joint decoding fashion. We also create a new data set with newly added normalization annotation beyond the existing named entity labels. This is the first data set with such annotation and we release it for research purpose. Our experiment results demonstrate the effectiveness of our NSW detection method and the benefit of NSW detection for NER. Our proposed methods perform better than the state-of-the-art NER system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aiti Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for sms text normalization.</title>
<date>2006</date>
<booktitle>In Processing of COLING/ACL.</booktitle>
<contexts>
<context position="1991" citStr="Aw et al., 2006" startWordPosition="315" endWordPosition="318">ial media websites such as Facebook and Twitter have become one of the most popular communication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which toke</context>
<context position="5695" citStr="Aw et al., 2006" startWordPosition="930" endWordPosition="933">NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in w</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, Su, 2006</marker>
<rawString>Aiti Aw, Min Zhang, Juan Xiao, Jian Su, and Jian Su. 2006. A phrase-based statistical model for sms text normalization. In Processing of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
</authors>
<title>Normalizing tweets with edit scripts and recurrent neural embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6458" citStr="Chrupała (2014)" startWordPosition="1047" endWordPosition="1048"> unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standard and non-standard words is characterized by a log-linear model, permitting the use of arbitrary features. Chrupała (2014) proposed a text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled data via recurrent network derived character-level neural text embeddings. These studies only focused on how to normalize a given ill-OOV word and did not address the problem of detecting an ill-OOV word. Han and Baldwin (2011) is the only previous study that conducted the detection work. For any OOV word, they replaced it with its possible correct candidate, then if the possible candidate together with OOV’s original context adheres to the knowledge they</context>
</contexts>
<marker>Chrupała, 2014</marker>
<rawString>Grzegorz Chrupała. 2014. Normalizing tweets with edit scripts and recurrent neural embeddings. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>An unsupervised model for text message normalization.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="2017" citStr="Cook and Stevenson, 2009" startWordPosition="319" endWordPosition="322">s such as Facebook and Twitter have become one of the most popular communication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need norma</context>
<context position="5604" citStr="Cook and Stevenson, 2009" startWordPosition="913" endWordPosition="916"> is the first time to our knowledge that an effective and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct</context>
</contexts>
<marker>Cook, Stevenson, 2009</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2009. An unsupervised model for text message normalization. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred J Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>Communications of the ACM,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="5530" citStr="Damerau, 1964" startWordPosition="904" endWordPosition="905">ion information, in addition to the existing NER labels. (3) It is the first time to our knowledge that an effective and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlab</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>Fred J Damerau. 1964. A technique for computer detection and correction of spelling errors. Communications of the ACM, 7(3):171–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a #twitter.</title>
<date>2011</date>
<booktitle>In Proceeding of ACL.</booktitle>
<contexts>
<context position="2724" citStr="Han and Baldwin (2011)" startWordPosition="433" endWordPosition="436">. Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then different methods are applied only to these tokens. To our knowledge, Han and Baldwin (2011) is the only previous work which made a pilot research on NSW detection. One straight forward method to do this is to use a dictionary to classify a token into in-vocabulary (IV) words and out-of-vocabulary (OOV) words, and just treat all the OOV words as NSW. The shortcoming of this method is obvious. For example, tokens like ‘iPhone’, ‘PES’(a game name) and ‘Xbox’ will be considered as NSW, however, these words do not need normalization. Han and Baldwin (2011) called these OOV words correct-OOV, and named those OOV words that do need normalization as ill-OOV. We will follow their naming conv</context>
<context position="6826" citStr="Han and Baldwin (2011)" startWordPosition="1103" endWordPosition="1106"> words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standard and non-standard words is characterized by a log-linear model, permitting the use of arbitrary features. Chrupała (2014) proposed a text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled data via recurrent network derived character-level neural text embeddings. These studies only focused on how to normalize a given ill-OOV word and did not address the problem of detecting an ill-OOV word. Han and Baldwin (2011) is the only previous study that conducted the detection work. For any OOV word, they replaced it with its possible correct candidate, then if the possible candidate together with OOV’s original context adheres to the knowledge they learned from large formal corpora, the replacement could be considered as a better choice and that OOV token is classified as ill-OOV. In this paper, we propose a different method for NSW detection. Similar to (Han and Baldwin, 2011), we also use normalization information for OOV words, but we use a feature based learning approach. In order to improve robustness of</context>
<context position="20930" citStr="Han and Baldwin, 2011" startWordPosition="3470" endWordPosition="3473">4.1 Data Set and Experiment Setup The NSW detection model is trained using the data released by (Li and Liu, 2014). It has 2,577 Twitter messages (selected from the Edinburgh Twitter corpus (Petrovic et al., 2010)), in which there are 2,333 unique pairs of NSW and their standard words. This data is used for training the different normalization models. We labeled this data set using the given dictionary for NSW detection. 4,121 tokens are labeled as ill-OOV, 1,455 as correctOOV, and the rest 33,740 tokens are IV words. We have two test sets for evaluating the NSW detection system. One is from (Han and Baldwin, 2011), which includes 549 tweets. Each tweet contains at least one ill-OOV and the corresponding correct word. We call it Test set 1 in the following. The other is from (Li and Liu, 2015), who further processed the tweets data from (Owoputi et al., 2013). Briefly, Owoputi et al. (2013) released 2,347 tweets with their designed POS tags for social media text, and then Li and Liu (2015) further annotated this data with normalization information for each token. The released data by (Li and Liu, 2015) contains 798 tweets with ill-OOV. We use these 798 tweets as the second data set for NSW detection, an</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Proceeding of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hany Hassan</author>
<author>Arul Menezes</author>
</authors>
<title>Social text normalization using contextual graph random walks.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6001" citStr="Hassan and Menezes (2013)" startWordPosition="979" endWordPosition="982"> lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standard and non-standard words is characterized by a log-linear model, permitting the use of arbitrary features. Chrupała (2014) proposed a text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled da</context>
</contexts>
<marker>Hassan, Menezes, 2013</marker>
<rawString>Hany Hassan and Arul Menezes. 2013. Social text normalization using contextual graph random walks. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Accurate word segmentation and pos tagging for Japanese microblogs: Corpus annotation and joint modeling with lexical normalization.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="8203" citStr="Kaji and Kitsuregawa (2014)" startWordPosition="1332" endWordPosition="1336"> and capitalized information on tweets, (Ritter et al., 2011) proposed a system which reduced the POS tagging error by 41% compared with Stanford POS Tagger, and by 50% in NER compared with the baseline systems. Gimpel et al. (2011) created a specific set of POS tags for twitter data. With this tag set and word cluster information extracted from a huge Twitter corpus, their proposed system obtained significant improvement on POS tagging accuracy in Twitter data. At the same time, increasing research work has been done to integrate lexical normalization into the NLP tasks in social media data. Kaji and Kitsuregawa (2014) combined lexical normalization, word segmentation and POS tagging on Japanese microblog. They used rich character-level and word-level features from the state-of-the-art models of joint word segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2014</marker>
<rawString>Nobuhiro Kaji and Masaru Kitsuregawa. 2014. Accurate word segmentation and pos tagging for Japanese microblogs: Corpus annotation and joint modeling with lexical normalization. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Kucuk</author>
<author>Ralf Steinberger</author>
</authors>
<title>Experiments to improve named entity recognition on turkish tweets.</title>
<date>2014</date>
<booktitle>In Proceedings of Workshop on Language Analysis for Social Media (LASM) on EACL.</booktitle>
<contexts>
<context position="9355" citStr="Kucuk and Steinberger (2014)" startWordPosition="1516" endWordPosition="1520">word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normalization (NEN) for tweets. They proposed a novel graphical model to simultaneously conduct NER and NEN on multiple tweets. Although this work involved text normalization, it only focused on the NER task, and there was no reported result for normalization. On Turkish tweets, Kucuk and Steinberger (2014) adapted NER rules and resources to better fit Twitter language by relaxing its capitalization constraint, expanding its lexical resources based on diacritics, and using a normalization scheme on tweets. These showed positive effect on the overall NER performance. Rangarajan Sridhar et al. (2014) decoupled the SMS translation task into normalization followed by translation. They exploited bi-text resources, and presented a normalization approach using distributed representation of words learned through neural networks. In this study, we propose new methods to effectively integrate information </context>
</contexts>
<marker>Kucuk, Steinberger, 2014</marker>
<rawString>Dilek Kucuk and Ralf Steinberger. 2014. Experiments to improve named entity recognition on turkish tweets. In Proceedings of Workshop on Language Analysis for Social Media (LASM) on EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying conditional random fields to Japanese morphological analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="8454" citStr="Kudo et al., 2004" startWordPosition="1369" endWordPosition="1372">S tags for twitter data. With this tag set and word cluster information extracted from a huge Twitter corpus, their proposed system obtained significant improvement on POS tagging accuracy in Twitter data. At the same time, increasing research work has been done to integrate lexical normalization into the NLP tasks in social media data. Kaji and Kitsuregawa (2014) combined lexical normalization, word segmentation and POS tagging on Japanese microblog. They used rich character-level and word-level features from the state-of-the-art models of joint word segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normali</context>
</contexts>
<marker>Kudo, Yamamoto, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto. 2004. Applying conditional random fields to Japanese morphological analysis. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1966</date>
<booktitle>In Soviet physics doklady,</booktitle>
<volume>10</volume>
<pages>707</pages>
<contexts>
<context position="5550" citStr="Levenshtein, 1966" startWordPosition="906" endWordPosition="907">, in addition to the existing NER labels. (3) It is the first time to our knowledge that an effective and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to </context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. In Soviet physics doklady, volume 10, page 707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Improving text normalization using character-blocks based models and system combination.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="5736" citStr="Li and Liu, 2012" startWordPosition="938" endWordPosition="941">ove the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standar</context>
</contexts>
<marker>Li, Liu, 2012</marker>
<rawString>Chen Li and Yang Liu. 2012a. Improving text normalization using character-blocks based models and system combination. In Proceedings of COLING 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Normalization of text messages using character- and phone-based machine translation approaches.</title>
<date>2012</date>
<booktitle>In Proceedings of 13th Interspeech.</booktitle>
<contexts>
<context position="5736" citStr="Li and Liu, 2012" startWordPosition="938" endWordPosition="941">ove the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standar</context>
</contexts>
<marker>Li, Liu, 2012</marker>
<rawString>Chen Li and Yang Liu. 2012b. Normalization of text messages using character- and phone-based machine translation approaches. In Proceedings of 13th Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Improving text normalization via unsupervised model and discriminative reranking.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2077" citStr="Li and Liu, 2014" startWordPosition="331" endWordPosition="334">ommunication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then different methods are applied only to these t</context>
<context position="15133" citStr="Li and Liu, 2014" startWordPosition="2468" endWordPosition="2471"> normalization system’s first candidate w and this token t, calculated by longest common string(w,t) length(t) 16. the similarity value between each individual normalization system’s first candidate w and this token t, calculated by longest common sequence(w,t) length(t) Table 1: Features used in NSW detection system. to leverage the normalization result of an OOV token to help its classification. Before we describe the reason why normalization information could benefit this task, we first introduce the normalization system we used. We apply a state-of-theart normalization system proposed by (Li and Liu, 2014). Briefly, in this normalization system there are three supervised and two unsupervised subsystems for each OOV token, resulting in six candidate lists (one system provides two lists). Then a maximum entropy reranking model is adopted to combine and rerank these candidate lists, using a rich set of features. Please refer to (Li and Liu, 2014) for more details. By analyzing each individual system, we find that for ill-OOV words most normalization systems can generate many candidates, which may contain a correct candidate; for correct-OOV words, many normalization systems have few candidates or </context>
<context position="20422" citStr="Li and Liu, 2014" startWordPosition="3381" endWordPosition="3384"> are worth pointing out: (1) the label is a combination of NSW and NER labels, and thus there are nine in total; (2) the label transition probability is a linear sum of the previous two transition probabilities: p(yi oi|yj oj) = p(yi|yj) + Q * p(oi|oj), where yi and yj are BIO tags and oi and oj are NSW tags; (3) similarly, p(yi oi|ti) equals to p(yi|ti) + α * p(oi|ti). Please note all these probabilities are log probabilities and they are trained separately from each system. 4 Data and Experiment 4.1 Data Set and Experiment Setup The NSW detection model is trained using the data released by (Li and Liu, 2014). It has 2,577 Twitter messages (selected from the Edinburgh Twitter corpus (Petrovic et al., 2010)), in which there are 2,333 unique pairs of NSW and their standard words. This data is used for training the different normalization models. We labeled this data set using the given dictionary for NSW detection. 4,121 tokens are labeled as ill-OOV, 1,455 as correctOOV, and the rest 33,740 tokens are IV words. We have two test sets for evaluating the NSW detection system. One is from (Han and Baldwin, 2011), which includes 549 tweets. Each tweet contains at least one ill-OOV and the corresponding </context>
</contexts>
<marker>Li, Liu, 2014</marker>
<rawString>Chen Li and Yang Liu. 2014. Improving text normalization via unsupervised model and discriminative reranking. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Joint POS tagging and text normalization for informal text.</title>
<date>2015</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="8560" citStr="Li and Liu (2015)" startWordPosition="1389" endWordPosition="1392">us, their proposed system obtained significant improvement on POS tagging accuracy in Twitter data. At the same time, increasing research work has been done to integrate lexical normalization into the NLP tasks in social media data. Kaji and Kitsuregawa (2014) combined lexical normalization, word segmentation and POS tagging on Japanese microblog. They used rich character-level and word-level features from the state-of-the-art models of joint word segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normalization (NEN) for tweets. They proposed a novel graphical model to simultaneously conduct NER and NEN on mu</context>
<context position="21112" citStr="Li and Liu, 2015" startWordPosition="3505" endWordPosition="3508">us (Petrovic et al., 2010)), in which there are 2,333 unique pairs of NSW and their standard words. This data is used for training the different normalization models. We labeled this data set using the given dictionary for NSW detection. 4,121 tokens are labeled as ill-OOV, 1,455 as correctOOV, and the rest 33,740 tokens are IV words. We have two test sets for evaluating the NSW detection system. One is from (Han and Baldwin, 2011), which includes 549 tweets. Each tweet contains at least one ill-OOV and the corresponding correct word. We call it Test set 1 in the following. The other is from (Li and Liu, 2015), who further processed the tweets data from (Owoputi et al., 2013). Briefly, Owoputi et al. (2013) released 2,347 tweets with their designed POS tags for social media text, and then Li and Liu (2015) further annotated this data with normalization information for each token. The released data by (Li and Liu, 2015) contains 798 tweets with ill-OOV. We use these 798 tweets as the second data set for NSW detection, and call it Test set 2 in the following. In addition, we use all of these 2,347 tweets to train a POS model which then is used to predict tokens’ POS tags for NER (see Section 3.2 abou</context>
</contexts>
<marker>Li, Liu, 2015</marker>
<rawString>Chen Li and Yang Liu. 2015. Joint POS tagging and text normalization for informal text. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Xiao Jiang</author>
</authors>
<title>A broad-coverage normalization system for social media language.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2058" citStr="Liu et al., 2012" startWordPosition="327" endWordPosition="330"> the most popular communication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then different methods are appl</context>
<context position="5645" citStr="Liu et al., 2012" startWordPosition="921" endWordPosition="924">tive and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presen</context>
<context position="9008" citStr="Liu et al. (2012" startWordPosition="1462" endWordPosition="1465">rd segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normalization (NEN) for tweets. They proposed a novel graphical model to simultaneously conduct NER and NEN on multiple tweets. Although this work involved text normalization, it only focused on the NER task, and there was no reported result for normalization. On Turkish tweets, Kucuk and Steinberger (2014) adapted NER rules and resources to better fit Twitter language by relaxing its capitalization constraint, expanding its lexical resources based on diacritics, and using a normalization scheme on tweets. These showed positive effect on the overall NER p</context>
</contexts>
<marker>Liu, Weng, Jiang, 2012</marker>
<rawString>Fei Liu, Fuliang Weng, and Xiao Jiang. 2012a. A broad-coverage normalization system for social media language. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Ming Zhou</author>
<author>Xiangyang Zhou</author>
<author>Zhongyang Fu</author>
<author>Furu Wei</author>
</authors>
<title>Joint inference of named entity recognition and normalization for tweets.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2058" citStr="Liu et al., 2012" startWordPosition="327" endWordPosition="330"> the most popular communication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then different methods are appl</context>
<context position="5645" citStr="Liu et al., 2012" startWordPosition="921" endWordPosition="924">tive and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presen</context>
<context position="9008" citStr="Liu et al. (2012" startWordPosition="1462" endWordPosition="1465">rd segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normalization (NEN) for tweets. They proposed a novel graphical model to simultaneously conduct NER and NEN on multiple tweets. Although this work involved text normalization, it only focused on the NER task, and there was no reported result for normalization. On Turkish tweets, Kucuk and Steinberger (2014) adapted NER rules and resources to better fit Twitter language by relaxing its capitalization constraint, expanding its lexical resources based on diacritics, and using a normalization scheme on tweets. These showed positive effect on the overall NER p</context>
</contexts>
<marker>Liu, Zhou, Zhou, Fu, Wei, 2012</marker>
<rawString>Xiaohua Liu, Ming Zhou, Xiangyang Zhou, Zhongyang Fu, and Furu Wei. 2012b. Joint inference of named entity recognition and normalization for tweets. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Yosuke Nakata</author>
<author>Shinsuke Mori</author>
</authors>
<title>Pointwise prediction for robust, adaptable Japanese morphological analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8476" citStr="Neubig et al., 2011" startWordPosition="1373" endWordPosition="1376">data. With this tag set and word cluster information extracted from a huge Twitter corpus, their proposed system obtained significant improvement on POS tagging accuracy in Twitter data. At the same time, increasing research work has been done to integrate lexical normalization into the NLP tasks in social media data. Kaji and Kitsuregawa (2014) combined lexical normalization, word segmentation and POS tagging on Japanese microblog. They used rich character-level and word-level features from the state-of-the-art models of joint word segmentation and POS tagging in Japanese (Kudo et al., 2004; Neubig et al., 2011). Their model can also be trained on a partially annotated corpus. Li and Liu (2015) conducted a similar research on joint POS tagging and text normalization for English. Wang and Kan 930 (2013) proposed a method of joint ill-OOV word recognition and word segmentation in Chinese Microblog. But with their method, ill-OOV words are merely recognized and not normalized. Therefore, they did not investigate how to exploit the information that may be derived from normalization to increase word segmentation accuracy. Liu et al. (2012b) studied the problem of named entity normalization (NEN) for tweet</context>
</contexts>
<marker>Neubig, Nakata, Mori, 2011</marker>
<rawString>Graham Neubig, Yosuke Nakata, and Shinsuke Mori. 2011. Pointwise prediction for robust, adaptable Japanese morphological analysis. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Brendan O’Connor</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<marker>Owoputi, O’Connor, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deana Pennell</author>
<author>Yang Liu</author>
</authors>
<title>Normalization of text messages for text-to-speech.</title>
<date>2010</date>
<booktitle>In ICASSP.</booktitle>
<contexts>
<context position="5627" citStr="Pennell and Liu, 2010" startWordPosition="917" endWordPosition="920">knowledge that an effective and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisens</context>
</contexts>
<marker>Pennell, Liu, 2010</marker>
<rawString>Deana Pennell and Yang Liu. 2010. Normalization of text messages for text-to-speech. In ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deana Pennell</author>
<author>Yang Liu</author>
</authors>
<title>A character-level machine translation approach for normalization of sms abbreviations.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP.</booktitle>
<contexts>
<context position="2040" citStr="Pennell and Liu, 2011" startWordPosition="323" endWordPosition="326">tter have become one of the most popular communication forms in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then differen</context>
<context position="5718" citStr="Pennell and Liu, 2011" startWordPosition="934" endWordPosition="937"> NER techniques to improve the performance of these two tasks at the same time on social media data. (4) We demonstrate the effectiveness of our proposed method. Our proposed NER system outperforms the state-of-the-art system. 2 Related Work There has been a surge of interest in lexical normalization with the advent of social media data. Lots of approaches have been developed for this task, from using edit distance (Damerau, 1964; Levenshtein, 1966), to the noisy channel model (Cook and Stevenson, 2009; Pennell and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship b</context>
</contexts>
<marker>Pennell, Liu, 2011</marker>
<rawString>Deana Pennell and Yang Liu. 2011. A character-level machine translation approach for normalization of sms abbreviations. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasa Petrovic</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>The Edinburgh twitter corpus.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="20521" citStr="Petrovic et al., 2010" startWordPosition="3398" endWordPosition="3401">are nine in total; (2) the label transition probability is a linear sum of the previous two transition probabilities: p(yi oi|yj oj) = p(yi|yj) + Q * p(oi|oj), where yi and yj are BIO tags and oi and oj are NSW tags; (3) similarly, p(yi oi|ti) equals to p(yi|ti) + α * p(oi|ti). Please note all these probabilities are log probabilities and they are trained separately from each system. 4 Data and Experiment 4.1 Data Set and Experiment Setup The NSW detection model is trained using the data released by (Li and Liu, 2014). It has 2,577 Twitter messages (selected from the Edinburgh Twitter corpus (Petrovic et al., 2010)), in which there are 2,333 unique pairs of NSW and their standard words. This data is used for training the different normalization models. We labeled this data set using the given dictionary for NSW detection. 4,121 tokens are labeled as ill-OOV, 1,455 as correctOOV, and the rest 33,740 tokens are IV words. We have two test sets for evaluating the NSW detection system. One is from (Han and Baldwin, 2011), which includes 549 tweets. Each tweet contains at least one ill-OOV and the corresponding correct word. We call it Test set 1 in the following. The other is from (Li and Liu, 2015), who fur</context>
</contexts>
<marker>Petrovic, Osborne, Lavrenko, 2010</marker>
<rawString>Sasa Petrovic, Miles Osborne, and Victor Lavrenko. 2010. The Edinburgh twitter corpus. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Kumar Rangarajan Sridhar</author>
<author>John Chen</author>
<author>Srinivas Bangalore</author>
<author>Ron Shacham</author>
</authors>
<title>A framework for translating SMS messages.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="9652" citStr="Sridhar et al. (2014)" startWordPosition="1561" endWordPosition="1564">of named entity normalization (NEN) for tweets. They proposed a novel graphical model to simultaneously conduct NER and NEN on multiple tweets. Although this work involved text normalization, it only focused on the NER task, and there was no reported result for normalization. On Turkish tweets, Kucuk and Steinberger (2014) adapted NER rules and resources to better fit Twitter language by relaxing its capitalization constraint, expanding its lexical resources based on diacritics, and using a normalization scheme on tweets. These showed positive effect on the overall NER performance. Rangarajan Sridhar et al. (2014) decoupled the SMS translation task into normalization followed by translation. They exploited bi-text resources, and presented a normalization approach using distributed representation of words learned through neural networks. In this study, we propose new methods to effectively integrate information of OOV words and their normalization for the NER task. In particular, by adopting joint decoding for both NSW detection and NER, we are able to outperform stateof-the-art results for both tasks. This is the first study that systematically evaluates the effect of OOV words and normalization on NER</context>
</contexts>
<marker>Sridhar, Chen, Bangalore, Shacham, 2014</marker>
<rawString>Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas Bangalore, and Ron Shacham. 2014. A framework for translating SMS messages. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: an experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7637" citStr="Ritter et al., 2011" startWordPosition="1237" endWordPosition="1240">nal context adheres to the knowledge they learned from large formal corpora, the replacement could be considered as a better choice and that OOV token is classified as ill-OOV. In this paper, we propose a different method for NSW detection. Similar to (Han and Baldwin, 2011), we also use normalization information for OOV words, but we use a feature based learning approach. In order to improve robustness of NLP modules in social media domain, some works chose to design specific linguistic information. For example, by designing or annotating POS, chunking and capitalized information on tweets, (Ritter et al., 2011) proposed a system which reduced the POS tagging error by 41% compared with Stanford POS Tagger, and by 50% in NER compared with the baseline systems. Gimpel et al. (2011) created a specific set of POS tags for twitter data. With this tag set and word cluster information extracted from a huge Twitter corpus, their proposed system obtained significant improvement on POS tagging accuracy in Twitter data. At the same time, increasing research work has been done to integrate lexical normalization into the NLP tasks in social media data. Kaji and Kitsuregawa (2014) combined lexical normalization, w</context>
<context position="22721" citStr="Ritter et al., 2011" startWordPosition="3763" endWordPosition="3766">essi is (C) (A) (B) p(B|B)+ β * p(IVIIV) p(B|B)+ β * p(ill-OOVIIV) B_IV p(B|Messi)+ α* p(IV|Messi) p(B|is)+ α* p(correct-OOV|is) B_ill-OOV I_IV p(I|B)+ β * p(IVIIV) I_IV B_correct-OOV B_ill-OOV I_IV B_IV B_correct-OOV p(B|well-known)+ α* p(ill-OOV|well-known) B_IV B_correct-OOV B_ill-OOV p(IV|IV) p(B|B) IV B B IV B p(IV|Messi) p(correct-OOV|IV) p(I|B) p(B|Messi) correct-OOV I I I p(O|B) p(ill-OOV|IV) p(I|Messi) Ill-OOV O O O p(Ill-OOV|Messi) p(O|Messi) well-known is is Messi well-known Messi correct-OOV p(correct-OOV|Messi) Ill-OOV IV correct-OOV Ill-OOV The data with the NER labels are from (Ritter et al., 2011) who annotated 2,396 tweets (34K tokens) with named entities, but there is no information on the tweets’ ill-OOV words. In order to evaluate the impact of ill-OOV on NER, we ask six annotators to annotate the ill-OOV words and the corresponding standard words in this data. There are only 1,012 sentences with ill-OOV words. We use all the sentences (2,396) for the NER experiments. This data set,6 to our knowledge, is the first one having both ill-OOV and NER annotation in social media domain. For joint decoding, the parameters α and β are empirically set as 0.95 and 0.5. 4.2 Experiment Results </context>
<context position="27509" citStr="Ritter et al., 2011" startWordPosition="4589" endWordPosition="4592">wo-step 81.66 88.74 85.05 57.60 90.04 70.26 3-way 87.63 83.49 85.51 73.53 90.42 81.10 Table 3: NSW detection results. Features Two-Step 3-way Classification R P F R P F 1 88.73 72.35 79.71 87.13 70.04 77.66 2∼10 87.21 77.44 82.04 82.59 67.49 74.28 11∼16 86.45 78.77 82.43 91.75 74.97 82.51 1∼10 76.78 92.87 84.07 77.12 93.09 84.36 2∼16 81.16 89.02 84.90 87.13 86.54 85.30 1,11∼16 78.30 91.00 84.17 78.55 93.77 85.48 Table 4: Feature impact on NSW detection on Test Set 1. The feature number corresponds to that in Table 1. 4.2.2 NER Results For the NER task, in order to make a fair comparison with (Ritter et al., 2011), we conducted 4-fold cross validation experiments as they did. First we present the result on the NSW detection task on this date set when using our proposed joint deFeatures Two-Step 3-way Classification R P F R P F 1 67.86 69.59 68.72 66.45 64.27 65.34 2∼10 64.33 79.52 71.12 69.56 76.26 72.76 11∼16 53.78 91.34 67.70 54.35 91.42 68.17 1∼10 63.12 81.53 71.16 78.41 81.65 80.00 2∼16 56.40 89.02 69.06 72.32 90.28 80.31 1,11∼16 56.40 92.35 70.03 56.68 92.81 70.38 Table 5: Feature impact on NSW detection on Test Set 2. coding method integrating NER and NSW. This is done using the 1,012 sentences t</context>
<context position="28886" citStr="Ritter et al., 2011" startWordPosition="4835" endWordPosition="4838"> baseline here. It is the same model as used in the previous section, and applied to the entire NER data. For each cross validation experiment of the joint decoding method, the NSW detection model is kept the same (from 3-way classification method), but NER model is tested on 1/4 of the data and trained from the remaining 3/4 of the data. From the Table 6, we can see that joint decoding yields some marginal improvement for the NSW detection task. System R P F 3-way classification 58.65 72.83 64.97 Joint decoding w all features 59.53 72.96 65.56 Table 6: NSW detection results on the data from (Ritter et al., 2011) with our new NSW annotation. In the following, we will focus on the impact of NSW detection on NER. Table 7 shows the NER performance from different systems on the data with NER and NSW labels. From this table, we can see that when using our pipeline system, adding NSW label features has a significant improvement compared to the basic features. The F value of 67.4% when using all the features is even higher than the state-of-the-art performance from (Ritter et al., 2011). Please note that Ritter et al. (2011) used much more information than us for this task, such as dictionaries including a s</context>
<context position="30237" citStr="Ritter et al., 2011" startWordPosition="5062" endWordPosition="5065"> components7. Then they 7The chunk and capitalization components are specially created by them for social media domain data. Then they created a data set to train these models. 935 improved their baseline performance from 65% to the reported best one at 67%. However, we only added our predicted NSW labels and related features, and we already achieved similar or slightly better results. Using joint decoding can further boost the performance to 69%. System R P F Pipeline w basic features 55.85 74.33 63.76 Pipeline w all features 60.00 77.09 67.40 Joint decoding w all features 73.56 65.02 69.00 (Ritter et al., 2011) 73.00 61.00 67.00 Table 7: NER results from different systems on data from (Ritter et al., 2011). Table 8 shows the impact of different features. This analysis is based on the pipeline system. First, we can see that adding feature 4 and 5 (Uni-, Bi- and Tri-gram of the dictionary and predicted NSW labels) yields the most improvement compared with other features, and between these two kinds of features, using predicted NSW labels is better than the dictionary labels. It also shows the effectiveness of our NSW detection system. Second, comparing adding feature 6 and 7, it shows that combination</context>
</contexts>
<marker>Ritter, Clark, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, and Oren Etzioni. 2011. Named entity recognition in tweets: an experimental study. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cagil Sonmez</author>
<author>Arzucan Ozgur</author>
</authors>
<title>A graphbased approach for contextual text normalization.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2102" citStr="Sonmez and Ozgur, 2014" startWordPosition="335" endWordPosition="338"> in recent years. However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style). They post problems to many NLP techniques in this domain. There are many ways to improve language processing performance on the social media data. One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (Aw et al., 2006; Cook and Stevenson, 2009; Pennell and Liu, 2011; Liu et al., 2012a; Li and Liu, 2014; Sonmez and Ozgur, 2014). Intuitively this will ease subsequent language processing modules. For example, if ‘2mr’ is converted to ‘tomorrow’, a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression. This normalization task has received an increasing attention in social media language processing. However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization. Then different methods are applied only to these tokens. To our knowledge, </context>
</contexts>
<marker>Sonmez, Ozgur, 2014</marker>
<rawString>Cagil Sonmez and Arzucan Ozgur. 2014. A graphbased approach for contextual text normalization. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="21822" citStr="Stolcke, 2002" startWordPosition="3636" endWordPosition="3637">13) released 2,347 tweets with their designed POS tags for social media text, and then Li and Liu (2015) further annotated this data with normalization information for each token. The released data by (Li and Liu, 2015) contains 798 tweets with ill-OOV. We use these 798 tweets as the second data set for NSW detection, and call it Test set 2 in the following. In addition, we use all of these 2,347 tweets to train a POS model which then is used to predict tokens’ POS tags for NER (see Section 3.2 about the POS tags). The CRF model is implemented using the pocket-CRF toolkit5. The SRILM toolkit (Stolcke, 2002) is used to build the character-level language model (LM) for generating the LM features in NSW detection system. 5http://sourceforge.net/projects/pocket-crf-1/ 933 Figure 1: Trellis Viterbi decoding for different systems. p(I|B)+ β * p(IVIill-OOV) . . . well-known . . . . . . Messi is (C) (A) (B) p(B|B)+ β * p(IVIIV) p(B|B)+ β * p(ill-OOVIIV) B_IV p(B|Messi)+ α* p(IV|Messi) p(B|is)+ α* p(correct-OOV|is) B_ill-OOV I_IV p(I|B)+ β * p(IVIIV) I_IV B_correct-OOV B_ill-OOV I_IV B_IV B_correct-OOV p(B|well-known)+ α* p(ill-OOV|well-known) B_IV B_correct-OOV B_ill-OOV p(IV|IV) p(B|B) IV B B IV B p(IV</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM-an extensible language modeling toolkit. In Proceedings International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aobo Wang</author>
<author>Min-Yen Kan</author>
</authors>
<title>Mining informal language from Chinese microtext: Joint word recognition and segmentation.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Wang, Kan, 2013</marker>
<rawString>Aobo Wang and Min-Yen Kan. 2013. Mining informal language from Chinese microtext: Joint word recognition and segmentation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Yang</author>
<author>Jacob Eisenstein</author>
</authors>
<title>A log-linear model for unsupervised text normalization.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="6238" citStr="Yang and Eisenstein (2013)" startWordPosition="1014" endWordPosition="1017">l and Liu, 2010; Liu et al., 2012a) and machine translation method (Aw et al., 2006; Pennell and Liu, 2011; Li and Liu, 2012b; Li and Liu, 2012a). Normalization performance on some benchmark data has been improved a lot. Currently, unsupervised models are widely used to extract latent relationship between non-standard words and correct words from a huge corpus. Hassan and Menezes (2013) applied the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus to build relation between non-standard tokens and correct words. Yang and Eisenstein (2013) presented a unified unsupervised statistical model, in which the relationship between the standard and non-standard words is characterized by a log-linear model, permitting the use of arbitrary features. Chrupała (2014) proposed a text normalization model based on learning edit operations from labeled data while incorporating features induced from unlabeled data via recurrent network derived character-level neural text embeddings. These studies only focused on how to normalize a given ill-OOV word and did not address the problem of detecting an ill-OOV word. Han and Baldwin (2011) is the only</context>
</contexts>
<marker>Yang, Eisenstein, 2013</marker>
<rawString>Yi Yang and Jacob Eisenstein. 2013. A log-linear model for unsupervised text normalization. In Proceedings of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>