<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000575">
<title confidence="0.982822">
Multidimensional Dialogue Management
</title>
<author confidence="0.997646">
Simon Keizer and Harry Bunt
</author>
<affiliation confidence="0.9991">
Department of Language and Information Science
Faculty of Arts, Tilburg University
</affiliation>
<address confidence="0.950076">
P.O. Box 90153, 5000 LE Tilburg, The Netherlands
</address>
<email confidence="0.999385">
{s.keizer,harry.bunt}@uvt.nl
</email>
<sectionHeader confidence="0.997405" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999682576923077">
In this paper we present an approach to
dialogue management that supports the
generation of multifunctional utterances.
It is based on the multidimensional dia-
logue act taxonomy and associated con-
text model as developed in Dynamic Inter-
pretation Theory (DIT). The multidimen-
sional organisation of the taxonomy re-
flects that there are various aspects that di-
alogue participants have to deal with si-
multaneously during a dialogue. Besides
performing some underlying task, a par-
ticipant also has to pay attention to vari-
ous aspects of the communication process
itself, including social conventions.
Therefore, a multi-agent approach is pro-
posed, in which for each of the dimensions
in the taxonomy a specialised dialogue act
agent is designed, dedicated to the gener-
ation of dialogue acts from that particular
dimension. These dialogue act agents op-
erate in parallel on the information state of
the system. For a simplified version of the
taxonomy, a dialogue manager has been
implemented and integrated into an inter-
active QA system.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999965217391305">
During (task-oriented) dialogues, the participants
have to deal with many different aspects of com-
munication simultaneously. Besides some under-
lying task that may be performed through the dia-
logue, there are also various aspects of managing
the communicative process itself, including deal-
ing with social obligations. Therefore, speakers
often use utterances that are multifunctional.
We will present an approach to dialogue man-
agement that accounts for the generation of multi-
functional utterances. The approach is based on a
dialogue theory involving a multidimensional dia-
logue act taxonomy and associated context model.
In this theory, called Dynamic Interpretation The-
ory (DIT) (Bunt, 1996; Bunt, 2000a), a dialogue is
modelled as a sequence of (sets of) dialogue acts
operating on the Information State of each of the
participants. The dialogue acts are organised in a
taxonomy that is multidimensional, i.e., each ut-
terance may involve dialogue acts of at most one
type from each dimension. The taxonomy has di-
mensions for aspects like feedback, interaction-
management, social obligations management and
managing the underlying task.
In a dialogue system developed according to
the principles of DIT, the information state is rep-
resented through a context model, containing all
information considered relevant for interpreting
user utterances an generating system utterances in
terms of dialogue acts. Hence, given the multidi-
mensionality of the taxonomy, the input interpre-
tation components of the system result in several
dialogue acts for each utterance, at most one from
each of the dimensions. Using these recognised
user dialogue acts, the context model is updated.
On the other hand, the ultimate task for a di-
alogue manager component of a dialogue system
is deciding which dialogue acts to generate. So,
again with the multidimensional organisation of
the taxonomy in mind, we argue for a multi-agent
approach, in which the dialogue act generation
task is divided over several agents that operate in
parallel on the context model, each agent being
dedicated to the generation of dialogue acts from
one particular dimension in the taxonomy. This
leads to the design of a number of so-called Di-
</bodyText>
<page confidence="0.992942">
37
</page>
<note confidence="0.5666435">
Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 37–45,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999911265625">
alogue Act Agents, including e.g. a task-oriented
agent, two feedback agents and an agent dealing
with social obligations management.
The multi-agent approach to dialogue manage-
ment itself is not new: JASPIS (Turunen and
Hakulinen, 2000; Salonen et al., 2004) is a multi-
agent framework for dialogue systems which al-
lows for implementations of several agents for the
same tasks, varying from input interpretation and
output presentation to dialogue management. De-
pending on the situation, the agent that is most
appropriate for a given task is selected in a pro-
cess involving several so-called ’evaluators’. In
JASPIS the multi-agent approach is aimed at flex-
ibility and adaptiveness, while our approach fo-
cuses more on supporting multidimensionality in
communication.
In a very general sense, our dialogue manage-
ment approach follows an information state update
approach similar to the dialogue managers that are
developed within the TRINDI framework (Lars-
son and Traum, 2000). For example, Matheson
et al. (2000) describe the implementation of a di-
alogue management system focusing in the con-
cepts of grounding and discourse obligations.
An approach to dialogue management which
identifies several simultaneous processes in the
generation of system utterances, is described in
(Stent, 2002). In this approach, which is imple-
mented in the TRIPS dialogue system, dialogue
contributions are generated through three core
components operating independently and concur-
rently, using a system of conversation acts or-
ganised in several levels (Traum and Hinkelman,
1992).
Although there are apparent similarities be-
tween our approach and that of the TRINDI based
dialogue managers and the TRIPS system, there
are clear differences as well, which for an impor-
tant part stem from the system of dialogue acts
used and the way the information state is organ-
ised. More particularly, the way in which mech-
anisms for generating dialogue acts along multi-
ple dimensions are modelled and implemented by
means of multiple agents, differs from existing ap-
proaches.
This paper is organised as follows. First we ex-
plain the closely connected DIT notions of dia-
logue act and information state, and the multi-
dimensional dialogue act taxonomy and context
model (Sections 2 and 3). We then introduce
the multi-agent approach to dialogue management
(Section 4) and illustrate it by a description of
the current implementation (Section 4.1). This
implementation is carried out in the PARADIME
project (PARallel Agent-based DIalogue Manage-
ment Engine), which is part of the multiproject
IMIX (Interactive Multimodal Information Ex-
traction). The PARADIME dialogue manager is
integrated into an interactive question-answering
system that is developed in a collaboration be-
tween several projects participating in IMIX. The
paper ends with conclusions and directions for fu-
ture research (Section 5).
</bodyText>
<sectionHeader confidence="0.985274" genericHeader="method">
2 The DIT dialogue act taxonomy
</sectionHeader>
<bodyText confidence="0.999913791666667">
Based on studies of a variety of dialogues from
several dialogue corpora, a dialogue act taxonomy
was developed consisting of a number of dimen-
sions, reflecting the idea that during a dialogue,
several aspects of the communication need to be
attended to by the dialogue participants (Bunt,
2006). Even within single utterances, several as-
pects are dealt with at the same time, i.e., in gen-
eral, utterances are multifunctional. The multidi-
mensional organisation of the taxonomy supports
this multifunctionality in that it allows several di-
alogue acts to be performed in each utterance, at
most one from each dimension. The 11 dimen-
sions of the taxonomy are listed below, with brief
descriptions and/or specific dialogue act types in
that dimension. For convenience, the dimensions
are further grouped into so-called layers. At the
top level are two layers: one for dialogue con-
trol acts and one coinciding with the task-domain
dimension. Dialogue control is further divided
into 3 layers: Feedback (2 dimensions), Interac-
tion Management (7 dimensions), and a layer co-
inciding with the Social Obligations Management
dimension.
</bodyText>
<listItem confidence="0.966910818181818">
• Dialogue Control
– Feedback
1. Auto-Feedback: acts dealing with the
speaker’s processing of the addressee’s
utterances; contains positive and nega-
tive feedback acts on the levels of per-
ception, interpretation, evaluation, and
execution;
2. Allo-Feedback: acts dealing with the
addressee’s processing of the speaker’s
previous utterances (as viewed by the
</listItem>
<page confidence="0.998459">
38
</page>
<bodyText confidence="0.9957508">
speaker); contains positive and negative
feedback-giving acts and feedback elic-
itation acts, both on the levels of per-
ception, interpretation, evaluation, and
execution;
</bodyText>
<listItem confidence="0.9766254">
– Interaction management
3. Turn Management: turn accepting,
giving, grabbing, keeping;
4. Time Management: stalling, pausing;
5. Dialogue Structuring: opening,
preclosing, closing, dialogue act an-
nouncement;
6. Partner Processing Management:
completion, correct-misspeaking;
7. Own Processing Management: error
signalling, retraction, self-correction;
8. Contact Management: contact check,
contact indication;
9. Topic Management: topic introduction,
closing, shift, shift announcement;
10. Social Obligations Management: saluta-
tion, self-introduction, gratitude, apology,
valediction;
11. Task/domain: acts that concern the specific
underlying task and/or domain.
</listItem>
<bodyText confidence="0.999252814814815">
Formally, a dialogue act in DIT consists of a
Semantic Content and a Communicative Function,
the latter specifying how the information state
of the addressee is to be updated with the for-
mer. A dialogue act in a particular dimension
may have either a dimension-specific communica-
tive function, or a General-Purpose communica-
tive function with a content type (type of semantic
content) in that dimension. The general-purpose
communicative functions are hierarchically or-
ganised into the branches of Information Trans-
fer and Action Discussion functions, Information
Transfer consisting of information-seeking (e.g.,
WH-QUESTION, YN-QUESTION, CHECK) and
information-providing functions (e.g., INFORM,
WH-ANSWER, YN-ANSWER, CONFIRM), and
Action Discussion consisting of commissives
(e.g., OFFER, PROMISE, ACCEPT-REQUEST) and
directives (e.g., INSTRUCT, REQUEST, DECLINE-
OFFER).
The taxonomy is currently being evaluated in
annotation experiments, involving several anno-
tators and several dialogue corpora. Measuring
inter-annotator agreement will give an indication
of the usability of the taxonomy and annotation
scheme. A first analysis has resulted in promising
scores (Geertzen and Bunt, 2006).
</bodyText>
<sectionHeader confidence="0.991976" genericHeader="method">
3 The DIT context model
</sectionHeader>
<bodyText confidence="0.999975571428571">
The Information State according to DIT is repre-
sented by a Context Model, containing all infor-
mation considered relevant for interpreting user
utterances (in terms of dialogue acts) and gener-
ating system dialogue acts (leading to system ut-
terances). The contents of the context model are
therefore very closely related to the dialogue act
taxonomy; in (Bunt and Keizer, 2005) it is ar-
gued that the context model serves as a formal se-
mantics for dialogue annotation, such an annota-
tion being a kind of underspecified semantic rep-
resentation. In combination with additional gen-
eral conceptual considerations, the context model
has evolved into a five component structure:
</bodyText>
<listItem confidence="0.996977888888889">
1. Linguistic Context: linguistic information
about the utterances produced in the dialogue
so far (a kind of ’extended dialogue history’);
information about planned system dialogue
acts (a ’dialogue future’);
2. Semantic Context: contains current infor-
mation about the task/domain, including as-
sumptions about the dialogue partner’s infor-
mation;
3. Cognitive Context: the current processing
states of both participants (on the levels of
perception, interpretation, evaluation, and
task execution), as viewed by the speaker;
4. Physical and Perceptual Context: the percep-
tible aspects of the communication process
and the task/domain;
5. Social Context: current communicative pres-
sures.
</listItem>
<bodyText confidence="0.9999075">
In Figure 1, a feature structure representation of
the context model is given, in which the five com-
ponents have been specified in further detail. This
specification forms the basis for the dialogue man-
ager being implemented in the PARADIME project.
The Linguistic Context contains features for
storing dialogue acts performed in the dialogue so
far: user utts and system utts, having lists of di-
alogue act representations as values. It also has
features for information about topics and conver-
sational structure: topic struct and conv state re-
spectively. Finally, there are two features that
</bodyText>
<page confidence="0.963894">
39
</page>
<figure confidence="0.764986538461538">
�
� � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � �
�
� � � � � � � �
LingContext :
�
� � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � �
1
user utts : hlast user dial act = uda0, uda_1, uda_2 ,...i
system utts : hlast system dial act = sda0, sda_1, sda_2 ,...i
topic struct : hreferentsi
conv state : opening|body|closing
candidate dial acts :...
dial acts pres :...
� �
task progress : comp quest|quest qa|answ eval|user sat
� �i
user info needs : h... , question :... � �
satisfied : +|−
CogContext : qa answers : h ...i
[own proc state : [proc problem : perc |int |eval |exec |none]
partner proc state : [proc problem : perc|int|eval|exec|none]
PhysPercContext : I I
� reactive pressures : none|grt|apo|thk|valed
SocContext :
interactive pressures : none|grt|apo|thk|valed
</figure>
<figureCaption confidence="0.999377">
Figure 1: Feature structure representation of the PARADIME context model.
</figureCaption>
<bodyText confidence="0.979264933333333">
SemContext :
are related to the actual generation of system di-
alogue acts: candidate dial acts stores the dia-
logue acts generated by the dialogue act agents,
and dial acts pres stores combined dialogue acts
for presentation as system output; in Section 4,
this will be discussed in more detail.
The specification of the Semantic Context is
determined by the character of the task-domain.
In Section 4.1, the task-domain of interactive
question-answering on encyclopedic medical in-
formation will be discussed and from that, the
specification of the Semantic Context for this pur-
pose.
The Cognitive Context is specified by means of
two features, representing the processing states of
the system (own proc state) and the user (part-
ner proc state). Both features indicate whether or
not a processing problem was encountered, and if
so, on which level of processing this happened.
The Physical and Perceptual Context is consid-
ered not to be relevant for the current system func-
tionality.
The Social Context is specified in terms of re-
active and interactive pressures; the correspond-
ing features indicate whether or not a pressure ex-
ists and if so, for which social obligations manage-
ment act it is a pressure (e.g., reactive pressures:
grt indicates a pressure for the system to respond
to a greeting).
</bodyText>
<sectionHeader confidence="0.995892" genericHeader="method">
4 Dialogue Act Agents
</sectionHeader>
<bodyText confidence="0.999963896551724">
Having discussed the dialogue act taxonomy and
context model in DIT, we can now move on to the
dialogue management approach that is also closely
connected to these concepts. Having 11 dimen-
sions of dialogue acts that each attend to a dif-
ferent aspect of communication, the generation of
(system) dialogue acts should also happen along
those 11 dimensions. As a dialogue act in a di-
mension can be selected independent of the other
dimensions, we propose to divide the generation
process over 11 Dialogue Act Agents operating in
parallel on the information state of the system,
each agent dedicated to generating dialogue acts
from one particular dimension.
All of the dialogue act agents continuously
monitor the context model and, if appropriate, try
to generate candidate dialogue acts from their as-
sociated dimension. This process of monitoring
and act generation is modelled through a trigger-
ing mechanism: if the information state satisfies
the agent’s triggering conditions, i.e., if there is
a motivation for generating a dialogue act from a
particular dimension, the corresponding agent gets
triggered and tries to generate such a dialogue act.
For example, the Auto-Feedback Agent gets trig-
gered if a processing problem is recorded in the
Own Processing State of the Cognitive Context.
The agent then tries to generate a negative auto-
feedback act in order to solve the processing prob-
</bodyText>
<page confidence="0.992187">
40
</page>
<bodyText confidence="0.999884">
lem (e.g., “Could you repeat that please?” or “Did
you say ’five’?”). The Auto-Feedback Agent may
also be triggered if it has reason to believe that the
user is not certain that the system has understood
a previous utterance, or simply if it has not given
any explicit positive feedback for some time. In
these cases of triggering, the agent tries to gener-
ate a positive auto-feedback act.
Hence the dialogue management process in-
volves 11 dialogue act agents that operate in par-
allel on the context model. The dialogue acts gen-
erated by these agents are kept in the linguistic
context as candidates. The selection of dialogue
acts from different dimensions may happen inde-
pendently, but for their order of performance and
their combination, the relative importance of the
dimensions at the given point in the dialogue has
to be taken into account.
An additional Evaluation Agent monitors the
list of candidates and decides which of them can
be combined into a multifunctional system utter-
ance for generation, and when. Some of the dia-
logue act candidates may have higher priority and
should be generated at once, some may be stored
for possible generation in later system turns, and
some will already be implicitly performed through
the performance of other candidate acts.
</bodyText>
<subsectionHeader confidence="0.98396">
4.1 A dialogue manager for interactive QA
</subsectionHeader>
<bodyText confidence="0.999968918032787">
The current implementation of the PARADIME
dialogue manager is integrated in an interactive
question-answering (QA) system, as developed
the IMIX multiproject. The task-domain at hand
concerns encyclopedic information in the medical
domain, in particular RSI (Repetitive Strain In-
jury). The system consists of several input anal-
ysis modules (ASR, syntactic analysis in terms
of dependency trees, and shallow semantic tag-
ging), three different QA modules that take self-
contained domain questions and return answers
retrieved from several electronic documents with
text data in the medical domain, and a presentation
module that takes the output from the dialogue
manager, possibly combining any QA-answers to
be presented, into a multimodal system utterance.
The dialogue management module provides
support for more interactive, coherent dialogues,
in which problems can be solved about both com-
munication and question-answering processes. In
interaction with the user, the system should play
the role of an Information Search Assistant (ISA).
This HCI metaphor posits that the dialogue system
is not an expert on the domain, but merely assists
the user in formulating questions about the domain
that will lead to QA answers from the QA mod-
ules satisfying the user’s information need (Akker
et al., 2005).
In the context model for this dialogue manager,
as represented by the feature structure in Figure 1,
the Semantic Context has been further specified
according to this underlying task. It contains a
state variable for keeping track of the question-
answering process (the feature task progress with
values to distinguish between the states of com-
posing a self-contained question to send to the QA
modules, waiting for the QA results in case a QA-
question has been sent, evaluating the QA results,
and discussing the results with the user). Also, the
Semantic Context keeps a record of user’s infor-
mation need, by means of a list user info needs
of ’information need’ specifications in terms of
semantic descriptions of domain questions and
whether or not these info-needs have been satis-
fied.
For the first version of the dialogue manager
we have defined a limited system functionality,
and following from that a simplified version of
the dialogue act taxonomy. This simplification
means for example that Social Obligations Man-
agement (SOM) and the various dimensions in
the Interaction Management (IM) layer have been
merged into one dimension, following the obser-
vation that utterances with a SOM function very
often also have a function in the IM layer, es-
pecially in human-computer dialogue; see (Bunt,
2000b). Also several general-purpose commu-
nicative functions have been clustered into single
types. Table 1 lists the dialogue acts that the dia-
logue act recogniser is able to identify from user
utterances.
</bodyText>
<table confidence="0.993652666666667">
GP AUF IM-SOM
YN-Question PosAutoFb Init-Open
WH-Question NegAutoFb-Int Init-Close
H-Question NegAutoFb-Eval
Request
Instruct
</table>
<tableCaption confidence="0.9627192">
Table 1: Dialogue act types for interpreting user
utterances.
Table 2 lists the dialogue acts that can be gen-
erated by the dialogue manager. Task-domain
acts, generally answers to questions about the do-
</tableCaption>
<page confidence="0.999455">
41
</page>
<bodyText confidence="0.9998478">
main, consist of a general-purpose function (either
a WH-ANSWER or UNC-WH-ANSWER; the latter
reflecting that the speaker is uncertain about the in-
formation provided) with a semantic content con-
taining the answers obtained from QA.
</bodyText>
<table confidence="0.994173">
AUF ALF IM-SOM
NegAutoFb-Int Fb-Elicit React-Open
NegAutoFb-Exe React-Close
</table>
<tableCaption confidence="0.869037">
Table 2: Dialogue act types for generating system
responses.
</tableCaption>
<bodyText confidence="0.998562695652174">
The above considerations have resulted in a di-
alogue manager containing 4 dialogue act agents
that operate on a slightly simplified version of the
context model as specified in Figure 1: a Task-
Oriented (TO) Agent, an Auto-Feedback (AUF)
Agent, an Allo-Feedback (AUF) Agent, and an
Interaction Management and Social Obligations
Management (IMSOM) Agent. In addition, a (cur-
rently very simple) Evaluation Agent takes care of
merging candidate dialogue acts for output presen-
tation.
In Appendices A.1 and A.2, two example di-
alogues with the IMIX demonstrator system are
given, showing system responses based on can-
didate dialogue acts from several dialogue act
agents. The ISA metaphor is reflected in the sys-
tem behaviour especially in the way in which QA
results are presented to the user. In system utter-
ances S2 and S3 in Appendix A.1, for example,
the answer derived from the retrieved QA results is
isolated from the first part of the system utterance,
showing that the system has a neutral attitude con-
cerning that answer.
</bodyText>
<subsectionHeader confidence="0.840305">
4.1.1 The Task-Oriented Agent
</subsectionHeader>
<bodyText confidence="0.999975486486486">
The TO-Agent is dedicated to the generation of
task-specific dialogue acts, which in practice in-
volves ANSWER dialogue acts intended to satisfy
the user’s information need about the (medical)
domain as indicated through his/her domain ques-
tions. The agent is triggered if a new information
need is recorded in the Semantic Context. Once it
has been triggered, the agent sends a request to the
QA modules to come up with answers to a ques-
tion asked, and evaluates the returned results. This
evaluation is based on the number of answers re-
ceived and the confidence scores of the answers;
the confidence scores are also part of the output of
the QA modules. If the QA did not find any an-
swers or if the answers produced had confidence
scores that were all below some lower threshold,
the TO-Agent will not generate a dialogue act, but
write an execution problem in the Own Process-
ing State of the Cognitive Context (which causes
the Auto-Feedback Agent to be triggered, see Sec-
tion 4.1.2; an example can be found in the dia-
logue in Appendix A.2). Otherwise, the TO-Agent
tries to make a selection from the QA answers
to be presented to the user. If this selection will
end up containing extremely many answers, again,
an execution problem is written in the Cognitive
Context (the question might have been too gen-
eral to be answerable). Otherwise, the selection
will be included in an answer dialogue act, either
a WHANSWER, or UNCWHANSWER (uncertain
wh-answer) in case the confidence scores are be-
low some upper threshold. System utterances S1
and S2 in the example dialogue in Appendix A.1
illustrate this variation. The selection is narrowed
down further if there is a subselection of answers
with confidences that are significantly higher than
those of the other answers in the selection.
</bodyText>
<subsubsectionHeader confidence="0.735579">
4.1.2 The Auto-Feedback-Agent
</subsubsectionHeader>
<bodyText confidence="0.989586277777778">
The AUF-Agent is dedicated to the generation
of auto-feedback dialogue acts. It currently pro-
duces negative auto-feedback acts on the levels
of interpretation (“I didn’t understand what you
said”), evaluation (“I do not know what to do with
this”) and execution (“I could not find any answers
to your question”). It may also decide to occa-
sionally give positive feedback to the user. In the
future, we would also like this agent to be able
to generate articulate feedback acts, for example
with the purpose of resolving reference resolution
problems, as in:
U: what is RSI?
S: RSI (repetitive strain injury) is a pain or
discomfort caused by small repetitive move-
ments or tensions.
U: how can it be prevented?
S: do you mean ’RSI’ or ’pain’?
</bodyText>
<subsectionHeader confidence="0.857371">
4.1.3 The Allo-Feedback Agent
</subsectionHeader>
<bodyText confidence="0.999849333333333">
The ALF-Agent is dedicated to the generation
of allo-feedback dialogue acts. For example, it
may generate a feedback-elicitation act if it has
reason to believe that the user might not be sat-
isfied with an answer (“Was this an answer to your
question?”).
</bodyText>
<page confidence="0.99801">
42
</page>
<subsectionHeader confidence="0.6468505">
4.1.4 Interaction Management and Social
Obligations Management Agent
</subsectionHeader>
<bodyText confidence="0.999391272727273">
The IM-SOM Agent is dedicated to the gener-
ation of social obligations management acts, pos-
sibly also functioning as dialogue structuring acts
(opening resp. closing a dialogue through a greet-
ing resp. valediction act). It gets triggered if
communicative pressures are recorded in the So-
cial Context. Currently it only responds to re-
active pressures as caused by initiative greetings
and goodbyes. The example dialogues in Appen-
dices A.1 and A.2 illustrate this type of social be-
haviour.
</bodyText>
<subsectionHeader confidence="0.9055265">
4.1.5 Multi-agent Architecture of the
Dialogue Manager
</subsectionHeader>
<bodyText confidence="0.99999664516129">
In Figure 2, a schematic overview of the multi-
agent dialogue manager is given. It shows the
context model with four components (for now, the
Physical and Perceptual Context is considered to
be of minor importance and is therefore ignored),
a set of dialogue act agents, and an Evaluation
Agent. The dialogue act agents each monitor the
context model and may be triggered if certain con-
ditions are satisfied. The TO-agent may also write
to the Cognitive Context (particularly in case of
execution problems). All agents may construct
a dialogue act and write it in the candidates list
in the Linguistic Context. The Evaluation Agent
monitors this candidates list and selects one or
more dialogue acts from it for presentation as sys-
tem output. In this way, a control module may
decide to take this combination of dialogue act for
presentation anytime and send it to the presenta-
tion module to produce a system utterance.
With this initial design of a multi-agent dia-
logue manager, the system is able to support mul-
tifunctional output. The beginning of the example
dialogue in Appendix A.1 illustrates multifunc-
tionality, both in input interpretation and output
generation. The system has recognised two dia-
logue acts in processing U1 (a conventional open-
ing and a domain question), and S1 is generated
on the basis of two candidate dialogue acts gen-
erated by different dialogue act agents: the IM-
SOM-Agent (generated the react-greeting act) and
the TO-Agent (generated the answer act).
</bodyText>
<sectionHeader confidence="0.986594" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9998875">
We have presented a dialogue management ap-
proach supporting the generation of multifunc-
</bodyText>
<figure confidence="0.721299">
Eval−Agent
</figure>
<figureCaption confidence="0.9875335">
Figure 2: Architecture of the PARADIME dialogue
manager.
</figureCaption>
<bodyText confidence="0.998635612903226">
tional utterances. The approach builds on a di-
alogue theory involving a multidimensional dia-
logue act taxonomy and an information state on
which the dialogue acts operate. Several dialogue
acts from different dimensions are generated by
dialogue act agents associated with these dimen-
sions, and can thus be combined into multifunc-
tional system utterances.
A first implementation of a dialogue manager
following this multi-agent approach has been in-
tegrated into an interactive QA system and sup-
ports a limited range of dialogue acts from the
DIT taxonomy, both for interpreting user utter-
ances and generating system utterances. The sys-
tem is able to attend to different aspects of the
communication simultaneously, involving reactive
social behaviour, answering domain questions and
giving feedback about utterance interpretation and
the question-answering process.
Future development will involve extending the
range of dialogue acts to be covered by the dia-
logue manager, for a part following from the def-
inition of an extended system functionality, and
consequently, extending the set of dialogue act
agents. This also has consequences for the Eval-
uation Agent: the process of combination and se-
lection will be more complex if more dialogue act
types can be expected and if the dialogue acts have
a semantic content that is more than just a collec-
tion of QA-answers.
In terms of system functionality we aim at sup-
</bodyText>
<figure confidence="0.9974494375">
candidate
dialogue acts
dialogue acts
for presentation
DIALOGUE ACT AGENTS
IM−SOM−Agent
AUF−Agent
ALF−Agent
TO−Agent
candidate
dialogue acts
CONTEXT MODEL
Cognitive Context
Semantic Context
Linguistic Context
Social Context
</figure>
<page confidence="0.999768">
43
</page>
<bodyText confidence="0.999924513513513">
port for generating articulate feedback, i.e., feed-
back acts that are not merely signalling processing
success or failure, but (in case of negative feed-
back) also contain a further specification of the
processing problem at hand. For example, the sys-
tem may have encountered problems in processing
certain parts of a user utterance, or in resolving an
anaphor; then it should be able to ask the user a
specific question in order to obtain the informa-
tion required to solve the processing problem (see
the example in Section 4.1.2). The articulate feed-
back acts may also involve dealing with problems
in the question answering process, where the sys-
tem should be able to give specific instructions to
the user to reformulate his question or give addi-
tional information about his information need.
In addition to supporting generation of articu-
late feedback acts, we also aim at dialogues be-
tween user and system that are more coherent and
natural, i.e., the system should be more aware of
the conversational structure, and display more re-
fined social behaviour. Not only should it gener-
ate simple reactions to greetings, apologies, and
goodbyes; it should also be able to generate initia-
tive social acts, for example, apologies after sev-
eral cases of negative auto-feedback.
The extended set of dialogue acts will also lead
to an extended context model. Related to the
context model and updating mechanism is on-
going work on belief dynamics and grounding
in DIT (Morante and Bunt, 2005). The defined
mechanisms for the creation, strengthening, adop-
tion, and cancelling of beliefs and goals in the
context model are currently being implemented
in a demonstrator tool and will also be integrated
in the information state update mechanism of the
PARADIME dialogue manager.
</bodyText>
<sectionHeader confidence="0.957016" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999972333333333">
This work is part of PARADIME (Parallel Agent-
based Dialogue Management Engine), which is a
subproject of IMIX (Interactive Multimodal Infor-
mation eXtraction), a multiproject on Dutch lan-
guage and speech technology, funded by the Dutch
national science foundation (NWO).
We would like to thank the reviewers for their
valuable comments, which really helped us to im-
prove our paper.
</bodyText>
<sectionHeader confidence="0.996077" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723377358491">
R. op den Akker, H. Bunt, S. Keizer, and B. van
Schooten. 2005. From question answering to spo-
ken dialogue: Towards an information search assis-
tant for interactive multimodal information extrac-
tion. In Proceedings of the 9th European Confer-
ence on Speech Communication and Technology, In-
terspeech 2005, pages 2793–2796.
H. Bunt and S. Keizer. 2005. Dialogue semantics
links annotation to context representation. In Joint
TALK/AMI Workshop on Standards for Multimodal
Dialogue Context. http://homepages.inf.
ed.ac.uk/olemon/standcon-SOI.html.
H. Bunt. 1996. Dynamic interpretation and dia-
logue theory. In M.M. Taylor, F. N´eel, and D.G.
Bouwhuis, editors, The Structure of Multimodal Di-
alogue, Volume 2, pages 139–166. John Benjamins.
H. Bunt. 2000a. Dialogue pragmatics and context
specification. In H. Bunt and W. Black, editors,
Abduction, Belief and Context in Dialogue, Studies
in Computational Pragmatics, pages 81–150. John
Benjamins.
H. Bunt. 2000b. Non-problems and social obliga-
tions in human-computer conversation. In Proceed-
ings of the 3rd International Workshop on Human-
Computer Conversation, pages 36–41.
H. Bunt. 2006. Dimensions in dialogue act anno-
tation. In Proceedings Fifth International Confer-
ence on Language Resources and Evaluation (LREC
2006).
J. Geertzen and H. Bunt. 2006. Measuring annotator
agreement in a complex hierarchical dialogue act an-
notation scheme. In 7th SIGdial Workshop on Dis-
course and Dialogue.
S. Larsson and D. Traum. 2000. Information state
and dialogue management in the TRINDI dialogue
move engine toolkit. Natural Language Engineer-
ing: Special Issue on Best Practice in Spoken Lan-
guage Dialogue Systems, 6(3–4):323–340.
C. Matheson, M. Poesio, and D. Traum. 2000. Mod-
eling grounding and discourse obligations using up-
date rules. In Proceedings of the First Annual Meet-
ing of the North American Chapter of the ACL.
R. Morante and H. Bunt. 2005. Micro-analysis of the
belief transfer in information dialogues. In C. Gar-
dent and B. Gaiffe, editors, DIALOR’05 Proceed-
ings of the Ninth Workshop on the Semantics and
Pragmatics of Dialogue, pages 135–138.
E.P. Salonen, M. Hartikainen, M. Turunen, J. Hakuli-
nen, and J.A. Funk. 2004. Flexible dialogue man-
agement using distributed and dynamic dialogue
control. In Proceedings of ICSLP 2004.
A.J. Stent. 2002. A conversation acts model for gen-
erating spoken dialogue contributions. Computer
</reference>
<page confidence="0.979988">
44
</page>
<reference confidence="0.88653956097561">
Speech and Language, Special Issue on Spoken Lan-
guage Generation, 16(3–4):313–352.
D.R. Traum and E.R. Hinkelman. 1992. Conversa-
tion acts in task-oriented spoken dialogue. Compu-
tational Intelligence, 3(8):575–599.
M. Turunen and J. Hakulinen. 2000. Jaspis – a frame-
work for multilingual adaptive speech applications.
In Sixth International Conference on Spoken Lan-
guage Processing (ICSLP 2000), volume 2, pages
719–722.
A Example dialogues
A.1 Example 1: greetings, answers and
unc-answers
U1: hallo, ik wilde graag weten wat rsi is
(hello, I wanted to know what is rsi)
[INIT-OPEN; INDWHQ, task-domain]
S1: Hallo. Ik heb de volgende informatie gevonden:
(repetitive strain injury) Algemene benaming voor
(blijvende) beschadigingen aan het lichaam ten gevolge
van langdurige, eentonige werkzaamheden.
(Hello. I found the following information:...)
[REACT-OPEN; ANSWER, task-domain]
U2: wat moet ik doen als ik denk rsi te hebben
(what should I do if I think I have RSI)
[WHQUESTION, task-domain]
S2: De volgende informatie levert mogelijk een antwoord
op uw vraag:
Ontspanning betekent minder stress, minder aange-
spannen spieren en dus minder kans op RSI.
(The following information might answer your ques-
tion:...)
[UNCANSWER, task-domain]
U3: helpt ontspanning ook als ik eenmaal rsi heb
(does relaxing help as well, once I have RSI)
[YNQUESTION, task-domain]
S3: Ik heb de volgende informatie gevonden:
Behandelmethoden bij RSI Er zijn vele wegen die naar
Rome leiden. Verbetering van de doorbloeding ...
(I found the following information:...)
[ANSWER, task-domain]
U4: oke, bedankt
(okay, thanks)
[INIT-CLOSE]
S4: tot ziens. U kunt de buttons gebruiken om te stoppen
of om een nieuwe dialoog te beginnen.
(Goodbye. You may use the buttons to stop or to start a
new dialogue.)
[REACT-CLOSE]
A.2 Example 2: negative execution-feedback
U1: hallo!
(hello!)
[INIT-OPEN]
S1: Hallo. Stel uw vraag.
(Hello. Ask your question.)
[REACT-OPEN]
U2: wat kan ik als beelschermwerker tegen rugpijn doen
(what can I, a person working behind a computer
screen all the time, do against pain in the back)
[WHQUESTION, task-domain]
S2: Ik heb helaas geen antwoorden kunnen vinden; probeer
de vraag te herformuleren.
(Unfortunately, I could notfind any answers; please try
to reformulate the question)
[NEGAUTOFB-EXEC]
U3: wat kan men tegen rugpijn doen
(what can be done against pain in the back)
[WHQUESTION, task-domain]
S3: ik heb de volgende informatie gevonden:
Deze is afhankelijk van de oorzaak. Rugpijn die door
instabiliteit of door tekortschietende spieren en ban-
den ontstaat, kan behandeld worden met houdingscor-
rigerende oefentherapie.
(Ifound the following information:...)
[ANSWER, task-domain]
U4: bedankt!
(thanks!)
[INIT-CLOSE]
S4: Tot ziens. U kunt de buttons gebruiken om te stoppen
of om een nieuwe dialoog te beginnen.
(Goodbye. U may use the buttons to stop or to start a
new dialogue.)
[REACT-CLOSE]
</reference>
<page confidence="0.997179">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.561621">
<title confidence="0.999692">Multidimensional Dialogue Management</title>
<author confidence="0.99733">Simon Keizer</author>
<author confidence="0.99733">Harry</author>
<affiliation confidence="0.999838">Department of Language and Information</affiliation>
<address confidence="0.847434">Faculty of Arts, Tilburg P.O. Box 90153, 5000 LE Tilburg, The</address>
<abstract confidence="0.992878518518518">In this paper we present an approach to dialogue management that supports the generation of multifunctional utterances. It is based on the multidimensional dialogue act taxonomy and associated context model as developed in Dynamic Interpretation Theory (DIT). The multidimensional organisation of the taxonomy reflects that there are various aspects that dialogue participants have to deal with simultaneously during a dialogue. Besides performing some underlying task, a participant also has to pay attention to various aspects of the communication process itself, including social conventions. Therefore, a multi-agent approach is proposed, in which for each of the dimensions in the taxonomy a specialised dialogue act agent is designed, dedicated to the generation of dialogue acts from that particular dimension. These dialogue act agents operate in parallel on the information state of the system. For a simplified version of the taxonomy, a dialogue manager has been implemented and integrated into an interactive QA system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R op den Akker</author>
<author>H Bunt</author>
<author>S Keizer</author>
<author>B van Schooten</author>
</authors>
<title>From question answering to spoken dialogue: Towards an information search assistant for interactive multimodal information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology, Interspeech</booktitle>
<pages>2793--2796</pages>
<marker>den Akker, Bunt, Keizer, van Schooten, 2005</marker>
<rawString>R. op den Akker, H. Bunt, S. Keizer, and B. van Schooten. 2005. From question answering to spoken dialogue: Towards an information search assistant for interactive multimodal information extraction. In Proceedings of the 9th European Conference on Speech Communication and Technology, Interspeech 2005, pages 2793–2796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
<author>S Keizer</author>
</authors>
<title>Dialogue semantics links annotation to context representation.</title>
<date>2005</date>
<booktitle>In Joint TALK/AMI Workshop on Standards for Multimodal Dialogue Context.</booktitle>
<note>http://homepages.inf. ed.ac.uk/olemon/standcon-SOI.html.</note>
<contexts>
<context position="10452" citStr="Bunt and Keizer, 2005" startWordPosition="1557" endWordPosition="1560">and several dialogue corpora. Measuring inter-annotator agreement will give an indication of the usability of the taxonomy and annotation scheme. A first analysis has resulted in promising scores (Geertzen and Bunt, 2006). 3 The DIT context model The Information State according to DIT is represented by a Context Model, containing all information considered relevant for interpreting user utterances (in terms of dialogue acts) and generating system dialogue acts (leading to system utterances). The contents of the context model are therefore very closely related to the dialogue act taxonomy; in (Bunt and Keizer, 2005) it is argued that the context model serves as a formal semantics for dialogue annotation, such an annotation being a kind of underspecified semantic representation. In combination with additional general conceptual considerations, the context model has evolved into a five component structure: 1. Linguistic Context: linguistic information about the utterances produced in the dialogue so far (a kind of ’extended dialogue history’); information about planned system dialogue acts (a ’dialogue future’); 2. Semantic Context: contains current information about the task/domain, including assumptions </context>
</contexts>
<marker>Bunt, Keizer, 2005</marker>
<rawString>H. Bunt and S. Keizer. 2005. Dialogue semantics links annotation to context representation. In Joint TALK/AMI Workshop on Standards for Multimodal Dialogue Context. http://homepages.inf. ed.ac.uk/olemon/standcon-SOI.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>Dynamic interpretation and dialogue theory.</title>
<date>1996</date>
<booktitle>The Structure of Multimodal Dialogue,</booktitle>
<volume>2</volume>
<pages>139--166</pages>
<editor>In M.M. Taylor, F. N´eel, and D.G. Bouwhuis, editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="1976" citStr="Bunt, 1996" startWordPosition="295" endWordPosition="296">aspects of communication simultaneously. Besides some underlying task that may be performed through the dialogue, there are also various aspects of managing the communicative process itself, including dealing with social obligations. Therefore, speakers often use utterances that are multifunctional. We will present an approach to dialogue management that accounts for the generation of multifunctional utterances. The approach is based on a dialogue theory involving a multidimensional dialogue act taxonomy and associated context model. In this theory, called Dynamic Interpretation Theory (DIT) (Bunt, 1996; Bunt, 2000a), a dialogue is modelled as a sequence of (sets of) dialogue acts operating on the Information State of each of the participants. The dialogue acts are organised in a taxonomy that is multidimensional, i.e., each utterance may involve dialogue acts of at most one type from each dimension. The taxonomy has dimensions for aspects like feedback, interactionmanagement, social obligations management and managing the underlying task. In a dialogue system developed according to the principles of DIT, the information state is represented through a context model, containing all informatio</context>
</contexts>
<marker>Bunt, 1996</marker>
<rawString>H. Bunt. 1996. Dynamic interpretation and dialogue theory. In M.M. Taylor, F. N´eel, and D.G. Bouwhuis, editors, The Structure of Multimodal Dialogue, Volume 2, pages 139–166. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>Dialogue pragmatics and context specification.</title>
<date>2000</date>
<booktitle>Abduction, Belief and Context in Dialogue, Studies in Computational Pragmatics,</booktitle>
<pages>81--150</pages>
<editor>In H. Bunt and W. Black, editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="1988" citStr="Bunt, 2000" startWordPosition="297" endWordPosition="298">ommunication simultaneously. Besides some underlying task that may be performed through the dialogue, there are also various aspects of managing the communicative process itself, including dealing with social obligations. Therefore, speakers often use utterances that are multifunctional. We will present an approach to dialogue management that accounts for the generation of multifunctional utterances. The approach is based on a dialogue theory involving a multidimensional dialogue act taxonomy and associated context model. In this theory, called Dynamic Interpretation Theory (DIT) (Bunt, 1996; Bunt, 2000a), a dialogue is modelled as a sequence of (sets of) dialogue acts operating on the Information State of each of the participants. The dialogue acts are organised in a taxonomy that is multidimensional, i.e., each utterance may involve dialogue acts of at most one type from each dimension. The taxonomy has dimensions for aspects like feedback, interactionmanagement, social obligations management and managing the underlying task. In a dialogue system developed according to the principles of DIT, the information state is represented through a context model, containing all information considered</context>
<context position="19567" citStr="Bunt, 2000" startWordPosition="3074" endWordPosition="3075">c descriptions of domain questions and whether or not these info-needs have been satisfied. For the first version of the dialogue manager we have defined a limited system functionality, and following from that a simplified version of the dialogue act taxonomy. This simplification means for example that Social Obligations Management (SOM) and the various dimensions in the Interaction Management (IM) layer have been merged into one dimension, following the observation that utterances with a SOM function very often also have a function in the IM layer, especially in human-computer dialogue; see (Bunt, 2000b). Also several general-purpose communicative functions have been clustered into single types. Table 1 lists the dialogue acts that the dialogue act recogniser is able to identify from user utterances. GP AUF IM-SOM YN-Question PosAutoFb Init-Open WH-Question NegAutoFb-Int Init-Close H-Question NegAutoFb-Eval Request Instruct Table 1: Dialogue act types for interpreting user utterances. Table 2 lists the dialogue acts that can be generated by the dialogue manager. Task-domain acts, generally answers to questions about the do41 main, consist of a general-purpose function (either a WH-ANSWER or</context>
</contexts>
<marker>Bunt, 2000</marker>
<rawString>H. Bunt. 2000a. Dialogue pragmatics and context specification. In H. Bunt and W. Black, editors, Abduction, Belief and Context in Dialogue, Studies in Computational Pragmatics, pages 81–150. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>Non-problems and social obligations in human-computer conversation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 3rd International Workshop on HumanComputer Conversation,</booktitle>
<pages>36--41</pages>
<contexts>
<context position="1988" citStr="Bunt, 2000" startWordPosition="297" endWordPosition="298">ommunication simultaneously. Besides some underlying task that may be performed through the dialogue, there are also various aspects of managing the communicative process itself, including dealing with social obligations. Therefore, speakers often use utterances that are multifunctional. We will present an approach to dialogue management that accounts for the generation of multifunctional utterances. The approach is based on a dialogue theory involving a multidimensional dialogue act taxonomy and associated context model. In this theory, called Dynamic Interpretation Theory (DIT) (Bunt, 1996; Bunt, 2000a), a dialogue is modelled as a sequence of (sets of) dialogue acts operating on the Information State of each of the participants. The dialogue acts are organised in a taxonomy that is multidimensional, i.e., each utterance may involve dialogue acts of at most one type from each dimension. The taxonomy has dimensions for aspects like feedback, interactionmanagement, social obligations management and managing the underlying task. In a dialogue system developed according to the principles of DIT, the information state is represented through a context model, containing all information considered</context>
<context position="19567" citStr="Bunt, 2000" startWordPosition="3074" endWordPosition="3075">c descriptions of domain questions and whether or not these info-needs have been satisfied. For the first version of the dialogue manager we have defined a limited system functionality, and following from that a simplified version of the dialogue act taxonomy. This simplification means for example that Social Obligations Management (SOM) and the various dimensions in the Interaction Management (IM) layer have been merged into one dimension, following the observation that utterances with a SOM function very often also have a function in the IM layer, especially in human-computer dialogue; see (Bunt, 2000b). Also several general-purpose communicative functions have been clustered into single types. Table 1 lists the dialogue acts that the dialogue act recogniser is able to identify from user utterances. GP AUF IM-SOM YN-Question PosAutoFb Init-Open WH-Question NegAutoFb-Int Init-Close H-Question NegAutoFb-Eval Request Instruct Table 1: Dialogue act types for interpreting user utterances. Table 2 lists the dialogue acts that can be generated by the dialogue manager. Task-domain acts, generally answers to questions about the do41 main, consist of a general-purpose function (either a WH-ANSWER or</context>
</contexts>
<marker>Bunt, 2000</marker>
<rawString>H. Bunt. 2000b. Non-problems and social obligations in human-computer conversation. In Proceedings of the 3rd International Workshop on HumanComputer Conversation, pages 36–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>Dimensions in dialogue act annotation.</title>
<date>2006</date>
<booktitle>In Proceedings Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="6833" citStr="Bunt, 2006" startWordPosition="1050" endWordPosition="1051">dal Information Extraction). The PARADIME dialogue manager is integrated into an interactive question-answering system that is developed in a collaboration between several projects participating in IMIX. The paper ends with conclusions and directions for future research (Section 5). 2 The DIT dialogue act taxonomy Based on studies of a variety of dialogues from several dialogue corpora, a dialogue act taxonomy was developed consisting of a number of dimensions, reflecting the idea that during a dialogue, several aspects of the communication need to be attended to by the dialogue participants (Bunt, 2006). Even within single utterances, several aspects are dealt with at the same time, i.e., in general, utterances are multifunctional. The multidimensional organisation of the taxonomy supports this multifunctionality in that it allows several dialogue acts to be performed in each utterance, at most one from each dimension. The 11 dimensions of the taxonomy are listed below, with brief descriptions and/or specific dialogue act types in that dimension. For convenience, the dimensions are further grouped into so-called layers. At the top level are two layers: one for dialogue control acts and one c</context>
<context position="10051" citStr="Bunt, 2006" startWordPosition="1494" endWordPosition="1495">ng of information-seeking (e.g., WH-QUESTION, YN-QUESTION, CHECK) and information-providing functions (e.g., INFORM, WH-ANSWER, YN-ANSWER, CONFIRM), and Action Discussion consisting of commissives (e.g., OFFER, PROMISE, ACCEPT-REQUEST) and directives (e.g., INSTRUCT, REQUEST, DECLINEOFFER). The taxonomy is currently being evaluated in annotation experiments, involving several annotators and several dialogue corpora. Measuring inter-annotator agreement will give an indication of the usability of the taxonomy and annotation scheme. A first analysis has resulted in promising scores (Geertzen and Bunt, 2006). 3 The DIT context model The Information State according to DIT is represented by a Context Model, containing all information considered relevant for interpreting user utterances (in terms of dialogue acts) and generating system dialogue acts (leading to system utterances). The contents of the context model are therefore very closely related to the dialogue act taxonomy; in (Bunt and Keizer, 2005) it is argued that the context model serves as a formal semantics for dialogue annotation, such an annotation being a kind of underspecified semantic representation. In combination with additional ge</context>
</contexts>
<marker>Bunt, 2006</marker>
<rawString>H. Bunt. 2006. Dimensions in dialogue act annotation. In Proceedings Fifth International Conference on Language Resources and Evaluation (LREC 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Geertzen</author>
<author>H Bunt</author>
</authors>
<title>Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme.</title>
<date>2006</date>
<booktitle>In 7th SIGdial Workshop on Discourse and Dialogue.</booktitle>
<contexts>
<context position="10051" citStr="Geertzen and Bunt, 2006" startWordPosition="1492" endWordPosition="1495">sfer consisting of information-seeking (e.g., WH-QUESTION, YN-QUESTION, CHECK) and information-providing functions (e.g., INFORM, WH-ANSWER, YN-ANSWER, CONFIRM), and Action Discussion consisting of commissives (e.g., OFFER, PROMISE, ACCEPT-REQUEST) and directives (e.g., INSTRUCT, REQUEST, DECLINEOFFER). The taxonomy is currently being evaluated in annotation experiments, involving several annotators and several dialogue corpora. Measuring inter-annotator agreement will give an indication of the usability of the taxonomy and annotation scheme. A first analysis has resulted in promising scores (Geertzen and Bunt, 2006). 3 The DIT context model The Information State according to DIT is represented by a Context Model, containing all information considered relevant for interpreting user utterances (in terms of dialogue acts) and generating system dialogue acts (leading to system utterances). The contents of the context model are therefore very closely related to the dialogue act taxonomy; in (Bunt and Keizer, 2005) it is argued that the context model serves as a formal semantics for dialogue annotation, such an annotation being a kind of underspecified semantic representation. In combination with additional ge</context>
</contexts>
<marker>Geertzen, Bunt, 2006</marker>
<rawString>J. Geertzen and H. Bunt. 2006. Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme. In 7th SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>D Traum</author>
</authors>
<title>Information state and dialogue management in the TRINDI dialogue move engine toolkit.</title>
<date>2000</date>
<journal>Natural Language Engineering: Special Issue on Best Practice in Spoken Language Dialogue Systems,</journal>
<pages>6--3</pages>
<contexts>
<context position="4615" citStr="Larsson and Traum, 2000" startWordPosition="704" endWordPosition="708">gents for the same tasks, varying from input interpretation and output presentation to dialogue management. Depending on the situation, the agent that is most appropriate for a given task is selected in a process involving several so-called ’evaluators’. In JASPIS the multi-agent approach is aimed at flexibility and adaptiveness, while our approach focuses more on supporting multidimensionality in communication. In a very general sense, our dialogue management approach follows an information state update approach similar to the dialogue managers that are developed within the TRINDI framework (Larsson and Traum, 2000). For example, Matheson et al. (2000) describe the implementation of a dialogue management system focusing in the concepts of grounding and discourse obligations. An approach to dialogue management which identifies several simultaneous processes in the generation of system utterances, is described in (Stent, 2002). In this approach, which is implemented in the TRIPS dialogue system, dialogue contributions are generated through three core components operating independently and concurrently, using a system of conversation acts organised in several levels (Traum and Hinkelman, 1992). Although the</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>S. Larsson and D. Traum. 2000. Information state and dialogue management in the TRINDI dialogue move engine toolkit. Natural Language Engineering: Special Issue on Best Practice in Spoken Language Dialogue Systems, 6(3–4):323–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Matheson</author>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<title>Modeling grounding and discourse obligations using update rules.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Annual Meeting of the North American Chapter of the ACL.</booktitle>
<contexts>
<context position="4652" citStr="Matheson et al. (2000)" startWordPosition="711" endWordPosition="714">input interpretation and output presentation to dialogue management. Depending on the situation, the agent that is most appropriate for a given task is selected in a process involving several so-called ’evaluators’. In JASPIS the multi-agent approach is aimed at flexibility and adaptiveness, while our approach focuses more on supporting multidimensionality in communication. In a very general sense, our dialogue management approach follows an information state update approach similar to the dialogue managers that are developed within the TRINDI framework (Larsson and Traum, 2000). For example, Matheson et al. (2000) describe the implementation of a dialogue management system focusing in the concepts of grounding and discourse obligations. An approach to dialogue management which identifies several simultaneous processes in the generation of system utterances, is described in (Stent, 2002). In this approach, which is implemented in the TRIPS dialogue system, dialogue contributions are generated through three core components operating independently and concurrently, using a system of conversation acts organised in several levels (Traum and Hinkelman, 1992). Although there are apparent similarities between </context>
</contexts>
<marker>Matheson, Poesio, Traum, 2000</marker>
<rawString>C. Matheson, M. Poesio, and D. Traum. 2000. Modeling grounding and discourse obligations using update rules. In Proceedings of the First Annual Meeting of the North American Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Morante</author>
<author>H Bunt</author>
</authors>
<title>Micro-analysis of the belief transfer in information dialogues.</title>
<date>2005</date>
<booktitle>DIALOR’05 Proceedings of the Ninth Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<pages>135--138</pages>
<editor>In C. Gardent and B. Gaiffe, editors,</editor>
<contexts>
<context position="29783" citStr="Morante and Bunt, 2005" startWordPosition="4721" endWordPosition="4724">we also aim at dialogues between user and system that are more coherent and natural, i.e., the system should be more aware of the conversational structure, and display more refined social behaviour. Not only should it generate simple reactions to greetings, apologies, and goodbyes; it should also be able to generate initiative social acts, for example, apologies after several cases of negative auto-feedback. The extended set of dialogue acts will also lead to an extended context model. Related to the context model and updating mechanism is ongoing work on belief dynamics and grounding in DIT (Morante and Bunt, 2005). The defined mechanisms for the creation, strengthening, adoption, and cancelling of beliefs and goals in the context model are currently being implemented in a demonstrator tool and will also be integrated in the information state update mechanism of the PARADIME dialogue manager. Acknowledgement This work is part of PARADIME (Parallel Agentbased Dialogue Management Engine), which is a subproject of IMIX (Interactive Multimodal Information eXtraction), a multiproject on Dutch language and speech technology, funded by the Dutch national science foundation (NWO). We would like to thank the rev</context>
</contexts>
<marker>Morante, Bunt, 2005</marker>
<rawString>R. Morante and H. Bunt. 2005. Micro-analysis of the belief transfer in information dialogues. In C. Gardent and B. Gaiffe, editors, DIALOR’05 Proceedings of the Ninth Workshop on the Semantics and Pragmatics of Dialogue, pages 135–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E P Salonen</author>
<author>M Hartikainen</author>
<author>M Turunen</author>
<author>J Hakulinen</author>
<author>J A Funk</author>
</authors>
<title>Flexible dialogue management using distributed and dynamic dialogue control.</title>
<date>2004</date>
<booktitle>In Proceedings of ICSLP</booktitle>
<contexts>
<context position="3898" citStr="Salonen et al., 2004" startWordPosition="594" endWordPosition="597">ts that operate in parallel on the context model, each agent being dedicated to the generation of dialogue acts from one particular dimension in the taxonomy. This leads to the design of a number of so-called Di37 Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 37–45, Sydney, July 2006. c�2006 Association for Computational Linguistics alogue Act Agents, including e.g. a task-oriented agent, two feedback agents and an agent dealing with social obligations management. The multi-agent approach to dialogue management itself is not new: JASPIS (Turunen and Hakulinen, 2000; Salonen et al., 2004) is a multiagent framework for dialogue systems which allows for implementations of several agents for the same tasks, varying from input interpretation and output presentation to dialogue management. Depending on the situation, the agent that is most appropriate for a given task is selected in a process involving several so-called ’evaluators’. In JASPIS the multi-agent approach is aimed at flexibility and adaptiveness, while our approach focuses more on supporting multidimensionality in communication. In a very general sense, our dialogue management approach follows an information state upda</context>
</contexts>
<marker>Salonen, Hartikainen, Turunen, Hakulinen, Funk, 2004</marker>
<rawString>E.P. Salonen, M. Hartikainen, M. Turunen, J. Hakulinen, and J.A. Funk. 2004. Flexible dialogue management using distributed and dynamic dialogue control. In Proceedings of ICSLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Stent</author>
</authors>
<title>A conversation acts model for generating spoken dialogue contributions.</title>
<date>2002</date>
<journal>Computer Speech and Language, Special Issue on Spoken Language Generation,</journal>
<pages>16--3</pages>
<contexts>
<context position="4930" citStr="Stent, 2002" startWordPosition="753" endWordPosition="754">ess, while our approach focuses more on supporting multidimensionality in communication. In a very general sense, our dialogue management approach follows an information state update approach similar to the dialogue managers that are developed within the TRINDI framework (Larsson and Traum, 2000). For example, Matheson et al. (2000) describe the implementation of a dialogue management system focusing in the concepts of grounding and discourse obligations. An approach to dialogue management which identifies several simultaneous processes in the generation of system utterances, is described in (Stent, 2002). In this approach, which is implemented in the TRIPS dialogue system, dialogue contributions are generated through three core components operating independently and concurrently, using a system of conversation acts organised in several levels (Traum and Hinkelman, 1992). Although there are apparent similarities between our approach and that of the TRINDI based dialogue managers and the TRIPS system, there are clear differences as well, which for an important part stem from the system of dialogue acts used and the way the information state is organised. More particularly, the way in which mech</context>
</contexts>
<marker>Stent, 2002</marker>
<rawString>A.J. Stent. 2002. A conversation acts model for generating spoken dialogue contributions. Computer Speech and Language, Special Issue on Spoken Language Generation, 16(3–4):313–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
<author>E R Hinkelman</author>
</authors>
<title>Conversation acts in task-oriented spoken dialogue.</title>
<date>1992</date>
<journal>Computational Intelligence,</journal>
<volume>3</volume>
<issue>8</issue>
<contexts>
<context position="5201" citStr="Traum and Hinkelman, 1992" startWordPosition="791" endWordPosition="794">INDI framework (Larsson and Traum, 2000). For example, Matheson et al. (2000) describe the implementation of a dialogue management system focusing in the concepts of grounding and discourse obligations. An approach to dialogue management which identifies several simultaneous processes in the generation of system utterances, is described in (Stent, 2002). In this approach, which is implemented in the TRIPS dialogue system, dialogue contributions are generated through three core components operating independently and concurrently, using a system of conversation acts organised in several levels (Traum and Hinkelman, 1992). Although there are apparent similarities between our approach and that of the TRINDI based dialogue managers and the TRIPS system, there are clear differences as well, which for an important part stem from the system of dialogue acts used and the way the information state is organised. More particularly, the way in which mechanisms for generating dialogue acts along multiple dimensions are modelled and implemented by means of multiple agents, differs from existing approaches. This paper is organised as follows. First we explain the closely connected DIT notions of dialogue act and informatio</context>
</contexts>
<marker>Traum, Hinkelman, 1992</marker>
<rawString>D.R. Traum and E.R. Hinkelman. 1992. Conversation acts in task-oriented spoken dialogue. Computational Intelligence, 3(8):575–599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Turunen</author>
<author>J Hakulinen</author>
</authors>
<title>Jaspis – a framework for multilingual adaptive speech applications.</title>
<date>2000</date>
<booktitle>In Sixth International Conference on Spoken Language Processing (ICSLP</booktitle>
<volume>2</volume>
<pages>719--722</pages>
<contexts>
<context position="3875" citStr="Turunen and Hakulinen, 2000" startWordPosition="590" endWordPosition="593"> is divided over several agents that operate in parallel on the context model, each agent being dedicated to the generation of dialogue acts from one particular dimension in the taxonomy. This leads to the design of a number of so-called Di37 Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 37–45, Sydney, July 2006. c�2006 Association for Computational Linguistics alogue Act Agents, including e.g. a task-oriented agent, two feedback agents and an agent dealing with social obligations management. The multi-agent approach to dialogue management itself is not new: JASPIS (Turunen and Hakulinen, 2000; Salonen et al., 2004) is a multiagent framework for dialogue systems which allows for implementations of several agents for the same tasks, varying from input interpretation and output presentation to dialogue management. Depending on the situation, the agent that is most appropriate for a given task is selected in a process involving several so-called ’evaluators’. In JASPIS the multi-agent approach is aimed at flexibility and adaptiveness, while our approach focuses more on supporting multidimensionality in communication. In a very general sense, our dialogue management approach follows an</context>
</contexts>
<marker>Turunen, Hakulinen, 2000</marker>
<rawString>M. Turunen and J. Hakulinen. 2000. Jaspis – a framework for multilingual adaptive speech applications. In Sixth International Conference on Spoken Language Processing (ICSLP 2000), volume 2, pages 719–722.</rawString>
</citation>
<citation valid="false">
<title>A Example dialogues A.1 Example 1: greetings, answers and unc-answers</title>
<marker></marker>
<rawString>A Example dialogues A.1 Example 1: greetings, answers and unc-answers</rawString>
</citation>
<citation valid="false">
<title>U1: hallo, ik wilde graag weten wat rsi is (hello, I wanted to know what is rsi) [INIT-OPEN; INDWHQ, task-domain] S1: Hallo. Ik heb de volgende informatie gevonden: (repetitive strain injury) Algemene benaming voor (blijvende) beschadigingen aan het lichaam ten gevolge van langdurige, eentonige werkzaamheden.</title>
<marker></marker>
<rawString>U1: hallo, ik wilde graag weten wat rsi is (hello, I wanted to know what is rsi) [INIT-OPEN; INDWHQ, task-domain] S1: Hallo. Ik heb de volgende informatie gevonden: (repetitive strain injury) Algemene benaming voor (blijvende) beschadigingen aan het lichaam ten gevolge van langdurige, eentonige werkzaamheden.</rawString>
</citation>
<citation valid="false">
<title>I found the following information:...) [REACT-OPEN;</title>
<note>ANSWER, task-domain</note>
<marker></marker>
<rawString>(Hello. I found the following information:...) [REACT-OPEN; ANSWER, task-domain]</rawString>
</citation>
<citation valid="false">
<title>U2: wat moet ik doen als ik denk rsi te hebben (what should I do if I think I have RSI)</title>
<note>[WHQUESTION, task-domain]</note>
<marker></marker>
<rawString>U2: wat moet ik doen als ik denk rsi te hebben (what should I do if I think I have RSI) [WHQUESTION, task-domain]</rawString>
</citation>
<citation valid="false">
<title>S2: De volgende informatie levert mogelijk een antwoord op uw vraag: Ontspanning betekent minder stress, minder aangespannen spieren en dus minder kans op RSI. (The following information might answer your question:...)</title>
<marker></marker>
<rawString>S2: De volgende informatie levert mogelijk een antwoord op uw vraag: Ontspanning betekent minder stress, minder aangespannen spieren en dus minder kans op RSI. (The following information might answer your question:...)</rawString>
</citation>
<citation valid="false">
<title>U3: helpt ontspanning ook als ik eenmaal rsi heb (does relaxing help as well, once I have RSI) [YNQUESTION, task-domain] S3: Ik heb de volgende informatie gevonden: Behandelmethoden bij RSI Er zijn vele wegen die naar Rome leiden. Verbetering van de doorbloeding ... (I found the following information:...)</title>
<note>[ANSWER, task-domain]</note>
<marker></marker>
<rawString>[UNCANSWER, task-domain] U3: helpt ontspanning ook als ik eenmaal rsi heb (does relaxing help as well, once I have RSI) [YNQUESTION, task-domain] S3: Ik heb de volgende informatie gevonden: Behandelmethoden bij RSI Er zijn vele wegen die naar Rome leiden. Verbetering van de doorbloeding ... (I found the following information:...) [ANSWER, task-domain]</rawString>
</citation>
<citation valid="false">
<note>U4: oke, bedankt (okay, thanks) [INIT-CLOSE]</note>
<marker></marker>
<rawString>U4: oke, bedankt (okay, thanks) [INIT-CLOSE]</rawString>
</citation>
<citation valid="false">
<title>S4: tot ziens. U kunt de buttons gebruiken om te stoppen of om een nieuwe dialoog te beginnen.</title>
<marker></marker>
<rawString>S4: tot ziens. U kunt de buttons gebruiken om te stoppen of om een nieuwe dialoog te beginnen.</rawString>
</citation>
<citation valid="false">
<title>You may use the buttons to stop or to start a new dialogue.</title>
<marker></marker>
<rawString>(Goodbye. You may use the buttons to stop or to start a new dialogue.)</rawString>
</citation>
<citation valid="false">
<title>[REACT-CLOSE] A.2 Example 2: negative execution-feedback U1: hallo!</title>
<note>(hello!) [INIT-OPEN]</note>
<marker></marker>
<rawString>[REACT-CLOSE] A.2 Example 2: negative execution-feedback U1: hallo! (hello!) [INIT-OPEN]</rawString>
</citation>
<citation valid="false">
<authors>
<author>S1 Hallo</author>
</authors>
<title>Stel uw vraag.</title>
<note>(Hello. Ask your question.) [REACT-OPEN]</note>
<marker>Hallo, </marker>
<rawString>S1: Hallo. Stel uw vraag. (Hello. Ask your question.) [REACT-OPEN]</rawString>
</citation>
<citation valid="false">
<title>U2: wat kan ik als beelschermwerker tegen rugpijn doen (what can I, a person working behind a computer screen all the time, do against pain in the back) [WHQUESTION, task-domain]</title>
<marker></marker>
<rawString>U2: wat kan ik als beelschermwerker tegen rugpijn doen (what can I, a person working behind a computer screen all the time, do against pain in the back) [WHQUESTION, task-domain]</rawString>
</citation>
<citation valid="false">
<title>S2: Ik heb helaas geen antwoorden kunnen vinden; probeer de vraag te herformuleren.</title>
<marker></marker>
<rawString>S2: Ik heb helaas geen antwoorden kunnen vinden; probeer de vraag te herformuleren.</rawString>
</citation>
<citation valid="false">
<title>could notfind any answers; please try to reformulate the question</title>
<marker></marker>
<rawString>(Unfortunately, I could notfind any answers; please try to reformulate the question)</rawString>
</citation>
<citation valid="false">
<title>[NEGAUTOFB-EXEC] U3: wat kan men tegen rugpijn doen (what can be done against pain in the back) [WHQUESTION, task-domain] S3: ik heb de volgende informatie gevonden: Deze is afhankelijk van de oorzaak. Rugpijn die door instabiliteit of door tekortschietende spieren en banden ontstaat, kan behandeld worden met houdingscorrigerende oefentherapie. (Ifound the following information:...)</title>
<note>[ANSWER, task-domain]</note>
<marker></marker>
<rawString>[NEGAUTOFB-EXEC] U3: wat kan men tegen rugpijn doen (what can be done against pain in the back) [WHQUESTION, task-domain] S3: ik heb de volgende informatie gevonden: Deze is afhankelijk van de oorzaak. Rugpijn die door instabiliteit of door tekortschietende spieren en banden ontstaat, kan behandeld worden met houdingscorrigerende oefentherapie. (Ifound the following information:...) [ANSWER, task-domain]</rawString>
</citation>
<citation valid="false">
<note>U4: bedankt! (thanks!) [INIT-CLOSE]</note>
<marker></marker>
<rawString>U4: bedankt! (thanks!) [INIT-CLOSE]</rawString>
</citation>
<citation valid="false">
<title>S4: Tot ziens. U kunt de buttons gebruiken om te stoppen of om een nieuwe dialoog te beginnen.</title>
<marker></marker>
<rawString>S4: Tot ziens. U kunt de buttons gebruiken om te stoppen of om een nieuwe dialoog te beginnen.</rawString>
</citation>
<citation valid="false">
<authors>
<author>U</author>
</authors>
<title>may use the buttons to stop or to start a new dialogue.</title>
<marker>U, </marker>
<rawString>(Goodbye. U may use the buttons to stop or to start a new dialogue.)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>