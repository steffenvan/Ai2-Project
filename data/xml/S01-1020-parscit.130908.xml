<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000566">
<bodyText confidence="0.560966">
ClassifieroptimizationandcombinationintheEnglishallwords
task.
VeroniqueHosteandAnneKoolandWalterDaelemans
CNTS - Language Technology Group
</bodyText>
<affiliation confidence="0.627212">
University of Antwerp
</affiliation>
<address confidence="0.653145">
Universiteitsplein 1, 2610 Wilrijk
</address>
<email confidence="0.746437">
hoste@uia.ua.ac.be, kool@uia.ua.ac.be, daelem@uia.ua.ac.be
</email>
<note confidence="0.693547">
Proceedings of SENSEVAL-2, Preiss &amp; Yarowsky, eds., p. 83-86, 2001
</note>
<sectionHeader confidence="0.893411" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999782157894737">
We report on the use of machine learning tech-
niques for word sense disambiguation in the
English all words task of SENSEVAL2. The
task was to automatically assign the appropri-
ate sense to a possibly ambiguous word form
givenitscontext.A\wordexpert&amp;quot;approach
wasadopted,leadingtoasetofclassifiers,each
specializedinonesinglewordform-POScombi-
nation.Expertsconsistofmultipleclassifiers
trainedonSemcorusingtwotypesoflearn-
ingtechniques,viz.memory-basedlearningand
rule-induction.Throughoptimizationbycross-
validationoftheindividualclassifiersandthe
votingschemeforcombiningthem,thebest
possiblewordexpertwasdetermined.Results
showthatespeciallymemory-basedlearningin
aword-expertapproachisafeasiblemethodfor
unrestrictedword-sensedisambiguation,even
withlimitedtrainingdata.
</bodyText>
<sectionHeader confidence="0.994193" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970414634146">
We report on the use of machine learning,
especially memory-based learning and classi-
fier combination, for word sense disambiguation
(WSD) in the English all words task of SEN-
SEVAL2. WSD can be described as the prob-
lem of assigning the appropriate sense to a given
word in a given context. Machine learning tech-
niques show state-of-the-art accuracy on WSD,
e.g. memory-based learning (Ng and Lee, 1996;
Veenstra et al., 2000), decision lists (Yarowsky,
2000), and combination methods (Escudero et
al., 2000).
Results of the first SENSEVAL exercise for
English (Killgarriff and Rosenzweig, 2000), in
which only a restricted set of words had to be
disambiguated, showed that supervised learn-
ing systems outperform unsupervised ones, even
when little corpus training material was avail-
able. In our submission to SENSEVAL2, we in-
vestigated whether the supervised learning ap-
proach can be scaled to the all-words task. As a
back-offforword-tagpairsforwhichnoornot
enoughtrainingdatawasavailable,weusedthe
mostfrequentsenseintheWordNet1.7sense
lexicon(Fellbaum,1998)asdefaultclassifierin
thedisambiguationprocess.Sensedisambigua-
tionwasmainlyperformedbyamemory-based
learningclassifier.Alsotheuseofruleinduc-
tionwasexplored.Furthermore,theoutputsof
thesedifferentclassifierswerecombinedinorder
tostudytheusefulnessofdifferentvotingstrate-
gies.Resultsshowthatallclassifiersoutperform
theWordNetbaselineandthatmemory-based
learningcomparesfavorablytoruleinduction
anddifferentvotingstrategies.
In the remainder of this paper, we first out-
line the sense-disambiguation architecture used
in the experiments, and discuss the word ex-
pert approach and the optimization procedure.
Then we report on the generalization accuracy
achieved for the SENSEVAL2 test data.
</bodyText>
<sectionHeader confidence="0.992672" genericHeader="method">
2 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.540032">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999956142857143">
In the experiments, the Semcor corpus included
in WordNet1.6 was used as training corpus. In
the corpus, every word is linked to its appropri-
ate sense in the lexicon. Texts that were used
to create the semantic concordances were ex-
tracted from the Brown Corpus and then linked
tosensesintheWordNetlexicon.Thetraining
corpusconsistsof409,990wordforms,ofwhich
190,481 are sense-tagged. For each word form
in the corpus, a lemma and a part of speech is
given.
The test data in the English all words task
consist of three articles on different topics, with
at total of 2,473 words to be sense-tagged. For
</bodyText>
<figure confidence="0.988481">
ASSIGN SENSE
TEXT
Tokenization
Lemmatization
POS tagging
WordNet lookup
per word/POS
YES
above
threshold?
YES
senses?
more
NO
Local context
(word-lemma-POS)
Context keywords &gt; threshold +
keywords WN examples
Local context+
all context keywords
WORD EXPERT MODULE
WordNet
Ripper
TiMBL
TiMBL
TWO-LEVEL
CROSS-VALIDATION
Majority voting
Weighted Voting
NO
</figure>
<figureCaption confidence="0.611728">
Figure1:Disambiguationprocess.
</figureCaption>
<bodyText confidence="0.9951465">
boththetrainingandthetestcorpus,onlythe
wordformswereusedandtokenization,lemma-
tizationandPOS-taggingweredonewithour
ownsoftware.Forthepartofspeechtagging,
thememory-basedtaggerMBT(Daelemanset
al.,1996),trainedontheWallStreetJournal
corpusï¿½,wasused.Onthebasisofwordand
POSinformation,lemmatizationwasdonee.
</bodyText>
<subsectionHeader confidence="0.992995">
2.2 Word experts
</subsectionHeader>
<bodyText confidence="0.973918057142858">
After the preprocessing stage, WordNet1.7 was
used to guide the sense disambiguation pro-
cess. For every combination of a word form and
a POS, WordNet was consulted to determine
whether this combination had one or more pos-
sible senses. In case of only one possible sense
(about 20% of the test words), the appropriate
WordNet sense was assigned. In case of more
possible senses, a threshold of 11 occurrences
in the Semcor training data was determined.
For all words below this threshold, the most
frequent sense according to WordNet was as-
signed as sense-tag. For the other words, which
representmorethan60%ofthewordformsto
besense-tagged,wordexpertswerebuiltfor
eachwordform-POScombination,leadingto
568 word experts for the SENSEVAL2 test data.
These word experts consist of different
trained subcomponents (see Figure 1) which
&apos;ACL Data Collection Initiative CD-Rom 1, Septem-
ber 1991
With a memory-based lemmatizer trained by Antal
van den Bosch, see http://ilk.kub.nl/
makeuseofdifferentknowledge.
The first subcomponent is trained us-
ing TiMBL, a package containing several
memory-based learning algorithms and metrics
(Daelemans et al., 2000). It takes as input
a vector representing the local context of the
focus word in a window of three word forms to
the left and three to the right. For the focus
word, also the lemma and POS are provided.
For the context word forms, POS information is
given. E.g., the following is a training instance:
many JJ times NNS , , yet yet RB on
</bodyText>
<equation confidence="0.520236">
IN each JJ occasion NN yet%4:02:02::.
</equation>
<bodyText confidence="0.999230869565217">
During training, those instances are stored in
memory and during sense-tagging, the instance
most similar to that of the ambiguous word
and its context is selected and the associated
class is returned as sense-tag.
A second subcomponent of each word ex-
pert trained with TiMBL is trained with in-
formation about possible disambiguating con-
tent keywords in a context of three sentences.
The method used to extract these keywords for
each sense is based on the work of (Ng and
Lee, 1996). They determine the probability of
a sense s of a focus word f given keyword k by
dividing Ns;kloc (the number of occurrences of
a possible local context keyword k with a par-
ticular focus word-POS combination w with a
particularsenses)byNkloc(thenumberofoc-
currencesofapossiblelocalcontextkeyword
klocwithaparticularfocusword-POScombi-
nationwignoringitssense).Inaddition,we
alsotookintoaccountthefrequencyofapos-
siblekeywordinthecompletetrainingcorpus
Nkcorp.
</bodyText>
<equation confidence="0.428731">
p(sl k) = N8;kloc X ( )
Nkloc Nkcorp
</equation>
<bodyText confidence="0.999893482758621">
A word is a keyword for a given sense if (i) the
word occurs more than M1 times in that sense
s, where M1 is a predefined minimum number
of times and if (ii) p(slk) &gt; M2 for that sense s,
where M2 is some predefined minimum proba-
bility. Due to time restrictions M1 was not op-
timized by cross-validation, but arbitrarily set
to 3 and M2 to 0.001.
In addition to the keyword information ex-
tracted from the local context of the focus word,
possible disambiguating content words were also
extracted from the examples that accompany
the different sense definitions for a given focus
word in WordNet. For each combination of a
wordform,POSandsense,allcontentwords
wereextractedandaddedtotheinputvector
ofthememory-basedlearner.Boththecontex-
tualkeywordsandtheexamplekeywordswere
representedasbinaryfeatures,withavalueof
1 when the keyword was present in the example
and 0 if nota.
The third subcomponent of each word expert
was trained with Ripper (Cohen, 1995), a rule
learning algorithm, allowing both single-valued
and set-valued attributes. In our disambigua-
tion task, the ripper input vector contained lo-
cal context feature values (as the first TiMBL),
andaset-valuedfeaturewithallcontentwords
inacontextofthreesentences.
</bodyText>
<sectionHeader confidence="0.931048" genericHeader="method">
3 Optimization and Voting
</sectionHeader>
<bodyText confidence="0.9999912">
In order to improve the predictions of the dif-
ferent single learning algorithms, algorithm pa-
rameter optimization was performed where pos-
sible. Furthermore, the possible gain in accu-
racy of different voting strategies was explored.
</bodyText>
<subsectionHeader confidence="0.977217">
3.1 Optimization
</subsectionHeader>
<bodyText confidence="0.999819913043479">
For the first TiMBL memory-based learner,
backward sequential selection (BSS) (Aha and
3Since no length limitations were taken into account
when building these vectors, they could grow very large.
Therefore, a version of TiMBL was used that is opti-
mized for sparse binary features, and allows a positional
representation of the active keywords rather than a bi-
nary one, written by Jakub Zavrel.
Bankert,1994)wasperformedforeachword
form-POScombination.BSSstartsfromthe
complete feature set and generates in each iter-
ation new subsets by discarding a feature. The
feature string with the best performance is re-
tained. Furthermore, the use of different fea-
ture weighting possibilities was explored, viz.
gain ratio weighting, information gain weight-
ing, chi-squared weighting and shared variance
weighting.Foreachfeatureweightingpossi-
bility,thekvalue,representingthenumberof
nearestneighboursusedforextrapolation,was
variedbetween1and19.Leave-one-outwas
usedastestingmethod:testingwasdoneon
eachinstanceofthetrainingfile,whilethere-
mainderofthetrainingfilefunctionedastrain-
ingmaterial.
Due to the size of the feature vectors for
the second memory-based learner, which takes
content words from the surrounding sentences
and from the example sentences in the Word-
Net definitions as input, no feature selection
was performed. For the same reasons, 10-fold
cross-validationwasusedastestingmethod:the
trainingdatawassplitinto10differentparts
andineachiteration,onepartservedastest
set,whiletheremainderwasusedtotrainthe
classifier.Thekvaluewasvaried(1-19),dif-
ferentweightingtechniques(gainratioweight-
ing,chi-squaredweightingandloglikelihood
weighting)anddifferentdistancemetrics(num-
berofmismatches,numberofmatches,number
ofmatchesminusnumberofmismatches)were
explored.
For Ripper, the default parameter settings
were used, due to time constraints and the slow-
ness of the cross-validation process. 10-fold-
cross-validation was used as testing method.
</bodyText>
<subsectionHeader confidence="0.998661">
3.2 Voting
</subsectionHeader>
<bodyText confidence="0.998231083333333">
On the output of these three (optimized) classi-
fiers and the default WordNet1.7. most frequent
sense, both majority voting and weighted vot-
ing was performed. In case of majority voting,
each sense-tagger is given one vote and the tag
with most votes is selected. In weighted vot-
ing, more weight is given to the taggers with
ahigheroverallaccuracy.Incaseoftieswhen
votingovertheoutputof4classifiers,thefirst
decision(TiMBL)wastakenasoutputclass.
Votingwasalsoperformedontheoutputofthe
threelearningclassifierswithouttakingintoac-
</bodyText>
<table confidence="0.9972277">
Classifier no. WE
Default (WordNet1.7) 16
TiMBL (context) 155
TiMBL (keywords) 185
Ripper 16
Majority Voting 33
Weighted Voting 58
Majority Voting (no WordNet) 53
Weighted Voting (no WordNet) 52
568
</table>
<tableCaption confidence="0.640943">
Table 1: Best performing word experts on the
Semcor train set
count the WordNet class. Table 1 shows the
best performing classifiers per word form-POS
combination of the Semcor train set: both op-
timized memory-based learners outperform the
other classifiers.
</tableCaption>
<sectionHeader confidence="0.998486" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.776840681818182">
Table 2 shows the accuracy of our disambigua-
tion system on the English all words test set.
Since all 2,473 word forms were covered, no dis-
tinction is made between precision and recall.
An accuracy of 63.61% and 64.54% were ob-
tained according to the fine-grained and coarse-
grained SENSEVAL2 scoring, respectively. Just
as in the first SENSEVAL task for English (Kill-
garriff and Rosenzweig, 2000), top performance
was for the nouns. All 86 \unknown&amp;quot; word
forms, for which the test set annotators decided
that no WordNet1.7 sense-tag was applicable,
were obviously incorrectly classified.
key fine % coarse %
noun (%1) 1,067 74.51 75.45
verb (%2) 554 47.83 49.64
adj. (%3- 465 62.58 63.44
%5)
adv. (%2) 301 73.42 73.42
unkn. 86 0.00 0.00
total 2,473 63.61 64.54
Table2:ResultsontheSENSEVAL2testdata.
</bodyText>
<sectionHeader confidence="0.908875" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.939701363636364">
This paper reported on the architecture and the
results of the CNTS-Antwerp automatic disam-
biguation system in the context of the SENSE-
VAL2 English all words task. Disambiguation
perwordform-POSpairisperformedthrough
theapplicationofwordexpertstrainedonlocal
contextinformationandcross-validatedonthe
limitedavailabletrainingdata.Amongthese
wordexperts,optimizedmemory-basedlearning
provestobemoreaccuratethandefaultRipper
rule-inductionandvariousvotingstrategies.
</bodyText>
<sectionHeader confidence="0.978119" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998429666666667">
We like to thank Antal van den Bosch for taking
care of the lemmatization and Erik Tjong Kim
Sangforprogrammingsupport.
</bodyText>
<sectionHeader confidence="0.991686" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999892375">
D.W. Aha and R.L. Bankert. 1994. Feature selec-
tion for case-based classification of cloud types:
An empirical comparison. In Proceedings of the
1994 AAAI Workshop on Case-Based Reasoning,
pages 106{112. AAAI Press.
W.W. Cohen. 1995. Fast effective rule induction. In
Proc. 12th International Conference on Machine
Learning, pages 115{123. Morgan Kaufmann.
W. Daelemans, J. Zavrel, P. Berck, and S. Gillis.
1996. Mbt: A memory-based part of speech
tagger-generator. In E. Ejerhed and I. Dagan, ed-
itors, Fourth Workshop on Very Large Corpora,
pages 14{27.
W. Daelemans, J. Zavrel, K. van der Sloot, and
A. van den Bosch. 2000. Timbl: Tilburg mem-
ory based learner, version 3.0, reference guide.
G. Escudero, L. Marquez, and G. Rigau. 2000.
Boosting applied to word sense disambiguation.
In European Conference on Machine Learning,
pages 129{141.
C. Fellbaum. 1998. WordNet : An Electronic Lexi-
cal Database. MIT Press.
A. Killgarriff and J. Rosenzweig. 2000. English sen-
seval: Report and results. In Proceedings of the
2nd International Conference on Language Re-
sources and Evaluation, pages 1239{1243.
H.T. Ng and H.B. Lee. 1996. Integrating multiple
knowledge sources to disambiguate word sense:
An exemplar-based approach. In Arivind Joshi
and Martha Palmer, editors, Proceedings of the
Thirty-Fourth Annual Meeting of the Association
for Computational Linguistics, pages 40{47, San
Francisco. Morgan Kaufmann Publishers.
J. Veenstra, A. Van den Bosch, S. Buchholz,
W. Daelemans, and J. Zavrel. 2000. Memory-
based word sense disambiguation. Computers and
the Humanities, 34(1/2):171{177.
D. Yarowsky. 2000. Hierarchical decision lists for
word sense disambiguation. Computers and the
Humanities, 34(1/2):179{186.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.292027">
<title confidence="0.872542">ClassifieroptimizationandcombinationintheEnglishallwords</title>
<email confidence="0.564298">task.</email>
<affiliation confidence="0.9542705">CNTS - Language Technology University of</affiliation>
<address confidence="0.753207">Universiteitsplein 1, 2610</address>
<email confidence="0.843347">hoste@uia.ua.ac.be,kool@uia.ua.ac.be,daelem@uia.ua.ac.be</email>
<note confidence="0.981151">Proceedings of SENSEVAL-2, Preiss &amp; Yarowsky, eds., p. 83-86, 2001</note>
<abstract confidence="0.99502865">We report on the use of machine learning techniques for word sense disambiguation in the English all words task of SENSEVAL2. The task was to automatically assign the appropriate sense to a possibly ambiguous word form givenitscontext.A\wordexpert&amp;quot;approach wasadopted,leadingtoasetofclassifiers,each specializedinonesinglewordform-POScombination.Expertsconsistofmultipleclassifiers trainedonSemcorusingtwotypesoflearningtechniques,viz.memory-basedlearningand rule-induction.Throughoptimizationbycrossvalidationoftheindividualclassifiersandthe votingschemeforcombiningthem,thebest possiblewordexpertwasdetermined.Results showthatespeciallymemory-basedlearningin aword-expertapproachisafeasiblemethodfor unrestrictedword-sensedisambiguation,even withlimitedtrainingdata.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D W Aha</author>
<author>R L Bankert</author>
</authors>
<title>Feature selection for case-based classification of cloud types: An empirical comparison.</title>
<date>1994</date>
<booktitle>In Proceedings of the 1994 AAAI Workshop on Case-Based Reasoning,</booktitle>
<pages>106--112</pages>
<publisher>AAAI Press.</publisher>
<marker>Aha, Bankert, 1994</marker>
<rawString>D.W. Aha and R.L. Bankert. 1994. Feature selection for case-based classification of cloud types: An empirical comparison. In Proceedings of the 1994 AAAI Workshop on Case-Based Reasoning, pages 106{112. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W W Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Proc. 12th International Conference on Machine Learning,</booktitle>
<pages>115--123</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="7665" citStr="Cohen, 1995" startWordPosition="961" endWordPosition="962">01. In addition to the keyword information extracted from the local context of the focus word, possible disambiguating content words were also extracted from the examples that accompany the different sense definitions for a given focus word in WordNet. For each combination of a wordform,POSandsense,allcontentwords wereextractedandaddedtotheinputvector ofthememory-basedlearner.Boththecontextualkeywordsandtheexamplekeywordswere representedasbinaryfeatures,withavalueof 1 when the keyword was present in the example and 0 if nota. The third subcomponent of each word expert was trained with Ripper (Cohen, 1995), a rule learning algorithm, allowing both single-valued and set-valued attributes. In our disambiguation task, the ripper input vector contained local context feature values (as the first TiMBL), andaset-valuedfeaturewithallcontentwords inacontextofthreesentences. 3 Optimization and Voting In order to improve the predictions of the different single learning algorithms, algorithm parameter optimization was performed where possible. Furthermore, the possible gain in accuracy of different voting strategies was explored. 3.1 Optimization For the first TiMBL memory-based learner, backward sequenti</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>W.W. Cohen. 1995. Fast effective rule induction. In Proc. 12th International Conference on Machine Learning, pages 115{123. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>P Berck</author>
<author>S Gillis</author>
</authors>
<title>Mbt: A memory-based part of speech tagger-generator.</title>
<date>1996</date>
<booktitle>Fourth Workshop on Very Large Corpora,</booktitle>
<pages>14--27</pages>
<editor>In E. Ejerhed and I. Dagan, editors,</editor>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>W. Daelemans, J. Zavrel, P. Berck, and S. Gillis. 1996. Mbt: A memory-based part of speech tagger-generator. In E. Ejerhed and I. Dagan, editors, Fourth Workshop on Very Large Corpora, pages 14{27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>K van der Sloot</author>
<author>A van den Bosch</author>
</authors>
<title>Timbl: Tilburg memory based learner, version 3.0, reference guide.</title>
<date>2000</date>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2000</marker>
<rawString>W. Daelemans, J. Zavrel, K. van der Sloot, and A. van den Bosch. 2000. Timbl: Tilburg memory based learner, version 3.0, reference guide.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L Marquez</author>
<author>G Rigau</author>
</authors>
<title>Boosting applied to word sense disambiguation.</title>
<date>2000</date>
<booktitle>In European Conference on Machine Learning,</booktitle>
<pages>129--141</pages>
<contexts>
<context position="1623" citStr="Escudero et al., 2000" startWordPosition="160" endWordPosition="163">pertapproachisafeasiblemethodfor unrestrictedword-sensedisambiguation,even withlimitedtrainingdata. 1 Introduction We report on the use of machine learning, especially memory-based learning and classifier combination, for word sense disambiguation (WSD) in the English all words task of SENSEVAL2. WSD can be described as the problem of assigning the appropriate sense to a given word in a given context. Machine learning techniques show state-of-the-art accuracy on WSD, e.g. memory-based learning (Ng and Lee, 1996; Veenstra et al., 2000), decision lists (Yarowsky, 2000), and combination methods (Escudero et al., 2000). Results of the first SENSEVAL exercise for English (Killgarriff and Rosenzweig, 2000), in which only a restricted set of words had to be disambiguated, showed that supervised learning systems outperform unsupervised ones, even when little corpus training material was available. In our submission to SENSEVAL2, we investigated whether the supervised learning approach can be scaled to the all-words task. As a back-offforword-tagpairsforwhichnoornot enoughtrainingdatawasavailable,weusedthe mostfrequentsenseintheWordNet1.7sense lexicon(Fellbaum,1998)asdefaultclassifierin thedisambiguationprocess.</context>
</contexts>
<marker>Escudero, Marquez, Rigau, 2000</marker>
<rawString>G. Escudero, L. Marquez, and G. Rigau. 2000. Boosting applied to word sense disambiguation. In European Conference on Machine Learning, pages 129{141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet : An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet : An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Killgarriff</author>
<author>J Rosenzweig</author>
</authors>
<title>English senseval: Report and results.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation,</booktitle>
<pages>1239--1243</pages>
<contexts>
<context position="1710" citStr="Killgarriff and Rosenzweig, 2000" startWordPosition="172" endWordPosition="175">ithlimitedtrainingdata. 1 Introduction We report on the use of machine learning, especially memory-based learning and classifier combination, for word sense disambiguation (WSD) in the English all words task of SENSEVAL2. WSD can be described as the problem of assigning the appropriate sense to a given word in a given context. Machine learning techniques show state-of-the-art accuracy on WSD, e.g. memory-based learning (Ng and Lee, 1996; Veenstra et al., 2000), decision lists (Yarowsky, 2000), and combination methods (Escudero et al., 2000). Results of the first SENSEVAL exercise for English (Killgarriff and Rosenzweig, 2000), in which only a restricted set of words had to be disambiguated, showed that supervised learning systems outperform unsupervised ones, even when little corpus training material was available. In our submission to SENSEVAL2, we investigated whether the supervised learning approach can be scaled to the all-words task. As a back-offforword-tagpairsforwhichnoornot enoughtrainingdatawasavailable,weusedthe mostfrequentsenseintheWordNet1.7sense lexicon(Fellbaum,1998)asdefaultclassifierin thedisambiguationprocess.Sensedisambiguationwasmainlyperformedbyamemory-based learningclassifier.Alsotheuseofrul</context>
<context position="11547" citStr="Killgarriff and Rosenzweig, 2000" startWordPosition="1435" endWordPosition="1439">experts on the Semcor train set count the WordNet class. Table 1 shows the best performing classifiers per word form-POS combination of the Semcor train set: both optimized memory-based learners outperform the other classifiers. 4 Results Table 2 shows the accuracy of our disambiguation system on the English all words test set. Since all 2,473 word forms were covered, no distinction is made between precision and recall. An accuracy of 63.61% and 64.54% were obtained according to the fine-grained and coarsegrained SENSEVAL2 scoring, respectively. Just as in the first SENSEVAL task for English (Killgarriff and Rosenzweig, 2000), top performance was for the nouns. All 86 \unknown&amp;quot; word forms, for which the test set annotators decided that no WordNet1.7 sense-tag was applicable, were obviously incorrectly classified. key fine % coarse % noun (%1) 1,067 74.51 75.45 verb (%2) 554 47.83 49.64 adj. (%3- 465 62.58 63.44 %5) adv. (%2) 301 73.42 73.42 unkn. 86 0.00 0.00 total 2,473 63.61 64.54 Table2:ResultsontheSENSEVAL2testdata. 5 Conclusion This paper reported on the architecture and the results of the CNTS-Antwerp automatic disambiguation system in the context of the SENSEVAL2 English all words task. Disambiguation perwo</context>
</contexts>
<marker>Killgarriff, Rosenzweig, 2000</marker>
<rawString>A. Killgarriff and J. Rosenzweig. 2000. English senseval: Report and results. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, pages 1239{1243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>H B Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach.</title>
<date>1996</date>
<booktitle>In Arivind Joshi and Martha Palmer, editors, Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Francisco.</location>
<contexts>
<context position="1517" citStr="Ng and Lee, 1996" startWordPosition="145" endWordPosition="148">em,thebest possiblewordexpertwasdetermined.Results showthatespeciallymemory-basedlearningin aword-expertapproachisafeasiblemethodfor unrestrictedword-sensedisambiguation,even withlimitedtrainingdata. 1 Introduction We report on the use of machine learning, especially memory-based learning and classifier combination, for word sense disambiguation (WSD) in the English all words task of SENSEVAL2. WSD can be described as the problem of assigning the appropriate sense to a given word in a given context. Machine learning techniques show state-of-the-art accuracy on WSD, e.g. memory-based learning (Ng and Lee, 1996; Veenstra et al., 2000), decision lists (Yarowsky, 2000), and combination methods (Escudero et al., 2000). Results of the first SENSEVAL exercise for English (Killgarriff and Rosenzweig, 2000), in which only a restricted set of words had to be disambiguated, showed that supervised learning systems outperform unsupervised ones, even when little corpus training material was available. In our submission to SENSEVAL2, we investigated whether the supervised learning approach can be scaled to the all-words task. As a back-offforword-tagpairsforwhichnoornot enoughtrainingdatawasavailable,weusedthe m</context>
<context position="6216" citStr="Ng and Lee, 1996" startWordPosition="759" endWordPosition="762">ation is given. E.g., the following is a training instance: many JJ times NNS , , yet yet RB on IN each JJ occasion NN yet%4:02:02::. During training, those instances are stored in memory and during sense-tagging, the instance most similar to that of the ambiguous word and its context is selected and the associated class is returned as sense-tag. A second subcomponent of each word expert trained with TiMBL is trained with information about possible disambiguating content keywords in a context of three sentences. The method used to extract these keywords for each sense is based on the work of (Ng and Lee, 1996). They determine the probability of a sense s of a focus word f given keyword k by dividing Ns;kloc (the number of occurrences of a possible local context keyword k with a particular focus word-POS combination w with a particularsenses)byNkloc(thenumberofoccurrencesofapossiblelocalcontextkeyword klocwithaparticularfocusword-POScombinationwignoringitssense).Inaddition,we alsotookintoaccountthefrequencyofapossiblekeywordinthecompletetrainingcorpus Nkcorp. p(sl k) = N8;kloc X ( ) Nkloc Nkcorp A word is a keyword for a given sense if (i) the word occurs more than M1 times in that sense s, where M1</context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>H.T. Ng and H.B. Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach. In Arivind Joshi and Martha Palmer, editors, Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics, pages 40{47, San Francisco. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Veenstra</author>
<author>A Van den Bosch</author>
<author>S Buchholz</author>
<author>W Daelemans</author>
<author>J Zavrel</author>
</authors>
<title>Memorybased word sense disambiguation. Computers and the Humanities,</title>
<date>2000</date>
<pages>34--1</pages>
<marker>Veenstra, Van den Bosch, Buchholz, Daelemans, Zavrel, 2000</marker>
<rawString>J. Veenstra, A. Van den Bosch, S. Buchholz, W. Daelemans, and J. Zavrel. 2000. Memorybased word sense disambiguation. Computers and the Humanities, 34(1/2):171{177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Hierarchical decision lists for word sense disambiguation. Computers and the Humanities,</title>
<date>2000</date>
<pages>34--1</pages>
<contexts>
<context position="1574" citStr="Yarowsky, 2000" startWordPosition="155" endWordPosition="156">tespeciallymemory-basedlearningin aword-expertapproachisafeasiblemethodfor unrestrictedword-sensedisambiguation,even withlimitedtrainingdata. 1 Introduction We report on the use of machine learning, especially memory-based learning and classifier combination, for word sense disambiguation (WSD) in the English all words task of SENSEVAL2. WSD can be described as the problem of assigning the appropriate sense to a given word in a given context. Machine learning techniques show state-of-the-art accuracy on WSD, e.g. memory-based learning (Ng and Lee, 1996; Veenstra et al., 2000), decision lists (Yarowsky, 2000), and combination methods (Escudero et al., 2000). Results of the first SENSEVAL exercise for English (Killgarriff and Rosenzweig, 2000), in which only a restricted set of words had to be disambiguated, showed that supervised learning systems outperform unsupervised ones, even when little corpus training material was available. In our submission to SENSEVAL2, we investigated whether the supervised learning approach can be scaled to the all-words task. As a back-offforword-tagpairsforwhichnoornot enoughtrainingdatawasavailable,weusedthe mostfrequentsenseintheWordNet1.7sense lexicon(Fellbaum,199</context>
</contexts>
<marker>Yarowsky, 2000</marker>
<rawString>D. Yarowsky. 2000. Hierarchical decision lists for word sense disambiguation. Computers and the Humanities, 34(1/2):179{186.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>