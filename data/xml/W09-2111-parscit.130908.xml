<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.219915">
<title confidence="0.97006">
User Input and Interactions on Microsoft Research ESL Assistant
</title>
<author confidence="0.967591">
Claudia Leacock Michael Gamon Chris Brockett
</author>
<affiliation confidence="0.807907">
Butler Hill Group Microsoft Research Microsoft Research
</affiliation>
<address confidence="0.7361605">
P.O. Box 935 One Microsoft Way One Microsoft Way
Ridgefield, CT, 06877, USA Redmond, WA, 98052, USA Redmond, WA, 98052, USA
</address>
<email confidence="0.939867">
claudia.leacock@gmail.com mgamon@microsoft.com chrisbkt@microsoft.com
</email>
<sectionHeader confidence="0.993868" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992489823529412">
ESL Assistant is a prototype web-based writ-
ing-assistance tool that is being developed for
English Language Learners. The system fo-
cuses on types of errors that are typically
made by non-native writers of American Eng-
lish. A freely-available prototype was dep-
loyed in June 2008. User data from this
system are manually evaluated to identify
writing domain and measure system accuracy.
Combining the user log data with the eva-
luated rewrite suggestions enables us to de-
termine how effectively English language
learners are using the system, across rule
types and across writing domains. We find
that repeat users typically make informed
choices and can distinguish correct sugges-
tions from incorrect.
</bodyText>
<sectionHeader confidence="0.999126" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999905642857143">
Much current research in grammatical error detec-
tion and correction is focused on writing by Eng-
lish Language Learners (ELL). The Microsoft
Research ESL Assistant is a web-based proofread-
ing tool designed primarily for ELLs who are na-
tive speakers of East-Asian languages. Initial
system development was informed by pre-existing
ELL error corpora, which were used both to identi-
fy common ELL mistakes and to evaluate system
performance. These corpora, however, were
created from data collected under arguably artifi-
cial classroom or examination conditions, leaving
unresolved the more practical question as to
whether the ESL Assistant can actually help a per-
</bodyText>
<page confidence="0.982805">
73
</page>
<bodyText confidence="0.999922222222222">
son who produced the text to improve their English
language writing skills in course of more realistic
everyday writing tasks.
In June of 2008, a prototype version of this sys-
tem was made freely available as a web service1 .
Both the writing suggestions that visitors see and
the actions that they then take are recorded. As
these more realistic data begin to accumulate, we
can now begin to answer the above question.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997699954545455">
Language learner error correction techniques typi-
cally fall into either of two categories: rule-based
or data-driven. Eeg-Olofsson and Knutsson (2003)
report on a rule-based system that detects and cor-
rects preposition errors in non-native Swedish text.
Rule-based approaches have also been used to pre-
dict definiteness and indefiniteness of Japanese
noun phrases as a preprocessing step for Japanese
to English machine translation (Murata and Nagao
1993; Bond et al, 1994; Heine, 1998), a task that is
similar to the prediction of English articles. More
recently, data-driven approaches have gained
popularity and been applied to article prediction in
English (Knight and Chander 1994; Minnen et al,
2000; Turner and Charniak 2007), to an array of
Japanese learners’ errors in English (Izumi et al,
2003), to verb errors (Lee and Seneff, 2008), and
to article and preposition correction in texts written
by non-native ELLs (Han et al, 2004, 2006; Nagata
et al, 2005; Nagata et al, 2006; De Felice and Pul-
man, 2007; Chodorow et al, 2007; Gamon et al,
2008, 2009; Tetreault and Chodorow, 2008a).
</bodyText>
<footnote confidence="0.972696">
1 http://www.eslassistant.com
</footnote>
<note confidence="0.9956755">
Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.994431322580645">
Noun Related Articles (ML) We have just checked *the our stock.
(61%) life is *journey/a journey, travel it well!
I think it &apos;s *a/the best way to resolve issues like this.
Noun Number London is one of the most attractive *city/cities in the world.
You have to write down all the details of each *things/thing to do.
Conversion always takes a lot of *efforts/effort.
Noun Of Noun Please send the *feedback of customer/customer feedback to me by
mail.
Preposition Preposition (ML) I&apos;m *on home today, call me if you have a problem.
Related It seems ok and I did not pay much attention *on/to it.
(27%) Below is my contact, looking forward *your/to your response, thanks!
Verb and Preposition Ben is involved *this/in this transaction.
I should *to ask/ask a rhetorical question ...
But I’ll think *it/about it a second time.
Verb Related Gerund / Infinitive He got me *roll/to roll up my sleeve and make a fist.
(10%) (ML) On Saturday, I with my classmate went *eating/to eat.
After *get/getting a visa, I want to study in New York.
Auxiliary Verb (ML) To learn English we should *be speak/speak it as much as possible .
Hope you will *happy/be happy in Taiwan .
what *is/do you want to say?
Verb formation If yes, I will *attached/attach and resend to Geoff .
The time and setting are *display/displayed at the same time.
You had *order/ordered 3 items ... this time.
I am really *hope/hoping to visit UCLA.
Cognate/Verb Con- We cannot *image/imagine what the environment really is at the site
fusion of end user .
Irregular Verbs I *teached/taught him all the things that I know ...
Adj Adjective Confu- She is very *interesting/interested in the problem.
Related sions So *Korea/Korean Government is intensively fostering trade .
(2%) ... and it is *much/much more reliable than your Courier Service.
Adjective order Employing the *Chinese ancient/ancient Chinese proverb, that is ...
</table>
<tableCaption confidence="0.99972">
Table 1: ESL Assistant grammatical error modules. ML modules are machine learned.
</tableCaption>
<sectionHeader confidence="0.996237" genericHeader="method">
3 ESL Assistant
</sectionHeader>
<bodyText confidence="0.999904766666667">
ESL Assistant takes a hybrid approach that com-
bines statistical and rule-based techniques. Ma-
chine learning is used for those error types that are
difficult to identify and resolve without taking into
account complex contextual interactions, like ar-
ticle and preposition errors. Rule-based approaches
handle those error types that are amenable to simp-
ler solutions. For example, a regular expression is
sufficient for identifying when a modal is (incor-
rectly) followed by a tensed verb.
The output of all modules, both machine-learned
and rule-based, is filtered through a very large lan-
guage model. Only when the language model finds
that the likelihood of the suggested rewrite is suffi-
ciently larger than the original text is a suggestion
shown to the user. For a detailed description of
ESL Assistant’s architecture, see Gamon et al
(2008, 2009).
Although this and the systems cited in section 2
are designed to be used by non-native writers, sys-
tem performance is typically reported in relation to
native text – the prediction of a preposition, for
example, will ideally be consistent with usage in
native, edited text. An error is counted each time
the system predicts a token that differs from the
observed usage and a correct prediction is counted
each time the system predicts the usage that occurs
in the text. Although somewhat artificial, this ap-
proach to evaluation offers the advantages of being
fully automatable and having abundant quantities
</bodyText>
<page confidence="0.999001">
74
</page>
<figureCaption confidence="0.999677">
Figure 1: Screen shot of ESL Assistant
</figureCaption>
<bodyText confidence="0.997929230769231">
of edited data readily available. With respect to
prepositions and articles, the ESL Assistant&apos;s clas-
sifiers achieve state-of-the-art performance when
compared to results reported in the literature (Ga-
mon et al, 2008), inasmuch as comparison is possi-
ble when the systems are evaluated on different
samples of native text. For articles, the system had
86.76% accuracy as compared to 86.74% reported
by Turner and Charniak (2007), who have the most
recently reported results. For the harder problem of
prepositions, ESL Assistant’s accuracy is compara-
ble to those reported by Tetreault and Chodorow
(2008a) and De Felice and Pulman (2007).
</bodyText>
<subsectionHeader confidence="0.975059">
3.1 Error Types
</subsectionHeader>
<bodyText confidence="0.999893357142857">
The ELL grammatical errors that ESL Assistant
tries to correct were distilled from analysis of the
most frequent errors made in Chinese and Japanese
English language learner corpora (Gui and Yang,
2001; Izumi et al. 2004). The error types are shown
in Table 1: modules identified with ML are ma-
chine-learned, while the remaining modules are
rule-based. ESL Assistant does not attempt to iden-
tify those errors currently found by Microsoft
WordTM, such as subject/verb agreement.
ESL Assistant further contains a component to
help address lexical selection issues. Since this
module is currently undergoing major revision, we
will not report on the results here.
</bodyText>
<subsectionHeader confidence="0.999428">
3.2 System Development
</subsectionHeader>
<bodyText confidence="0.999778545454545">
Whereas evaluation on native writing is essential
for system development and enables us to compare
ESL Assistant performance with that of other re-
ported results, it tells us little about how the system
would perform when being used by its true target
audience – non-native speakers of English engaged
in real-life writing tasks. In this context, perfor-
mance measurement inevitably entails manual
evaluation, a process that is notoriously time con-
suming, costly and potentially error-prone. Human
inter-rater agreement is known to be problematic
</bodyText>
<page confidence="0.997866">
75
</page>
<bodyText confidence="0.999944181818182">
on this task: it is likely to be high in the case of
certain user error types, such as over-regularized
verb inflection (where the system suggests replac-
ing “writed” with “wrote”), but other error types
are difficult to evaluate, and much may hinge upon
who is performing the evaluation: Tetreault and
Chodorow (2008b) report that for the annotation of
preposition errors “using a single rater as a gold
standard, there is the potential to over- or under-
estimate precision by as much as 10%.”
With these caveats in mind, we employed a sin-
gle annotator to evaluate system performance on
native data from the 1-million-word Chinese
Learner’s of English corpus (Gui and Yang, 2001;
2003). Half of the corpus was utilized to inform
system development, while the remaining half was
held back for &amp;quot;unseen&amp;quot; evaluation. While the abso-
lute numbers for some modules are more reliable
than for others, the relative change in numbers
across evaluations has proven a beneficial
yardstick of improved or degraded performance in
the course of development.
</bodyText>
<subsectionHeader confidence="0.999731">
3.3 The User Interface and Data Collection
</subsectionHeader>
<bodyText confidence="0.999966322580645">
Figure 1 shows the ESL Assistant user interface.
When a visitor to the site types or pastes text into
the box provided and clicks the &amp;quot;Check&amp;quot; button,
the text is sent to a server for analysis. Any loca-
tions in the text that trigger an error flag are then
displayed as underscored with a wavy line (known
as a &amp;quot;squiggle&amp;quot;). If the user hovers the mouse over
a squiggle, one or more suggested rewrites are dis-
played in a dropdown list. Then, if the user hovers
over one of these suggestions, the system launches
parallel web searches for both original and rewrite
phrases in order to allow the user to compare real-
word examples found on the World Wide Web. To
accept a suggestion, the user clicks on the sug-
gested rewrite, and the text is emended. Each of
these actions, by both system and user, are logged
on the server.
Since being launched in June, 2008, ESL Assis-
tant has been visited over 100,000 times. Current-
ly, the web page is being viewed between one to
two thousand times every day. From these numbers
alone it seems safe to conclude that there is much
public interest in an ESL proofreading tool.
Fifty-three percent of visitors to the ESL Assis-
tant web site are from countries in East Asia – its
primary target audience – and an additional 15%
are from the United States. Brazil, Canada, Ger-
many, and the United Kingdom each account for
about 2% of the site’s visitors. Other countries
represented in the database each account for 1% or
less of all those who visit the site.
</bodyText>
<subsectionHeader confidence="0.998645">
3.4 Database of User Input
</subsectionHeader>
<bodyText confidence="0.999957071428572">
User data are collected so that system performance
can be evaluated on actual user input – as opposed
to running pre-existing learner corpora through the
system. User data provide invaluable insight into
which rewrite suggestions users spend time view-
ing, and what action they subsequently take on the
basis of those suggestions.
These data must be screened, since not all of the
textual material entered by users in the web site is
valid learner English language data. As with any
publicly deployed web service, we find that nu-
merous users will play with the system, entering
nonsense strings or copying text from elsewhere on
the website and pasting it into the text box.
To filter out the more obvious non-English data,
we eliminate input that contains, for example, no
alphabetic characters, no vowels/consonants in a
sentence, or no white space. “Sentences” consist-
ing of email subject lines are also removed, as are
all the data entered by the ESL Assistant develop-
ers themselves. Since people often enter the same
sentence many times within a session, we also re-
move repetitions of identical sentences within a
single session.
Approximately 90% of the people who have vi-
sited the web site visit it once and never return.
This behavior is far from unusual on the web,
where site visits may have no clear purpose beyond
idle curiosity. In addition, some proportion of visi-
tors may in reality be automated &amp;quot;bots&amp;quot; that can be
nearly indistinguishable from human visitors.
Nevertheless, we observe a significant number
of repeat visitors who return several times to use
the system to proofread email or other writing, and
these are the users that we are intrinsically interest-
ed in. To measure performance, we therefore de-
cided to evaluate on data collected from users who
logged on and entered plausibly English-like text
on at least four occasions. As of 2/10/2009, the
frequent user database contained 39,944 session-
unique sentences from 578 frequent users in 5,305
sessions.
</bodyText>
<page confidence="0.927016">
76
</page>
<bodyText confidence="0.999486705882353">
Data from these users were manually annotated
to identify writing domains as shown in Table 2.
Fifty-three percent of the data consists of people
proofreading email.2 The dominance of email data
is presumably due to an Outlook plug-in that is
available on the web site, and automates copying
email content into the tool. The non-technical do-
main consists of student essays, material posted on
a personal web site, or employees writing about
their company – for example, its history or
processes. The technical writing is largely confe-
rence papers or dissertations in the fields of, for
example, medicine and computer science. The
“other” category includes lists and resumes (a writ-
ing style that deliberately omits articles and gram-
matical subjects), as well as text copied from
online newspapers or other media and pasted in.
</bodyText>
<table confidence="0.999534">
Writing Domain Percent
Email 53%
Non-technical / essays 24%
Technical / scientific 14%
Other (lists, resumes, etc) 4%
Unrelated sentences 5%
</table>
<tableCaption confidence="0.99964">
Table 2: Writing domains of frequent users
</tableCaption>
<bodyText confidence="0.999485125">
Sessions categorized as “unrelated sentences” typi-
cally consist of a series of short, unrelated sen-
tences that each contain one or more errors. These
users are testing the system to see what it does.
While this is a legitimate use of any grammar
checker, the user is unlikely to be proofreading his
or her writing, so these data are excluded from
evaluation.
</bodyText>
<sectionHeader confidence="0.989099" genericHeader="method">
4 System Evaluation &amp; User Interactions
</sectionHeader>
<bodyText confidence="0.999870727272727">
We are manually evaluating the rewrite sugges-
tions that ESL Assistant generated in order to de-
termine both system accuracy and whether user
acceptances led to an improvement in their writing.
These categories are shown in Table 3. Note that
results reported for non-native text look very dif-
ferent from those reported for native text (dis-
cussed in Section 3) because of the neutral
categories which do not appear in the evaluation of
native text. Systems reporting 87% accuracy on
native text cannot achieve anything near that on
</bodyText>
<table confidence="0.999827095238095">
Evaluation Subcategory: Description
Good Correct flag: The correction fixes a
problem in the user input.
Neutral Both Good: The suggestion is a legiti-
mate alternative to well-formed original
input: I like working/to work.
Misdiagnosis: the original input con-
tained an error but the suggested rewrite
neither improves nor further degrades
the input: If you have fail machine on
hand.
Both Wrong: An error type is correctly
diagnosed but the suggested rewrite
does not correct the problem: can you
give me suggestion. (suggests the in-
stead of a)
Non-ascii: A non-ascii or text markup
character is in the immediate context.
Bad False Flag: The suggestion resulted in
an error or would otherwise lead to a
degradation over the original user input.
</table>
<tableCaption confidence="0.99978">
Table 3: Evaluation categories
</tableCaption>
<bodyText confidence="0.98409164">
non-native ELL text because almost one third of
the flags fall into a neutral category.
In 51% of the 39,944 frequent user sentences,
the system generated at least one grammatical error
flag, for a total of 17,832 flags. Thirteen percent of
the time, the user ignored the flags. The remaining
87% of the flags were inspected by the user, and of
those, the user looked at the suggested rewrites
without taking further action 31% of the time. For
28% of the flags, the user hovered over a sugges-
tion to trigger a parallel web search but did not
accept the proposed rewrite. Nevertheless, 41% of
inspected rewrites were accepted, causing the orig-
inal string in the text to be revised. Overall, the
users inspected about 15.5K suggested rewrites to
accept about 6.4K. A significant number of users
appear to be inspecting the suggested revisions and
making deliberate choices to accept or not accept.
The next question is: Are users making the right
choices? To help answer this question, 34% of the
user sessions have been manually evaluated for
system accuracy – a total of approximately 5.1K
grammatical error flags. For each error category
and for the three major writing domains, we:
2 These are anonymized to protect user privacy.
</bodyText>
<page confidence="0.966527">
77
</page>
<figure confidence="0.999822985507246">
Noun
Related
Modules
Preposition
Related
Modules
Verb
Related
Modules
469 suggestions
157 acceptances
Adjective
Related
Modules
3,017 suggestions
972 acceptances
1,465 suggestions
479 acceptances
125 suggestions
40 acceptances
Rewrite Suggestion Evaluation Accepted Suggestion
bad
24%
bad
6%
neut
28%
neut
32%
neut
32%
neut
39%
bad
23%
bad
16%
good
45%
good
good
56%
62%
good
37%
bad
11%
bad
13%
bad
3%
bad
9%
neut
26%
neut
28%
neut
42%
neut
25%
good
63%
good
72%
good
good
63%
45%
</figure>
<figureCaption confidence="0.995646">
Figure 2: User interactions by module category
</figureCaption>
<listItem confidence="0.9993896">
1. Calculated system accuracy for all flags,
regardless of user actions.
2. Calculated system accuracy for only those
rewrites that the user accepted
3. Compared the ratio of good to bad flags.
</listItem>
<bodyText confidence="0.9981236">
Results for the individual error categories are
shown in Figure 2. Users consistently accept a
greater proportion of good suggestions than they
do bad ones across all error categories. This is
most pronounced for the adjective-related modules,
where the overall rate of good suggestions im-
proved 17.6% after the user made the decision to
accept a suggestion, while the system’s false posi-
tive rate dropped 14.1% after the decision. For the
noun-related modules, the system’s most produc-
</bodyText>
<page confidence="0.986495">
78
</page>
<figure confidence="0.999858431372549">
Email
Domain
2,614 suggestions
772 acceptances
Non-Technical
Writing
Domain
Technical
Writing
Domain
1,437 suggestions
684 acceptances
1,069 suggestions
205 acceptances
Rewrite Suggestion Evaluation Accepted Suggestion
bad
15%
bad
12%
neutral
28%
neutral
32%
neutral
32%
bad
34%
good
56%
good
good
38%
53%
bad
10%
bad
9%
neutral
28%
neutral
34%
neutral
29%
bad
19%
good
56%
good
good
52%
63%
</figure>
<figureCaption confidence="0.999882">
Figure 3: User interactions by writing domain
</figureCaption>
<bodyText confidence="0.999956027777778">
tive modules, the overall good flag rate increased
by 7% while the false positive rate dropped 5%.
All differences in false positive rates are statistical-
ly significant in Wilcoxon’s signed-ranks test.
When all of the modules are evaluated across
the three major writing domains, shown in figure 3,
the same pattern of user discrimination between
good and bad flags holds. This is most evident in
the technical writing domain, where the overall
rate of good suggestions improved 13.2% after
accepting the suggestion and the false positive rate
dropped 15.1% after the decision. It is least marked
for the essay/nontechnical writing domain. Here
the overall good flag rate increased by only .3%
while the false positive rate dropped 1.6%. Again,
all of the differences in false positive rates are sta-
tistically significant in Wilcoxon’s signed-ranks
test. These findings are consistent with those for
the machine learned articles and prepositions mod-
ules in the email domain (Chodorow et al, under
review).
A probable explanation for the differences seen
across the domains is that those users who are
proofreading non-technical writing are, as a whole,
less proficient in English than the users who are
writing in the other domains. Users who are proof-
reading technical writing are typically writing a
dissertation or paper in English and therefore tend
to relatively fluent in the language. The email do-
main comprises people who are confident enough
in their English language skills to communicate
with colleagues and friends by email in English.
With the essay/non-technical writers, it often is not
clear who the intended audience is. If there is any
indication of audience, it is often an instructor. Us-
ers in this domain appear to be the least English-
</bodyText>
<page confidence="0.996576">
79
</page>
<bodyText confidence="0.999972833333333">
language proficient of the ESL Assistant users, so it
is unsurprising that they are less effective in dis-
criminating between good and bad flags than their
more proficient counterparts. Thus it appears that
those users who are most in need of the system are
being helped by it least – an important direction for
future work.
Finally, we look at whether the neutral flags,
which account for 29% of the total flags, have any
effect. The two neutral categories highlighted in
Table 3, flags that either misdiagnose the error or
that diagnose it but do not correct it, account for
74% of ESL Assistant’s neutral flags. Although
these suggested rewrites do not improve the sen-
tence, they do highlight an environment that con-
tains an error. The question is: What is the effect of
identifying an error when the rewrite doesn’t im-
prove the sentence?
To estimate this, we searched for cases where
ESL Assistant produced a neutral flag and, though
the user did not accept the suggestion, a revised
sentence that generated no flag was subsequently
submitted for analysis. For example, one user en-
tered: “This early morning i got a from head office
...”. ESL Assistant suggested deleting from, which
does not improve the sentence. Subsequently, in
the same session, the user submitted, “This early
morning I heard from the head office ...” In this
instance, the system correctly identified the loca-
tion of an error. Moreover, even though the sug-
gested rewrite was not a good solution, the
information was sufficient to enable the user to fix
the error on his or her own.
Out of 1,349 sentences with neutral suggestions
that were not accepted, we identified (using a
fuzzy match) 215 cases where the user voluntarily
modified the sentence so that it contained no flag,
without accepting the suggestion. In 44% of these
cases, the user had simply typed in the suggested
correction instead of accepting it – indicating that
true acceptance rates might be higher than we orig-
inally estimated. Sixteen percent of the time, the
sentence was revised but there remained an error
that the system failed to detect. In the other 40% of
cases, the voluntary revision improved the sen-
tence. It appears that merely pointing out the poss-
ible location of an error to the user is often
sufficient to be helpful.
</bodyText>
<sectionHeader confidence="0.9977" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999966944444444">
In conclusion, judging from the number of people
who have visited the ESL Assistant web site, there
is considerable interest in ESL proofreading tools
and services.
When using the tool to proofread text, users do
not accept the proposed corrections blindly – they
are selective in their behavior. More importantly,
they are making informed choices – they can dis-
tinguish correct suggestions from incorrect ones.
Sometimes identifying the location of an error,
even when the solution offered is wrong, itself ap-
pears sufficient to cause the user to repair a prob-
lem on his or her own. Finally, the user
interactions that we have recorded indicate that
current state-of-the-art grammatical error correc-
tion technology has reached a point where it can be
helpful to English language learners in real-world
contexts.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999276">
We thank Bill Dolan, Lucy Vanderwende, Jianfeng
Gao, Alexandre Klementiev and Dmitriy Belenko
for their contributions to the ESL Assistant system.
We are also grateful to the two reviewers of this
paper who provided valuable feedback.
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995421818181818">
Francis Bond, Kentaro Ogura, and Satoru Ikehara. 1994.
Countability and number in Japanese to English ma-
chine translation. In Proceedings of the 15th Confe-
rence on Computational Linguistics (pp. 32-38).
Kyoto, Japan.
Martin Chodorow, Michael Gamon, and Joel Tetreault.
Under review. The utility of grammatical error detec-
tion systems for English language learners: Feedback
and Assessment.
Martin Chodorow, Joel Tetreault, and Na-Rae Han.
2007. Detection of grammatical errors involving pre-
positions. In Proceedings of the Fourth ACL-
SIGSEM Workshop on Prepositions (pp. 25-30). Pra-
gue, Czech Republic.
Rachele De Felice and Stephen G. Pulman. 2007. Au-
tomatically acquiring models of preposition use. In
Proceedings of the Fourth ACL-SIGSEM Workshop
on Prepositions (pp. 45-50). Prague, Czech Republic.
Jens Eeg-Olofsson and Ola Knutsson. 2003. Automatic
grammar checking for second language learners – the
use of prepositions. Proceedings of NoDaLiDa 2003.
Reykjavik, Iceland.
</reference>
<page confidence="0.985443">
80
</page>
<reference confidence="0.999635051546392">
Michael Gamon, Jianfeng Gao, Chris Brockett, Alexan-
dre Klementiev, William B. Dolan, Dmitriy Belenko,
and Lucy Vanderwende. 2008. Using contextual
speller techniques and language modeling for ESL
error correction. In Proceedings of the Third Interna-
tional Joint Conference on Natural Language
Processing (pp. 449-455). Hyderabad, India.
Michael Gamon, Claudia Leacock, Chris Brockett, Wil-
liam B. Dolan, Jianfeng Gao, Dmitriy Belenko, and
Alexandre Klementiev. 2009. Using statistical tech-
niques and web search to correct ESL errors. To ap-
pear in CALICO Journal, Special Issue on Automatic
Analysis of Learner Language.
Shicun Gui and Huizhong Yan. 2001. Computer analy-
sis of Chinese learner English. Presentation at Hong
Kong University of Science and Technolo-
gy.http://lc.ust.hk/~centre/conf2001/keynote/subsect4
/yang.pdf.
Shicun Gui and Huizhong Yang. (Eds.). 2003. Zhong-
guo Xuexizhe Yingyu Yuliaohu. (Chinese Learner
English Corpus). Shanghai Waiyu Jiaoyu Chubanshe.
(In Chinese).
Na-Rae Han, Martin Chodorow, and Claudia Leacock
2004). Detecting errors in English article usage with
a maximum entropy classifier trained on a large, di-
verse corpus. In Proceedings of the 4th Interna-
tional Conference on Language Resources and
Evaluation. Lisbon, Portugal.
Na-Rae Han, Martin Chodorow, and Claudia Leacock
2006. Detecting errors in English article usage by
non-native speakers. Natural Language Engineer-
ing, 12(2), 115-129.
Julia E. Heine. 1998. Definiteness predictions for Japa-
nese noun phrases. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics (pp. 519-525). Montreal,
Canada.
Emi Izumi, Kiyotaka Uchimoto, Toyomi Saiga, Thep-
chai Supnithi, and Hitoshi Isahara. 2003. Automatic
error detection in the Japanese learners&apos; English spo-
ken data. In Proceedings of the 41st Annual Meeting
of the Association for Computational Linguistics (pp.
145-148). Sapporo, Japan.
Kevin Knight and Ishwar Chander,. 1994. Automatic
postediting of documents. In Proceedings of the 12th
National Conference on Artificial Intelligence (pp.
779-784). Seattle: WA.
John Lee. 2004. Automatic article restoration. In Pro-
ceedings of the Human Language Technology Confe-
rence of the North American Chapter of the
Association for Computational Linguistics (pp. 31-
36). Boston, MA.
John Lee and Stephanie Seneff. 2008. Correcting mi-
suse of verb forms. In Proceedings of ACl-08/HLT
(pp. 174-182). Columbus, OH.
Guido Minnen, Francis Bond, and Anne Copestake.
2000. Memory-based learning for article generation.
In Proceedings of the Fourth Conference on Compu-
tational Natural Language Learning and of the
Second Learning Language in Logic Workshop (pp.
43-48). Lisbon, Portugal.
Masaki Murata and Makoto Nagao. 1993. Determina-
tion of referential property and number of nouns in
Japanese sentences for machine translation into Eng-
lish. In Proceedings of the Fifth International Confe-
rence on Theoretical and Methodological Issues in
Machine Translation (pp. 218-225). Kyoto, Japan.
Ryo Nagata, Takahiro Wakana, Fumito Masui, Atsui
Kawai, and Naoki Isu. 2005. Detecting article errors
based on the mass count distinction. In R. Dale, W.
Kam-Fie, J. Su and O.Y. Kwong (Eds.) Natural Lan-
guage Processing - IJCNLP 2005, Second Interna-
tional Joint Conference Proceedings (pp. 815-826).
New York: Springer.
Ryo Nagata, Atsuo Kawai, Koichiro Morihiro, and
Naoki Isu. 2006. A feedback-augmented method for
detecting errors in the writing of learners of English.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics
(pp. 241-248). Sydney, Australia.
Joel Tetreault and Martin Chodorow. 2008a. The ups
and downs of preposition error detection in ESL.
COLING. Manchester, UK.
Joel Tetreault and Martin Chodorow. 2008b. Native
judgments of non-native usage: Experiments in pre-
position error detection. In Proceedings of the Work-
shop on Human Judgments in Computational
Linguistics, 22nd International Conference on Com-
putational Linguistics (pp 43-48). Manchester, UK.
Jenine Turner and Eugene Charniak. 2007. Language
modeling for determiner selection. In Human Lan-
guage Technologies 2007: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics; Companion Volume, Short
Papers (pp. 177-180). Rochester, NY.
</reference>
<page confidence="0.99926">
81
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.441755">
<title confidence="0.997511">Input and Interactions on Research ESL Assistant</title>
<author confidence="0.998102">Claudia Leacock Michael Gamon Chris Brockett</author>
<affiliation confidence="0.521577">Butler Hill Group Microsoft Research Microsoft Research</affiliation>
<address confidence="0.9939785">P.O. Box 935 One Microsoft Way One Microsoft Way Ridgefield, CT, 06877, USA Redmond, WA, 98052, USA Redmond, WA, 98052, USA</address>
<email confidence="0.99922">claudia.leacock@gmail.commgamon@microsoft.comchrisbkt@microsoft.com</email>
<abstract confidence="0.991918444444445">Assistant a prototype web-based writing-assistance tool that is being developed for English Language Learners. The system focuses on types of errors that are typically made by non-native writers of American English. A freely-available prototype was deployed in June 2008. User data from this system are manually evaluated to identify writing domain and measure system accuracy. Combining the user log data with the evaluated rewrite suggestions enables us to determine how effectively English language learners are using the system, across rule types and across writing domains. We find that repeat users typically make informed choices and can distinguish correct suggestions from incorrect.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Francis Bond</author>
<author>Kentaro Ogura</author>
<author>Satoru Ikehara</author>
</authors>
<title>Countability and number in Japanese to English machine translation.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th Conference on Computational Linguistics</booktitle>
<pages>32--38</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="2651" citStr="Bond et al, 1994" startWordPosition="403" endWordPosition="406">at they then take are recorded. As these more realistic data begin to accumulate, we can now begin to answer the above question. 2 Related Work Language learner error correction techniques typically fall into either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault</context>
</contexts>
<marker>Bond, Ogura, Ikehara, 1994</marker>
<rawString>Francis Bond, Kentaro Ogura, and Satoru Ikehara. 1994. Countability and number in Japanese to English machine translation. In Proceedings of the 15th Conference on Computational Linguistics (pp. 32-38). Kyoto, Japan.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Martin Chodorow</author>
<author>Michael Gamon</author>
<author>Joel Tetreault</author>
</authors>
<title>Under review. The utility of grammatical error detection systems for English language learners: Feedback and Assessment.</title>
<marker>Chodorow, Gamon, Tetreault, </marker>
<rawString>Martin Chodorow, Michael Gamon, and Joel Tetreault. Under review. The utility of grammatical error detection systems for English language learners: Feedback and Assessment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Joel Tetreault</author>
<author>Na-Rae Han</author>
</authors>
<title>Detection of grammatical errors involving prepositions.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth ACLSIGSEM Workshop on Prepositions</booktitle>
<pages>25--30</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3215" citStr="Chodorow et al, 2007" startWordPosition="498" endWordPosition="501">ine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world. You have to write down all the details of each *things/thing to do. </context>
</contexts>
<marker>Chodorow, Tetreault, Han, 2007</marker>
<rawString>Martin Chodorow, Joel Tetreault, and Na-Rae Han. 2007. Detection of grammatical errors involving prepositions. In Proceedings of the Fourth ACLSIGSEM Workshop on Prepositions (pp. 25-30). Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachele De Felice</author>
<author>Stephen G Pulman</author>
</authors>
<title>Automatically acquiring models of preposition use.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth ACL-SIGSEM Workshop on Prepositions</booktitle>
<pages>45--50</pages>
<location>Prague, Czech Republic.</location>
<marker>De Felice, Pulman, 2007</marker>
<rawString>Rachele De Felice and Stephen G. Pulman. 2007. Automatically acquiring models of preposition use. In Proceedings of the Fourth ACL-SIGSEM Workshop on Prepositions (pp. 45-50). Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Eeg-Olofsson</author>
<author>Ola Knutsson</author>
</authors>
<title>Automatic grammar checking for second language learners – the use of prepositions.</title>
<date>2003</date>
<booktitle>Proceedings of NoDaLiDa 2003. Reykjavik,</booktitle>
<contexts>
<context position="2329" citStr="Eeg-Olofsson and Knutsson (2003)" startWordPosition="353" endWordPosition="356">her the ESL Assistant can actually help a per73 son who produced the text to improve their English language writing skills in course of more realistic everyday writing tasks. In June of 2008, a prototype version of this system was made freely available as a web service1 . Both the writing suggestions that visitors see and the actions that they then take are recorded. As these more realistic data begin to accumulate, we can now begin to answer the above question. 2 Related Work Language learner error correction techniques typically fall into either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of J</context>
</contexts>
<marker>Eeg-Olofsson, Knutsson, 2003</marker>
<rawString>Jens Eeg-Olofsson and Ola Knutsson. 2003. Automatic grammar checking for second language learners – the use of prepositions. Proceedings of NoDaLiDa 2003. Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Jianfeng Gao</author>
<author>Chris Brockett</author>
<author>Alexandre Klementiev</author>
<author>William B Dolan</author>
<author>Dmitriy Belenko</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Using contextual speller techniques and language modeling for ESL error correction.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Joint Conference on Natural Language Processing</booktitle>
<pages>449--455</pages>
<location>Hyderabad, India.</location>
<contexts>
<context position="3234" citStr="Gamon et al, 2008" startWordPosition="502" endWordPosition="505">a and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world. You have to write down all the details of each *things/thing to do. Conversion always t</context>
<context position="6325" citStr="Gamon et al (2008" startWordPosition="1004" endWordPosition="1007">al interactions, like article and preposition errors. Rule-based approaches handle those error types that are amenable to simpler solutions. For example, a regular expression is sufficient for identifying when a modal is (incorrectly) followed by a tensed verb. The output of all modules, both machine-learned and rule-based, is filtered through a very large language model. Only when the language model finds that the likelihood of the suggested rewrite is sufficiently larger than the original text is a suggestion shown to the user. For a detailed description of ESL Assistant’s architecture, see Gamon et al (2008, 2009). Although this and the systems cited in section 2 are designed to be used by non-native writers, system performance is typically reported in relation to native text – the prediction of a preposition, for example, will ideally be consistent with usage in native, edited text. An error is counted each time the system predicts a token that differs from the observed usage and a correct prediction is counted each time the system predicts the usage that occurs in the text. Although somewhat artificial, this approach to evaluation offers the advantages of being fully automatable and having abu</context>
</contexts>
<marker>Gamon, Gao, Brockett, Klementiev, Dolan, Belenko, Vanderwende, 2008</marker>
<rawString>Michael Gamon, Jianfeng Gao, Chris Brockett, Alexandre Klementiev, William B. Dolan, Dmitriy Belenko, and Lucy Vanderwende. 2008. Using contextual speller techniques and language modeling for ESL error correction. In Proceedings of the Third International Joint Conference on Natural Language Processing (pp. 449-455). Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Claudia Leacock</author>
<author>Chris Brockett</author>
<author>William B Dolan</author>
<author>Jianfeng Gao</author>
<author>Dmitriy Belenko</author>
<author>Alexandre Klementiev</author>
</authors>
<title>Using statistical techniques and web search to correct ESL errors.</title>
<date>2009</date>
<journal>CALICO Journal, Special Issue on Automatic Analysis of Learner Language.</journal>
<note>To appear in</note>
<marker>Gamon, Leacock, Brockett, Dolan, Gao, Belenko, Klementiev, 2009</marker>
<rawString>Michael Gamon, Claudia Leacock, Chris Brockett, William B. Dolan, Jianfeng Gao, Dmitriy Belenko, and Alexandre Klementiev. 2009. Using statistical techniques and web search to correct ESL errors. To appear in CALICO Journal, Special Issue on Automatic Analysis of Learner Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shicun Gui</author>
<author>Huizhong Yan</author>
</authors>
<title>Computer analysis of Chinese learner English. Presentation at Hong Kong</title>
<date>2001</date>
<booktitle>University of Science and Technology.http://lc.ust.hk/~centre/conf2001/keynote/subsect4 /yang.pdf.</booktitle>
<marker>Gui, Yan, 2001</marker>
<rawString>Shicun Gui and Huizhong Yan. 2001. Computer analysis of Chinese learner English. Presentation at Hong Kong University of Science and Technology.http://lc.ust.hk/~centre/conf2001/keynote/subsect4 /yang.pdf.</rawString>
</citation>
<citation valid="true">
<title>Zhongguo Xuexizhe Yingyu Yuliaohu. (Chinese Learner English Corpus). Shanghai Waiyu Jiaoyu Chubanshe. (In Chinese).</title>
<date>2003</date>
<contexts>
<context position="2329" citStr="(2003)" startWordPosition="356" endWordPosition="356">actually help a per73 son who produced the text to improve their English language writing skills in course of more realistic everyday writing tasks. In June of 2008, a prototype version of this system was made freely available as a web service1 . Both the writing suggestions that visitors see and the actions that they then take are recorded. As these more realistic data begin to accumulate, we can now begin to answer the above question. 2 Related Work Language learner error correction techniques typically fall into either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of J</context>
</contexts>
<marker>2003</marker>
<rawString>Shicun Gui and Huizhong Yang. (Eds.). 2003. Zhongguo Xuexizhe Yingyu Yuliaohu. (Chinese Learner English Corpus). Shanghai Waiyu Jiaoyu Chubanshe. (In Chinese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>Detecting errors in English article usage with a maximum entropy classifier trained on a large, diverse corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3119" citStr="Han et al, 2004" startWordPosition="479" endWordPosition="482">ndefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive</context>
</contexts>
<marker>Han, Chodorow, Leacock, 2004</marker>
<rawString>Na-Rae Han, Martin Chodorow, and Claudia Leacock 2004). Detecting errors in English article usage with a maximum entropy classifier trained on a large, diverse corpus. In Proceedings of the 4th International Conference on Language Resources and Evaluation. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>Detecting errors in English article usage by non-native speakers.</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>2</issue>
<pages>115--129</pages>
<marker>Han, Chodorow, Leacock, 2006</marker>
<rawString>Na-Rae Han, Martin Chodorow, and Claudia Leacock 2006. Detecting errors in English article usage by non-native speakers. Natural Language Engineering, 12(2), 115-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia E Heine</author>
</authors>
<title>Definiteness predictions for Japanese noun phrases.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</booktitle>
<pages>519--525</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2665" citStr="Heine, 1998" startWordPosition="407" endWordPosition="408">are recorded. As these more realistic data begin to accumulate, we can now begin to answer the above question. 2 Related Work Language learner error correction techniques typically fall into either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow,</context>
</contexts>
<marker>Heine, 1998</marker>
<rawString>Julia E. Heine. 1998. Definiteness predictions for Japanese noun phrases. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (pp. 519-525). Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emi Izumi</author>
<author>Kiyotaka Uchimoto</author>
<author>Toyomi Saiga</author>
<author>Thepchai Supnithi</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Automatic error detection in the Japanese learners&apos; English spoken data.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>145--148</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2984" citStr="Izumi et al, 2003" startWordPosition="456" endWordPosition="459">etects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey</context>
</contexts>
<marker>Izumi, Uchimoto, Saiga, Supnithi, Isahara, 2003</marker>
<rawString>Emi Izumi, Kiyotaka Uchimoto, Toyomi Saiga, Thepchai Supnithi, and Hitoshi Isahara. 2003. Automatic error detection in the Japanese learners&apos; English spoken data. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (pp. 145-148). Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Ishwar Chander</author>
</authors>
<title>Automatic postediting of documents.</title>
<date>1994</date>
<booktitle>In Proceedings of the 12th National Conference on Artificial Intelligence</booktitle>
<pages>779--784</pages>
<location>Seattle: WA.</location>
<contexts>
<context position="2864" citStr="Knight and Chander 1994" startWordPosition="435" endWordPosition="438">to either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Associat</context>
</contexts>
<marker>Knight, Chander, 1994</marker>
<rawString>Kevin Knight and Ishwar Chander,. 1994. Automatic postediting of documents. In Proceedings of the 12th National Conference on Artificial Intelligence (pp. 779-784). Seattle: WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
</authors>
<title>Automatic article restoration.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</booktitle>
<pages>31--36</pages>
<location>Boston, MA.</location>
<marker>Lee, 2004</marker>
<rawString>John Lee. 2004. Automatic article restoration. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (pp. 31-36). Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Stephanie Seneff</author>
</authors>
<title>Correcting misuse of verb forms.</title>
<date>2008</date>
<booktitle>In Proceedings of ACl-08/HLT</booktitle>
<pages>174--182</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="3023" citStr="Lee and Seneff, 2008" startWordPosition="463" endWordPosition="466">rs in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it </context>
</contexts>
<marker>Lee, Seneff, 2008</marker>
<rawString>John Lee and Stephanie Seneff. 2008. Correcting misuse of verb forms. In Proceedings of ACl-08/HLT (pp. 174-182). Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>Francis Bond</author>
<author>Anne Copestake</author>
</authors>
<title>Memory-based learning for article generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fourth Conference on Computational Natural Language Learning and of the Second Learning Language in Logic Workshop</booktitle>
<pages>43--48</pages>
<location>Lisbon,</location>
<contexts>
<context position="2884" citStr="Minnen et al, 2000" startWordPosition="439" endWordPosition="442">es: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computationa</context>
</contexts>
<marker>Minnen, Bond, Copestake, 2000</marker>
<rawString>Guido Minnen, Francis Bond, and Anne Copestake. 2000. Memory-based learning for article generation. In Proceedings of the Fourth Conference on Computational Natural Language Learning and of the Second Learning Language in Logic Workshop (pp. 43-48). Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Makoto Nagao</author>
</authors>
<title>Determination of referential property and number of nouns in Japanese sentences for machine translation into English.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation</booktitle>
<pages>218--225</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="2633" citStr="Murata and Nagao 1993" startWordPosition="399" endWordPosition="402"> see and the actions that they then take are recorded. As these more realistic data begin to accumulate, we can now begin to answer the above question. 2 Related Work Language learner error correction techniques typically fall into either of two categories: rule-based or data-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 200</context>
</contexts>
<marker>Murata, Nagao, 1993</marker>
<rawString>Masaki Murata and Makoto Nagao. 1993. Determination of referential property and number of nouns in Japanese sentences for machine translation into English. In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (pp. 218-225). Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Nagata</author>
<author>Takahiro Wakana</author>
<author>Fumito Masui</author>
<author>Atsui Kawai</author>
<author>Naoki Isu</author>
</authors>
<title>Detecting article errors based on the mass count distinction. In</title>
<date>2005</date>
<booktitle>Kwong (Eds.) Natural Language Processing - IJCNLP 2005, Second International Joint Conference Proceedings</booktitle>
<pages>815--826</pages>
<publisher>Springer.</publisher>
<location>New York:</location>
<contexts>
<context position="3145" citStr="Nagata et al, 2005" startWordPosition="484" endWordPosition="487">se noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world</context>
</contexts>
<marker>Nagata, Wakana, Masui, Kawai, Isu, 2005</marker>
<rawString>Ryo Nagata, Takahiro Wakana, Fumito Masui, Atsui Kawai, and Naoki Isu. 2005. Detecting article errors based on the mass count distinction. In R. Dale, W. Kam-Fie, J. Su and O.Y. Kwong (Eds.) Natural Language Processing - IJCNLP 2005, Second International Joint Conference Proceedings (pp. 815-826). New York: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Nagata</author>
<author>Atsuo Kawai</author>
<author>Koichiro Morihiro</author>
<author>Naoki Isu</author>
</authors>
<title>A feedback-augmented method for detecting errors in the writing of learners of English.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>241--248</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3165" citStr="Nagata et al, 2006" startWordPosition="488" endWordPosition="491"> preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world. You have to write </context>
</contexts>
<marker>Nagata, Kawai, Morihiro, Isu, 2006</marker>
<rawString>Ryo Nagata, Atsuo Kawai, Koichiro Morihiro, and Naoki Isu. 2006. A feedback-augmented method for detecting errors in the writing of learners of English. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (pp. 241-248). Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>The ups and downs of preposition error detection in ESL.</title>
<date>2008</date>
<publisher>COLING. Manchester, UK.</publisher>
<contexts>
<context position="3270" citStr="Tetreault and Chodorow, 2008" startWordPosition="507" endWordPosition="510"> al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world. You have to write down all the details of each *things/thing to do. Conversion always takes a lot of *efforts/effort. Noun </context>
<context position="7586" citStr="Tetreault and Chodorow (2008" startWordPosition="1206" endWordPosition="1209">een shot of ESL Assistant of edited data readily available. With respect to prepositions and articles, the ESL Assistant&apos;s classifiers achieve state-of-the-art performance when compared to results reported in the literature (Gamon et al, 2008), inasmuch as comparison is possible when the systems are evaluated on different samples of native text. For articles, the system had 86.76% accuracy as compared to 86.74% reported by Turner and Charniak (2007), who have the most recently reported results. For the harder problem of prepositions, ESL Assistant’s accuracy is comparable to those reported by Tetreault and Chodorow (2008a) and De Felice and Pulman (2007). 3.1 Error Types The ELL grammatical errors that ESL Assistant tries to correct were distilled from analysis of the most frequent errors made in Chinese and Japanese English language learner corpora (Gui and Yang, 2001; Izumi et al. 2004). The error types are shown in Table 1: modules identified with ML are machine-learned, while the remaining modules are rule-based. ESL Assistant does not attempt to identify those errors currently found by Microsoft WordTM, such as subject/verb agreement. ESL Assistant further contains a component to help address lexical sel</context>
<context position="9186" citStr="Tetreault and Chodorow (2008" startWordPosition="1459" endWordPosition="1462">ts true target audience – non-native speakers of English engaged in real-life writing tasks. In this context, performance measurement inevitably entails manual evaluation, a process that is notoriously time consuming, costly and potentially error-prone. Human inter-rater agreement is known to be problematic 75 on this task: it is likely to be high in the case of certain user error types, such as over-regularized verb inflection (where the system suggests replacing “writed” with “wrote”), but other error types are difficult to evaluate, and much may hinge upon who is performing the evaluation: Tetreault and Chodorow (2008b) report that for the annotation of preposition errors “using a single rater as a gold standard, there is the potential to over- or underestimate precision by as much as 10%.” With these caveats in mind, we employed a single annotator to evaluate system performance on native data from the 1-million-word Chinese Learner’s of English corpus (Gui and Yang, 2001; 2003). Half of the corpus was utilized to inform system development, while the remaining half was held back for &amp;quot;unseen&amp;quot; evaluation. While the absolute numbers for some modules are more reliable than for others, the relative change in nu</context>
</contexts>
<marker>Tetreault, Chodorow, 2008</marker>
<rawString>Joel Tetreault and Martin Chodorow. 2008a. The ups and downs of preposition error detection in ESL. COLING. Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>Native judgments of non-native usage: Experiments in preposition error detection.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Human Judgments in Computational Linguistics, 22nd International Conference on Computational Linguistics (pp</booktitle>
<pages>43--48</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="3270" citStr="Tetreault and Chodorow, 2008" startWordPosition="507" endWordPosition="510"> al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related Articles (ML) We have just checked *the our stock. (61%) life is *journey/a journey, travel it well! I think it &apos;s *a/the best way to resolve issues like this. Noun Number London is one of the most attractive *city/cities in the world. You have to write down all the details of each *things/thing to do. Conversion always takes a lot of *efforts/effort. Noun </context>
<context position="7586" citStr="Tetreault and Chodorow (2008" startWordPosition="1206" endWordPosition="1209">een shot of ESL Assistant of edited data readily available. With respect to prepositions and articles, the ESL Assistant&apos;s classifiers achieve state-of-the-art performance when compared to results reported in the literature (Gamon et al, 2008), inasmuch as comparison is possible when the systems are evaluated on different samples of native text. For articles, the system had 86.76% accuracy as compared to 86.74% reported by Turner and Charniak (2007), who have the most recently reported results. For the harder problem of prepositions, ESL Assistant’s accuracy is comparable to those reported by Tetreault and Chodorow (2008a) and De Felice and Pulman (2007). 3.1 Error Types The ELL grammatical errors that ESL Assistant tries to correct were distilled from analysis of the most frequent errors made in Chinese and Japanese English language learner corpora (Gui and Yang, 2001; Izumi et al. 2004). The error types are shown in Table 1: modules identified with ML are machine-learned, while the remaining modules are rule-based. ESL Assistant does not attempt to identify those errors currently found by Microsoft WordTM, such as subject/verb agreement. ESL Assistant further contains a component to help address lexical sel</context>
<context position="9186" citStr="Tetreault and Chodorow (2008" startWordPosition="1459" endWordPosition="1462">ts true target audience – non-native speakers of English engaged in real-life writing tasks. In this context, performance measurement inevitably entails manual evaluation, a process that is notoriously time consuming, costly and potentially error-prone. Human inter-rater agreement is known to be problematic 75 on this task: it is likely to be high in the case of certain user error types, such as over-regularized verb inflection (where the system suggests replacing “writed” with “wrote”), but other error types are difficult to evaluate, and much may hinge upon who is performing the evaluation: Tetreault and Chodorow (2008b) report that for the annotation of preposition errors “using a single rater as a gold standard, there is the potential to over- or underestimate precision by as much as 10%.” With these caveats in mind, we employed a single annotator to evaluate system performance on native data from the 1-million-word Chinese Learner’s of English corpus (Gui and Yang, 2001; 2003). Half of the corpus was utilized to inform system development, while the remaining half was held back for &amp;quot;unseen&amp;quot; evaluation. While the absolute numbers for some modules are more reliable than for others, the relative change in nu</context>
</contexts>
<marker>Tetreault, Chodorow, 2008</marker>
<rawString>Joel Tetreault and Martin Chodorow. 2008b. Native judgments of non-native usage: Experiments in preposition error detection. In Proceedings of the Workshop on Human Judgments in Computational Linguistics, 22nd International Conference on Computational Linguistics (pp 43-48). Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenine Turner</author>
<author>Eugene Charniak</author>
</authors>
<title>Language modeling for determiner selection.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers</booktitle>
<pages>177--180</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="2911" citStr="Turner and Charniak 2007" startWordPosition="443" endWordPosition="446">ta-driven. Eeg-Olofsson and Knutsson (2003) report on a rule-based system that detects and corrects preposition errors in non-native Swedish text. Rule-based approaches have also been used to predict definiteness and indefiniteness of Japanese noun phrases as a preprocessing step for Japanese to English machine translation (Murata and Nagao 1993; Bond et al, 1994; Heine, 1998), a task that is similar to the prediction of English articles. More recently, data-driven approaches have gained popularity and been applied to article prediction in English (Knight and Chander 1994; Minnen et al, 2000; Turner and Charniak 2007), to an array of Japanese learners’ errors in English (Izumi et al, 2003), to verb errors (Lee and Seneff, 2008), and to article and preposition correction in texts written by non-native ELLs (Han et al, 2004, 2006; Nagata et al, 2005; Nagata et al, 2006; De Felice and Pulman, 2007; Chodorow et al, 2007; Gamon et al, 2008, 2009; Tetreault and Chodorow, 2008a). 1 http://www.eslassistant.com Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 73–81, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Noun Related </context>
<context position="7411" citStr="Turner and Charniak (2007)" startWordPosition="1179" endWordPosition="1182">ccurs in the text. Although somewhat artificial, this approach to evaluation offers the advantages of being fully automatable and having abundant quantities 74 Figure 1: Screen shot of ESL Assistant of edited data readily available. With respect to prepositions and articles, the ESL Assistant&apos;s classifiers achieve state-of-the-art performance when compared to results reported in the literature (Gamon et al, 2008), inasmuch as comparison is possible when the systems are evaluated on different samples of native text. For articles, the system had 86.76% accuracy as compared to 86.74% reported by Turner and Charniak (2007), who have the most recently reported results. For the harder problem of prepositions, ESL Assistant’s accuracy is comparable to those reported by Tetreault and Chodorow (2008a) and De Felice and Pulman (2007). 3.1 Error Types The ELL grammatical errors that ESL Assistant tries to correct were distilled from analysis of the most frequent errors made in Chinese and Japanese English language learner corpora (Gui and Yang, 2001; Izumi et al. 2004). The error types are shown in Table 1: modules identified with ML are machine-learned, while the remaining modules are rule-based. ESL Assistant does n</context>
</contexts>
<marker>Turner, Charniak, 2007</marker>
<rawString>Jenine Turner and Eugene Charniak. 2007. Language modeling for determiner selection. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers (pp. 177-180). Rochester, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>