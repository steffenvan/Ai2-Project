<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9993185">
Integrating Co-occurrence Statistics with Information Extraction for
Robust Retrieval of Protein Interactions from Medline
</title>
<author confidence="0.996948">
Razvan Bunescu, Raymond Mooney Arun Ramani, Edward Marcotte
</author>
<affiliation confidence="0.99391">
Department of Computer Sciences Institute for Cellular and Molecular Biology
University of Texas at Austin University of Texas at Austin
1 University Station C0500 1 University Station A4800
</affiliation>
<address confidence="0.889199">
Austin, TX 78712 Austin, TX 78712
</address>
<email confidence="0.997832">
razvan@cs.utexas.edu arun@icmb.utexas.edu
mooney@cs.utexas.edu marcotte@icmb.utexas.edu
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999858066666667">
The task of mining relations from collec-
tions of documents is usually approached
in two different ways. One type of sys-
tems do relation extraction from individ-
ual sentences, followed by an aggrega-
tion of the results over the entire collec-
tion. Other systems follow an entirely dif-
ferent approach, in which co-occurrence
counts are used to determine whether the
mentioning together of two entities is due
to more than simple chance. We show
that increased extraction performance can
be obtained by combining the two ap-
proaches into an integrated relation ex-
traction model.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974645833333">
Information Extraction (IE) is a natural language
processing task in which text documents are ana-
lyzed with the aim of finding mentions of relevant
entities and important relationships between them.
In many cases, the subtask of relation extraction re-
duces to deciding whether a sentence asserts a par-
ticular relationship between two entities, which is
still a difficult, unsolved problem. There are how-
ever cases where the decision whether the two enti-
ties are in a relationship is made relative to an en-
tire document, or a collection of documents. In the
biomedical domain, for example, one may be inter-
ested in finding the pairs of human proteins that are
said to be interacting in any of the Medline abstracts,
where the answer is not required to specify which
abstracts are actually describing the interaction. As-
sembling a ranked list of interacting proteins can be
very useful to biologists - based on this list, they can
make more informed decisions with respect to which
genes to focus on in their research.
In this paper, we investigate methods that use
multiple occurrences of the same pair of entities
across a collection of documents in order to boost
the performance of a relation extraction system.
The proposed methods are evaluated on the task
of finding pairs of human proteins whose interac-
tions are reported in Medline abstracts. The major-
ity of known human protein interactions are derived
from individual, small-scale experiments reported in
Medline. Some of these interactions have already
been collected in the Reactome (Joshi-Tope et al.,
2005), BIND (Bader et al., 2003), DIP (Xenarios et
al., 2002), and HPRD (Peri et al., 2004) databases.
The amount of human effort involved in creating and
updating these databases is currently no match for
the continuous growth of Medline. It is therefore
very useful to have a method that automatically and
reliably extracts interaction pairs from Medline.
Systems that do relation extraction from a col-
lection of documents can be divided into two ma-
jor categories. In one category are IE systems
that first extract information from individual sen-
tences, and then combine the results into corpus-
level results (Craven, 1999; Skounakis and Craven,
2003). The second category corresponds to ap-
proaches that do not exploit much information from
the context of individual occurrences. Instead,
based on co-occurrence counts, various statistical
</bodyText>
<page confidence="0.994517">
49
</page>
<note confidence="0.9719115">
Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49–56,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.998785538461538">
or information-theoretic tests are used to decide
whether the two entities in a pair appear together
more often than simple chance would predict (Lee
et al., 2004; Ramani et al., 2005). We believe that
a combination of the two approaches can inherit the
advantages of each method and lead to improved re-
lation extraction accuracy.
The following two sections describe the two or-
thogonal approaches to corpus-level relation extrac-
tion. A model that integrates the two approaches is
then introduced in Section 4. This is followed by a
description of the dataset used for evaluation in Sec-
tion 5, and experimental results in Section 6.
</bodyText>
<sectionHeader confidence="0.904414" genericHeader="introduction">
2 Sentence-level relation extraction
</sectionHeader>
<bodyText confidence="0.99996656097561">
Most systems that identify relations between enti-
ties mentioned in text documents consider only pair
of entities that are mentioned in the same sentence
(Ray and Craven, 2001; Zhao and Grishman, 2005;
Bunescu and Mooney, 2005). To decide the exis-
tence and the type of a relationship, these systems
generally use lexico-semantic clues inferred from
the sentence context of the two entities. Much re-
search has been focused recently on automatically
identifying biologically relevant entities and their
relationships such as protein-protein interactions or
subcellular localizations. For example, the sentence
“TR6 specifically binds Fas ligand”, states an inter-
action between the two proteins TR6 and Fas ligand.
One of the first systems for extracting interactions
between proteins is described in (Blaschke and Va-
lencia, 2001). There, sentences are matched deter-
ministically against a set of manually developed pat-
terns, where a pattern is a sequence of words or Part-
of-Speech (POS) tags and two protein-name tokens.
Between every two adjacent words is a number in-
dicating the maximum number of words that can be
skipped at that position. An example is: “interaction
of (3)&lt;P&gt;(3) with (3)&lt;P&gt;”. This approach is
generalized in (Bunescu and Mooney, 2005), where
subsequences of words (or POS tags) from the sen-
tence are used as implicit features. Their weights are
learned by training a customized subsequence ker-
nel on a dataset of Medline abstracts annotated with
proteins and their interactions.
A relation extraction system that works at the
sentence-level and which outputs normalized confi-
dence values for each extracted pair of entities can
also be used for corpus-level relation extraction. A
straightforward way to do this is to apply an aggre-
gation operator over the confidence values inferred
for all occurrences of a given pair of entities. More
exactly, if p1 and p2 are two entities that occur in a
total of n sentences s1, s2, ..., sn in the entire corpus
C, then the confidence P (R (p 1; p2) I C) that they are
in a particular relationship R is defined as:
</bodyText>
<equation confidence="0.940362">
P(R(p1;p2)IC) =h({P(R(p1;p2)Isi)Ii=1: n})
</equation>
<tableCaption confidence="0.5774995">
Table 1 shows only four of the many possible
choices for the aggregation operator h.
</tableCaption>
<bodyText confidence="0.9771845">
max hn,,ax=maxP(R(p1; p2) I si)
i
noisy-or hnar = 1 — fl(1 — P(R(p1;p2)Isi))
i
avg havy P(R(pnp2)Isi)
= i
and hand = flP(R(p1;p2)Isi)1/n
i
</bodyText>
<tableCaption confidence="0.996081">
Table 1: Aggregation Operators.
</tableCaption>
<bodyText confidence="0.999895875">
Out of the four operators in Table 1, we believe
that the max operator is the most appropriate for ag-
gregating confidence values at the corpus-level. The
question that needs to be answered is whether there
is a sentence somewhere in the corpus that asserts
the relationship R between entities p1 and p2. Us-
ing avg instead would answer a different question -
whether R(p1; p2) is true in most of the sentences
containing p1 and p2. Also, the and operator would
be most appropriate for finding whether R(p1; p2)
is true in all corresponding sentences in the corpus.
The value of the noisy-or operator (Pearl, 1986) is
too dependent on the number of occurrences, there-
fore it is less appropriate for a corpus where the oc-
currence counts vary from one entity pair to another
(as confirmed in our experiments from Section 6).
For examples, if the confidence threshold is set at
0:5, and the entity pair(p1;p2)occurs in 6 sentences
or less, each with confidence0:1, thenR(p1;p2)is
false, according to the noisy-or operator. However,
if(p1;p2)occur in more than 6 sentences, with the
same confidence value of 0:1, then the correspond-
ing noisy-or value exceeds 0:5, making R(p1; p2)
true.
</bodyText>
<page confidence="0.997501">
50
</page>
<sectionHeader confidence="0.996094" genericHeader="method">
3 Co-occurrence statistics
</sectionHeader>
<bodyText confidence="0.99995596">
Given two entities with multiple mentions in a large
corpus, another approach to detect whether a re-
lationship holds between them is to use statistics
over their occurrences in textual patterns that are
indicative for that relation. Various measures such
as pointwise mutual information (PMI) , chi-square
(X2) or log-likelihood ratio (LLR) (Manning and
Sch¨utze, 1999) use the two entities’ occurrence
statistics to detect whether their co-occurrence is due
to chance, or to an underlying relationship.
A recent example is the co-citation approach from
(Ramani et al., 2005), which does not try to find spe-
cific assertions of interactions in text, but rather ex-
ploits the idea that if many different abstracts refer-
ence both proteinp1and proteinp2, thenp1andp2
are likely to interact. Particularly, if the two proteins
are co-cited significantly more often than one would
expect if they were cited independently at random,
then it is likely that they interact. The model used
to compute the probability of random co-citation is
based on the hypergeometric distribution (Lee et al.,
2004; Jenssen et al., 2001). Thus, ifNis the total
number of abstracts,nof which cite the first protein,
mcite the second protein, andkcite both, then the
probability of co-citation under a random model is:
</bodyText>
<equation confidence="0.969078">
Cnk/\Nnm—k
P(kjN; m; n) =N (1)
Cm
</equation>
<bodyText confidence="0.836024888888889">
their interaction. To compute the
of
between two
we use the
information-theoretic measure of pointwise mutual
information (Church and Hanks, 1990; Manning
and
1999), which is computed based on the
following quantities:
</bodyText>
<listItem confidence="0.988688333333333">
1. N the total number of protein pairs co-
occurring in the same sentence in the corpus.
2. P(p
</listItem>
<equation confidence="0.803557909090909">
p2)
n12
N : the probability that
“degree
inter-
action”
proteinsp1andp2,
Sch¨utze,
1;
&apos;
=
</equation>
<bodyText confidence="0.9825">
1andp2co-occur in the same sentence;n12= the
number of sentences mentioning both p
and
</bodyText>
<equation confidence="0.9029192">
2
1
p
.
3. P(p
p)
N: the probability that p
co-
occurs with any other protein in the same sen-
tence; n
</equation>
<bodyText confidence="0.781277">
= the number of sentences mention-
ing p
and p.
</bodyText>
<equation confidence="0.961868318181818">
4. P(p2
p)
n2
N : the probability that p2 co-
occurs with any other protein in the same sen-
tence; n2 = the number of sentences mention-
ing p2 an
1;
&apos;
1=
1
1
1
;
&apos;
=
d p.
The PMI is then defined as in Equation 2 below:
&apos;logNn12
p2) =
o P(p
p2)
g
(p
p) &apos; P(p2
1;
l
1;
P
1;
;p)
n1&apos;n2
can be ignored. For
sake of simplicity, we use the simpler formula fr
factorNandthelogoperator
om
Equation 3.
sPMI(p1;p2)=n12
n1&apos;n2
can be rewritt
ThesPMI(p1;p2)formula
en as:
sPMI (p1;p2) = 1
n1&apos;n2
</equation>
<bodyText confidence="0.948248307692308">
the sentence contexts corre-
sponding to
and assume that asentence-level relation extractor
is available, with the capability of computing nor-
malized confidence values for all extractions. Then
one way of using the extraction confidence is to have
each co-occurrence weighted by its confidence, i.e.
replace the
the normalized scores
P(R(p
p2)jsi), as illustrated in Equation 5. This
results in a new formula wPMI (weighted PMI),
which is equal with the product between sPMI an
</bodyText>
<equation confidence="0.81218775">
Lets1,s2,...,sn12be
then12co-occurrencesofp1andp2,
constant1with
1;
d
the average aggregation operator Pavg.
wPMI(p1;p2)= 1
P(R(p1;p2)jsi)
</equation>
<bodyText confidence="0.9701634">
The approach that we take in this paper is to con-
strain the two proteins to be mentioned in the same
sentence, based on the assumption that if there is
a reason for two protein names to co-occur in the
same sentence, then in most cases that is caused by
</bodyText>
<equation confidence="0.848578333333333">
PMI
(p
(2)
</equation>
<bodyText confidence="0.9007305">
Given that the PMI will be used only for ranking
pairs of potentially interacting proteins, the constant
</bodyText>
<sectionHeader confidence="0.964419" genericHeader="method">
4 Integrated model
</sectionHeader>
<equation confidence="0.616640692307692">
1 (4)
n12
&apos; ravg (
=
5)
n1 &apos; n2
(3)
n12
~ Xi=1
n1&apos;n2
n12
�
Xi=1
</equation>
<page confidence="0.993119">
51
</page>
<bodyText confidence="0.999405666666667">
The operator I&apos;az7g can be replaced with any other ag-
gregation operator from Table 1. As argued in Sec-
tion 2, we consider max to be the most appropriate
operator for our task, therefore the integrated model
is based on the weighted PMI product illustrated in
Equation 6.
</bodyText>
<equation confidence="0.999454">
wPMI n12
n12 . maxP(R(p1,p2)jsi)
n1 &apos; n2 (6)
n1 • n2 i
</equation>
<bodyText confidence="0.999701333333333">
If a pair of entities p1 and p2 is ranked by wPMI
among the top pairs, this means that it is unlikely
that p1 and p2 have co-occurred together in the en-
tire corpus by chance, and at the same time there is
at least one mention where the relation extractor de-
cides with high confidence that R(p1, p2) = 1.
</bodyText>
<sectionHeader confidence="0.998567" genericHeader="method">
5 Evaluation Corpus
</sectionHeader>
<bodyText confidence="0.99993775">
Contrasting the performance of the integrated model
against the sentence-level extractor or the PMI-
based ranking requires an evaluation dataset that
provides two types of annotations:
</bodyText>
<listItem confidence="0.9897078">
1. The complete list of interactions reported in the
corpus (Section 5.1).
2. Annotation of mentions of genes and proteins,
together with their corresponding gene identi-
fiers (Section 5.2).
</listItem>
<bodyText confidence="0.999918166666667">
We do not differentiate between genes and their
protein products, mapping them to the same gene
identifiers. Also, even though proteins may partic-
ipate in different types of interactions, we are con-
cerned only with detecting whether they interact in
the general sense of the word.
</bodyText>
<subsectionHeader confidence="0.992113">
5.1 Medline Abstracts and Interactions
</subsectionHeader>
<bodyText confidence="0.9847716">
In order to compile an evaluation corpus and an as-
sociated comprehensive list of interactions, we ex-
ploited information contained in the HPRD (Peri
et al., 2004) database. Every interaction listed in
HPRD is linked to a set of Medline articles where the
corresponding experiment is reported. More exactly,
each interaction is specified in the database as a tuple
that contains the LocusLink (now EntrezGene) iden-
tifiers of all genes involved and the PubMed identi-
fiers of the corresponding articles (as illustrated in
</bodyText>
<tableCaption confidence="0.801783">
Table 2).
</tableCaption>
<table confidence="0.9990518">
Interaction (XML) (HPRD)
&lt;interaction&gt;
&lt;gene&gt;2318&lt;/gene&gt;
&lt;gene&gt; 58529 &lt;/gene&gt;
&lt;pubmed&gt; 10984498 11 1 71996&lt;/pubmed&gt;
&lt;/interaction&gt;
Participant Genes (XML) (NCBI)
&lt;gene id=”2318”&gt;
&lt;name&gt;FLNC &lt;/name&gt;
&lt;description&gt;filaminC, gamma&lt;/description&gt;
&lt;synonyms&gt;
&lt;synonym&gt;ABPA&lt;/synonym&gt;
&lt; synonym&gt; ABPL &lt;/synonym&gt;
&lt;synonym&gt;FLN2 &lt;/synonym&gt;
&lt;synonym&gt;ABP-280&lt;/synonym&gt;
&lt;synonym&gt;ABP280A&lt;/synonym&gt;
&lt;/synonyms&gt;
&lt;proteins&gt;
&lt;protein&gt;gamma filamin&lt;/protein&gt;
&lt;protein&gt;filamin 2&lt;/protein&gt;
&lt;protein&gt; gamma-filamin &lt;/protein&gt;
&lt;protein&gt;ABP-L, gamma filamin&lt;/protein&gt;
&lt;protein&gt;actin-binding protein 280&lt;/protein&gt;
&lt;protein&gt;gamma actin-binding protein&lt;/protein&gt;
&lt;protein&gt;filamin C, gamma&lt;/protein&gt;
&lt;/proteins&gt;
&lt;/gene&gt;
&lt;gene id=”58529”&gt;
&lt;name&gt;MYOZ1 &lt;/name&gt;
&lt;description&gt;myozenin 1&lt;/description&gt;
&lt;synonyms&gt; ... &lt;/synonyms&gt;
&lt;proteins&gt; ... &lt;/proteins&gt;
&lt;/gene&gt;
Medline Abstract (XML) (NCBI)
&lt;PMID&gt; 10984498&lt;/PMID&gt;
&lt;AbstractText&gt;
We found that this protein binds to three other Z-disc pro-
teins; therefore, we have named it FATZ, gamma-filamin,
alpha-actinin and telethonin binding protein of the Z-disc.
&lt;/AbstractText&gt;
</table>
<tableCaption confidence="0.998646">
Table 2: Interactions, Genes and Abstracts.
</tableCaption>
<bodyText confidence="0.9999275">
The evaluation corpus (henceforth referred to as
the HPRD corpus) is created by collecting the Med-
line abstracts corresponding to interactions between
human proteins, as specified in HPRD. In total,
5,617 abstracts are included in this corpus, with an
associated list of 7,785 interactions. This list is com-
prehensive - the HPRD database is based on an an-
notation process in which the human annotators re-
port all interactions described in a Medline article.
On the other hand, the fact that only abstracts are
included in the corpus (as opposed to including the
full article) means that the list may contain interac-
tions that are not actually reported in the HPRD cor-
pus. Nevertheless, if the abstracts were annotated
</bodyText>
<page confidence="0.996509">
52
</page>
<bodyText confidence="0.99954784375">
with gene mentions and corresponding GIDs, then
a “quasi-exact” interaction list could be computed
based on the following heuristic:
[H] If two genes with identifiers gid, and gide are
mentioned in the same sentence in an abstract with
PubMed identifier Amid, and if gid, and gide are
participants in an interaction that is linked to Amid
in HPRD, then consider that the abstract (and con-
sequently the entire HPRD corpus) reports the inter-
action betweengid,andgide.■
An application of the above heuristic is shown at
the bottom of Table 2. The HPRD record at the
top of the table specifies that the Medline article
with ID 10984498 reports an interaction between the
proteins FATZ (with ID 58529) and gamma-filamin
(with ID 2318). The two protein names are men-
tioned in a sentence in the abstract for 10984498,
therefore, by [H], we consider that the HPRD cor-
pus reports this interaction.
This is very similar to the procedure used in
(Craven, 1999) for creating a “weakly-labeled”
dataset of subcellular-localization relations. [H] is
a strong heuristic – it is already known that the full
article reports an interaction between the two genes.
Finding the two genes collocated in the same sen-
tence in the abstract is very likely to be due to the
fact that the abstract discusses their interaction. The
heuristic can be made even more accurate if a pair
of genes is considered as interacting only if they co-
occur in a (predefined) minimum number of sen-
tences in the entire corpus – with the evaluation
modified accordingly, as described later in Section 6.
</bodyText>
<subsectionHeader confidence="0.99922">
5.2 Gene Name Annotation and Normalization
</subsectionHeader>
<bodyText confidence="0.999965416666667">
For the annotation of gene names and their normal-
ization, we use a dictionary-based approach similar
to (Cohen, 2005). NCBI1 provides a comprehen-
sive dictionary of human genes, where each gene is
specified by its unique identifier, and qualified with
an official name, a description, synonym names and
one or more protein names, as illustrated in Table 2.
All of these names, including the description, are
considered as potential referential expressions for
the gene entity. Each name string is reduced to a
normal form by: replacing dashes with spaces, intro-
ducing spaces between sequences of letters and se-
</bodyText>
<footnote confidence="0.827948">
1URL: http://www.ncbi.nih.gov
</footnote>
<bodyText confidence="0.999937684210526">
quences of digits, replacing Greek letters with their
Latin counterparts (capitalized), substituting Roman
numerals with Arabic numerals, decapitalizing the
first word if capitalized. All names are further tok-
enized, and checked against a dictionary of close to
100K English nouns. Names that are found in this
dictionary are simply filtered out. We also ignore
all ambiguous names (i.e. names corresponding to
more than one gene identifier). The remaining non-
ambiguous names are added to the final gene dictio-
nary, which is implemented as a trie-like structure in
order to allow a fast lookup of gene IDs based on the
associated normalized sequences of tokens.
Each abstract from the HPRD corpus is tokenized
and segmented in sentences using the OpenNLP2
package. The resulting sentences are then annotated
by traversing them from left to right and finding the
longest token sequences whose normal forms match
entries from the gene dictionary.
</bodyText>
<sectionHeader confidence="0.997969" genericHeader="method">
6 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.9980525">
The main purpose of the experiments in this section
is to compare the performance of the following four
methods on the task of corpus-level relation extrac-
tion:
</bodyText>
<listItem confidence="0.997852285714286">
1. Sentence-level relation extraction followed by
the application of an aggregation operator that
assembles corpus-level results (SSK.Max).
2. Pointwise Mutual Information (PMI).
3. The integrated model, a product of the two base
models (PMI.SSK.Max).
4. The hypergeometric co-citation method (HG).
</listItem>
<sectionHeader confidence="0.995015" genericHeader="method">
7 Experimental Methodology
</sectionHeader>
<bodyText confidence="0.99993">
All abstracts, either from the HPRD corpus, or
from the entire Medline, are annotated using the
dictionary-based approach described in Section 5.2.
The sentence-level extraction is done with the sub-
sequence kernel (SSK) approach from (Bunescu and
Mooney, 2005), which was shown to give good re-
sults on extracting interactions from biomedical ab-
stracts. The subsequence kernel was trained on a
set of 225 Medline abstracts which were manually
</bodyText>
<footnote confidence="0.971131">
2URL: http://opennlp.sourceforge.net
</footnote>
<page confidence="0.999024">
53
</page>
<bodyText confidence="0.922611736842105">
annotated with protein names and their interactions.
It is known that PMI gives undue importance to
low frequency events (Dunning, 1993), therefore the
evaluation considers only pairs of genes that occur at
least 5 times in the whole corpus.
When evaluating corpus-level extraction on
HPRD, because the “quasi-exact” list of interactions
is known, we report the precision-recall (PR) graphs,
where the precision (P) and recall (R) are computed
as follows:
P=#true interactions extracted
#total interaction extracted
R = #true interactions extracted
#true interactions
All pairs of proteins are ranked based on each scor-
ing method, and precision recall points are com-
puted by considering the topNpairs, whereN
varies from 1 to the total number of pairs.
When evaluating on the entire Medline, we used
the shared protein function benchmark described in
(Ramani et al., 2005). Given the set of interacting
pairs recovered at each recall level, this benchmark
calculates the extent to which interaction partners
in a data set share functional annotation, a measure
previously shown to correlate with the accuracy of
functional genomics data sets (Lee et al., 2004). The
KEGG (Kanehisa et al., 2004) and Gene Ontology
(Ashburner et al., 2000) databases provide specific
pathway and biological process annotations for ap-
proximately 7,500 human genes, assigning human
genes into 155 KEGG pathways (at the lowest level
of KEGG) and 1,356 GO pathways (at level 8 of the
GO biological process annotation).
The scoring scheme for measuring interaction set
accuracy is in the form of a log odds ratio of gene
pairs sharing functional annotations. To evaluate a
data set, a log likelihood ratio (LLR) is calculated as
follows:
</bodyText>
<equation confidence="0.999111333333333">
P(DjI)
=lnP(IjD)P(:I)(7)
P(:IjD)P(I)
</equation>
<bodyText confidence="0.9996695625">
where P (DjI) and P (Dj: I) are the probability
of observing the data D conditioned on the genes
sharing benchmark associations (I) and not sharing
benchmark associations (:I). In its expanded form
(obtained by Bayes theorem), P(Ij D) and P(:IjD)
are estimated using the frequencies of interactions
observed in the given data setDbetween annotated
genes sharing benchmark associations and not shar-
ing associations, respectively, while the priorsP(I)
andP(:I)are estimated based on the total frequen-
cies of all benchmark genes sharing the same asso-
ciations and not sharing associations, respectively.
A score of zero indicates interaction partners in the
data set being tested are no more likely than random
to belong to the same pathway or to interact; higher
scores indicate a more accurate data set.
</bodyText>
<sectionHeader confidence="0.97484" genericHeader="method">
8 Experimental Results
</sectionHeader>
<bodyText confidence="0.998508875">
The results for the HPRD corpus-level extraction are
shown in Figure 1. Overall, the integrated model has
a more consistent performance, with a gain in preci-
sion mostly at recall levels past 40%. The SSK.Max
and HG models both exhibit a sudden decrease in
precision at around 5% recall level. While SSK.Max
goes back to a higher precision level, the HG model
begins to recover only late at 70% recall.
</bodyText>
<equation confidence="0.494941">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</equation>
<figureCaption confidence="0.995713">
Figure 1: PR curves for corpus-level extraction.
</figureCaption>
<bodyText confidence="0.999964222222222">
A surprising result in this experiment is the be-
havior of the HG model, which is significantly out-
performed by PMI, and which does only marginally
better than a simple baseline that considers all pairs
to be interacting.
We also compared the two methods on corpus-
level extraction from the entire Medline, using the
shared protein function benchmark. As before, we
considered only protein pairs occurring in the same
</bodyText>
<figure confidence="0.922984894736842">
Precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
PMI.SSK.Max
PMI
SSK.Max
HG
LLR=ln P(Dj:I)
54
Precision
</figure>
<bodyText confidence="0.967041866666667">
sentence, with a minimum frequency count of 5. The
resulting 47,436 protein pairs were ranked accord-
ing to their PMI and HG scores, with pairs that are
most likely to be interacting being placed at the top.
For each ranking, the LLR score was computed for
the top N proteins, where N varied in increments of
1,000.
The comparative results for PMI and HG are
shown in Figure 2, together with the scores for three
human curated databases: HPRD, BIND and Reac-
tome. On the top 18,000 protein pairs, PMI outper-
forms HG substantially, after which both converge
to the same value for all the remaining pairs.
2500 5000 7500 10000 12500 15000 17500 20000 22500 25000
Top N pairs
</bodyText>
<figureCaption confidence="0.997411">
Figure 2: Functional annotation benchmark.
</figureCaption>
<bodyText confidence="0.9990835">
Figure 3 shows a comparison of the four aggre-
gation operators on the same HPRD corpus, which
confirms that, overall, max is most appropriate for
integrating corpus-level results.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="method">
9 Future Work
</sectionHeader>
<bodyText confidence="0.999798692307692">
The piece of related work that is closest to the aim of
this paper is the Bayesian approach from (Skounakis
and Craven, 2003). In their probabilistic model, co-
occurrence statistics are taken into account by using
a prior probability that a pair of proteins are inter-
acting, given the number of co-occurrences in the
corpus. However, they do not use the confidences of
the sentence-level extractions. The GeneWays sys-
tem from (Rzhetsky et al., 2004) takes a different
approach, in which co-occurrence frequencies are
simply used to re-rank the ouput from the relation
extractor.
An interesting direction for future research is to
</bodyText>
<figure confidence="0.939097">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</figure>
<figureCaption confidence="0.99938">
Figure 3: PR curves for aggregation operators.
</figureCaption>
<bodyText confidence="0.999866105263158">
design a model that takes into account both the ex-
traction confidences and the co-occurrence statis-
tics, without losing the probabilistic (or information-
theoretic) interpretation. One could investigate ways
of integrating the two orthogonal approaches to
corpus-level extraction based on other statistical
tests, such as chi-square and log-likelihood ratio.
The sentence-level extractor used in this paper
was trained to recognize relation mentions in iso-
lation. However, the trained model is later used,
through the max aggregation operator, to recognize
whether multiple mentions of the same pair of pro-
teins indicate a relationship between them. This
points to a fundamental mismatch between the train-
ing and testing phases of the model. We expect that
better accuracy can be obtained by designing an ap-
proach that is using information from multiple oc-
currences of the same pair in both training and test-
ing.
</bodyText>
<sectionHeader confidence="0.993106" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.999858">
Extracting relations from a collection of documents
can be approached in two fundamentally different
ways. In one approach, an IE system extracts rela-
tion instances from corpus sentences, and then ag-
gregates the local extractions into corpus-level re-
sults. In the second approach, statistical tests based
on co-occurrence counts are used for deciding if a
given pair of entities are mentioned together more
often than chance would predict. We have described
</bodyText>
<figure confidence="0.99901794117647">
LLR
4.75
4.25
2.75
2.25
3.75
3.25
4.5
2.5
3.5
4
2
5
3
PMI
HG
HPRD
BIND
Reactome
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Max
Noisy-Or
Avgd
An
</figure>
<page confidence="0.993432">
55
</page>
<bodyText confidence="0.9996045">
a method to integrate the two approaches, and given
experimental results that confirmed our intuition that
an integrated model would have a better perfor-
mance.
</bodyText>
<sectionHeader confidence="0.982387" genericHeader="acknowledgments">
11 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999414">
This work was supported by grants from the N.S.F.
(IIS-0325116, EIA-0219061), N.I.H. (GM06779-
01), Welch (F1515), and a Packard Fellowship
(E.M.M.).
</bodyText>
<sectionHeader confidence="0.999153" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999864600000001">
M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. Butler,
J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, and J. T.
et al. Eppig. 2000. Gene ontology: tool for the unification
of biology. the gene ontology consortium. Nature Genetics,
25(1):25–29.
G. D. Bader, D. Betel, and C. W. Hogue. 2003. Bind: the
biomolecular interaction network database. Nucleic Acids
Research, 31(1):248–250.
C. Blaschke and A. Valencia. 2001. Can bibliographic pointers
for known biological data be found automatically? protein
interactions as a case study. Comparative and Functional
Genomics, 2:196–206.
Razvan C. Bunescu and Raymond J. Mooney. 2005. Subse-
quence kernels for relation extraction. In Proceedings of the
Conference on Neural Information Processing Systems, Van-
couver, BC.
Kenneth W. Church and Patrick W. Hanks. 1990. Word associ-
ation norms, mutual information and lexicography. Compu-
tational Linguistics, 16(1):22–29.
Aaron M. Cohen. 2005. Unsupervised gene/protein named en-
tity normalization using automatically extracted dictionaries.
In Proceedings of the ACL-ISMB Workshop on Linking Bio-
logical Literature, Ontologies and Databases: Minining Bi-
ological Semantics, pages 17–24, Detroit, MI.
Mark Craven. 1999. Learning to extract relations from MED-
LINE. In Papers from the Sixteenth National Conference
on Artificial Intelligence (AAAI-99) Workshop on Machine
Learning for Information Extraction, pages 25–30, July.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguistics,
19(1):61–74.
T. K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig. 2001.
A literature network of human genes for high-throughput
analysis of gene expression. Nature Genetics, 28(1):21–28.
G. Joshi-Tope, M. Gillespie, I. Vastrik, P. D’Eustachio,
E. Schmidt, B. de Bono, B. Jassal, G. R. Gopinath, G. R.
Wu, L. Matthews, and et al. 2005. Reactome: a knowl-
edgebase of biological pathways. Nucleic Acids Research,
33 Database Issue:D428–432.
M. Kanehisa, S. Goto, S. Kawashima, Y. Okuno, and M. Hat-
tori. 2004. The KEGG resource for deciphering the genome.
Nucleic Acids Research, 32 Database issue:D277–280.
I. Lee, S. V. Date, A. T. Adai, and E. M. Marcotte. 2004. A
probabilistic functional network of yeast genes. Science,
306(5701):1555–1558.
Christopher D. Manning and Hinrich Sch¨utze. 1999. Foun-
dations of Statistical Natural Language Processing. MIT
Press, Cambridge, MA.
Judea Pearl. 1986. Fusion, propagation, and structuring in be-
lief networks. Artificial Intelligence, 29(3):241–288.
S. Peri, J. D. Navarro, T. Z. Kristiansen, R. Amanchy, V. Suren-
dranath, B. Muthusamy, T. K. Gandhi, K. N. Chandrika,
N. Deshpande, S. Suresh, and et al. 2004. Human protein
reference database as a discovery resource for proteomics.
Nucleic Acids Research, 32 Database issue:D497–501.
A. K. Ramani, R. C. Bunescu, R. J. Mooney, and E. M. Mar-
cotte. 2005. Consolidating the set of know human protein-
protein interactions in preparation for large-scale mapping of
the human interactome. Genome Biology, 6(5):r40.
Soumya Ray and Mark Craven. 2001. Representing sentence
structure in hidden Markov models for information extrac-
tion. In Proceedings of the Seventeenth International Joint
Conference on Artificial Intelligence (IJCAI-2001), pages
1273–1279, Seattle, WA.
A. Rzhetsky, T. Iossifov, I. Koike, M. Krauthammer, P. Kra,
M. Morris, H. Yu, P.A. Duboue, W. Weng, W.J. Wilbur,
V. Hatzivassiloglou, and C. Friedman. 2004. GeneWays: a
system for extracting, analyzing, visualizing, and integrating
molecular pathway data. Journal ofBiomedical Informatics,
37:43–53.
Marios Skounakis and Mark Craven. 2003. Evidence combina-
tion in biomedical natural-language processing. In Proceed-
ings of the 3nd ACM SIGKDD Workshop on Data Mining in
Bioinformatics (BIOKDD 2003), pages 25–32, Washington,
DC.
I. Xenarios, L. Salwinski, X. J. Duan, P. Higney, S. M. Kim, and
D. Eisenberg. 2002. DIP, the database of interacting pro-
teins: a research tool for studying cellular networks of pro-
tein interactions. Nucleic Acids Research, 30(1):303–305.
Shubin Zhao and Ralph Grishman. 2005. Extracting relations
with integrated information using kernel methods. In Pro-
ceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL’05), pages 419–426, Ann
Arbor, Michigan, June. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.998411">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.478880">
<title confidence="0.9973875">Integrating Co-occurrence Statistics with Information Extraction for Robust Retrieval of Protein Interactions from Medline</title>
<author confidence="0.999701">Razvan Bunescu</author>
<author confidence="0.999701">Raymond Mooney Arun Ramani</author>
<author confidence="0.999701">Edward Marcotte</author>
<affiliation confidence="0.863812">Department of Computer Sciences Institute for Cellular and Molecular Biology University of Texas at Austin University of Texas at Austin 1 University Station C0500 1 University Station A4800</affiliation>
<address confidence="0.889765">Austin, TX 78712 Austin, TX 78712</address>
<email confidence="0.997355">razvan@cs.utexas.eduarun@icmb.utexas.edumooney@cs.utexas.edumarcotte@icmb.utexas.edu</email>
<abstract confidence="0.9978979375">The task of mining relations from collections of documents is usually approached in two different ways. One type of systems do relation extraction from individual sentences, followed by an aggregation of the results over the entire collection. Other systems follow an entirely different approach, in which co-occurrence counts are used to determine whether the mentioning together of two entities is due to more than simple chance. We show that increased extraction performance can be obtained by combining the two approaches into an integrated relation extraction model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Ashburner</author>
<author>C A Ball</author>
<author>J A Blake</author>
<author>D Botstein</author>
<author>H Butler</author>
<author>J M Cherry</author>
<author>A P Davis</author>
<author>K Dolinski</author>
<author>S S Dwight</author>
<author>J T</author>
</authors>
<title>Gene ontology: tool for the unification of biology. the gene ontology consortium.</title>
<date>2000</date>
<journal>Nature Genetics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="20586" citStr="Ashburner et al., 2000" startWordPosition="3269" endWordPosition="3272"> scoring method, and precision recall points are computed by considering the topNpairs, whereN varies from 1 to the total number of pairs. When evaluating on the entire Medline, we used the shared protein function benchmark described in (Ramani et al., 2005). Given the set of interacting pairs recovered at each recall level, this benchmark calculates the extent to which interaction partners in a data set share functional annotation, a measure previously shown to correlate with the accuracy of functional genomics data sets (Lee et al., 2004). The KEGG (Kanehisa et al., 2004) and Gene Ontology (Ashburner et al., 2000) databases provide specific pathway and biological process annotations for approximately 7,500 human genes, assigning human genes into 155 KEGG pathways (at the lowest level of KEGG) and 1,356 GO pathways (at level 8 of the GO biological process annotation). The scoring scheme for measuring interaction set accuracy is in the form of a log odds ratio of gene pairs sharing functional annotations. To evaluate a data set, a log likelihood ratio (LLR) is calculated as follows: P(DjI) =lnP(IjD)P(:I)(7) P(:IjD)P(I) where P (DjI) and P (Dj: I) are the probability of observing the data D conditioned on</context>
</contexts>
<marker>Ashburner, Ball, Blake, Botstein, Butler, Cherry, Davis, Dolinski, Dwight, T, 2000</marker>
<rawString>M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. Butler, J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, and J. T. et al. Eppig. 2000. Gene ontology: tool for the unification of biology. the gene ontology consortium. Nature Genetics, 25(1):25–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Bader</author>
<author>D Betel</author>
<author>C W Hogue</author>
</authors>
<title>Bind: the biomolecular interaction network database.</title>
<date>2003</date>
<journal>Nucleic Acids Research,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="2688" citStr="Bader et al., 2003" startWordPosition="415" endWordPosition="418">ch genes to focus on in their research. In this paper, we investigate methods that use multiple occurrences of the same pair of entities across a collection of documents in order to boost the performance of a relation extraction system. The proposed methods are evaluated on the task of finding pairs of human proteins whose interactions are reported in Medline abstracts. The majority of known human protein interactions are derived from individual, small-scale experiments reported in Medline. Some of these interactions have already been collected in the Reactome (Joshi-Tope et al., 2005), BIND (Bader et al., 2003), DIP (Xenarios et al., 2002), and HPRD (Peri et al., 2004) databases. The amount of human effort involved in creating and updating these databases is currently no match for the continuous growth of Medline. It is therefore very useful to have a method that automatically and reliably extracts interaction pairs from Medline. Systems that do relation extraction from a collection of documents can be divided into two major categories. In one category are IE systems that first extract information from individual sentences, and then combine the results into corpuslevel results (Craven, 1999; Skounak</context>
</contexts>
<marker>Bader, Betel, Hogue, 2003</marker>
<rawString>G. D. Bader, D. Betel, and C. W. Hogue. 2003. Bind: the biomolecular interaction network database. Nucleic Acids Research, 31(1):248–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Blaschke</author>
<author>A Valencia</author>
</authors>
<title>Can bibliographic pointers for known biological data be found automatically? protein interactions as a case study. Comparative and Functional Genomics,</title>
<date>2001</date>
<pages>2--196</pages>
<contexts>
<context position="5186" citStr="Blaschke and Valencia, 2001" startWordPosition="801" endWordPosition="805">5; Bunescu and Mooney, 2005). To decide the existence and the type of a relationship, these systems generally use lexico-semantic clues inferred from the sentence context of the two entities. Much research has been focused recently on automatically identifying biologically relevant entities and their relationships such as protein-protein interactions or subcellular localizations. For example, the sentence “TR6 specifically binds Fas ligand”, states an interaction between the two proteins TR6 and Fas ligand. One of the first systems for extracting interactions between proteins is described in (Blaschke and Valencia, 2001). There, sentences are matched deterministically against a set of manually developed patterns, where a pattern is a sequence of words or Partof-Speech (POS) tags and two protein-name tokens. Between every two adjacent words is a number indicating the maximum number of words that can be skipped at that position. An example is: “interaction of (3)&lt;P&gt;(3) with (3)&lt;P&gt;”. This approach is generalized in (Bunescu and Mooney, 2005), where subsequences of words (or POS tags) from the sentence are used as implicit features. Their weights are learned by training a customized subsequence kernel on a datase</context>
</contexts>
<marker>Blaschke, Valencia, 2001</marker>
<rawString>C. Blaschke and A. Valencia. 2001. Can bibliographic pointers for known biological data be found automatically? protein interactions as a case study. Comparative and Functional Genomics, 2:196–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Subsequence kernels for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Neural Information Processing Systems,</booktitle>
<location>Vancouver, BC.</location>
<contexts>
<context position="4586" citStr="Bunescu and Mooney, 2005" startWordPosition="714" endWordPosition="717">ch method and lead to improved relation extraction accuracy. The following two sections describe the two orthogonal approaches to corpus-level relation extraction. A model that integrates the two approaches is then introduced in Section 4. This is followed by a description of the dataset used for evaluation in Section 5, and experimental results in Section 6. 2 Sentence-level relation extraction Most systems that identify relations between entities mentioned in text documents consider only pair of entities that are mentioned in the same sentence (Ray and Craven, 2001; Zhao and Grishman, 2005; Bunescu and Mooney, 2005). To decide the existence and the type of a relationship, these systems generally use lexico-semantic clues inferred from the sentence context of the two entities. Much research has been focused recently on automatically identifying biologically relevant entities and their relationships such as protein-protein interactions or subcellular localizations. For example, the sentence “TR6 specifically binds Fas ligand”, states an interaction between the two proteins TR6 and Fas ligand. One of the first systems for extracting interactions between proteins is described in (Blaschke and Valencia, 2001)</context>
<context position="19127" citStr="Bunescu and Mooney, 2005" startWordPosition="3043" endWordPosition="3046">k of corpus-level relation extraction: 1. Sentence-level relation extraction followed by the application of an aggregation operator that assembles corpus-level results (SSK.Max). 2. Pointwise Mutual Information (PMI). 3. The integrated model, a product of the two base models (PMI.SSK.Max). 4. The hypergeometric co-citation method (HG). 7 Experimental Methodology All abstracts, either from the HPRD corpus, or from the entire Medline, are annotated using the dictionary-based approach described in Section 5.2. The sentence-level extraction is done with the subsequence kernel (SSK) approach from (Bunescu and Mooney, 2005), which was shown to give good results on extracting interactions from biomedical abstracts. The subsequence kernel was trained on a set of 225 Medline abstracts which were manually 2URL: http://opennlp.sourceforge.net 53 annotated with protein names and their interactions. It is known that PMI gives undue importance to low frequency events (Dunning, 1993), therefore the evaluation considers only pairs of genes that occur at least 5 times in the whole corpus. When evaluating corpus-level extraction on HPRD, because the “quasi-exact” list of interactions is known, we report the precision-recall</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005. Subsequence kernels for relation extraction. In Proceedings of the Conference on Neural Information Processing Systems, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick W Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="9410" citStr="Church and Hanks, 1990" startWordPosition="1495" endWordPosition="1498">more often than one would expect if they were cited independently at random, then it is likely that they interact. The model used to compute the probability of random co-citation is based on the hypergeometric distribution (Lee et al., 2004; Jenssen et al., 2001). Thus, ifNis the total number of abstracts,nof which cite the first protein, mcite the second protein, andkcite both, then the probability of co-citation under a random model is: Cnk/\Nnm—k P(kjN; m; n) =N (1) Cm their interaction. To compute the of between two we use the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and 1999), which is computed based on the following quantities: 1. N the total number of protein pairs cooccurring in the same sentence in the corpus. 2. P(p p2) n12 N : the probability that “degree interaction” proteinsp1andp2, Sch¨utze, 1; &apos; = 1andp2co-occur in the same sentence;n12= the number of sentences mentioning both p and 2 1 p . 3. P(p p) N: the probability that p cooccurs with any other protein in the same sentence; n = the number of sentences mentioning p and p. 4. P(p2 p) n2 N : the probability that p2 cooccurs with any other protein in the same sentence; n2 = the number</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick W. Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron M Cohen</author>
</authors>
<title>Unsupervised gene/protein named entity normalization using automatically extracted dictionaries.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: Minining Biological Semantics,</booktitle>
<pages>17--24</pages>
<location>Detroit, MI.</location>
<contexts>
<context position="16887" citStr="Cohen, 2005" startWordPosition="2704" endWordPosition="2705">s an interaction between the two genes. Finding the two genes collocated in the same sentence in the abstract is very likely to be due to the fact that the abstract discusses their interaction. The heuristic can be made even more accurate if a pair of genes is considered as interacting only if they cooccur in a (predefined) minimum number of sentences in the entire corpus – with the evaluation modified accordingly, as described later in Section 6. 5.2 Gene Name Annotation and Normalization For the annotation of gene names and their normalization, we use a dictionary-based approach similar to (Cohen, 2005). NCBI1 provides a comprehensive dictionary of human genes, where each gene is specified by its unique identifier, and qualified with an official name, a description, synonym names and one or more protein names, as illustrated in Table 2. All of these names, including the description, are considered as potential referential expressions for the gene entity. Each name string is reduced to a normal form by: replacing dashes with spaces, introducing spaces between sequences of letters and se1URL: http://www.ncbi.nih.gov quences of digits, replacing Greek letters with their Latin counterparts (capi</context>
</contexts>
<marker>Cohen, 2005</marker>
<rawString>Aaron M. Cohen. 2005. Unsupervised gene/protein named entity normalization using automatically extracted dictionaries. In Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: Minining Biological Semantics, pages 17–24, Detroit, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
</authors>
<title>Learning to extract relations from MEDLINE.</title>
<date>1999</date>
<booktitle>In Papers from the Sixteenth National Conference on Artificial Intelligence (AAAI-99) Workshop on Machine Learning for Information Extraction,</booktitle>
<pages>25--30</pages>
<contexts>
<context position="3279" citStr="Craven, 1999" startWordPosition="513" endWordPosition="514"> (Bader et al., 2003), DIP (Xenarios et al., 2002), and HPRD (Peri et al., 2004) databases. The amount of human effort involved in creating and updating these databases is currently no match for the continuous growth of Medline. It is therefore very useful to have a method that automatically and reliably extracts interaction pairs from Medline. Systems that do relation extraction from a collection of documents can be divided into two major categories. In one category are IE systems that first extract information from individual sentences, and then combine the results into corpuslevel results (Craven, 1999; Skounakis and Craven, 2003). The second category corresponds to approaches that do not exploit much information from the context of individual occurrences. Instead, based on co-occurrence counts, various statistical 49 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics or information-theoretic tests are used to decide whether the two entities in a pair appear together more often than simple chance would predict (Lee et al., 2004; Ramani et al., 2005). We</context>
<context position="16119" citStr="Craven, 1999" startWordPosition="2576" endWordPosition="2577">id in HPRD, then consider that the abstract (and consequently the entire HPRD corpus) reports the interaction betweengid,andgide.■ An application of the above heuristic is shown at the bottom of Table 2. The HPRD record at the top of the table specifies that the Medline article with ID 10984498 reports an interaction between the proteins FATZ (with ID 58529) and gamma-filamin (with ID 2318). The two protein names are mentioned in a sentence in the abstract for 10984498, therefore, by [H], we consider that the HPRD corpus reports this interaction. This is very similar to the procedure used in (Craven, 1999) for creating a “weakly-labeled” dataset of subcellular-localization relations. [H] is a strong heuristic – it is already known that the full article reports an interaction between the two genes. Finding the two genes collocated in the same sentence in the abstract is very likely to be due to the fact that the abstract discusses their interaction. The heuristic can be made even more accurate if a pair of genes is considered as interacting only if they cooccur in a (predefined) minimum number of sentences in the entire corpus – with the evaluation modified accordingly, as described later in Sec</context>
</contexts>
<marker>Craven, 1999</marker>
<rawString>Mark Craven. 1999. Learning to extract relations from MEDLINE. In Papers from the Sixteenth National Conference on Artificial Intelligence (AAAI-99) Workshop on Machine Learning for Information Extraction, pages 25–30, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="19485" citStr="Dunning, 1993" startWordPosition="3099" endWordPosition="3100">abstracts, either from the HPRD corpus, or from the entire Medline, are annotated using the dictionary-based approach described in Section 5.2. The sentence-level extraction is done with the subsequence kernel (SSK) approach from (Bunescu and Mooney, 2005), which was shown to give good results on extracting interactions from biomedical abstracts. The subsequence kernel was trained on a set of 225 Medline abstracts which were manually 2URL: http://opennlp.sourceforge.net 53 annotated with protein names and their interactions. It is known that PMI gives undue importance to low frequency events (Dunning, 1993), therefore the evaluation considers only pairs of genes that occur at least 5 times in the whole corpus. When evaluating corpus-level extraction on HPRD, because the “quasi-exact” list of interactions is known, we report the precision-recall (PR) graphs, where the precision (P) and recall (R) are computed as follows: P=#true interactions extracted #total interaction extracted R = #true interactions extracted #true interactions All pairs of proteins are ranked based on each scoring method, and precision recall points are computed by considering the topNpairs, whereN varies from 1 to the total </context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Jenssen</author>
<author>A Laegreid</author>
<author>J Komorowski</author>
<author>E Hovig</author>
</authors>
<title>A literature network of human genes for high-throughput analysis of gene expression.</title>
<date>2001</date>
<journal>Nature Genetics,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="9051" citStr="Jenssen et al., 2001" startWordPosition="1439" endWordPosition="1442"> relationship. A recent example is the co-citation approach from (Ramani et al., 2005), which does not try to find specific assertions of interactions in text, but rather exploits the idea that if many different abstracts reference both proteinp1and proteinp2, thenp1andp2 are likely to interact. Particularly, if the two proteins are co-cited significantly more often than one would expect if they were cited independently at random, then it is likely that they interact. The model used to compute the probability of random co-citation is based on the hypergeometric distribution (Lee et al., 2004; Jenssen et al., 2001). Thus, ifNis the total number of abstracts,nof which cite the first protein, mcite the second protein, andkcite both, then the probability of co-citation under a random model is: Cnk/\Nnm—k P(kjN; m; n) =N (1) Cm their interaction. To compute the of between two we use the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and 1999), which is computed based on the following quantities: 1. N the total number of protein pairs cooccurring in the same sentence in the corpus. 2. P(p p2) n12 N : the probability that “degree interaction” proteinsp1andp2, Sc</context>
</contexts>
<marker>Jenssen, Laegreid, Komorowski, Hovig, 2001</marker>
<rawString>T. K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig. 2001. A literature network of human genes for high-throughput analysis of gene expression. Nature Genetics, 28(1):21–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Joshi-Tope</author>
<author>M Gillespie</author>
<author>I Vastrik</author>
<author>P D’Eustachio</author>
<author>E Schmidt</author>
<author>B de Bono</author>
<author>B Jassal</author>
<author>G R Gopinath</author>
<author>G R Wu</author>
<author>L Matthews</author>
</authors>
<title>Reactome: a knowledgebase of biological pathways.</title>
<date>2005</date>
<journal>Nucleic Acids Research,</journal>
<volume>33</volume>
<note>Database Issue:D428–432.</note>
<marker>Joshi-Tope, Gillespie, Vastrik, D’Eustachio, Schmidt, de Bono, Jassal, Gopinath, Wu, Matthews, 2005</marker>
<rawString>G. Joshi-Tope, M. Gillespie, I. Vastrik, P. D’Eustachio, E. Schmidt, B. de Bono, B. Jassal, G. R. Gopinath, G. R. Wu, L. Matthews, and et al. 2005. Reactome: a knowledgebase of biological pathways. Nucleic Acids Research, 33 Database Issue:D428–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kanehisa</author>
<author>S Goto</author>
<author>S Kawashima</author>
<author>Y Okuno</author>
<author>M Hattori</author>
</authors>
<title>The KEGG resource for deciphering the genome.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<note>Database issue:D277–280.</note>
<contexts>
<context position="20543" citStr="Kanehisa et al., 2004" startWordPosition="3262" endWordPosition="3265">pairs of proteins are ranked based on each scoring method, and precision recall points are computed by considering the topNpairs, whereN varies from 1 to the total number of pairs. When evaluating on the entire Medline, we used the shared protein function benchmark described in (Ramani et al., 2005). Given the set of interacting pairs recovered at each recall level, this benchmark calculates the extent to which interaction partners in a data set share functional annotation, a measure previously shown to correlate with the accuracy of functional genomics data sets (Lee et al., 2004). The KEGG (Kanehisa et al., 2004) and Gene Ontology (Ashburner et al., 2000) databases provide specific pathway and biological process annotations for approximately 7,500 human genes, assigning human genes into 155 KEGG pathways (at the lowest level of KEGG) and 1,356 GO pathways (at level 8 of the GO biological process annotation). The scoring scheme for measuring interaction set accuracy is in the form of a log odds ratio of gene pairs sharing functional annotations. To evaluate a data set, a log likelihood ratio (LLR) is calculated as follows: P(DjI) =lnP(IjD)P(:I)(7) P(:IjD)P(I) where P (DjI) and P (Dj: I) are the probabi</context>
</contexts>
<marker>Kanehisa, Goto, Kawashima, Okuno, Hattori, 2004</marker>
<rawString>M. Kanehisa, S. Goto, S. Kawashima, Y. Okuno, and M. Hattori. 2004. The KEGG resource for deciphering the genome. Nucleic Acids Research, 32 Database issue:D277–280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Lee</author>
<author>S V Date</author>
<author>A T Adai</author>
<author>E M Marcotte</author>
</authors>
<title>A probabilistic functional network of yeast genes.</title>
<date>2004</date>
<journal>Science,</journal>
<volume>306</volume>
<issue>5701</issue>
<contexts>
<context position="3853" citStr="Lee et al., 2004" startWordPosition="596" endWordPosition="599">lts into corpuslevel results (Craven, 1999; Skounakis and Craven, 2003). The second category corresponds to approaches that do not exploit much information from the context of individual occurrences. Instead, based on co-occurrence counts, various statistical 49 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics or information-theoretic tests are used to decide whether the two entities in a pair appear together more often than simple chance would predict (Lee et al., 2004; Ramani et al., 2005). We believe that a combination of the two approaches can inherit the advantages of each method and lead to improved relation extraction accuracy. The following two sections describe the two orthogonal approaches to corpus-level relation extraction. A model that integrates the two approaches is then introduced in Section 4. This is followed by a description of the dataset used for evaluation in Section 5, and experimental results in Section 6. 2 Sentence-level relation extraction Most systems that identify relations between entities mentioned in text documents consider on</context>
<context position="9028" citStr="Lee et al., 2004" startWordPosition="1435" endWordPosition="1438">r to an underlying relationship. A recent example is the co-citation approach from (Ramani et al., 2005), which does not try to find specific assertions of interactions in text, but rather exploits the idea that if many different abstracts reference both proteinp1and proteinp2, thenp1andp2 are likely to interact. Particularly, if the two proteins are co-cited significantly more often than one would expect if they were cited independently at random, then it is likely that they interact. The model used to compute the probability of random co-citation is based on the hypergeometric distribution (Lee et al., 2004; Jenssen et al., 2001). Thus, ifNis the total number of abstracts,nof which cite the first protein, mcite the second protein, andkcite both, then the probability of co-citation under a random model is: Cnk/\Nnm—k P(kjN; m; n) =N (1) Cm their interaction. To compute the of between two we use the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and 1999), which is computed based on the following quantities: 1. N the total number of protein pairs cooccurring in the same sentence in the corpus. 2. P(p p2) n12 N : the probability that “degree interacti</context>
<context position="20509" citStr="Lee et al., 2004" startWordPosition="3256" endWordPosition="3259">acted #true interactions All pairs of proteins are ranked based on each scoring method, and precision recall points are computed by considering the topNpairs, whereN varies from 1 to the total number of pairs. When evaluating on the entire Medline, we used the shared protein function benchmark described in (Ramani et al., 2005). Given the set of interacting pairs recovered at each recall level, this benchmark calculates the extent to which interaction partners in a data set share functional annotation, a measure previously shown to correlate with the accuracy of functional genomics data sets (Lee et al., 2004). The KEGG (Kanehisa et al., 2004) and Gene Ontology (Ashburner et al., 2000) databases provide specific pathway and biological process annotations for approximately 7,500 human genes, assigning human genes into 155 KEGG pathways (at the lowest level of KEGG) and 1,356 GO pathways (at level 8 of the GO biological process annotation). The scoring scheme for measuring interaction set accuracy is in the form of a log odds ratio of gene pairs sharing functional annotations. To evaluate a data set, a log likelihood ratio (LLR) is calculated as follows: P(DjI) =lnP(IjD)P(:I)(7) P(:IjD)P(I) where P (</context>
</contexts>
<marker>Lee, Date, Adai, Marcotte, 2004</marker>
<rawString>I. Lee, S. V. Date, A. T. Adai, and E. M. Marcotte. 2004. A probabilistic functional network of yeast genes. Science, 306(5701):1555–1558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judea Pearl</author>
</authors>
<title>Fusion, propagation, and structuring in belief networks.</title>
<date>1986</date>
<journal>Artificial Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="7342" citStr="Pearl, 1986" startWordPosition="1171" endWordPosition="1172">Out of the four operators in Table 1, we believe that the max operator is the most appropriate for aggregating confidence values at the corpus-level. The question that needs to be answered is whether there is a sentence somewhere in the corpus that asserts the relationship R between entities p1 and p2. Using avg instead would answer a different question - whether R(p1; p2) is true in most of the sentences containing p1 and p2. Also, the and operator would be most appropriate for finding whether R(p1; p2) is true in all corresponding sentences in the corpus. The value of the noisy-or operator (Pearl, 1986) is too dependent on the number of occurrences, therefore it is less appropriate for a corpus where the occurrence counts vary from one entity pair to another (as confirmed in our experiments from Section 6). For examples, if the confidence threshold is set at 0:5, and the entity pair(p1;p2)occurs in 6 sentences or less, each with confidence0:1, thenR(p1;p2)is false, according to the noisy-or operator. However, if(p1;p2)occur in more than 6 sentences, with the same confidence value of 0:1, then the corresponding noisy-or value exceeds 0:5, making R(p1; p2) true. 50 3 Co-occurrence statistics G</context>
</contexts>
<marker>Pearl, 1986</marker>
<rawString>Judea Pearl. 1986. Fusion, propagation, and structuring in belief networks. Artificial Intelligence, 29(3):241–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Peri</author>
<author>J D Navarro</author>
<author>T Z Kristiansen</author>
<author>R Amanchy</author>
<author>V Surendranath</author>
<author>B Muthusamy</author>
<author>T K Gandhi</author>
<author>K N Chandrika</author>
<author>N Deshpande</author>
<author>S Suresh</author>
</authors>
<title>Human protein reference database as a discovery resource for proteomics.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<note>Database issue:D497–501.</note>
<contexts>
<context position="2747" citStr="Peri et al., 2004" startWordPosition="426" endWordPosition="429">vestigate methods that use multiple occurrences of the same pair of entities across a collection of documents in order to boost the performance of a relation extraction system. The proposed methods are evaluated on the task of finding pairs of human proteins whose interactions are reported in Medline abstracts. The majority of known human protein interactions are derived from individual, small-scale experiments reported in Medline. Some of these interactions have already been collected in the Reactome (Joshi-Tope et al., 2005), BIND (Bader et al., 2003), DIP (Xenarios et al., 2002), and HPRD (Peri et al., 2004) databases. The amount of human effort involved in creating and updating these databases is currently no match for the continuous growth of Medline. It is therefore very useful to have a method that automatically and reliably extracts interaction pairs from Medline. Systems that do relation extraction from a collection of documents can be divided into two major categories. In one category are IE systems that first extract information from individual sentences, and then combine the results into corpuslevel results (Craven, 1999; Skounakis and Craven, 2003). The second category corresponds to ap</context>
<context position="12952" citStr="Peri et al., 2004" startWordPosition="2125" endWordPosition="2128">corpus (Section 5.1). 2. Annotation of mentions of genes and proteins, together with their corresponding gene identifiers (Section 5.2). We do not differentiate between genes and their protein products, mapping them to the same gene identifiers. Also, even though proteins may participate in different types of interactions, we are concerned only with detecting whether they interact in the general sense of the word. 5.1 Medline Abstracts and Interactions In order to compile an evaluation corpus and an associated comprehensive list of interactions, we exploited information contained in the HPRD (Peri et al., 2004) database. Every interaction listed in HPRD is linked to a set of Medline articles where the corresponding experiment is reported. More exactly, each interaction is specified in the database as a tuple that contains the LocusLink (now EntrezGene) identifiers of all genes involved and the PubMed identifiers of the corresponding articles (as illustrated in Table 2). Interaction (XML) (HPRD) &lt;interaction&gt; &lt;gene&gt;2318&lt;/gene&gt; &lt;gene&gt; 58529 &lt;/gene&gt; &lt;pubmed&gt; 10984498 11 1 71996&lt;/pubmed&gt; &lt;/interaction&gt; Participant Genes (XML) (NCBI) &lt;gene id=”2318”&gt; &lt;name&gt;FLNC &lt;/name&gt; &lt;description&gt;filaminC, gamma&lt;/descr</context>
</contexts>
<marker>Peri, Navarro, Kristiansen, Amanchy, Surendranath, Muthusamy, Gandhi, Chandrika, Deshpande, Suresh, 2004</marker>
<rawString>S. Peri, J. D. Navarro, T. Z. Kristiansen, R. Amanchy, V. Surendranath, B. Muthusamy, T. K. Gandhi, K. N. Chandrika, N. Deshpande, S. Suresh, and et al. 2004. Human protein reference database as a discovery resource for proteomics. Nucleic Acids Research, 32 Database issue:D497–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Ramani</author>
<author>R C Bunescu</author>
<author>R J Mooney</author>
<author>E M Marcotte</author>
</authors>
<title>Consolidating the set of know human proteinprotein interactions in preparation for large-scale mapping of the human interactome.</title>
<date>2005</date>
<journal>Genome Biology,</journal>
<volume>6</volume>
<issue>5</issue>
<contexts>
<context position="3875" citStr="Ramani et al., 2005" startWordPosition="600" endWordPosition="603">el results (Craven, 1999; Skounakis and Craven, 2003). The second category corresponds to approaches that do not exploit much information from the context of individual occurrences. Instead, based on co-occurrence counts, various statistical 49 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics or information-theoretic tests are used to decide whether the two entities in a pair appear together more often than simple chance would predict (Lee et al., 2004; Ramani et al., 2005). We believe that a combination of the two approaches can inherit the advantages of each method and lead to improved relation extraction accuracy. The following two sections describe the two orthogonal approaches to corpus-level relation extraction. A model that integrates the two approaches is then introduced in Section 4. This is followed by a description of the dataset used for evaluation in Section 5, and experimental results in Section 6. 2 Sentence-level relation extraction Most systems that identify relations between entities mentioned in text documents consider only pair of entities th</context>
<context position="8516" citStr="Ramani et al., 2005" startWordPosition="1353" endWordPosition="1356">(p1; p2) true. 50 3 Co-occurrence statistics Given two entities with multiple mentions in a large corpus, another approach to detect whether a relationship holds between them is to use statistics over their occurrences in textual patterns that are indicative for that relation. Various measures such as pointwise mutual information (PMI) , chi-square (X2) or log-likelihood ratio (LLR) (Manning and Sch¨utze, 1999) use the two entities’ occurrence statistics to detect whether their co-occurrence is due to chance, or to an underlying relationship. A recent example is the co-citation approach from (Ramani et al., 2005), which does not try to find specific assertions of interactions in text, but rather exploits the idea that if many different abstracts reference both proteinp1and proteinp2, thenp1andp2 are likely to interact. Particularly, if the two proteins are co-cited significantly more often than one would expect if they were cited independently at random, then it is likely that they interact. The model used to compute the probability of random co-citation is based on the hypergeometric distribution (Lee et al., 2004; Jenssen et al., 2001). Thus, ifNis the total number of abstracts,nof which cite the fi</context>
<context position="20221" citStr="Ramani et al., 2005" startWordPosition="3211" endWordPosition="3214">ating corpus-level extraction on HPRD, because the “quasi-exact” list of interactions is known, we report the precision-recall (PR) graphs, where the precision (P) and recall (R) are computed as follows: P=#true interactions extracted #total interaction extracted R = #true interactions extracted #true interactions All pairs of proteins are ranked based on each scoring method, and precision recall points are computed by considering the topNpairs, whereN varies from 1 to the total number of pairs. When evaluating on the entire Medline, we used the shared protein function benchmark described in (Ramani et al., 2005). Given the set of interacting pairs recovered at each recall level, this benchmark calculates the extent to which interaction partners in a data set share functional annotation, a measure previously shown to correlate with the accuracy of functional genomics data sets (Lee et al., 2004). The KEGG (Kanehisa et al., 2004) and Gene Ontology (Ashburner et al., 2000) databases provide specific pathway and biological process annotations for approximately 7,500 human genes, assigning human genes into 155 KEGG pathways (at the lowest level of KEGG) and 1,356 GO pathways (at level 8 of the GO biologic</context>
</contexts>
<marker>Ramani, Bunescu, Mooney, Marcotte, 2005</marker>
<rawString>A. K. Ramani, R. C. Bunescu, R. J. Mooney, and E. M. Marcotte. 2005. Consolidating the set of know human proteinprotein interactions in preparation for large-scale mapping of the human interactome. Genome Biology, 6(5):r40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soumya Ray</author>
<author>Mark Craven</author>
</authors>
<title>Representing sentence structure in hidden Markov models for information extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001),</booktitle>
<pages>1273--1279</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="4534" citStr="Ray and Craven, 2001" startWordPosition="706" endWordPosition="709">two approaches can inherit the advantages of each method and lead to improved relation extraction accuracy. The following two sections describe the two orthogonal approaches to corpus-level relation extraction. A model that integrates the two approaches is then introduced in Section 4. This is followed by a description of the dataset used for evaluation in Section 5, and experimental results in Section 6. 2 Sentence-level relation extraction Most systems that identify relations between entities mentioned in text documents consider only pair of entities that are mentioned in the same sentence (Ray and Craven, 2001; Zhao and Grishman, 2005; Bunescu and Mooney, 2005). To decide the existence and the type of a relationship, these systems generally use lexico-semantic clues inferred from the sentence context of the two entities. Much research has been focused recently on automatically identifying biologically relevant entities and their relationships such as protein-protein interactions or subcellular localizations. For example, the sentence “TR6 specifically binds Fas ligand”, states an interaction between the two proteins TR6 and Fas ligand. One of the first systems for extracting interactions between pr</context>
</contexts>
<marker>Ray, Craven, 2001</marker>
<rawString>Soumya Ray and Mark Craven. 2001. Representing sentence structure in hidden Markov models for information extraction. In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001), pages 1273–1279, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rzhetsky</author>
<author>T Iossifov</author>
<author>I Koike</author>
<author>M Krauthammer</author>
<author>P Kra</author>
<author>M Morris</author>
<author>H Yu</author>
<author>P A Duboue</author>
<author>W Weng</author>
<author>W J Wilbur</author>
<author>V Hatzivassiloglou</author>
<author>C Friedman</author>
</authors>
<title>GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data.</title>
<date>2004</date>
<journal>Journal ofBiomedical Informatics,</journal>
<pages>37--43</pages>
<contexts>
<context position="24299" citStr="Rzhetsky et al., 2004" startWordPosition="3887" endWordPosition="3890">mparison of the four aggregation operators on the same HPRD corpus, which confirms that, overall, max is most appropriate for integrating corpus-level results. 9 Future Work The piece of related work that is closest to the aim of this paper is the Bayesian approach from (Skounakis and Craven, 2003). In their probabilistic model, cooccurrence statistics are taken into account by using a prior probability that a pair of proteins are interacting, given the number of co-occurrences in the corpus. However, they do not use the confidences of the sentence-level extractions. The GeneWays system from (Rzhetsky et al., 2004) takes a different approach, in which co-occurrence frequencies are simply used to re-rank the ouput from the relation extractor. An interesting direction for future research is to 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Figure 3: PR curves for aggregation operators. design a model that takes into account both the extraction confidences and the co-occurrence statistics, without losing the probabilistic (or informationtheoretic) interpretation. One could investigate ways of integrating the two orthogonal approaches to corpus-level extraction based on other statistical tests, such as chi-</context>
</contexts>
<marker>Rzhetsky, Iossifov, Koike, Krauthammer, Kra, Morris, Yu, Duboue, Weng, Wilbur, Hatzivassiloglou, Friedman, 2004</marker>
<rawString>A. Rzhetsky, T. Iossifov, I. Koike, M. Krauthammer, P. Kra, M. Morris, H. Yu, P.A. Duboue, W. Weng, W.J. Wilbur, V. Hatzivassiloglou, and C. Friedman. 2004. GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data. Journal ofBiomedical Informatics, 37:43–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marios Skounakis</author>
<author>Mark Craven</author>
</authors>
<title>Evidence combination in biomedical natural-language processing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 3nd ACM SIGKDD Workshop on Data Mining in Bioinformatics (BIOKDD</booktitle>
<pages>25--32</pages>
<location>Washington, DC.</location>
<contexts>
<context position="3308" citStr="Skounakis and Craven, 2003" startWordPosition="515" endWordPosition="518">, 2003), DIP (Xenarios et al., 2002), and HPRD (Peri et al., 2004) databases. The amount of human effort involved in creating and updating these databases is currently no match for the continuous growth of Medline. It is therefore very useful to have a method that automatically and reliably extracts interaction pairs from Medline. Systems that do relation extraction from a collection of documents can be divided into two major categories. In one category are IE systems that first extract information from individual sentences, and then combine the results into corpuslevel results (Craven, 1999; Skounakis and Craven, 2003). The second category corresponds to approaches that do not exploit much information from the context of individual occurrences. Instead, based on co-occurrence counts, various statistical 49 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics or information-theoretic tests are used to decide whether the two entities in a pair appear together more often than simple chance would predict (Lee et al., 2004; Ramani et al., 2005). We believe that a combination o</context>
<context position="23976" citStr="Skounakis and Craven, 2003" startWordPosition="3835" endWordPosition="3838"> three human curated databases: HPRD, BIND and Reactome. On the top 18,000 protein pairs, PMI outperforms HG substantially, after which both converge to the same value for all the remaining pairs. 2500 5000 7500 10000 12500 15000 17500 20000 22500 25000 Top N pairs Figure 2: Functional annotation benchmark. Figure 3 shows a comparison of the four aggregation operators on the same HPRD corpus, which confirms that, overall, max is most appropriate for integrating corpus-level results. 9 Future Work The piece of related work that is closest to the aim of this paper is the Bayesian approach from (Skounakis and Craven, 2003). In their probabilistic model, cooccurrence statistics are taken into account by using a prior probability that a pair of proteins are interacting, given the number of co-occurrences in the corpus. However, they do not use the confidences of the sentence-level extractions. The GeneWays system from (Rzhetsky et al., 2004) takes a different approach, in which co-occurrence frequencies are simply used to re-rank the ouput from the relation extractor. An interesting direction for future research is to 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Figure 3: PR curves for aggregation operators. de</context>
</contexts>
<marker>Skounakis, Craven, 2003</marker>
<rawString>Marios Skounakis and Mark Craven. 2003. Evidence combination in biomedical natural-language processing. In Proceedings of the 3nd ACM SIGKDD Workshop on Data Mining in Bioinformatics (BIOKDD 2003), pages 25–32, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Xenarios</author>
<author>L Salwinski</author>
<author>X J Duan</author>
<author>P Higney</author>
<author>S M Kim</author>
<author>D Eisenberg</author>
</authors>
<title>DIP, the database of interacting proteins: a research tool for studying cellular networks of protein interactions.</title>
<date>2002</date>
<journal>Nucleic Acids Research,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="2717" citStr="Xenarios et al., 2002" startWordPosition="420" endWordPosition="423">eir research. In this paper, we investigate methods that use multiple occurrences of the same pair of entities across a collection of documents in order to boost the performance of a relation extraction system. The proposed methods are evaluated on the task of finding pairs of human proteins whose interactions are reported in Medline abstracts. The majority of known human protein interactions are derived from individual, small-scale experiments reported in Medline. Some of these interactions have already been collected in the Reactome (Joshi-Tope et al., 2005), BIND (Bader et al., 2003), DIP (Xenarios et al., 2002), and HPRD (Peri et al., 2004) databases. The amount of human effort involved in creating and updating these databases is currently no match for the continuous growth of Medline. It is therefore very useful to have a method that automatically and reliably extracts interaction pairs from Medline. Systems that do relation extraction from a collection of documents can be divided into two major categories. In one category are IE systems that first extract information from individual sentences, and then combine the results into corpuslevel results (Craven, 1999; Skounakis and Craven, 2003). The sec</context>
</contexts>
<marker>Xenarios, Salwinski, Duan, Higney, Kim, Eisenberg, 2002</marker>
<rawString>I. Xenarios, L. Salwinski, X. J. Duan, P. Higney, S. M. Kim, and D. Eisenberg. 2002. DIP, the database of interacting proteins: a research tool for studying cellular networks of protein interactions. Nucleic Acids Research, 30(1):303–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shubin Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>419--426</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4559" citStr="Zhao and Grishman, 2005" startWordPosition="710" endWordPosition="713">erit the advantages of each method and lead to improved relation extraction accuracy. The following two sections describe the two orthogonal approaches to corpus-level relation extraction. A model that integrates the two approaches is then introduced in Section 4. This is followed by a description of the dataset used for evaluation in Section 5, and experimental results in Section 6. 2 Sentence-level relation extraction Most systems that identify relations between entities mentioned in text documents consider only pair of entities that are mentioned in the same sentence (Ray and Craven, 2001; Zhao and Grishman, 2005; Bunescu and Mooney, 2005). To decide the existence and the type of a relationship, these systems generally use lexico-semantic clues inferred from the sentence context of the two entities. Much research has been focused recently on automatically identifying biologically relevant entities and their relationships such as protein-protein interactions or subcellular localizations. For example, the sentence “TR6 specifically binds Fas ligand”, states an interaction between the two proteins TR6 and Fas ligand. One of the first systems for extracting interactions between proteins is described in (B</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 419–426, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>