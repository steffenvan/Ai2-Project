<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.042034">
<title confidence="0.9991945">
A Multi-Representational and Multi-Layered
Treebank for Hindi/Urdu
</title>
<author confidence="0.996419">
Rajesh Bhatt
</author>
<affiliation confidence="0.993171">
U. of Massachusetts
</affiliation>
<address confidence="0.809796">
Amherst, MA, USA
</address>
<email confidence="0.998959">
bhatt@linguist.umass.edu
</email>
<author confidence="0.998337">
Owen Rambow
</author>
<affiliation confidence="0.997966">
Columbia University
</affiliation>
<address confidence="0.802073">
New York, NY, USA
</address>
<email confidence="0.996734">
rambow@ccls.columbia.edu
</email>
<author confidence="0.986028">
Bhuvana Narasimhan
</author>
<affiliation confidence="0.989568">
U. of Colorado
</affiliation>
<address confidence="0.775907">
Boulder, CO, USA
</address>
<email confidence="0.998926">
narasimb@colorado.edu
</email>
<author confidence="0.997817">
Dipti Misra Sharma
</author>
<affiliation confidence="0.8928095">
Int’l Institute of Info. Technology
Hyderabad, India
</affiliation>
<email confidence="0.975949">
dipti@iiit.ac.in
</email>
<author confidence="0.971099">
Martha Palmer
</author>
<affiliation confidence="0.981215">
U. of Colorado
</affiliation>
<address confidence="0.77643">
Boulder, CO, USA
</address>
<email confidence="0.999116">
mpalmer@colorado.edu
</email>
<author confidence="0.998683">
Fei Xia
</author>
<affiliation confidence="0.999252">
University of Washington
</affiliation>
<address confidence="0.891263">
Seattle, WA, USA
</address>
<email confidence="0.997887">
fxia@u.washington.edu
</email>
<sectionHeader confidence="0.995628" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999828888888889">
This paper describes the simultaneous develop-
ment of dependency structure and phrase structure
treebanks for Hindi and Urdu, as well as a Prop-
Bank. The dependency structure and the Prop-
Bank are manually annotated, and then the phrase
structure treebank is produced automatically. To
ensure successful conversion the development of
the guidelines for all three representations are care-
fully coordinated.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999825729166667">
Annotated corpora have played an increasingly
important role in the training of supervised natu-
ral language processing components. Today,
treebanks have been constructed for many lan-
guages, including Arabic, Chinese, Czech, Eng-
lish, French, German, Korean, Spanish, and
Turkish. This paper describes the creation of a
Hindi/Urdu multi-representational and multi-
layered treebank. Multi-layered means that we
design the annotation process from the outset to
include both a syntactic annotation and a lexical
semantic annotation such as the English Prop-
Bank (Palmer et al. 2005). Multi-
representational means that we distinguish con-
ceptually what is being represented from how it
is represented; for example, in a case of long-
distance wh-movement in English as in Who do
you think will come, we can choose to represent
the fact that who is an argument of come, or not
(what to represent). Having made this choice,
we can determine how to represent it: For exam-
ple, we can use a discontinuous constituent
(crossing arcs), or we can use a trace and co-
indexation.
Flexibility of representation is important be-
cause the proper choice of representation of the
syntax of a language is itself an issue in parsing
research. In the application of the Collins parser
to the Prague Dependency Treebank (Collins et
al. 1999) the automatic mapping from depend-
ency to phrase-structure was a major area of re-
search. Similarly, automatically changing the
representation in a phrase structure treebank can
also improve parsing results (for example Klein
&amp; Manning 2003). Finally, there is increasing
interest in the use of dependency parses in NLP
applications, as they are considered to be simpler
structures which can be computed more rapidly
and are closer to the kinds of semantic represen-
tations that applications can make immediate use
of (McDonald et al. 2005, CoNLL 2006 Shared
Task). We first provide a comparison of de-
pendency structure and phrase structure in Sec-
tion 2. Section 3 describes our treebank, Section
4 explores language-specific linguistic issues that
require special attention to ensure consistent
conversion, and Section 5 summarizes our con-
version approach.
</bodyText>
<sectionHeader confidence="0.905708" genericHeader="method">
2 Two Kinds of Syntactic Structure
</sectionHeader>
<bodyText confidence="0.995532166666667">
Two different approaches to describing syntactic
structure, dependency structure (DS) (Mel’čuk
1979) and phrase structure (PS) (Chomsky,
1981), have in a sense divided the field in two,
with parallel efforts on both sides. Formally, in a
PS tree, all and only the leaf nodes are labeled
</bodyText>
<page confidence="0.983915">
186
</page>
<note confidence="0.957431">
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 186–189,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999934127272727">
with words from the sentence (or empty catego-
ries), while the interior nodes are labeled with
nonterminal labels. In a dependency tree, all
nodes are labeled with words from the sentence
(or empty categories). Linguistically, a PS
groups consecutive words hierarchically into
phrases (or constituents), and each phrase is as-
signed a syntactic label. In a DS, syntactic de-
pendency (i.e., the relation between a syntactic
head and its arguments and adjuncts) is the pri-
mary syntactic relation represented. The notion
of constituent is only derived.
In a dependency representation, a node stands for
itself, for the lexical category (or “preterminal”)
spanning only the word itself (e.g., N), and for its
maximal projection spanning the node and all
words in the subtree it anchors (e.g., NP). Thus,
intermediate projections which cover only some
of the dependents of a word (such as N’ or VP)
do not directly correspond to anything in a de-
pendency representation. Attachments at the dif-
ferent levels of projection are therefore not dis-
tinguished in a dependency tree. This has certain
ramifications for annotation. Conisder for ex-
ample scope in conjunctions. The two readings
of young men and women can be distinguished
(are the women young as well or not?). If a de-
pendency representation represents conjunction
by treating the conjunction as a dependent to the
first conjunct, then the two readings do not re-
ceive different syntactic representations, unless a
scope feature is introduced for the adjective.
Suppose y depends on x in a DS, we need to ad-
dress the following questions in order to devise a
DS-to-PS conversion algorithm that builds the
corresponding phrase structure: 1) What kinds of
projections do x and y have? 2) How far should y
project before it attaches to x&apos;s projection? 3) What
position on x&apos;s projection chain should y&apos;s projec-
tion attach to? These questions are answered by
the annotation manual of the target PS represen-
tation – there are many possible answers. If the
source dependency representation contains the
right kind of information (for example, the scope
of adjectives in conjunctions), and if the target
phrase structure representation is well docu-
mented, then we can devise a conversion algo-
rithm.
Another important issue is that of “non-
projectivity” which is used to represent discon-
tinuous constituents. Non-projectivity is common
in dependency-based syntactic theories, but rare
in phrase structure-based theories. The next sec-
tion highlights our most salient representation
choices in Treebank design.
</bodyText>
<sectionHeader confidence="0.989225" genericHeader="method">
3 Treebank Design
</sectionHeader>
<bodyText confidence="0.999984382978723">
Our goal is the delivery of a treebank that is
multi-representational: it will have a syntactic
dependency version and a phrase structure ver-
sion. Another recent trend in treebanking is the
addition of deeper, semantic levels of annotation
on top of the syntactic annotations of the PTB,
for example PropBank (Palmer et al. 2005). A
multi-layered approach is also found in the Pra-
gue Dependency Treebank (Hajič et al. 2001), or
in treebanks based on LFG (King et al. 2003) or
HPSG (Oepen et al. 2002). A lesson learned here
is that the addition of deeper, more semantic lev-
els may be complicated if the syntactic annota-
tion was not designed with the possibility of mul-
tiple layers of annotation in mind. We therefore
also propose a treebank that is from the start
multi-layered: we will include a PropBank-style
predicate-argument annotation in the release.
Crucially, the lexical subcategorization frames
that are made explicit during the process of prop-
banking should always inform the syntactic
structure of the treebanking effort. In addition,
some of the distinctions made by PS that are not
naturally present in DS, such as unaccusativity
and null arguments, are more naturally made dur-
ing PropBank annotation. Our current approach
anticipates that the addition of the PropBank an-
notation to the DS will provide a rich enough
structure for accurate PS conversion.
In order to ensure successful conversion from DS
to PS, we are simultaneously developing three
sets of guidelines for Hindi: dependency struc-
ture, phrase structure, and PropBank. While al-
lowing DS and PS guidelines to be based on dif-
ferent, independently motivated principles (see
Section 4), we have been going through a com-
prehensive list of constructions in Hindi, care-
fully exploring any potentially problematic is-
sues. Specifically, we make sure that both DS
and PS represent the same syntactic facts (what
is represented): we know that if PS makes a dis-
tinction that neither DS nor PropBank make, then
we cannot possibly convert automatically. Fur-
thermore, we coordinate the guidelines for DS
and PS with respect to the examples chosen to
support the conversion process. These examples
form a conversion test suite.
</bodyText>
<page confidence="0.998162">
187
</page>
<sectionHeader confidence="0.976854" genericHeader="method">
4 Syntactic Annotation Choices
</sectionHeader>
<subsectionHeader confidence="0.996179">
4.1 Dependency Structure Guidelines
</subsectionHeader>
<bodyText confidence="0.99999316">
Our dependency analysis is based on the Pan-
inian grammatical model (Bharati et al 1999,
Sharma et al. 2007). The model offers a syntac-
tico-semantic level of linguistic knowledge with
an especially transparent relationship between
the syntax and the semantics. The sentence is
treated as a series of modifier-modified relations
which has a primary modified (generally the
main verb). The appropriate syntactic cues (rela-
tion markers) help in identifying various rela-
tions. The relations are of two types – karaka
and others. &apos;Karakas&apos; are the roles of various par-
ticipants in an action (arguments). For a noun to
hold a karaka relation with a verb, it is important
that they (noun and verb) have a direct syntactic
relation. Relations other than &apos;karaka&apos; such as
purpose, reason, and possession are also captured
using the relational concepts of the model (ad-
juncts). These argument labels are very similar in
spirit to the verb specific semantic role labels
used by PropBank, which have already been suc-
cessfully mapped to richer semantic role labels
from VerbNet and FrameNet. This suggests that
much of the task of PropBanking can be done as
part of the dependency annotation.
</bodyText>
<subsectionHeader confidence="0.998383">
4.2 Phrase Structure Guidelines
</subsectionHeader>
<bodyText confidence="0.999979448275862">
Our PS guidelines are inspired by the Principles-
and-Parameters methodology, as instantiated by
the theoretical developments starting with Gov-
ernment and Binding Theory (Chomsky 1981).
We assume binary branching. There are three
theoretical commitments/design considerations
that underlie the guidelines. First, any minimal
clause distinguishes at most two positions struc-
turally (the core arguments). These positions can
be identified as the specifier of VP and the com-
plement of V. With a transitive predicate, these
positions are occupied by distinct NPs while with
an unaccusative or passive, the same NP occu-
pies both positions. All other NPs are represented
as adjuncts. Second, we represent any displace-
ment of core arguments from their canonical po-
sitions, irrespective of whether a clause boundary
is crossed, via traces. The displacement of other
arguments is only represented if a clause bound-
ary is crossed. Third, syntactic relationships such
as agreement and case always require c-
command but do not necessarily require a [speci-
fier, head] configuration. Within these con-
straints, we always choose the simplest structure
compatible with the word order. We work with a
very limited set of category labels (NP, AP,
AdvP, VP, CP) assuming that finer distinctions
between different kinds of verbal functional
heads can be made via features.
</bodyText>
<subsectionHeader confidence="0.999491">
4.3 Two Constructions in Hindi
</subsectionHeader>
<bodyText confidence="0.932501">
We give examples for two constructions in Hindi
and show the DS and PS for each.
Simple Transitive Clauses:
</bodyText>
<listItem confidence="0.778139">
(1) raam-ne khiir khaayii
</listItem>
<bodyText confidence="0.969643">
ram-erg rice-pudding ate
‘Ram ate rice-pudding.’
The two main arguments of the Hindi verb in
Figure 1(b) have dependency types k1 and k2.
They correspond roughly to subject and object,
and they are the only arguments that can agree
with the verb. In the PS, Figure 1(a), the two
arguments that correspond to k1 and k2 have
fixed positions in the phrase structure as ex-
plained in Section 4.2.
</bodyText>
<figureCaption confidence="0.99882">
Figure 1: PS and DS for transitive clause in (1).
</figureCaption>
<figure confidence="0.45302">
Unaccusative verbs:
(2) darwaazaa khul rahaa hai
door.M open Prog.MSg be.Prs.Sg
‘The door is opening.’
</figure>
<bodyText confidence="0.9987874">
Here, the issue is that the DS guidelines treats
unaccusatives like other intransitives, with the
surface argument simply annotated as k1. In
contrast, PS shows a derivation in which the sub-
ject originates in object position.
</bodyText>
<figureCaption confidence="0.991218">
Figure 2: PS and DS for the unaccusative in (2).
</figureCaption>
<sectionHeader confidence="0.996412" genericHeader="method">
5 Conversion Process
</sectionHeader>
<bodyText confidence="0.998791">
The DS-to-PS conversion process has three
steps. First, for each (DS, PS) pair appearing in
the conversion test suite, we run a consistency
</bodyText>
<page confidence="0.996888">
188
</page>
<bodyText confidence="0.999988777777778">
checking algorithm to determine whether the DS
and the PS are consistent. The inconsistent cases
are studied manually and if the inconsistency
cannot be resolved by changing the analyses
used in the guidelines, a new DS that is consis-
tent with the PS is proposed. We call this new
dependency structure “DScons” (“cons” for “con-
sistency”; DScons is the same as DS for the con-
sistent cases). Because the DS and PS guidelines
are carefully coordinated, we expect the incon-
sistent cases to be rare and well-motivated. Sec-
ond, conversion rules are extracted automatically
from these (DScons, PS) pairs. Last, given a new
DS, a PS is created by applying conversion rules.
Note that non-projective DSs will be converted
to projective DScons. (For an alternate account of
handling non-projective DSs, see Kuhlman and
Mšhl (2007).) A preliminary study on the Eng-
lish Penn Treebank showed promising results
and error analyses indicated that most conversion
errors were caused by ambiguous DS patterns in
the conversion rules. This implies that including
sufficient information in the input DS could re-
duce ambiguity, significantly improving the per-
formance of the conversion algorithm. The de-
tails of the conversion algorithm and the experi-
mental results are described in (Xia et al., 2009).
</bodyText>
<sectionHeader confidence="0.999234" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999972705882353">
We presented our approach to the joint develop-
ment of DS and PS treebanks and a PropBank for
Hindi/Urdu. Since from the inception of the pro-
ject we have planned manual annotation of DS
and automatic conversion to PS, we are develop-
ing the annotation guidelines for all structures in
parallel. A series of linguistic constructions with
specific examples are being carefully examined
for any DS annotation decisions that might result
in inconsistency between DS and PS and/or mul-
tiple conversion rules with identical DS patterns.
Our preliminary studies yield promising results,
indicating that coordinating the design of DS/PS
and PropBank guidelines and running the con-
version algorithm in the early stages is essential
to the success of building a multi-
representational and multi-layered treebank.
</bodyText>
<sectionHeader confidence="0.989273" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996202333333333">
This work is supported by NSF grants CNS-
0751089, CNS-0751171, CNS-0751202, and
CNS-0751213.
</bodyText>
<sectionHeader confidence="0.989939" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999529170212766">
A. Bharati, V. Chaitanya and R. Sangal. 1999. Natu-
ral Language Processesing: A Paninian Per-
spective, Prentice Hall of India, New Delhi.
N. Chomsky. 1981. Lectures on Government and
Binding: The Pisa Lectures. Holland: Foris Pub-
lications.
M. Collins, Jan Hajič, L. Ramshaw and C. Tillmann.
1999. A Statistical Parser for Czech. In the Proc
of ACL-1999, pages 505-512.
J. Hajič, E. Hajicova, M. Holub, P. Pajas, P. Sgall, B.
Vidova-Hladka, and V. Reznickova. 2001. The
Current Status of the Prague Dependency Tree-
bank. Lecture Notes in Artificial Intelligence
(LNAI) 2166, pp 11—20, NY.
T. H. King, R. Crouch, S. Riezler, M. Dalrymple and
R. Kaplan. 2003. The PARC700 Dependency
Bank. In Proc. of the 4th Int’ Workshop on
Linguistically Interpreted Corpora (LINC-
2003), Budapest, Hungary.
D. Klein and C. D. Manning. 2003. Accurate Unlexi-
calized Parsing. In the Proc of ACL-2003,.Japan
M. Kuhlmann and M. Mšhl. 2007. Mildly context-
sensitive dependency language. In the Proc of
ACL 2007. Prague, Czech Republic.
R. McDonald, F. Pereira, K. Ribarov and J. Hajič.
2005. Non-Projective Dependency Parsing using
Spanning Tree Algorithms. In Proc. of HLT-
EMNLP 2005.
I. Melčuk. 1979. Studies in Dependency Syntax.
Karoma Publishers, Inc.
S. Oepen, K. Toutanova, S. M. Shieber, C. D. Man-
ning, D. Flickinger, and T. Brants, 2002. The
LinGO Redwoods Treebank: Motivation and Pre-
liminary Applications. In Proc. of COLING,
2002. Taipei, Taiwan.
M. Palmer, D. Gildea, P. Kingsbury. 2005. The
Proposition Bank: An Annotated Corpus of Seman-
tic Roles.Computational Linguistics, 31(1):71-
106.
D. M. Sharma, R. Sangal, L. Bai, R. Begam, and K.V.
Ramakrishnamacharyulu. 2007. AnnCorra :
TreeBanks for Indian Languages, Annotation
Guidelines (manuscript), IIIT, Hyderabad, India.
F. Xia, O. Rambow, R. Bhatt, M. Palmer and D.
Sharma, 2009. Towards a Multi-Representational
Treebank. In Proc. of the 7th Int’lWorkshop on
Treebanks and Linguistic Theories (TLT-7).
</reference>
<page confidence="0.998915">
189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.212992">
<title confidence="0.9944865">A Multi-Representational and Treebank for Hindi/Urdu</title>
<author confidence="0.783801">Rajesh</author>
<affiliation confidence="0.952682">U. of</affiliation>
<address confidence="0.998776">Amherst, MA, USA</address>
<email confidence="0.9998">bhatt@linguist.umass.edu</email>
<author confidence="0.99862">Owen Rambow</author>
<affiliation confidence="0.999971">Columbia University</affiliation>
<address confidence="0.999589">New York, NY, USA</address>
<email confidence="0.9996">rambow@ccls.columbia.edu</email>
<author confidence="0.542802">Bhuvana</author>
<affiliation confidence="0.929211">U. of</affiliation>
<address confidence="0.996749">Boulder, CO, USA</address>
<email confidence="0.99965">narasimb@colorado.edu</email>
<author confidence="0.997239">Dipti Misra Sharma</author>
<affiliation confidence="0.999969">Int’l Institute of Info.</affiliation>
<address confidence="0.960709">Hyderabad, India</address>
<email confidence="0.801994">dipti@iiit.ac.in</email>
<author confidence="0.965334">Martha</author>
<affiliation confidence="0.984569">U. of</affiliation>
<address confidence="0.993943">Boulder, CO, USA</address>
<email confidence="0.999591">mpalmer@colorado.edu</email>
<author confidence="0.998948">Fei Xia</author>
<affiliation confidence="0.999793">University of</affiliation>
<address confidence="0.997094">Seattle, WA, USA</address>
<email confidence="0.999922">fxia@u.washington.edu</email>
<abstract confidence="0.9670016">This paper describes the simultaneous development of dependency structure and phrase structure treebanks for Hindi and Urdu, as well as a Prop- Bank. The dependency structure and the Prop- Bank are manually annotated, and then the phrase structure treebank is produced automatically. To ensure successful conversion the development of the guidelines for all three representations are carefully coordinated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>V Chaitanya</author>
<author>R Sangal</author>
</authors>
<title>Natural Language Processesing: A Paninian Perspective, Prentice Hall of India,</title>
<date>1999</date>
<location>New Delhi.</location>
<contexts>
<context position="8492" citStr="Bharati et al 1999" startWordPosition="1329" endWordPosition="1332">Hindi, carefully exploring any potentially problematic issues. Specifically, we make sure that both DS and PS represent the same syntactic facts (what is represented): we know that if PS makes a distinction that neither DS nor PropBank make, then we cannot possibly convert automatically. Furthermore, we coordinate the guidelines for DS and PS with respect to the examples chosen to support the conversion process. These examples form a conversion test suite. 187 4 Syntactic Annotation Choices 4.1 Dependency Structure Guidelines Our dependency analysis is based on the Paninian grammatical model (Bharati et al 1999, Sharma et al. 2007). The model offers a syntactico-semantic level of linguistic knowledge with an especially transparent relationship between the syntax and the semantics. The sentence is treated as a series of modifier-modified relations which has a primary modified (generally the main verb). The appropriate syntactic cues (relation markers) help in identifying various relations. The relations are of two types – karaka and others. &apos;Karakas&apos; are the roles of various participants in an action (arguments). For a noun to hold a karaka relation with a verb, it is important that they (noun and ve</context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, 1999</marker>
<rawString>A. Bharati, V. Chaitanya and R. Sangal. 1999. Natural Language Processesing: A Paninian Perspective, Prentice Hall of India, New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Lectures on Government and Binding: The Pisa Lectures.</title>
<date>1981</date>
<publisher>Foris Publications.</publisher>
<location>Holland:</location>
<contexts>
<context position="3286" citStr="Chomsky, 1981" startWordPosition="491" endWordPosition="492"> are closer to the kinds of semantic representations that applications can make immediate use of (McDonald et al. 2005, CoNLL 2006 Shared Task). We first provide a comparison of dependency structure and phrase structure in Section 2. Section 3 describes our treebank, Section 4 explores language-specific linguistic issues that require special attention to ensure consistent conversion, and Section 5 summarizes our conversion approach. 2 Two Kinds of Syntactic Structure Two different approaches to describing syntactic structure, dependency structure (DS) (Mel’čuk 1979) and phrase structure (PS) (Chomsky, 1981), have in a sense divided the field in two, with parallel efforts on both sides. Formally, in a PS tree, all and only the leaf nodes are labeled 186 Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 186–189, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP with words from the sentence (or empty categories), while the interior nodes are labeled with nonterminal labels. In a dependency tree, all nodes are labeled with words from the sentence (or empty categories). Linguistically, a PS groups consecutive words hierarchically into phrases (or constituents), an</context>
<context position="9799" citStr="Chomsky 1981" startWordPosition="1537" endWordPosition="1538">nd possession are also captured using the relational concepts of the model (adjuncts). These argument labels are very similar in spirit to the verb specific semantic role labels used by PropBank, which have already been successfully mapped to richer semantic role labels from VerbNet and FrameNet. This suggests that much of the task of PropBanking can be done as part of the dependency annotation. 4.2 Phrase Structure Guidelines Our PS guidelines are inspired by the Principlesand-Parameters methodology, as instantiated by the theoretical developments starting with Government and Binding Theory (Chomsky 1981). We assume binary branching. There are three theoretical commitments/design considerations that underlie the guidelines. First, any minimal clause distinguishes at most two positions structurally (the core arguments). These positions can be identified as the specifier of VP and the complement of V. With a transitive predicate, these positions are occupied by distinct NPs while with an unaccusative or passive, the same NP occupies both positions. All other NPs are represented as adjuncts. Second, we represent any displacement of core arguments from their canonical positions, irrespective of wh</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>N. Chomsky. 1981. Lectures on Government and Binding: The Pisa Lectures. Holland: Foris Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Jan Hajič</author>
<author>L Ramshaw</author>
<author>C Tillmann</author>
</authors>
<title>A Statistical Parser for Czech.</title>
<date>1999</date>
<booktitle>In the Proc of ACL-1999,</booktitle>
<pages>505--512</pages>
<contexts>
<context position="2253" citStr="Collins et al. 1999" startWordPosition="333" endWordPosition="336">ed; for example, in a case of longdistance wh-movement in English as in Who do you think will come, we can choose to represent the fact that who is an argument of come, or not (what to represent). Having made this choice, we can determine how to represent it: For example, we can use a discontinuous constituent (crossing arcs), or we can use a trace and coindexation. Flexibility of representation is important because the proper choice of representation of the syntax of a language is itself an issue in parsing research. In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research. Similarly, automatically changing the representation in a phrase structure treebank can also improve parsing results (for example Klein &amp; Manning 2003). Finally, there is increasing interest in the use of dependency parses in NLP applications, as they are considered to be simpler structures which can be computed more rapidly and are closer to the kinds of semantic representations that applications can make immediate use of (McDonald et al. 2005, CoNLL 2006 Shared Task). We first provide a comparison of dep</context>
</contexts>
<marker>Collins, Hajič, Ramshaw, Tillmann, 1999</marker>
<rawString>M. Collins, Jan Hajič, L. Ramshaw and C. Tillmann. 1999. A Statistical Parser for Czech. In the Proc of ACL-1999, pages 505-512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajič</author>
<author>E Hajicova</author>
<author>M Holub</author>
<author>P Pajas</author>
<author>P Sgall</author>
<author>B Vidova-Hladka</author>
<author>V Reznickova</author>
</authors>
<date>2001</date>
<booktitle>The Current Status of the Prague Dependency Treebank. Lecture Notes in Artificial Intelligence (LNAI)</booktitle>
<pages>2166--11</pages>
<contexts>
<context position="6566" citStr="Hajič et al. 2001" startWordPosition="1018" endWordPosition="1021">mon in dependency-based syntactic theories, but rare in phrase structure-based theories. The next section highlights our most salient representation choices in Treebank design. 3 Treebank Design Our goal is the delivery of a treebank that is multi-representational: it will have a syntactic dependency version and a phrase structure version. Another recent trend in treebanking is the addition of deeper, semantic levels of annotation on top of the syntactic annotations of the PTB, for example PropBank (Palmer et al. 2005). A multi-layered approach is also found in the Prague Dependency Treebank (Hajič et al. 2001), or in treebanks based on LFG (King et al. 2003) or HPSG (Oepen et al. 2002). A lesson learned here is that the addition of deeper, more semantic levels may be complicated if the syntactic annotation was not designed with the possibility of multiple layers of annotation in mind. We therefore also propose a treebank that is from the start multi-layered: we will include a PropBank-style predicate-argument annotation in the release. Crucially, the lexical subcategorization frames that are made explicit during the process of propbanking should always inform the syntactic structure of the treebank</context>
</contexts>
<marker>Hajič, Hajicova, Holub, Pajas, Sgall, Vidova-Hladka, Reznickova, 2001</marker>
<rawString>J. Hajič, E. Hajicova, M. Holub, P. Pajas, P. Sgall, B. Vidova-Hladka, and V. Reznickova. 2001. The Current Status of the Prague Dependency Treebank. Lecture Notes in Artificial Intelligence (LNAI) 2166, pp 11—20, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H King</author>
<author>R Crouch</author>
<author>S Riezler</author>
<author>M Dalrymple</author>
<author>R Kaplan</author>
</authors>
<title>The PARC700 Dependency Bank.</title>
<date>2003</date>
<booktitle>In Proc. of the 4th Int’ Workshop on Linguistically Interpreted Corpora (LINC2003),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="6615" citStr="King et al. 2003" startWordPosition="1028" endWordPosition="1031">re in phrase structure-based theories. The next section highlights our most salient representation choices in Treebank design. 3 Treebank Design Our goal is the delivery of a treebank that is multi-representational: it will have a syntactic dependency version and a phrase structure version. Another recent trend in treebanking is the addition of deeper, semantic levels of annotation on top of the syntactic annotations of the PTB, for example PropBank (Palmer et al. 2005). A multi-layered approach is also found in the Prague Dependency Treebank (Hajič et al. 2001), or in treebanks based on LFG (King et al. 2003) or HPSG (Oepen et al. 2002). A lesson learned here is that the addition of deeper, more semantic levels may be complicated if the syntactic annotation was not designed with the possibility of multiple layers of annotation in mind. We therefore also propose a treebank that is from the start multi-layered: we will include a PropBank-style predicate-argument annotation in the release. Crucially, the lexical subcategorization frames that are made explicit during the process of propbanking should always inform the syntactic structure of the treebanking effort. In addition, some of the distinctions</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>T. H. King, R. Crouch, S. Riezler, M. Dalrymple and R. Kaplan. 2003. The PARC700 Dependency Bank. In Proc. of the 4th Int’ Workshop on Linguistically Interpreted Corpora (LINC2003), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In the Proc of ACL-2003,.Japan</booktitle>
<contexts>
<context position="2493" citStr="Klein &amp; Manning 2003" startWordPosition="369" endWordPosition="372">how to represent it: For example, we can use a discontinuous constituent (crossing arcs), or we can use a trace and coindexation. Flexibility of representation is important because the proper choice of representation of the syntax of a language is itself an issue in parsing research. In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research. Similarly, automatically changing the representation in a phrase structure treebank can also improve parsing results (for example Klein &amp; Manning 2003). Finally, there is increasing interest in the use of dependency parses in NLP applications, as they are considered to be simpler structures which can be computed more rapidly and are closer to the kinds of semantic representations that applications can make immediate use of (McDonald et al. 2005, CoNLL 2006 Shared Task). We first provide a comparison of dependency structure and phrase structure in Section 2. Section 3 describes our treebank, Section 4 explores language-specific linguistic issues that require special attention to ensure consistent conversion, and Section 5 summarizes our conve</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C. D. Manning. 2003. Accurate Unlexicalized Parsing. In the Proc of ACL-2003,.Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kuhlmann</author>
<author>M Mšhl</author>
</authors>
<title>Mildly contextsensitive dependency language.</title>
<date>2007</date>
<booktitle>In the Proc of ACL 2007.</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Kuhlmann, Mšhl, 2007</marker>
<rawString>M. Kuhlmann and M. Mšhl. 2007. Mildly contextsensitive dependency language. In the Proc of ACL 2007. Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajič</author>
</authors>
<title>Non-Projective Dependency Parsing using Spanning Tree Algorithms.</title>
<date>2005</date>
<booktitle>In Proc. of HLTEMNLP</booktitle>
<contexts>
<context position="2790" citStr="McDonald et al. 2005" startWordPosition="418" endWordPosition="421">ation of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research. Similarly, automatically changing the representation in a phrase structure treebank can also improve parsing results (for example Klein &amp; Manning 2003). Finally, there is increasing interest in the use of dependency parses in NLP applications, as they are considered to be simpler structures which can be computed more rapidly and are closer to the kinds of semantic representations that applications can make immediate use of (McDonald et al. 2005, CoNLL 2006 Shared Task). We first provide a comparison of dependency structure and phrase structure in Section 2. Section 3 describes our treebank, Section 4 explores language-specific linguistic issues that require special attention to ensure consistent conversion, and Section 5 summarizes our conversion approach. 2 Two Kinds of Syntactic Structure Two different approaches to describing syntactic structure, dependency structure (DS) (Mel’čuk 1979) and phrase structure (PS) (Chomsky, 1981), have in a sense divided the field in two, with parallel efforts on both sides. Formally, in a PS tree,</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajič, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov and J. Hajič. 2005. Non-Projective Dependency Parsing using Spanning Tree Algorithms. In Proc. of HLTEMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Melčuk</author>
</authors>
<title>Studies in Dependency Syntax.</title>
<date>1979</date>
<publisher>Karoma Publishers, Inc.</publisher>
<marker>Melčuk, 1979</marker>
<rawString>I. Melčuk. 1979. Studies in Dependency Syntax. Karoma Publishers, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>K Toutanova</author>
<author>S M Shieber</author>
<author>C D Manning</author>
<author>D Flickinger</author>
<author>T Brants</author>
</authors>
<title>The LinGO Redwoods Treebank: Motivation and Preliminary Applications.</title>
<date>2002</date>
<booktitle>In Proc. of COLING,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="6643" citStr="Oepen et al. 2002" startWordPosition="1034" endWordPosition="1037">d theories. The next section highlights our most salient representation choices in Treebank design. 3 Treebank Design Our goal is the delivery of a treebank that is multi-representational: it will have a syntactic dependency version and a phrase structure version. Another recent trend in treebanking is the addition of deeper, semantic levels of annotation on top of the syntactic annotations of the PTB, for example PropBank (Palmer et al. 2005). A multi-layered approach is also found in the Prague Dependency Treebank (Hajič et al. 2001), or in treebanks based on LFG (King et al. 2003) or HPSG (Oepen et al. 2002). A lesson learned here is that the addition of deeper, more semantic levels may be complicated if the syntactic annotation was not designed with the possibility of multiple layers of annotation in mind. We therefore also propose a treebank that is from the start multi-layered: we will include a PropBank-style predicate-argument annotation in the release. Crucially, the lexical subcategorization frames that are made explicit during the process of propbanking should always inform the syntactic structure of the treebanking effort. In addition, some of the distinctions made by PS that are not nat</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>S. Oepen, K. Toutanova, S. M. Shieber, C. D. Manning, D. Flickinger, and T. Brants, 2002. The LinGO Redwoods Treebank: Motivation and Preliminary Applications. In Proc. of COLING, 2002. Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.Computational Linguistics,</title>
<date>2005</date>
<pages>31--1</pages>
<contexts>
<context position="1520" citStr="Palmer et al. 2005" startWordPosition="206" endWordPosition="209">s are carefully coordinated. 1 Introduction Annotated corpora have played an increasingly important role in the training of supervised natural language processing components. Today, treebanks have been constructed for many languages, including Arabic, Chinese, Czech, English, French, German, Korean, Spanish, and Turkish. This paper describes the creation of a Hindi/Urdu multi-representational and multilayered treebank. Multi-layered means that we design the annotation process from the outset to include both a syntactic annotation and a lexical semantic annotation such as the English PropBank (Palmer et al. 2005). Multirepresentational means that we distinguish conceptually what is being represented from how it is represented; for example, in a case of longdistance wh-movement in English as in Who do you think will come, we can choose to represent the fact that who is an argument of come, or not (what to represent). Having made this choice, we can determine how to represent it: For example, we can use a discontinuous constituent (crossing arcs), or we can use a trace and coindexation. Flexibility of representation is important because the proper choice of representation of the syntax of a language is </context>
<context position="6472" citStr="Palmer et al. 2005" startWordPosition="1002" endWordPosition="1005">nonprojectivity” which is used to represent discontinuous constituents. Non-projectivity is common in dependency-based syntactic theories, but rare in phrase structure-based theories. The next section highlights our most salient representation choices in Treebank design. 3 Treebank Design Our goal is the delivery of a treebank that is multi-representational: it will have a syntactic dependency version and a phrase structure version. Another recent trend in treebanking is the addition of deeper, semantic levels of annotation on top of the syntactic annotations of the PTB, for example PropBank (Palmer et al. 2005). A multi-layered approach is also found in the Prague Dependency Treebank (Hajič et al. 2001), or in treebanks based on LFG (King et al. 2003) or HPSG (Oepen et al. 2002). A lesson learned here is that the addition of deeper, more semantic levels may be complicated if the syntactic annotation was not designed with the possibility of multiple layers of annotation in mind. We therefore also propose a treebank that is from the start multi-layered: we will include a PropBank-style predicate-argument annotation in the release. Crucially, the lexical subcategorization frames that are made explicit </context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, P. Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles.Computational Linguistics, 31(1):71-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Sharma</author>
<author>R Sangal</author>
<author>L Bai</author>
<author>R Begam</author>
<author>K V Ramakrishnamacharyulu</author>
</authors>
<title>AnnCorra : TreeBanks for Indian Languages, Annotation Guidelines (manuscript), IIIT,</title>
<date>2007</date>
<location>Hyderabad, India.</location>
<contexts>
<context position="8513" citStr="Sharma et al. 2007" startWordPosition="1333" endWordPosition="1336">loring any potentially problematic issues. Specifically, we make sure that both DS and PS represent the same syntactic facts (what is represented): we know that if PS makes a distinction that neither DS nor PropBank make, then we cannot possibly convert automatically. Furthermore, we coordinate the guidelines for DS and PS with respect to the examples chosen to support the conversion process. These examples form a conversion test suite. 187 4 Syntactic Annotation Choices 4.1 Dependency Structure Guidelines Our dependency analysis is based on the Paninian grammatical model (Bharati et al 1999, Sharma et al. 2007). The model offers a syntactico-semantic level of linguistic knowledge with an especially transparent relationship between the syntax and the semantics. The sentence is treated as a series of modifier-modified relations which has a primary modified (generally the main verb). The appropriate syntactic cues (relation markers) help in identifying various relations. The relations are of two types – karaka and others. &apos;Karakas&apos; are the roles of various participants in an action (arguments). For a noun to hold a karaka relation with a verb, it is important that they (noun and verb) have a direct syn</context>
</contexts>
<marker>Sharma, Sangal, Bai, Begam, Ramakrishnamacharyulu, 2007</marker>
<rawString>D. M. Sharma, R. Sangal, L. Bai, R. Begam, and K.V. Ramakrishnamacharyulu. 2007. AnnCorra : TreeBanks for Indian Languages, Annotation Guidelines (manuscript), IIIT, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>O Rambow</author>
<author>R Bhatt</author>
<author>M Palmer</author>
<author>D Sharma</author>
</authors>
<title>Towards a Multi-Representational Treebank.</title>
<date>2009</date>
<booktitle>In Proc. of the 7th Int’lWorkshop on Treebanks and Linguistic Theories (TLT-7).</booktitle>
<contexts>
<context position="13396" citStr="Xia et al., 2009" startWordPosition="2119" endWordPosition="2122">s. Note that non-projective DSs will be converted to projective DScons. (For an alternate account of handling non-projective DSs, see Kuhlman and Mšhl (2007).) A preliminary study on the English Penn Treebank showed promising results and error analyses indicated that most conversion errors were caused by ambiguous DS patterns in the conversion rules. This implies that including sufficient information in the input DS could reduce ambiguity, significantly improving the performance of the conversion algorithm. The details of the conversion algorithm and the experimental results are described in (Xia et al., 2009). 6 Conclusion We presented our approach to the joint development of DS and PS treebanks and a PropBank for Hindi/Urdu. Since from the inception of the project we have planned manual annotation of DS and automatic conversion to PS, we are developing the annotation guidelines for all structures in parallel. A series of linguistic constructions with specific examples are being carefully examined for any DS annotation decisions that might result in inconsistency between DS and PS and/or multiple conversion rules with identical DS patterns. Our preliminary studies yield promising results, indicati</context>
</contexts>
<marker>Xia, Rambow, Bhatt, Palmer, Sharma, 2009</marker>
<rawString>F. Xia, O. Rambow, R. Bhatt, M. Palmer and D. Sharma, 2009. Towards a Multi-Representational Treebank. In Proc. of the 7th Int’lWorkshop on Treebanks and Linguistic Theories (TLT-7).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>