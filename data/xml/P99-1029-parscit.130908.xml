<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005000">
<title confidence="0.998407">
Using Mutual Information to Resolve Query Translation
Ambiguities and Query Term Weighting
</title>
<author confidence="0.960262">
Myung-Gil Jang, 2 Sung Hyon Myaeng and 1 Se Young Park
</author>
<affiliation confidence="0.945071">
1 Dept. of Knowledge Information, Electronics
and Telecommunications Research Institute
</affiliation>
<address confidence="0.9280335">
161 Kajong-Dong, Yusong-Gu,
Taejon, Korea 305-350
</address>
<email confidence="0.865937">
( mgjang, syparkl@etri.re.kr
</email>
<affiliation confidence="0.9729535">
2 Dept. of Computer Science,
Chungnam National University
</affiliation>
<address confidence="0.947708">
220 Gung-Dong, Yusong-Gu,
Taejon, Korea 305-764
</address>
<email confidence="0.992613">
shmyaeng@cs.chungnam.ac.kr
</email>
<sectionHeader confidence="0.998558" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999816">
An easy way of translating queries in one
language to the other for cross-language
information retrieval (IR) is to use a simple
bilingual dictionary. Because of the general-
purpose nature of such dictionaries, however,
this simple method yields a severe
translation ambiguity problem. This paper
describes the degree to which this problem
arises in Korean-English cross-language IR
and suggests a relatively simple yet effective
method for disambiguation using mutual
information statistics obtained only from the
target document collection. In this method,
mutual information is used not only to select
the best candidate but also to assign a weight
to query terms in the target language. Our
experimental results based on the TREC-6
collection shows that this method can
achieve up to 85% of the monolingual
retrieval case and 96% of the manual
disambiguation case.
</bodyText>
<sectionHeader confidence="0.97215" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99967644">
Cross-language information retrieval (IR)
enables a user to retrieve documents written in
diverse languages using queries expressed in his
or her own language. For cross-language IR,
either queries or documents are translated to
overcome the language differences. Although it
is possible to apply a high-quality machine
translation system for documents as in Oard &amp;
Hackett (1997), query translation has emerged as
a more popular method because it is much
simpler and more economical compared to
document translation. Query translation can be
done in one or more of the three approaches: a
dictionary-based approach, a thesaurus-based
approach, or a corpus-based approach.
There are three problems that a cross-language
IR system using a query translation method must
solve (Grefenstette, 1998). The first problem is
to figure out how a term expressed in one
language might be written in another. The
second problem is to determine which of the
possible translations should be retained. The
third problem is to determine how to properly
weight the importance of translation alternatives
when more than one is retained.
For cross-language IR between Korean and
English, i.e. between Korean queries and English
documents, an easy way to handle query
translation is to use a Korean-English machine-
readable dictionary (MRD) because such
bilingual MRDs are more widely available than
other resources such as parallel corpora.
However, it has been known that with a simple
use of bilingual dictionaries in other language
pairs, retrieval effectiveness can be only 40%-
60% of that with monolingual retrieval
(Ballesteros &amp; Croft, 1997). It is obvious that
other additional resources need to be used for
better performance.
This paper focuses on the last two problems:
pruning translations and calculating the weights
for translation alternatives. We first describe the
overall query translation process and the extent
to which the ambiguity problem arises in
Korean-English cross-language IR. We then
propose a relatively simple yet effective method
for resolving translation disambiguation using
mutual information (MI) (Church and Hanks,
1990) statistics obtained only from the target
document collection. In this method, mutual
</bodyText>
<page confidence="0.997745">
223
</page>
<bodyText confidence="0.986883">
information is used not only to select the best
candidate but also to assign a weight to query
terms in the target language.
</bodyText>
<sectionHeader confidence="0.888264" genericHeader="method">
1 Overall Query Translation Process
</sectionHeader>
<bodyText confidence="0.999507714285714">
Our Korean-to-English query translation scheme
works in four stages: keyword selection,
dictionary-based query translation, bilingual
word sense disambiguation, and query term
weighting. Although none of the common
resources such as dictionaries, thesauri, and
corpora alone is complete enough to produce
high quality English queries, we decided to use a
bilingual dictionary at the second stage and a
target-language corpus for the third and the
fourth stages. Our strategy was to try not to
depend on scarce resources to make the
approach practical. Figure 1 shows the four
stages of Korean-to-English query translation.
</bodyText>
<subsectionHeader confidence="0.841118">
Korean English
Query Query
</subsectionHeader>
<bodyText confidence="0.4990435">
Fig. 1. Four Stages for Korean-to-English Query
Translation.
</bodyText>
<subsectionHeader confidence="0.999035">
1.1 Keyword Selection
</subsectionHeader>
<bodyText confidence="0.99994115">
At the first stage, Korean keywords to be fed
into the query translation process are extracted
from a quasi-natural language query. This
keyword selection is done with a morphological
analyzer and a stochastic part-of-speech (POS)
tagger for the Korean language (Shin et al.,
1996). The role of the tagger is to help select the
exact morpheme sequence from the multiple
candidate sequences generated by the
morphological analysis. This process of
employing a morphological analysis and a tagger
is crucial for selecting legitimate query words
from the topic statements because Korean is an
agglutinative language. Without the tagger, all
the extraneous candidate keywords generated
from the morphological analyzer will have to be
entered into the translation process, which in and
of itself will generate extraneous words, due to
one-to-many mapping in the bilingual
dictionary.
</bodyText>
<subsectionHeader confidence="0.995881">
1.2 Dictionary-Based Query Translation
</subsectionHeader>
<bodyText confidence="0.999985933333333">
The second stage does the actual query
translation based on a dictionary look-up, by
applying both word-by-word translation and
phrase-level translation. For the correct
identification of phrases in a Korean query, it
would help to identify the lexical relations and
produce statistical information on pairs of words
in a text corpus as in Smadja (1993). Since the
bilingual dictionary lacks some words that are
essential for a correct interpretation of the
Korean query, it is important to identify
unknown words such as foreign words and
transliterate them into English strings that need
to be matched against an English dictionary
(Jeong etal., 1997).
</bodyText>
<subsectionHeader confidence="0.999481">
1.3 Selection of the Correct Translations
</subsectionHeader>
<bodyText confidence="0.999981428571428">
At the word disambiguation stage, we filter out
the extraneous words generated blindly from the
dictionary lookup process. In addition to the
POS tagger, we employed a bilingual word
disambiguation technique using the co-
occurrence information extracted from the
collection of target documents. More specifically,
The mutual information statistics between pairs
of words were used to determine whether
English words from different sets generated by
the translation process are &amp;quot;compatible&amp;quot;. In a
sense, we make use of mutual disambiguation
effect among query terms. More details are
described in Section 3.
</bodyText>
<subsectionHeader confidence="0.997562">
1.4 Query Term Weighting
</subsectionHeader>
<bodyText confidence="0.9999907">
Finally, we apply our query term weighting
technique to produce the final target query. The
term weighting scheme basically reflects the
degree of associations between the translated
terms, and we give a high or low term weighting
value according to the degree of mutual
association between query terms. This is another
area where we make use of mutual information
obtained from a text corpus. The result from the
four stages is a set of query terms to be used in a
</bodyText>
<figure confidence="0.998232647058824">
Query Term
Weighting —
Keyword I +_. English
Selection Bilingual Word Text Corpus
.....
Disambiguation
I
Dictionary-Based
Query Translation
.-- ----, --0.
......_ -,
Bilingual
Dictionary
*--------
Korean-to-English
Query Trans ation
1
</figure>
<page confidence="0.941081">
224
</page>
<bodyText confidence="0.746766">
vector-space retrieval model.
</bodyText>
<subsectionHeader confidence="0.527538">
2 Analysis of Translation Ambiguity
</subsectionHeader>
<bodyText confidence="0.999689484848485">
Although an easy way to find translations of
query terms is to use a bilingual dictionary, this
method alone suffers from problems caused by
translation ambiguity since there are often one-
to-many correspondences in a bilingual
dictionary. For example, in a Korean query
consisting of three words, &amp;quot;A--Y,-A- 71
&amp;quot;(ja-dong-cha gong-gi oh-yum) that means
air pollution caused by automobiles, each word
can be translated into multiple English words
when a Korean-English dictionary is used in a
straightforward way. The first word &amp;quot;4-Y,-4&amp;quot;
(ja-dong-cha) of the query can be translated into
English words with semantically similar but
different words like &amp;quot;motorcar&amp;quot;, &amp;quot;automobile&amp;quot;,
and &amp;quot;car&amp;quot;. The second word &amp;quot; 70&apos;71&amp;quot; (gong-gi), a
homonymous word, can be translated into
English words with different meanings: &amp;quot;air&amp;quot;,
&amp;quot;atmosphere&amp;quot;, &amp;quot;empty vessel&amp;quot;, and &amp;quot;bowl&amp;quot;. And
the last word &amp;quot;_2_ &amp;quot; (oh-yum) can be translated
into two English words, &amp;quot;pollution&amp;quot; and
&amp;quot;contamination&amp;quot;.
Retaining multiple candidate words can be
useful in promoting recall in monolingual IR
system, but previous research indicates that
failure to disambiguate the meanings of the
words can hurt retrieval effectiveness
tremendously. For instance, it is obvious that a
phrase like empty vessel would change the
meaning of the query entirely. Even a word like
contamination, a synonym of pollution, may end
up retrieving unrelated documents due to the
slight differences in meaning.
</bodyText>
<tableCaption confidence="0.998569">
Table 1. The Degree of Ambiguities
</tableCaption>
<table confidence="0.995949166666667">
Words Word Pairs
# in S. # in T. Average # in S. # in T. Average
Lan. Lang. Ambiguity Lan. Lang. Ambiguity
Title 48 158 3.29 24 212 8.83
Short 112 447 3.99 91 1459 16.03
Long 462 1835 3.97 423 6196 14.65
</table>
<bodyText confidence="0.99329575">
Table 1 shows the extent to which ambiguity
occurs in our query translation when an English-
Korean dictionary is used blindly after the
morphological analysis and tagging. The three
rows, title, short, and long, indicate three
different ways of composing queries from the
topic statements in the TREC collection. The left
half shows the average number of English words
per Korean word for each query, whereas the
right half shows the average number of word
pairs in English that can be formed from a single
word pair in Korean. The latter indicates that the
disambiguation process will have to select one
out of more than 9 possible pairs on the average,
regardless of which part of the topic statements
is used for formal query generation.
</bodyText>
<sectionHeader confidence="0.9927135" genericHeader="method">
3 Query Translation and Mutual
Information
</sectionHeader>
<bodyText confidence="0.999969227272727">
Our strategy for cross-language IR aims at
practicality in that we try not to depend on
scarce resources. Along the same line of
reasoning, we opted for a disambiguation
approach that requires only a collection of
documents in the target language, which is
always available in any cross-language IR
environment. Since the goal of disambiguation is
to select the best pair among many alternatives
as described above, the mutual information
statistic is a natural choice in judging the degree
to which two words co-occur within a certain
text boundary. It would be reasonable to choose
the pair of words that are most strongly
associated with each other, thereby eliminating
those translations that are not likely to be correct
ones.
Mutual information values are calculated based
on word co-occurrence statistics and used as a
measure to calculate correlation between words.
The mutual information MI(x,y) is defined as the
following formula (Church and Hanks, 1990).
</bodyText>
<equation confidence="0.9975485">
M/(x, y) =log p(x, y) =log N fw(x, y) (1)
p(x)p(y) f(x)f(y)
</equation>
<bodyText confidence="0.999435538461538">
Here x and y are words occurring within a
window of w words.
The probabilities p(x) and p(y) are estimated by
counting the number of observations of x and y
in a corpus, f(x) and f(y), and normalizing each
by N, the size of the corpus. Joint probabilities,
p(x,y), are estimated by counting the number of
times, fi,(x,y), that x is followed by y in a
window of w words and normalizing it by N. In
our application of query translation, the joint co-
occurrence frequency Px,y) has 6-word window
size which seems to allow semantic relations of
query as well as fixed expressions (idioms such
</bodyText>
<page confidence="0.992458">
225
</page>
<bodyText confidence="0.999639666666667">
as bread and butter). We ensure that the word x
be followed by the word y within the same
sentence only.
In our query translation scheme, MI values are
used to select most likely translations after each
Korean query word is translated into one or
more English words. Our use of MI values is
based on the assumption that when two words
co-occur in the same query, they are likely to co-
occur in the same affinity in documents.
Conversely, two words that do not co-occur in
the same affinity are not likely to show up in the
same query. In a sense, we are conjecturing
Mutual information can reveal some degree of
semantic association between words.
Table 2 gives some examples of MI values for
the alternative word pairs for translated queries
of TREC-6 Cross-Language IR Track. These MI
values were extracted from the English text
corpus consisting of 1988 — 1990 AP news,
which contains 116,759,540 words.
</bodyText>
<tableCaption confidence="0.997158">
Table 2. Example of M/(x, ) Values
</tableCaption>
<table confidence="0.910883736842105">
Word x Wordy f(x) f(Y) f(x,Y) Mi(x,Y)
respiratory ailment 716 1134 74 9.272506
teddy bear 679 7932 262 8.644690
fossil fuel 676 13176 333 8.381424
air pollution 52216 4878 890 6.011214
research development 24278 24213 1317 5.566768
AIDS spread 18575 10199 212 4.872597
ivory trade 1885 86608 84 4.095613
environment protection 7771 13139 36 3.717652
bear doll 7932 1394 3 3.455646
region country 21093 103833 358 2.948925
point interest 30419 51917 107 2.068232
law terrorism 70182 4762 20 1.944089
treatment result 13432 38055 22 1.614487
terrorism government 4762 193977 29 1.299005
opinion news 9124 82220 21 1.184332
food life 32222 40625 30 0.984281
copy price 6803 90594 10 0.638950
labor information 26571 30245 11 0.468861
</table>
<bodyText confidence="0.9980358">
When MI(x,y) is large, the word associations are
strong and produce credible results for
disambiguation of translations. However, if
MI(x,y) &lt;0, we can predict that the word x and
word y are in complementary distribution.
</bodyText>
<sectionHeader confidence="0.992783" genericHeader="method">
4 Disambiguation and Weight
Calculation
</sectionHeader>
<bodyText confidence="0.999835208333333">
We can alleviate the translation ambiguity by
discriminating against those word pairs with low
MI values. The word pair with the highest MI
value is considered to be the correct one among
all the candidates in the two sets. Since a query
is likely to be targeted at a single concept,
regardless of how broad or narrow it is, we
conjecture that words describing the concept are
likely to have a high degree of association.
Although we use the mutual information statistic
to measure the association, others such as those
used by Ballesteros &amp; Croft (1998) can be
considered.
In the example of Section 2, each Korean word
has multiple English words due to translation
ambiguity. Figure 2 shows the MI values
calculated for the word pairs comprising the
translations of the original query. The words
under wl, w2, and w3 are the translations from
the three query words, respectively. The lines
indicate that mutual information values are
available for the pairs, and the numbers show
some of the significant MI values for the
corresponding pairs among all the possible pairs.
</bodyText>
<figure confidence="0.985988636363636">
wl w2 w3
2.277149
air
ni°t°1:114!:;PY ollution
O162740
°InI°13 Adta213
950
11/tyvesse
tamination
car
bowl
</figure>
<figureCaption confidence="0.781375">
Fig. 2. An Example of Word Pairs with MI
Values
</figureCaption>
<bodyText confidence="0.985774">
Our bilingual word disambiguation and
weighting schemes rely on both relative and
absolute magnitudes of the MI vales. The
algorithm first looks for the pair with the highest
MI value and selects the best candidates before
and after the pair by comparing the MI values
for the pairs that are connected with the initially
chosen pairs. This process is applied to the
words immediately before or after the chosen
pair in order to limit the effect of the choice that
may be incorrect.
It should be noted that the words not chosen in
this process are not used in the translated query
unless the MI values are greater than a threshold.
As described below, we assume that the
candidates not in the first tier may still be useful
if they are strongly associated with the adjacent
word selected.
aut
</bodyText>
<page confidence="0.996208">
226
</page>
<bodyText confidence="0.99998635483871">
For example, the word pair &lt;air, pollution&gt; that
has the bold line representing the strongest
association in the column is choisen first. Then
the three MI values for the pairs containing
air are compared to select the &lt;automobile, air&gt;
pair, resulting in &lt;automobile, air, pollution&gt;. If
there were additional columns in the example,
the same process would be applied to the rest of
the network.
There are three reasons why query term
weighting is of some value in addition to the
pruning of conceptually unrelated terms. First,
our word selection method is not guaranteed to
give the correct translation. The method would
give a reasonable result only when two
consecutive query terms are actually used
together in many documents, which is a
hypothesis yet to be confirmed for its validity.
Second, there may be more than one strong
association whose degrees are different from
each other by a large magnitude. Third,
seemingly extraneous terms may serve as a
recall-enhancing device with a query expansion
effect.
The basic idea in our term weighting scheme is
to give a large weight to the best candidate and
divide the remaining quantity to assign equal
weights to the rest of the candidates. In other
words, the weight for the best candidate, W,„ is
either 1 if it is greater than a threshold value or
expressed as follows.
</bodyText>
<equation confidence="0.7456815">
Wb = (x)x 0.5 + 0.5 (2)
0+1
</equation>
<bodyText confidence="0.999904">
Here x and 0 are a MI value and a threshold,
respectively. The numerator, f(x), gives the
smallest integer greater than the MI value so that
the resulting weight is the same for all the
candidates whose MI values are within a certain
interval. Once the value for Wb is calculated, the
weight for the rest of the candidates are
calculated as follows:
</bodyText>
<equation confidence="0.982815333333333">
1—W
W =
n-1
</equation>
<bodyText confidence="0.999776684210526">
where n is the number of candidates. It should be
noted that W„ + EWr= 1.
Based on our observation of the calculated MI
values, we chose to use 3.0 as the cut-off value
in choosing the best candidate and assign a fairly
high weight. The cut-off value was determined
purely based on the data we obtained; it can vary
based on the new range of MI values when
different corpora are used.
In the example of Fig. 2, the word pair candidate
between wl and w2 are (motorcar, air),
(automobile, air), and (car, air). Here because the
weight of the word pairs (automobile, air) is W,
= 0.83, the word &amp;quot;automobile&amp;quot; has a relatively
higher term weight than the other two words
&amp;quot;motorcar&amp;quot; and &amp;quot;car&amp;quot;. Finally the optimal
English query set with their term weight,
&lt;(motocar,0.085), (automobile, 0.83), (car,
0.085) &gt;, is generated for the translations of w/.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999956828571429">
We developed a system for our cross-language
IR techniques and conducted some basic
experiments using the collection from the Cross-
Language Track of TREC 6. The 24 English
queries are comprised of three fields: titles,
descriptions, and narratives. These English
queries were manually translated into Korean
queries so that we can pretend as if the Korean
queries had been generated by human users for
cross-language IR. In order to compare cross-
language IR and mono-language IR, we used the
Smart 11.0 system developed by Cornell
University.
Our goal was to examine the efficacy of the
disambiguation and term weighting schemes in
our query translation. We ran our system with
three sets of queries, differentiated by the query
lengths: &apos;title&apos; queries with title fields only, &apos;short&apos;
queries with description fields only, and &apos;long&apos;
queries with all the three fields. The retrieval
effectiveness measured with 11-point average
precision was used for comparison against the
baseline of monolingual retrieval using the
original English query.
Table 3 gives the experimental results from
using the four types of query set. The result from
&amp;quot;Translated Query I&amp;quot; was generated only with
the keyword selection and dictionary-based
query translation stages. The result &amp;quot;Translated
Query II&amp;quot; was generated after all the stages of
our word disambiguation and query term
weighting were done. And the result from the
manually disambiguated query set was generated
by manually selecting the best candidate terms
from the Translated Query I.
</bodyText>
<figure confidence="0.47622">
(3)
</figure>
<page confidence="0.994409">
227
</page>
<tableCaption confidence="0.998343">
Table 3. Experimental Results
</tableCaption>
<table confidence="0.998006636363636">
Query Title Short Long
Sets
I I pt. P C/M(&apos;A) I I pt. P C/M(%) I I pt. P C/MN )
Original 0.3251 - 0.3189 - 0.2821
Query
Tran. 0.2290 70.44 0.21443 67.20 0.1587 56.26
Query I
Tran. 0.2675 82.28 0.2698 84.60 0.2232 79.t2
Query II
M.Disam. 0.2779 85.48 0.3002 94.14 0.2433 86.25
Query
</table>
<bodyText confidence="0.999932620689655">
The performance of the Translated query set I
was about 70%, 67%, and 56% of monolingual
retrieval for the three cases, respectively. The
performances of the translated query set II were
about 82%, 85%, and 79% of monolingual
retrieval for the three cases, respectively. The
performance of the disambiguated queries, 85%,
94%, and 86% of monolingual retrieval for the
three cases, respectively, can be treated as the
upper limit for the cross-language retrieval. The
reason why they are not 100% is attributed to the
several factors. They are: 1) the inaccuracy of
the manual translation of the original English
query into the Korean queries, 2) the inaccuracy
of the Korean morphological analyzer and the
tagger in generating query words, and 3) the
inaccuracy in generating candidate terms using
the bilingual dictionary.
The difference between Translated Query I and
Translated Query II indicates that the MI-based
disambiguation and the term weighting schemes
are effective in enhancing the retrieval
effectiveness. In addition, the results show that
the use of these query translation schemes is
more effective with long queries than with
shorter queries. This is expected because the
longer the queries are, the more contextual
information can be used for mutual
disambiguation.
</bodyText>
<sectionHeader confidence="0.937689" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999991184210526">
It has been known that query translation using a
simple bilingual dictionary leads to a more than
40% drop in retrieval effectiveness due to
translation ambiguity. Our query translation
method uses mutual information extracted from
the 1988 - 1990 AP corpus in order to solve the
problems of the bilingual word disambiguation
and query term weighting. The experiments
using test collection of TREC-6 Cross-Language
Track show that the method improves retrieval
effectiveness in Korean-to-English cross-
language IR. The performance can be up to 85%
of the monolingual retrieval case. We also found
that we obtained the largest percent increase
with long queries.
While the experimental results are very
promising, there are several issues to be
explored. First, we need to test how effectively
the method can be applied. Second, we intend to
experiment with other co-occurrence metrics,
instead of the mutual information statistic, for
possible improvement. This investigation is
motivated by our observation of some counter-
intuitive M/ values. Third, we also plan on using
different algorithms for choosing the terms and
calculating the weights.
In addition, we plan to use the pseudo relevance
feedback method that has been proven to be
effective in monolingual retrieval. Terms in
some top-ranked documents are thrown into the
original query with an assumption that at least
some, if not all, of the documents are relevant to
the original query and that the terms appearing
in the documents are useful in representing
user&apos;s information need. Here we need to
determine a threshold value for the number of
top ranked document for our cross-language
retrieval situation, let alone other phenomenon.
</bodyText>
<sectionHeader confidence="0.998982" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996037541666667">
Douglas W. Oard and Paul Hackett (1997).
Document Translation for the Cross-Language Text
Retrieval at the University of Maryland, The Sixth
Text Retrieval Conference (TREC-6), NIST.
Gregory Grefenstette (1998). Cross-Language
Information Retrieval, Kluwer Academic
Publishers.
Lisa Ballesteros and W. Bruce Croft(1997). Phrasal
Translation and Query Expansion Techniques for
Cross-lingual Information Retrieval, SIGIR&apos; 97.
Lisa Ballesteros and W. Bruce Croft(1998).
Resolving Ambiguity for Cross-language Retrieval,
SIGIR&apos; 98.
Kenneth W. Church and Patrick Hanks (1990). Word
Association Norms, Mutual Information, and
Lexicography, Computational Linguistics, Vol. 16,
No. 1, pp. 22-29.
Joong-Ho Shin, Young-Soek Han, Key-Sun Choi
(1996). A HMM Part of Speech Tagger for Korean
with Word Phrasal Relations, In Proceedings of
Recent Advances in Natural Language Processing.
Frank Samdja (1993) Retrieval Collection from Text:
Xtract, Computational Linguistics, Vol. 19, No. 1,
pp.143-177.
</reference>
<page confidence="0.973395">
228
</page>
<reference confidence="0.9993248">
Jeong, K. S., Kwon,Y. H. and Myaeng, S. H. (1997).
Construction of Equivalence Classes through
Automatic Extraction and Identification of Foreign
Words, In Proceedings of NLPRS&apos;97, Phuket,
Tailand.
</reference>
<page confidence="0.998908">
229
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.804734">
<title confidence="0.991531">Using Mutual Information to Resolve Query Translation Ambiguities and Query Term Weighting</title>
<author confidence="0.932186">Sung Hyon Myaeng Jang</author>
<author confidence="0.932186">Se Young Park</author>
<affiliation confidence="0.9846025">1Dept. of Knowledge Information, Electronics and Telecommunications Research Institute</affiliation>
<address confidence="0.9954565">161 Kajong-Dong, Yusong-Gu, Taejon, Korea 305-350</address>
<email confidence="0.949805">(mgjang,syparkl@etri.re.kr</email>
<affiliation confidence="0.9871535">2Dept. of Computer Science, Chungnam National University</affiliation>
<address confidence="0.997048">220 Gung-Dong, Yusong-Gu, Taejon, Korea 305-764</address>
<email confidence="0.990683">shmyaeng@cs.chungnam.ac.kr</email>
<abstract confidence="0.999302681818182">An easy way of translating queries in one language to the other for cross-language information retrieval (IR) is to use a simple bilingual dictionary. Because of the generalpurpose nature of such dictionaries, however, this simple method yields a severe translation ambiguity problem. This paper describes the degree to which this problem arises in Korean-English cross-language IR and suggests a relatively simple yet effective method for disambiguation using mutual information statistics obtained only from the target document collection. In this method, mutual information is used not only to select the best candidate but also to assign a weight to query terms in the target language. Our experimental results based on the TREC-6 collection shows that this method can achieve up to 85% of the monolingual retrieval case and 96% of the manual disambiguation case.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas W Oard</author>
<author>Paul Hackett</author>
</authors>
<title>Document Translation for the Cross-Language Text Retrieval at the University of Maryland,</title>
<date>1997</date>
<booktitle>The Sixth Text Retrieval Conference (TREC-6),</booktitle>
<location>NIST.</location>
<contexts>
<context position="1716" citStr="Oard &amp; Hackett (1997)" startWordPosition="245" endWordPosition="248">n a weight to query terms in the target language. Our experimental results based on the TREC-6 collection shows that this method can achieve up to 85% of the monolingual retrieval case and 96% of the manual disambiguation case. Introduction Cross-language information retrieval (IR) enables a user to retrieve documents written in diverse languages using queries expressed in his or her own language. For cross-language IR, either queries or documents are translated to overcome the language differences. Although it is possible to apply a high-quality machine translation system for documents as in Oard &amp; Hackett (1997), query translation has emerged as a more popular method because it is much simpler and more economical compared to document translation. Query translation can be done in one or more of the three approaches: a dictionary-based approach, a thesaurus-based approach, or a corpus-based approach. There are three problems that a cross-language IR system using a query translation method must solve (Grefenstette, 1998). The first problem is to figure out how a term expressed in one language might be written in another. The second problem is to determine which of the possible translations should be ret</context>
</contexts>
<marker>Oard, Hackett, 1997</marker>
<rawString>Douglas W. Oard and Paul Hackett (1997). Document Translation for the Cross-Language Text Retrieval at the University of Maryland, The Sixth Text Retrieval Conference (TREC-6), NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Cross-Language Information Retrieval,</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="2130" citStr="Grefenstette, 1998" startWordPosition="309" endWordPosition="310">age IR, either queries or documents are translated to overcome the language differences. Although it is possible to apply a high-quality machine translation system for documents as in Oard &amp; Hackett (1997), query translation has emerged as a more popular method because it is much simpler and more economical compared to document translation. Query translation can be done in one or more of the three approaches: a dictionary-based approach, a thesaurus-based approach, or a corpus-based approach. There are three problems that a cross-language IR system using a query translation method must solve (Grefenstette, 1998). The first problem is to figure out how a term expressed in one language might be written in another. The second problem is to determine which of the possible translations should be retained. The third problem is to determine how to properly weight the importance of translation alternatives when more than one is retained. For cross-language IR between Korean and English, i.e. between Korean queries and English documents, an easy way to handle query translation is to use a Korean-English machinereadable dictionary (MRD) because such bilingual MRDs are more widely available than other resources</context>
</contexts>
<marker>Grefenstette, 1998</marker>
<rawString>Gregory Grefenstette (1998). Cross-Language Information Retrieval, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lisa Ballesteros</author>
<author>W Bruce Croft</author>
</authors>
<title>Phrasal Translation and Query Expansion Techniques for Cross-lingual Information Retrieval,</title>
<booktitle>SIGIR&apos; 97.</booktitle>
<marker>Ballesteros, Croft, </marker>
<rawString>Lisa Ballesteros and W. Bruce Croft(1997). Phrasal Translation and Query Expansion Techniques for Cross-lingual Information Retrieval, SIGIR&apos; 97.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lisa Ballesteros</author>
<author>W Bruce</author>
</authors>
<title>Croft(1998). Resolving Ambiguity for Cross-language Retrieval,</title>
<journal>SIGIR&apos;</journal>
<volume>98</volume>
<marker>Ballesteros, Bruce, </marker>
<rawString>Lisa Ballesteros and W. Bruce Croft(1998). Resolving Ambiguity for Cross-language Retrieval, SIGIR&apos; 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics,</journal>
<volume>16</volume>
<pages>22--29</pages>
<contexts>
<context position="3475" citStr="Church and Hanks, 1990" startWordPosition="512" endWordPosition="515">airs, retrieval effectiveness can be only 40%- 60% of that with monolingual retrieval (Ballesteros &amp; Croft, 1997). It is obvious that other additional resources need to be used for better performance. This paper focuses on the last two problems: pruning translations and calculating the weights for translation alternatives. We first describe the overall query translation process and the extent to which the ambiguity problem arises in Korean-English cross-language IR. We then propose a relatively simple yet effective method for resolving translation disambiguation using mutual information (MI) (Church and Hanks, 1990) statistics obtained only from the target document collection. In this method, mutual 223 information is used not only to select the best candidate but also to assign a weight to query terms in the target language. 1 Overall Query Translation Process Our Korean-to-English query translation scheme works in four stages: keyword selection, dictionary-based query translation, bilingual word sense disambiguation, and query term weighting. Although none of the common resources such as dictionaries, thesauri, and corpora alone is complete enough to produce high quality English queries, we decided to </context>
<context position="10902" citStr="Church and Hanks, 1990" startWordPosition="1672" endWordPosition="1675">on is to select the best pair among many alternatives as described above, the mutual information statistic is a natural choice in judging the degree to which two words co-occur within a certain text boundary. It would be reasonable to choose the pair of words that are most strongly associated with each other, thereby eliminating those translations that are not likely to be correct ones. Mutual information values are calculated based on word co-occurrence statistics and used as a measure to calculate correlation between words. The mutual information MI(x,y) is defined as the following formula (Church and Hanks, 1990). M/(x, y) =log p(x, y) =log N fw(x, y) (1) p(x)p(y) f(x)f(y) Here x and y are words occurring within a window of w words. The probabilities p(x) and p(y) are estimated by counting the number of observations of x and y in a corpus, f(x) and f(y), and normalizing each by N, the size of the corpus. Joint probabilities, p(x,y), are estimated by counting the number of times, fi,(x,y), that x is followed by y in a window of w words and normalizing it by N. In our application of query translation, the joint cooccurrence frequency Px,y) has 6-word window size which seems to allow semantic relations o</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks (1990). Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, Vol. 16, No. 1, pp. 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joong-Ho Shin</author>
</authors>
<title>Young-Soek Han, Key-Sun Choi</title>
<date>1996</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing.</booktitle>
<marker>Shin, 1996</marker>
<rawString>Joong-Ho Shin, Young-Soek Han, Key-Sun Choi (1996). A HMM Part of Speech Tagger for Korean with Word Phrasal Relations, In Proceedings of Recent Advances in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Samdja</author>
</authors>
<title>Retrieval Collection from Text: Xtract,</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<pages>143--177</pages>
<marker>Samdja, 1993</marker>
<rawString>Frank Samdja (1993) Retrieval Collection from Text: Xtract, Computational Linguistics, Vol. 19, No. 1, pp.143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K S Jeong</author>
<author>Y H Kwon</author>
<author>S H Myaeng</author>
</authors>
<title>Construction of Equivalence Classes through Automatic Extraction and Identification of Foreign Words,</title>
<date>1997</date>
<booktitle>In Proceedings of NLPRS&apos;97,</booktitle>
<location>Phuket, Tailand.</location>
<marker>Jeong, Kwon, Myaeng, 1997</marker>
<rawString>Jeong, K. S., Kwon,Y. H. and Myaeng, S. H. (1997). Construction of Equivalence Classes through Automatic Extraction and Identification of Foreign Words, In Proceedings of NLPRS&apos;97, Phuket, Tailand.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>