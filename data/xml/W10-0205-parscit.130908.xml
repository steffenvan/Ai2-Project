<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000159">
<title confidence="0.999145">
A Corpus-based Method for Extracting Paraphrases of Emotion Terms
</title>
<author confidence="0.991335">
Fazel Keshtkar Diana Inkpen
</author>
<affiliation confidence="0.999866">
University of Ottawa University of Ottawa
</affiliation>
<address confidence="0.951778">
Ottawa, ON, K1N 6N5, Canada Ottawa, ON, K1N 6N5, Canada
</address>
<email confidence="0.997845">
akeshtka@site.uOttawa.ca diana@site.uOttawa.ca
</email>
<sectionHeader confidence="0.997363" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995763125">
Since paraphrasing is one of the crucial tasks
in natural language understanding and gener-
ation, this paper introduces a novel technique
to extract paraphrases for emotion terms, from
non-parallel corpora. We present a bootstrap-
ping technique for identifying paraphrases,
starting with a small number of seeds. Word-
Net Affect emotion words are used as seeds.
The bootstrapping approach learns extraction
patterns for six classes of emotions. We use
annotated blogs and other datasets as texts
from which to extract paraphrases, based on
the highest-scoring extraction patterns. The
results include lexical and morpho-syntactic
paraphrases, that we evaluate with human
judges.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999845176470589">
Paraphrases are different ways to express the same
information. Algorithms to extract and automati-
cally identify paraphrases are of interest from both
linguistic and practical points of view. Many ma-
jor challenges in Natural Language Processing ap-
plications, for example multi-document summariza-
tion, need to avoid repetitive information from the
input documents. In Natural Language Genera-
tion, paraphrasing is employed to create more var-
ied and natural text. In our research, we ex-
tract paraphrases for emotions, with the goal of us-
ing them to automatically-generate emotional texts
(such as friendly or hostile texts) for conversations
between intelligent agents and characters in educa-
tional games. Paraphrasing is applied to generate
text with more variety. To our knowledge, most cur-
rent applications manually collect paraphrases for
</bodyText>
<page confidence="0.514389">
35
</page>
<bodyText confidence="0.977123588235294">
specific applications, or they use lexical resources
such as WordNet (Miller et al., 1993) to identify
paraphrases.
This paper introduces a novel method for ex-
tracting paraphrases for emotions from texts. We
focus on the six basic emotions proposed by Ek-
man (1992): happiness, sadness, anger, disgust,
surprise, and fear.
We describe the construction of the paraphrases
extractor. We also propose a k-window algorithm
for selecting contexts that are used in the paraphrase
extraction method. We automatically learn patterns
that are able to extract the emotion paraphrases from
corpora, starting with a set of seed words. We use
data sets such as blogs and other annotated cor-
pora, in which the emotions are marked. We use
a large collection of non-parallel corpora which are
described in Section 3. These corpora contain many
instances of paraphrases different words to express
the same emotion.
An example of sentence fragments for one
emotion class, happiness, is shown in Table 1. From
them, the paraphrase pair that our method will
extract is:
&amp;quot;so happy to see&amp;quot;
&amp;quot;very glad to visit&amp;quot;.
In the following sections, we give an overview of
related work on paraphrasing in Section 2. In Sec-
tion 3 we describe the datasets used in this work.
We explain the details of our paraphrase extraction
method in Section 4. We present results of our evalu-
ation and discuss our results in Section 5, and finally
in Section 6 we present the conclusions and future
work.
</bodyText>
<note confidence="0.9888295">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 35–44,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.633508">
his little boy was so happy to see him
princess and she were very glad to visit him
</bodyText>
<tableCaption confidence="0.984517">
Table 1: Two sentence fragments (candidate contexts)
from the emotion class happy, from the blog corpus.
</tableCaption>
<sectionHeader confidence="0.999604" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999369">
Three main approaches for collecting paraphrases
were proposed in the literature: manual collection,
utilization of existing lexical resources, and corpus-
based extraction of expressions that occur in similar
contexts (Barzilay and McKeown, 2001). Manually-
collected paraphrases were used in natural language
generation (NLG) (Iordanskaja et al., 1991). Langk-
ilde et al. (1998) used lexical resources in statistical
sentence generation, summarization, and question-
answering. Barzilay and McKeown (2001) used a
corpus-based method to identify paraphrases from a
corpus of multiple English translations of the same
source text. Our method is similar to this method,
but it extracts paraphrases only for a particular emo-
tion, and it needs only a regular corpus, not a parallel
corpus of multiple translations.
Some research has been done in paraphrase ex-
traction for natural language processing and genera-
tion for different applications. Das and Smith (2009)
presented a approach to decide whether two sen-
tences hold a paraphrase relationship. They ap-
plied a generative model that generates a paraphrase
of a given sentence, then used probabilistic infer-
ence to reason about whether two sentences share
the paraphrase relationship. In another research,
Wang et. al (2009) studied the problem of extract-
ing technical paraphrases from a parallel software
corpus. Their aim was to report duplicate bugs. In
their method for paraphrase extraction, they used:
sentence selection, global context-based and co-
occurrence-based scoring. Also, some studies have
been done in paraphrase generation in NLG (Zhao
et al., 2009), (Chevelu et al., 2009). Bootstrapping
methods have been applied to various natural lan-
guage applications, for example to word sense dis-
ambiguation (Yarowsky, 1995), lexicon construction
for information extraction (Riloff and Jones, 1999),
and named entity classification (Collins and Singer,
1999). In our research, we use the bootstrapping ap-
proach to learn paraphrases for emotions.
</bodyText>
<sectionHeader confidence="0.996193" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999976333333333">
The text data from which we will extract paraphrases
is composed of four concatenated datasets. They
contain sentences annotated with the six basic emo-
tions. The number of sentences in each dataset
is presented in Table 2. We briefly describe the
datasets, as follows.
</bodyText>
<subsectionHeader confidence="0.999819">
3.1 LiveJournal blog dataset
</subsectionHeader>
<bodyText confidence="0.999784636363637">
We used the blog corpus that Mishne collected for
his research (Mishne, 2005). The corpus contains
815,494 blog posts from Livejournal 1, a free we-
blog service used by millions of people to create
weblogs. In Livejournal, users are able to option-
ally specify their current emotion or mood. To se-
lect their emotion/mood users can choose from a list
of 132 provided moods. So, the data is annotated
by the user who created the blog. We selected only
the texts corresponding to the six emotions that we
mentioned.
</bodyText>
<subsectionHeader confidence="0.999441">
3.2 Text Affect Dataset
</subsectionHeader>
<bodyText confidence="0.999902375">
This dataset (Strapparava and Mihalcea, 2007) con-
sists of newspaper headlines that were used in the
SemEval 2007-Task 14. It includes a development
dataset of 250 annotated headlines, and a test dataset
of 1000 news headlines. We use all of them. The an-
notations were made with the six basic emotions on
intensity scales of [-100, 100], therefore a threshold
is used to choose the main emotion of each sentence.
</bodyText>
<subsectionHeader confidence="0.999586">
3.3 Fairy Tales Dataset
</subsectionHeader>
<bodyText confidence="0.9998755">
This dataset consists in 1580 annotated sentences
(Alm et al., 2005), from tales by the Grimm brothers,
H.C. Andersen, and B. Potter. The annotations used
the extended set of nine basic emotions of Izard
(1971). We selected only those marked with the six
emotions that we focus on.
</bodyText>
<subsectionHeader confidence="0.989973">
3.4 Annotated Blog Dataset
</subsectionHeader>
<bodyText confidence="0.998848833333333">
We also used the dataset provided by Aman and Sz-
pakowicz (2007). Emotion-rich sentences were se-
lected from personal blogs, and annotated with the
six emotions (as well as a non-emotion class, that
we ignore here). They worked with blog posts and
collected directly from the Web. First, they prepared
</bodyText>
<footnote confidence="0.998028">
1http://www.livejournalinc.com
</footnote>
<page confidence="0.995317">
36
</page>
<table confidence="0.9994162">
Dataset Happiness Sadness Anger Disgust Surprise Fear
LiveJournal 7705 1698 4758 1191 1191 3996
TextAffect 334 214 175 28 131 166
Fairy tales 445 264 216 217 113 165
Annotated blog dataset 536 173 115 115 172 179
</table>
<tableCaption confidence="0.999166">
Table 2: The number of emotion-annotated sentences in each dataset.
</tableCaption>
<figureCaption confidence="0.996861">
Figure 1: High-level view of the paraphrase extraction
method.
</figureCaption>
<bodyText confidence="0.992083833333333">
a list of seed words for six basic emotion categories
proposed by Ekman (1992). Then, they took words
commonly used in the context of a particular emo-
tion. Finally, they used the seed words for each
category, and retrieved blog posts containing one or
more of those words for the annotation process.
</bodyText>
<sectionHeader confidence="0.994838" genericHeader="method">
4 Method for Paraphrase Extraction
</sectionHeader>
<bodyText confidence="0.9995815">
For each of the six emotions, we run our method
on the set of sentences marked with the correspond-
ing emotion from the concatenated corpus. We
start with a set of seed words form WordNet Af-
fect (Strapparava and Valitutti, 2004), for each emo-
tion of interest. The number of seed words is the fol-
lowing: for happiness 395, for surprise 68, for fear
140, for disgust 50, for anger 250, and for sadness
200. Table 3 shows some of seeds for each category
of emotion.
Since sentences are different in our datasets
and they are not aligned as parallel sentences as
in (Barzilay and McKeown, 2001), our algorithm
constructs pairs of similar sentences, based on the
local context. On the other hand, we assume that,
if the contexts surrounding two seeds look similar,
then these contexts are likely to help in extracting
new paraphrases.
Figure 1 illustrates the high-level architecture of
our paraphrase extraction method. The input to the
method is a text corpus for a emotion category and
a manually defined list of seed words. Before boot-
strapping starts, we run the k-window algorithm on
every sentence in the corpus, in order to construct
candidate contexts. In Section 4.5 we explain how
the bootstrapping algorithm processes and selects
the paraphrases based on strong surrounding con-
texts. As it is shown in Figure 1, our method has
several stages: extracting candidate contexts, using
them to extract patterns, selecting the best patterns,
extracting potential paraphrases, and filtering them
to obtain the final paraphrases.
</bodyText>
<subsectionHeader confidence="0.995778">
4.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999857888888889">
During preprocessing, HTML and XML tags are
eliminated from the blogs data and other datasets,
then the text is tokenized and annotated with part
of speech tags. We use the Stanford part-of-speech
tagger and chunker (Toutanova et al., 2003) to iden-
tify noun and verb phrases in the sentences. In the
next step, we use a sliding window based on the
k-window approach, to identify candidate contexts
that contain the target seeds.
</bodyText>
<subsectionHeader confidence="0.999166">
4.2 The k-window Algorithm
</subsectionHeader>
<bodyText confidence="0.9999956">
We use the k-window algorithm introduced by
Bostad (2003) in order to identify all the tokens
surrounding a specific term in a window with
size of fk. Here, we use this approach to ex-
tract candidate patterns for each seed, from the
sentences. We start with one seed and truncate
all contexts around the seed within a window of
fk words before and fk words after the seed,
until all the seeds are processed. For these exper-
iments, we set the value of k to f5. Therefore
</bodyText>
<page confidence="0.968228">
37
</page>
<bodyText confidence="0.9677995">
Happiness: avidness, glad, warmheartedness, exalt, enjoy, comforting, joviality, amorous, joyful,
like, cheer, adoring, fascinating, happy, impress, great, satisfaction, cheerful, charmed, romantic, joy,
pleased, inspire, good, fulfill, gladness, merry
Sadness: poor, sorry, woeful, guilty, miserable, glooming, bad, grim, tearful, glum, mourning, joyless,
sadness, blue, rueful, hamed, regret, hapless, regretful, dismay, dismal, misery, godforsaken, oppression,
harass, dark, sadly, attrition
Anger: belligerence, envious, aggravate, resentful, abominate, murderously, greedy, hatred, disdain,
envy, annoy, mad, jealousy, huffiness, sore, anger, harass, bother, enraged, hateful, irritating, hostile,
outrage, devil, irritate, angry
Disgust: nauseous, sicken, foul, disgust, nausea, revolt, hideous, horror, detestable, wicked, repel,
offensive, repulse, yucky, repulsive, queasy, obscene, noisome
Surprise: wondrous, amaze, gravel, marvel, fantastic, wonderful, surprising, marvelous, wonderment,
astonish, wonder, admiration, terrific, dumfounded, trounce
Fear: fearful, apprehensively, anxiously, presage, horrified, hysterical, timidity, horrible, timid,
fright, hesitance, affright, trepid, horrific, unassertive, apprehensiveness, hideous, scarey, cruel, panic,
scared, terror, awful, dire, fear, dread, crawl, anxious, distrust, diffidence
</bodyText>
<tableCaption confidence="0.992914">
Table 3: Some of the seeds from WordNet Affect for each category of emotion.
</tableCaption>
<bodyText confidence="0.9979734">
the longest candidate contexts will have the form
w1, w2, w3, w4, w5, seed, w6, w7, w8, w9, w10, w11.
In the next subsection, we explain what features we
extract from each candidate context, to allow us to
determine similar contexts.
</bodyText>
<equation confidence="0.44895275">
Candidate context: He was further annoyed by the jay bird
’PRP VBD RB VBN IN DT NN NN’,65,8,’VBD RB’,?,was,
?,?,?,He/PRP,was/VBD,further/RB,annoyed,by/IN,the/DT,
jay/NN,bird/NN,?,?,jay,?,’IN DT NN’,2,2,0,1
</equation>
<tableCaption confidence="0.996849">
Table 4: An example of extracted features.
</tableCaption>
<subsectionHeader confidence="0.996326">
4.3 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999970689655172">
Previous research on word sense disambiguation on
contextual analysis has acknowledged several local
and topical features as good indicators of word prop-
erties. These include surrounding words and their
part of speech tags, collocations, keywords in con-
texts (Mihalcea, 2004). Also recently, other fea-
tures have been proposed: bigrams, named entities,
syntactic features, and semantic relations with other
words in the context.
We transfer the candidate phrases extracted by the
sliding k-window into the vector space of features.
We consider features that include both lexical and
syntactic descriptions of the paraphrases for all pairs
of two candidates. The lexical features include the
sequence of tokens for each phrase in the paraphrase
pair; the syntactic feature consists of a sequence of
part-of-speech (PoS) tags where equal words and
words with the same root and PoS are marked.
For example, the value of the syntactic feature for
the pair “so glad to see”and “very
happy to visit”is “RB1 JJ1 TO V B1”
and ”RB1 JJ2 TO V B2”, where indices indicate
word equalities. However, based on the above ev-
idences and our previous research, we also investi-
gate other features that are well suited for our goal.
Table 5 lists the features that we used for paraphrase
extraction. They include some term frequency fea-
tures. As an example, in Table 4 we show extracted
features from a relevant context.
</bodyText>
<subsectionHeader confidence="0.998324">
4.4 Extracting Patterns
</subsectionHeader>
<bodyText confidence="0.999973416666667">
From each candidate context, we extracted the fea-
tures as described above. Then we learn extraction
patterns, in which some words might be substituted
by their part-of-speech. We use the seeds to build
initial patterns. Two candidate contexts that con-
tain the same seed create one positive example. By
using each initial seed, we can extract all contexts
surrounding these positive examples. Then we se-
lect the stronger ones. We used Collins and Singer
method (Collins and Singer, 1999) to compute the
strength of each example. If we consider x as a con-
text, the strength as a positive example of x is de-
</bodyText>
<page confidence="0.990843">
38
</page>
<table confidence="0.979578105263158">
Features Description
F1 Sequence of part-of-speech
F2 Length of sequence in bytes
F3 Number of tokens
F4 Sequence of PoS between the seed and the first verb before the seed
F5 Sequence of PoS between the seed and the first noun before the seed
F6 First verb before the seed
F7 First noun before the seed
F8 Token before the seed
F9 Seed
F10 Token after the seed
F11 First verb after the seed
F12 First noun after the seed
F13 Sequence of PoS between the seed and the first verb after the seed
F14 Sequence of PoS between the seed and the first noun after the seed
F15 Number of verbs in the candidate context
F16 Number of nouns in the candidate context
F17 Number of adjective in the candidate context
F18 Number of adverbs in the candidate context
</table>
<tableCaption confidence="0.999314">
Table 5: The features that we used for paraphrase extraction.
</tableCaption>
<equation confidence="0.873588">
fined as:
Strength(x) = count(x+)/count(x) (1)
</equation>
<bodyText confidence="0.999287">
In Equation 1, count(x+) is the number of times
context x surrounded a seed in a positive example
and count(x) is frequency of the context x. This
allows us to score the potential pattern.
</bodyText>
<subsectionHeader confidence="0.9509715">
4.5 Bootstrapping Algorithm for Paraphrase
Extraction
</subsectionHeader>
<bodyText confidence="0.9999865">
Our bootstrapping algorithm is summarized in Fig-
ure 2. It starts with a set of seeds, which are consid-
ered initial paraphrases. A set of extraction patterns
is initially empty. The algorithm generates candidate
contexts, from the aligned similar contexts. The can-
didate patterns are scored by how many paraphrases
they can extract. Those with the highest scores are
added to the set of extraction patterns. Using the ex-
tended set of extraction patterns, more paraphrase
pairs are extracted and added to the set of para-
phrases. Using the enlarged set of paraphrases, more
extraction patterns are extracted. The process keeps
iterating until no new patterns or no new paraphrases
are learned.
Our method is able to accumulate a large lexi-
con of emotion phrases by bootstrapping from the
manually initialized list of seed words. In each it-
eration, the paraphrase set is expanded with related
phrases found in the corpus, which are filtered by
using a measure of strong surrounding context sim-
ilarity. The bootstrapping process starts by select-
ing a subset of the extraction patterns that aim to
extract the paraphrases. We call this set the pattern
pool. The phrases extracted by these patterns be-
come candidate paraphrases. They are filtered based
on how many patterns select them, in order to pro-
duce the final paraphrases from the set of candidate
paraphrases.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="method">
5 Results and Evaluation
</sectionHeader>
<bodyText confidence="0.9999855">
The result of our algorithm is a set of extraction pat-
terns and a set of pairs of paraphrases. Some of the
paraphrases extracted by our system are shown in
Table 6. The paraphrases that are considered correct
are shown under Correct paraphrases. As explained
in the next section, two human judges agreed that
these are acceptable paraphrases. The results con-
sidered incorrect by the two judges are shown un-
</bodyText>
<page confidence="0.999233">
39
</page>
<table confidence="0.342390333333333">
Algorithm 1: Bootstrapping Algorithm.
For each seed for an emotion
Loop until no more paraphrases or no more contexts are learned.
</table>
<listItem confidence="0.9620174">
1- Locate the seeds in each sentence
2- Find similar contexts surrounding a pair of two seeds
3- Analyze all contexts surrounding the two seeds to extract
the strongest patterns
4- Use the new patterns to learn more paraphrases
</listItem>
<figureCaption confidence="0.990044">
Figure 2: Our bootstrapping algorithm for extracting paraphrases.
</figureCaption>
<bodyText confidence="0.999965384615385">
der Incorrect paraphrases. Our algorithm learnt 196
extraction patterns and produced 5926 pairs of para-
phrases. Table 7 shows the number of extraction pat-
terns and the number of paraphrase pairs that were
produced by our algorithm for each class of emo-
tions. For evaluation of our algorithm, we use two
techniques. One uses human judges to judge if a
sample of paraphrases extracted by our method are
correct; we also measures the agreement between
the judges (See Section 5.1). The second estimates
the recall and the precision of our method (See Sec-
tion 5.2. In the following subsections we describe
these evaluations.
</bodyText>
<subsectionHeader confidence="0.798539">
5.1 Evaluating Correctness with Human
Judges
</subsectionHeader>
<bodyText confidence="0.999936951219512">
We evaluate the correctness of the extracted para-
phrase pairs, using the same method as Brazilay and
McKeown (2001). We randomly selected 600 para-
phrase pairs from the lexical paraphrases produced
by our algorithm: for each class of emotion we
selected 100 paraphrase pairs. We evaluated their
correctness with two human judges. They judged
whether the two expressions are good paraphrases
or not.
We provided a page of guidelines for the judges.
We defined paraphrase as ”approximate conceptual
equivalence”, the same definition used in (Barzilay
and McKeown, 2001). Each human judge had to
choose a ”Yes” or ”No” answer for each pair of para-
phrases under test. We did not include example sen-
tences containing these paraphrases. A similar Ma-
chine Translation evaluation task for word-to-word
translation was done in (Melamed, 2001).
Figure 3 presents the results of the evaluation: the
correctness for each class of emotion according to
judge A, and according to judge B. The judges were
graduate students in computational linguistics, na-
tive speakers of English.
We also measured the agreement between the two
judges and the Kappa coefficient (Siegel and Castel-
lan, 1988). If there is complete agreement between
two judges Kappa is 1, and if there is no agreement
between the judges then Kappa = 0. The Kappa
values and the agreement values for our judges are
presented in Figure 4.
The inter-judge agreement over all the para-
phrases for the six classes of emotions is 81.72%,
which is 490 out of the 600 paraphrases pairs in our
sample. Note that they agreed that some pairs are
good paraphrases, or they agreed that some pairs
are not good paraphrases, that is why the numbers
in Figure 4 are higher than the correctness numbers
from Figure 3. The Kappa coefficient compensates
for the chance agreement. The Kappa value over
all the paraphrase pairs is 74.41% which shows a
significant agreement.
</bodyText>
<figureCaption confidence="0.973772">
Figure 3: The correctness results according the judge A
and judge B, for each class of emotion.
</figureCaption>
<subsectionHeader confidence="0.999303">
5.2 Estimating Recall
</subsectionHeader>
<bodyText confidence="0.992615333333333">
Evaluating the Recall of our algorithm is difficult
due to following reasons. Our algorithm is not able
to cover all the English words; it can only detect
</bodyText>
<page confidence="0.992185">
40
</page>
<table confidence="0.999848111111111">
Disgust
Correct paraphrases:
being a wicked::getting of evil; been rather sick::feeling rather nauseated;
feels somewhat queasy::felt kind of sick; damn being sick::am getting sick
Incorrect paraphrases:
disgusting and vile::appealing and nauseated; get so sick::some truly disgusting
Fear
Correct paraphrases:
was freaking scared::was quite frightened; just very afraid::just so scared;
tears of fright::full of terror; freaking scary::intense fear;
Incorrect paraphrases:
serious panic attack::easily scared; not necessarily fear::despite your fear
Anger
Correct paraphrases:
upset and angry::angry and pissed; am royally pissed::feeling pretty angry;
made me mad::see me angry; do to torment::just to spite
Incorrect paraphrases:
very pretty annoying::very very angry; bitter and spite::tired and angry
Happiness
Correct paraphrases:
the love of::the joy of; in great mood::in good condition;
the joy of::the glad of; good feeling::good mood
Incorrect paraphrases:
as much eagerness::as many gladness; feeling smart::feel happy
Sadness
Correct paraphrases:
too depressing::so sad; quite miserable::quite sorrowful;
strangely unhappy::so misery; been really down::feel really sad
Incorrect paraphrases:
out of pity::out of misery; akward and depressing::terrible and gloomy
Surprise
Correct paraphrases:
amazement at::surprised by; always wonder::always surprised;
still astounded::still amazed; unexpected surprise::got shocked
Incorrect paraphrases:
passion and tremendous::serious and amazing; tremendous stress::huge shock
</table>
<tableCaption confidence="0.998417">
Table 6: Examples of paraphrases extracted by our algorithm (correctly and incorrectly).
</tableCaption>
<page confidence="0.975564">
41
</page>
<table confidence="0.9974645">
Class of Emotion # Paraphrases Pairs # Extraction Patterns
Disgust 1125 12
Fear 1004 31
Anger 670 47
Happiness 1095 68
Sadness 1308 25
Surprise 724 13
Total 5926 196
</table>
<tableCaption confidence="0.998738">
Table 7: The number of lexical and extraction patterns produced by the algorithm.
</tableCaption>
<figureCaption confidence="0.9941915">
Figure 4: The Kappa coefficients and the agreement be-
tween the two human judges.
</figureCaption>
<bodyText confidence="0.9999054">
paraphrasing relations with words which appeared
in our corpus. Moreover, to compare directly with
an electronic thesaurus such as WordNet is not fea-
sible, because WordNet contains mostly synonym
sets between words, and only a few multi-word ex-
pressions. We decided to estimate recall manually,
by asking a human judge to extract paraphrases by
hand from a sample of text. We randomly selected
60 texts (10 for each emotion class) and asked the
judge to extract paraphrases from these sentences.
For each emotion class, the judge extracted expres-
sions that reflect the emotion, and then made pairs
that were conceptually equivalent. It was not feasi-
ble to ask a second judge to do the same task, be-
cause the process is time-consuming and tedious.
In Information Retrieval, Precision and Recall are
defined in terms of a set of retrieved documents and
a set of relevant documents 2. In the following sec-
tions we describe how we compute the Precision and
Recall for our algorithm compared to the manually
</bodyText>
<footnote confidence="0.96262">
2http://en.wikipedia.org/wiki/
</footnote>
<table confidence="0.999599125">
Category of Emotions Precision Recall
Disgust 82.33% 92.91%
Fear 82.64% 88.20%
Anger 93.67% 80.57%
Happiness 82.00% 90.89%
Sadness 82.00% 89.88%
Surprise 79.78% 89.50%
Average 84.23% 88.66%
</table>
<tableCaption confidence="0.9993115">
Table 8: Precision and Recall for a sample of texts, for
each category of emotion, and their average.
</tableCaption>
<bodyText confidence="0.989772">
extracted paraphrases.
From the paraphrases that were extracted by the
algorithm from the same texts, we counted how
many of them were also extracted by the human
judge. Equation 2 defines the Precision. On av-
erage, from 89 paraphrases extracted by the algo-
rithm, 74 were identified as paraphrases by the hu-
man judge (84.23%). See Table 8 for the values for
all the classes.
</bodyText>
<equation confidence="0.5181505">
# Correctly Retrieved Paraphrases by the Algorithm
P _ (2)
</equation>
<subsubsectionHeader confidence="0.73346">
All Paraphrases Retrieved by the Algorithm
</subsubsectionHeader>
<bodyText confidence="0.999692">
For computing the Recall we count how many of
the paraphrases extracted by the human judge were
correctly extracted by the algorithm (Equation 3).
</bodyText>
<figure confidence="0.614444333333333">
# Correctly Retrieved Paraphrases by the Algorithm
R _ (3)
All Paraphrases Retrieved by the Human Judge
</figure>
<sectionHeader confidence="0.503566" genericHeader="method">
5.3 Discussion and Comparison to Related
Work
</sectionHeader>
<bodyText confidence="0.99963975">
To the best of our knowledge, no similar research
has been done in extracting paraphrases for emotion
terms from corpora. However, Barzilay and McKe-
own (2001) did similar work to corpus-based iden-
</bodyText>
<page confidence="0.996994">
42
</page>
<bodyText confidence="0.9967719">
tification of general paraphrases from multiple En-
glish translations of the same source text. We can
compare the pros and cons of our method compared
to their method. The advantages are:
• In our method, there is no requirement for the
corpus to be parallel. Our algorithm uses the
entire corpus together to construct its boot-
strapping method, while in (Barzilay and McK-
eown, 2001) the parallel corpus is needed in or-
der detect positive contexts.
• Since we construct the candidate contexts
based on the k-window approach, there is no
need for sentences to be aligned in our method.
In (Barzilay and McKeown, 2001) sentence
alignment is essential in order to recognize
identical words and positive contexts.
• The algorithm in (Barzilay and McKeown,
2001) has to find positive contexts first, then
it looks for appropriate patterns to extract para-
phrases. Therefore, if identical words do not
occur in the aligned sentences, the algorithm
fails to find positive contexts. But, our al-
gorithm starts with given seeds that allow us
to detect positive context with the k-window
method.
A limitation of our method is the need for the initial
seed words. However, obtaining these seed words
is not a problem nowadays. They can be found in
on line dictionaries, WordNet, and other lexical re-
courses.
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999967117647059">
In this paper, we introduced a method for corpus-
based extraction of paraphrases for emotion terms.
We showed a method that used a bootstrapping tech-
nique based on contextual and lexical features and
is able to successfully extract paraphrases using a
non-parallel corpus. We showed that a bootstrapping
algorithm based on contextual surrounding context
features of paraphrases achieves significant perfor-
mance on our data set.
In future work, we will extend this techniques to
extract paraphrases from more corpora and for more
types of emotions. In terms of evaluation, we will
use the extracted paraphrases as features in machine
learning classifiers that classify candidate sentences
into classes of emotions. If the results of the classifi-
cation are good, this mean the extracted paraphrases
are of good quality.
</bodyText>
<sectionHeader confidence="0.996065" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999830413043478">
Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat.
2005. Emotions from text: machine learning for text-
based emotion prediction. In Proceedings of the Hu-
man Language Technology Conference Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP 2005).
Saima Aman and Stan Szpakowicz. 2007. Identifying
expressions of emotion in text. In TSD, pages 196–
205.
Regina Barzilay and Kathleen McKeown. 2001. Extract-
ing paraphrases from a parallel corpus. In Proceeding
ofACL/EACL, 2001, Toulouse.
Thorstein Bostad. 2003. Sentence Based Automatic Sen-
timent Classification. Ph.D. thesis, University of Cam-
bridge, Computer Speech Text and Internet Technolo-
gies (CSTIT), Computer Laboratory, Jan.
Jonathan Chevelu, Thomas Lavergne, Yves Lepage, and
Thierry Moudenc. 2009. Introduction of a new para-
phrase generation tool based on Monte-Carlo sam-
pling. In Proceedings of ACL-IJCNLP 2009, Singa-
pore, pages 249–25.
Michael Collins and Yoram Singer. 1999. Unsupervised
models for named entity classification. In proceedings
of the Joint SIGDAT Conference on Empirical Meth-
ods in Natural Language Processing and Very Large
Corpora.
Dipanjan Das and Noah A. Smith. 2009. Paraphrase
identification as probabilistic quasi-synchronous
recognition. In Proceedings of ACL-IJCNLP 2009,
Singapore, pages 468–476.
Paul Ekman. 1992. An argument for basic emotions.
Cognition and Emotion, 6:169–200.
L. Iordanskaja, Richard Kittredget, and Alain Polguere,
1991. Natural Language Generation in Artificial In-
telligence and Computational Linguistics. Kluwer
Academic.
Carroll E. Izard. 1971. The Face of Emotion. Appleton-
Century-Crofts., New York.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In
COLING-ACL.
Ilya Dan Melamed. 2001. Empirical Methods for Ex-
ploiting Parallel Texts. MIT Press.
Rada Mihalcea. 2004. Co-training and self-training
for word sense disambiguation. In Natural Language
Learning (CoNLL 2004), Boston, May.
</reference>
<page confidence="0.995518">
43
</page>
<reference confidence="0.999863625">
George Miller, Richard Beckwith, Christiane Fellbaum,
Derek Gross, and Katherine Miller, 1993. Introduc-
tion to Wordnet: An On-Line Lexical Database. Cog-
nitive Science Laboratory, Princeton University, Au-
gust.
Gilad Mishne. 2005. Experiments with mood classifica-
tion in blog posts. ACM SIGIR.
Ellen Riloff and Rosie Jones. 1999. Learning dictio-
naries for information extraction by multi-level boot-
strapping. In Proceedings of the Sixteenth National
Conference on Artificial Intelligence, page 10441049.
The AAAI Press/MIT Press.
Sidney Siegel and John Castellan, 1988. Non Parametric
Statistics for Behavioral Sciences.. McGraw-Hill.
Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. In Proceedings of the 4th
International Workshop on the Semantic Evaluations
(SemEval 2007), Prague, Czech Republic, June 2007.
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of wordnet. In
Proceedings of the 4th International Conference on
Language Resources and Evaluation (LREC 2004),
Lisbon, May 2004, pages 1083–1086.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of HLT-NAACL, pages 252–259.
Xiaoyin Wang, David Lo, Jing Jiang, Lu Zhang, and
Hong Mei. 2009. Extracting paraphrases of tech-
nical terms from noisy parallel software corpora. In
Proceedings of ACL-IJCNLP 2009, Singapore, pages
197–200.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Proceed-
ings of the 33rd Annual Meeting of the Association for
Computational Linguistics, pages 189–196.
Shiqi Zhao, Xiang Lan, Ting Liu, , and Sheng Li.
2009. Application-driven statistical paraphrase gen-
eration. In Proceedings of ACL-IJCNLP 2009, Singa-
pore, pages 834–842.
</reference>
<page confidence="0.999294">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.889062">
<title confidence="0.999891">A Corpus-based Method for Extracting Paraphrases of Emotion Terms</title>
<author confidence="0.998262">Fazel Keshtkar Diana Inkpen</author>
<affiliation confidence="0.999954">University of Ottawa University of Ottawa</affiliation>
<address confidence="0.999624">Ottawa, ON, K1N 6N5, Canada Ottawa, ON, K1N 6N5, Canada</address>
<email confidence="0.974395">akeshtka@site.uOttawa.cadiana@site.uOttawa.ca</email>
<abstract confidence="0.994856">Since paraphrasing is one of the crucial tasks in natural language understanding and generation, this paper introduces a novel technique to extract paraphrases for emotion terms, from non-parallel corpora. We present a bootstrapping technique for identifying paraphrases, starting with a small number of seeds. Word- Net Affect emotion words are used as seeds. The bootstrapping approach learns extraction patterns for six classes of emotions. We use annotated blogs and other datasets as texts from which to extract paraphrases, based on the highest-scoring extraction patterns. The results include lexical and morpho-syntactic paraphrases, that we evaluate with human judges.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cecilia Ovesdotter Alm</author>
<author>Dan Roth</author>
<author>Richard Sproat</author>
</authors>
<title>Emotions from text: machine learning for textbased emotion prediction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP</booktitle>
<contexts>
<context position="6997" citStr="Alm et al., 2005" startWordPosition="1087" endWordPosition="1090">he blog. We selected only the texts corresponding to the six emotions that we mentioned. 3.2 Text Affect Dataset This dataset (Strapparava and Mihalcea, 2007) consists of newspaper headlines that were used in the SemEval 2007-Task 14. It includes a development dataset of 250 annotated headlines, and a test dataset of 1000 news headlines. We use all of them. The annotations were made with the six basic emotions on intensity scales of [-100, 100], therefore a threshold is used to choose the main emotion of each sentence. 3.3 Fairy Tales Dataset This dataset consists in 1580 annotated sentences (Alm et al., 2005), from tales by the Grimm brothers, H.C. Andersen, and B. Potter. The annotations used the extended set of nine basic emotions of Izard (1971). We selected only those marked with the six emotions that we focus on. 3.4 Annotated Blog Dataset We also used the dataset provided by Aman and Szpakowicz (2007). Emotion-rich sentences were selected from personal blogs, and annotated with the six emotions (as well as a non-emotion class, that we ignore here). They worked with blog posts and collected directly from the Web. First, they prepared 1http://www.livejournalinc.com 36 Dataset Happiness Sadness</context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: machine learning for textbased emotion prediction. In Proceedings of the Human Language Technology Conference Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saima Aman</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Identifying expressions of emotion in text.</title>
<date>2007</date>
<booktitle>In TSD,</booktitle>
<pages>196--205</pages>
<contexts>
<context position="7301" citStr="Aman and Szpakowicz (2007)" startWordPosition="1139" endWordPosition="1143">, and a test dataset of 1000 news headlines. We use all of them. The annotations were made with the six basic emotions on intensity scales of [-100, 100], therefore a threshold is used to choose the main emotion of each sentence. 3.3 Fairy Tales Dataset This dataset consists in 1580 annotated sentences (Alm et al., 2005), from tales by the Grimm brothers, H.C. Andersen, and B. Potter. The annotations used the extended set of nine basic emotions of Izard (1971). We selected only those marked with the six emotions that we focus on. 3.4 Annotated Blog Dataset We also used the dataset provided by Aman and Szpakowicz (2007). Emotion-rich sentences were selected from personal blogs, and annotated with the six emotions (as well as a non-emotion class, that we ignore here). They worked with blog posts and collected directly from the Web. First, they prepared 1http://www.livejournalinc.com 36 Dataset Happiness Sadness Anger Disgust Surprise Fear LiveJournal 7705 1698 4758 1191 1191 3996 TextAffect 334 214 175 28 131 166 Fairy tales 445 264 216 217 113 165 Annotated blog dataset 536 173 115 115 172 179 Table 2: The number of emotion-annotated sentences in each dataset. Figure 1: High-level view of the paraphrase extr</context>
</contexts>
<marker>Aman, Szpakowicz, 2007</marker>
<rawString>Saima Aman and Stan Szpakowicz. 2007. Identifying expressions of emotion in text. In TSD, pages 196– 205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceeding ofACL/EACL, 2001,</booktitle>
<location>Toulouse.</location>
<contexts>
<context position="3903" citStr="Barzilay and McKeown, 2001" startWordPosition="597" endWordPosition="600">shop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 35–44, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics his little boy was so happy to see him princess and she were very glad to visit him Table 1: Two sentence fragments (candidate contexts) from the emotion class happy, from the blog corpus. 2 Related Work Three main approaches for collecting paraphrases were proposed in the literature: manual collection, utilization of existing lexical resources, and corpusbased extraction of expressions that occur in similar contexts (Barzilay and McKeown, 2001). Manuallycollected paraphrases were used in natural language generation (NLG) (Iordanskaja et al., 1991). Langkilde et al. (1998) used lexical resources in statistical sentence generation, summarization, and questionanswering. Barzilay and McKeown (2001) used a corpus-based method to identify paraphrases from a corpus of multiple English translations of the same source text. Our method is similar to this method, but it extracts paraphrases only for a particular emotion, and it needs only a regular corpus, not a parallel corpus of multiple translations. Some research has been done in paraphras</context>
<context position="8840" citStr="Barzilay and McKeown, 2001" startWordPosition="1401" endWordPosition="1404">s. 4 Method for Paraphrase Extraction For each of the six emotions, we run our method on the set of sentences marked with the corresponding emotion from the concatenated corpus. We start with a set of seed words form WordNet Affect (Strapparava and Valitutti, 2004), for each emotion of interest. The number of seed words is the following: for happiness 395, for surprise 68, for fear 140, for disgust 50, for anger 250, and for sadness 200. Table 3 shows some of seeds for each category of emotion. Since sentences are different in our datasets and they are not aligned as parallel sentences as in (Barzilay and McKeown, 2001), our algorithm constructs pairs of similar sentences, based on the local context. On the other hand, we assume that, if the contexts surrounding two seeds look similar, then these contexts are likely to help in extracting new paraphrases. Figure 1 illustrates the high-level architecture of our paraphrase extraction method. The input to the method is a text corpus for a emotion category and a manually defined list of seed words. Before bootstrapping starts, we run the k-window algorithm on every sentence in the corpus, in order to construct candidate contexts. In Section 4.5 we explain how the</context>
<context position="19240" citStr="Barzilay and McKeown, 2001" startWordPosition="3046" endWordPosition="3049">se evaluations. 5.1 Evaluating Correctness with Human Judges We evaluate the correctness of the extracted paraphrase pairs, using the same method as Brazilay and McKeown (2001). We randomly selected 600 paraphrase pairs from the lexical paraphrases produced by our algorithm: for each class of emotion we selected 100 paraphrase pairs. We evaluated their correctness with two human judges. They judged whether the two expressions are good paraphrases or not. We provided a page of guidelines for the judges. We defined paraphrase as ”approximate conceptual equivalence”, the same definition used in (Barzilay and McKeown, 2001). Each human judge had to choose a ”Yes” or ”No” answer for each pair of paraphrases under test. We did not include example sentences containing these paraphrases. A similar Machine Translation evaluation task for word-to-word translation was done in (Melamed, 2001). Figure 3 presents the results of the evaluation: the correctness for each class of emotion according to judge A, and according to judge B. The judges were graduate students in computational linguistics, native speakers of English. We also measured the agreement between the two judges and the Kappa coefficient (Siegel and Castellan</context>
<context position="25059" citStr="Barzilay and McKeown (2001)" startWordPosition="3945" endWordPosition="3949">human judge (84.23%). See Table 8 for the values for all the classes. # Correctly Retrieved Paraphrases by the Algorithm P _ (2) All Paraphrases Retrieved by the Algorithm For computing the Recall we count how many of the paraphrases extracted by the human judge were correctly extracted by the algorithm (Equation 3). # Correctly Retrieved Paraphrases by the Algorithm R _ (3) All Paraphrases Retrieved by the Human Judge 5.3 Discussion and Comparison to Related Work To the best of our knowledge, no similar research has been done in extracting paraphrases for emotion terms from corpora. However, Barzilay and McKeown (2001) did similar work to corpus-based iden42 tification of general paraphrases from multiple English translations of the same source text. We can compare the pros and cons of our method compared to their method. The advantages are: • In our method, there is no requirement for the corpus to be parallel. Our algorithm uses the entire corpus together to construct its bootstrapping method, while in (Barzilay and McKeown, 2001) the parallel corpus is needed in order detect positive contexts. • Since we construct the candidate contexts based on the k-window approach, there is no need for sentences to be</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceeding ofACL/EACL, 2001, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorstein Bostad</author>
</authors>
<title>Sentence Based Automatic Sentiment Classification.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge, Computer Speech Text and Internet Technologies (CSTIT), Computer Laboratory,</institution>
<contexts>
<context position="10309" citStr="Bostad (2003)" startWordPosition="1636" endWordPosition="1637">acting potential paraphrases, and filtering them to obtain the final paraphrases. 4.1 Preprocessing During preprocessing, HTML and XML tags are eliminated from the blogs data and other datasets, then the text is tokenized and annotated with part of speech tags. We use the Stanford part-of-speech tagger and chunker (Toutanova et al., 2003) to identify noun and verb phrases in the sentences. In the next step, we use a sliding window based on the k-window approach, to identify candidate contexts that contain the target seeds. 4.2 The k-window Algorithm We use the k-window algorithm introduced by Bostad (2003) in order to identify all the tokens surrounding a specific term in a window with size of fk. Here, we use this approach to extract candidate patterns for each seed, from the sentences. We start with one seed and truncate all contexts around the seed within a window of fk words before and fk words after the seed, until all the seeds are processed. For these experiments, we set the value of k to f5. Therefore 37 Happiness: avidness, glad, warmheartedness, exalt, enjoy, comforting, joviality, amorous, joyful, like, cheer, adoring, fascinating, happy, impress, great, satisfaction, cheerful, charm</context>
</contexts>
<marker>Bostad, 2003</marker>
<rawString>Thorstein Bostad. 2003. Sentence Based Automatic Sentiment Classification. Ph.D. thesis, University of Cambridge, Computer Speech Text and Internet Technologies (CSTIT), Computer Laboratory, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chevelu</author>
<author>Thomas Lavergne</author>
<author>Yves Lepage</author>
<author>Thierry Moudenc</author>
</authors>
<title>Introduction of a new paraphrase generation tool based on Monte-Carlo sampling.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009, Singapore,</booktitle>
<pages>249--25</pages>
<contexts>
<context position="5290" citStr="Chevelu et al., 2009" startWordPosition="808" endWordPosition="811"> a paraphrase relationship. They applied a generative model that generates a paraphrase of a given sentence, then used probabilistic inference to reason about whether two sentences share the paraphrase relationship. In another research, Wang et. al (2009) studied the problem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been done in paraphrase generation in NLG (Zhao et al., 2009), (Chevelu et al., 2009). Bootstrapping methods have been applied to various natural language applications, for example to word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is presented in Table 2. We brie</context>
</contexts>
<marker>Chevelu, Lavergne, Lepage, Moudenc, 2009</marker>
<rawString>Jonathan Chevelu, Thomas Lavergne, Yves Lepage, and Thierry Moudenc. 2009. Introduction of a new paraphrase generation tool based on Monte-Carlo sampling. In Proceedings of ACL-IJCNLP 2009, Singapore, pages 249–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Yoram Singer</author>
</authors>
<title>Unsupervised models for named entity classification.</title>
<date>1999</date>
<booktitle>In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="5565" citStr="Collins and Singer, 1999" startWordPosition="845" endWordPosition="848">blem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been done in paraphrase generation in NLG (Zhao et al., 2009), (Chevelu et al., 2009). Bootstrapping methods have been applied to various natural language applications, for example to word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is presented in Table 2. We briefly describe the datasets, as follows. 3.1 LiveJournal blog dataset We used the blog corpus that Mishne collected for his research (Mishne, 2005). The corpus contains 815,494 blog posts from Livejournal 1, a free weblog service used by millions of people to create weblogs. I</context>
<context position="14565" citStr="Collins and Singer, 1999" startWordPosition="2260" endWordPosition="2263">nclude some term frequency features. As an example, in Table 4 we show extracted features from a relevant context. 4.4 Extracting Patterns From each candidate context, we extracted the features as described above. Then we learn extraction patterns, in which some words might be substituted by their part-of-speech. We use the seeds to build initial patterns. Two candidate contexts that contain the same seed create one positive example. By using each initial seed, we can extract all contexts surrounding these positive examples. Then we select the stronger ones. We used Collins and Singer method (Collins and Singer, 1999) to compute the strength of each example. If we consider x as a context, the strength as a positive example of x is de38 Features Description F1 Sequence of part-of-speech F2 Length of sequence in bytes F3 Number of tokens F4 Sequence of PoS between the seed and the first verb before the seed F5 Sequence of PoS between the seed and the first noun before the seed F6 First verb before the seed F7 First noun before the seed F8 Token before the seed F9 Seed F10 Token after the seed F11 First verb after the seed F12 First noun after the seed F13 Sequence of PoS between the seed and the first verb a</context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Michael Collins and Yoram Singer. 1999. Unsupervised models for named entity classification. In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Paraphrase identification as probabilistic quasi-synchronous recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009, Singapore,</booktitle>
<pages>468--476</pages>
<contexts>
<context position="4611" citStr="Das and Smith (2009)" startWordPosition="704" endWordPosition="707">aja et al., 1991). Langkilde et al. (1998) used lexical resources in statistical sentence generation, summarization, and questionanswering. Barzilay and McKeown (2001) used a corpus-based method to identify paraphrases from a corpus of multiple English translations of the same source text. Our method is similar to this method, but it extracts paraphrases only for a particular emotion, and it needs only a regular corpus, not a parallel corpus of multiple translations. Some research has been done in paraphrase extraction for natural language processing and generation for different applications. Das and Smith (2009) presented a approach to decide whether two sentences hold a paraphrase relationship. They applied a generative model that generates a paraphrase of a given sentence, then used probabilistic inference to reason about whether two sentences share the paraphrase relationship. In another research, Wang et. al (2009) studied the problem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been d</context>
</contexts>
<marker>Das, Smith, 2009</marker>
<rawString>Dipanjan Das and Noah A. Smith. 2009. Paraphrase identification as probabilistic quasi-synchronous recognition. In Proceedings of ACL-IJCNLP 2009, Singapore, pages 468–476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>An argument for basic emotions. Cognition and Emotion,</title>
<date>1992</date>
<pages>6--169</pages>
<contexts>
<context position="2046" citStr="Ekman (1992)" startWordPosition="299" endWordPosition="301">rases for emotions, with the goal of using them to automatically-generate emotional texts (such as friendly or hostile texts) for conversations between intelligent agents and characters in educational games. Paraphrasing is applied to generate text with more variety. To our knowledge, most current applications manually collect paraphrases for 35 specific applications, or they use lexical resources such as WordNet (Miller et al., 1993) to identify paraphrases. This paper introduces a novel method for extracting paraphrases for emotions from texts. We focus on the six basic emotions proposed by Ekman (1992): happiness, sadness, anger, disgust, surprise, and fear. We describe the construction of the paraphrases extractor. We also propose a k-window algorithm for selecting contexts that are used in the paraphrase extraction method. We automatically learn patterns that are able to extract the emotion paraphrases from corpora, starting with a set of seed words. We use data sets such as blogs and other annotated corpora, in which the emotions are marked. We use a large collection of non-parallel corpora which are described in Section 3. These corpora contain many instances of paraphrases different wo</context>
<context position="7994" citStr="Ekman (1992)" startWordPosition="1253" endWordPosition="1254">e six emotions (as well as a non-emotion class, that we ignore here). They worked with blog posts and collected directly from the Web. First, they prepared 1http://www.livejournalinc.com 36 Dataset Happiness Sadness Anger Disgust Surprise Fear LiveJournal 7705 1698 4758 1191 1191 3996 TextAffect 334 214 175 28 131 166 Fairy tales 445 264 216 217 113 165 Annotated blog dataset 536 173 115 115 172 179 Table 2: The number of emotion-annotated sentences in each dataset. Figure 1: High-level view of the paraphrase extraction method. a list of seed words for six basic emotion categories proposed by Ekman (1992). Then, they took words commonly used in the context of a particular emotion. Finally, they used the seed words for each category, and retrieved blog posts containing one or more of those words for the annotation process. 4 Method for Paraphrase Extraction For each of the six emotions, we run our method on the set of sentences marked with the corresponding emotion from the concatenated corpus. We start with a set of seed words form WordNet Affect (Strapparava and Valitutti, 2004), for each emotion of interest. The number of seed words is the following: for happiness 395, for surprise 68, for f</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Paul Ekman. 1992. An argument for basic emotions. Cognition and Emotion, 6:169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>Richard Kittredget</author>
<author>Alain Polguere</author>
</authors>
<date>1991</date>
<booktitle>Natural Language Generation in Artificial Intelligence and Computational Linguistics.</booktitle>
<publisher>Kluwer Academic.</publisher>
<contexts>
<context position="4008" citStr="Iordanskaja et al., 1991" startWordPosition="611" endWordPosition="614">alifornia, June 2010. c�2010 Association for Computational Linguistics his little boy was so happy to see him princess and she were very glad to visit him Table 1: Two sentence fragments (candidate contexts) from the emotion class happy, from the blog corpus. 2 Related Work Three main approaches for collecting paraphrases were proposed in the literature: manual collection, utilization of existing lexical resources, and corpusbased extraction of expressions that occur in similar contexts (Barzilay and McKeown, 2001). Manuallycollected paraphrases were used in natural language generation (NLG) (Iordanskaja et al., 1991). Langkilde et al. (1998) used lexical resources in statistical sentence generation, summarization, and questionanswering. Barzilay and McKeown (2001) used a corpus-based method to identify paraphrases from a corpus of multiple English translations of the same source text. Our method is similar to this method, but it extracts paraphrases only for a particular emotion, and it needs only a regular corpus, not a parallel corpus of multiple translations. Some research has been done in paraphrase extraction for natural language processing and generation for different applications. Das and Smith (20</context>
</contexts>
<marker>Iordanskaja, Kittredget, Polguere, 1991</marker>
<rawString>L. Iordanskaja, Richard Kittredget, and Alain Polguere, 1991. Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carroll E Izard</author>
</authors>
<title>The Face of Emotion. AppletonCentury-Crofts.,</title>
<date>1971</date>
<location>New York.</location>
<contexts>
<context position="7139" citStr="Izard (1971)" startWordPosition="1113" endWordPosition="1114">lcea, 2007) consists of newspaper headlines that were used in the SemEval 2007-Task 14. It includes a development dataset of 250 annotated headlines, and a test dataset of 1000 news headlines. We use all of them. The annotations were made with the six basic emotions on intensity scales of [-100, 100], therefore a threshold is used to choose the main emotion of each sentence. 3.3 Fairy Tales Dataset This dataset consists in 1580 annotated sentences (Alm et al., 2005), from tales by the Grimm brothers, H.C. Andersen, and B. Potter. The annotations used the extended set of nine basic emotions of Izard (1971). We selected only those marked with the six emotions that we focus on. 3.4 Annotated Blog Dataset We also used the dataset provided by Aman and Szpakowicz (2007). Emotion-rich sentences were selected from personal blogs, and annotated with the six emotions (as well as a non-emotion class, that we ignore here). They worked with blog posts and collected directly from the Web. First, they prepared 1http://www.livejournalinc.com 36 Dataset Happiness Sadness Anger Disgust Surprise Fear LiveJournal 7705 1698 4758 1191 1191 3996 TextAffect 334 214 175 28 131 166 Fairy tales 445 264 216 217 113 165 A</context>
</contexts>
<marker>Izard, 1971</marker>
<rawString>Carroll E. Izard. 1971. The Face of Emotion. AppletonCentury-Crofts., New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In COLING-ACL.</booktitle>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Dan Melamed</author>
</authors>
<title>Empirical Methods for Exploiting Parallel Texts.</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="19506" citStr="Melamed, 2001" startWordPosition="3092" endWordPosition="3093"> each class of emotion we selected 100 paraphrase pairs. We evaluated their correctness with two human judges. They judged whether the two expressions are good paraphrases or not. We provided a page of guidelines for the judges. We defined paraphrase as ”approximate conceptual equivalence”, the same definition used in (Barzilay and McKeown, 2001). Each human judge had to choose a ”Yes” or ”No” answer for each pair of paraphrases under test. We did not include example sentences containing these paraphrases. A similar Machine Translation evaluation task for word-to-word translation was done in (Melamed, 2001). Figure 3 presents the results of the evaluation: the correctness for each class of emotion according to judge A, and according to judge B. The judges were graduate students in computational linguistics, native speakers of English. We also measured the agreement between the two judges and the Kappa coefficient (Siegel and Castellan, 1988). If there is complete agreement between two judges Kappa is 1, and if there is no agreement between the judges then Kappa = 0. The Kappa values and the agreement values for our judges are presented in Figure 4. The inter-judge agreement over all the paraphra</context>
</contexts>
<marker>Melamed, 2001</marker>
<rawString>Ilya Dan Melamed. 2001. Empirical Methods for Exploiting Parallel Texts. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Co-training and self-training for word sense disambiguation.</title>
<date>2004</date>
<journal>In Natural Language Learning (CoNLL</journal>
<location>Boston,</location>
<contexts>
<context position="12931" citStr="Mihalcea, 2004" startWordPosition="1993" endWordPosition="1994"> each candidate context, to allow us to determine similar contexts. Candidate context: He was further annoyed by the jay bird ’PRP VBD RB VBN IN DT NN NN’,65,8,’VBD RB’,?,was, ?,?,?,He/PRP,was/VBD,further/RB,annoyed,by/IN,the/DT, jay/NN,bird/NN,?,?,jay,?,’IN DT NN’,2,2,0,1 Table 4: An example of extracted features. 4.3 Feature Extraction Previous research on word sense disambiguation on contextual analysis has acknowledged several local and topical features as good indicators of word properties. These include surrounding words and their part of speech tags, collocations, keywords in contexts (Mihalcea, 2004). Also recently, other features have been proposed: bigrams, named entities, syntactic features, and semantic relations with other words in the context. We transfer the candidate phrases extracted by the sliding k-window into the vector space of features. We consider features that include both lexical and syntactic descriptions of the paraphrases for all pairs of two candidates. The lexical features include the sequence of tokens for each phrase in the paraphrase pair; the syntactic feature consists of a sequence of part-of-speech (PoS) tags where equal words and words with the same root and P</context>
</contexts>
<marker>Mihalcea, 2004</marker>
<rawString>Rada Mihalcea. 2004. Co-training and self-training for word sense disambiguation. In Natural Language Learning (CoNLL 2004), Boston, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>Introduction to Wordnet: An On-Line Lexical Database.</title>
<date>1993</date>
<institution>Cognitive Science Laboratory, Princeton University,</institution>
<contexts>
<context position="1872" citStr="Miller et al., 1993" startWordPosition="269" endWordPosition="272">d repetitive information from the input documents. In Natural Language Generation, paraphrasing is employed to create more varied and natural text. In our research, we extract paraphrases for emotions, with the goal of using them to automatically-generate emotional texts (such as friendly or hostile texts) for conversations between intelligent agents and characters in educational games. Paraphrasing is applied to generate text with more variety. To our knowledge, most current applications manually collect paraphrases for 35 specific applications, or they use lexical resources such as WordNet (Miller et al., 1993) to identify paraphrases. This paper introduces a novel method for extracting paraphrases for emotions from texts. We focus on the six basic emotions proposed by Ekman (1992): happiness, sadness, anger, disgust, surprise, and fear. We describe the construction of the paraphrases extractor. We also propose a k-window algorithm for selecting contexts that are used in the paraphrase extraction method. We automatically learn patterns that are able to extract the emotion paraphrases from corpora, starting with a set of seed words. We use data sets such as blogs and other annotated corpora, in which</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1993</marker>
<rawString>George Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller, 1993. Introduction to Wordnet: An On-Line Lexical Database. Cognitive Science Laboratory, Princeton University, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilad Mishne</author>
</authors>
<title>Experiments with mood classification in blog posts.</title>
<date>2005</date>
<publisher>ACM SIGIR.</publisher>
<contexts>
<context position="6035" citStr="Mishne, 2005" startWordPosition="924" endWordPosition="925">ky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is presented in Table 2. We briefly describe the datasets, as follows. 3.1 LiveJournal blog dataset We used the blog corpus that Mishne collected for his research (Mishne, 2005). The corpus contains 815,494 blog posts from Livejournal 1, a free weblog service used by millions of people to create weblogs. In Livejournal, users are able to optionally specify their current emotion or mood. To select their emotion/mood users can choose from a list of 132 provided moods. So, the data is annotated by the user who created the blog. We selected only the texts corresponding to the six emotions that we mentioned. 3.2 Text Affect Dataset This dataset (Strapparava and Mihalcea, 2007) consists of newspaper headlines that were used in the SemEval 2007-Task 14. It includes a develo</context>
</contexts>
<marker>Mishne, 2005</marker>
<rawString>Gilad Mishne. 2005. Experiments with mood classification in blog posts. ACM SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence,</booktitle>
<pages>10441049</pages>
<publisher>The AAAI Press/MIT Press.</publisher>
<contexts>
<context position="5505" citStr="Riloff and Jones, 1999" startWordPosition="837" endWordPosition="840">p. In another research, Wang et. al (2009) studied the problem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been done in paraphrase generation in NLG (Zhao et al., 2009), (Chevelu et al., 2009). Bootstrapping methods have been applied to various natural language applications, for example to word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is presented in Table 2. We briefly describe the datasets, as follows. 3.1 LiveJournal blog dataset We used the blog corpus that Mishne collected for his research (Mishne, 2005). The corpus contains 815,494 blog posts from Livejournal 1, a free we</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence, page 10441049. The AAAI Press/MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Siegel</author>
<author>John Castellan</author>
</authors>
<title>Non Parametric Statistics for Behavioral Sciences..</title>
<date>1988</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context position="19847" citStr="Siegel and Castellan, 1988" startWordPosition="3144" endWordPosition="3148">y and McKeown, 2001). Each human judge had to choose a ”Yes” or ”No” answer for each pair of paraphrases under test. We did not include example sentences containing these paraphrases. A similar Machine Translation evaluation task for word-to-word translation was done in (Melamed, 2001). Figure 3 presents the results of the evaluation: the correctness for each class of emotion according to judge A, and according to judge B. The judges were graduate students in computational linguistics, native speakers of English. We also measured the agreement between the two judges and the Kappa coefficient (Siegel and Castellan, 1988). If there is complete agreement between two judges Kappa is 1, and if there is no agreement between the judges then Kappa = 0. The Kappa values and the agreement values for our judges are presented in Figure 4. The inter-judge agreement over all the paraphrases for the six classes of emotions is 81.72%, which is 490 out of the 600 paraphrases pairs in our sample. Note that they agreed that some pairs are good paraphrases, or they agreed that some pairs are not good paraphrases, that is why the numbers in Figure 4 are higher than the correctness numbers from Figure 3. The Kappa coefficient com</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>Sidney Siegel and John Castellan, 1988. Non Parametric Statistics for Behavioral Sciences.. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval2007 task 14: Affective text.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on the Semantic Evaluations (SemEval</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="6538" citStr="Strapparava and Mihalcea, 2007" startWordPosition="1008" endWordPosition="1011">datasets, as follows. 3.1 LiveJournal blog dataset We used the blog corpus that Mishne collected for his research (Mishne, 2005). The corpus contains 815,494 blog posts from Livejournal 1, a free weblog service used by millions of people to create weblogs. In Livejournal, users are able to optionally specify their current emotion or mood. To select their emotion/mood users can choose from a list of 132 provided moods. So, the data is annotated by the user who created the blog. We selected only the texts corresponding to the six emotions that we mentioned. 3.2 Text Affect Dataset This dataset (Strapparava and Mihalcea, 2007) consists of newspaper headlines that were used in the SemEval 2007-Task 14. It includes a development dataset of 250 annotated headlines, and a test dataset of 1000 news headlines. We use all of them. The annotations were made with the six basic emotions on intensity scales of [-100, 100], therefore a threshold is used to choose the main emotion of each sentence. 3.3 Fairy Tales Dataset This dataset consists in 1580 annotated sentences (Alm et al., 2005), from tales by the Grimm brothers, H.C. Andersen, and B. Potter. The annotations used the extended set of nine basic emotions of Izard (1971</context>
</contexts>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>Carlo Strapparava and Rada Mihalcea. 2007. Semeval2007 task 14: Affective text. In Proceedings of the 4th International Workshop on the Semantic Evaluations (SemEval 2007), Prague, Czech Republic, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of wordnet.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<pages>1083--1086</pages>
<location>Lisbon,</location>
<contexts>
<context position="8478" citStr="Strapparava and Valitutti, 2004" startWordPosition="1335" endWordPosition="1338">taset. Figure 1: High-level view of the paraphrase extraction method. a list of seed words for six basic emotion categories proposed by Ekman (1992). Then, they took words commonly used in the context of a particular emotion. Finally, they used the seed words for each category, and retrieved blog posts containing one or more of those words for the annotation process. 4 Method for Paraphrase Extraction For each of the six emotions, we run our method on the set of sentences marked with the corresponding emotion from the concatenated corpus. We start with a set of seed words form WordNet Affect (Strapparava and Valitutti, 2004), for each emotion of interest. The number of seed words is the following: for happiness 395, for surprise 68, for fear 140, for disgust 50, for anger 250, and for sadness 200. Table 3 shows some of seeds for each category of emotion. Since sentences are different in our datasets and they are not aligned as parallel sentences as in (Barzilay and McKeown, 2001), our algorithm constructs pairs of similar sentences, based on the local context. On the other hand, we assume that, if the contexts surrounding two seeds look similar, then these contexts are likely to help in extracting new paraphrases</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, May 2004, pages 1083–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="10036" citStr="Toutanova et al., 2003" startWordPosition="1588" endWordPosition="1591">tion 4.5 we explain how the bootstrapping algorithm processes and selects the paraphrases based on strong surrounding contexts. As it is shown in Figure 1, our method has several stages: extracting candidate contexts, using them to extract patterns, selecting the best patterns, extracting potential paraphrases, and filtering them to obtain the final paraphrases. 4.1 Preprocessing During preprocessing, HTML and XML tags are eliminated from the blogs data and other datasets, then the text is tokenized and annotated with part of speech tags. We use the Stanford part-of-speech tagger and chunker (Toutanova et al., 2003) to identify noun and verb phrases in the sentences. In the next step, we use a sliding window based on the k-window approach, to identify candidate contexts that contain the target seeds. 4.2 The k-window Algorithm We use the k-window algorithm introduced by Bostad (2003) in order to identify all the tokens surrounding a specific term in a window with size of fk. Here, we use this approach to extract candidate patterns for each seed, from the sentences. We start with one seed and truncate all contexts around the seed within a window of fk words before and fk words after the seed, until all th</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of HLT-NAACL, pages 252–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyin Wang</author>
<author>David Lo</author>
<author>Jing Jiang</author>
<author>Lu Zhang</author>
<author>Hong Mei</author>
</authors>
<title>Extracting paraphrases of technical terms from noisy parallel software corpora.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009, Singapore,</booktitle>
<pages>197--200</pages>
<marker>Wang, Lo, Jiang, Zhang, Mei, 2009</marker>
<rawString>Xiaoyin Wang, David Lo, Jing Jiang, Lu Zhang, and Hong Mei. 2009. Extracting paraphrases of technical terms from noisy parallel software corpora. In Proceedings of ACL-IJCNLP 2009, Singapore, pages 197–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="5431" citStr="Yarowsky, 1995" startWordPosition="830" endWordPosition="831">eason about whether two sentences share the paraphrase relationship. In another research, Wang et. al (2009) studied the problem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been done in paraphrase generation in NLG (Zhao et al., 2009), (Chevelu et al., 2009). Bootstrapping methods have been applied to various natural language applications, for example to word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is presented in Table 2. We briefly describe the datasets, as follows. 3.1 LiveJournal blog dataset We used the blog corpus that Mishne collected for his research (Mishne, 2</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 189–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
</authors>
<title>Application-driven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009, Singapore,</booktitle>
<pages>834--842</pages>
<contexts>
<context position="5266" citStr="Zhao et al., 2009" startWordPosition="804" endWordPosition="807">er two sentences hold a paraphrase relationship. They applied a generative model that generates a paraphrase of a given sentence, then used probabilistic inference to reason about whether two sentences share the paraphrase relationship. In another research, Wang et. al (2009) studied the problem of extracting technical paraphrases from a parallel software corpus. Their aim was to report duplicate bugs. In their method for paraphrase extraction, they used: sentence selection, global context-based and cooccurrence-based scoring. Also, some studies have been done in paraphrase generation in NLG (Zhao et al., 2009), (Chevelu et al., 2009). Bootstrapping methods have been applied to various natural language applications, for example to word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our research, we use the bootstrapping approach to learn paraphrases for emotions. 3 Data The text data from which we will extract paraphrases is composed of four concatenated datasets. They contain sentences annotated with the six basic emotions. The number of sentences in each dataset is prese</context>
</contexts>
<marker>Zhao, Lan, Liu, 2009</marker>
<rawString>Shiqi Zhao, Xiang Lan, Ting Liu, , and Sheng Li. 2009. Application-driven statistical paraphrase generation. In Proceedings of ACL-IJCNLP 2009, Singapore, pages 834–842.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>