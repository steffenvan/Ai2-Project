<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.056927">
<title confidence="0.9995555">
Data-Driven Dependency Parsing across Languages and Domains:
Perspectives from the CoNLL 2007 Shared Task
</title>
<author confidence="0.993464">
Joakim Nivre
</author>
<affiliation confidence="0.997588">
V¨axj¨o University, School of Mathematics and Systems Engineering
Uppsala University, Department of Linguistics and Philology
</affiliation>
<email confidence="0.999785">
E-mail: nivre@msi.vxu.se
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999754818181818">
The Conference on Computational Natural
Language Learning features a shared task, in
which participants train and test their learn-
ing systems on the same data sets. In 2007,
as in 2006, the shared task has been devoted
to dependency parsing, this year with both a
multilingual track and a domain adaptation
track. In this paper, I summarize the main
findings from the 2007 shared task and try
to identify major challenges for the parsing
community based on these findings.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999938166666667">
The annual Conference on Computational Natural
Language Learning (CoNLL) has for the past nine
years organized a shared task, where participants
train and test their learning systems on the same
data sets. In 2006, the shared task was multilin-
gual dependency parsing, where participants had to
train and test a parser on data from thirteen differ-
ent languages (Buchholz and Marsi, 2006). In 2007,
the task was extended by adding a second track for
(monolingual) domain adaptation.
The CoNLL 2007 shared task on dependency
parsing featured two tracks:
</bodyText>
<listItem confidence="0.997187833333333">
• In the multilingual track, the task was to train a
parser using labeled data from Arabic, Basque,
Catalan, Chinese, Czech, English, Greek, Hun-
garian, Italian, and Turkish.
• In the domain adaptation track, the task was
to adapt a parser for English news text to other
</listItem>
<bodyText confidence="0.923146181818182">
domains using unlabeled data from the target
domains: biomedical and chemical abstracts,
parent-child dialogues.&apos; In the closed class, the
base parser had to be trained using the English
training set for the multilingual track and no
external resources were allowed. In the open
class, any base parser could be used and any
external resources were allowed.
Both tracks used the same column-based format for
labeled data with six input columns and two output
columns for each word of a sentence:
</bodyText>
<listItem confidence="0.99944125">
• Input: word-id, word form, lemma, coarse part
of speech, fine part-of-speech, morphosyntactic
features.
• Output: head (word-id), dependency label.
</listItem>
<bodyText confidence="0.998425555555555">
The main evaluation metric for both tracks was the
labeled attachment score (LAS), i.e., the percentage
of words that have been assigned the correct head
and dependency label. For more information about
the setup, see Nivre et al. (2007)
In this paper, I will summarize the main findings
from the CoNLL 2007 shared task, starting with
a characterization of the different approaches used
(section 2), and moving on to the most interesting
results in the multilingual track (section 3) and the
domain adaptation track (section 4). Finally, based
on these findings, I will try to identify some im-
portant challenges for the wider parsing community
(section 5).
&apos;The biomedical domain was the development domain,
which means that a small labeled development set was available
for this domain. The final testing was only done on chemical
abstracts and (optionally) parent-child dialogues.
</bodyText>
<page confidence="0.940824">
168
</page>
<note confidence="0.4379745">
Proceedings of the 10th Conference on Parsing Technologies, pages 168–170,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.977778" genericHeader="introduction">
2 Approaches
</sectionHeader>
<bodyText confidence="0.999882">
In total, test runs were submitted for twenty-three
systems in the multilingual track, and ten systems in
the domain adaptation track (six of which also par-
ticipated in the multilingual track). The majority of
these systems used models belonging to one of the
two dominant approaches in data-driven dependency
parsing in recent years (McDonald and Nivre, 2007):
</bodyText>
<listItem confidence="0.999548428571429">
• In graph-based models, every possible depen-
dency graph for a given input sentence is given
a score that decomposes into scores for the arcs
of the graph. The optimal parse can be found
using a spanning tree algorithm (Eisner, 1996;
McDonald et al., 2005).
• In transition-based models, dependency graphs
</listItem>
<bodyText confidence="0.9307436">
are modeled by sequences of parsing actions
(or transitions) for building them. The search
for an optimal parse is often deterministic and
guided by classifiers (Yamada and Matsumoto,
2003; Nivre, 2003).
The majority of graph-based parsers in the shared
task were based on what McDonald and Pereira
(2006) call the first-order model, where the score
of each arc is independent of every other arc, but
there were also attempts at exploring higher-order
models, either with exact inference limited to pro-
jective dependency graphs (Carreras, 2007), or with
approximate inference (Nakagawa, 2007). Another
innovation was the use of k-best spanning tree algo-
rithms for inference with a non-projective first-order
model (Hall et al., 2007b).
For transition-based parsers, the trend was clearly
to move away from deterministic parsing by adding
a probability model for scoring a set of candidate
parses typically derived using a heuristic search
strategy. The probability model may be either con-
ditional (Duan et al., 2007) or generative (Titov and
Henderson, 2007).
An interesting way of combining the two main
approaches is to use a graph-based model to build
an ensemble of transition-based parsers. This tech-
nique, first proposed by Sagae and Lavie (2006), was
used in the highest scoring system in both the mul-
tilingual track (Hall et al., 2007a) and the domain
adaptation track (Sagae and Tsujii, 2007).
</bodyText>
<sectionHeader confidence="0.992714" genericHeader="method">
3 Multilingual Parsing
</sectionHeader>
<bodyText confidence="0.999582">
The ten languages involved in the multilingual track
can be grouped into three classes with respect to the
best parsing accuracy achieved:
</bodyText>
<listItem confidence="0.930655833333333">
• Low (LAS = 76.3–76.9):
Arabic, Basque, Greek
• Medium (LAS = 79.2–80.2):
Czech, Hungarian, Turkish
• High (LAS = 84.4–89.6):
Catalan, Chinese, English, Italian
</listItem>
<bodyText confidence="0.999902631578947">
To a large extent, these classes appear to be definable
from typological properties. The class with the high-
est top scores contains languages with a rather im-
poverished morphology. Medium scores are reached
by the two agglutinative languages, Hungarian and
Turkish, as well as by Czech. The most difficult lan-
guages are those that combine a relatively free word
order with a high degree of inflection. Based on
these characteristics, one would expect to find Czech
in the last class. However, the Czech training set
is four times the size of the training set for Arabic,
which is the language with the largest training set
of the difficult languages. On the whole, however,
training set size alone is a poor predictor of parsing
accuracy, which can be seen from the fact that the
Italian training set is only about half the size of the
Arabic one and only one sixth of Czech one. Thus,
there seems to be a need for parsing methods that
can cope better with richly inflected languages.
</bodyText>
<sectionHeader confidence="0.994724" genericHeader="method">
4 Domain Adaptation
</sectionHeader>
<bodyText confidence="0.999908285714286">
One result from the domain adaptation track that
may seem surprising at first was the fact that the
best closed class systems outperformed the best
open class systems on the official test set containing
chemical abstracts. To some extent, this may be ex-
plained by the greater number of participants in the
closed class (eight vs. four). However, it also seems
that the major problem in adapting existing, often
grammar-based, parsers to the new domain was not
the domain as such but the mapping from the native
output of the parser to the kind of annotation pro-
vided in the shared task data sets. In this respect,
the closed class systems had an advantage by having
been trained on exactly this kind of annotation. This
</bodyText>
<page confidence="0.997454">
169
</page>
<bodyText confidence="0.999921357142857">
result serves to highlight the fact that domain adapta-
tion, as well as the integration of grammar-based and
data-driven methods, often involves transformations
between different kinds of linguistic representations.
The best performing (closed class) system in the
domain adaptation track used a combination of co-
learning and active learning by training two different
parsers on the labeled training data, parsing the un-
labeled domain data with both parsers, and adding
parsed sentences to the training data only if the two
parsers agreed on their analysis (Sagae and Tsujii,
2007). This resulted in a LAS of 81.1 on the test set
of chemical abstracts, to be compared with 89.0 for
the English test set in the multilingual track.
</bodyText>
<sectionHeader confidence="0.996541" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999944166666667">
Based on the results from the CoNLL 2007 shared
task, it is clear that we need to improve our methods
for parsing richly inflected languages. We also need
to find better ways of integrating parsers developed
within different frameworks, so that they can be
reused effectively for, among other things, domain
adaptation. More generally, we need to increase our
knowledge of the multi-causal relationship between
language characteristics, syntactic representations,
and parsing and learning methods. In order to do
this, perhaps we also need a shared task at the Inter-
national Conference on Parsing Technologies.
</bodyText>
<sectionHeader confidence="0.997643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999221285714286">
I want to thank my fellow organizers of the shared
task, Johan Hall, Sandra K¨ubler, Ryan McDonald,
Jens Nilsson, Sebastian Riedel, and Deniz Yuret,
who are also co-authors of the longer paper on which
this paper is partly based (Nivre et al., 2007). I am
also indebted to all the people who have contributed
to the shared task by providing data or participating.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99983162264151">
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL, 149–164.
X. Carreras. 2007. Experiments with a high-order pro-
jective dependency parser. In Proc. of EMNLP-CoNLL
(Shared Task).
X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic parsing
action models for multi-lingual dependency parsing.
In Proc. of EMNLP-CoNLL (Shared Task).
J. M. Eisner. 1996. Three new probabilistic models for
dependency parsing: An exploration. In Proc. of COL-
ING, 340–345.
J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi,
M. Nilsson, and M. Saers. 2007a. Single malt or
blended? A study in multilingual parser optimization.
In Proc. of EMNLP-CoNLL (Shared Task).
K. Hall, J. Havelka, and D. Smith. 2007b. Log-linear
models of non-projective trees, k-best MST parsing
and tree-ranking. In Proc. of EMNLP-CoNLL (Shared
Task).
R. McDonald and J. Nivre. 2007. Characterizing the
errors of data-driven dependency parsing models. In
Proc. of EMNLP-CoNLL.
R. McDonald and F. Pereira. 2006. Online learning of
approximate dependency parsing algorithms. In Proc.
of EACL, 81–88.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005.
Non-projective dependency parsing using spanning
tree algorithms. In Proc. of HLT/EMNLP, 523–530.
T. Nakagawa. 2007. Multilingual dependency parsing
using gibbs sampling. In Proc. of EMNLP-CoNLL
(Shared Task).
J. Nivre and J. Nilsson. 2005. Pseudo-projective depen-
dency parsing. In Proc. of ACL, 99–106.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc. of
EMNLP-CoNLL (Shared Task).
J. Nivre. 2003. An efficient algorithm for projective de-
pendency parsing. In Proc. of IWPT, 149–160.
K. Sagae and A. Lavie. 2006. Parser combination by
reparsing. In Proc. of HLT-NAACL (Short Papers),
129–132.
K. Sagae and J. Tsujii. 2007. Dependency parsing and
domain adaptation with LR models and parser ensem-
bles. In Proc. of EMNLP-CoNLL (Shared Task).
I. Titov and J. Henderson. 2007. Fast and robust mul-
tilingual dependency parsing with a generative latent
variable model. In Proc. of EMNLP-CoNLL (Shared
Task).
H. Yamada and Y. Matsumoto. 2003. Statistical depen-
dency analysis with support vector machines. In Proc.
of IWPT, 195–206.
</reference>
<page confidence="0.997426">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.554851">
<title confidence="0.87048">Data-Driven Dependency Parsing across Languages and Perspectives from the CoNLL 2007 Shared Task</title>
<author confidence="0.647003">Joakim</author>
<affiliation confidence="0.972018">V¨axj¨o University, School of Mathematics and Systems Uppsala University, Department of Linguistics and</affiliation>
<email confidence="0.969842">E-mail:nivre@msi.vxu.se</email>
<abstract confidence="0.999105416666667">The Conference on Computational Natural Language Learning features a shared task, in which participants train and test their learning systems on the same data sets. In 2007, as in 2006, the shared task has been devoted to dependency parsing, this year with both a multilingual track and a domain adaptation track. In this paper, I summarize the main findings from the 2007 shared task and try to identify major challenges for the parsing community based on these findings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="1153" citStr="Buchholz and Marsi, 2006" startWordPosition="173" endWordPosition="176">ar with both a multilingual track and a domain adaptation track. In this paper, I summarize the main findings from the 2007 shared task and try to identify major challenges for the parsing community based on these findings. 1 Introduction The annual Conference on Computational Natural Language Learning (CoNLL) has for the past nine years organized a shared task, where participants train and test their learning systems on the same data sets. In 2006, the shared task was multilingual dependency parsing, where participants had to train and test a parser on data from thirteen different languages (Buchholz and Marsi, 2006). In 2007, the task was extended by adding a second track for (monolingual) domain adaptation. The CoNLL 2007 shared task on dependency parsing featured two tracks: • In the multilingual track, the task was to train a parser using labeled data from Arabic, Basque, Catalan, Chinese, Czech, English, Greek, Hungarian, Italian, and Turkish. • In the domain adaptation track, the task was to adapt a parser for English news text to other domains using unlabeled data from the target domains: biomedical and chemical abstracts, parent-child dialogues.&apos; In the closed class, the base parser had to be trai</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL, 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
</authors>
<title>Experiments with a high-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="4504" citStr="Carreras, 2007" startWordPosition="704" endWordPosition="705">cDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based mode</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>X. Carreras. 2007. Experiments with a high-order projective dependency parser. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Duan</author>
<author>J Zhao</author>
<author>B Xu</author>
</authors>
<title>Probabilistic parsing action models for multi-lingual dependency parsing.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="4976" citStr="Duan et al., 2007" startWordPosition="774" endWordPosition="777">ut there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 3 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Me</context>
</contexts>
<marker>Duan, Zhao, Xu, 2007</marker>
<rawString>X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic parsing action models for multi-lingual dependency parsing. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>340--345</pages>
<contexts>
<context position="3886" citStr="Eisner, 1996" startWordPosition="609" endWordPosition="610">tics 2 Approaches In total, test runs were submitted for twenty-three systems in the multilingual track, and ten systems in the domain adaptation track (six of which also participated in the multilingual track). The majority of these systems used models belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graph</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. M. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of COLING, 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nilsson</author>
<author>J Nivre</author>
<author>G Eryigit</author>
<author>B Megyesi</author>
<author>M Nilsson</author>
<author>M Saers</author>
</authors>
<title>Single malt or blended? A study in multilingual parser optimization.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="4692" citStr="Hall et al., 2007" startWordPosition="730" endWordPosition="733">often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et</context>
</contexts>
<marker>Hall, Nilsson, Nivre, Eryigit, Megyesi, Nilsson, Saers, 2007</marker>
<rawString>J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M. Nilsson, and M. Saers. 2007a. Single malt or blended? A study in multilingual parser optimization. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hall</author>
<author>J Havelka</author>
<author>D Smith</author>
</authors>
<title>Log-linear models of non-projective trees, k-best MST parsing and tree-ranking.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="4692" citStr="Hall et al., 2007" startWordPosition="730" endWordPosition="733">often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et</context>
</contexts>
<marker>Hall, Havelka, Smith, 2007</marker>
<rawString>K. Hall, J. Havelka, and D. Smith. 2007b. Log-linear models of non-projective trees, k-best MST parsing and tree-ranking. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="3652" citStr="McDonald and Nivre, 2007" startWordPosition="566" endWordPosition="569">nal testing was only done on chemical abstracts and (optionally) parent-child dialogues. 168 Proceedings of the 10th Conference on Parsing Technologies, pages 168–170, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics 2 Approaches In total, test runs were submitted for twenty-three systems in the multilingual track, and ten systems in the domain adaptation track (six of which also participated in the multilingual track). The majority of these systems used models belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and P</context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>R. McDonald and J. Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="4265" citStr="McDonald and Pereira (2006)" startWordPosition="665" endWordPosition="668">d Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL, 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP,</booktitle>
<pages>523--530</pages>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. of HLT/EMNLP, 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nakagawa</author>
</authors>
<title>Multilingual dependency parsing using gibbs sampling.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="4552" citStr="Nakagawa, 2007" startWordPosition="710" endWordPosition="711">els, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parse</context>
</contexts>
<marker>Nakagawa, 2007</marker>
<rawString>T. Nakagawa. 2007. Multilingual dependency parsing using gibbs sampling. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>99--106</pages>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>J. Nivre and J. Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. of ACL, 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proc. of IWPT,</booktitle>
<pages>149--160</pages>
<contexts>
<context position="4162" citStr="Nivre, 2003" startWordPosition="650" endWordPosition="651">e two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away f</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>J. Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proc. of IWPT, 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>A Lavie</author>
</authors>
<title>Parser combination by reparsing.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL (Short Papers),</booktitle>
<pages>129--132</pages>
<contexts>
<context position="5212" citStr="Sagae and Lavie (2006)" startWordPosition="812" endWordPosition="815">best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 3 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian, Turkish • High (LAS = 84.4–89.6): Catalan, Chinese, English, Italian To a large extent, these classes appear to be definable from typological properties. The class with the highest top scores co</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>K. Sagae and A. Lavie. 2006. Parser combination by reparsing. In Proc. of HLT-NAACL (Short Papers), 129–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>J Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="5361" citStr="Sagae and Tsujii, 2007" startWordPosition="838" endWordPosition="841">s clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 3 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian, Turkish • High (LAS = 84.4–89.6): Catalan, Chinese, English, Italian To a large extent, these classes appear to be definable from typological properties. The class with the highest top scores contains languages with a rather impoverished morphology. Medium scores are reached by the two agglutinative languages, Hungarian and Turkish, as well </context>
<context position="7996" citStr="Sagae and Tsujii, 2007" startWordPosition="1277" endWordPosition="1280"> exactly this kind of annotation. This 169 result serves to highlight the fact that domain adaptation, as well as the integration of grammar-based and data-driven methods, often involves transformations between different kinds of linguistic representations. The best performing (closed class) system in the domain adaptation track used a combination of colearning and active learning by training two different parsers on the labeled training data, parsing the unlabeled domain data with both parsers, and adding parsed sentences to the training data only if the two parsers agreed on their analysis (Sagae and Tsujii, 2007). This resulted in a LAS of 81.1 on the test set of chemical abstracts, to be compared with 89.0 for the English test set in the multilingual track. 5 Conclusion Based on the results from the CoNLL 2007 shared task, it is clear that we need to improve our methods for parsing richly inflected languages. We also need to find better ways of integrating parsers developed within different frameworks, so that they can be reused effectively for, among other things, domain adaptation. More generally, we need to increase our knowledge of the multi-causal relationship between language characteristics, s</context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>K. Sagae and J. Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>Fast and robust multilingual dependency parsing with a generative latent variable model.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL (Shared Task).</booktitle>
<contexts>
<context position="5018" citStr="Titov and Henderson, 2007" startWordPosition="780" endWordPosition="783">loring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 3 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian, </context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>I. Titov and J. Henderson. 2007. Fast and robust multilingual dependency parsing with a generative latent variable model. In Proc. of EMNLP-CoNLL (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. of IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="4148" citStr="Yamada and Matsumoto, 2003" startWordPosition="646" endWordPosition="649">odels belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly </context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proc. of IWPT, 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>