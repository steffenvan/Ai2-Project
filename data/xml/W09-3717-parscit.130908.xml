<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000033">
<title confidence="0.989708">
Using English for commonsense knowledge
</title>
<author confidence="0.997111">
Allan Ramsay Debora Field
</author>
<affiliation confidence="0.9735305">
School of Computer Science Dept of Computer Science
Univ of Manchester Univ of Sheffield
</affiliation>
<address confidence="0.921434">
Manchester M60 1QD, UK Sheffield S1 4DP, UK
</address>
<sectionHeader confidence="0.685841" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999686">
The work reported here arises from an attempt to provide a body
of simple information about diet and its effect on various common
medical conditions. Expressing this knowledge in natural language
has a number of advantages. It also raises a number of difficult issues.
We will consider solutions, and partial solutions, to these issues below.
</bodyText>
<sectionHeader confidence="0.914961" genericHeader="method">
1 Commonse knowledge
</sectionHeader>
<bodyText confidence="0.99133925">
Suppose you wanted to have a system that could provide advice about what
you should and should not eat if you suffer from various common medical
conditions. You might expect, at the very least, to be able to have dialogues
like (1).
</bodyText>
<table confidence="0.886016066666667">
(1) a. User: I am allergic to eggs.
Computer: OK
User: Should I eat pancakes
Computer: No, because pancakes contain eggs, and eating things which
contain eggs will make you ill if you are allergic to eggs.
b. User: My son is very fat.
Computer: OK
User: Should he go swimming.
Computer: Yes, because swimming is a form of exercise, and exercise is
good for people who are overweight.
c. User: I have scurvy.
Computer: OK
User: Is eating berries good for me?
Computer: Yes, because berries contain vitamin C and eating fruit which
contains vitamin C is good for people who scurvy.
</table>
<page confidence="0.983598">
181
</page>
<bodyText confidence="0.884404625">
Proceedings of the 8th International Conference on Computational Semantics, pages 181–194,
Tilburg, January 2009. c�2009 International Conference on Computational Semantics
These are comparatively simple dialogues, requiring a very limited
amount of knowledge about foods and medical conditions. As we will see,
however, dealing with them does require a remarkable amount of knowledge
about language.
The framework we are using makes a number of very basic assumptions
about how you design a system to deal with such dialogues.
</bodyText>
<listItem confidence="0.9837162">
• To give appropriate answers to these questions you have to consider
whether the available information supports or contradicts the queried
proposition.
• In order to see whether the available information supports or contra-
dicts a proposition you need a body of domain knowledge, and you
need to be able to reason with it.
• Natural languages provide numerous ways of saying almost identical
things. There is, for instance, almost no difference between ‘I am
allergic to eggs’ and ‘I have an allergy to eggs’. You therefore have to
have a way of dealing with paraphrases.
</listItem>
<bodyText confidence="0.987916">
We will explore each of these issues in turn below.
</bodyText>
<sectionHeader confidence="0.967581" genericHeader="method">
2 Answering questions
</sectionHeader>
<bodyText confidence="0.999908411764706">
We will concentrate here on polar (YES/NO) questions. We also take the
very simple view that when someone asks a polar question it is because they
want to know whether the proposition encoded in the question is true or
not. Someone who asks ‘Is it safe for me to eggs?’ wants to be told ‘Yes’
if it is and ‘No’ if it is not. We have explored the nature of WH-questions
elsewhere (Ramsay &amp; Seville, 2001), and we have discussed situations where
people use language in indirect ways (Ramsay &amp; Field, 2008), but for the
moment just trying to answer polar questions will pose enough problems to
keep us occupied.
In order to answer such a question by saying ‘Yes’ you have to see
whether ‘It is safe for the speaker to eat eggs’ follows from what you know
about the speaker and your general knowledge. You cannot, however, say
‘No’ simply because your attempted proof that it is safe failed. If you failed
to prove that it is safe you should then see whether you can prove that it is
not. If, and only if, you can then you should say ‘no’.
In general, then, answering a polar question may involve two attempted
proofs–one aimed at showing that the proposition under discussion is true
</bodyText>
<page confidence="0.997242">
182
</page>
<bodyText confidence="0.999968325">
and then possibly a second aimed at showing that it is false. If you are
lucky you might discover evidence that the proposition is false while you are
trying to show that it is true, but in general you may have to attempt two
proofs.
In order to carry out proofs you need an inference engine. Inference
engines come in all sorts of shapes and sizes–fast or slow, sound or unsound,
complete or incomplete–and they can be applied to a variety of knowledge
representation schemes. The choice of representation scheme, and of the
inference engine that you apply to it, will depend on what you want to do
with it. For our current task we assume that soundness is crucial, since
you really would not want a medical advice system to give wrong advice;
and that the representation scheme has to be highly expressive, since the
relations involved are subtle and need to be represented very carefully.
This leads us to a very classical architecture: we construct formal para-
phrases (logical forms, LFs) of the user’s statements and questions, and we
use a theorem prover to investigate the status of the propositions encoded in
the user’s questions. We are, in particular, not following the pattern match-
ing path taken in most ‘textual entailment’ systems, since the informal rules
used in such systems are not guaranteed to be sound.
We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our
formal language. There are very strong grounds for believing that natural
language is inherently intensional (we will see some examples below, but
the simple presence of verbs of propositional attitude is hard to cope with
unless you allow some degree of intensionality). There are a number of
logics which allow for a degree of intensionality–the typed logic used by
Montague (Montague, 1974; Dowty et al., 1981), the notion of non-well-
founded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry,
1983), Bealer (1989)’s intensional logic, and so on. We choose property
theory because one of Turner’s axiomatisations draws a very strong analogy
with modal logic which in turn suggests ways of adapting standard first-order
theorem proving techniques for it. We have developed a theorem prover for
a constructive version of property theory along these lines (Ramsay, 1995;
Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001).
No theorem prover for a logic with this degree of expressive power can be
complete–property theory, like default logic, is worse than first-order logic
in this respect, in that it is not even recursively enumerable. Practical
systems for first-order logic, however, do not proceed by enumerating all the
theorems. They do their best, and if they cannot find an answer within a
reasonable period of time then they give up. This the only sensible thing to
do, and it is just as sensible when reasoning with more expressive languages.
</bodyText>
<page confidence="0.998612">
183
</page>
<bodyText confidence="0.9998715">
We do not, however, just want to find out whether the answer to the
user’s question is ‘Yes’ or ‘No’. We would also like to provide them with
some explanation of how we arrived at our conclusion. It is much better to
answer ‘Should I eat pancakes?’ with ‘No, because pancakes contain eggs,
and eating things which contain eggs will make you ill if you are allergic
to eggs.’ than just by saying ‘No’. The user will be more likely to accept
the system’s answer if it comes with some supporting explanation, and they
may also be able to generalise from the explanation to cover other cases.
Where might we get such explanatory material from? The obvious place
to look is in the trace of the proof that led to the conclusion. The proof
tree contains the facts and rules that the system used in arriving at its
conclusion. Showing these facts and rules to the user would let them see
why the system believes that the queried proposition is true or false, and
lets them judge the trustworthiness of what the system says.
There are two difficult problems to be addressed here. The first is that
the proof tree will contain a mixture of things that the user themselves
said, things are blindingly obvious and things that the system suspects that
the user might not know. The explanation should probably concentrate on
things that the user might not have been aware of, so we should be looking
for items in the proof tree that the system believes the user may not know.
In other words, we need an epistemic version of property theory, and we
need to be able to inspect facts and rules to see who has access to them.
We will not discuss this further here, except to note that in the concrete
examples below we are not doing this, so that the support for the system’s
conclusions currently includes material that the user would actually already
be aware of.
The second problem is that it is extremely difficult to generate natural
language text from arbitrary logical expressions. We use standard composi-
tional techniques to build our logical forms on the basis of the form of the
input text (van Genabith &amp; Crouch, 1997; Konrad et al., 1996). However,
as with virtually any practical theorem prover, we then perform a number of
transformations (Skolemisation, distribution of negation, splitting rules with
conjunctive heads) to our logical forms in order to make them amenable to
the theorem prover. By the time we have done this there is very little hope
of using the compositional semantics in reverse to generate natural language
text from elements of the proof tree. There is, in particular, no chance of
using head-driven generation (Shieber et al., 1990) to produce text from el-
ements of the logical form, since this approach requires that the elements of
the logical form be unifiable with the meanings of lexical items in order to
drive the selection and combination of words. This is just not feasible with
</bodyText>
<page confidence="0.993837">
184
</page>
<bodyText confidence="0.999532083333333">
the elements of a proof tree.
Where do the facts and rules that appear in the proof tree come from?
We clearly have to specify them in advance in some form. Some of this
information comes from the user, in the form of statements about their
conditions, but most of it will have to provided explicitly.
We can do this in a variety of ways. We could try to use some existing
resource–WordNet, CYC, some medical ontology. It turns out that these re-
sources, or at least the publicly available ones, lack a great deal of what we
need. Very few such resources contain the kind of rules you need for answer-
ing questions such as the ones in (1). Lexical resources contain information
about relations between words. WordNet, for instance, provides hypersensi-
tivity reaction, hypersensitivity, sensitivity, susceptibility, condition, state,
attribute, abstraction, entity as hypernyms of ‘allergy’–all perfectly sensi-
ble hypernyms, but not all that useful for answering (1a). Likewise the
only mention of allergy or allergic in the ontology in OpenGalen (version
7, downloaded 09/10/08) says that an allergy is a kind of pathology, and
SnoMed has ‘propensity to adverse reactions’ and disease as hypernyms, and
a variety of links to special types of allergies and other related conditions.
This is not, of course, an exhaustive search of all potentially relevant
ontologies, but it does suggest that the kind of information stored in a typical
ontology is not what we require for answering our questions. It is, however,
extremely interesting to note that WordNet contains an English gloss for
‘allergy’ as ‘hypersensitivity reaction to a particular allergen; symptoms can
vary greatly in intensity’, OpenGalen contains the text ‘Hypersensitivity
caused by exposure to a particular antigen (allergen) resulting in a marked
increase in reactivity to that antigen upon subsequent exposure sometimes
resulting in harmful immunologic consequences.’ and SnoMed provides very
brief English glosses. It seems as though when ontology designers want to
say what a term really means, they resort to natural language.
It also seems as though this kind of ontology fails to include ‘common-
sense’ knowledge, e.g. that if you are allergic to a foodstuff then you should
not eat it. We need this kind of information in order to answer questions.
The prevalence of natural language glosses in ontological resources of this
kind, suggests that expressing it in natural language might be a good idea.
Using natural language to express the knowledge that we need has a
number of advantages:
</bodyText>
<listItem confidence="0.978995333333333">
• It is comparatively easy. Most people (even logicians and semanti-
cists!) generally find it easiest to express themselves in their native
language. It is much easier to write ‘If you are allergic to something
</listItem>
<page confidence="0.994236">
185
</page>
<bodyText confidence="0.9742635">
then eating it will make you ill’ than to express the same rule in some
formal language.
</bodyText>
<listItem confidence="0.620214076923077">
• Linking knowledge that has been expressed in natural language with
facts and queries that have been expressed in natural language obvi-
ates the need for a set of terminological mappings between domain
knowledge and natural language. The vocabularies used in termino-
logical databases tend to have a superfical resemblance to words in
natural languages, but the mapping is seldom exact, and indeed the
types associated with such terms are often quite different. If all your
knowledge is expressed in natural language then this kind of problem
can be avoided.
• Finally, it makes it much easier to generate answers. If we keep a link
between surface text and logic we can retrieve the surface text from
the proof tree. This does not entirely solve the problem of producing
coherent natural language answers, but it does make it much simpler.
</listItem>
<sectionHeader confidence="0.817927" genericHeader="method">
3 English with variables
</sectionHeader>
<bodyText confidence="0.999995333333333">
We therefore want to try writing down various commonsense rules in English.
To make it slightly easier to write rules, we allow variables in various places.
Thus we write (2b) rather than (2a).
</bodyText>
<listItem confidence="0.652959333333333">
(2) a. Eating fruit which contains vitamin C is good for you if you have
scurvy
b. Eating fruit which contains vitamin C is good for X if X has scurvy
</listItem>
<bodyText confidence="0.999305833333333">
This is helpful here simply to get around the fact that ‘you’ is normally
taken to be a reference to the hearer, whereas in (2a) it is being used in a
rather generic way. Rather than allowing ‘you’ to be ambiguous in this way,
we simply allow variables to be used in natural language.
The logical form we obtain for (2b) is shown in Fig. 1. There are a
number of things to note about Fig. 1:
</bodyText>
<listItem confidence="0.9099942">
• It’s enormous. Reading it you can see how it relates to (2b) itself,
but producing something like this by hand would certainly be a major
challenge. However, if we have a set of rules that explain the relation-
ship between structural (lexical and syntactic) choices and semantics
then we can obtain Fig. 1 directly from the parse tree of (2b). This and
</listItem>
<page confidence="0.918468">
186
</page>
<equation confidence="0.986094857142857">
∀X3Bevent(B,have)
&amp;3C : {scurvy(C, D)}θ(B,object,C)
&amp;θ(B,agent,X )
&amp;aspect(now,simple,B)
→ 3Estate(E,
AF(3Gevent(G,eat)
&amp; 3H : {fruit(H, I)
&amp; 3Jevent(J,contain)
&amp; θ(J,
object,
ref (AK(vitamin(K)
&amp; θ(K,
type,
ref (AL(named(L,C)))))))
&amp; θ(J,agent,H)
&amp; aspect(now,simple,J)}
θ(G,object,H)
&amp; θ(G, agent, F)),
AM(AN(good(N,M,normal))))
&amp;for(E,X)
&amp;aspect(now,simple,E)
</equation>
<figureCaption confidence="0.998356">
Figure 1: Logical form for (2b)
</figureCaption>
<bodyText confidence="0.99778975">
all other logical forms in this paper were produced by applying compo-
sitional rules to the first parse we obtained from the relevant texts. So
although it is indeed enormous, and complicated, all we have to do is
write the rule in English and the system will take care of the rest.
</bodyText>
<listItem confidence="0.8194654">
• The analysis of ‘eating fruit which contains vitamin C is good for you’
introduces a relationship between two intensional objects, namely ‘the
kind of event where someone eats fruit which contains vitamin C’ and
‘the property of being good’. This has significant consequences for the
kind of inference that is required. We will explore this further below.
</listItem>
<bodyText confidence="0.994055">
Once we allow variables in places where you might expect an NP, it
becomes tempting to introduce them in other places. The consequences of
doing this are interesting:
</bodyText>
<listItem confidence="0.9948445">
(3) a. Eating something will make you ill if you are allergic to it
b. Eating P will make X ill if X is allergic to P
</listItem>
<page confidence="0.9973">
187
</page>
<bodyText confidence="0.9977625">
Again the second version of the rule sidesteps some tricky details to do
with pronouns, but the formal paraphrase throws up some awkward issues.
</bodyText>
<equation confidence="0.973728166666667">
`dX`dP3Cstate(C,X, AD(AE(allergic(E,D,normal)))) &amp;to(C,P)
&amp;aspect(now,simple,C)
→ 3F : {future(now,F)}
3Bevent(B,make)
&amp;B(B,object,X )
&amp;B(B,object1 , AG(AH(ill(H,G,normal))))
&amp;B(B,
agent,
AI 3Jevent(J,eat)
&amp;3K : {P : K}B(J,object,K)
&amp;B(J,agent,I))
&amp;aspect(F,simple,B)
</equation>
<figureCaption confidence="0.99325">
Figure 2: Logical form for (3b)
</figureCaption>
<bodyText confidence="0.999745166666667">
The new problem in Fig. 2 is the paraphrase of ‘eating P will make X ill’,
where ‘P’ stands for something like ‘something of type P’. In other words,
P here is a variable noun rather than a variable NP.
Under almost any analysis, nouns denote kinds rather than individuals.
But that means that (3b) involves quantification over kinds, which is again
very intensional.
</bodyText>
<sectionHeader confidence="0.999665" genericHeader="method">
4 Inference
</sectionHeader>
<bodyText confidence="0.999967538461539">
Constructing LFs which involve relations between intensional entities is not
problematic. As noted above, we know there are formal languages which al-
low for intensionality, so all we have to do is choose one of these for our LFs.
Indeed, most approaches to compositionality exploit λ-abstraction and β-
reduction, so the intermediate objects that are constructed are inherently in-
tensional anyway. Anyone who takes the interpretation of ‘man in a park’ to
be something like λA(∃B : {park(B, C)}∃D(man(D, E) &amp; in(D,B))&amp;(A :
D)) (i.e. the standard Montague representation) is using an intensional
language as an intermediate representation.
Problems only arise when we try to reason with representations of this
kind. There is, however, very little point in making LFs if you are not going
to reason with them, so we do have to worry about it. To see a concrete
example, reconsider (1c), repeated as (4):
</bodyText>
<page confidence="0.985799">
188
</page>
<figure confidence="0.9320664">
(4) [ User: I have scurvy.
Computer: OK
User: Is eating berries good for me?
Computer: Yes, because berries contain vitamin C and eating fruit which
contains vitamin C is good for people who scurvy.
</figure>
<bodyText confidence="0.9985657">
Our rule about scurvy says that events of a certain kind are good for
people who have scurvy. The description of these events occupies an argu-
ment position in the LF, as one of the terms describing the general state of
affairs that holds if someone has scurvy.
In Prolog-based first-order theorem provers, you determine whether you
can use a rule to prove a goal by unifying the arguments of the goal with
the arguments of the consequent of the rule&apos;. In the current case, this would
mean unifying the terms describing ‘eating fruit which contains vitamin C’-
events and ‘eating berries’-events.
Clearly these descriptions will not unify. What we have to do is to accept
that the rule can be used with terms that describe subsets of the classes that
appear in argument positions.
We do not want to do this everywhere. This is a characteristic of the rule
about the link between vitamin C and scurvy, not a general characteristic
of all rules. When we want to allow for this, we have to say so explicitly.
We therefore include a rule which says that the idea that events of some
kind are good or bad or safe or ... for you is ‘downward entailing’: if eating
fruit which contains vitamin C is good for you then eating berries is good
for you, because the set of ‘eating berries’-events is a subset of the set of
‘eating fruit which contains vitamin C’-events. This rule is given in Fig. 3.
</bodyText>
<equation confidence="0.52187">
∀B∀C∀D : {∀F : {state(B,F,E,for(C))&amp;(∀G(D:G) → (F:G))}
state(B,D,E,for(C))
</equation>
<figureCaption confidence="0.99858">
Figure 3: Downward entailment for states
</figureCaption>
<bodyText confidence="0.98746375">
Fig. 3 says that if events that satisfy the description F satisfy the property
E for the individual C, then so do all events whose description G entails F.
We need a similar rule to say that this kind of relationship is upward
entailing in the third argument–that anything which is good for you, for
&apos;Prolog-based theorem proving is a special case of resolution theorem proving. In
general resolution theorem provers you have to unify some positive literal in one clause with
a negative one in another. For simplicity we will talk in terms of goals and consequents,
but the analysis would apply to other resolution-based engines.
</bodyText>
<page confidence="0.997799">
189
</page>
<bodyText confidence="0.999852916666667">
instance, is also safe for you. Rules like these exploit a notion of ‘guarded
intensionality’, in that they are only applicable when you already know what
properties you are interested in. They thus essentially act as schemas for
first-order rules. If we only use them backwards, in situations where we
know what properties we are interested in, they can be applied in a fairly
controlled way, and hence do not introduce wild combinatorial problems.
This is not the only kind of intensional rule that we need, but it does
cover a substantial number of interesting cases. The theorem prover de-
scribed in (Ramsay, 2001) can cope with more general intensional rules, but
guarded rules of this kind can be dealt with more efficiently than general
rules, and they are particularly useful for axiomatising the phenomena that
interest us.
</bodyText>
<sectionHeader confidence="0.576654" genericHeader="evaluation">
5 Paraphrases and other lexical relations
</sectionHeader>
<bodyText confidence="0.9967275">
It is clear that we need to treat with a variety of relations between everyday
terms. We will return, as an example, to (1b), repeated here as (5).
</bodyText>
<listItem confidence="0.734187">
(5) User: My son is very fat.
</listItem>
<table confidence="0.585837">
Computer: OK
User: Should he go swimming.
Computer: Yes, because swimming is a form of exercise, and exercise is good
for people who are overweight.
</table>
<bodyText confidence="0.999896625">
The computer’s answer to the user’s question clearly depends on an
understanding that if something is good for you then you should do it.
To say this is not, of course, to provide a complete characterisation of the
meaning of ‘should’. It is just a piece of commonsense. Nonetheless, for a
system to be able to cope with (1b) it has to have access to this piece of
commonsense. Fig. 4 shows the axiomatisation of this notion: if events of
the kind described by B are good C, then if I describes an action whose
performance entailed that B held for C then I should happen.
</bodyText>
<equation confidence="0.999560666666667">
∀B∀C∀D : {state(D,B, AE(AF(good(E,F,G))),for(C))
&amp;(∃H(I:H)) → (B:C))}
∃J : {aspect(now,simple,J)}should(J,I)
</equation>
<figureCaption confidence="0.976832">
Figure 4: If something’s good for you then you should do it
</figureCaption>
<page confidence="0.991154">
190
</page>
<bodyText confidence="0.999387785714286">
There are a variety of other very basic elements of commonsense which
have to be captured, and which are not generally included in formal ontolo-
gies. We need to know, for instance, that something cannot be both good
and bad, and that dangerous things are bad, and so on. Some of these can
only be axiomatised manually, but the aim is to keep things that have to
be encoded manually to a minimum. As noted earlier, writing axioms in
English is generally easier and it also makes them easily available for use
in explanations. Very basic things like the fact that things cannot be both
good and bad are unlikely to be required for explanations, even if they do
take part in proofs, so the fact that they are unavailable for this purpose
does not matter.
Some of these basic relations turn out to be bi-equivalences, or as near to
bi-equivalences as makes no difference. It is extremely difficult, for instance,
to articulate any difference between (6a) and (6b).
</bodyText>
<listItem confidence="0.509201">
(6) a. I have an allergy to eggs.
b. I am allergic to eggs.
</listItem>
<bodyText confidence="0.999755318181818">
We could take account of this by introducing a pair of implications: ‘X
has an allergy to P if X is allergic to P’ and ‘X is allergic to P if X has
an allergy to P’. This would work, in the sense that we would be able to
use these two constructions interchangeably, but it would slow the inference
engine down considerably. The presence of any pair of rules of the form
P —* Q and Q —* P will inevitably slow any theorem prover down, since any
attempt to prove Q is likely to lead to an attempt to prove P, which will in
turn lead to an attempt to prove Q. It is not difficult to catch simple loops
of this kind, but it is better to avoid them in the first place if possible.
We therefore use rules like this as part of the normal-forming pro-
cess. Construction of normal forms generally involves application of bi-
equivalences where one side has a form which is particularly well-suited to
the needs of a particular theorem proving algorithm. In resolution, for in-
stance, the rules -,(P&amp;Q) H (-,P V -,Q) and -,(P V Q) H (-,P&amp;-,Q) are
used during the construction of the normal form because resolution looks
for matching positive and negative literals, so axioms that can be used to
ensure that the only negation signs appear at the lowest possible level are
useful.
The point of normal-forming, then, is to ensure that bi-equivalences are
applied just once, and in just one direction. We thus apply bi-equivalences
like the one between (6a) and (6b) during the construction the construction
of logical forms. This lets us cope with the fact that natural languages
</bodyText>
<page confidence="0.995596">
191
</page>
<bodyText confidence="0.9983792">
typically provide a range of ways of saying virtually the same thing without
incurring the expense of applying rules which potentially lead to loops when
we are carrying out inferences.
There is a complication here. The system needs to realise that (7a) and
(7b) are also the same (and likewise for other variations).
</bodyText>
<listItem confidence="0.3787845">
(7) a. I have a severe allergy to eggs.
b. I am severely allergic to eggs.
</listItem>
<bodyText confidence="0.989487666666667">
Dealing with this requires considerable care in the design of logical forms.
Space precludes a deeper discussion of this issue, but this is something we
have to take care over.
</bodyText>
<sectionHeader confidence="0.999604" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99999284">
The work described here covers very similar ground to work in textual en-
tailment (Dagan et al., 2005), in that we want to draw inferences based
on facts and rules expressed in natural language. Producing logical forms
and then using a theorem prover to carry out the required inference leads
to more reliable conclusions, since we can check that the theorem prover is
sound, and hence we can rely on the conclusions that it draws. It also leads
to deeper chains of inference, since the pattern matching algorithms gen-
erally employed for textual entailment do not lend themselves to repeated
application.
The approach outlined here does involve a number of risks. We might
not be able to express all the knowledge we want in natural language; we
might not be able to produce logical forms from our natural language rules;
when we have more rules the theorem prover might not be able to cope.
The last of these is the most dangerous. If there are rules which we
cannot express in natural language, or where we cannot convert the natural
language into a logical form, we can always express them directly in property
theory (or property theory with procedural attachment of appropriate, e.g.
mathematical, rules (Steels, 1979)). How long will it take when there are
large numbers of rules? The proofs for the examples here take around 0.1
sec. Most of this time is spent investigating intensional rules. Most of the
commonsense knowledge, however, is represented as Horn clauses. Indeed it
is represented as pure Prolog. The speed of Prolog programs is not affected
by the number of clauses that are present, so we are confident that adding
more rules will have very little effect on the performance so long as they
can be represented as Horn clauses. The key issue, then, is how many new
</bodyText>
<page confidence="0.993998">
192
</page>
<bodyText confidence="0.99969725">
intensional rules we will need. Only time will tell, but we are hopeful that
we will retain a reasonable level of performance even when we have a more
substantial set of rules. If not, we will just have to make the theorem prover
faster.
</bodyText>
<sectionHeader confidence="0.991916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99948715625">
P. Aczel (1988). Non-Well-Founded-Sets. CSLI Publications, Stanford.
J. Barwise &amp; J. Perry (1983). Situations and Attitudes. Bradford Books, Cambridge,
MA.
G. Bealer (1989). ‘Fine-grained type-free intensionality’. In G. Chierchia, B. H.
Partee, &amp; R. Turner (eds.), Properties, types and meaning: vol I, foundational
issues. Kluwer Academic Publishers, Dordrecht/Boston/London.
G. Chierchia &amp; R. Turner (1987). ‘Semantics and Property Theory’. Linguistics
and Philosophy 11(3).
M. Cryan &amp; A. M. Ramsay (1997). ‘A Normal Form for Property Theory’. In Pro-
ceedings of the 14th International Conference on Automated Deduction (CADE-
14), vol. 1249 of Lecture Notes in Artificial Intelligence, pp. 237–251, Berlin.
Springer-Verlag.
I. Dagan, et al. (2005). ‘The PASCAL Recognising Textual Entailment Challenge’.
In Proceedings of Pascal Challenge Workshop on Recognizing Textual Entailment.
D. R. Dowty, et al. (1981). Introduction to Montague Semantics. D. Reidel, Dor-
drecht.
K. Konrad, et al. (1996). ‘An education and research tool for computational se-
mantics’. In Proceedings of the 16th International Conference on Computational
Linguistics (COLING-96), pp. 1098–1102, Copenhagen.
R. Montague (1974). ‘The proper treatment of quantification in ordinary English’.
In R. Thomason (ed.), Formal Philosophy: Selected Papers of Richard Montague,
New Haven. Yale University Press.
A. M. Ramsay (1995). ‘A Theorem Prover for an Intensional Logic’. Journal of
Automated Reasoning 14:237–255.
A. M. Ramsay (2001). ‘Theorem proving for untyped constructive λ-calculus: im-
plementation and application’. Logic Journal of the Interest Group in Pure and
Applied Logics 9(1):89–106.
A. M. Ramsay &amp; D. G. Field (2008). ‘Speech acts, epistemic planning and Grice’s
maxims’. Logic and Computation 18:431–457.
A. M. Ramsay &amp; H. L. Seville (2001). ‘Relevant Answers to WH-questions’. In 3rd
International Conference on Inference in Computational Semantics, pp. 73–86,
Siena.
</reference>
<page confidence="0.990658">
193
</page>
<reference confidence="0.9796696875">
S. M. Shieber, et al. (1990). ‘Semantic-Head-Driven Generation’. Computational
Linguistics 16(1):30–42.
L. Steels (1979). ‘Procedural attachment’. Tech. rep., MIT.
R. Turner (1987). ‘A Theory of Properties’. Journal of Symbolic Logic 52(2):455–
472.
J. van Genabith &amp; R. Crouch (1997). ‘How to glue a donkey to an f-structure’.
In H. C. Bunt, L. Kievit, R. Muskens, &amp; M. Verlinden (eds.), 2nd International
Workshop on Computational Semantics, pp. 52–65, University of Tilburg.
Appendix: commonsense rules
(8) a. eating P will make X ill if X is allergic to P.
b. exercise is good for X if X is overweight.
c. swimming is good for X if exercise is good for X.
d. walking is good for X if exercise is good for X.
e. eating fruit which contains vitamin C is good for X if X has scurvy.
f. X eats P if X eats something which contains P.
g. X is dangerous for Y if X will make Y ill.
</reference>
<page confidence="0.998578">
194
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.009649">
<title confidence="0.999973">Using English for commonsense knowledge</title>
<author confidence="0.999983">Allan Ramsay Debora Field</author>
<affiliation confidence="0.9999445">School of Computer Science Dept of Computer Science Univ of Manchester Univ of Sheffield</affiliation>
<address confidence="0.997183">Manchester M60 1QD, UK Sheffield S1 4DP, UK</address>
<abstract confidence="0.995884741935484">The work reported here arises from an attempt to provide a body of simple information about diet and its effect on various common medical conditions. Expressing this knowledge in natural language has a number of advantages. It also raises a number of difficult issues. We will consider solutions, and partial solutions, to these issues below. 1 Commonse knowledge Suppose you wanted to have a system that could provide advice about what you should and should not eat if you suffer from various common medical conditions. You might expect, at the very least, to be able to have dialogues like (1). (1) a. User: I am allergic to eggs. Computer: OK User: Should I eat pancakes Computer: No, because pancakes contain eggs, and eating things which contain eggs will make you ill if you are allergic to eggs. b. User: My son is very fat. Computer: OK User: Should he go swimming. Computer: Yes, because swimming is a form of exercise, and exercise is good for people who are overweight. c. User: I have scurvy. Computer: OK User: Is eating berries good for me? Computer: Yes, because berries contain vitamin C and eating fruit which contains vitamin C is good for people who scurvy. 181 of the 8th International Conference on Computational pages 181–194, January 2009. International Conference on Computational Semantics These are comparatively simple dialogues, requiring a very limited amount of knowledge about foods and medical conditions. As we will see, however, dealing with them does require a remarkable amount of knowledge about language. The framework we are using makes a number of very basic assumptions about how you design a system to deal with such dialogues. • To give appropriate answers to these questions you have to consider the available information supports contradicts queried proposition. • In order to see whether the available information supports or contradicts a proposition you need a body of domain knowledge, and you need to be able to reason with it. • Natural languages provide numerous ways of saying almost identical There is, for instance, almost no difference between am to eggs’ have an allergy to You therefore have to have a way of dealing with paraphrases. We will explore each of these issues in turn below. 2 Answering questions We will concentrate here on polar (YES/NO) questions. We also take the very simple view that when someone asks a polar question it is because they want to know whether the proposition encoded in the question is true or Someone who asks it safe for me to eggs?’ to be told it is and it is not. We have explored the nature of WH-questions elsewhere (Ramsay &amp; Seville, 2001), and we have discussed situations where people use language in indirect ways (Ramsay &amp; Field, 2008), but for the moment just trying to answer polar questions will pose enough problems to keep us occupied. order to answer such a question by saying have to see is safe for the speaker to eat eggs’ from what you know about the speaker and your general knowledge. You cannot, however, say because your attempted proof that it is safe failed. If you failed to prove that it is safe you should then see whether you can prove that it is If, and only if, you can then you should say In general, then, answering a polar question may involve two attempted proofs–one aimed at showing that the proposition under discussion is true 182 and then possibly a second aimed at showing that it is false. If you are lucky you might discover evidence that the proposition is false while you are trying to show that it is true, but in general you may have to attempt two proofs. In order to carry out proofs you need an inference engine. Inference engines come in all sorts of shapes and sizes–fast or slow, sound or unsound, complete or incomplete–and they can be applied to a variety of knowledge representation schemes. The choice of representation scheme, and of the inference engine that you apply to it, will depend on what you want to do with it. For our current task we assume that soundness is crucial, since you really would not want a medical advice system to give wrong advice; and that the representation scheme has to be highly expressive, since the relations involved are subtle and need to be represented very carefully. This leads us to a very classical architecture: we construct formal paraphrases (logical forms, LFs) of the user’s statements and questions, and we use a theorem prover to investigate the status of the propositions encoded in the user’s questions. We are, in particular, not following the pattern matching path taken in most ‘textual entailment’ systems, since the informal rules used in such systems are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this respect, in that it is not even recursively enumerable. Practical systems for first-order logic, however, do not proceed by enumerating all the theorems. They do their best, and if they cannot find an answer within a reasonable period of time then they give up. This the only sensible thing to do, and it is just as sensible when reasoning with more expressive languages. 183 We do not, however, just want to find out whether the answer to the question is We would also like to provide them with some explanation of how we arrived at our conclusion. It is much better to I eat pancakes?’ because pancakes contain eggs, and eating things which contain eggs will make you ill if you are allergic eggs.’ just by saying The user will be more likely to accept the system’s answer if it comes with some supporting explanation, and they may also be able to generalise from the explanation to cover other cases. Where might we get such explanatory material from? The obvious place to look is in the trace of the proof that led to the conclusion. The proof tree contains the facts and rules that the system used in arriving at its conclusion. Showing these facts and rules to the user would let them see why the system believes that the queried proposition is true or false, and lets them judge the trustworthiness of what the system says. There are two difficult problems to be addressed here. The first is that the proof tree will contain a mixture of things that the user themselves said, things are blindingly obvious and things that the system suspects that the user might not know. The explanation should probably concentrate on things that the user might not have been aware of, so we should be looking for items in the proof tree that the system believes the user may not know. In other words, we need an epistemic version of property theory, and we need to be able to inspect facts and rules to see who has access to them. We will not discuss this further here, except to note that in the concrete below we are this, so that the support for the system’s conclusions currently includes material that the user would actually already be aware of. The second problem is that it is extremely difficult to generate natural language text from arbitrary logical expressions. We use standard compositional techniques to build our logical forms on the basis of the form of the input text (van Genabith &amp; Crouch, 1997; Konrad et al., 1996). However, as with virtually any practical theorem prover, we then perform a number of transformations (Skolemisation, distribution of negation, splitting rules with conjunctive heads) to our logical forms in order to make them amenable to the theorem prover. By the time we have done this there is very little hope of using the compositional semantics in reverse to generate natural language text from elements of the proof tree. There is, in particular, no chance of using head-driven generation (Shieber et al., 1990) to produce text from elements of the logical form, since this approach requires that the elements of the logical form be unifiable with the meanings of lexical items in order to drive the selection and combination of words. This is just not feasible with 184 the elements of a proof tree. Where do the facts and rules that appear in the proof tree come from? We clearly have to specify them in advance in some form. Some of this information comes from the user, in the form of statements about their conditions, but most of it will have to provided explicitly. We can do this in a variety of ways. We could try to use some existing resource–WordNet, CYC, some medical ontology. It turns out that these resources, or at least the publicly available ones, lack a great deal of what we need. Very few such resources contain the kind of rules you need for answering questions such as the ones in (1). Lexical resources contain information about relations between words. WordNet, for instance, provides hypersensitivity reaction, hypersensitivity, sensitivity, susceptibility, condition, state, abstraction, entity as hypernyms of perfectly sensible hypernyms, but not all that useful for answering (1a). Likewise the only mention of allergy or allergic in the ontology in OpenGalen (version 7, downloaded 09/10/08) says that an allergy is a kind of pathology, and SnoMed has ‘propensity to adverse reactions’ and disease as hypernyms, and a variety of links to special types of allergies and other related conditions. This is not, of course, an exhaustive search of all potentially relevant ontologies, but it does suggest that the kind of information stored in a typical ontology is not what we require for answering our questions. It is, however, extremely interesting to note that WordNet contains an English gloss for reaction to a particular allergen; symptoms can greatly in OpenGalen contains the text caused by exposure to a particular antigen (allergen) resulting in a marked increase in reactivity to that antigen upon subsequent exposure sometimes in harmful immunologic consequences.’ SnoMed provides very brief English glosses. It seems as though when ontology designers want to say what a term really means, they resort to natural language. It also seems as though this kind of ontology fails to include ‘commonsense’ knowledge, e.g. that if you are allergic to a foodstuff then you should not eat it. We need this kind of information in order to answer questions. The prevalence of natural language glosses in ontological resources of this kind, suggests that expressing it in natural language might be a good idea. Using natural language to express the knowledge that we need has a number of advantages: • It is comparatively easy. Most people (even logicians and semanticists!) generally find it easiest to express themselves in their native It is much easier to write you are allergic to something 185 eating it will make you ill’ to express the same rule in some formal language. • Linking knowledge that has been expressed in natural language with facts and queries that have been expressed in natural language obviates the need for a set of terminological mappings between domain knowledge and natural language. The vocabularies used in terminological databases tend to have a superfical resemblance to words in natural languages, but the mapping is seldom exact, and indeed the types associated with such terms are often quite different. If all your knowledge is expressed in natural language then this kind of problem can be avoided. • Finally, it makes it much easier to generate answers. If we keep a link between surface text and logic we can retrieve the surface text from the proof tree. This does not entirely solve the problem of producing coherent natural language answers, but it does make it much simpler. 3 English with variables We therefore want to try writing down various commonsense rules in English. To make it slightly easier to write rules, we allow variables in various places. Thus we write (2b) rather than (2a). (2) a. Eating fruit which contains vitamin C is good for you if you have scurvy b. Eating fruit which contains vitamin C is good for X if X has scurvy is helpful here simply to get around the fact that normally taken to be a reference to the hearer, whereas in (2a) it is being used in a generic way. Rather than allowing be ambiguous in this way, we simply allow variables to be used in natural language. The logical form we obtain for (2b) is shown in Fig. 1. There are a number of things to note about Fig. 1: • It’s enormous. Reading it you can see how it relates to (2b) itself, but producing something like this by hand would certainly be a major challenge. However, if we have a set of rules that explain the relationship between structural (lexical and syntactic) choices and semantics we can obtain Fig. 1 directly from the parse tree of (2b). and 186 : &amp;θ(B,agent,X ) &amp;aspect(now,simple,B) : I) &amp; θ(J, object, ref (AK(vitamin(K) &amp; θ(K, type, ref (AL(named(L,C))))))) &amp; θ(J,agent,H) θ(G,object,H) &amp; θ(G, agent, F)), AM(AN(good(N,M,normal)))) &amp;for(E,X) &amp;aspect(now,simple,E) Figure 1: Logical form for (2b) all other logical forms in this paper were produced by applying comporules to the first parse we obtained from the relevant texts. although it is indeed enormous, and complicated, all we have to do is write the rule in English and the system will take care of the rest. The analysis of fruit which contains vitamin C is good for you’ introduces a relationship between two intensional objects, namely ‘the kind of event where someone eats fruit which contains vitamin C’ and ‘the property of being good’. This has significant consequences for the kind of inference that is required. We will explore this further below. Once we allow variables in places where you might expect an NP, it becomes tempting to introduce them in other places. The consequences of doing this are interesting: (3) a. Eating something will make you ill if you are allergic to it b. Eating P will make X ill if X is allergic to P 187 Again the second version of the rule sidesteps some tricky details to do with pronouns, but the formal paraphrase throws up some awkward issues. AD(AE(allergic(E,D,normal)))) &amp;to(C,P) &amp;aspect(now,simple,C) : &amp;B(B,object,X ) &amp;B(B,object1 , AG(AH(ill(H,G,normal)))) &amp;B(B, agent, : : &amp;B(J,agent,I)) &amp;aspect(F,simple,B) Figure 2: Logical form for (3b) new problem in Fig. 2 is the paraphrase of P will make X for something like of type In other words, P here is a variable noun rather than a variable NP. Under almost any analysis, nouns denote kinds rather than individuals. But that means that (3b) involves quantification over kinds, which is again very intensional. 4 Inference Constructing LFs which involve relations between intensional entities is not problematic. As noted above, we know there are formal languages which allow for intensionality, so all we have to do is choose one of these for our LFs. most approaches to compositionality exploit and reduction, so the intermediate objects that are constructed are inherently inanyway. Anyone who takes the interpretation of in a park’ something like &amp; (i.e. the standard Montague representation) is using an intensional language as an intermediate representation. Problems only arise when we try to reason with representations of this kind. There is, however, very little point in making LFs if you are not going to reason with them, so we do have to worry about it. To see a concrete example, reconsider (1c), repeated as (4): 188 (4) [ User: I have scurvy. Computer: OK User: Is eating berries good for me? Computer: Yes, because berries contain vitamin C and eating fruit which contains vitamin C is good for people who scurvy. Our rule about scurvy says that events of a certain kind are good for who have scurvy. The description of these events occupies an arguin the LF, as one of the terms describing the general state of affairs that holds if someone has scurvy. In Prolog-based first-order theorem provers, you determine whether you use a rule to prove a goal by arguments of the goal with arguments of the consequent of the In the current case, this would mean unifying the terms describing ‘eating fruit which contains vitamin C’events and ‘eating berries’-events. Clearly these descriptions will not unify. What we have to do is to accept that the rule can be used with terms that describe subsets of the classes that appear in argument positions. We do not want to do this everywhere. This is a characteristic of the rule about the link between vitamin C and scurvy, not a general characteristic of all rules. When we want to allow for this, we have to say so explicitly. We therefore include a rule which says that the idea that events of some kind are good or bad or safe or ... for you is ‘downward entailing’: if eating fruit which contains vitamin C is good for you then eating berries is good for you, because the set of ‘eating berries’-events is a subset of the set of ‘eating fruit which contains vitamin C’-events. This rule is given in Fig. 3. Figure 3: Downward entailment for states 3 says that if events that satisfy the description the property the individual then so do all events whose description We need a similar rule to say that this kind of relationship is upward entailing in the third argument–that anything which is good for you, for theorem proving is a special case of resolution theorem proving. In general resolution theorem provers you have to unify some positive literal in one clause with a negative one in another. For simplicity we will talk in terms of goals and consequents, but the analysis would apply to other resolution-based engines. 189 instance, is also safe for you. Rules like these exploit a notion of ‘guarded intensionality’, in that they are only applicable when you already know what properties you are interested in. They thus essentially act as schemas for first-order rules. If we only use them backwards, in situations where we know what properties we are interested in, they can be applied in a fairly controlled way, and hence do not introduce wild combinatorial problems. This is not the only kind of intensional rule that we need, but it does cover a substantial number of interesting cases. The theorem prover described in (Ramsay, 2001) can cope with more general intensional rules, but guarded rules of this kind can be dealt with more efficiently than general rules, and they are particularly useful for axiomatising the phenomena that interest us. 5 Paraphrases and other lexical relations It is clear that we need to treat with a variety of relations between everyday terms. We will return, as an example, to (1b), repeated here as (5). (5) User: My son is very fat. Computer: OK User: Should he go swimming. Computer: Yes, because swimming is a form of exercise, and exercise is good for people who are overweight. The computer’s answer to the user’s question clearly depends on an understanding that if something is good for you then you should do it. To say this is not, of course, to provide a complete characterisation of the of It is just a piece of commonsense. Nonetheless, for a system to be able to cope with (1b) it has to have access to this piece of commonsense. Fig. 4 shows the axiomatisation of this notion: if events of kind described by good then if an action whose entailed that for happen. : AE(AF(good(E,F,G))),for(C)) : Figure 4: If something’s good for you then you should do it 190 There are a variety of other very basic elements of commonsense which have to be captured, and which are not generally included in formal ontologies. We need to know, for instance, that something cannot be both good and bad, and that dangerous things are bad, and so on. Some of these can only be axiomatised manually, but the aim is to keep things that have to be encoded manually to a minimum. As noted earlier, writing axioms in English is generally easier and it also makes them easily available for use in explanations. Very basic things like the fact that things cannot be both good and bad are unlikely to be required for explanations, even if they do take part in proofs, so the fact that they are unavailable for this purpose does not matter. Some of these basic relations turn out to be bi-equivalences, or as near to bi-equivalences as makes no difference. It is extremely difficult, for instance, to articulate any difference between (6a) and (6b). (6) a. I have an allergy to eggs. b. I am allergic to eggs. could take account of this by introducing a pair of implications: an allergy to P if X is allergic to P’ is allergic to P if X has allergy to This would work, in the sense that we would be able to use these two constructions interchangeably, but it would slow the inference engine down considerably. The presence of any pair of rules of the form P —* Q and Q —* P will inevitably slow any theorem prover down, since any attempt to prove Q is likely to lead to an attempt to prove P, which will in turn lead to an attempt to prove Q. It is not difficult to catch simple loops of this kind, but it is better to avoid them in the first place if possible. We therefore use rules like this as part of the normal-forming process. Construction of normal forms generally involves application of biequivalences where one side has a form which is particularly well-suited to the needs of a particular theorem proving algorithm. In resolution, for instance, the rules -,(P&amp;Q) H (-,P V -,Q) and -,(P V Q) H (-,P&amp;-,Q) are used during the construction of the normal form because resolution looks for matching positive and negative literals, so axioms that can be used to ensure that the only negation signs appear at the lowest possible level are useful. The point of normal-forming, then, is to ensure that bi-equivalences are applied just once, and in just one direction. We thus apply bi-equivalences like the one between (6a) and (6b) during the construction the construction of logical forms. This lets us cope with the fact that natural languages 191 typically provide a range of ways of saying virtually the same thing without incurring the expense of applying rules which potentially lead to loops when we are carrying out inferences. There is a complication here. The system needs to realise that (7a) and (7b) are also the same (and likewise for other variations). (7) a. I have a severe allergy to eggs. b. I am severely allergic to eggs. Dealing with this requires considerable care in the design of logical forms. Space precludes a deeper discussion of this issue, but this is something we have to take care over. 6 Conclusions The work described here covers very similar ground to work in textual entailment (Dagan et al., 2005), in that we want to draw inferences based on facts and rules expressed in natural language. Producing logical forms and then using a theorem prover to carry out the required inference leads to more reliable conclusions, since we can check that the theorem prover is sound, and hence we can rely on the conclusions that it draws. It also leads to deeper chains of inference, since the pattern matching algorithms generally employed for textual entailment do not lend themselves to repeated application. The approach outlined here does involve a number of risks. We might not be able to express all the knowledge we want in natural language; we might not be able to produce logical forms from our natural language rules; when we have more rules the theorem prover might not be able to cope. The last of these is the most dangerous. If there are rules which we cannot express in natural language, or where we cannot convert the natural language into a logical form, we can always express them directly in property theory (or property theory with procedural attachment of appropriate, e.g. mathematical, rules (Steels, 1979)). How long will it take when there are large numbers of rules? The proofs for the examples here take around 0.1 sec. Most of this time is spent investigating intensional rules. Most of the commonsense knowledge, however, is represented as Horn clauses. Indeed it is represented as pure Prolog. The speed of Prolog programs is not affected by the number of clauses that are present, so we are confident that adding rules will have very little effect on the performance long as they be represented as Horn The key issue, then, is how many new 192 intensional rules we will need. Only time will tell, but we are hopeful that we will retain a reasonable level of performance even when we have a more substantial set of rules. If not, we will just have to make the theorem prover faster.</abstract>
<note confidence="0.955706958333333">References Aczel (1988). CSLI Publications, Stanford. Barwise &amp; J. Perry (1983). and Bradford Books, Cambridge, MA. G. Bealer (1989). ‘Fine-grained type-free intensionality’. In G. Chierchia, B. H. &amp; R. Turner (eds.), types and meaning: vol I, foundational Kluwer Academic Publishers, Dordrecht/Boston/London. Chierchia &amp; R. Turner (1987). ‘Semantics and Property Theory’. Philosophy Cryan &amp; A. M. Ramsay (1997). ‘A Normal Form for Property Theory’. In Proceedings of the 14th International Conference on Automated Deduction (CADEvol. 1249 of Notes in Artificial pp. 237–251, Berlin. Springer-Verlag. I. Dagan, et al. (2005). ‘The PASCAL Recognising Textual Entailment Challenge’. of Pascal Challenge Workshop on Recognizing Textual R. Dowty, et al. (1981). to Montague D. Reidel, Dordrecht. K. Konrad, et al. (1996). ‘An education and research tool for computational se- In of the 16th International Conference on Computational pp. 1098–1102, Copenhagen. R. Montague (1974). ‘The proper treatment of quantification in ordinary English’. R. Thomason (ed.), Philosophy: Selected Papers of Richard New Haven. Yale University Press. M. Ramsay (1995). ‘A Theorem Prover for an Intensional Logic’. of</note>
<title confidence="0.92869">Reasoning</title>
<author confidence="0.859041">‘Theorem proving for untyped constructive im-</author>
<affiliation confidence="0.606942">and application’. Journal of the Interest Group in Pure and</affiliation>
<title confidence="0.686704666666667">Logics A. M. Ramsay &amp; D. G. Field (2008). ‘Speech acts, epistemic planning and Grice’s and Computation</title>
<author confidence="0.908881">M Ramsay</author>
<author confidence="0.908881">H L Seville</author>
<note confidence="0.909534571428572">Conference on Inference in Computational pp. 73–86, Siena. 193 M. Shieber, et al. (1990). ‘Semantic-Head-Driven Generation’. L. Steels (1979). ‘Procedural attachment’. Tech. rep., MIT. Turner (1987). ‘A Theory of Properties’. of Symbolic Logic 472.</note>
<abstract confidence="0.868948818181818">J. van Genabith &amp; R. Crouch (1997). ‘How to glue a donkey to an f-structure’. H. C. Bunt, L. Kievit, R. Muskens, &amp; M. Verlinden (eds.), International on Computational pp. 52–65, University of Tilburg. Appendix: commonsense rules (8) a. eating P will make X ill if X is allergic to P. b. exercise is good for X if X is overweight. c. swimming is good for X if exercise is good for X. d. walking is good for X if exercise is good for X. e. eating fruit which contains vitamin C is good for X if X has scurvy. f. X eats P if X eats something which contains P. g. X is dangerous for Y if X will make Y ill.</abstract>
<intro confidence="0.750511">194</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Aczel</author>
</authors>
<title>Non-Well-Founded-Sets.</title>
<date>1988</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford.</location>
<contexts>
<context position="5609" citStr="Aczel, 1988" startWordPosition="950" endWordPosition="951">nce the informal rules used in such systems are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like def</context>
</contexts>
<marker>Aczel, 1988</marker>
<rawString>P. Aczel (1988). Non-Well-Founded-Sets. CSLI Publications, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Barwise</author>
<author>J Perry</author>
</authors>
<title>Situations and Attitudes.</title>
<date>1983</date>
<publisher>Bradford Books,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5661" citStr="Barwise &amp; Perry, 1983" startWordPosition="956" endWordPosition="959">s are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this </context>
</contexts>
<marker>Barwise, Perry, 1983</marker>
<rawString>J. Barwise &amp; J. Perry (1983). Situations and Attitudes. Bradford Books, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bealer</author>
</authors>
<title>Fine-grained type-free intensionality’.</title>
<date>1989</date>
<editor>In G. Chierchia, B. H. Partee, &amp; R. Turner (eds.),</editor>
<publisher>Kluwer Academic Publishers, Dordrecht/Boston/London.</publisher>
<contexts>
<context position="5676" citStr="Bealer (1989)" startWordPosition="960" endWordPosition="961">be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this respect, in tha</context>
</contexts>
<marker>Bealer, 1989</marker>
<rawString>G. Bealer (1989). ‘Fine-grained type-free intensionality’. In G. Chierchia, B. H. Partee, &amp; R. Turner (eds.), Properties, types and meaning: vol I, foundational issues. Kluwer Academic Publishers, Dordrecht/Boston/London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Chierchia</author>
<author>R Turner</author>
</authors>
<date>1987</date>
<booktitle>Semantics and Property Theory’. Linguistics and Philosophy</booktitle>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="5138" citStr="Chierchia &amp; Turner, 1987" startWordPosition="872" endWordPosition="875">ntation scheme has to be highly expressive, since the relations involved are subtle and need to be represented very carefully. This leads us to a very classical architecture: we construct formal paraphrases (logical forms, LFs) of the user’s statements and questions, and we use a theorem prover to investigate the status of the propositions encoded in the user’s questions. We are, in particular, not following the pattern matching path taken in most ‘textual entailment’ systems, since the informal rules used in such systems are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory bec</context>
</contexts>
<marker>Chierchia, Turner, 1987</marker>
<rawString>G. Chierchia &amp; R. Turner (1987). ‘Semantics and Property Theory’. Linguistics and Philosophy 11(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cryan</author>
<author>A M Ramsay</author>
</authors>
<title>A Normal Form for Property Theory’.</title>
<date>1997</date>
<booktitle>In Proceedings of the 14th International Conference on Automated Deduction (CADE14),</booktitle>
<volume>1249</volume>
<pages>237--251</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin.</location>
<contexts>
<context position="6051" citStr="Cryan &amp; Ramsay, 1997" startWordPosition="1016" endWordPosition="1019">number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this respect, in that it is not even recursively enumerable. Practical systems for first-order logic, however, do not proceed by enumerating all the theorems. They do their best, and if they cannot find an answer within a reasonable period of time then they give up. This the only sensible thing to do, and it is just as sensible when reasoning with more expressive languages. 183 We do not, how</context>
</contexts>
<marker>Cryan, Ramsay, 1997</marker>
<rawString>M. Cryan &amp; A. M. Ramsay (1997). ‘A Normal Form for Property Theory’. In Proceedings of the 14th International Conference on Automated Deduction (CADE14), vol. 1249 of Lecture Notes in Artificial Intelligence, pp. 237–251, Berlin. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
</authors>
<title>The PASCAL Recognising Textual Entailment Challenge’.</title>
<date>2005</date>
<booktitle>In Proceedings of Pascal Challenge Workshop on Recognizing Textual Entailment.</booktitle>
<marker>Dagan, 2005</marker>
<rawString>I. Dagan, et al. (2005). ‘The PASCAL Recognising Textual Entailment Challenge’. In Proceedings of Pascal Challenge Workshop on Recognizing Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Dowty</author>
</authors>
<title>Introduction to Montague Semantics.</title>
<date>1981</date>
<location>D. Reidel, Dordrecht.</location>
<marker>Dowty, 1981</marker>
<rawString>D. R. Dowty, et al. (1981). Introduction to Montague Semantics. D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Konrad</author>
</authors>
<title>An education and research tool for computational semantics’.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96),</booktitle>
<pages>1098--1102</pages>
<location>Copenhagen.</location>
<marker>Konrad, 1996</marker>
<rawString>K. Konrad, et al. (1996). ‘An education and research tool for computational semantics’. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96), pp. 1098–1102, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>The proper treatment of quantification in ordinary English’. In</title>
<date>1974</date>
<booktitle>Formal Philosophy: Selected Papers of</booktitle>
<editor>R. Thomason (ed.),</editor>
<publisher>Yale University Press.</publisher>
<contexts>
<context position="5538" citStr="Montague, 1974" startWordPosition="938" endWordPosition="939"> the pattern matching path taken in most ‘textual entailment’ systems, since the informal rules used in such systems are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with th</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>R. Montague (1974). ‘The proper treatment of quantification in ordinary English’. In R. Thomason (ed.), Formal Philosophy: Selected Papers of Richard Montague, New Haven. Yale University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Ramsay</author>
</authors>
<title>A Theorem Prover for an Intensional Logic’.</title>
<date>1995</date>
<journal>Journal of Automated Reasoning</journal>
<pages>14--237</pages>
<contexts>
<context position="6028" citStr="Ramsay, 1995" startWordPosition="1014" endWordPosition="1015">. There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this respect, in that it is not even recursively enumerable. Practical systems for first-order logic, however, do not proceed by enumerating all the theorems. They do their best, and if they cannot find an answer within a reasonable period of time then they give up. This the only sensible thing to do, and it is just as sensible when reasoning with more expressive langua</context>
</contexts>
<marker>Ramsay, 1995</marker>
<rawString>A. M. Ramsay (1995). ‘A Theorem Prover for an Intensional Logic’. Journal of Automated Reasoning 14:237–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Ramsay</author>
</authors>
<title>Theorem proving for untyped constructive λ-calculus: implementation and application’.</title>
<date>2001</date>
<journal>Logic Journal of the Interest Group in Pure and Applied Logics</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="6099" citStr="Ramsay, 2001" startWordPosition="1027" endWordPosition="1028">ity–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We choose property theory because one of Turner’s axiomatisations draws a very strong analogy with modal logic which in turn suggests ways of adapting standard first-order theorem proving techniques for it. We have developed a theorem prover for a constructive version of property theory along these lines (Ramsay, 1995; Cryan &amp; Ramsay, 1997), and have shown that it is sound (Ramsay, 2001). No theorem prover for a logic with this degree of expressive power can be complete–property theory, like default logic, is worse than first-order logic in this respect, in that it is not even recursively enumerable. Practical systems for first-order logic, however, do not proceed by enumerating all the theorems. They do their best, and if they cannot find an answer within a reasonable period of time then they give up. This the only sensible thing to do, and it is just as sensible when reasoning with more expressive languages. 183 We do not, however, just want to find out whether the answer t</context>
<context position="20384" citStr="Ramsay, 2001" startWordPosition="3433" endWordPosition="3434">ance, is also safe for you. Rules like these exploit a notion of ‘guarded intensionality’, in that they are only applicable when you already know what properties you are interested in. They thus essentially act as schemas for first-order rules. If we only use them backwards, in situations where we know what properties we are interested in, they can be applied in a fairly controlled way, and hence do not introduce wild combinatorial problems. This is not the only kind of intensional rule that we need, but it does cover a substantial number of interesting cases. The theorem prover described in (Ramsay, 2001) can cope with more general intensional rules, but guarded rules of this kind can be dealt with more efficiently than general rules, and they are particularly useful for axiomatising the phenomena that interest us. 5 Paraphrases and other lexical relations It is clear that we need to treat with a variety of relations between everyday terms. We will return, as an example, to (1b), repeated here as (5). (5) User: My son is very fat. Computer: OK User: Should he go swimming. Computer: Yes, because swimming is a form of exercise, and exercise is good for people who are overweight. The computer’s a</context>
</contexts>
<marker>Ramsay, 2001</marker>
<rawString>A. M. Ramsay (2001). ‘Theorem proving for untyped constructive λ-calculus: implementation and application’. Logic Journal of the Interest Group in Pure and Applied Logics 9(1):89–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Ramsay</author>
<author>D G Field</author>
</authors>
<title>Speech acts, epistemic planning and Grice’s maxims’. Logic and Computation 18:431–457.</title>
<date>2008</date>
<contexts>
<context position="3066" citStr="Ramsay &amp; Field, 2008" startWordPosition="510" endWordPosition="513"> to have a way of dealing with paraphrases. We will explore each of these issues in turn below. 2 Answering questions We will concentrate here on polar (YES/NO) questions. We also take the very simple view that when someone asks a polar question it is because they want to know whether the proposition encoded in the question is true or not. Someone who asks ‘Is it safe for me to eggs?’ wants to be told ‘Yes’ if it is and ‘No’ if it is not. We have explored the nature of WH-questions elsewhere (Ramsay &amp; Seville, 2001), and we have discussed situations where people use language in indirect ways (Ramsay &amp; Field, 2008), but for the moment just trying to answer polar questions will pose enough problems to keep us occupied. In order to answer such a question by saying ‘Yes’ you have to see whether ‘It is safe for the speaker to eat eggs’ follows from what you know about the speaker and your general knowledge. You cannot, however, say ‘No’ simply because your attempted proof that it is safe failed. If you failed to prove that it is safe you should then see whether you can prove that it is not. If, and only if, you can then you should say ‘no’. In general, then, answering a polar question may involve two attemp</context>
</contexts>
<marker>Ramsay, Field, 2008</marker>
<rawString>A. M. Ramsay &amp; D. G. Field (2008). ‘Speech acts, epistemic planning and Grice’s maxims’. Logic and Computation 18:431–457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Ramsay</author>
<author>H L Seville</author>
</authors>
<title>Relevant Answers to WH-questions’.</title>
<date>2001</date>
<booktitle>In 3rd International Conference on Inference in Computational Semantics,</booktitle>
<pages>73--86</pages>
<location>Siena.</location>
<contexts>
<context position="2966" citStr="Ramsay &amp; Seville, 2001" startWordPosition="494" endWordPosition="497">most no difference between ‘I am allergic to eggs’ and ‘I have an allergy to eggs’. You therefore have to have a way of dealing with paraphrases. We will explore each of these issues in turn below. 2 Answering questions We will concentrate here on polar (YES/NO) questions. We also take the very simple view that when someone asks a polar question it is because they want to know whether the proposition encoded in the question is true or not. Someone who asks ‘Is it safe for me to eggs?’ wants to be told ‘Yes’ if it is and ‘No’ if it is not. We have explored the nature of WH-questions elsewhere (Ramsay &amp; Seville, 2001), and we have discussed situations where people use language in indirect ways (Ramsay &amp; Field, 2008), but for the moment just trying to answer polar questions will pose enough problems to keep us occupied. In order to answer such a question by saying ‘Yes’ you have to see whether ‘It is safe for the speaker to eat eggs’ follows from what you know about the speaker and your general knowledge. You cannot, however, say ‘No’ simply because your attempted proof that it is safe failed. If you failed to prove that it is safe you should then see whether you can prove that it is not. If, and only if, y</context>
</contexts>
<marker>Ramsay, Seville, 2001</marker>
<rawString>A. M. Ramsay &amp; H. L. Seville (2001). ‘Relevant Answers to WH-questions’. In 3rd International Conference on Inference in Computational Semantics, pp. 73–86, Siena.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Procedural attachment’.</title>
<date>1990</date>
<booktitle>Semantic-Head-Driven Generation’. Computational Linguistics 16(1):30–42. L. Steels</booktitle>
<tech>Tech. rep., MIT.</tech>
<marker>Shieber, 1990</marker>
<rawString>S. M. Shieber, et al. (1990). ‘Semantic-Head-Driven Generation’. Computational Linguistics 16(1):30–42. L. Steels (1979). ‘Procedural attachment’. Tech. rep., MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Turner</author>
</authors>
<title>A Theory of Properties’.</title>
<date>1987</date>
<journal>Journal of Symbolic Logic</journal>
<volume>52</volume>
<issue>2</issue>
<pages>472</pages>
<contexts>
<context position="5111" citStr="Turner, 1987" startWordPosition="870" endWordPosition="871">at the representation scheme has to be highly expressive, since the relations involved are subtle and need to be represented very carefully. This leads us to a very classical architecture: we construct formal paraphrases (logical forms, LFs) of the user’s statements and questions, and we use a theorem prover to investigate the status of the propositions encoded in the user’s questions. We are, in particular, not following the pattern matching path taken in most ‘textual entailment’ systems, since the informal rules used in such systems are not guaranteed to be sound. We use ‘property theory’ (Turner, 1987; Chierchia &amp; Turner, 1987) as our formal language. There are very strong grounds for believing that natural language is inherently intensional (we will see some examples below, but the simple presence of verbs of propositional attitude is hard to cope with unless you allow some degree of intensionality). There are a number of logics which allow for a degree of intensionality–the typed logic used by Montague (Montague, 1974; Dowty et al., 1981), the notion of non-wellfounded sets (Aczel, 1988) used in situation semantics (Barwise &amp; Perry, 1983), Bealer (1989)’s intensional logic, and so on. We</context>
</contexts>
<marker>Turner, 1987</marker>
<rawString>R. Turner (1987). ‘A Theory of Properties’. Journal of Symbolic Logic 52(2):455– 472.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J van Genabith</author>
<author>R Crouch</author>
</authors>
<title>How to glue a donkey to an f-structure’. In</title>
<date>1997</date>
<booktitle>2nd International Workshop on Computational Semantics,</booktitle>
<pages>52--65</pages>
<editor>H. C. Bunt, L. Kievit, R. Muskens, &amp; M. Verlinden (eds.),</editor>
<institution>University of Tilburg.</institution>
<marker>van Genabith, Crouch, 1997</marker>
<rawString>J. van Genabith &amp; R. Crouch (1997). ‘How to glue a donkey to an f-structure’. In H. C. Bunt, L. Kievit, R. Muskens, &amp; M. Verlinden (eds.), 2nd International Workshop on Computational Semantics, pp. 52–65, University of Tilburg. Appendix: commonsense rules (8) a. eating P will make X ill if X is allergic to P. b. exercise is good for X if X is overweight. c. swimming is good for X if exercise is good for X. d. walking is good for X if exercise is good for X. e. eating fruit which contains vitamin C is good for X if X has scurvy. f. X eats P if X eats something which contains P.</rawString>
</citation>
<citation valid="false">
<authors>
<author>g</author>
</authors>
<title>X is dangerous for Y if X will make Y ill.</title>
<marker>g, </marker>
<rawString>g. X is dangerous for Y if X will make Y ill.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>