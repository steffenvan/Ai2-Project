<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002665">
<title confidence="0.837289">
SENSEVAL-2 Japanese Translation Task
</title>
<author confidence="0.984558">
Sadao Kurohashi
</author>
<affiliation confidence="0.995549">
University of Tokyo
</affiliation>
<email confidence="0.692685">
kurakc.t.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.971561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922416666667">
This paper reports an overview of SENSEVAL-2
Japanese translation task. In this task, word
senses are defined according to translation dis-
tinction. A translation Memory (TM) was
constructed, which contains, for each Japanese
head word, a list of typical Japanese expressions
and their English translations. For each target
word instance, a TM record best approximating
that usage had to be submitted. Alternatively,
submission could take the form of actual target
word translations. 9 systems from 7 organiza-
tions participated in the task.
</bodyText>
<sectionHeader confidence="0.993778" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969906976744">
In written texts, words which have multiple
senses can be classified into two categories;
homonyms and polysemous words. Generally
speaking, while homonymy sense distinction is
quite clear, polysemy sense distinction is very
subtle and hard. English texts contain many
homonyms. On the other hand, Japanese texts
in which most content words are written by
ideograms rarely contain homonyms. That is,
the main target in Japanese WSD is polysemy,
which makes Japanese WSD task setup very
hard. What sense distinction of polysemous
words is reasonable and effective heavily de-
pends on how to use it, that is, an application
of WSD.
Considering such a situation, in addition to
the ordinary dictionary task we organized an-
other task for Japanese, a translation task, in
which word sense is defined according to trans-
lation distinction. Here, we set up the task as-
suming the example-based machine translation
paradigm (Nagao, 1981). That is, first, a trans-
lation memory (TM) is constructed which con-
tains, for each Japanese head word, a list of typ-
ical Japanese expressions (phrases/sentences)
involving the head word and an English trans-
lation for each (Figure 1). We call a pair of
Japanese and English expressions in the TM as
a TM record. Given an evaluation document
containing a target word, participants have to
submit the TM record best approximating that
usage.
Alternatively, submissions can take the form
of actual target word translations, or transla-
tions of phrases or sentences including each tar-
get word. This allows existing rule-based ma-
chine translation (MT) systems to participate
in the task, and we can compare TM based sys-
tems with existing MT systems.
For evaluation, we distributed newspaper ar-
ticles. The number of target words was 40, and
30 instances of each target word were provided,
making for a total of 1,200 instances.
</bodyText>
<sectionHeader confidence="0.898786" genericHeader="method">
2 Construction of Translation
Memory
</sectionHeader>
<bodyText confidence="0.9979785">
The translation memory (TM) was constructed
in two steps:
</bodyText>
<listItem confidence="0.9696255">
1. By referring to the KWIC (Key Word
In Context) of a target word, its typical
Japanese expressions are picked up by lex-
icographers.
2. The Japanese expressions are translated by
a translation company.
</listItem>
<bodyText confidence="0.868506333333333">
KWIC was made from the nine years vol-
ume of Mainichi Newspaper corpus. They are
morphologically analyzed and segmented into
phrase sequences, and then the 100 most fre-
quent phrase uni-grams, hi-grams (two types;
the target word is in the first phrase or the sec-
ond phrase) and tri-grams (the target word is
in the middle phrase) are provided to lexicogra-
phers (Figure 2).
</bodyText>
<page confidence="0.997318">
37
</page>
<figure confidence="0.882133">
ISS muri
</figure>
<figureCaption confidence="0.997133">
Figure 1: An example of Translation Memory.
</figureCaption>
<table confidence="0.957454625">
Phrase nn-gram Phrase bi-gram Phrase tri-gram
597 ,MlitS 151 ,,„F11,1 tsL). 19 Li
7 LT_ „„ gk.
551 ,WiNkl 138 14 L-r 6 .*&amp;560)ift
416 ;l) 106 ;W&apos; 0 13 5 „,,111kGzia
413 101 ;I.ffl 10 :056 0) ;1,1011 5 &lt; t ,,„ga teCO 0
403 67 ,,, J110) ts 1.) 10 L-Ct 5 INZU „
351 56 ;i::,fgki 6..1 9 &apos;5 0A1 4 U-Ct tVi)0
</table>
<figureCaption confidence="0.967475">
Figure 2: An example of KWIC (numbers indicate phrase frequency).
</figureCaption>
<figure confidence="0.983051125">
IMP U„9fIlt-,-:
-4&apos;71:10it*Ic: it „31.k16
RkIPEZ
,J110)fsti)M
„.:51Et6
1,3NtSI6
,MNtS3._q L)kg
„ C_,■11:1Vg1Z
</figure>
<bodyText confidence="0.995075181818182">
It is impossible to participate.
It is impossible to make use of the library in this hour.
This bill is hard to pass.
It is no wonder he got angry.
the most natural way
to work too much
unreasonable demand
passing by force
to commit a forced double suicide
The lexicographers pick up a typical expres-
sion of the target word from the KWIC. If its
sense is context-independently clear, the expres-
sion is adopted as it is. If its sense is not clear,
some pre/post expressions are supplemented by
referring original sentences in the newspaper
corpus.
Then, we asked a translation company to
translate the Japanese expressions. As a re-
sult, a TM containing 320 head words and 6920
records was constructed (one head word has
21.6 records on average). The average number
of words of a Japanese expression is 4.5.
</bodyText>
<sectionHeader confidence="0.7333925" genericHeader="method">
3 Gold Standard Data and the
Evaluation of Translations
</sectionHeader>
<bodyText confidence="0.999531037037037">
As a gold standard data of the task, 40 target
words were chosen out of 320 TM words. Con-
sidering the possible comparison of the trans-
lation task and the dictionary task, 40 target
words were fully overlapped with 100 target
words of the dictionary task.
In the Japanese dictionary task, target words
are classified into three categories according
to the difficulty (difficult, intermediate, easy),
based on the entropy of word sense distri-
bution in the training data of the dictionary
task(Shirai, 2001). 40 target words of the tram
lation task consists of 20 nouns and 20 verbs:
difficult nouns and verbs, 10 intermediate nom
and verbs, and 5 easy nouns and verbs.
For each target word, 30 instances were ch(
sen from Mainichi Newspaper corpus (in tot,
1,200 instances) and they are also overlappE
with the dictionary task. Since the dictionai
task uses 100 instances for each target won
the translation task used 1st, 4th, 7th, ... 90t
instances of the dictionary task.
As a gold standard data, zero or more ai
propriate TM records were assigned to each ii
stance by the same translation company. AI
propriate TM records were classified into th
following three classes:
</bodyText>
<listItem confidence="0.7464008">
0 : A TM record which can be used t
translate the instance. POS, tense, plura
singular, and subtle nuance do not necet
sarily match.
0 : If the instance is considered alone, th
</listItem>
<bodyText confidence="0.87355">
English translation is correct, but usin
the TM record in the given context is nc
so good, for example, making very round
about translation.
</bodyText>
<page confidence="0.996158">
38
</page>
<bodyText confidence="0.999959705882353">
: If the instance is considered alone, the
English translation is correct, but using the
TM record in the given context is inappro-
priate.
Out of 1,200 instances, 34 instances (2.8%)
were assigned no TM records (there was no ap-
propriate TM record). To one instance, on aver-
age, 6.6 records were assigned as 0, 1.4 records
as 0, and 0.1 records as A, in total 8.1 records.
If a system chooses a TM record randomly as
an answer, the accuracy becomes 36.8% in case
that all of 0, 0 and A records are regarded
as correct, and 29.0% in case that only 0 is re-
garded as correct (they are the baseline scores
used in the next section).
In the gold standard data construction, 90
instances (9 words x 10 instances) were dealt
with by two annotators doubly, and then their
agreement were checked. For each instance one
record is chosen randomly from annotator B&apos;s
answers, and it was checked whether it is con-
tained in annotator A&apos;s answers (annotator A
made the whole gold standard data). The agree-
ment was 86.6% in case that all of 0, 0 and
A records are regarded as correct, and 80.9% in
case that only 0 is regarded as correct.
In the case that the submission is in the
form of translation data, translation experts
(the same company as constructed the TM and
the gold standard data) were asked to rank the
supplied translation 0, 0 or X. This evalua-
tion does not pay attention to the total transla-
tion, but just the appropriateness of the target
instance translation.
</bodyText>
<sectionHeader confidence="0.903488" genericHeader="method">
4 Result
</sectionHeader>
<bodyText confidence="0.43910925">
In the Japanese translation task, 9 systems from
7 organizations submitted the answers. The
characteristics of the systems are summarized
as follows:
</bodyText>
<listItem confidence="0.96751">
• AnonymX, AnonymY
Commercial, rule-based MT systems.
• CRL-NYU (Communications Research
Laboratory ,Sz New York Univ.)
</listItem>
<bodyText confidence="0.999238333333333">
TM records are classified according to
the English head word, and each cluster
is supplemented by several corpora. The
system returns a TM record when the
similarity between a TM record and an
input sentence is very high. Otherwise, it
returns the English head word of the most
similar cluster by using several machine
learning techniques.
</bodyText>
<listItem confidence="0.989635">
• Ibaraki (Ibaraki Univ.)
</listItem>
<bodyText confidence="0.999769666666667">
A training data was constructed manually
from newspaper articles, 170 instances for
each target word. Features were collected
in 7-word window around the target word,
and decision list method was used for learn-
ing.
</bodyText>
<listItem confidence="0.970809">
• Stanford-Titech1 (Stanford Univ. Sz Tokyo
Institute of Technology)
</listItem>
<bodyText confidence="0.9001072">
The system selects the appropriate TM
record based on the character-bigram-
based Dice&apos;s coefficient. It also utilized the
context of the other target word instances
in the evaluation text.
</bodyText>
<listItem confidence="0.961551">
• AnonymZ
</listItem>
<bodyText confidence="0.877181">
A sentence (TM records for learning, and
an input for testing) is morphologically an-
alyzed and converted into a semantic tag
sequence, and maximum entropy method
was used for learning.
</bodyText>
<listItem confidence="0.962099">
• ATR
</listItem>
<bodyText confidence="0.999897">
The system selects the most similar TM
record based on the cosine similarity be-
tween context vectors, which were con-
structed from semantic features and syn-
tactic relations of neighboring words of the
target word.
</bodyText>
<listItem confidence="0.991057">
• Kyoto (Kyoto Univ.)
</listItem>
<bodyText confidence="0.996877333333333">
The system selects the most similar
TM record by bottom-up, shared-memory
based matching algorithm.
</bodyText>
<listItem confidence="0.9642215">
• Stanford-Titech2 (Stanford Univ. &amp; Tokyo
Institute of Technology)
</listItem>
<bodyText confidence="0.999849181818182">
The system selects the appropriate TM
record based on the case-frame-based sim-
ilarity, using NTT Goi-Taikei thesaurus.
The results of all systems are shown in Fig-
ure 3. The left bar charts indicate the accuracy
based on the lenient evaluation (0, 0 and A
in TM selection and 0 and 0 in MT are re-
garded as correct); the right bar charts indicate
the accuracy based on the strict evaluation (0
is only regarded as correct both in TM selection
and MT). Note that since the TM does not have
</bodyText>
<page confidence="0.995631">
39
</page>
<figure confidence="0.881059">
0 Lenient evaluation III Strict evaluation)
</figure>
<figureCaption confidence="0.969678">
Figure 3: Result of the Japanese translation
task.
</figureCaption>
<figure confidence="0.9974056">
10 Noun • Verb I
e e
e 40. go&apos;
-4A ,e
e
</figure>
<figureCaption confidence="0.999951">
Figure 4: Scores for nouns and verbs.
</figureCaption>
<bodyText confidence="0.991679181818182">
a hierarchical structure, there is no evaluation
options such as fine, coarse, and mixed.
Figure 4 shows scores for nouns and verbs
separately, and Figure 5 shows scores for dif-
ficult/intermediate/easy words. Both of them
were evaluated by the lenient criteria.
In these figures, &amp;quot;Agreement&amp;quot; and &amp;quot;Baseline&amp;quot;
were as described in the previous section. When
the system judges that there is no appropri-
ate TM record for an instance, it can return
&amp;quot;UNASSIGNABLE&amp;quot;. In that case, if there is
no appropriate TM record assigned in the gold
standard data, the answer is regarded as cor-
rect.
Among TM selection systems, systems using
some extra learning data outperformed other
systems just using the TM. The comparison be-
tween TM selection systems and MT systems
is not easy, but the result indicates the effec-
tiveness of the accumulated know-how of MT
systems. However, the performance of the best
TM selection system is not so different from MT
</bodyText>
<figure confidence="0.506188">
I0 Difficult • Interrnidiate • Easy
</figure>
<figureCaption confidence="0.999343">
Figure 5: Scores for difficulty classes.
</figureCaption>
<bodyText confidence="0.970914">
systems, which indicates the promising future oi
TM based techniques.
</bodyText>
<sectionHeader confidence="0.997955" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9997828">
This paper described an overview of SENSEVAL-
2 Japanese translation task. The data used it
this task are available at SENSEVAL-2 web site
We hope this valuable data helps improve WSE
and MT systems.
</bodyText>
<sectionHeader confidence="0.966161" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999568222222222">
I wish to express my gratitude to Mainich
Newspapers for providing articles. I would alsc
like to thank Prof. Takenobu Tokunaga (Tokyc
Institute of Technology) and Prof. Kiyoaki Shi-
rai (JAIST) and Dr. Kiyotaka Uchimoto (CRL)
for their valuable advise about task organiza-
tion, Yuiko Igura (Kyoto Univ.) and Intet
Group Corp. for data construction, and all par-
ticipants to the task.
</bodyText>
<sectionHeader confidence="0.998282" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.978998">
Makoto Nagao. 1981. A framework of mechan-
ical translation between Japanease and En-
glish by analogy priciple. In Proc. of the In-
ternational NATO Symposium on Artificia
and Human Intelligence.
Kiyoaki Shirai. 2001. SENSEVAL-2 Japanese
dictionary task. In Proceedings of thf
SENSEVAL-2 Workshop.
</reference>
<figure confidence="0.980912214285714">
100
00
00
70
es
50
40
30
20
70
4&lt;&apos; 64&apos; .e e
„
04Y
41
</figure>
<page confidence="0.964347">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.640954">
<title confidence="0.821754">SENSEVAL-2 Japanese Translation Task</title>
<author confidence="0.696523">Sadao</author>
<affiliation confidence="0.998383">University of Tokyo</affiliation>
<email confidence="0.975485">kurakc.t.u-tokyo.ac.jp</email>
<abstract confidence="0.997513230769231">This paper reports an overview of SENSEVAL-2 Japanese translation task. In this task, word senses are defined according to translation distinction. A translation Memory (TM) was constructed, which contains, for each Japanese head word, a list of typical Japanese expressions and their English translations. For each target word instance, a TM record best approximating that usage had to be submitted. Alternatively, submission could take the form of actual target word translations. 9 systems from 7 organizations participated in the task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Makoto Nagao</author>
</authors>
<title>A framework of mechanical translation between Japanease and English by analogy priciple.</title>
<date>1981</date>
<booktitle>In Proc. of the International NATO Symposium on Artificia and Human Intelligence.</booktitle>
<contexts>
<context position="1586" citStr="Nagao, 1981" startWordPosition="240" endWordPosition="241">n which most content words are written by ideograms rarely contain homonyms. That is, the main target in Japanese WSD is polysemy, which makes Japanese WSD task setup very hard. What sense distinction of polysemous words is reasonable and effective heavily depends on how to use it, that is, an application of WSD. Considering such a situation, in addition to the ordinary dictionary task we organized another task for Japanese, a translation task, in which word sense is defined according to translation distinction. Here, we set up the task assuming the example-based machine translation paradigm (Nagao, 1981). That is, first, a translation memory (TM) is constructed which contains, for each Japanese head word, a list of typical Japanese expressions (phrases/sentences) involving the head word and an English translation for each (Figure 1). We call a pair of Japanese and English expressions in the TM as a TM record. Given an evaluation document containing a target word, participants have to submit the TM record best approximating that usage. Alternatively, submissions can take the form of actual target word translations, or translations of phrases or sentences including each target word. This allows</context>
</contexts>
<marker>Nagao, 1981</marker>
<rawString>Makoto Nagao. 1981. A framework of mechanical translation between Japanease and English by analogy priciple. In Proc. of the International NATO Symposium on Artificia and Human Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoaki Shirai</author>
</authors>
<title>SENSEVAL-2 Japanese dictionary task.</title>
<date>2001</date>
<booktitle>In Proceedings of thf SENSEVAL-2 Workshop.</booktitle>
<contexts>
<context position="5078" citStr="Shirai, 2001" startWordPosition="838" endWordPosition="839">age number of words of a Japanese expression is 4.5. 3 Gold Standard Data and the Evaluation of Translations As a gold standard data of the task, 40 target words were chosen out of 320 TM words. Considering the possible comparison of the translation task and the dictionary task, 40 target words were fully overlapped with 100 target words of the dictionary task. In the Japanese dictionary task, target words are classified into three categories according to the difficulty (difficult, intermediate, easy), based on the entropy of word sense distribution in the training data of the dictionary task(Shirai, 2001). 40 target words of the tram lation task consists of 20 nouns and 20 verbs: difficult nouns and verbs, 10 intermediate nom and verbs, and 5 easy nouns and verbs. For each target word, 30 instances were ch( sen from Mainichi Newspaper corpus (in tot, 1,200 instances) and they are also overlappE with the dictionary task. Since the dictionai task uses 100 instances for each target won the translation task used 1st, 4th, 7th, ... 90t instances of the dictionary task. As a gold standard data, zero or more ai propriate TM records were assigned to each ii stance by the same translation company. AI p</context>
</contexts>
<marker>Shirai, 2001</marker>
<rawString>Kiyoaki Shirai. 2001. SENSEVAL-2 Japanese dictionary task. In Proceedings of thf SENSEVAL-2 Workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>