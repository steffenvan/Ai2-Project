<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059307">
<title confidence="0.995416">
Statistical Thesaurus Construction for a Morphologically Rich Language
</title>
<author confidence="0.996401">
Chaya Liebeskind, Ido Dagan and Jonathan Schler
</author>
<affiliation confidence="0.990234">
Computer Science Department
Bar-Ilan University
</affiliation>
<address confidence="0.787751">
Ramat-Gan, Israel
</address>
<email confidence="0.996483">
liebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com
</email>
<sectionHeader confidence="0.995874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9863666">
Corpus-based thesaurus construction for Mor-
phologically Rich Languages (MRL) is a com-
plex task, due to the morphological variability
of MRL. In this paper we explore alternative
term representations, complemented by cluster-
ing of morphological variants. We introduce a
generic algorithmic scheme for thesaurus con-
struction in MRL, and demonstrate the empiri-
cal benefit of our methodology for a Hebrew
thesaurus.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996522954545454">
Corpus-based thesaurus construction has been an
active research area (Grefenstette, 1994; Curran
and Moens, 2002; Kilgarriff, 2003; Rychly and
Kilgarriff, 2007). Typically, two statistical ap-
proaches for identifying semantic relationships
between words were investigated: first-order, co-
occurrence-based methods which assume that
words that occur frequently together are topically
related (Schutze and Pederson, 1997) and second-
order, distributional similarity methods (Hindle,
1990; Lin, 1998; Gasperin et al, 2001; Weeds and
Weir, 2003; Kotlerman et al., 2010), which suggest
that words occurring within similar contexts are
semantically similar (Harris, 1968).
While most prior work focused on English, we
are interested in applying these methods to MRL.
Such languages, Hebrew in our case, are character-
ized by highly productive morphology which may
produce as many as thousands of word forms for a
given root form.
Thesauri usually provide related terms for each
entry term (denoted target term). Since both target
</bodyText>
<page confidence="0.995515">
59
</page>
<bodyText confidence="0.999969466666667">
and related terms correspond to word lemmas, sta-
tistics collection from the corpus would be most
directly applied at the lemma level as well, using a
morphological analyzer and tagger (Linden and
Piitulainen, 2004; Peirsman et al., 2008; Rapp,
2009). However, due to the rich and challenging
morphology of MRL, such tools often have limited
performance. In our research, the accuracy of a
state-of-the-art modern Hebrew tagger on a cross
genre corpus was only about 60%.
Considering such limited performance of mor-
phological processing, we propose a schematic
methodology for generating a co-occurrence based
thesaurus in MRL. In particular, we propose and
investigate three options for term representation,
namely surface form, lemma and multiple lemmas,
supplemented with clustering of term variants.
While the default lemma representation is depend-
ent on tagger performance, the two other represen-
tations avoid choosing the right lemma for each
word occurrence. Instead, the multiple-lemma rep-
resentation assumes that the right analysis will ac-
cumulate enough statistical prominence throughout
the corpus, while the surface representation solves
morphological disambiguation &amp;quot;in retrospect&amp;quot;, by
clustering term variants at the end of the extraction
process. As the methodology provides a generic
scheme for exploring the alternative representation
levels, each corpus and language-specific tool set
might yield a different optimal configuration.
</bodyText>
<sectionHeader confidence="0.994634" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.97933125">
Thesauri usually contain thousands of entries,
termed here target terms. Each entry holds a list of
related terms, covering various semantic relations.
In this paper we assume that the list of target terms
</bodyText>
<note confidence="0.3245715">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 59–64,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997680625">
is given as input, and focus on the process of ex-
tracting a ranked list of candidate related terms
(termed candidate terms) for each target term. The
top ranked candidates may be further examined
(manually) by a lexicographer, who will select the
eventual related terms for the thesaurus entry.
Our methodology was applied for statistical
measures of first order similarity (word co-
occurrence). These statistics consider the number
of times each candidate term co-occurs with the
target term in the same document, relative to their
total frequencies in the corpus. Common co-
occurrence metrics are Dice coefficient (Smadja et
al, 1996), Pointwise Mutual Information (PMI)
(Church and Hanks, 1990) and log-likelihood test
(Dunning, 1993).
</bodyText>
<subsectionHeader confidence="0.974982">
2.1 Term Representation
</subsectionHeader>
<bodyText confidence="0.99897995">
Statistical extraction is affected by term
representation in the corpus. Usually, related terms
in a thesaurus are lemmas, which can be identified
by morphological disambiguation tools. However,
we present two other approaches for term
representation (either a target term or a candidate
related term), which are less dependent on
morphological processing.
Typically, a morphological analyzer produces
all possible analyses for a given token in the cor-
pus. Then, a Part Of Speech (POS) tagger selects
the most probable analysis and solves morphology
disambiguation. However, considering the poor
performance of the POS tagger on our corpus, we
distinguish between these two analysis levels.
Consequently, we examined three levels of term
representation: (i) Surface form (surface) (ii) Best
lemma, as indentified by a POS tagger (best), and
(iii) All possible lemmas, produced by a morpho-
logical analyzer (all).
</bodyText>
<subsectionHeader confidence="0.999685">
2.2 Algorithmic Scheme
</subsectionHeader>
<bodyText confidence="0.996878315789474">
We used the following algorithmic scheme for the-
saurus construction. Our input is a target term in
one of the possible term representations (surface,
best or all). For each target term we retrieve all the
documents in the corpus where the target term ap-
pears. Then, we define a set of candidate terms that
consists of all the terms that appear in all these
documents (this again for each of the three possible
term representations). Next, a co-occurrence score
between the target term and each of the candidates
is calculated. Then, candidates are sorted, and the
highest rated candidate terms are clustered into
lemma-oriented clusters. Finally, we rank the clus-
ters according to their members&apos; co-occurrence
scores and the highest rated clusters become relat-
ed terms in the thesaurus.
Figure 1 presents the algorithm’s pseudo code.
The notion rep(term) is used to describe the possi-
ble term representations and may be either surface,
best or all. In our experiments, when
rep(target_term)=best, the correct lemma was
manually assigned (assuming a lexicographer in-
volvement with each thesaurus entry in our set-
ting). While, when rep(word)=best, the most prob-
able lemma is assigned by the tagger (since there
are numerous candidates for each target term we
cannot resort the manual involvement for each of
them). The two choices for rep(term) are inde-
pendent, resulting in nine possible configurations
of the algorithm for representing both the target
term and the candidate terms. Thus, these 9 con-
figurations cover the space of possibilities for term
representation. Exploring all of them in a systemat-
ic manner would reveal the best configuration in a
particular setting.
Input: target term, corpus, a pair of values for
rep(target_term) and rep(word)
Output: clusters of related terms
</bodyText>
<figure confidence="0.960094833333333">
target_term F rep(target_term)
docs_list F search(target_term)
FOR doc IN docs_list
FOR word IN doc
add rep(word) to candidates
ENDFOR
ENDFOR
compute co-occurrence scores for all candidates
sort(candidates) by score
clusters F cluster(top(candidates))
rank(clusters)
related terms F top(clusters)
</figure>
<figureCaption confidence="0.999898">
Figure 1: Methodology implementation algorithm
</figureCaption>
<subsectionHeader confidence="0.999185">
2.3 Clustering
</subsectionHeader>
<bodyText confidence="0.999991">
The algorithm of Figure 1 suggests clustering the
extracted candidates before considering them for
the thesaurus. Clustering aims at grouping together
related terms with the same lemma into clusters,
using some measure of morphological equivalence.
Accordingly, an equivalence measure between re-
lated terms needs to be defined, and a clustering
</bodyText>
<page confidence="0.991162">
60
</page>
<bodyText confidence="0.999978791666667">
algorithm needs to be selected. Each obtained clus-
ter is intended to correspond to the lemma of a sin-
gle candidate term. Obviously, clustering is mostly
needed for surface-level representation, in order to
group all different inflections of the same lemma.
Yet, we note that it was also found necessary for
the lemma-level representations, because the tag-
ger often identifies slightly different lemmas for
the same term.
The equivalence measure is used for building a
graph representation of the related terms. We rep-
resented each term by a vertex and added an edge
between each pair of terms that were deemed
equivalent. We investigated alternative equiva-
lence measures for measuring the morphological
distance between two vertices in our graph. We
considered the string edit distance measure and
suggested two morphological-based equivalence
measures. The first measure, given two vertices&apos;
terms, extracts all possible lemmas for each term
and searches for an overlap of at least one lemma.
The second measure considers the most probable
lemma of the vertices&apos; terms and checks whether
these lemmas are equal. The probability of a lem-
ma was defined as the sum of probabilities for all
morphological analyses containing the lemma, us-
ing a morpho-lexical context-independent proba-
bilities approximation (Goldberg et al., 2008). The
clustering was done by finding the connected com-
ponents in our graph of terms using the JUNG1
implementation (WeakComponentVertexClusterer
algorithm with default parameters). The connected
components are expected to correspond to different
lemmas of terms. Hierarchical clustering methods
(Jain et al., 1999) were examined as well (Single-
link and Complete-link clustering), but they were
inferior.
After applying the clustering algorithm, we re-
ranked the clusters aiming to get the best clusters
at the top of clusters list. We investigated two scor-
ing approaches for cluster ranking; maximization
and averaging. The maximization approach assigns
the maximal score of the cluster members as the
cluster score. While the averaging approach as-
signs the average of the cluster members&apos; scores as
the cluster score. The score obtained by either of
the approaches may be scaled by the cluster length,
to account for the accumulative impact of all class
</bodyText>
<footnote confidence="0.83419">
1 http://jung.sourceforge.net/
</footnote>
<bodyText confidence="0.9835915">
members (corresponding to morphological variants
of the candidate term).
</bodyText>
<sectionHeader confidence="0.942267" genericHeader="method">
3 Case Study: Cross-genre Hebrew
Thesaurus
</sectionHeader>
<bodyText confidence="0.999977375">
Our research targets the construction of a cross
genre thesaurus for the Responsa project2. The
corpus includes questions posed to rabbis along
with their detailed rabbinic answers, consisting of
various genres and styles. It contains 76,710 arti-
cles and about 100 million word tokens, and was
used for previous IR and NLP research (Choueka,
1972; Fraenkel, 1976; Choueka et al., 1987; Kernel
et al, 2008).
Unfortunately, due to the different genres in the
Responsa corpus, available tools for Hebrew pro-
cessing perform poorly on this corpus. In a prelim-
inary experiment, the POS tagger (Adler and
Elhadad, 2006) accuracy on the Responsa Corpus
was less than 60%, while the accuracy of the same
tagger on modern Hebrew corpora is ~90% (Bar-
Haim et al., 2007).
For this project, we utilized the MILA Hebrew
Morphological Analyzer3 (Itai and Wintner, 2008;
Yona and Wintner, 2008) and the (Adler and
Elhadad 2006) POS tagger for lemma representa-
tion. The latter had two important characteristics:
The first is flexibility- This tagger allows adapting
the estimates of the prior (context-independent)
probability of each morphological analysis in an
unsupervised manner, from an unlabeled corpus of
the target domain (Goldberg et al., 2008). The se-
cond advantage is its mechanism for analyzing un-
known tokens (Adler et al., 2008). Since about
50% of the words in our corpora are unknown
(with respect to MILA&apos;s lexicon), such mechanism
is essential.
For statistics extraction, we used Lucene4. We
took the top 1000 documents retrieved for the tar-
get term and extracted candidate terms from them.
Dice coefficient was used as our co-occurrence
measure, most probable lemma was considered for
clustering equivalence, and clusters were ranked
based on maximization, where the maximal score
was multiplied by cluster size.
</bodyText>
<footnote confidence="0.98816675">
2 Corpus kindly provided - http://www.biu.ac.il/jh/Responsa/
3 http://mila.cs.technion.ac.il/mila/eng/tools_analysis.html
3 mila.cs.technionac
4 http://lucene.apache.org/
</footnote>
<page confidence="0.999441">
61
</page>
<sectionHeader confidence="0.999166" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997702">
4.1 Dataset and Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.999956761904762">
The results reported in this paper were obtained
from a sample of 108 randomly selected terms
from a list of 5000 terms, extracted from two pub-
licly available term lists: the University of Haifa’s
entry list5 and Hebrew Wikipedia entries6.
In our experiments, we compared the perfor-
mance of the alternative 9 configurations by four
commonly used IR measures: precision (P), rela-
tive recall (R), F1, and Average Precision (AP).
The scores were macro-averaged. We assumed that
our automatically-generated candidate terms will
be manually filtered, thus, recall becomes more
important than precision. Since we do not have any
pre-defined thesaurus, we evaluated the relative-
recall. Our relative-recall considered the number of
suitable related terms from the output of all meth-
ods as the full set of related terms. As our system
yielded a ranked sequence of related terms clusters,
we also considered their ranking order. Therefore,
we adopted the recall-oriented AP for ranking
(Voorhees and Harman, 1999).
</bodyText>
<subsectionHeader confidence="0.998573">
4.2 Annotation Scheme
</subsectionHeader>
<bodyText confidence="0.999971666666667">
The output of the statistical extraction is a ranked
list of clusters of candidate related terms. Since
manual annotation is expensive and time consum-
ing, we annotated for the gold standard the top 15
clusters constructed from the top 50 candidate
terms, for each target term. Then, an annotator
judged each of the clusters&apos; terms. A cluster was
considered as relevant if at least one of its terms
was judged relevant7.
</bodyText>
<subsectionHeader confidence="0.965889">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999878125">
Table 1 compares the performance of all nine term
representation configurations. Due to data sparse-
ness, the lemma-based representations of the target
term outperform its surface representation. How-
ever, the best results were obtained from candidate
representation at the surface level, which was
complemented by grouping term variants to lem-
mas in the clustering phase.
</bodyText>
<footnote confidence="0.99792475">
5 http://lib.haifa.ac.il/systems/ihp.html
6 http://he.wikipedia.org
7 This was justified by empirical results that found only a few
clusters with some terms judged positive and others negative
</footnote>
<table confidence="0.9993134375">
Candidate surface best All
Target
Surface R 36.59 29.37 26.68
P 24.29 21.09 18.71
F1 29.20 24.55 21.99
AP 20.87 15.83 14.13
Best R 46.70 39.88 36.97
lemma
P 25.03 23.08 20.94
F1 32.59 29.24 26.74
AP 26.84 20.86 19.32
All R 47.13 42.52 42.13
lemmas
P 23.72 22.47 21.23
F1 31.56 29.40 28.24
AP 27.86 22.99 21.14
</table>
<tableCaption confidence="0.999921">
Table 1: Performances of the nine configuratrions
</tableCaption>
<bodyText confidence="0.9998413">
Furthermore, we note that the target representa-
tion by all possible lemmas (all) yielded the best R
and AP scores, which we consider as most im-
portant for the thesaurus construction setting. The
improvement over the common default best lemma
representation, for both target and candidate, is
notable (7 points) and is statistically significant
according to the two-sided Wilcoxon signed-rank
test (Wilcoxon, 1945) at the 0.01 level for AP and
0.05 for R.
</bodyText>
<sectionHeader confidence="0.989289" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999929933333333">
We presented a methodological scheme for ex-
ploring alternative term representations in statisti-
cal thesaurus construction for MRL, complemented
by lemma-oriented clustering at the end of the pro-
cess. The scheme was investigated for a Hebrew
cross-genre corpus, but can be generically applied
in other settings to find the optimal configuration
in each case.
We plan to adopt our methodology to second
order distributional similarity methods as well. In
this case there is an additional dimension, namely
feature representation, whose representation level
should be explored as well. In addition, we plan to
extend our methods to deal with Multi Word Ex-
pressions (MWE).
</bodyText>
<sectionHeader confidence="0.998311" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.945259666666667">
This work was partially supported by the
PASCAL-2 Network of Excellence of the Europe-
an Community FP7-ICT-2007-1-216886.
</bodyText>
<page confidence="0.998915">
62
</page>
<sectionHeader confidence="0.989824" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994508510638298">
Adler Meni and Michael Elhadad. 2006. An Unsuper-
vised Morpheme-Based HMM for Hebrew Morpho-
logical Disambiguation, in Proceedings of COLING-
ACL, Sydney, Australia.
Adler Meni, Yoav Goldberg, David Gabay and Michael
Elhadad. 2008. Unsupervised Lexicon-Based Resolu-
tion of Unknown Words for Full Morphological
Analysis, in Proceedings of ACL.
Bar-Haim Roy, Khalil Sima&apos;an, and Yoad Winter. 2007.
Part-of-speech tagging of Modern Hebrew text. Nat-
ural Language Engineering, 14(02):223.251.
Choueka, Yaacov. 1972. Fast searching and retrieval
techniques for large dictionaries and concordances.
Hebrew Computational Linguistics, 6:12–32, July.
Choueka, Y., A.S. Fraenkel, S.T. Klein and E. Segal.
1987. Improved techniques for processing queries in
full-text systems. Proceedings of the 10th annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval.
Church, K. W., and Hanks, P. 1990. Word association
norms, mutual information and lexicography. Com-
putational Linguistics 16(1): 22–29.
Curran, James R. and Marc Moens. 2002. Improve-
ments in automatic thesaurus extraction. In Proceed-
ings of the ACL-SIGLEX Workshop on Unsupervised
Lexical Acquisition, pages 59–67, Philadelphia, PA.
Dunning, T.E. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics 19, 61–74 (1993).
Fraenkel, Aviezri S. 1976. All about the Responsa re-
trieval project – what you always wanted to know but
were afraid to ask. Jurimetrics Journal, 16(3):149–
156, Spring.
Gasperin, C., Gamallo, P., Agustini, A., Lopes, G., and
de Lima, V. 2001. Using syntactic contexts for meas-
uring word similarity. In the Workshop on Semantic
Knowledge Acquisition and Categorisation (ESSLI
2001), Helsinki, Finland.
Goldberg Yoav, Meni Adler and Michael Elhadad,
2008. EM Can Find Pretty Good HMM POS-Taggers
(When Given a Good Start), in Proceedings of ACL.
Grefenstette, G. 1994. Explorations in Automatic The-
saurus Construction. Kluwer Academic Publishers,
Boston, USA
Harris, Zelig S. 1968. Mathematical Structures of Lan-
guage. John Wiley, New York.
Hindle, D. 1990. Noun classification from predicate
argument structures. In Proceedings of ACL.
Itai Alon and Shuly Wintner. 2008. Language Re-
sources for Hebrew. Language Resources and Evalu-
ation 42(1):75-98, March 2008.
Jain, A. K., M. N. Murty, P. J. Flynn. 1999. Data Clus-
tering: A Review. ACM Computing Surveys
31(3):264-323.
Kerner Yaakov HaCohen, Ariel Kass, Ariel Peretz.
2008. Combined One Sense Disambiguation of Ab-
breviations. In Proceedings of ACL (Short Papers),
pp. 61-64.
Kilgarriff, Adam. 2003. Thesauruses for natural lan-
guage processing. In Proceedings of the Joint Con-
ference on Natural Language Processing and
Knowledge Engineering, pages 5–13, Beijing, China.
Kotlerman Lili, Dagan Ido, Szpektor Idan, and
Zhitomirsky-Geffet Maayan. 2010. Directional Dis-
tributional Similarity for Lexical Inference. Natural
Language Engineering, 16(4):359–389.
Linden Krister, and Jussi Olavi Piitulainen. 2004. Dis-
covering Synonyms and Other Related Words. In
Proceedings of COLING 2004 : CompuTerm 2004:
3rd International Workshop on Computational Ter-
minology, Pages 63-70, Geneva, Switzerland
Lin, D. 1998. Automatic retrieval and clustering of
similar words. In Proceedings of COLING-ACL.
Peirsman Yves, Kris Heylen, and Dirk Speelman. 2008.
Putting things in order. first and second order con-
texts models for the calculation of semantic similari-
ty. In Actes des 9i`emes Journ´ees internationales
d’Analyse statistique des Donn´ees Textuelles (JADT
2008), pages 907–916.
Rapp, R. 2009. The Automatic Generation of Thesauri
of Related Words for English, French, German, and
Russian, International Journal of Speech Technolo-
gy, 11, 3-4, 147-156.
Rychly, P. and Kilgarriff, A. 2007. An efficient algo-
rithm for building a distributional thesaurus (and oth-
er Sketch Engine developments). In Proceedings of
ACL-07, demo session. Prague, Czech Republic.
Schutze Hinrich and Jan 0. Pederson. 1997. A
cooccurrence-based thesaurus and two applications
to information retrieval. Information Processing
and Management, 33(3):307-318.
Smadja, F., McKeown, K.R., Hatzivassiloglou, V. 1996.
Translating collocations for bilingual lexicons: A sta-
tistical approach. Computational Linguistics 22, 1–38
</reference>
<page confidence="0.987176">
63
</page>
<reference confidence="0.998981357142857">
Voorhees E.M. and D. Harman. 1999. Overview of the
seventh text retrieval conference . In Proceedings of
the Seventh Text Retrieval 73 Conference, 1999.
NIST Special Publication. 58.
Weeds, J., and Weir, D. 2003. A general framework for
distributional similarity. In Proceedings of EMILP,
Sapporo, Japan.
Wilcoxon F. 1945. Individual comparisons by ranking
methods. Biometrics Bulletin, 1:80–83.
Yona Shlomo and Shuly Wintner. 2008. A Finite-State
Morphological Grammar of Hebrew. Iatural Lan-
guage Engineering 14(2):173-190, April 2008. Lan-
guage Resources and Evaluation 42(1):75-98, March
2008.
</reference>
<page confidence="0.999415">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.807180">
<title confidence="0.981064">Statistical Thesaurus Construction for a Morphologically Rich Language</title>
<author confidence="0.992258">Chaya Liebeskind</author>
<author confidence="0.992258">Ido Dagan</author>
<author confidence="0.992258">Jonathan</author>
<affiliation confidence="0.950856">Computer Science Bar-Ilan</affiliation>
<address confidence="0.99527">Ramat-Gan, Israel</address>
<abstract confidence="0.991879090909091">Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL. In this paper we explore alternative term representations, complemented by clustering of morphological variants. We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adler Meni</author>
<author>Michael Elhadad</author>
</authors>
<title>An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation,</title>
<date>2006</date>
<booktitle>in Proceedings of COLINGACL,</booktitle>
<location>Sydney, Australia.</location>
<marker>Meni, Elhadad, 2006</marker>
<rawString>Adler Meni and Michael Elhadad. 2006. An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation, in Proceedings of COLINGACL, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adler Meni</author>
<author>Yoav Goldberg</author>
<author>David Gabay</author>
<author>Michael Elhadad</author>
</authors>
<title>Unsupervised Lexicon-Based Resolution of Unknown Words for Full Morphological Analysis,</title>
<date>2008</date>
<booktitle>in Proceedings of ACL.</booktitle>
<marker>Meni, Goldberg, Gabay, Elhadad, 2008</marker>
<rawString>Adler Meni, Yoav Goldberg, David Gabay and Michael Elhadad. 2008. Unsupervised Lexicon-Based Resolution of Unknown Words for Full Morphological Analysis, in Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bar-Haim Roy</author>
<author>Khalil Sima&apos;an</author>
<author>Yoad Winter</author>
</authors>
<title>Part-of-speech tagging of Modern Hebrew text.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>02</issue>
<marker>Roy, Sima&apos;an, Winter, 2007</marker>
<rawString>Bar-Haim Roy, Khalil Sima&apos;an, and Yoad Winter. 2007. Part-of-speech tagging of Modern Hebrew text. Natural Language Engineering, 14(02):223.251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaacov Choueka</author>
</authors>
<title>Fast searching and retrieval techniques for large dictionaries and concordances. Hebrew Computational Linguistics,</title>
<date>1972</date>
<pages>6--12</pages>
<contexts>
<context position="10504" citStr="Choueka, 1972" startWordPosition="1563" endWordPosition="1564">ed by either of the approaches may be scaled by the cluster length, to account for the accumulative impact of all class 1 http://jung.sourceforge.net/ members (corresponding to morphological variants of the candidate term). 3 Case Study: Cross-genre Hebrew Thesaurus Our research targets the construction of a cross genre thesaurus for the Responsa project2. The corpus includes questions posed to rabbis along with their detailed rabbinic answers, consisting of various genres and styles. It contains 76,710 articles and about 100 million word tokens, and was used for previous IR and NLP research (Choueka, 1972; Fraenkel, 1976; Choueka et al., 1987; Kernel et al, 2008). Unfortunately, due to the different genres in the Responsa corpus, available tools for Hebrew processing perform poorly on this corpus. In a preliminary experiment, the POS tagger (Adler and Elhadad, 2006) accuracy on the Responsa Corpus was less than 60%, while the accuracy of the same tagger on modern Hebrew corpora is ~90% (BarHaim et al., 2007). For this project, we utilized the MILA Hebrew Morphological Analyzer3 (Itai and Wintner, 2008; Yona and Wintner, 2008) and the (Adler and Elhadad 2006) POS tagger for lemma representation</context>
</contexts>
<marker>Choueka, 1972</marker>
<rawString>Choueka, Yaacov. 1972. Fast searching and retrieval techniques for large dictionaries and concordances. Hebrew Computational Linguistics, 6:12–32, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
<author>A S Fraenkel</author>
<author>S T Klein</author>
<author>E Segal</author>
</authors>
<title>Improved techniques for processing queries in full-text systems.</title>
<date>1987</date>
<booktitle>Proceedings of the 10th annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<contexts>
<context position="10542" citStr="Choueka et al., 1987" startWordPosition="1567" endWordPosition="1570">may be scaled by the cluster length, to account for the accumulative impact of all class 1 http://jung.sourceforge.net/ members (corresponding to morphological variants of the candidate term). 3 Case Study: Cross-genre Hebrew Thesaurus Our research targets the construction of a cross genre thesaurus for the Responsa project2. The corpus includes questions posed to rabbis along with their detailed rabbinic answers, consisting of various genres and styles. It contains 76,710 articles and about 100 million word tokens, and was used for previous IR and NLP research (Choueka, 1972; Fraenkel, 1976; Choueka et al., 1987; Kernel et al, 2008). Unfortunately, due to the different genres in the Responsa corpus, available tools for Hebrew processing perform poorly on this corpus. In a preliminary experiment, the POS tagger (Adler and Elhadad, 2006) accuracy on the Responsa Corpus was less than 60%, while the accuracy of the same tagger on modern Hebrew corpora is ~90% (BarHaim et al., 2007). For this project, we utilized the MILA Hebrew Morphological Analyzer3 (Itai and Wintner, 2008; Yona and Wintner, 2008) and the (Adler and Elhadad 2006) POS tagger for lemma representation. The latter had two important charact</context>
</contexts>
<marker>Choueka, Fraenkel, Klein, Segal, 1987</marker>
<rawString>Choueka, Y., A.S. Fraenkel, S.T. Klein and E. Segal. 1987. Improved techniques for processing queries in full-text systems. Proceedings of the 10th annual international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="4233" citStr="Church and Hanks, 1990" startWordPosition="608" endWordPosition="611">of candidate related terms (termed candidate terms) for each target term. The top ranked candidates may be further examined (manually) by a lexicographer, who will select the eventual related terms for the thesaurus entry. Our methodology was applied for statistical measures of first order similarity (word cooccurrence). These statistics consider the number of times each candidate term co-occurs with the target term in the same document, relative to their total frequencies in the corpus. Common cooccurrence metrics are Dice coefficient (Smadja et al, 1996), Pointwise Mutual Information (PMI) (Church and Hanks, 1990) and log-likelihood test (Dunning, 1993). 2.1 Term Representation Statistical extraction is affected by term representation in the corpus. Usually, related terms in a thesaurus are lemmas, which can be identified by morphological disambiguation tools. However, we present two other approaches for term representation (either a target term or a candidate related term), which are less dependent on morphological processing. Typically, a morphological analyzer produces all possible analyses for a given token in the corpus. Then, a Part Of Speech (POS) tagger selects the most probable analysis and so</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K. W., and Hanks, P. 1990. Word association norms, mutual information and lexicography. Computational Linguistics 16(1): 22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Marc Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>59--67</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="791" citStr="Curran and Moens, 2002" startWordPosition="100" endWordPosition="103">mat-Gan, Israel liebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com Abstract Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL. In this paper we explore alternative term representations, complemented by clustering of morphological variants. We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>Curran, James R. and Marc Moens. 2002. Improvements in automatic thesaurus extraction. In Proceedings of the ACL-SIGLEX Workshop on Unsupervised Lexical Acquisition, pages 59–67, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T E Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>61--74</pages>
<contexts>
<context position="4273" citStr="Dunning, 1993" startWordPosition="615" endWordPosition="616">s) for each target term. The top ranked candidates may be further examined (manually) by a lexicographer, who will select the eventual related terms for the thesaurus entry. Our methodology was applied for statistical measures of first order similarity (word cooccurrence). These statistics consider the number of times each candidate term co-occurs with the target term in the same document, relative to their total frequencies in the corpus. Common cooccurrence metrics are Dice coefficient (Smadja et al, 1996), Pointwise Mutual Information (PMI) (Church and Hanks, 1990) and log-likelihood test (Dunning, 1993). 2.1 Term Representation Statistical extraction is affected by term representation in the corpus. Usually, related terms in a thesaurus are lemmas, which can be identified by morphological disambiguation tools. However, we present two other approaches for term representation (either a target term or a candidate related term), which are less dependent on morphological processing. Typically, a morphological analyzer produces all possible analyses for a given token in the corpus. Then, a Part Of Speech (POS) tagger selects the most probable analysis and solves morphology disambiguation. However,</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, T.E. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics 19, 61–74 (1993).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aviezri S Fraenkel</author>
</authors>
<title>All about the Responsa retrieval project – what you always wanted to know but were afraid to ask.</title>
<date>1976</date>
<journal>Jurimetrics Journal,</journal>
<volume>16</volume>
<issue>3</issue>
<pages>156</pages>
<publisher>Spring.</publisher>
<contexts>
<context position="10520" citStr="Fraenkel, 1976" startWordPosition="1565" endWordPosition="1566"> the approaches may be scaled by the cluster length, to account for the accumulative impact of all class 1 http://jung.sourceforge.net/ members (corresponding to morphological variants of the candidate term). 3 Case Study: Cross-genre Hebrew Thesaurus Our research targets the construction of a cross genre thesaurus for the Responsa project2. The corpus includes questions posed to rabbis along with their detailed rabbinic answers, consisting of various genres and styles. It contains 76,710 articles and about 100 million word tokens, and was used for previous IR and NLP research (Choueka, 1972; Fraenkel, 1976; Choueka et al., 1987; Kernel et al, 2008). Unfortunately, due to the different genres in the Responsa corpus, available tools for Hebrew processing perform poorly on this corpus. In a preliminary experiment, the POS tagger (Adler and Elhadad, 2006) accuracy on the Responsa Corpus was less than 60%, while the accuracy of the same tagger on modern Hebrew corpora is ~90% (BarHaim et al., 2007). For this project, we utilized the MILA Hebrew Morphological Analyzer3 (Itai and Wintner, 2008; Yona and Wintner, 2008) and the (Adler and Elhadad 2006) POS tagger for lemma representation. The latter had</context>
</contexts>
<marker>Fraenkel, 1976</marker>
<rawString>Fraenkel, Aviezri S. 1976. All about the Responsa retrieval project – what you always wanted to know but were afraid to ask. Jurimetrics Journal, 16(3):149– 156, Spring.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gasperin</author>
<author>P Gamallo</author>
<author>A Agustini</author>
<author>G Lopes</author>
<author>V de Lima</author>
</authors>
<title>Using syntactic contexts for measuring word similarity.</title>
<date>2001</date>
<booktitle>In the Workshop on Semantic Knowledge Acquisition and Categorisation (ESSLI</booktitle>
<location>Helsinki, Finland.</location>
<marker>Gasperin, Gamallo, Agustini, Lopes, de Lima, 2001</marker>
<rawString>Gasperin, C., Gamallo, P., Agustini, A., Lopes, G., and de Lima, V. 2001. Using syntactic contexts for measuring word similarity. In the Workshop on Semantic Knowledge Acquisition and Categorisation (ESSLI 2001), Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goldberg Yoav</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start),</title>
<date>2008</date>
<booktitle>in Proceedings of ACL.</booktitle>
<marker>Yoav, Adler, Elhadad, 2008</marker>
<rawString>Goldberg Yoav, Meni Adler and Michael Elhadad, 2008. EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start), in Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
</authors>
<title>Explorations in Automatic Thesaurus Construction.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston, USA</location>
<contexts>
<context position="767" citStr="Grefenstette, 1994" startWordPosition="98" endWordPosition="99">r-Ilan University Ramat-Gan, Israel liebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com Abstract Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL. In this paper we explore alternative term representations, complemented by clustering of morphological variants. We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work fo</context>
</contexts>
<marker>Grefenstette, 1994</marker>
<rawString>Grefenstette, G. 1994. Explorations in Automatic Thesaurus Construction. Kluwer Academic Publishers, Boston, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig S Harris</author>
</authors>
<title>Mathematical Structures of Language.</title>
<date>1968</date>
<publisher>John Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="1341" citStr="Harris, 1968" startWordPosition="175" endWordPosition="176">ctive research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in applying these methods to MRL. Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms for a given root form. Thesauri usually provide related terms for each entry term (denoted target term). Since both target 59 and related terms correspond to word lemmas, statistics collection from the corpus would be most directly applied at the lemma level as well, using a morphological analyzer and tagger (Linden and Piitulainen, 2004; Peirsman et al., 2008; R</context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Harris, Zelig S. 1968. Mathematical Structures of Language. John Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Noun classification from predicate argument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1161" citStr="Hindle, 1990" startWordPosition="148" endWordPosition="149">or thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in applying these methods to MRL. Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms for a given root form. Thesauri usually provide related terms for each entry term (denoted target term). Since both target 59 and related terms correspond to word lemmas, statistics col</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, D. 1990. Noun classification from predicate argument structures. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Itai Alon</author>
<author>Shuly Wintner</author>
</authors>
<title>Language Resources for Hebrew. Language Resources and Evaluation 42(1):75-98,</title>
<date>2008</date>
<marker>Alon, Wintner, 2008</marker>
<rawString>Itai Alon and Shuly Wintner. 2008. Language Resources for Hebrew. Language Resources and Evaluation 42(1):75-98, March 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Jain</author>
<author>M N Murty</author>
<author>P J Flynn</author>
</authors>
<title>Data Clustering: A Review.</title>
<date>1999</date>
<journal>ACM Computing Surveys</journal>
<pages>31--3</pages>
<contexts>
<context position="9371" citStr="Jain et al., 1999" startWordPosition="1386" endWordPosition="1389">the most probable lemma of the vertices&apos; terms and checks whether these lemmas are equal. The probability of a lemma was defined as the sum of probabilities for all morphological analyses containing the lemma, using a morpho-lexical context-independent probabilities approximation (Goldberg et al., 2008). The clustering was done by finding the connected components in our graph of terms using the JUNG1 implementation (WeakComponentVertexClusterer algorithm with default parameters). The connected components are expected to correspond to different lemmas of terms. Hierarchical clustering methods (Jain et al., 1999) were examined as well (Singlelink and Complete-link clustering), but they were inferior. After applying the clustering algorithm, we reranked the clusters aiming to get the best clusters at the top of clusters list. We investigated two scoring approaches for cluster ranking; maximization and averaging. The maximization approach assigns the maximal score of the cluster members as the cluster score. While the averaging approach assigns the average of the cluster members&apos; scores as the cluster score. The score obtained by either of the approaches may be scaled by the cluster length, to account f</context>
</contexts>
<marker>Jain, Murty, Flynn, 1999</marker>
<rawString>Jain, A. K., M. N. Murty, P. J. Flynn. 1999. Data Clustering: A Review. ACM Computing Surveys 31(3):264-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kerner Yaakov HaCohen</author>
<author>Ariel Kass</author>
<author>Ariel Peretz</author>
</authors>
<title>Combined One Sense Disambiguation of Abbreviations.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL (Short Papers),</booktitle>
<pages>61--64</pages>
<marker>HaCohen, Kass, Peretz, 2008</marker>
<rawString>Kerner Yaakov HaCohen, Ariel Kass, Ariel Peretz. 2008. Combined One Sense Disambiguation of Abbreviations. In Proceedings of ACL (Short Papers), pp. 61-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Thesauruses for natural language processing.</title>
<date>2003</date>
<booktitle>In Proceedings of the Joint Conference on Natural Language Processing and Knowledge Engineering,</booktitle>
<pages>5--13</pages>
<location>Beijing, China.</location>
<contexts>
<context position="809" citStr="Kilgarriff, 2003" startWordPosition="104" endWordPosition="105">a@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com Abstract Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL. In this paper we explore alternative term representations, complemented by clustering of morphological variants. We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in app</context>
</contexts>
<marker>Kilgarriff, 2003</marker>
<rawString>Kilgarriff, Adam. 2003. Thesauruses for natural language processing. In Proceedings of the Joint Conference on Natural Language Processing and Knowledge Engineering, pages 5–13, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotlerman Lili</author>
<author>Dagan Ido</author>
<author>Szpektor Idan</author>
<author>Zhitomirsky-Geffet Maayan</author>
</authors>
<title>Directional Distributional Similarity for Lexical Inference.</title>
<date>2010</date>
<journal>Natural Language Engineering,</journal>
<volume>16</volume>
<issue>4</issue>
<marker>Lili, Ido, Idan, Maayan, 2010</marker>
<rawString>Kotlerman Lili, Dagan Ido, Szpektor Idan, and Zhitomirsky-Geffet Maayan. 2010. Directional Distributional Similarity for Lexical Inference. Natural Language Engineering, 16(4):359–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linden Krister</author>
<author>Jussi Olavi Piitulainen</author>
</authors>
<title>Discovering Synonyms and Other Related Words.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING 2004 : CompuTerm 2004: 3rd International Workshop on Computational Terminology,</booktitle>
<pages>63--70</pages>
<location>Geneva, Switzerland</location>
<marker>Krister, Piitulainen, 2004</marker>
<rawString>Linden Krister, and Jussi Olavi Piitulainen. 2004. Discovering Synonyms and Other Related Words. In Proceedings of COLING 2004 : CompuTerm 2004: 3rd International Workshop on Computational Terminology, Pages 63-70, Geneva, Switzerland</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL.</booktitle>
<contexts>
<context position="1172" citStr="Lin, 1998" startWordPosition="150" endWordPosition="151">onstruction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in applying these methods to MRL. Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms for a given root form. Thesauri usually provide related terms for each entry term (denoted target term). Since both target 59 and related terms correspond to word lemmas, statistics collection fro</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, D. 1998. Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peirsman Yves</author>
<author>Kris Heylen</author>
<author>Dirk Speelman</author>
</authors>
<title>Putting things in order. first and second order contexts models for the calculation of semantic similarity.</title>
<date>2008</date>
<booktitle>In Actes des 9i`emes Journ´ees internationales d’Analyse statistique des Donn´ees Textuelles (JADT</booktitle>
<pages>907--916</pages>
<marker>Yves, Heylen, Speelman, 2008</marker>
<rawString>Peirsman Yves, Kris Heylen, and Dirk Speelman. 2008. Putting things in order. first and second order contexts models for the calculation of semantic similarity. In Actes des 9i`emes Journ´ees internationales d’Analyse statistique des Donn´ees Textuelles (JADT 2008), pages 907–916.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>The Automatic Generation of Thesauri of Related Words for English,</title>
<date>2009</date>
<journal>Russian, International Journal of Speech Technology,</journal>
<volume>11</volume>
<pages>3--4</pages>
<location>French, German, and</location>
<contexts>
<context position="1951" citStr="Rapp, 2009" startWordPosition="275" endWordPosition="276">). While most prior work focused on English, we are interested in applying these methods to MRL. Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms for a given root form. Thesauri usually provide related terms for each entry term (denoted target term). Since both target 59 and related terms correspond to word lemmas, statistics collection from the corpus would be most directly applied at the lemma level as well, using a morphological analyzer and tagger (Linden and Piitulainen, 2004; Peirsman et al., 2008; Rapp, 2009). However, due to the rich and challenging morphology of MRL, such tools often have limited performance. In our research, the accuracy of a state-of-the-art modern Hebrew tagger on a cross genre corpus was only about 60%. Considering such limited performance of morphological processing, we propose a schematic methodology for generating a co-occurrence based thesaurus in MRL. In particular, we propose and investigate three options for term representation, namely surface form, lemma and multiple lemmas, supplemented with clustering of term variants. While the default lemma representation is depe</context>
</contexts>
<marker>Rapp, 2009</marker>
<rawString>Rapp, R. 2009. The Automatic Generation of Thesauri of Related Words for English, French, German, and Russian, International Journal of Speech Technology, 11, 3-4, 147-156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rychly</author>
<author>A Kilgarriff</author>
</authors>
<title>An efficient algorithm for building a distributional thesaurus (and other Sketch Engine developments).</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-07, demo session.</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="839" citStr="Rychly and Kilgarriff, 2007" startWordPosition="106" endWordPosition="109">@cs.biu.ac.il, schler@gmail.com Abstract Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL. In this paper we explore alternative term representations, complemented by clustering of morphological variants. We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in applying these methods to MRL. Su</context>
</contexts>
<marker>Rychly, Kilgarriff, 2007</marker>
<rawString>Rychly, P. and Kilgarriff, A. 2007. An efficient algorithm for building a distributional thesaurus (and other Sketch Engine developments). In Proceedings of ACL-07, demo session. Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schutze Hinrich</author>
<author>Jan</author>
</authors>
<title>A cooccurrence-based thesaurus and two applications to information retrieval.</title>
<date>1997</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>33--3</pages>
<marker>Hinrich, Jan, 1997</marker>
<rawString>Schutze Hinrich and Jan 0. Pederson. 1997. A cooccurrence-based thesaurus and two applications to information retrieval. Information Processing and Management, 33(3):307-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
<author>K R McKeown</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<volume>22</volume>
<pages>1--38</pages>
<contexts>
<context position="4172" citStr="Smadja et al, 1996" startWordPosition="600" endWordPosition="603">ut, and focus on the process of extracting a ranked list of candidate related terms (termed candidate terms) for each target term. The top ranked candidates may be further examined (manually) by a lexicographer, who will select the eventual related terms for the thesaurus entry. Our methodology was applied for statistical measures of first order similarity (word cooccurrence). These statistics consider the number of times each candidate term co-occurs with the target term in the same document, relative to their total frequencies in the corpus. Common cooccurrence metrics are Dice coefficient (Smadja et al, 1996), Pointwise Mutual Information (PMI) (Church and Hanks, 1990) and log-likelihood test (Dunning, 1993). 2.1 Term Representation Statistical extraction is affected by term representation in the corpus. Usually, related terms in a thesaurus are lemmas, which can be identified by morphological disambiguation tools. However, we present two other approaches for term representation (either a target term or a candidate related term), which are less dependent on morphological processing. Typically, a morphological analyzer produces all possible analyses for a given token in the corpus. Then, a Part Of </context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Smadja, F., McKeown, K.R., Hatzivassiloglou, V. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational Linguistics 22, 1–38</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
<author>D Harman</author>
</authors>
<title>Overview of the seventh text retrieval conference .</title>
<date>1999</date>
<journal>NIST Special Publication.</journal>
<booktitle>In Proceedings of the Seventh Text Retrieval 73 Conference,</booktitle>
<volume>58</volume>
<contexts>
<context position="13199" citStr="Voorhees and Harman, 1999" startWordPosition="1971" endWordPosition="1974">ative recall (R), F1, and Average Precision (AP). The scores were macro-averaged. We assumed that our automatically-generated candidate terms will be manually filtered, thus, recall becomes more important than precision. Since we do not have any pre-defined thesaurus, we evaluated the relativerecall. Our relative-recall considered the number of suitable related terms from the output of all methods as the full set of related terms. As our system yielded a ranked sequence of related terms clusters, we also considered their ranking order. Therefore, we adopted the recall-oriented AP for ranking (Voorhees and Harman, 1999). 4.2 Annotation Scheme The output of the statistical extraction is a ranked list of clusters of candidate related terms. Since manual annotation is expensive and time consuming, we annotated for the gold standard the top 15 clusters constructed from the top 50 candidate terms, for each target term. Then, an annotator judged each of the clusters&apos; terms. A cluster was considered as relevant if at least one of its terms was judged relevant7. 4.3 Results Table 1 compares the performance of all nine term representation configurations. Due to data sparseness, the lemma-based representations of the </context>
</contexts>
<marker>Voorhees, Harman, 1999</marker>
<rawString>Voorhees E.M. and D. Harman. 1999. Overview of the seventh text retrieval conference . In Proceedings of the Seventh Text Retrieval 73 Conference, 1999. NIST Special Publication. 58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weeds</author>
<author>D Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of EMILP,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="1216" citStr="Weeds and Weir, 2003" startWordPosition="156" endWordPosition="159">te the empirical benefit of our methodology for a Hebrew thesaurus. 1 Introduction Corpus-based thesaurus construction has been an active research area (Grefenstette, 1994; Curran and Moens, 2002; Kilgarriff, 2003; Rychly and Kilgarriff, 2007). Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related (Schutze and Pederson, 1997) and secondorder, distributional similarity methods (Hindle, 1990; Lin, 1998; Gasperin et al, 2001; Weeds and Weir, 2003; Kotlerman et al., 2010), which suggest that words occurring within similar contexts are semantically similar (Harris, 1968). While most prior work focused on English, we are interested in applying these methods to MRL. Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms for a given root form. Thesauri usually provide related terms for each entry term (denoted target term). Since both target 59 and related terms correspond to word lemmas, statistics collection from the corpus would be most directly applied </context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>Weeds, J., and Weir, D. 2003. A general framework for distributional similarity. In Proceedings of EMILP, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wilcoxon</author>
</authors>
<title>Individual comparisons by ranking methods.</title>
<date>1945</date>
<journal>Biometrics Bulletin,</journal>
<pages>1--80</pages>
<contexts>
<context position="14992" citStr="Wilcoxon, 1945" startWordPosition="2257" endWordPosition="2258">5.03 23.08 20.94 F1 32.59 29.24 26.74 AP 26.84 20.86 19.32 All R 47.13 42.52 42.13 lemmas P 23.72 22.47 21.23 F1 31.56 29.40 28.24 AP 27.86 22.99 21.14 Table 1: Performances of the nine configuratrions Furthermore, we note that the target representation by all possible lemmas (all) yielded the best R and AP scores, which we consider as most important for the thesaurus construction setting. The improvement over the common default best lemma representation, for both target and candidate, is notable (7 points) and is statistically significant according to the two-sided Wilcoxon signed-rank test (Wilcoxon, 1945) at the 0.01 level for AP and 0.05 for R. 5 Conclusions and Future Work We presented a methodological scheme for exploring alternative term representations in statistical thesaurus construction for MRL, complemented by lemma-oriented clustering at the end of the process. The scheme was investigated for a Hebrew cross-genre corpus, but can be generically applied in other settings to find the optimal configuration in each case. We plan to adopt our methodology to second order distributional similarity methods as well. In this case there is an additional dimension, namely feature representation, </context>
</contexts>
<marker>Wilcoxon, 1945</marker>
<rawString>Wilcoxon F. 1945. Individual comparisons by ranking methods. Biometrics Bulletin, 1:80–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yona Shlomo</author>
<author>Shuly Wintner</author>
</authors>
<title>A Finite-State Morphological Grammar of Hebrew.</title>
<date>2008</date>
<journal>Iatural Language Engineering</journal>
<pages>14--2</pages>
<marker>Shlomo, Wintner, 2008</marker>
<rawString>Yona Shlomo and Shuly Wintner. 2008. A Finite-State Morphological Grammar of Hebrew. Iatural Language Engineering 14(2):173-190, April 2008. Language Resources and Evaluation 42(1):75-98, March 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>