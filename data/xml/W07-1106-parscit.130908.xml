<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.086280">
<title confidence="0.8817655">
Pulling their Weight: Exploiting Syntactic Forms for the Automatic
Identification of Idiomatic Expressions in Context
</title>
<author confidence="0.990322">
Paul Cook and Afsaneh Fazly and Suzanne Stevenson
</author>
<affiliation confidence="0.844378">
Department of Computer Science
University of Toronto
Toronto, Canada
</affiliation>
<email confidence="0.998983">
{pcook,afsaneh,suzanne}@cs.toronto.edu
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997638125">
Much work on idioms has focused on type
identification, i.e., determining whether a se-
quence of words can form an idiomatic ex-
pression. Since an idiom type often has a
literal interpretation as well, token classifi-
cation of potential idioms in context is criti-
cal for NLP. We explore the use of informa-
tive prior knowledge about the overall syn-
tactic behaviour of a potentially-idiomatic
expression (type-based knowledge) to de-
termine whether an instance of the expres-
sion is used idiomatically or literally (token-
based knowledge). We develop unsuper-
vised methods for the task, and show that
their performance is comparable to that of
state-of-the-art supervised techniques.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999247291666667">
Identification of multiword expressions (MWEs),
such as car park, make a decision, and kick the
bucket, is extremely important for accurate natural
language processing (NLP) (Sag et al., 2002). Most
MWEs need to be treated as single units of mean-
ing, e.g., make a decision roughly means “decide”.
Nonetheless, the components of an MWE can be
separated, making it hard for an NLP system to iden-
tify the expression as a whole. Many researchers
have recently developed methods for the automatic
acquisition of various properties of MWEs from cor-
pora (Lin, 1999; Krenn and Evert, 2001; Baldwin et
al., 2003; McCarthy et al., 2003; Venkatapathy and
Joshi, 2005; Villada Moir´on and Tiedemann, 2006;
Fazly and Stevenson, 2006). These studies look
into properties, such as the collocational behaviour
of MWEs, their semantic non-compositionality, and
their lexicosyntactic fixedness, in order to distin-
guish them from similar-on-the-surface literal com-
binations.
Most of these methods have been aimed at rec-
ognizing MWE types; less attention has been paid
to the identification of instances (tokens) of MWEs
in context. For example, most such techniques (if
successful) would identify make a face as a poten-
tial MWE. This expression is, however, ambiguous
between an idiom, as in The little girl made a funny
face at her mother, and a literal combination, as in
She made a face on the snowman using a carrot and
two buttons. Despite the common perception that
phrases that can be idioms are mainly used in their
idiomatic sense, our analysis of 60 idioms has shown
otherwise. We found that close to half of these id-
ioms also have a clear literal meaning; and of the ex-
pressions with a literal meaning, on average around
40% of their usages are literal. Distinguishing token
phrases as MWEs or literal combinations of words is
thus essential for NLP applications that require the
identification of multiword semantic units, such as
semantic parsing and machine translation.
Recent studies addressing MWE token classifi-
cation mainly perform the task as one of word
sense disambiguation, and draw on the local con-
text of an expression to disambiguate it. Such
techniques either do not use any information re-
garding the linguistic properties of MWEs (Birke
and Sarkar, 2006), or mainly focus on their non-
compositionality (Katz and Giesbrecht, 2006). Pre-
</bodyText>
<page confidence="0.993585">
41
</page>
<note confidence="0.784408">
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 41–48,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999963205882353">
vious work on the identification of MWE types,
however, has found other properties of MWEs, such
as their syntactic fixedness, to be relevant to their
identification (Evert et al., 2004; Fazly and Steven-
son, 2006). In this paper, we propose techniques that
draw on this property to classify individual tokens of
a potentially idiomatic phrase as literal or idiomatic.
We also put forward classification techniques that
combine such information with evidence from the
local context of an MWE.
We explore the hypothesis that informative prior
knowledge about the overall syntactic behaviour of
an idiomatic expression (type-based knowledge) can
be used to determine whether an instance of the
expression is used literally or idiomatically (token-
based knowledge). Based on this hypothesis, we de-
velop unsupervised methods for token classification,
and show that their performance is comparable to
that of a standard supervised method.
Many verbs can be combined with one or more of
their arguments to form MWEs (Cowie et al., 1983;
Fellbaum, 2002). Here, we focus on a broadly doc-
umented class of idiomatic MWEs that are formed
from the combination of a verb with a noun in its di-
rect object position, as in make a face. In the rest
of the paper, we refer to these verb+noun combi-
nations, which are potentially idiomatic, as VNCs.
In Section 2, we propose unsupervised methods that
classify a VNC token as an idiomatic or literal usage.
Section 3 describes our experimental setup, includ-
ing experimental expressions and their annotation.
In Section 4, we present a detailed discussion of our
results. Section 5 compares our work with similar
previous studies, and Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.969175" genericHeader="method">
2 Unsupervised Idiom Identification
</sectionHeader>
<bodyText confidence="0.9995655">
We first explain an important linguistic property at-
tributed to idioms—that is, their syntactic fixedness
(Section 2.1). We then propose unsupervised meth-
ods that draw on this property to automatically dis-
tinguish between idiomatic and literal usages of an
expression (Section 2.2).
</bodyText>
<subsectionHeader confidence="0.999021">
2.1 Syntactic Fixedness and Canonical Forms
</subsectionHeader>
<bodyText confidence="0.999984783783784">
Idioms tend to be somewhat fixed with respect to
the syntactic configurations in which they occur
(Nunberg et al., 1994). For example, pull one’s
weight tends to mainly appear in this form when
used idiomatically. Other forms of the expression,
such as pull the weights, typically are only used
with a literal meaning. In their work on automati-
cally identifying idiom types, Fazly and Stevenson
(2006)—henceforth FS06—show that an idiomatic
VNC tends to have one (or at most a small number
of) canonical form(s), which are its most preferred
syntactic patterns. The preferred patterns can vary
across different idiom types, and can involve a num-
ber of syntactic properties: the voice of the verb (ac-
tive or passive), the determiner introducing the noun
(the, one’s, etc.), and the number of the noun (singu-
lar or plural). For example, while pull one’s weight
has only one canonical form, holdfire and hold one’s
fire are two canonical forms of the same idiom, as
listed in an idiom dictionary (Seaton and Macaulay,
2002).
In our work, we assume that in most cases, id-
iomatic usages of an expression tend to occur in a
small number of canonical form(s) for that idiom.
We also assume that, in contrast, the literal usages
of an expression are less syntactically restricted, and
are expressed in a greater variety of patterns. Be-
cause of their relative unrestrictiveness, literal us-
ages may occur in a canonical idiomatic form for
that expression, but usages in a canonical form are
more likely to be idiomatic. Usages in alternative
syntactic patterns for the expression, which we refer
to as the non-canonical forms of the idiom, are more
likely to be literal. Drawing on these assumptions,
we develop three unsupervised methods that deter-
mine, for each VNC token in context, whether it has
an idiomatic or a literal interpretation.
</bodyText>
<subsectionHeader confidence="0.975861">
2.2 Statistical Methods
</subsectionHeader>
<bodyText confidence="0.999962833333333">
The following paragraphs elaborate on our proposed
methods for identifying the idiomatic and literal us-
ages of a VNC: the CForm method that uses knowl-
edge of canonical forms only, and two Diff methods
that draw on further contextual evidence as well. All
three methods draw on our assumptions described
above, that usages in the canonical form for an id-
iom are more likely to be idiomatic, and those in
other forms are more likely to be literal. Thus, for
all three methods, we need access to the canonical
form of the idiom. Since we want our token iden-
tification methods to be unsupervised, we adopt the
</bodyText>
<page confidence="0.998318">
42
</page>
<bodyText confidence="0.986421276595745">
unsupervised statistical method of FS06 for finding
canonical forms for an idiomatic VNC. This method
determines the canonical forms of an expression to
be those forms whose frequency is much higher than
the average frequency of all its forms.
CForm: The underlying assumption of this
method is that information about the canonical
form(s) of an idiom type is extremely informative
in classifying the meaning of its individual instances
(tokens) as literal or idiomatic. Our CForm classi-
fies a token as idiomatic if it occurs in the automat-
ically determined canonical form(s) for that expres-
sion, and as literal otherwise.
Diff: Our two Diff methods combine local con-
text information with knowledge about the canon-
ical forms of an idiom type to determine if its to-
ken usages are literal or idiomatic. In developing
these methods, we adopt a distributional approach
to meaning, where the meaning of an expression is
approximated by the words with which it co-occurs
(Firth, 1957). Although there may be fine-grained
differences in meaning across the idiomatic usages
of an expression, as well as across its literal usages,
we assume that the idiomatic and literal usages cor-
respond to two coarse-grained senses of the expres-
sion. Since we further assume these two groups
of usages will have more in common semantically
within each group than between the two groups, we
expect that literal and idiomatic usages of an ex-
pression will typically occur with different sets of
words. We will refer then to each of the literal and
idiomatic designations as a (coarse-grained) mean-
ing of the expression, while acknowledging that
each may have multiple fine-grained senses. Clearly,
the success of our method depends on the extent to
which these assumptions hold.
We estimate the meaning of a set of usages of an
expression e as a word frequency vector ve where
each dimension i of ve is the frequency with which
e co-occurs with word i across the usages of e. We
similarly estimate the meaning of a single token of
an expression t as a vector vt capturing that usage.
To determine if an instance of an expression is literal
or idiomatic, we compare its co-occurrence vector to
the co-occurrence vectors representing each of the
literal and idiomatic meanings of the expression. We
use a standard measure of distributional similarity,
cosine, to compare co-occurrence vectors.
In supervised approaches, such as that of Katz and
Giesbrecht (2006), co-occurrence vectors for literal
and idiomatic meanings are formed from manually-
annotated training data. Here, we propose unsuper-
vised methods for estimating these vectors. We use
one way of estimating the idiomatic meaning of an
expression, and two ways for estimating its literal
meaning, yielding two methods for token classifica-
tion.
Our first Diff method draws further on our expec-
tation that canonical forms are more likely idiomatic
usages, and non-canonical forms are more likely lit-
eral usages. We estimate the idiomatic meaning of
an expression by building a co-occurrence vector,
�vI-CF, for all uses of the expression in its auto-
matically determined canonical form(s). Since we
hypothesize that idiomatic usages of an expression
tend to occur in its canonical form, we expect these
co-occurrence vectors to be largely representative of
the idiomatic usage of the expression. We similarly
estimate the literal meaning by constructing a co-
occurrence vector, iL-NCF, of all uses of the expres-
sion in its non-canonical forms. We use the term
DiffI-CF,L-NCF to refer to this method.
Our second Diff method also uses the vector
�vI-CF to estimate the idiomatic meaning of an ex-
pression. However, this approach follows that of
Katz and Giesbrecht (2006) in assuming that literal
meanings are compositional. The literal meaning of
an expression is thus estimated by composing (sum-
ming and then normalizing) the co-occurrence vec-
tors for its component words. The resulting vec-
tor is referred to as vL-Comp, and this method as
DiffI-CF,L-Comp.
For both Diff methods, if the meaning of
an instance of an expression is determined to
be more similar to its idiomatic meaning (e.g.,
cosine (it, iI-CF) &gt; cosine (it, iL-NCF)), then
we label it as an idiomatic usage. Otherwise, it is
labeled as literal.1
1We also performed experiments using a KNN classifier
in which the co-occurrence vector for a token was compared
against the co-occurrence vectors for the canonical and non-
canonical forms of that expression, which were assumed to
be idiomatic and literal usages respectively. However, perfor-
mance was generally worse using this method.
</bodyText>
<page confidence="0.998926">
43
</page>
<bodyText confidence="0.9998738">
Note that all three of our proposed techniques for
token identification depend on how accurately the
canonical forms of an expression can be acquired.
FS06’s canonical form acquisition technique, which
we use here, works well if the idiomatic usage of
a VNC is sufficiently frequent compared to its lit-
eral usage. In our experiments, we examine the
performance of our proposed classification methods
for VNCs with different proportions of idiomatic-to-
literal usages.
</bodyText>
<sectionHeader confidence="0.999597" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.999965">
3.1 Experimental Expressions and Annotation
</subsectionHeader>
<bodyText confidence="0.99997765625">
We use data provided by FS06, which consists of a
list of VNCs and their canonical forms. From this
data, we discarded expressions whose frequency in
the British National Corpus2 (BNC) is lower than
20, in an effort to make sure that there would be lit-
eral and idiomatic usages of each expression. The
frequency cut-off further ensures an accurate esti-
mate of the vectors representing each of the lit-
eral and idiomatic meanings of the expression. We
also discarded expressions that were not found in at
least one of two dictionaries of idioms (Seaton and
Macaulay, 2002; Cowie et al., 1983). This process
resulted in the selection of 60 candidate expressions.
For each of these 60 expressions, 100 sentences
containing its usage were randomly selected from
the automatically parsed BNC (Collins, 1999), using
the automatic VNC identification method described
by FS06. For an expression which occurs less than
100 times in the BNC, all of its usages were ex-
tracted. Our primary judge, a native English speaker
and an author of this paper, then annotated each use
of each candidate expression as one of literal, id-
iomatic, or unknown. When annotating a token, the
judge had access to only the sentence in which it oc-
curred, and not the surrounding sentences. If this
context was insufficient to determine the class of the
expression, the judge assigned the unknown label.
Idiomaticity is not a binary property, rather it is
known to fall on a continuum from completely se-
mantically transparent, or literal, to entirely opaque,
or idiomatic. The human annotators were required
to pick the label, literal or idiomatic, that best fit the
</bodyText>
<footnote confidence="0.778363">
2http://www.natcorp.ox.ac.uk
</footnote>
<bodyText confidence="0.999926361111112">
usage in their judgment; they were not to use the un-
known label for intermediate cases. Figurative ex-
tensions of literal meanings were classified as literal
if their overall meaning was judged to be fairly trans-
parent, as in You turn right when we hit the road at
the end of this track (taken from the BNC). Some-
times an idiomatic usage, such as had words in I
was in a bad mood, and he kept pestering me, so
we had words, is somewhat directly related to its
literal meaning, which is not the case for more se-
mantically opaque idioms such as hit the roof. The
above sentence was classified as idiomatic since the
idiomatic meaning is much more salient than the lit-
eral meaning.
Based on the primary judge’s annotations, we re-
moved expressions with fewer than 5 instances of
either of their literal or idiomatic meanings, leav-
ing 28 expressions. The remaining expressions were
then split into development (DEV) and test (TEST)
sets of 14 expressions each. The data was divided
such that DEV and TEST would be approximately
equal with respect to the frequency, and proportion
of idiomatic-to-literal usages, of their expressions.
Before consensus annotation, DEV and TEST con-
tained a total of 813 and 743 tokens, respectively.
A second human judge, also a native English-
speaking author of this paper, then annotated DEV
and TEST. The observed agreement and unweighted
kappa score on TEST were 76% and 0.62 respec-
tively. The judges discussed tokens on which they
disagreed to achieve a consensus annotation. Final
annotations were generated by removing tokens that
received the unknown label as the consensus anno-
tation, leaving DEV and TEST with a total of 573 and
607 tokens, and an average of 41 and 43 tokens per
expression, respectively.
</bodyText>
<subsectionHeader confidence="0.999939">
3.2 Creation of Co-occurrence Vectors
</subsectionHeader>
<bodyText confidence="0.998832666666667">
We create co-occurrence vectors for each expression
in our study from counts in the BNC. We form co-
occurrence vectors for the following items.
</bodyText>
<listItem confidence="0.9934556">
• Each token instance of the target expression
• The target expression in its automatically deter-
mined canonical form(s)
• The target expression in its non-canonical
form(s)
</listItem>
<page confidence="0.875088">
44
</page>
<listItem confidence="0.990628">
• The verb in the target expression
• The noun in the target expression
</listItem>
<bodyText confidence="0.999883076923077">
The co-occurrence vectors measure the frequency
with which the above items co-occur with each of
1000 content bearing words in the same sentence.3
The content bearing words were chosen to be the
most frequent words in the BNC which are used as
a noun, verb, adjective, adverb, or determiner. Al-
though determiners are often in a typical stoplist, we
felt it would be beneficial to use them here. Deter-
miners have been shown to be very informative in
recognizing the idiomaticity of MWE types, as they
are incorporated in the patterns used to automati-
cally determine canonical forms (Fazly and Steven-
son, 2006).4
</bodyText>
<subsectionHeader confidence="0.997114">
3.3 Evaluation and Baseline
</subsectionHeader>
<bodyText confidence="0.999984785714286">
Our baseline for comparison is that of always pre-
dicting an idiomatic label, the most frequent class
in our development data. We also compare our un-
supervised methods against the supervised method
proposed by Katz and Giesbrecht (2006). In this
study, co-occurrence vectors for the tokens were
formed from uses of a German idiom manually an-
notated as literal or idiomatic. Tokens were classi-
fied in a leave-one-out methodology using h-nearest
neighbours, with h = 1. We report results using this
method (1NN) as well as one which considers a to-
ken’s 5 nearest neighbours (5NN). In all cases, we
report the accuracy macro-averaged across the ex-
perimental expressions.
</bodyText>
<sectionHeader confidence="0.972727" genericHeader="method">
4 Experimental Results and Analysis
</sectionHeader>
<bodyText confidence="0.941538857142857">
In Section 4.1, we discuss the overall performance
of our proposed unsupervised methods. Section 4.2
explores possible causes of the differences observed
in the performance of the methods. We examine
our estimated idiomatic and literal vectors, and com-
pare them with the actual vectors calculated from
3We also considered 10 and 20 word windows on either side
of the target expression, but experiments on development data
indicated that using the sentence as a window performed better.
4We employed singular value decomposition (Deerwester et
al., 1990) to reduce the dimensionality of the co-occurrence
vectors. This had a negative effect on the results, likely be-
cause information about determiners, which occur frequently
with many expressions, is lost in the dimensionality reduction.
</bodyText>
<table confidence="0.999168285714286">
Method %Acc (%RER)
Baseline 61.9 -
Unsupervised DiffI-CF, L-C—p 67.8 (15.5)
DiffI-CF, L-NCF 70.1 (21.5)
CForm 72.4 (27.6)
Supervised 1NN 72.4 (27.6)
5NN 76.2 (37.5)
</table>
<tableCaption confidence="0.989849">
Table 1: Macro-averaged accuracy (%Acc) and relative error
reduction (%RER) over TEST.
</tableCaption>
<bodyText confidence="0.998607428571429">
manually-annotated data. Results reported in Sec-
tions 4.1 and 4.2 are on TEST (results on DEV have
very similar trends). Section 4.3 then examines the
performance of the unsupervised methods on ex-
pressions with different proportions of idiomatic-to-
literal usages. This section presents results on TEST
and DEV combined, as explained below.
</bodyText>
<subsectionHeader confidence="0.992604">
4.1 Overall Performance
</subsectionHeader>
<bodyText confidence="0.999893785714286">
Table 4.1 shows the macro-averaged accuracy on
TEST of our three unsupervised methods, as well as
that of the baseline and the two supervised methods
for comparison (see Section 3.3). The best super-
vised performance and the best unsupervised perfor-
mance are indicated in boldface. As the table shows,
all three unsupervised methods outperform the base-
line, confirming that the canonical forms of an ex-
pression, and local context, are both informative in
distinguishing literal and idiomatic instances of the
expression.
The table also shows that DiffI-CF, L-NCF per-
forms better than DiffI-CF L-C,�p. This suggests
that estimating the literal meaning of an expression
using the non-canonical forms is more accurate than
using the composed vector, iL-C,�p. In Section 4.2
we find more evidence for this. Another interesting
observation is that CForm has the highest perfor-
mance (among unsupervised methods), very closely
followed by DiffI-CF, L-NCF. These results confirm
our hypothesis that canonical forms—which reflect
the overall behaviour of a VNC type—are strongly
informative about the class of a token, perhaps even
more so than the local context of the token. Im-
portantly, this is the case even though the canonical
forms that we use are imperfect knowledge obtained
automatically through an unsupervised method.
Our results using 1NN, 72.4%, are comparable
</bodyText>
<page confidence="0.997383">
45
</page>
<table confidence="0.964491">
Vectors cosine Vectors cosine
-�idm and -alit .55
-�I-CF and -alit .70 -�I-CF and -�idm .90
-�L-NCF and -alit .80 -�L-NCF and -�idm .60
-�L-Comp and -alit .72 -�L-Comp and -�idm .76
</table>
<tableCaption confidence="0.9717525">
Table 2: Average similarity between the actual vectors (-d) and
the estimated vectors (v-), for the idiomatic and literal meanings.
</tableCaption>
<bodyText confidence="0.999655714285714">
to those of Katz and Giesbrecht (2006) using this
method on their German data (72%). However, their
baseline is slightly lower than ours at 58%, and
they only report results for 1 expression with 67 in-
stances. Interestingly, our best unsupervised results
are in line with the results using 1NN and not sub-
stantially lower than the results using 5NN.
</bodyText>
<subsectionHeader confidence="0.998393">
4.2 A Closer Look into the Estimated Vectors
</subsectionHeader>
<bodyText confidence="0.999995447368421">
In this section, we compare our estimated idiomatic
and literal vectors with the actual vectors for these
usages calculated from manually-annotated data.
Such a comparison helps explain some of the differ-
ences we observed in the performance of the meth-
ods. Table 4.2 shows the similarity between the esti-
mated and actual vectors representing the idiomatic
and literal meanings, averaged over the 14 TEST ex-
pressions. Actual vectors, referred to as aidm and
alit, are calculated over idiomatic and literal usages
of the expressions as determined by the human an-
notations. Estimated vectors, vI-CF, iL-CF, and
�vL-Comp, are calculated using our methods described
in Section 2.2.
For comparison purposes, the first row of Ta-
ble 4.2 shows the average similarity between the
actual idiomatic and literal vectors, aidm and alit.
These vectors are expected to be very dissimilar,
hence the low average cosine between them serves
as a baseline for comparison. We now look into the
relative similarity of each estimated vector, �vI-CF,
iL-CF, vL-Comp, with these two vectors.
The second row of the table shows that, as de-
sired, our estimated idiomatic vector, �vI-CF, is no-
tably more similar to the actual idiomatic vector than
to the actual literal vector. Also, iL-NCF is more
similar to the actual literal vector than to the actual
idiomatic vector (third row). Surprisingly, however,
iL-Comp is somewhat similar to both actual literal
and idiomatic vectors (in fact it is slightly more simi-
lar to the latter). These results suggest that the vector
composed of the context vectors for the constituents
of an expression may not always be the best estimate
of the literal meaning of the expression.5 Given this
observation, the overall better-than-baseline perfor-
mance of Diffr-CF,L-Comp might seem unjustified at
a first glance. However, we believe this performance
is mainly due to an accurate estimate of �vI-CF .
</bodyText>
<subsectionHeader confidence="0.999188">
4.3 Performance Based on Class Distribution
</subsectionHeader>
<bodyText confidence="0.999837114285714">
We further divide our 28 DEV and TEST expres-
sions according to their proportion of idiomatic-to-
literal usages, as determined by the human annota-
tors. In order to have a sufficient number of expres-
sions in each group, here we merge DEV and TEST
(we refer to the new set as DT). DTIhigh contains
17 expressions with 65%–90% of their usages be-
ing idiomatic—i.e., their idiomatic usage is domi-
nant. DTIlow contains 11 expressions with 8%–58%
of their occurrences being idiomatic—i.e., their id-
iomatic usage is not dominant.
Table 4.3 shows the average accuracy of all the
methods on these two groups of expressions, with
the best performance on each group shown in bold-
face. On DTIhigh, both DiffI-CF, L-NCF and CForm
outperform the baseline, with CForm having the
highest reduction in error rate. The two methods per-
form similarly to each other on DTIlow, though note
that the error reduction of CForm is more in line
with its performance on DTIhigh . These results show
that even for VNCs whose idiomatic meaning is
not dominant—i.e., those in DTIlow —automatically-
acquired canonical forms can help with their token
classification.
An interesting observation in Table 4.3 is the
inconsistent performance of DiffI-CF, L-Comp: the
method has a very poor performance on DTIhigh , but
outperforms the other two unsupervised methods on
DTIlow. As we noted earlier in Section 2.2, the more
frequent the idiomatic meaning of an expression,
the more reliable the acquired canonical forms for
that expression. Since the performance of CForm
and DiffI-CF, L-NCF depends highly on the accu-
racy of the automatically acquired canonical forms,
it is not surprising that these two methods perform
</bodyText>
<footnote confidence="0.997967">
5This was also noted by Katz and Giesbrecht (2006) in their
second experiment.
</footnote>
<page confidence="0.996224">
46
</page>
<table confidence="0.999779714285714">
Method DTIhi h DTI,_,
Baseline 81.4 (-) 35.0 (-)
Unsuper- Diffr-CF, L-Co�, 73.1 (-44.6) 58.6 (36.3)
vised Diffr-CF, L-NCF 82.3 (4.8) 52.7 (27.2)
CForm 84.7 (17.7) 53.4 (28.3)
Super- 1NN 78.3 (-16.7) 65.8 (47.4)
vised 5NN 82.3 (4.8) 72.4 (57.5)
</table>
<tableCaption confidence="0.9602375">
Table 3: Macro-averaged accuracy over DEV and TEST, di-
vided according to the proportion of idiomatic-to-literal usages.
</tableCaption>
<bodyText confidence="0.997567533333333">
worse than Diffr-CF, L-Comp on VNCs whose id-
iomatic usage is not dominant.
The high performance of the supervised meth-
ods on DTI,ow also confirms that the poorer perfor-
mance of the unsupervised methods on these VNCs
is likely due to the inaccuracy of the canonical forms
extracted for them. Interestingly, when canonical
forms can be extracted with a high accuracy (i.e.,
for VNCs in DTI,.9,) the performance of the unsu-
pervised methods is comparable to (or even slightly
better than) that of the best supervised method. One
possible way of improving the performance of unsu-
pervised methods is thus to develop more accurate
techniques for the automatic acquisition of canoni-
cal forms.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999953872727273">
Various properties of MWEs have been exploited
in developing automatic identification methods for
MWE types (Lin, 1999; Krenn and Evert, 2001; Fa-
zly and Stevenson, 2006). Much research has ad-
dressed the non-compositionality of MWEs as an
important property related to their idiomaticity, and
has used it in the classification of both MWE types
and tokens (Baldwin et al., 2003; McCarthy et al.,
2003; Katz and Giesbrecht, 2006). We also make
use of this property in an MWE token classification
task, but in addition, we draw on other salient char-
acteristics of MWEs which have been previously
shown to be useful for their type classification (Evert
et al., 2004; Fazly and Stevenson, 2006).
The idiomatic/literal token classification methods
of Birke and Sarkar (2006) and Katz and Giesbrecht
(2006) rely primarily on the local context of a to-
ken, and fail to exploit specific linguistic properties
of non-literal language. Our results suggest that such
properties are often more informative than the local
context, in determining the class of an MWE token.
The supervised classifier of Patrick and Fletcher
(2005) distinguishes between compositional and
non-compositional English verb-particle con-
struction tokens. Their classifier incorporates
linguistically-motivated features, such as the degree
of separation between the verb and particle. Here,
we focus on a different class of English MWEs,
verb+noun combinations. Moreover, by making
a more direct use of their syntactic behaviour, we
develop unsupervised token classification methods
that perform well. The unsupervised token classifier
of Hashimoto et al. (2006) uses manually-encoded
information about allowable and non-allowable
syntactic transformations of Japanese idioms—that
are roughly equivalent to our notions of canonical
and non-canonical forms. The rule-based classifier
of Uchiyama et al. (2005) incorporates syntac-
tic information about Japanese compound verbs
(JCVs), a type of MWE composed of two verbs.
In both cases, although the classifiers incorporate
syntactic information about MWEs, their manual
development limits the scalability of the approaches.
Uchiyama et al. (2005) also propose a statistical
token classification method for JCVs. This method
is similar to ours, in that it also uses type-based
knowledge to determine the class of each token
in context. However, their method is supervised,
whereas our methods are unsupervised. Moreover,
Uchiyama et al. (2005) evaluate their methods on a
set of JCVs that are mostly monosemous. Here, we
intentionally exclude such cases from consideration,
and focus on those MWEs that have two clear id-
iomatic and literal meanings, and that are frequently
used with either meaning.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9997475">
While a great deal of research has focused on prop-
erties of MWE types, such as their compositional-
ity, less attention has been paid to issues surround-
ing MWE tokens. In this study, we have developed
techniques for a semantic classification of tokens of
a potential MWE in context. We focus on a broadly
documented class of English MWEs that are formed
from the combination of a verb and a noun in its
direct object position, referred to as VNCs. We an-
notated a total of 1180 tokens for 28 VNCs accord-
</bodyText>
<page confidence="0.997698">
47
</page>
<bodyText confidence="0.9999735">
ing to whether they are a literal or idiomatic usage,
and we found that approximately 40% of the to-
kens were literal usages. These figures indicate that
automatically determining whether a VNC token is
used idiomatically or literally is of great importance
for NLP applications. In this work, we have pro-
posed three unsupervised methods that perform such
a task. Our proposed methods incorporate automati-
cally acquired knowledge about the overall syntactic
behaviour of a VNC type, in order to do token classi-
fication. More specifically, our methods draw on the
syntactic fixedness of VNCs—a property which has
been largely ignored in previous studies of MWE
tokens. Our results confirm the usefulness of this
property as incorporated into our methods. All our
methods outperform the baseline of always predict-
ing the most frequent class. Moreover, considering
our approach is unsupervised, our best accuracy of
72.4% is not substantially lower than the accuracy
of a standard supervised approach at 76.2%.
</bodyText>
<sectionHeader confidence="0.999458" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923369047619">
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model of
multiword expression decomposability. In Proceed-
ings of the ACL-SIGLEX Workshop on Multiword Ex-
pressions: Analysis, Acquisition and Treatment.
Julia Birke and Anoop Sarkar. 2006. A clustering ap-
proach for nearly unsupervised recognition of nonlit-
eral language. In Proceedings of EACL-06, 329–336.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Anthony P. Cowie, Ronald Mackin, and Isabel R. Mc-
Caig. 1983. Oxford Dictionary of Current Idiomatic
English, volume 2. Oxford University Press.
Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society of Information Science,
41(6):391–407.
Stefan Evert, Ulrich Heid, and Kristina Spranger. 2004.
Identifying morphosyntactic preferences in colloca-
tions. In Proceedings LREC-04.
Afsaneh Fazly and Suzanne Stevenson. 2006. Automat-
ically constructing a lexicon of verb phrase idiomatic
combinations. In Proceedings ofEACL-06, 337–344.
Christiane Fellbaum. 2002. VP idioms in the lexicon:
Topics for research using a very large corpus. In
S. Busemann, editor, Proceedings of the KONVENS-
02 Conference.
John R. Firth. 1957. A synopsis of linguistic theory
1930–1955. In Studies in Linguistic Analysis (special
volume of the Philological Society), 1–32. The Philo-
logical Society, Oxford.
Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro.
2006. Japanese idiom recognition: Drawing a line be-
tween literal and idiomatic meanings. In Proceedings
of the COLING/ACL 2006 Main Conference Poster
Sessions, 353–360.
Graham Katz and Eugenie Giesbrecht. 2006. Auto-
matic identification of non-compositional multi-word
expressions using latent semantic analysis. In Pro-
ceedings of the ACL/COLING-06 Workshop on Multi-
word Expressions: Identifying and Exploiting Under-
lying Properties, 12–19.
Brigitte Krenn and Stefan Evert. 2001. Can we do better
than frequency? A case study on extracting PP-verb
collocations. In Proceedings of the ACL-01 Workshop
on Collocations.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proceedings of ACL-99,
317–324.
Diana McCarthy, Bill Keller, and John Carroll. 2003.
Detecting a continuum of compositionality in phrasal
verbs. In Proceedings of the ACL-SIGLEX Workshop
on Multiword Expressions: Analysis, Acquisition and
Treatment.
Geoffrey Nunberg, Ivan A. Sag, and Thomas Wasow.
1994. Idioms. Language, 70(3):491–538.
Jon Patrick and Jeremy Fletcher. 2005. Classifying verb-
particle constructions by verb arguments. In Proceed-
ings of the Second ACL-SIGSEM Workshop on the Lin-
guistic Dimensions of Prepositions and their use in
Computational Linguistics Formalisms and Applica-
tions, 200–209.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword ex-
pressions: A pain in the neck for NLP. In Proceedings
of CICLing-02, 1–15.
Maggie Seaton and Alison Macaulay, editors. 2002.
Collins COBUILD Idioms Dictionary. HarperCollins
Publishers, second edition.
Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki.
2005. Disambiguating Japanese compound verbs.
Computer Speech and Language, Special Issue on
Multiword Expressions, 19(4):497–512.
Sriram Venkatapathy and Aravid Joshi. 2005. Measur-
ing the relative compositionality of verb-noun (V-N)
collocations by integrating features. In Proceedings of
HLT/EMNLP-05, 899–906.
Bego˜na Villada Moir´on and J¨org Tiedemann. 2006.
Identifying idiomatic expressions using automatic
word-alignment. In Proceedings of the EACL-06
Workshop on Multiword Expressions in a Multilingual
Context, 33–40.
</reference>
<page confidence="0.999352">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.778125">
<title confidence="0.998824">Pulling their Weight: Exploiting Syntactic Forms for the Identification of Idiomatic Expressions in Context</title>
<author confidence="0.997854">Paul Cook</author>
<author confidence="0.997854">Afsaneh Fazly</author>
<author confidence="0.997854">Suzanne</author>
<affiliation confidence="0.999868">Department of Computer University of</affiliation>
<address confidence="0.785002">Toronto,</address>
<abstract confidence="0.999738117647059">Much work on idioms has focused on type identification, i.e., determining whether a sequence of words can form an idiomatic expression. Since an idiom type often has a literal interpretation as well, token classification of potential idioms in context is critical for NLP. We explore the use of informative prior knowledge about the overall syntactic behaviour of a potentially-idiomatic expression (type-based knowledge) to determine whether an instance of the expression is used idiomatically or literally (tokenbased knowledge). We develop unsupervised methods for the task, and show that their performance is comparable to that of state-of-the-art supervised techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</booktitle>
<contexts>
<context position="1577" citStr="Baldwin et al., 2003" startWordPosition="239" endWordPosition="242">s. 1 Introduction Identification of multiword expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if successful) would identify make a face as a potenti</context>
<context position="26923" citStr="Baldwin et al., 2003" startWordPosition="4349" endWordPosition="4352">r even slightly better than) that of the best supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often m</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>A clustering approach for nearly unsupervised recognition of nonliteral language.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-06,</booktitle>
<pages>329--336</pages>
<contexts>
<context position="3238" citStr="Birke and Sarkar, 2006" startWordPosition="508" endWordPosition="511">eaning; and of the expressions with a literal meaning, on average around 40% of their usages are literal. Distinguishing token phrases as MWEs or literal combinations of words is thus essential for NLP applications that require the identification of multiword semantic units, such as semantic parsing and machine translation. Recent studies addressing MWE token classification mainly perform the task as one of word sense disambiguation, and draw on the local context of an expression to disambiguate it. Such techniques either do not use any information regarding the linguistic properties of MWEs (Birke and Sarkar, 2006), or mainly focus on their noncompositionality (Katz and Giesbrecht, 2006). Pre41 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics vious work on the identification of MWE types, however, has found other properties of MWEs, such as their syntactic fixedness, to be relevant to their identification (Evert et al., 2004; Fazly and Stevenson, 2006). In this paper, we propose techniques that draw on this property to classify individual tokens of a potentially idiomatic phrase as literal or i</context>
<context position="27315" citStr="Birke and Sarkar (2006)" startWordPosition="4412" endWordPosition="4415">zly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than the local context, in determining the class of an MWE token. The supervised classifier of Patrick and Fletcher (2005) distinguishes between compositional and non-compositional English verb-particle construction tokens. Their classifier incorporates linguistically-motivated features, such as the degree of separation between the verb and particle. Here, we focus on a dif</context>
</contexts>
<marker>Birke, Sarkar, 2006</marker>
<rawString>Julia Birke and Anoop Sarkar. 2006. A clustering approach for nearly unsupervised recognition of nonliteral language. In Proceedings of EACL-06, 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="13913" citStr="Collins, 1999" startWordPosition="2242" endWordPosition="2243"> lower than 20, in an effort to make sure that there would be literal and idiomatic usages of each expression. The frequency cut-off further ensures an accurate estimate of the vectors representing each of the literal and idiomatic meanings of the expression. We also discarded expressions that were not found in at least one of two dictionaries of idioms (Seaton and Macaulay, 2002; Cowie et al., 1983). This process resulted in the selection of 60 candidate expressions. For each of these 60 expressions, 100 sentences containing its usage were randomly selected from the automatically parsed BNC (Collins, 1999), using the automatic VNC identification method described by FS06. For an expression which occurs less than 100 times in the BNC, all of its usages were extracted. Our primary judge, a native English speaker and an author of this paper, then annotated each use of each candidate expression as one of literal, idiomatic, or unknown. When annotating a token, the judge had access to only the sentence in which it occurred, and not the surrounding sentences. If this context was insufficient to determine the class of the expression, the judge assigned the unknown label. Idiomaticity is not a binary pr</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony P Cowie</author>
<author>Ronald Mackin</author>
<author>Isabel R McCaig</author>
</authors>
<date>1983</date>
<journal>Oxford Dictionary of Current Idiomatic English,</journal>
<volume>2</volume>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="4507" citStr="Cowie et al., 1983" startWordPosition="703" endWordPosition="706">ques that combine such information with evidence from the local context of an MWE. We explore the hypothesis that informative prior knowledge about the overall syntactic behaviour of an idiomatic expression (type-based knowledge) can be used to determine whether an instance of the expression is used literally or idiomatically (tokenbased knowledge). Based on this hypothesis, we develop unsupervised methods for token classification, and show that their performance is comparable to that of a standard supervised method. Many verbs can be combined with one or more of their arguments to form MWEs (Cowie et al., 1983; Fellbaum, 2002). Here, we focus on a broadly documented class of idiomatic MWEs that are formed from the combination of a verb with a noun in its direct object position, as in make a face. In the rest of the paper, we refer to these verb+noun combinations, which are potentially idiomatic, as VNCs. In Section 2, we propose unsupervised methods that classify a VNC token as an idiomatic or literal usage. Section 3 describes our experimental setup, including experimental expressions and their annotation. In Section 4, we present a detailed discussion of our results. Section 5 compares our work w</context>
<context position="13702" citStr="Cowie et al., 1983" startWordPosition="2209" endWordPosition="2212">l Expressions and Annotation We use data provided by FS06, which consists of a list of VNCs and their canonical forms. From this data, we discarded expressions whose frequency in the British National Corpus2 (BNC) is lower than 20, in an effort to make sure that there would be literal and idiomatic usages of each expression. The frequency cut-off further ensures an accurate estimate of the vectors representing each of the literal and idiomatic meanings of the expression. We also discarded expressions that were not found in at least one of two dictionaries of idioms (Seaton and Macaulay, 2002; Cowie et al., 1983). This process resulted in the selection of 60 candidate expressions. For each of these 60 expressions, 100 sentences containing its usage were randomly selected from the automatically parsed BNC (Collins, 1999), using the automatic VNC identification method described by FS06. For an expression which occurs less than 100 times in the BNC, all of its usages were extracted. Our primary judge, a native English speaker and an author of this paper, then annotated each use of each candidate expression as one of literal, idiomatic, or unknown. When annotating a token, the judge had access to only the</context>
</contexts>
<marker>Cowie, Mackin, McCaig, 1983</marker>
<rawString>Anthony P. Cowie, Ronald Mackin, and Isabel R. McCaig. 1983. Oxford Dictionary of Current Idiomatic English, volume 2. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="18839" citStr="Deerwester et al., 1990" startWordPosition="3056" endWordPosition="3059">ross the experimental expressions. 4 Experimental Results and Analysis In Section 4.1, we discuss the overall performance of our proposed unsupervised methods. Section 4.2 explores possible causes of the differences observed in the performance of the methods. We examine our estimated idiomatic and literal vectors, and compare them with the actual vectors calculated from 3We also considered 10 and 20 word windows on either side of the target expression, but experiments on development data indicated that using the sentence as a window performed better. 4We employed singular value decomposition (Deerwester et al., 1990) to reduce the dimensionality of the co-occurrence vectors. This had a negative effect on the results, likely because information about determiners, which occur frequently with many expressions, is lost in the dimensionality reduction. Method %Acc (%RER) Baseline 61.9 - Unsupervised DiffI-CF, L-C—p 67.8 (15.5) DiffI-CF, L-NCF 70.1 (21.5) CForm 72.4 (27.6) Supervised 1NN 72.4 (27.6) 5NN 76.2 (37.5) Table 1: Macro-averaged accuracy (%Acc) and relative error reduction (%RER) over TEST. manually-annotated data. Results reported in Sections 4.1 and 4.2 are on TEST (results on DEV have very similar </context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society of Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Ulrich Heid</author>
<author>Kristina Spranger</author>
</authors>
<title>Identifying morphosyntactic preferences in collocations.</title>
<date>2004</date>
<booktitle>In Proceedings LREC-04.</booktitle>
<contexts>
<context position="3665" citStr="Evert et al., 2004" startWordPosition="572" endWordPosition="575">tion, and draw on the local context of an expression to disambiguate it. Such techniques either do not use any information regarding the linguistic properties of MWEs (Birke and Sarkar, 2006), or mainly focus on their noncompositionality (Katz and Giesbrecht, 2006). Pre41 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics vious work on the identification of MWE types, however, has found other properties of MWEs, such as their syntactic fixedness, to be relevant to their identification (Evert et al., 2004; Fazly and Stevenson, 2006). In this paper, we propose techniques that draw on this property to classify individual tokens of a potentially idiomatic phrase as literal or idiomatic. We also put forward classification techniques that combine such information with evidence from the local context of an MWE. We explore the hypothesis that informative prior knowledge about the overall syntactic behaviour of an idiomatic expression (type-based knowledge) can be used to determine whether an instance of the expression is used literally or idiomatically (tokenbased knowledge). Based on this hypothesis</context>
<context position="27208" citStr="Evert et al., 2004" startWordPosition="4398" endWordPosition="4401">ted in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than the local context, in determining the class of an MWE token. The supervised classifier of Patrick and Fletcher (2005) distinguishes between compositional and non-compositional English verb-particle construction tokens. Their classifier incorporates linguistically-</context>
</contexts>
<marker>Evert, Heid, Spranger, 2004</marker>
<rawString>Stefan Evert, Ulrich Heid, and Kristina Spranger. 2004. Identifying morphosyntactic preferences in collocations. In Proceedings LREC-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proceedings ofEACL-06,</booktitle>
<pages>337--344</pages>
<contexts>
<context position="1695" citStr="Fazly and Stevenson, 2006" startWordPosition="256" endWordPosition="259">e bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if successful) would identify make a face as a potential MWE. This expression is, however, ambiguous between an idiom, as in The little girl made a funny face at her mother</context>
<context position="3693" citStr="Fazly and Stevenson, 2006" startWordPosition="576" endWordPosition="580">e local context of an expression to disambiguate it. Such techniques either do not use any information regarding the linguistic properties of MWEs (Birke and Sarkar, 2006), or mainly focus on their noncompositionality (Katz and Giesbrecht, 2006). Pre41 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics vious work on the identification of MWE types, however, has found other properties of MWEs, such as their syntactic fixedness, to be relevant to their identification (Evert et al., 2004; Fazly and Stevenson, 2006). In this paper, we propose techniques that draw on this property to classify individual tokens of a potentially idiomatic phrase as literal or idiomatic. We also put forward classification techniques that combine such information with evidence from the local context of an MWE. We explore the hypothesis that informative prior knowledge about the overall syntactic behaviour of an idiomatic expression (type-based knowledge) can be used to determine whether an instance of the expression is used literally or idiomatically (tokenbased knowledge). Based on this hypothesis, we develop unsupervised me</context>
<context position="5936" citStr="Fazly and Stevenson (2006)" startWordPosition="934" endWordPosition="937">ess (Section 2.1). We then propose unsupervised methods that draw on this property to automatically distinguish between idiomatic and literal usages of an expression (Section 2.2). 2.1 Syntactic Fixedness and Canonical Forms Idioms tend to be somewhat fixed with respect to the syntactic configurations in which they occur (Nunberg et al., 1994). For example, pull one’s weight tends to mainly appear in this form when used idiomatically. Other forms of the expression, such as pull the weights, typically are only used with a literal meaning. In their work on automatically identifying idiom types, Fazly and Stevenson (2006)—henceforth FS06—show that an idiomatic VNC tends to have one (or at most a small number of) canonical form(s), which are its most preferred syntactic patterns. The preferred patterns can vary across different idiom types, and can involve a number of syntactic properties: the voice of the verb (active or passive), the determiner introducing the noun (the, one’s, etc.), and the number of the noun (singular or plural). For example, while pull one’s weight has only one canonical form, holdfire and hold one’s fire are two canonical forms of the same idiom, as listed in an idiom dictionary (Seaton </context>
<context position="17552" citStr="Fazly and Stevenson, 2006" startWordPosition="2852" endWordPosition="2856">target expression The co-occurrence vectors measure the frequency with which the above items co-occur with each of 1000 content bearing words in the same sentence.3 The content bearing words were chosen to be the most frequent words in the BNC which are used as a noun, verb, adjective, adverb, or determiner. Although determiners are often in a typical stoplist, we felt it would be beneficial to use them here. Determiners have been shown to be very informative in recognizing the idiomaticity of MWE types, as they are incorporated in the patterns used to automatically determine canonical forms (Fazly and Stevenson, 2006).4 3.3 Evaluation and Baseline Our baseline for comparison is that of always predicting an idiomatic label, the most frequent class in our development data. We also compare our unsupervised methods against the supervised method proposed by Katz and Giesbrecht (2006). In this study, co-occurrence vectors for the tokens were formed from uses of a German idiom manually annotated as literal or idiomatic. Tokens were classified in a leave-one-out methodology using h-nearest neighbours, with h = 1. We report results using this method (1NN) as well as one which considers a token’s 5 nearest neighbour</context>
<context position="26716" citStr="Fazly and Stevenson, 2006" startWordPosition="4314" endWordPosition="4318">racy of the canonical forms extracted for them. Interestingly, when canonical forms can be extracted with a high accuracy (i.e., for VNCs in DTI,.9,) the performance of the unsupervised methods is comparable to (or even slightly better than) that of the best supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) </context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings ofEACL-06, 337–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>VP idioms in the lexicon: Topics for research using a very large corpus.</title>
<date>2002</date>
<booktitle>Proceedings of the KONVENS02 Conference.</booktitle>
<editor>In S. Busemann, editor,</editor>
<contexts>
<context position="4524" citStr="Fellbaum, 2002" startWordPosition="707" endWordPosition="708">ch information with evidence from the local context of an MWE. We explore the hypothesis that informative prior knowledge about the overall syntactic behaviour of an idiomatic expression (type-based knowledge) can be used to determine whether an instance of the expression is used literally or idiomatically (tokenbased knowledge). Based on this hypothesis, we develop unsupervised methods for token classification, and show that their performance is comparable to that of a standard supervised method. Many verbs can be combined with one or more of their arguments to form MWEs (Cowie et al., 1983; Fellbaum, 2002). Here, we focus on a broadly documented class of idiomatic MWEs that are formed from the combination of a verb with a noun in its direct object position, as in make a face. In the rest of the paper, we refer to these verb+noun combinations, which are potentially idiomatic, as VNCs. In Section 2, we propose unsupervised methods that classify a VNC token as an idiomatic or literal usage. Section 3 describes our experimental setup, including experimental expressions and their annotation. In Section 4, we present a detailed discussion of our results. Section 5 compares our work with similar previ</context>
</contexts>
<marker>Fellbaum, 2002</marker>
<rawString>Christiane Fellbaum. 2002. VP idioms in the lexicon: Topics for research using a very large corpus. In S. Busemann, editor, Proceedings of the KONVENS02 Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930–1955.</title>
<date>1957</date>
<booktitle>In Studies in Linguistic Analysis (special volume of the Philological Society), 1–32. The Philological Society,</booktitle>
<location>Oxford.</location>
<contexts>
<context position="8979" citStr="Firth, 1957" startWordPosition="1446" endWordPosition="1447">ely informative in classifying the meaning of its individual instances (tokens) as literal or idiomatic. Our CForm classifies a token as idiomatic if it occurs in the automatically determined canonical form(s) for that expression, and as literal otherwise. Diff: Our two Diff methods combine local context information with knowledge about the canonical forms of an idiom type to determine if its token usages are literal or idiomatic. In developing these methods, we adopt a distributional approach to meaning, where the meaning of an expression is approximated by the words with which it co-occurs (Firth, 1957). Although there may be fine-grained differences in meaning across the idiomatic usages of an expression, as well as across its literal usages, we assume that the idiomatic and literal usages correspond to two coarse-grained senses of the expression. Since we further assume these two groups of usages will have more in common semantically within each group than between the two groups, we expect that literal and idiomatic usages of an expression will typically occur with different sets of words. We will refer then to each of the literal and idiomatic designations as a (coarse-grained) meaning of</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John R. Firth. 1957. A synopsis of linguistic theory 1930–1955. In Studies in Linguistic Analysis (special volume of the Philological Society), 1–32. The Philological Society, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Satoshi Sato</author>
<author>Takehito Utsuro</author>
</authors>
<title>Japanese idiom recognition: Drawing a line between literal and idiomatic meanings.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>353--360</pages>
<contexts>
<context position="28169" citStr="Hashimoto et al. (2006)" startWordPosition="4534" endWordPosition="4537">e local context, in determining the class of an MWE token. The supervised classifier of Patrick and Fletcher (2005) distinguishes between compositional and non-compositional English verb-particle construction tokens. Their classifier incorporates linguistically-motivated features, such as the degree of separation between the verb and particle. Here, we focus on a different class of English MWEs, verb+noun combinations. Moreover, by making a more direct use of their syntactic behaviour, we develop unsupervised token classification methods that perform well. The unsupervised token classifier of Hashimoto et al. (2006) uses manually-encoded information about allowable and non-allowable syntactic transformations of Japanese idioms—that are roughly equivalent to our notions of canonical and non-canonical forms. The rule-based classifier of Uchiyama et al. (2005) incorporates syntactic information about Japanese compound verbs (JCVs), a type of MWE composed of two verbs. In both cases, although the classifiers incorporate syntactic information about MWEs, their manual development limits the scalability of the approaches. Uchiyama et al. (2005) also propose a statistical token classification method for JCVs. Th</context>
</contexts>
<marker>Hashimoto, Sato, Utsuro, 2006</marker>
<rawString>Chikara Hashimoto, Satoshi Sato, and Takehito Utsuro. 2006. Japanese idiom recognition: Drawing a line between literal and idiomatic meanings. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, 353–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
<author>Eugenie Giesbrecht</author>
</authors>
<title>Automatic identification of non-compositional multi-word expressions using latent semantic analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL/COLING-06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>12--19</pages>
<contexts>
<context position="3312" citStr="Katz and Giesbrecht, 2006" startWordPosition="519" endWordPosition="522">d 40% of their usages are literal. Distinguishing token phrases as MWEs or literal combinations of words is thus essential for NLP applications that require the identification of multiword semantic units, such as semantic parsing and machine translation. Recent studies addressing MWE token classification mainly perform the task as one of word sense disambiguation, and draw on the local context of an expression to disambiguate it. Such techniques either do not use any information regarding the linguistic properties of MWEs (Birke and Sarkar, 2006), or mainly focus on their noncompositionality (Katz and Giesbrecht, 2006). Pre41 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics vious work on the identification of MWE types, however, has found other properties of MWEs, such as their syntactic fixedness, to be relevant to their identification (Evert et al., 2004; Fazly and Stevenson, 2006). In this paper, we propose techniques that draw on this property to classify individual tokens of a potentially idiomatic phrase as literal or idiomatic. We also put forward classification techniques that combine such </context>
<context position="10436" citStr="Katz and Giesbrecht (2006)" startWordPosition="1686" endWordPosition="1689">sion e as a word frequency vector ve where each dimension i of ve is the frequency with which e co-occurs with word i across the usages of e. We similarly estimate the meaning of a single token of an expression t as a vector vt capturing that usage. To determine if an instance of an expression is literal or idiomatic, we compare its co-occurrence vector to the co-occurrence vectors representing each of the literal and idiomatic meanings of the expression. We use a standard measure of distributional similarity, cosine, to compare co-occurrence vectors. In supervised approaches, such as that of Katz and Giesbrecht (2006), co-occurrence vectors for literal and idiomatic meanings are formed from manuallyannotated training data. Here, we propose unsupervised methods for estimating these vectors. We use one way of estimating the idiomatic meaning of an expression, and two ways for estimating its literal meaning, yielding two methods for token classification. Our first Diff method draws further on our expectation that canonical forms are more likely idiomatic usages, and non-canonical forms are more likely literal usages. We estimate the idiomatic meaning of an expression by building a co-occurrence vector, �vI-CF</context>
<context position="11697" citStr="Katz and Giesbrecht (2006)" startWordPosition="1885" endWordPosition="1888"> its automatically determined canonical form(s). Since we hypothesize that idiomatic usages of an expression tend to occur in its canonical form, we expect these co-occurrence vectors to be largely representative of the idiomatic usage of the expression. We similarly estimate the literal meaning by constructing a cooccurrence vector, iL-NCF, of all uses of the expression in its non-canonical forms. We use the term DiffI-CF,L-NCF to refer to this method. Our second Diff method also uses the vector �vI-CF to estimate the idiomatic meaning of an expression. However, this approach follows that of Katz and Giesbrecht (2006) in assuming that literal meanings are compositional. The literal meaning of an expression is thus estimated by composing (summing and then normalizing) the co-occurrence vectors for its component words. The resulting vector is referred to as vL-Comp, and this method as DiffI-CF,L-Comp. For both Diff methods, if the meaning of an instance of an expression is determined to be more similar to its idiomatic meaning (e.g., cosine (it, iI-CF) &gt; cosine (it, iL-NCF)), then we label it as an idiomatic usage. Otherwise, it is labeled as literal.1 1We also performed experiments using a KNN classifier in</context>
<context position="17818" citStr="Katz and Giesbrecht (2006)" startWordPosition="2895" endWordPosition="2898">un, verb, adjective, adverb, or determiner. Although determiners are often in a typical stoplist, we felt it would be beneficial to use them here. Determiners have been shown to be very informative in recognizing the idiomaticity of MWE types, as they are incorporated in the patterns used to automatically determine canonical forms (Fazly and Stevenson, 2006).4 3.3 Evaluation and Baseline Our baseline for comparison is that of always predicting an idiomatic label, the most frequent class in our development data. We also compare our unsupervised methods against the supervised method proposed by Katz and Giesbrecht (2006). In this study, co-occurrence vectors for the tokens were formed from uses of a German idiom manually annotated as literal or idiomatic. Tokens were classified in a leave-one-out methodology using h-nearest neighbours, with h = 1. We report results using this method (1NN) as well as one which considers a token’s 5 nearest neighbours (5NN). In all cases, we report the accuracy macro-averaged across the experimental expressions. 4 Experimental Results and Analysis In Section 4.1, we discuss the overall performance of our proposed unsupervised methods. Section 4.2 explores possible causes of the</context>
<context position="21411" citStr="Katz and Giesbrecht (2006)" startWordPosition="3453" endWordPosition="3456">ss of a token, perhaps even more so than the local context of the token. Importantly, this is the case even though the canonical forms that we use are imperfect knowledge obtained automatically through an unsupervised method. Our results using 1NN, 72.4%, are comparable 45 Vectors cosine Vectors cosine -�idm and -alit .55 -�I-CF and -alit .70 -�I-CF and -�idm .90 -�L-NCF and -alit .80 -�L-NCF and -�idm .60 -�L-Comp and -alit .72 -�L-Comp and -�idm .76 Table 2: Average similarity between the actual vectors (-d) and the estimated vectors (v-), for the idiomatic and literal meanings. to those of Katz and Giesbrecht (2006) using this method on their German data (72%). However, their baseline is slightly lower than ours at 58%, and they only report results for 1 expression with 67 instances. Interestingly, our best unsupervised results are in line with the results using 1NN and not substantially lower than the results using 5NN. 4.2 A Closer Look into the Estimated Vectors In this section, we compare our estimated idiomatic and literal vectors with the actual vectors for these usages calculated from manually-annotated data. Such a comparison helps explain some of the differences we observed in the performance of</context>
<context position="25451" citStr="Katz and Giesbrecht (2006)" startWordPosition="4111" endWordPosition="4114">eir token classification. An interesting observation in Table 4.3 is the inconsistent performance of DiffI-CF, L-Comp: the method has a very poor performance on DTIhigh , but outperforms the other two unsupervised methods on DTIlow. As we noted earlier in Section 2.2, the more frequent the idiomatic meaning of an expression, the more reliable the acquired canonical forms for that expression. Since the performance of CForm and DiffI-CF, L-NCF depends highly on the accuracy of the automatically acquired canonical forms, it is not surprising that these two methods perform 5This was also noted by Katz and Giesbrecht (2006) in their second experiment. 46 Method DTIhi h DTI,_, Baseline 81.4 (-) 35.0 (-) Unsuper- Diffr-CF, L-Co�, 73.1 (-44.6) 58.6 (36.3) vised Diffr-CF, L-NCF 82.3 (4.8) 52.7 (27.2) CForm 84.7 (17.7) 53.4 (28.3) Super- 1NN 78.3 (-16.7) 65.8 (47.4) vised 5NN 82.3 (4.8) 72.4 (57.5) Table 3: Macro-averaged accuracy over DEV and TEST, divided according to the proportion of idiomatic-to-literal usages. worse than Diffr-CF, L-Comp on VNCs whose idiomatic usage is not dominant. The high performance of the supervised methods on DTI,ow also confirms that the poorer performance of the unsupervised methods on</context>
<context position="26974" citStr="Katz and Giesbrecht, 2006" startWordPosition="4357" endWordPosition="4360"> supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than the local context, in determin</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>Graham Katz and Eugenie Giesbrecht. 2006. Automatic identification of non-compositional multi-word expressions using latent semantic analysis. In Proceedings of the ACL/COLING-06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, 12–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting PP-verb collocations.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL-01 Workshop on Collocations.</booktitle>
<contexts>
<context position="1555" citStr="Krenn and Evert, 2001" startWordPosition="235" endWordPosition="238">rt supervised techniques. 1 Introduction Identification of multiword expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if successful) would identify ma</context>
<context position="26688" citStr="Krenn and Evert, 2001" startWordPosition="4310" endWordPosition="4313">ikely due to the inaccuracy of the canonical forms extracted for them. Interestingly, when canonical forms can be extracted with a high accuracy (i.e., for VNCs in DTI,.9,) the performance of the unsupervised methods is comparable to (or even slightly better than) that of the best supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb collocations. In Proceedings of the ACL-01 Workshop on Collocations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL-99,</booktitle>
<pages>317--324</pages>
<contexts>
<context position="1532" citStr="Lin, 1999" startWordPosition="233" endWordPosition="234">te-of-the-art supervised techniques. 1 Introduction Identification of multiword expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if succes</context>
<context position="26665" citStr="Lin, 1999" startWordPosition="4308" endWordPosition="4309">e VNCs is likely due to the inaccuracy of the canonical forms extracted for them. Interestingly, when canonical forms can be extracted with a high accuracy (i.e., for VNCs in DTI,.9,) the performance of the unsupervised methods is comparable to (or even slightly better than) that of the best supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proceedings of ACL-99, 317–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</booktitle>
<contexts>
<context position="1600" citStr="McCarthy et al., 2003" startWordPosition="243" endWordPosition="246">tification of multiword expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if successful) would identify make a face as a potential MWE. This expression</context>
<context position="26946" citStr="McCarthy et al., 2003" startWordPosition="4353" endWordPosition="4356"> than) that of the best supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. 5 Related Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006). Much research has addressed the non-compositionality of MWEs as an important property related to their idiomaticity, and has used it in the classification of both MWE types and tokens (Baldwin et al., 2003; McCarthy et al., 2003; Katz and Giesbrecht, 2006). We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than th</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
<author>Ivan A Sag</author>
<author>Thomas Wasow</author>
</authors>
<date>1994</date>
<journal>Idioms. Language,</journal>
<volume>70</volume>
<issue>3</issue>
<contexts>
<context position="5655" citStr="Nunberg et al., 1994" startWordPosition="888" endWordPosition="891">esent a detailed discussion of our results. Section 5 compares our work with similar previous studies, and Section 6 concludes the paper. 2 Unsupervised Idiom Identification We first explain an important linguistic property attributed to idioms—that is, their syntactic fixedness (Section 2.1). We then propose unsupervised methods that draw on this property to automatically distinguish between idiomatic and literal usages of an expression (Section 2.2). 2.1 Syntactic Fixedness and Canonical Forms Idioms tend to be somewhat fixed with respect to the syntactic configurations in which they occur (Nunberg et al., 1994). For example, pull one’s weight tends to mainly appear in this form when used idiomatically. Other forms of the expression, such as pull the weights, typically are only used with a literal meaning. In their work on automatically identifying idiom types, Fazly and Stevenson (2006)—henceforth FS06—show that an idiomatic VNC tends to have one (or at most a small number of) canonical form(s), which are its most preferred syntactic patterns. The preferred patterns can vary across different idiom types, and can involve a number of syntactic properties: the voice of the verb (active or passive), the</context>
</contexts>
<marker>Nunberg, Sag, Wasow, 1994</marker>
<rawString>Geoffrey Nunberg, Ivan A. Sag, and Thomas Wasow. 1994. Idioms. Language, 70(3):491–538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Patrick</author>
<author>Jeremy Fletcher</author>
</authors>
<title>Classifying verbparticle constructions by verb arguments.</title>
<date>2005</date>
<booktitle>In Proceedings of the Second ACL-SIGSEM Workshop on the Linguistic Dimensions of Prepositions and their use in Computational Linguistics Formalisms and Applications,</booktitle>
<pages>200--209</pages>
<contexts>
<context position="27661" citStr="Patrick and Fletcher (2005)" startWordPosition="4467" endWordPosition="4470">cation task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006). The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than the local context, in determining the class of an MWE token. The supervised classifier of Patrick and Fletcher (2005) distinguishes between compositional and non-compositional English verb-particle construction tokens. Their classifier incorporates linguistically-motivated features, such as the degree of separation between the verb and particle. Here, we focus on a different class of English MWEs, verb+noun combinations. Moreover, by making a more direct use of their syntactic behaviour, we develop unsupervised token classification methods that perform well. The unsupervised token classifier of Hashimoto et al. (2006) uses manually-encoded information about allowable and non-allowable syntactic transformatio</context>
</contexts>
<marker>Patrick, Fletcher, 2005</marker>
<rawString>Jon Patrick and Jeremy Fletcher. 2005. Classifying verbparticle constructions by verb arguments. In Proceedings of the Second ACL-SIGSEM Workshop on the Linguistic Dimensions of Prepositions and their use in Computational Linguistics Formalisms and Applications, 200–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of CICLing-02,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="1167" citStr="Sag et al., 2002" startWordPosition="168" endWordPosition="171">or NLP. We explore the use of informative prior knowledge about the overall syntactic behaviour of a potentially-idiomatic expression (type-based knowledge) to determine whether an instance of the expression is used idiomatically or literally (tokenbased knowledge). We develop unsupervised methods for the task, and show that their performance is comparable to that of state-of-the-art supervised techniques. 1 Introduction Identification of multiword expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviou</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of CICLing-02, 1–15.</rawString>
</citation>
<citation valid="true">
<date>2002</date>
<booktitle>Collins COBUILD Idioms Dictionary. HarperCollins Publishers,</booktitle>
<editor>Maggie Seaton and Alison Macaulay, editors.</editor>
<note>second edition.</note>
<marker>2002</marker>
<rawString>Maggie Seaton and Alison Macaulay, editors. 2002. Collins COBUILD Idioms Dictionary. HarperCollins Publishers, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoko Uchiyama</author>
<author>Timothy Baldwin</author>
<author>Shun Ishizaki</author>
</authors>
<title>Disambiguating Japanese compound verbs.</title>
<date>2005</date>
<journal>Computer Speech and Language, Special Issue on Multiword Expressions,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="28415" citStr="Uchiyama et al. (2005)" startWordPosition="4565" endWordPosition="4568">linguistically-motivated features, such as the degree of separation between the verb and particle. Here, we focus on a different class of English MWEs, verb+noun combinations. Moreover, by making a more direct use of their syntactic behaviour, we develop unsupervised token classification methods that perform well. The unsupervised token classifier of Hashimoto et al. (2006) uses manually-encoded information about allowable and non-allowable syntactic transformations of Japanese idioms—that are roughly equivalent to our notions of canonical and non-canonical forms. The rule-based classifier of Uchiyama et al. (2005) incorporates syntactic information about Japanese compound verbs (JCVs), a type of MWE composed of two verbs. In both cases, although the classifiers incorporate syntactic information about MWEs, their manual development limits the scalability of the approaches. Uchiyama et al. (2005) also propose a statistical token classification method for JCVs. This method is similar to ours, in that it also uses type-based knowledge to determine the class of each token in context. However, their method is supervised, whereas our methods are unsupervised. Moreover, Uchiyama et al. (2005) evaluate their me</context>
</contexts>
<marker>Uchiyama, Baldwin, Ishizaki, 2005</marker>
<rawString>Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki. 2005. Disambiguating Japanese compound verbs. Computer Speech and Language, Special Issue on Multiword Expressions, 19(4):497–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriram Venkatapathy</author>
<author>Aravid Joshi</author>
</authors>
<title>Measuring the relative compositionality of verb-noun (V-N) collocations by integrating features.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-05,</booktitle>
<pages>899--906</pages>
<contexts>
<context position="1630" citStr="Venkatapathy and Joshi, 2005" startWordPosition="247" endWordPosition="250"> expressions (MWEs), such as car park, make a decision, and kick the bucket, is extremely important for accurate natural language processing (NLP) (Sag et al., 2002). Most MWEs need to be treated as single units of meaning, e.g., make a decision roughly means “decide”. Nonetheless, the components of an MWE can be separated, making it hard for an NLP system to identify the expression as a whole. Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moir´on and Tiedemann, 2006; Fazly and Stevenson, 2006). These studies look into properties, such as the collocational behaviour of MWEs, their semantic non-compositionality, and their lexicosyntactic fixedness, in order to distinguish them from similar-on-the-surface literal combinations. Most of these methods have been aimed at recognizing MWE types; less attention has been paid to the identification of instances (tokens) of MWEs in context. For example, most such techniques (if successful) would identify make a face as a potential MWE. This expression is, however, ambiguous betwee</context>
</contexts>
<marker>Venkatapathy, Joshi, 2005</marker>
<rawString>Sriram Venkatapathy and Aravid Joshi. 2005. Measuring the relative compositionality of verb-noun (V-N) collocations by integrating features. In Proceedings of HLT/EMNLP-05, 899–906.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bego˜na Villada Moir´on</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Identifying idiomatic expressions using automatic word-alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL-06 Workshop on Multiword Expressions in a Multilingual Context,</booktitle>
<pages>33--40</pages>
<marker>Moir´on, Tiedemann, 2006</marker>
<rawString>Bego˜na Villada Moir´on and J¨org Tiedemann. 2006. Identifying idiomatic expressions using automatic word-alignment. In Proceedings of the EACL-06 Workshop on Multiword Expressions in a Multilingual Context, 33–40.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>