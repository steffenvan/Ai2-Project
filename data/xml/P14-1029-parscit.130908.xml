<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.966092">
An Empirical Study on the Effect of Negation Words on Sentiment
</title>
<author confidence="0.997249">
Xiaodan Zhu, Hongyu Guo, Saif Mohammad and Svetlana Kiritchenko
</author>
<affiliation confidence="0.993604">
National Research Council Canada
</affiliation>
<address confidence="0.710422">
1200 Montreal Road
Ottawa, K1A 0R6, ON, Canada
{Xiaodan.Zhu,Hongyu.Guo,Saif.Mohammad,Svetlana.Kiritchenko}
</address>
<email confidence="0.718308">
@nrc-cnrc.gc.ca
</email>
<sectionHeader confidence="0.983702" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999919884615385">
Negation words, such as no and not, play
a fundamental role in modifying sentiment
of textual expressions. We will refer to a
negation word as the negator and the text
span within the scope of the negator as the
argument. Commonly used heuristics to
estimate the sentiment of negated expres-
sions rely simply on the sentiment of ar-
gument (and not on the negator or the ar-
gument itself). We use a sentiment tree-
bank to show that these existing heuristics
are poor estimators of sentiment. We then
modify these heuristics to be dependent on
the negators and show that this improves
prediction. Next, we evaluate a recently
proposed composition model (Socher et
al., 2013) that relies on both the negator
and the argument. This model learns the
syntax and semantics of the negator’s ar-
gument with a recursive neural network.
We show that this approach performs bet-
ter than those mentioned above. In ad-
dition, we explicitly incorporate the prior
sentiment of the argument and observe that
this information can help reduce fitting er-
rors.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999436545454545">
Morante and Sporleder (2012) define negation to
be “a grammatical category that allows the chang-
ing of the truth value of a proposition”. Nega-
tion is often expressed through the use of nega-
tive signals or negators–words like isn’t and never,
and it can significantly affect the sentiment of
its scope. Understanding the impact of negation
on sentiment is essential in automatic analysis of
sentiment. The literature contains interesting re-
search attempting to model and understand the
behavior (reviewed in Section 2). For example,
</bodyText>
<figureCaption confidence="0.670856">
Figure 1: Effect of a list of common negators
</figureCaption>
<bodyText confidence="0.988328888888889">
in modifying sentiment values in Stanford Senti-
ment Treebank. The x-axis is s(w), and y-axis
is s(w,,,, w). Each dot in the figure corresponds
to a text span being modified by (composed with)
a negator in the treebank. The red diagonal line
corresponds to the sentiment-reversing hypothesis
that simply reverses the sign of sentiment values.
a simple yet influential hypothesis posits that a
negator reverses the sign of the sentiment value
of the modified text (Polanyi and Zaenen, 2004;
Kennedy and Inkpen, 2006). The shifting hypoth-
esis (Taboada et al., 2011), however, assumes that
negators change sentiment values by a constant
amount. In this paper, we refer to a negation word
as the negator (e.g., isn’t), a text span being mod-
ified by and composed with a negator as the ar-
gument (e.g., very good), and entire phrase (e.g.,
isn’t very good) as the negated phrase.
The recently available Stanford Sentiment Tree-
bank (Socher et al., 2013) renders manually anno-
tated, real-valued sentiment scores for all phrases
in parse trees. This corpus provides us with the
data to further understand the quantitative behav-
ior of negators, as the effect of negators can now
be studied with arguments of rich syntactic and se-
mantic variety. Figure 1 illustrates the effect of a
common list of negators on sentiment as observed
</bodyText>
<page confidence="0.98606">
304
</page>
<note confidence="0.832886">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 304–313,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.998268404761905">
on the Stanford Sentiment Treebank.1 Each dot in
the figure corresponds to a negated phrase in the
treebank. The x-axis is the sentiment score of its
argument s(w) and y-axis the sentiment score of
the entire negated phrase s(wn, w).
We can see that the reversing assumption (the
red diagonal line) does capture some regularity of
human perception, but rather roughly. Moreover,
the figure shows that same or similar s(w) scores
(x-axis) can correspond to very different s(wn, w)
scores (y-axis), which, to some degree, suggests
the potentially complicated behavior of negators.2
This paper describes a quantitative study of
the effect of a list of frequent negators on sen-
timent. We regard the negators’ behavior as an
underlying function embedded in annotated data;
we aim to model this function from different as-
pects. By examining sentiment compositions of
negators and arguments, we model the quantita-
tive behavior of negators in changing sentiment.
That is, given a negated phrase (e.g., isn’t very
good) and the sentiment score of its argument
(e.g., s(“very good″) = 0.5), we focus on un-
derstanding the negator’s quantitative behavior in
yielding the sentiment score of the negated phrase
s(“isn′t very good″).
We first evaluate the modeling capabilities of
two influential heuristics and show that they cap-
ture only very limited regularity of negators’ ef-
fect. We then extend the models to be dependent
on the negators and demonstrate that such a sim-
ple extension can significantly improve the per-
formance of fitting to the human annotated data.
Next, we evaluate a recently proposed composi-
tion model (Socher, 2013) that relies on both the
negator and the argument. This model learns the
syntax and semantics of the negator’s argument
with a recursive neural network. This approach
performs significantly better than those mentioned
above. In addition, we explicitly incorporate the
prior sentiment of the argument and observe that
this information helps reduce fitting errors.
</bodyText>
<footnote confidence="0.996809428571429">
1The sentiment values have been linearly rescaled from
the original range [0, 1] to [-0.5, 0.5]; in the figure a negative
or positive value corresponds to a negative or a positive sen-
timent respectively; zero means neutral. The negator list will
be discussed later in the paper.
2Similar distribution is observed in other data such as
Tweets (Kiritchenko et al., 2014).
</footnote>
<sectionHeader confidence="0.992559" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99972346">
Automatic sentiment analysis The expression of
sentiment is an integral component of human lan-
guage. In written text, sentiment is conveyed with
word senses and their composition, and in speech
also via prosody such as pitch (Mairesse et al.,
2012). Early work on automatic sentiment anal-
ysis includes the widely cited work of (Hatzivas-
siloglou and McKeown, 1997; Pang et al., 2002;
Turney, 2002), among others. Since then, there has
been an explosion of research addressing various
aspects of the problem, including detecting sub-
jectivity, rating and classifying sentiment, label-
ing sentiment-related semantic roles (e.g., target
of sentiment), and visualizing sentiment (see sur-
veys by Pang and Lee (2008) and Liu and Zhang
(2012)).
Negation modeling Negation is a general gram-
matical category pertaining to the changing of the
truth values of propositions; negation modeling is
not limited to sentiment. For example, paraphrase
and contradiction detection systems rely on detect-
ing negated expressions and opposites (Harabagiu
et al., 2006). In general, a negated expression and
the opposite of the expression may or may not con-
vey the same meaning. For example, not alive has
the same meaning as dead, however, not tall does
not always mean short. Some automatic methods
to detect opposites were proposed by Hatzivas-
siloglou and McKeown (1997) and Mohammad et
al. (2013).
Negation modeling for sentiment An early yet
influential reversing assumption conjectures that a
negator reverses the sign of the sentiment value
of the modified text (Polanyi and Zaenen, 2004;
Kennedy and Inkpen, 2006), e.g., from +0.5 to -
0.5, or vice versa. A different hypothesis, called
the shifting hypothesis in this paper, assumes that
negators change the sentiment values by a con-
stant amount (Taboada et al., 2011; Liu and Sen-
eff, 2009). Other approaches to negation modeling
have been discussed in (Jia et al., 2009; Wiegand
et al., 2010; Lapponi et al., 2012; Benamara et al.,
2012).
In the process of semantic composition, the ef-
fect of negators could depend on the syntax and
semantics of the text spans they modify. The ap-
proaches of modeling this include bag-of-word-
based models. For example, in the work of
(Kennedy and Inkpen, 2006), a feature not good
will be created if the word good is encountered
</bodyText>
<page confidence="0.998651">
305
</page>
<bodyText confidence="0.999797321428572">
within a predefined range after a negator.
There exist different ways of incorporating
more complicated syntactic and semantic infor-
mation. Much recent work considers sentiment
analysis from a semantic-composition perspec-
tive (Moilanen and Pulman, 2007; Choi and
Cardie, 2008; Socher et al., 2012; Socher et al.,
2013), which achieved the state-of-the-art perfor-
mance. Moilanen and Pulman (2007) used a col-
lection of hand-written compositional rules to as-
sign sentiment values to different granularities of
text spans. Choi and Cardie (2008) proposed a
learning-based framework. The more recent work
of (Socher et al., 2012; Socher et al., 2013) pro-
posed models based on recursive neural networks
that do not rely on any heuristic rules. Such mod-
els work in a bottom-up fashion over the parse
tree of a sentence to infer the sentiment label of
the sentence as a composition of the sentiment ex-
pressed by its constituting parts. The approach
leverages a principled method, the forward and
backward propagation, to learn a vector represen-
tation to optimize the system performance. In
principle neural network is able to fit very compli-
cated functions (Mitchell, 1997), and in this paper,
we adapt the state-of-the-art approach described in
(Socher et al., 2013) to help understand the behav-
ior of negators specifically.
</bodyText>
<sectionHeader confidence="0.98171" genericHeader="method">
3 Negation models based on heuristics
</sectionHeader>
<bodyText confidence="0.99998275">
We begin with previously proposed methods that
leverage heuristics to model the behavior of nega-
tors. We then propose to extend them to consider
lexical information of the negators themselves.
</bodyText>
<subsectionHeader confidence="0.983055">
3.1 Non-lexicalized assumptions and
modeling
</subsectionHeader>
<bodyText confidence="0.999990222222222">
In previous research, some influential, widely
adopted assumptions posit the effect of negators
to be independent of both the specific negators and
the semantics and syntax of the arguments. In this
paper, we call a model based on such assumptions
a non-lexicalized model. In general, we can sim-
ply define this category of models in Equation 1.
That is, the model parameters are only based on
the sentiment value of the arguments.
</bodyText>
<equation confidence="0.768346">
s(wn, ~w) def = f(s(~w)) (1)
</equation>
<subsectionHeader confidence="0.918244">
3.1.1 Reversing hypothesis
</subsectionHeader>
<bodyText confidence="0.9997565">
A typical model falling into this category is the
reversing hypothesis discussed in Section 2, where
a negator simply reverses the sentiment score s(~w)
to be −s(~w); i.e., f(s(~w)) = −s(~w).
</bodyText>
<subsectionHeader confidence="0.969415">
3.1.2 Shifting hypothesis
</subsectionHeader>
<bodyText confidence="0.9966595">
Basic shifting Similarly, a shifting based model
depends on s(~w) only, which can be written as:
</bodyText>
<equation confidence="0.995829">
f(s(~w)) = s(~w) − sign(s(~w)) * C (2)
</equation>
<bodyText confidence="0.999978166666667">
where sign(.) is the standard sign function
which determines if the constant C should be
added to or deducted from s(wn): the constant is
added to a negative s(~w) but deducted from a pos-
itive one.
Polarity-based shifting As will be shown in our
experiments, negators can have different shifting
power when modifying a positive or a negative
phrase. Thus, we explore the use of two different
constants for these two situations, i.e., f(s(~w)) =
s(~w)−sign(s(~w))*C(sign(s(~w))). The constant
C now can take one of two possible values. We
will show that this simple modification improves
the fitting performance statistically significantly.
Note also that instead of determining these con-
stants by human intuition, we use the training data
to find the constants in all shifting-based models
as well as for the parameters in other models.
</bodyText>
<subsectionHeader confidence="0.999552">
3.2 Simple lexicalized assumptions
</subsectionHeader>
<bodyText confidence="0.999994375">
The above negation hypotheses rely on s(~w). As
intuitively shown in Figure 1, the capability of the
non-lexicalized heuristics might be limited. Fur-
ther semantic or syntactic information from either
the negators or the phrases they modify could be
helpful. The most straightforward way of expand-
ing the non-lexicalized heuristics is probably to
make the models to be dependent on the negators.
</bodyText>
<equation confidence="0.896349">
s(wn, ~w) def = f(wn, s(~w)) (3)
</equation>
<bodyText confidence="0.999835666666667">
Negator-based shifting We can simply extend the
basic shifting model above to consider the lexi-
cal information of negators: f(s(~w)) = s(~w) −
sign(s(~w)) * C(wn). That is, each negator has its
own C. We call this model negator-based shift-
ing. We will show that this model also statistically
significantly outperforms the basic shifting with-
out overfitting, although the number of parameters
have increased.
</bodyText>
<page confidence="0.995625">
306
</page>
<bodyText confidence="0.994136909090909">
Combined shifting We further combine the
negator-based shifting and polarity-based shift-
ing above: f(s(~w)) = s(~w) − sign(s(~w)) ∗
C(wn, sign(s(~w))). This shifting model is
based on negators and the polarity of the text
they modify: constants can be different for each
negator-polarity pair. The number of parameters
in this model is the multiplication of number
of negators by two (the number of sentiment
polarities). This model further improves the fitting
performance on the test data.
</bodyText>
<sectionHeader confidence="0.991463" genericHeader="method">
4 Semantics-enriched modeling
</sectionHeader>
<bodyText confidence="0.9998275">
Negators can interact with arguments in complex
ways. Figure 1 shows the distribution of the ef-
fect of negators on sentiment without considering
further semantics of the arguments. The question
then is that whether and how much incorporating
further syntax and semantic information can help
better fit or predict the negation effect. Above, we
have considered the semantics of the negators. Be-
low, we further make the models to be dependent
on the arguments. This can be written as:
</bodyText>
<equation confidence="0.90638">
s(wn, ~w) def = f(wn, s(~w), r(~w)) (4)
</equation>
<bodyText confidence="0.9993886875">
In the formula, r(~w) is a certain type of repre-
sentation for the argument w~ and it models the se-
mantics or/and syntax of the argument. There ex-
ist different ways of implementing r(~w). We con-
sider two models in this study: one drops s(~w) in
Equation 4 and directly models f(wn, r(~w)). That
is, the non-uniform information shown in Figure 1
is not directly modeled. The other takes into ac-
count s(~w) too.
For the former, we adopt the recursive neu-
ral tensor network (RNTN) proposed recently by
Socher et al. (2013), which has showed to achieve
the state-of-the-art performance in sentiment anal-
ysis. For the latter, we propose a prior sentiment-
enriched tensor network (PSTN) to take into ac-
count the prior sentiment of the argument s(~w).
</bodyText>
<subsectionHeader confidence="0.986815">
4.1 RITI: Recursive neural tensor network
</subsectionHeader>
<bodyText confidence="0.997834625">
A recursive neural tensor network (RNTN) is
a specific form of feed-forward neural network
based on syntactic (phrasal-structure) parse tree
to conduct compositional sentiment analysis. For
completeness, we briefly review it here. More de-
tails can be found in (Socher et al., 2013).
As shown in the black portion of Figure 2, each
instance of RNTN corresponds to a binary parse
</bodyText>
<figureCaption confidence="0.858862">
Figure 2: Prior sentiment-enriched tensor network
(PSTN) model for sentiment analysis.
</figureCaption>
<bodyText confidence="0.998106714285714">
tree of a given sentence. Each node of the parse
tree is a fixed-length vector that encodes composi-
tional semantics and syntax, which can be used to
predict the sentiment of this node. The vector of a
node, say p2 in Figure 2, is computed from the d-
dimensional vectors of its two children, namely a
and p1 (a, p1 E Rdx1), with a non-linear function:
</bodyText>
<equation confidence="0.9974968">
1
p2 = tanh( [ a] T V [1:d] [pa
]+ W [p1]
a) (5)
p1 1
</equation>
<bodyText confidence="0.9814837">
where, W E Rdx(d+d) and V E R(d+d)x(d+d)xd
are the matrix and tensor for the composition func-
tion. A major difference of RNTN from the con-
ventional recursive neural network (RRN) (Socher
et al., 2012) is the use of the tensor V in order
to directly capture the multiplicative interaction of
two input vectors, although the matrix W implic-
itly captures the nonlinear interaction between the
input vectors. The training of RNTN uses conven-
tional forward-backward propagation.
</bodyText>
<sectionHeader confidence="0.5960795" genericHeader="method">
4.2 PSTI: Prior sentiment-enriched tensor
network
</sectionHeader>
<bodyText confidence="0.999822642857143">
The non-uniform distribution in Figure 1 has
showed certain correlations between the sentiment
values of s(wn, ~w) and s(~w), and such informa-
tion has been leveraged in the models discussed in
Section 3. We intend to devise a model that imple-
ments Equation 4. It bridges between the models
we have discussed above that use either s(~w) or
r(~w).
We extend RNTN to directly consider the senti-
ment information of arguments. Consider the node
p2 in Figure 2. When calculating its vector, we
aim to directly engage the sentiment information
of its right child, i.e., the argument. To this end,
we make use of the sentiment class information of
</bodyText>
<page confidence="0.985705">
307
</page>
<bodyText confidence="0.848256">
p1, noted as psen
</bodyText>
<equation confidence="0.70018075">
1 .As a result, the vector of p2 is
calculated as follows:
[ a]T [pa1 [p1]
p2 = tanh( V [1:d] J+Wa(6)
p1 1
� a ~T V sen[1:d] � a � � a �
+ + Wsen )
psen psen psen
1 1 1
As shown in Equation 6, for the node vector
p1 E Rdx1, we employ a matrix, namely Wsen E
Rdx(d+m) and a tensor, V sen E R(d+m)x(d+m)xd,
</equation>
<bodyText confidence="0.873003">
aiming at explicitly capturing the interplays be-
tween the sentiment class of p1, denoted as psen
</bodyText>
<sectionHeader confidence="0.586891" genericHeader="method">
1 (E
</sectionHeader>
<bodyText confidence="0.997480222222222">
Rmx1), and the negator a. Here, we assume the
sentiment task has m classes. Following the idea
of Wilson et al. (2005), we regard the sentiment of
p1 as a prior sentiment as it has not been affected
by the specific context (negators), so we denote
our method as prior sentiment-enriched tensor net-
work (PSTN). In Figure 2, the red portion shows
the added components of PSTN.
Note that depending on different purposes, psen
</bodyText>
<equation confidence="0.779485">
1
</equation>
<bodyText confidence="0.999284176470588">
can take the value of the automatically predicted
sentiment distribution obtained in forward propa-
gation, the gold sentiment annotation of node p1,
or even other normalized prior sentiment value or
confidence score from external sources (e.g., sen-
timent lexicons or external training data). This
is actually an interesting place to extend the cur-
rent recursive neural network to consider extrinsic
knowledge. However, in our current study, we fo-
cus on exploring the behavior of negators. As we
have discussed above, we will use the human an-
notated sentiment for the arguments, same as in
the models discussed in Section 3.
With the new matrix and tensor, we then have
0 = (V, V sen, W, Wsen, Wlabel, L) as the PSTN
model’s parameters. Here, L denotes the vector
representations of the word dictionary.
</bodyText>
<subsubsectionHeader confidence="0.465849">
4.2.1 Inference and Learning
</subsubsectionHeader>
<bodyText confidence="0.923378555555556">
Inference and learning in PSTN follow a forward-
backward propagation process similar to that in
(Socher et al., 2013), and for completeness, we
depict the details as follows. To train the model,
one first needs to calculate the predicted sentiment
distribution for each node:
psen i= Wlabelpi, psen iE Rmx1
and then compute the posterior probability over
the m labels:
</bodyText>
<equation confidence="0.957031">
yi = softmax(psen)
i
</equation>
<bodyText confidence="0.999728714285714">
During learning, following the method used by
the RNTN model in (Socher et al., 2013), PSTN
also aims to minimize the cross-entropy error be-
tween the predicted distribution yi E Rmx1 at
node i and the target distribution ti E Rmx1 at that
node. That is, the error for a sentence is calculated
as:
</bodyText>
<equation confidence="0.975113">
E(0) = X X tijlogyij + A 110112 (7)
i j
</equation>
<bodyText confidence="0.999845037037037">
where, A represents the regularization hyperpa-
rameters, and j E m denotes the j-th element of
the multinomial target distribution.
To minimize E(0), the gradient of the objec-
tive function with respect to each of the param-
eters in 0 is calculated efficiently via backprop-
agation through structure, as proposed by Goller
and Kchler (1996). Specifically, we first compute
the prediction errors in all tree nodes bottom-up.
After this forward process, we then calculate the
derivatives of the softmax classifiers at each node
in the tree in a top-down fashion. We will discuss
the gradient computation for the Vsen and Wsen
in detail next. Note that the gradient calculations
for the V, W, W label, L are the same as that of pre-
sented in (Socher et al., 2013).
In the backpropogation process of the training,
each node (except the root node) in the tree car-
ries two kinds of errors: the local softmax error
and the error passing down from its parent node.
During the derivative computation, the two errors
will be summed up as the complement incoming
error for the node. We denote the complete incom-
ing error and the softmax error vector for node i
as Si,com E Rdx1 and Si,s E Rdx1, respectively.
With this notation, the error for the root node p2
can be formulated as follows.
</bodyText>
<equation confidence="0.996632">
Sp2,com = Sp2,s
= (WT (yp2 − tp2)) ® f′([a;p1]) (8)
</equation>
<bodyText confidence="0.9998944">
where ® is the Hadamard product between the two
vectors and f′ is the element-wise derivative of
f = tanh. With the results from Equation 8, we
then can calculate the derivatives for the Wsen at
node p2 using the following equation:
</bodyText>
<sectionHeader confidence="0.6472265" genericHeader="method">
= Sp2,com([a; psen
1 ])T
</sectionHeader>
<bodyText confidence="0.986012">
Similarly, for the derivative of each slice k(k =
</bodyText>
<page confidence="0.638797333333333">
∂Ep2
Wsen
308
</page>
<equation confidence="0.867961666666667">
1, ... , d) of the V sen tensor, we have the follow-
ing:
= δp2,com
a a
k [psen] [psen]
1 1
</equation>
<bodyText confidence="0.999884818181818">
Now, let’s form the equations for computing the
error for the two children of the p2 node. The dif-
ference for the error at p2 and its two children is
that the error for the latter will need to compute the
error message passing down from p2. We denote
the error passing down as δp2,down, where the left
child and the right child of p2 take the 1st and 2nd
half of the error δp2,down, namely δp2,down[1 : d]
and δp2,down[d + 1 : 2d], respectively. Follow-
ing this notation, we have the error message for
the two children of p2, provided that we have the
</bodyText>
<equation confidence="0.989736">
δp2,down:
δp1,com = δp1,s + δp2,down[d + 1 : 2d]
= (WT(yp1 − tp1)) ® f′([b;c])
+ δp2,down[d + 1 : 2d]
</equation>
<bodyText confidence="0.99505775">
The incoming error message of node a can be
calculated similarly. Finally, we can finish the
above equations with the following formula for
computing δp2,down:
</bodyText>
<equation confidence="0.890085">
δp2,down = (WT δp2,com) ® f′([a; p1]) + δtensor
where
δtensor = [δV [1 : d] + δV se&apos;[1 : d], δV [d + 1 : 2d]]
δp2,com
k (V[k] + (V[k])T) ® f′([a; p1])[1 : d]
δp2,com(V[k]n + (Uk]n)T) ® f′([a; p1en])[1 : d
k
δp2,com
k (V[k] + (V[k])T) ® f′([a; p1])[d + 1 : 2d]
After the models are trained, they are applied to
</equation>
<bodyText confidence="0.998165571428571">
predict the sentiment of the test data. The orig-
inal RNTN and the PSTN predict 5-class senti-
ment for each negated phrase; we map the out-
put to real-valued scores based on the scale that
Socher et al. (2013) used to map real-valued senti-
ment scores to sentiment categories. Specifically,
we conduct the mapping with the formula: preal
</bodyText>
<equation confidence="0.8128575">
i =
yi · [0.1 0.3 0.5 0.7 0.9]; i.e., we calculate the dot
</equation>
<bodyText confidence="0.996032428571428">
product of the posterior probability yi and the scal-
ing vector. For example, if yi = [0.5 0.5 0 0 0],
meaning this phrase has a 0.5 probability to be
in the first category (strong negative) and 0.5 for
the second category (weak negative), the resulting
preal will be 0.2 (0.5*0.1+0.5*0.3).
i
</bodyText>
<sectionHeader confidence="0.996121" genericHeader="method">
5 Experiment set-up
</sectionHeader>
<bodyText confidence="0.999894575">
Data As described earlier, the Stanford Sentiment
Treebank (Socher et al., 2013) has manually anno-
tated, real-valued sentiment values for all phrases
in parse trees. This provides us with the training
and evaluation data to study the effect of negators
with syntax and semantics of different complex-
ity in a natural setting. The data contain around
11,800 sentences from movie reviews that were
originally collected by Pang and Lee (2005). The
sentences were parsed with the Stanford parser
(Klein and Manning, 2003). The phrases at all
tree nodes were manually annotated with one of 25
sentiment values that uniformly span between the
positive and negative poles. The values are nor-
malized to the range of [0, 1].
In this paper, we use a list of most frequent
negators that include the words not, no, never, and
their combinations with auxiliaries (e.g., didn’t).
We search these negators in the Stanford Senti-
ment Treebank and normalize the same negators to
a single form; e.g., “is n’t”, “isn’t”, and “is not”
are all normalized to “is not”. Each occurrence of
a negator and the phrase it is directly composed
with in the treebank, i.e., (wn, ~w), is considered
a data point in our study. In total, we collected
2,261 pairs, including 1,845 training and 416 test
cases. The split of training and test data is same as
specified in (Socher et al., 2013).
Evaluation metrics We use the mean absolute er-
ror (MAE) to evaluate the models, which mea-
sures the averaged absolute offsets between the
predicted sentiment values and the gold stan-
dard. More specifically, MAE is calculated as:
MAE = N E�wn,~w)  |(ˆs (wn, w) − s(wn, w))|,
where ˆs(wn, ~w) denotes the gold sentiment value
and s(wn, ~w) the predicted one for the pair
(wn, ~w), and N is the total number of test in-
stances. Note that mean square error (MSE) is an-
other widely used measure for regression, but it is
less intuitive for out task here.
</bodyText>
<sectionHeader confidence="0.997862" genericHeader="method">
6 Experimental results
</sectionHeader>
<bodyText confidence="0.998418">
Overall regression performance Table 1 shows
the overall fitting performance of all models. The
first row of the table is a random baseline, which
</bodyText>
<figure confidence="0.990146307692308">
∂Ep2
V sen
[k]
T
= d
E
k=1
d
+ E
k=1
d
+E
k=1
</figure>
<page confidence="0.997447">
309
</page>
<bodyText confidence="0.9617733125">
simply guesses the sentiment value for each test
case randomly in the range [0,1]. The table shows
that the basic reversing and shifting heuristics do
capture negators’ behavior to some degree, as their
MAE scores are higher than that of the baseline.
Making the basic shifting model to be dependent
on the negators (model 4) reduces the prediction
error significantly as compared with the error of
the basic shifting (model 3). The same is true
for the polarity-based shifting (model 5), reflect-
ing that the roles of negators are different when
modifying positive and negative phrases. Merging
these two models yields additional improvement
(model 6).
Assumptions MAE
Baseline
</bodyText>
<listItem confidence="0.998820909090909">
(1) Random 0.2796
Non-lexicalized
(2) Reversing 0.1480*
(3) Basic shifting 0.1452*
Simple-lexicalized
(4) Negator-based shifting 0.1415†
(5) Polarity-based shifting 0.1417†
(6) Combined shifting 0.1387†
Semantics-enriched
(7) RNTN 0.1097**
(8) PSTN 0.1062††
</listItem>
<tableCaption confidence="0.959542">
Table 1: Mean absolute errors (MAE) of fitting
</tableCaption>
<bodyText confidence="0.993088857142857">
different models to Stanford Sentiment Treebank.
Models marked with an asterisk (*) are statisti-
cally significantly better than the random baseline.
Models with a dagger sign (†) significantly outper-
form model (3). Double asterisks ** indicates a
statistically significantly different from model (6),
and the model with the double dagger ††is signif-
icantly better than model (7). One-tailed paired
t-test with a 95% significance level is used here.
Furthermore, modeling the syntax and seman-
tics with the state-of-the-art recursive neural net-
work (model 7 and 8) can dramatically improve
the performance over model 6. The PSTN model,
which takes into account the human-annotated
prior sentiment of arguments, performs the best.
This could suggest that additional external knowl-
edge, e.g., that from human-built resources or au-
tomatically learned from other data (e.g., as in
(Kiritchenko et al., 2014)), including sentiment
that cannot be inferred from its constituent expres-
sions, might be incorporated to benefit the current
</bodyText>
<figure confidence="0.998281833333333">
0.30
0.25
0.20
0.15
0.10
0.05
</figure>
<figureCaption confidence="0.9984485">
Figure 3: Effect of different negators in shifting
sentiment values.
</figureCaption>
<bodyText confidence="0.994146676470588">
neural-network-based models as prior knowledge.
Note that the two neural network based models
incorporate the syntax and semantics by represent-
ing each node with a vector. One may consider
that a straightforward way of considering the se-
mantics of the modified phrases is simply memo-
rizing them. For example, if a phrase very good
modified by a negator not appears in the train-
ing and test data, the system can simply memorize
the sentiment score of not very good in training
and use this score at testing. When incorporating
this memorizing strategy into model (6), we ob-
served a MAE score of 0.1222. It’s not surprising
that memorizing the phrases has some benefit, but
such matching relies on the exact reoccurrences of
phrases. Note that this is a special case of what the
neural network based models can model.
Discriminating negators The results in Table 1
has demonstrated the benefit of discriminating
negators. To understand this further, we plot in
Figure 3 the behavior of different negators: the
x-axis is a subset of our negators and the y-axis
denotes absolute shifting in sentiment values. For
example, we can see that the negator “is never”
on average shifts the sentiment of the arguments
by 0.26, which is a significant change considering
the range of sentiment value is [0, 1]. For each
negator, a 95% confidence interval is shown by
the boxes in the figure, which is calculated with
the bootstrapping resampling method. We can ob-
serve statistically significant differences of shift-
ing abilities between many negator pairs such as
that between “is never” and “do not” as well as
between “does not” and “can not”.
</bodyText>
<figureCaption confidence="0.54659">
Figure 3 also includes three diminishers (the
</figureCaption>
<figure confidence="0.9891525625">
is_never
will_not
is_not
does_not
barely
was_not
could_not
not
did_not
unlikely
do_not
can_not
no
has_not
superficial
would_not
should_not
310
0.30
0.25
0.20
0.15
is_not(nn)
is_not(np)
does_not(nn)
does_not(np)
not(nn)
not(np)
do_not(nn)
do_not(np)
no(nn)
no(np)
</figure>
<figureCaption confidence="0.92311">
Figure 4: The behavior of individual negators in
negated negative (nn) and negated positive (np)
context.
</figureCaption>
<bodyText confidence="0.9982950625">
white bars), i.e., barely, unlikely, and superficial.
By following (Kennedy and Inkpen, 2006), we ex-
tracted 319 diminishers (also called understate-
ment or downtoners) from General Inquirer3. We
calculated their shifting power in the same man-
ner as for the negators and found three diminish-
ers having shifting capability in the shifting range
of these negators. This shows that the boundary
between negators and diminishers can by fuzzy.
In general, we argue that one should always con-
sider modeling negators individually in a senti-
ment analysis system. Alternatively, if the model-
ing has to be done in groups, one should consider
clustering valence shifters by their shifting abili-
ties in training or external data.
Figure 4 shows the shifting capacity of negators
when they modify positive (blue boxes) or nega-
tive phrases (red boxes). The figure includes five
most frequently used negators found in the sen-
timent treebank. Four of them have significantly
different shifting power when composed with pos-
itive or negative phrases, which can explain why
the polarity-based shifting model achieves im-
provement over the basic shifting model.
Modeling syntax and semantics We have seen
above that modeling syntax and semantics through
the-state-of-the-art neural networks help improve
the fitting performance. Below, we take a closer
look at the fitting errors made at different depths
of the sentiment treebank. The depth here is de-
fined as the longest distance between the root of a
negator-phrase pair (wn, w) and their descendant
</bodyText>
<footnote confidence="0.991374">
3http://www.wjh.harvard.edu/ inquirer/
</footnote>
<figureCaption confidence="0.99791">
Figure 5: Errors made at different depths in the
sentiment tree bank.
</figureCaption>
<bodyText confidence="0.9996994">
leafs. Negators appearing at deeper levels of the
tree tend to have more complicated syntax and se-
mantics. In Figure 5, the x-axis corresponds to
different depths and y-axis is the mean absolute
errors (MAE).
The figure shows that both RNTN and PSTN
perform much better at all depths than the model
6 in Table 1. When the depths are within 4,
the RNTN performs very well and the (human
annotated) prior sentiment of arguments used
in PSTN does not bring additional improvement
over RNTN. PSTN outperforms RNTN at greater
depths, where the syntax and semantics are more
complicated and harder to model. The errors made
by model 6 is bumpy, as the model considers
no semantics and hence its errors are not depen-
dent on the depths. On the other hand, the er-
rors of RNTN and PSTN monotonically increase
with depths, indicating the increase in the task dif-
ficulty.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99996">
Negation plays a fundamental role in modifying
sentiment. In the process of semantic compo-
sition, the impact of negators is complicated by
the syntax and semantics of the text spans they
modify. This paper provides a comprehensive
and quantitative study of the behavior of negators
through a unified view of fitting human annota-
tion. We first measure the modeling capabilities of
two influential heuristics on a sentiment treebank
and find that they capture some effect of negation;
however, extending these non-lexicalized models
to be dependent on the negators improves the per-
</bodyText>
<page confidence="0.996374">
311
</page>
<bodyText confidence="0.999983333333333">
formance statistically significantly. The detailed
analysis reveals the differences in the behavior
among negators, and we argue that they should al-
ways be modeled separately. We further make the
models to be dependent on the text being modi-
fied by negators, through adaptation of a state-of-
the-art recursive neural network to incorporate the
syntax and semantics of the arguments; we dis-
cover this further reduces fitting errors.
</bodyText>
<sectionHeader confidence="0.998425" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999504414893617">
Farah Benamara, Baptiste Chardon, Yannick Mathieu,
Vladimir Popescu, and Nicholas Asher. 2012. How
do negation and modality impact on opinions? In
Proceedings of the ACL-2012 Workshop on Extra-
Propositional Aspects ofMeaning in Computational
Linguistics, pages 10–18, Jeju, Republic of Korea.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, EMNLP ’08, pages 793–801,
Honolulu, Hawaii.
Christoph Goller and Andreas Kchler. 1996. Learn-
ing task-dependent distributed representations by
backpropagation through structure. In In Proc. of
the ICNN-96, pages 347–352, Bochum, Germany.
IEEE.
Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.
2006. Negation, contrast and contradiction in text
processing. In AAAI, volume 6, pages 755–762.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the 8th Conference ofEuro-
pean Chapter of the Association for Computational
Linguistics, EACL ’97, pages 174–181, Madrid,
Spain.
Lifeng Jia, Clement Yu, and Weiyi Meng. 2009. The
effect of negation on sentiment analysis and retrieval
effectiveness. In Proceedings of the 18th ACM Con-
ference on Information and Knowledge Manage-
ment, CIKM ’09, pages 1827–1830, Hong Kong,
China. ACM.
Alistair Kennedy and Diana Inkpen. 2006. Senti-
ment classification of movie reviews using contex-
tual valence shifters. Computational Intelligence,
22(2):110–125.
Svetlana Kiritchenko, Xiaodan Zhu, and Saif Moham-
mad. 2014. Sentiment analysis of short informal
texts. (to appear) Journal of Artificial Intelligence
Research.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 423–
430, Sapporo, Japan. Association for Computational
Linguistics.
Emanuele Lapponi, Jonathon Read, and Lilja Ovre-
lid. 2012. Representing and resolving negation
for sentiment analysis. In Jilles Vreeken, Charles
Ling, Mohammed Javeed Zaki, Arno Siebes, Jef-
frey Xu Yu, Bart Goethals, Geoffrey I. Webb, and
Xindong Wu, editors, ICDM Workshops, pages 687–
692. IEEE Computer Society.
Jingjing Liu and Stephanie Seneff. 2009. Review sen-
timent scoring via a parse-and-paraphrase paradigm.
In EMNLP, pages 161–169, Singapore.
Bing Liu and Lei Zhang. 2012. A survey of opin-
ion mining and sentiment analysis. In Charu C. Ag-
garwal and ChengXiang Zhai, editors, Mining Text
Data, pages 415–463. Springer US.
Franc¸ois Mairesse, Joseph Polifroni, and Giuseppe
Di Fabbrizio. 2012. Can prosody inform sentiment
analysis? experiments on short spoken reviews. In
ICASSP, pages 5093–5096, Kyoto, Japan.
Tom M Mitchell. 1997. Machine learning. 1997. Burr
Ridge, IL: McGraw Hill, 45.
Saif M. Mohammad, Bonnie J. Dorr, Graeme Hirst, and
Peter D. Turney. 2013. Computing lexical contrast.
Computational Linguistics, 39(3):555–590.
Karo Moilanen and Stephen Pulman. 2007. Senti-
ment composition. In Proceedings of RANLP 2007,
Borovets, Bulgaria.
Roser Morante and Caroline Sporleder. 2012. Modal-
ity and negation: An introduction to the special is-
sue. Computational linguistics, 38(2):223–260.
Bo Pang and Lillian Lee. 2005. Seeing stars: Ex-
ploiting class relationships for sentiment categoriza-
tion with respect to rating scales. In Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics, ACL ’05, pages 115–124.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification us-
ing machine learning techniques. In Proceedings of
EMNLP, pages 79–86, Philadelphia, USA.
Livia Polanyi and Annie Zaenen. 2004. Contextual
valence shifters. In Exploring Attitude and Affect in
Text: Theories and Applications (AAAI Spring Sym-
posium Series).
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In
</reference>
<page confidence="0.983694">
312
</page>
<reference confidence="0.998828852941177">
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’12,
Jeju, Korea. Association for Computational Linguis-
tics.
Richard Socher, Alex Perelygin, Jean Y. Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’13, Seattle, USA. Association for Compu-
tational Linguistics.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional Linguistics, 37(2):267–307.
Peter Turney. 2002. Thumbs up or thumbs down? se-
mantic orientation applied to unsupervised classifi-
cation of reviews. In ACL, pages 417–424, Philadel-
phia, USA.
Michael Wiegand, Alexandra Balahur, Benjamin Roth,
Dietrich Klakow, and Andr´es Montoyo. 2010. A
survey on the role of negation in sentiment analysis.
In Proceedings of the Workshop on Negation and
Speculation in Natural Language Processing, NeSp-
NLP ’10, pages 60–68, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the Con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
HLT ’05, pages 347–354, Stroudsburg, PA, USA.
Association for Computational Linguistics.
</reference>
<page confidence="0.999512">
313
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.697773">
<title confidence="0.999162">An Empirical Study on the Effect of Negation Words on Sentiment</title>
<author confidence="0.84911">Xiaodan Zhu</author>
<author confidence="0.84911">Hongyu Guo</author>
<author confidence="0.84911">Saif Mohammad</author>
<author confidence="0.84911">Svetlana</author>
<affiliation confidence="0.994423">National Research Council</affiliation>
<address confidence="0.9904865">1200 Montreal Ottawa, K1A 0R6, ON,</address>
<email confidence="0.995135">@nrc-cnrc.gc.ca</email>
<abstract confidence="0.994110185185185">words, such as play a fundamental role in modifying sentiment of textual expressions. We will refer to a word as the the text span within the scope of the negator as the Commonly used heuristics to estimate the sentiment of negated expressions rely simply on the sentiment of argument (and not on the negator or the argument itself). We use a sentiment treebank to show that these existing heuristics are poor estimators of sentiment. We then modify these heuristics to be dependent on the negators and show that this improves prediction. Next, we evaluate a recently proposed composition model (Socher et al., 2013) that relies on both the negator and the argument. This model learns the syntax and semantics of the negator’s argument with a recursive neural network. We show that this approach performs better than those mentioned above. In addition, we explicitly incorporate the prior sentiment of the argument and observe that this information can help reduce fitting errors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Farah Benamara</author>
<author>Baptiste Chardon</author>
<author>Yannick Mathieu</author>
<author>Vladimir Popescu</author>
<author>Nicholas Asher</author>
</authors>
<title>How do negation and modality impact on opinions?</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL-2012 Workshop on ExtraPropositional Aspects ofMeaning in Computational Linguistics,</booktitle>
<pages>10--18</pages>
<location>Jeju, Republic of</location>
<contexts>
<context position="7782" citStr="Benamara et al., 2012" startWordPosition="1241" endWordPosition="1244">nd Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, </context>
</contexts>
<marker>Benamara, Chardon, Mathieu, Popescu, Asher, 2012</marker>
<rawString>Farah Benamara, Baptiste Chardon, Yannick Mathieu, Vladimir Popescu, and Nicholas Asher. 2012. How do negation and modality impact on opinions? In Proceedings of the ACL-2012 Workshop on ExtraPropositional Aspects ofMeaning in Computational Linguistics, pages 10–18, Jeju, Republic of Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with compositional semantics as structural inference for subsentential sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>793--801</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="8386" citStr="Choi and Cardie, 2008" startWordPosition="1338" endWordPosition="1341">ara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Socher et al., 2012; Socher et al., 2013), which achieved the state-of-the-art performance. Moilanen and Pulman (2007) used a collection of hand-written compositional rules to assign sentiment values to different granularities of text spans. Choi and Cardie (2008) proposed a learning-based framework. The more recent work of (Socher et al., 2012; Socher et al., 2013) proposed models based on recursive neural networks that do not rely on any heuristic rules. Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition o</context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with compositional semantics as structural inference for subsentential sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 793–801, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Goller</author>
<author>Andreas Kchler</author>
</authors>
<title>Learning task-dependent distributed representations by backpropagation through structure. In</title>
<date>1996</date>
<booktitle>In Proc. of the ICNN-96,</booktitle>
<pages>347--352</pages>
<publisher>IEEE.</publisher>
<location>Bochum, Germany.</location>
<contexts>
<context position="18868" citStr="Goller and Kchler (1996)" startWordPosition="3098" endWordPosition="3101"> RNTN model in (Socher et al., 2013), PSTN also aims to minimize the cross-entropy error between the predicted distribution yi E Rmx1 at node i and the target distribution ti E Rmx1 at that node. That is, the error for a sentence is calculated as: E(0) = X X tijlogyij + A 110112 (7) i j where, A represents the regularization hyperparameters, and j E m denotes the j-th element of the multinomial target distribution. To minimize E(0), the gradient of the objective function with respect to each of the parameters in 0 is calculated efficiently via backpropagation through structure, as proposed by Goller and Kchler (1996). Specifically, we first compute the prediction errors in all tree nodes bottom-up. After this forward process, we then calculate the derivatives of the softmax classifiers at each node in the tree in a top-down fashion. We will discuss the gradient computation for the Vsen and Wsen in detail next. Note that the gradient calculations for the V, W, W label, L are the same as that of presented in (Socher et al., 2013). In the backpropogation process of the training, each node (except the root node) in the tree carries two kinds of errors: the local softmax error and the error passing down from i</context>
</contexts>
<marker>Goller, Kchler, 1996</marker>
<rawString>Christoph Goller and Andreas Kchler. 1996. Learning task-dependent distributed representations by backpropagation through structure. In In Proc. of the ICNN-96, pages 347–352, Bochum, Germany. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Andrew Hickl</author>
<author>Finley Lacatusu</author>
</authors>
<title>Negation, contrast and contradiction in text processing.</title>
<date>2006</date>
<booktitle>In AAAI,</booktitle>
<volume>6</volume>
<pages>755--762</pages>
<contexts>
<context position="6854" citStr="Harabagiu et al., 2006" startWordPosition="1086" endWordPosition="1089">en, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A dif</context>
</contexts>
<marker>Harabagiu, Hickl, Lacatusu, 2006</marker>
<rawString>Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu. 2006. Negation, contrast and contradiction in text processing. In AAAI, volume 6, pages 755–762.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the 8th Conference ofEuropean Chapter of the Association for Computational Linguistics, EACL ’97,</booktitle>
<pages>174--181</pages>
<location>Madrid,</location>
<contexts>
<context position="6173" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="984" endWordPosition="988">negative or positive value corresponds to a negative or a positive sentiment respectively; zero means neutral. The negator list will be discussed later in the paper. 2Similar distribution is observed in other data such as Tweets (Kiritchenko et al., 2014). 2 Related work Automatic sentiment analysis The expression of sentiment is an integral component of human language. In written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection sys</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the 8th Conference ofEuropean Chapter of the Association for Computational Linguistics, EACL ’97, pages 174–181, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lifeng Jia</author>
<author>Clement Yu</author>
<author>Weiyi Meng</author>
</authors>
<title>The effect of negation on sentiment analysis and retrieval effectiveness.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09,</booktitle>
<pages>1827--1830</pages>
<publisher>ACM.</publisher>
<location>Hong Kong, China.</location>
<contexts>
<context position="7714" citStr="Jia et al., 2009" startWordPosition="1229" endWordPosition="1232">posites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-c</context>
</contexts>
<marker>Jia, Yu, Meng, 2009</marker>
<rawString>Lifeng Jia, Clement Yu, and Weiyi Meng. 2009. The effect of negation on sentiment analysis and retrieval effectiveness. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09, pages 1827–1830, Hong Kong, China. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Kennedy</author>
<author>Diana Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="2433" citStr="Kennedy and Inkpen, 2006" startWordPosition="385" endWordPosition="388">nd understand the behavior (reviewed in Section 2). For example, Figure 1: Effect of a list of common negators in modifying sentiment values in Stanford Sentiment Treebank. The x-axis is s(w), and y-axis is s(w,,,, w). Each dot in the figure corresponds to a text span being modified by (composed with) a negator in the treebank. The red diagonal line corresponds to the sentiment-reversing hypothesis that simply reverses the sign of sentiment values. a simple yet influential hypothesis posits that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006). The shifting hypothesis (Taboada et al., 2011), however, assumes that negators change sentiment values by a constant amount. In this paper, we refer to a negation word as the negator (e.g., isn’t), a text span being modified by and composed with a negator as the argument (e.g., very good), and entire phrase (e.g., isn’t very good) as the negated phrase. The recently available Stanford Sentiment Treebank (Socher et al., 2013) renders manually annotated, real-valued sentiment scores for all phrases in parse trees. This corpus provides us with the data to further understand the quantitative beh</context>
<context position="7406" citStr="Kennedy and Inkpen, 2006" startWordPosition="1176" endWordPosition="1179">y on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the wo</context>
<context position="28470" citStr="Kennedy and Inkpen, 2006" startWordPosition="4738" endWordPosition="4741">between many negator pairs such as that between “is never” and “do not” as well as between “does not” and “can not”. Figure 3 also includes three diminishers (the is_never will_not is_not does_not barely was_not could_not not did_not unlikely do_not can_not no has_not superficial would_not should_not 310 0.30 0.25 0.20 0.15 is_not(nn) is_not(np) does_not(nn) does_not(np) not(nn) not(np) do_not(nn) do_not(np) no(nn) no(np) Figure 4: The behavior of individual negators in negated negative (nn) and negated positive (np) context. white bars), i.e., barely, unlikely, and superficial. By following (Kennedy and Inkpen, 2006), we extracted 319 diminishers (also called understatement or downtoners) from General Inquirer3. We calculated their shifting power in the same manner as for the negators and found three diminishers having shifting capability in the shifting range of these negators. This shows that the boundary between negators and diminishers can by fuzzy. In general, we argue that one should always consider modeling negators individually in a sentiment analysis system. Alternatively, if the modeling has to be done in groups, one should consider clustering valence shifters by their shifting abilities in trai</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>Alistair Kennedy and Diana Inkpen. 2006. Sentiment classification of movie reviews using contextual valence shifters. Computational Intelligence, 22(2):110–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
<author>Saif Mohammad</author>
</authors>
<title>Sentiment analysis of short informal texts. (to appear)</title>
<date>2014</date>
<journal>Journal of Artificial Intelligence Research.</journal>
<contexts>
<context position="5794" citStr="Kiritchenko et al., 2014" startWordPosition="924" endWordPosition="927">or’s argument with a recursive neural network. This approach performs significantly better than those mentioned above. In addition, we explicitly incorporate the prior sentiment of the argument and observe that this information helps reduce fitting errors. 1The sentiment values have been linearly rescaled from the original range [0, 1] to [-0.5, 0.5]; in the figure a negative or positive value corresponds to a negative or a positive sentiment respectively; zero means neutral. The negator list will be discussed later in the paper. 2Similar distribution is observed in other data such as Tweets (Kiritchenko et al., 2014). 2 Related work Automatic sentiment analysis The expression of sentiment is an integral component of human language. In written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling</context>
<context position="26105" citStr="Kiritchenko et al., 2014" startWordPosition="4362" endWordPosition="4365">ifferent from model (6), and the model with the double dagger ††is significantly better than model (7). One-tailed paired t-test with a 95% significance level is used here. Furthermore, modeling the syntax and semantics with the state-of-the-art recursive neural network (model 7 and 8) can dramatically improve the performance over model 6. The PSTN model, which takes into account the human-annotated prior sentiment of arguments, performs the best. This could suggest that additional external knowledge, e.g., that from human-built resources or automatically learned from other data (e.g., as in (Kiritchenko et al., 2014)), including sentiment that cannot be inferred from its constituent expressions, might be incorporated to benefit the current 0.30 0.25 0.20 0.15 0.10 0.05 Figure 3: Effect of different negators in shifting sentiment values. neural-network-based models as prior knowledge. Note that the two neural network based models incorporate the syntax and semantics by representing each node with a vector. One may consider that a straightforward way of considering the semantics of the modified phrases is simply memorizing them. For example, if a phrase very good modified by a negator not appears in the tra</context>
</contexts>
<marker>Kiritchenko, Zhu, Mohammad, 2014</marker>
<rawString>Svetlana Kiritchenko, Xiaodan Zhu, and Saif Mohammad. 2014. Sentiment analysis of short informal texts. (to appear) Journal of Artificial Intelligence Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<institution>Sapporo, Japan. Association for Computational Linguistics.</institution>
<contexts>
<context position="22614" citStr="Klein and Manning, 2003" startWordPosition="3787" endWordPosition="3790">e second category (weak negative), the resulting preal will be 0.2 (0.5*0.1+0.5*0.3). i 5 Experiment set-up Data As described earlier, the Stanford Sentiment Treebank (Socher et al., 2013) has manually annotated, real-valued sentiment values for all phrases in parse trees. This provides us with the training and evaluation data to study the effect of negators with syntax and semantics of different complexity in a natural setting. The data contain around 11,800 sentences from movie reviews that were originally collected by Pang and Lee (2005). The sentences were parsed with the Stanford parser (Klein and Manning, 2003). The phrases at all tree nodes were manually annotated with one of 25 sentiment values that uniformly span between the positive and negative poles. The values are normalized to the range of [0, 1]. In this paper, we use a list of most frequent negators that include the words not, no, never, and their combinations with auxiliaries (e.g., didn’t). We search these negators in the Stanford Sentiment Treebank and normalize the same negators to a single form; e.g., “is n’t”, “isn’t”, and “is not” are all normalized to “is not”. Each occurrence of a negator and the phrase it is directly composed wit</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423– 430, Sapporo, Japan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuele Lapponi</author>
<author>Jonathon Read</author>
<author>Lilja Ovrelid</author>
</authors>
<title>Representing and resolving negation for sentiment analysis.</title>
<date>2012</date>
<pages>687--692</pages>
<editor>In Jilles Vreeken, Charles Ling, Mohammed Javeed Zaki, Arno Siebes, Jeffrey Xu Yu, Bart Goethals, Geoffrey I. Webb, and Xindong Wu, editors, ICDM Workshops,</editor>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="7758" citStr="Lapponi et al., 2012" startWordPosition="1237" endWordPosition="1240">u and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman,</context>
</contexts>
<marker>Lapponi, Read, Ovrelid, 2012</marker>
<rawString>Emanuele Lapponi, Jonathon Read, and Lilja Ovrelid. 2012. Representing and resolving negation for sentiment analysis. In Jilles Vreeken, Charles Ling, Mohammed Javeed Zaki, Arno Siebes, Jeffrey Xu Yu, Bart Goethals, Geoffrey I. Webb, and Xindong Wu, editors, ICDM Workshops, pages 687– 692. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingjing Liu</author>
<author>Stephanie Seneff</author>
</authors>
<title>Review sentiment scoring via a parse-and-paraphrase paradigm. In</title>
<date>2009</date>
<booktitle>EMNLP,</booktitle>
<pages>161--169</pages>
<contexts>
<context position="7634" citStr="Liu and Seneff, 2009" startWordPosition="1215" endWordPosition="1219">ad, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and seman</context>
</contexts>
<marker>Liu, Seneff, 2009</marker>
<rawString>Jingjing Liu and Stephanie Seneff. 2009. Review sentiment scoring via a parse-and-paraphrase paradigm. In EMNLP, pages 161–169, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Lei Zhang</author>
</authors>
<title>A survey of opinion mining and sentiment analysis.</title>
<date>2012</date>
<booktitle>In Charu C. Aggarwal and ChengXiang Zhai, editors, Mining Text Data,</booktitle>
<pages>415--463</pages>
<publisher>Springer US.</publisher>
<contexts>
<context position="6543" citStr="Liu and Zhang (2012)" startWordPosition="1041" endWordPosition="1044">text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and</context>
</contexts>
<marker>Liu, Zhang, 2012</marker>
<rawString>Bing Liu and Lei Zhang. 2012. A survey of opinion mining and sentiment analysis. In Charu C. Aggarwal and ChengXiang Zhai, editors, Mining Text Data, pages 415–463. Springer US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franc¸ois Mairesse</author>
<author>Joseph Polifroni</author>
<author>Giuseppe Di Fabbrizio</author>
</authors>
<title>Can prosody inform sentiment analysis? experiments on short spoken reviews.</title>
<date>2012</date>
<booktitle>In ICASSP,</booktitle>
<pages>5093--5096</pages>
<location>Kyoto, Japan.</location>
<marker>Mairesse, Polifroni, Di Fabbrizio, 2012</marker>
<rawString>Franc¸ois Mairesse, Joseph Polifroni, and Giuseppe Di Fabbrizio. 2012. Can prosody inform sentiment analysis? experiments on short spoken reviews. In ICASSP, pages 5093–5096, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom M Mitchell</author>
</authors>
<date>1997</date>
<booktitle>Machine learning.</booktitle>
<pages>45</pages>
<publisher>McGraw Hill,</publisher>
<location>Burr Ridge, IL:</location>
<contexts>
<context position="9276" citStr="Mitchell, 1997" startWordPosition="1485" endWordPosition="1486"> a learning-based framework. The more recent work of (Socher et al., 2012; Socher et al., 2013) proposed models based on recursive neural networks that do not rely on any heuristic rules. Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition of the sentiment expressed by its constituting parts. The approach leverages a principled method, the forward and backward propagation, to learn a vector representation to optimize the system performance. In principle neural network is able to fit very complicated functions (Mitchell, 1997), and in this paper, we adapt the state-of-the-art approach described in (Socher et al., 2013) to help understand the behavior of negators specifically. 3 Negation models based on heuristics We begin with previously proposed methods that leverage heuristics to model the behavior of negators. We then propose to extend them to consider lexical information of the negators themselves. 3.1 Non-lexicalized assumptions and modeling In previous research, some influential, widely adopted assumptions posit the effect of negators to be independent of both the specific negators and the semantics and synta</context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Tom M Mitchell. 1997. Machine learning. 1997. Burr Ridge, IL: McGraw Hill, 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Bonnie J Dorr</author>
<author>Graeme Hirst</author>
<author>Peter D Turney</author>
</authors>
<title>Computing lexical contrast.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="7185" citStr="Mohammad et al. (2013)" startWordPosition="1143" endWordPosition="1146"> Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). I</context>
</contexts>
<marker>Mohammad, Dorr, Hirst, Turney, 2013</marker>
<rawString>Saif M. Mohammad, Bonnie J. Dorr, Graeme Hirst, and Peter D. Turney. 2013. Computing lexical contrast. Computational Linguistics, 39(3):555–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment composition.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP</booktitle>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="8363" citStr="Moilanen and Pulman, 2007" startWordPosition="1334" endWordPosition="1337">Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Socher et al., 2012; Socher et al., 2013), which achieved the state-of-the-art performance. Moilanen and Pulman (2007) used a collection of hand-written compositional rules to assign sentiment values to different granularities of text spans. Choi and Cardie (2008) proposed a learning-based framework. The more recent work of (Socher et al., 2012; Socher et al., 2013) proposed models based on recursive neural networks that do not rely on any heuristic rules. Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sent</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. 2007. Sentiment composition. In Proceedings of RANLP 2007, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Caroline Sporleder</author>
</authors>
<title>Modality and negation: An introduction to the special issue.</title>
<date>2012</date>
<journal>Computational linguistics,</journal>
<volume>38</volume>
<issue>2</issue>
<contexts>
<context position="1369" citStr="Morante and Sporleder (2012)" startWordPosition="213" endWordPosition="216">tics are poor estimators of sentiment. We then modify these heuristics to be dependent on the negators and show that this improves prediction. Next, we evaluate a recently proposed composition model (Socher et al., 2013) that relies on both the negator and the argument. This model learns the syntax and semantics of the negator’s argument with a recursive neural network. We show that this approach performs better than those mentioned above. In addition, we explicitly incorporate the prior sentiment of the argument and observe that this information can help reduce fitting errors. 1 Introduction Morante and Sporleder (2012) define negation to be “a grammatical category that allows the changing of the truth value of a proposition”. Negation is often expressed through the use of negative signals or negators–words like isn’t and never, and it can significantly affect the sentiment of its scope. Understanding the impact of negation on sentiment is essential in automatic analysis of sentiment. The literature contains interesting research attempting to model and understand the behavior (reviewed in Section 2). For example, Figure 1: Effect of a list of common negators in modifying sentiment values in Stanford Sentimen</context>
</contexts>
<marker>Morante, Sporleder, 2012</marker>
<rawString>Roser Morante and Caroline Sporleder. 2012. Modality and negation: An introduction to the special issue. Computational linguistics, 38(2):223–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</title>
<date>2005</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="22536" citStr="Pang and Lee (2005)" startWordPosition="3775" endWordPosition="3778"> probability to be in the first category (strong negative) and 0.5 for the second category (weak negative), the resulting preal will be 0.2 (0.5*0.1+0.5*0.3). i 5 Experiment set-up Data As described earlier, the Stanford Sentiment Treebank (Socher et al., 2013) has manually annotated, real-valued sentiment values for all phrases in parse trees. This provides us with the training and evaluation data to study the effect of negators with syntax and semantics of different complexity in a natural setting. The data contain around 11,800 sentences from movie reviews that were originally collected by Pang and Lee (2005). The sentences were parsed with the Stanford parser (Klein and Manning, 2003). The phrases at all tree nodes were manually annotated with one of 25 sentiment values that uniformly span between the positive and negative poles. The values are normalized to the range of [0, 1]. In this paper, we use a list of most frequent negators that include the words not, no, never, and their combinations with auxiliaries (e.g., didn’t). We search these negators in the Stanford Sentiment Treebank and normalize the same negators to a single form; e.g., “is n’t”, “isn’t”, and “is not” are all normalized to “is</context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, ACL ’05, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="6518" citStr="Pang and Lee (2008)" startWordPosition="1036" endWordPosition="1039">an language. In written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were propose</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1–2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>79--86</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="6192" citStr="Pang et al., 2002" startWordPosition="989" endWordPosition="992">ds to a negative or a positive sentiment respectively; zero means neutral. The negator list will be discussed later in the paper. 2Similar distribution is observed in other data such as Tweets (Kiritchenko et al., 2014). 2 Related work Automatic sentiment analysis The expression of sentiment is an integral component of human language. In written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detect</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of EMNLP, pages 79–86, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Annie Zaenen</author>
</authors>
<title>Contextual valence shifters.</title>
<date>2004</date>
<booktitle>In Exploring Attitude and Affect in Text: Theories and Applications (AAAI Spring Symposium Series).</booktitle>
<contexts>
<context position="2406" citStr="Polanyi and Zaenen, 2004" startWordPosition="381" endWordPosition="384">arch attempting to model and understand the behavior (reviewed in Section 2). For example, Figure 1: Effect of a list of common negators in modifying sentiment values in Stanford Sentiment Treebank. The x-axis is s(w), and y-axis is s(w,,,, w). Each dot in the figure corresponds to a text span being modified by (composed with) a negator in the treebank. The red diagonal line corresponds to the sentiment-reversing hypothesis that simply reverses the sign of sentiment values. a simple yet influential hypothesis posits that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006). The shifting hypothesis (Taboada et al., 2011), however, assumes that negators change sentiment values by a constant amount. In this paper, we refer to a negation word as the negator (e.g., isn’t), a text span being modified by and composed with a negator as the argument (e.g., very good), and entire phrase (e.g., isn’t very good) as the negated phrase. The recently available Stanford Sentiment Treebank (Socher et al., 2013) renders manually annotated, real-valued sentiment scores for all phrases in parse trees. This corpus provides us with the data to further unde</context>
<context position="7379" citStr="Polanyi and Zaenen, 2004" startWordPosition="1172" endWordPosition="1175">tion detection systems rely on detecting negated expressions and opposites (Harabagiu et al., 2006). In general, a negated expression and the opposite of the expression may or may not convey the same meaning. For example, not alive has the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased mod</context>
</contexts>
<marker>Polanyi, Zaenen, 2004</marker>
<rawString>Livia Polanyi and Annie Zaenen. 2004. Contextual valence shifters. In Exploring Attitude and Affect in Text: Theories and Applications (AAAI Spring Symposium Series).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’12, Jeju, Korea. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8407" citStr="Socher et al., 2012" startWordPosition="1342" endWordPosition="1345">he process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Socher et al., 2012; Socher et al., 2013), which achieved the state-of-the-art performance. Moilanen and Pulman (2007) used a collection of hand-written compositional rules to assign sentiment values to different granularities of text spans. Choi and Cardie (2008) proposed a learning-based framework. The more recent work of (Socher et al., 2012; Socher et al., 2013) proposed models based on recursive neural networks that do not rely on any heuristic rules. Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition of the sentiment expre</context>
<context position="15157" citStr="Socher et al., 2012" startWordPosition="2450" endWordPosition="2453">iment analysis. tree of a given sentence. Each node of the parse tree is a fixed-length vector that encodes compositional semantics and syntax, which can be used to predict the sentiment of this node. The vector of a node, say p2 in Figure 2, is computed from the ddimensional vectors of its two children, namely a and p1 (a, p1 E Rdx1), with a non-linear function: 1 p2 = tanh( [ a] T V [1:d] [pa ]+ W [p1] a) (5) p1 1 where, W E Rdx(d+d) and V E R(d+d)x(d+d)xd are the matrix and tensor for the composition function. A major difference of RNTN from the conventional recursive neural network (RRN) (Socher et al., 2012) is the use of the tensor V in order to directly capture the multiplicative interaction of two input vectors, although the matrix W implicitly captures the nonlinear interaction between the input vectors. The training of RNTN uses conventional forward-backward propagation. 4.2 PSTI: Prior sentiment-enriched tensor network The non-uniform distribution in Figure 1 has showed certain correlations between the sentiment values of s(wn, ~w) and s(~w), and such information has been leveraged in the models discussed in Section 3. We intend to devise a model that implements Equation 4. It bridges betwe</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’12, Jeju, Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’13,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, USA.</location>
<contexts>
<context position="961" citStr="Socher et al., 2013" startWordPosition="146" endWordPosition="149">mental role in modifying sentiment of textual expressions. We will refer to a negation word as the negator and the text span within the scope of the negator as the argument. Commonly used heuristics to estimate the sentiment of negated expressions rely simply on the sentiment of argument (and not on the negator or the argument itself). We use a sentiment treebank to show that these existing heuristics are poor estimators of sentiment. We then modify these heuristics to be dependent on the negators and show that this improves prediction. Next, we evaluate a recently proposed composition model (Socher et al., 2013) that relies on both the negator and the argument. This model learns the syntax and semantics of the negator’s argument with a recursive neural network. We show that this approach performs better than those mentioned above. In addition, we explicitly incorporate the prior sentiment of the argument and observe that this information can help reduce fitting errors. 1 Introduction Morante and Sporleder (2012) define negation to be “a grammatical category that allows the changing of the truth value of a proposition”. Negation is often expressed through the use of negative signals or negators–words </context>
<context position="2863" citStr="Socher et al., 2013" startWordPosition="459" endWordPosition="462">sentiment values. a simple yet influential hypothesis posits that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006). The shifting hypothesis (Taboada et al., 2011), however, assumes that negators change sentiment values by a constant amount. In this paper, we refer to a negation word as the negator (e.g., isn’t), a text span being modified by and composed with a negator as the argument (e.g., very good), and entire phrase (e.g., isn’t very good) as the negated phrase. The recently available Stanford Sentiment Treebank (Socher et al., 2013) renders manually annotated, real-valued sentiment scores for all phrases in parse trees. This corpus provides us with the data to further understand the quantitative behavior of negators, as the effect of negators can now be studied with arguments of rich syntactic and semantic variety. Figure 1 illustrates the effect of a common list of negators on sentiment as observed 304 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 304–313, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics on the Stanford Sentiment</context>
<context position="8429" citStr="Socher et al., 2013" startWordPosition="1346" endWordPosition="1349">c composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Socher et al., 2012; Socher et al., 2013), which achieved the state-of-the-art performance. Moilanen and Pulman (2007) used a collection of hand-written compositional rules to assign sentiment values to different granularities of text spans. Choi and Cardie (2008) proposed a learning-based framework. The more recent work of (Socher et al., 2012; Socher et al., 2013) proposed models based on recursive neural networks that do not rely on any heuristic rules. Such models work in a bottom-up fashion over the parse tree of a sentence to infer the sentiment label of the sentence as a composition of the sentiment expressed by its constituti</context>
<context position="13821" citStr="Socher et al. (2013)" startWordPosition="2218" endWordPosition="2221">els to be dependent on the arguments. This can be written as: s(wn, ~w) def = f(wn, s(~w), r(~w)) (4) In the formula, r(~w) is a certain type of representation for the argument w~ and it models the semantics or/and syntax of the argument. There exist different ways of implementing r(~w). We consider two models in this study: one drops s(~w) in Equation 4 and directly models f(wn, r(~w)). That is, the non-uniform information shown in Figure 1 is not directly modeled. The other takes into account s(~w) too. For the former, we adopt the recursive neural tensor network (RNTN) proposed recently by Socher et al. (2013), which has showed to achieve the state-of-the-art performance in sentiment analysis. For the latter, we propose a prior sentimentenriched tensor network (PSTN) to take into account the prior sentiment of the argument s(~w). 4.1 RITI: Recursive neural tensor network A recursive neural tensor network (RNTN) is a specific form of feed-forward neural network based on syntactic (phrasal-structure) parse tree to conduct compositional sentiment analysis. For completeness, we briefly review it here. More details can be found in (Socher et al., 2013). As shown in the black portion of Figure 2, each in</context>
<context position="17922" citStr="Socher et al., 2013" startWordPosition="2933" endWordPosition="2936">e to extend the current recursive neural network to consider extrinsic knowledge. However, in our current study, we focus on exploring the behavior of negators. As we have discussed above, we will use the human annotated sentiment for the arguments, same as in the models discussed in Section 3. With the new matrix and tensor, we then have 0 = (V, V sen, W, Wsen, Wlabel, L) as the PSTN model’s parameters. Here, L denotes the vector representations of the word dictionary. 4.2.1 Inference and Learning Inference and learning in PSTN follow a forwardbackward propagation process similar to that in (Socher et al., 2013), and for completeness, we depict the details as follows. To train the model, one first needs to calculate the predicted sentiment distribution for each node: psen i= Wlabelpi, psen iE Rmx1 and then compute the posterior probability over the m labels: yi = softmax(psen) i During learning, following the method used by the RNTN model in (Socher et al., 2013), PSTN also aims to minimize the cross-entropy error between the predicted distribution yi E Rmx1 at node i and the target distribution ti E Rmx1 at that node. That is, the error for a sentence is calculated as: E(0) = X X tijlogyij + A 11011</context>
<context position="19287" citStr="Socher et al., 2013" startWordPosition="3172" endWordPosition="3175">inimize E(0), the gradient of the objective function with respect to each of the parameters in 0 is calculated efficiently via backpropagation through structure, as proposed by Goller and Kchler (1996). Specifically, we first compute the prediction errors in all tree nodes bottom-up. After this forward process, we then calculate the derivatives of the softmax classifiers at each node in the tree in a top-down fashion. We will discuss the gradient computation for the Vsen and Wsen in detail next. Note that the gradient calculations for the V, W, W label, L are the same as that of presented in (Socher et al., 2013). In the backpropogation process of the training, each node (except the root node) in the tree carries two kinds of errors: the local softmax error and the error passing down from its parent node. During the derivative computation, the two errors will be summed up as the complement incoming error for the node. We denote the complete incoming error and the softmax error vector for node i as Si,com E Rdx1 and Si,s E Rdx1, respectively. With this notation, the error for the root node p2 can be formulated as follows. Sp2,com = Sp2,s = (WT (yp2 − tp2)) ® f′([a;p1]) (8) where ® is the Hadamard produ</context>
<context position="21599" citStr="Socher et al. (2013)" startWordPosition="3617" endWordPosition="3620">imilarly. Finally, we can finish the above equations with the following formula for computing δp2,down: δp2,down = (WT δp2,com) ® f′([a; p1]) + δtensor where δtensor = [δV [1 : d] + δV se&apos;[1 : d], δV [d + 1 : 2d]] δp2,com k (V[k] + (V[k])T) ® f′([a; p1])[1 : d] δp2,com(V[k]n + (Uk]n)T) ® f′([a; p1en])[1 : d k δp2,com k (V[k] + (V[k])T) ® f′([a; p1])[d + 1 : 2d] After the models are trained, they are applied to predict the sentiment of the test data. The original RNTN and the PSTN predict 5-class sentiment for each negated phrase; we map the output to real-valued scores based on the scale that Socher et al. (2013) used to map real-valued sentiment scores to sentiment categories. Specifically, we conduct the mapping with the formula: preal i = yi · [0.1 0.3 0.5 0.7 0.9]; i.e., we calculate the dot product of the posterior probability yi and the scaling vector. For example, if yi = [0.5 0.5 0 0 0], meaning this phrase has a 0.5 probability to be in the first category (strong negative) and 0.5 for the second category (weak negative), the resulting preal will be 0.2 (0.5*0.1+0.5*0.3). i 5 Experiment set-up Data As described earlier, the Stanford Sentiment Treebank (Socher et al., 2013) has manually annotat</context>
<context position="23452" citStr="Socher et al., 2013" startWordPosition="3935" endWordPosition="3938">se a list of most frequent negators that include the words not, no, never, and their combinations with auxiliaries (e.g., didn’t). We search these negators in the Stanford Sentiment Treebank and normalize the same negators to a single form; e.g., “is n’t”, “isn’t”, and “is not” are all normalized to “is not”. Each occurrence of a negator and the phrase it is directly composed with in the treebank, i.e., (wn, ~w), is considered a data point in our study. In total, we collected 2,261 pairs, including 1,845 training and 416 test cases. The split of training and test data is same as specified in (Socher et al., 2013). Evaluation metrics We use the mean absolute error (MAE) to evaluate the models, which measures the averaged absolute offsets between the predicted sentiment values and the gold standard. More specifically, MAE is calculated as: MAE = N E�wn,~w) |(ˆs (wn, w) − s(wn, w))|, where ˆs(wn, ~w) denotes the gold sentiment value and s(wn, ~w) the predicted one for the pair (wn, ~w), and N is the total number of test instances. Note that mean square error (MSE) is another widely used measure for regression, but it is less intuitive for out task here. 6 Experimental results Overall regression performan</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’13, Seattle, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="2481" citStr="Taboada et al., 2011" startWordPosition="393" endWordPosition="396">For example, Figure 1: Effect of a list of common negators in modifying sentiment values in Stanford Sentiment Treebank. The x-axis is s(w), and y-axis is s(w,,,, w). Each dot in the figure corresponds to a text span being modified by (composed with) a negator in the treebank. The red diagonal line corresponds to the sentiment-reversing hypothesis that simply reverses the sign of sentiment values. a simple yet influential hypothesis posits that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006). The shifting hypothesis (Taboada et al., 2011), however, assumes that negators change sentiment values by a constant amount. In this paper, we refer to a negation word as the negator (e.g., isn’t), a text span being modified by and composed with a negator as the argument (e.g., very good), and entire phrase (e.g., isn’t very good) as the negated phrase. The recently available Stanford Sentiment Treebank (Socher et al., 2013) renders manually annotated, real-valued sentiment scores for all phrases in parse trees. This corpus provides us with the data to further understand the quantitative behavior of negators, as the effect of negators can</context>
<context position="7611" citStr="Taboada et al., 2011" startWordPosition="1211" endWordPosition="1214">the same meaning as dead, however, not tall does not always mean short. Some automatic methods to detect opposites were proposed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complica</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<pages>417--424</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="6207" citStr="Turney, 2002" startWordPosition="993" endWordPosition="994"> a positive sentiment respectively; zero means neutral. The negator list will be discussed later in the paper. 2Similar distribution is observed in other data such as Tweets (Kiritchenko et al., 2014). 2 Related work Automatic sentiment analysis The expression of sentiment is an integral component of human language. In written text, sentiment is conveyed with word senses and their composition, and in speech also via prosody such as pitch (Mairesse et al., 2012). Early work on automatic sentiment analysis includes the widely cited work of (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002), among others. Since then, there has been an explosion of research addressing various aspects of the problem, including detecting subjectivity, rating and classifying sentiment, labeling sentiment-related semantic roles (e.g., target of sentiment), and visualizing sentiment (see surveys by Pang and Lee (2008) and Liu and Zhang (2012)). Negation modeling Negation is a general grammatical category pertaining to the changing of the truth values of propositions; negation modeling is not limited to sentiment. For example, paraphrase and contradiction detection systems rely on detecting negated exp</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In ACL, pages 417–424, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wiegand</author>
<author>Alexandra Balahur</author>
<author>Benjamin Roth</author>
<author>Dietrich Klakow</author>
<author>Andr´es Montoyo</author>
</authors>
<title>A survey on the role of negation in sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, NeSpNLP ’10,</booktitle>
<pages>60--68</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7736" citStr="Wiegand et al., 2010" startWordPosition="1233" endWordPosition="1236">sed by Hatzivassiloglou and McKeown (1997) and Mohammad et al. (2013). Negation modeling for sentiment An early yet influential reversing assumption conjectures that a negator reverses the sign of the sentiment value of the modified text (Polanyi and Zaenen, 2004; Kennedy and Inkpen, 2006), e.g., from +0.5 to - 0.5, or vice versa. A different hypothesis, called the shifting hypothesis in this paper, assumes that negators change the sentiment values by a constant amount (Taboada et al., 2011; Liu and Seneff, 2009). Other approaches to negation modeling have been discussed in (Jia et al., 2009; Wiegand et al., 2010; Lapponi et al., 2012; Benamara et al., 2012). In the process of semantic composition, the effect of negators could depend on the syntax and semantics of the text spans they modify. The approaches of modeling this include bag-of-wordbased models. For example, in the work of (Kennedy and Inkpen, 2006), a feature not good will be created if the word good is encountered 305 within a predefined range after a negator. There exist different ways of incorporating more complicated syntactic and semantic information. Much recent work considers sentiment analysis from a semantic-composition perspective</context>
</contexts>
<marker>Wiegand, Balahur, Roth, Klakow, Montoyo, 2010</marker>
<rawString>Michael Wiegand, Alexandra Balahur, Benjamin Roth, Dietrich Klakow, and Andr´es Montoyo. 2010. A survey on the role of negation in sentiment analysis. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, NeSpNLP ’10, pages 60–68, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>347--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16668" citStr="Wilson et al. (2005)" startWordPosition="2724" endWordPosition="2727">argument. To this end, we make use of the sentiment class information of 307 p1, noted as psen 1 .As a result, the vector of p2 is calculated as follows: [ a]T [pa1 [p1] p2 = tanh( V [1:d] J+Wa(6) p1 1 � a ~T V sen[1:d] � a � � a � + + Wsen ) psen psen psen 1 1 1 As shown in Equation 6, for the node vector p1 E Rdx1, we employ a matrix, namely Wsen E Rdx(d+m) and a tensor, V sen E R(d+m)x(d+m)xd, aiming at explicitly capturing the interplays between the sentiment class of p1, denoted as psen 1 (E Rmx1), and the negator a. Here, we assume the sentiment task has m classes. Following the idea of Wilson et al. (2005), we regard the sentiment of p1 as a prior sentiment as it has not been affected by the specific context (negators), so we denote our method as prior sentiment-enriched tensor network (PSTN). In Figure 2, the red portion shows the added components of PSTN. Note that depending on different purposes, psen 1 can take the value of the automatically predicted sentiment distribution obtained in forward propagation, the gold sentiment annotation of node p1, or even other normalized prior sentiment value or confidence score from external sources (e.g., sentiment lexicons or external training data). Th</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 347–354, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>