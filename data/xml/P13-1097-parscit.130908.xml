<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.99047">
Probabilistic Sense Sentiment Similarity through Hidden Emotions
</title>
<author confidence="0.999687">
Mitra Mohtarami1, Man Lan2, and Chew Lim Tan1
</author>
<affiliation confidence="0.9995715">
1Department of Computer Science, National University of Singapore;
2Department of Computer Science, East China Normal University
</affiliation>
<email confidence="0.998478">
{mitra,tancl}@comp.nus.edu.sg;mlan@cs.ecnu.edu.cn
</email>
<sectionHeader confidence="0.99522" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.98122494117647">
Sentiment Similarity of word pairs reflects the
distance between the words regarding their
underlying sentiments. This paper aims to in-
fer the sentiment similarity between word
pairs with respect to their senses. To achieve
this aim, we propose a probabilistic emotion-
based approach that is built on a hidden emo-
tional model. The model aims to predict a vec-
tor of basic human emotions for each sense of
the words. The resultant emotional vectors are
then employed to infer the sentiment similarity
of word pairs. We apply the proposed ap-
proach to address two main NLP tasks, name-
ly, Indirect yes/no Question Answer Pairs in-
ference and Sentiment Orientation prediction.
Extensive experiments demonstrate the effec-
tiveness of the proposed approach.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999508916666667">
Sentiment similarity reflects the distance be-
tween words based on their underlying senti-
ments. Semantic similarity measures such as La-
tent Semantic Analysis (LSA) (Landauer et al.,
1998) can effectively capture the similarity be-
tween semantically related words like &amp;quot;car&amp;quot; and
&amp;quot;automobile&amp;quot;, but they are less effective in relat-
ing words with similar sentiment orientation like
&amp;quot;excellent&amp;quot; and &amp;quot;superior&amp;quot;. For example, the fol-
lowing relations show the semantic similarity
between some sentiment words computed by
LSA:
</bodyText>
<equation confidence="0.856903">
E1: LSA (excellent, superior) = 0.40
&lt; LSA (excellent, good) = 0.46
&lt; LSA (good, bad) = 0.65
</equation>
<bodyText confidence="0.998222277777778">
Clearly, the sentiment similarity between the
above words should be in the reversed order. In
fact, the sentiment intensity in &amp;quot;excellent&amp;quot; is
closer to &amp;quot;superior&amp;quot; than &amp;quot;good&amp;quot;. Furthermore,
sentiment similarity between &amp;quot;good&amp;quot; and &amp;quot;bad&amp;quot;
should be 0.
In this paper, we propose a probabilistic ap-
proach to detect the sentiment similarity of
words regarding their senses and underlying sen-
timents. For this purpose, we propose to model
the hidden emotions of word senses. We show
that our approach effectively outperforms the
semantic similarity measures in two NLP tasks:
Indirect yes/no Question Answer Pairs (IQAPs)
Inference and Sentiment Orientation (SO) pre-
diction that are described as follows:
In IQAPs, answers do not explicitly contain
the yes or no keywords, but rather provide con-
text information to infer the yes or no answer
(e.g. Q: Was she the best one on that old show?
A: She was simply funny). Clearly, the sentiment
words in IQAPs are the pivots to infer the yes or
no answers. We show that sentiment similarity
between such words (e.g., here the adjectives
best and Funny) can be used effectively to infer
the answers.
The second application (SO prediction) aims to
determine the sentiment orientation of individual
words. Previous research utilized the semantic
relations between words obtained from WordNet
(Hassan and Radev, 2010) and semantic similari-
ty measures (e.g. Turney and Littman, 2003) for
this purpose. In this paper, we show that senti-
ment similarity between word pairs can be effec-
tively utilized to compute SO of words.
The contributions of this paper are follows:
</bodyText>
<listItem confidence="0.973228375">
• We propose an effective approach to predict
the sentiment similarity between word pairs
through hidden emotions at the sense level,
• We show the utility of sentiment similarity
prediction in IQAP inference and SO predic-
tion tasks, and
• Our hidden emotional model can infer the type
and number of hidden emotions in a corpus.
</listItem>
<page confidence="0.991623">
983
</page>
<note confidence="0.9390925">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 983–992,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.872979" genericHeader="introduction">
2 Sentiment Similarity through Hidden
Emotions
</sectionHeader>
<bodyText confidence="0.9820755">
As we discussed above, semantic similarity
measures are less effective to infer sentiment
similarity between word pairs. In addition, dif-
ferent senses of sentiment words carry different
human emotions. In fact, a sentiment word can
be represented as a vector of emotions with in-
tensity values from &amp;quot;very weak&amp;quot; to &amp;quot;very strong&amp;quot;.
For example, Table 1 shows several sentiment
words and their corresponding emotion vectors
based the following set of emotions: e = [anger,
disgust, sadness, fear, guilt, interest, joy, shame,
surprise]. For example, &amp;quot;deceive&amp;quot; has 0.4 and 0.5
intensity values with respect to the emotions
&amp;quot;disgust&amp;quot; and &amp;quot;sadness&amp;quot; with an overall -0.9 (i.e.
-0.4-0.5) value for sentiment orientation
(Neviarouskaya et al., 2007; Neviarouskaya et
al., 2009).
Word Emotional Vector SO
e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise]
Rude [&apos;0.2&apos;, &apos;0.4&apos;,0,0,0,0,0,0,0] -0.6
doleful [0, 0, &apos;0.4&apos;,0,0,0,0,0,0] -0.4
smashed [0,0, &apos;0.8&apos;, &apos;0.6&apos;,0,0,0,0,0] -1.4
shamefully [0,0,0,0,0,0,0, &apos;0.7&apos;,0] -0.7
deceive [0, &apos;0.4&apos;, &apos;0.5&apos;,0,0,0,0,0,0] -0.9
</bodyText>
<tableCaption confidence="0.976081">
Table 1. Sample of emotional vectors
</tableCaption>
<bodyText confidence="0.999951333333334">
The difficulty of the sentiment similarity predic-
tion task is evident when terms carry different
types of emotions. For instance, all the words in
Table 1 have negative sentiment orientation, but,
they carry different emotions with different emo-
tion vectors. For example, &amp;quot;rude&amp;quot; reflects the
emotions &amp;quot;anger&amp;quot; and &amp;quot;disgust&amp;quot;, while the word
&amp;quot;doleful&amp;quot; only reflects the emotion &amp;quot;sadness&amp;quot;. As
such, the word &amp;quot;doleful&amp;quot; is closer to the words
&amp;quot;smashed&amp;quot; and &amp;quot;deceive&amp;quot; involving the emotion
&amp;quot;sadness&amp;quot; than others. We show that emotion
vectors of the words can be effectively utilized to
predict the sentiment similarity between them.
Previous research shows little agreement about
the number and types of the basic emotions
(Ortony and Turner 1990; Izard 1971). Thus, we
assume that the number and types of basic emo-
tions are hidden and not pre-defined and propose
a Probabilistic Sense Sentiment Similarity
(PSSS) approach to extract the hidden emotions
of word senses to infer their sentiment similarity.
</bodyText>
<sectionHeader confidence="0.994146" genericHeader="method">
3 Hidden Emotional Model
</sectionHeader>
<bodyText confidence="0.996292">
Online review portals provide rating mechanisms
(in terms of stars, e.g. 5- or 10-star rating) to al-
</bodyText>
<figureCaption confidence="0.534156">
igure 1.
Figure The structure of PSSS model
</figureCaption>
<bodyText confidence="0.997144217391304">
low users to attach ratings to their reviews. A
rating indicates the summarized opinion of a user
who ranks a product or service based on his feel-
ings. There are various feelings and emotions
behind such ratings with respect to the content of
the reviews.
Figure 1 shows the intermediate layer of hid-
den emotions behind the ratings (sentiments)
assigned to the documents (reviews) containing
the words. This Figure indicates the general
structure of our PSSS model. It shows that hid-
den emotions (ei) link the rating (rj) and the doc-
uments (dk). In this Section, we aim to employ
ratings and the relations among ratings, docu-
ments, and words to extract the hidden emotions.
Figure 2 illustrates a simple graphical model
using plate representation of Figure 1. As Figures
2 shows, the rating r from a set of ratings R=
{r1,...,rp} is assigned to a hidden emotion set
E={e1,...,ek}. A document d from a set of docu-
ments D= {d1,...,dN} with vocabulary set W=
{w1,...,wM} is associated with the hidden emotion
set.
</bodyText>
<figureCaption confidence="0.9959015">
(d): Bridged model
Figure 2. Hidden emotional model
</figureCaption>
<bodyText confidence="0.998676">
The model presented in Figure 2(a) has been
explored in (Mohtarami et al., 2013) and is called
Series Hidden Emotional Model (SHEM). This
representation assumes that the word w is de-
pendent to d and independent to e (we refer to
this Assumption as A1). However, in reality, a
word w can inherit properties (e.g., emotions)
</bodyText>
<figure confidence="0.335504">
(a): Series model
</figure>
<page confidence="0.87441">
984
</page>
<equation confidence="0.351863">
I
</equation>
<bodyText confidence="0.999870357142857">
from the document d that contains w. Thus, we
can assume that w is implicitly dependant on e.
To account for this, we present Bridged Hidden
Emotional Model (BHEM) shown in Figure 2(b).
Our assumption, A2, in the BHEM model is as
follows: w is dependent to both d and e.
Considering Figure 1, we represent the entire
text collection as a set of (w,d,r) in which each
observation (w,d,r) is associated with a set of
unobserved emotions. If we assume that the ob-
served tuples are independently generated, the
whole data set is generated based on the joint
probability of the observation tuples (w,d,r) as
the follows (Mohtarami et al., 2013):
</bodyText>
<equation confidence="0.99518575">
D = F1 F1F1 P(w, d, r)n(w,d,r)
r d w
= F1 F1 F1 P(w, d, r)n(w,d)n(d,r) (1)
r d w
</equation>
<bodyText confidence="0.998516">
where, P(w,d,r) is the joint probability of the tu-
ple (w,d,r), and n(w,d,r) is the frequency of w in
document d of rating r (note that n(w,d) is the
term frequency of w in d and n(d,r) is one if r is
assigned to d, and 0 otherwise). The joint proba-
bility for the BHEM is defined as follows con-
sidering hidden emotion e:
- regarding class probability of the hidden emotion e
to be assigned to the observation (w,d,r):
</bodyText>
<equation confidence="0.986614285714285">
P(w,d,r) = YP(w,d,r|e)P(e) =
= YP(w,d|e)P(r|e)P(e)
�
- regarding assumption A2 and Bayes&apos; Rule:
= YP(w|d,e)P(d,e)P(r|e)
e
- using Bayes&apos; Rule:
= YP(d, e|w)P(w)P(r|e)
e
- regarding A2 and conditional independency:
= YP(d|w)P(e|w)P(w)P(r|e)
e
= P(d|w) Y P(w|e)P(e)P(r|e) (2)
e
</equation>
<bodyText confidence="0.999065166666667">
In the bridged model, the joint probability does
not depend on the probability P(d|e) and the
probabilities P(w|e), P(e) and P(r|e) are un-
known, while in the SHEM model explained in
(Mohtarami et al., 2013), the joint probability
does not depend on P(w|e), and probabilities
P(d|e), P(e), and P(r|e) are unknown.
We employ Maximum Likelihood approach to
learn the probabilities and infer the possible hid-
den emotions. The log-likelihood of the whole
data set D in Equation (1) can be defined as fol-
lows:
</bodyText>
<equation confidence="0.991386555555555">
L = YY
Yn(w,d)n(d,r)logP(w, d,r) (3)
r d w
Replacing P(w,d,r) by the values computed us-
ing the bridged model in Equation (2) results in:
L
= Y Y Y n(w, d)n(d,r)log[P(d|w) Y P(w|e)P(e)P(r|e)
r d w e
(4)
</equation>
<bodyText confidence="0.996052">
The above optimization problems are hard to
compute due to the log of sum. Thus, Expecta-
tion-maximization (EM) is usually employed.
EM consists of two following steps:
</bodyText>
<listItem confidence="0.998171166666667">
1. E-step: Calculates posterior probabilities for
hidden emotions given the words, documents
and ratings, and
2. M-step: Updates unknown probabilities (such
as P(w|e) etc) using the posterior probabilities
in the E-step.
</listItem>
<bodyText confidence="0.97694725">
The steps of EM can be computed for BHEM
model. EM of the model employs assumptions
A2 and Bayes Rule and is defined as follows:
E-step:
</bodyText>
<equation confidence="0.999147384615385">
P(r|e)P(e)P(w|e)
P(e|w,d,r) = (5)
EeP(r|e)P(e)P(w|e)
M-step:
Er Ewn(w, r) P(e|w, d, r)
P(w|e) = Ew Er Ed n(w, d)n(d, r) P(e|w, d, r)
Er Edn(w,d)n(d,r)P(e|w,d,r)
Er n(w, r) P(e|w, d, r) =(2)
EwErn(w, r) P(e|w, d, r)
P(e) = E rEdEwn(w,d)n(d,r)P(e|w, d,r)
Ee Ed Er Ew n(w, d)n(d, r) P(e|w, d, r)
ErEwn(w, r) P(e|w,d,r) (8)
E8 Er Ewn(w, r) P(e|w, d, r)
</equation>
<bodyText confidence="0.9986508">
Note that in Equation (5), the probability
P(e|w,d,r) does not depend on the document d.
Also, in Equations (6)-(8) we remove the de-
pendency on document d using the following
Equation:
</bodyText>
<equation confidence="0.887895">
Yn(w, d)n(d,r) =n(w,r) (9)
</equation>
<bodyText confidence="0.9342435">
d
where n(w,r) is the occurrence of w in all the
documents in the rating r.
The EM steps computed by the bridged model
do not depend on the variable document d, and
discard d from the model. The reason is that w
bypasses d to directly associate with the hidden
emotion e in Figure 2(b).
</bodyText>
<equation confidence="0.996553">
Ed Ewn(w, d)n(d,r)P(e|w, d,r)
P(r|e) =
ErEdEwn(w, d)n(d, r) P(e|w, d, r)
Ew n(w, r) P(e|w, d, r) (6)
</equation>
<page confidence="0.986153">
985
</page>
<bodyText confidence="0.999884">
Similar to BHEM, the EM steps for SHEM can
be computed by considering assumptions A1 and
Bayes Rule as follows (Mohtarami et al., 2013):
</bodyText>
<equation confidence="0.990045928571429">
E-step:
P(r|e)P(e)P(d|e)
P(e|w,d, r) = (10)
Ee P(r|e)P(e)P(d|e)
M-step:
E� E�n(w, d)n(d,r)P(e|w, d,r)
P(r|e) = (11)
ET EdEwn(w, d)n(d, r) P(e|w, d, r)
ETE�n(w,d)n(d,r)P(e|w,d, r)
P(d|e) = (12)
EdETEwn(w, d)n(d, r) P(e|w, d, r)
ET E�E�n(w,d)n(d,r) P(e|w,d, r)
P(e) = (13)
EeEdETEwn(w, d)n(d, r) P(e|w, d, r)
</equation>
<bodyText confidence="0.9998212">
Finally, we construct the emotional vectors us-
ing the algorithm presented in Table 2. The algo-
rithm employs document-rating, term-document
and term-rating matrices to infer the unknown
probabilities. This algorithm can be used with
both bridged or series models. Our goal is to in-
fer the emotional vector for each word w that can
be obtained by the probability P(w|e). Note that,
this probability can be simply computed for the
SHEM model using P(d|e) as follows:
</bodyText>
<equation confidence="0.998229">
P(w|e) = �P(w|d)P(d|e) (14)
</equation>
<bodyText confidence="0.542463">
d
</bodyText>
<subsectionHeader confidence="0.997197">
3.1 Enriching Hidden Emotional Models
</subsectionHeader>
<bodyText confidence="0.999988777777778">
We enrich our emotional model by employing
the requirement that the emotional vectors of two
synonym words w1 and w2 should be similar. For
this purpose, we utilize the semantic similarity
between each two words and create an enriched
matrix. Equation (15) shows how we compute
this matrix. To compute the semantic similarity
between word senses, we utilize their synsets as
follows:
</bodyText>
<equation confidence="0.999870166666667">
wjwi = P(syn(wj)|syn(wi))
= |�yn(wi) |� P�w�|wi�
|�yn(w�)|
1 � 1
|sm(wi) ||sm(wj)|
� � (15)
</equation>
<bodyText confidence="0.999749">
where, syn(w) is the synset of w. Let count(wi,
w;) be the co-occurrence of the wi and w;, and let
count(w;) be the total word count. The probabil-
ity of wi given w; will then be P(wi|w;) =
count(wi, w;)/ count(w;). In addition, note that
employing the synset of the words help to obtain
different emotional vectors for each sense of a
word.
The resultant enriched matrix WXW is multi-
plied to the inputs of our hidden model (matrices
WXD or WXR). Note that this takes into account
</bodyText>
<tableCaption confidence="0.996067">
Table 2. Constructing emotional vectors via P(w|e)
</tableCaption>
<bodyText confidence="0.999955238095238">
the senses of the words as well. The learning step
of EM is done using the updated inputs. In this
case, the correlated words can inherit the proper-
ties of each other. For example, if wi does not
occur in a document or rating involving another
word (i.e., w;), the word wi can still be indirectly
associated with the document or rating through
the word w;. However, the distribution of the
opinion words in documents and ratings is not
uniform. This may decrease the effectiveness of
the enriched matrix.
The nonuniform distribution of opinion words
has been also reported by Amiri et al. (2012)
who showed that the positive words are frequent-
ly used in negative reviews. We also observed
the same pattern in the development dataset. Fig-
ure 3 shows the overall occurrence of some posi-
tive and negative seeds in various ratings. As
shown, in spite of the negative words, the posi-
tive words may frequently occur in both positive
and negative documents. Such distribution of
</bodyText>
<table confidence="0.904711344827586">
Input:
Series Model: Document-Rate D×R, Term-Document
W×D
Bridged Model: Term-Rate W×R
Output: Emotional vectors {e1, e2, ...,ek} for w
Algorithm:
1. Enriching hidden emotional model:
Series Model: Update Term-Document W×D
Bridged Model: Update Term-Rate W×R
2. Initialize unknown probabilities:
Series Model: Initialize P(d|e), P(r|e), and P(e), ran-
domly
Bridged Model: Initialize P(w|e), P(r|e), and P(e)
3. while L has not converged to a pre-specified value do
4. E-step;
Series Model: estimate the value of P(e|w,d,r) in
Equation 10
Bridged Model: estimate the value of P(e|w,d,r) in
Equation 5
5. M-step;
Series Model: estimate the values of P(r|e), P(d|e),
and P(e) in Equations 11-13, respectively
Bridged Model: estimate the values of P(r|e), P(w|e),
and P(e) in Equations 6-8, respectively
6. end while
7. If series hidden emotional model is used then
8. Infer word emotional vector: estimate P(w|e) in
Equation 14.
9. End if
</table>
<page confidence="0.924554">
986
</page>
<figureCaption confidence="0.999053">
Figure 3. Nonuniform distribution of opinion words
</figureCaption>
<bodyText confidence="0.9998725">
positive words can mislead the enriched model.
To address this issue, we measure the confi-
dence of an opinion word in the enriched matrix
as follows.
</bodyText>
<equation confidence="0.992636">
ABS[(TF,,� x DF,,�) — (TF,,� x DF,,�)]
�)
(TF,, � x DF,, �) + (TF,, � x DF,,
(16)
</equation>
<bodyText confidence="0.9997226">
where, TF,,� (TF,,�) is the frequency of w in the
ratings 1 to 4 (7 to 10), and DF,,� (DF,,�) is the
total number of documents with rating 1 to 4 (7
to 10) that contain w. The confidence value of w
varies from 0 to 1, and it increases if:
</bodyText>
<listItem confidence="0.977621">
• There is a large difference between the occur-
rences of w in positive and negative ratings.
• There is a large number of reviews involving
w in the relative ratings.
</listItem>
<bodyText confidence="0.995503666666667">
To improve the efficiency of enriched matrix,
the columns corresponding to each word in the
matrix are multiplied by its confidence value.
</bodyText>
<sectionHeader confidence="0.989145" genericHeader="method">
4 Predicting Sentiment Similarity
</sectionHeader>
<bodyText confidence="0.998943333333333">
We utilize the approach proposed in (Mohtarami
et al., 2013) to compute the sentiment similarity
between two words. This approach compares the
emotional vector of the given words. Let X and Y
be the emotional vectors of two words. Equation
(17) computes their correlation:
</bodyText>
<equation confidence="0.977791">
corr , En i (Xi — X� (Y
X( — i — Y�) (17)
(n � 1)S�Sy
</equation>
<bodyText confidence="0.8953565">
where, n is number of emotional categories, X, Y
and SX, Sy are the mean and standard deviation
values of X and Y respectively. corr(X,Y) _ —1
indicates that the two vectors are completely dis-
similar, and corr(X,Y) _ 1 indicates that the vec-
tors have perfect similarity.
The approach makes use of a thresholding
mechanism to estimate the proper correlation
value to find sentimentally similar words. For
this, as in Mohtarami et al. (2013) we utilized the
antonyms of the words. We consider two words,
Input:
SAQ: The adjective in the question of given IQAP.
SAA: The adjective in the answer of given IQAP.
Output: answer C f yes, no, uncertain)
Algorithm:
</bodyText>
<listItem confidence="0.951755333333333">
1. if SAQ or SAA are missing from our corpus then
2. answer=Uncertain;
3. else if SS(SAQ, SAA) &lt; 0 then
4. answer=No;
5. else if SS(SAQ, SAA) &gt; 0 then
6. answer=yes;
</listItem>
<figureCaption confidence="0.993566">
Figure 4. Sentiment similarity for IQAP inference
</figureCaption>
<bodyText confidence="0.9602715">
wi and wj as similar in sentiment iff they satisfy
both of the following conditions:
</bodyText>
<listItem confidence="0.913852">
1. corr(wi, wj) &gt; corr(wi, ^-wj), and
2. corr(wi,wj) &gt; corr(—wi,wj)
</listItem>
<bodyText confidence="0.995669">
where, —wi is antonym of wi, and corr(wi,wj�
is obtained from Equation (17). Finally, we com-
pute the sentiment similarity (SS) as follows:
</bodyText>
<equation confidence="0.9961395">
SS(wi,wj) _
corr(wi, wj) — M ax{corr(wi,^-wj), corr�—wi, wj)} (18)
</equation>
<bodyText confidence="0.9995004">
Equation (18) enforces two sentimentally simi-
lar words to have weak correlation to the anto-
nym of each others. A positive value of SS(.,.)
indicates the words are sentimentally similar and
a negative value shows that they are dissimilar.
</bodyText>
<sectionHeader confidence="0.997709" genericHeader="method">
5 Applications
</sectionHeader>
<bodyText confidence="0.999995304347826">
We explain our approach in utilizing sentiment
similarity between words to perform IQAP infer-
ence and SO prediction tasks respectively.
In IQAPs, we employ the sentiment similarity
between the adjectives in questions and answers
to interpret the indirect answers. Figure 4 shows
the algorithm for this purpose. SS(.,.) indicates
sentiment similarity computed by Equation (18).
A positive SS means the words are sentimentally
similar and thus the answer is yes. However,
negative SS leads to a no response.
In SO-prediction task, we aim to compute
more accurate SO using our sentiment similarity
method. Turney and Littman (2003) proposed a
method in which the SO of a word is calculated
based on its semantic similarity with seven posi-
tive words minus its similarity with seven nega-
tive words as shown in Figure 5. As the similari-
ty function, A(.,.), they employed point-wise mu-
tual information (PMI) to compute the similarity
between the words. Here, we utilize the same
approach, but instead of PMI we use our SS(.,.)
measure as the similarity function.
</bodyText>
<equation confidence="0.344211">
Confidence,, _
</equation>
<page confidence="0.779559">
987
</page>
<figure confidence="0.9963429">
Input:
Pwords: seven words with positive SO
Nwords: seven words with negative SO
A(. ,. ): similarity function, and w: a given word with
unknown SO
Output: sentiment orientation of w
Algorithm:
1. P _ SO�A(w) _
�A(w, pword) − �A(w, ,word)
pwordE wwords nwordE Nwords
</figure>
<figureCaption confidence="0.999531">
Figure 5. SO based on the similarity function A(.,.)
</figureCaption>
<sectionHeader confidence="0.980769" genericHeader="evaluation">
6 Evaluation and Results
</sectionHeader>
<subsectionHeader confidence="0.989859">
6.1 Data and Settings
</subsectionHeader>
<bodyText confidence="0.9999576">
We used the review dataset employed by Maas et
al. (2011) as the development dataset that con-
tains movie reviews with star rating from one
star (most negative) to 10 stars (most positive).
We exclude the ratings 5 and 6 that are more
neutral. We used this dataset to compute all the
input matrices in Table 2 as well as the enriched
matrix. The development dataset contains 50k
movie reviews and 90k vocabulary.
We also used two datasets for the evaluation
purpose: the MPQA (Wilson et al., 2005) and
IQAPs (Marneffe et al., 2010) datasets. The
MPQA dataset is used for SO prediction experi-
ments, while the IQAP dataset is used for the
IQAP experiments. We ignored the neutral
words in MPQA dataset and used the remaining
4k opinion words. Also, the IQAPs dataset
(Marneffe et al., 2010) contains 125 IQAPs and
their corresponding yes or no labels as the
ground truth.
</bodyText>
<subsectionHeader confidence="0.997201">
6.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999988666666667">
To evaluate our PSSS model, we perform exper-
iments on the SO prediction and IQAPs infer-
ence tasks. Here, we consider six emotions for
both bridged and series models. We study the
effect of emotion numbers in Section 7.1. Also,
we set a threshold of 0.3 for the confidence value
in Equation (16), i.e. we set the confidence val-
ues smaller than the threshold to 0. We explain
the effect of this parameter in Section 7.3.
</bodyText>
<subsectionHeader confidence="0.830584">
Evaluation of SO Prediction
</subsectionHeader>
<bodyText confidence="0.9998102">
We evaluate the performance of our PSSS mod-
els in the SO prediction task using the algorithm
explained in Figure 5 by setting our PSSS as
similarity function (A). The results on SO predic-
tion are presented in Table 3. The first and se-
</bodyText>
<table confidence="0.9995408">
Method Precision Recall F1
PMI 56.20 56.36 55.01
ER 65.68 65.68 63.27
PSSS-SHEM 68.51 69.19 67.96
PSSS-BHEM 69.39 70.07 68.68
</table>
<tableCaption confidence="0.999865">
Table 3. Performance on SO prediction task
</tableCaption>
<bodyText confidence="0.9996738">
cond rows present the results of our baselines,
PMI (Turney and Littman, 2003) and Expected
Rating (ER) (Potts, 2011) of words respectively.
PMI extracts the semantic similarity between
words using their co-occurrences. As Table 3
shows, it leads to poor performance. This is
mainly due to the relatively small size of the de-
velopment dataset which affects the quality of
the co-occurrence information used by the PMI.
ER computes the expected rating of a word
based on the distribution of the word across rat-
ing categories. The value of ER indicates the SO
of the word. As shown in the two last rows of the
table, the results of PSSS approach are higher
than PMI and ER. The reason is that PSSS is
based on the combination between sentiment
space (through using ratings, and matrices W×R
in BHEM, D×R in SHEM) and semantic space
(through the input W×D in SHEM and enriched
matrix W×W in both hidden models). However,
the PMI employs only the semantic space (i.e.,
the co-occurrence of the words) and ER uses oc-
currence of the words in rating categories.
Furthermore, the PSSS model achieves higher
performance with BHEM rather than SHEM.
This is because the emotional vectors of the
words are directly computed from the EM steps
of BHEM. However, the emotional vectors of
SHEM are computed after finishing the EM steps
using Equation (14). This causes the SHEM
model to estimate the number and type of the
hidden emotions with a lower performance as
compared to BHEM, although the performances
of SHEM and BHEM are comparable as ex-
plained in Section 7.1.
</bodyText>
<subsectionHeader confidence="0.714453">
Evaluation of IQAPs Inference
</subsectionHeader>
<bodyText confidence="0.999957454545455">
To apply our PSSS on IQAPs inference task, we
use it as the sentiment similarity measure in the
algorithm explained in Figure 4. The results are
presented in Table 4. The first and second rows
are baselines. The first row is the result obtained
by Marneffe et al. (2010) approach. This ap-
proach is based on the similarity between the SO
of the adjectives in question and answer. The
second row of Table 4 show the results of using a
popular semantic similarity measure, PMI, as the
sentiment similarity (SS) measure in Figure 4.
</bodyText>
<page confidence="0.993981">
988
</page>
<table confidence="0.998840333333333">
Method Prec. Rec. F1
Marneffe et al. (2010) 60.00 60.00 60.00
PMI 60.61 58.70 59.64
PSSS-SHEM 62.55 61.75 61.71
PSSS-BHEM (w/o WSD) 65.90 66.11 63.74
SS-BHEM (with WSD) 66.95 67.15 65.66
</table>
<tableCaption confidence="0.999894">
Table 4. Performance on IQAP inference task
</tableCaption>
<bodyText confidence="0.999952923076923">
The result shows that PMI is less effective to
capture the sentiment similarity.
Our PSSS approach directly infers yes or no
responses using SS between the adjectives and
does not require computing SO of the adjectives.
In Table 4, PSSS-SHEM and PSSS-BHEM indi-
cate the results when we use our PSSS with
SHEM and BHEM respectively. Table 4 shows
the effectiveness of our sentiment similarity
measure. Both models improve the performance
over the baselines, while the bridged model leads
to higher performance than the series model.
Furthermore, we employ Word Sense Disam-
biguation (WSD) to disambiguate the adjectives
in the question and its corresponding answer. For
example, Q: ... Is that true? A: This is extraor-
dinary and preposterous. In the answer, the cor-
rect sense of the extraordinary is unusual and as
such answer no can be correctly inferred. In the
table, (w/o WSD) is based on the first sense (most
common sense) of the words, whereas (with
WSD) utilizes the real sense of the words. As
Table 4 shows, WSD increases the performance.
WSD could have higher effect, if more IQAPs
contain adjectives with senses different from the
first sense.
</bodyText>
<sectionHeader confidence="0.9574" genericHeader="evaluation">
7 Analysis and Discussions
</sectionHeader>
<subsectionHeader confidence="0.994713">
7.1 Number and Types of Emotions
</subsectionHeader>
<bodyText confidence="0.999779444444445">
In our PSSS approach, there is no limitation on
the number and types of emotions as we assumed
emotions are hidden. In this Section, we perform
experiments to predict the number and type of
hidden emotions.
Figure 6 and 7 show the results of the hidden
models (SHEM and BHEM) on SO prediction
and IQAPs inference tasks respectively with dif-
ferent number of emotions. As the Figures show,
in both tasks, SHEM achieved high performanc-
es with 11 emotions. However, BHEM achieved
high performances with six emotions. Now, the
question is which emotion number should be
considered? To answer this question, we further
study the results as follows.
First, for SHEM, there is no significant differ-
ence between the performances with six and 11
emotions in the SO prediction task. This is the
</bodyText>
<figureCaption confidence="0.99786975">
Figure 6. Performance of BHEM and SHEM on SO
prediction through different #of emotions
Figure 7. Performance of BHEM and SHEM on
IQAPs inference through different #of emotions
</figureCaption>
<bodyText confidence="0.999952433333333">
same for BHEM. Also, the performances of
SHEM on the IQAP inference task with six and
11 emotions are comparable. However, there is a
significant difference between the performances
of BHEM in six and 11 emotions. So, we consid-
er the dimension in which both hidden emotional
models present a reasonable performance over
both tasks. This dimension is six here.
Second, as shown in the Figures 6 and 7, in
contrast to BHEM, the performance of SHEM
does not considerably change with different
number of emotions over both tasks. This is be-
cause, in SHEM, the emotional vectors of the
words are derived from the emotional vectors of
the documents after the EM steps, see Equation
(14). However, in BHEM, the emotional vectors
are directly obtained from the EM steps. Thus,
the bridged model is more sensitive than series
model to the number of emotions. This could
indicate that the bridged model is more accurate
than the series model to estimate the number of
emotions.
Therefore, based on the above discussion, the
estimated number of emotions is six in our de-
velopment dataset. This number may vary using
different development datasets.
In addition to the number of emotions, their
types can also be interpreted using our approach.
To achieve this aim, we sort the words based on
their probability values, P(w|e), with respect to
</bodyText>
<page confidence="0.996999">
989
</page>
<figureCaption confidence="0.9937995">
Figure 8. Effect of synonyms &amp; antonyms in SO pre-
diction task with different emotion numbers in BHEM
Figure 9. Effect of confidence values in SO prediction
with different emotion numbers in BHEM
</figureCaption>
<table confidence="0.553871428571429">
Emotion#1 Emotion#2 Emotion#3
excellent (1) unimpressive (1) disreputable (1)
magnificently(1) humorlessly (1) villian (1)
blessed (1) paltry (1) onslaught (1)
sublime (1) humiliating (1) ugly (1)
affirmation (1) uncreative (1) old (1)
tremendous (2) lackluster (1) disrupt (1)
</table>
<tableCaption confidence="0.991487">
Table 5. Sample words in three emotions
</tableCaption>
<bodyText confidence="0.999971066666667">
each emotion. Then, the type of the emotions can
be interpreted by observing the top k words in
each emotion. For example, Table 5 shows the
top 6 words for three out of six emotions ob-
tained for BHEM. The numbers in parentheses
show the sense of the words. The corresponding
emotions for these categories can be interpreted
as &amp;quot;wonderful&amp;quot;, &amp;quot;boring&amp;quot; and &amp;quot;disreputable&amp;quot;, re-
spectively.
We also observed that, in SHEM with eleven
emotion numbers, some of the emotion catego-
ries have similar top k words such that they can
be merged to represent the same emotion. Thus,
it indicates that the BHEM is better than SHEM
to estimates the number of emotions than SHEM.
</bodyText>
<subsectionHeader confidence="0.998882">
7.2 Effect of Synsets and Antonyms
</subsectionHeader>
<bodyText confidence="0.999928107142857">
We show the important effect of synsets and an-
tonyms in computing the sentiment similarity of
words. For this purpose, we repeat the experi-
ment for SO prediction by computing sentiment
similarity of word pairs with and without using
synonyms and antonyms. Figure 8 shows the
results of obtained from BHEM. As the Figure
shown, the highest performance can be achieved
when synonyms and antonyms are used, while
the lowest performance is obtained without using
them. Note that, when the synonyms are not
used, the entries of enriched matrix are computed
using P(wi|wj) instead of P(syn(wi)|syn(wj)) in the
Equation (15). Also, when the antonyms are not
used, the Max(,) in Equation (18) is 0 and SS is
computed using only correlation between words.
The results show that synonyms can improve
the performance. As Figure 8 shows, the two
highest performances are obtained when we use
synonyms and the two lowest performances are
achieved when we don&apos;t use synonyms. This is
indicates that the synsets of the words can im-
prove the quality of the enriched matrix. The re-
sults also show that the antonyms can improve
the result (compare WOSynWAnt with
WOSynWOAnt). However, synonyms lead to
greater improvement than antonyms (compare
WSynWOAnt with WOSynWAnt).
</bodyText>
<subsectionHeader confidence="0.998963">
7.3 Effect of Confidence Value
</subsectionHeader>
<bodyText confidence="0.99992632">
In Section 3.1, we defined a confidence value for
each word to improve the quality of the enriched
matrix. To illustrate the utility of the confidence
value, we repeat the experiment for SO predic-
tion by BHEM using all the words appears in
enriched matrix with different confidence
thresholds. The results are shown in Figure 9,
&amp;quot;w/o confidence&amp;quot; shows the results when we
don’t use the confidence values, while &amp;quot;with con-
fidence&amp;quot; shows the results when use the confi-
dence values. Also, &amp;quot;confidence&gt;x&amp;quot; indicates the
results when we set all the confidence value
smaller than x to 0. The thresholding helps to
eliminate the effect of low confident words.
As Figure 9 shows, &amp;quot;w/o confidence&amp;quot; leads to
the lowest performance, while &amp;quot;with confidence&amp;quot;
improves the performance with different number
of emotions. The thresholding is also effective.
For example, a threshold like 0.3 or 0.4 improves
the performance. However, if a large value (e.g.,
0.6) is selected as threshold, the performance
decreases. This is because a large threshold fil-
ters a large number of words from enriched mod-
el that decreases the effect of the enriched ma-
trix.
</bodyText>
<subsectionHeader confidence="0.997808">
7.4 Convergence Analysis
</subsectionHeader>
<bodyText confidence="0.9632815">
The PSSS approach is based on the EM algo-
rithm for the BHEM (or SHEM) presented in
</bodyText>
<tableCaption confidence="0.654255">
Table 2. This algorithm performs a predefined
</tableCaption>
<page confidence="0.991784">
990
</page>
<bodyText confidence="0.999854636363636">
number of iterations or until convergence. To
study the convergence of the algorithm, we re-
peat our experiments for SO prediction and
IQAPs inference tasks using BHEM with differ-
ent number of iterations. Figure 10 shows that
after the first 15 iterations the performance does
not change dramatically and is nearly constant
when more than 30 iterations are performed. This
shows that our algorithm will converge in less
than 30 iterations for BHEM. We observed the
same pattern in SHEM.
</bodyText>
<subsectionHeader confidence="0.992456">
7.5 Bridged Vs. Series Model
</subsectionHeader>
<bodyText confidence="0.9999895">
The bridged and series models are both based on
the hidden emotions that were developed to pre-
dict the sense sentiment similarity. Although
their best results on the SO prediction and IQAPs
inference tasks are comparable, they have some
significant differences as follows:
</bodyText>
<listItem confidence="0.993807">
• BHEM is considerably faster than SHEM. The
reason is that, the input matrix of BHEM (i.e.,
W×R) is significantly smaller than the input
matrix of SHEM (i.e., W×D).
• In BHEM, the emotional vectors are directly
</listItem>
<bodyText confidence="0.7613175">
computed from the EM steps. However, the
emotional vector of a word in SHEM is com-
puted using the emotional vectors of the doc-
uments containing the word. This adds noises
to the emotional vectors of the words.
• BHEM gives more accurate estimation over
type and number of emotions versus SHEM.
The reason is explained in Section 7.1.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="related work">
8 Related Works
</sectionHeader>
<bodyText confidence="0.99993495">
Sentiment similarity has not received enough
attention to date. Most previous works employed
semantic similarity of word pairs to address SO
prediction and IQAP inference tasks. Turney and
Littman (2003) proposed to compute pair-wised
mutual information (PMI) between a target word
and a set of seed positive and negative words to
infer the SO of the target word. They also uti-
lized Latent Semantic Analysis (LSA) (Landauer
et al., 1998) as another semantic similarity meas-
ure. However, both PMI and LSA are semantic
similarity measure. Similarly, Hassan and Radev
(2010) presented a graph-based method for pre-
dicting SO of words. They constructed a lexical
graph where nodes are words and edges connect
two words with semantic similarity obtained
from Wordnet (Fellbaum 1998). They propagat-
ed the SO of a set of seeds through this graph.
However, such approaches did not take into ac-
count the sentiment similarity between words.
</bodyText>
<figureCaption confidence="0.994572">
Figure 10. Convergence of BHEM
</figureCaption>
<bodyText confidence="0.999993266666667">
In IQAPs, Marneffe et al. (2010) inferred the
yes/no answers using SO of the adjectives. If SO
of the adjectives have different signs, then the
answer conveys no, and Otherwise, if the abso-
lute value of SO for the adjective in question is
smaller than the absolute value of the adjective in
answer, then the answer conveys yes, and other-
wise no. In Mohtarami et al. (2012), we used two
semantic similarity measures (PMI and LSA) for
the IQAP inference task. We showed that meas-
uring the sentiment similarities between the ad-
jectives in question and answer leads to higher
performance as compared to semantic similarity
measures.
In Mohtarami et al. (2012), we proposed an
approach to predict the sentiment similarity of
words using their emotional vectors. We as-
sumed that the type and number of emotions are
pre-defined and our approach was based on this
assumption. However, in previous research, there
is little agreement about the number and types of
basic emotions. Furthermore, the emotions in
different dataset can be varied. We relaxed this
assumption in Mohtarami et al., (2013) by con-
sidering the emotions as hidden and presented a
hidden emotional model called SHEM. This pa-
per also consider the emotions as hidden and pre-
sents another hidden emotional model called
BHEM that gives more accurate estimation of
the numbers and types of the hidden emotions.
</bodyText>
<sectionHeader confidence="0.997704" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999993909090909">
We propose a probabilistic approach to infer the
sentiment similarity between word senses with
respect to automatically learned hidden emo-
tions. We propose to utilize the correlations be-
tween reviews, ratings, and words to learn the
hidden emotions. We show the effectiveness of
our method in two NLP tasks. Experiments show
that our sentiment similarity models lead to ef-
fective emotional vector construction and signif-
icantly outperform semantic similarity measures
for the two NLP task.
</bodyText>
<page confidence="0.997275">
991
</page>
<sectionHeader confidence="0.995766" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999897236111111">
Hadi Amiri and Tat S. Chua. 2012. Mining Slang
and Urban Opinion Words and Phrases from
cQA Services: An Optimization Approach.
Proceedings of the fifth ACM international confer-
ence on Web search and data mining (WSDM). Pp.
193-202.
Christiane Fellbaum. 1998. WordNet: An Electron-
ic Lexical Database. Cambridge, MA: MIT
Press.
Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing Text Polarity Using Random Walks. Pro-
ceeding in the Association for Computational Lin-
guistics (ACL). Pp: 395–403.
Aminul Islam and Diana Inkpen. 2008. Semantic text
similarity using corpus-based word similarity
and string similarity. ACM Transactions on
Knowledge Discovery from Data (TKDD).
Carroll E. Izard. 1971. The face of emotion. New
York: Appleton-Century-Crofts.
Soo M. Kim and Eduard Hovy. 2004. Determining
the sentiment of opinions. Proceeding of the
Conference on Computational Linguistics
(COLING). Pp: 1367–1373.
Thomas K. Landauer, Peter W. Foltz, and Darrell
Laham. 1998. Introduction to Latent Semantic
Analysis. Discourse Processes. Pp: 259-284.
Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Dan Huang, Andrew Y. Ng, and Christopher Potts.
2011. Learning Word Vectors for Sentiment
Analysis. Proceeding in the Association for Com-
putational Linguistics (ACL). Pp:142-150.
Marie-Catherine D. Marneffe, Christopher D. Man-
ning, and Christopher Potts. 2010. &amp;quot;Was it good?
It was provocative.&amp;quot; Learning the meaning of
scalar adjectives. Proceeding in the Association
for Computational Linguistics (ACL). Pp: 167–
176.
Mitra Mohtarami, Hadi Amiri, Man Lan, Thanh P.
Tran, and Chew L. Tan. 2012. Sense Sentiment
Similarity: An Analysis. Proceeding of the Con-
ference on Artificial Intelligence (AAAI).
Mitra Mohtarami, Man Lan, and Chew L. Tan. 2013.
From Semantic to Emotional Space in Proba-
bilistic Sense Sentiment Analysis. Proceeding of
the Conference on Artificial Intelligence (AAAI).
Alena Neviarouskaya, Helmut Prendinger, and
Mitsuru Ishizuka. 2007. Textual Affect Sensing
for Sociable and Expressive Online Communi-
cation. Proceedings of the conference on Affective
Computing and Intelligent Interaction (ACII). Pp:
218-229.
Alena Neviarouskaya, Helmut Prendinger, and
Mitsuru Ishizuka. 2009. SentiFul: Generating a
Reliable Lexicon for Sentiment Analysis. Pro-
ceeding of the conference on Affective Computing
and Intelligent Interaction (ACII). Pp: 363-368.
Andrew Ortony and Terence J. Turner. 1990. What&apos;s
Basic About Basic Emotions. American Psycho-
logical Association. 97(3), 315-331.
Christopher Potts, C. 2011. On the negativity of
negation. In Nan Li and David Lutz, eds., Pro-
ceedings of Semantics and Linguistic Theory 20,
636-659.
Peter D. Turney and Michael L. Littman. 2003.
Measuring Praise and Criticism: Inference of
Semantic Orientation from Association. ACM
Transactions on Information Systems, 21(4), 315–
346.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in
phrase-level sentiment analysis. Proceeding in
HLT-EMNLP. Pp: 347–354.
</reference>
<page confidence="0.99734">
992
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.819646">
<title confidence="0.999901">Probabilistic Sense Sentiment Similarity through Hidden Emotions</title>
<author confidence="0.998738">Man</author>
<author confidence="0.998738">Chew Lim</author>
<affiliation confidence="0.9872165">of Computer Science, National University of of Computer Science, East China Normal University</affiliation>
<email confidence="0.895038">mitra@comp.nus.edu.sg;mlan@cs.ecnu.edu.cn</email>
<email confidence="0.895038">tancl@comp.nus.edu.sg;mlan@cs.ecnu.edu.cn</email>
<abstract confidence="0.995404888888889">Similarity word pairs reflects the distance between the words regarding their underlying sentiments. This paper aims to infer the sentiment similarity between word pairs with respect to their senses. To achieve this aim, we propose a probabilistic emotionbased approach that is built on a hidden emotional model. The model aims to predict a vector of basic human emotions for each sense of the words. The resultant emotional vectors are then employed to infer the sentiment similarity of word pairs. We apply the proposed approach to address two main NLP tasks, nameyes/no Question Answer Pairs inand Orientation Extensive experiments demonstrate the effectiveness of the proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hadi Amiri</author>
<author>Tat S Chua</author>
</authors>
<title>Mining Slang and Urban Opinion Words and Phrases from cQA Services: An Optimization Approach.</title>
<date>2012</date>
<booktitle>Proceedings of the fifth ACM international conference on Web</booktitle>
<pages>193--202</pages>
<marker>Amiri, Chua, 2012</marker>
<rawString>Hadi Amiri and Tat S. Chua. 2012. Mining Slang and Urban Opinion Words and Phrases from cQA Services: An Optimization Approach. Proceedings of the fifth ACM international conference on Web search and data mining (WSDM). Pp. 193-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="32644" citStr="Fellbaum 1998" startWordPosition="5435" endWordPosition="5436">nference tasks. Turney and Littman (2003) proposed to compute pair-wised mutual information (PMI) between a target word and a set of seed positive and negative words to infer the SO of the target word. They also utilized Latent Semantic Analysis (LSA) (Landauer et al., 1998) as another semantic similarity measure. However, both PMI and LSA are semantic similarity measure. Similarly, Hassan and Radev (2010) presented a graph-based method for predicting SO of words. They constructed a lexical graph where nodes are words and edges connect two words with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of a set of seeds through this graph. However, such approaches did not take into account the sentiment similarity between words. Figure 10. Convergence of BHEM In IQAPs, Marneffe et al. (2010) inferred the yes/no answers using SO of the adjectives. If SO of the adjectives have different signs, then the answer conveys no, and Otherwise, if the absolute value of SO for the adjective in question is smaller than the absolute value of the adjective in answer, then the answer conveys yes, and otherwise no. In Mohtarami et al. (2012), we used two semantic similarity measures </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying Text Polarity Using Random Walks.</title>
<date>2010</date>
<booktitle>Proceeding in the Association for Computational Linguistics (ACL). Pp:</booktitle>
<pages>395--403</pages>
<contexts>
<context position="3019" citStr="Hassan and Radev, 2010" startWordPosition="460" endWordPosition="463">icitly contain the yes or no keywords, but rather provide context information to infer the yes or no answer (e.g. Q: Was she the best one on that old show? A: She was simply funny). Clearly, the sentiment words in IQAPs are the pivots to infer the yes or no answers. We show that sentiment similarity between such words (e.g., here the adjectives best and Funny) can be used effectively to infer the answers. The second application (SO prediction) aims to determine the sentiment orientation of individual words. Previous research utilized the semantic relations between words obtained from WordNet (Hassan and Radev, 2010) and semantic similarity measures (e.g. Turney and Littman, 2003) for this purpose. In this paper, we show that sentiment similarity between word pairs can be effectively utilized to compute SO of words. The contributions of this paper are follows: • We propose an effective approach to predict the sentiment similarity between word pairs through hidden emotions at the sense level, • We show the utility of sentiment similarity prediction in IQAP inference and SO prediction tasks, and • Our hidden emotional model can infer the type and number of hidden emotions in a corpus. 983 Proceedings of the</context>
<context position="32439" citStr="Hassan and Radev (2010)" startWordPosition="5401" endWordPosition="5404">reason is explained in Section 7.1. 8 Related Works Sentiment similarity has not received enough attention to date. Most previous works employed semantic similarity of word pairs to address SO prediction and IQAP inference tasks. Turney and Littman (2003) proposed to compute pair-wised mutual information (PMI) between a target word and a set of seed positive and negative words to infer the SO of the target word. They also utilized Latent Semantic Analysis (LSA) (Landauer et al., 1998) as another semantic similarity measure. However, both PMI and LSA are semantic similarity measure. Similarly, Hassan and Radev (2010) presented a graph-based method for predicting SO of words. They constructed a lexical graph where nodes are words and edges connect two words with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of a set of seeds through this graph. However, such approaches did not take into account the sentiment similarity between words. Figure 10. Convergence of BHEM In IQAPs, Marneffe et al. (2010) inferred the yes/no answers using SO of the adjectives. If SO of the adjectives have different signs, then the answer conveys no, and Otherwise, if the absolute value of SO for </context>
</contexts>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir Radev. 2010. Identifying Text Polarity Using Random Walks. Proceeding in the Association for Computational Linguistics (ACL). Pp: 395–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Semantic text similarity using corpus-based word similarity and string similarity.</title>
<date>2008</date>
<journal>ACM Transactions on Knowledge Discovery from Data (TKDD).</journal>
<marker>Islam, Inkpen, 2008</marker>
<rawString>Aminul Islam and Diana Inkpen. 2008. Semantic text similarity using corpus-based word similarity and string similarity. ACM Transactions on Knowledge Discovery from Data (TKDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carroll E Izard</author>
</authors>
<title>The face of emotion.</title>
<date>1971</date>
<location>New York: Appleton-Century-Crofts.</location>
<contexts>
<context position="5697" citStr="Izard 1971" startWordPosition="868" endWordPosition="869">ds in Table 1 have negative sentiment orientation, but, they carry different emotions with different emotion vectors. For example, &amp;quot;rude&amp;quot; reflects the emotions &amp;quot;anger&amp;quot; and &amp;quot;disgust&amp;quot;, while the word &amp;quot;doleful&amp;quot; only reflects the emotion &amp;quot;sadness&amp;quot;. As such, the word &amp;quot;doleful&amp;quot; is closer to the words &amp;quot;smashed&amp;quot; and &amp;quot;deceive&amp;quot; involving the emotion &amp;quot;sadness&amp;quot; than others. We show that emotion vectors of the words can be effectively utilized to predict the sentiment similarity between them. Previous research shows little agreement about the number and types of the basic emotions (Ortony and Turner 1990; Izard 1971). Thus, we assume that the number and types of basic emotions are hidden and not pre-defined and propose a Probabilistic Sense Sentiment Similarity (PSSS) approach to extract the hidden emotions of word senses to infer their sentiment similarity. 3 Hidden Emotional Model Online review portals provide rating mechanisms (in terms of stars, e.g. 5- or 10-star rating) to aligure 1. Figure The structure of PSSS model low users to attach ratings to their reviews. A rating indicates the summarized opinion of a user who ranks a product or service based on his feelings. There are various feelings and e</context>
</contexts>
<marker>Izard, 1971</marker>
<rawString>Carroll E. Izard. 1971. The face of emotion. New York: Appleton-Century-Crofts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo M Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>Proceeding of the Conference on Computational Linguistics (COLING). Pp:</booktitle>
<pages>1367--1373</pages>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo M. Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. Proceeding of the Conference on Computational Linguistics (COLING). Pp: 1367–1373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>Introduction to Latent Semantic Analysis. Discourse Processes.</title>
<date>1998</date>
<tech>Pp:</tech>
<pages>259--284</pages>
<contexts>
<context position="1247" citStr="Landauer et al., 1998" startWordPosition="179" endWordPosition="182">The model aims to predict a vector of basic human emotions for each sense of the words. The resultant emotional vectors are then employed to infer the sentiment similarity of word pairs. We apply the proposed approach to address two main NLP tasks, namely, Indirect yes/no Question Answer Pairs inference and Sentiment Orientation prediction. Extensive experiments demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment similarity reflects the distance between words based on their underlying sentiments. Semantic similarity measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1998) can effectively capture the similarity between semantically related words like &amp;quot;car&amp;quot; and &amp;quot;automobile&amp;quot;, but they are less effective in relating words with similar sentiment orientation like &amp;quot;excellent&amp;quot; and &amp;quot;superior&amp;quot;. For example, the following relations show the semantic similarity between some sentiment words computed by LSA: E1: LSA (excellent, superior) = 0.40 &lt; LSA (excellent, good) = 0.46 &lt; LSA (good, bad) = 0.65 Clearly, the sentiment similarity between the above words should be in the reversed order. In fact, the sentiment intensity in &amp;quot;excellent&amp;quot; is closer to &amp;quot;superior&amp;quot; than &amp;quot;good&amp;quot;. F</context>
<context position="32305" citStr="Landauer et al., 1998" startWordPosition="5381" endWordPosition="5384">oises to the emotional vectors of the words. • BHEM gives more accurate estimation over type and number of emotions versus SHEM. The reason is explained in Section 7.1. 8 Related Works Sentiment similarity has not received enough attention to date. Most previous works employed semantic similarity of word pairs to address SO prediction and IQAP inference tasks. Turney and Littman (2003) proposed to compute pair-wised mutual information (PMI) between a target word and a set of seed positive and negative words to infer the SO of the target word. They also utilized Latent Semantic Analysis (LSA) (Landauer et al., 1998) as another semantic similarity measure. However, both PMI and LSA are semantic similarity measure. Similarly, Hassan and Radev (2010) presented a graph-based method for predicting SO of words. They constructed a lexical graph where nodes are words and edges connect two words with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of a set of seeds through this graph. However, such approaches did not take into account the sentiment similarity between words. Figure 10. Convergence of BHEM In IQAPs, Marneffe et al. (2010) inferred the yes/no answers using SO of the</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K. Landauer, Peter W. Foltz, and Darrell Laham. 1998. Introduction to Latent Semantic Analysis. Discourse Processes. Pp: 259-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Maas</author>
<author>Raymond E Daly</author>
<author>Peter T Pham</author>
<author>Dan Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Learning Word Vectors for Sentiment Analysis. Proceeding in the Association for Computational Linguistics (ACL).</title>
<date>2011</date>
<pages>142--150</pages>
<contexts>
<context position="19189" citStr="Maas et al. (2011)" startWordPosition="3174" endWordPosition="3177">l information (PMI) to compute the similarity between the words. Here, we utilize the same approach, but instead of PMI we use our SS(.,.) measure as the similarity function. Confidence,, _ 987 Input: Pwords: seven words with positive SO Nwords: seven words with negative SO A(. ,. ): similarity function, and w: a given word with unknown SO Output: sentiment orientation of w Algorithm: 1. P _ SO�A(w) _ �A(w, pword) − �A(w, ,word) pwordE wwords nwordE Nwords Figure 5. SO based on the similarity function A(.,.) 6 Evaluation and Results 6.1 Data and Settings We used the review dataset employed by Maas et al. (2011) as the development dataset that contains movie reviews with star rating from one star (most negative) to 10 stars (most positive). We exclude the ratings 5 and 6 that are more neutral. We used this dataset to compute all the input matrices in Table 2 as well as the enriched matrix. The development dataset contains 50k movie reviews and 90k vocabulary. We also used two datasets for the evaluation purpose: the MPQA (Wilson et al., 2005) and IQAPs (Marneffe et al., 2010) datasets. The MPQA dataset is used for SO prediction experiments, while the IQAP dataset is used for the IQAP experiments. We </context>
</contexts>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning Word Vectors for Sentiment Analysis. Proceeding in the Association for Computational Linguistics (ACL). Pp:142-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine D Marneffe</author>
<author>Christopher D Manning</author>
<author>Christopher Potts</author>
</authors>
<title>Was it good? It was provocative.&amp;quot; Learning the meaning of scalar adjectives.</title>
<date>2010</date>
<booktitle>Proceeding in the Association for Computational Linguistics (ACL). Pp:</booktitle>
<pages>167--176</pages>
<contexts>
<context position="19662" citStr="Marneffe et al., 2010" startWordPosition="3257" endWordPosition="3260">. SO based on the similarity function A(.,.) 6 Evaluation and Results 6.1 Data and Settings We used the review dataset employed by Maas et al. (2011) as the development dataset that contains movie reviews with star rating from one star (most negative) to 10 stars (most positive). We exclude the ratings 5 and 6 that are more neutral. We used this dataset to compute all the input matrices in Table 2 as well as the enriched matrix. The development dataset contains 50k movie reviews and 90k vocabulary. We also used two datasets for the evaluation purpose: the MPQA (Wilson et al., 2005) and IQAPs (Marneffe et al., 2010) datasets. The MPQA dataset is used for SO prediction experiments, while the IQAP dataset is used for the IQAP experiments. We ignored the neutral words in MPQA dataset and used the remaining 4k opinion words. Also, the IQAPs dataset (Marneffe et al., 2010) contains 125 IQAPs and their corresponding yes or no labels as the ground truth. 6.2 Experimental Results To evaluate our PSSS model, we perform experiments on the SO prediction and IQAPs inference tasks. Here, we consider six emotions for both bridged and series models. We study the effect of emotion numbers in Section 7.1. Also, we set a </context>
<context position="22732" citStr="Marneffe et al. (2010)" startWordPosition="3789" endWordPosition="3792">HEM. However, the emotional vectors of SHEM are computed after finishing the EM steps using Equation (14). This causes the SHEM model to estimate the number and type of the hidden emotions with a lower performance as compared to BHEM, although the performances of SHEM and BHEM are comparable as explained in Section 7.1. Evaluation of IQAPs Inference To apply our PSSS on IQAPs inference task, we use it as the sentiment similarity measure in the algorithm explained in Figure 4. The results are presented in Table 4. The first and second rows are baselines. The first row is the result obtained by Marneffe et al. (2010) approach. This approach is based on the similarity between the SO of the adjectives in question and answer. The second row of Table 4 show the results of using a popular semantic similarity measure, PMI, as the sentiment similarity (SS) measure in Figure 4. 988 Method Prec. Rec. F1 Marneffe et al. (2010) 60.00 60.00 60.00 PMI 60.61 58.70 59.64 PSSS-SHEM 62.55 61.75 61.71 PSSS-BHEM (w/o WSD) 65.90 66.11 63.74 SS-BHEM (with WSD) 66.95 67.15 65.66 Table 4. Performance on IQAP inference task The result shows that PMI is less effective to capture the sentiment similarity. Our PSSS approach directl</context>
<context position="32861" citStr="Marneffe et al. (2010)" startWordPosition="5471" endWordPosition="5474">so utilized Latent Semantic Analysis (LSA) (Landauer et al., 1998) as another semantic similarity measure. However, both PMI and LSA are semantic similarity measure. Similarly, Hassan and Radev (2010) presented a graph-based method for predicting SO of words. They constructed a lexical graph where nodes are words and edges connect two words with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of a set of seeds through this graph. However, such approaches did not take into account the sentiment similarity between words. Figure 10. Convergence of BHEM In IQAPs, Marneffe et al. (2010) inferred the yes/no answers using SO of the adjectives. If SO of the adjectives have different signs, then the answer conveys no, and Otherwise, if the absolute value of SO for the adjective in question is smaller than the absolute value of the adjective in answer, then the answer conveys yes, and otherwise no. In Mohtarami et al. (2012), we used two semantic similarity measures (PMI and LSA) for the IQAP inference task. We showed that measuring the sentiment similarities between the adjectives in question and answer leads to higher performance as compared to semantic similarity measures. In </context>
</contexts>
<marker>Marneffe, Manning, Potts, 2010</marker>
<rawString>Marie-Catherine D. Marneffe, Christopher D. Manning, and Christopher Potts. 2010. &amp;quot;Was it good? It was provocative.&amp;quot; Learning the meaning of scalar adjectives. Proceeding in the Association for Computational Linguistics (ACL). Pp: 167– 176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitra Mohtarami</author>
<author>Hadi Amiri</author>
<author>Man Lan</author>
<author>Thanh P Tran</author>
<author>Chew L Tan</author>
</authors>
<title>Sense Sentiment Similarity: An Analysis.</title>
<date>2012</date>
<booktitle>Proceeding of the Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="33201" citStr="Mohtarami et al. (2012)" startWordPosition="5532" endWordPosition="5535">rds with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of a set of seeds through this graph. However, such approaches did not take into account the sentiment similarity between words. Figure 10. Convergence of BHEM In IQAPs, Marneffe et al. (2010) inferred the yes/no answers using SO of the adjectives. If SO of the adjectives have different signs, then the answer conveys no, and Otherwise, if the absolute value of SO for the adjective in question is smaller than the absolute value of the adjective in answer, then the answer conveys yes, and otherwise no. In Mohtarami et al. (2012), we used two semantic similarity measures (PMI and LSA) for the IQAP inference task. We showed that measuring the sentiment similarities between the adjectives in question and answer leads to higher performance as compared to semantic similarity measures. In Mohtarami et al. (2012), we proposed an approach to predict the sentiment similarity of words using their emotional vectors. We assumed that the type and number of emotions are pre-defined and our approach was based on this assumption. However, in previous research, there is little agreement about the number and types of basic emotions. F</context>
</contexts>
<marker>Mohtarami, Amiri, Lan, Tran, Tan, 2012</marker>
<rawString>Mitra Mohtarami, Hadi Amiri, Man Lan, Thanh P. Tran, and Chew L. Tan. 2012. Sense Sentiment Similarity: An Analysis. Proceeding of the Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitra Mohtarami</author>
<author>Man Lan</author>
<author>Chew L Tan</author>
</authors>
<title>From Semantic to Emotional Space</title>
<date>2013</date>
<booktitle>in Probabilistic Sense Sentiment Analysis. Proceeding of the Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="7256" citStr="Mohtarami et al., 2013" startWordPosition="1129" endWordPosition="1132">) and the documents (dk). In this Section, we aim to employ ratings and the relations among ratings, documents, and words to extract the hidden emotions. Figure 2 illustrates a simple graphical model using plate representation of Figure 1. As Figures 2 shows, the rating r from a set of ratings R= {r1,...,rp} is assigned to a hidden emotion set E={e1,...,ek}. A document d from a set of documents D= {d1,...,dN} with vocabulary set W= {w1,...,wM} is associated with the hidden emotion set. (d): Bridged model Figure 2. Hidden emotional model The model presented in Figure 2(a) has been explored in (Mohtarami et al., 2013) and is called Series Hidden Emotional Model (SHEM). This representation assumes that the word w is dependent to d and independent to e (we refer to this Assumption as A1). However, in reality, a word w can inherit properties (e.g., emotions) (a): Series model 984 I from the document d that contains w. Thus, we can assume that w is implicitly dependant on e. To account for this, we present Bridged Hidden Emotional Model (BHEM) shown in Figure 2(b). Our assumption, A2, in the BHEM model is as follows: w is dependent to both d and e. Considering Figure 1, we represent the entire text collection </context>
<context position="9143" citStr="Mohtarami et al., 2013" startWordPosition="1464" endWordPosition="1467">ned as follows considering hidden emotion e: - regarding class probability of the hidden emotion e to be assigned to the observation (w,d,r): P(w,d,r) = YP(w,d,r|e)P(e) = = YP(w,d|e)P(r|e)P(e) � - regarding assumption A2 and Bayes&apos; Rule: = YP(w|d,e)P(d,e)P(r|e) e - using Bayes&apos; Rule: = YP(d, e|w)P(w)P(r|e) e - regarding A2 and conditional independency: = YP(d|w)P(e|w)P(w)P(r|e) e = P(d|w) Y P(w|e)P(e)P(r|e) (2) e In the bridged model, the joint probability does not depend on the probability P(d|e) and the probabilities P(w|e), P(e) and P(r|e) are unknown, while in the SHEM model explained in (Mohtarami et al., 2013), the joint probability does not depend on P(w|e), and probabilities P(d|e), P(e), and P(r|e) are unknown. We employ Maximum Likelihood approach to learn the probabilities and infer the possible hidden emotions. The log-likelihood of the whole data set D in Equation (1) can be defined as follows: L = YY Yn(w,d)n(d,r)logP(w, d,r) (3) r d w Replacing P(w,d,r) by the values computed using the bridged model in Equation (2) results in: L = Y Y Y n(w, d)n(d,r)log[P(d|w) Y P(w|e)P(e)P(r|e) r d w e (4) The above optimization problems are hard to compute due to the log of sum. Thus, Expectation-maximiz</context>
<context position="11257" citStr="Mohtarami et al., 2013" startWordPosition="1834" endWordPosition="1837">we remove the dependency on document d using the following Equation: Yn(w, d)n(d,r) =n(w,r) (9) d where n(w,r) is the occurrence of w in all the documents in the rating r. The EM steps computed by the bridged model do not depend on the variable document d, and discard d from the model. The reason is that w bypasses d to directly associate with the hidden emotion e in Figure 2(b). Ed Ewn(w, d)n(d,r)P(e|w, d,r) P(r|e) = ErEdEwn(w, d)n(d, r) P(e|w, d, r) Ew n(w, r) P(e|w, d, r) (6) 985 Similar to BHEM, the EM steps for SHEM can be computed by considering assumptions A1 and Bayes Rule as follows (Mohtarami et al., 2013): E-step: P(r|e)P(e)P(d|e) P(e|w,d, r) = (10) Ee P(r|e)P(e)P(d|e) M-step: E� E�n(w, d)n(d,r)P(e|w, d,r) P(r|e) = (11) ET EdEwn(w, d)n(d, r) P(e|w, d, r) ETE�n(w,d)n(d,r)P(e|w,d, r) P(d|e) = (12) EdETEwn(w, d)n(d, r) P(e|w, d, r) ET E�E�n(w,d)n(d,r) P(e|w,d, r) P(e) = (13) EeEdETEwn(w, d)n(d, r) P(e|w, d, r) Finally, we construct the emotional vectors using the algorithm presented in Table 2. The algorithm employs document-rating, term-document and term-rating matrices to infer the unknown probabilities. This algorithm can be used with both bridged or series models. Our goal is to infer the emo</context>
<context position="15938" citStr="Mohtarami et al., 2013" startWordPosition="2622" endWordPosition="2625">,,�) is the frequency of w in the ratings 1 to 4 (7 to 10), and DF,,� (DF,,�) is the total number of documents with rating 1 to 4 (7 to 10) that contain w. The confidence value of w varies from 0 to 1, and it increases if: • There is a large difference between the occurrences of w in positive and negative ratings. • There is a large number of reviews involving w in the relative ratings. To improve the efficiency of enriched matrix, the columns corresponding to each word in the matrix are multiplied by its confidence value. 4 Predicting Sentiment Similarity We utilize the approach proposed in (Mohtarami et al., 2013) to compute the sentiment similarity between two words. This approach compares the emotional vector of the given words. Let X and Y be the emotional vectors of two words. Equation (17) computes their correlation: corr , En i (Xi — X� (Y X( — i — Y�) (17) (n � 1)S�Sy where, n is number of emotional categories, X, Y and SX, Sy are the mean and standard deviation values of X and Y respectively. corr(X,Y) _ —1 indicates that the two vectors are completely dissimilar, and corr(X,Y) _ 1 indicates that the vectors have perfect similarity. The approach makes use of a thresholding mechanism to estimate</context>
<context position="33916" citStr="Mohtarami et al., (2013)" startWordPosition="5646" endWordPosition="5649">owed that measuring the sentiment similarities between the adjectives in question and answer leads to higher performance as compared to semantic similarity measures. In Mohtarami et al. (2012), we proposed an approach to predict the sentiment similarity of words using their emotional vectors. We assumed that the type and number of emotions are pre-defined and our approach was based on this assumption. However, in previous research, there is little agreement about the number and types of basic emotions. Furthermore, the emotions in different dataset can be varied. We relaxed this assumption in Mohtarami et al., (2013) by considering the emotions as hidden and presented a hidden emotional model called SHEM. This paper also consider the emotions as hidden and presents another hidden emotional model called BHEM that gives more accurate estimation of the numbers and types of the hidden emotions. 9 Conclusion We propose a probabilistic approach to infer the sentiment similarity between word senses with respect to automatically learned hidden emotions. We propose to utilize the correlations between reviews, ratings, and words to learn the hidden emotions. We show the effectiveness of our method in two NLP tasks.</context>
</contexts>
<marker>Mohtarami, Lan, Tan, 2013</marker>
<rawString>Mitra Mohtarami, Man Lan, and Chew L. Tan. 2013. From Semantic to Emotional Space in Probabilistic Sense Sentiment Analysis. Proceeding of the Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Textual Affect Sensing for Sociable and Expressive Online Communication.</title>
<date>2007</date>
<booktitle>Proceedings of the conference on Affective Computing and Intelligent Interaction (ACII). Pp:</booktitle>
<pages>218--229</pages>
<contexts>
<context position="4572" citStr="Neviarouskaya et al., 2007" startWordPosition="702" endWordPosition="705">rd pairs. In addition, different senses of sentiment words carry different human emotions. In fact, a sentiment word can be represented as a vector of emotions with intensity values from &amp;quot;very weak&amp;quot; to &amp;quot;very strong&amp;quot;. For example, Table 1 shows several sentiment words and their corresponding emotion vectors based the following set of emotions: e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise]. For example, &amp;quot;deceive&amp;quot; has 0.4 and 0.5 intensity values with respect to the emotions &amp;quot;disgust&amp;quot; and &amp;quot;sadness&amp;quot; with an overall -0.9 (i.e. -0.4-0.5) value for sentiment orientation (Neviarouskaya et al., 2007; Neviarouskaya et al., 2009). Word Emotional Vector SO e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise] Rude [&apos;0.2&apos;, &apos;0.4&apos;,0,0,0,0,0,0,0] -0.6 doleful [0, 0, &apos;0.4&apos;,0,0,0,0,0,0] -0.4 smashed [0,0, &apos;0.8&apos;, &apos;0.6&apos;,0,0,0,0,0] -1.4 shamefully [0,0,0,0,0,0,0, &apos;0.7&apos;,0] -0.7 deceive [0, &apos;0.4&apos;, &apos;0.5&apos;,0,0,0,0,0,0] -0.9 Table 1. Sample of emotional vectors The difficulty of the sentiment similarity prediction task is evident when terms carry different types of emotions. For instance, all the words in Table 1 have negative sentiment orientation, but, they carry different emotions </context>
</contexts>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2007</marker>
<rawString>Alena Neviarouskaya, Helmut Prendinger, and Mitsuru Ishizuka. 2007. Textual Affect Sensing for Sociable and Expressive Online Communication. Proceedings of the conference on Affective Computing and Intelligent Interaction (ACII). Pp: 218-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>SentiFul: Generating a Reliable Lexicon for Sentiment Analysis.</title>
<date>2009</date>
<booktitle>Proceeding of the conference on Affective Computing and Intelligent Interaction (ACII). Pp:</booktitle>
<pages>363--368</pages>
<contexts>
<context position="4601" citStr="Neviarouskaya et al., 2009" startWordPosition="706" endWordPosition="709">rent senses of sentiment words carry different human emotions. In fact, a sentiment word can be represented as a vector of emotions with intensity values from &amp;quot;very weak&amp;quot; to &amp;quot;very strong&amp;quot;. For example, Table 1 shows several sentiment words and their corresponding emotion vectors based the following set of emotions: e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise]. For example, &amp;quot;deceive&amp;quot; has 0.4 and 0.5 intensity values with respect to the emotions &amp;quot;disgust&amp;quot; and &amp;quot;sadness&amp;quot; with an overall -0.9 (i.e. -0.4-0.5) value for sentiment orientation (Neviarouskaya et al., 2007; Neviarouskaya et al., 2009). Word Emotional Vector SO e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise] Rude [&apos;0.2&apos;, &apos;0.4&apos;,0,0,0,0,0,0,0] -0.6 doleful [0, 0, &apos;0.4&apos;,0,0,0,0,0,0] -0.4 smashed [0,0, &apos;0.8&apos;, &apos;0.6&apos;,0,0,0,0,0] -1.4 shamefully [0,0,0,0,0,0,0, &apos;0.7&apos;,0] -0.7 deceive [0, &apos;0.4&apos;, &apos;0.5&apos;,0,0,0,0,0,0] -0.9 Table 1. Sample of emotional vectors The difficulty of the sentiment similarity prediction task is evident when terms carry different types of emotions. For instance, all the words in Table 1 have negative sentiment orientation, but, they carry different emotions with different emotion vector</context>
</contexts>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2009</marker>
<rawString>Alena Neviarouskaya, Helmut Prendinger, and Mitsuru Ishizuka. 2009. SentiFul: Generating a Reliable Lexicon for Sentiment Analysis. Proceeding of the conference on Affective Computing and Intelligent Interaction (ACII). Pp: 363-368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Ortony</author>
<author>Terence J Turner</author>
</authors>
<title>What&apos;s Basic About Basic Emotions.</title>
<date>1990</date>
<journal>American Psychological Association.</journal>
<volume>97</volume>
<issue>3</issue>
<pages>315--331</pages>
<contexts>
<context position="5684" citStr="Ortony and Turner 1990" startWordPosition="864" endWordPosition="867">or instance, all the words in Table 1 have negative sentiment orientation, but, they carry different emotions with different emotion vectors. For example, &amp;quot;rude&amp;quot; reflects the emotions &amp;quot;anger&amp;quot; and &amp;quot;disgust&amp;quot;, while the word &amp;quot;doleful&amp;quot; only reflects the emotion &amp;quot;sadness&amp;quot;. As such, the word &amp;quot;doleful&amp;quot; is closer to the words &amp;quot;smashed&amp;quot; and &amp;quot;deceive&amp;quot; involving the emotion &amp;quot;sadness&amp;quot; than others. We show that emotion vectors of the words can be effectively utilized to predict the sentiment similarity between them. Previous research shows little agreement about the number and types of the basic emotions (Ortony and Turner 1990; Izard 1971). Thus, we assume that the number and types of basic emotions are hidden and not pre-defined and propose a Probabilistic Sense Sentiment Similarity (PSSS) approach to extract the hidden emotions of word senses to infer their sentiment similarity. 3 Hidden Emotional Model Online review portals provide rating mechanisms (in terms of stars, e.g. 5- or 10-star rating) to aligure 1. Figure The structure of PSSS model low users to attach ratings to their reviews. A rating indicates the summarized opinion of a user who ranks a product or service based on his feelings. There are various f</context>
</contexts>
<marker>Ortony, Turner, 1990</marker>
<rawString>Andrew Ortony and Terence J. Turner. 1990. What&apos;s Basic About Basic Emotions. American Psychological Association. 97(3), 315-331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Potts</author>
<author>C</author>
</authors>
<title>On the negativity of negation.</title>
<date>2011</date>
<booktitle>In Nan Li and David Lutz, eds., Proceedings of Semantics and Linguistic Theory</booktitle>
<volume>20</volume>
<pages>636--659</pages>
<marker>Potts, C, 2011</marker>
<rawString>Christopher Potts, C. 2011. On the negativity of negation. In Nan Li and David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20, 636-659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring Praise and Criticism: Inference of Semantic Orientation from Association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>315--346</pages>
<contexts>
<context position="3084" citStr="Turney and Littman, 2003" startWordPosition="470" endWordPosition="473">xt information to infer the yes or no answer (e.g. Q: Was she the best one on that old show? A: She was simply funny). Clearly, the sentiment words in IQAPs are the pivots to infer the yes or no answers. We show that sentiment similarity between such words (e.g., here the adjectives best and Funny) can be used effectively to infer the answers. The second application (SO prediction) aims to determine the sentiment orientation of individual words. Previous research utilized the semantic relations between words obtained from WordNet (Hassan and Radev, 2010) and semantic similarity measures (e.g. Turney and Littman, 2003) for this purpose. In this paper, we show that sentiment similarity between word pairs can be effectively utilized to compute SO of words. The contributions of this paper are follows: • We propose an effective approach to predict the sentiment similarity between word pairs through hidden emotions at the sense level, • We show the utility of sentiment similarity prediction in IQAP inference and SO prediction tasks, and • Our hidden emotional model can infer the type and number of hidden emotions in a corpus. 983 Proceedings of the 51st Annual Meeting of the Association for Computational Linguis</context>
<context position="18318" citStr="Turney and Littman (2003)" startWordPosition="3023" endWordPosition="3026">explain our approach in utilizing sentiment similarity between words to perform IQAP inference and SO prediction tasks respectively. In IQAPs, we employ the sentiment similarity between the adjectives in questions and answers to interpret the indirect answers. Figure 4 shows the algorithm for this purpose. SS(.,.) indicates sentiment similarity computed by Equation (18). A positive SS means the words are sentimentally similar and thus the answer is yes. However, negative SS leads to a no response. In SO-prediction task, we aim to compute more accurate SO using our sentiment similarity method. Turney and Littman (2003) proposed a method in which the SO of a word is calculated based on its semantic similarity with seven positive words minus its similarity with seven negative words as shown in Figure 5. As the similarity function, A(.,.), they employed point-wise mutual information (PMI) to compute the similarity between the words. Here, we utilize the same approach, but instead of PMI we use our SS(.,.) measure as the similarity function. Confidence,, _ 987 Input: Pwords: seven words with positive SO Nwords: seven words with negative SO A(. ,. ): similarity function, and w: a given word with unknown SO Outpu</context>
<context position="20954" citStr="Turney and Littman, 2003" startWordPosition="3482" endWordPosition="3485"> set the confidence values smaller than the threshold to 0. We explain the effect of this parameter in Section 7.3. Evaluation of SO Prediction We evaluate the performance of our PSSS models in the SO prediction task using the algorithm explained in Figure 5 by setting our PSSS as similarity function (A). The results on SO prediction are presented in Table 3. The first and seMethod Precision Recall F1 PMI 56.20 56.36 55.01 ER 65.68 65.68 63.27 PSSS-SHEM 68.51 69.19 67.96 PSSS-BHEM 69.39 70.07 68.68 Table 3. Performance on SO prediction task cond rows present the results of our baselines, PMI (Turney and Littman, 2003) and Expected Rating (ER) (Potts, 2011) of words respectively. PMI extracts the semantic similarity between words using their co-occurrences. As Table 3 shows, it leads to poor performance. This is mainly due to the relatively small size of the development dataset which affects the quality of the co-occurrence information used by the PMI. ER computes the expected rating of a word based on the distribution of the word across rating categories. The value of ER indicates the SO of the word. As shown in the two last rows of the table, the results of PSSS approach are higher than PMI and ER. The re</context>
<context position="32071" citStr="Turney and Littman (2003)" startWordPosition="5341" endWordPosition="5344">trix of SHEM (i.e., W×D). • In BHEM, the emotional vectors are directly computed from the EM steps. However, the emotional vector of a word in SHEM is computed using the emotional vectors of the documents containing the word. This adds noises to the emotional vectors of the words. • BHEM gives more accurate estimation over type and number of emotions versus SHEM. The reason is explained in Section 7.1. 8 Related Works Sentiment similarity has not received enough attention to date. Most previous works employed semantic similarity of word pairs to address SO prediction and IQAP inference tasks. Turney and Littman (2003) proposed to compute pair-wised mutual information (PMI) between a target word and a set of seed positive and negative words to infer the SO of the target word. They also utilized Latent Semantic Analysis (LSA) (Landauer et al., 1998) as another semantic similarity measure. However, both PMI and LSA are semantic similarity measure. Similarly, Hassan and Radev (2010) presented a graph-based method for predicting SO of words. They constructed a lexical graph where nodes are words and edges connect two words with semantic similarity obtained from Wordnet (Fellbaum 1998). They propagated the SO of</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2003. Measuring Praise and Criticism: Inference of Semantic Orientation from Association. ACM Transactions on Information Systems, 21(4), 315– 346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>Proceeding in HLT-EMNLP. Pp:</booktitle>
<pages>347--354</pages>
<contexts>
<context position="19628" citStr="Wilson et al., 2005" startWordPosition="3251" endWordPosition="3254">dE wwords nwordE Nwords Figure 5. SO based on the similarity function A(.,.) 6 Evaluation and Results 6.1 Data and Settings We used the review dataset employed by Maas et al. (2011) as the development dataset that contains movie reviews with star rating from one star (most negative) to 10 stars (most positive). We exclude the ratings 5 and 6 that are more neutral. We used this dataset to compute all the input matrices in Table 2 as well as the enriched matrix. The development dataset contains 50k movie reviews and 90k vocabulary. We also used two datasets for the evaluation purpose: the MPQA (Wilson et al., 2005) and IQAPs (Marneffe et al., 2010) datasets. The MPQA dataset is used for SO prediction experiments, while the IQAP dataset is used for the IQAP experiments. We ignored the neutral words in MPQA dataset and used the remaining 4k opinion words. Also, the IQAPs dataset (Marneffe et al., 2010) contains 125 IQAPs and their corresponding yes or no labels as the ground truth. 6.2 Experimental Results To evaluate our PSSS model, we perform experiments on the SO prediction and IQAPs inference tasks. Here, we consider six emotions for both bridged and series models. We study the effect of emotion numbe</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. Proceeding in HLT-EMNLP. Pp: 347–354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>