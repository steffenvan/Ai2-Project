<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.977251">
Speech-input multi-target machine translation
</title>
<author confidence="0.979703">
Alicia P´erez, M. In´es Torres M. Teresa Gonz´alez, Francisco Casacuberta
</author>
<affiliation confidence="0.947195">
Dep. of Electricity and Electronics Dep. of Information Systems and Computation
University of the Basque Country Technical University of Valencia
</affiliation>
<email confidence="0.985031">
manes@we.lc.ehu.es fcn@dsic.upv.es
</email>
<sectionHeader confidence="0.996453" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999226875">
In order to simultaneously translate speech
into multiple languages an extension of
stochastic finite-state transducers is pro-
posed. In this approach the speech trans-
lation model consists of a single network
where acoustic models (in the input) and the
multilingual model (in the output) are em-
bedded.
The multi-target model has been evaluated
in a practical situation, and the results have
been compared with those obtained using
several mono-target models. Experimental
results show that the multi-target one re-
quires less amount of memory. In addition, a
single decoding is enough to get the speech
translated into multiple languages.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977041666667">
In this work we deal with finite-state models which
constitute an important framework in syntactic pat-
tern recognition for language and speech processing
applications (Mohri et al., 2002; Pereira and Riley,
1997). One of their outstanding characteristics is the
availability of efficient algorithms for both optimiza-
tion and decoding purposes.
Specifically, stochastic finite-state transducers
(SFSTs) have proved to be useful for machine trans-
lation tasks within restricted domains. There are
several approaches implemented over SFSTs which
range from word-based systems (Knight and Al-
Onaizan, 1998) to phrase-based systems (P´erez et
al., 2007). SFSTs usually offer high speed during
the decoding step and they provide competitive re-
sults in terms of error rates. In addition, SFSTs have
proved to be versatile models, which can be easily
integrated with other finite-state models, such as a
speech recognition system for speech-input transla-
tion purposes (Vidal, 1997). In fact, the integrated
architecture has proved to work better than the de-
coupled one. Our main goal is, hence, to extend
and assess these methodologies to accomplish spo-
ken language multi-target translation.
As far as multilingual translation is concerned,
there are two main trends in machine translation de-
voted to translate an input string simultaneously into
m languages (Hutchins and Somers, 1992): inter-
lingua and parallel transfer. The former has his-
torically been a knowledge-based technique that re-
quires a deep-analysis effort, and the latter consists
on m decoupled translators in a parallel architec-
ture. These translators can be either knowledge or
example-based. On the other hand, in (Gonz´alez
and Casacuberta, 2006) an example based technique
consisting of a single SFST that cope with multiple
target languages was presented. In that approach,
when translating an input sentence, only one search
through the multi-target SFST is required, instead of
the m independent decoding processes required by
the mono-target translators.
The classical layout for speech-input multi-target
translation includes a speech recognition system in
a serial architecture with m decoupled text-to-text
translators. Thus, this architecture entails a decod-
ing stage of the speech signal into the source lan-
guage text, and m further decoding stages to trans-
late the source text into each of the m target lan-
</bodyText>
<page confidence="0.973344">
56
</page>
<note confidence="0.8908455">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 56–63,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999938631578947">
guages. If we supplant the m translators with the
multi-target SFST, the problem would be reduced to
2 searching stages. Nevertheless, in this paper we
propose a natural way for acoustic models to be in-
tegrated in the multilingual network itself, in such
a way that the input speech signal can be simulta-
neously decoded and translated into m target lan-
guages. As a result, due to the fact that there is just
a single searching stage, this novel approach entails
less computational cost.
The remainder of the present paper is structured
as follows: section 2 describes both multi-target SF-
STs and the inference algorithm from training ex-
amples; in section 3 a novel integrated architecture
for speech-input multi-target translation is proposed;
section 4 presents a practical application of these
methods, including the experimental setup and the
results they produced; finally, section 5 summarizes
the main conclusions of this work.
</bodyText>
<sectionHeader confidence="0.9622525" genericHeader="method">
2 Multi-target stochastic finite-state
transducers
</sectionHeader>
<bodyText confidence="0.99996675">
A multi-target SFST is a generalization of standard
SFSTs, in such a way that every input string in the
source language results in a tuple of output strings
each being associated to a different target language.
</bodyText>
<subsectionHeader confidence="0.944372">
2.1 Definition
</subsectionHeader>
<bodyText confidence="0.8972505">
A multi-target stochastic finite-state transducer is a
tuple T = (E, A1 ... Am, Q, q0, R, F, P), where:
</bodyText>
<equation confidence="0.980050571428571">
E is a finite set of input symbols (source vocabu-
lary);
A1 ... Am are m finite sets of output symbols (tar-
get vocabularies);
Q is a finite set of states;
q0 E Q is the initial state;
R C_ Q x E x A∗ 1 ... A∗ m x Q is a set of transitions
</equation>
<bodyText confidence="0.9216375">
such as (q, w, p1, . .. , pm, q0), which is a tran-
sition from the state q to the state q0, with the
source symbol w and producing the substrings
(P1, ... , f9m);
</bodyText>
<equation confidence="0.905761444444444">
P : R —* [0, 1] is the transition probability distri-
bution;
F : Q —* [0, 1] is the final state probability distri-
bution;
The probability distributions satisfy the stochastic
constraint:
Vq E Q (1)
F(q)+ E P(q, w, �p1, ... , f9m, q0) = 1
w,˜p1,...,˜pm,q/
</equation>
<subsectionHeader confidence="0.996889">
2.2 Training the multilingual translation model
</subsectionHeader>
<bodyText confidence="0.999926571428572">
Both topology and parameters of an SFST can
be learned fully automatically from bilingual ex-
amples making use of underlying alignment mod-
els (Casacuberta and Vidal, 2004). Furthermore,
a multi-target SFST can be inferred from a multi-
lingual set of samples (Gonz´alez and Casacuberta,
2006). Even though in realistic situations multilin-
gual corpora are too scarce, recent works (Popovi´c
et al., 2005) show that bilingual corpora covering the
same domain are sufficient to obtain generalized cor-
pora based on which one can subsequently create the
required collections of aligned tuples.
The inference algorithm, GIAMTI (grammatical
inference and alignments for multi-target transducer
inference), requires a multilingual corpus, that is, a
finite set of multilingual samples (s, t 1 ... , tm) E
E∗xA∗1x· · ·xA∗m, where ti denotes the translation
of the source sentence s into the i-th target language;
E denotes the source language vocabulary, and Ai
the i-th target language vocabulary; the algorithm
can be outlined as follows:
</bodyText>
<listItem confidence="0.68542925">
1. Each multilingual sample is transformed into
a single string from an extended vocabulary
(F C_ E x A∗1 x · · · x A∗m) using a labeling
function (Lm). This transformation searches an
</listItem>
<bodyText confidence="0.994429166666667">
adequate monotonic segmentation for each of
the m source-target language pairs on the basis
of bilingual alignments such as those given by
GIZA++ (Och, 2000). A monotonic segmen-
tation copes with monotonic alignments, that
is, j &lt; k ==&gt;. aj &lt; ak following the notation
of (Brown et al., 1993). Each source token,
which can be either a word or a phrase (P´erez
et al., 2007), is then joined with a target phrase
of each language as the corresponding segmen-
tation suggests. Each extended symbol consists
of a token from the source language plus zero
</bodyText>
<page confidence="0.978943">
57
</page>
<figure confidence="0.999567285714286">
3:da
2:jeitsiko
1:minimoa
0:tenperatura
2:falling
1:temperatures
0:low
0:temperaturas
1:minimas
2:en
3:descenso
(a) Spanish-Basque
0:temperaturas
1:minimas
2:en
3:descenso
(b) Spanish-English
temperaturas  |temperatura  |NIL maximas  |maximoak  |high temperatures en  |NIL  |NIL descenso  |jaitsiko da  |falling
0 1 2 3 5
minimas  |minimoak  |low temperatures ascenso  |igoko da  |rising
(c) Multi-target SFSTfrom Spanish into English and Basque.
</figure>
<figureCaption confidence="0.9815515">
Figure 1: Example of a trilingual alignment over a trilingual sentence extracted from the task under consid-
eration;the related multi-target SFST (with Spanish as input, and English and Basque as output).
</figureCaption>
<listItem confidence="0.887533">
or more words from each target language in
their turn.
2. Once the set of multilingual samples has been
converted into a set of single extended strings
(z E P), a stochastic regular grammar can be
inferred. Specifically, in this work we deal with
k-testable in the string-sense grammars (Garcia
and Vidal, 1990), which are considered to be
a syntactic approach of the n-gram models. In
addition, they allow the integration of several
order models in a single smoothed automa-
ton (Torres and Varona, 2001).
3. The extended symbols associated with the
transitions of the automaton are transformed
into one input token and m output phrases
(w/�p1 |... |�pm) by the inverse labeling function
</listItem>
<bodyText confidence="0.983190368421053">
(G−m), leading to the required transducer.
Example An illustration of the inference of the
multi-target SFST can be shown over a couple of
simple trilingual sentences from the corpus (where
“B” stands for Basque, “S” for Spanish and “E” for
English):
1-B tenperatura maximoa jaitsiko da
1-S temperaturas m´aximas en descenso
1-E high temperatures falling
2-B tenperatura minimoa igoko da
2-S temperaturas minimas en ascenso
2-E low temperatures rising
From the alignments, depicted in Figures 1(a)
and 1(b), an input-language-synchronized
monotonous segmentation can be built (bear in
mind that we are considering Spanish as the input
language). The corresponding extended strings with
the following constituents for the first and second
samples respectively are the following ones:
</bodyText>
<equation confidence="0.574313888888889">
1 temperaturas|tenperatura|A
minimas|minimoa|low temperatures
en|A|A
descenso|jaitsiko da|falling
58
2 temperaturas|tenperatura|A
m´aximas|maximoa|high temperatures
en|A|A
ascenso|igoko da|rising
</equation>
<bodyText confidence="0.999549333333333">
Finally, from this representation of the data, the
multi-target SFST can be built as shown in Fig-
ure 1(c).
</bodyText>
<subsectionHeader confidence="0.999326">
2.3 Decoding
</subsectionHeader>
<bodyText confidence="0.9999798">
Given an input string s (a sentence in the source lan-
guage), the decoding module has to search the opti-
mal m output strings tm E Di x · · · x A;t (a sen-
tence in each of the target language) according to the
underlying translation model (7):
</bodyText>
<sectionHeader confidence="0.9164175" genericHeader="method">
3 An embedded architecture for
speech-input multi-target translation
</sectionHeader>
<subsectionHeader confidence="0.999776">
3.1 Statistical framework
</subsectionHeader>
<bodyText confidence="0.999970857142857">
Given the acoustic representation (x) of a speech
signal, the goal of multi-target speech translation
is to find the most likely m target strings (tm);
that is, one string (ti) per target language involved
(i E {1, ... , m}). This approach is summarized
in eq. (5), where the hidden variable s can be in-
terpreted as the transcription of the speech signal:
</bodyText>
<figure confidence="0.6120979">
P(tm, s|x)
(5)
Making use of Bayes’ rule, the former expression
turns into:
� �P(tm|x) = arg max
tm = arg max tm s
tm
� PT (s, tm) (2) � � P(tm, s)P(x|tm, s) (6)
tm = arg max tm = arg max
tmEDix···xD*m tm
</figure>
<bodyText confidence="0.938882666666667">
Solving equation (2) is a hard computational prob-
lem, however, it can be efficiently computed under
the so called maximum approach as follows:
</bodyText>
<equation confidence="0.973945">
PT (s, tm) Pz� max PT(O(s, tm)) (3)
O(s,tm)
</equation>
<bodyText confidence="0.99955">
where O(s, tm) is a translation form, that is, a se-
quence of transitions in the multi-target SFST com-
patible with both the input and the m output strings.
</bodyText>
<equation confidence="0.581906">
O(s, tm) : (q0, w1, �fim1 , q1) ··· (qJ−1, wJ,pj , qJ)
</equation>
<bodyText confidence="0.999137666666667">
The input string (s) is a sequence of J input sym-
bols, s = wJ1 , and each of the m output strings
consists of J phrases in its corresponding language
tm = (t1, ··· , tm) = (�p1)J1 , ··· , ( pm)J1. Thus, the
probability supplied by the multi-target SFST to the
translation form is given by:
</bodyText>
<equation confidence="0.9761135">
J
PT(O(s, tm)) = F(qJ) P(qj−1, wj, �pmj , qj)
j=1
(4)
</equation>
<bodyText confidence="0.999936833333333">
In this context, the Viterbi algorithm can be used
to obtain the optimal sequence of states through the
multi-target SFST for a given input string. As a
result, the established m translations are built con-
catenating the (J) output phrases for each language
through the optimal path.
</bodyText>
<subsectionHeader confidence="0.339844">
s
</subsectionHeader>
<bodyText confidence="0.9989374">
Empirically, there is no loss of generality if we as-
sume that the acoustic signal representation depends
only on the source string, i.e. P(x|tm, s) is inde-
pendent of tm. In this sense, eq. (6) can be rewritten
as:
</bodyText>
<equation confidence="0.98006475">
�
�tm = arg max
tm
s
</equation>
<bodyText confidence="0.997210727272727">
Equation (7) combines a standard acoustic model,
P(x|s), and a multi-target translation model,
P(tm, s), both of whom can be integrated on the fly
during the searching routine as shown in Figure 2.
That is, each acoustic sub-network is only expanded
at decoding time when it is required.
The outer sum is computationally very expensive
to search for the optimal tuple of target strings tm
in an effective way. Thus we make use of the so
called Viterbi approximation, which finds the best
path over the whole transducer.
</bodyText>
<subsectionHeader confidence="0.99886">
3.2 Practical issues
</subsectionHeader>
<bodyText confidence="0.999766125">
The underlying recognizer used in this work is our
own continuous-speech recognition system, which
implements stochastic finite-state models at all lev-
els: acoustic-phonetic, lexical and syntactic, and
which allows to infer them based on samples.
The signal analysis was carried out in a stan-
dard way, based on the classical Mel-cepstrum
parametrization. Each phone-like unit was modeled
</bodyText>
<equation confidence="0.955249">
P(tm, s)P(x|s) (7)
</equation>
<page confidence="0.929448">
59
</page>
<figure confidence="0.949981">
/e/  |NIL  |NIL /n/  |NIL  |NIL
1 2
</figure>
<figureCaption confidence="0.998903">
Figure 2: Integration on the fly of acoustic models in one edge of the SFST shown in Figure 1(c)
</figureCaption>
<bodyText confidence="0.9997209375">
by a typical left to right hidden Markov model. A
phonetically-balanced Spanish database, called Al-
bayzin (Moreno et al., 1993), was used to train these
models.
The lexical model consisted of the extended to-
kens of the multi-target SFST instead of running
words. The acoustic transcription for each extended
token was automatically obtained on the basis of the
input projection of each unit, that is, the Spanish vo-
cabulary in this case.
Instead of the usual language model, we make use
of the multi-target SFST itself, which had the syn-
tactic structure provided by a k-testable in the strict
sense model, with k=3, and Witten-Bell smoothing.
Note that the SFST implicitly involves both input
and output language models.
</bodyText>
<sectionHeader confidence="0.994559" genericHeader="evaluation">
4 Experimental results
</sectionHeader>
<subsectionHeader confidence="0.999498">
4.1 Task and corpus
</subsectionHeader>
<bodyText confidence="0.999894390243903">
The described general methodology has been put
into practice in a highly practical application that
aims to translate on-line TV weather forecasts into
several languages, taking the speech of the presen-
ter as the input and producing as output text-strings,
or sub-titles, in several languages. For this purpose,
we used the corpus METEUS which consists of a
set of trilingual sentences, in English, Spanish and
Basque, as extracted from weather forecast reports
that had been published on the Internet. Let us no-
tice that it is a real trilingual corpus, which they are
usually quite scarce.
Basque is a pre-Indoeuropean language of still
unknown origin. It is a minority language, spo-
ken in a small area of Europe and also within some
small American communities (such as that in Reno,
Nevada). In the Basque Country (located in the
north of Spain) it has an official status along with
Spanish. However, despite having coexisted for cen-
turies in the same area, they differ greatly both in
syntax and in semantics. Hence, efforts are being
devoted nowadays to machine translation tools in-
volving these two languages (Alegria et al., 2004),
although they are still scarce. With regard to the or-
der of the phrases within a sentence, the most com-
mon one in Basque is Subject plus Objects plus Verb
(even though some alternative structures are also ac-
cepted), whereas in Spanish and English other con-
structions such as Subject plus Verb plus Objects are
more frequent (see Figures 1(a) and 1(b)). Another
difference between Basque and Spanish or English
is that Basque is an extremely inflected language.
In this experiment we intend to translate Span-
ish speech simultaneously into both Basque and En-
glish. Just by having a look at the main features of
the corpus in Table 1, we can realize that there are
substantial differences among these three languages,
in terms both of the size of the vocabulary and of the
amount of running words. These figures reveal the
agglutinant nature of the Basque language in com-
parison with English or Spanish.
</bodyText>
<table confidence="0.9992771">
Spanish Basque English
Total sentences 14,615
Different sentences 7,225 7,523 6,634
Words 191,156 187,462 195,627
Vocabulary 702 1,147 498
Average Length 13.0 12.8 13.3
Sentences 500
st Words 8,706 8,274 9,150
Te Average Length 17.4 16.5 18.3
Perplexity (3grams) 4.8 6.7 5.8
</table>
<tableCaption confidence="0.999897">
Table 1: Main features of the METEUS corpus.
</tableCaption>
<bodyText confidence="0.999935142857143">
With regard to the speech test, the input consisted
of the speech signal recorded by 36 speakers, each
one reading out 50 sentences from the test-set in Ta-
ble 1. That is, each sentence was read out by at least
three speakers. The input speech resulted in approx-
imately 3.50 hours of audio signal. Needless to say,
the application that we envisage has to be speaker-
</bodyText>
<page confidence="0.986081">
60
</page>
<bodyText confidence="0.799383">
independent if it is to be realistic.
</bodyText>
<subsectionHeader confidence="0.988659">
4.2 System evaluation
</subsectionHeader>
<bodyText confidence="0.999961625">
The performance obtained by the acoustic integra-
tion has been experimentally tested for both multi-
target and mono-target devices. As a matter of com-
parison, text-input translation results are also re-
ported.
The multi-target SFST was learned from the train-
ing set described in Table 1 using the previously de-
scribed GIAMTI algorithm. The 500 test sentences
were then translated by the multi-target SFST. The
translation provided by the system in each language
was compared to the corresponding reference sen-
tence. Additionally, two mono-target SFSTs were
inferred with their outputs for the aforementioned
test to be taken as baseline. The evaluation includes
both computational cost and performance of the sys-
tem.
</bodyText>
<subsectionHeader confidence="0.647086">
4.2.1 Computational cost
</subsectionHeader>
<bodyText confidence="0.998591714285714">
The expected searching time and the amount of
memory that needs to be allocated for a given model
are two key parameters to bear in mind in speech-
input machine translation applications. These val-
ues can be objectively measured in terms of the size
and on the average branching factor of the model
displayed in Table 2.
</bodyText>
<table confidence="0.9893114">
multi-target mono-target
S2B S2E
Nodes 52,074 35,034 20,148
Edges 163,146 115,526 69,690
Branching factor 3.30 3.13 3.46
</table>
<tableCaption confidence="0.966543">
Table 2: Features of multi-target model and the two
</tableCaption>
<bodyText confidence="0.981677523809524">
decoupled mono-target models (one for Spanish to
Basque translation, referred to as S2B, and the sec-
ond for Spanish to English, S2E).
Adding the edges up for the two mono-target SF-
STs that take part in the decoupled architecture (see
Table 2), we conclude that the decoupled model
needs a total of 185, 216 edges to be allocated in
memory, which represents an increment of 13%
in memory-space with respect to the multi-target
model.
On the other hand, the multi-target approach of-
fers a slightly smaller branching factor than each
mono-target approach. As a result, fewer paths have
to be explored with the multi-target approach than
with the decoupled one, which suggests that search-
ing for a translation might be faster. As a matter of
fact, experimental results in Table 3 show that the
mono-target architecture works 11% more slowly
than the multi-target one for speech-input machine
translation and decoding, and 30% for text to text
translation.
</bodyText>
<table confidence="0.9978444">
Time (s)
multi-target mono-target
S2B+S2E
Text-input 0.36 0.47
Speech-input 16.9 18.9
</table>
<tableCaption confidence="0.893513">
Table 3: Average time needed to translate each input
sentence into two languages.
</tableCaption>
<bodyText confidence="0.984939333333333">
Summarizing, in terms of computational cost
(space and time), a multi-target SFST performs bet-
ter than the mono-target decoupled system.
</bodyText>
<subsectionHeader confidence="0.581851">
4.2.2 Performance
</subsectionHeader>
<bodyText confidence="0.99999062962963">
So far, the capability of the systems has been as-
sessed in terms of time and spatial costs. However,
the quality of the translations they provide is, doubt-
less, the most relevant evaluation criterion. In or-
der to determine the performance of the system in
a quantitative manner, the following evaluation pa-
rameters were computed for each scenario: bilingual
evaluation under study (BLEU), position indepen-
dent error rate (PER) and word error rate (WER).
Both text and speech-input translation results pro-
vided by the multi-target and the mono-target mod-
els respectively are shown in Table 4.
As can be derived from the translation results,
for text-input translation the classical approach per-
forms slightly better than the multi-target one, but
for speech-input translation from Spanish into En-
glish is the other way around. In any case, the dif-
ferences in performance are marginal.
Comparing the text-input with the speech-input
results we realize that, as could be expected, the pro-
cess of speech signal decoding is itself introducing
some errors. In an attempt to measure these errors,
the text transcription of the recognized input signal
was extracted and compared to the input reference
in terms of WER as shown in the last row of the Ta-
ble 4. Note that even though the input sentences are
the same the three results differ due to the fact that
</bodyText>
<page confidence="0.997681">
61
</page>
<bodyText confidence="0.8935555">
we are making use of different SFST models that de-
code and translate at the same time.
</bodyText>
<table confidence="0.997440555555556">
multi-target mono-target
S2B S2E S2B S2E
Text BLEU 42.7 66.7 43.4 67.8
PER 39.9 19.9 38.2 19.0
WER 48.0 27.5 46.2 26.6
Speech BLEU 39.5 59.0 39.2 61.1
PER 42.2 25.3 41.5 23.6
WER 51.5 33.9 50.5 31.9
recognition WER 10.7 9.3 9.1
</table>
<tableCaption confidence="0.989995">
Table 4: Text-input and speech-input translation re-
</tableCaption>
<bodyText confidence="0.99095580952381">
sults for Spanish into Basque (S2B) and Spanish into
English (S2E) using a multi-target SFST (columns
on the left) or two mono-target SFSTs (columns on
the right). The last row shows Spanish speech de-
coding results using each of the three devices.
In these series of experiments the same task has
been compared with two extremely different lan-
guage pairs under the same conditions. There is a
noticeable difference in terms of quality between the
English and the Basque translations. The underlying
reason might be due to the fact that SFST models
do not capture properly the rich morphology of the
Basque as they have to face long-distance reordering
issues. These differences in the performance of the
system when translating into English or into Basque
have been previously detected in other works (Or-
tiz et al., 2003). In our case, a manual review of the
models and the obtained translations encourage us to
make use of reordering models in future work, since
they have proved to report good results in a similar
framework (Kanthak et al., 2005).
</bodyText>
<sectionHeader confidence="0.68508" genericHeader="conclusions">
5 Concluding remarks and further work
</sectionHeader>
<bodyText confidence="0.9999811">
The main contribution of this paper is the proposal
of a fully embedded architecture for multiple speech
translation. Thus, acoustic models are integrated on
the fly into a multi-target translation model. The
most significant feature of this approach is its abil-
ity to carry out both the recognition and the transla-
tion into multiple languages integrated in a unique
model. Due to the finite-state nature of this model,
the speech translation engine is based on a Viterbi-
like algorithm.
In contrast to the mono-target systems, multi-
target SFSTs enable the translation from one source
language simultaneously into several target lan-
guages with lower computational costs (in terms
of space and time) and comparable qualitative re-
sults. Moreover, the integration of several languages
and acoustic models is straightforward on means of
finite-state devices.
Nevertheless, the integrated architecture needs
more parameters to be estimated. In fact, as the
amount of targets increase the data sparseness might
become a difficult problem to cope with. In future
work we intend to make a deeper study on the per-
formance of the multi-target system with regard to
the amount of parameters to be estimated. In ad-
dition, as the first step of the learning algorithm is
decisive, we are planning to make use of reordering
models in an attempt to face up to with long dis-
tance reordering and in order to homogenize all the
languages involved.
</bodyText>
<sectionHeader confidence="0.998464" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996314">
This work has been partially supported by the Uni-
versity of the Basque Country and by Spanish CI-
CYT under grants 9/UPV 00224.310-15900/2004,
TIC2003-08681-C02-02, and CICYT es TIN2005-
08660-C04-03 respectively.
</bodyText>
<sectionHeader confidence="0.997851" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99925355">
I˜naki Alegria, Olatz Ansa, Xabier Artola, Nerea Ezeiza,
Koldo Gojenola, and Ruben Urizar. 2004. Repre-
sentation and treatment of multiword expressions in
basque. In Takaaki Tanaka, Aline Villavicencio, Fran-
cis Bond, and Anna Korhonen, editors, Second ACL
Workshop on Multiword Expressions: Integrating Pro-
cessing, pages 48–55, Barcelona, Spain, July. Associ-
ation for Computational Linguistics.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and R. L. Mercer. 1993. The mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.
Francisco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(2):205–
225.
P. Garc´ıa and E. Vidal. 1990. Inference of k-testable
languages in the strict sense and application to syntac-
tic pattern recognition. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 12(9):920–925.
</reference>
<page confidence="0.980836">
62
</page>
<reference confidence="0.998973016666667">
M.T. Gonz´alez and F. Casacuberta. 2006. Multi-Target
Machine Translation using Finite-State Transducers.
In Proceedings of TC-Star Speech to Speech Transla-
tion Workshop, pages 105–110.
John Hutchins and Harold L. Somers. 1992. An In-
troduction to Machine Translation. Academic Press,
Cambridge, MA.
Stephan Kanthak, David Vilar, Evgeny Matusov, Richard
Zens, and Hermann Ney. 2005. Novel reordering ap-
proaches in phrase-based statistical machine transla-
tion. In Proceedings of the ACL Workshop on Building
and Using Parallel Texts, pages 167–174, Ann Arbor,
Michigan, June. Association for Computational Lin-
guistics.
K. Knight and Y. Al-Onaizan. 1998. Translation with
finite-state devices. In 4th AMTA (Association for Ma-
chine Translation in the Americas).
Mehryar Mohri, Fernando Pereira, and Michael Ri-
ley. 2002. Weighted finite-state transducers in
speech recognition. Computer, Speech and Language,
16(1):69–88, January.
A. Moreno, D. Poch, A. Bonafonte, E. Lleida, J. Llisterri,
J. B. Mario, and C. Nadeu. 1993. Albayzin speech
database: Design of the phonetic corpus. In Proc. of
the European Conference on Speech Communications
and Technology (EUROSPEECH), Berl´ın, Germany.
Franz J. Och. 2000. GIZA++: Train-
ing of statistical translation models.
http://www.fjoch.com/GIZA++.html.
Daniel Ortiz, Ismael Garc´ıa-Varea, Francisco Casacu-
berta, Antonio Lagarda, and Jorge Gonz´alez. 2003.
On the use of statistical machine translation techniques
within a memory-based translation system (AME-
TRA). In Proc. of Machine Translation Summit IX,
pages 115–120, New Orleans, USA, September.
Fernando C.N. Pereira and Michael D. Riley. 1997.
Speech Recognition by Composition of Weighted Fi-
nite Automata. In Emmanuel Roche and Yves Sch-
abes, editors, Finite-State Language Processing, Lan-
guage, Speech and Communication series, pages 431–
453. The MIT Press, Cambridge, Massachusetts.
Alicia P´erez, M. In´es Torres, and Francisco Casacuberta.
2007. Speech translation with phrase based stochas-
tic finite-state transducers. In Proceedings of the 32nd
International Conference on Acoustics, Speech, and
Signal Processing (ICASSP 2007), Honolulu, Hawaii
USA, April 15-20. IEEE.
Maja Popovi´c, David Vilar, Hermann Ney, Slobodan
Joviˇci´c, and Zoran ˇSari´c. 2005. Augmenting a small
parallel text with morpho-syntactic language. In Pro-
ceedings of the ACL Workshop on Building and Us-
ing Parallel Texts, pages 41–48, Ann Arbor, Michigan,
June. Association for Computational Linguistics.
M. In´es Torres and Amparo Varona. 2001. k-tss lan-
guage models in speech recognition systems. Com-
puter Speech and Language, 15(2):127–149.
Enrique Vidal. 1997. Finite-state speech-to-speech
translation. In Proc. IEEE International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 111–114, Munich, Germany, April.
</reference>
<page confidence="0.999449">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.711967">
<title confidence="0.998281">Speech-input multi-target machine translation</title>
<author confidence="0.998154">Alicia P´erez</author>
<author confidence="0.998154">M In´es Torres M Teresa Gonz´alez</author>
<author confidence="0.998154">Francisco Casacuberta</author>
<affiliation confidence="0.998521">Dep. of Electricity and Electronics Dep. of Information Systems and Computation University of the Basque Country Technical University of Valencia</affiliation>
<email confidence="0.720803">manes@we.lc.ehu.esfcn@dsic.upv.es</email>
<abstract confidence="0.999544470588235">In order to simultaneously translate speech into multiple languages an extension of stochastic finite-state transducers is proposed. In this approach the speech translation model consists of a single network where acoustic models (in the input) and the multilingual model (in the output) are embedded. The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models. Experimental results show that the multi-target one requires less amount of memory. In addition, a single decoding is enough to get the speech translated into multiple languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I˜naki Alegria</author>
</authors>
<title>Olatz Ansa, Xabier Artola, Nerea Ezeiza, Koldo Gojenola, and</title>
<date>2004</date>
<booktitle>Second ACL Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>48--55</pages>
<editor>In Takaaki Tanaka, Aline Villavicencio, Francis Bond, and Anna Korhonen, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<marker>Alegria, 2004</marker>
<rawString>I˜naki Alegria, Olatz Ansa, Xabier Artola, Nerea Ezeiza, Koldo Gojenola, and Ruben Urizar. 2004. Representation and treatment of multiword expressions in basque. In Takaaki Tanaka, Aline Villavicencio, Francis Bond, and Anna Korhonen, editors, Second ACL Workshop on Multiword Expressions: Integrating Processing, pages 48–55, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="7017" citStr="Brown et al., 1993" startWordPosition="1114" endWordPosition="1117">rget language; E denotes the source language vocabulary, and Ai the i-th target language vocabulary; the algorithm can be outlined as follows: 1. Each multilingual sample is transformed into a single string from an extended vocabulary (F C_ E x A∗1 x · · · x A∗m) using a labeling function (Lm). This transformation searches an adequate monotonic segmentation for each of the m source-target language pairs on the basis of bilingual alignments such as those given by GIZA++ (Och, 2000). A monotonic segmentation copes with monotonic alignments, that is, j &lt; k ==&gt;. aj &lt; ak following the notation of (Brown et al., 1993). Each source token, which can be either a word or a phrase (P´erez et al., 2007), is then joined with a target phrase of each language as the corresponding segmentation suggests. Each extended symbol consists of a token from the source language plus zero 57 3:da 2:jeitsiko 1:minimoa 0:tenperatura 2:falling 1:temperatures 0:low 0:temperaturas 1:minimas 2:en 3:descenso (a) Spanish-Basque 0:temperaturas 1:minimas 2:en 3:descenso (b) Spanish-English temperaturas |temperatura |NIL maximas |maximoak |high temperatures en |NIL |NIL descenso |jaitsiko da |falling 0 1 2 3 5 minimas |minimoak |low temp</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Casacuberta</author>
<author>Enrique Vidal</author>
</authors>
<title>Machine translation with inferred stochastic finite-state transducers.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<pages>225</pages>
<contexts>
<context position="5682" citStr="Casacuberta and Vidal, 2004" startWordPosition="898" endWordPosition="901">s (q, w, p1, . .. , pm, q0), which is a transition from the state q to the state q0, with the source symbol w and producing the substrings (P1, ... , f9m); P : R —* [0, 1] is the transition probability distribution; F : Q —* [0, 1] is the final state probability distribution; The probability distributions satisfy the stochastic constraint: Vq E Q (1) F(q)+ E P(q, w, �p1, ... , f9m, q0) = 1 w,˜p1,...,˜pm,q/ 2.2 Training the multilingual translation model Both topology and parameters of an SFST can be learned fully automatically from bilingual examples making use of underlying alignment models (Casacuberta and Vidal, 2004). Furthermore, a multi-target SFST can be inferred from a multilingual set of samples (Gonz´alez and Casacuberta, 2006). Even though in realistic situations multilingual corpora are too scarce, recent works (Popovi´c et al., 2005) show that bilingual corpora covering the same domain are sufficient to obtain generalized corpora based on which one can subsequently create the required collections of aligned tuples. The inference algorithm, GIAMTI (grammatical inference and alignments for multi-target transducer inference), requires a multilingual corpus, that is, a finite set of multilingual samp</context>
</contexts>
<marker>Casacuberta, Vidal, 2004</marker>
<rawString>Francisco Casacuberta and Enrique Vidal. 2004. Machine translation with inferred stochastic finite-state transducers. Computational Linguistics, 30(2):205– 225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Garc´ıa</author>
<author>E Vidal</author>
</authors>
<title>Inference of k-testable languages in the strict sense and application to syntactic pattern recognition.</title>
<date>1990</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>12</volume>
<issue>9</issue>
<marker>Garc´ıa, Vidal, 1990</marker>
<rawString>P. Garc´ıa and E. Vidal. 1990. Inference of k-testable languages in the strict sense and application to syntactic pattern recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12(9):920–925.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Gonz´alez</author>
<author>F Casacuberta</author>
</authors>
<title>Multi-Target Machine Translation using Finite-State Transducers.</title>
<date>2006</date>
<booktitle>In Proceedings of TC-Star Speech to Speech Translation Workshop,</booktitle>
<pages>105--110</pages>
<marker>Gonz´alez, Casacuberta, 2006</marker>
<rawString>M.T. Gonz´alez and F. Casacuberta. 2006. Multi-Target Machine Translation using Finite-State Transducers. In Proceedings of TC-Star Speech to Speech Translation Workshop, pages 105–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hutchins</author>
<author>Harold L Somers</author>
</authors>
<title>An Introduction to Machine Translation.</title>
<date>1992</date>
<publisher>Academic Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2339" citStr="Hutchins and Somers, 1992" startWordPosition="339" endWordPosition="342">of error rates. In addition, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state models, such as a speech recognition system for speech-input translation purposes (Vidal, 1997). In fact, the integrated architecture has proved to work better than the decoupled one. Our main goal is, hence, to extend and assess these methodologies to accomplish spoken language multi-target translation. As far as multilingual translation is concerned, there are two main trends in machine translation devoted to translate an input string simultaneously into m languages (Hutchins and Somers, 1992): interlingua and parallel transfer. The former has historically been a knowledge-based technique that requires a deep-analysis effort, and the latter consists on m decoupled translators in a parallel architecture. These translators can be either knowledge or example-based. On the other hand, in (Gonz´alez and Casacuberta, 2006) an example based technique consisting of a single SFST that cope with multiple target languages was presented. In that approach, when translating an input sentence, only one search through the multi-target SFST is required, instead of the m independent decoding process</context>
</contexts>
<marker>Hutchins, Somers, 1992</marker>
<rawString>John Hutchins and Harold L. Somers. 1992. An Introduction to Machine Translation. Academic Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Kanthak</author>
<author>David Vilar</author>
<author>Evgeny Matusov</author>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Novel reordering approaches in phrase-based statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>167--174</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="21765" citStr="Kanthak et al., 2005" startWordPosition="3563" endWordPosition="3566">uality between the English and the Basque translations. The underlying reason might be due to the fact that SFST models do not capture properly the rich morphology of the Basque as they have to face long-distance reordering issues. These differences in the performance of the system when translating into English or into Basque have been previously detected in other works (Ortiz et al., 2003). In our case, a manual review of the models and the obtained translations encourage us to make use of reordering models in future work, since they have proved to report good results in a similar framework (Kanthak et al., 2005). 5 Concluding remarks and further work The main contribution of this paper is the proposal of a fully embedded architecture for multiple speech translation. Thus, acoustic models are integrated on the fly into a multi-target translation model. The most significant feature of this approach is its ability to carry out both the recognition and the translation into multiple languages integrated in a unique model. Due to the finite-state nature of this model, the speech translation engine is based on a Viterbilike algorithm. In contrast to the mono-target systems, multitarget SFSTs enable the tran</context>
</contexts>
<marker>Kanthak, Vilar, Matusov, Zens, Ney, 2005</marker>
<rawString>Stephan Kanthak, David Vilar, Evgeny Matusov, Richard Zens, and Hermann Ney. 2005. Novel reordering approaches in phrase-based statistical machine translation. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 167–174, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>Y Al-Onaizan</author>
</authors>
<title>Translation with finite-state devices.</title>
<date>1998</date>
<booktitle>In 4th AMTA (Association for Machine Translation in the Americas).</booktitle>
<marker>Knight, Al-Onaizan, 1998</marker>
<rawString>K. Knight and Y. Al-Onaizan. 1998. Translation with finite-state devices. In 4th AMTA (Association for Machine Translation in the Americas).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Weighted finite-state transducers in speech recognition.</title>
<date>2002</date>
<journal>Computer, Speech and Language,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="1149" citStr="Mohri et al., 2002" startWordPosition="161" endWordPosition="164">c models (in the input) and the multilingual model (in the output) are embedded. The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models. Experimental results show that the multi-target one requires less amount of memory. In addition, a single decoding is enough to get the speech translated into multiple languages. 1 Introduction In this work we deal with finite-state models which constitute an important framework in syntactic pattern recognition for language and speech processing applications (Mohri et al., 2002; Pereira and Riley, 1997). One of their outstanding characteristics is the availability of efficient algorithms for both optimization and decoding purposes. Specifically, stochastic finite-state transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains. There are several approaches implemented over SFSTs which range from word-based systems (Knight and AlOnaizan, 1998) to phrase-based systems (P´erez et al., 2007). SFSTs usually offer high speed during the decoding step and they provide competitive results in terms of error rates. In addition, SFSTs h</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2002</marker>
<rawString>Mehryar Mohri, Fernando Pereira, and Michael Riley. 2002. Weighted finite-state transducers in speech recognition. Computer, Speech and Language, 16(1):69–88, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moreno</author>
<author>D Poch</author>
<author>A Bonafonte</author>
<author>E Lleida</author>
<author>J Llisterri</author>
<author>J B Mario</author>
<author>C Nadeu</author>
</authors>
<title>Albayzin speech database: Design of the phonetic corpus.</title>
<date>1993</date>
<booktitle>In Proc. of the European Conference on Speech Communications and Technology (EUROSPEECH),</booktitle>
<location>Berl´ın, Germany.</location>
<contexts>
<context position="13066" citStr="Moreno et al., 1993" startWordPosition="2118" endWordPosition="2121"> our own continuous-speech recognition system, which implements stochastic finite-state models at all levels: acoustic-phonetic, lexical and syntactic, and which allows to infer them based on samples. The signal analysis was carried out in a standard way, based on the classical Mel-cepstrum parametrization. Each phone-like unit was modeled P(tm, s)P(x|s) (7) 59 /e/ |NIL |NIL /n/ |NIL |NIL 1 2 Figure 2: Integration on the fly of acoustic models in one edge of the SFST shown in Figure 1(c) by a typical left to right hidden Markov model. A phonetically-balanced Spanish database, called Albayzin (Moreno et al., 1993), was used to train these models. The lexical model consisted of the extended tokens of the multi-target SFST instead of running words. The acoustic transcription for each extended token was automatically obtained on the basis of the input projection of each unit, that is, the Spanish vocabulary in this case. Instead of the usual language model, we make use of the multi-target SFST itself, which had the syntactic structure provided by a k-testable in the strict sense model, with k=3, and Witten-Bell smoothing. Note that the SFST implicitly involves both input and output language models. 4 Expe</context>
</contexts>
<marker>Moreno, Poch, Bonafonte, Lleida, Llisterri, Mario, Nadeu, 1993</marker>
<rawString>A. Moreno, D. Poch, A. Bonafonte, E. Lleida, J. Llisterri, J. B. Mario, and C. Nadeu. 1993. Albayzin speech database: Design of the phonetic corpus. In Proc. of the European Conference on Speech Communications and Technology (EUROSPEECH), Berl´ın, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>GIZA++: Training of statistical translation models.</title>
<date>2000</date>
<note>http://www.fjoch.com/GIZA++.html.</note>
<contexts>
<context position="6883" citStr="Och, 2000" startWordPosition="1091" endWordPosition="1092">gual samples (s, t 1 ... , tm) E E∗xA∗1x· · ·xA∗m, where ti denotes the translation of the source sentence s into the i-th target language; E denotes the source language vocabulary, and Ai the i-th target language vocabulary; the algorithm can be outlined as follows: 1. Each multilingual sample is transformed into a single string from an extended vocabulary (F C_ E x A∗1 x · · · x A∗m) using a labeling function (Lm). This transformation searches an adequate monotonic segmentation for each of the m source-target language pairs on the basis of bilingual alignments such as those given by GIZA++ (Och, 2000). A monotonic segmentation copes with monotonic alignments, that is, j &lt; k ==&gt;. aj &lt; ak following the notation of (Brown et al., 1993). Each source token, which can be either a word or a phrase (P´erez et al., 2007), is then joined with a target phrase of each language as the corresponding segmentation suggests. Each extended symbol consists of a token from the source language plus zero 57 3:da 2:jeitsiko 1:minimoa 0:tenperatura 2:falling 1:temperatures 0:low 0:temperaturas 1:minimas 2:en 3:descenso (a) Spanish-Basque 0:temperaturas 1:minimas 2:en 3:descenso (b) Spanish-English temperaturas |t</context>
</contexts>
<marker>Och, 2000</marker>
<rawString>Franz J. Och. 2000. GIZA++: Training of statistical translation models. http://www.fjoch.com/GIZA++.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz</author>
<author>Ismael Garc´ıa-Varea</author>
<author>Francisco Casacuberta</author>
<author>Antonio Lagarda</author>
<author>Jorge Gonz´alez</author>
</authors>
<title>On the use of statistical machine translation techniques within a memory-based translation system (AMETRA).</title>
<date>2003</date>
<booktitle>In Proc. of Machine Translation Summit IX,</booktitle>
<pages>115--120</pages>
<location>New Orleans, USA,</location>
<marker>Ortiz, Garc´ıa-Varea, Casacuberta, Lagarda, Gonz´alez, 2003</marker>
<rawString>Daniel Ortiz, Ismael Garc´ıa-Varea, Francisco Casacuberta, Antonio Lagarda, and Jorge Gonz´alez. 2003. On the use of statistical machine translation techniques within a memory-based translation system (AMETRA). In Proc. of Machine Translation Summit IX, pages 115–120, New Orleans, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Michael D Riley</author>
</authors>
<title>Speech Recognition by Composition of Weighted Finite Automata.</title>
<date>1997</date>
<booktitle>In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, Language, Speech and Communication series,</booktitle>
<pages>431--453</pages>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1175" citStr="Pereira and Riley, 1997" startWordPosition="165" endWordPosition="168">ut) and the multilingual model (in the output) are embedded. The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models. Experimental results show that the multi-target one requires less amount of memory. In addition, a single decoding is enough to get the speech translated into multiple languages. 1 Introduction In this work we deal with finite-state models which constitute an important framework in syntactic pattern recognition for language and speech processing applications (Mohri et al., 2002; Pereira and Riley, 1997). One of their outstanding characteristics is the availability of efficient algorithms for both optimization and decoding purposes. Specifically, stochastic finite-state transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains. There are several approaches implemented over SFSTs which range from word-based systems (Knight and AlOnaizan, 1998) to phrase-based systems (P´erez et al., 2007). SFSTs usually offer high speed during the decoding step and they provide competitive results in terms of error rates. In addition, SFSTs have proved to be versatile</context>
</contexts>
<marker>Pereira, Riley, 1997</marker>
<rawString>Fernando C.N. Pereira and Michael D. Riley. 1997. Speech Recognition by Composition of Weighted Finite Automata. In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, Language, Speech and Communication series, pages 431– 453. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alicia P´erez</author>
<author>M In´es Torres</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Speech translation with phrase based stochastic finite-state transducers.</title>
<date>2007</date>
<booktitle>In Proceedings of the 32nd International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2007),</booktitle>
<publisher>IEEE.</publisher>
<location>Honolulu, Hawaii USA,</location>
<marker>P´erez, Torres, Casacuberta, 2007</marker>
<rawString>Alicia P´erez, M. In´es Torres, and Francisco Casacuberta. 2007. Speech translation with phrase based stochastic finite-state transducers. In Proceedings of the 32nd International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2007), Honolulu, Hawaii USA, April 15-20. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maja Popovi´c</author>
<author>David Vilar</author>
<author>Hermann Ney</author>
<author>Slobodan Joviˇci´c</author>
<author>Zoran ˇSari´c</author>
</authors>
<title>Augmenting a small parallel text with morpho-syntactic language.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>41--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<marker>Popovi´c, Vilar, Ney, Joviˇci´c, ˇSari´c, 2005</marker>
<rawString>Maja Popovi´c, David Vilar, Hermann Ney, Slobodan Joviˇci´c, and Zoran ˇSari´c. 2005. Augmenting a small parallel text with morpho-syntactic language. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 41–48, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M In´es Torres</author>
<author>Amparo Varona</author>
</authors>
<title>k-tss language models in speech recognition systems.</title>
<date>2001</date>
<journal>Computer Speech and Language,</journal>
<volume>15</volume>
<issue>2</issue>
<contexts>
<context position="8418" citStr="Torres and Varona, 2001" startWordPosition="1330" endWordPosition="1333">om the task under consideration;the related multi-target SFST (with Spanish as input, and English and Basque as output). or more words from each target language in their turn. 2. Once the set of multilingual samples has been converted into a set of single extended strings (z E P), a stochastic regular grammar can be inferred. Specifically, in this work we deal with k-testable in the string-sense grammars (Garcia and Vidal, 1990), which are considered to be a syntactic approach of the n-gram models. In addition, they allow the integration of several order models in a single smoothed automaton (Torres and Varona, 2001). 3. The extended symbols associated with the transitions of the automaton are transformed into one input token and m output phrases (w/�p1 |... |�pm) by the inverse labeling function (G−m), leading to the required transducer. Example An illustration of the inference of the multi-target SFST can be shown over a couple of simple trilingual sentences from the corpus (where “B” stands for Basque, “S” for Spanish and “E” for English): 1-B tenperatura maximoa jaitsiko da 1-S temperaturas m´aximas en descenso 1-E high temperatures falling 2-B tenperatura minimoa igoko da 2-S temperaturas minimas en </context>
</contexts>
<marker>Torres, Varona, 2001</marker>
<rawString>M. In´es Torres and Amparo Varona. 2001. k-tss language models in speech recognition systems. Computer Speech and Language, 15(2):127–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Vidal</author>
</authors>
<title>Finite-state speech-to-speech translation. In</title>
<date>1997</date>
<booktitle>Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<volume>1</volume>
<pages>111--114</pages>
<location>Munich, Germany,</location>
<contexts>
<context position="1934" citStr="Vidal, 1997" startWordPosition="278" endWordPosition="279">tochastic finite-state transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains. There are several approaches implemented over SFSTs which range from word-based systems (Knight and AlOnaizan, 1998) to phrase-based systems (P´erez et al., 2007). SFSTs usually offer high speed during the decoding step and they provide competitive results in terms of error rates. In addition, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state models, such as a speech recognition system for speech-input translation purposes (Vidal, 1997). In fact, the integrated architecture has proved to work better than the decoupled one. Our main goal is, hence, to extend and assess these methodologies to accomplish spoken language multi-target translation. As far as multilingual translation is concerned, there are two main trends in machine translation devoted to translate an input string simultaneously into m languages (Hutchins and Somers, 1992): interlingua and parallel transfer. The former has historically been a knowledge-based technique that requires a deep-analysis effort, and the latter consists on m decoupled translators in a par</context>
</contexts>
<marker>Vidal, 1997</marker>
<rawString>Enrique Vidal. 1997. Finite-state speech-to-speech translation. In Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 111–114, Munich, Germany, April.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>