<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000468">
<title confidence="0.976696">
Automatically Learning Qualia Structures from the Web
</title>
<author confidence="0.982944">
Philipp Cimiano &amp; Johanna Wenderoth
</author>
<affiliation confidence="0.9710715">
Institute AIFB
University of Karlsruhe
</affiliation>
<sectionHeader confidence="0.978637" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99987895">
Qualia Structures have many applications
within computational linguistics, but currently
there are no corresponding lexical resources
such as WordNet or FrameNet. This paper
presents an approach to automatically learn
qualia structures for nominals from the World
Wide Web and thus opens the possibility to ex-
plore the impact of qualia structures for natural
language processing at a larger scale. Further-
more, our approach can be also used support a
lexicographer in the task of manually creating
a lexicon of qualia structures. The approach is
based on the idea of matching certain lexico-
syntactic patterns conveying a certain seman-
tic relation on the World Wide Web using stan-
dard search engines. We evaluate our approach
qualitatively by comparing our automatically
learned qualia structures with the ones from the
literature, but also quantitatively by presenting
results of a human evaluation.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998876785714286">
Qualia Structures have been originally introduced by
(Pustejovsky, 1991) and are used for a variety ofpurposes
in Natural Language processing such as the analysis of
compounds (Johnston and Busa, 1996), co-composition
and coercion (Pustejovsky, 1991) as well as for bridging
reference resolution (Bos et al., 1995). Further, it has also
been argued that qualia structures and lexical semantic
relations in general have applications in information re-
trieval (Voorhees, 1994; Pustejovsky et al., 1993). One
major bottleneck however is that currently Qualia Struc-
tures need to be created by hand, which is probably also
the reason why there are no practical system using qualia
structures, but a lot of systems using globally available re-
sources such as WordNet (Fellbaum, 1998) or FrameNet&apos;
</bodyText>
<footnote confidence="0.930331">
1http://framenet.icsi.berkeley.edu/
</footnote>
<bodyText confidence="0.9999282">
as source of lexical/world knowledge. The work de-
scribed in this paper addresses this issue and presents
an approach to automatically learning qualia structures
for nominals from the Web. The approach is inspired
in recent work on using the Web to identify instances
of a relation of interest such as in (Markert et al., 2003)
and (Cimiano and Staab, 2004). These approaches are
in essence a combination of the usage of lexico-syntactic
pattens conveying a certain relation of interest such as in
(Hearst, 1992), (Charniak and Berland, 1999), (Iwanska
et al., 2000) or (Poesio et al., 2002) with the idea of us-
ing the web as a big corpus (Resnik and Smith, 2003),
(Grefenstette, 1999), (Keller et al., 2002).
The idea of learning Qualia Structures from the Web is
not only a very practical, it is in fact a principled one.
While single lexicographers creating qualia structures -
or lexicon entries in general - might take very subjective
decisions, the structures learned from the Web do not mir-
ror the view of a single person, but of the whole world as
represented on the World Wide Web. Thus, an approach
learning qualia structures from the Web is in principle
more reliable than letting lexicographers craft lexical en-
tries on their own. Obviously, on the other hand, using
an automatic web based approach yields also a lot of in-
appropriate results which are due to 1) errors produced
by the linguistic analysis (e.g. part-of-speech tagging), 2)
idiosyncrasies of ranking algorithms of search machines,
3) the fact that the Web or in particular search engines
are to a great extent commercially biased, 4) the fact that
people also publish erroneous information on the Web,
and 5) lexical ambiguities. Because of these reasons our
aim is in fact not to replace lexicographers, but to support
them in the task of creating qualia structures on the basis
of the automatically learned qualia structures. The pa-
per is structured as follows: Section 2 introduces qualia
structures and describes the specific qualia structures we
aim to acquire. Section 3 describes our approach in detail
and section 4 presents a quantitative and qualitative eval-
uation of our approach. Before concluding, we discuss
some related work in Section 5.
</bodyText>
<page confidence="0.992691">
28
</page>
<note confidence="0.9706665">
Proceedings o�the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 28–37,
Ann Alm, June 2005. c�2005 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.819819" genericHeader="method">
2 Qualia Structures
</sectionHeader>
<bodyText confidence="0.973515978723404">
According to Aristotle, there are four basic factors or
causes by which the nature of an object can be described
(cf. (Kronlid, 2003)):
the material cause, i.e. the material an object is
made of
the agentive cause, i.e. the source of movement, cre-
ation or change
the formal cause, i.e. its form or type
the final cause, i.e. its purpose, intention or aim
In his Generative Lexicon (GL) framework (Puste-
jovsky, 1991) reused Aristotle’s basic factors for the de-
scription of the meaning of lexical elements. In fact he in-
troduced so called Qualia Structures by which the mean-
ing of a lexical element is described in terms of four roles:
Constitutive: describing physical properties of an
object, i.e. its weight, material as well as parts and
components
Agentive: describing factors involved in the bringing
about of an object, i.e. its creator or the causal chain
leading to its creation
Formal: describing that properties which distinguish
an object in a larger domain, i.e. orientation, magni-
tude, shape and dimensionality
Telic: describing the purpose or function of an object
Most of the qualia structures used in (Pustejovsky,
1991) however seem to have a more restricted interpre-
tation. In fact, in most examples the Constitutive role
seems to describe the parts or components of an object,
while the Agentive role is typically described by a verb
denoting an action which typically brings the object in
question into existence. The Formal role normally con-
sists in typing information about the object, i.e. its hyper-
nym or superconcept. Finally, the Telic role describes the
purpose or function of an object either by a verb or nom-
inal phrase. The qualia structure for knife for example
could look as follows (cf. (Johnston and Busa, 1996)):
Formal: artifact tool
Constitutive: blade,handle,...
Telic: cut act
Agentive: make act
Our understanding of Qualia Structure is in line with this
restricted interpretation of the qualia roles. Our aim is to
automatically acquire Qualia Structures from the Web for
nominals, looking for (i) nominals describing the type of
the object, (ii) verbs defining its agentive role, (iii) nomi-
nals describing its parts or components and (iv) nouns or
verbs describing its intended purpose.
</bodyText>
<sectionHeader confidence="0.997198" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.9955795">
Our approach to learning qualia structures from the
Web is on the one hand based on the assumption that
instances of a certain semantic relation can be learned by
matching certain lexico-syntactic patterns more or less
reliably conveying the relation of interest in line with
the seminal work of (Hearst, 1992), who defined the
following patterns conveying a hypernym relation:
According to Hearst, from such patterns we can derive
that for all .
For example, for the expression: Bruises, wounds,
broken bones or other injuries, we would extract:
hypernym(bruise,injury), hypernym(broken bone,injury)
and hypernym(wound,injury). However, it is well known
that Hearst-style patterns occur rarely, such that it seems
intuitive to match them on the Web. So in our case we
are looking not only for the hypernym relation (com-
parable to the Formal-Relation) but for similar patterns
conveying a Constitutive, Telic or Agentive relation. As
currently there is no support for searching using regular
expressions in standard search engines such as Google or
Altavista3, our approach consists of 5 phases (compare
Figure 1):
</bodyText>
<listItem confidence="0.9922769">
1. generate for each qualia role a set of so called clues,
i.e. search engine queries indicating the relation of
interest
2. download the snippets of the 10 first Google hits
matching the generated clues 4
3. part-of-speech-tagging of the downloaded snippets
4. match regular expressions conveying the qualia role
of interest
5. weight the returned qualia elements according to
some measure
</listItem>
<bodyText confidence="0.8046935">
The outcome of this process are then so called
Weighted Qualia Structures (WQSs) in which every
</bodyText>
<footnote confidence="0.948831714285714">
2 stands for a noun phrase.
3An exception is certainly the Linguist’s Search Engine
(Resnik and Elkiss, 2003)
4The reason for using only the 10 first hits is to maintain
efficiency. With the current setting the systems needs between
3 and 10 minutes to generate the qualia structure for a given
nominal
</footnote>
<equation confidence="0.785677666666666">
2
(2) such as
, ,... (andor)
, ,..., (andor) other
(andor)
(1) such as
, , ...,(andor)
(4) , (includingespecially)
, , ...,
</equation>
<page confidence="0.993342">
29
</page>
<bodyText confidence="0.999694">
qualia element in a certain role is weighted according to
some measure. The patterns in our pattern library are ac-
tually tuples where is a regular expression defined
over part-of-speech tags and a function
called the clue. Given a nominal and a clue , the
query is sent to the Google API and we download the
abstracts of the first documents matching this query and
then process the abstracts to find instances of pattern .
For example, given the clue and
the instance computer we would download abstracts
matching the query f(computer), i.e. ”such as comput-
ers”. Hereby is a function returning the plural form
of x. We implemented this function as a lookup in a lexi-
con in which plural nouns are mapped to their base form.
With the use of such clues, we thus download a number
of Google-abstracts in which a corresponding pattern will
probably be matched thus restricting the linguistic analy-
sis to a few promising pages. The downloaded abstracts
are then part-of-speech tagged using QTag (Tufis and Ma-
son, 1998). Then we match the corresponding pattern
in the downloaded snippets thus yielding candidate qualia
elements as output. In our approach we then calculate the
weight of a candidate qualia element for the term we
want to compute the qualia structure for by the Jaccard
Coefficient:
The result is then a Weighted Qualia Structure (WQS) in
which for each role the qualia elements are weighted ac-
cording to this Jaccard coefficient. In what follows we
describe in detail the procedure for acquiring qualia el-
ements for each qualia role. In particular, we describe
in detail the clues and lexico-syntactic patterns used. In
general, the patterns have been crafted by hand, testing
and refining them in an iterative process, paying attention
to maximize their coverage but also accuracy.
In general it is important to mention that by this approach
we are not able to detect and separate multiple meanings
of words, i.e. to handle polysemy, which is appropriately
accounted for in the framework of the Generative Lexi-
con (Pustejovsky, 1991).
</bodyText>
<subsectionHeader confidence="0.99711">
3.1 The Formal Role
</subsectionHeader>
<bodyText confidence="0.999988142857143">
To derive qualia elements for the Formal role, we first
download for each of the clues in Table 1 the first 10
abstracts matching the clue and then process them offline
matching the patterns defined over part-of-speech-tags5
thus yielding up to 10 different qualia element candidates
per clue. The patterns are specified in form of regular
expressions, whereby the part-of-speech tags are always
</bodyText>
<footnote confidence="0.999046">
5We use the well-known Penn Treebank tagset described at
http://www.computing.dcu.ie/ acahill/tagset.html.
</footnote>
<figureCaption confidence="0.999798">
Figure 1: General Approach
</figureCaption>
<bodyText confidence="0.990983513513514">
given in square brackets after the token. Further, besides
using the traditional regular expression operators such
as , and , we also use Perl-like symbols such as
denoting any alphabetic character as well as [a-z]
denoting the set of all lower case letters.
As there are 4 different clues for the Formal role, we thus
yield up to 40 qualia elements as potential candidates
to fill the Formal role. In general, we paid attention to
create clues relying on indefinite articles as we found
out that they produce more general and reliable results
than when using definite articles. In order to choose the
correct indefinite article – a or an – or even using no
article at all, we implemented some ad-hoc heuristics
checking if the first letter of the term in question is a
vowel and checking if the term is used more often with
an article or without an article on the Web by a set of
corresponding Google queries. The alternative ’(a/an/?)’
means that we use either the indefinite article ’a’ ’an’
or no article depending on the results of the above
mentioned Google queries.
A general question raised also by Hearst (Hearst, 1992)
is how to deal with NP modification. Hearst’s conclusion
is that this depends on the application. In our case we
mainly remove adjective modifiers, keeping only the
heads of noun phrases as candidate qualia elements.
The lemmatized heads of the NP noun phrase are then
regarded as qualia role candidates for the Formal role.
These candidates are then weighted using the above
defined Jaccard Coefficient measure. Hereby, a noun
phrase is an instance matching the following regular
expression:
NP:=[a-z]+[DT]? ([a-z]+[JJ])+? ([a-z]+[NN(S?)])+,
where the head is the underlined expression, which
is lemmatized and considered as a candidate qualia
element. After some initial experiments we decided not
to use the patterns ’X is Y’ and ’X is a kind of Y’ such
as in a book is an item or a book is a kind ofpublication
</bodyText>
<page confidence="0.996835">
30
</page>
<bodyText confidence="0.995389">
as well as the pattern ’Y, including X’ (compare (Hearst,
1992)) as we found that in our settings they delivered
quite spurious results.
</bodyText>
<table confidence="0.9956904">
Clue Pattern
such as NP ,? such[DT] as[IN] NP
especially NP ,? especially[RB] NP
or other NP or[CC] other[JJ] NP
and other NP and[CC] other[JJ] NP
</table>
<tableCaption confidence="0.999761">
Table 1: Clues and Patterns for the Formal role
</tableCaption>
<subsectionHeader confidence="0.998434">
3.2 The Constitutive Role
</subsectionHeader>
<bodyText confidence="0.8643072">
The procedure for finding elements of the Constitutive
role is similar to the one described above for the Formal
role. The corresponding clues and patterns are given in
Table 2. As above, the candidate qualia elements are then
the lemmatized heads of the noun phrase NP .
</bodyText>
<table confidence="0.591251692307692">
Clue Pattern
(a/an)? is made NP is[VBZ] made[VBN]
up of up[RP] of[IN] NP
are made up of NP are[VBP] made[VBN]
up[RP] of[IN] NP
(a/an)? is made of NP are[VBP] made[VBN]
of[IN] NP
are made of NP are[VBP] made[VBN]
of[IN] NP
(a/an)? comprises NP comprises[VBZ] NP
comprise NP comprise[VBP] NP
(a/an)? consists of NP consists[VBZ] of[IN] NP
consist of NP consist[VBP] of[IN] NP
</table>
<tableCaption confidence="0.972504">
Table 2: Clues and Patterns for the Constitutive Role
</tableCaption>
<bodyText confidence="0.99997125">
As an additional heuristic, we test if the lemmatized
head of NP is an element of the following list contain-
ing nouns denoting an indication of amount: variety,
bundle, majority, thousands, million, millions, hundreds,
number, numbers, set, sets, series, range and further-
more this NP is followed by the preposition ’of’. In
that case we would take the head of the noun phrase after
the preposition ’of’ as potential candidate of the Consti-
tutive role. For example, when considering a conversa-
tion is made up of a series of observable interpersonal
exchanges, we would take exchange as a potential qualia
element candidate instead of series.
</bodyText>
<subsectionHeader confidence="0.998055">
3.3 The Telic Role
</subsectionHeader>
<bodyText confidence="0.99166975">
The Telic Role is in principle acquired in the same way as
the Formal and Constitutive roles with the exception that
the qualia element is not only the head of a noun phrase,
but also a verb or a verb followed by a noun phrase. Table
3 gives the corresponding clues and patterns. In particu-
lar, the returned candidate qualia elements are the lem-
matized underlined expressions in PURP:= w+[VB] NP
NP be[VB] w+[VBD]).
</bodyText>
<table confidence="0.971732111111111">
Clue Pattern
purpose of a is purpose[NN] of[IN]
NP is[VBZ] (to[TO])? PURP
purpose of is purpose[NN] of[IN]
NP is[VBZ] (to[TO])? PURP
(a/an)? is used to (AaAnan) NP is[VBZ]
used[VBN] to[TO] PURP
are used to NP are[VBZ] used[VBN]
to[TO] PURP
</table>
<tableCaption confidence="0.999168">
Table 3: Clues and Patterns for the Telic Role
</tableCaption>
<subsectionHeader confidence="0.923526">
3.4 The Agentive Role
</subsectionHeader>
<bodyText confidence="0.999971387096774">
As mentioned in (Hearst, 1992), it is not always as
straightforward to find lexico-syntactic patterns reliably
conveying a certain relation. In fact, we did not find any
patterns reliably identifying qualia elements for the Agen-
tive role. Certainly, it would have been possible to find
the source of the creation by using patterns such as X is
made by Y or X is produced by Y. However, we found
that these patterns do not reliably convey a verb describ-
ing how an object is brought into existence. The fact
that it is far from straightforward to find patterns indi-
cating an Agentive role is further corroborated by the re-
search in (Yamada and Baldwin, 2004), in which only
one pattern indicating a qualia relation is used, namely
’NN BE V[+en]’ in order to match passive constructions
such as the book was written. On the other hand it is
clear that constructing a reliable clue for this pattern is
not straightforward given the current state-of-the-art con-
cerning search engine queries. Nevertheless, in order to
also get results for the Agentive role, we apply a different
method here. Instead of issuing a query which is used to
search for possible candidates for the role, we take advan-
tage of the fact that the verbs which describe how some-
thing comes into being, particularly artificial things, are
often quite general phrases like ”make, produce, write,
build...”. So instead of generating clues as above, we
calculate the value
for the nominal we want to acquire a qualia structure for
as well as the following verbs: build, produce, make,
write, plant, elect, create, cook, construct and design. If
this value is over a threshold (0.0005 in our case), we as-
sume that it is a valid filler of the Agentive qualia role.
</bodyText>
<sectionHeader confidence="0.998432" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999779">
We evaluate our approach for the lexical elements knife,
beer, book, which are also discussed in (Johnston and
</bodyText>
<page confidence="0.999327">
31
</page>
<bodyText confidence="0.999960076923077">
Busa, 1996) or (Pustejovsky, 1991), as well as computer,
an abstract noun, i.e. conversation, as well as two very
specific multi-term words, i.e. natural language process-
ing and data mining. We give the automatically learned
weighted Qualia Structures for these entries in Figures 3,
4, 5 and 6. The evaluation of our approach consists on
the one hand of a discussion of the weighted qualia struc-
tures, in particular comparing them to the ideal struc-
tures form the literature. On the other hand, we also
asked a student at our institute to assign credits to each
of the qualia elements from 0 (incorrect) to 3 (totally cor-
rect) whereby 1 credit meaning ’not totally wrong’ and 2
meaning ’still acceptable’.
</bodyText>
<subsectionHeader confidence="0.994644">
4.1 Quantitative Evaluation
</subsectionHeader>
<bodyText confidence="0.999996157894737">
The distribution of credits for each qualia role and term
is given in Table 4. It can be seen that with three
exceptions: beer formal, book agentive as well as
beer constitutive, ’3’ is the mark assigned in most
cases to the automatically learned qualia elements. Fur-
ther, for almost every query term and qualia role, at
least 50% of the automatically learned qualia structures
have a mark of ’2’ or ’3’ – the only exceptions being
beer formal with 45.45%, book agentive with 33.33%
and beer constitutive with 28.57%. In general this
shows that the automatically learned qualia roles are in-
deed reasonable. Considering the average over all the
terms (’All’ in the table), we observe that the qualia role
which is recognized most reliably is the Telic one with
73.15% assignments of credit ’3’ and 75.93% of cred-
its ’2’ or ’3’, followed by the Agentive role with 71.43%
assignments of credit 3. The results for the Formal and
Constitutive role are still reasonable with 62.09% assign-
ments of credit ’3’ and 66.01% assignments of credits
’2’ or ’3’ for the Formal role; and respectively 61.61%
and 64.61% for the Constitutive role. The worst results
are achieved for the Constitutive role due to the fact that
26.26% of the qualia elements are regarded as totally
wrong. Table 5 supports the above claims and shows
the average credits assigned by the human evaluator per
query term and role. It shows again that the roles with
the best results are the Agentive and Telic roles, while the
Formal and Constitutive roles are not identified as accu-
rately. This is certainly due to the fact that the patterns
for the Telic role are much less ambiguous than the ones
for the Formal and Constitutive roles. Finally, we also
discuss the correlation between the credits assigned and
the Jaccard Coefficient. Figure 2 shows this correlation.
While for the Formal role the correlation is as expected,
i.e. the higher the credit assigned, the higher also the Jac-
card Coefficient, for the Constitutive and Telic roles this
correlation is unfortunately less clear, thus making the
task of finding a cut-off threshold more difficult.
</bodyText>
<subsectionHeader confidence="0.988276">
4.2 Qualitative Evaluation &amp; Discussion
</subsectionHeader>
<bodyText confidence="0.999995924528302">
In this section we provide a more subjective evaluation
of the automatically learned qualia structures by compar-
ing them to ideal qualia structures discussed in the liter-
ature wherever possible. In particular, we discuss more
in detail the qualia structure for book, knife and beer and
leave the detailed assessment of the qualia structures for
computer, natural language processing, data mining and
conversation to the interested reader.
For book, the first four candidates of the Formal role,
i.e. product, item, publication and document are very ap-
propriate, but alluding to the physical object meaning of
book as opposed to the meaning in the sense of informa-
tion container (compare (Pustejovsky, 1991). As candi-
dates for the Agentive role we have make, write and cre-
ate which are appropriate, write being the ideal filler of
the Agentive role according to (Pustejovsky, 1991). For
the Constitutive role of book we get – besides it at the
first position which could be easily filtered out – sign
(2nd position), letter (3rd position) and page (6th posi-
tion), which are quite appropriate. The top four candi-
dates for the Telic role are give, select, read and purchase.
It seems that give is emphasizing the role of a book as a
gift, read is referring to the most obvious purpose of a
book as specified in the ideal qualia structures of (Puste-
jovsky, 1991) as well as (Johnston and Busa, 1996) and
purchase denotes the more general purpose of a book, i.e.
to be bought.
The first element of the Formal role of knife unfortunately
denotes the material it is typically made of, i.e. steel, but
the next 5 elements are definitely appropriate: weapon,
item, kitchenware, object and instrument. The ideal ele-
ment artifact tool (compare (Johnston and Busa, 1996))
can be found at the 10th position. The results are inter-
esting in that on the one hand the most prominent mean-
ing of knife according to the web is the one of a weapon.
On the other hand our results are more specific, classify-
ing a knife as kitchenware instead of merely as an arti-
fact tool. Very interesting are the specific and accurate
results at the end of the list. The reason why they appear
at the end is that the Jaccard Coefficient ranks them lower
because they are more specific, thus appearing less fre-
quently. This shows that using some other measure less
sensitive to frequency could yield more accurate results.
The fillers of the Agentive role produce, make and create
seem all appropriate, whereby make corresponds exactly
to the ideal filler for the Agentive role as mentioned in
(Johnston and Busa, 1996). The results for the Constitu-
tive role contain not only parts but also materials a knife
is made of and thus contain more information than the
typical qualia structures assumed in the literature. The
best results are (in this order) blade, metal, steel, wood
and handle at the 6th position. In fact, in the ideal qualia
structure in (Johnston and Busa, 1996) blade and han-
</bodyText>
<page confidence="0.988951">
32
</page>
<table confidence="0.999873810810811">
0 Formal 2 3
1
Book 2/17 (11.76%) 4/17 (23.52%) 1/17 (5.88%) 10/17 (58.82%)
Computer 8/28 (28.57%) 1/28 (3.57%) 2/28 (7.14%) 17/28 (60.71%)
Knife 3/16 (18.75%) 0/16 (0%) 0/16 (0%) 13/16 (81.25%)
Beer 12/22 (54.54%) 0/22 (0%) 2/22 (9.09%) 8/22 (36.36%)
Data Mining 6/25 (24%) 0/25 (0%) 0/25 (0%) 19/25 (76%)
Natural Language Processing 2/15 (13.33%) 1/15 (6.66%) 0/15 (0%) 12/15 (80%)
Conversation 10/30 (33.33%) 4/30 (13.33%) 0/30 (0%) 16/30 (53.33%)
All 43/153 (28.10%) 11/153 (7.19%) 6/153 (3.92%) 95/153 (62.09%)
Agentive
Book 0/3 (0%) 2/3 (66.66%) 0/3 (0%) 1/3 (33.33%)
Computer 0/1 (0%) 0/1 (0%) 0/1 (0%) 1/1 (100%)
Knife 0/3 (0%) 0/3 (0%) 0/3 (0%) 3/3 (100%)
Beer 0/3 (0%) 1/3 (33.33%) 0/3 (0%) 2/3 (66.66%)
Data Mining 0/1 (0%) 0/1 (0%) 0/1 (0%) 1/1 (100%)
Natural Language Processing 0/1 (0%) 0/1 (0%) 0/1 (0%) 1/1 (100%)
Conversation 1/2 (50%) 0/2 (0%) 0/2 (0%) 1/2 (50%)
All 1/14 (7.14%) 3/14 (21.43%) 0/14 (0%) 10/14 (71.43%)
Constitutive
Book 8/29 (27.58%) 4/29 (13.79%) 1/29 (3.44%) 16/29 (55.17%)
Computer 6/26 (23.07%) 1/26 (3.84%) 0/26 (0%) 19/26 (73.07%)
Knife 4/15 (26.66%) 0/15 (0%) 0/15 (0%) 11/15 (73.33%)
Beer 5/7 (71.42%) 0/7 (0%) 0/7 (0%) 2/7 (28.57%)
Data Mining 0/1 (0%) 0/1 (0%) 0/1 (0%) 1/1 (100%)
Natural Language Processing
Conversation 3/21 (14.28%) 4/21 (19.04%) 0/21 (0%) 14/21 (66.66%)
All 26/99 (26.26%) 9/99 (9%) 3/99 (3%) 61/99 (61.61%)
Telic
Book 3/22 (13.63%) 2/22 (9.09%) 3/22 (13.63%) 14/22 (63.63%)
Computer 0/27 (0%) 3/27 (11.11%) 0/27 (0%) 24/27 (88.88%)
Knife 5/18 (27.77%) 0/18 (0%) 0/18 (0%) 13/18 (72.22%)
Beer
Data Mining 2/22 (9.09%) 4/22 (18.18%) 0/22 (0%) 16/22 (72.72%)
Natural Language Processing 1/6 (16.66%) 0/6 (0%) 0/6 (0%) 5/6 (83.33%)
Conversation 6/13 (46.15%) 0/13 (0%) 0/13 (0%) 7/13 (53.84%)
All 17/108 (15.74%) 9/108 (8.33%) 3/108 (2.78%) 79/108 (73.15%)
</table>
<tableCaption confidence="0.94529">
Table 4: Distribution of credits for each role and term
</tableCaption>
<table confidence="0.999979">
Formal Agentive Constitutive Telic
Book 2.12 1.67 1.86 2.27
Computer 2 3 2.23 2.78
Knife 2.44 3 2.2 2.17
Beer 1.27 2.33 0.96 n.a.
Data Mining 2.28 3 3 2.36
Natural Language Processing 2.47 3 n.a. 2.5
Conversation 1.73 1.5 2.19 1.62
All 1.99 2.36 2.02 2.33
</table>
<tableCaption confidence="0.999372">
Table 5: Average credits for each role
</tableCaption>
<page confidence="0.974596">
33
</page>
<figure confidence="0.984317">
0 0.5 1 1.5 2 2.5 3
Credit
</figure>
<figureCaption confidence="0.927094">
Figure 2: Average Jaccard Coefficient value per credit
</figureCaption>
<figure confidence="0.997934066666667">
11
10
9
8
7
6
5
4
3
2
1
Formal
Constitutive
Telic
Jaccard Coefficient
</figure>
<bodyText confidence="0.99747205882353">
dle are mentioned as fillers of the Constitutive role, while
there are no elements describing the materials of which a
knife is made of. Finally, the top four candidates for the
Telic role are kill, slit, cut and slice, whereby cut corre-
sponds to the ideal filler of the qualia structure for knife
as mentioned in (Johnston and Busa, 1996).
Considering the qualia structure for beer, it is surpris-
ing that no purpose has been found. The reason is that
currently no results are returned by Google for the clue
a beer is used to and the four snippets returned for the
purpose of a beer contain expressions of the form the
purpose of a beer is to drink it which is not matched
by our patterns as it is a pronoun and not matched by
our NP pattern (unless it is matched by an error as in the
Qualia Structure for book in Figure 4). Considering the
results for the Formal role, the elements drink (1st), al-
cohol (2nd) and beverage (4th) are much more specific
than liquid as given in (Pustejovsky, 1991), while thing
at the 3rd position is certainly too general. Furthermore,
according to the automatically learned qualia structure,
beer is made of rice, malt and hop, which are perfectly
reasonable results. Very interesting are the results con-
coction and libation for the Formal role of beer, which
unfortunately were rated low by our evaluator (compare
Figure 3).
Overall, the discussion has shown that the results pro-
duced by our method are reasonable when compared to
the qualia structures from the literature. In general, our
method produces in some cases additional qualia candi-
dates, such as the ones describing the material a knife is
typically made of. In other cases it discovers more spe-
cific candidates, such as for example weapon or kitchen-
ware as elements of the Formal role for knife instead of
the general term artifact tool.
</bodyText>
<sectionHeader confidence="0.999954" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999987565217392">
There is quite a lot of work related to the use of lin-
guistic patterns to discover certain ontological relations
from text. Hearst’s (Hearst, 1992) seminal work had the
aim of discovering taxonomic relations from electronic
dictionaries. The precision of the is-a-relations learned
is 61/106 (57.55%) when measured against WordNet
as gold standard, which is comparable to our results.
Hearst’s idea has been reapplied by different researchers
with either slight variations in the patterns used (Iwan-
ska et al., 2000), to acquire knowledge for anaphora res-
olution (Poesio et al., 2002), or to discover other kinds
of semantic relations such as part-of relations (Char-
niak and Berland, 1999) or causation relations (Girju and
Moldovan, 2002).
Instead of matching these patterns in a large text collec-
tion, some researchers have recently turned to the Web
to match these patterns such as in (Cimiano and Staab,
2004) or (Markert et al., 2003). (Cimiano and Staab,
2004) for example aim at learning instance-of as well as
taxonomic (is-a) relations. This is very related to the ac-
quisition of the Formal role proposed here. (Markert et
al., 2003) aim at acquiring knowledge for anaphora res-
olution, while (Etzioni et al., 2004) aim at learning the
complete extension of a certain concept. For example,
they aim at finding all the actors in the world.
Our approach goes further in that it not only learns typing,
superconcept or instance-of relations, but also Constitu-
tive and Telic relations.
There also exist approaches specifically aiming at learn-
ing qualia elements from corpora based on machine
learning techniques. (Claveau et al., 2003) for example
use Inductive Logic Programming to learn if a given verb
is a qualia element or not. However, their approach goes
not as far as learning the complete qualia structure for a
lexical element in an unsupervised way as presented in
our approach. In fact, in their approach they do not dis-
tinguish between different qualia roles and restrict them-
selves to verbs as potential fillers of qualia roles. (Ya-
mada and Baldwin, 2004) present an approach to learn-
ing Telic and Agentive relations from corpora analyzing
two different approaches: one relying on matching cer-
tain lexico-syntactic patterns as in the work presented
here, but also a second approach consisting in training
a maximum entropy model classifier. Their conclusion is
that the results produced by the classification approach
correlate better with two hand-crafted gold standards.
</bodyText>
<page confidence="0.997929">
34
</page>
<bodyText confidence="0.9999091">
The patterns used by (Yamada and Baldwin, 2004) differ
substantially from the ones used in this paper, which is
mainly due to the fact that search engines do not provide
support for regular expressions and thus instantiating a
pattern as ’V[+ing] Noun’ is impossible in our approach
as the verbs are unknown a priori.
Finally, (Pustejovsky et al., 1993) present an interesting
framework for the acquisition of semantic relations from
corpora not only relying on statistics, but guided by the-
oretical lexicon principles.
</bodyText>
<sectionHeader confidence="0.998205" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999576">
We have presented an approach to automatically learn-
ing Qualia Structures from the Web. Such an approach is
especially interesting either for lexicographers aiming at
constructing lexicons, but even more for natural language
processing systems relying on deep lexical knowledge as
represented by qualia structures. We have in particular
shown that the qualia structures learned by our system
are reasonable. In general, it is valid to claim that our
system is the first one automatically producing complete
qualia structures for a given nominal.
Our system can be tested online at http://km.aifb.uni-
karlsruhe.de/pankow/qualia/. Further work will aim at
improving the system but also at using the automatically
learned structures within NLP applications.
Acknowledgments The work reported in this paper
has been partially supported by the SmartWeb project6,
funded by the German Ministry of Research. Thanks also
to Laura Goebes for assisting in the evaluation of the sys-
tem.
</bodyText>
<table confidence="0.997399782608695">
Knife
Formal
steel 3.8666 3
weapon 3.4876 3
item 1.7458 3
kitchenware 1.6840 3
object 1.6025 3
instrument 1.2963 3
utensil 1.2886 3
court 1.1441 0
equipment 0.9479 3
tool 0.7090 3
action 0.7028 0
time 0.6590 0
cutting instrument 0.0739 3
cutting instruments 0.0551 3
emergency items 0.0383 3
cutting weapons 0.0232 3
Agentive
produce 3
make 3
create 3
Constitutive
blade 5.4618 3
metal 5.0205 3
steel 3.8666 3
wood 2.9699 3
person 2.6829 0
handle 1.9223 3
tang 1.6784 3
gold 1.6609 0
alloy 1.2466 3
dragonfly 0.8742 3
model 0.7513 3
tool 0.7090 0
quality 0.6575 3
group 0.5764 0
rotating discs 0.0062 3
Telic
kill 3.7626 3
slit 3.4829 3
cut 3.4373 3
slice 3.2499 3
begin 2.4192 0
split 1.7241 3
avoid 1.3190 0
score 1.0204 0
an instrument 0.8137 0
process 0.5327 3
prune 0.4505 3
incise 0.0573 3
cut things 0.0545 3
remove moisture 0.0479 3
add details 0.0361 0
cut a flap 0.0264 3
split a cake 0.0010 3
slit a wide variety 0.0004 3
Beer
Formal
drink 9.6677 3
alcohol 4.6006 3
thing 4.0028 3
beverage 3.6182 3
adventure 3.0825 0
mistake 2.7014 0
matter 2.6533 0
style 2.1583 0
delight 1.9198 3
people 1.4465 0
creation 1.2201 0
can 0.9433 3
list 0.8432 0
product 0.8224 3
refreshment 0.5328 3
concoction 0.4851 0
libation 0.1147 0
summery 0.0872 0
adult beverages 0.0848 2
speciality beers 0.0269 2
looney things 0.0002 0
Agentive
produce 3
make 3
create 1
Constitutive
rice 2.9871 0
malt 2.5724 3
hop 2.1744 3
bottom 2.1179 0
continuum 0.4808 0
puree 0.3563 0
stoneware 0.3325 0
</table>
<sectionHeader confidence="0.886626" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.932653466666666">
J. Bos, P. Buitelaar, and M. Mineur. 1995. Bridging
as coercive accomodation. In E. Klein, S. Manand-
har, W. Nutt, and J. Siekmann, editors, Working Notes
of the Edinburgh Conference on Computational Logic
and Natural Language Processing (CLNLP-95).
E. Charniak and M. Berland. 1999. Finding parts in
very large corpora. In Proceedings of the 37th Annual
Meeting of the ACL, pages 57–64.
P. Cimiano and S. Staab. 2004. Learning by googling.
SIGKDD Explorations, 6(2), December.
V. Claveau, P. Sebillot, C. Fabre, and P. Bouillon. 2003.
Learning semantic lexicons from a part-of-speech and
semantically tagged corpus using inductive logic pro-
gramming. Journal of Machine Learning Research,
(4):493–525.
</bodyText>
<footnote confidence="0.961459">
6http://www.smartweb-projekt.de/
</footnote>
<figureCaption confidence="0.999545">
Figure 3: Weighted Qualia Structure for knife and beer
</figureCaption>
<bodyText confidence="0.907187533333333">
O. Etzioni, M. Cafarella, D. Downey, S. Kok, A.-M.
Popescu, T. Shaked, S. Soderland, D.S. Weld, and
A. Yates. 2004. Web-scale information extraction in
KnowItAll (preliminary results). In Proceedings of the
13th World Wide Web Conference, pages 100–109.
C. Fellbaum. 1998. WordNet, an electronic lexical
database. MIT Press.
R. Girju and M. Moldovan. 2002. Text mining for causal
relations. In Proceedings of the FLAIRS Conference,
pages 360–364.
G. Grefenstette. 1999. The WWW as a resource for
example-based MT tasks. In Proceedings ofASLIB’99
Translating and the Computer 21.
M.A. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proceedings of the 14th In-
</bodyText>
<page confidence="0.993721">
35
</page>
<table confidence="0.993154502164503">
Book
Formal
product 34.6238 3
item 33.8573 3
publication 20.2621 3
document 14.4778 3
history 12.7262 1
project 8.9809 2
material 8.6704 3
reader 8.3890 0
resource 7.7259 3
source 7.6739 3
piece 7.6131 3
format 7.2203 0
tool 6.1124 1
object 3.7705 3
specifics 0.5374 1
library materials 0.1468 3
library property 0.0026 1
Agentive
make 1
write 3
create 1
Constitutive
it 21.5785 0
sign 21.0870 3
letter 18.7778 3
part 11.7830 1
individual 11.4043 0
page 10.9202 3
collection 10.7901 0
teaching 10.7004 2
language 9.6041 1
period 9.4002 0
paper 9.3551 3
table 8.7089 3
material 8.6704 3
word 8.1424 3
piece 7.6131 0
chapter 7.4746 3
presentation 7.0955 3
detail 6.8218 3
minute 5.3550 0
sheet 4.4369 3
lie 3.0866 1
ticket 2.3198 0
ink 2.2769 3
dot 1.7427 3
leather 1.1162 1
leaf 1.0266 3
title page 0.3639 3
peice 0.0530 0
dedication page 0.0076 3
Telic
give 14.8954 1
select 12.9594 0
read 12.4937 3
purchase 9.0372 3
support 8.0204 3
identify 7.9388 1
represent 5.7829 2
inspire 1.7292 3
convey 1.3940 3
present information 0.0728 3
provide additional information 0.0368 3
convey information 0.0260 3
filch 0.0101 3
share a story 0.0081 3
commit crime 0.0061 0
contain words 0.0055 3
introduce concepts 0.0038 2
traprock 0.0015 0
stock libraries 0.0009 3
hold a collection 0.0008 3
fund special projects 0.0007 2
support teachings 0.0001 3
Computer
Formal
technology 20.3667 3
information 20.2418 0
network 14.8052 3
hardware 14.6539 3
service 13.9161 3
office 12.2881 0
equipment 7.4594 2
machine 7.0099 3
item 6.7469 3
device 5.6259 3
medium 4.0503 3
fix 3.9188 0
piece 3.5898 3
notebook 2.1126 3
circuit 1.8663 0
consumer electronics 1.1544 0
appliance 1.0045 3
toy 0.7934 3
office equipment 0.4055 3
datum 0.3262 0
computer clipart 0.3156 1
mentality 0.1158 0
network device 0.0343 3
artefact 0.0339 3
data stores 0.0133 3
display screen equipment 0.0042 2
library equipment 0.0037 3
complex computer processes 0.0001 0
Agentive
build 3
Constitutive
software 25.5230 3
hardware 14.6539 3
part 14.6224 1
electronics 9.6139 3
individual 9.3791 0
memory 8.9683 3
man 5.9584 0
device 5.6259 3
unit 5.2078 3
component 4.3808 3
switch 4.2159 3
mix 3.8996 0
string 1.8896 3
circuit 1.8663 0
silicon 1.7717 3
actor 1.2127 0
processing unit 0.1444 3
individual components 0.1122 3
hardware components 0.1087 3
centra 0.0530 0
computer codes 0.0463 3
plastic case 0.0167 3
data storage device 0.0077 3
transitors 0.0022 3
Telic
make 16.9616 1
access 15.5691 3
control 12.2216 3
run 8.6411 3
assist 4.1410 3
publish 3.0015 3
solve 2.9701 3
facilitate 2.8860 3
insight 2.2718 3
combine 1.9592 1
calculate 1.2977 3
execute 1.2792 3
translate 1.2530 3
suppose 1.1340 3
provide information 0.8969 3
access data 0.1025 3
imitate 0.0998 1
provide feedback 0.0900 3
human freedom 0.0065 3
teach children 0.0266 3
enable people 0.0255 3
manage information 0.0231 3
process words 0.0009 3
support program goals 0.0003 3
reduce analysis time 0.0002 3
perform useful computations 0.0001 3
Conversation
Formal
concept 6.6834 3
expression 5.8487 3
context 5.2338 3
object 4.6343 0
sound 4.4566 0
function 4.1414 0
material 4.1324 0
place 3.7806 0
employee 3.4710 0
skill 3.3323 3
interaction 3.1092 3
communication 3.0006 3
activity 2.9859 3
people 2.9027 0
label 2.7427 3
time 2.6158 1
source 1.6782 0
text 1.5877 1
transmission 1.2251 3
information 1.2182 3
contact 1.1309 3
utterance 0.9499 1
transaction 0.9412 3
school activities 0.2094 3
datum 0.1462 3
mannerism 0.0635 0
communication difficulties 0.0412 1
ambient audio 0.0148 3
official forms 0.0140 3
priceless tidbits 0.0002 0
Agentive
make 3
create 0
Constitutive
relationship 6.1848 3
silence 5.7213 3
answer 5.6855 3
question 4.8714 3
sentence 4.8663 3
story 4.4669 3
laughter 3.1766 1
unit 2.9359 1
tree 2.7633 0
contribution 2.6421 3
world 2.1804 0
sequence 1.8986 3
requests 1.4969 3
repetition 1.4267 3
token 1.2746 1
bonus 1.2155 1
pauses 1.1568 3
utterance 0.9499 0
cliches 0.2556 3
interpersonal exchanges 0.0082 3
brief debates 0.0003 3
Telic
exchange 4.2769 3
establish 3.3530 3
further 3.2694 0
allow 3.2489 3
create 2.7141 0
generate 2.0107 0
get 1.9484 0
gloss 0.4780 0
exchange information 0.2313 3
exchange ideas 0.1896 3
enable people 0.1151 3
pass time 0.0469 0
teach skills 0.0171 3
</table>
<figureCaption confidence="0.989848">
Figure 4: Weighted Qualia Structures for book, computer and conversation
</figureCaption>
<page confidence="0.976252">
36
</page>
<table confidence="0.989400666666667">
Data Mining
Formal
data analysis 2.1492 3
intelligence 1.4242 0
analysis 1.2009 3
tool 1.1987 3
prediction 0.9682 3
approach 0.7279 3
speciality 0.6245 3
system 0.6018 3
application 0.5209 3
functionality 0.3974 3
process 0.3840 3
mechanism 0.3503 3
type 0.3372 0
practice 0.3310 3
technology 0.3240 3
activity 0.3207 3
employment 0.2565 0
use 0.2128 3
name 0.1944 3
</table>
<bodyText confidence="0.616773848484849">
area 0.1856 0
datum 0.1701 0
data warehousing technologies 0.1497 3
subject 0.1403 0
information process 0.0498 3
information process techniques 0.0005 3
Agentive
design 3
Constitutive
knowledge 0.7062 3
Telic
connect 0.5949 0
achieve 0.3651 3
uncover 0.3460 3
research 0.3374 3
answer 0.2122 3
support 0.2025 3
look 0.1834 0
provide information 0.1527 3
search 0.1451 3
tell 0.1099 1
identify patterns 0.0959 3
discover patterns 0.0934 3
identify trends 0.0765 3
provide a foundation 0.0620 1
improve services 0.0559 3
gain business intelligence 0.0048 3
explore knowledge 0.0045 3
detect dependencies 0.0036 3
gain business 0.0223 1
analyse large volumes 0.0022 1
find new prospects 0.0011 3
analyze disparate customer data 0.0002 3
</bodyText>
<figureCaption confidence="0.997708">
Figure 5: Weighted Qualia Structure for data mining
</figureCaption>
<table confidence="0.980324592592592">
Natural Language Processing
Formal
linguistics 1.0047 3
technique 0.4983 3
intelligence 0.3559 3
method 0.2748 3
model 0.1847 3
aspect 0.1380 3
scheme 0.1258 3
system 0.0750 1
research 0.0636 3
application 0.0603 3
science 0.0536 3
technology 0.0414 3
area 0.0373 0
product 0.0337 0
document processing applications 0.0174 3
Agentive
design 3
Constitutive
Telic
build 0.1037 3
keep track 0.0820 3
understand 0.0662 3
soften 0.0501 0
provide 0.0384 3
build tailored knowledge base 0.0008 3
</table>
<figureCaption confidence="0.848611">
Figure 6: Weighted Qualia Structure for natural language
</figureCaption>
<reference confidence="0.997101365384616">
processing
ternational Conference on Computational Linguistics,
pages 539–545.
L.M. Iwanska, N. Mata, and K. Kruger. 2000. Fully
automatic acquisition of taxonomic knowledge from
large corpora of texts. In L.M. Iwanksa and S.C.
Shapiro, editors, Natural Language Processing and
Knowledge Processing, pages 335–345. MIT/AAAI
Press.
M. Johnston and F. Busa. 1996. Qualia structure and the
compositional interpretation of compounds.
F. Keller, M. Lapata, and O. Ourioupina. 2002. Using
the web to overcome data sparseness. In Proceedings
of EMNLP-02, pages 230–237.
F. Kronlid. 2003. Modes of explanation - aristotelian
philosophy and pustejovskyan linguistics. Ms. Univer-
sity of Gteborg.
K. Markert, N. Modjeska, and M. Nissim. 2003. Us-
ing the web for nominal anaphora resolution. In
EACL Workshop on the Computational Treatment of
Anaphora.
M. Poesio, T. Ishikawa, S. Schulte im Walde, and
R. Viera. 2002. Acquiring lexical knowledge for
anaphora resolution. In Proceedings of the 3rd Con-
ference on Language Resources and Evaluation.
J. Pustejovsky, P. Anick, and S. Bergler. 1993. Lexi-
cal semantic techniques for corpus analysis. Compu-
tationalLingustics, Special Issue on Using Large Cor-
pora II, 19(2):331–358.
J. Pustejovsky. 1991. The generative lexicon. Computa-
tional Linguistics, 17(4):209–441.
P. Resnik and A. Elkiss. 2003. The linguist’s
search engine: Getting started guide. Tech-
nical Report LAMP-TR-108/CS-TR-4541/UMIACS-
TR-2003-109, University of Maryland, College Park,
November.
P. Resnik and N. Smith. 2003. The web as a parallel
corpus. Computational Lingusitics, 29(3):349–380.
D. Tufis and O. Mason. 1998. Tagging Romanian
Texts: a Case Study for QTAG, a Language Indepen-
dent Probabilistic Tagger. In Proceedings of the First
International Conference on Language Resources and
Evaluation (LREC), pages 589–96.
E.M. Voorhees. 1994. Query expansion using lexical-
semantic relations. In Proceedings of the 17th annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 61–69.
I. Yamada and T. Baldwin. 2004. Automatic discov-
ery of telic and agentive roles from corpus data. In
Proceedings of the The 18th Pacific Asia Conference
on Language, Information and Computation (PACLIC
18).
</reference>
<page confidence="0.999606">
37
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973286">
<title confidence="0.999113">Automatically Learning Qualia Structures from the Web</title>
<author confidence="0.996555">Philipp Cimiano</author>
<author confidence="0.996555">Johanna</author>
<affiliation confidence="0.989207">Institute AIFB University of Karlsruhe</affiliation>
<abstract confidence="0.999877523809524">Qualia Structures have many applications within computational linguistics, but currently there are no corresponding lexical resources such as WordNet or FrameNet. This paper presents an approach to automatically learn qualia structures for nominals from the World Wide Web and thus opens the possibility to explore the impact of qualia structures for natural language processing at a larger scale. Furthermore, our approach can be also used support a lexicographer in the task of manually creating a lexicon of qualia structures. The approach is based on the idea of matching certain lexicosyntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines. We evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of a human evaluation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>processing ternational Conference on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<marker></marker>
<rawString>processing ternational Conference on Computational Linguistics, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L M Iwanska</author>
<author>N Mata</author>
<author>K Kruger</author>
</authors>
<title>Fully automatic acquisition of taxonomic knowledge from large corpora of texts.</title>
<date>2000</date>
<booktitle>Natural Language Processing and Knowledge Processing,</booktitle>
<pages>335--345</pages>
<editor>In L.M. Iwanksa and S.C. Shapiro, editors,</editor>
<publisher>MIT/AAAI Press.</publisher>
<contexts>
<context position="2443" citStr="Iwanska et al., 2000" startWordPosition="368" endWordPosition="371"> 1998) or FrameNet&apos; 1http://framenet.icsi.berkeley.edu/ as source of lexical/world knowledge. The work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a relation of interest such as in (Markert et al., 2003) and (Cimiano and Staab, 2004). These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al., 2000) or (Poesio et al., 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al., 2002). The idea of learning Qualia Structures from the Web is not only a very practical, it is in fact a principled one. While single lexicographers creating qualia structures - or lexicon entries in general - might take very subjective decisions, the structures learned from the Web do not mirror the view of a single person, but of the whole world as represented on the World Wide Web. Thus, an approach learning qualia structures from the Web is in principle m</context>
<context position="27932" citStr="Iwanska et al., 2000" startWordPosition="4639" endWordPosition="4643">nware as elements of the Formal role for knife instead of the general term artifact tool. 5 Related Work There is quite a lot of work related to the use of linguistic patterns to discover certain ontological relations from text. Hearst’s (Hearst, 1992) seminal work had the aim of discovering taxonomic relations from electronic dictionaries. The precision of the is-a-relations learned is 61/106 (57.55%) when measured against WordNet as gold standard, which is comparable to our results. Hearst’s idea has been reapplied by different researchers with either slight variations in the patterns used (Iwanska et al., 2000), to acquire knowledge for anaphora resolution (Poesio et al., 2002), or to discover other kinds of semantic relations such as part-of relations (Charniak and Berland, 1999) or causation relations (Girju and Moldovan, 2002). Instead of matching these patterns in a large text collection, some researchers have recently turned to the Web to match these patterns such as in (Cimiano and Staab, 2004) or (Markert et al., 2003). (Cimiano and Staab, 2004) for example aim at learning instance-of as well as taxonomic (is-a) relations. This is very related to the acquisition of the Formal role proposed he</context>
</contexts>
<marker>Iwanska, Mata, Kruger, 2000</marker>
<rawString>L.M. Iwanska, N. Mata, and K. Kruger. 2000. Fully automatic acquisition of taxonomic knowledge from large corpora of texts. In L.M. Iwanksa and S.C. Shapiro, editors, Natural Language Processing and Knowledge Processing, pages 335–345. MIT/AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>F Busa</author>
</authors>
<title>Qualia structure and the compositional interpretation of compounds.</title>
<date>1996</date>
<contexts>
<context position="1254" citStr="Johnston and Busa, 1996" startWordPosition="184" endWordPosition="187">ating a lexicon of qualia structures. The approach is based on the idea of matching certain lexicosyntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines. We evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of a human evaluation. 1 Introduction Qualia Structures have been originally introduced by (Pustejovsky, 1991) and are used for a variety ofpurposes in Natural Language processing such as the analysis of compounds (Johnston and Busa, 1996), co-composition and coercion (Pustejovsky, 1991) as well as for bridging reference resolution (Bos et al., 1995). Further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (Voorhees, 1994; Pustejovsky et al., 1993). One major bottleneck however is that currently Qualia Structures need to be created by hand, which is probably also the reason why there are no practical system using qualia structures, but a lot of systems using globally available resources such as WordNet (Fellbaum, 1998) or FrameNet&apos; 1http://fram</context>
<context position="6024" citStr="Johnston and Busa, 1996" startWordPosition="960" endWordPosition="963">tejovsky, 1991) however seem to have a more restricted interpretation. In fact, in most examples the Constitutive role seems to describe the parts or components of an object, while the Agentive role is typically described by a verb denoting an action which typically brings the object in question into existence. The Formal role normally consists in typing information about the object, i.e. its hypernym or superconcept. Finally, the Telic role describes the purpose or function of an object either by a verb or nominal phrase. The qualia structure for knife for example could look as follows (cf. (Johnston and Busa, 1996)): Formal: artifact tool Constitutive: blade,handle,... Telic: cut act Agentive: make act Our understanding of Qualia Structure is in line with this restricted interpretation of the qualia roles. Our aim is to automatically acquire Qualia Structures from the Web for nominals, looking for (i) nominals describing the type of the object, (ii) verbs defining its agentive role, (iii) nominals describing its parts or components and (iv) nouns or verbs describing its intended purpose. 3 Approach Our approach to learning qualia structures from the Web is on the one hand based on the assumption that in</context>
<context position="21676" citStr="Johnston and Busa, 1996" startWordPosition="3575" endWordPosition="3578">ate which are appropriate, write being the ideal filler of the Agentive role according to (Pustejovsky, 1991). For the Constitutive role of book we get – besides it at the first position which could be easily filtered out – sign (2nd position), letter (3rd position) and page (6th position), which are quite appropriate. The top four candidates for the Telic role are give, select, read and purchase. It seems that give is emphasizing the role of a book as a gift, read is referring to the most obvious purpose of a book as specified in the ideal qualia structures of (Pustejovsky, 1991) as well as (Johnston and Busa, 1996) and purchase denotes the more general purpose of a book, i.e. to be bought. The first element of the Formal role of knife unfortunately denotes the material it is typically made of, i.e. steel, but the next 5 elements are definitely appropriate: weapon, item, kitchenware, object and instrument. The ideal element artifact tool (compare (Johnston and Busa, 1996)) can be found at the 10th position. The results are interesting in that on the one hand the most prominent meaning of knife according to the web is the one of a weapon. On the other hand our results are more specific, classifying a knif</context>
<context position="23221" citStr="Johnston and Busa, 1996" startWordPosition="3842" endWordPosition="3845">asure less sensitive to frequency could yield more accurate results. The fillers of the Agentive role produce, make and create seem all appropriate, whereby make corresponds exactly to the ideal filler for the Agentive role as mentioned in (Johnston and Busa, 1996). The results for the Constitutive role contain not only parts but also materials a knife is made of and thus contain more information than the typical qualia structures assumed in the literature. The best results are (in this order) blade, metal, steel, wood and handle at the 6th position. In fact, in the ideal qualia structure in (Johnston and Busa, 1996) blade and han32 0 Formal 2 3 1 Book 2/17 (11.76%) 4/17 (23.52%) 1/17 (5.88%) 10/17 (58.82%) Computer 8/28 (28.57%) 1/28 (3.57%) 2/28 (7.14%) 17/28 (60.71%) Knife 3/16 (18.75%) 0/16 (0%) 0/16 (0%) 13/16 (81.25%) Beer 12/22 (54.54%) 0/22 (0%) 2/22 (9.09%) 8/22 (36.36%) Data Mining 6/25 (24%) 0/25 (0%) 0/25 (0%) 19/25 (76%) Natural Language Processing 2/15 (13.33%) 1/15 (6.66%) 0/15 (0%) 12/15 (80%) Conversation 10/30 (33.33%) 4/30 (13.33%) 0/30 (0%) 16/30 (53.33%) All 43/153 (28.10%) 11/153 (7.19%) 6/153 (3.92%) 95/153 (62.09%) Agentive Book 0/3 (0%) 2/3 (66.66%) 0/3 (0%) 1/3 (33.33%) Computer </context>
<context position="25903" citStr="Johnston and Busa, 1996" startWordPosition="4295" endWordPosition="4298">anguage Processing 2.47 3 n.a. 2.5 Conversation 1.73 1.5 2.19 1.62 All 1.99 2.36 2.02 2.33 Table 5: Average credits for each role 33 0 0.5 1 1.5 2 2.5 3 Credit Figure 2: Average Jaccard Coefficient value per credit 11 10 9 8 7 6 5 4 3 2 1 Formal Constitutive Telic Jaccard Coefficient dle are mentioned as fillers of the Constitutive role, while there are no elements describing the materials of which a knife is made of. Finally, the top four candidates for the Telic role are kill, slit, cut and slice, whereby cut corresponds to the ideal filler of the qualia structure for knife as mentioned in (Johnston and Busa, 1996). Considering the qualia structure for beer, it is surprising that no purpose has been found. The reason is that currently no results are returned by Google for the clue a beer is used to and the four snippets returned for the purpose of a beer contain expressions of the form the purpose of a beer is to drink it which is not matched by our patterns as it is a pronoun and not matched by our NP pattern (unless it is matched by an error as in the Qualia Structure for book in Figure 4). Considering the results for the Formal role, the elements drink (1st), alcohol (2nd) and beverage (4th) are much</context>
</contexts>
<marker>Johnston, Busa, 1996</marker>
<rawString>M. Johnston and F. Busa. 1996. Qualia structure and the compositional interpretation of compounds.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>M Lapata</author>
<author>O Ourioupina</author>
</authors>
<title>Using the web to overcome data sparseness.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-02,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="2585" citStr="Keller et al., 2002" startWordPosition="395" endWordPosition="398">ssue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a relation of interest such as in (Markert et al., 2003) and (Cimiano and Staab, 2004). These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al., 2000) or (Poesio et al., 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al., 2002). The idea of learning Qualia Structures from the Web is not only a very practical, it is in fact a principled one. While single lexicographers creating qualia structures - or lexicon entries in general - might take very subjective decisions, the structures learned from the Web do not mirror the view of a single person, but of the whole world as represented on the World Wide Web. Thus, an approach learning qualia structures from the Web is in principle more reliable than letting lexicographers craft lexical entries on their own. Obviously, on the other hand, using an automatic web based approa</context>
</contexts>
<marker>Keller, Lapata, Ourioupina, 2002</marker>
<rawString>F. Keller, M. Lapata, and O. Ourioupina. 2002. Using the web to overcome data sparseness. In Proceedings of EMNLP-02, pages 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Kronlid</author>
</authors>
<title>Modes of explanation - aristotelian philosophy and pustejovskyan linguistics.</title>
<date>2003</date>
<institution>Ms. University of Gteborg.</institution>
<contexts>
<context position="4413" citStr="Kronlid, 2003" startWordPosition="695" endWordPosition="696">ctured as follows: Section 2 introduces qualia structures and describes the specific qualia structures we aim to acquire. Section 3 describes our approach in detail and section 4 presents a quantitative and qualitative evaluation of our approach. Before concluding, we discuss some related work in Section 5. 28 Proceedings o�the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 28–37, Ann Alm, June 2005. c�2005 Association for Computational Linguistics 2 Qualia Structures According to Aristotle, there are four basic factors or causes by which the nature of an object can be described (cf. (Kronlid, 2003)): the material cause, i.e. the material an object is made of the agentive cause, i.e. the source of movement, creation or change the formal cause, i.e. its form or type the final cause, i.e. its purpose, intention or aim In his Generative Lexicon (GL) framework (Pustejovsky, 1991) reused Aristotle’s basic factors for the description of the meaning of lexical elements. In fact he introduced so called Qualia Structures by which the meaning of a lexical element is described in terms of four roles: Constitutive: describing physical properties of an object, i.e. its weight, material as well as par</context>
</contexts>
<marker>Kronlid, 2003</marker>
<rawString>F. Kronlid. 2003. Modes of explanation - aristotelian philosophy and pustejovskyan linguistics. Ms. University of Gteborg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Markert</author>
<author>N Modjeska</author>
<author>M Nissim</author>
</authors>
<title>Using the web for nominal anaphora resolution.</title>
<date>2003</date>
<booktitle>In EACL Workshop on the Computational Treatment of Anaphora.</booktitle>
<contexts>
<context position="2204" citStr="Markert et al., 2003" startWordPosition="331" endWordPosition="334">is that currently Qualia Structures need to be created by hand, which is probably also the reason why there are no practical system using qualia structures, but a lot of systems using globally available resources such as WordNet (Fellbaum, 1998) or FrameNet&apos; 1http://framenet.icsi.berkeley.edu/ as source of lexical/world knowledge. The work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a relation of interest such as in (Markert et al., 2003) and (Cimiano and Staab, 2004). These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al., 2000) or (Poesio et al., 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al., 2002). The idea of learning Qualia Structures from the Web is not only a very practical, it is in fact a principled one. While single lexicographers creating qualia structures - or lexicon entries in general - might take ver</context>
<context position="28355" citStr="Markert et al., 2003" startWordPosition="4710" endWordPosition="4713">inst WordNet as gold standard, which is comparable to our results. Hearst’s idea has been reapplied by different researchers with either slight variations in the patterns used (Iwanska et al., 2000), to acquire knowledge for anaphora resolution (Poesio et al., 2002), or to discover other kinds of semantic relations such as part-of relations (Charniak and Berland, 1999) or causation relations (Girju and Moldovan, 2002). Instead of matching these patterns in a large text collection, some researchers have recently turned to the Web to match these patterns such as in (Cimiano and Staab, 2004) or (Markert et al., 2003). (Cimiano and Staab, 2004) for example aim at learning instance-of as well as taxonomic (is-a) relations. This is very related to the acquisition of the Formal role proposed here. (Markert et al., 2003) aim at acquiring knowledge for anaphora resolution, while (Etzioni et al., 2004) aim at learning the complete extension of a certain concept. For example, they aim at finding all the actors in the world. Our approach goes further in that it not only learns typing, superconcept or instance-of relations, but also Constitutive and Telic relations. There also exist approaches specifically aiming a</context>
</contexts>
<marker>Markert, Modjeska, Nissim, 2003</marker>
<rawString>K. Markert, N. Modjeska, and M. Nissim. 2003. Using the web for nominal anaphora resolution. In EACL Workshop on the Computational Treatment of Anaphora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>T Ishikawa</author>
<author>S Schulte im Walde</author>
<author>R Viera</author>
</authors>
<title>Acquiring lexical knowledge for anaphora resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="2468" citStr="Poesio et al., 2002" startWordPosition="373" endWordPosition="376">//framenet.icsi.berkeley.edu/ as source of lexical/world knowledge. The work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a relation of interest such as in (Markert et al., 2003) and (Cimiano and Staab, 2004). These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al., 2000) or (Poesio et al., 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al., 2002). The idea of learning Qualia Structures from the Web is not only a very practical, it is in fact a principled one. While single lexicographers creating qualia structures - or lexicon entries in general - might take very subjective decisions, the structures learned from the Web do not mirror the view of a single person, but of the whole world as represented on the World Wide Web. Thus, an approach learning qualia structures from the Web is in principle more reliable than letting</context>
<context position="28000" citStr="Poesio et al., 2002" startWordPosition="4651" endWordPosition="4654"> term artifact tool. 5 Related Work There is quite a lot of work related to the use of linguistic patterns to discover certain ontological relations from text. Hearst’s (Hearst, 1992) seminal work had the aim of discovering taxonomic relations from electronic dictionaries. The precision of the is-a-relations learned is 61/106 (57.55%) when measured against WordNet as gold standard, which is comparable to our results. Hearst’s idea has been reapplied by different researchers with either slight variations in the patterns used (Iwanska et al., 2000), to acquire knowledge for anaphora resolution (Poesio et al., 2002), or to discover other kinds of semantic relations such as part-of relations (Charniak and Berland, 1999) or causation relations (Girju and Moldovan, 2002). Instead of matching these patterns in a large text collection, some researchers have recently turned to the Web to match these patterns such as in (Cimiano and Staab, 2004) or (Markert et al., 2003). (Cimiano and Staab, 2004) for example aim at learning instance-of as well as taxonomic (is-a) relations. This is very related to the acquisition of the Formal role proposed here. (Markert et al., 2003) aim at acquiring knowledge for anaphora r</context>
</contexts>
<marker>Poesio, Ishikawa, Walde, Viera, 2002</marker>
<rawString>M. Poesio, T. Ishikawa, S. Schulte im Walde, and R. Viera. 2002. Acquiring lexical knowledge for anaphora resolution. In Proceedings of the 3rd Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Anick</author>
<author>S Bergler</author>
</authors>
<title>Lexical semantic techniques for corpus analysis.</title>
<date>1993</date>
<journal>ComputationalLingustics, Special Issue on Using Large Corpora II,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1552" citStr="Pustejovsky et al., 1993" startWordPosition="227" endWordPosition="230">ctures with the ones from the literature, but also quantitatively by presenting results of a human evaluation. 1 Introduction Qualia Structures have been originally introduced by (Pustejovsky, 1991) and are used for a variety ofpurposes in Natural Language processing such as the analysis of compounds (Johnston and Busa, 1996), co-composition and coercion (Pustejovsky, 1991) as well as for bridging reference resolution (Bos et al., 1995). Further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (Voorhees, 1994; Pustejovsky et al., 1993). One major bottleneck however is that currently Qualia Structures need to be created by hand, which is probably also the reason why there are no practical system using qualia structures, but a lot of systems using globally available resources such as WordNet (Fellbaum, 1998) or FrameNet&apos; 1http://framenet.icsi.berkeley.edu/ as source of lexical/world knowledge. The work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a re</context>
<context position="30263" citStr="Pustejovsky et al., 1993" startWordPosition="5019" endWordPosition="5022">-syntactic patterns as in the work presented here, but also a second approach consisting in training a maximum entropy model classifier. Their conclusion is that the results produced by the classification approach correlate better with two hand-crafted gold standards. 34 The patterns used by (Yamada and Baldwin, 2004) differ substantially from the ones used in this paper, which is mainly due to the fact that search engines do not provide support for regular expressions and thus instantiating a pattern as ’V[+ing] Noun’ is impossible in our approach as the verbs are unknown a priori. Finally, (Pustejovsky et al., 1993) present an interesting framework for the acquisition of semantic relations from corpora not only relying on statistics, but guided by theoretical lexicon principles. 6 Conclusion We have presented an approach to automatically learning Qualia Structures from the Web. Such an approach is especially interesting either for lexicographers aiming at constructing lexicons, but even more for natural language processing systems relying on deep lexical knowledge as represented by qualia structures. We have in particular shown that the qualia structures learned by our system are reasonable. In general, </context>
</contexts>
<marker>Pustejovsky, Anick, Bergler, 1993</marker>
<rawString>J. Pustejovsky, P. Anick, and S. Bergler. 1993. Lexical semantic techniques for corpus analysis. ComputationalLingustics, Special Issue on Using Large Corpora II, 19(2):331–358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The generative lexicon.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="1125" citStr="Pustejovsky, 1991" startWordPosition="165" endWordPosition="166">rocessing at a larger scale. Furthermore, our approach can be also used support a lexicographer in the task of manually creating a lexicon of qualia structures. The approach is based on the idea of matching certain lexicosyntactic patterns conveying a certain semantic relation on the World Wide Web using standard search engines. We evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of a human evaluation. 1 Introduction Qualia Structures have been originally introduced by (Pustejovsky, 1991) and are used for a variety ofpurposes in Natural Language processing such as the analysis of compounds (Johnston and Busa, 1996), co-composition and coercion (Pustejovsky, 1991) as well as for bridging reference resolution (Bos et al., 1995). Further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (Voorhees, 1994; Pustejovsky et al., 1993). One major bottleneck however is that currently Qualia Structures need to be created by hand, which is probably also the reason why there are no practical system using qual</context>
<context position="4695" citStr="Pustejovsky, 1991" startWordPosition="743" endWordPosition="745">ome related work in Section 5. 28 Proceedings o�the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 28–37, Ann Alm, June 2005. c�2005 Association for Computational Linguistics 2 Qualia Structures According to Aristotle, there are four basic factors or causes by which the nature of an object can be described (cf. (Kronlid, 2003)): the material cause, i.e. the material an object is made of the agentive cause, i.e. the source of movement, creation or change the formal cause, i.e. its form or type the final cause, i.e. its purpose, intention or aim In his Generative Lexicon (GL) framework (Pustejovsky, 1991) reused Aristotle’s basic factors for the description of the meaning of lexical elements. In fact he introduced so called Qualia Structures by which the meaning of a lexical element is described in terms of four roles: Constitutive: describing physical properties of an object, i.e. its weight, material as well as parts and components Agentive: describing factors involved in the bringing about of an object, i.e. its creator or the causal chain leading to its creation Formal: describing that properties which distinguish an object in a larger domain, i.e. orientation, magnitude, shape and dimensi</context>
<context position="10594" citStr="Pustejovsky, 1991" startWordPosition="1707" endWordPosition="1708"> coefficient. In what follows we describe in detail the procedure for acquiring qualia elements for each qualia role. In particular, we describe in detail the clues and lexico-syntactic patterns used. In general, the patterns have been crafted by hand, testing and refining them in an iterative process, paying attention to maximize their coverage but also accuracy. In general it is important to mention that by this approach we are not able to detect and separate multiple meanings of words, i.e. to handle polysemy, which is appropriately accounted for in the framework of the Generative Lexicon (Pustejovsky, 1991). 3.1 The Formal Role To derive qualia elements for the Formal role, we first download for each of the clues in Table 1 the first 10 abstracts matching the clue and then process them offline matching the patterns defined over part-of-speech-tags5 thus yielding up to 10 different qualia element candidates per clue. The patterns are specified in form of regular expressions, whereby the part-of-speech tags are always 5We use the well-known Penn Treebank tagset described at http://www.computing.dcu.ie/ acahill/tagset.html. Figure 1: General Approach given in square brackets after the token. Furthe</context>
<context position="17423" citStr="Pustejovsky, 1991" startWordPosition="2859" endWordPosition="2860">particularly artificial things, are often quite general phrases like ”make, produce, write, build...”. So instead of generating clues as above, we calculate the value for the nominal we want to acquire a qualia structure for as well as the following verbs: build, produce, make, write, plant, elect, create, cook, construct and design. If this value is over a threshold (0.0005 in our case), we assume that it is a valid filler of the Agentive qualia role. 4 Evaluation We evaluate our approach for the lexical elements knife, beer, book, which are also discussed in (Johnston and 31 Busa, 1996) or (Pustejovsky, 1991), as well as computer, an abstract noun, i.e. conversation, as well as two very specific multi-term words, i.e. natural language processing and data mining. We give the automatically learned weighted Qualia Structures for these entries in Figures 3, 4, 5 and 6. The evaluation of our approach consists on the one hand of a discussion of the weighted qualia structures, in particular comparing them to the ideal structures form the literature. On the other hand, we also asked a student at our institute to assign credits to each of the qualia elements from 0 (incorrect) to 3 (totally correct) whereb</context>
<context position="20987" citStr="Pustejovsky, 1991" startWordPosition="3452" endWordPosition="3453">lia structures by comparing them to ideal qualia structures discussed in the literature wherever possible. In particular, we discuss more in detail the qualia structure for book, knife and beer and leave the detailed assessment of the qualia structures for computer, natural language processing, data mining and conversation to the interested reader. For book, the first four candidates of the Formal role, i.e. product, item, publication and document are very appropriate, but alluding to the physical object meaning of book as opposed to the meaning in the sense of information container (compare (Pustejovsky, 1991). As candidates for the Agentive role we have make, write and create which are appropriate, write being the ideal filler of the Agentive role according to (Pustejovsky, 1991). For the Constitutive role of book we get – besides it at the first position which could be easily filtered out – sign (2nd position), letter (3rd position) and page (6th position), which are quite appropriate. The top four candidates for the Telic role are give, select, read and purchase. It seems that give is emphasizing the role of a book as a gift, read is referring to the most obvious purpose of a book as specified i</context>
<context position="26561" citStr="Pustejovsky, 1991" startWordPosition="4421" endWordPosition="4422">eer, it is surprising that no purpose has been found. The reason is that currently no results are returned by Google for the clue a beer is used to and the four snippets returned for the purpose of a beer contain expressions of the form the purpose of a beer is to drink it which is not matched by our patterns as it is a pronoun and not matched by our NP pattern (unless it is matched by an error as in the Qualia Structure for book in Figure 4). Considering the results for the Formal role, the elements drink (1st), alcohol (2nd) and beverage (4th) are much more specific than liquid as given in (Pustejovsky, 1991), while thing at the 3rd position is certainly too general. Furthermore, according to the automatically learned qualia structure, beer is made of rice, malt and hop, which are perfectly reasonable results. Very interesting are the results concoction and libation for the Formal role of beer, which unfortunately were rated low by our evaluator (compare Figure 3). Overall, the discussion has shown that the results produced by our method are reasonable when compared to the qualia structures from the literature. In general, our method produces in some cases additional qualia candidates, such as the</context>
</contexts>
<marker>Pustejovsky, 1991</marker>
<rawString>J. Pustejovsky. 1991. The generative lexicon. Computational Linguistics, 17(4):209–441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>A Elkiss</author>
</authors>
<title>The linguist’s search engine: Getting started guide.</title>
<date>2003</date>
<tech>Technical Report LAMP-TR-108/CS-TR-4541/UMIACSTR-2003-109,</tech>
<institution>University of Maryland, College Park,</institution>
<contexts>
<context position="8229" citStr="Resnik and Elkiss, 2003" startWordPosition="1303" endWordPosition="1306"> phases (compare Figure 1): 1. generate for each qualia role a set of so called clues, i.e. search engine queries indicating the relation of interest 2. download the snippets of the 10 first Google hits matching the generated clues 4 3. part-of-speech-tagging of the downloaded snippets 4. match regular expressions conveying the qualia role of interest 5. weight the returned qualia elements according to some measure The outcome of this process are then so called Weighted Qualia Structures (WQSs) in which every 2 stands for a noun phrase. 3An exception is certainly the Linguist’s Search Engine (Resnik and Elkiss, 2003) 4The reason for using only the 10 first hits is to maintain efficiency. With the current setting the systems needs between 3 and 10 minutes to generate the qualia structure for a given nominal 2 (2) such as , ,... (andor) , ,..., (andor) other (andor) (1) such as , , ...,(andor) (4) , (includingespecially) , , ..., 29 qualia element in a certain role is weighted according to some measure. The patterns in our pattern library are actually tuples where is a regular expression defined over part-of-speech tags and a function called the clue. Given a nominal and a clue , the query is sent to the Go</context>
</contexts>
<marker>Resnik, Elkiss, 2003</marker>
<rawString>P. Resnik and A. Elkiss. 2003. The linguist’s search engine: Getting started guide. Technical Report LAMP-TR-108/CS-TR-4541/UMIACSTR-2003-109, University of Maryland, College Park, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>N Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Lingusitics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="2540" citStr="Resnik and Smith, 2003" startWordPosition="389" endWordPosition="392">he work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to identify instances of a relation of interest such as in (Markert et al., 2003) and (Cimiano and Staab, 2004). These approaches are in essence a combination of the usage of lexico-syntactic pattens conveying a certain relation of interest such as in (Hearst, 1992), (Charniak and Berland, 1999), (Iwanska et al., 2000) or (Poesio et al., 2002) with the idea of using the web as a big corpus (Resnik and Smith, 2003), (Grefenstette, 1999), (Keller et al., 2002). The idea of learning Qualia Structures from the Web is not only a very practical, it is in fact a principled one. While single lexicographers creating qualia structures - or lexicon entries in general - might take very subjective decisions, the structures learned from the Web do not mirror the view of a single person, but of the whole world as represented on the World Wide Web. Thus, an approach learning qualia structures from the Web is in principle more reliable than letting lexicographers craft lexical entries on their own. Obviously, on the ot</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>P. Resnik and N. Smith. 2003. The web as a parallel corpus. Computational Lingusitics, 29(3):349–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis</author>
<author>O Mason</author>
</authors>
<title>Tagging Romanian Texts: a Case Study for QTAG, a Language Independent Probabilistic Tagger.</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>589--96</pages>
<contexts>
<context position="9562" citStr="Tufis and Mason, 1998" startWordPosition="1536" endWordPosition="1540">s to find instances of pattern . For example, given the clue and the instance computer we would download abstracts matching the query f(computer), i.e. ”such as computers”. Hereby is a function returning the plural form of x. We implemented this function as a lookup in a lexicon in which plural nouns are mapped to their base form. With the use of such clues, we thus download a number of Google-abstracts in which a corresponding pattern will probably be matched thus restricting the linguistic analysis to a few promising pages. The downloaded abstracts are then part-of-speech tagged using QTag (Tufis and Mason, 1998). Then we match the corresponding pattern in the downloaded snippets thus yielding candidate qualia elements as output. In our approach we then calculate the weight of a candidate qualia element for the term we want to compute the qualia structure for by the Jaccard Coefficient: The result is then a Weighted Qualia Structure (WQS) in which for each role the qualia elements are weighted according to this Jaccard coefficient. In what follows we describe in detail the procedure for acquiring qualia elements for each qualia role. In particular, we describe in detail the clues and lexico-syntactic </context>
</contexts>
<marker>Tufis, Mason, 1998</marker>
<rawString>D. Tufis and O. Mason. 1998. Tagging Romanian Texts: a Case Study for QTAG, a Language Independent Probabilistic Tagger. In Proceedings of the First International Conference on Language Resources and Evaluation (LREC), pages 589–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Query expansion using lexicalsemantic relations.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>61--69</pages>
<contexts>
<context position="1525" citStr="Voorhees, 1994" startWordPosition="225" endWordPosition="226">rned qualia structures with the ones from the literature, but also quantitatively by presenting results of a human evaluation. 1 Introduction Qualia Structures have been originally introduced by (Pustejovsky, 1991) and are used for a variety ofpurposes in Natural Language processing such as the analysis of compounds (Johnston and Busa, 1996), co-composition and coercion (Pustejovsky, 1991) as well as for bridging reference resolution (Bos et al., 1995). Further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (Voorhees, 1994; Pustejovsky et al., 1993). One major bottleneck however is that currently Qualia Structures need to be created by hand, which is probably also the reason why there are no practical system using qualia structures, but a lot of systems using globally available resources such as WordNet (Fellbaum, 1998) or FrameNet&apos; 1http://framenet.icsi.berkeley.edu/ as source of lexical/world knowledge. The work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the Web. The approach is inspired in recent work on using the Web to</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>E.M. Voorhees. 1994. Query expansion using lexicalsemantic relations. In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval, pages 61–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Yamada</author>
<author>T Baldwin</author>
</authors>
<title>Automatic discovery of telic and agentive roles from corpus data.</title>
<date>2004</date>
<booktitle>In Proceedings of the The 18th Pacific Asia Conference on Language, Information and Computation (PACLIC 18).</booktitle>
<contexts>
<context position="16193" citStr="Yamada and Baldwin, 2004" startWordPosition="2649" endWordPosition="2652"> it is not always as straightforward to find lexico-syntactic patterns reliably conveying a certain relation. In fact, we did not find any patterns reliably identifying qualia elements for the Agentive role. Certainly, it would have been possible to find the source of the creation by using patterns such as X is made by Y or X is produced by Y. However, we found that these patterns do not reliably convey a verb describing how an object is brought into existence. The fact that it is far from straightforward to find patterns indicating an Agentive role is further corroborated by the research in (Yamada and Baldwin, 2004), in which only one pattern indicating a qualia relation is used, namely ’NN BE V[+en]’ in order to match passive constructions such as the book was written. On the other hand it is clear that constructing a reliable clue for this pattern is not straightforward given the current state-of-the-art concerning search engine queries. Nevertheless, in order to also get results for the Agentive role, we apply a different method here. Instead of issuing a query which is used to search for possible candidates for the role, we take advantage of the fact that the verbs which describe how something comes </context>
<context position="29489" citStr="Yamada and Baldwin, 2004" startWordPosition="4897" endWordPosition="4901">ut also Constitutive and Telic relations. There also exist approaches specifically aiming at learning qualia elements from corpora based on machine learning techniques. (Claveau et al., 2003) for example use Inductive Logic Programming to learn if a given verb is a qualia element or not. However, their approach goes not as far as learning the complete qualia structure for a lexical element in an unsupervised way as presented in our approach. In fact, in their approach they do not distinguish between different qualia roles and restrict themselves to verbs as potential fillers of qualia roles. (Yamada and Baldwin, 2004) present an approach to learning Telic and Agentive relations from corpora analyzing two different approaches: one relying on matching certain lexico-syntactic patterns as in the work presented here, but also a second approach consisting in training a maximum entropy model classifier. Their conclusion is that the results produced by the classification approach correlate better with two hand-crafted gold standards. 34 The patterns used by (Yamada and Baldwin, 2004) differ substantially from the ones used in this paper, which is mainly due to the fact that search engines do not provide support f</context>
</contexts>
<marker>Yamada, Baldwin, 2004</marker>
<rawString>I. Yamada and T. Baldwin. 2004. Automatic discovery of telic and agentive roles from corpus data. In Proceedings of the The 18th Pacific Asia Conference on Language, Information and Computation (PACLIC 18).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>