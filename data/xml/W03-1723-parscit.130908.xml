<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000169">
<title confidence="0.993375">
A two-stage statistical word segmentation system for Chinese
</title>
<author confidence="0.994763">
Guohong Fu
</author>
<affiliation confidence="0.990314">
Dept of Linguistics
The University of Hong Kong
</affiliation>
<address confidence="0.528141">
Pokfulam Road, Hong Kong
</address>
<email confidence="0.995016">
ghfu@hkucc.hku.hk
</email>
<author confidence="0.904957">
K.K. Luke
</author>
<affiliation confidence="0.957725">
Dept of Linguistics
The University of Hong Kong
</affiliation>
<address confidence="0.515581">
Pokfulam Road, Hong Kong
</address>
<email confidence="0.997231">
kkluke@hkusua.hku.hk
</email>
<sectionHeader confidence="0.998596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99925375">
In this paper we present a two-stage
statistical word segmentation system for
Chinese based on word bigram and word-
formation models. This system was
evaluated on Peking University corpora at
the First International Chinese Word
Segmentation Bakeoff. We also give
results and discussions on this evaluation.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943629629629">
Word segmentation is very important for Chinese
language processing, which aims to recognize the
implicit word boundaries in Chinese text. During
the past decades, great success has been achieved in
Chinese word segmentation (Nie, et al, 1995; Yao,
1997; Fu and Wang, 1999; Wang et al, 2000;
Zhang, et al, 2002). However, there still remain two
difficult problems, i.e. ambiguity resolution and
unknown word (so-called OOV word) identification,
while developing a practical segmentation system
for large open applications.
In this paper, we present a two-stage statistical
word segmentation system for Chinese. In the first
stage, we employ word bigram model to segment
known words (viz. the words included in the system
dictionary) in input. In the second stage, we develop
a hybrid algorithm to perform unknown word
identification incorporating word contextual
information, word-formation patterns and word
juncture model.
The rest of this paper is organized as follows:
Section 2 presents a word bigram solution for
known word segmentation. Section 3 describes a
hybrid approach for unknown word identification.
In section 4, we report the results of our system at
the SIGHAN evaluation program, and in the final
section we give our conclusions on this work.
</bodyText>
<sectionHeader confidence="0.996387" genericHeader="method">
2 The first stage: Segmentation of known
words
</sectionHeader>
<bodyText confidence="0.9895108">
In a sense, known word segmentation is a process
of disambiguation. In our system, we use word
bigram language models and Viterbi algorithm
(1967) to resolve word boundary ambiguities in
known word segmentation.
For a particular input Chinese character string
C = c1c2 L cn , there is usually more than one
possible segmentation W = w1 w2 L wm according to
given system dictionary. Word bigram segmentation
aims to find the most appropriate segmentation
</bodyText>
<equation confidence="0.995924636363636">
W w 1 w 2 L wm
ˆ = that maximizes the probability
m
∏Pr(wi  |wi−
i=1
m
ˆ
W = argmax (  |) argmax
P W C ≈
r
W W
</equation>
<bodyText confidence="0.99603">
where Pr (wi  |wi−1) is the probability that word wl
will occur given previous word wi −1 , which can be
easily estimated from segmented corpus using
maximum likelihood estimation (MLE), i.e.
</bodyText>
<equation confidence="0.728794">
Pr (wi  |wi−1) ≈
</equation>
<bodyText confidence="0.9955085">
To avoid the problem of data sparseness in MLE,
here we apply the linear interpolation technique
(Jelinek and Mercer, 1980) to smooth the estimated
word bigram probabilities.
</bodyText>
<equation confidence="0.977167714285714">
1)
, i.e.
∏Pr(wi  |wi− 1) (1)
i=1
(2)
Count(wi−1 wi )
Count(wi−1)
</equation>
<sectionHeader confidence="0.9861085" genericHeader="method">
3 The second stage: Unknown word
identification
</sectionHeader>
<bodyText confidence="0.999909111111111">
The second stage mainly concerns unknown words
segmentation that remains unresolved in first stage.
This section describes a hybrid algorithm for
unknown word identification, which can incorporate
word juncture model, word-formation patterns and
contextual information. To avoid the complicated
normalization of the probabilities of different
dimensions, the simple superposition principle is
also used in merging these models.
</bodyText>
<subsectionHeader confidence="0.998566">
3.1 Word juncture model
</subsectionHeader>
<bodyText confidence="0.9998834">
Word juncture model score an unknown word by
assigning word juncture type. Obviously, most
unknown words appear as a string of known words
after segmentation in first stage. Therefore,
unknown word identification can be viewed as a
process of re-assigning correct word juncture type
to each known word pair in input. Given a known
word string W =w1w2 wn , between each word pair
wiwi+1(1 ≤i ≤n−1) is a word juncture. In general,
there are two types of junctures in unknown word
identification, namely word boundary (denoted by
tB ) and non-word boundary (denoted by tN ).
Let t(wi wi +1) denote the type of a word juncture
wi wi +1 , and Pr (t(wi wi+1)) denote the relevant
conditional probability, then
general, a known word w may take one of the
following four patterns while forming a word: (1)
w itself is a word. (2) w is the beginning of an
unknown word. (3) w is at the middle of an
unknown word. (4) w appears at the end of an
</bodyText>
<equation confidence="0.56997675">
Pr (pttn(w)) denote the relevant
probability, then
Obviously,
And 1- Pr (S(w)) is the
</equation>
<bodyText confidence="0.984369333333333">
word-formation power of the known word w .
(wU) be the overall word-formation
pattern probability of a cert
</bodyText>
<equation confidence="0.967741823529412">
∑ ( ( )) =1
Pr pttn w .
pttn
Ppttn
ain unknown word
=∏Pr pttn w i
( ( )) (6)
wi wU
∈
(3)
Thus, the word juncture probability
(wU) of a
particular unknown word wU =
wj
PCJM
wiwi+1
(1≤i≤j≤ n) can be calculated by
</equation>
<subsectionHeader confidence="0.997456">
3.2 Word-formation patterns
</subsectionHeader>
<bodyText confidence="0.999494">
Word-formation pattern model scores an unknown
word according to the probability of how each
intern
unknown word. For convenience, we use S , B ,
M and E to denote the four patterns respectively.
Let pttn(w) denote a particular pattern of w in an
unknown word and
Let
</bodyText>
<equation confidence="0.9986085">
wU = w1 w2 ... wl , then
Ppttn ( wU)
</equation>
<bodyText confidence="0.999794571428571">
Theoretically speaking, a known word can take any
pattern while forming an unknown word. But it is
not even in probability for different known words
and different patterns. For example, the word
(xing4, nature) is more likely to act as the suffix of
words. According to our investigation on the
training corpus, the character
</bodyText>
<equation confidence="0.687241">
性
性 appears at the end
</equation>
<bodyText confidence="0.972147">
of a multiword in more than 93% of cases.
</bodyText>
<subsectionHeader confidence="0.988837">
3.3 Hybrid algorithm for unknown
</subsectionHeader>
<bodyText confidence="0.956645266666667">
word
identification
Current algorithm for unknown word identification
consists of three major components: (1) an
unknown word extractor firstly extracts a fragment
of known words
that that may have
unknown words based on the related word-
formation power and word juncture probability and
its left and right contextual word
, wR from the
output of the first stage. (2) A candidate word
constructor then generates a lattice of all possible
new segmentations {WU
=
</bodyText>
<footnote confidence="0.713857">
xm } that may
involve unknown words from the extracted
fragment. (3) A decoder finally incorporates word
juncture model
</footnote>
<equation confidence="0.692613461538462">
word-formation
patterns
w1 w2wn
wL
|WU
x1x2
PWJM(WU),
Ppttn(WU) and word bigram probability
Pr (pttn(w))
= (5)
def
Count
(pttn(w))
Count(w)
def Count t w w
( ( ))
i i+1
P t w w
( ( ))
i i+ =
r 1 Count w w
( )
i i+1
j−1
PCJM(wU)=Pr(tB(wi−1wi))×Pr(tB(wjwj+1))×∏Pr(tN(clcl+1)) (4)
l
</equation>
<bodyText confidence="0.949076933333333">
In a sense, word juncture model mirrors the affinity
of known word pairs in forming an unknown word.
For a word juncture (wi, wi+1) , the larger the
probability Pr (tN (wi wi +1)) , the more likely the two
words are merged together into one new word.
i
=
al known word contributes to its formation. In
Pbigram (WU) to score these candidates, and then
applies the Viterbi algorithm again to find the best
new segmentation WU x 1x 2 L x m
ˆ = that has the
maximum score:
where x0 = wL and xn+1 = wR . Let wU denote any
unknown word in the training corpus. If xi is an
</bodyText>
<sectionHeader confidence="0.999842" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9998274">
Our system participated in both closed and open
tests on Peking University corpora at the First
International Chinese Word Segmentation Bakeoff.
This section reports the results and discussions on
its evaluation.
</bodyText>
<subsectionHeader confidence="0.971639">
4.1 Measures
</subsectionHeader>
<bodyText confidence="0.9999285">
In the evaluation program of the First International
Chinese Word Segmentation Bakeoff, six measures
are employed to score the performance of a word
segmentation system, namely test recall (R), test
precision (denoted by P), the balanced F-measure
(F), the out-of-vocabulary (OOV) rate for the test
corpus, the recall on OOV words (ROOV), and the
recall on in-vocabulary (Riv) words. OOV is defined
as the set of words in the test corpus not occurring
in the training corpus in the closed test, and the set
of words in the test corpus not occurring in the
lexicon used in the open test.
</bodyText>
<subsectionHeader confidence="0.997409">
4.2 Experimental lexicons and corpora
</subsectionHeader>
<bodyText confidence="0.916408454545455">
As shown in Table 1, we only used the training data
from Peking University corpus to train our system
in both the open and closed tests. As for the
dictionary, we compiled a dictionary for the closed
test from the training corpus, which contained 55,
226 words, and used a dictionary in the open test
that contained about 65, 269 words.
Items # words in # train. # test.
lexicon words words
Closed 55,226 1,121,017 17,194
Open 65,269 1,121,017 17,194
</bodyText>
<tableCaption confidence="0.999303">
Table 1: Experimental lexicons and corpora
</tableCaption>
<table confidence="0.88176175">
4.3 Experimental results and discussion
Items F R P OOV ROOV Riv
Closed 0.939 0.936 0.942 0.069 0.675 95.5
Open 0.937 0.933 0.941 0.094 0.762 95.0
</table>
<tableCaption confidence="0.986736">
Table 2: Test results on PK corpus
</tableCaption>
<bodyText confidence="0.986761404761905">
(Pp
Segmentation speed: There are in all about 28,458
characters in the test corpus. It takes about 3.21
and 3.07 seconds in all for our system to perform
full segmentation (including known word
segmentation and unknown word identification) on
the closed and open test corpus respectively,
running on an ACER notebook (TM632XC-P4M).
This indicates that our system is able to process
about 531,925~556,182 characters per minute.
Results and discussions: The results for the closed
and open test are presented in Table 2. We can
draw some conclusions from these results.
Firstly, the overall performance of our system is
very stable in both the closed and open tests. As
shown in Table 2, the out-of-vocabulary (OOV)
rate is 6.9% in the closed test and 9.4% in the open
test. However, the overall test F-measure drops by
only 0.2 percent in the open test, compared with the
closed test.
Secondly, our approach can handle most unknown
words in the input. As can be seen from Table 2,
the recall on OOV words are 67.5% the closed-test
and 76.2% in the open-test. Wang et al (2000) and
Yao (1997) have proposed a character juncture
model and word-formation patterns for Chinese
unknown word identification. However, their
approaches can only work for the unknown words
that are made up of pure monosyllable character in
that they are character-based methods. To address
this problem, we introduce both word juncture
model and word-based word-formation patterns into
our system. As a result, our system can deal with
different unknown words that consist of different
known words, including monosyllable characters
and multiword.
Although our system is effective for most
ambiguities and unknown words in the input, it has
its inherent deficiencies. Firstly, to avoid data
sparseness, we do not differentiate known words
and unknown words while estimating word juncture
models and word-formation patterns from the
</bodyText>
<figure confidence="0.96732437037037">
{Ppttn(WU)+ (WU)+Pbigram(WU )}
P�
(7)
ˆ
=
arg max
WU
WU
1
−
{
arg max
))}
(xi|xi
(x
ttn
i
∑
n
WU
unknown word, then
Coun t x w
( )
− 1
i U
w .
U
</figure>
<equation confidence="0.924825285714286">
P x x =
r i i
(  |)
− 1Count x
( )
i− 1
∑
</equation>
<bodyText confidence="0.99992584">
training corpus. This simplification may introduce
some noises into these models for identifying
unknown words. Our further investigations show
that the precision on OOV words is still very low,
i.e. 67.1% for closed test and 72.5% for open test.
As a result, our system may yield a number of
mistaken unknown words in the processing.
Secondly, we regard known word segmentation and
unknown word identification as two independent
stages in our system. This strategy is obviously
simple and more easily applicable. However, it does
not work while the input contains a mixture of
ambiguities and unknown words. For example,
there was a sentence 中行长葛支行注重健身 in
the test corpus, where, the string 中行长葛 is a
fragment mixed with ambiguity and unknown
words. The correct segmentation should be 中行/长
葛/, where 中行(Zhonghang, the Bank of China) is
a abbreviation of organization name, and 长 葛
(Changge) is a place name. Actually, this fragment
is segmented as 中/行长/葛/ in the first stage of our
system. However, the unknown word identification
stage does not have a mechanism to split the word
行长(Hangzhang, president) and finally resulted in
wrong segmentation.
</bodyText>
<sectionHeader confidence="0.999652" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999989888888889">
This paper presents a two-stage statistical word
segmentation system for Chinese. In the first stage,
word bigram model and Viterbi algorithm are
applied to perform known word segmentation on
input plain text, and then a hybrid approach is
employed in the second stage to incorporate word
bigram probabilities, word juncture model and
word-based word-formation patterns to detect OOV
words. The experiments on Peking University
corpora have shown that the present system based
on fairly simple word bigram and word-formation
models can achieve a F-score of 93.7% or above. In
future work, we hope to improve our strategies on
estimating word juncture model and word-formation
patterns and develop an integrated segmentation
technique that can perform known word
segmentation and unknown word identification at
one time.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999967">
We would like to thank all colleagues of the First
International Chinese Word Segmentation Bakeoff
for their evaluations of the results and the Institute
of Computational Linguistics, Peking University for
providing the experimental corpora.
</bodyText>
<sectionHeader confidence="0.999418" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998881451612903">
Fu, Guohong and Xiaolong Wang. 1999. Unsupervised
Chinese word segmentation and unknown word
identification. In: Proceedings of NLPRS’99,
Beijing, China, 32-37.
Jelinek, Frederick, and Robert L. Mercer. 1980.
Interpolated estimation of Markov source parameters
from sparse data. In: Proceedings of Workshop on
Pattern Recognition in Practice, Amsterdam, 381-
397.
Nie, Jian-Yuan, M.-L. Hannan and W.-Y. Jin. 1995.
Unknown word detection and segmentation of
Chinese using statistical and heuristic knowledge.
Communication of COLIPS, 5(1&amp;2): 47-57.
Viterbi, A.J. 1967. Error bounds for convolutional
codes and an asymmetrically optimum decoding
algorithm. IEEE Transactions on Information
Theory, IT-13(2): 260-269.
Wang, Xiaolong, Fu Guohong, Danial S.Yeung, James
N.K.Liu, and Robert Luk. 2000. Models and
algorithms of Chinese word segmentation. In:
Proceedings of the International Conference on
Artificial Intelligence (IC-AI’2000), Las Vegas,
Nevada, USA, 1279-1284.
Yao, Yuan. 1997. Statistics Based approaches towards
Chinese language processing. Ph.D. thesis. National
University of Singapore.
Zhang, Hua-Ping, Qun Liu, Hao Zhang, and Xue-Qi
Cheng. 2002. Automatic recognition of Chinese
unknown words based on roles tagging. In:
Proceedings of The First SIGHAN Workshop on
Chinese Language Processing, Taiwan, 71-77.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.184153">
<title confidence="0.999202">A two-stage statistical word segmentation system for Chinese</title>
<author confidence="0.632421">Guohong</author>
<affiliation confidence="0.821221">Dept of The University of Hong</affiliation>
<address confidence="0.709648">Pokfulam Road, Hong</address>
<email confidence="0.972593">ghfu@hkucc.hku.hk</email>
<affiliation confidence="0.7858">K.K. Dept of The University of Hong</affiliation>
<address confidence="0.823543">Pokfulam Road, Hong</address>
<email confidence="0.989055">kkluke@hkusua.hku.hk</email>
<abstract confidence="0.998888777777778">In this paper we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Guohong Fu</author>
<author>Xiaolong Wang</author>
</authors>
<title>Unsupervised Chinese word segmentation and unknown word identification. In:</title>
<date>1999</date>
<booktitle>Proceedings of NLPRS’99,</booktitle>
<pages>32--37</pages>
<location>Beijing, China,</location>
<contexts>
<context position="870" citStr="Fu and Wang, 1999" startWordPosition="126" endWordPosition="129">hkusua.hku.hk Abstract In this paper we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation. 1 Introduction Word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text. During the past decades, great success has been achieved in Chinese word segmentation (Nie, et al, 1995; Yao, 1997; Fu and Wang, 1999; Wang et al, 2000; Zhang, et al, 2002). However, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called OOV word) identification, while developing a practical segmentation system for large open applications. In this paper, we present a two-stage statistical word segmentation system for Chinese. In the first stage, we employ word bigram model to segment known words (viz. the words included in the system dictionary) in input. In the second stage, we develop a hybrid algorithm to perform unknown word identification incorporating word contextual informati</context>
</contexts>
<marker>Fu, Wang, 1999</marker>
<rawString>Fu, Guohong and Xiaolong Wang. 1999. Unsupervised Chinese word segmentation and unknown word identification. In: Proceedings of NLPRS’99, Beijing, China, 32-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
<author>Robert L Mercer</author>
</authors>
<title>Interpolated estimation of Markov source parameters from sparse data. In:</title>
<date>1980</date>
<booktitle>Proceedings of Workshop on Pattern Recognition in Practice,</booktitle>
<pages>381--397</pages>
<location>Amsterdam,</location>
<contexts>
<context position="2800" citStr="Jelinek and Mercer, 1980" startWordPosition="449" endWordPosition="452"> L cn , there is usually more than one possible segmentation W = w1 w2 L wm according to given system dictionary. Word bigram segmentation aims to find the most appropriate segmentation W w 1 w 2 L wm ˆ = that maximizes the probability m ∏Pr(wi |wi− i=1 m ˆ W = argmax ( |) argmax P W C ≈ r W W where Pr (wi |wi−1) is the probability that word wl will occur given previous word wi −1 , which can be easily estimated from segmented corpus using maximum likelihood estimation (MLE), i.e. Pr (wi |wi−1) ≈ To avoid the problem of data sparseness in MLE, here we apply the linear interpolation technique (Jelinek and Mercer, 1980) to smooth the estimated word bigram probabilities. 1) , i.e. ∏Pr(wi |wi− 1) (1) i=1 (2) Count(wi−1 wi ) Count(wi−1) 3 The second stage: Unknown word identification The second stage mainly concerns unknown words segmentation that remains unresolved in first stage. This section describes a hybrid algorithm for unknown word identification, which can incorporate word juncture model, word-formation patterns and contextual information. To avoid the complicated normalization of the probabilities of different dimensions, the simple superposition principle is also used in merging these models. 3.1 Wor</context>
</contexts>
<marker>Jelinek, Mercer, 1980</marker>
<rawString>Jelinek, Frederick, and Robert L. Mercer. 1980. Interpolated estimation of Markov source parameters from sparse data. In: Proceedings of Workshop on Pattern Recognition in Practice, Amsterdam, 381-397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yuan Nie</author>
<author>M-L Hannan</author>
<author>W-Y Jin</author>
</authors>
<title>Unknown word detection and segmentation of Chinese using statistical and heuristic knowledge.</title>
<date>1995</date>
<journal>Communication of COLIPS,</journal>
<volume>5</volume>
<issue>1</issue>
<pages>47--57</pages>
<contexts>
<context position="840" citStr="Nie, et al, 1995" startWordPosition="120" endWordPosition="123">fulam Road, Hong Kong kkluke@hkusua.hku.hk Abstract In this paper we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation. 1 Introduction Word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text. During the past decades, great success has been achieved in Chinese word segmentation (Nie, et al, 1995; Yao, 1997; Fu and Wang, 1999; Wang et al, 2000; Zhang, et al, 2002). However, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called OOV word) identification, while developing a practical segmentation system for large open applications. In this paper, we present a two-stage statistical word segmentation system for Chinese. In the first stage, we employ word bigram model to segment known words (viz. the words included in the system dictionary) in input. In the second stage, we develop a hybrid algorithm to perform unknown word identification incorpora</context>
</contexts>
<marker>Nie, Hannan, Jin, 1995</marker>
<rawString>Nie, Jian-Yuan, M.-L. Hannan and W.-Y. Jin. 1995. Unknown word detection and segmentation of Chinese using statistical and heuristic knowledge. Communication of COLIPS, 5(1&amp;2): 47-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Viterbi</author>
</authors>
<title>Error bounds for convolutional codes and an asymmetrically optimum decoding algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>260--269</pages>
<marker>Viterbi, 1967</marker>
<rawString>Viterbi, A.J. 1967. Error bounds for convolutional codes and an asymmetrically optimum decoding algorithm. IEEE Transactions on Information Theory, IT-13(2): 260-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaolong Wang</author>
<author>Fu Guohong</author>
<author>Danial S Yeung</author>
<author>James N K Liu</author>
<author>Robert Luk</author>
</authors>
<title>Models and algorithms of Chinese word segmentation. In:</title>
<date>2000</date>
<booktitle>Proceedings of the International Conference on Artificial Intelligence (IC-AI’2000),</booktitle>
<pages>1279--1284</pages>
<location>Las Vegas, Nevada, USA,</location>
<contexts>
<context position="888" citStr="Wang et al, 2000" startWordPosition="130" endWordPosition="133">act In this paper we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation. 1 Introduction Word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text. During the past decades, great success has been achieved in Chinese word segmentation (Nie, et al, 1995; Yao, 1997; Fu and Wang, 1999; Wang et al, 2000; Zhang, et al, 2002). However, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called OOV word) identification, while developing a practical segmentation system for large open applications. In this paper, we present a two-stage statistical word segmentation system for Chinese. In the first stage, we employ word bigram model to segment known words (viz. the words included in the system dictionary) in input. In the second stage, we develop a hybrid algorithm to perform unknown word identification incorporating word contextual information, word-formation</context>
<context position="9558" citStr="Wang et al (2000)" startWordPosition="1628" endWordPosition="1631">sults for the closed and open test are presented in Table 2. We can draw some conclusions from these results. Firstly, the overall performance of our system is very stable in both the closed and open tests. As shown in Table 2, the out-of-vocabulary (OOV) rate is 6.9% in the closed test and 9.4% in the open test. However, the overall test F-measure drops by only 0.2 percent in the open test, compared with the closed test. Secondly, our approach can handle most unknown words in the input. As can be seen from Table 2, the recall on OOV words are 67.5% the closed-test and 76.2% in the open-test. Wang et al (2000) and Yao (1997) have proposed a character juncture model and word-formation patterns for Chinese unknown word identification. However, their approaches can only work for the unknown words that are made up of pure monosyllable character in that they are character-based methods. To address this problem, we introduce both word juncture model and word-based word-formation patterns into our system. As a result, our system can deal with different unknown words that consist of different known words, including monosyllable characters and multiword. Although our system is effective for most ambiguities</context>
</contexts>
<marker>Wang, Guohong, Yeung, Liu, Luk, 2000</marker>
<rawString>Wang, Xiaolong, Fu Guohong, Danial S.Yeung, James N.K.Liu, and Robert Luk. 2000. Models and algorithms of Chinese word segmentation. In: Proceedings of the International Conference on Artificial Intelligence (IC-AI’2000), Las Vegas, Nevada, USA, 1279-1284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Yao</author>
</authors>
<title>Statistics Based approaches towards Chinese language processing.</title>
<date>1997</date>
<tech>Ph.D. thesis.</tech>
<institution>National University of Singapore.</institution>
<contexts>
<context position="851" citStr="Yao, 1997" startWordPosition="124" endWordPosition="125">ong kkluke@hkusua.hku.hk Abstract In this paper we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation. 1 Introduction Word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text. During the past decades, great success has been achieved in Chinese word segmentation (Nie, et al, 1995; Yao, 1997; Fu and Wang, 1999; Wang et al, 2000; Zhang, et al, 2002). However, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called OOV word) identification, while developing a practical segmentation system for large open applications. In this paper, we present a two-stage statistical word segmentation system for Chinese. In the first stage, we employ word bigram model to segment known words (viz. the words included in the system dictionary) in input. In the second stage, we develop a hybrid algorithm to perform unknown word identification incorporating word c</context>
<context position="9573" citStr="Yao (1997)" startWordPosition="1633" endWordPosition="1634">nd open test are presented in Table 2. We can draw some conclusions from these results. Firstly, the overall performance of our system is very stable in both the closed and open tests. As shown in Table 2, the out-of-vocabulary (OOV) rate is 6.9% in the closed test and 9.4% in the open test. However, the overall test F-measure drops by only 0.2 percent in the open test, compared with the closed test. Secondly, our approach can handle most unknown words in the input. As can be seen from Table 2, the recall on OOV words are 67.5% the closed-test and 76.2% in the open-test. Wang et al (2000) and Yao (1997) have proposed a character juncture model and word-formation patterns for Chinese unknown word identification. However, their approaches can only work for the unknown words that are made up of pure monosyllable character in that they are character-based methods. To address this problem, we introduce both word juncture model and word-based word-formation patterns into our system. As a result, our system can deal with different unknown words that consist of different known words, including monosyllable characters and multiword. Although our system is effective for most ambiguities and unknown wo</context>
</contexts>
<marker>Yao, 1997</marker>
<rawString>Yao, Yuan. 1997. Statistics Based approaches towards Chinese language processing. Ph.D. thesis. National University of Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Ping Zhang</author>
<author>Qun Liu</author>
<author>Hao Zhang</author>
<author>Xue-Qi Cheng</author>
</authors>
<title>Automatic recognition of Chinese unknown words based on roles tagging. In:</title>
<date>2002</date>
<booktitle>Proceedings of The First SIGHAN Workshop on Chinese Language Processing, Taiwan,</booktitle>
<pages>71--77</pages>
<contexts>
<context position="909" citStr="Zhang, et al, 2002" startWordPosition="134" endWordPosition="137">we present a two-stage statistical word segmentation system for Chinese based on word bigram and wordformation models. This system was evaluated on Peking University corpora at the First International Chinese Word Segmentation Bakeoff. We also give results and discussions on this evaluation. 1 Introduction Word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text. During the past decades, great success has been achieved in Chinese word segmentation (Nie, et al, 1995; Yao, 1997; Fu and Wang, 1999; Wang et al, 2000; Zhang, et al, 2002). However, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called OOV word) identification, while developing a practical segmentation system for large open applications. In this paper, we present a two-stage statistical word segmentation system for Chinese. In the first stage, we employ word bigram model to segment known words (viz. the words included in the system dictionary) in input. In the second stage, we develop a hybrid algorithm to perform unknown word identification incorporating word contextual information, word-formation patterns and word ju</context>
</contexts>
<marker>Zhang, Liu, Zhang, Cheng, 2002</marker>
<rawString>Zhang, Hua-Ping, Qun Liu, Hao Zhang, and Xue-Qi Cheng. 2002. Automatic recognition of Chinese unknown words based on roles tagging. In: Proceedings of The First SIGHAN Workshop on Chinese Language Processing, Taiwan, 71-77.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>