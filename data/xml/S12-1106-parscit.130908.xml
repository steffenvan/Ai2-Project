<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026704">
<title confidence="0.97782">
BUAP: Lexical and Semantic Similarity for Cross-lingual Textual
Entailment
</title>
<author confidence="0.99014">
Darnes Vilari˜no, David Pinto, Mireya Tovar, Saul Le´on, Esteban Castillo
</author>
<affiliation confidence="0.9893135">
Benem´erita Universidad Aut´onoma de Puebla,
Faculty of Computer Science
</affiliation>
<address confidence="0.9831405">
14 Sur &amp; Av. San Claudio, CU
Puebla, Puebla, M´exico
</address>
<email confidence="0.978338">
{darnes, dpinto, mtovar}@cs.buap.mx
saul.ls@live.com,ecjbuap@gmail.com
</email>
<sectionHeader confidence="0.995799" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995050666666667">
In this paper we present a report of the two di-
fferent runs submitted to the task 8 of Semeval
2012 for the evaluation of Cross-lingual Tex-
tual Entailment in the framework of Content
Synchronization. Both approaches are based
on textual similarity, and the entailment judg-
ment (bidirectional, forward, backward or no
entailment) is given based on a set of decision
rules. The first approach uses textual simi-
larity on the translated and original versions
of the texts, whereas the second approach ex-
pands the terms by means of synonyms. The
evaluation of both approaches show a similar
behavior which is still close to the average and
median.
</bodyText>
<sectionHeader confidence="0.998974" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995527476190476">
Cross-lingual Textual Entailment (CLTE) has been
recently proposed by (Mehdad et al., 2010; Mehdad
et al., 2011) as an extension of the Textual Entail-
ment task (Dagan and Glickman, 2004). Given a text
(T) and an hypothesis (H) in different languages,
the CLTE task consists of determining if the mea-
ning of H can be inferred from the meaning of T.
In this paper we present a report of the obtained
results after submitting two different runs for the
Task 8 of Semeval 2012, named “Cross-lingual Tex-
tual Entailment for Content Synchronization” (Negri
et al., 2012). In this task, the Cross-Lingual Tex-
tual Entailment addresses textual entailment recog-
nition under a new dimension (cross-linguality), and
within a new challenging application scenario (con-
tent synchronization). The task 8 of Semeval 2012
may be formally defined as follows:
Given a pair of topically related text fragments
(T1 and T2) in different languages, the task consists
of automatically annotating it with one of the follo-
wing entailment judgments:
</bodyText>
<listItem confidence="0.998098222222222">
• Bidirectional (T1 —* T2 &amp; T1 +— T2): the two
fragments entail each other (semantic equiva-
lence)
• Forward (T1 —* T2 &amp; T1 ! +— T2): unidirec-
tional entailment from T1 to T2
• Backward (T1 ! —* T2 &amp; T1 +— T2): unidirec-
tional entailment from T2 to T1
• No Entailment (T1 ! —* T2 &amp; T1 ! +— T2): there
is no entailment between T1 and T2
</listItem>
<bodyText confidence="0.93830375">
In this task, both T1 and T2 are assumed to be
TRUE statements; hence in the dataset there are no
contradictory pairs. Cross-lingual datasets are avai-
lable for the following language combinations:
</bodyText>
<listItem confidence="0.99986975">
• Spanish/English (SPA-ENG)
• German/English (DEU-ENG)
• Italian/English (ITA-ENG)
• French/English (FRA-ENG)
</listItem>
<bodyText confidence="0.9919482">
The remaining of this paper is structured as fo-
llows: Section 2 describes the two different approa-
ches presented in the competition. The obtained re-
sults are shown and dicussed in Section 3. Finally,
the findings of this work are given in Section 4.
</bodyText>
<page confidence="0.984304">
706
</page>
<note confidence="0.714145">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 706–709,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.988502" genericHeader="introduction">
2 Experimental setup
</sectionHeader>
<bodyText confidence="0.99997825">
For this experiment we have considered to tackle the
CLTE task by means of textual similarity and textual
length. In particular, the textual similarity is used to
determine whether some kind of entailment exists or
not. We have established the threshold of 0.5 for the
similarity function as evidence of textual entailment.
Since the two sentences to be evaluated are written
in two different languages, we have translated each
sentence to the other language, so that, we have two
sentences in English, and two sentences in the origi-
nal language (Spanish, German, Italian and French).
We have used the Google translate for this purpose
</bodyText>
<equation confidence="0.43659">
1.
</equation>
<bodyText confidence="0.999923633333333">
The corpora used in the experiments comes from
a cross-lingual Textual Entailment dataset presented
in (Negri et al., 2011), and provided by the task orga-
nizers. We have employed the training dataset only
for adjust some parameters of the system, but the
approach is knowledge-based and, therefore, it does
not need a training corpus. Both, the training and
test corpus contain 500 sentences for each language.
The textual length is used to determine the entail-
ment judgment (bidirectional, forward, backward,
no entailment). We have basically, assumed that the
length of a text may give some evidence of the type
of entailment. The decision rules used for determi-
ning the entailment judgment are described in Sec-
tion 2.3.
In this competition we have submitted two diffe-
rent runs which differ with respect to the type of tex-
tual similarity used (lexical vs semantic). The first
one, calculates the similarity using only the trans-
lated version of the original sentences, whereas the
second approach uses text expansion by means of
synonyms and, thereafter, it calculates the similarity
between the pair of sentences.
Let T1 be the sentence in the original language,
T2 the T1 topically related text fragment (written in
English). Let T3 be the English translation of T1,
and T4 the translation of T2 to the original language
(Spanish, German, Italian and French). The formal
description of these two approaches are given as fo-
llows.
</bodyText>
<footnote confidence="0.981254">
1http://translate.google.com.mx/
</footnote>
<subsectionHeader confidence="0.971934">
2.1 Approach 1: Lexical similarity
</subsectionHeader>
<bodyText confidence="0.999680384615384">
The evidence of textual entailment between T1 and
T2 is calculated using two formulae of lexical si-
milarity. Firstly, we determine the similarity bet-
ween the two texts written in the source language
(5im5). Additionally, we calculate the lexical simi-
larity between the two sentences written in the target
language (5imT), in this case English.
Given the limited text length of the text fragments,
we have used the Jaccard coefficient as similarity
measure. Eq. (1) shows the lexical similarity for the
two texts written in the original language, whereas,
Eq. (2) presents the Jaccard coefficient for the texts
written in English.
</bodyText>
<equation confidence="0.996243166666667">
4|
T
�
sim5 = simJaccard(T1,T4) = |T1 |T1 U ∩ T4 |(1)
simT = simJaccard(T2, T3) = |T2 ∪ T3 |(2)
|T2 ∩ T3|
</equation>
<subsectionHeader confidence="0.978993">
2.2 Approach 2: Semantic similarity
</subsectionHeader>
<bodyText confidence="0.999485913043478">
In this case we calculate the semantic similarity bet-
ween the two texts written in the original language
(sim5), and the semantic similarity between the two
text fragments written in English (simT). The se-
mantic level of similarity is given by considering
the synonyms of each term for each sentence (in
the original and target language). For this purpose,
we have employed five dictionaries containing syno-
nyms for the five different languages considered in
the competition (English, Spanish, German, Italian,
and French)2. In Table 1 we show the number of
terms, so as the number of synonyms in average by
term considered for each language.
Let T1 = w1,1w1,2...w1,|T1|, T2 =
w2,1w2,2...w2,|T2 |be the source and target
sentences, and let T3 = w3,1w3,2...w3,|Ts|,
T4 = w4,1w4,2...w4,|T4 |be translated version of the
original source and target sentences, respectively.
The synonyms of a given word wi,k, expressed as
synset(wi,k), are obtained from the aforementioned
dictionaries by extracting the synonyms of wi,k. In
order to obtain a better matching between the terms
contained in the text fragments and the terms in the
</bodyText>
<footnote confidence="0.945108">
2http://extensions.services.openoffice.org/en/dictionaries
</footnote>
<page confidence="0.997157">
707
</page>
<tableCaption confidence="0.842924">
Table 1: Dictionaries of synonyms used for term expan-
sion
</tableCaption>
<table confidence="0.992906714285714">
Language Terms synonyms per term
(average)
English 2,764 60
Spanish 9,887 45
German 21,958 115
Italian 25,724 56
French 36,207 93
</table>
<bodyText confidence="0.998162142857143">
dictionary, we have stemmed all the terms using the
Porter stemmer.
In order to determine the semantic similarity bet-
ween two terms of sentences written in the source
language (w1,i and w4,j) we use Eq. (3). The se-
mantic similariy between two terms of the English
sentences are calculated as shown in Eq. (4).
</bodyText>
<subsectionHeader confidence="0.997329">
2.3 Decision rules
</subsectionHeader>
<bodyText confidence="0.99205575">
Both approches used the same decision rules in or-
der to determine the entailment judgment for a given
pair of text fragments (T1 and T2). The following al-
gorithm shows the decision rules used.
</bodyText>
<figure confidence="0.960784">
Algorithm 1.
If |T2 |&lt; |T3 |then
If (simT &gt; 0.5 and sim5 &gt; 0.5)
then forward
ElseIf |T2 |&gt; |T3 |then
If (simT &gt; 0.5 and sim5 &gt; 0.5)
then backward
ElseIf (|T1 |== |T4 |and |T2 |== |T3|) then
If (simT &gt; 0.5 and sim5 &gt; 0.5)
then bidirectional
Else no entailment
</figure>
<bodyText confidence="0.937623">
As mentioned above, the rules employed the le-
xical or semantic textual similarity, and the textual
length for determining the textual entailment.
</bodyText>
<table confidence="0.792790444444444">
sim(w1,i, w4,j) =  1 if (w1,i == w4,j)  ||3 Results
 w1,i E synset(w4,j)  ||In Table 2 we show the overall results obtained by
 w4,j E synset(w1,i) the two approaches submitted to the competition.
0 otherwise We also show the highest, lowest, average and me-
(3) dian overall results obtained in the competition.
sim(w2,i, w3,j) =



</table>
<equation confidence="0.9647918">
1 if (w2,i == w3,j) ||
w2,i E synset(w3,j) ||
w3,j E synset(w2,i)
0 otherwise
(4)
</equation>
<bodyText confidence="0.999683888888889">
Both equations consider the existence of semantic
similarity when the two words are identical, or when
the some of the two words appear in the synonym set
of the other word.
The semantic similarity of the complete text frag-
ments T1 and T4 (sim5) is calculated as shown in
Eq. (5). Whereas, the semantic similarity of the
complete text fragments T2 and T3 (simT) is cal-
culated as shown in Eq. (6).
</bodyText>
<equation confidence="0.9936795">
T T
sim5 T T4) E _41 sim(w1,i,w4,j) ( )
( i, 4) = i=1 j=1∪T4 |5
T T
simT (T2, T �i Pj 31 sim(w2,i,w3,j) (6)
3) _ |T2∪T3|
</equation>
<table confidence="0.999432625">
SPA- ITA- FRA- DEU-
ENG ENG ENG ENG
Highest 0.632 0.566 0.57 0.558
Average 0.407 0.362 0.366 0.357
Median 0.346 0.336 0.336 0.336
Lowest 0.266 0.278 0.278 0.262
BUAP run1 0.35 0.336 0.334 0.33
BUAP run2 0.366 0.344 0.342 0.268
</table>
<tableCaption confidence="0.9911715">
Table 2: Overall statistics obtained in the Task 8 of Se-
meval 2012
</tableCaption>
<bodyText confidence="0.9999359">
The runs submitted perform similar, but the se-
mantic approach obtained a slightly better perfor-
mance. The two results are above the median but
below the average. We consider that better results
may be obtained if the two features used (textual si-
milarity and textual length) were introduced into a
supervised classifier, so that, the decision rules were
approximated on the basis of a training dataset, ins-
tead of the empirical setting done in this work. Fu-
ture experiments will be carried out in this direction.
</bodyText>
<page confidence="0.996805">
708
</page>
<sectionHeader confidence="0.993823" genericHeader="discussions">
4 Discussion and conclusion
</sectionHeader>
<bodyText confidence="0.999987176470588">
Two different approaches for the Cross-lingual Tex-
tual Entailment for Content Synchronization task of
Semeval 2012 are reported in this paper. We used
two features for determining the textual entailment
judgment between two texts T1 and T2 (written in
two different languages). The first approach pro-
posed used lexical similarity, meanwhile the second
used semantic similarity by means of term expan-
sion with synonyms.
Even if the performance of both approaches is
above the median and slighly below the average,
we consider that we may easily improve this perfor-
mance by using syntactic features of the text frag-
ments. Additionally, we are planning to integrate
some supervised techniques based on decision rules
which may be trained in a supervised dataset. Future
experiments will be executed in this direction.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995952">
This project has been partially supported by projects
CONACYT #106625, #VIAD-ING11-II and VIEP
#PIAD-ING11-II.
</bodyText>
<sectionHeader confidence="0.998792" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99985435483871">
Ido Dagan and Oren Glickman. 2004. Probabilistic Tex-
tual Entailment: Generic Applied Modeling of Lan-
guage Variability. In Learning Methods for Text Un-
derstanding and Mining, January.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010. Towards Cross-Lingual Textual Entailment. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 321–
324, Los Angeles, California, June. Association for
Computational Linguistics.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-
lingual textual entailment. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Volume
1, HLT ’11, pages 1336–1345, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo
Giampiccolo, and Alessandro Marchetti. 2011. Di-
vide and conquer: crowdsourcing the creation of cross-
lingual textual entailment corpora. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, EMNLP ’11, pages 670–679,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and
D. Giampiccolo. 2012. Semeval-2012 Task 8: Cross-
lingual Textual Entailment for Content Synchroniza-
tion. In Proceedings of the 6th International Workshop
on Semantic Evaluation (SemEval 2012).
</reference>
<page confidence="0.998665">
709
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.339104">
<title confidence="0.9943955">BUAP: Lexical and Semantic Similarity for Cross-lingual Textual Entailment</title>
<author confidence="0.999057">David Pinto</author>
<author confidence="0.999057">Mireya Tovar</author>
<author confidence="0.999057">Saul Le´on</author>
<author confidence="0.999057">Esteban</author>
<affiliation confidence="0.738154">Benem´erita Universidad Aut´onoma de Faculty of Computer 14 Sur &amp; Av. San Claudio,</affiliation>
<address confidence="0.990267">Puebla, Puebla,</address>
<email confidence="0.99591">dpinto,</email>
<abstract confidence="0.996030625">In this paper we present a report of the two different runs submitted to the task 8 of Semeval 2012 for the evaluation of Cross-lingual Textual Entailment in the framework of Content Synchronization. Both approaches are based on textual similarity, and the entailment judgment (bidirectional, forward, backward or no entailment) is given based on a set of decision rules. The first approach uses textual similarity on the translated and original versions of the texts, whereas the second approach expands the terms by means of synonyms. The evaluation of both approaches show a similar behavior which is still close to the average and median.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability.</title>
<date>2004</date>
<booktitle>In Learning Methods for Text Understanding and Mining,</booktitle>
<contexts>
<context position="1199" citStr="Dagan and Glickman, 2004" startWordPosition="179" endWordPosition="182"> based on textual similarity, and the entailment judgment (bidirectional, forward, backward or no entailment) is given based on a set of decision rules. The first approach uses textual similarity on the translated and original versions of the texts, whereas the second approach expands the terms by means of synonyms. The evaluation of both approaches show a similar behavior which is still close to the average and median. 1 Introduction Cross-lingual Textual Entailment (CLTE) has been recently proposed by (Mehdad et al., 2010; Mehdad et al., 2011) as an extension of the Textual Entailment task (Dagan and Glickman, 2004). Given a text (T) and an hypothesis (H) in different languages, the CLTE task consists of determining if the meaning of H can be inferred from the meaning of T. In this paper we present a report of the obtained results after submitting two different runs for the Task 8 of Semeval 2012, named “Cross-lingual Textual Entailment for Content Synchronization” (Negri et al., 2012). In this task, the Cross-Lingual Textual Entailment addresses textual entailment recognition under a new dimension (cross-linguality), and within a new challenging application scenario (content synchronization). The task 8</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. In Learning Methods for Text Understanding and Mining, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>321--324</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="1103" citStr="Mehdad et al., 2010" startWordPosition="162" endWordPosition="165">ingual Textual Entailment in the framework of Content Synchronization. Both approaches are based on textual similarity, and the entailment judgment (bidirectional, forward, backward or no entailment) is given based on a set of decision rules. The first approach uses textual similarity on the translated and original versions of the texts, whereas the second approach expands the terms by means of synonyms. The evaluation of both approaches show a similar behavior which is still close to the average and median. 1 Introduction Cross-lingual Textual Entailment (CLTE) has been recently proposed by (Mehdad et al., 2010; Mehdad et al., 2011) as an extension of the Textual Entailment task (Dagan and Glickman, 2004). Given a text (T) and an hypothesis (H) in different languages, the CLTE task consists of determining if the meaning of H can be inferred from the meaning of T. In this paper we present a report of the obtained results after submitting two different runs for the Task 8 of Semeval 2012, named “Cross-lingual Textual Entailment for Content Synchronization” (Negri et al., 2012). In this task, the Cross-Lingual Textual Entailment addresses textual entailment recognition under a new dimension (cross-ling</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2010. Towards Cross-Lingual Textual Entailment. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 321– 324, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using bilingual parallel corpora for crosslingual textual entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1336--1345</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1125" citStr="Mehdad et al., 2011" startWordPosition="166" endWordPosition="169">ment in the framework of Content Synchronization. Both approaches are based on textual similarity, and the entailment judgment (bidirectional, forward, backward or no entailment) is given based on a set of decision rules. The first approach uses textual similarity on the translated and original versions of the texts, whereas the second approach expands the terms by means of synonyms. The evaluation of both approaches show a similar behavior which is still close to the average and median. 1 Introduction Cross-lingual Textual Entailment (CLTE) has been recently proposed by (Mehdad et al., 2010; Mehdad et al., 2011) as an extension of the Textual Entailment task (Dagan and Glickman, 2004). Given a text (T) and an hypothesis (H) in different languages, the CLTE task consists of determining if the meaning of H can be inferred from the meaning of T. In this paper we present a report of the obtained results after submitting two different runs for the Task 8 of Semeval 2012, named “Cross-lingual Textual Entailment for Content Synchronization” (Negri et al., 2012). In this task, the Cross-Lingual Textual Entailment addresses textual entailment recognition under a new dimension (cross-linguality), and within a </context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using bilingual parallel corpora for crosslingual textual entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1336–1345, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Luisa Bentivogli</author>
<author>Yashar Mehdad</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Marchetti</author>
</authors>
<title>Divide and conquer: crowdsourcing the creation of crosslingual textual entailment corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>670--679</pages>
<contexts>
<context position="3880" citStr="Negri et al., 2011" startWordPosition="623" endWordPosition="626">milarity is used to determine whether some kind of entailment exists or not. We have established the threshold of 0.5 for the similarity function as evidence of textual entailment. Since the two sentences to be evaluated are written in two different languages, we have translated each sentence to the other language, so that, we have two sentences in English, and two sentences in the original language (Spanish, German, Italian and French). We have used the Google translate for this purpose 1. The corpora used in the experiments comes from a cross-lingual Textual Entailment dataset presented in (Negri et al., 2011), and provided by the task organizers. We have employed the training dataset only for adjust some parameters of the system, but the approach is knowledge-based and, therefore, it does not need a training corpus. Both, the training and test corpus contain 500 sentences for each language. The textual length is used to determine the entailment judgment (bidirectional, forward, backward, no entailment). We have basically, assumed that the length of a text may give some evidence of the type of entailment. The decision rules used for determining the entailment judgment are described in Section 2.3. </context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo Giampiccolo, and Alessandro Marchetti. 2011. Divide and conquer: crowdsourcing the creation of crosslingual textual entailment corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 670–679,</rawString>
</citation>
<citation valid="false">
<authors>
<author>PA Stroudsburg</author>
</authors>
<institution>USA. Association for Computational Linguistics.</institution>
<marker>Stroudsburg, </marker>
<rawString>Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="1576" citStr="Negri et al., 2012" startWordPosition="245" endWordPosition="248">s still close to the average and median. 1 Introduction Cross-lingual Textual Entailment (CLTE) has been recently proposed by (Mehdad et al., 2010; Mehdad et al., 2011) as an extension of the Textual Entailment task (Dagan and Glickman, 2004). Given a text (T) and an hypothesis (H) in different languages, the CLTE task consists of determining if the meaning of H can be inferred from the meaning of T. In this paper we present a report of the obtained results after submitting two different runs for the Task 8 of Semeval 2012, named “Cross-lingual Textual Entailment for Content Synchronization” (Negri et al., 2012). In this task, the Cross-Lingual Textual Entailment addresses textual entailment recognition under a new dimension (cross-linguality), and within a new challenging application scenario (content synchronization). The task 8 of Semeval 2012 may be formally defined as follows: Given a pair of topically related text fragments (T1 and T2) in different languages, the task consists of automatically annotating it with one of the following entailment judgments: • Bidirectional (T1 —* T2 &amp; T1 +— T2): the two fragments entail each other (semantic equivalence) • Forward (T1 —* T2 &amp; T1 ! +— T2): unidirect</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. 2012. Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>