<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000763">
<title confidence="0.972545">
DKPro Keyphrases: Flexible and Reusable Keyphrase Extraction
Experiments
</title>
<author confidence="0.984629">
Nicolai Erbs†, Pedro Bispo Santos†, Iryna Gurevych†$ and Torsten Zesch5$
</author>
<bodyText confidence="0.535881">
† UKP Lab, Technische Universit¨at Darmstadt
‡ Information Center for Education, DIPF, Frankfurt
§ Language Technology Lab, University of Duisburg-Essen
http://www.ukp.tu-darmstadt.de
</bodyText>
<sectionHeader confidence="0.969698" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999648875">
DKPro Keyphrases is a keyphrase extrac-
tion framework based on UIMA. It offers
a wide range of state-of-the-art keyphrase
experiments approaches. At the same
time, it is a workbench for developing new
extraction approaches and evaluating their
impact. DKPro Keyphrases is publicly
available under an open-source license.1
</bodyText>
<sectionHeader confidence="0.998764" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999230923076923">
Keyphrases are single words or phrases that pro-
vide a summary of a text (Tucker and Whittaker,
2009) and thus might improve searching (Song et
al., 2006) in a large collection of texts. As man-
ual extraction of keyphrases is a tedious task, a
wide variety of keyphrase extraction approaches
has been proposed. Only few of them are freely
available which makes it hard for researchers to
replicate previous results or use keyphrase extrac-
tion in some other application, such as informa-
tion retrieval (Manning et al., 2008), or question
answering (Kwok et al., 2001).
In this paper, we describe our keyphrase extrac-
tion framework called DKPro Keyphrases. It inte-
grates a wide range of state-of-the-art approaches
for keyphrase extraction that can be directly used
with limited knowledge of programming. How-
ever, for developers of new keyphrase extrac-
tion approaches, DKPro Keyphrases also offers a
programming framework for developing new ex-
traction algorithms and for evaluation of result-
ing effects. DKPro Keyphrases is based on the
Unstructured Information Management Architec-
ture (Ferrucci and Lally, 2004), which provides a
rich source of libraries with preprocessing compo-
nents.
</bodyText>
<footnote confidence="0.761778">
1http://code.google.com/p/dkpro-keyphrases/
</footnote>
<figure confidence="0.991315571428572">
Text
Preprocessing
Select keyphrases
Filter keyphrases
Rank keyphrases
Evaluate
Results
</figure>
<figureCaption confidence="0.8091605">
Figure 1: Architecture overview of DKPro
Keyphrases
</figureCaption>
<sectionHeader confidence="0.98368" genericHeader="introduction">
2 Architecture
</sectionHeader>
<bodyText confidence="0.99911325">
The architecture of DKPro Keyphrases models the
five fundamental steps of keyphrase extraction:
(i) Reading of input data and enriching it with
standard linguistic preprocessing, (ii) selecting
phrases as keyphrase candidates based on the pre-
processed text, (iii) filtering selected keyphrases,
(iv) ranking remaining keyphrases, and (v) evalu-
ating ranked keyphrases against a gold standard.
This process is visualized in Figure 1. In this
section, we will describe details of each step, in-
cluding components already included in DKPro
Keyphrases.
</bodyText>
<subsectionHeader confidence="0.962636">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.99953725">
DKPro Keyphrases relies on UIMA-based pre-
processing components developed in the natu-
ral language processing framework DKPro Core
(Gurevych et al., 2007; Eckart de Castilho and
Gurevych, 2009). Thus, a wide range of linguis-
tic preprocessing components are readily available
such as word segmentation, lemmatization, part-
of-speech tagging, named entity recognition, syn-
</bodyText>
<page confidence="0.998526">
31
</page>
<bodyText confidence="0.609489">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 31–36,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
tactic parsing, or co-reference resolution.
</bodyText>
<subsectionHeader confidence="0.999513">
2.2 Selecting Keyphrases
</subsectionHeader>
<bodyText confidence="0.999389310344828">
In this step, DKPro Keyphrases selects all phrases
as keyphrases that match user-specified criteria. A
criterium is typically a linguistic type, e.g. tokens,
or more sophisticated types such as noun phrases.
The resulting list of keyphrases should cover all
gold keyphrases and at the same time be as selec-
tive as possible. We use the following sentence
with the two gold keyphrases “dog” and “old cat”
as a step through example:
A [dog] chases an [old cat] in my gar-
den.
Taking all uni- and bi-grams as keyphrases will
easily match both gold keyphrases, but it will also
result in many other less useful keyphrases like “in
my”.
In the given example, the keyphrase list consists
of nine tokens (lemmas, resp.) but covers only one
gold keyphrase (i.e. “dog”). Noun chunks and
named entities are alternative keyphrases, limiting
the set of keyphrases further. Experiments where
noun chunks are selected as keyphrases perform
best for this example. Named entities are too re-
strictive, but applicable for identifying relevant en-
tities in a text. This is useful for tasks that are
targeted towards entities, e.g. for finding experts
(D¨orner et al., 2007) in a collection of domain-
dependent texts. The selection of a linguistic type
is not limited as preprocessing components might
introduce further types.
</bodyText>
<subsectionHeader confidence="0.998449">
2.3 Filtering
</subsectionHeader>
<bodyText confidence="0.999800125">
Filtering can be used together with over-
generating selection approaches like taking all n-
grams to decrease the number of keyphrases be-
fore ranking. One possible approach is based
on POS patterns. For example, using the POS
patterns, Adjective-Noun, Adjective, and
Noun limits the set of possible keyphrases to
“dog”, “old cat”, “cat”, and “garden” in the pre-
vious example. This step can also been per-
formed as part of the selection step, however,
keeping it separated enables researchers to ap-
ply filters to keyphrases of any linguistic type.
DKPro Keyphrases provides the possibility to use
controlled-vocabulary keyphrase extraction by fil-
tering out all keyphrases which are not included in
a keyphrase list.
Developers of keyphrase extraction approaches
can create their own filter simply by extending
from a base class and adding filter-specific code.
Additionally, DKPro Keyphrases does not impose
workflow-specific requirements, such as a fixed
number of filters. This leaves room for keyphrase
extraction experiments testing new or extended fil-
ters.
</bodyText>
<subsectionHeader confidence="0.996725">
2.4 Ranking
</subsectionHeader>
<bodyText confidence="0.999879538461539">
In this step, a ranker assigns a score to each re-
maining keyphrase candidate. DKPro Keyphrases
contains rankers based on the candidate position,
frequency, tf-idf, TextRank (Mihalcea and Tarau,
2004), and LexRank (Erkan and Radev, 2004).
DKPro Keyphrases also contains a special ex-
tension of tf-idf, called tf-idfweb, for which Google
web1t (Brants and Franz, 2006) is used for obtain-
ing approximate df counts. In case of keyphrase
extraction for a single document or for domain-
independent keyphrase extraction, web1t provides
reliable n-gram statistics without any domain-
dependence.
</bodyText>
<subsectionHeader confidence="0.959241">
2.5 Evaluation
</subsectionHeader>
<bodyText confidence="0.99999224">
DKPro Keyphrases ships with all the metrics
that have been traditionally used for evaluating
keyphrase extraction. Kim et al. (2010) use
precision and recall for a different number of
keyphrases (5, 10 and 15 keyphrases). These met-
rics are widely used for evaluation in information
retrieval. Precision @5 is the ratio of true pos-
itives in the set of extracted keyphrases when 5
keyphrases are extracted. Recall @5 is the ratio of
true positives in the set of gold keyphrases when
5 keyphrases are extracted. Moreover, DKPro
Keyphrases evaluates with MAP and R-precision.
MAP is the mean average precision of extracted
keyphrases from the highest scored keyphrase to
the total number of extracted keyphrases. For each
position in the rank, the precision at that position
will be computed. Summing up the precision at
each recall point and then taking its average will
return the average precision for the text being eval-
uated. The mean average precision will be the
mean from the sum of each text’s average preci-
sion from the dataset. R-precision is the ratio of
true positives in the set of extracted keyphrases,
when the set is limited to the same size as the set
of gold keyphrases (Zesch and Gurevych, 2009).
</bodyText>
<page confidence="0.998566">
32
</page>
<sectionHeader confidence="0.998984" genericHeader="method">
3 Experimental framework
</sectionHeader>
<bodyText confidence="0.999893041666667">
In this section, we show how researchers can per-
form experiments covering many different config-
urations for preprocessing, selection, and ranking.
To facilitate the construction of experiments, the
framework contains a module to make its archi-
tecture compatible to the DKPro Lab framework
(Eckart de Castilho and Gurevych, 2011), thus al-
lowing to sweep through the parameter space of
configurations. The parameter space is the combi-
nation of all possible parameters, e.g. one parame-
ter with two possible values for preprocessing and
a second parameter with two values for rankers
lead to four possible combinations. We refer to pa-
rameter sweeping experiments when running the
experiment with all possible combinations.
DKPro Keyphrases divides the experimental
setup in three tasks. Tasks are processing steps
defined in the Lab framework, which – in case of
keyphrase extraction – are based on the steps de-
scribed in Section 2. In the first task, the input
text is fed into a pipeline and preprocessed. In the
second task, the keyphrases are selected and fil-
tered. In the third and final task they are ranked
and evaluated. The output of the first two tasks are
serialized objects which can be processed further
by the following task. The output of the third task
is a report containing all configurations and results
in terms of all evaluation metrics.
The division into three tasks speeds up process-
ing of the entire experiment. Each task has mul-
tiple configuration parameters which influence the
forthcoming tasks. Instead of running the prepro-
cessing tasks for every single possible combina-
tion, the intermediate objects are stored once and
then used for every possible configuration in the
keyphrase selection step.
To illustrate the advantages of experimental set-
tings in DKPro Keyphrases, we run the previously
used example sentence through the entire parame-
ter space. Hence, tokens, lemmas, n-grams, noun
chunks, and named entities will be combined with
all filters and all rankers (not yet considering all
possible parameters). This results in more than
10,000 configurations. Although the number of
configurations is high, the computation time is
low2 as not the entire pipeline needs to run that
often. This scales well for longer texts.
The experimental framework runs all possible
</bodyText>
<footnote confidence="0.5184455">
2Less than five minutes on a desktop computer with a 3.4
GHz 8-core processor.
</footnote>
<bodyText confidence="0.99922884">
combinations automatically and collects individ-
ual results in a report, such as a spreadsheet or
text file. This allows for comparing results of dif-
ferent rankers, mitigating the influence of differ-
ent preprocessing and filtering components. This
way, the optimal experimental configuration can
be found empirically. It is a great improvement
for researchers because a variety of system con-
figurations can be compared without the effort of
reimplementing the entire pipeline.
Code example 1 shows the main method of an
example experiment, selecting all tokens as pos-
sible keyphrases and ranking them with their tf-
idf values. Lines 1 to 34 show values for dimen-
sions which span the parameter space. A dimen-
sion consists of an identifier, followed by one or
more values. Lines 36 to 40 show the creation of
tasks, and in lines 42 to 48 the tasks and a re-
port are added to one batch task, which is then
executed. Researchers can run multiple configu-
rations by setting multiple values to a dimension.
Line 25 shows an example of a dimension with
two values (using the logarithm or unchanged text
frequency), in this case two configurations3 for the
ranker based on tf-idf scores.
</bodyText>
<figure confidence="0.96158540625">
Code example 1: Example experiment
1 ParameterSpace params = new
ParameterSpace(
2 Dimension.create(&amp;quot;language&amp;quot;, &amp;quot;en&amp;quot;),
3 Dimension.create(&amp;quot;frequencies&amp;quot;,
&amp;quot;web1t&amp;quot;),
4 Dimension.create(&amp;quot;tfidfFeaturePath&amp;quot;,
Token.class&amp;quot;),
5
6 Dimension.create(&amp;quot;dataset&amp;quot;,
datasetPath),
7 Dimension.create(&amp;quot;goldSuffix&amp;quot;, &amp;quot;.key&amp;quot;),
8
9 //Selection
10 Dimension.create(&amp;quot;segmenter&amp;quot;,
OpenNlpSegmenter.class),
11 Dimension.create(&amp;quot;keyphraseFeaturePath&amp;quot;,
Token.class),
12
13 //PosSequence filter
14 Dimension.create(&amp;quot;runPosSequenceFilter&amp;quot;,
true),
15 Dimension.create(&amp;quot;posSequence&amp;quot;,
standard),
16
17 //Stopword filter
18 Dimension.create(&amp;quot;runStopwordFilter&amp;quot;,
true),
19 Dimension.create(&amp;quot;stopwordlists&amp;quot;,
&amp;quot;stopwords.txt&amp;quot;),
20
21 // Ranking
</figure>
<footnote confidence="0.9723345">
3DKPro Keyphrases provides ways to configure experi-
ments using Groovy and JSON.
</footnote>
<page confidence="0.994404">
33
</page>
<figure confidence="0.669942159090909">
22 Dimension.create(&amp;quot;rankerClass&amp;quot;,
TfidfRanking.class),
23
24 //TfIdf
25 Dimension.create(&amp;quot;weightingModeTf&amp;quot;,
NORMAL, LOG),
26 Dimension.create(&amp;quot;weightingModeIdf&amp;quot;,
LOG),
27 Dimension.create(&amp;quot;tfidfAggregate&amp;quot;,
MAX),
28
29 //Evaluator
30 Dimension.create(&amp;quot;evalMatchingType&amp;quot;,
MatchingType.Exact),
31 Dimension.create(&amp;quot;evalN&amp;quot;, 50),
32 Dimension.create(&amp;quot;evalLowercase&amp;quot;,
true),
33 Dimension.create(&amp;quot;evalType&amp;quot;,
EvaluatorType.Lemma),
34 );
35
36 Task preprocessingTask = new
PreprocessingTask();
37 Task filteringTask = new
KeyphraseFilteringTask();
38 candidateSelectionTask.addImport(
preprocessingTask,
PreprocessingTask.OUTPUT,
KeyphraseFilteringTask.INPUT);
39 Task keyphraseRankingTask = new
KeyphraseRankingTask();
40 keyphraseRankingTask.addImport(
filteringTask,
KeyphraseFilteringTask.OUTPUT,
KeyphraseRankingTask.INPUT);
41
42 BatchTask batch = new BatchTask();
43 batch.setParameterSpace(params);
44 batch.addTask(preprocessingTask);
45 batch.addTask(candidateSelectionTask);
46 batch.addTask(keyphraseRankingTask);
47 batch.addReport(
KeyphraseExtractionReport.class);
48 Lab.getInstance().run(batch);
</figure>
<bodyText confidence="0.9988446">
A use case for the experimental framework is
the evaluation of new preprocessing components.
For example, keyphrase extraction should be eval-
uated with Twitter data: One collects a dataset
with tweets and their corresponding keyphrases
(possibly, the hash tags). The standard preprocess-
ing will most likely fail as non-canonical language
will be hard to process (e.g. hash tags or emoti-
cons).
The preprocessing components can be set as a
parameter and compared directly without chang-
ing the remaining parameters for filters and
rankers. This allows researchers to perform reli-
able extrinsic evaluation of their components in a
keyphrase extraction setting.
</bodyText>
<figureCaption confidence="0.949121">
Figure 2: Screenshot of web demo in DKPro
Keyphrases
</figureCaption>
<sectionHeader confidence="0.893211" genericHeader="method">
4 Visualization and wrappers
</sectionHeader>
<bodyText confidence="0.999928608695652">
To foster analysis of keyphrase extraction ex-
periments, we created a web-based visualization
framework with Spring4. It allows for running off-
the-shelf experiments and manually inspecting re-
sults without the need to install any additional soft-
ware. Figure 2 shows a visualization of one pre-
configured experiment. The web demo is avail-
able online.5 Currently, a table overview of ex-
tracted keyphrases is implemented, but develop-
ers can change it to highlighting all keyphrases.
The latter is recommend for a binary classification
of keyphrases. This is the case, if a system only
returns keyphrases with a score above a certain
threshold. The table in Figure 2 shows keyphrases
with the assigned scores, which can be sorted to
get a ranking of keyphrases. However, the visual-
ization framework does not provide any evaluation
capabilities.
To help new users of DKPro Keyphrases, it in-
cludes a module with two demo experiments us-
ing preconfigured parameter sets. This is espe-
cially useful for applying keyphrase extraction in
other tasks, e.g. text summarization (Goldstein et
</bodyText>
<footnote confidence="0.990282666666667">
4http://projects.spring.io/spring-ws/
5https://dkpro.ukp.informatik.tu-
darmstadt.de/DKProWebDemo/livedemo/3
</footnote>
<page confidence="0.998262">
34
</page>
<bodyText confidence="0.9996255">
al., 2000). Both demo experiments are frequently
used keyphrase extraction systems. The first one
is based on TextRank (Mihalcea and Tarau, 2004)
and the second one is based on the supervised sys-
tem KEA (Witten et al., 1999). Both configura-
tions do not require any additional installation of
software packages.
This module offers setters to configure param-
eters, e.g. the size of co-occurrence windows in
case of the TextRank extractor.
</bodyText>
<sectionHeader confidence="0.999837" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999932819672132">
Most work on keyphrase extraction is not accom-
panied with free and open software. The tools
listed in this section allow users to combine differ-
ent configurations with respect to preprocessing,
keyphrase selection, filtering, and ranking. In the
following, we give an overview of software tools
for keyphrase extraction.
KEA (Witten et al., 1999) provides a Java API,
which offers automatic keyphrase extraction from
texts. They provide a supervised approach for
keyphrase extraction. For each keyphrase, KEA
computes frequency, position, and semantic relat-
edness as features. Thus, for using KEA, the user
needs to provide annotated training data. KEA
generates keyphrases from n-grams with length
from 1 to 3 tokens. A controlled vocabulary can
be used to filter keyphrases. The configuration for
keyphrase selection and filtering is limited com-
pared to DKPro Keyphrases, which offers capa-
bilities for changing the entire preprocessing or
adding filters.
Maui (Medelyan et al., 2009) enhances KEA
by allowing the computation of semantic related-
ness of keyphrases. It uses Wikipedia as a the-
saurus and computes the keyphraseness of each
keyphrase, which is the number of times a can-
didate was used as keyphrase in the training data
(Medelyan et al., 2009).
Although Maui provides training data along
with their software, this training data is highly
domain-specific. A shortcoming of KEA and
Maui is the lack of any evaluation capabilities or
the possibility to run parameter sweeping exper-
iments. DKPro Keyphrases provides evaluation
tools for automatic testing of many parameter set-
tings.
Besides KEA and Mau, which are Java sys-
tems, there are several modules in Python,
e.g. topia.termextract6, which offer capabili-
ties for tokenization, part-of-speech tagging and
keyphrase extraction. Keyphrase extraction from
topia.termextract is based on noun phrases and
ranks them according to their frequencies.
BibClassify7 is a python module which auto-
matically extracts keywords from a text based on
the occurrence of terms in a thesaurus. The ranker
is frequency-based like topia.termextract. Bib-
Classify and topia.termextract do not provide eval-
uation capabilities or parameter sweeping experi-
ments.
Besides these software tools, there exist web
services for keyphrase extraction. AlchemyAPI8
offers a web service for keyword extraction. It
may return keyphrases encoded in various markup
languages. TerMine9 offers a SOAP service for
extracting keyphrases from documents and a web
demo. The input must be a String and the extracted
terms will be returned as a String. Although web
services can be integrated easily due to their proto-
col stacks, they are not extensible and replicability
cannot be guaranteed over time.
</bodyText>
<sectionHeader confidence="0.996099" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999994047619048">
We presented DKPro Keyphrases, a framework for
flexible and reusable keyphrase extraction experi-
ments. This helps researchers to effectively de-
velop new keyphrase extraction components with-
out the need to re-implement state-of-the-art ap-
proaches.
The UIMA-based architecture of DKPro
Keyphrases allows users to easily evaluate
keyphrase extraction configurations. Researchers
can integrate keyphrase extraction with different
existing linguistic preprocessing components of-
fered by the open-source community and evaluate
them in terms of all commonly used evaluation
metrics.
As future work, we plan to wrap further
third-party libraries with keyphrase extraction ap-
proaches in DKPro Keyphrases and to add a super-
vised system using the unsupervised components
as features. We expect that a supervised system us-
ing a large variety of features would improve the
state of the art in keyphrase extraction.
</bodyText>
<footnote confidence="0.999655">
6https://pypi.python.org/pypi/topia.termextract/
7http://invenio-demo.cern.ch/help/admin/bibclassify-
admin-guide
8http://www.alchemyapi.com/api/keyword-extraction/
9http://www.nactem.ac.uk/software/termine/
</footnote>
<page confidence="0.9989">
35
</page>
<sectionHeader confidence="0.998332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99996925">
This work has been supported by the Volk-
swagen Foundation as part of the Lichtenberg-
Professorship Program under grant No. I/82806,
by the Klaus Tschira Foundation under project No.
00.133.2008, and by the German Federal Min-
istry of Education and Research (BMBF) within
the context of the Software Campus project open
window under grant No. 01IS12054. The authors
assume responsibility for the content. We thank
Richard Eckart de Castilho and all contributors for
their valuable collaboration and the we thank the
anonymous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999811746987952">
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
Gram Corpus Version 1.1. Technical report, Google
Research.
Christian D¨orner, Volkmar Pipek, and Markus Won.
2007. Supporting Expertise Awareness: Finding
Out What Others Know. In Proceedings of the 2007
Symposium on Computer Human Interaction for the
Management of Information Technology.
Richard Eckart de Castilho and Iryna Gurevych. 2009.
DKPro-UGD: A Flexible Data-Cleansing Approach
to Processing User-Generated Discourse. In Online-
proceedings of the First French-speaking meeting
around the framework Apache UIMA.
Richard Eckart de Castilho and Iryna Gurevych. 2011.
A Lightweight Framework for Reproducible Param-
eter Sweeping in Information Retrieval. In Pro-
ceedings of the 2011 Workshop on Data Infrastruc-
tures for Supporting Information Retrieval Evalua-
tion, pages 7–10.
G¨unes Erkan and Dragomir Radev. 2004. LexRank:
Graph-based Lexical Centrality as Salience in Text
Summarization. Journal of Artificial Intelligence
Research, 22:457–479.
David Ferrucci and Adam Lally. 2004. UIMA: An
Architectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327–348.
Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and
Mark Kantrowitz. 2000. Multi-Document Summa-
rization By Sentence Extraction. In Proceedings of
the NAACL-ANLP 2000 Workshop: Automatic Sum-
marization, pages 40–48.
Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller,
J¨urgen Steimle, Markus Weimer, and Torsten Zesch.
2007. Darmstadt Knowledge Processing Repository
Based on UIMA. In Proceedings of the First Work-
shop on Unstructured Information Management Ar-
chitecture at Biannual Conference of the Society for
Computational Linguistics and Language Technol-
ogy.
Su Nam Kim, Olena Medelyan, Min-Yen Kan, and
Timothy Baldwin. 2010. Semeval-2010 Task 5:
Automatic Keyphrase Extraction from Scientific Ar-
ticles. In Proceedings of the 5th International Work-
shop on Semantic Evaluation, pages 21–26.
Cody Kwok, Oren Etzioni, and Daniel S. Weld. 2001.
Scaling Question Answering to the Web. ACM
Transactions on Information Systems, 19(3):242–
262.
Christopher D Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. An Introduction to Infor-
mation Retrieval. Cambridge University Press Cam-
bridge.
Olena Medelyan, Eibe Frank, and Ian H Witten.
2009. Human-competitive Tagging using Automatic
Keyphrase Extraction. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1318–1327.
Rada Mihalcea and Paul Tarau. 2004. TextRank:
Bringing Order into Texts. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 404–411.
Min Song, Il Yeol Song, Robert B. Allen, and Zo-
ran Obradovic. 2006. Keyphrase Extraction-based
Query Expansion in Digital Libraries. In Proceed-
ings of the 6th ACM/IEEE-CS Joint Conference on
Digital Libraries, pages 202–209.
Simon Tucker and Steve Whittaker. 2009. Have A Say
Over What You See: Evaluating Interactive Com-
pression Techniques. In Proceedings of the 2009
International Conference on Intelligent User Inter-
faces, pages 37–46.
Ian H. Witten, Gordon W. Paynter, Eibe Frank,
Carl Andrew Gutwin, and Craig G . Nevill-
Manning. 1999. KEA: Practical Automatic
Keyphrase Extraction. In Proceedings of the 4th
ACM Conference on Digital Libraries, pages 254–
255.
Torsten Zesch and Iryna Gurevych. 2009. Approx-
imate Matching for Evaluating Keyphrase Extrac-
tion. In Proceedings of the 7th International Confer-
ence on Recent Advances in Natural Language Pro-
cessing, pages 484–489.
</reference>
<page confidence="0.998939">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.513598">
<title confidence="0.998088">DKPro Keyphrases: Flexible and Reusable Keyphrase Extraction Experiments</title>
<author confidence="0.997292">Pedro Bispo Iryna Torsten</author>
<affiliation confidence="0.834279333333333">Lab, Technische Universit¨at Center for Education, DIPF, Technology Lab, University of</affiliation>
<web confidence="0.985712">http://www.ukp.tu-darmstadt.de</web>
<abstract confidence="0.985054777777778">DKPro Keyphrases is a keyphrase extraction framework based on UIMA. It offers a wide range of state-of-the-art keyphrase experiments approaches. At the same time, it is a workbench for developing new extraction approaches and evaluating their impact. DKPro Keyphrases is publicly under an open-source</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-Gram Corpus Version 1.1.</title>
<date>2006</date>
<tech>Technical report, Google Research.</tech>
<contexts>
<context position="6024" citStr="Brants and Franz, 2006" startWordPosition="895" endWordPosition="898"> base class and adding filter-specific code. Additionally, DKPro Keyphrases does not impose workflow-specific requirements, such as a fixed number of filters. This leaves room for keyphrase extraction experiments testing new or extended filters. 2.4 Ranking In this step, a ranker assigns a score to each remaining keyphrase candidate. DKPro Keyphrases contains rankers based on the candidate position, frequency, tf-idf, TextRank (Mihalcea and Tarau, 2004), and LexRank (Erkan and Radev, 2004). DKPro Keyphrases also contains a special extension of tf-idf, called tf-idfweb, for which Google web1t (Brants and Franz, 2006) is used for obtaining approximate df counts. In case of keyphrase extraction for a single document or for domainindependent keyphrase extraction, web1t provides reliable n-gram statistics without any domaindependence. 2.5 Evaluation DKPro Keyphrases ships with all the metrics that have been traditionally used for evaluating keyphrase extraction. Kim et al. (2010) use precision and recall for a different number of keyphrases (5, 10 and 15 keyphrases). These metrics are widely used for evaluation in information retrieval. Precision @5 is the ratio of true positives in the set of extracted keyph</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-Gram Corpus Version 1.1. Technical report, Google Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian D¨orner</author>
<author>Volkmar Pipek</author>
<author>Markus Won</author>
</authors>
<title>Supporting Expertise Awareness: Finding Out What Others Know.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Symposium on Computer Human Interaction for the Management of Information Technology.</booktitle>
<marker>D¨orner, Pipek, Won, 2007</marker>
<rawString>Christian D¨orner, Volkmar Pipek, and Markus Won. 2007. Supporting Expertise Awareness: Finding Out What Others Know. In Proceedings of the 2007 Symposium on Computer Human Interaction for the Management of Information Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Eckart de Castilho</author>
<author>Iryna Gurevych</author>
</authors>
<title>DKPro-UGD: A Flexible Data-Cleansing Approach to Processing User-Generated Discourse.</title>
<date>2009</date>
<booktitle>In Onlineproceedings of the First French-speaking meeting around the framework Apache UIMA.</booktitle>
<marker>de Castilho, Gurevych, 2009</marker>
<rawString>Richard Eckart de Castilho and Iryna Gurevych. 2009. DKPro-UGD: A Flexible Data-Cleansing Approach to Processing User-Generated Discourse. In Onlineproceedings of the First French-speaking meeting around the framework Apache UIMA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Eckart de Castilho</author>
<author>Iryna Gurevych</author>
</authors>
<title>A Lightweight Framework for Reproducible Parameter Sweeping in Information Retrieval.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Workshop on Data Infrastructures for Supporting Information Retrieval Evaluation,</booktitle>
<pages>7--10</pages>
<marker>de Castilho, Gurevych, 2011</marker>
<rawString>Richard Eckart de Castilho and Iryna Gurevych. 2011. A Lightweight Framework for Reproducible Parameter Sweeping in Information Retrieval. In Proceedings of the 2011 Workshop on Data Infrastructures for Supporting Information Retrieval Evaluation, pages 7–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes Erkan</author>
<author>Dragomir Radev</author>
</authors>
<title>LexRank: Graph-based Lexical Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>22--457</pages>
<contexts>
<context position="5895" citStr="Erkan and Radev, 2004" startWordPosition="875" endWordPosition="878">cluded in a keyphrase list. Developers of keyphrase extraction approaches can create their own filter simply by extending from a base class and adding filter-specific code. Additionally, DKPro Keyphrases does not impose workflow-specific requirements, such as a fixed number of filters. This leaves room for keyphrase extraction experiments testing new or extended filters. 2.4 Ranking In this step, a ranker assigns a score to each remaining keyphrase candidate. DKPro Keyphrases contains rankers based on the candidate position, frequency, tf-idf, TextRank (Mihalcea and Tarau, 2004), and LexRank (Erkan and Radev, 2004). DKPro Keyphrases also contains a special extension of tf-idf, called tf-idfweb, for which Google web1t (Brants and Franz, 2006) is used for obtaining approximate df counts. In case of keyphrase extraction for a single document or for domainindependent keyphrase extraction, web1t provides reliable n-gram statistics without any domaindependence. 2.5 Evaluation DKPro Keyphrases ships with all the metrics that have been traditionally used for evaluating keyphrase extraction. Kim et al. (2010) use precision and recall for a different number of keyphrases (5, 10 and 15 keyphrases). These metrics a</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes Erkan and Dragomir Radev. 2004. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22:457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--3</pages>
<contexts>
<context position="1782" citStr="Ferrucci and Lally, 2004" startWordPosition="260" endWordPosition="263">ation retrieval (Manning et al., 2008), or question answering (Kwok et al., 2001). In this paper, we describe our keyphrase extraction framework called DKPro Keyphrases. It integrates a wide range of state-of-the-art approaches for keyphrase extraction that can be directly used with limited knowledge of programming. However, for developers of new keyphrase extraction approaches, DKPro Keyphrases also offers a programming framework for developing new extraction algorithms and for evaluation of resulting effects. DKPro Keyphrases is based on the Unstructured Information Management Architecture (Ferrucci and Lally, 2004), which provides a rich source of libraries with preprocessing components. 1http://code.google.com/p/dkpro-keyphrases/ Text Preprocessing Select keyphrases Filter keyphrases Rank keyphrases Evaluate Results Figure 1: Architecture overview of DKPro Keyphrases 2 Architecture The architecture of DKPro Keyphrases models the five fundamental steps of keyphrase extraction: (i) Reading of input data and enriching it with standard linguistic preprocessing, (ii) selecting phrases as keyphrase candidates based on the preprocessed text, (iii) filtering selected keyphrases, (iv) ranking remaining keyphras</context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>David Ferrucci and Adam Lally. 2004. UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment. Natural Language Engineering, 10(3-4):327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jade Goldstein</author>
<author>Vibhu Mittal</author>
<author>Jaime Carbonell</author>
<author>Mark Kantrowitz</author>
</authors>
<title>Multi-Document Summarization By Sentence Extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of the NAACL-ANLP</booktitle>
<pages>40--48</pages>
<marker>Goldstein, Mittal, Carbonell, Kantrowitz, 2000</marker>
<rawString>Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. Multi-Document Summarization By Sentence Extraction. In Proceedings of the NAACL-ANLP 2000 Workshop: Automatic Summarization, pages 40–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Max M¨uhlh¨auser</author>
<author>Christof M¨uller</author>
<author>J¨urgen Steimle</author>
<author>Markus Weimer</author>
<author>Torsten Zesch</author>
</authors>
<title>Darmstadt Knowledge Processing Repository Based on UIMA.</title>
<date>2007</date>
<booktitle>In Proceedings of the First Workshop on Unstructured Information Management Architecture at Biannual Conference of the Society for Computational Linguistics and Language Technology.</booktitle>
<marker>Gurevych, M¨uhlh¨auser, M¨uller, Steimle, Weimer, Zesch, 2007</marker>
<rawString>Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller, J¨urgen Steimle, Markus Weimer, and Torsten Zesch. 2007. Darmstadt Knowledge Processing Repository Based on UIMA. In Proceedings of the First Workshop on Unstructured Information Management Architecture at Biannual Conference of the Society for Computational Linguistics and Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Olena Medelyan</author>
<author>Min-Yen Kan</author>
<author>Timothy Baldwin</author>
</authors>
<title>Semeval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>21--26</pages>
<contexts>
<context position="6390" citStr="Kim et al. (2010)" startWordPosition="949" endWordPosition="952">sed on the candidate position, frequency, tf-idf, TextRank (Mihalcea and Tarau, 2004), and LexRank (Erkan and Radev, 2004). DKPro Keyphrases also contains a special extension of tf-idf, called tf-idfweb, for which Google web1t (Brants and Franz, 2006) is used for obtaining approximate df counts. In case of keyphrase extraction for a single document or for domainindependent keyphrase extraction, web1t provides reliable n-gram statistics without any domaindependence. 2.5 Evaluation DKPro Keyphrases ships with all the metrics that have been traditionally used for evaluating keyphrase extraction. Kim et al. (2010) use precision and recall for a different number of keyphrases (5, 10 and 15 keyphrases). These metrics are widely used for evaluation in information retrieval. Precision @5 is the ratio of true positives in the set of extracted keyphrases when 5 keyphrases are extracted. Recall @5 is the ratio of true positives in the set of gold keyphrases when 5 keyphrases are extracted. Moreover, DKPro Keyphrases evaluates with MAP and R-precision. MAP is the mean average precision of extracted keyphrases from the highest scored keyphrase to the total number of extracted keyphrases. For each position in th</context>
</contexts>
<marker>Kim, Medelyan, Kan, Baldwin, 2010</marker>
<rawString>Su Nam Kim, Olena Medelyan, Min-Yen Kan, and Timothy Baldwin. 2010. Semeval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 21–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cody Kwok</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
</authors>
<title>Scaling Question Answering to the Web.</title>
<date>2001</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>19</volume>
<issue>3</issue>
<pages>262</pages>
<contexts>
<context position="1238" citStr="Kwok et al., 2001" startWordPosition="180" endWordPosition="183">vailable under an open-source license.1 1 Introduction Keyphrases are single words or phrases that provide a summary of a text (Tucker and Whittaker, 2009) and thus might improve searching (Song et al., 2006) in a large collection of texts. As manual extraction of keyphrases is a tedious task, a wide variety of keyphrase extraction approaches has been proposed. Only few of them are freely available which makes it hard for researchers to replicate previous results or use keyphrase extraction in some other application, such as information retrieval (Manning et al., 2008), or question answering (Kwok et al., 2001). In this paper, we describe our keyphrase extraction framework called DKPro Keyphrases. It integrates a wide range of state-of-the-art approaches for keyphrase extraction that can be directly used with limited knowledge of programming. However, for developers of new keyphrase extraction approaches, DKPro Keyphrases also offers a programming framework for developing new extraction algorithms and for evaluation of resulting effects. DKPro Keyphrases is based on the Unstructured Information Management Architecture (Ferrucci and Lally, 2004), which provides a rich source of libraries with preproc</context>
</contexts>
<marker>Kwok, Etzioni, Weld, 2001</marker>
<rawString>Cody Kwok, Oren Etzioni, and Daniel S. Weld. 2001. Scaling Question Answering to the Web. ACM Transactions on Information Systems, 19(3):242– 262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>An Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press Cambridge.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. An Introduction to Information Retrieval. Cambridge University Press Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>Eibe Frank</author>
<author>Ian H Witten</author>
</authors>
<title>Human-competitive Tagging using Automatic Keyphrase Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1318--1327</pages>
<contexts>
<context position="16302" citStr="Medelyan et al., 2009" startWordPosition="2381" endWordPosition="2384">API, which offers automatic keyphrase extraction from texts. They provide a supervised approach for keyphrase extraction. For each keyphrase, KEA computes frequency, position, and semantic relatedness as features. Thus, for using KEA, the user needs to provide annotated training data. KEA generates keyphrases from n-grams with length from 1 to 3 tokens. A controlled vocabulary can be used to filter keyphrases. The configuration for keyphrase selection and filtering is limited compared to DKPro Keyphrases, which offers capabilities for changing the entire preprocessing or adding filters. Maui (Medelyan et al., 2009) enhances KEA by allowing the computation of semantic relatedness of keyphrases. It uses Wikipedia as a thesaurus and computes the keyphraseness of each keyphrase, which is the number of times a candidate was used as keyphrase in the training data (Medelyan et al., 2009). Although Maui provides training data along with their software, this training data is highly domain-specific. A shortcoming of KEA and Maui is the lack of any evaluation capabilities or the possibility to run parameter sweeping experiments. DKPro Keyphrases provides evaluation tools for automatic testing of many parameter set</context>
</contexts>
<marker>Medelyan, Frank, Witten, 2009</marker>
<rawString>Olena Medelyan, Eibe Frank, and Ian H Witten. 2009. Human-competitive Tagging using Automatic Keyphrase Extraction. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1318–1327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing Order into Texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="5858" citStr="Mihalcea and Tarau, 2004" startWordPosition="869" endWordPosition="872">ring out all keyphrases which are not included in a keyphrase list. Developers of keyphrase extraction approaches can create their own filter simply by extending from a base class and adding filter-specific code. Additionally, DKPro Keyphrases does not impose workflow-specific requirements, such as a fixed number of filters. This leaves room for keyphrase extraction experiments testing new or extended filters. 2.4 Ranking In this step, a ranker assigns a score to each remaining keyphrase candidate. DKPro Keyphrases contains rankers based on the candidate position, frequency, tf-idf, TextRank (Mihalcea and Tarau, 2004), and LexRank (Erkan and Radev, 2004). DKPro Keyphrases also contains a special extension of tf-idf, called tf-idfweb, for which Google web1t (Brants and Franz, 2006) is used for obtaining approximate df counts. In case of keyphrase extraction for a single document or for domainindependent keyphrase extraction, web1t provides reliable n-gram statistics without any domaindependence. 2.5 Evaluation DKPro Keyphrases ships with all the metrics that have been traditionally used for evaluating keyphrase extraction. Kim et al. (2010) use precision and recall for a different number of keyphrases (5, 1</context>
<context position="15010" citStr="Mihalcea and Tarau, 2004" startWordPosition="2180" endWordPosition="2183">hich can be sorted to get a ranking of keyphrases. However, the visualization framework does not provide any evaluation capabilities. To help new users of DKPro Keyphrases, it includes a module with two demo experiments using preconfigured parameter sets. This is especially useful for applying keyphrase extraction in other tasks, e.g. text summarization (Goldstein et 4http://projects.spring.io/spring-ws/ 5https://dkpro.ukp.informatik.tudarmstadt.de/DKProWebDemo/livedemo/3 34 al., 2000). Both demo experiments are frequently used keyphrase extraction systems. The first one is based on TextRank (Mihalcea and Tarau, 2004) and the second one is based on the supervised system KEA (Witten et al., 1999). Both configurations do not require any additional installation of software packages. This module offers setters to configure parameters, e.g. the size of co-occurrence windows in case of the TextRank extractor. 5 Related work Most work on keyphrase extraction is not accompanied with free and open software. The tools listed in this section allow users to combine different configurations with respect to preprocessing, keyphrase selection, filtering, and ranking. In the following, we give an overview of software tool</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order into Texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Song</author>
<author>Il Yeol Song</author>
<author>Robert B Allen</author>
<author>Zoran Obradovic</author>
</authors>
<title>Keyphrase Extraction-based Query Expansion in Digital Libraries.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th ACM/IEEE-CS Joint Conference on Digital Libraries,</booktitle>
<pages>202--209</pages>
<contexts>
<context position="828" citStr="Song et al., 2006" startWordPosition="112" endWordPosition="115">r for Education, DIPF, Frankfurt § Language Technology Lab, University of Duisburg-Essen http://www.ukp.tu-darmstadt.de Abstract DKPro Keyphrases is a keyphrase extraction framework based on UIMA. It offers a wide range of state-of-the-art keyphrase experiments approaches. At the same time, it is a workbench for developing new extraction approaches and evaluating their impact. DKPro Keyphrases is publicly available under an open-source license.1 1 Introduction Keyphrases are single words or phrases that provide a summary of a text (Tucker and Whittaker, 2009) and thus might improve searching (Song et al., 2006) in a large collection of texts. As manual extraction of keyphrases is a tedious task, a wide variety of keyphrase extraction approaches has been proposed. Only few of them are freely available which makes it hard for researchers to replicate previous results or use keyphrase extraction in some other application, such as information retrieval (Manning et al., 2008), or question answering (Kwok et al., 2001). In this paper, we describe our keyphrase extraction framework called DKPro Keyphrases. It integrates a wide range of state-of-the-art approaches for keyphrase extraction that can be direct</context>
</contexts>
<marker>Song, Song, Allen, Obradovic, 2006</marker>
<rawString>Min Song, Il Yeol Song, Robert B. Allen, and Zoran Obradovic. 2006. Keyphrase Extraction-based Query Expansion in Digital Libraries. In Proceedings of the 6th ACM/IEEE-CS Joint Conference on Digital Libraries, pages 202–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Tucker</author>
<author>Steve Whittaker</author>
</authors>
<title>Have A Say Over What You See: Evaluating Interactive Compression Techniques.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 International Conference on Intelligent User Interfaces,</booktitle>
<pages>37--46</pages>
<contexts>
<context position="775" citStr="Tucker and Whittaker, 2009" startWordPosition="103" endWordPosition="106">UKP Lab, Technische Universit¨at Darmstadt ‡ Information Center for Education, DIPF, Frankfurt § Language Technology Lab, University of Duisburg-Essen http://www.ukp.tu-darmstadt.de Abstract DKPro Keyphrases is a keyphrase extraction framework based on UIMA. It offers a wide range of state-of-the-art keyphrase experiments approaches. At the same time, it is a workbench for developing new extraction approaches and evaluating their impact. DKPro Keyphrases is publicly available under an open-source license.1 1 Introduction Keyphrases are single words or phrases that provide a summary of a text (Tucker and Whittaker, 2009) and thus might improve searching (Song et al., 2006) in a large collection of texts. As manual extraction of keyphrases is a tedious task, a wide variety of keyphrase extraction approaches has been proposed. Only few of them are freely available which makes it hard for researchers to replicate previous results or use keyphrase extraction in some other application, such as information retrieval (Manning et al., 2008), or question answering (Kwok et al., 2001). In this paper, we describe our keyphrase extraction framework called DKPro Keyphrases. It integrates a wide range of state-of-the-art a</context>
</contexts>
<marker>Tucker, Whittaker, 2009</marker>
<rawString>Simon Tucker and Steve Whittaker. 2009. Have A Say Over What You See: Evaluating Interactive Compression Techniques. In Proceedings of the 2009 International Conference on Intelligent User Interfaces, pages 37–46.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ian H Witten</author>
<author>Gordon W Paynter</author>
<author>Eibe Frank</author>
<author>Carl Andrew Gutwin</author>
<author>G Craig</author>
</authors>
<publisher>Nevill-</publisher>
<marker>Witten, Paynter, Frank, Gutwin, Craig, </marker>
<rawString>Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl Andrew Gutwin, and Craig G . Nevill-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manning</author>
</authors>
<title>KEA: Practical Automatic Keyphrase Extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 4th ACM Conference on Digital Libraries,</booktitle>
<pages>254--255</pages>
<marker>Manning, 1999</marker>
<rawString>Manning. 1999. KEA: Practical Automatic Keyphrase Extraction. In Proceedings of the 4th ACM Conference on Digital Libraries, pages 254– 255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
</authors>
<title>Approximate Matching for Evaluating Keyphrase Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 7th International Conference on Recent Advances in Natural Language Processing,</booktitle>
<pages>484--489</pages>
<contexts>
<context position="7469" citStr="Zesch and Gurevych, 2009" startWordPosition="1133" endWordPosition="1136">n average precision of extracted keyphrases from the highest scored keyphrase to the total number of extracted keyphrases. For each position in the rank, the precision at that position will be computed. Summing up the precision at each recall point and then taking its average will return the average precision for the text being evaluated. The mean average precision will be the mean from the sum of each text’s average precision from the dataset. R-precision is the ratio of true positives in the set of extracted keyphrases, when the set is limited to the same size as the set of gold keyphrases (Zesch and Gurevych, 2009). 32 3 Experimental framework In this section, we show how researchers can perform experiments covering many different configurations for preprocessing, selection, and ranking. To facilitate the construction of experiments, the framework contains a module to make its architecture compatible to the DKPro Lab framework (Eckart de Castilho and Gurevych, 2011), thus allowing to sweep through the parameter space of configurations. The parameter space is the combination of all possible parameters, e.g. one parameter with two possible values for preprocessing and a second parameter with two values fo</context>
</contexts>
<marker>Zesch, Gurevych, 2009</marker>
<rawString>Torsten Zesch and Iryna Gurevych. 2009. Approximate Matching for Evaluating Keyphrase Extraction. In Proceedings of the 7th International Conference on Recent Advances in Natural Language Processing, pages 484–489.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>