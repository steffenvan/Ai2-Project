<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.702189">
SYNTACTIC CHOICE IN LANGUAGE GENERATION
</note>
<author confidence="0.901943">
Lee Fedder,
</author>
<affiliation confidence="0.99937">
University of Cambridge, Computer Laboratory, Pembroke Street,
</affiliation>
<address confidence="0.804291">
Cambridge CB2 3QG, England.
</address>
<email confidence="0.603847">
lffluk.ac.cam.c1
</email>
<sectionHeader confidence="0.990037" genericHeader="abstract">
1 Abstract
</sectionHeader>
<bodyText confidence="0.999957260869565">
A considerable amount of study has recently
been concentrated on the use of linguistically
motivated unification based grammars for sen-
tence generation (see for example Appelt 1987,
Calder 1989, Shieber 1988, Shieber et al. 1989).
The grammars state correspondences between
semantic structures and syntactic ones. In
most grammars, several syntactic structures
will correspond to each semantic one. It was
suggested at a fairly early stage that control
over which sentence is generated could be ap-
plied by adding &amp;quot;functional&amp;quot; features to the
grammar.
This idea has been extended in the work
presented here. The use of feature threading
techniques allows control over a wide range
of syntactic structures, in a fairly sophisti-
cated grammar, while avoiding the need for
rule duplication even when generating un-
bounded dependencies. However, we will see
that the feature system required quickly be-
comes complex, and may be difficult to ex-
tend to more comprehensive grammars.
</bodyText>
<sectionHeader confidence="0.998976" genericHeader="introduction">
2 Introduction
</sectionHeader>
<bodyText confidence="0.999933684210526">
&amp;quot;A thematic system is one where
corresponding members of the con-
trasting terms normally have the
same propositional meaning, and
the same illocutionary potential.&amp;quot;
(Huddleston 1984:p437).
Most phrase structure or categorial unifi-
cation based grammars encode some form of
thematic system. The simplest would involve
the inclusion of both active and passive voice.
Typically, the grammar defines the syntactic
structure of each form, but does not include
the pragmatic information that distinguishes
one from another. When using such a gram-
mar for parsing, this is not important, so
long as the information is not required by the
system using the parser&apos;s output. However,
there has recently been an upsurge in the use
of these grammars for generation. The lack
of pragmatic data now becomes important:
the generator is under-constrained, being ca-
pable of producing any of the available the-
matic forms. One way of applying the neces-
sary constraints, is to introduce a system of
&amp;quot;functional&amp;quot; features into the feature struc-
ture of the grammar itself. These features are
so called because they refer to the function
of the various parts of the sentence in a dis-
course. McKeown suggested the use of func-
tional features for the TEXT system (McKe-
own 1985) in which the grammar was based
on the FUG formalism (Kay 1979). The func-
tional features were defined as part of the ini-
tial specification of the sentence, which was
then filled out by traversing the grammar in
a &amp;quot;Top Down&amp;quot; fashion. For example, the fol-
lowing was given by McKeown as an initial
sentence specification.
</bodyText>
<equation confidence="0.995735">
PROT = [N === DOG]
VERB = [V === BITE]
[TENSE === PAST]
COAL = [ADJ === OLD]
[N === MAN]
TOPIC = [PROT]
</equation>
<page confidence="0.99254">
45
</page>
<bodyText confidence="0.99998515">
The functional feature is &amp;quot;TOPIC&amp;quot;, and
is specified as being the agent (or PROTago-
fist) of the semantic structure. The feature
value controls wether an active or passive sen-
tence will be produced.
The work reported in this paper extends
this technique to a grammar which encodes a
richer thematic system than just active and
passive. We use a unification based gram-
mar with a phrase structure backbone, which
was originally developed to provide a simple
computational description of current linguis-
tic theories (mainly GPSG, Gazdar 1985). As
in the example above, a system of functional
features is introduced. A bottom-up genera-
tion algorithm allows the production of sen-
tences given an initial semantic form. The
assignment of some initial values to the func-
tional features constrains the structures gen-
erated, and typically just one sentence will
be generated for each semantic input.
This work was done in the context of a
database enquiery system with single sentence
output. We assume there is a discourse man-
ager which initiates generation by passing the
generator a &amp;quot;message&amp;quot;. This message con-
sists of the propositional content of the out-
put required, and some pragmatic informa-
tion.
The rest of this paper is in three main
parts. The first is the definition of a co-
herent set of discourse parameters that de-
scribe the behaviour in discourse of the var-
ious elements of a sentence. The second sec-
tion describes the thematic system used, and
how each member relates to the discourse pa-
rameters. Finally, we see how the grammar
can be augmented with functional features to
provide filtering during generation consistent
with the discourse parameters.
</bodyText>
<sectionHeader confidence="0.996415" genericHeader="method">
3 Discourse Parameters
</sectionHeader>
<bodyText confidence="0.999936090909091">
The members of the thematic system to be
described below behave differently in discourse.
In the linguistics literature, there is a long
tradition, of assigning labels to various clause
constituents in order to describe this behaviour.
Labels such as &amp;quot;given&amp;quot; and &amp;quot;new&amp;quot;, &amp;quot;topic&amp;quot;
and &amp;quot;comment&amp;quot; ,&amp;quot;theme&amp;quot; and &amp;quot;rheme&amp;quot; and so
on (a summary can be found in Quirk 1985,
18.9). We have adopted a set which allows a
distinction between the members of the the-
matic system we use.
</bodyText>
<subsectionHeader confidence="0.999676">
3.1 Speech Act Type
</subsectionHeader>
<bodyText confidence="0.9998084">
This parameter conveys information about
the sentence as a whole. Something similar
is to be found in most grammars, but prece-
dents in generation can be found in Appelt
1985, and Bunt 1987. Values are :-
</bodyText>
<listItem confidence="0.9996288">
1. Declarative - John gave a book to Mary
2. yes-no question - Did John give a book
to Mary
3. wh-question - Which book did John give
to Mary
</listItem>
<subsectionHeader confidence="0.996559">
3.2 Theme
</subsectionHeader>
<bodyText confidence="0.991208583333333">
The theme is :-
&amp;quot;... somehow an element seman-
tically crucial to the clause ... the
communicative point of departure
for the rest of the clause&amp;quot; — Quirk
1985,
In general, the theme is the established or
given part of a message, and lays the ground
for the rest of the communication. So, when
it occurs in its expected or unmarked form,
it will tend to be the first element of the sen-
tence.
</bodyText>
<subsectionHeader confidence="0.995487">
3.3 Focus
</subsectionHeader>
<bodyText confidence="0.997993666666667">
The label &amp;quot;focus&amp;quot; has been widely used in the
linguistics and A.I. to name a whole range of
concepts. We use the following definition :-
&amp;quot;The focus ... indicates where the
new information lies&amp;quot; - Quirk 1985.
This definition is easy to assimilate in terms
of a database enquiry system where the new
data is easily identified. As to where the fo-
cus occurs in the sentence
</bodyText>
<page confidence="0.998807">
46
</page>
<bodyText confidence="0.999828">
&amp;quot;The neutral position of focus is
what we may call END-FOCUS,
that is (generally speaking) chief
prominence on the last open-class
item or proper noun in the clause&amp;quot;
- Quirk 1985.
There may be several elements in the gen-
erator&apos;s input which are given, and several
which are new. For simplicity, we assume
the discourse manager is able to specify one
as the most thematic, and one as the most
focussed.
</bodyText>
<subsectionHeader confidence="0.927605">
3.4 Emphasis
</subsectionHeader>
<bodyText confidence="0.978208705882353">
The emphasis parameter indicates that some
stress is to be laid on the indicated sentence
element, above that supplied by an unmarked
sentence, as when correcting a false presup-
position. Emphasis is associated with par-
ticular marked sentence constructions, as we
will see below. Either the topic or the focus
may be emphasised: other sentence elements
may not.
4 Discourse parameters and
the thematic system
We can now move on to see how the discourse
parameters relate to the thematic system in
the grammar. In general, guided by Quirk&apos;s
definitions, we have adopted the simple rule
that the theme is the first NP in the sentence,
and the focus is the last.
</bodyText>
<subsectionHeader confidence="0.990146">
4.1 Active
</subsectionHeader>
<bodyText confidence="0.96367075">
The active sentence is considered as &amp;quot;unmarked&amp;quot;
form in which the parameters adopt their de-
fault or neutral values. Thus the subject NP
will be the theme, and the focus will be on the
verb, direct object, indirect object, or verb
modifier, whichever comes last.
4. John slept in the garden. [theme =
John, focus = the garden}
</bodyText>
<subsectionHeader confidence="0.947012">
4.2 Passive
</subsectionHeader>
<bodyText confidence="0.997281666666667">
Creider (1979) classifies the passive as prin-
cipally a topicalising structure, whilst Quirk
(1985) discusses the focussing effect.
We have modeled these effects as follows.
With transitive verbs, the subject is focused
and the object becomes theme. If the subject
is omitted, the verb itself can be focused, but
in addition, this produces some emphasis. If
the subject is not omitted, the verb can still
be focussed and emphasised by fronting the
object, which then becomes the theme (see
fronting). Modifiers may take the emphasis.
</bodyText>
<listItem confidence="0.897605833333333">
5. Mary was loved by Jim. [theme = Mary,
focus = Jim]
For bi-transitive verbs, the direct or indi-
rect object can be thematised.
6. Mary was sold a book by Jim. [theme
= Mary, focus = Jim]
</listItem>
<subsectionHeader confidence="0.96947">
4.3 The indirect object transforma-
tion
</subsectionHeader>
<bodyText confidence="0.947337933333333">
Creider (1979) classifies this transformation
as having a thematising function.
Q. What did you give to George?
A. I gave George a pennywhistle.
A. ?I gave a pennywhistle to George.
This is modeled by transferring theme to
the indirect object, and focus to the direct
object.
7. I gave George a pennywhistle. [theme
= George, focus = a pennywhistle]
The transformation can be combined with
class II passivisation. The result is treated as
a passive :-
8. A book was given by John to Mary.
[theme = a book, focus = Mary]
</bodyText>
<subsectionHeader confidence="0.998027">
4.4 Fronting
</subsectionHeader>
<bodyText confidence="0.999950833333333">
This construction is generally accepted as es-
tablishing the theme (see Creider 1979 - he
calls theme &amp;quot;topic&amp;quot;, and fronting &amp;quot;topicali-
sation&amp;quot;). The fronted item is not new data,
and seems to be associated with some form
of contrast. This shows up in examples like
</bodyText>
<page confidence="0.993007">
47
</page>
<listItem confidence="0.688347">
9. John I like, but Mary I hate.
</listItem>
<bodyText confidence="0.96896">
This is modeled by assigning both the
&amp;quot;theme&amp;quot; and &amp;quot;emphasis&amp;quot; parameters to the
fronted item, the focus being at the end of
the sentence as usual.
</bodyText>
<listItem confidence="0.698737">
10. To Mary John gave a book. [theme
= Mary, focus = a book, emphasis =
Mary]
</listItem>
<subsectionHeader confidence="0.751571">
4.5 Clefts
</subsectionHeader>
<bodyText confidence="0.999924333333333">
These constructions introduce the clefted el-
ement as new data, and apply special empha-
sis, as when correcting a presupposition :-
</bodyText>
<equation confidence="0.963088">
Q : Was it John who robbed the
bank?
A : No, it was Art her
</equation>
<bodyText confidence="0.986516222222222">
Usually, the other entities in the sentence
are given, and uncontested. As we saw in the
description of the grammar above, any NP or
modifier in as sentence can be clefted. So, the
clefted item is in focus, and the theme now
moves to the end of the sentence.
11. It was to Mary that John gave a book.
[theme = a book, focus = Mary, em-
phasis = Mary]
</bodyText>
<subsectionHeader confidence="0.589432">
4.6 Intonation
</subsectionHeader>
<bodyText confidence="0.999985">
The intonational centre is assumed to be at
the end of the phrase, except in cleft forms,
where it falls at the end of the first clause.
If the theme or focus is realised as a relative
clause, the intonational centre comes at the
end of that clause. These are important as-
sumptions since non-standard intonation can
serve to shift the emphasis or focus to almost
any part of a sentence.
</bodyText>
<sectionHeader confidence="0.985672" genericHeader="method">
5 The Grammar Formalism
</sectionHeader>
<bodyText confidence="0.999455304347826">
The grammar is encoded in a framework built
as part of the Alvey natural language tools
project, and known as the GDE (Grammar
Development Environment). The syntactic
analyses are based on those developed by Pul-
man 1987, with extensions to cover all the
thematic forms mentioned in the last section.
They are couched within a simple unification-
enriched phrase structure formalism. Seman-
tic rules are associated with the syntactic rules
on a rule-to-rule basis. The semantic rules
are instructions for building logical forms of
a typed higher order logic. The semantic
translation of an expression is assembled us-
ing function application and composition, and
by using beta-reduction. The logical forms
the rules built are a type of &amp;quot;intensionless
Montague&amp;quot;, similar to PTQ (Dowty 1981),
but without the intension and extension op-
erators. Here, we are only interested in the
syntactic part of the rules, so the semantics
can be omitted. The following rules couched
in GDE notation will serve as an illustration
</bodyText>
<listItem confidence="0.8486384">
R1. S[type decl] NP[agr Ox] VP[agr Ox]
R2. NP[agr Oa]
Det[agr Oa] Nbar[agr Oa]
R3. Nbar[agr Ox] = N[agr Ox]
R4. VP[agr Oa] = V[agr Oa, subcat np] NP
</listItem>
<bodyText confidence="0.999284666666667">
Here, the prefix &amp;quot;0&amp;quot; denotes a variable.
NP&apos;s are type raised. Syntactic categories,
subcategorisation, and unbounded dependen-
cies, are treated similarly to GPSG (Gaz-
dar 1985). Topicalisation, cleft forms, and
relatives are all treated as problems of un-
bounded dependency, using gap threading tech-
niques. The tricky problems of passives and
dative shift are covered by a version of the
neat treatment presented in Pulman 1987.
This involves the construction of passive and
dative shifted versions of verbs, before inclu-
sion in the rules which combine them with
noun phrases, such as R4. No special struc-
ture rules for passives are needed.
</bodyText>
<sectionHeader confidence="0.990096" genericHeader="method">
6 The generation algorithm
</sectionHeader>
<bodyText confidence="0.9995665">
The current GDE generation system uses a
chart based bottom-up grammar traversal al-
gorithm, similar to that described in Shieber
1988).
The starting point for generation is a log-
ical form involving symbols which represent
</bodyText>
<page confidence="0.998249">
48
</page>
<bodyText confidence="0.981777653846154">
entities in the discourse model of the applica-
tion program. For example &amp;quot;LOVE(ENT1,ENT2
The referring expressions for these entities
are pre-generated and entered in the chart,
along with all the lexical items compatible
with the rest of the logical form.
During generation, chart entries are re-
peatedly combined into larger constituents
via the grammar rules. A semantic filter blocks
any constituents whose semantic formulae are
incompatible with the goal logical form.
7 How the discourse param-
eters are encoded in the
grammar
So, how can the diScourse parameters be em-
bodied in in the feature system of the gram-
mar.
The speech act type of the sentence is in-
troduced at the sentence level using the fea-
tures &amp;quot;sentence-type&amp;quot; and &amp;quot;wh&amp;quot;. Assignments
are as follows :-
Declarative S[type decl)
Question - S[type quest, wh —]
WH-Question - S[type quest, wh
The other parameters, theme, focus, and
emphasis, are connected with entities in the
application program&apos;s discourse model. For
generation, they are added to the initial chart
entries for those entities. Assume, to be-
gin with, that we have a functional feature
for each discourse parameter, &amp;quot;thm&amp;quot;, &amp;quot;foc&amp;quot;
and &amp;quot;emp&amp;quot;, which take the values + or —
as appropriate. Then, given the start logical
form above, assume ENT1 is pre-generated
as &amp;quot;John&amp;quot; and ENT2 as &amp;quot;Mary&amp;quot;. From the
discourse model, We discover that ENT1 is to
be the theme, ENT2 the focus, and that nei-
ther is to receive emphasis. This gives us an
initial chart with the following entries for the
referring expressions :-
John:NP[thm 1-,foc —,emp
Mary:NP[thm —,foc +,emp —]
According to the description of the the-
)&amp;quot; matic system above, a plain active sentence
would be suitable.
12. John loves Mary
We could constrain the generator to pro-
duce just the active form by augmenting the
grammar rules as follows (irrelevant features
will be omitted from the rules; altered rules
retain their original numbers, augmented with
a,b,c ... and so on) :-
</bodyText>
<equation confidence="0.463386666666667">
Ria S NP[thm 4-,foc —,emp —] VP.
R4a VP V[foc —,emp —1
NP[thm —,foc +,emp —].
</equation>
<bodyText confidence="0.999642235294118">
Functional features on the verb will be in-
cluded for completeness, but are not actually
used in the current system.
Here, the NP of R4a is assumed to be the
last constituent in the sentence. Our treat-
ment of passives means that these rules would
generate passive sentences correctly as well,
since there is no separate passive transfor-
mation rule. Rules for intransitive and bi-
transitive verbs could be handled in the same
way. However, the system breaks down when
we introduce VP modifiers. Now, we no longer
know which NP will be last until the VP
has been incorporated into a sentence. This
can be handled by making the focus value of
the NP dependent on a similar feature in the
mother VP, as follows :-
</bodyText>
<equation confidence="0.820251">
Rib S
NP[thm +,foc —,emp —] VP[foc
1Mb VP[foc Of]
V[foc —] NP[thm —,foc Of,emp —]
11.5 VP[foc Of] VP[foc —]
VPMOD[thm foc Of,emp -]
</equation>
<bodyText confidence="0.999430666666667">
This, however, only works if there are no
gaps.If the NP of rule R4b were a gap, and
there were no modifiers, the V would then
carry the focus. This can be handled by thread-
ing the focus feature through the NP. If the
NP turns out to be a trace (that is, the cre-
ation of a gap), the focus value is threaded
through to the V, but if it is a real NP, it
keeps the focus value for itself, and passes
</bodyText>
<page confidence="0.9987">
49
</page>
<bodyText confidence="0.998721733333333">
the value &amp;quot;foc —&amp;quot; to the V. The &amp;quot;foc&amp;quot; feature
is now replaced by &amp;quot;fin&amp;quot; and &amp;quot;font&amp;quot; features.
This allows a gap in the VPMOD as well. If
there is a fronted NP, the theme shifts to it,
from the subject NP. This can be accounted
for by linking the value of &amp;quot;thm&amp;quot; to the sen-
tence. If a fronted element takes the theme,
this is set to —, otherwise it is set to -I- . Be-
low, the topicalisation rule assigns + to the
thm of the fronted NP, and — to the thin
of the subsequent sentence. The thematised
NP receives emphasis as well. Transitive or
bitransitive verbs which ends up as the focus
also receives emphasis. So, we also link the
emp value of such a verb to its &amp;quot;fout&amp;quot; value.
</bodyText>
<table confidence="0.530619888888889">
RO SFIN S[thm +1; Top level
Rlc S[thm Ot]
NP[thm Ut,fin —,emp --1 VP[fin +1
R2a NP[thm at, fin Ofi, fout emp @e]
Det Nbar
R4c VP[fin @fi] = V[fin Ofo,emp —]
NP[thm —, fin 4fi, fout @fo, emp —]
R5a VP[fin @fi] VP[fin MO] VPMOD[thm
—,fin @fi, fout Ofo,emp —]
</table>
<listItem confidence="0.44486925">
1t6 NP[thm —, fin Of, fout Of, emp —]
[] ; trace NP
R7 S = NP[thm -F,fin —,emp +1 S[thm -]
; Topicalisation
R8 VP[fin @fi] = V[fin @fol,emp loll
NP[thm —, fin MO, fout On, emp —]
PP[thm —, fin @fi,fout Ofo,emp -]
; Datives
</listItem>
<bodyText confidence="0.999756846153846">
Now we need to deal with clefting. In this
construction, the theme is shifted from the
front of the sentence to the end, and the fo-
cus shifts to the clefted element, which is also
emphasised. In response to this, we need to
introduce a &amp;quot;shifted theme&amp;quot; feature, &amp;quot;sthm&amp;quot;,
and link the fin feature up to the sentence
category. Once shifted, the theme needs to
be treated just like the focus - landing at the
end of the sentence. That means it needs
threading, and we replace turn with the fea-
tures &amp;quot;tin&amp;quot; and &amp;quot;tout&amp;quot;. Treatment of clefting,
then, causes the following alterations
</bodyText>
<table confidence="0.902353461538462">
ROa SFIN = S[tin +,fin +1
Rid S[tin @t,sthm Os,fin Of]
NP[tin Ot,fin —,emp—] VP[tin @s,fin
Of]
R2b NP[tout fout emp @e] Det
Nbar
R4d VP[tin Oti,fin @fi]
V[tin @to,fin Ofo,emp —]
NP[tin ©ti, tout ©to, fin @fi, fout
emp —]
R5b VP[tin Oti,fin Ofi]
VP[tin Oto,fin Ofo]
VPMOD[tin ato,tout ato,fin @fi,fout
</table>
<equation confidence="0.912582333333333">
Ofo,emp —]
R6b NP[tin at, tout Ot, fin Of, fout Of, emp
—] = [] ; trace NP
R7b S = NP[tin +,fin —,emp +1
S[tin —,sthm —,fin +1
R9 S Pro Aux NP[tin —,fin
</equation>
<bodyText confidence="0.9825075625">
S[type rel,tin —,sthm -F,fin —]
; Clefting rule
Finally, for dative movement, focus stays
at the end of the sentence, (unless a cleft from
is used) but the theme moves to the indirect
object. This can happen if the theme has al-
ready been shifted by a cleft, or if it hasn&apos;t.
This is treated by introducing one final fea-
ture &amp;quot;normal shifted theme&amp;quot; or &amp;quot;nst&amp;quot;. This
feature is set to — if there is a dative shift,
and + otherwise. Then, wherever tin used
to be set to +, it is now takes its value from
the nst feature. The exception is topicalisa-
tion, when dative movement is prevented by
setting nst to —. The rules changes that im-
plement this are as follows :-
</bodyText>
<footnote confidence="0.845860625">
ROb SFIN Skin Od,nst Od,fin +1
Rle S[tin Ot,sthm Os,nst Od,fin Of]
NP[tin Ot,fin —,emp —]
VP[tin Os,nst Od,fin Of]
R4e VP[tin Oti,nst 4-,fin CH]
V[tin Oto,fin Ofo,emp —]
NP[tin ©ti, tout ©to, fin Ofi, fout Ofo,
emp —]
</footnote>
<page confidence="0.923802">
50
</page>
<table confidence="0.827095086956522">
R5c VP[tin Oti,nst Od,fin Ofi]
VP[tin Oto,nst Od,fin Ofo]
VPMOD[tin Oto,tout @to,fin ©Mout
Ofo,emp —]
C2. Mary:
NP[tin Ot, tout Ot,fin fout emp
C3. loves:V
R7b S = NP[tin +,fin —,emp +1
S[tin —,sthm —,nst -F,fin +1
R8a VP[tin Oti,nst +,fin
V[tin Otolfin Ofol,emp fol]
NP[tin ©to, tout Otol,fin @fo, fout On,
emp—}
PP[tin ©ti, tout ©to, fin Ofi,fout Ofo,emp
—] ; threading as normal
R9a S #. Pro Aux NP[tin —,fin -F,emp -F]
S[type rel,tin —,sthm Od,nst ad,fin —]
; Clefting rule
R10 VP[tin -F,tout —,nst —,fin Ofi]
V[tin —,fin Ofol,emp fol]
NP[tin +,fin Ofo, fout Oft, emp —]
NP[tin -,fin Ofi,fout @fo,emp —] ; da-
tive movement
</table>
<subsectionHeader confidence="0.968169">
7.1 Initial feature values
</subsectionHeader>
<bodyText confidence="0.998934142857143">
An NP now carries five functional features, as
opposed to the three we assumed at the start.
They are initially set as follows. If the entity
is theme, we have [tin -F,tout H. If the entity
is focus, we have fin +, fout H. Otherwise,
theme and focus values are threaded, as in
[tin Ot, tout @t, fin Of, fout Of].
</bodyText>
<sectionHeader confidence="0.992494" genericHeader="method">
8 A Simple Example
</sectionHeader>
<construct confidence="0.5798144">
Let the message be :-
LF - LOVE(ENT1,ENT2)
Speech-Act-Type - Declarative
Theme - ENT1
Focus - ENT2
</construct>
<bodyText confidence="0.724379592592593">
ENT1 is pre-generated as the NP &amp;quot;John&amp;quot;
and ENT2 as &amp;quot;Mary&amp;quot;, and this gives the fol-
lowing initial chart entries :-
Cl. John:
NP[tin -F, tout&apos; —,fin @f, Lout @f,emp
C3 represents the entries in the lexicon
which are compatible with the initial logical
form.
From this position, C2 and C3 can be
combined via rule R4e to give the new chart
entry :-
C4 loves Mary:VP[tin Ot, nst fin +1
Then, Cl and C4 can be combined via
rule le to give :-
05 John loves Mary:S[type ded, tin nst
+, fin +1
Other sentence forms are blocked by the
functional features. If the NP &amp;quot;Mary&amp;quot; were
originally assigned &amp;quot;emp the generation
would only be able to succeed by using the
cleft form &amp;quot;It was Mary who was loved by
John&amp;quot;. If &amp;quot;John&amp;quot; were emphasised, genera-
tion would fail: the current system has no
way of emphasising a thematised agent. It
would be necessary to use a different verb, or
use prosodic stress. Neither of these methods
is available in the current system.
</bodyText>
<sectionHeader confidence="0.999291" genericHeader="method">
9 Discussion
</sectionHeader>
<bodyText confidence="0.9932134">
The functional feature system is clearly be-
coming rather complex, a problem which will
only increase with the inclusion of more elab-
orate thematic forms. Further research would
show if this becomes completely unmanagable.
A possible solution to this problem is dis-
cussed in McKeown 1987 in which pragmatic
constraints are added to a FUG grammer.
They show how the constraints can be stated
in one place, rather than duplicated through-
out the feature system.
Certain combinations of initial feature as-
signments cause failure to generate. In these
cases, some form of constraints relaxation will
be necessary.
</bodyText>
<page confidence="0.757305">
5].
</page>
<sectionHeader confidence="0.997558" genericHeader="conclusions">
10 Conclusions
</sectionHeader>
<bodyText confidence="0.99990525">
The addition of &amp;quot;functional&amp;quot; features to a
unification grammar is used to provide con-
trol of syntactic variants during generation.
The use of threading avoids the need for du-
plication of rules, whilst allowing a fairly wide
range of thematic variants. However, the fea-
ture system required quickly becomes com-
plex.
</bodyText>
<sectionHeader confidence="0.987773" genericHeader="acknowledgments">
11 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999839333333333">
This work was made possible by funding from
the Science and Engineering Research Coun-
cil, and Logica U.K. I would like to thank
Marianne McKormick and Steve Pulman for
the insights underlying this work, and John
Levine for much discussion and collaboration.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999953047619048">
[8] Kay, Martin. 1979. Functional Gram-
mar. Proceedings of the Annual Meet-
ing of the Berkley Linguistics Society.
[9] McKeown K.1985. Text Generation.
Cambridge University Press.
[10] McKeown K, and Cecile Paris. 1987.
Functional Unification Grammar Re-
visited. ACL Proceedings.
[11] Pulman, S. 1987. Passives. The pro-
ceedings of the European ACL - Copen-
hagen.
[12] Quirk, R., Greenbaum, S., Leech, G.
and Svartvik, J. (1985) A Comprehen-
sive Grammar of the English Language.
Longman.
[13] Shieber, Stuart M. 1988. A uniform ar-
chitecture for parsing and generation.
Coling proceedings.
[14] Shieber et al. 1989.A semantic head
driven generation algorithm. ACL Pro-
ceedings - Vancouver.
</reference>
<figureCaption confidence="0.827599222222222">
[1] Appelt, Douglas E. 1987. Bidirectional
grammars. TINLAP-3, position pa-
pers. New Mexico State University.
University Press, Cambridge, England.
[2] Bunt, H. 1987. Utterance Generation
from semantic representations aug-
mented with pragmatic information. In
Natural Language Generation by Kem-
pen (Ed.). Martinus Nijhoff.
</figureCaption>
<bodyText confidence="0.448360285714286">
[3] Calder et al. Unification Categorial
Grammar. The Centre for Cognitive
Science, University of Edinburgh.
[4] Creider, C. 1979. On the explanation
of transformations. Syntax and Seman-
tics, Vol 12. By Talmy Givon (Ed.).
Academic Press NY.
</bodyText>
<reference confidence="0.999567777777778">
[51 Dowty, D, It Wall, S Peters. 1981.
Introduction to Montague Semantics.
Reidel, Dordrecht.
[6] Gazdar G, E. Klein, K. Pullum, I.
Sag. 1985. Generalized Phrase Struc-
ture Grammar. Basil Blackwell.
[7] Huddleston 1984. Introduction to the
grammar of English. Cambridge Uni-
versity Press.
</reference>
<page confidence="0.998858">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.273224">
<title confidence="0.996689">SYNTACTIC CHOICE IN LANGUAGE GENERATION</title>
<author confidence="0.999823">Lee Fedder</author>
<affiliation confidence="0.99918">University of Cambridge, Computer Laboratory, Pembroke Street,</affiliation>
<address confidence="0.998307">Cambridge CB2 3QG, England.</address>
<email confidence="0.324081">lffluk.ac.cam.c1</email>
<abstract confidence="0.992633041666667">1 Abstract A considerable amount of study has recently been concentrated on the use of linguistically motivated unification based grammars for sentence generation (see for example Appelt 1987, Calder 1989, Shieber 1988, Shieber et al. 1989). The grammars state correspondences between semantic structures and syntactic ones. In most grammars, several syntactic structures will correspond to each semantic one. It was suggested at a fairly early stage that control over which sentence is generated could be applied by adding &amp;quot;functional&amp;quot; features to the grammar. This idea has been extended in the work presented here. The use of feature threading techniques allows control over a wide range of syntactic structures, in a fairly sophisticated grammar, while avoiding the need for rule duplication even when generating unbounded dependencies. However, we will see that the feature system required quickly becomes complex, and may be difficult to extend to more comprehensive grammars.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional Grammar.</title>
<date>1979</date>
<booktitle>Proceedings of the Annual Meeting of the Berkley Linguistics Society.</booktitle>
<marker>[8]</marker>
<rawString>Kay, Martin. 1979. Functional Grammar. Proceedings of the Annual Meeting of the Berkley Linguistics Society.</rawString>
</citation>
<citation valid="false">
<authors>
<author>McKeown K 1985</author>
</authors>
<title>Text Generation.</title>
<publisher>Cambridge University Press.</publisher>
<marker>[9]</marker>
<rawString>McKeown K.1985. Text Generation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
<author>Cecile Paris</author>
</authors>
<title>Functional Unification Grammar Revisited.</title>
<date>1987</date>
<publisher>ACL Proceedings.</publisher>
<marker>[10]</marker>
<rawString>McKeown K, and Cecile Paris. 1987. Functional Unification Grammar Revisited. ACL Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pulman</author>
</authors>
<date>1987</date>
<booktitle>Passives. The proceedings of the European ACL - Copenhagen.</booktitle>
<marker>[11]</marker>
<rawString>Pulman, S. 1987. Passives. The proceedings of the European ACL - Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<date>1985</date>
<journal>A Comprehensive Grammar of the English Language. Longman.</journal>
<marker>[12]</marker>
<rawString>Quirk, R., Greenbaum, S., Leech, G. and Svartvik, J. (1985) A Comprehensive Grammar of the English Language. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>A uniform architecture for parsing and generation. Coling proceedings.</title>
<date>1988</date>
<marker>[13]</marker>
<rawString>Shieber, Stuart M. 1988. A uniform architecture for parsing and generation. Coling proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shieber</author>
</authors>
<title>1989.A semantic head driven generation algorithm.</title>
<date>1981</date>
<booktitle>ACL Proceedings - Vancouver.</booktitle>
<volume>51</volume>
<location>Reidel, Dordrecht.</location>
<marker>[14]</marker>
<rawString>Shieber et al. 1989.A semantic head driven generation algorithm. ACL Proceedings - Vancouver. [51 Dowty, D, It Wall, S Peters. 1981. Introduction to Montague Semantics. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>K Pullum</author>
<author>I Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Basil Blackwell.</publisher>
<marker>[6]</marker>
<rawString>Gazdar G, E. Klein, K. Pullum, I. Sag. 1985. Generalized Phrase Structure Grammar. Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huddleston</author>
</authors>
<title>Introduction to the grammar of English.</title>
<date>1984</date>
<publisher>Cambridge University Press.</publisher>
<marker>[7]</marker>
<rawString>Huddleston 1984. Introduction to the grammar of English. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>