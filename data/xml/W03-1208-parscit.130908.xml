<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002892">
<title confidence="0.990819">
Question Classification using HDAG Kernel
</title>
<author confidence="0.969436">
Jun Suzuki, Hirotoshi Taira, Yutaka Sasaki, and Eisaku Maeda
</author>
<affiliation confidence="0.870412">
NTT Communication Science Laboratories, NTT Corp.
</affiliation>
<address confidence="0.957645">
2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan
</address>
<email confidence="0.971804">
jun, taira, sasaki, maeda @cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.995072" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999883888888889">
This paper proposes a machine learning
based question classification method us-
ing a kernel function, Hierarchical Di-
rected Acyclic Graph (HDAG) Kernel.
The HDAG Kernel directly accepts struc-
tured natural language data, such as sev-
eral levels of chunks and their relations,
and computes the value of the kernel func-
tion at a practical cost and time while re-
flecting all of these structures. We ex-
amine the proposed method in a ques-
tion classification experiment using 5011
Japanese questions that are labeled by
150 question types. The results demon-
strate that our proposed method improves
the performance of question classification
over that by conventional methods such as
bag-of-words and their combinations.
</bodyText>
<sectionHeader confidence="0.997364" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991808015151515">
Open-domain Question Answering (ODQA) in-
volves the extraction of correct answer(s) to a given
free-form factual question from a large collection
of texts. ODQA has been actively studied all over
the world since the start of the Question Answering
Track at TREC-8 in 1999.
The definition of ODQA tasks at the TREC QA-
Track has been revised and extended year after
year. At first, ODQA followed the Passage Retrieval
method as used at TREC-8. That is, the ODQA task
was to answer a question in the form of strings of
50 bytes or 250 bytes excerpted from a large set of
news wires. Recently, however, the ODQA task is
considered to be a task of extracting exact answers
to a question. For instance, if a QA system is given
the question “When was Queen Victoria born?”, it
should answer “1832”.
Typically, QA systems have the following compo-
nents for achieving ODQA:
Question analysis analyzes a given question and
determines the question type and keywords.
Text retrieval finds the top paragraphs or docu-
ments that match the result of the question anal-
ysis component.
Answer candidate extraction extracts answer can-
didates of the given question from the docu-
ments retrieved by the text retrieval component,
based on the results of the question types.
Answer selection selects the most plausible an-
swer(s) to the given question from among the
answer candidates extracted by the answer can-
didate extraction component.
One of the most important processes of those
listed above is identifying the target of intention in a
given question to determine the type of sought-after
answer. This process of determining the question
type for a given question is usually called question
classification. Without a question type, that is, the
result of question classification, it would be much
more difficult or even nearly infeasible to select cor-
rect answers from among the possible answer can-
didates, which would necessarily be all of the noun
phrases or named entities in the texts. Question clas-
sification provides the benefit of a powerful restric-
tion that reduces to a practical number of the answer
candidates that should be evaluated in the answer se-
lection process.
This work develops a machine learning approach
to question classification (Harabagiu et al., 2000;
Hermjakob, 2001; Li and Roth, 2002). We use the
Hierarchical Directed Acyclic Graph (HDAG) Ker-
nel (Suzuki et al., 2003), which is suited to handle
structured natural language data. It can handle struc-
tures within texts as the features of texts without
converting the structures to the explicit representa-
tion of numerical feature vectors. This framework is
useful for question classification because the works
of (Li and Roth, 2002; Suzuki et al., 2002a) showed
that richer information, such as structural and se-
mantical information inside a given question, im-
proves the question classification performance over
using the information of just simple key terms.
In Section 2, we present the question classifica-
tion problem. In Section 3, we explain our proposed
method for question classification. Finally, in Sec-
tion 4, we describe our experiment and results.
</bodyText>
<sectionHeader confidence="0.987083" genericHeader="method">
2 Question Classification
</sectionHeader>
<bodyText confidence="0.999433">
Question classification is defined as a task that maps
a given question to more than one of question
types (classes).
In the general concept of QA systems, the result
of question classification is used in a downstream
process, answer selection, to select a correct answer
from among the large number of answer candidates
that are extracted from the source documents. The
result of the question classification, that is, the la-
bels of the question types, can reduce the number
of answer candidates. Therefore, we no longer have
to evaluate every noun phrase in the source docu-
ments to see whether it provides a correct answer to
a given question. Evaluating only answer candidates
that match the results of question classification is an
efficient method of obtaining correct answers. Thus,
question classification is an important process of a
QA system. Better performance in question classi-
fication will lead to better total performance of the
QA system.
</bodyText>
<subsectionHeader confidence="0.998956">
2.1 Question Types: Classes of Questions
</subsectionHeader>
<bodyText confidence="0.999986227272727">
Numerous question taxonomies have been defined,
but unfortunately, no standard exists.
In the case of the TREC QA-Track, most systems
have their own question taxonomy, and these are re-
constructed year by year. For example, (Ittycheriah
et al., 2001) defined 31 original question types in
two levels of hierarchical structure. (Harabagiu et
al., 2000) also defined a large hierarchical question
taxonomy, and (Hovy et al., 2001) defined 141 ques-
tion types of a hierarchical question taxonomy.
Within all of these taxonomies, question types are
defined from the viewpoint of the target intention of
the given questions, and they have hierarchical struc-
tures, even though these question taxonomies are de-
fined by different researchers. This because the pur-
pose of question classification is to reduce the large
number of answer candidates by restricting the tar-
get intention via question types. Moreover, it is very
useful to handle question taxonomy constructed in a
hierarchical structure in the downstream processes.
Thus, question types should be the target intention
and constructed in a hierarchical structure.
</bodyText>
<subsectionHeader confidence="0.992251">
2.2 Properties
</subsectionHeader>
<bodyText confidence="0.999968275862069">
Question classification is quite similar to Text Cate-
gorization, which is one of the major tasks in Nat-
ural Language Processing (NLP). These tasks re-
quire classification of the given text to certain de-
fined classes. In general, in the case of text catego-
rization, the given text is one document, such as a
newspaper article, and the classes are the topics of
the articles. In the case of question classification,
a given text is one short question sentence, and the
classes are the target answers corresponding to the
intention of the given question.
However, question classification requires much
more complicated features than text categorization,
as shown by (Li and Roth, 2002). They proved that
question classification needs richer information than
simple key terms (bag-of-words), which usually give
us high performance in text classification. More-
over, the previous work of (Suzuki et al., 2002a)
showed that the sequential patterns constructed by
different levels of attributes, such as words, part-of-
speech (POS) and semantical information, improve
the performance of question classification. The ex-
periments in these previous works indicated that
the structural and semantical features inside ques-
tions have the potential to improve the performance
of question classification. In other words, high-
performance question classification requires us to
extract the structural and semantical features from
the given question.
</bodyText>
<subsectionHeader confidence="0.999817">
2.3 Learning and Classification Task
</subsectionHeader>
<bodyText confidence="0.999953681818182">
This paper focuses on the machine learning ap-
proach to question classification. The machine
learning approach has several advantages over man-
ual methods.
First, the construction of a manual classifier for
questions is a tedious task that requires the analy-
sis of a large number of questions. Moreover, map-
ping questions into question types requires the use
of lexical items and, therefore, an explicit represen-
tation of the mapping may be very large. On the
other hand, machine learning approaches only need
to define features. Finally, the classifier can be more
flexibly reconstructed than a manual one because it
can be trained on a new taxonomy in a very short
time.
As the machine learning algorithm, we chose the
Support Vector Machines (SVMs) (Cortes and Vap-
nik, 1995) because the work of (Joachims, 1998;
Taira and Haruno, 1999) reported state-of-the-art
performance in text categorization as long as ques-
tion classification is a similar process to text catego-
rization.
</bodyText>
<sectionHeader confidence="0.997473" genericHeader="method">
3 HDAG Kernel
</sectionHeader>
<bodyText confidence="0.999988789473684">
Recently, the design of kernel functions has become
a hot topic in the research field of machine learning.
A specific kernel can drastically increase the perfor-
mance of specific tasks. Moreover, a specific kernel
can handle new feature spaces that are difficult to
manage directly with conventional methods.
The HDAG Kernel is a new kernel function that
is designed to easily handle structured natural lan-
guage data. According to the discussion in the pre-
vious section, richer information such as structural
and semantical information is required for high-
performance question classification.
We think that the HDAG Kernel is suitable for
improving the performance of question classifica-
tion: The HDAG Kernel can handle various linguis-
tic structures within texts, such as chunks and their
relations, as the features of the text without convert-
ing such structures to numerical feature vectors ex-
plicitly.
</bodyText>
<subsectionHeader confidence="0.999408">
3.1 Feature Space
</subsectionHeader>
<bodyText confidence="0.999787414634146">
Figure 1 shows examples of the structures within
questions that are handled by the HDAG kernel.
As shown in Figure 1, the HDAG kernel accepts
several levels of chunks and their relations inside the
text. The nodes represent several levels of chunks in-
cluding words, and directed links represent their re-
lations. Suppose and rep-
resent each node. Some nodes have a graph inside
themselves, which are called “non-terminal nodes”.
Each node can have more than one attribute, such
as words, part-of-speech tags, semantic information
like WordNet (Fellbaum, 1998), and class names of
the named entity. Moreover, nodes are allowed to
not have any attribute, in other words, we do not
have to assign attributes to all nodes.
The “attribute sequence” is a sequence of at-
tributes extracted from the node in sub-paths of
HDAGs. One type of attribute sequence becomes
one element in the feature vector. The framework of
the HDAG Kernel allows node skips during the ex-
traction of attribute sequences, and its cost is based
the decay factor , since HDAG Kernel
deals with not only the exact matching of the sub-
structures between HDAGs but also the approximate
structure matching of them.
Explicit representation of feature vectors in
the HDAG kernel can be written as
, where represents the ex-
plicit feature mapping from the HDAG to the feature
vector and represents the number of all possible
types of attribute sequences extracted to the HDAGs.
The value of is the number of occurrences of
the’th attribute sequence in the HDAG , weighted
according to the node skip.
Table 1 shows a example of attribute sequences
that are extracted from the example question in Fig-
ure 1. The symbol in the sub-path column shows
that more than one node skip occurred there. The
parentheses “( )” in the attribute sequence column
represents the boundaries of a node. For example,
attribute sequence “purchased-(NNP-Bush)” is ex-
</bodyText>
<note confidence="0.472287">
Question: George Bush purchased a small interest in which baseball team ?
</note>
<figureCaption confidence="0.999902">
Figure 1: Example of text structure handled by HDAG (From the questions in TREC-10)
</figureCaption>
<figure confidence="0.99745126984127">
George Bush
p1
p2
NNP
PERSON
NP
NNP
p3
purchased
VBD
p4
p6 p7
DT JJ
a
small
p5
NP
interest
NN
p8
in
IN
PP
p9
which
WDT
p11
p10
baseball
NP
NN
p12 p13 p14
team
NN .
?
Question: How far is it from Denver to Aspen ?
q8
q9 q10
q3
q2
How
WRB
ADVP
far
is
VBZ
it
PRP
from
IN
to
TO
?
RB
.
WHADVP
q1 q4 q5 q6 q7
Denver
NNP
LOCATION
Aspen
NNP
LOCATION
</figure>
<tableCaption confidence="0.959482">
Table 1: Examples of attribute sequences, elements
</tableCaption>
<bodyText confidence="0.954424166666667">
of feature vectors, extracted from the example ques-
tion in Figure 1
tracted from sub-path “ - ”,and “NNP-Bush” is
in the node .
The return value of the HDAG Kernel can be de-
fined as:
</bodyText>
<equation confidence="0.891727">
(1)
</equation>
<bodyText confidence="0.999802666666667">
where input objects and are the objects rep-
resented in HDAG and , respectively. Ac-
cording to this formula, the HDAG Kernel calculates
the inner product of the common attribute sequences
weighted according to their node skips and the oc-
currence between the two HDAGs, and .
</bodyText>
<subsectionHeader confidence="0.993222">
3.2 Efficient Calculation Method
</subsectionHeader>
<bodyText confidence="0.987214433333333">
In general, the dimension of the feature space in
equation (1) becomes very high or even infinity. It
might thus be computationally infeasible to generate
feature vector explicitly.
To solve this problem, we focus on the framework
of the kernel functions defined for a discrete struc-
ture, Convolution Kernels (Haussler, 1999). One
of the most remarkable properties of this kernel
methodology is that it can calculate kernel functions
by the “inner products between pairs of objects”
while it retains the original representation of objects.
This means that we do not have to map input objects
to the numerical feature vectors by explicitly repre-
senting them, as long as an efficient calculation for
the inner products between a pair of texts is defined.
However, Convolution Kernels are abstract con-
cepts. The Tree Kernel (Collins and Duffy, 2001)
and String Subsequence Kernel (SSK) (Lodhi et al.,
2002) are examples of instances in the Convolution
Kernels developed in the NLP field.
The HDAG Kernel also use this framework: we
can learn and classify without creating explicit nu-
merical feature vectors like equation (1). The effi-
cient calculation of inner products between HDAGs,
the return value of HDAG Kernel, was defined in a
recursive formulation (Suzuki et al., 2003). This re-
cursive formulation for HDAG Kernel can be rewrit-
ten as “for loops” by using the dynamic program-
ming technique. Finally, the HDAG Kernel can be
calculated in time.
</bodyText>
<figure confidence="0.998244795454545">
attribute sequence: element
PERSON
George
NNP
George-Bush
NNP-Bush
George-NNP
NNP-NNP
...
purchased-(NNP-Bush)
purchased-(PERSON)
purchased-(Bush)
...
purchased-(NP)
...
VBD-(a-small-interest)-(which-baseball-team)
purchased-(NP)-(which-team)
sub-path
-
-
-
...
-
-
-
-
...
- --
---
--
...
value
1
1
1
1
1
1
1
...
1
1
...
...
</figure>
<tableCaption confidence="0.95329">
Table 2: Distribution of 5011 questions over question type hierarchy
</tableCaption>
<table confidence="0.964170039215686">
question type # question type # question type #
0 !TOP 4963 3 LINE 24 3 !POSITION TITLE 97
1 NAME 3190 4 *RAILROAD 3 2 *LANGUAGE 8
2 PERSON 824 4 !ROAD 11 2 *RELIGION 6
3 *LASTNAME 0 4 *WATERWAY 0 1 NATURAL OBJECT 96
3 *MALE FIRSTNAME 1 4 *TUNNEL 1 2 ANIMAL 18
3 *FEMALE FIRSTNAME 2 4 *BRIDGE 1 2 VEGETABLE 15
2 ORGANIZATION 733 3 *PARK 2 2 MINERAL 54
3 COMPANY 119 3 *MONUMENT 3 1 COLOR 10
3 *COMPANY GROUP 0 2 PRODUCT 468 1 TIME TOP 779
3 *MILITARY 4 3 VEHICLE 37 2 TIMEX 652
3 INSTITUTE 26 4 *CAR 8 3 TIME 50
3 *MARKET 0 4 *TRAIN 2 3 DATE 594
3 POLITICAL ORGANIZATION 103 4 *AIRCRAFT 5 3 *ERA 5
4 GOVERNMENT 38 4 *SPACESHIP 8 2 PERIODX 125
4 POLITICAL PARTY 43 4 !SHIP 12 3 *TIME PERIOD 9
4 PUBLIC INSTITUTION 19 3 DRUG 15 3 *DATE PERIOD 9
3 GROUP 96 3 *WEAPON 4 3 *WEEK PERIOD 4
4 !SPORTS TEAM 20 3 *STOCK 0 3 *MONTH PERIOD 6
3 *ETHNIC GROUP 4 3 *CURRENCY 8 3 !YEAR PERIOD 41
3 *NATIONALITY 4 3 AWARD 11 1 NUMEX 882
2 LOCATION 752 3 *THEORY 1 2 MONEY 187
3 GPE 265 3 RULE 66 2 *STOCK INDEX 0
4 CITY 77 3 *SERVICE 2 2 *POINT 9
4 *COUNTY 1 3 *CHARCTER 4 2 PERCENT 94
4 PROVINCE 47 3 METHOD SYSTEM 33 2 MULTIPLICATION 10
4 COUNTRY 116 3 ACTION MOVEMENT 21 2 FREQUENCY 27
3 REGION 23 3 *PLAN 1 2 *RANK 8
3 GEOLOGICAL REGION 22 3 *ACADEMIC 5 2 AGE 58
4 *LANDFORM 9 3 *CATEGORY 0 2 MEASUREMENT 133
4 *WATER FORM 7 3 SPORTS 11 3 PHYSICAL EXTENT 53
4 *SEA 3 3 OFFENCE 10 3 SPACE 18
3 *ASTRAL BODY 5 3 ART 78 3 VOLUME 14
4 *STAR 2 4 *PICTURE 2 3 WEIGHT 22
4 *PLANET 2 4 *BROADCAST PROGRAM 6 3 *SPEED 9
3 ADDRESS 59 4 MOVIE 15 3 *INTENSITY 0
4 POSTAL ADDRESS 24 4 *SHOW 4 3 *TEMPERATURE 7
4 PHONE NUMBER 22 4 MUSIC 13 3 *CALORIE 1
4 *EMAIL 4 3 PRINTING 31 3 *SEISMIC INTENSITY 2
4 *URL 8 4 !BOOK 10 2 COUNTX 326
2 FACILITY 147 4 *NEWSPAPER 7 3 N PERSON 162
3 GOE 99 4 *MAGAZINE 4 3 N ORGANIZATION 49
4 SCHOOL 27 2 DISEASE 44 3 N LOCATION 27
4 *MUSEUM 3 2 EVENT 99 4 *N COUNTRY 9
4 *AMUSEMENT PARK 4 3 *GAMES 8 3 *N FACILITY 6
4 WORSHIP PLACE 10 3 !CONFERENCE 17 3 N PRODUCT 47
4 STATION TOP 12 3 *PHENOMENA 6 3 *N EVENT 8
5 *AIRPORT 6 3 *WAR 3 3 *N ANIMAL 7
5 *STATION 3 3 *NATURAL DISASTER 5 3 *N VEGETABLE 0
5 *PORT 3 3 *CRIME 6 3 *N MINERAL 0
5 *CAR STOP 0 2 TITLE 97 0 *OTHER 48
</table>
<sectionHeader confidence="0.98733" genericHeader="method">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.993804">
4.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999976923076923">
We used three different QA data sets together to
evaluate the performance of our proposed method.
One is the 1011 questions of NTCIR-QAC11, which
were gathered from ’dry-run’, ’formal-run’ and
’additional-run.’ The second is the 2000 questions
described in (Suzuki et al., 2002b). The last one is
the 2000 questions of CRL-QA data2. These three
QA data sets are written in Japanese.
These data were labeled with the 150 question
types that are defined in the CRL-QA data, along
with one additional question type, “OTHER”. Ta-
ble 2 shows all of the question types we used in this
experiment, where represents the depth of the hi-
</bodyText>
<footnote confidence="0.998423">
1http://www.nlp.cs.ritsumei.ac.jp/qac/
2http://www.cs.nyu.edu/˜sekine/PROJECT/CRLQA/
</footnote>
<bodyText confidence="0.997885714285714">
erarchy and # represents the number of questions of
each question type, including the number of ques-
tions in “child question types”.
While considering question classification as a
learning and classification problem, we decided not
to use question types that do not have enough ques-
tions (more than ten questions), indicated by an as-
terisk (*) in front of the name of the question type,
because classifier learning is very difficult with very
few data. In addition, after the above operations, if
only one question type belongs to one parent ques-
tion type, we also deleted it, which is indicated by
an exclamation mark (!). Ultimately, we evaluated
68 question types.
</bodyText>
<subsectionHeader confidence="0.776026">
4.2 Comparison Methods
</subsectionHeader>
<bodyText confidence="0.99893452">
We compared the HDAG Kernel (HDAG) to a base-
line method that is sometimes referred to as the bag-
of-words kernel, a bag-of-words (BOW) with a poly-
nomial kernel (d1: first degree polynomial kernel,
d2: second degree polynomial kernel).
HDAG and BOW differ in how they consider the
structures of a given question. BOW only con-
siders attributes independently (d1) or combinato-
rially (d2) in a given question. On the other hand,
HDAG can consider the structures (relations) of the
attributes in a given question.
We selected SVM for the learning and classifica-
tion algorithm. Additionally, we evaluated the per-
formance using SNoW3 to compare our method to
indirectly the SNoW-based question classifier (Li
and Roth, 2002). Note that BOW was used as fea-
tures for SNoW.
Finally, we compared the performances of
HDAG-SVM, BOW(d2)-SVM, BOW(d1)-SVM,
and BOW-SNoW. The parameters of each com-
parison method were set as follows: The decay
factor was 0.5 for HDAG, and the soft-margin
of all SVM was set to 1. For SNoW, we used
, and . These parameters
were selected based on preliminary experiments.
</bodyText>
<subsectionHeader confidence="0.986321">
4.3 Decision Model
</subsectionHeader>
<bodyText confidence="0.999705904761905">
Since the SVM is a two-class classification method,
we have to make a decision model to determine the
question type of a given question that is adapted for
question classification, which is a multi-class hierar-
chical classification problem.
Figure 2 shows how we constructed the final de-
cision model for question classification.
First, we made 68 SVM classifiers for each ques-
tion type, and then we constructed “one-vs-rest
models” for each node in the hierarchical question
taxonomy. One of the one-vs-rest models was con-
structed by some of the SVM classifiers, which were
the child question types of the focused node. For
example, the one-vs-rest model at the node “TOP”
was constructed by five SVM classifiers: “NAME”,
“NATURAL OBJECT”, “COLOR”, “TIME TOP”
and “NUMEX”. The total number of one-vs-rest
models was 17.
Finally, the decision model was constructed by
setting one-vs-rest models in the hierarchical ques-
tion taxonomy to determine the most plausible ques-
</bodyText>
<footnote confidence="0.906225">
3http://l2r.cs.uiuc.edu/˜cogcomp/cc-software.html
</footnote>
<figureCaption confidence="0.976587">
Figure 2: Hierarchical classifier constructed by
SVM classifiers
</figureCaption>
<bodyText confidence="0.983881">
tion type of a given question.
</bodyText>
<subsectionHeader confidence="0.927036">
4.4 Features
</subsectionHeader>
<bodyText confidence="0.9989485">
We set four feature sets for each comparison
method.
</bodyText>
<listItem confidence="0.990441">
1. words only (W)
2. words and named entities (W+N)
3. words and semantic information (W+S)
4. words, named entities and semantic informa-
tion (W+N+S)
</listItem>
<bodyText confidence="0.999979090909091">
The words were analyzed in basic form, and the
semantic information was obtained from the “Goi-
taikei” (Ikehara et al., 1997), which is similar to
WordNet in English. Words, chunks and their rela-
tions in the texts were analyzed by CaboCha (Kudo
and Matsumoto, 2002), and named entities were an-
alyzed by the SVM-based NE tagger (Isozaki and
Kazawa, 2002).
Note that even when using the same feature sets,
method of how to construct feature spaces are en-
tirely different between HDAG and BOW.
</bodyText>
<subsectionHeader confidence="0.978556">
4.5 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999253666666667">
We evaluated the 5011 questions by using five-
fold cross-validation and used the following two ap-
proaches to evaluate the performance.
</bodyText>
<table confidence="0.865246454545454">
TOP
NAME
NATURAL_OBJECT
NUMEX
PERSON
: one SVM classifier
: one-vs-rest model :
constructed by the SVM
classifiers of child QTs
: label of question type
Dicision Model
</table>
<tableCaption confidence="0.8110994">
Table 3: Results of question classification experi-
ment by five-fold cross-validation
Table 4: Accuracy of each question (Qacc) evalu-
ated at different depths of hierarchy in question tax-
onomy
</tableCaption>
<table confidence="0.9993095">
Macc
W W+N W+S W+N+S
HDAG-SVM 0.862 0.871 0.877 0.882
BOW(d2)-SVM 0.841 0.847 0.847 0.856
BOW(d1)-SVM 0.839 0.843 0.837 0.851
BOW-SNoW 0.760 0.774 0.800 0.808
Qacc
W W+N W+S W+N+S
HDAG-SVM 0.730 0.736 0.742 0.749
BOW(d2)-SVM 0.678 0.691 0.686 0.704
BOW(d1)-SVM 0.679 0.686 0.671 0.694
BOW-SNoW 0.562 0.573 0.614 0.626
</table>
<listItem confidence="0.9834">
1. Average accuracy of each one-vs-rest model
(Macc)
</listItem>
<bodyText confidence="0.999834">
This measure evaluates the performance of
each one-vs-rest model independently. If a one-
vs-rest model classifies a given question cor-
rectly, it scores a 1, otherwise, it scores a 0.
</bodyText>
<listItem confidence="0.875487">
2. Average accuracy of each given question
(Qacc)
</listItem>
<bodyText confidence="0.999975">
This measure evaluates the total performance
of the decision model, the question classifier.
If each given question is classified in a correct
question type, it scores a 1, otherwise, it scores
a 0.
In Qacc, classifying with a correct question type im-
plies that all of the one-vs-rest models from the top
of the hierarchy of the question taxonomy to the
given question type must classify correctly.
</bodyText>
<sectionHeader confidence="0.758043" genericHeader="evaluation">
4.6 Results
</sectionHeader>
<bodyText confidence="0.999905333333333">
Table 3 shows the results of our question classifi-
cation experiment, which is evaluated by five-fold
cross-validation.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999920571428571">
First, we could increase the performance by using
the information on named entities and semantic in-
formation compared to only using the words, which
is the same result given in (Li and Roth, 2002). This
result proved that high-performance question clas-
sification requires not only word features but also
many more types of information in the question.
</bodyText>
<table confidence="0.977256571428571">
# of QTs W W+N W+S W+N+S
HDAG-SVM
1 5 0.946 0.944 0.953 0.948
2 25 0.795 0.794 0.800 0.803
3 55 0.741 0.743 0.751 0.756
4 68 0.730 0.736 0.742 0.749
BOW(d2)-SVM
1 5 0.906 0.914 0.908 0.925
2 25 0.736 0.748 0.748 0.763
3 55 0.687 0.698 0.695 0.712
4 68 0.678 0.691 0.686 0.704
BOW(d1)-SVM
1 5 0.906 0.918 0.905 0.917
2 25 0.736 0.752 0.730 0.752
3 55 0.688 0.697 0.678 0.701
4 68 0.679 0.686 0.671 0.694
BOW-SNoW
1 5 0.862 0.870 0.880 0.896
2 25 0.635 0.640 0.687 0.696
3 55 0.570 0.582 0.623 0.634
4 68 0.562 0.573 0.614 0.626
</table>
<bodyText confidence="0.999474538461539">
Second, our proposed method showed higher per-
formance than any method using BOW. This re-
sult indicates that the structural information in the
question, which includes several levels of chunks
and their relations, must provide powerful features
to classify the target intention of a given question.
We assume that such structural information must
provide shallow semantic information of the text.
Therefore, it is natural to improve the performance
to identify the intention of the question in order to
use the structural information in the manner of our
proposed method.
Table 4 shows the results of Qacc at each depth
of the question taxonomy. The results of depth
represent the total performance measured by Qacc,
considering only the upper levels of question types
in the question taxonomy. If the depth goes lower,
all results show worse performance. There are sev-
eral reasons for this. One problem is the unbalanced
training data, where the lower depth question types
have fewer positive labeled samples (questions) as
shown in table 2. Moreover, during the classifica-
tion process misclassification is multiplied. Conse-
quently, if the upper-level classifier performed mis-
classification, we would no longer get a correct an-
swer, even though a lower-level classifier has the
ability to classify correctly. Thus, using a machine
learning approach (not only SVM) is not suitable
for deep hierarchically structured class labels. We
should arrange a question taxonomy that is suit-
able for machine learning to achieve the total per-
formance of question classification.
The performance by using SVM is better than
that by SNoW, even in handling the same feature of
BOW. One advantage of using SNoW is its much
faster learning and classifying speed than those of
SVM. We should thus select the best approach for
the purpose, depending on whether speed or accu-
racy is needed.
</bodyText>
<sectionHeader confidence="0.999849" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999965272727273">
This paper presents a machine learning approach to
question classification. We proposed the HDAG ker-
nel, a new kernel function, that can easily handle
structured natural language data.
Our experimental results proved that features of
the structure in a given question, which can be com-
puted by the HDAG kernel, are useful for improving
the performance of question classification. This is
because structures inside a text provide the seman-
tic features of question that are required for high-
performance question classification.
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999100179104477">
M. Collins and N. Duffy. 2001. Convolution Kernels
for Natural Language. In Proc. ofNeural Information
Processing Systems (NIPS’2001).
C. Cortes and V. N. Vapnik. 1995. Support Vector Net-
works. Machine Learning, 20:273–297.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
S. Harabagiu, M. Pasca, and S. Maiorano. 2000. FAL-
CON: Boosting Knowledge for Answer Engines. In
Proc. of the 9th Text Retrieval Conference (TREC-9).
NIST.
D. Haussler. 1999. Convolution Kernels on Discrete
Structures. In Technical Report UCS-CRL-99-10. UC
Santa Cruz.
U. Hermjakob. 2001. Parsing and Question Classifica-
tions for Question Answering. In Proc. of the Work-
shop on Open-Domain Question Answering at ACL-
2001. ACL.
E. H. Hovy, L. Gerber, U. Hermjakob, C.-Y. Lin, and
D. Ravichandran. 2001. Toward Semantics-Based
Answer Pinpointing. In Proc. of the Human Language
Technology Conference (HLT2001).
S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo,
H. Nakaiwa, K. Ogura, Y. Oyama, and Y. Hayashi,
editors. 1997. The Semantic Attribute System, Goi-
Taikei — A Japanese Lexicon, volume 1. Iwanami
Publishing. (in Japanese).
H. Isozaki and H. Kazawa. 2002. Efficient Support
Vector Classifiers for Named Entity Recognition. In
Proc. of the 19th International Conference on Compu-
tational Linguistics (COLING 2002), pages 390–396.
A. Ittycheriah, M. Franz, and S. Roukos. 2001. IBM’s
Statistical Question Answering System – TREC-10.
In Proc. of TREC 2001. NIST.
T. Joachims. 1998. Text Categorization with Support
Vector Machines: Learning with Many Relevant Fea-
tures. In Proc. of European Conference on Machine
Learning(ECML ’98), pages 137–142.
T. Kudo and Y. Matsumoto. 2002. Japanese Depen-
dency Analysis using Cascaded Chunking. In Proc.
of the 6th Conference on Natural Language Learning
(CoNLL 2002), pages 63–69.
X. Li and D. Roth. 2002. Learning Question Classi-
fiers. In Proc. of the 19th International Conference
on Computational Linguistics (COLING 2002), pages
556–562.
H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini,
and C. Watkins. 2002. Text Classification Using
String Kernel. Journal ofMachine Learning Research,
2:419–444.
J. Suzuki, Y. Sasaki, and E. Maeda. 2002a. Question
type classification using statistical machine learning.
In Forum on Information Technology (FIT2002), Infor-
mation Technology Letters (in Japanese), pages 89–90.
J. Suzuki, Y. Sasaki, and E. Maeda. 2002b. SVM Answer
Selection for Open-Domain Question Answering. In
Proc. of the 19th International Conference on Compu-
tational Linguistics (COLING 2002), pages 974–980.
J. Suzuki, T. Hirao, Y. Sasaki, and E. Maeda. 2003. Hi-
erarchical directed acyclic graph kernel: Methods for
natural language data. In Proc. of the 41st Annual
Meeting ofthe Associationfor Computational Linguis-
tics (ACL-2003), page to appear.
H. Taira and M. Haruno. 1999. Feature Selection in
SVM Text Categorization. In Proc. of the 16th Con-
ference of the American Association for Artificial In-
telligence (AAAI ’99), pages 480–486.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.759615">
<title confidence="0.999311">Question Classification using HDAG Kernel</title>
<author confidence="0.996272">Jun Suzuki</author>
<author confidence="0.996272">Hirotoshi Taira</author>
<author confidence="0.996272">Yutaka Sasaki</author>
<author confidence="0.996272">Eisaku Maeda</author>
<affiliation confidence="0.997627">NTT Communication Science Laboratories, NTT Corp.</affiliation>
<address confidence="0.965697">2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan</address>
<email confidence="0.797745">taira,sasaki,maeda</email>
<abstract confidence="0.998701157894737">This paper proposes a machine learning based question classification method usa kernel function, Di- Acyclic Graph (HDAG) The HDAG Kernel directly accepts structured natural language data, such as several levels of chunks and their relations, and computes the value of the kernel function at a practical cost and time while reflecting all of these structures. We examine the proposed method in a question classification experiment using 5011 Japanese questions that are labeled by 150 question types. The results demonstrate that our proposed method improves the performance of question classification over that by conventional methods such as their combinations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>Convolution Kernels for Natural Language. In</title>
<date>2001</date>
<booktitle>Proc. ofNeural Information Processing Systems (NIPS’2001).</booktitle>
<contexts>
<context position="13428" citStr="Collins and Duffy, 2001" startWordPosition="2172" endWordPosition="2175">ramework of the kernel functions defined for a discrete structure, Convolution Kernels (Haussler, 1999). One of the most remarkable properties of this kernel methodology is that it can calculate kernel functions by the “inner products between pairs of objects” while it retains the original representation of objects. This means that we do not have to map input objects to the numerical feature vectors by explicitly representing them, as long as an efficient calculation for the inner products between a pair of texts is defined. However, Convolution Kernels are abstract concepts. The Tree Kernel (Collins and Duffy, 2001) and String Subsequence Kernel (SSK) (Lodhi et al., 2002) are examples of instances in the Convolution Kernels developed in the NLP field. The HDAG Kernel also use this framework: we can learn and classify without creating explicit numerical feature vectors like equation (1). The efficient calculation of inner products between HDAGs, the return value of HDAG Kernel, was defined in a recursive formulation (Suzuki et al., 2003). This recursive formulation for HDAG Kernel can be rewritten as “for loops” by using the dynamic programming technique. Finally, the HDAG Kernel can be calculated in time</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>M. Collins and N. Duffy. 2001. Convolution Kernels for Natural Language. In Proc. ofNeural Information Processing Systems (NIPS’2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cortes</author>
<author>V N Vapnik</author>
</authors>
<title>Support Vector Networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<pages>20--273</pages>
<contexts>
<context position="8503" citStr="Cortes and Vapnik, 1995" startWordPosition="1337" endWordPosition="1341">s. First, the construction of a manual classifier for questions is a tedious task that requires the analysis of a large number of questions. Moreover, mapping questions into question types requires the use of lexical items and, therefore, an explicit representation of the mapping may be very large. On the other hand, machine learning approaches only need to define features. Finally, the classifier can be more flexibly reconstructed than a manual one because it can be trained on a new taxonomy in a very short time. As the machine learning algorithm, we chose the Support Vector Machines (SVMs) (Cortes and Vapnik, 1995) because the work of (Joachims, 1998; Taira and Haruno, 1999) reported state-of-the-art performance in text categorization as long as question classification is a similar process to text categorization. 3 HDAG Kernel Recently, the design of kernel functions has become a hot topic in the research field of machine learning. A specific kernel can drastically increase the performance of specific tasks. Moreover, a specific kernel can handle new feature spaces that are difficult to manage directly with conventional methods. The HDAG Kernel is a new kernel function that is designed to easily handle </context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>C. Cortes and V. N. Vapnik. 1995. Support Vector Networks. Machine Learning, 20:273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10198" citStr="Fellbaum, 1998" startWordPosition="1606" endWordPosition="1607">o numerical feature vectors explicitly. 3.1 Feature Space Figure 1 shows examples of the structures within questions that are handled by the HDAG kernel. As shown in Figure 1, the HDAG kernel accepts several levels of chunks and their relations inside the text. The nodes represent several levels of chunks including words, and directed links represent their relations. Suppose and represent each node. Some nodes have a graph inside themselves, which are called “non-terminal nodes”. Each node can have more than one attribute, such as words, part-of-speech tags, semantic information like WordNet (Fellbaum, 1998), and class names of the named entity. Moreover, nodes are allowed to not have any attribute, in other words, we do not have to assign attributes to all nodes. The “attribute sequence” is a sequence of attributes extracted from the node in sub-paths of HDAGs. One type of attribute sequence becomes one element in the feature vector. The framework of the HDAG Kernel allows node skips during the extraction of attribute sequences, and its cost is based the decay factor , since HDAG Kernel deals with not only the exact matching of the substructures between HDAGs but also the approximate structure m</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>M Pasca</author>
<author>S Maiorano</author>
</authors>
<title>FALCON: Boosting Knowledge for Answer Engines.</title>
<date>2000</date>
<booktitle>In Proc. of the 9th Text Retrieval Conference (TREC-9).</booktitle>
<publisher>NIST.</publisher>
<contexts>
<context position="3250" citStr="Harabagiu et al., 2000" startWordPosition="516" endWordPosition="519"> question is usually called question classification. Without a question type, that is, the result of question classification, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts. Question classification provides the benefit of a powerful restriction that reduces to a practical number of the answer candidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification per</context>
<context position="5482" citStr="Harabagiu et al., 2000" startWordPosition="869" endWordPosition="872">cation is an efficient method of obtaining correct answers. Thus, question classification is an important process of a QA system. Better performance in question classification will lead to better total performance of the QA system. 2.1 Question Types: Classes of Questions Numerous question taxonomies have been defined, but unfortunately, no standard exists. In the case of the TREC QA-Track, most systems have their own question taxonomy, and these are reconstructed year by year. For example, (Ittycheriah et al., 2001) defined 31 original question types in two levels of hierarchical structure. (Harabagiu et al., 2000) also defined a large hierarchical question taxonomy, and (Hovy et al., 2001) defined 141 question types of a hierarchical question taxonomy. Within all of these taxonomies, question types are defined from the viewpoint of the target intention of the given questions, and they have hierarchical structures, even though these question taxonomies are defined by different researchers. This because the purpose of question classification is to reduce the large number of answer candidates by restricting the target intention via question types. Moreover, it is very useful to handle question taxonomy co</context>
</contexts>
<marker>Harabagiu, Pasca, Maiorano, 2000</marker>
<rawString>S. Harabagiu, M. Pasca, and S. Maiorano. 2000. FALCON: Boosting Knowledge for Answer Engines. In Proc. of the 9th Text Retrieval Conference (TREC-9). NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Haussler</author>
</authors>
<title>Convolution Kernels on Discrete Structures. In</title>
<date>1999</date>
<tech>Technical Report UCS-CRL-99-10.</tech>
<institution>UC Santa Cruz.</institution>
<contexts>
<context position="12907" citStr="Haussler, 1999" startWordPosition="2089" endWordPosition="2090">cts and are the objects represented in HDAG and , respectively. According to this formula, the HDAG Kernel calculates the inner product of the common attribute sequences weighted according to their node skips and the occurrence between the two HDAGs, and . 3.2 Efficient Calculation Method In general, the dimension of the feature space in equation (1) becomes very high or even infinity. It might thus be computationally infeasible to generate feature vector explicitly. To solve this problem, we focus on the framework of the kernel functions defined for a discrete structure, Convolution Kernels (Haussler, 1999). One of the most remarkable properties of this kernel methodology is that it can calculate kernel functions by the “inner products between pairs of objects” while it retains the original representation of objects. This means that we do not have to map input objects to the numerical feature vectors by explicitly representing them, as long as an efficient calculation for the inner products between a pair of texts is defined. However, Convolution Kernels are abstract concepts. The Tree Kernel (Collins and Duffy, 2001) and String Subsequence Kernel (SSK) (Lodhi et al., 2002) are examples of insta</context>
</contexts>
<marker>Haussler, 1999</marker>
<rawString>D. Haussler. 1999. Convolution Kernels on Discrete Structures. In Technical Report UCS-CRL-99-10. UC Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
</authors>
<title>Parsing and Question Classifications for Question Answering.</title>
<date>2001</date>
<booktitle>In Proc. of the Workshop on Open-Domain Question Answering at ACL2001.</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="3267" citStr="Hermjakob, 2001" startWordPosition="520" endWordPosition="521">led question classification. Without a question type, that is, the result of question classification, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts. Question classification provides the benefit of a powerful restriction that reduces to a practical number of the answer candidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over usi</context>
</contexts>
<marker>Hermjakob, 2001</marker>
<rawString>U. Hermjakob. 2001. Parsing and Question Classifications for Question Answering. In Proc. of the Workshop on Open-Domain Question Answering at ACL2001. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
<author>L Gerber</author>
<author>U Hermjakob</author>
<author>C-Y Lin</author>
<author>D Ravichandran</author>
</authors>
<title>Toward Semantics-Based Answer Pinpointing.</title>
<date>2001</date>
<booktitle>In Proc. of the Human Language Technology Conference (HLT2001).</booktitle>
<contexts>
<context position="5559" citStr="Hovy et al., 2001" startWordPosition="881" endWordPosition="884">ication is an important process of a QA system. Better performance in question classification will lead to better total performance of the QA system. 2.1 Question Types: Classes of Questions Numerous question taxonomies have been defined, but unfortunately, no standard exists. In the case of the TREC QA-Track, most systems have their own question taxonomy, and these are reconstructed year by year. For example, (Ittycheriah et al., 2001) defined 31 original question types in two levels of hierarchical structure. (Harabagiu et al., 2000) also defined a large hierarchical question taxonomy, and (Hovy et al., 2001) defined 141 question types of a hierarchical question taxonomy. Within all of these taxonomies, question types are defined from the viewpoint of the target intention of the given questions, and they have hierarchical structures, even though these question taxonomies are defined by different researchers. This because the purpose of question classification is to reduce the large number of answer candidates by restricting the target intention via question types. Moreover, it is very useful to handle question taxonomy constructed in a hierarchical structure in the downstream processes. Thus, ques</context>
</contexts>
<marker>Hovy, Gerber, Hermjakob, Lin, Ravichandran, 2001</marker>
<rawString>E. H. Hovy, L. Gerber, U. Hermjakob, C.-Y. Lin, and D. Ravichandran. 2001. Toward Semantics-Based Answer Pinpointing. In Proc. of the Human Language Technology Conference (HLT2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ikehara</author>
<author>M Miyazaki</author>
<author>S Shirai</author>
<author>A Yokoo</author>
<author>H Nakaiwa</author>
<author>K Ogura</author>
<author>Y Oyama</author>
<author>Y Hayashi</author>
<author>editors</author>
</authors>
<date>1997</date>
<booktitle>The Semantic Attribute System, GoiTaikei — A Japanese Lexicon,</booktitle>
<volume>1</volume>
<note>Iwanami Publishing. (in Japanese).</note>
<contexts>
<context position="20590" citStr="Ikehara et al., 1997" startWordPosition="3466" endWordPosition="3469">decision model was constructed by setting one-vs-rest models in the hierarchical question taxonomy to determine the most plausible ques3http://l2r.cs.uiuc.edu/˜cogcomp/cc-software.html Figure 2: Hierarchical classifier constructed by SVM classifiers tion type of a given question. 4.4 Features We set four feature sets for each comparison method. 1. words only (W) 2. words and named entities (W+N) 3. words and semantic information (W+S) 4. words, named entities and semantic information (W+N+S) The words were analyzed in basic form, and the semantic information was obtained from the “Goitaikei” (Ikehara et al., 1997), which is similar to WordNet in English. Words, chunks and their relations in the texts were analyzed by CaboCha (Kudo and Matsumoto, 2002), and named entities were analyzed by the SVM-based NE tagger (Isozaki and Kazawa, 2002). Note that even when using the same feature sets, method of how to construct feature spaces are entirely different between HDAG and BOW. 4.5 Evaluation Method We evaluated the 5011 questions by using fivefold cross-validation and used the following two approaches to evaluate the performance. TOP NAME NATURAL_OBJECT NUMEX PERSON : one SVM classifier : one-vs-rest model </context>
</contexts>
<marker>Ikehara, Miyazaki, Shirai, Yokoo, Nakaiwa, Ogura, Oyama, Hayashi, editors, 1997</marker>
<rawString>S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo, H. Nakaiwa, K. Ogura, Y. Oyama, and Y. Hayashi, editors. 1997. The Semantic Attribute System, GoiTaikei — A Japanese Lexicon, volume 1. Iwanami Publishing. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Isozaki</author>
<author>H Kazawa</author>
</authors>
<title>Efficient Support Vector Classifiers for Named Entity Recognition.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics (COLING</booktitle>
<pages>390--396</pages>
<contexts>
<context position="20818" citStr="Isozaki and Kazawa, 2002" startWordPosition="3505" endWordPosition="3508">ructed by SVM classifiers tion type of a given question. 4.4 Features We set four feature sets for each comparison method. 1. words only (W) 2. words and named entities (W+N) 3. words and semantic information (W+S) 4. words, named entities and semantic information (W+N+S) The words were analyzed in basic form, and the semantic information was obtained from the “Goitaikei” (Ikehara et al., 1997), which is similar to WordNet in English. Words, chunks and their relations in the texts were analyzed by CaboCha (Kudo and Matsumoto, 2002), and named entities were analyzed by the SVM-based NE tagger (Isozaki and Kazawa, 2002). Note that even when using the same feature sets, method of how to construct feature spaces are entirely different between HDAG and BOW. 4.5 Evaluation Method We evaluated the 5011 questions by using fivefold cross-validation and used the following two approaches to evaluate the performance. TOP NAME NATURAL_OBJECT NUMEX PERSON : one SVM classifier : one-vs-rest model : constructed by the SVM classifiers of child QTs : label of question type Dicision Model Table 3: Results of question classification experiment by five-fold cross-validation Table 4: Accuracy of each question (Qacc) evaluated a</context>
</contexts>
<marker>Isozaki, Kazawa, 2002</marker>
<rawString>H. Isozaki and H. Kazawa. 2002. Efficient Support Vector Classifiers for Named Entity Recognition. In Proc. of the 19th International Conference on Computational Linguistics (COLING 2002), pages 390–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ittycheriah</author>
<author>M Franz</author>
<author>S Roukos</author>
</authors>
<date>2001</date>
<booktitle>IBM’s Statistical Question Answering System – TREC-10. In Proc. of TREC</booktitle>
<publisher>NIST.</publisher>
<contexts>
<context position="5381" citStr="Ittycheriah et al., 2001" startWordPosition="854" endWordPosition="857">swer to a given question. Evaluating only answer candidates that match the results of question classification is an efficient method of obtaining correct answers. Thus, question classification is an important process of a QA system. Better performance in question classification will lead to better total performance of the QA system. 2.1 Question Types: Classes of Questions Numerous question taxonomies have been defined, but unfortunately, no standard exists. In the case of the TREC QA-Track, most systems have their own question taxonomy, and these are reconstructed year by year. For example, (Ittycheriah et al., 2001) defined 31 original question types in two levels of hierarchical structure. (Harabagiu et al., 2000) also defined a large hierarchical question taxonomy, and (Hovy et al., 2001) defined 141 question types of a hierarchical question taxonomy. Within all of these taxonomies, question types are defined from the viewpoint of the target intention of the given questions, and they have hierarchical structures, even though these question taxonomies are defined by different researchers. This because the purpose of question classification is to reduce the large number of answer candidates by restrictin</context>
</contexts>
<marker>Ittycheriah, Franz, Roukos, 2001</marker>
<rawString>A. Ittycheriah, M. Franz, and S. Roukos. 2001. IBM’s Statistical Question Answering System – TREC-10. In Proc. of TREC 2001. NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machines: Learning with Many Relevant Features.</title>
<date>1998</date>
<booktitle>In Proc. of European Conference on Machine Learning(ECML ’98),</booktitle>
<pages>137--142</pages>
<contexts>
<context position="8539" citStr="Joachims, 1998" startWordPosition="1346" endWordPosition="1347">ier for questions is a tedious task that requires the analysis of a large number of questions. Moreover, mapping questions into question types requires the use of lexical items and, therefore, an explicit representation of the mapping may be very large. On the other hand, machine learning approaches only need to define features. Finally, the classifier can be more flexibly reconstructed than a manual one because it can be trained on a new taxonomy in a very short time. As the machine learning algorithm, we chose the Support Vector Machines (SVMs) (Cortes and Vapnik, 1995) because the work of (Joachims, 1998; Taira and Haruno, 1999) reported state-of-the-art performance in text categorization as long as question classification is a similar process to text categorization. 3 HDAG Kernel Recently, the design of kernel functions has become a hot topic in the research field of machine learning. A specific kernel can drastically increase the performance of specific tasks. Moreover, a specific kernel can handle new feature spaces that are difficult to manage directly with conventional methods. The HDAG Kernel is a new kernel function that is designed to easily handle structured natural language data. Ac</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text Categorization with Support Vector Machines: Learning with Many Relevant Features. In Proc. of European Conference on Machine Learning(ECML ’98), pages 137–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Japanese Dependency Analysis using Cascaded Chunking.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th Conference on Natural Language Learning (CoNLL</booktitle>
<pages>63--69</pages>
<contexts>
<context position="20730" citStr="Kudo and Matsumoto, 2002" startWordPosition="3490" endWordPosition="3493">http://l2r.cs.uiuc.edu/˜cogcomp/cc-software.html Figure 2: Hierarchical classifier constructed by SVM classifiers tion type of a given question. 4.4 Features We set four feature sets for each comparison method. 1. words only (W) 2. words and named entities (W+N) 3. words and semantic information (W+S) 4. words, named entities and semantic information (W+N+S) The words were analyzed in basic form, and the semantic information was obtained from the “Goitaikei” (Ikehara et al., 1997), which is similar to WordNet in English. Words, chunks and their relations in the texts were analyzed by CaboCha (Kudo and Matsumoto, 2002), and named entities were analyzed by the SVM-based NE tagger (Isozaki and Kazawa, 2002). Note that even when using the same feature sets, method of how to construct feature spaces are entirely different between HDAG and BOW. 4.5 Evaluation Method We evaluated the 5011 questions by using fivefold cross-validation and used the following two approaches to evaluate the performance. TOP NAME NATURAL_OBJECT NUMEX PERSON : one SVM classifier : one-vs-rest model : constructed by the SVM classifiers of child QTs : label of question type Dicision Model Table 3: Results of question classification experi</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>T. Kudo and Y. Matsumoto. 2002. Japanese Dependency Analysis using Cascaded Chunking. In Proc. of the 6th Conference on Natural Language Learning (CoNLL 2002), pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>D Roth</author>
</authors>
<title>Learning Question Classifiers.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics (COLING</booktitle>
<pages>556--562</pages>
<contexts>
<context position="3287" citStr="Li and Roth, 2002" startWordPosition="522" endWordPosition="525">sification. Without a question type, that is, the result of question classification, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts. Question classification provides the benefit of a powerful restriction that reduces to a practical number of the answer candidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over using the information o</context>
<context position="6942" citStr="Li and Roth, 2002" startWordPosition="1100" endWordPosition="1103">, which is one of the major tasks in Natural Language Processing (NLP). These tasks require classification of the given text to certain defined classes. In general, in the case of text categorization, the given text is one document, such as a newspaper article, and the classes are the topics of the articles. In the case of question classification, a given text is one short question sentence, and the classes are the target answers corresponding to the intention of the given question. However, question classification requires much more complicated features than text categorization, as shown by (Li and Roth, 2002). They proved that question classification needs richer information than simple key terms (bag-of-words), which usually give us high performance in text classification. Moreover, the previous work of (Suzuki et al., 2002a) showed that the sequential patterns constructed by different levels of attributes, such as words, part-ofspeech (POS) and semantical information, improve the performance of question classification. The experiments in these previous works indicated that the structural and semantical features inside questions have the potential to improve the performance of question classifica</context>
<context position="18746" citStr="Li and Roth, 2002" startWordPosition="3173" endWordPosition="3176">-words kernel, a bag-of-words (BOW) with a polynomial kernel (d1: first degree polynomial kernel, d2: second degree polynomial kernel). HDAG and BOW differ in how they consider the structures of a given question. BOW only considers attributes independently (d1) or combinatorially (d2) in a given question. On the other hand, HDAG can consider the structures (relations) of the attributes in a given question. We selected SVM for the learning and classification algorithm. Additionally, we evaluated the performance using SNoW3 to compare our method to indirectly the SNoW-based question classifier (Li and Roth, 2002). Note that BOW was used as features for SNoW. Finally, we compared the performances of HDAG-SVM, BOW(d2)-SVM, BOW(d1)-SVM, and BOW-SNoW. The parameters of each comparison method were set as follows: The decay factor was 0.5 for HDAG, and the soft-margin of all SVM was set to 1. For SNoW, we used , and . These parameters were selected based on preliminary experiments. 4.3 Decision Model Since the SVM is a two-class classification method, we have to make a decision model to determine the question type of a given question that is adapted for question classification, which is a multi-class hierar</context>
<context position="22813" citStr="Li and Roth, 2002" startWordPosition="3828" endWordPosition="3831">assified in a correct question type, it scores a 1, otherwise, it scores a 0. In Qacc, classifying with a correct question type implies that all of the one-vs-rest models from the top of the hierarchy of the question taxonomy to the given question type must classify correctly. 4.6 Results Table 3 shows the results of our question classification experiment, which is evaluated by five-fold cross-validation. 5 Discussion First, we could increase the performance by using the information on named entities and semantic information compared to only using the words, which is the same result given in (Li and Roth, 2002). This result proved that high-performance question classification requires not only word features but also many more types of information in the question. # of QTs W W+N W+S W+N+S HDAG-SVM 1 5 0.946 0.944 0.953 0.948 2 25 0.795 0.794 0.800 0.803 3 55 0.741 0.743 0.751 0.756 4 68 0.730 0.736 0.742 0.749 BOW(d2)-SVM 1 5 0.906 0.914 0.908 0.925 2 25 0.736 0.748 0.748 0.763 3 55 0.687 0.698 0.695 0.712 4 68 0.678 0.691 0.686 0.704 BOW(d1)-SVM 1 5 0.906 0.918 0.905 0.917 2 25 0.736 0.752 0.730 0.752 3 55 0.688 0.697 0.678 0.701 4 68 0.679 0.686 0.671 0.694 BOW-SNoW 1 5 0.862 0.870 0.880 0.896 2 25</context>
</contexts>
<marker>Li, Roth, 2002</marker>
<rawString>X. Li and D. Roth. 2002. Learning Question Classifiers. In Proc. of the 19th International Conference on Computational Linguistics (COLING 2002), pages 556–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lodhi</author>
<author>C Saunders</author>
<author>J Shawe-Taylor</author>
<author>N Cristianini</author>
<author>C Watkins</author>
</authors>
<title>Text Classification Using String Kernel.</title>
<date>2002</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>2--419</pages>
<contexts>
<context position="13485" citStr="Lodhi et al., 2002" startWordPosition="2181" endWordPosition="2184">ure, Convolution Kernels (Haussler, 1999). One of the most remarkable properties of this kernel methodology is that it can calculate kernel functions by the “inner products between pairs of objects” while it retains the original representation of objects. This means that we do not have to map input objects to the numerical feature vectors by explicitly representing them, as long as an efficient calculation for the inner products between a pair of texts is defined. However, Convolution Kernels are abstract concepts. The Tree Kernel (Collins and Duffy, 2001) and String Subsequence Kernel (SSK) (Lodhi et al., 2002) are examples of instances in the Convolution Kernels developed in the NLP field. The HDAG Kernel also use this framework: we can learn and classify without creating explicit numerical feature vectors like equation (1). The efficient calculation of inner products between HDAGs, the return value of HDAG Kernel, was defined in a recursive formulation (Suzuki et al., 2003). This recursive formulation for HDAG Kernel can be rewritten as “for loops” by using the dynamic programming technique. Finally, the HDAG Kernel can be calculated in time. attribute sequence: element PERSON George NNP George-Bu</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins. 2002. Text Classification Using String Kernel. Journal ofMachine Learning Research, 2:419–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Suzuki</author>
<author>Y Sasaki</author>
<author>E Maeda</author>
</authors>
<title>Question type classification using statistical machine learning.</title>
<date>2002</date>
<booktitle>In Forum on Information Technology (FIT2002), Information Technology Letters (in Japanese),</booktitle>
<pages>89--90</pages>
<contexts>
<context position="3704" citStr="Suzuki et al., 2002" startWordPosition="589" endWordPosition="592">andidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over using the information of just simple key terms. In Section 2, we present the question classification problem. In Section 3, we explain our proposed method for question classification. Finally, in Section 4, we describe our experiment and results. 2 Question Classification Question classification is defined as a task that maps a given question to more than one of question types (classes). In the general concept of QA systems, the result </context>
<context position="7162" citStr="Suzuki et al., 2002" startWordPosition="1132" endWordPosition="1135">one document, such as a newspaper article, and the classes are the topics of the articles. In the case of question classification, a given text is one short question sentence, and the classes are the target answers corresponding to the intention of the given question. However, question classification requires much more complicated features than text categorization, as shown by (Li and Roth, 2002). They proved that question classification needs richer information than simple key terms (bag-of-words), which usually give us high performance in text classification. Moreover, the previous work of (Suzuki et al., 2002a) showed that the sequential patterns constructed by different levels of attributes, such as words, part-ofspeech (POS) and semantical information, improve the performance of question classification. The experiments in these previous works indicated that the structural and semantical features inside questions have the potential to improve the performance of question classification. In other words, highperformance question classification requires us to extract the structural and semantical features from the given question. 2.3 Learning and Classification Task This paper focuses on the machine </context>
<context position="16905" citStr="Suzuki et al., 2002" startWordPosition="2877" endWordPosition="2880">N COUNTRY 9 4 *AMUSEMENT PARK 4 3 *GAMES 8 3 *N FACILITY 6 4 WORSHIP PLACE 10 3 !CONFERENCE 17 3 N PRODUCT 47 4 STATION TOP 12 3 *PHENOMENA 6 3 *N EVENT 8 5 *AIRPORT 6 3 *WAR 3 3 *N ANIMAL 7 5 *STATION 3 3 *NATURAL DISASTER 5 3 *N VEGETABLE 0 5 *PORT 3 3 *CRIME 6 3 *N MINERAL 0 5 *CAR STOP 0 2 TITLE 97 0 *OTHER 48 4 Experiment 4.1 Data Set We used three different QA data sets together to evaluate the performance of our proposed method. One is the 1011 questions of NTCIR-QAC11, which were gathered from ’dry-run’, ’formal-run’ and ’additional-run.’ The second is the 2000 questions described in (Suzuki et al., 2002b). The last one is the 2000 questions of CRL-QA data2. These three QA data sets are written in Japanese. These data were labeled with the 150 question types that are defined in the CRL-QA data, along with one additional question type, “OTHER”. Table 2 shows all of the question types we used in this experiment, where represents the depth of the hi1http://www.nlp.cs.ritsumei.ac.jp/qac/ 2http://www.cs.nyu.edu/˜sekine/PROJECT/CRLQA/ erarchy and # represents the number of questions of each question type, including the number of questions in “child question types”. While considering question classi</context>
</contexts>
<marker>Suzuki, Sasaki, Maeda, 2002</marker>
<rawString>J. Suzuki, Y. Sasaki, and E. Maeda. 2002a. Question type classification using statistical machine learning. In Forum on Information Technology (FIT2002), Information Technology Letters (in Japanese), pages 89–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Suzuki</author>
<author>Y Sasaki</author>
<author>E Maeda</author>
</authors>
<title>SVM Answer Selection for Open-Domain Question Answering.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics (COLING</booktitle>
<pages>974--980</pages>
<contexts>
<context position="3704" citStr="Suzuki et al., 2002" startWordPosition="589" endWordPosition="592">andidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over using the information of just simple key terms. In Section 2, we present the question classification problem. In Section 3, we explain our proposed method for question classification. Finally, in Section 4, we describe our experiment and results. 2 Question Classification Question classification is defined as a task that maps a given question to more than one of question types (classes). In the general concept of QA systems, the result </context>
<context position="7162" citStr="Suzuki et al., 2002" startWordPosition="1132" endWordPosition="1135">one document, such as a newspaper article, and the classes are the topics of the articles. In the case of question classification, a given text is one short question sentence, and the classes are the target answers corresponding to the intention of the given question. However, question classification requires much more complicated features than text categorization, as shown by (Li and Roth, 2002). They proved that question classification needs richer information than simple key terms (bag-of-words), which usually give us high performance in text classification. Moreover, the previous work of (Suzuki et al., 2002a) showed that the sequential patterns constructed by different levels of attributes, such as words, part-ofspeech (POS) and semantical information, improve the performance of question classification. The experiments in these previous works indicated that the structural and semantical features inside questions have the potential to improve the performance of question classification. In other words, highperformance question classification requires us to extract the structural and semantical features from the given question. 2.3 Learning and Classification Task This paper focuses on the machine </context>
<context position="16905" citStr="Suzuki et al., 2002" startWordPosition="2877" endWordPosition="2880">N COUNTRY 9 4 *AMUSEMENT PARK 4 3 *GAMES 8 3 *N FACILITY 6 4 WORSHIP PLACE 10 3 !CONFERENCE 17 3 N PRODUCT 47 4 STATION TOP 12 3 *PHENOMENA 6 3 *N EVENT 8 5 *AIRPORT 6 3 *WAR 3 3 *N ANIMAL 7 5 *STATION 3 3 *NATURAL DISASTER 5 3 *N VEGETABLE 0 5 *PORT 3 3 *CRIME 6 3 *N MINERAL 0 5 *CAR STOP 0 2 TITLE 97 0 *OTHER 48 4 Experiment 4.1 Data Set We used three different QA data sets together to evaluate the performance of our proposed method. One is the 1011 questions of NTCIR-QAC11, which were gathered from ’dry-run’, ’formal-run’ and ’additional-run.’ The second is the 2000 questions described in (Suzuki et al., 2002b). The last one is the 2000 questions of CRL-QA data2. These three QA data sets are written in Japanese. These data were labeled with the 150 question types that are defined in the CRL-QA data, along with one additional question type, “OTHER”. Table 2 shows all of the question types we used in this experiment, where represents the depth of the hi1http://www.nlp.cs.ritsumei.ac.jp/qac/ 2http://www.cs.nyu.edu/˜sekine/PROJECT/CRLQA/ erarchy and # represents the number of questions of each question type, including the number of questions in “child question types”. While considering question classi</context>
</contexts>
<marker>Suzuki, Sasaki, Maeda, 2002</marker>
<rawString>J. Suzuki, Y. Sasaki, and E. Maeda. 2002b. SVM Answer Selection for Open-Domain Question Answering. In Proc. of the 19th International Conference on Computational Linguistics (COLING 2002), pages 974–980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Suzuki</author>
<author>T Hirao</author>
<author>Y Sasaki</author>
<author>E Maeda</author>
</authors>
<title>Hierarchical directed acyclic graph kernel: Methods for natural language data.</title>
<date>2003</date>
<booktitle>In Proc. of the 41st Annual Meeting ofthe Associationfor Computational Linguistics (ACL-2003),</booktitle>
<pages>page</pages>
<note>to appear.</note>
<contexts>
<context position="3371" citStr="Suzuki et al., 2003" startWordPosition="536" endWordPosition="539">n, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts. Question classification provides the benefit of a powerful restriction that reduces to a practical number of the answer candidates that should be evaluated in the answer selection process. This work develops a machine learning approach to question classification (Harabagiu et al., 2000; Hermjakob, 2001; Li and Roth, 2002). We use the Hierarchical Directed Acyclic Graph (HDAG) Kernel (Suzuki et al., 2003), which is suited to handle structured natural language data. It can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors. This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al., 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over using the information of just simple key terms. In Section 2, we present the question classification proble</context>
<context position="13857" citStr="Suzuki et al., 2003" startWordPosition="2241" endWordPosition="2244">m, as long as an efficient calculation for the inner products between a pair of texts is defined. However, Convolution Kernels are abstract concepts. The Tree Kernel (Collins and Duffy, 2001) and String Subsequence Kernel (SSK) (Lodhi et al., 2002) are examples of instances in the Convolution Kernels developed in the NLP field. The HDAG Kernel also use this framework: we can learn and classify without creating explicit numerical feature vectors like equation (1). The efficient calculation of inner products between HDAGs, the return value of HDAG Kernel, was defined in a recursive formulation (Suzuki et al., 2003). This recursive formulation for HDAG Kernel can be rewritten as “for loops” by using the dynamic programming technique. Finally, the HDAG Kernel can be calculated in time. attribute sequence: element PERSON George NNP George-Bush NNP-Bush George-NNP NNP-NNP ... purchased-(NNP-Bush) purchased-(PERSON) purchased-(Bush) ... purchased-(NP) ... VBD-(a-small-interest)-(which-baseball-team) purchased-(NP)-(which-team) sub-path - - - ... - - - - ... - -- --- -- ... value 1 1 1 1 1 1 1 ... 1 1 ... ... Table 2: Distribution of 5011 questions over question type hierarchy question type # question type # </context>
</contexts>
<marker>Suzuki, Hirao, Sasaki, Maeda, 2003</marker>
<rawString>J. Suzuki, T. Hirao, Y. Sasaki, and E. Maeda. 2003. Hierarchical directed acyclic graph kernel: Methods for natural language data. In Proc. of the 41st Annual Meeting ofthe Associationfor Computational Linguistics (ACL-2003), page to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Taira</author>
<author>M Haruno</author>
</authors>
<title>Feature Selection in SVM Text Categorization.</title>
<date>1999</date>
<booktitle>In Proc. of the 16th Conference of the American Association for Artificial Intelligence (AAAI ’99),</booktitle>
<pages>480--486</pages>
<contexts>
<context position="8564" citStr="Taira and Haruno, 1999" startWordPosition="1348" endWordPosition="1351">s is a tedious task that requires the analysis of a large number of questions. Moreover, mapping questions into question types requires the use of lexical items and, therefore, an explicit representation of the mapping may be very large. On the other hand, machine learning approaches only need to define features. Finally, the classifier can be more flexibly reconstructed than a manual one because it can be trained on a new taxonomy in a very short time. As the machine learning algorithm, we chose the Support Vector Machines (SVMs) (Cortes and Vapnik, 1995) because the work of (Joachims, 1998; Taira and Haruno, 1999) reported state-of-the-art performance in text categorization as long as question classification is a similar process to text categorization. 3 HDAG Kernel Recently, the design of kernel functions has become a hot topic in the research field of machine learning. A specific kernel can drastically increase the performance of specific tasks. Moreover, a specific kernel can handle new feature spaces that are difficult to manage directly with conventional methods. The HDAG Kernel is a new kernel function that is designed to easily handle structured natural language data. According to the discussion</context>
</contexts>
<marker>Taira, Haruno, 1999</marker>
<rawString>H. Taira and M. Haruno. 1999. Feature Selection in SVM Text Categorization. In Proc. of the 16th Conference of the American Association for Artificial Intelligence (AAAI ’99), pages 480–486.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>