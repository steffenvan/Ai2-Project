<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9881065">
Exploiting Lexical Expansions and Boolean Compositions for
Web Querying
</title>
<author confidence="0.897435">
Bernardo Magnin&apos; and Roberto Prevete
</author>
<bodyText confidence="0.9044786">
ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica
Via Sommarive
38050 Povo (TN), Italy,
{ magnini I prevete } @irst.itc.it
http://ecate.itc.it:1024/projects/question-answering.html
</bodyText>
<sectionHeader confidence="0.988982" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999791333333333">
This paper describes an experiment aiming at
evaluating the role of NLP based optimizations
(i.e. morphological derivation and synonymy
expansion) in web search strategies. Keywords
and their expansions are composed in two
different Boolean expressions (i.e. expansion
insertion and Cartesian combination) and then
compared with a keyword conjunctive
composition, considered as the baseline.
Results confirm the hypothesis that linguistic
optimizations significantly improve the search
engine performances.
</bodyText>
<sectionHeader confidence="0.97902" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999544724137931">
The purpose of this work was to verify if, and in
which measure, some linguistic optimizations
on the input query can improve the performance
of an existing search engine on the webl.
First of all we tried to determine a proper
baseline to compare the optimized search
strategies. Such a baseline should reflect as
much as possible the average use of the search
engine by typical users when querying the web.
A query is usually composed of a limited
number of keywords (i.e. two or three), in a
lemmatized form, that the search engine
composes by default in a conjunctive
I The results reported in this paper are part of a more
extended project under development at ITC-irst,
which involves a collaboration with Kataweb, an
Italian web portal. We thank both Kataweb and
Inktomi Corporation for kindly having placed the
search engine for the experiments at our disposal.
expression. Starting from this level (we call it
&amp;quot;basic level&amp;quot;) we have designed two more
sophisticated search strategies that introduce a
number of linguistic optimizations over the
keywords and adopt two composition modalities
allowed by the &amp;quot;advanced search&amp;quot; capabilities of
the search engine. One modality (i.e. Keyword
expansion Insertion Search - KIS) first expands
each keyword of the base level with
morphological derivations and synonyms, then
it builds a Boolean expression where each
expansion is added to the base keyword list. The
second modality (i.e. Keyword Cartesian
expansion Search - KCS) adopts the same
expansions of the previous one, but composes a
Boolean expression where all the possible tuples
among the base keywords and expansions are
considered.
The working hypothesis is that the introduction
of lexical expansions should bring an
improvement in the retrieval of relevant
documents. To verify the hypothesis, a
comparative evaluation has been carried out
using the three search modalities described
above over a set of factual questions. The results
of the queries have been manually scored along
a five value scale, with the aim of taking into
account not only the presence in the document
of the answer to the question, but also the
degree of contextual information provided by
the document itself with respect to the question.
Both the presence of the answer and the
contextual information have been estimated by
two relevance functions, one that considers the
document position, the other that does not.
The experiment results confirm that the
introduction of a limited number of lexical
expansions (i.e. 2-3) improves the engine
performance. In addition, the Cartesian
</bodyText>
<page confidence="0.998304">
13
</page>
<bodyText confidence="0.999891531914893">
composition of the expansions behaves
significantly better than the search modality
based on keyword insertion.
Some of the problems that we faced with in this
work have been already discussed in previous
works in the literature. The use of query
expansions for text retrieval is a debated topic.
Voorhees (1998) argues that WordNet derived
query expansions are effective for very short
queries, while they do not bring any
improvements for long queries. From a number
of experiments (Mandala et al., 1998) conclude
that WordNet query expansions can increase
recall but degrade precision performances. Three
reasons are suggested to explain this behavior:
(i) the lack of relations among terms of different
parts of speech in WordNet; (ii) many semantic
relations are not present in WordNet; (iii) proper
names are not included in WordNet. (Gonzalo et
al., 1998) pointed out some more weaknesses of
WordNet for Information Retrieval purposes, in
particular the lack of domain information and
the fact that sense distinctions are excessively
fine-grained for the task. A related topic of
query expansion is query translation, which is
performed in Cross-Language Information
Retrieval (Verdejo et al. 2000).
This work brings additional elements in favor of
the thesis that using linguistic expansions can
improve IR in a web search scenario. In addition
we argue that, to be effective, query expansion
has to be combined with proper search
modalities. The evaluation experiment we
carried out, even within the limitations due to
time and budget constraints, was designed to
take into account the indications that came out
at the recent TREC workshop on Question
Answering (Voorhees, 2000).
The paper is structured as follows. Section 1 and
2 respectively present the modalities for the
linguistic expansion and for the query
composition. Section 3 reports the experimental
setting for the comparative evaluation of the
three search modalities. Section 4 describes and
discusses the results obtained, while in the
conclusions we propose some directions for
future work.
</bodyText>
<sectionHeader confidence="0.881385" genericHeader="method">
1 Lexical expansion
</sectionHeader>
<bodyText confidence="0.999593285714286">
Two kinds of lexical expansion have been used
in the experiment: morphological derivations
and synonym expansions. Both of them try to
expand a &amp;quot;basic-keyword&amp;quot;, that is a keyword
directly derived from a natural language
question. The language used in the experiments
is Italian.
</bodyText>
<subsectionHeader confidence="0.999282">
1.1 Basic keywords
</subsectionHeader>
<bodyText confidence="0.995051">
The idea is that this level of keywords should
reflect as much as possible the words used by an
average user to query a web search engine.
Given a question expressed with a natural
language sentence, its basic keywords are
derived selecting the lemmas for each content
word of the question. Verbs are transformed in
their corresponding nominalization. Furthermore
we decided to consider collocations and
multiwords as single keywords, as most of the
currently available search engines allow the user
to specify &amp;quot;phrases&amp;quot; in a very simple way. In the
experiments presented in the paper multiword
expressions are manually recognized and then
added to the basic keyword list.
Figure 1 shows a couple of questions with their
respective basic keywords.
</bodyText>
<figure confidence="0.691440333333333">
NL-QUESTION: Chi ha inventato la luce
elettrica? (Who invented the electric light?)
BASIC-KEYWORDS: inventore (inventor)
luce_elettrica (electric_light)
NL-QUESTION: Quale Ã¨ ii fiume pi
lungo del mondo? (Which is the longest world
river?)
BASIC-KEYWORDS: flume (river) piii_lungo
(longest) mondo (world)
</figure>
<figureCaption confidence="0.999356">
Figure 1: Basic keywords extraction from questions.
</figureCaption>
<subsectionHeader confidence="0.997067">
1.2 Morphological derivation
</subsectionHeader>
<bodyText confidence="0.999781444444445">
Morphological derivations are considered
because they introduce new lemmas that we
might find in possible correct answers to the
question, improving in this way the engine
recall. For instance, for a question like &amp;quot;Chi ha
inventato la luce elettrica?&amp;quot; (&amp;quot;Who invented the
electric light?&amp;quot;) we can imagine different
contexts for the correct answer, such as &amp;quot;la luce
elettrica fu inventata da Edison&amp;quot; (&amp;quot;Electric light
</bodyText>
<page confidence="0.998272">
14
</page>
<bodyText confidence="0.9999165">
was invented by Edison&amp;quot;), &amp;quot;L&apos;inventore della
luce elettrica fu Edison&amp;quot; (&amp;quot;The inventor of
electric light was Edison&amp;quot;), &amp;quot;L&apos;invenzione della
luce elettrica e dovuta a Edison&amp;quot; (&amp;quot;The invention
of electric light is due to Edison&amp;quot;), where
different morphological derivations of the same
basic keyword &amp;quot;inventore&amp;quot; (&amp;quot;inventor&amp;quot;) appear.
Derivations have been automatically extracted
from an Italian monolingual dictionary (Disc,
1997), and collected without considering the
derivation order (i.e. &amp;quot;inventare&amp;quot; belongs to the
derivation set of &amp;quot;inventore&amp;quot; even if in the actual
derivation it is the noun that derives from the
verb).
</bodyText>
<subsectionHeader confidence="0.979541">
1.3 Synonyms
</subsectionHeader>
<bodyText confidence="0.999926517241379">
Keyword expansion based on synonyms can
potentially improve the system recall, as the
answer to the question might contain synonyms
of the basic keyword. For instance, the answer
to the question &amp;quot;Chi ha inventato la luce
elettrica?&amp;quot; (&amp;quot;Who invented the electric light?&amp;quot;)
might be one among &amp;quot;Lo scopritore della luce
elettrica fu Edison&amp;quot; (&amp;quot;The discoverer of electric
light was Edison&amp;quot;), &amp;quot;L&apos; inventore della
illuminazione elettrica fu Edison&amp;quot; (&amp;quot;The
inventor of electric illumination was Edison&amp;quot;),
&amp;quot;La scopritore della illuminazione elettrica fu
Edison&amp;quot; (&amp;quot;The discoverer of electric
illumination was Edison&amp;quot;), where different
synonyms of &amp;quot;inventore&amp;quot; (&amp;quot;inventor&amp;quot;) and &amp;quot;luce
elettrica&amp;quot; (&amp;quot;electric light&amp;quot;) appear. In the
experiment reported in section 3 Italian
synonyms have been manually extracted from
the ItalianWordnet database (Roventini et a/.,
2000), a further extension of the Italian Wordnet
produced by the EuroWordNet project (Vossen,
1998). Once the correct synset for a basic
keyword is selected, its synonyms are added to
the expansion list. In the near future we plan to
automate the process of synset selection using
word domain disambiguation, a variant of word
sense disambiguation based on subject field
code information added to WordNet (Magnini
and Cavaglia, 2000).
</bodyText>
<subsectionHeader confidence="0.99276">
1.4 Expansion chains
</subsectionHeader>
<bodyText confidence="0.950408666666667">
The expansions described in the previous
sections could be recursively applied to every
lemma derived by a morphological or a
synonym expansion. For example, at the first
expansion level we can pass from &amp;quot;inventore&amp;quot;
&amp;quot;inventor&amp;quot; to its synonym &amp;quot;scopritore&amp;quot;
&amp;quot;discoverer&amp;quot;, from which in turn we can
morphologically derive the noun &amp;quot;discovery&amp;quot;,
and so on (cfr. Figure 2). This would allow the
retrieval of answers such as &amp;quot;La scoperta della
lampada ad incandescenza Ã¨ dovuta a Edison&amp;quot;
(&amp;quot;The discovery of the incandescent lamp is due
to Edison&amp;quot;).
Although in the experiment reported in this
paper we do not use recursive expansions (i.e.
we stop at the first level of the expansion chain),
a long term goal of this work is to verify their
effects on the document relevance.
inventore (inventor)
synonym &gt; scopritore (discoverer),
ideatore (artificer)
</bodyText>
<figure confidence="0.8486168">
derivation invenzione (invention)
synewm scoperta (discoverer)
derivanco
inventare (invent)
1------&gt;sYwnYnE scoprire (discover)
</figure>
<figureCaption confidence="0.997325">
Figure 2: Lexical chain for &amp;quot;inventore&amp;quot; (&amp;quot;inventor&amp;quot;)
</figureCaption>
<sectionHeader confidence="0.825609" genericHeader="method">
2 Query compositions
</sectionHeader>
<bodyText confidence="0.999988153846154">
We wanted to take advantage of the &amp;quot;advanced&amp;quot;
capabilities of the search engine. In particular
we experimented the &amp;quot;Boolean phrase&amp;quot;
modality, which allows the user to submit
queries with keywords composed by means of
logical operators. However we quickly realised
that realistic choices were restricted to disjoint
compositions of short AND clauses (i.e. with a
limited number of elements, typically not more
than four). This constrained us to two
hypothesis, described in sections 2.2 and 2.3,
which have been compared with a baseline
composition strategy, described in 2.1.
</bodyText>
<sectionHeader confidence="0.5629905" genericHeader="method">
2.1 Keyword &amp;quot;AND&amp;quot; composition search
(KAS)
</sectionHeader>
<bodyText confidence="0.968494666666667">
This search strategy corresponds to the default
method that most search engines implement.
Given a list of basic keywords, no expansion is
performed and keywords are composed in an
AND clause. An example is reported in Figure
3.
</bodyText>
<page confidence="0.967208">
15
</page>
<construct confidence="0.396040857142857">
NL-QUESTION: Chi ha inventato la luce
elettrica? (1,1710 invented the electric light?)
BASIC-KEYWORDS: inventore (inventor)
luce_elettrica (elearic_ligh0
EXPANSIONS: ,
COMPOSITION: ( inventore AND
luce_elettrica)
</construct>
<figureCaption confidence="0.999476">
Figure 3: Example of AND composition search
</figureCaption>
<subsectionHeader confidence="0.6026515">
2.2 Keyword expansion insertion search
(KIS)
</subsectionHeader>
<bodyText confidence="0.999894352941176">
In this composition modality a disjunctive
expression is constructed where each disjoint
element is an AND clause formed by the base
keywords plus the insertion of a single
expansion. In addition, to guarantee that at least
the same documents of the KAS modality are
retrieved, both an AND clause with the basic
keywords and all the single basic keywords are
added as disjoint elements. Figure 4 reports an
example. If the AND combination of the basic
keywords produces a non empty set of
documents, then the MS modality should return
the same set of documents rearranged by the
presence of the keyword expansions. What we
expect is an improvement in the position of a
significant document, which is relevant when
huge amounts of documents are retrieved.
</bodyText>
<figure confidence="0.9505446">
OR (inventore AND luce_elettrica AND
scoperta)
OR (inventore AND luce_elettrica AND
inventare)
OR (inventore AND luce_elettrica AND
scoprire)
OR (inventore AND luce_elettrica AND
lampada_a_incandescenza)
OR (inventore AND luce_elettrica)
OR inventore OR luce_elettrica)
</figure>
<listItem confidence="0.633695">
â¢ Figure 4: Example of expansion insertion
composition
</listItem>
<subsectionHeader confidence="0.9869315">
2.3 Keyword Cartesian composition
search (KCS)
</subsectionHeader>
<bodyText confidence="0.996248533333333">
In this composition modality a disjunctive
expression is constructed where each disjoint
element is an AND clause formed by one of the
possible tuple derived by the expansion set of
each base keyword. In addition, to guarantee
that at least the same documents of the KAS
modality are retrieved, the single basic
keywords are added as disjoint elements. Figure
5 reports an example.
As in the previous case we expect that at least
the same results of the KAS search are returned,
because the AND composition of the basic
keywords is guaranteed. We also expect a
possible improvement of the recall, because new
AND clauses are inserted.
</bodyText>
<figure confidence="0.940838432432432">
NL-QUESTION: Chi ha inventato la luce
elettrica?
BASIC-KEYWORDS: inventore
luce_elettrica
EXPANSIONS:
inventore
sYncors
NL-QUESTION: Chi ha inventato la luce
elettrica? (Who invented the electric light?)
BASIC-KEYWORDS: invent ore (inventor)
luce_elettrica (electric_light)
EXPANSIONS:
inventore
daivation
scopritore ideatore
invenzione
I sYmrs &gt; scoperta
scopritore, ideatore
invenzione
1 srcars scoperta
inventare
LIEETTL4 scoprire
luce_elettrica
1-22171321.-larnpada_a_incandescenza
COMPOSITION:
(OR (inventore AND luce_elettrica AND
scopritore)
OR (inventore AND luce_elettrica AND
ideatore)
OR (inventore AND luce_elettrica AND
invenzione)
&amp;dvatim
&gt; inventare
Isr-29-&gt;Yns scoprire
luce_elettrica
LjlnlIE1â* lampada_a_incandescenza
COMPOSITION:
</figure>
<table confidence="0.9768269375">
(OR (inventore AND luce_elettrica)
OR (inventore AND lampada_a_incandescenza)
OR (scopritore AND luce_elettrica)
OR (scopritore AND lampada_a_incandescenza)
OR (ideatore AND luce_elettrica)
OR (ideatore AND lampada_a_incandescenza)
OR (invenzione AND luce_elettrica)
OR (invenzione AND lampada_a_incandescenza)
OR (scoperta AND luce_elettrica)
OR (scoperta AND lampada_a_incandescenza)
16
OR (inventare AND luce_elettrica)
OR (inventare AND lampada_a_incandescenza)
OR (scoprire AND luce_elettrica)
OR (scoprire AND lampada_a_incandescenza)
OR inventore OR luce_elettrica))
</table>
<figureCaption confidence="0.974455">
Figure 5: Example of Cartesian composition search
</figureCaption>
<sectionHeader confidence="0.959798" genericHeader="method">
3 Comparison experiment
</sectionHeader>
<bodyText confidence="0.99667">
This section reports about the problems we
faced with comparing the three search strategies
presented in section 2. The question set, the
document assessment and the scoring used in
the experiment are described.
</bodyText>
<subsectionHeader confidence="0.999717">
3.1 Creating the Question Set
</subsectionHeader>
<bodyText confidence="0.963837">
Initially, a question set of 40 fact-based, short-
answer questions such as &amp;quot;Chi Ã¨ l&apos;autore della
Divina Commedia?&amp;quot; (&amp;quot;Who is the author of The
Divine Comedy?&amp;quot;) was created. Language was
Italian and each question was guaranteed to have
at least one web document that answered the
question. Ambiguous questions (about 15%)
were not eliminated (see Voorhees, 2000 for a
discussion). A total of 20 questions from the
initial question set have been randomly
selected, this way preventing possible bias in
favour of queries that would perform better with
lexical expansions. Figure 6 reports the final
question set of the experiment.
</bodyText>
<table confidence="0.93637336">
1 Chi ha inventato la luce elettrica?
(Who invented the electric light?)
2 Come si chiama l&apos;autore del libro &amp;quot;I
Malavoglia&amp;quot;?
(Who is the author of the book &amp;quot;I
Malavoglia&amp;quot;?)
3 Chi ha scoperto la legge di gravita?
(Who discovered the gravitational law)
4 Chi ha inventato la stampa?
(Who is the inventor of printing)
5 Chi ha vinto il campionato di calcio nel
1985?
(Who won the soccer championship in
1985?)
6 Chi 6 il regista di &amp;quot;I Mostri&amp;quot;
(Who is the director of &amp;quot;I Mostri&amp;quot;)
7 Quale attore ha recitato con Benigni nel film
&amp;quot;11 piccolo Diavolo&amp;quot;?
(Who played with Benigni in the film &amp;quot;II
piccolo Diavolo&amp;quot; ?)
8 Chi ha ucciso John Kennedy?
(Who assassinated John Kennedy?)
9 Chi detiene il recod italiano dei 200 metri?
(Who holds the Italian record for the 200-
meters dash?)
10 Chi 6 stato il primo uomo sulla Luna?
(Who was the first man on the moon?)
11 Chi ha inventato il Lisp?
(Who is the inventor of the Lisp)
12 Premio nobel per la letteratura nel 1998
(1998 Nobel Prize in literature)
13 Quale e il flume piii lungÂ° del mondo?
(Which is the longest river of the world?)
14 In quale squadra di calcio Italiana ha giocato
Van Basten?
(Which Italian soccer team did Van Basten
play in?)
15 Chi ha vinto i mondiali di Calcio nel 1986?
(Who won the World Cup Soccer in 1986?)
16 Chi ha progettato la Reggia di Caserta?
(Who was the architect of the Caserta royal
palace?)
17 Dove 6 nato Alessandro Manzoni?
(Where was Alessandro Manzoni born?)
18 Quale 6 il lago pia grande d&apos;Italia?
(Which is the largest Italian lake?)
19 Chi ha fondato la Microsoft?
(Who is the founder of Microsoft?)
20 Chi 6 il padre della relativita?
(VIzo is the father of the relativity theory?)
</table>
<figureCaption confidence="0.999619">
Figure 6: Question set used in the experiments.
</figureCaption>
<bodyText confidence="0.999880071428571">
Each question was then associated with a
corresponding human-generated set of basic
keywords, resulting in an ordered list of [nl-
question, basic-keywords] pairs. We supposed a
maximum of 3 basic keywords for each
question, obtaining an average of 2.25. This is
in line with (Jansen et al., 1998) where it is
reported that, over a sample of 51.473 queries
submitted to a major search service (Excite), the
average query length was 2.35. Basic keywords
are then expanded with their morphological
derivations and synonyms (see Section 2), with
an average of two expansions for question
(min=0, max=6).
</bodyText>
<subsectionHeader confidence="0.999672">
3.2 Document assessment
</subsectionHeader>
<bodyText confidence="0.9999618">
An automatic query generator has been realised
that, given a question with its basic keywords
and lexical expansions, builds up three queries,
corresponding to KAS, KIS and KCS, and
submits them to the search engine. Results are
collected considering up to ten documents for
search; then the union set is used for the
evaluation experiment. There was no way for
the assessor to relate a document to the search
modality the document was retrieved by. Query
</bodyText>
<page confidence="0.997918">
17
</page>
<bodyText confidence="0.969742625">
generation, web querying and result displaying
were all been made runtime, during the
evaluation session.
Fifteen researchers at ITC-irst were selected as
assessors in the experiment. They were asked to
judge the web documents returned by the query
generator with respect to a given question,
choosing a value among the following five:
1) answer in_context: The answer
corresponding to the question is recovered and
the document context is appropriate. For
example, if the question is &amp;quot;Who is the inventor
of the electric light?&amp;quot; then &amp;quot;Edison&amp;quot; is reported
in the document, in some way, as the inventor of
the electric light and the whole document deals
with inventors and/or Edison&apos;s life.
</bodyText>
<listItem confidence="0.969076096774194">
2) answer no_context: The answer to the
question is recovered but the document context
is not appropriate. (e.g. the document does not
deal neither with inventors or Edison&apos;s life).
3) no_answer in_context: The answer
corresponding to the question is not recovered
but the document context is appropriate.
4) no_answer_no_context: The answer
corresponding to the question is not recovered
and the document context is not appropriate.
5) no_document: the requested document is not
retrieved.
The following instructions were provided to
assessors:
â¢ The judgement has to be based on the
document text only, that is no further links
exploration is allowed.
â¢ If a question is considered ambiguous then
give it just one interpretation and use that
interpretation to judge all question-related
documents consistently. For example, if the
question &amp;quot;Chi 6 il vincitore del Tour de
France?&amp;quot; (&amp;quot;Who is the winner of the Tour
de France?&amp;quot;) is considered ambiguous
because the answer may change over time,
then the assessor could decide that the
correct interpretation is &amp;quot;Who is the winner
of the 1999 Tour de France?&amp;quot; and judge all
the documents consistently.
â¢ A document contains the answer only if it is
explicitly reported in the text. That is, if the
</listItem>
<bodyText confidence="0.904471133333333">
question is &amp;quot;Who is the author of Options?&amp;quot;
it is not sufficient that the string &amp;quot;Robert
Sheckley&amp;quot; or &amp;quot;Sheckley&amp;quot; is in the text, but
the document has to say that Robert
Sheckley is the author of Options.
Each question was judged independently by
three assessors. The number of texts to be
judged for a question ranged from 10 to 18, with
an average of 12. For each question k we
obtained three sets VICAS,k, VKIS,k and VKcs,k of
(pos, assessment) pairs corresponding to the
three search methods, where pos is the position
of the document in the ordered list returned by
the search method, and assessment is the
assessment of one participant.
</bodyText>
<subsectionHeader confidence="0.999967">
3.3 Assessment scoring
</subsectionHeader>
<bodyText confidence="0.999834">
We eliminated all the (pos, assessment) pairs
whose assessment was equal to no_document.
Said i a (pos, assessment) pair belonging to
</bodyText>
<equation confidence="0.9459922">
VKAS,Ic, k or VKCS, k we define:
0 if assessment is no_answer_no_context
1 if assessment is no_ answer_ in_ context
2 if assessment is answer_no _context
3 if assessment is answer_ in_ context
</equation>
<bodyText confidence="0.999635857142857">
Given a question k and a set Vk of (pos,
assessment) pairs corresponding to an ordered
list Lk of documents, to evaluate the relevance of
Lk with respect to k we have defined two
relevance functions, defmed in [1]: f,. that
considers the document position, midi: that does
not.
</bodyText>
<equation confidence="0.96717475">
Ev(i)/ p(i)
f +(k)â ievk
Eli;
j=1
</equation>
<bodyText confidence="0.948763923076923">
where
p(i) is the position of the web document in the
ordered list.
- v(0=a(r(0)*K0+13(40)
a(x), 13(x) : {0,1,2,3) -4 (0,1) are
tuning functions that allow to weight the
assessments.
- m is the maximum length of an ordered list of
web documents.
For each search method we obtained a set of 20
(f, 14.) pairs by the assessing process, i.e., we
obtained 20 (f, f+)KAS, k pairs, 20 (f, f4.)Kis, k pairs
and 20 (f,f+)KCS, k pairs.
</bodyText>
<equation confidence="0.590203333333333">
r(i)
E v(i)
f -(k).
</equation>
<page confidence="0.997287">
18
</page>
<sectionHeader confidence="0.998276" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.9948726">
During the assessing process, some requested
URLs were not retrieved. We have a total of 546
URLs and 516 retrieved web documents,
meaning that about 6% of URLs were not
retrieved (see Table 1).
</bodyText>
<table confidence="0.999604333333333">
KAS MS KCS Total
Total URLs 146 200 200 546
Retrieved 137 191 188 516
URLs
% Retrieved 94% 95% 94% 94%
URLs
</table>
<tableCaption confidence="0.988699">
Table 1: URLs returned by KAS, MS and KCS
methods and URLs retrieved during the assessing
process.
</tableCaption>
<bodyText confidence="0.99754225">
Table 2 shows the assessments on the KAS
search method, which we consider the baseline
of the experiment, being search by keywords a
standard search method on the Web.
Results are presented for three partitions of the
question set. QS1 is the subset of questions
whose number of morphological derivations and
synonyms is higher than three; QS2 is the subset
whose number of lexical expansions is equal to
two or three; QS3 is the subset whose number of
lexical expansions is lower than two. The table
reports the average values of f (i.e. document
order not considered) and (i.e. order
considered) with respect to each partition. The
obtained values, f 0.23 and f., 0.25, indicate
that, on average, about 2 web documents have
an answer in_context assessment and 7 web
documents have no_answer no_context
assessment out of 10 documents returned by this
method.
</bodyText>
<table confidence="0.99675725">
KAS
Mean Sdev
f- f4. f- 1,
(-pos.) (+pos.) (- pos) (+ pos.)
QS1 0.14 0.20 0.20 0.23
QS2 0.37 0.31 0.43 0.34
QS3 0.22 0.23 0.20 0.21
all 0.21 0.23 0.25 0.23
</table>
<tableCaption confidence="0.998065">
Table 2: Mean and standard deviation of the
relevance values f. (without position) and (with
position) of retrieved web documents returned by
KAS method.
</tableCaption>
<bodyText confidence="0.9970516875">
Table 3 reports the relevance values for the
documents retrieved respectively by KIS and
KCS. For MS we have a growth of the 19%
and 13% compared with the KAS method. For
KCS the average growth is 33 % and 22%
compared with KAS. On QS2 there is a
remarkable improvement in the KCS
performances compared with KAS (+59% and
+77%). In this case the average value of is
greater than f, meaning that KCS recovers good
web documents in a better position than KAS.
On QS3 there is also a good performance of
both MS and KCS compared with KAS (+18%
and +17% for KIS, +23% and +17% for KCS).
On the contrary, on the subset QS1 both MS
and KCS performances are comparable to KAS.
</bodyText>
<table confidence="0.9959965">
MS KCS
% KAS % KAS
f- 1+ f f-,
(- pos.) (+ pos.) (- pos.) (+ pos.)
QS1 +7% -15% +7% - 15 %
QS2 -3 % +19 % +59 % +77 %
QS3 +18% +17% +23% +17%
all +19% +13% -1-33% +22%
</table>
<tableCaption confidence="0.9612615">
Table 3 MS and KCS increasing of the average
relevance with respect to KAS.
</tableCaption>
<bodyText confidence="0.998587285714286">
From the data presented here it does not emerge
a clear correlation between the performance of a
search method and the number of lexical
expansions. It can be noted that both MS and
KCS perform quite well, compared with KAS,
on the set of questions having no expansions.
This can be explained because MS and KCS
create queries less restrictive than KAS and are
able to recover the same documents of KAS as
well as other documents that can be meaningful.
In case lexical expansions are present, the best
performance compared with KAS is carried out
by KCS method on question 1 (Figure 6), which
have a total of four derivations and four
synonyms. In this case KAS recovered two
documents and KCS more than ten documents,
improving also the answer in_context
assessments thanks to both the morphological
derivation &amp;quot;invenzione&amp;quot; (&amp;quot;invention&amp;quot;) and the
synonym &amp;quot;lampadina_ elettrica&amp;quot;
(&amp;quot;electric_lamp&amp;quot;).
</bodyText>
<page confidence="0.997303">
19
</page>
<bodyText confidence="0.999708386363636">
It is not clear if synonyms affect search
performance more than morphological
derivation or vice versa. It seems that synonyms
and morphological derivations are significant
expansions in the same way. If we consider the
set of the questions characterised by an
improvement in the KCS and MS performance
compared with KAS performance, then there are
four questions having the number of synonyms
greater than the number of morphological
derivations, three questions having the number
of synonyms lower than the number of
morphological derivations and three questions
having the number of synonyms equal to the
number of morphological derivations (zero
included).
If we consider the set of questions having the
number of synonyms higher than the number of
morphological derivations, then there are four
cases out of eight where MS and KCS enhance
the performance of KAS. If instead we consider
the set of questions having the number of
synonyms lower than the number of
morphological derivations there are three cases
out of six where MS and KCS enhance the
performance of KAS.
Finally, Table 4 synthetically shows how MS
and KCS perform with respect to document
&amp;quot;context retrieval&amp;quot;, that is the degree of
contextual information provided by the
document with respect to the question, no
matter if the answer to the question was present
or not in the document itself. To focus on
context we set the tuning functions a(x) and
0(x) to a(0 )=0, a(1)=1, a(2)=0, a(3)=1/3 and
13(x)=0. The reason for considering a context
retrieval score is that, in case the answer is not
present, context increases the probability that
other relevant documents can be found
following hypertextual links, possibly including
the correct answer to the question.
Results obtained with MS and KCS confirm
that they provide a significant increase (from
31% to 41%) of context retrieval score.
</bodyText>
<table confidence="0.9952714">
% context retrieval increasing with
respect to KAS
1. (- pos.) 1+ (+ pos.)
KIS 37% + 31 %
KCS 41% + 38 %
</table>
<tableCaption confidence="0.917827">
Table 4: KIS and KCS context retrieval increasing
with respect to KAS.
</tableCaption>
<sectionHeader confidence="0.826461" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999975755555555">
A comparative experiment among three search
strategies has been carried out with the aim of
estimating the benefits of lexical expansions and
of composition strategies over the basic
keywords of a query. Results lead us believe
that search strategies that combine a number of
linguistic optimizations with a proper Boolean
composition can improve the performance of an
existing search engine on the web. In particular
given KAS (no expansions, with AND
composition search) as baseline, MS (expansion
insertion search) performs better but one case
(i.e. with expansions greater than 3) and KCS
(Cartesian composition search) performs better
than MS. Furthermore, KCS has a maximum
performance, with expansions equal to 2 or 3,
significantly higher than MS, probably because
KCS retrieves web documents that are not
retrieved by MS, which basically rearranges the
order of KAS documents.
At present we still have no clear data to
determine which number and which kind (i.e.
morphological derivations and synonyms) of
lexical expansions performs better for a single
question, even if all the three search strategies
definitely perform better with questions with a
limited number of expansions (i.e. two or three).
An evaluation that will take into considerations
such variations is planned for the near future. A
crucial related problem for the future is that of
the automatic evaluation of the search strategies
(see Breck et al., 2000), which will enormously
speed up the design and evaluation cycle.
The experiments reported in this paper are part
of a feasibility study for the realisation of a
Natural Language Based search engine on the
Web. At the present state of development, some
steps in the query expansion (i.e. multiword
recognition and synset selection) have been
done manually, while both the keyword
composition and the actual search are automatic
and very efficient. In order to completely
automate the process, the main source of
inefficiency is likely to be keywords
disambiguation in WordNet. The idea is to use a
</bodyText>
<page confidence="0.976329">
20
</page>
<bodyText confidence="0.99919675">
two stage disambiguation algorithm (Voorhees,
1998), based on topic information, which
performs linearly with respect to the number of
words to be disambiguated.
</bodyText>
<sectionHeader confidence="0.994155" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999373981818182">
Breck, E.J., Burger J.D., Ferro L., Hirschman
L., House D., Light M., Mani I (2000) How
to Evaluate Your Question Answering System
Every Day ...and Still Get Real Work Done.
Proceedings of LREC-2000, Second
International Conference on Language
Resources and Evaluation, pp. 1495-1500.
Disc (1997) Dizionario Italiano Sabatini
Coletti, Firenze, Giunti.
Gonzalo J., Verdejo F., Peters C. and Calzolari
N. (1998) Applying Euro Wordnet to Cross-
Language Text Retrieval. Computers and the
Humanities, 32, 2-3, pp. 185-207.
Gonzalo J., Verdejo F., Chugur I., Cigar J.
(1998) Indexing with WordNet synsets can
improve text retrieval. Proceedings of the
Workshop &amp;quot;Usage of Wordnet in NLP
systems&amp;quot; Coling-ACL.
Jansen B. J., Spink A., Bateman J., Saracevic
T. (1998) Real life information retrieval: A
study of user queries on the Web. SIGIR
Forum, 32(1), 5-17.
Magnini B. and Cavaglia G. (2000) Integrating
Subject Field Codes into Wordnet.
Proceedings of LREC-2000, Second
International Conference on Language
Resources and Evaluation, pp. 1413-1418.
Mandala R., Takenobu T. and Hozumi T. (1998)
The Use of WordNet in Information
Retrieval. Proceedings of Coling-ACL.
Roventini A., Alonge A., Bertagna F., Calzolari
N., Magnini B., Martinelli R. (2000)
ItalWordNet, a large semantic database for
Italian. Proceedings of LREC-2000, Second
International Conference on Language
Resources and Evaluation, pp. 783-790.
Verdejo F., Gonzalo J., Penas A., Lopez F.,
Fernandez D. (2000) Evaluating wordnets in
Cross-Language Information Retrieval: the
ITEM search engine. Proceedings of LREC-
2000, Second International Conference on
Language Resources and Evaluation, pp.
1769-1774.
Voorhees, Ellen M., Using WordNet for Text
Retrieval, in Fellbaum C. (1998) WordNet,
an Electronic Lexical Database. MIT Press.
Voorhees, Ellen M. and Tice Dawn M. (2000)
Implementing a Question Answering
Evaluation. Proceedings of the Workshop
&amp;quot;Using Evaluation within HLT Programs:
Results and Trends&amp;quot;, Athens, Greece, May
30, 2000.
Vossen P. (1998) Euro Wordnet: a multilingual
database with lexical semantic networks.
Kluver Academic Publishers.
</reference>
<page confidence="0.999432">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.195683">
<title confidence="0.999967">Exploiting Lexical Expansions and Boolean Compositions</title>
<author confidence="0.840951">Web Querying Bernardo Magnin&apos;</author>
<author confidence="0.840951">Roberto</author>
<affiliation confidence="0.984511">ITC-irst, Istituto per la Ricerca Scientifica e</affiliation>
<address confidence="0.7581585">Via 38050 Povo (TN),</address>
<author confidence="0.43553">magnini</author>
<web confidence="0.993343">http://ecate.itc.it:1024/projects/question-answering.html</web>
<abstract confidence="0.998770384615385">This paper describes an experiment aiming at evaluating the role of NLP based optimizations (i.e. morphological derivation and synonymy expansion) in web search strategies. Keywords and their expansions are composed in two different Boolean expressions (i.e. expansion insertion and Cartesian combination) and then compared with a keyword conjunctive composition, considered as the baseline. Results confirm the hypothesis that linguistic optimizations significantly improve the search engine performances.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E J Breck</author>
<author>J D Burger</author>
<author>L Ferro</author>
<author>L Hirschman</author>
<author>D House</author>
<author>M Light</author>
<author>I Mani</author>
</authors>
<title>How to Evaluate Your Question Answering System Every Day ...and Still Get Real Work Done.</title>
<date>2000</date>
<booktitle>Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1495--1500</pages>
<contexts>
<context position="28894" citStr="Breck et al., 2000" startWordPosition="4574" endWordPosition="4577">etrieved by MS, which basically rearranges the order of KAS documents. At present we still have no clear data to determine which number and which kind (i.e. morphological derivations and synonyms) of lexical expansions performs better for a single question, even if all the three search strategies definitely perform better with questions with a limited number of expansions (i.e. two or three). An evaluation that will take into considerations such variations is planned for the near future. A crucial related problem for the future is that of the automatic evaluation of the search strategies (see Breck et al., 2000), which will enormously speed up the design and evaluation cycle. The experiments reported in this paper are part of a feasibility study for the realisation of a Natural Language Based search engine on the Web. At the present state of development, some steps in the query expansion (i.e. multiword recognition and synset selection) have been done manually, while both the keyword composition and the actual search are automatic and very efficient. In order to completely automate the process, the main source of inefficiency is likely to be keywords disambiguation in WordNet. The idea is to use a 20</context>
</contexts>
<marker>Breck, Burger, Ferro, Hirschman, House, Light, Mani, 2000</marker>
<rawString>Breck, E.J., Burger J.D., Ferro L., Hirschman L., House D., Light M., Mani I (2000) How to Evaluate Your Question Answering System Every Day ...and Still Get Real Work Done. Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation, pp. 1495-1500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Disc</author>
</authors>
<title>Dizionario Italiano Sabatini Coletti,</title>
<date>1997</date>
<location>Firenze, Giunti.</location>
<contexts>
<context position="7767" citStr="Disc, 1997" startWordPosition="1175" endWordPosition="1176"> la luce elettrica?&amp;quot; (&amp;quot;Who invented the electric light?&amp;quot;) we can imagine different contexts for the correct answer, such as &amp;quot;la luce elettrica fu inventata da Edison&amp;quot; (&amp;quot;Electric light 14 was invented by Edison&amp;quot;), &amp;quot;L&apos;inventore della luce elettrica fu Edison&amp;quot; (&amp;quot;The inventor of electric light was Edison&amp;quot;), &amp;quot;L&apos;invenzione della luce elettrica e dovuta a Edison&amp;quot; (&amp;quot;The invention of electric light is due to Edison&amp;quot;), where different morphological derivations of the same basic keyword &amp;quot;inventore&amp;quot; (&amp;quot;inventor&amp;quot;) appear. Derivations have been automatically extracted from an Italian monolingual dictionary (Disc, 1997), and collected without considering the derivation order (i.e. &amp;quot;inventare&amp;quot; belongs to the derivation set of &amp;quot;inventore&amp;quot; even if in the actual derivation it is the noun that derives from the verb). 1.3 Synonyms Keyword expansion based on synonyms can potentially improve the system recall, as the answer to the question might contain synonyms of the basic keyword. For instance, the answer to the question &amp;quot;Chi ha inventato la luce elettrica?&amp;quot; (&amp;quot;Who invented the electric light?&amp;quot;) might be one among &amp;quot;Lo scopritore della luce elettrica fu Edison&amp;quot; (&amp;quot;The discoverer of electric light was Edison&amp;quot;), &amp;quot;L&apos; i</context>
</contexts>
<marker>Disc, 1997</marker>
<rawString>Disc (1997) Dizionario Italiano Sabatini Coletti, Firenze, Giunti.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejo</author>
<author>C Peters</author>
<author>N Calzolari</author>
</authors>
<title>Applying Euro Wordnet to CrossLanguage Text Retrieval.</title>
<date>1998</date>
<journal>Computers and the Humanities,</journal>
<volume>32</volume>
<pages>2--3</pages>
<contexts>
<context position="4268" citStr="Gonzalo et al., 1998" startWordPosition="648" endWordPosition="651">query expansions for text retrieval is a debated topic. Voorhees (1998) argues that WordNet derived query expansions are effective for very short queries, while they do not bring any improvements for long queries. From a number of experiments (Mandala et al., 1998) conclude that WordNet query expansions can increase recall but degrade precision performances. Three reasons are suggested to explain this behavior: (i) the lack of relations among terms of different parts of speech in WordNet; (ii) many semantic relations are not present in WordNet; (iii) proper names are not included in WordNet. (Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. A related topic of query expansion is query translation, which is performed in Cross-Language Information Retrieval (Verdejo et al. 2000). This work brings additional elements in favor of the thesis that using linguistic expansions can improve IR in a web search scenario. In addition we argue that, to be effective, query expansion has to be combined with proper search modalities. The evaluat</context>
</contexts>
<marker>Gonzalo, Verdejo, Peters, Calzolari, 1998</marker>
<rawString>Gonzalo J., Verdejo F., Peters C. and Calzolari N. (1998) Applying Euro Wordnet to CrossLanguage Text Retrieval. Computers and the Humanities, 32, 2-3, pp. 185-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejo</author>
<author>I Chugur</author>
<author>J Cigar</author>
</authors>
<title>Indexing with WordNet synsets can improve text retrieval.</title>
<date>1998</date>
<booktitle>Proceedings of the Workshop &amp;quot;Usage of Wordnet in NLP systems&amp;quot; Coling-ACL.</booktitle>
<contexts>
<context position="4268" citStr="Gonzalo et al., 1998" startWordPosition="648" endWordPosition="651">query expansions for text retrieval is a debated topic. Voorhees (1998) argues that WordNet derived query expansions are effective for very short queries, while they do not bring any improvements for long queries. From a number of experiments (Mandala et al., 1998) conclude that WordNet query expansions can increase recall but degrade precision performances. Three reasons are suggested to explain this behavior: (i) the lack of relations among terms of different parts of speech in WordNet; (ii) many semantic relations are not present in WordNet; (iii) proper names are not included in WordNet. (Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. A related topic of query expansion is query translation, which is performed in Cross-Language Information Retrieval (Verdejo et al. 2000). This work brings additional elements in favor of the thesis that using linguistic expansions can improve IR in a web search scenario. In addition we argue that, to be effective, query expansion has to be combined with proper search modalities. The evaluat</context>
</contexts>
<marker>Gonzalo, Verdejo, Chugur, Cigar, 1998</marker>
<rawString>Gonzalo J., Verdejo F., Chugur I., Cigar J. (1998) Indexing with WordNet synsets can improve text retrieval. Proceedings of the Workshop &amp;quot;Usage of Wordnet in NLP systems&amp;quot; Coling-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Jansen</author>
<author>A Spink</author>
<author>J Bateman</author>
<author>T Saracevic</author>
</authors>
<title>Real life information retrieval: A study of user queries on the Web.</title>
<date>1998</date>
<journal>SIGIR Forum,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>5--17</pages>
<contexts>
<context position="17522" citStr="Jansen et al., 1998" startWordPosition="2655" endWordPosition="2658">dro Manzoni? (Where was Alessandro Manzoni born?) 18 Quale 6 il lago pia grande d&apos;Italia? (Which is the largest Italian lake?) 19 Chi ha fondato la Microsoft? (Who is the founder of Microsoft?) 20 Chi 6 il padre della relativita? (VIzo is the father of the relativity theory?) Figure 6: Question set used in the experiments. Each question was then associated with a corresponding human-generated set of basic keywords, resulting in an ordered list of [nlquestion, basic-keywords] pairs. We supposed a maximum of 3 basic keywords for each question, obtaining an average of 2.25. This is in line with (Jansen et al., 1998) where it is reported that, over a sample of 51.473 queries submitted to a major search service (Excite), the average query length was 2.35. Basic keywords are then expanded with their morphological derivations and synonyms (see Section 2), with an average of two expansions for question (min=0, max=6). 3.2 Document assessment An automatic query generator has been realised that, given a question with its basic keywords and lexical expansions, builds up three queries, corresponding to KAS, KIS and KCS, and submits them to the search engine. Results are collected considering up to ten documents f</context>
</contexts>
<marker>Jansen, Spink, Bateman, Saracevic, 1998</marker>
<rawString>Jansen B. J., Spink A., Bateman J., Saracevic T. (1998) Real life information retrieval: A study of user queries on the Web. SIGIR Forum, 32(1), 5-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglia</author>
</authors>
<title>Integrating Subject Field Codes into Wordnet.</title>
<date>2000</date>
<booktitle>Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1413--1418</pages>
<contexts>
<context position="9256" citStr="Magnini and Cavaglia, 2000" startWordPosition="1395" endWordPosition="1398">ntor&amp;quot;) and &amp;quot;luce elettrica&amp;quot; (&amp;quot;electric light&amp;quot;) appear. In the experiment reported in section 3 Italian synonyms have been manually extracted from the ItalianWordnet database (Roventini et a/., 2000), a further extension of the Italian Wordnet produced by the EuroWordNet project (Vossen, 1998). Once the correct synset for a basic keyword is selected, its synonyms are added to the expansion list. In the near future we plan to automate the process of synset selection using word domain disambiguation, a variant of word sense disambiguation based on subject field code information added to WordNet (Magnini and Cavaglia, 2000). 1.4 Expansion chains The expansions described in the previous sections could be recursively applied to every lemma derived by a morphological or a synonym expansion. For example, at the first expansion level we can pass from &amp;quot;inventore&amp;quot; &amp;quot;inventor&amp;quot; to its synonym &amp;quot;scopritore&amp;quot; &amp;quot;discoverer&amp;quot;, from which in turn we can morphologically derive the noun &amp;quot;discovery&amp;quot;, and so on (cfr. Figure 2). This would allow the retrieval of answers such as &amp;quot;La scoperta della lampada ad incandescenza Ã¨ dovuta a Edison&amp;quot; (&amp;quot;The discovery of the incandescent lamp is due to Edison&amp;quot;). Although in the experiment reported </context>
</contexts>
<marker>Magnini, Cavaglia, 2000</marker>
<rawString>Magnini B. and Cavaglia G. (2000) Integrating Subject Field Codes into Wordnet. Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation, pp. 1413-1418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mandala</author>
<author>T Takenobu</author>
<author>T Hozumi</author>
</authors>
<title>The Use of WordNet in Information Retrieval.</title>
<date>1998</date>
<booktitle>Proceedings of Coling-ACL.</booktitle>
<contexts>
<context position="3912" citStr="Mandala et al., 1998" startWordPosition="593" endWordPosition="596">f a limited number of lexical expansions (i.e. 2-3) improves the engine performance. In addition, the Cartesian 13 composition of the expansions behaves significantly better than the search modality based on keyword insertion. Some of the problems that we faced with in this work have been already discussed in previous works in the literature. The use of query expansions for text retrieval is a debated topic. Voorhees (1998) argues that WordNet derived query expansions are effective for very short queries, while they do not bring any improvements for long queries. From a number of experiments (Mandala et al., 1998) conclude that WordNet query expansions can increase recall but degrade precision performances. Three reasons are suggested to explain this behavior: (i) the lack of relations among terms of different parts of speech in WordNet; (ii) many semantic relations are not present in WordNet; (iii) proper names are not included in WordNet. (Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. A related topic of query expansion is </context>
</contexts>
<marker>Mandala, Takenobu, Hozumi, 1998</marker>
<rawString>Mandala R., Takenobu T. and Hozumi T. (1998) The Use of WordNet in Information Retrieval. Proceedings of Coling-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Roventini</author>
<author>A Alonge</author>
<author>F Bertagna</author>
<author>N Calzolari</author>
<author>B Magnini</author>
<author>R Martinelli</author>
</authors>
<title>ItalWordNet, a large semantic database for Italian.</title>
<date>2000</date>
<booktitle>Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>783--790</pages>
<marker>Roventini, Alonge, Bertagna, Calzolari, Magnini, Martinelli, 2000</marker>
<rawString>Roventini A., Alonge A., Bertagna F., Calzolari N., Magnini B., Martinelli R. (2000) ItalWordNet, a large semantic database for Italian. Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation, pp. 783-790.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Verdejo</author>
<author>J Gonzalo</author>
<author>A Penas</author>
<author>F Lopez</author>
<author>D Fernandez</author>
</authors>
<title>Evaluating wordnets in Cross-Language Information Retrieval: the ITEM search engine.</title>
<date>2000</date>
<booktitle>Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1769--1774</pages>
<contexts>
<context position="4611" citStr="Verdejo et al. 2000" startWordPosition="698" endWordPosition="701">on performances. Three reasons are suggested to explain this behavior: (i) the lack of relations among terms of different parts of speech in WordNet; (ii) many semantic relations are not present in WordNet; (iii) proper names are not included in WordNet. (Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for Information Retrieval purposes, in particular the lack of domain information and the fact that sense distinctions are excessively fine-grained for the task. A related topic of query expansion is query translation, which is performed in Cross-Language Information Retrieval (Verdejo et al. 2000). This work brings additional elements in favor of the thesis that using linguistic expansions can improve IR in a web search scenario. In addition we argue that, to be effective, query expansion has to be combined with proper search modalities. The evaluation experiment we carried out, even within the limitations due to time and budget constraints, was designed to take into account the indications that came out at the recent TREC workshop on Question Answering (Voorhees, 2000). The paper is structured as follows. Section 1 and 2 respectively present the modalities for the linguistic expansion</context>
</contexts>
<marker>Verdejo, Gonzalo, Penas, Lopez, Fernandez, 2000</marker>
<rawString>Verdejo F., Gonzalo J., Penas A., Lopez F., Fernandez D. (2000) Evaluating wordnets in Cross-Language Information Retrieval: the ITEM search engine. Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation, pp. 1769-1774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Using WordNet for Text Retrieval, in Fellbaum C.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3718" citStr="Voorhees (1998)" startWordPosition="564" endWordPosition="565">extual information have been estimated by two relevance functions, one that considers the document position, the other that does not. The experiment results confirm that the introduction of a limited number of lexical expansions (i.e. 2-3) improves the engine performance. In addition, the Cartesian 13 composition of the expansions behaves significantly better than the search modality based on keyword insertion. Some of the problems that we faced with in this work have been already discussed in previous works in the literature. The use of query expansions for text retrieval is a debated topic. Voorhees (1998) argues that WordNet derived query expansions are effective for very short queries, while they do not bring any improvements for long queries. From a number of experiments (Mandala et al., 1998) conclude that WordNet query expansions can increase recall but degrade precision performances. Three reasons are suggested to explain this behavior: (i) the lack of relations among terms of different parts of speech in WordNet; (ii) many semantic relations are not present in WordNet; (iii) proper names are not included in WordNet. (Gonzalo et al., 1998) pointed out some more weaknesses of WordNet for I</context>
</contexts>
<marker>Voorhees, 1998</marker>
<rawString>Voorhees, Ellen M., Using WordNet for Text Retrieval, in Fellbaum C. (1998) WordNet, an Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
<author>Tice Dawn M</author>
</authors>
<title>Implementing a Question Answering Evaluation. Proceedings of the Workshop &amp;quot;Using Evaluation within HLT Programs: Results and Trends&amp;quot;,</title>
<date>2000</date>
<location>Athens, Greece,</location>
<marker>Voorhees, M, 2000</marker>
<rawString>Voorhees, Ellen M. and Tice Dawn M. (2000) Implementing a Question Answering Evaluation. Proceedings of the Workshop &amp;quot;Using Evaluation within HLT Programs: Results and Trends&amp;quot;, Athens, Greece, May 30, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>Euro Wordnet: a multilingual database with lexical semantic networks.</title>
<date>1998</date>
<publisher>Kluver Academic Publishers.</publisher>
<contexts>
<context position="8922" citStr="Vossen, 1998" startWordPosition="1343" endWordPosition="1344">on&amp;quot; (&amp;quot;The discoverer of electric light was Edison&amp;quot;), &amp;quot;L&apos; inventore della illuminazione elettrica fu Edison&amp;quot; (&amp;quot;The inventor of electric illumination was Edison&amp;quot;), &amp;quot;La scopritore della illuminazione elettrica fu Edison&amp;quot; (&amp;quot;The discoverer of electric illumination was Edison&amp;quot;), where different synonyms of &amp;quot;inventore&amp;quot; (&amp;quot;inventor&amp;quot;) and &amp;quot;luce elettrica&amp;quot; (&amp;quot;electric light&amp;quot;) appear. In the experiment reported in section 3 Italian synonyms have been manually extracted from the ItalianWordnet database (Roventini et a/., 2000), a further extension of the Italian Wordnet produced by the EuroWordNet project (Vossen, 1998). Once the correct synset for a basic keyword is selected, its synonyms are added to the expansion list. In the near future we plan to automate the process of synset selection using word domain disambiguation, a variant of word sense disambiguation based on subject field code information added to WordNet (Magnini and Cavaglia, 2000). 1.4 Expansion chains The expansions described in the previous sections could be recursively applied to every lemma derived by a morphological or a synonym expansion. For example, at the first expansion level we can pass from &amp;quot;inventore&amp;quot; &amp;quot;inventor&amp;quot; to its synonym &amp;quot;</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen P. (1998) Euro Wordnet: a multilingual database with lexical semantic networks. Kluver Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>