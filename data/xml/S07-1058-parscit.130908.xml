<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.397885">
<title confidence="0.994483">
PSNUS: Web People Name Disambiguation by Simple Clustering
with Rich Features
</title>
<author confidence="0.998421">
Ergin Elmacioglu&apos; Yee Fan Tan2 Su Yan&apos; Min-Yen Kan2 Dongwon Lee&apos;
</author>
<affiliation confidence="0.999631">
&apos;The Pennsylvania State University, USA
2National University of Singapore, Singapore
</affiliation>
<email confidence="0.998501">
{ergin,syan,dongwon}@psu.edu, {tanyeefa,kanmy}@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99968125">
We describe about the system description of
the PSNUS team for the SemEval-2007 Web
People Search Task. The system is based
on the clustering of the web pages by us-
ing a variety of features extracted and gen-
erated from the data provided. This system
achieves Fα=0.5 = 0.75 and Fα=0.2 = 0.78
for the final test data set of the task.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999993034482759">
We consider the problem of disambiguating person
names in a Web searching scenario as described by
the Web People Search Task in SemEval 2007 (Ar-
tiles et al., 2007). Here, the system receives as in-
put a set of web pages retrieved from a search en-
gine using a given person name as a query. The goal
is to determine how many different people are rep-
resented for that name in the input web pages, and
correctly assign each namesake to its corresponding
subset of web pages.
There are many challenges towards an effective
solution. We are to correctly estimate the number of
namesakes for a given person name and group doc-
uments referring to the same individual. Moreover,
the information sources to be processed are unstruc-
tured web pages and there is no certain way of cor-
rectly establishing a relation between any two web
pages belonging to the same or different individuals.
We have taken several approaches to analyze dif-
ferent sources of information provided with the in-
put data, and also compared strategies to combine
these individual features together. The configuration
that achieved the best performance (which were sub-
mitted for our run) used a single named entity fea-
ture as input to clustering. In the remainder of this
paper, we first describe our system in terms of the
clustering approach used and alternative features in-
vestigated. We then analyze the results on the train-
ing set before concluding the paper.
</bodyText>
<sectionHeader confidence="0.929192" genericHeader="method">
2 Clustering Algorithm
</sectionHeader>
<bodyText confidence="0.99989616">
Clustering is the key part for such a task. We have
chosen to view the problem as an unsupervised hard
clustering problem. First, we view the problem as
unsupervised, using the training data for parameter
validation, to optimally tune the parameters in the
clustering algorithm. Secondly, we observed that the
majority of the input pages reference a single indi-
vidual, although there are a few that reference mul-
tiple individuals sharing the same name. Hence, we
view the problem as hard clustering, assigning input
pages to exactly one individual, so that the produced
clusters do not overlap.
Hard clustering algorithms can be classified as ei-
ther partitive or hierarchical. Agglomerative hierar-
chical clustering generates a series of nested clusters
by merging simple clusters into larger ones, while
partitive methods try to find a pre-specified num-
ber of clusters that best capture the data. As the
correct number of clusters is not given a priori, we
chose a method from the second group. We use the
Hierarchical Agglomerative Clustering (HAC) algo-
rithm (Jain et al., 1999) for all experiments reported
in this paper. HAC views each input web page as
a separate cluster and iteratively combines the most
similar pair of clusters to form a new cluster that re-
</bodyText>
<page confidence="0.958283">
268
</page>
<bodyText confidence="0.80051">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 268–271,
Prague, June 2007. c�2007 Association for Computational Linguistics
places the pair.
</bodyText>
<sectionHeader confidence="0.999089" genericHeader="method">
3 Features
</sectionHeader>
<bodyText confidence="0.999822337349398">
As input to the clustering, we consider several dif-
ferent representations of the input documents. Each
representation views the input web pages as a vector
of features. HAC then computes the cosine similar-
ity between the feature vectors for each pair of clus-
ters to determine which clusters to merge. We now
review the inventory of features studied in our work.
Tokens (T). Identical to the task baseline by (Ar-
tiles et al., 2005), we stemmed the words in the web
pages using the Porter stemmer (Porter, 1980), to
conflate semantically similar English words with the
stem. Each stemmed word is considered to be a fea-
ture and weighted by its Term Frequency x Inverse
Document Frequency (TFxIDF).
Named Entities (NE). We extract the named enti-
ties from the web pages using the Stanford Named
Entity Recognizer (Finkel et al., 2005). This tagger
identifies and labels names of places, organizations
and people in the input. Each named entity token
is treated as a separate feature, again weighted by
TFxIDF. We do not perform stemming for NE fea-
tures.
We also consider a more target-centric form of
the NE feature, motivated by the observation that
person names can be differentiated using their mid-
dle names or titles. We first discard all named enti-
ties that do not contain any token of the search tar-
get, and then discard any token from the remain-
ing named entities that appears in the search tar-
get. The remaining tokens are then used as features,
and weighted by their TFxIDF. For example, for the
search target “Edward Fox”, the features generated
from the name “Edward Charles Morrice Fox” are
“Charles” and “Morrice”. We call this variation NE
targeted (NE-T).
Hostnames and domains (H and D). If two
web pages have links pointing to the exact same
URL, then there is a good chance that these two
web pages refer the same person. However, we
find such exact matches of URLs are rare, so
we relax the condition and consider their host-
names or domain names instead. For example, the
URL http://portal.acm.org/guide.cfm has host-
name portal.acm.org and domain name acm.org.
As such, for each web page, we can extract the list
of hostnames from the links in this page.
We observe that some host/domain names serve
as more discriminative evidence than others (e.g.,
a link to a university homepage is more telling
than a link to the list of publications page of
Google Scholar when disambiguating computer sci-
ence scholars). To model this, we weight each
host/domain name by its IDF. Note that we do not
use TF as web pages often contain multiple inter-
nal links in the form of menus or navigation bars.
Using IDF and cosine similarity has been proven
effective for disambiguating bibliographic citation
records sharing a common author name (Tan et al.,
2006).
We also considered a variant where we include
the URL of the input web page itself as a “link”. We
tried this variation only with hostnames, calling this
Host with Self URL (H-S).
Page URLs (U). Uniform resource locations
(URLs) themselves contain a rich amount
of information. For example, the URL
http://www.cs.ualberta.ca/˜lindek/ itself sug-
gests a home page of “lindek” in the Computer
Science department, University of Alberta, Canada.
We used the MeURLin system (Kan and Nguyen
Thi, 2005) to segment the URL of each web page
into tokens as well as to generate additional fea-
tures. These features include (a) segmentation of
tokens such as “www.allposters.com” to “www”,
“all”, “posters” and “com”; (b) the parts in the URL
where the tokens occur, e.g., protocol, domain name,
and directory paths; (c) length of the tokens; (d) or-
thographic features; (e) sequential n-grams; and (f)
sequential bigrams. As each of these features can be
seen as a “token”, the output of the MeURLin seg-
menter for a web page can be seen as a “document”,
and hence it is possible to compute the TFxIDF co-
sine similarity between two such documents.
</bodyText>
<subsectionHeader confidence="0.991389">
3.1 Feature Combination
</subsectionHeader>
<bodyText confidence="0.999898714285714">
The features described above represent largely or-
thogonal sources of information in the input: input
content, hyperlinks, and source location. We hy-
pothesize that by combining these different features
we can obtain better performance. To combine these
features for use with HAC, we consider simply con-
catenating individual feature vectors together to cre-
</bodyText>
<page confidence="0.995765">
269
</page>
<bodyText confidence="0.999467">
ate a single feature vector, and compute cosine sim-
ilarity. We used this method in two configurations:
namely, (T + NE + H-S), (T + D + NE + NE-T + U).
We also tried using the maximum and average
component-wise similarities of individual features.
(max(NE, H-S)) uses the maximum value of the
Named Entity and Host with Self features. For the
(avg(T, H-S)) and (avg(T, D, NE, NE-T, U)) runs,
we compute the average similarity over the two and
five sets of individual features, respectively.
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999984253012049">
We present the clustering performances of the var-
ious methods in our system based on the different
features that we extracted. Each experiment uses
HAC with single linkage clustering. Since the num-
ber of clusters is not known, when to terminate the
agglomeration process is a crucial point and signifi-
cantly affects the quality of the clustering result. We
empirically determine the best similarity thresholds
to be 0.1 and 0.2 for all the experiments on the three
different data sets provided. We found that larger
values for these data sets do not allow the HAC algo-
rithm to create enough clustering hierarchy by caus-
ing it to terminate early, and therefore result in many
small clusters increasing purity but dramatically suf-
fering from inverse purity performance.
Table 1 shows the results of our experiments on
the training data sets (ECDL, Wikipedia and Cen-
sus). Two different evaluation measures are reported
as described by the task: Fα=0.5 is a harmonic mean
of purity and inverse purity of the clustering result,
and Fα=0.2 is a version of F that gives more impor-
tance to inverse purity (Artiles et al., 2007).
Among the individual features, Tokens and
Named Entity features consistently show close to
best performance for all training data sets. In most
cases, NE is better than Tokens because some web
pages contain lots of irrelevant text for this task (e.g.,
headers and footers, menus etc). Also, we found that
the NEs have far more discriminative power than
most other tokens in determining similarity between
web pages. The NE variation, NE targeted, performs
worse among the token based methods. Although
NE targeted aims for highly precise disambiguation,
it seems that it throws away too much information
so that inverse purity is very much reduced. The
other NEs, such as locations and organizations are
also very helpful for this task. For example, the or-
ganization may indicate the affiliation of a particular
name. This explains the superiority of NE over NE
targeted for all three data sets.
Among the link based features, Domain gives bet-
ter performance over Host as it leads to better in-
verse purity. The reason is that there are usually
many pages on different hosts from a single domain
for a given name (e.g., the web pages belonging to
a researcher from university domain). This greatly
helps in resolving the name while results in a slight
drop in purity. Using a web page’s URL itself in the
features Host+Self and Domain+Self shows a larger
increase in inverse purity at a smaller decrease in pu-
rity, hence these have improved F-measure in com-
parison to Domain and Host. Not surprisingly, these
link based features perform very well for the ECDL
data set, compared to the other two. A significant
portion of the people in the ECDL data set are most
likely present-day computer scientists, likely having
extensive an web presence, which makes the task
much easier. Although the other two data sets may
have popular people with many web pages, their
web presence are usually created by others and often
scatter across many domains with little hyperlink-
age between them. This explains why our link based
methods are not very effective for such data sets.
Our final individual feature URL performs worst
among all. Although highly precise, its resulting in-
verse purity is poor. While the features generated
by MeURLin do improve the performance over pure
host name and domain on the page URLs, its incor-
poration in a richer feature set does not lead to better
results, as the other features which have richer infor-
mation to process.
Each of the individual features has different de-
gree of discriminative power in many different
cases. By combining them, we expect to get bet-
ter performance than individually. However, we do
not obtain significant improvement in any of the data
sets. Furthermore, in the Census data set, the com-
bined features fail to outperform the individual NE
and Tokens features. The relatively poor perfor-
mance of the remaining features also degrades the
performance of Tokens and NE when combined.
Considering the performances using the harmonic
mean, we do not see any clear winner in all of three
</bodyText>
<page confidence="0.984171">
270
</page>
<table confidence="0.9998888">
Feature ECDL Wikipedia Census
Fα=0.5 Fα=0.2 Fα=0.5 Fα=0.2 Fα=0.5 Fα=0.2
Tokens (T) .72 / .77 .83 / .84 .72 / .76 .85 / .84 .82 / .84 .88 / .86
Named Entities (NE) .75 / .80 .84 / .79 .75 / .77 .85 / .78 .89 / .78 .89 / .73
NE targeted (NE-T) .54 / .55 .49 / .47 .66 / .64 .60 / .57 .64 / .64 .57 / .58
Host (H) .72 / .57 .64 / .48 .67 / .51 .58 / .41 .67 / .63 .59 / .55
Host + Self (H-S) .73 / .59 .66 / .49 .68 / .54 .60 / .43 .68 / .63 .60 / .56
Domain (D) .78 / .69 .72 / .60 .71 / .59 .66 / .50 .69 / .65 .61 / .58
Domain + Self (D-S) .79 / .70 .74 / .61 .72 / .62 .67 / .52 .70 / .66 .62 / .59
URL (U) .50 / .43 .43 / .35 .56 / .42 .50 / .33 .64 / .58 .56 / .51
(T + NE + H-S) .71 / .77 .83 / .83 .72 / .76 .85 / .83 .65 / .67 .78 / .76
(T + D + NE + NE-T + U) .72 / .76 .83 / .80 .72 / .77 .84 / .83 .66 / .66 .78 / .74
(max(NE, H-S)) .74 / .80 .84 / .82 .74 / .77 .86 / .82 .71 / .66 .80 / .70
(avg(T, H-S)) .77 / .81 .86 / .76 .75 / .77 .86 / .76 .70 / .64 .80 / .67
(avg(T, D, NE, NE-T, U)) .78 / .77 .86 / .73 .75 / .78 .86 / .76 .69 / .61 .77 / .62
</table>
<tableCaption confidence="0.994496333333333">
Table 1: Experimental results for each training data set of the task: ECDL, Wikipedia and Census. Each
experiment uses single link HAC with the similarity threshold values of 0.1 / 0.2. Best Fα=0.5 performances
are shown in bold.
</tableCaption>
<bodyText confidence="0.990759533333333">
training data sets. In addition, the method showing
the best performance does not result in a win with
a large margin in each data set. Relatively com-
plicated methods do not always perform better over
simpler, single featured based methods on all train-
ing data sets. Considering the results and Occam’s
razor (Thorburn, 1915), we conclude that a simple
method should most likely work relatively well in
many other different settings as well. Therefore, we
selected the method based on the individual NE fea-
ture with the similarity threshold value of 0.2 for the
final test submission run. We are able to achieve
the following results for this submission run: pu-
rity = 0.73, inverse purity = 0.82, Fα=0.5 = 0.75,
Fα=0.2 = 0.78.
</bodyText>
<sectionHeader confidence="0.999597" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.995792909090909">
We described our PSNUS system that disambiguates
people mentions in web pages returned by a web
search scenario, as defined in the inaugural Web
People Search Task. As such, we mainly focus on
extracting various kinds of information from web
pages and utilizing them in the similarity computa-
tion of the clustering algorithm. The experimental
results show that a simple Hierarchical Agglomera-
tive Clustering approach using a single named entity
feature seems promising as a robust solution for the
various datasets.
</bodyText>
<sectionHeader confidence="0.999014" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99198125">
Javier Artiles, Julio Gonzalo, and Felisa Verdejo. 2005.
A testbed for people searching strategies in the WWW.
In ACMSIGIR, pages 569–570, August.
Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 2007.
The SemEval-2007 WePS evaluation: Establishing a
benchmark for the Web People Search Task. In Se-
mEval 2007, ACL, June.
Jenny R. Finkel, Trond Grenager, and Christopher Man-
ning. 2005. Incorporating non-local information into
information extraction systems by Gibbs sampling. In
ACL, pages 363–370, June.
Anil K. Jain, M. Narasimha Murty, and Patrick J. Flynn.
1999. Data clustering: A review. ACM Computing
Surveys, 31(3):264–323, September.
Min-Yen Kan and Hoang Oanh Nguyen Thi. 2005. Fast
webpage classification using URL features. In CIKM,
pages 325–326, October/November.
Martin F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137, July.
Yee Fan Tan, Min-Yen Kan, and Dongwon Lee. 2006.
Search engine driven author disambiguation. In
ACM/IEEE JCDL, pages 314–315, June.
William M. Thorburn. 1915. Occam’s razor. Mind,
24:287–288.
</reference>
<page confidence="0.997804">
271
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925037">
<title confidence="0.9895535">PSNUS: Web People Name Disambiguation by Simple Clustering with Rich Features</title>
<author confidence="0.995905">Fan Su Dongwon</author>
<affiliation confidence="0.9818145">Pennsylvania State University, USA University of Singapore, Singapore</affiliation>
<abstract confidence="0.99715575">We describe about the system description of the PSNUS team for the SemEval-2007 Web People Search Task. The system is based on the clustering of the web pages by using a variety of features extracted and generated from the data provided. This system for the final test data set of the task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Javier Artiles</author>
<author>Julio Gonzalo</author>
<author>Felisa Verdejo</author>
</authors>
<title>A testbed for people searching strategies in the WWW.</title>
<date>2005</date>
<booktitle>In ACMSIGIR,</booktitle>
<pages>569--570</pages>
<contexts>
<context position="3988" citStr="Artiles et al., 2005" startWordPosition="649" endWordPosition="653">dings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 268–271, Prague, June 2007. c�2007 Association for Computational Linguistics places the pair. 3 Features As input to the clustering, we consider several different representations of the input documents. Each representation views the input web pages as a vector of features. HAC then computes the cosine similarity between the feature vectors for each pair of clusters to determine which clusters to merge. We now review the inventory of features studied in our work. Tokens (T). Identical to the task baseline by (Artiles et al., 2005), we stemmed the words in the web pages using the Porter stemmer (Porter, 1980), to conflate semantically similar English words with the stem. Each stemmed word is considered to be a feature and weighted by its Term Frequency x Inverse Document Frequency (TFxIDF). Named Entities (NE). We extract the named entities from the web pages using the Stanford Named Entity Recognizer (Finkel et al., 2005). This tagger identifies and labels names of places, organizations and people in the input. Each named entity token is treated as a separate feature, again weighted by TFxIDF. We do not perform stemmin</context>
</contexts>
<marker>Artiles, Gonzalo, Verdejo, 2005</marker>
<rawString>Javier Artiles, Julio Gonzalo, and Felisa Verdejo. 2005. A testbed for people searching strategies in the WWW. In ACMSIGIR, pages 569–570, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier Artiles</author>
<author>Julio Gonzalo</author>
<author>Satoshi Sekine</author>
</authors>
<title>The SemEval-2007 WePS evaluation: Establishing a benchmark for the Web People Search Task. In SemEval</title>
<date>2007</date>
<location>ACL,</location>
<contexts>
<context position="811" citStr="Artiles et al., 2007" startWordPosition="123" endWordPosition="127">al University of Singapore, Singapore {ergin,syan,dongwon}@psu.edu, {tanyeefa,kanmy}@comp.nus.edu.sg Abstract We describe about the system description of the PSNUS team for the SemEval-2007 Web People Search Task. The system is based on the clustering of the web pages by using a variety of features extracted and generated from the data provided. This system achieves Fα=0.5 = 0.75 and Fα=0.2 = 0.78 for the final test data set of the task. 1 Introduction We consider the problem of disambiguating person names in a Web searching scenario as described by the Web People Search Task in SemEval 2007 (Artiles et al., 2007). Here, the system receives as input a set of web pages retrieved from a search engine using a given person name as a query. The goal is to determine how many different people are represented for that name in the input web pages, and correctly assign each namesake to its corresponding subset of web pages. There are many challenges towards an effective solution. We are to correctly estimate the number of namesakes for a given person name and group documents referring to the same individual. Moreover, the information sources to be processed are unstructured web pages and there is no certain way </context>
<context position="9452" citStr="Artiles et al., 2007" startWordPosition="1571" endWordPosition="1574">found that larger values for these data sets do not allow the HAC algorithm to create enough clustering hierarchy by causing it to terminate early, and therefore result in many small clusters increasing purity but dramatically suffering from inverse purity performance. Table 1 shows the results of our experiments on the training data sets (ECDL, Wikipedia and Census). Two different evaluation measures are reported as described by the task: Fα=0.5 is a harmonic mean of purity and inverse purity of the clustering result, and Fα=0.2 is a version of F that gives more importance to inverse purity (Artiles et al., 2007). Among the individual features, Tokens and Named Entity features consistently show close to best performance for all training data sets. In most cases, NE is better than Tokens because some web pages contain lots of irrelevant text for this task (e.g., headers and footers, menus etc). Also, we found that the NEs have far more discriminative power than most other tokens in determining similarity between web pages. The NE variation, NE targeted, performs worse among the token based methods. Although NE targeted aims for highly precise disambiguation, it seems that it throws away too much inform</context>
</contexts>
<marker>Artiles, Gonzalo, Sekine, 2007</marker>
<rawString>Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 2007. The SemEval-2007 WePS evaluation: Establishing a benchmark for the Web People Search Task. In SemEval 2007, ACL, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="4387" citStr="Finkel et al., 2005" startWordPosition="717" endWordPosition="720">between the feature vectors for each pair of clusters to determine which clusters to merge. We now review the inventory of features studied in our work. Tokens (T). Identical to the task baseline by (Artiles et al., 2005), we stemmed the words in the web pages using the Porter stemmer (Porter, 1980), to conflate semantically similar English words with the stem. Each stemmed word is considered to be a feature and weighted by its Term Frequency x Inverse Document Frequency (TFxIDF). Named Entities (NE). We extract the named entities from the web pages using the Stanford Named Entity Recognizer (Finkel et al., 2005). This tagger identifies and labels names of places, organizations and people in the input. Each named entity token is treated as a separate feature, again weighted by TFxIDF. We do not perform stemming for NE features. We also consider a more target-centric form of the NE feature, motivated by the observation that person names can be differentiated using their middle names or titles. We first discard all named entities that do not contain any token of the search target, and then discard any token from the remaining named entities that appears in the search target. The remaining tokens are the</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny R. Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In ACL, pages 363–370, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil K Jain</author>
<author>M Narasimha Murty</author>
<author>Patrick J Flynn</author>
</authors>
<title>Data clustering: A review.</title>
<date>1999</date>
<journal>ACM Computing Surveys,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="3172" citStr="Jain et al., 1999" startWordPosition="517" endWordPosition="520">e view the problem as hard clustering, assigning input pages to exactly one individual, so that the produced clusters do not overlap. Hard clustering algorithms can be classified as either partitive or hierarchical. Agglomerative hierarchical clustering generates a series of nested clusters by merging simple clusters into larger ones, while partitive methods try to find a pre-specified number of clusters that best capture the data. As the correct number of clusters is not given a priori, we chose a method from the second group. We use the Hierarchical Agglomerative Clustering (HAC) algorithm (Jain et al., 1999) for all experiments reported in this paper. HAC views each input web page as a separate cluster and iteratively combines the most similar pair of clusters to form a new cluster that re268 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 268–271, Prague, June 2007. c�2007 Association for Computational Linguistics places the pair. 3 Features As input to the clustering, we consider several different representations of the input documents. Each representation views the input web pages as a vector of features. HAC then computes the cosine similarity betwe</context>
</contexts>
<marker>Jain, Murty, Flynn, 1999</marker>
<rawString>Anil K. Jain, M. Narasimha Murty, and Patrick J. Flynn. 1999. Data clustering: A review. ACM Computing Surveys, 31(3):264–323, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
<author>Hoang Oanh Nguyen Thi</author>
</authors>
<title>Fast webpage classification using URL features.</title>
<date>2005</date>
<booktitle>In CIKM,</booktitle>
<pages>325--326</pages>
<marker>Kan, Thi, 2005</marker>
<rawString>Min-Yen Kan and Hoang Oanh Nguyen Thi. 2005. Fast webpage classification using URL features. In CIKM, pages 325–326, October/November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="4067" citStr="Porter, 1980" startWordPosition="666" endWordPosition="667">68–271, Prague, June 2007. c�2007 Association for Computational Linguistics places the pair. 3 Features As input to the clustering, we consider several different representations of the input documents. Each representation views the input web pages as a vector of features. HAC then computes the cosine similarity between the feature vectors for each pair of clusters to determine which clusters to merge. We now review the inventory of features studied in our work. Tokens (T). Identical to the task baseline by (Artiles et al., 2005), we stemmed the words in the web pages using the Porter stemmer (Porter, 1980), to conflate semantically similar English words with the stem. Each stemmed word is considered to be a feature and weighted by its Term Frequency x Inverse Document Frequency (TFxIDF). Named Entities (NE). We extract the named entities from the web pages using the Stanford Named Entity Recognizer (Finkel et al., 2005). This tagger identifies and labels names of places, organizations and people in the input. Each named entity token is treated as a separate feature, again weighted by TFxIDF. We do not perform stemming for NE features. We also consider a more target-centric form of the NE featur</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Fan Tan</author>
<author>Min-Yen Kan</author>
<author>Dongwon Lee</author>
</authors>
<title>Search engine driven author disambiguation.</title>
<date>2006</date>
<booktitle>In ACM/IEEE JCDL,</booktitle>
<pages>314--315</pages>
<contexts>
<context position="6315" citStr="Tan et al., 2006" startWordPosition="1048" endWordPosition="1051">from the links in this page. We observe that some host/domain names serve as more discriminative evidence than others (e.g., a link to a university homepage is more telling than a link to the list of publications page of Google Scholar when disambiguating computer science scholars). To model this, we weight each host/domain name by its IDF. Note that we do not use TF as web pages often contain multiple internal links in the form of menus or navigation bars. Using IDF and cosine similarity has been proven effective for disambiguating bibliographic citation records sharing a common author name (Tan et al., 2006). We also considered a variant where we include the URL of the input web page itself as a “link”. We tried this variation only with hostnames, calling this Host with Self URL (H-S). Page URLs (U). Uniform resource locations (URLs) themselves contain a rich amount of information. For example, the URL http://www.cs.ualberta.ca/˜lindek/ itself suggests a home page of “lindek” in the Computer Science department, University of Alberta, Canada. We used the MeURLin system (Kan and Nguyen Thi, 2005) to segment the URL of each web page into tokens as well as to generate additional features. These featu</context>
</contexts>
<marker>Tan, Kan, Lee, 2006</marker>
<rawString>Yee Fan Tan, Min-Yen Kan, and Dongwon Lee. 2006. Search engine driven author disambiguation. In ACM/IEEE JCDL, pages 314–315, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Thorburn</author>
</authors>
<date>1915</date>
<booktitle>Occam’s razor. Mind,</booktitle>
<pages>24--287</pages>
<contexts>
<context position="14105" citStr="Thorburn, 1915" startWordPosition="2463" endWordPosition="2464">.78 / .77 .86 / .73 .75 / .78 .86 / .76 .69 / .61 .77 / .62 Table 1: Experimental results for each training data set of the task: ECDL, Wikipedia and Census. Each experiment uses single link HAC with the similarity threshold values of 0.1 / 0.2. Best Fα=0.5 performances are shown in bold. training data sets. In addition, the method showing the best performance does not result in a win with a large margin in each data set. Relatively complicated methods do not always perform better over simpler, single featured based methods on all training data sets. Considering the results and Occam’s razor (Thorburn, 1915), we conclude that a simple method should most likely work relatively well in many other different settings as well. Therefore, we selected the method based on the individual NE feature with the similarity threshold value of 0.2 for the final test submission run. We are able to achieve the following results for this submission run: purity = 0.73, inverse purity = 0.82, Fα=0.5 = 0.75, Fα=0.2 = 0.78. 5 Conclusion We described our PSNUS system that disambiguates people mentions in web pages returned by a web search scenario, as defined in the inaugural Web People Search Task. As such, we mainly f</context>
</contexts>
<marker>Thorburn, 1915</marker>
<rawString>William M. Thorburn. 1915. Occam’s razor. Mind, 24:287–288.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>