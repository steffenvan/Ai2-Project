<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.981122">
Incremental Parsing Models for Dialog Task Structure
</title>
<author confidence="0.354005">
Srinivas Bangalore and Amanda J. Stent
</author>
<affiliation confidence="0.318494">
AT&amp;T Labs – Research, Inc., 180 Park Avenue,
</affiliation>
<address confidence="0.539558">
Florham Park, NJ 07932, USA
</address>
<email confidence="0.989885">
{srini,stent}@research.att.com
</email>
<sectionHeader confidence="0.994867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999416875">
In this paper, we present an integrated
model of the two central tasks of dialog
management: interpreting user actions and
generating system actions. We model the
interpretation task as a classification prob-
lem and the generation task as a predic-
tion problem. These two tasks are inter-
leaved in an incremental parsing-based di-
alog model. We compare three alterna-
tive parsing methods for this dialog model
using a corpus of human-human spoken
dialog from a catalog ordering domain
that has been annotated for dialog acts
and task/subtask information. We contrast
the amount of context provided by each
method and its impact on performance.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999735">
Corpora of spoken dialog are now widely avail-
able, and frequently come with annotations for
tasks/games, dialog acts, named entities and ele-
ments of syntactic structure. These types of infor-
mation provide rich clues for building dialog mod-
els (Grosz and Sidner, 1986). Dialog models can
be built offline (for dialog mining and summariza-
tion), or online (for dialog management).
A dialog manager is the component of a dia-
log system that is responsible for interpreting user
actions in the dialog context, and for generating
system actions. Needless to say, a dialog manager
operates incrementally as the dialog progresses. In
typical commercial dialog systems, the interpre-
tation and generation processes operate indepen-
dently of each other, with only a small amount of
shared context. By contrast, in this paper we de-
scribe a dialog model that (1) tightly integrates in-
terpretation and generation, (2) makes explicit the
type and amount of shared context, (3) includes
the task structure of the dialog in the context, (4)
can be trained from dialog data, and (5) runs in-
crementally, parsing the dialog as it occurs and in-
terleaving generation and interpretation.
At the core of our model is a parser that in-
crementally builds the dialog task structure as the
dialog progresses. In this paper, we experiment
with three different incremental tree-based parsing
methods. We compare these methods using a cor-
pus of human-human spoken dialogs in a catalog
ordering domain that has been annotated for dialog
acts and task/subtask information. We show that
all these methods outperform a baseline method
for recovering the dialog structure.
The rest of this paper is structured as follows:
In Section 2, we review related work. In Sec-
tion 3, we present our view of the structure of task-
oriented human-human dialogs. In Section 4, we
present the parsing approaches included in our ex-
periments. In Section 5, we describe our data and
experiments. Finally, in Section 6, we present con-
clusions and describe our current and future work.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999890038461539">
There are two threads of research that are relevant
to our work: work on parsing (written and spoken)
discourse, and work on plan-based dialog models.
Discourse Parsing Discourse parsing is the pro-
cess of building a hierarchical model of a dis-
course from its basic elements (sentences or
clauses), as one would build a parse of a sen-
tence from its words. There has now been con-
siderable work on discourse parsing using statisti-
cal bottom-up parsing (Soricut and Marcu, 2003),
hierarchical agglomerative clustering (Sporleder
and Lascarides, 2004), parsing from lexicalized
tree-adjoining grammars (Cristea, 2000), and rule-
based approaches that use rhetorical relations and
discourse cues (Forbes et al., 2003; Polanyi et al.,
2004; LeThanh et al., 2004). With the exception of
Cristea (2000), most of this research has been lim-
ited to non-incremental parsing of textual mono-
logues where, in contrast to incremental dialog
parsing, predicting a system action is not relevant.
The work on discourse parsing that is most
similar to ours is that of Baldridge and Las-
carides (2005). They used a probabilistic head-
driven parsing method (described in (Collins,
2003)) to construct rhetorical structure trees for a
spoken dialog corpus. However, their parser was
</bodyText>
<note confidence="0.9229615">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 94–102,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.996318">
94
</page>
<figure confidence="0.823066">
Task Task Task
Clause
</figure>
<figureCaption confidence="0.9861525">
Figure 1: A schema of a shared plan tree for a
dialog.
</figureCaption>
<bodyText confidence="0.99601503125">
not incremental; it used global features such as the
number of turn changes. Also, it focused strictly
in interpretation of input utterances; it could not
predict actions by either dialog partner.
In contrast to other work on discourse parsing,
we wish to use the parsing process directly for di-
alog management (rather than for information ex-
traction or summarization). This influences our
approach to dialog modeling in two ways. First,
the subtask tree we build represents the functional
task structure of the dialog (rather than the rhetor-
ical structure of the dialog). Second, our dialog
parser must be entirely incremental.
Plan-Based Dialog Models Plan-based ap-
proaches to dialog modeling, like ours, operate di-
rectly on the dialog’s task structure. The process
of task-oriented dialog is treated as a special case
of AI-style plan recognition (Sidner,1985; Litman
and Allen, 1987; Rich and Sidner,1997; Carberry,
2001; Bohus and Rudnicky, 2003; Lochbaum,
1998). Plan-based dialog models are used for both
interpretation of user utterances and prediction of
agent actions. In addition to the hand-crafted mod-
els listed above, researchers have built stochastic
plan recognition models for interaction, includ-
ing ones based on Hidden Markov Models (Bui,
2003; Blaylock and Allen, 2006) and on proba-
bilistic context-free grammars (Alexandersson and
Reithinger,1997; Pynadath and Wellman, 2000).
In this area, the work most closely related to
ours is that of Barrett and Weld (Barrett and Weld,
1994), who build an incremental bottom-up parser
</bodyText>
<subsectionHeader confidence="0.594983">
Order Placement
</subsectionHeader>
<bodyText confidence="0.6507516">
Figure 2: Sample output (subtask tree) from a
parse-based model for the catalog ordering do-
main.
to parse plans. Their parser, however, was not
probabilistic or targeted at dialog processing.
</bodyText>
<sectionHeader confidence="0.938245" genericHeader="method">
3 Dialog Structure
</sectionHeader>
<bodyText confidence="0.999309216216216">
We consider a task-oriented dialog to be the re-
sult of incremental creation of a shared plan by
the participants (Lochbaum, 1998). The shared
plan is represented as a single tree T that incorpo-
rates the task/subtask structure, dialog acts, syn-
tactic structure and lexical content of the dialog,
as shown in Figure 1. A task is a sequence of sub-
tasks ST ∈ S. A subtask is a sequence of dialog
acts DA ∈ D. Each dialog act corresponds to one
clause spoken by one speaker, customer (cu) or
agent (ca) (for which we may have acoustic, lexi-
cal, syntactic and semantic representations).
Figure 2 shows the subtask tree for a sample di-
alog in our domain (catalog ordering). An order
placement task is typically composed of the se-
quence of subtasks opening, contact-information,
order-item, related-offers, summary. Subtasks can
be nested; the nesting can be as deep as five lev-
els in our data. Most often the nesting is at the
leftmost or rightmost frontier of the subtask tree.
As the dialog proceeds, an utterance from a par-
ticipant is accommodated into the subtask tree in
an incremental manner, much like an incremen-
tal syntactic parser accommodates the next word
into a partial parse tree (Alexandersson and Rei-
thinger, 1997). An illustration of the incremental
evolution of dialog structure is shown in Figure 4.
However, while a syntactic parser processes in-
put from a single source, our dialog parser parses
user-system exchanges: user utterances are inter-
preted, while system utterances are generated. So
the steps taken by our dialog parser to incorpo-
rate an utterance into the subtask tree depend on
whether the utterance was produced by the agent
or the user (as shown in Figure 3).
User utterances Each user turn is split into
clauses (utterances). Each clause is supertagged
</bodyText>
<figure confidence="0.998815214285714">
Dialog
Utterance
Utterance
Utterance
Topic/Subtask
Topic/Subtask
Topic/Subtask
DialogAct,Pred—Args DialogAct,Pred—Args DialogAct,Pred—Args
Opening
Contact Info
Order Item Payment Info Summary
Closing
Delivery Info
Shipping Info
</figure>
<page confidence="0.737378">
95
</page>
<table confidence="0.39568">
Interpretation of a user’s utterance:
DAC: daui = argmax P(u u i−1 i−1 i−1
du∈D d  |ci , STi−k , DAi−k, ci−k)
</table>
<equation confidence="0.973746416666667">
P(su|dau i , cu i , ST i−1
i−k , DAi−1
i−k, ci−1
i−k)
Generation of an agent’s utterance:
STC : stui = argmax
su∈S
STP : stai = argmax P(sa|STi−1 Figure 3: Dialog management process
sa∈S i−k ,DAi−1
i−k, ci−1
i−k)
(3)
</equation>
<tableCaption confidence="0.893318285714286">
Table 1: Equations used for modeling dialog act and sub-
task labeling of agent and user utterances. cui /cai = the
words, syntactic information and named entities associated
with the ith utterance of the dialog, spoken by user/agent
u/a. daui /daai = the dialog act of the ith utterance, spoken
by user/agent u/a. stui /stai = the subtask label of the ith ut-
terance, spoken by user/agent u/a. DAi−1
</tableCaption>
<bodyText confidence="0.9865922">
i−k represents the
dialog act tags for utterances i − 1 to i − k.
and labeled with named entities1. Interpretation of
the clause (cyi ) involves assigning a dialog act la-
bel (dayi ) and a subtask label (styi ). We use ST i−1
</bodyText>
<equation confidence="0.936863">
i−k ,
DAi−1
i−k, and ci−1
</equation>
<bodyText confidence="0.943995166666666">
i−k to represent the sequence of pre-
ceeding k subtask labels, dialog act labels and
clauses respectively. The dialog act label dayi is
determined from information about the clause and
(a kth order approximation of) the subtask tree so
far (Ti−1 = (STi−1
</bodyText>
<equation confidence="0.6751355">
i−k , DAi−1
i−k, ci−1
</equation>
<bodyText confidence="0.9992737">
i−k)), as shown in
Equation 1 (Table 1). The subtask label styi is de-
termined from information about the clause, its di-
alog act and the subtask tree so far, as shown in
Equation 2. Then, the clause is incorporated into
the subtask tree.
Agent utterances In contrast, a dialog sys-
tem starts planning an agent utterance by iden-
tifying the subtask to contribute to next, sta ,
based on the subtask tree so far (Ti−1 =
</bodyText>
<equation confidence="0.8978125">
(STi−1 i−k, DAi−1
i−k,ci−1
</equation>
<bodyText confidence="0.995876111111111">
i−k)), as shown in Equation 3
(Table 1) . Then, it chooses the dialog act of the
utterance, daa , based on the subtask tree so far and
the chosen subtask for the utterance, as shown in
Equation 4. Finally, it generates an utterance, ca ,
to realize its communicative intent (represented
as a subtask and dialog act pair, with associated
named entities)2.
Note that the current clause cy i is used in the
</bodyText>
<footnote confidence="0.972811666666667">
1This results in a syntactic parse of the clause and could
be done incrementally as well.
2We do not address utterance realization in this paper.
</footnote>
<bodyText confidence="0.9997564">
conditioning context of the interpretation model
(for user utterances), but the corresponding clause
for the agent utterance ca is to be predicted and
hence is not part of conditioning context in the
generation model.
</bodyText>
<sectionHeader confidence="0.993774" genericHeader="method">
4 Dialog Parsing
</sectionHeader>
<bodyText confidence="0.999992333333333">
A dialog parser can produce a “shallow” or “deep”
tree structure. A shallow parse is one in which
utterances are grouped together into subtasks, but
the dominance relations among subtasks are not
tracked. We call this model a chunk-based dia-
log model (Bangalore et al., 2006). The chunk-
based model has limitations. For example, dom-
inance relations among subtasks are important
for dialog processes such as anaphora resolu-
tion (Grosz and Sidner, 1986). Also, the chunk-
based model is representationally inadequate for
center-embedded nestings of subtasks, which do
occur in our domain, although less frequently than
the more prevalent “tail-recursive” structures.
We use the term parse-based dialog model to
refer to deep parsing models for dialog which
not only segment the dialog into chunks but also
predict dominance relations among chunks. For
this paper, we experimented with three alternative
methods for building parse-based models: shift-
reduce, start-complete and connection path.
Each of these operates on the subtask tree for
the dialog incrementally, from left-to-right, with
access only to the preceding dialog context, as
shown in Figure 4. They differ in the parsing ac-
tions and the data structures used by the parser;
this has implications for robustness to errors. The
instructions to reconstruct the parse are either en-
tirely encoded in the stack (in the shift-reduce
method), or entirely in the parsing actions (in the
start-complete and connection path methods). For
each of the four types of parsing action required
to build the parse tree (see Table 1), we construct
</bodyText>
<figure confidence="0.9975596">
DAP: daai = argmax P(da|sta i , ST i−1
da∈D i−k , DAi−1
i−k, ci−1
i−k)
(4)
</figure>
<page confidence="0.648083">
96
</page>
<figureCaption confidence="0.980597">
Figure 4: An illustration of incremental evolution of dialog structure
</figureCaption>
<figure confidence="0.998885347826087">
Ack
Request(MakeOrder) Ack
yes i would like
yes one
for calling to place an order second
XYZ catalog
this is mary
how may I
help you
Opening
Opening
Opening
Opening
Shipping—Address
Contact—Info
Contact—Info
Contact—Info
Order Item Task
Order Item Task
Order Item Task
Order Item Task
Hello
Ack
Ack
Hello Request(MakeOrder)
Ack
Hello Request(MakeOrder) Ack
please
can i have your
home telephone
number with area code
......
you
Hello
Ack
Request(MakeOrder) Ack
yes i would like
to place an order
yes i would like
to place an order
yes i would like
to place an order
thank you
for calling
XYZ catalog
this is mary
how may I
help you
thank you
thank
thank you
for calling
XYZ catalog
this is mary
thank you
for calling
XYZ catalog
this is mary
yes one
second
please
thank
yes one
thank
you
can i have your
home telephone
number with area code
......
thank
you
yes one
second
please
you
second
please
how may I
help you
how may I
help you
Order Item Task
Order Item Task
may we deliver this
order to your home
yes please
can i have your
home telephone
number with area code
...... ......
please
can i have your
home telephone
number with area code
......
you
.........
.........
Closing
Opening
Contact—Info
Opening
Contact—Info
thank you
for calling
XYZ catalog
this is mary
how may I
help you
Ack
Hello
thank you
for calling
XYZ catalog
this is mary
how may I
help you
Ack
may we deliver this
order to your home
yes please
......
Request(MakeOrder) Ack
Hello Request(MakeOrder) Ack
thank
yes one
second
please
Shipping—Address
Shipping—Address
thank
yes one
second
you
yes i would like
to place an order
yes i would like
to place an order
</figure>
<bodyText confidence="0.989415625">
a feature vector containing contextual information
for the parsing action (see Section 5.1). These fea-
ture vectors and the associated parser actions are
used to train maximum entropy models (Berger et
al., 1996). These models are then used to incre-
mentally incorporate the utterances for a new di-
alog into that dialog’s subtask tree as the dialog
progresses, as shown in Figure 3.
</bodyText>
<subsectionHeader confidence="0.956914">
4.1 Shift-Reduce Method
</subsectionHeader>
<bodyText confidence="0.999932648648649">
In this method, the subtask tree is recovered
through a right-branching shift-reduce parsing
process (Hall et al., 2006; Sagae and Lavie, 2006).
The parser shifts each utterance on to the stack. It
then inspects the stack and decides whether to do
one or more reduce actions that result in the cre-
ation of subtrees in the subtask tree. The parser
maintains two data structures – a stack and a tree.
The actions of the parser change the contents of
the stack and create nodes in the dialog tree struc-
ture. The actions for the parser include unary-
reduce-X, binary-reduce-X and shift, where X is
each of the non-terminals (subtask labels) in the
tree. Shift pushes a token representing the utter-
ance onto the stack; binary-reduce-X pops two to-
kens off the stack and pushes the non-terminal X;
and unary-reduce-X pops one token off the stack
and pushes the non-terminal X. Each type of re-
duce action creates a constituent X in the dialog
tree and the tree(s) associated with the reduced el-
ements as subtree(s) of X. At the end of the dialog,
the output is a binary branching subtask tree.
Consider the example subdialog A: would you
like a free magazine? U: no. The process-
ing of this dialog using our shift-reduce dialog
parser would proceed as follows: the STP model
predicts shift for st&apos;; the DAP model predicts
YNP(Promotions) for da&apos;; the generator outputs
would you like a free magazine?; and the parser
shifts a token representing this utterance onto the
stack. Then, the customer says no. The DAC
model classifies dal as No; the STC model clas-
sifies st&apos; as shift and binary-reduce-special-offer;
and the parser shifts a token representing the ut-
terance onto the stack, before popping the top two
elements off the stack and adding the subtree for
special-order into the dialog’s subtask tree.
</bodyText>
<subsectionHeader confidence="0.911415">
4.2 Start-Complete Method
</subsectionHeader>
<bodyText confidence="0.999976756097561">
In the shift-reduce method, the dialog tree is con-
structed as a side effect of the actions performed
on the stack: each reduce action on the stack in-
troduces a non-terminal in the tree. By contrast,
in the start-complete method the instructions to
build the tree are directly encoded in the parser ac-
tions. A stack is used to maintain the global parse
state. The actions the parser can take are similar
to those described in (Ratnaparkhi, 1997). The
parser must decide whether to join each new termi-
nal onto the existing left-hand edge of the tree, or
start a new subtree. The actions for the parser in-
clude start-X, n-start-X, complete-X, u-complete-
X and b-complete-X, where X is each of the non-
terminals (subtask labels) in the tree. Start-X
pushes a token representing the current utterance
onto the stack; n-start-X pushes non-terminal X
onto the stack; complete-X pushes a token repre-
senting the current utterance onto the stack, then
pops the top two tokens off the stack and pushes
the non-terminal X; u-complete-X pops the top to-
ken off the stack and pushes the non-terminal X;
and b-complete-X pops the top two tokens off the
stack and pushes the non-terminal X. This method
produces a dialog subtask tree directly, rather than
producing an equivalent binary-branching tree.
Consider the same subdialog as before, A:
would you like a free magazine? U: no. The
processing of this dialog using our start-complete
dialog parser would proceed as follows: the STP
model predicts start-special-offer for sta; the DAP
model predicts YNP(Promotions) for daa; the gen-
erator outputs would you like a free magazine?;
and the parser shifts a token representing this ut-
terance onto the stack. Then, the customer says
no. The DAC model classifies dau as No; the STC
model classifies stu as complete-special-offer; and
the parser shifts a token representing the utter-
ance onto the stack, before popping the top two
elements off the stack and adding the subtree for
special-order into the dialog’s subtask tree.
</bodyText>
<subsectionHeader confidence="0.999641">
4.3 Connection Path Method
</subsectionHeader>
<bodyText confidence="0.999856">
In contrast to the shift-reduce and the start-
complete methods described above, the connec-
tion path method does not use a stack to track the
global state of the parse. Instead, the parser di-
rectly predicts the connection path (path from the
root to the terminal) for each utterance. The col-
lection of connection paths for all the utterances in
a dialog defines the parse tree. This encoding was
previously used for incremental sentence parsing
by (Costa et al., 2001). With this method, there
are many more choices of decision for the parser
(195 decisions for our data) compared to the shift-
reduce (32) and start-complete (82) methods.
Consider the same subdialog as before, A:
would you like a free magazine? U: no. The pro-
cessing of this dialog using our connection path
dialog parser would proceed as follows. First, the
STP model predicts S-special-offer for sta; the
DAP model predicts YNP(Promotions) for daa;
the generator outputs would you like a free mag-
azine?; and the parser adds a subtree rooted at
special-offer, with one terminal for the current ut-
terance, into the top of the subtask tree. Then,
the customer says no. The DAC model classi-
fies dau as No and the STC model classifies stu
as S-special-offer. Since the right frontier of the
subtask tree has a subtree matching this path, the
</bodyText>
<table confidence="0.98105875">
Type Task/subtask labels
Call-level call-forward, closing, misc-other, open-
ing, out-of-domain, sub-call
Task-level check-availability, contact-info,
delivery-info, discount, order-change,
order-item, order-problem, payment-
info, related-offer, shipping-address,
special-offer, summary
</table>
<tableCaption confidence="0.918754">
Table 2: Task/subtask labels in CHILD
</tableCaption>
<table confidence="0.999874125">
Type Subtype
Ask Info
Explain Catalog, CC Related, Discount, Order Info
Order Problem, Payment Rel, Product Info
Promotions, Related Offer, Shipping
Convers- Ack, Goodbye, Hello, Help, Hold,
-ational YoureWelcome, Thanks, Yes, No, Ack,
Repeat, Not(Information)
Request Code, Order Problem, Address, Catalog,
CC Related, Change Order, Conf, Credit,
Customer Info, Info, Make Order, Name,
Order Info, Order Status, Payment Rel,
Phone Number, Product Info, Promotions,
Shipping, Store Info
YNQ Address, Email, Info, Order Info,
Order Status,Promotions, Related Offer
</table>
<tableCaption confidence="0.999701">
Table 3: Dialog act labels in CHILD
</tableCaption>
<bodyText confidence="0.9957395">
parser simply incorporates the current utterance as
a terminal of the special-offer subtree.
</bodyText>
<sectionHeader confidence="0.988231" genericHeader="conclusions">
5 Data and Experiments
</sectionHeader>
<bodyText confidence="0.999989230769231">
To evaluate our parse-based dialog model, we used
817 two-party dialogs from the CHILD corpus of
telephone-based dialogs in a catalog-purchasing
domain. Each dialog was transcribed by hand;
all numbers (telephone, credit card, etc.) were
removed for privacy reasons. The average di-
alog in this data set had 60 turns. The di-
alogs were automatically segmented into utter-
ances and automatically annotated with part-of-
speech tag and supertag information and named
entities. They were annotated by hand for dia-
log acts and tasks/subtasks. The dialog act and
task/subtask labels are given in Tables 2 and 3.
</bodyText>
<subsectionHeader confidence="0.887354">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.9989904">
In our experiments we used the following features
for each utterance: (a) the speaker ID; (b) uni-
grams, bigrams and trigrams of the words; (c) un-
igrams, bigrams and trigrams of the part of speech
tags; (d) unigrams, bigrams and trigrams of the su-
pertags; (e) binary features indicating the presence
or absence of particular types of named entity; (f)
the dialog act (determined by the parser); (g) the
task/subtask label (determined by the parser); and
(h) the parser stack at the current utterance (deter-
</bodyText>
<page confidence="0.995256">
98
</page>
<bodyText confidence="0.999973380952381">
mined by the parser). Each input feature vector for
agent subtask prediction has these features for up
to three utterances of left-hand context (see Equa-
tion 3). Each input feature vector for dialog act
prediction has the same features as for agent sub-
task prediction, plus the actual or predicted sub-
task label (see Equation 4). Each input feature
vector for dialog act interpretation has features a-
h for up to three utterances of left-hand context,
plus the current utterance (see Equation 1). Each
input feature vector for user subtask classification
has the same features as for user dialog act inter-
pretation, plus the actual or classified dialog act
(see Equation 2).
The label for each input feature vector is the
parsing action (for subtask classification and pre-
diction) or the dialog act label (for dialog act clas-
sification and prediction). If more than one pars-
ing action takes place on a particular utterance
(e.g. a shift and then a reduce), the feature vec-
tor is repeated twice with different stack contents.
</bodyText>
<subsectionHeader confidence="0.99949">
5.2 Training Method
</subsectionHeader>
<bodyText confidence="0.999980625">
We randomly selected roughly 90% of the dialogs
for training, and used the remainder for testing.
We separately trained models for: user dia-
log act classification (DAC, Equation 1); user
task/subtask classification (STC, Equation 2);
agent task/subtask prediction (STP, Equation 3);
and agent dialog act prediction (DAP, Equation 4).
In order to estimate the conditional distributions
shown in Table 1, we use the general technique of
choosing the MaxEnt distribution that properly es-
timates the average of each feature over the train-
ing data (Berger et al., 1996). We use the machine
learning toolkit LLAMA (Haffner, 2006), which
encodes multiclass classification problems using
binary MaxEnt classifiers to increase the speed of
training and to scale the method to large data sets.
</bodyText>
<subsectionHeader confidence="0.999446">
5.3 Decoding Method
</subsectionHeader>
<bodyText confidence="0.999988744186047">
The decoding process for the three parsing meth-
ods is illustrated in Figure 3 and has four stages:
STP, DAP, DAC, and STC. As already explained,
each of these steps in the decoding process is mod-
eled as either a prediction task or a classifica-
tion task. The decoder constructs an input feature
vector depending on the amount of context being
used. This feature vector is used to query the ap-
propriate classifier model to obtain a vector of la-
bels with weights. The parser action labels (STP
and STC) are used to extend the subtask tree. For
example, in the shift-reduce method, shift results
in a push action on the stack, while reduce-X re-
sults in popping the top two elements off the stack
and pushing X on to the stack. The dialog act la-
bels (DAP and DAC) are used to label the leaves
of the subtask tree (the utterances).
The decoder can use n-best results from the
classifier to enlarge the search space. In order
to manage the search space effectively, the de-
coder uses a beam pruning strategy. The decod-
ing process proceeds until the end of the dialog is
reached. In this paper, we assume that the end of
the dialog is given to the decoder3.
Given that the classifiers are error-prone in their
assignment of labels, the parsing step of the de-
coder needs to be robust to these errors. We ex-
ploit the state of the stack in the different meth-
ods to rule out incompatible parser actions (e.g. a
reduce-X action when the stack has one element,
a shift action on an already shifted utterance). We
also use n-best results to alleviate the impact of
classification errors. Finally, at the end of the di-
alog, if there are unattached constituents on the
stack, the decoder attaches them as sibling con-
stituents to produce a rooted tree structure. These
constraints contribute to robustness, but cannot be
used with the connection path method, since any
connection path (parsing action) suggested by the
classifier can be incorporated into the incremental
parse tree. Consequently, in the connection path
method there are fewer opportunities to correct the
errors made by the classifiers.
</bodyText>
<subsectionHeader confidence="0.987071">
5.4 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.993246933333333">
We evaluate dialog act classification and predic-
tion by comparing the automatically assigned di-
alog act tags to the reference dialog act tags.
For these tasks we report accuracy. We evaluate
subtask classification and prediction by compar-
ing the subtask trees output by the different pars-
ing methods to the reference subtask tree. We
use the labeled crossing bracket metric (typically
used in the syntactic parsing literature (Harrison et
al., 1991)), which computes recall, precision and
crossing brackets for the constituents (subtrees) in
a hypothesized parse tree given the reference parse
tree. We report F-measure, which is a combination
of recall and precision.
For each task, performance is reported for 1, 3,
</bodyText>
<footnote confidence="0.999160666666667">
3This is an unrealistic assumption if the decoder is to
serve as a dialog model. We expect to address this limitation
in future work.
</footnote>
<page confidence="0.994614">
99
</page>
<figure confidence="0.8666442">
F
5, and 10-best dynamic decoding as well as oracle
(Or) and for 0, 1 and 3 utterances of context.
5.5 Results
100
80
60
40
20
0
</figure>
<figureCaption confidence="0.9989635">
Figure 5: Performance of parse-based methods for
subtask tree building
</figureCaption>
<bodyText confidence="0.997192636363636">
Figure 5 shows the performance of the different
methods for determining the subtask tree of the di-
alog. Wider beam widths do not lead to improved
performance for any method. One utterance of
context is best for shift-reduce and start-join; three
is best for the connection path method. The shift-
reduce method performs the best. With 1 utter-
ance of context, its 1-best f-score is 47.86, as com-
pared with 34.91 for start-complete, 25.13 for the
connection path method, and 21.32 for the chunk-
based baseline. These performance differences are
statistically significant at p &lt; .001. However, the
best performance for the shift-reduce method is
still significantly worse than oracle.
All of the methods are subject to some ‘stick-
iness’, a certain preference to stay within the
current subtask rather than starting a new one.
Also, all of the methods tended to perform poorly
on parsing subtasks that occur rarely (e.g. call-
forward, order-change) or that occur at many dif-
ferent locations in the dialog (e.g. out-of-domain,
order-problem, check-availability). For example,
the shift-reduce method did not make many shift
errors but did frequently b-reduce on an incor-
rect non-terminal (indicating trouble identifying
subtask boundaries). Some non-terminals most
likely to be labeled incorrectly by this method
(for both agent and user) are: call-forward, order-
change, summary, order-problem, opening and
out-of-domain.
Similarly, the start-complete method frequently
mislabeled a non-terminal in a complete action,
e.g. misc-other, check-availability, summary or
contact-info. It also quite frequently mislabeled
nonterminals in n-start actions, e.g. order-item,
contact-info or summary. Both of these errors in-
dicate trouble identifying subtask boundaries.
It is harder to analyze the output from the con-
nection path method. This method is more likely
to mislabel tree-internal nodes than those imme-
diately above the leaves. However, the same
non-terminals show up as error-prone for this
method as for the others: out-of-domain, check-
availability, order-problem and summary.
</bodyText>
<figure confidence="0.730948">
Number utterances history
Nbest
</figure>
<figureCaption confidence="0.9992075">
Figure 6: Performance of dialog act assignment to
user’s utterances.
</figureCaption>
<bodyText confidence="0.9294645">
Figure 6 shows accuracy for classification of
user dialog acts. Wider beam widths do not
lead to signficantly improved performance for any
method. Zero utterances of context gives the high-
est accuracy for all methods. All methods per-
form fairly well, but no method significantly out-
performs any other: with 0 utterances of context,
1-best accuracy is .681 for the connection path
method, .698 for the start-complete method and
.698 for the shift-reduce method. We note that
these results are competitive with those reported
in the literature (e.g. (Poesio and Mikheev, 1998;
Serafin and Eugenio, 2004)), although the dialog
corpus and the label sets are different.
The most common errors in dialog act classifi-
cation occur with dialog acts that occur 40 times
or fewer in the testing data (out of 3610 testing
utterances), and with Not(Information).
</bodyText>
<figureCaption confidence="0.9852265">
Figure 7 shows accuracy for prediction of agent
dialog acts. Performance for this task is lower than
</figureCaption>
<figure confidence="0.997299052631579">
0 1 3 0 1 3 0 1 3 0 1 3 0 1 3
1 3 5 10 Or
Accuracy
0.8
0.6
0.4
0.2
0.0
1.0
start—complete
connection—paths
shift—reduce
start—complete
connection—paths
shift—reduce
0 1 3 0 1 3 0 1 3 0 1 3 0 1 3
1 3 5 10 Or
Number utterances history
Nbest
</figure>
<page confidence="0.698029">
100
</page>
<table confidence="0.995948">
Speaker Utterance Shift-Reduce Start-Complete Connection Path
A This is Sally shift, Hello start-opening, Hello opening S, Hello
A How may I help you shift, binary-reduce-out-of- complete-opening, opening S, Hello
domain, Hello Hello
B Yes Not(Information), shift, Not(Information), Not(Information), open-
binary-reduce-out-of-domain complete-opening ing S
B Um I would like to place Rquest(Make-Order), shift, Rquest(Make-Order), Rquest(Make-Order),
an order please binary-reduce-opening complete-opening, opening S
n-start-S
A May I have your tele- shift, Acknowledge start-contact-info, Ac- contact-info S,
phone number with the knowledge Request(Phone-Number)
area code
B Uh the phone number is Explain(Phone-Number), Explain(Phone- Explain(Phone-Number),
[number] shift, binary-reduce-contact- Number), complete- contact-info S
info contact-info
</table>
<tableCaption confidence="0.999112">
Table 4: Dialog extract with subtask tree building actions for three parsing methods
</tableCaption>
<figure confidence="0.989015">
Accuracy
0.8
0.6
0.4
0.2
0.0
1.0
start—complete
connection—paths
shift—reduce
</figure>
<bodyText confidence="0.999335555555555">
dialog acts pertaining to Order-Info and Product-
Info acts are commonly mislabeled, which could
potentially indicate that these labels require a sub-
tle distinction between information pertaining to
an order and information pertaining to a product.
Table 4 shows the parsing actions performed by
each of our methods on the dialog snippet pre-
sented in Figure 4. For this example, the connec-
tion path method’s output is correct in all cases.
</bodyText>
<figure confidence="0.999287857142857">
0 1 3 0 1 3 0 1 3 0 1
1 3 5 10
Number utterances history
Nbest
3 0 1 3
Or
6 Conclusions and Future Work
</figure>
<figureCaption confidence="0.9905265">
Figure 7: Performance of dialog act prediction
used to generate agent utterances.
</figureCaption>
<bodyText confidence="0.999980071428571">
that for dialog act classification because this is a
prediction task. Wider beam widths do not gener-
ally lead to improved performance for any method.
Three utterances of context generally gives the
best performance. The shift-reduce method per-
forms significantly better than the connection path
method with a beam width of 1 (p &lt; .01), but not
at larger beam widths; there are no other signifi-
cant performance differences between methods at
3 utterances of context. With 3 utterances of con-
text, 1-best accuracies are .286 for the connection
path method, .329 for the start-complete method
and .356 for the shift-reduce method.
The most common errors in dialog act predic-
tion occur with rare dialog acts, Not(Information),
and the prediction of Acknowledge at the start of a
turn (we did not remove grounding acts from the
data). With the shift-reduce method, some YNQ
acts are commonly mislabeled. With all methods,
In this paper, we present a parsing-based model
of task-oriented dialog that tightly integrates in-
terpretation and generation using a subtask tree
representation, can be trained from data, and runs
incrementally for use in dialog management. At
the core of this model is a parser that incremen-
tally builds the dialog task structure as it interprets
user actions and generates system actions. We ex-
periment with three different incremental parsing
methods for our dialog model. Our proposed shift-
reduce method is the best-performing so far, and
performance of this method for dialog act classifi-
cation and task/subtask modeling is good enough
to be usable. However, performance of all the
methods for dialog act prediction is too low to be
useful at the moment. In future work, we will ex-
plore improved models for this task that make use
of global information about the task (e.g. whether
each possible subtask has yet been completed;
whether required and optional task-related con-
cepts such as shipping address have been filled).
We will also separate grounding and task-related
behaviors in our model.
</bodyText>
<page confidence="0.998593">
101
</page>
<sectionHeader confidence="0.998339" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999780626262626">
J. Alexandersson and N. Reithinger. 1997. Learning
dialogue structures from a corpus. In Proceedings
of Eurospeech.
J. Baldridge and A. Lascarides. 2005. Probabilistic
head-driven parsing for discourse. In Proceedings
of CoNLL.
S. Bangalore, G. Di Fabbrizio, and A. Stent. 2006.
Learning the structure of task-driven human-human
dialogs. In Proceedings of COLING/ACL.
A. Barrett and D. Weld. 1994. Task-decomposition via
plan parsing. In Proceedings of AAAI.
A. Berger, S.D. Pietra, and V.D. Pietra. 1996. A Max-
imum Entropy Approach to Natural Language Pro-
cessing. Computational Linguistics, 22(1):39–71.
N. Blaylock and J. F. Allen. 2006. Hierarchical instan-
tiated goal recognition. In Proceedings of the AAAI
Workshop on Modeling Others from Observations.
D. Bohus and A. Rudnicky. 2003. RavenClaw: Dialog
management using hierarchical task decomposition
and an expectation agenda. In Proceedings of Eu-
rospeech.
H.H. Bui. 2003. A general model for online probabal-
istic plan recognition. In Proceedings of IJCAI.
S. Carberry. 2001. Techniques for plan recogni-
tion. User Modeling and User-Adapted Interaction,
11(1–2):31–48.
M. Collins. 2003. Head-driven statistical models for
natural language parsing. Computational Linguis-
tics, 29(4):589–638.
F. Costa, V. Lombardo, P. Frasconi, and G. Soda. 2001.
Wide coverage incremental parsing by learning at-
tachment preferences. In Proceedings of the Con-
ference of the Italian Association for ArtiÞcial Intel-
ligence (AIIA).
D. Cristea. 2000. An incremental discourse parser ar-
chitecture. In Proceedings of the 2nd International
Conference on Natural Language Processing.
K. Forbes, E. Miltsakaki, R. Prasad, A. Sarkar,
A. Joshi, and B. Webber. 2003. D-LTAG system:
Discourse parsing with a lexicalized tree-adjoining
grammar. Journal of Logic, Language and Informa-
tion, 12(3):261–279.
B.J. Grosz and C.L. Sidner. 1986. Attention, inten-
tions and the structure of discourse. Computational
Linguistics, 12(3):175–204.
P. Haffner. 2006. Scaling large margin classifiers for
spoken language understanding. Speech Communi-
cation, 48(3–4):239–261.
J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative
classifiers for deterministic dependency parsing. In
Proceedings of COLING/ACL.
P. Harrison, S. Abney, D. Fleckenger, C. Gdaniec,
R. Grishman, D. Hindle, B. Ingria, M. Marcus,
B. Santorini, and T. Strzalkowski. 1991. Evaluating
syntax performance of parser/grammars of English.
In Proceedings of the Workshop on Evaluating Nat-
ural Language Processing Systems, ACL.
H. LeThanh, G. Abeysinghe, and C. Huyck. 2004.
Generating discourse structures for written texts. In
Proceedings of COLING.
D. Litman and J. Allen. 1987. A plan recognition
model for subdialogs in conversations. Cognitive
Science, 11(2):163–200.
K. Lochbaum. 1998. A collaborative planning model
of intentional structure. Computational Linguistics,
24(4):525–572.
M. Poesio and A. Mikheev. 1998. The predictive
power of game structure in dialogue act recognition:
experimental results using maximum entropy esti-
mation. In Proceedings of ICSLP.
L. Polanyi, C. Culy, M. van den Berg, G. L. Thione, and
D. Ahn. 2004. A rule based approach to discourse
parsing. In Proceedings of SIGdial.
D.V. Pynadath and M.P. Wellman. 2000. Probabilistic
state-dependent grammars for plan recognition. In
Proceedings of UAI.
A. Ratnaparkhi. 1997. A linear observed time statis-
tical parser based on maximum entropy models. In
Proceedings of EMNLP.
C. Rich and C.L. Sidner. 1997. COLLAGEN: When
agents collaborate with people. In Proceedings of
the First International Conference on Autonomous
Agents.
K. Sagae and A. Lavie. 2006. A best-first proba-
bilistic shift-reduce parser. In Proceedings of COL-
ING/ACL.
R. Serafin and B. Di Eugenio. 2004. FLSA: Extending
latent semantic analysis with features for dialogue
act classification. In Proceedings of ACL.
C.L. Sidner. 1985. Plan parsing for intended re-
sponse recognition in discourse. Computational In-
telligence, 1(1):1–10.
R. Soricut and D. Marcu. 2003. Sentence level dis-
course parsing using syntactic and lexical informa-
tion. In Proceedings of NAACL/HLT.
C. Sporleder and A. Lascarides. 2004. Combining hi-
erarchical clustering and machine learning to pre-
dict high-level discourse structure. In Proceedings
of COLING.
</reference>
<page confidence="0.99862">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973632">
<title confidence="0.990087">Incremental Parsing Models for Dialog Task Structure</title>
<author confidence="0.999978">Bangalore J Stent</author>
<affiliation confidence="0.990674">AT&amp;T Labs – Research, Inc., 180 Park Avenue,</affiliation>
<address confidence="0.999501">Florham Park, NJ 07932, USA</address>
<abstract confidence="0.999567470588235">In this paper, we present an integrated model of the two central tasks of dialog management: interpreting user actions and generating system actions. We model the task as a problem and the generation task as a prediction problem. These two tasks are interleaved in an incremental parsing-based dialog model. We compare three alternative parsing methods for this dialog model using a corpus of human-human spoken dialog from a catalog ordering domain that has been annotated for dialog acts and task/subtask information. We contrast the amount of context provided by each method and its impact on performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Alexandersson</author>
<author>N Reithinger</author>
</authors>
<title>Learning dialogue structures from a corpus.</title>
<date>1997</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="7406" citStr="Alexandersson and Reithinger, 1997" startWordPosition="1188" endWordPosition="1192">2 shows the subtask tree for a sample dialog in our domain (catalog ordering). An order placement task is typically composed of the sequence of subtasks opening, contact-information, order-item, related-offers, summary. Subtasks can be nested; the nesting can be as deep as five levels in our data. Most often the nesting is at the leftmost or rightmost frontier of the subtask tree. As the dialog proceeds, an utterance from a participant is accommodated into the subtask tree in an incremental manner, much like an incremental syntactic parser accommodates the next word into a partial parse tree (Alexandersson and Reithinger, 1997). An illustration of the incremental evolution of dialog structure is shown in Figure 4. However, while a syntactic parser processes input from a single source, our dialog parser parses user-system exchanges: user utterances are interpreted, while system utterances are generated. So the steps taken by our dialog parser to incorporate an utterance into the subtask tree depend on whether the utterance was produced by the agent or the user (as shown in Figure 3). User utterances Each user turn is split into clauses (utterances). Each clause is supertagged Dialog Utterance Utterance Utterance Topi</context>
</contexts>
<marker>Alexandersson, Reithinger, 1997</marker>
<rawString>J. Alexandersson and N. Reithinger. 1997. Learning dialogue structures from a corpus. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Baldridge</author>
<author>A Lascarides</author>
</authors>
<title>Probabilistic head-driven parsing for discourse.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="3976" citStr="Baldridge and Lascarides (2005)" startWordPosition="635" endWordPosition="639">ing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (Collins, 2003)) to construct rhetorical structure trees for a spoken dialog corpus. However, their parser was Proceedings of the 12th Conference of the European Chapter of the ACL, pages 94–102, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 94 Task Task Task Clause Figure 1: A schema of a shared plan tree for a dialog. not incremental; it used global features such as the number of turn changes. Also, it focused strictly in interpretation of input utterances; it could not predict act</context>
</contexts>
<marker>Baldridge, Lascarides, 2005</marker>
<rawString>J. Baldridge and A. Lascarides. 2005. Probabilistic head-driven parsing for discourse. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Di Fabbrizio</author>
<author>A Stent</author>
</authors>
<title>Learning the structure of task-driven human-human dialogs.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<marker>Bangalore, Di Fabbrizio, Stent, 2006</marker>
<rawString>S. Bangalore, G. Di Fabbrizio, and A. Stent. 2006. Learning the structure of task-driven human-human dialogs. In Proceedings of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Barrett</author>
<author>D Weld</author>
</authors>
<title>Task-decomposition via plan parsing.</title>
<date>1994</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="5912" citStr="Barrett and Weld, 1994" startWordPosition="937" endWordPosition="940">n, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Order Placement Figure 2: Sample output (subtask tree) from a parse-based model for the catalog ordering domain. to parse plans. Their parser, however, was not probabilistic or targeted at dialog processing. 3 Dialog Structure We consider a task-oriented dialog to be the result of incremental creation of a shared plan by the participants (Lochbaum, 1998). The shared plan is represented as a single tree T that incorporates the task/subtask structure, dialog acts, syntactic structure and lexical content of the dialog, as shown in Figure 1. A task is a </context>
</contexts>
<marker>Barrett, Weld, 1994</marker>
<rawString>A. Barrett and D. Weld. 1994. Task-decomposition via plan parsing. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S D Pietra</author>
<author>V D Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="14259" citStr="Berger et al., 1996" startWordPosition="2358" endWordPosition="2361">nk you for calling XYZ catalog this is mary how may I help you Ack Hello thank you for calling XYZ catalog this is mary how may I help you Ack may we deliver this order to your home yes please ...... Request(MakeOrder) Ack Hello Request(MakeOrder) Ack thank yes one second please Shipping—Address Shipping—Address thank yes one second you yes i would like to place an order yes i would like to place an order a feature vector containing contextual information for the parsing action (see Section 5.1). These feature vectors and the associated parser actions are used to train maximum entropy models (Berger et al., 1996). These models are then used to incrementally incorporate the utterances for a new dialog into that dialog’s subtask tree as the dialog progresses, as shown in Figure 3. 4.1 Shift-Reduce Method In this method, the subtask tree is recovered through a right-branching shift-reduce parsing process (Hall et al., 2006; Sagae and Lavie, 2006). The parser shifts each utterance on to the stack. It then inspects the stack and decides whether to do one or more reduce actions that result in the creation of subtrees in the subtask tree. The parser maintains two data structures – a stack and a tree. The act</context>
<context position="23381" citStr="Berger et al., 1996" startWordPosition="3845" endWordPosition="3848">wice with different stack contents. 5.2 Training Method We randomly selected roughly 90% of the dialogs for training, and used the remainder for testing. We separately trained models for: user dialog act classification (DAC, Equation 1); user task/subtask classification (STC, Equation 2); agent task/subtask prediction (STP, Equation 3); and agent dialog act prediction (DAP, Equation 4). In order to estimate the conditional distributions shown in Table 1, we use the general technique of choosing the MaxEnt distribution that properly estimates the average of each feature over the training data (Berger et al., 1996). We use the machine learning toolkit LLAMA (Haffner, 2006), which encodes multiclass classification problems using binary MaxEnt classifiers to increase the speed of training and to scale the method to large data sets. 5.3 Decoding Method The decoding process for the three parsing methods is illustrated in Figure 3 and has four stages: STP, DAP, DAC, and STC. As already explained, each of these steps in the decoding process is modeled as either a prediction task or a classification task. The decoder constructs an input feature vector depending on the amount of context being used. This feature</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S.D. Pietra, and V.D. Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Blaylock</author>
<author>J F Allen</author>
</authors>
<title>Hierarchical instantiated goal recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the AAAI Workshop on Modeling Others from Observations.</booktitle>
<contexts>
<context position="5699" citStr="Blaylock and Allen, 2006" startWordPosition="904" endWordPosition="907"> approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Order Placement Figure 2: Sample output (subtask tree) from a parse-based model for the catalog ordering domain. to parse plans. Their parser, however, was not probabilistic or targeted at dialog processing. 3 Dialog Structure We consider a task-oriented dialog to be the result of incremental creation of a shared plan by the participants (Lo</context>
</contexts>
<marker>Blaylock, Allen, 2006</marker>
<rawString>N. Blaylock and J. F. Allen. 2006. Hierarchical instantiated goal recognition. In Proceedings of the AAAI Workshop on Modeling Others from Observations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bohus</author>
<author>A Rudnicky</author>
</authors>
<title>RavenClaw: Dialog management using hierarchical task decomposition and an expectation agenda.</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="5360" citStr="Bohus and Rudnicky, 2003" startWordPosition="854" endWordPosition="857">r information extraction or summarization). This influences our approach to dialog modeling in two ways. First, the subtask tree we build represents the functional task structure of the dialog (rather than the rhetorical structure of the dialog). Second, our dialog parser must be entirely incremental. Plan-Based Dialog Models Plan-based approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Orde</context>
</contexts>
<marker>Bohus, Rudnicky, 2003</marker>
<rawString>D. Bohus and A. Rudnicky. 2003. RavenClaw: Dialog management using hierarchical task decomposition and an expectation agenda. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Bui</author>
</authors>
<title>A general model for online probabalistic plan recognition.</title>
<date>2003</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="5672" citStr="Bui, 2003" startWordPosition="902" endWordPosition="903"> Plan-based approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Order Placement Figure 2: Sample output (subtask tree) from a parse-based model for the catalog ordering domain. to parse plans. Their parser, however, was not probabilistic or targeted at dialog processing. 3 Dialog Structure We consider a task-oriented dialog to be the result of incremental creation of a shared p</context>
</contexts>
<marker>Bui, 2003</marker>
<rawString>H.H. Bui. 2003. A general model for online probabalistic plan recognition. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Techniques for plan recognition. User Modeling and User-Adapted Interaction,</title>
<date>2001</date>
<pages>11--1</pages>
<contexts>
<context position="5334" citStr="Carberry, 2001" startWordPosition="852" endWordPosition="853"> (rather than for information extraction or summarization). This influences our approach to dialog modeling in two ways. First, the subtask tree we build represents the functional task structure of the dialog (rather than the rhetorical structure of the dialog). Second, our dialog parser must be entirely incremental. Plan-Based Dialog Models Plan-based approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an increme</context>
</contexts>
<marker>Carberry, 2001</marker>
<rawString>S. Carberry. 2001. Techniques for plan recognition. User Modeling and User-Adapted Interaction, 11(1–2):31–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="4059" citStr="Collins, 2003" startWordPosition="650" endWordPosition="651">), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (Collins, 2003)) to construct rhetorical structure trees for a spoken dialog corpus. However, their parser was Proceedings of the 12th Conference of the European Chapter of the ACL, pages 94–102, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 94 Task Task Task Clause Figure 1: A schema of a shared plan tree for a dialog. not incremental; it used global features such as the number of turn changes. Also, it focused strictly in interpretation of input utterances; it could not predict actions by either dialog partner. In contrast to other work on discourse parsing, we w</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>M. Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–638.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Costa</author>
<author>V Lombardo</author>
<author>P Frasconi</author>
<author>G Soda</author>
</authors>
<title>Wide coverage incremental parsing by learning attachment preferences.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference of the Italian Association for ArtiÞcial Intelligence (AIIA).</booktitle>
<contexts>
<context position="18774" citStr="Costa et al., 2001" startWordPosition="3122" endWordPosition="3125">k, before popping the top two elements off the stack and adding the subtree for special-order into the dialog’s subtask tree. 4.3 Connection Path Method In contrast to the shift-reduce and the startcomplete methods described above, the connection path method does not use a stack to track the global state of the parse. Instead, the parser directly predicts the connection path (path from the root to the terminal) for each utterance. The collection of connection paths for all the utterances in a dialog defines the parse tree. This encoding was previously used for incremental sentence parsing by (Costa et al., 2001). With this method, there are many more choices of decision for the parser (195 decisions for our data) compared to the shiftreduce (32) and start-complete (82) methods. Consider the same subdialog as before, A: would you like a free magazine? U: no. The processing of this dialog using our connection path dialog parser would proceed as follows. First, the STP model predicts S-special-offer for sta; the DAP model predicts YNP(Promotions) for daa; the generator outputs would you like a free magazine?; and the parser adds a subtree rooted at special-offer, with one terminal for the current uttera</context>
</contexts>
<marker>Costa, Lombardo, Frasconi, Soda, 2001</marker>
<rawString>F. Costa, V. Lombardo, P. Frasconi, and G. Soda. 2001. Wide coverage incremental parsing by learning attachment preferences. In Proceedings of the Conference of the Italian Association for ArtiÞcial Intelligence (AIIA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cristea</author>
</authors>
<title>An incremental discourse parser architecture.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="3512" citStr="Cristea, 2000" startWordPosition="561" endWordPosition="562">k There are two threads of research that are relevant to our work: work on parsing (written and spoken) discourse, and work on plan-based dialog models. Discourse Parsing Discourse parsing is the process of building a hierarchical model of a discourse from its basic elements (sentences or clauses), as one would build a parse of a sentence from its words. There has now been considerable work on discourse parsing using statistical bottom-up parsing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (Collins, 2003)) to construct rhetorical structure trees for a spoke</context>
</contexts>
<marker>Cristea, 2000</marker>
<rawString>D. Cristea. 2000. An incremental discourse parser architecture. In Proceedings of the 2nd International Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes</author>
<author>E Miltsakaki</author>
<author>R Prasad</author>
<author>A Sarkar</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>D-LTAG system: Discourse parsing with a lexicalized tree-adjoining grammar.</title>
<date>2003</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="3608" citStr="Forbes et al., 2003" startWordPosition="574" endWordPosition="577"> and spoken) discourse, and work on plan-based dialog models. Discourse Parsing Discourse parsing is the process of building a hierarchical model of a discourse from its basic elements (sentences or clauses), as one would build a parse of a sentence from its words. There has now been considerable work on discourse parsing using statistical bottom-up parsing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (Collins, 2003)) to construct rhetorical structure trees for a spoken dialog corpus. However, their parser was Proceedings of the 12th Conference of the European Ch</context>
</contexts>
<marker>Forbes, Miltsakaki, Prasad, Sarkar, Joshi, Webber, 2003</marker>
<rawString>K. Forbes, E. Miltsakaki, R. Prasad, A. Sarkar, A. Joshi, and B. Webber. 2003. D-LTAG system: Discourse parsing with a lexicalized tree-adjoining grammar. Journal of Logic, Language and Information, 12(3):261–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1126" citStr="Grosz and Sidner, 1986" startWordPosition="172" endWordPosition="175">incremental parsing-based dialog model. We compare three alternative parsing methods for this dialog model using a corpus of human-human spoken dialog from a catalog ordering domain that has been annotated for dialog acts and task/subtask information. We contrast the amount of context provided by each method and its impact on performance. 1 Introduction Corpora of spoken dialog are now widely available, and frequently come with annotations for tasks/games, dialog acts, named entities and elements of syntactic structure. These types of information provide rich clues for building dialog models (Grosz and Sidner, 1986). Dialog models can be built offline (for dialog mining and summarization), or online (for dialog management). A dialog manager is the component of a dialog system that is responsible for interpreting user actions in the dialog context, and for generating system actions. Needless to say, a dialog manager operates incrementally as the dialog progresses. In typical commercial dialog systems, the interpretation and generation processes operate independently of each other, with only a small amount of shared context. By contrast, in this paper we describe a dialog model that (1) tightly integrates </context>
<context position="11124" citStr="Grosz and Sidner, 1986" startWordPosition="1827" endWordPosition="1830">erances), but the corresponding clause for the agent utterance ca is to be predicted and hence is not part of conditioning context in the generation model. 4 Dialog Parsing A dialog parser can produce a “shallow” or “deep” tree structure. A shallow parse is one in which utterances are grouped together into subtasks, but the dominance relations among subtasks are not tracked. We call this model a chunk-based dialog model (Bangalore et al., 2006). The chunkbased model has limitations. For example, dominance relations among subtasks are important for dialog processes such as anaphora resolution (Grosz and Sidner, 1986). Also, the chunkbased model is representationally inadequate for center-embedded nestings of subtasks, which do occur in our domain, although less frequently than the more prevalent “tail-recursive” structures. We use the term parse-based dialog model to refer to deep parsing models for dialog which not only segment the dialog into chunks but also predict dominance relations among chunks. For this paper, we experimented with three alternative methods for building parse-based models: shiftreduce, start-complete and connection path. Each of these operates on the subtask tree for the dialog incr</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B.J. Grosz and C.L. Sidner. 1986. Attention, intentions and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Haffner</author>
</authors>
<title>Scaling large margin classifiers for spoken language understanding.</title>
<date>2006</date>
<journal>Speech Communication,</journal>
<pages>48--3</pages>
<contexts>
<context position="23440" citStr="Haffner, 2006" startWordPosition="3856" endWordPosition="3857">ly selected roughly 90% of the dialogs for training, and used the remainder for testing. We separately trained models for: user dialog act classification (DAC, Equation 1); user task/subtask classification (STC, Equation 2); agent task/subtask prediction (STP, Equation 3); and agent dialog act prediction (DAP, Equation 4). In order to estimate the conditional distributions shown in Table 1, we use the general technique of choosing the MaxEnt distribution that properly estimates the average of each feature over the training data (Berger et al., 1996). We use the machine learning toolkit LLAMA (Haffner, 2006), which encodes multiclass classification problems using binary MaxEnt classifiers to increase the speed of training and to scale the method to large data sets. 5.3 Decoding Method The decoding process for the three parsing methods is illustrated in Figure 3 and has four stages: STP, DAP, DAC, and STC. As already explained, each of these steps in the decoding process is modeled as either a prediction task or a classification task. The decoder constructs an input feature vector depending on the amount of context being used. This feature vector is used to query the appropriate classifier model t</context>
</contexts>
<marker>Haffner, 2006</marker>
<rawString>P. Haffner. 2006. Scaling large margin classifiers for spoken language understanding. Speech Communication, 48(3–4):239–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Discriminative classifiers for deterministic dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<contexts>
<context position="14572" citStr="Hall et al., 2006" startWordPosition="2409" endWordPosition="2412">ank yes one second you yes i would like to place an order yes i would like to place an order a feature vector containing contextual information for the parsing action (see Section 5.1). These feature vectors and the associated parser actions are used to train maximum entropy models (Berger et al., 1996). These models are then used to incrementally incorporate the utterances for a new dialog into that dialog’s subtask tree as the dialog progresses, as shown in Figure 3. 4.1 Shift-Reduce Method In this method, the subtask tree is recovered through a right-branching shift-reduce parsing process (Hall et al., 2006; Sagae and Lavie, 2006). The parser shifts each utterance on to the stack. It then inspects the stack and decides whether to do one or more reduce actions that result in the creation of subtrees in the subtask tree. The parser maintains two data structures – a stack and a tree. The actions of the parser change the contents of the stack and create nodes in the dialog tree structure. The actions for the parser include unaryreduce-X, binary-reduce-X and shift, where X is each of the non-terminals (subtask labels) in the tree. Shift pushes a token representing the utterance onto the stack; binary</context>
</contexts>
<marker>Hall, Nivre, Nilsson, 2006</marker>
<rawString>J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative classifiers for deterministic dependency parsing. In Proceedings of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Harrison</author>
<author>S Abney</author>
<author>D Fleckenger</author>
<author>C Gdaniec</author>
<author>R Grishman</author>
<author>D Hindle</author>
<author>B Ingria</author>
<author>M Marcus</author>
<author>B Santorini</author>
<author>T Strzalkowski</author>
</authors>
<title>Evaluating syntax performance of parser/grammars of English.</title>
<date>1991</date>
<booktitle>In Proceedings of the Workshop on Evaluating Natural Language Processing Systems, ACL.</booktitle>
<contexts>
<context position="26178" citStr="Harrison et al., 1991" startWordPosition="4320" endWordPosition="4323"> the incremental parse tree. Consequently, in the connection path method there are fewer opportunities to correct the errors made by the classifiers. 5.4 Evaluation Metrics We evaluate dialog act classification and prediction by comparing the automatically assigned dialog act tags to the reference dialog act tags. For these tasks we report accuracy. We evaluate subtask classification and prediction by comparing the subtask trees output by the different parsing methods to the reference subtask tree. We use the labeled crossing bracket metric (typically used in the syntactic parsing literature (Harrison et al., 1991)), which computes recall, precision and crossing brackets for the constituents (subtrees) in a hypothesized parse tree given the reference parse tree. We report F-measure, which is a combination of recall and precision. For each task, performance is reported for 1, 3, 3This is an unrealistic assumption if the decoder is to serve as a dialog model. We expect to address this limitation in future work. 99 F 5, and 10-best dynamic decoding as well as oracle (Or) and for 0, 1 and 3 utterances of context. 5.5 Results 100 80 60 40 20 0 Figure 5: Performance of parse-based methods for subtask tree bui</context>
</contexts>
<marker>Harrison, Abney, Fleckenger, Gdaniec, Grishman, Hindle, Ingria, Marcus, Santorini, Strzalkowski, 1991</marker>
<rawString>P. Harrison, S. Abney, D. Fleckenger, C. Gdaniec, R. Grishman, D. Hindle, B. Ingria, M. Marcus, B. Santorini, and T. Strzalkowski. 1991. Evaluating syntax performance of parser/grammars of English. In Proceedings of the Workshop on Evaluating Natural Language Processing Systems, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H LeThanh</author>
<author>G Abeysinghe</author>
<author>C Huyck</author>
</authors>
<title>Generating discourse structures for written texts.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="3653" citStr="LeThanh et al., 2004" startWordPosition="582" endWordPosition="585">sed dialog models. Discourse Parsing Discourse parsing is the process of building a hierarchical model of a discourse from its basic elements (sentences or clauses), as one would build a parse of a sentence from its words. There has now been considerable work on discourse parsing using statistical bottom-up parsing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (Collins, 2003)) to construct rhetorical structure trees for a spoken dialog corpus. However, their parser was Proceedings of the 12th Conference of the European Chapter of the ACL, pages 94–102, Athens, Greec</context>
</contexts>
<marker>LeThanh, Abeysinghe, Huyck, 2004</marker>
<rawString>H. LeThanh, G. Abeysinghe, and C. Huyck. 2004. Generating discourse structures for written texts. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>J Allen</author>
</authors>
<title>A plan recognition model for subdialogs in conversations.</title>
<date>1987</date>
<journal>Cognitive Science,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="5296" citStr="Litman and Allen, 1987" startWordPosition="845" endWordPosition="848">parsing process directly for dialog management (rather than for information extraction or summarization). This influences our approach to dialog modeling in two ways. First, the subtask tree we build represents the functional task structure of the dialog (rather than the rhetorical structure of the dialog). Second, our dialog parser must be entirely incremental. Plan-Based Dialog Models Plan-based approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett</context>
</contexts>
<marker>Litman, Allen, 1987</marker>
<rawString>D. Litman and J. Allen. 1987. A plan recognition model for subdialogs in conversations. Cognitive Science, 11(2):163–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lochbaum</author>
</authors>
<title>A collaborative planning model of intentional structure.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="5377" citStr="Lochbaum, 1998" startWordPosition="858" endWordPosition="859">r summarization). This influences our approach to dialog modeling in two ways. First, the subtask tree we build represents the functional task structure of the dialog (rather than the rhetorical structure of the dialog). Second, our dialog parser must be entirely incremental. Plan-Based Dialog Models Plan-based approaches to dialog modeling, like ours, operate directly on the dialog’s task structure. The process of task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Order Placement Figur</context>
</contexts>
<marker>Lochbaum, 1998</marker>
<rawString>K. Lochbaum. 1998. A collaborative planning model of intentional structure. Computational Linguistics, 24(4):525–572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>A Mikheev</author>
</authors>
<title>The predictive power of game structure in dialogue act recognition: experimental results using maximum entropy estimation.</title>
<date>1998</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<contexts>
<context position="29529" citStr="Poesio and Mikheev, 1998" startWordPosition="4841" endWordPosition="4844">nce of dialog act assignment to user’s utterances. Figure 6 shows accuracy for classification of user dialog acts. Wider beam widths do not lead to signficantly improved performance for any method. Zero utterances of context gives the highest accuracy for all methods. All methods perform fairly well, but no method significantly outperforms any other: with 0 utterances of context, 1-best accuracy is .681 for the connection path method, .698 for the start-complete method and .698 for the shift-reduce method. We note that these results are competitive with those reported in the literature (e.g. (Poesio and Mikheev, 1998; Serafin and Eugenio, 2004)), although the dialog corpus and the label sets are different. The most common errors in dialog act classification occur with dialog acts that occur 40 times or fewer in the testing data (out of 3610 testing utterances), and with Not(Information). Figure 7 shows accuracy for prediction of agent dialog acts. Performance for this task is lower than 0 1 3 0 1 3 0 1 3 0 1 3 0 1 3 1 3 5 10 Or Accuracy 0.8 0.6 0.4 0.2 0.0 1.0 start—complete connection—paths shift—reduce start—complete connection—paths shift—reduce 0 1 3 0 1 3 0 1 3 0 1 3 0 1 3 1 3 5 10 Or Number utteranc</context>
</contexts>
<marker>Poesio, Mikheev, 1998</marker>
<rawString>M. Poesio and A. Mikheev. 1998. The predictive power of game structure in dialogue act recognition: experimental results using maximum entropy estimation. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Polanyi</author>
<author>C Culy</author>
<author>M van den Berg</author>
<author>G L Thione</author>
<author>D Ahn</author>
</authors>
<title>A rule based approach to discourse parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGdial.</booktitle>
<marker>Polanyi, Culy, van den Berg, Thione, Ahn, 2004</marker>
<rawString>L. Polanyi, C. Culy, M. van den Berg, G. L. Thione, and D. Ahn. 2004. A rule based approach to discourse parsing. In Proceedings of SIGdial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D V Pynadath</author>
<author>M P Wellman</author>
</authors>
<title>Probabilistic state-dependent grammars for plan recognition.</title>
<date>2000</date>
<booktitle>In Proceedings of UAI.</booktitle>
<contexts>
<context position="5806" citStr="Pynadath and Wellman, 2000" startWordPosition="917" endWordPosition="920">f task-oriented dialog is treated as a special case of AI-style plan recognition (Sidner,1985; Litman and Allen, 1987; Rich and Sidner,1997; Carberry, 2001; Bohus and Rudnicky, 2003; Lochbaum, 1998). Plan-based dialog models are used for both interpretation of user utterances and prediction of agent actions. In addition to the hand-crafted models listed above, researchers have built stochastic plan recognition models for interaction, including ones based on Hidden Markov Models (Bui, 2003; Blaylock and Allen, 2006) and on probabilistic context-free grammars (Alexandersson and Reithinger,1997; Pynadath and Wellman, 2000). In this area, the work most closely related to ours is that of Barrett and Weld (Barrett and Weld, 1994), who build an incremental bottom-up parser Order Placement Figure 2: Sample output (subtask tree) from a parse-based model for the catalog ordering domain. to parse plans. Their parser, however, was not probabilistic or targeted at dialog processing. 3 Dialog Structure We consider a task-oriented dialog to be the result of incremental creation of a shared plan by the participants (Lochbaum, 1998). The shared plan is represented as a single tree T that incorporates the task/subtask structu</context>
</contexts>
<marker>Pynadath, Wellman, 2000</marker>
<rawString>D.V. Pynadath and M.P. Wellman. 2000. Probabilistic state-dependent grammars for plan recognition. In Proceedings of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A linear observed time statistical parser based on maximum entropy models.</title>
<date>1997</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="16720" citStr="Ratnaparkhi, 1997" startWordPosition="2783" endWordPosition="2784">tterance onto the stack, before popping the top two elements off the stack and adding the subtree for special-order into the dialog’s subtask tree. 4.2 Start-Complete Method In the shift-reduce method, the dialog tree is constructed as a side effect of the actions performed on the stack: each reduce action on the stack introduces a non-terminal in the tree. By contrast, in the start-complete method the instructions to build the tree are directly encoded in the parser actions. A stack is used to maintain the global parse state. The actions the parser can take are similar to those described in (Ratnaparkhi, 1997). The parser must decide whether to join each new terminal onto the existing left-hand edge of the tree, or start a new subtree. The actions for the parser include start-X, n-start-X, complete-X, u-completeX and b-complete-X, where X is each of the nonterminals (subtask labels) in the tree. Start-X pushes a token representing the current utterance onto the stack; n-start-X pushes non-terminal X onto the stack; complete-X pushes a token representing the current utterance onto the stack, then pops the top two tokens off the stack and pushes the non-terminal X; u-complete-X pops the top token off</context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>A. Ratnaparkhi. 1997. A linear observed time statistical parser based on maximum entropy models. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rich</author>
<author>C L Sidner</author>
</authors>
<title>COLLAGEN: When agents collaborate with people.</title>
<date>1997</date>
<booktitle>In Proceedings of the First International Conference on Autonomous Agents.</booktitle>
<marker>Rich, Sidner, 1997</marker>
<rawString>C. Rich and C.L. Sidner. 1997. COLLAGEN: When agents collaborate with people. In Proceedings of the First International Conference on Autonomous Agents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>A Lavie</author>
</authors>
<title>A best-first probabilistic shift-reduce parser.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<contexts>
<context position="14596" citStr="Sagae and Lavie, 2006" startWordPosition="2413" endWordPosition="2416">you yes i would like to place an order yes i would like to place an order a feature vector containing contextual information for the parsing action (see Section 5.1). These feature vectors and the associated parser actions are used to train maximum entropy models (Berger et al., 1996). These models are then used to incrementally incorporate the utterances for a new dialog into that dialog’s subtask tree as the dialog progresses, as shown in Figure 3. 4.1 Shift-Reduce Method In this method, the subtask tree is recovered through a right-branching shift-reduce parsing process (Hall et al., 2006; Sagae and Lavie, 2006). The parser shifts each utterance on to the stack. It then inspects the stack and decides whether to do one or more reduce actions that result in the creation of subtrees in the subtask tree. The parser maintains two data structures – a stack and a tree. The actions of the parser change the contents of the stack and create nodes in the dialog tree structure. The actions for the parser include unaryreduce-X, binary-reduce-X and shift, where X is each of the non-terminals (subtask labels) in the tree. Shift pushes a token representing the utterance onto the stack; binary-reduce-X pops two token</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>K. Sagae and A. Lavie. 2006. A best-first probabilistic shift-reduce parser. In Proceedings of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Serafin</author>
<author>B Di Eugenio</author>
</authors>
<title>FLSA: Extending latent semantic analysis with features for dialogue act classification.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Serafin, Di Eugenio, 2004</marker>
<rawString>R. Serafin and B. Di Eugenio. 2004. FLSA: Extending latent semantic analysis with features for dialogue act classification. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Plan parsing for intended response recognition in discourse.</title>
<date>1985</date>
<journal>Computational Intelligence,</journal>
<volume>1</volume>
<issue>1</issue>
<marker>Sidner, 1985</marker>
<rawString>C.L. Sidner. 1985. Plan parsing for intended response recognition in discourse. Computational Intelligence, 1(1):1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Soricut</author>
<author>D Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL/HLT.</booktitle>
<contexts>
<context position="3374" citStr="Soricut and Marcu, 2003" startWordPosition="545" endWordPosition="548">ction 5, we describe our data and experiments. Finally, in Section 6, we present conclusions and describe our current and future work. 2 Related Work There are two threads of research that are relevant to our work: work on parsing (written and spoken) discourse, and work on plan-based dialog models. Discourse Parsing Discourse parsing is the process of building a hierarchical model of a discourse from its basic elements (sentences or clauses), as one would build a parse of a sentence from its words. There has now been considerable work on discourse parsing using statistical bottom-up parsing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (200</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>R. Soricut and D. Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sporleder</author>
<author>A Lascarides</author>
</authors>
<title>Combining hierarchical clustering and machine learning to predict high-level discourse structure.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="3446" citStr="Sporleder and Lascarides, 2004" startWordPosition="552" endWordPosition="555">n 6, we present conclusions and describe our current and future work. 2 Related Work There are two threads of research that are relevant to our work: work on parsing (written and spoken) discourse, and work on plan-based dialog models. Discourse Parsing Discourse parsing is the process of building a hierarchical model of a discourse from its basic elements (sentences or clauses), as one would build a parse of a sentence from its words. There has now been considerable work on discourse parsing using statistical bottom-up parsing (Soricut and Marcu, 2003), hierarchical agglomerative clustering (Sporleder and Lascarides, 2004), parsing from lexicalized tree-adjoining grammars (Cristea, 2000), and rulebased approaches that use rhetorical relations and discourse cues (Forbes et al., 2003; Polanyi et al., 2004; LeThanh et al., 2004). With the exception of Cristea (2000), most of this research has been limited to non-incremental parsing of textual monologues where, in contrast to incremental dialog parsing, predicting a system action is not relevant. The work on discourse parsing that is most similar to ours is that of Baldridge and Lascarides (2005). They used a probabilistic headdriven parsing method (described in (C</context>
</contexts>
<marker>Sporleder, Lascarides, 2004</marker>
<rawString>C. Sporleder and A. Lascarides. 2004. Combining hierarchical clustering and machine learning to predict high-level discourse structure. In Proceedings of COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>