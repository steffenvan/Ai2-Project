<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000018">
<title confidence="0.995583">
Chinese Base-Phrases Chunking
</title>
<author confidence="0.996532">
Yuqi Zhang and Qiang Zhou
</author>
<affiliation confidence="0.976289">
State Key Laboratory of Intelligent Technology and Systems
Department of Computer Science and Technology
Tsinghua University, Beijing, 100084, P.R.China
</affiliation>
<email confidence="0.990436">
{zyq, zhouq}@s1000e.cs.Tsinghua.edu.cn
</email>
<sectionHeader confidence="0.993695" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999678">
This paper introduces new definitions of Chinese
base phrases and presents a hybrid model to
combine Memory-Based Learning method and
disambiguation proposal based on lexical
information and grammar rules populated from a
large corpus for 9 types of Chinese base phrases
chunking. Our experiment achieves an accuracy
(F-measure) of 93.4%. The significance of the
research lies in the fact that it provides a solid
foundation for the Chinese parser.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999945933333333">
Recognizing simple and non-recursive base phrases
is an important subtask for many natural language
processing applications, such as information
retrieval. Gee and Grosjean (Gee and Grosjean,
1983) showed psychological evidence that chunks
like base phrases play an important role in human
language understanding. CoNLL-2000’s shared
task identified many kinds of English base phrases,
which are syntactically related non-overlapping
groups of words (Tjong and Buchholz, 2000). The
shared task has significantly heightened the
progress in the techniques of English partial
parsing. For Chinese processing, Zhao (1998) put
forward a definition of Chinese baseNP that is a
combination of determinative modifier and head
noun (Zhao, 1998). Based on that research, Zhao et
al. (2000) extended the concept of baseNP to seven
types of Chinese base phrases. These base phrases
may consist of words or other base phrases, but its
constituents, in turn, should not contain any base
phrases.
In this paper, we put forward the new definition
of Chinese base phrases, which are simple and
non-recursive, similar to the CoNLL-2000’s shared
task. The definition enables us to resolve most local
ambiguities and is very useful for NLP tasks such as
name entity recognition and information extraction.
We construct a hybrid model to recognize nine
types of Chinese base phrases. Many researches in
Chinese partial parsing (Zhou, 1996; Zhao, 1998;
Sun, 2001) have shown that statistical learning is of
great use for Chinese chunking, especially for large
corpus. However, the lack of morphological hints in
Chinese makes it necessary to use semantic and
syntactic information such as context free grammar
rules in Chinese processing. In our approach,
viewing chunking as a tagging problem by
encoding the chunk structure in new tags attached
to each word, we use Memory-Based Learning
(MBL) method to set a tag indicating type and
position in a base phrase on each word. After which
grammar rules are used to disambiguate the tags.
Our test with a corpus of about 2 MB showed that
the experiment achieves 94.4% in precision and
92.5% in recall.
</bodyText>
<sectionHeader confidence="0.6722415" genericHeader="introduction">
2 Definitions of Chinese Base
Phrases
</sectionHeader>
<bodyText confidence="0.998135083333333">
The idea of parsing by chunks goes back to Abney
(1991). In his definition of chunks in English, he
assumed that a chunk has syntactic structure and he
defined chunks in terms of major heads, which are
all content words except those that appear between
a function word and the content word which
f f
selects. A major head is the ‘semantic’ head (s-head)
for the root of the chunk headed by it. However,
s-heads can be defined in terms of syntactic heads.
If the syntactic head h of a phrase P is a content
word, is also the s-head of P. If h is a function
</bodyText>
<equation confidence="0.2872765">
h
word, the s-head of P is the s-head of the phrase
selected by .
h
</equation>
<bodyText confidence="0.980927433333333">
The research enlightens us about the definition of
Chinese base phrases. In this paper, a Chinese base
phrase consists of a single content word surrounded
by a cluster of function words. The single content
word is the semantic head of the base phrase. The
forms of base phrases can be expressed as follows.
{Modifier} * + head + {complement}* or
Coordinate structure
The components of ‘modifier’ and ‘complement’
are optional. A head could be a simple word as well
as the structure of “modifier + head” or “head +
complement”, but not “modifier + head +
complement”. Coordinate structure could not
consist of coordinate symbols such as comma and
co-ordinating conjunction. The type of base phrases
is congruent with its head’s semantic information.
In most cases, the type accords with the head’s
syntactical information, for example, when the head
is a noun, the phrase is a noun phrase. However,
when a head is a noun that denotes a place, the base
phrase including that head is not a noun phrase, but
a location phrase.
We consider 9 types of Chinese base phrases in
our research: namely adjective phrase (ap),
distinguisher phrase (bp), adverbial phrase (dp),
noun phrase (np), temporal phrase (tp), location
phrase (sp), verb phrase (vp), quantity phrase (mp),
quasi quantity phrase (mbar). The inner grammar
structures of every base phrase are very important
too, but we will discuss that in another paper.
</bodyText>
<sectionHeader confidence="0.998018" genericHeader="method">
3 Overview
</sectionHeader>
<bodyText confidence="0.999838393939394">
The frame of Chinese base phrase parsing is
composed of two parts: one is the “Type and
bracket tagging model”, the other is the “Base
phrases acquisition model” which consists of two
modules which are “brackets matching ”and
“correct the types of base phrases”. (See figure 1.)
The input to the system is a sequence of POS. In the
“Predict the phrase boundary” module, we predict
the type, which each word belongs to, and the
position of each word in a base phrase with
Memory-Based Learning (MBL)(Using the
software package provided by Tilburg University.).
And the result is expressed as a pair formed by base
phrase type and position information. Because our
Chinese base phrases are non-recursive and
non-overlapping, the left and right boundaries of
base phrases must match with each other which
means they should be a pair and alternative.
However, the errors involving in the first part will
lead to incorrect base phrases because the
boundaries do not match, for example “[...[...]”. In
the second part, grammar rules that indicate the
inner structures of base phrases are used to resolve
the boundary ambiguities. Furthermore, it also
takes lexical information into account to correct the
type mistakes.
The corpus used in the experiment includes 7606
sentences. It comes from the Chinese Balance
Corpus including about 2000 thousand words with
four types: literature (44%), news (30%), academic
article (20%) and spoken Chinese (6%). These 7606
sentences are split into 6846 training sentences and
760 held out for testing.
</bodyText>
<figure confidence="0.8013916">
Input Type and bracket tagging
model
Obtain feature vectors
Predict the phrase boundary
Output Base phrases acquisition model
</figure>
<figureCaption confidence="0.999952">
Figure 1: system overview
</figureCaption>
<sectionHeader confidence="0.5338785" genericHeader="method">
4 Predicting the phrase boundaries
with MBL
</sectionHeader>
<bodyText confidence="0.999932214285714">
Memory-Based Learning (MBL) is a classification
based, supervised learning approach: a
memory-based learning algorithm constructs a
classifier for a task by storing a set of examples.
Each example associates a finite number of classes.
Given a new feature vector, the classifier
extrapolates its class from those of the most similar
feature vectors in memory (Daelemans et, al., 1999).
The input to the “Predict the phrase boundary”
module is some feature vectors, which compose of a
sequence of POS. The solution of the module is to
find &lt; r;, c; &gt; (Wojciech and Thorsten, 1998), a
duple formed by a type tag and a boundary tag for
each word t . Here r indicates the boundary tag,
</bodyText>
<equation confidence="0.889556428571428">
; ;
while c; denotes the type tag.
ci E { , , ,
np vp ap dp, sp, tp, bp, mp, mbar,−}
the word is not in any type of base phrases.)
r; E {L, R, I, O, LR} The indicates the position
r;
</equation>
<bodyText confidence="0.9842515">
of the word in a base phrase as shown below:
‘L’: the left boundary, ‘R’: the right boundary,
</bodyText>
<figure confidence="0.966771875">
Brackets matching
Correct the types of base
phrases
Lexical
information
Grammar
rules
(“-” denotes
</figure>
<bodyText confidence="0.983517166666667">
‘I’: the middle position, ‘O’: outside any base
phrases, ‘LR’: the left and right boundary.
What information is used to represent data in
feature vectors is an important aspect in MBL
algorithms. We tried many feature vectors with
various lengths. And it is interesting to note that the
feature window is not the bigger the better. When
the feature window is (-2, +2) in the context, the
result is the best. So the feature vector in the
experiment is: (POS-2, POS-1, POS0, POS+1,
POS+2). The pattern describes the combination of
feature vector and result duple &lt; rn cm &gt;
</bodyText>
<equation confidence="0.912851">
0&lt;_n&lt;_4,0&lt;_m&lt;_ 9:
</equation>
<bodyText confidence="0.951459666666667">
(POS-2, POS-1, POS0, POS+1, POS+2,&lt; rncm &gt;).
For the experiment in the first step, we use
TiMBL , an MBL software package developed in
the ILK-group (Daelemans et, al., 2001). The
results of phrase boundary prediction with MBL
shows in table 1.
</bodyText>
<tableCaption confidence="0.83327">
Table1:The result of word boundary prediction
</tableCaption>
<table confidence="0.999901">
Precision Recall
for&lt;rncm &gt; For&lt;rncm&gt;
np 92.27% 93.61%
vp 90.40% 89.65%
sp 75.15% 48.41%
tp 82.87% 71.62%
ap 93.52% 91.89%
bp 92.60% 76.38%
dp 97.56% 97.63%
mp 93.90% 92.38%
mbar 74.15% 72.26%
Total1 91.90% 91.65%
- 97.85% 98.41%
Total2 93.83% 93.83%
</table>
<tableCaption confidence="0.621989">
Table 1 shows that there is much difference
</tableCaption>
<bodyText confidence="0.9947211">
between the results of various types of base phrases.
The precisions and recalls of np, vp, mp, ap and dp
are all almost over 90%. Comparatively, the results
of sp, tp, bp and mbar are much lower, especially
their recalls. This is due to some resemblances
between sp, tp and np in Chinese syntactical
grammars. Sp and tp may be considered as belong
to NP, however, in the definition of Chinese base
phrases, sp, tp and np are defined separately for the
semantic difference. And the separation can also
</bodyText>
<footnote confidence="0.6171">
1 TiMBL is a software bag about many MBL
algorithms. It can be download free from
http://ilk.kub.nl/
</footnote>
<bodyText confidence="0.9967385">
help in other tasks such as proper noun
identification, information retrieval etc.
</bodyText>
<sectionHeader confidence="0.450677666666667" genericHeader="method">
5 Obtaining Chinese base phrases
5.1 The errors in phrase boundary
prediction
</sectionHeader>
<bodyText confidence="0.99905">
There are three types of errors in the results of first
processing model.
</bodyText>
<listItem confidence="0.805683214285714">
(1) Boundary ambiguity: the r ‘s mistakes
i
will cause the multiple choices regarding the
boundaries. For example: “ {np iA/rN } —/m if*/n } ,
/, Af/p {np Ft1t/t {np �f*/n } M/u {np R)K/vN W,C-
/vN } {ap WdD )/a } o/o”. (Please pay attention to the
‘__’ part.) There are altogether three modalities:
“{ cm ...{ cm ...}”, “{ cm ...}...}” and
“{ ...{ ...}...}”. These are caused by the
cm cm
redundancy and absence of boundaries.
(2) The type mistake of base phrases: For
example: in the sentence of “{np �NK/n } {dp 4*-L
/d } {vp A/vC } {np *MA- W,/nS } -L/f {tp M /nR AK
/n } V-/p...”, the parser mistakes the type of “{ ��
/nR AK/n }” ,which is np, for tp. This error type
commonly appears between sp, tp and np, as well as
mbar and mp.
(3) Boundaries absence: For example, in the
sentence of “{vp �,M/v } {np f Jffc/n } ,/, {np #M/n 3A
#J/n } STA/c {vp WfO./v }”, “{np #41/n 3A#J/n }”
should be “{np #M/n } {np 3A#J/n }”. It is very
difficult to correct this type of errors because the
boundary distribution accords with the definition of
Chinese base phrases. The left and right boundaries
alternate with each other. Therefore, it is very
difficult to find the errors in the sequence from the
modalities.
</listItem>
<subsectionHeader confidence="0.9782075">
5.2 Obtaining the whole base phrases
with Grammar rules
</subsectionHeader>
<bodyText confidence="0.9939421">
With the bracket (boundary) representation,
incorrect bracket will be generated but these will be
eliminated in the bracket combination process. In
the experiment, we attempt to apply grammar rules
that represent the inner structures of Chinese base
phrases to get rid of the boundary ambiguities.
These grammar rules are derived from the corpus.
On the other hand, boundary predictions can find
many base phrases that do not accord with the
limited grammar rules.
</bodyText>
<figureCaption confidence="0.42117">
Figure 2 shows the main strategy of how to use
the grammar rules. When if ()&gt;1, there are more
Step 1: Finding the sequence where the errors appear. The sequences are three types:
</figureCaption>
<figure confidence="0.852847076923077">
“{...{...}”, “{...}...}”, “{...{...}...}”.
Step 2: if (the number of sequences of POS in a pair of matched boundaries according with the grammar
rules) &gt;1
then {Select the boundaries that make the sequence longest}
Step 3: if (the number of sequences of POS in a pair of combined boundaries according with the grammar
rules) =1
if (Only the sequence with the shortest length accords with the grammar rules).
then { Find partitions such as conjunctions, localizers, punctuations and some
prepositions between the ambiguous boundaries in sequences;
if (The partitions exist)
then {Add boundaries to generate whole base phrases according to the
partitions}
}
</figure>
<figureCaption confidence="0.999925">
Figure 2: The Algorithm of Matching Boundaries
</figureCaption>
<bodyText confidence="0.99915975">
than one pair of combined brackets in which the
sequences accord with the grammar rules. We are
apt to choose the longest possible because the
shorter sequences appear more in the corpus. The
longer the sequence, the more weight it should carry.
When there is only the shorter sequence according
with grammar rules, it is more possible to be the
correct one. In this case, one or more boundaries
will be left. They often need some other boundaries
to match, so we try to retrieve some missing
boundaries through the partitions in the sentences
that should not belong to any base phrases. These
partitions are the marks of base phrase boundaries.
If we find these partitions between two ambiguous
boundaries, we will know where to place the new
boundary.
</bodyText>
<subsectionHeader confidence="0.9958865">
5.3 Correct the type mistake with
lexical information
</subsectionHeader>
<bodyText confidence="0.999992285714286">
In the Chinese language, some POS sequences may
belong to different types. For example, “{vN n}”
could be np, sp or tp. These sequences often appear
in np, sp, tp, mp and mbar. It is difficult to know its
right type even with the grammar rules, as we have
done in section 5.2. In order to resolve this problem,
we attempt to use lexical information because it
implies semantic information to some extent.
The lexical information is distinctive between mp
and mbar. mbar is often composed of numbers such
as “1200” and numbers in Chinese such as “N”.
The lexical information between tp and np is also
obvious, such as “Rfft”, “Rfft” and “12” etc. For
sp and np, the words are “AC”, “&apos;1 *” etc.
</bodyText>
<subsectionHeader confidence="0.991041">
5.4 Experimental results
</subsectionHeader>
<bodyText confidence="0.999657714285714">
The simplest bracket combination algorithm is very
strict: it only uses adjacent brackets if they appear
next to each other in the correct order (first open
and then close) without any intervening brackets.
The result of the algorithm is shown in table 2, as
the baseline of the boundary combination
experiment.
</bodyText>
<tableCaption confidence="0.99812">
Table 2: The base-line result
</tableCaption>
<table confidence="0.999971545454546">
Precision Recall F_M
Np 93.9% 86.1% 89.8%
Vp 90.6% 86.2% 88.4%
Sp 75.5% 47.7% 58.4%
Tp 85.4% 70.2% 77.0%
Ap 93.4% 83.4% 88.1%
Bp 93.4% 71.3% 80.9%
dp 97.7% 94.0% 95.8%
mp 92.0% 85.3% 88.5%
mbar 0
Total 92.9% 85.7% 89.2%
</table>
<tableCaption confidence="0.993324">
Table 3: The result of disambiguation with
rammar rules
</tableCaption>
<table confidence="0.999316727272727">
Precision Recall F_M
np 94.3% 91.9% 93.1%
vp 95.0% 94.2% 94.6%
sp 73.6% 50.9% 60.2%
tp 84.9% 73.8% 79.0%
ap 93.5% 89.7% 91.5%
bp 91.6% 79.4% 85.0%
dp 97.6% 98.1% 97.8%
mp 86.7% 90.9% 88.7%
mbar 63.6% 12.6% 21.1%
Total 93.9% 92.0% 92.9%
</table>
<bodyText confidence="0.9998782">
From the table 2, we could see the recalls are
commonly low. We change another strategy to
obtain the whole base phrases as described in
section 5.2. The result of using the grammar rules is
shown in table 3.
With the help of grammar rules, all kinds of base
phrases improved their f-measures though the
precisions or recalls of some types decrease slightly.
Comparing with the baseline results in table 2, all
the recalls increase significantly. However, the
recalls of sp, tp and mp still do not satisfy us. There
are more than twenty structures of np which also
belong to tp or sp. Except in the case where mp and
mbar have the same structure {m}, they are easily
distinguished in other structures. (Mbar is always
composed of numerals and mp always ends with a
quantifier.) In order to distinguish tp from np, sp
from np and mbar from mp, we use lexical
information for the type disambiguation. The
results are shown in table 4.
</bodyText>
<tableCaption confidence="0.7776825">
Table 4: The result after using lexical
information
</tableCaption>
<table confidence="0.999504272727273">
Precision Recall F M
np 95.0% 91.9% 93.5%
vp 95.0% 94.3% 94.6%
sp 69.2% 71.3% 70.2%
tp 79.8% 84.1% 81.9%
ap 93.1% 90.0% 91.5%
bp 91.6% 79.4% 85.0%
dp 97.6% 98.1% 97.8%
mp 93.4% 90.9% 92.1%
mbar 67.6% 54.1% 60.1%
Total 94.4% 92.5% 93.4%
</table>
<bodyText confidence="0.999934636363637">
From the table 4, we could see improvement in
all the results (precisions and recalls) of mp and
mbar. It shows that the lexical information is
effective for distinguishing between them. On the
contrary, although the f-measures of np and sp
increase, their precisions decline. Thus, those words
marking tp and sp are not appropriate for
disambiguation. We could see the effect of lexical
information is limited because it is difficult to find
the words that could distinguish different types of
base phrases.
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999982571428571">
The experiment on identifying Chinese base
phrases shows that the definition of Chinese base
phrases is suitable for parsing. It shows good results
and the efficiency of the proposed approach in
simplifying sentence structures. Many tasks such as
chunking on high level could benefit from this.
With the system described here, we get 9 types of
Chinese base phrases, and acquire high precisions
and recalls on most types of base phrases. The
results of the experiment also show that the use of
grammar rules is necessary. Grammar rules have
effects on boundary disambiguation particularly.
The lexical information is effective in
distinguishing between mbar and mp.
</bodyText>
<sectionHeader confidence="0.996378" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.995576">
This work was supported by the National Science
Foundation of China (Grant No. 69903007),
National 973 Foundation (Grant No. 1998030507)
and National 863 Plan (Grant No. 2001AA114040).
</bodyText>
<sectionHeader confidence="0.999153" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997142657142857">
Abney, Steven. (1991) Parsing by chunks. In
Berwick, Abney, and Tenny, editors,
Principle-Based Parsing. Kluwer Academic
Publishers.
Erik F. Tjong Kim Sang and Sabine Buchholz.
(2000). “Introduction to CoNLL-200 Shared
Task: Chunking”. Proceedings of CoNLL-2000
and LLL-2000. Lisbon, Portugal. 127-132.
J. P. Gee and F. Grosjean (1983) Performance
structures: A psycholinguistic and linguistic
appraisal. Cognitive Psychology, 15:411-458
Sun Honglin (2001) A Content Chunk Parser for
Unrestricted Chinese Text, Dissertation for the
degree of Doctor of Science, Peking University.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot
(2001) TiMBL:Tilburg Memory-Based Learner
version 4.0 Reference Guide.
http://ilk.kub.nl/downloads/pub/papers/ilk0104.p
s.pz.
Wojciech Skut and Thorsten Brants (1998) Chunk
Tagger, Statistical Recognition of Noun Phrase,
In ESSLLI-98 Workshop on Automated
Acquisition of Syntax and Parsing, Saarbrvcken.
Zhao Jun (1998) The research on Chinese BaseNP
Recognition and Structure Analysis, Dissertation
for the degree of Doctor of Engineering,
Tsinghua University.
Zhao et al., (2000) Tie-jun ZHAO, et al. “Statistics
Based Hybrid Approach to Chinese Base Phrase
Identification”, In Proceedings of the Second
Chinese Language Processing Workshop, ACL
2000, 73-77.
Zhou, Qiang (1996). Phrase Bracketing and
Annotating on Chinese Language Corpus, Ph.D.
dissertation, Peking University.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.283702">
<title confidence="0.999769">Chinese Base-Phrases Chunking</title>
<author confidence="0.99074">Yuqi Zhang</author>
<author confidence="0.99074">Qiang Zhou</author>
<affiliation confidence="0.746962">State Key Laboratory of Intelligent Technology and Department of Computer Science and Technology</affiliation>
<address confidence="0.861996">Tsinghua University, Beijing, 100084,</address>
<email confidence="0.708827">zyq@s1000e.cs.Tsinghua.edu.cn</email>
<email confidence="0.708827">zhouq@s1000e.cs.Tsinghua.edu.cn</email>
<abstract confidence="0.988863090909091">This paper introduces new definitions of Chinese base phrases and presents a hybrid model to combine Memory-Based Learning method and disambiguation proposal based on lexical information and grammar rules populated from a large corpus for 9 types of Chinese base phrases chunking. Our experiment achieves an accuracy (F-measure) of 93.4%. The significance of the research lies in the fact that it provides a solid foundation for the Chinese parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Parsing by chunks.</title>
<date>1991</date>
<editor>In Berwick, Abney, and Tenny, editors, Principle-Based Parsing.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="2942" citStr="Abney (1991)" startWordPosition="450" endWordPosition="451">cessary to use semantic and syntactic information such as context free grammar rules in Chinese processing. In our approach, viewing chunking as a tagging problem by encoding the chunk structure in new tags attached to each word, we use Memory-Based Learning (MBL) method to set a tag indicating type and position in a base phrase on each word. After which grammar rules are used to disambiguate the tags. Our test with a corpus of about 2 MB showed that the experiment achieves 94.4% in precision and 92.5% in recall. 2 Definitions of Chinese Base Phrases The idea of parsing by chunks goes back to Abney (1991). In his definition of chunks in English, he assumed that a chunk has syntactic structure and he defined chunks in terms of major heads, which are all content words except those that appear between a function word and the content word which f f selects. A major head is the ‘semantic’ head (s-head) for the root of the chunk headed by it. However, s-heads can be defined in terms of syntactic heads. If the syntactic head h of a phrase P is a content word, is also the s-head of P. If h is a function h word, the s-head of P is the s-head of the phrase selected by . h The research enlightens us abou</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Abney, Steven. (1991) Parsing by chunks. In Berwick, Abney, and Tenny, editors, Principle-Based Parsing. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to CoNLL-200 Shared Task: Chunking”.</title>
<date>2000</date>
<booktitle>Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<pages>127--132</pages>
<location>Lisbon,</location>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. (2000). “Introduction to CoNLL-200 Shared Task: Chunking”. Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. 127-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Gee</author>
<author>F Grosjean</author>
</authors>
<title>Performance structures: A psycholinguistic and linguistic appraisal. Cognitive Psychology,</title>
<date>1983</date>
<pages>15--411</pages>
<contexts>
<context position="918" citStr="Gee and Grosjean, 1983" startWordPosition="124" endWordPosition="127">of Chinese base phrases and presents a hybrid model to combine Memory-Based Learning method and disambiguation proposal based on lexical information and grammar rules populated from a large corpus for 9 types of Chinese base phrases chunking. Our experiment achieves an accuracy (F-measure) of 93.4%. The significance of the research lies in the fact that it provides a solid foundation for the Chinese parser. 1 Introduction Recognizing simple and non-recursive base phrases is an important subtask for many natural language processing applications, such as information retrieval. Gee and Grosjean (Gee and Grosjean, 1983) showed psychological evidence that chunks like base phrases play an important role in human language understanding. CoNLL-2000’s shared task identified many kinds of English base phrases, which are syntactically related non-overlapping groups of words (Tjong and Buchholz, 2000). The shared task has significantly heightened the progress in the techniques of English partial parsing. For Chinese processing, Zhao (1998) put forward a definition of Chinese baseNP that is a combination of determinative modifier and head noun (Zhao, 1998). Based on that research, Zhao et al. (2000) extended the conc</context>
</contexts>
<marker>Gee, Grosjean, 1983</marker>
<rawString>J. P. Gee and F. Grosjean (1983) Performance structures: A psycholinguistic and linguistic appraisal. Cognitive Psychology, 15:411-458</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sun Honglin</author>
</authors>
<title>A Content Chunk Parser for Unrestricted Chinese Text, Dissertation for the degree of</title>
<date>2001</date>
<institution>Doctor of Science, Peking University.</institution>
<marker>Honglin, 2001</marker>
<rawString>Sun Honglin (2001) A Content Chunk Parser for Unrestricted Chinese Text, Dissertation for the degree of Doctor of Science, Peking University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
</authors>
<title>Jakub Zavrel, Ko van der Sloot</title>
<date>2001</date>
<marker>Daelemans, 2001</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Ko van der Sloot (2001) TiMBL:Tilburg Memory-Based Learner version 4.0 Reference Guide. http://ilk.kub.nl/downloads/pub/papers/ilk0104.p s.pz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Skut</author>
<author>Thorsten Brants</author>
</authors>
<title>Chunk Tagger, Statistical Recognition of Noun Phrase,</title>
<date>1998</date>
<booktitle>In ESSLLI-98 Workshop on Automated Acquisition of Syntax and Parsing, Saarbrvcken.</booktitle>
<marker>Skut, Brants, 1998</marker>
<rawString>Wojciech Skut and Thorsten Brants (1998) Chunk Tagger, Statistical Recognition of Noun Phrase, In ESSLLI-98 Workshop on Automated Acquisition of Syntax and Parsing, Saarbrvcken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhao Jun</author>
</authors>
<title>The research on Chinese BaseNP Recognition and Structure Analysis, Dissertation for the degree of</title>
<date>1998</date>
<institution>Doctor of Engineering, Tsinghua University.</institution>
<marker>Jun, 1998</marker>
<rawString>Zhao Jun (1998) The research on Chinese BaseNP Recognition and Structure Analysis, Dissertation for the degree of Doctor of Engineering, Tsinghua University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhao</author>
</authors>
<title>Statistics Based Hybrid Approach to Chinese Base Phrase Identification”,</title>
<date>2000</date>
<booktitle>In Proceedings of the Second Chinese Language Processing Workshop, ACL</booktitle>
<pages>73--77</pages>
<marker>Zhao, 2000</marker>
<rawString>Zhao et al., (2000) Tie-jun ZHAO, et al. “Statistics Based Hybrid Approach to Chinese Base Phrase Identification”, In Proceedings of the Second Chinese Language Processing Workshop, ACL 2000, 73-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
</authors>
<title>Phrase Bracketing and Annotating on Chinese Language Corpus,</title>
<date>1996</date>
<institution>Peking University.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="2138" citStr="Zhou, 1996" startWordPosition="314" endWordPosition="315">eNP to seven types of Chinese base phrases. These base phrases may consist of words or other base phrases, but its constituents, in turn, should not contain any base phrases. In this paper, we put forward the new definition of Chinese base phrases, which are simple and non-recursive, similar to the CoNLL-2000’s shared task. The definition enables us to resolve most local ambiguities and is very useful for NLP tasks such as name entity recognition and information extraction. We construct a hybrid model to recognize nine types of Chinese base phrases. Many researches in Chinese partial parsing (Zhou, 1996; Zhao, 1998; Sun, 2001) have shown that statistical learning is of great use for Chinese chunking, especially for large corpus. However, the lack of morphological hints in Chinese makes it necessary to use semantic and syntactic information such as context free grammar rules in Chinese processing. In our approach, viewing chunking as a tagging problem by encoding the chunk structure in new tags attached to each word, we use Memory-Based Learning (MBL) method to set a tag indicating type and position in a base phrase on each word. After which grammar rules are used to disambiguate the tags. Ou</context>
</contexts>
<marker>Zhou, 1996</marker>
<rawString>Zhou, Qiang (1996). Phrase Bracketing and Annotating on Chinese Language Corpus, Ph.D. dissertation, Peking University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>