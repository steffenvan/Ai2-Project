<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.040013">
<title confidence="0.9987145">
GPLSI-IXA: Using Semantic Classes to Acquire Monosemous Training
Examples from Domain Texts
</title>
<author confidence="0.998981">
Rub´en Izquierdo &amp; Armando Su´arez
</author>
<affiliation confidence="0.989608">
GPLSI Group
University of Alicante. Spain
</affiliation>
<email confidence="0.996318">
{ruben,armando}@dlsi.ua.es
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989153846154">
This paper summarizes our participation
in task #17 of SemEval–2 (All–words
WSD on a specific domain) using a su-
pervised class-based Word Sense Disam-
biguation system. Basically, we use Sup-
port Vector Machines (SVM) as learning
algorithm and a set of simple features to
build three different models. Each model
considers a different training corpus: Sem-
Cor (SC), examples from monosemous
words extracted automatically from back-
ground data (BG), and both SC and
BG (SCBG). Our system explodes the
monosemous words appearing as mem-
bers of a particular WordNet semantic
class to automatically acquire class-based
annotated examples from the domain text.
We use the class-based examples gathered
from the domain corpus to adapt our tra-
ditional system trained on SemCor. The
evaluation reveal that the best results are
achieved training with SemCor and the
background examples from monosemous
words, obtaining results above the first
sense baseline and the fifth best position
in the competition rank.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998215545454545">
As empirically demonstrated by the last SensEval
and SemEval exercises, assigning the appropriate
meaning to words in context has resisted all at-
tempts to be successfully addressed. In fact, super-
vised word-based WSD systems are very depen-
dent of the corpora used for training and testing
the system (Escudero et al., 2000). One possible
reason could be the use of inappropriate level of
abstraction.
Most supervised systems simply model each
polysemous word as a classification problem
</bodyText>
<note confidence="0.974193333333333">
German Rigau
IXA NLP Group.
EHU. Donostia, Spain
</note>
<email confidence="0.937722">
german.rigau@ehu.es
</email>
<bodyText confidence="0.999726692307692">
where each class corresponds to a particular synset
of the word. But, WordNet (WN) has been widely
criticized for being a sense repository that often
provides too fine–grained sense distinctions for
higher level applications like Machine Translation
or Question &amp; Answering. In fact, WSD at this
level of granularity has resisted all attempts of in-
ferring robust broad-coverage models. It seems
that many word–sense distinctions are too subtle
to be captured by automatic systems with the cur-
rent small volumes of word–sense annotated ex-
amples.
Thus, some research has been focused on deriv-
ing different word-sense groupings to overcome
the fine–grained distinctions of WN (Hearst and
Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea
and Moldovan, 2001), (Agirre and LopezDeLa-
Calle, 2003), (Navigli, 2006) and (Snow et al.,
2007). That is, they provide methods for grouping
senses of the same word, thus producing coarser
word sense groupings for better disambiguation.
In contrast, some research have been focused on
using predefined sets of sense-groupings for learn-
ing class-based classifiers for WSD (Segond et al.,
1997), (Ciaramita and Johnson, 2003), (Villarejo
et al., 2005), (Curran, 2005), (Kohomban and Lee,
2005) and (Ciaramita and Altun, 2006). That is,
grouping senses of different words into the same
explicit and comprehensive semantic class. Most
of the later approaches used the original Lexico-
graphical Files of WN (more recently called Su-
perSenses) as very coarse–grained sense distinc-
tions.
We suspect that selecting the appropriate level
of abstraction could be on between both levels.
Thus, we use the semantic classes modeled by the
Basic Level Concepts1 (BLC) (Izquierdo et al.,
2007). Our previous research using BLC empiri-
cally demonstrated that this automatically derived
</bodyText>
<footnote confidence="0.982611">
1http://adimen.si.ehu.es/web/BLC
</footnote>
<page confidence="0.965543">
402
</page>
<bodyText confidence="0.958106739130435">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 402–406,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
set of meanings groups senses into an adequate
level of abstraction in order to perform class-based
Word Sense Disambiguation (WSD) (Izquierdo et
al., 2009). Now, we also show that class-based
WSD allows to successfully incorporate monose-
mous examples from the domain text. In fact,
the robustness of our class-based WSD approach
is shown by our system that just uses the Sem-
Cor examples (SC). It performs without any kind
of domain adaptation as the Most Frequent Sense
(MFS) baseline.
This paper describes our participation in
SemEval-2010 Task 17 (Agirre et al., 2010). In
section 2 semantic classes used and selection al-
gorithm used to obtain them automatically from
WordNet are described. In section 3 the technique
employed to extract monosemous examples from
background data is described. Section 4 explains
the general approach of our system, and the ex-
periments designed, and finally, in section 5, the
results and some analysis are shown.
</bodyText>
<sectionHeader confidence="0.972588" genericHeader="method">
2 Semantic Classes
</sectionHeader>
<bodyText confidence="0.999951222222222">
The set of semantic classes used in this work are
the Basic Level Concepts2 (BLC) (Izquierdo et
al., 2007). These concepts are small sets of mean-
ings representing the whole nominal and verbal
part of WN. BLC can be obtained by a very simple
method that uses basic structural WordNet proper-
ties. In fact, the algorithm only considers the rel-
ative number of relations of each synset along the
hypernymy chain. The process follows a bottom-
up approach using the chain of hypernymy rela-
tions. For each synset in WN, the process selects
as its BLC the first local maximum according to
the relative number of relations. The local maxi-
mum is the synset in the hypernymy chain having
more relations than its immediate hyponym and
immediate hypernym. For synsets having multi-
ple hypernyms, the path having the local maxi-
mum with higher number of relations is selected.
Usually, this process finishes having a number of
preliminary BLC. Figure 1 shows an example of
selection of a BLC. The figure represents the hy-
pernymy hierarchy of WordNet, with circles rep-
resenting synsets, and links between them repre-
senting hypernym relations. The algorithm selects
the D synset as BLC for J, due to D is the first
maximum in the hypernymy chain, according to
the number of relations (F has 2 hyponyms, D has
</bodyText>
<footnote confidence="0.788529">
2http://adimen.si.ehu.es/web/BLC
</footnote>
<listItem confidence="0.70398">
3, and A has 2, so D is the first maximum).
</listItem>
<figureCaption confidence="0.999632">
Figure 1: Example of BLC selection
</figureCaption>
<bodyText confidence="0.999943">
Obviously, while ascending through this chain,
more synsets are subsumed by each concept. The
process finishes checking if the number of con-
cepts subsumed by the preliminary list of BLC is
higher than a certain threshold. For those BLC
not representing enough concepts according to the
threshold, the process selects the next local max-
imum following the hypernymy hierarchy. Thus,
depending on the type of relations considered to
be counted and the threshold established, different
sets of BLC can be easily obtained for each WN
version.
We have selected the set which considers WN
version 3.0, the total number of relations per
synset, and a minimum threshold of 20 concepts to
filter out not representative BLC (BLC–20). This
set has shown to reach good performance on previ-
ous SensEval and SemEval exercices (Izquierdo et
al., 2009). There are 649 different BLC for nouns
on WordNet 3.0, and 616 for verbs. Table 2 shows
the three most frequent BLC per POS, with the
number of synsets subsumed by each concept, and
its WordNet gloss.
</bodyText>
<sectionHeader confidence="0.9810305" genericHeader="method">
3 Using Monosemous Examples from the
Domain
</sectionHeader>
<bodyText confidence="0.999869125">
We did not applied any kind of specific domain
adaptation technique to our class-based supervised
system. In order to adapt our supervised system to
the environmental domain we only increased the
training data with new examples of the domain. To
acquire these examples, we used the environmen-
tal domain background documents provided by the
organizers. Specifically, we used the 122 back-
</bodyText>
<figure confidence="0.9986566">
E
B
2
I
F
2
C
J
A
2
3
D
G H
Synset
BLC
</figure>
<page confidence="0.991769">
403
</page>
<table confidence="0.999824444444445">
PoS Num. BLC Gloss
4.792 person.n.01 a human being
Nouns 1.935 activity.n.01 any specific behavior
1.846 act.n.02 something that people do or cause to happen
1.541 change.v.01 cause to change; make different; cause a transformation
Verbs 1.085 change.v.02 undergo a change; become different in essence; losing one’s or its original na-
ture
519 move.v.02 cause to move or shift into a new position or place, both in a concrete and in an
abstract sense
</table>
<tableCaption confidence="0.999746">
Table 1: Most frequent BLC–20 semantic classes on WordNet 3.0
</tableCaption>
<bodyText confidence="0.999645941176471">
ground documents3. TreeTagger has been used
to preprocess the documents, performing PoS tag-
ging and lemmatization. Since the background
documents are not semantically annotated, and our
supervised system needs labeled data, we have se-
lected only the monosemous words occurring in
the documents. In this way, we have obtained au-
tomatically a large set of examples annotated with
BLC. Table 3 presents the total number of training
examples extracted from SemCor (SC) and from
the background documents (BG). As expected, by
this method a large number of monosemous ex-
amples can be obtained for nouns and verbs. Also
as expected, verbs are much less productive than
nouns. However, all these background examples
correspond to a reduced set of 7,646 monosemous
words.
</bodyText>
<table confidence="0.99878425">
Nouns Verbs N+V
SC 87.978 48.267 136.245
BG 193.536 10.821 204.357
Total 281.514 59.088 340.602
</table>
<tableCaption confidence="0.6118354">
Table 2: Number of training examples
Table 3 lists the ten most frequent monosemous
nouns and verbs occurring in the background doc-
uments. Note that all these examples are monose-
mous according to BLC–20 semantic classes.
</tableCaption>
<table confidence="0.999574333333333">
Nouns Verbs
Lemma # ex. Lemma # ex.
1 biodiversity 7.476 monitor 788
2 habitat 7.206 achieve 784
3 specie 7.067 target 484
4 climate 3.539 select 345
5 european 2.818 enable 334
6 ecosystem 2.669 seem 287
7 river 2.420 pine 281
8 grassland 2.303 evaluate 246
9 datum 2.276 explore 200
10 directive 2.197 believe 172
</table>
<tableCaption confidence="0.999071">
Table 3: Most frequent monosemic words in BG
</tableCaption>
<footnote confidence="0.982335">
3We used the documents contained on the trial data and
the background.
</footnote>
<sectionHeader confidence="0.981963" genericHeader="method">
4 System Overview
</sectionHeader>
<bodyText confidence="0.99998058974359">
Our system applies a supervised machine learn-
ing approach. We apply a feature extractor to
represent the training examples of the examples
acquired from SemCor and the background doc-
uments. Then, a machine learning engine uses
the annotated examples to train a set of classi-
fiers. Support Vector Machines (SVM) have been
proven to be robust and very competitive in many
NLP tasks, and in WSD in particular (M`arquez et
al., 2006). We used the SVM-Light implementa-
tion4 (Joachims, 1998).
We create a classifier for each semantic class.
This approach has several advantages compared to
word–based approach. The training data per clas-
sifier is increased (we can use examples of dif-
ferent target words for a single classifier, when-
ever all examples belong to the same semantic
class), the polysemy is reduced (some different
word senses can be collapsed into the same se-
mantic class), and, finally, semantic classes pro-
vide higher levels of abstraction.
For each polysemous word occurring in the test
corpus, we obtain its potential BLC–20 classes.
Then, we only apply the classifiers corresponding
to the BLC-20 classes of the polysemous word. Fi-
nally, our system simply selects the BLC–20 class
with the greater prediction.
In order to obtain the correct WordNet 3.0
synset required by the task, we apply a simple
heuristic that has shown to be robust and accurate
(Kohomban and Lee, 2005). Our classifiers ob-
tain first the semantic class, and then, the synset of
the first WordNet sense that fits with the semantic
class is assigned to the word.
We selected a simple feature set widely used in
many WSD systems. In particular, we use a win-
dow of five tokens around the target word to ex-
tract word forms, lemmas; bigrams and trigrams
of word forms and lemmas; trigrams of PoS tags,
</bodyText>
<footnote confidence="0.992954">
4http://svmlight.joachims.org
</footnote>
<page confidence="0.998787">
404
</page>
<bodyText confidence="0.9979984">
and also the most frequent BLC–20 semantic class
of the target word in the training corpus.
Our system is fully described in (Izquierdo et
al., 2009). The novelty introduced here is the use
of semantic classes to obtain monosemous exam-
ples from the domain corpus.
Following the same framework (BLC–20 se-
mantic architecture and basic set of features) we
designed three runs, each one using a different
training corpus.
</bodyText>
<listItem confidence="0.976313833333333">
• SC: only training examples extracted from
SemCor
• BG: only monosemous examples extracted
from the background data
• SCBG: training examples extracted from
SemCor and monosemous background data
</listItem>
<bodyText confidence="0.999938625">
The first run shows the behavior of a supervised
system trained on a general corpus, and tested in a
specific domain. The second one analyzes the con-
tribution of the monosemous examples extracted
from the background data. Finally, the third run
studies the robustness of the approach when com-
bining the training examples from SemCor and
from the background.
</bodyText>
<sectionHeader confidence="0.998646" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999766333333333">
obtains the 5th position with a Precision and Re-
call of 0.513 (0.534 for nouns, 0.454 for verbs)
which is slightly above the baseline.
</bodyText>
<table confidence="0.9999115">
Rank Precision Recall
1 0.570 0.555
2 0.554 0.540
3 0.534 0.528
4 0.522 0.516
(SCBG) 5 0.513 0.513
]sense 0.505 0.505
(SC) 6 0.505 0.505
7 0.512 0.495
8 0.506 0.493
9 0.504 0.491
10 0.481 0.481
11 0.492 0.479
12 0.461 0.460
13 0.447 0.441
14 0.436 0.435
15 0.440 0.434
16 0.496 0.433
17 0.498 0.432
18 0.433 0.431
19 0.426 0.425
20 0.424 0.422
21 0.437 0.392
22 0.384 0.384
(BG) 23 0.380 0.380
24 0.381 0.356
25 0.351 0.350
26 0.370 0.345
27 0.328 0.322
28 0.321 0.315
29 0.312 0.303
Random 0.230 0.230
</table>
<tableCaption confidence="0.999702">
Table 4: Results of task#17
</tableCaption>
<bodyText confidence="0.9999765">
A total of 29 runs has been submitted for the En-
glish All–words WSD on a Specific Domain. Ta-
ble 5 shows the ranking results of our three runs
with respect to the other participants. The figures
for the first sense (]sense) and random sense (Ran-
dom) baselines are included.
In general, the results obtained are not very
high. The best system only achieves a precision of
0.570, and the first sense baseline reaches a preci-
sion of 0.505. This shows that the task is hard to
solve, and the domain adaptation of WSD systems
is not an easy task.
Interestingly, our worst result is obtained by the
system using only the monosemous background
examples (BG). This system ranks 23th with a Pre-
cision and Recall of 0.380 (0.385 for nouns and
0.366 for verbs). The system using only SemCor
(SC) ranks 6th with Precision and Recall of 0.505
(0.527 for nouns and 0.443 for verbs). This is also
the performance of the first sense baseline. As ex-
pected, the best result of our three runs is obtained
when combining the examples from SemCor and
the background (SCBG). This supervised system
Possibly, the reason of low performance of the
BG system is the high correlation between the fea-
tures of the target word and its semantic class. In
this case, these features correspond to the monose-
mous word while when testing corresponds to the
target word. However, it also seems that class-
based systems are robust enough to incorporate
large sets of monosemous examples from the do-
main text. In fact, to our knowledge, this is the first
time that a supervised WSD algorithm have been
successfully adapted to an specific domain. Fur-
thermore, our system trained only on SemCor also
achieves a good performance, reaching the first
sense baseline, showing that class-based WSD ap-
proaches seem to be robust to domain variations.
</bodyText>
<sectionHeader confidence="0.998294" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9964746">
This paper has been supported by the Euro-
pean Union under the project KYOTO (FP7 ICT-
211423), the Valencian Region Government un-
der PROMETEO project for excellence groups
and the Spanish Government under the projects
</bodyText>
<page confidence="0.995753">
405
</page>
<note confidence="0.525354">
KNOW2 (TIN2009-14715-C04-04) and TEXT-
MESS-2 (TIN2009-13391-C04-04).
</note>
<sectionHeader confidence="0.970106" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99888633">
E. Agirre and O. LopezDeLaCalle. 2003. Clustering
wordnet word senses. In Proceedings of RANLP’03,
Borovets, Bulgaria.
Eneko Agirre, Oier Lopez de Lacalle, Christiane Fell-
baum, Shu kai Hsieh, Maurizio Tesconi, Mon-
ica Monachini, Piek Vossen, and Roxanne Segers.
2010. Semeval-2010 task 17: All-words word sense
disambiguation on a specific domain. In Proceed-
ings of the 5th International Workshop on Semantic
Evaluations (SemEval-2010), Association for Com-
putational Linguistics.
M. Ciaramita and Y. Altun. 2006. Broad-coverage
sense disambiguation and information extraction
with a supersense sequence tagger. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’06), pages 594–602,
Sydney, Australia. ACL.
M. Ciaramita and M. Johnson. 2003. Supersense tag-
ging of unknown nouns in wordnet. In Proceedings
of the Conference on Empirical methods in natural
language processing (EMNLP’03), pages 168–175.
ACL.
J. Curran. 2005. Supersense tagging of unknown
nouns using semantic similarity. In Proceedings of
the 43rd Annual Meeting on Association for Compu-
tational Linguistics (ACL’05), pages 26–33. ACL.
G. Escudero, L. M`arquez, and G. Rigau. 2000. An
Empirical Study of the Domain Dependence of Su-
pervised Word Sense Disambiguation Systems. In
Proceedings of the joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing
and Very Large Corpora, EMNLP/VLC, Hong Kong,
China.
M. Hearst and H. Sch¨utze. 1993. Customizing a lexi-
con to better suit a computational task. In Proceed-
ingns of the ACL SIGLEX Workshop on Lexical Ac-
quisition, Stuttgart, Germany.
R. Izquierdo, A. Suarez, and G. Rigau. 2007. Explor-
ing the automatic selection of basic level concepts.
In Galia Angelova et al., editor, International Con-
ference Recent Advances in Natural Language Pro-
cessing, pages 298–302, Borovets, Bulgaria.
Rub´en Izquierdo, Armando Su´arez, and German Rigau.
2009. An empirical study on class-based word sense
disambiguation. In Proceedings of the 12th Con-
ference of the European Chapter of the ACL (EACL
2009), pages 389–397, Athens, Greece, March. As-
sociation for Computational Linguistics.
T. Joachims. 1998. Text categorization with sup-
port vector machines: learning with many relevant
features. In Claire N´edellec and C´eline Rouveirol,
editors, Proceedings of ECML-98, 10th European
Conference on Machine Learning, pages 137–142,
Chemnitz, DE. Springer Verlag, Heidelberg, DE.
Upali S. Kohomban and Wee Sun Lee. 2005. Learning
semantic classes for word sense disambiguation. In
ACL ’05: Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, pages
34–41, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Ll. M`arquez, G. Escudero, D. Martinez, and G. Rigau.
2006. Supervised corpus-based methods for wsd. In
E. Agirre and P. Edmonds (Eds.) Word Sense Disam-
biguation: Algorithms and applications., volume 33
of Text, Speech and Language Technology. Springer.
R. Mihalcea and D. Moldovan. 2001. Automatic gen-
eration of coarse grained wordnet. In Proceding of
the NAACL workshop on WordNet and Other Lex-
ical Resources: Applications, Extensions and Cus-
tomizations, Pittsburg, USA.
R. Navigli. 2006. Meaningful clustering of senses
helps boost word sense disambiguation perfor-
mance. In ACL-44: Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, pages 105–112, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
W. Peters, I. Peters, and P. Vossen. 1998. Automatic
sense clustering in eurowordnet. In First Interna-
tional Conference on Language Resources and Eval-
uation (LREC’98), Granada, Spain.
F. Segond, A. Schiller, G. Greffenstette, and J. Chanod.
1997. An experiment in semantic tagging using hid-
den markov model tagging. In ACL Workshop on
Automatic Information Extraction and Building of
Lexical Semantic Resources for NLP Applications,
pages 78–81. ACL, New Brunswick, New Jersey.
R. Snow, Prakash S., Jurafsky D., and Ng A. 2007.
Learning to merge word senses. In Proceedings of
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pages 1005–
1014.
L. Villarejo, L. M`arquez, and G. Rigau. 2005. Ex-
ploring the construction of semantic class classi-
fiers for wsd. In Proceedings of the 21th Annual
Meeting of Sociedad Espaola para el Procesamiento
del Lenguaje Natural SEPLN’05, pages 195–202,
Granada, Spain, September. ISSN 1136-5948.
</reference>
<page confidence="0.999049">
406
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.984315">
<title confidence="0.9973265">GPLSI-IXA: Using Semantic Classes to Acquire Monosemous Training Examples from Domain Texts</title>
<author confidence="0.999962">Rub´en Izquierdo</author>
<author confidence="0.999962">Armando Su´arez</author>
<affiliation confidence="0.9986735">GPLSI Group University of Alicante. Spain</affiliation>
<abstract confidence="0.999688592592593">This paper summarizes our participation in task #17 of SemEval–2 (All–words WSD on a specific domain) using a supervised class-based Word Sense Disambiguation system. Basically, we use Support Vector Machines (SVM) as learning algorithm and a set of simple features to build three different models. Each model considers a different training corpus: Sem- Cor (SC), examples from monosemous words extracted automatically from background data (BG), and both SC and BG (SCBG). Our system explodes the monosemous words appearing as members of a particular WordNet semantic class to automatically acquire class-based annotated examples from the domain text. We use the class-based examples gathered from the domain corpus to adapt our traditional system trained on SemCor. The evaluation reveal that the best results are achieved training with SemCor and the background examples from monosemous words, obtaining results above the first sense baseline and the fifth best position in the competition rank.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O LopezDeLaCalle</author>
</authors>
<title>Clustering wordnet word senses.</title>
<date>2003</date>
<booktitle>In Proceedings of RANLP’03, Borovets,</booktitle>
<contexts>
<context position="2561" citStr="Agirre and LopezDeLaCalle, 2003" startWordPosition="383" endWordPosition="387">s too fine–grained sense distinctions for higher level applications like Machine Translation or Question &amp; Answering. In fact, WSD at this level of granularity has resisted all attempts of inferring robust broad-coverage models. It seems that many word–sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches </context>
</contexts>
<marker>Agirre, LopezDeLaCalle, 2003</marker>
<rawString>E. Agirre and O. LopezDeLaCalle. 2003. Clustering wordnet word senses. In Proceedings of RANLP’03, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
</authors>
<title>Oier Lopez de Lacalle, Christiane Fellbaum,</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), Association for Computational Linguistics.</booktitle>
<location>Shu</location>
<marker>Agirre, 2010</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, Christiane Fellbaum, Shu kai Hsieh, Maurizio Tesconi, Monica Monachini, Piek Vossen, and Roxanne Segers. 2010. Semeval-2010 task 17: All-words word sense disambiguation on a specific domain. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ciaramita</author>
<author>Y Altun</author>
</authors>
<title>Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’06),</booktitle>
<pages>594--602</pages>
<publisher>ACL.</publisher>
<location>Sydney, Australia.</location>
<contexts>
<context position="3029" citStr="Ciaramita and Altun, 2006" startWordPosition="455" endWordPosition="458">rcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous research using BLC empirically demonstrated that this automatically derived 1http://adimen.si.ehu.es/web/BLC 402 Proceedings of the </context>
</contexts>
<marker>Ciaramita, Altun, 2006</marker>
<rawString>M. Ciaramita and Y. Altun. 2006. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’06), pages 594–602, Sydney, Australia. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ciaramita</author>
<author>M Johnson</author>
</authors>
<title>Supersense tagging of unknown nouns in wordnet.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP’03),</booktitle>
<pages>168--175</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2929" citStr="Ciaramita and Johnson, 2003" startWordPosition="440" endWordPosition="443">tated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous research using BLC empirically d</context>
</contexts>
<marker>Ciaramita, Johnson, 2003</marker>
<rawString>M. Ciaramita and M. Johnson. 2003. Supersense tagging of unknown nouns in wordnet. In Proceedings of the Conference on Empirical methods in natural language processing (EMNLP’03), pages 168–175. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Curran</author>
</authors>
<title>Supersense tagging of unknown nouns using semantic similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL’05),</booktitle>
<pages>26--33</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2971" citStr="Curran, 2005" startWordPosition="448" endWordPosition="449">eriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous research using BLC empirically demonstrated that this automatically derive</context>
</contexts>
<marker>Curran, 2005</marker>
<rawString>J. Curran. 2005. Supersense tagging of unknown nouns using semantic similarity. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL’05), pages 26–33. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L M`arquez</author>
<author>G Rigau</author>
</authors>
<title>An Empirical Study of the Domain Dependence of Supervised Word Sense Disambiguation Systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, EMNLP/VLC,</booktitle>
<location>Hong Kong, China.</location>
<marker>Escudero, M`arquez, Rigau, 2000</marker>
<rawString>G. Escudero, L. M`arquez, and G. Rigau. 2000. An Empirical Study of the Domain Dependence of Supervised Word Sense Disambiguation Systems. In Proceedings of the joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, EMNLP/VLC, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
<author>H Sch¨utze</author>
</authors>
<title>Customizing a lexicon to better suit a computational task.</title>
<date>1993</date>
<booktitle>In Proceedingns of the ACL SIGLEX Workshop on Lexical Acquisition,</booktitle>
<location>Stuttgart, Germany.</location>
<marker>Hearst, Sch¨utze, 1993</marker>
<rawString>M. Hearst and H. Sch¨utze. 1993. Customizing a lexicon to better suit a computational task. In Proceedingns of the ACL SIGLEX Workshop on Lexical Acquisition, Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Izquierdo</author>
<author>A Suarez</author>
<author>G Rigau</author>
</authors>
<title>Exploring the automatic selection of basic level concepts.</title>
<date>2007</date>
<booktitle>In Galia Angelova</booktitle>
<pages>298--302</pages>
<editor>et al., editor,</editor>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="3482" citStr="Izquierdo et al., 2007" startWordPosition="526" endWordPosition="529">assifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous research using BLC empirically demonstrated that this automatically derived 1http://adimen.si.ehu.es/web/BLC 402 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 402–406, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics set of meanings groups senses into an adequate level of abstraction in order to perform class-based Word Sense Disambiguation (WSD) (Izquierdo et al., 2009). Now, we also show that class-based WSD allows to successfully incorporate monosemous examples from the domain text. In fact, the robustn</context>
<context position="4862" citStr="Izquierdo et al., 2007" startWordPosition="737" endWordPosition="740">Most Frequent Sense (MFS) baseline. This paper describes our participation in SemEval-2010 Task 17 (Agirre et al., 2010). In section 2 semantic classes used and selection algorithm used to obtain them automatically from WordNet are described. In section 3 the technique employed to extract monosemous examples from background data is described. Section 4 explains the general approach of our system, and the experiments designed, and finally, in section 5, the results and some analysis are shown. 2 Semantic Classes The set of semantic classes used in this work are the Basic Level Concepts2 (BLC) (Izquierdo et al., 2007). These concepts are small sets of meanings representing the whole nominal and verbal part of WN. BLC can be obtained by a very simple method that uses basic structural WordNet properties. In fact, the algorithm only considers the relative number of relations of each synset along the hypernymy chain. The process follows a bottomup approach using the chain of hypernymy relations. For each synset in WN, the process selects as its BLC the first local maximum according to the relative number of relations. The local maximum is the synset in the hypernymy chain having more relations than its immedia</context>
</contexts>
<marker>Izquierdo, Suarez, Rigau, 2007</marker>
<rawString>R. Izquierdo, A. Suarez, and G. Rigau. 2007. Exploring the automatic selection of basic level concepts. In Galia Angelova et al., editor, International Conference Recent Advances in Natural Language Processing, pages 298–302, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rub´en Izquierdo</author>
<author>Armando Su´arez</author>
<author>German Rigau</author>
</authors>
<title>An empirical study on class-based word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>389--397</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<marker>Izquierdo, Su´arez, Rigau, 2009</marker>
<rawString>Rub´en Izquierdo, Armando Su´arez, and German Rigau. 2009. An empirical study on class-based word sense disambiguation. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 389–397, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with support vector machines: learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Claire N´edellec and C´eline Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<publisher>Springer Verlag,</publisher>
<location>Chemnitz, DE.</location>
<contexts>
<context position="10194" citStr="Joachims, 1998" startWordPosition="1636" endWordPosition="1637">e 3: Most frequent monosemic words in BG 3We used the documents contained on the trial data and the background. 4 System Overview Our system applies a supervised machine learning approach. We apply a feature extractor to represent the training examples of the examples acquired from SemCor and the background documents. Then, a machine learning engine uses the annotated examples to train a set of classifiers. Support Vector Machines (SVM) have been proven to be robust and very competitive in many NLP tasks, and in WSD in particular (M`arquez et al., 2006). We used the SVM-Light implementation4 (Joachims, 1998). We create a classifier for each semantic class. This approach has several advantages compared to word–based approach. The training data per classifier is increased (we can use examples of different target words for a single classifier, whenever all examples belong to the same semantic class), the polysemy is reduced (some different word senses can be collapsed into the same semantic class), and, finally, semantic classes provide higher levels of abstraction. For each polysemous word occurring in the test corpus, we obtain its potential BLC–20 classes. Then, we only apply the classifiers corr</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text categorization with support vector machines: learning with many relevant features. In Claire N´edellec and C´eline Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137–142, Chemnitz, DE. Springer Verlag, Heidelberg, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Upali S Kohomban</author>
<author>Wee Sun Lee</author>
</authors>
<title>Learning semantic classes for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>34--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2997" citStr="Kohomban and Lee, 2005" startWordPosition="450" endWordPosition="453">t word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous research using BLC empirically demonstrated that this automatically derived 1http://adimen.si.ehu.es</context>
<context position="11096" citStr="Kohomban and Lee, 2005" startWordPosition="1782" endWordPosition="1785">semantic class), the polysemy is reduced (some different word senses can be collapsed into the same semantic class), and, finally, semantic classes provide higher levels of abstraction. For each polysemous word occurring in the test corpus, we obtain its potential BLC–20 classes. Then, we only apply the classifiers corresponding to the BLC-20 classes of the polysemous word. Finally, our system simply selects the BLC–20 class with the greater prediction. In order to obtain the correct WordNet 3.0 synset required by the task, we apply a simple heuristic that has shown to be robust and accurate (Kohomban and Lee, 2005). Our classifiers obtain first the semantic class, and then, the synset of the first WordNet sense that fits with the semantic class is assigned to the word. We selected a simple feature set widely used in many WSD systems. In particular, we use a window of five tokens around the target word to extract word forms, lemmas; bigrams and trigrams of word forms and lemmas; trigrams of PoS tags, 4http://svmlight.joachims.org 404 and also the most frequent BLC–20 semantic class of the target word in the training corpus. Our system is fully described in (Izquierdo et al., 2009). The novelty introduced</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Upali S. Kohomban and Wee Sun Lee. 2005. Learning semantic classes for word sense disambiguation. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 34–41, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero M`arquez</author>
<author>D Martinez</author>
<author>G Rigau</author>
</authors>
<title>Supervised corpus-based methods for wsd. In E. Agirre and P. Edmonds (Eds.) Word Sense Disambiguation: Algorithms and applications., volume 33 of Text, Speech and Language Technology.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<marker>M`arquez, Martinez, Rigau, 2006</marker>
<rawString>Ll. M`arquez, G. Escudero, D. Martinez, and G. Rigau. 2006. Supervised corpus-based methods for wsd. In E. Agirre and P. Edmonds (Eds.) Word Sense Disambiguation: Algorithms and applications., volume 33 of Text, Speech and Language Technology. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D Moldovan</author>
</authors>
<title>Automatic generation of coarse grained wordnet.</title>
<date>2001</date>
<booktitle>In Proceding of the NAACL workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations,</booktitle>
<location>Pittsburg, USA.</location>
<contexts>
<context position="2526" citStr="Mihalcea and Moldovan, 2001" startWordPosition="379" endWordPosition="382">e repository that often provides too fine–grained sense distinctions for higher level applications like Machine Translation or Question &amp; Answering. In fact, WSD at this level of granularity has resisted all attempts of inferring robust broad-coverage models. It seems that many word–sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic c</context>
</contexts>
<marker>Mihalcea, Moldovan, 2001</marker>
<rawString>R. Mihalcea and D. Moldovan. 2001. Automatic generation of coarse grained wordnet. In Proceding of the NAACL workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations, Pittsburg, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
</authors>
<title>Meaningful clustering of senses helps boost word sense disambiguation performance.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>105--112</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2578" citStr="Navigli, 2006" startWordPosition="388" endWordPosition="389">ns for higher level applications like Machine Translation or Question &amp; Answering. In fact, WSD at this level of granularity has resisted all attempts of inferring robust broad-coverage models. It seems that many word–sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original</context>
</contexts>
<marker>Navigli, 2006</marker>
<rawString>R. Navigli. 2006. Meaningful clustering of senses helps boost word sense disambiguation performance. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 105–112, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Peters</author>
<author>I Peters</author>
<author>P Vossen</author>
</authors>
<title>Automatic sense clustering in eurowordnet.</title>
<date>1998</date>
<booktitle>In First International Conference on Language Resources and Evaluation (LREC’98),</booktitle>
<location>Granada,</location>
<contexts>
<context position="2495" citStr="Peters et al., 1998" startWordPosition="375" endWordPosition="378">icized for being a sense repository that often provides too fine–grained sense distinctions for higher level applications like Machine Translation or Question &amp; Answering. In fact, WSD at this level of granularity has resisted all attempts of inferring robust broad-coverage models. It seems that many word–sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explic</context>
</contexts>
<marker>Peters, Peters, Vossen, 1998</marker>
<rawString>W. Peters, I. Peters, and P. Vossen. 1998. Automatic sense clustering in eurowordnet. In First International Conference on Language Resources and Evaluation (LREC’98), Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Segond</author>
<author>A Schiller</author>
<author>G Greffenstette</author>
<author>J Chanod</author>
</authors>
<title>An experiment in semantic tagging using hidden markov model tagging.</title>
<date>1997</date>
<booktitle>In ACL Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications,</booktitle>
<pages>78--81</pages>
<publisher>ACL,</publisher>
<location>New Brunswick, New Jersey.</location>
<contexts>
<context position="2898" citStr="Segond et al., 1997" startWordPosition="436" endWordPosition="439">umes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files of WN (more recently called SuperSenses) as very coarse–grained sense distinctions. We suspect that selecting the appropriate level of abstraction could be on between both levels. Thus, we use the semantic classes modeled by the Basic Level Concepts1 (BLC) (Izquierdo et al., 2007). Our previous r</context>
</contexts>
<marker>Segond, Schiller, Greffenstette, Chanod, 1997</marker>
<rawString>F. Segond, A. Schiller, G. Greffenstette, and J. Chanod. 1997. An experiment in semantic tagging using hidden markov model tagging. In ACL Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, pages 78–81. ACL, New Brunswick, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>S Prakash</author>
<author>D Jurafsky</author>
<author>A Ng</author>
</authors>
<title>Learning to merge word senses.</title>
<date>2007</date>
<booktitle>In Proceedings of Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1005--1014</pages>
<contexts>
<context position="2602" citStr="Snow et al., 2007" startWordPosition="391" endWordPosition="394">applications like Machine Translation or Question &amp; Answering. In fact, WSD at this level of granularity has resisted all attempts of inferring robust broad-coverage models. It seems that many word–sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word–sense annotated examples. Thus, some research has been focused on deriving different word-sense groupings to overcome the fine–grained distinctions of WN (Hearst and Sch¨utze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007). That is, they provide methods for grouping senses of the same word, thus producing coarser word sense groupings for better disambiguation. In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006). That is, grouping senses of different words into the same explicit and comprehensive semantic class. Most of the later approaches used the original Lexicographical Files o</context>
</contexts>
<marker>Snow, Prakash, Jurafsky, Ng, 2007</marker>
<rawString>R. Snow, Prakash S., Jurafsky D., and Ng A. 2007. Learning to merge word senses. In Proceedings of Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1005– 1014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Villarejo</author>
<author>L M`arquez</author>
<author>G Rigau</author>
</authors>
<title>Exploring the construction of semantic class classifiers for wsd.</title>
<date>2005</date>
<journal>ISSN</journal>
<booktitle>In Proceedings of the 21th Annual Meeting of Sociedad Espaola para el Procesamiento del Lenguaje Natural SEPLN’05,</booktitle>
<pages>195--202</pages>
<location>Granada, Spain,</location>
<marker>Villarejo, M`arquez, Rigau, 2005</marker>
<rawString>L. Villarejo, L. M`arquez, and G. Rigau. 2005. Exploring the construction of semantic class classifiers for wsd. In Proceedings of the 21th Annual Meeting of Sociedad Espaola para el Procesamiento del Lenguaje Natural SEPLN’05, pages 195–202, Granada, Spain, September. ISSN 1136-5948.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>