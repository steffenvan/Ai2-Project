<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000424">
<title confidence="0.999049">
Learning Semantic Representations of Users and Products
for Document Level Sentiment Classification
</title>
<author confidence="0.997632">
Duyu Tang, Bing Qin∗, Ting Liu
</author>
<affiliation confidence="0.996059">
Harbin Institute of Technology, Harbin, China
</affiliation>
<email confidence="0.959378">
{dytang, qinb, tliu}@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.994555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99969128">
Neural network methods have achieved
promising results for sentiment classifica-
tion of text. However, these models on-
ly use semantics of texts, while ignoring
users who express the sentiment and prod-
ucts which are evaluated, both of which
have great influences on interpreting the
sentiment of text. In this paper, we ad-
dress this issue by incorporating user- and
product- level information into a neural
network approach for document level sen-
timent classification. Users and product-
s are modeled using vector space mod-
els, the representations of which capture
important global clues such as individu-
al preferences of users or overall quali-
ties of products. Such global evidence
in turn facilitates embedding learning pro-
cedure at document level, yielding better
text representations. By combining ev-
idence at user-, product- and document-
level in a unified neural framework, the
proposed model achieves state-of-the-art
performances on IMDB and Yelp dataset-
s1.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943375">
Document-level sentiment classification is a fun-
damental problem in the field of sentiment analy-
sis and opinion mining (Pang and Lee, 2008; Liu,
2012). The task is to infer the sentiment polari-
ty or intensity (e.g. 1-5 or 1-10 stars on review
sites) of a document. Dominating studies follow
Pang et al. (2002; 2005) and regard this problem
as a multi-class classification task. They usually
</bodyText>
<note confidence="0.733347">
∗Corresponding author.
</note>
<footnote confidence="0.962003">
1The codes and datasets are available at http://ir.
hit.edu.cn/˜dytang/
</footnote>
<bodyText confidence="0.999774594594595">
use machine learning algorithms, and build sen-
timent classifier from documents with accompa-
nying sentiment labels. Since the performance
of a machine learner is heavily dependent on the
choice of data representations (Domingos, 2012),
many works focus on designing effective features
(Pang et al., 2002; Qu et al., 2010; Kiritchenko et
al., 2014) or learning discriminative features from
data with neural networks (Socher et al., 2013;
Kalchbrenner et al., 2014; Le and Mikolov, 2014).
Despite the apparent success of neural network
methods, they typically only use text information
while ignoring the important influences of users
and products. Let us take reviews with respect to
1-5 rating scales as an example. A critical user
might write a review “it works great” and mark 4
stars, while a lenient user might give 5 stars even if
he posts an (almost) identical review. In this case,
user preference affects the sentiment rating of a re-
view. Product quality also has an impact on review
sentiment rating. Reviews towards high-quality
products (e.g. Macbook) tend to receive higher
ratings than those towards low-quality products.
Therefore, it is feasible to leverage individual pref-
erences of users and overall qualities of products
to build a smarter sentiment classifier and achieve
better performance2.
In this paper, we propose a new model dubbed
User Product Neural Network (UPNN) to capture
user- and product-level information for sentiment
classification of documents (e.g. reviews). UPNN
takes as input a variable-sized document as well
as the user who writes the review and the product
which is evaluated. It outputs sentiment polarity
label of a document. Users and products are en-
coded in continuous vector spaces, the representa-
tions of which capture important global clues such
</bodyText>
<footnote confidence="0.927537">
2One can manually design a small number of user and
product features (Gao et al., 2013). However, we argue that
they are not effective enough to capture sophisticated seman-
tics of users and products.
</footnote>
<page confidence="0.901243">
1014
</page>
<note confidence="0.974413333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1014–1023,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999962352941176">
as user preferences and product qualities. These
representations are further integrated with contin-
uous text representation in a unified neural frame-
work for sentiment classification.
We apply UPNN to three datasets derived from
IMDB and Yelp Dataset Challenge. We compare
to several neural network models including recur-
sive neural networks (Socher et al., 2013), para-
graph vector (Le and Mikolov, 2014), sentiment-
specific word embedding (Tang et al., 2014b),
and a state-of-the-art recommendation algorithm
JMARS (Diao et al., 2014). Experimental results
show that: (1) UPNN outperforms baseline meth-
ods for sentiment classification of documents; (2)
incorporating representations of users and prod-
ucts significantly improves classification accuracy.
The main contributions of this work are as follows:
</bodyText>
<listItem confidence="0.994620333333333">
• We present a new neural network method
(UPNN) by leveraging users and products for
document-level sentiment classification.
• We validate the influences of users and prod-
ucts in terms of sentiment and text on massive
IMDB and Yelp reviews.
• We report empirical results on three datasets,
and show that UPNN outperforms state-of-the-art
methods for sentiment classification.
</listItem>
<sectionHeader confidence="0.721496" genericHeader="method">
2 Consistency Assumption Verification
</sectionHeader>
<bodyText confidence="0.999776">
We detail the effects of users and products in terms
of sentiment (e.g. 1-5 rating stars) and text, and
verify them on review datasets.
We argue that the influences of users and prod-
ucts include the following four aspects.
</bodyText>
<listItem confidence="0.9068805">
• user-sentiment consistency. A user has spe-
cific preference on providing sentiment ratings.
Some users favor giving higher ratings like 5 stars
and some users tend to give lower ratings. In oth-
er words, sentiment ratings from the same user are
more consistent than those from different users.
• product-sentiment consistency. Similar
with user-sentiment consistency, a product also
has its “preference” to receive different average
ratings on account of its overall quality. Sentiment
ratings towards the same product are more consis-
tent than those towards different products.
• user-text consistency. A user likes to use per-
sonalized sentiment words when expressing opin-
ion polarity or intensity. For example, a strict user
might use “good” to express an excellent attitude,
but a lenient user may use “good” to evaluate an
ordinary product.
</listItem>
<bodyText confidence="0.657795666666667">
Algorithm 1 Consistency Assumption Testing
Input: data X, number of users/products m,
number of iterations n
</bodyText>
<equation confidence="0.980444222222222">
Output: mea5amek, meaDiffk, 1 &lt; k &lt; n
fork=1tondo
mea5amek = 0, mea5amek = 0
for i = 1 to m do
Sample xi, x+i , x−i from X
mea5amek += measure(xi, x+i )
meaDiffk += measure(xi, x−i )
end for
mea5amek /= m, meaDiffk /= m
</equation>
<listItem confidence="0.677041285714286">
end for
• product-text consistency. Similar with user-
text consistency, a product also has a collection of
product-specific words suited to evaluate it. For
example, people prefer using “sleek” and “stable”
to evaluate a smartphone, while like to use “wire-
less” and “mechanical” to evaluate a keyboard.
</listItem>
<bodyText confidence="0.999896392857143">
We test four consistency assumptions men-
tioned above with the same testing criterion,
which is formalized in Algorithm 1. For each
consistency assumption, we test it for n = 50 iter-
ations on each of IMDB, Yelp Dataset Challenge
2013 and 2014 datasets. Taking user-sentiment
consistency as an example, in each iteration,
we randomly select two reviews xi, x+i written
by the same user ui, and a review x−i written
by another randomly selected user. Afterwards,
we calculate the measurements of (xi, x+i ) and
(xi, x−i ), and aggregate these statistics for m
users. In user-sentiment assumption test, we use
absolute rating difference ||ratinga − ratingb||
as the measurement between two reviews a and
b. We illustrate the results in Figure 1 (a)3,
where 2013same/2014same/amzsame (red
plots) means that two reviews are written by a
same user, and 2013diff/2014diff/amzdiff
(black plots) means that two reviews are written
by different users. We can find that: the absolute
rating differences between two reviews written by
a same user are lower than those written by dif-
ferent users (t-test with p-value &lt; 0.01). In other
words, sentiment ratings from the same user are
more consistent than those from different users.
This validates the user-sentiment consistency.
For testing product-sentiment consistency, we
</bodyText>
<footnote confidence="0.995981333333333">
3Since the rating scale of IMDB (1-10) is different from
Yelp (1-5), we divide the rating difference of IMDB reviews
by two for better visualizing and analyzing the results.
</footnote>
<page confidence="0.994655">
1015
</page>
<figure confidence="0.999397790697674">
2013Same 2013Diff 2014Same 2014Diff IMDBSame IMDBDiff
(a) user-sentiment consistency
2013Same 2013Diff 2014Same 2014Diff IMDBSame IMDBDiff
(c) user-text consistency
2013Same 2013Oiff 2014Same 2014Oiff IMOBSame IMOBOiff
(b) product-sentiment consistency
2013Same 2013Diff 2014Same 2014Diff IMDBSame IMDBDiff
(d) product-text consistency
1.6
1.55
1.5
1.45
1.4
1.35
1.3
1.25
1.2
0.28
0.27
0.26
0.25
0.24
0.23
0.22
0.21
0.2
0.27
0.26
0.25
0.24
0.23
0.22
0.21
0.2
1.55
1.5
1.45
1.4
1.35
1.3
1.25
1.2
1.15
</figure>
<figureCaption confidence="0.973125">
Figure 1: Assumption testing of user-sentiment, product-sentiment, user-text and product-text consisten-
cies. We test them on the datasets from IMDB and Yelp Dataset Challenge in 2013 and 2014.
</figureCaption>
<bodyText confidence="0.999944214285714">
use absolute rating difference as the measuremen-
t. The reviews xi, x+i are towards a same product
pi, and x−i is towards another randomly selected
product. From Figure 1 (b), we can see that sen-
timent ratings towards the same product are more
consistent than those towards different products.
In order to verify the assumptions of user-text and
product-text consistencies, we use cosine similar-
ity between bag-of-words of two reviews as the
measurement. Results are given in Figure 1 (c) and
(d). We can see that the textual similarity between
two reviews written by a same user (or towards a
same product) are higher than those written by d-
ifferent users (or towards different products).
</bodyText>
<sectionHeader confidence="0.988489" genericHeader="method">
3 User Product Neural Network (UPNN)
</sectionHeader>
<subsectionHeader confidence="0.633132">
for Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.99997625">
We present the details of User Product Neural Net-
work (UPNN) for sentiment classification. An il-
lustration of UPNN is given in Figure 2. It takes
as input a review, the user who posts the review,
and the product which is evaluated. UPNN cap-
tures four kinds of consistencies which are veri-
fied in Section 2. It outputs the sentiment category
(e.g. 1-5 stars) of a review by considering not only
the semantics of review text, but also the informa-
tion of user and product. In following subsection-
s, we first describe the use of neural network for
modeling semantics of variable-sized documents.
We then present the methods for incorporating us-
er and product information, followed by the use
of UPNN in a supervised learning framework for
sentiment classification.
</bodyText>
<subsectionHeader confidence="0.999892">
3.1 Modeling Semantics of Document
</subsectionHeader>
<bodyText confidence="0.999689142857143">
We model the semantics of documents based on
the principle of compositionality (Frege, 1892),
which states that the meaning of a longer expres-
sion (e.g. a sentence or a document) comes from
the meanings of its words and the rules used to
combine them. Since a document consists of a list
of sentences and each sentence is made up of a list
of words, we model the semantic representation of
a document in two stages. We first produce con-
tinuous vector of each sentence from word repre-
sentations. Afterwards, we feed sentence vectors
as inputs to compose document representation.
For modeling the semantics of words, we rep-
resent each word as a low dimensional, continu-
</bodyText>
<page confidence="0.966127">
1016
</page>
<figure confidence="0.999696947368421">
uk vd pj
Pooling
Linear
Softmax gold rating = 2
Convolution
Lookup
Tanh
Uk w1 Pj
h1
X
X
w1
Uk w2 Pj w2
h2 hn
X
X
Uk wn Pj wn
X
X
</figure>
<figureCaption confidence="0.993552">
Figure 2: An illustration of the neural network approach for sentiment classification. wi means the
</figureCaption>
<bodyText confidence="0.993877042553191">
i-th word of a review text. uk and pj are continuous vector representations of user k and product j
for capturing user-sentiment and product-sentiment consistencies. Uk and Pj are continuous matrix
representations of user k and product j for capturing user-text and product-text consistencies.
ous and real-valued vector, also known as word
embedding (Bengio et al., 2003). All the word
vectors are stacked in a word embedding matrix
Lw E Rdx�V �, where d is the dimension of word
vector and |V  |is the size of word vocabulary.
These word vectors can be randomly initialized
from a uniform distribution, regarded as a param-
eter and jointly trained with other parameters of
neural networks. Alternatively, they can be pre-
trained from text corpus with embedding learning
algorithms (Mikolov et al., 2013; Pennington et
al., 2014; Tang et al., 2014b), and applied as ini-
tial values of word embedding matrix. We adopt
the latter strategy which better exploits the seman-
tic and grammatical associations of words.
To model semantic representations of sentences,
convolutional neural network (CNN) and recur-
sive neural network (Socher et al., 2013) are t-
wo state-of-the-art methods. We use CNN (Kim,
2014; Kalchbrenner et al., 2014) in this work as
it does not rely on external parse tree. Specifical-
ly, we use multiple convolutional filters with dif-
ferent widths to produce sentence representation.
The reason is that they are capable of capturing lo-
cal semantics of n-grams of various granularities,
which are proven powerful for sentiment classifi-
cation. The convolutional filter with a width of 3
essentially captures the semantics of trigrams in a
sentence. Accordingly, multiple convolutional fil-
ters with widths of 1, 2 and 3 encode the semantics
of unigrams, bigrams and trigrams in a sentence.
An illustration of CNN with three convolu-
tional filters is given in Figure 3. Let us
denote a sentence consisting of n words as
{w1, w2, ...wi, ...wn}. Each word wi is mapped to
its embedding representation ei E Rd. A convo-
lutional filter is a list of linear layers with shared
parameters. Let lcf be the width of a convolution-
al filter, and let Wcf, bcf be the shared parameters
of linear layers in the filter. The input of a linear
layer is the concatenation of word embeddings in a
fixed-length window size lcf, which is denoted as
Icf = [ei; ei+1; ...; ei+lgf−1] E Rd·lgf . The output
of a linear layer is calculated as
</bodyText>
<equation confidence="0.951437">
Ocf = Wcf · Icf + bcf (1)
</equation>
<bodyText confidence="0.9998723125">
where Wcf E Rlenxd·lgf, bcf E Rlen, len is the
output length of linear layer. In order to capture
the global semantics of a sentence, we feed the
output of a convolutional filter to an average pool-
ing layer, resulting in an output vector with fixed-
length. We further add hyperbolic tangent func-
tions (tanh) to incorporate element-wise nonlin-
earity, and fold (average) their outputs to generate
sentence representation.
We feed sentence vectors as the input of an av-
erage pooling layer to obtain the document rep-
resentation. Alternative document modeling ap-
proaches include CNN or recurrent neural net-
work. However, we prefer average pooling for its
computational efficiency and good performance in
our experiment.
</bodyText>
<subsectionHeader confidence="0.9856075">
3.2 Modeling Semantics of Users and
Products
</subsectionHeader>
<bodyText confidence="0.9982785">
We integrate semantic representations of users
and products in UPNN to capture user-sentiment,
</bodyText>
<page confidence="0.994108">
1017
</page>
<figureCaption confidence="0.9236345">
Figure 3: Convolutional neural network with mul-
tiple convolutional filters for sentence modeling.
</figureCaption>
<bodyText confidence="0.997985378378378">
product-sentiment, user-text and product-text con-
sistencies.
For modeling user-sentiment and product-
sentiment consistencies, we embed each user as
a continuous vector uk E Rdu and embed each
product as a continuous vector pj E Rdp, where du
and dp are dimensions of user vector and product
vector, respectively. The basic idea behind this is
to map users with similar rating preferences (e.g.
prefer assigning 4 stars) into close vectors in user
embedding space. Similarly, the products which
receive similar averaged ratings are mapped into
neighboring vectors in product embedding space.
In order to model user-text consistency, we rep-
resent each user as a continuous matrix Uk E
RdU ×d, which acts as an operator to modify the
semantic meaning of a word. This is on the basis
of vector based semantic composition (Mitchel-
l and Lapata, 2010). They regard compositional
modifier as a matrix X1 to modify another com-
ponent x2, and use matrix-vector multiplication
y = X1 x x2 as the composition function. Multi-
plicative semantic composition is suitable for our
need of user modifying word meaning, and it
has been successfully utilized to model adjective-
noun composition (Clark et al., 2008; Baroni and
Zamparelli, 2010) and adverb-adjective composi-
tion (Socher et al., 2012). Similarly, we model
product-text consistency by encoding each prod-
uct as a matrix Pj E RdP ×d, where d is the di-
mension of word vector, dP is the output length
of product-word multiplicative composition. After
conducting user-word multiplication and product-
word multiplication operations, we concatenate
their outputs and feed them to CNN (detailed in
Section 3.1) for producing user and product en-
hanced document representation.
</bodyText>
<subsectionHeader confidence="0.999055">
3.3 Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.9999545">
We apply UPNN to document level sentiment clas-
sification under a supervised learning framework
(Pang and Lee, 2005). Instead of using hand-
crafted features, we use continuous representation
of documents, users and products as discrimina-
tive features. The sentiment classifier is built from
documents with gold standard sentiment labels.
As is shown in Figure 2, the feature represen-
tation for building rating predictor is the concate-
nation of three parts: continuous user representa-
tion uk, continuous product representation pj and
continuous document representation vd, where vd
encodes user-text consistency, product-text consis-
tency and document level semantic composition.
We use softmax to build the classifier because its
outputs can be interpreted as conditional probabil-
ities. Softmax is calculated as given in Equation
2, where C is the category number (e.g. 5 or 10).
</bodyText>
<equation confidence="0.9459665">
sof tmaxi = exp(xi)C (2)
�if=1 exp(xi�)
</equation>
<bodyText confidence="0.999696166666666">
We regard cross-entropy error between
gold sentiment distribution and predicted sen-
timent distribution as the loss function of
softmax. We take the derivative of loss
function through back-propagation with re-
spect to the whole set of parameters θ =
</bodyText>
<equation confidence="0.921177">
[W 1,2,3
cf ; b1,2,3
cf ;uk;pj; Uk; Pj; Wsoftmax, bsoftmax],
</equation>
<bodyText confidence="0.99990875">
and update parameters with stochastic gradient
descent. We set the widths of three convolutional
filters as 1, 2 and 3. We learn 200-dimensional
sentiment-specific word embeddings (Tang et
al., 2014b) on each dataset separately, randomly
initialize other parameters from a uniform distri-
bution U(−0.01,0.01), and set learning rate as
0.03.
</bodyText>
<sectionHeader confidence="0.999063" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999506">
We conduct experiments to evaluate UPNN by ap-
plying it to sentiment classification of documents.
</bodyText>
<subsectionHeader confidence="0.987386">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999985875">
Existing benchmark datasets for sentiment clas-
sification such as Stanford Sentiment Treebank
(Socher et al., 2013) typically only have text infor-
mation, but do not contain users who express the
sentiment or products which are evaluated. There-
fore, we build the datasets by ourselves. In order
to obtain large scale corpora without manual anno-
tation, we derive three datasets from IMDB (Diao
</bodyText>
<figure confidence="0.871345625">
Lookup
Folding
Pooling
Tanh
Convolution
filter1 filter2 filter3
W1
W2 W3 W4 Wn−1 Wn
</figure>
<page confidence="0.813488">
1018
</page>
<table confidence="0.98958625">
Dataset #users #products #reviews #docs/user #docs/product #sents/doc #words/doc
IMDB 1,310 1,635 84,919 64.82 51.94 16.08 394.6
Yelp 2014 4,818 4,194 231,163 47.97 55.11 11.41 196.9
Yelp 2013 1,631 1,633 78,966 48.42 48.36 10.89 189.3
</table>
<tableCaption confidence="0.996898">
Table 1: Statistical information of IMDB, Yelp 2014 and Yelp 2013 datasets used for sentiment classifi-
</tableCaption>
<bodyText confidence="0.9751030625">
cation. The rating scale of IMDB dataset is 1-10. The rating scale of Yelp 2014 and Yelp 2013 datasets is
1-5. |V  |is the vocabulary size of words in each dataset. #users is the number of users, #docs/user means
the average number of documents per user posts in the corpus.
et al., 2014) and Yelp Dataset Challenge4 in 2013
and 2014. Statistical information of the generated
datasets are given in Table 1.
We split each corpus into training, development
and testing sets with a 80/10/10 split, and conduct
tokenization and sentence splitting with Stanford
CoreNLP (Manning et al., 2014). We use standard
accuracy (Manning and Sch¨utze, 1999; Jurafsky
and Martin, 2000) to measure the overall senti-
ment classification performance, and use MAE
and RM5E to measure the divergences between
predicted sentiment ratings (pr) and ground truth
ratings (gd).
</bodyText>
<equation confidence="0.997327">
MAE = Ei |gdi − pri  |(3)
N
RM5E = l �i(gdi − pri)2 (4)
V N
</equation>
<sectionHeader confidence="0.71739" genericHeader="method">
4.2 Baseline Methods
</sectionHeader>
<bodyText confidence="0.997846666666667">
We compare UPNN with the following baseline
methods for document-level sentiment classifica-
tion.
</bodyText>
<listItem confidence="0.987613166666667">
(1) Majority is a heuristic baseline method,
which assigns the majority sentiment category in
training set to each review in the test dataset.
(2) In Trigram, we use unigrams, bigrams and
trigrams as features and train classifier with sup-
ported vector machine (SVM) (Fan et al., 2008).
(3) In TextFeature, we implement hand-crafted
text features including word/character ngrams,
sentiment lexicon features, negation features, etc
al. (Kiritchenko et al., 2014).
(4) We extract user-leniency features (Gao et al.,
2013) and corresponding product features (denot-
ed as UPF) from training data, and concatenate
them with the features in baseline (2) and (3).
(5) We learn word embeddings from training
and development sets with word2vec (Mikolov et
al., 2013), average word embeddings to get docu-
ment representation, and train a SVM classifier.
</listItem>
<footnote confidence="0.661704">
4http://www.yelp.com/dataset_challenge
</footnote>
<listItem confidence="0.973808294117647">
(6) We learn sentiment-specific word embed-
dings (SSWE) from training and development set-
s, and use max/min/average pooling (Tang et al.,
2014b) to generate document representation.
(7) We represent sentence with RNTN (Socher
et al., 2013) and compose document representa-
tion with recurrent neural network. We average
hidden vectors of recurrent neural network as the
features for sentiment classification.
(8) We re-implement PVDM in Paragraph Vec-
tor (Le and Mikolov, 2014) because its codes are
not officially provided. The window size is tuned
on development set.
(9) We compare with a state-of-the-art recom-
mendation algorithm JMARS (Diao et al., 2014),
which leverages user and aspects of a review with
collaborative filtering and topic modeling.
</listItem>
<subsectionHeader confidence="0.998566">
4.3 Model Comparisons
</subsectionHeader>
<bodyText confidence="0.9999905">
Experimental results are given in Table 2. The re-
sults are separated into two groups: the methods
above only use texts of review, and the methods
below also use user and product information.
From the first group, we can see that majori-
ty performs very poor because it does not cap-
ture any text or user information. SVM classi-
fiers with trigrams and hand-crafted text features
are powerful for document level sentiment classi-
fication and hard to beat. We compare the word
embedding learnt from each corpus with off-the-
shell general word embeddings5. Results show
that tailored word embedding from each corpus
performs slightly better than general word embed-
dings (about 0.01 improvement in terms of accu-
racy). SSWE performs better than context-based
word embedding by incorporating sentiment in-
formation of texts. Setting a large window size
(e.g. 15) is crucial for effectively training SS-
WE from documents with accompanying senti-
</bodyText>
<footnote confidence="0.886029">
5We compare with Glove embeddings learnt from
Wikipedia and Twitter http://nlp.stanford.edu/
projects/glove/
</footnote>
<page confidence="0.970942">
1019
</page>
<table confidence="0.999921357142857">
IMDB Yelp 2014 Yelp 2013
Acc MAE RMSE Acc MAE RMSE Acc MAE RMSE
Majority 0.196 1.838 2.495 0.392 0.779 1.097 0.411 0.744 1.060
Trigram 0.399 1.147 1.783 0.577 0.487 0.804 0.569 0.513 0.814
TextFeature 0.402 1.134 1.793 0.572 0.490 0.800 0.556 0.520 0.845
AvgWordvec + SVM 0.304 1.361 1.985 0.530 0.562 0.893 0.526 0.568 0.898
SSWE + SVM 0.312 1.347 1.973 0.557 0.523 0.851 0.549 0.529 0.849
Paragraph Vector 0.341 1.211 1.814 0.564 0.496 0.802 0.554 0.515 0.832
RNTN + Recurrent 0.400 1.133 1.764 0.582 0.478 0.821 0.574 0.489 0.804
UPNN (no UP) 0.405 1.030 1.629 0.585 0.483 0.808 0.577 0.485 0.812
Trigram + UPF 0.404 1.132 1.764 0.576 0.471 0.789 0.570 0.491 0.803
TextFeature + UPF 0.402 1.129 1.774 0.579 0.476 0.791 0.561 0.509 0.822
JMARS N/A 1.285 1.773 N/A 0.710 0.999 N/A 0.699 0.985
UPNN (full) 0.435 0.979 1.602 0.608 0.447 0.764 0.596 0.464 0.784
</table>
<tableCaption confidence="0.991084">
Table 2: Sentiment classification on IMDB, Yelp 2014 and Yelp 2013 datasets. Evaluation metrics are
</tableCaption>
<bodyText confidence="0.992966923076923">
accuracy (Acc, higher is better), MAE (lower is better) and RMSE (lower is better). Our full model is
UPNN (full). Our model without using user and product information is abbreviated as UPNN (no UP).
The best method in each group is in bold.
ment labels. RNTN+Reccurent is a strong per-
former by effectively modeling document repre-
sentation with semantic composition. Our text
based model (UPNN no UP) performs slightly bet-
ter than RNTN+Reccurent, trigram and text fea-
tures.
From the second group, we can see that con-
catenating user product feature (UPF) with exist-
ing feature sets does not show significant improve-
ments. This is because the dimension of existing
feature sets is typically huge (e.g. 1M trigram fea-
tures in Yelp 2014), so that concatenating a smal-
l number of UPF features does not have a great
influence on the whole model. We do not evalu-
ate JMARS in terms of accuracy because JMARS
outputs real-valued ratings. Our full model UPNN
yields the best performance on all three dataset-
s. Incorporating semantic representations of us-
er and product significantly (t-test with p-value &lt;
0.01) boosts our text based model (UPNN no UP).
This shows the effectiveness of UPNN over stan-
dard trigrams and hand-crafted features when in-
corporating user and product information.
</bodyText>
<subsectionHeader confidence="0.9999075">
4.4 Model Analysis: Effect of User and
Product Representations
</subsectionHeader>
<bodyText confidence="0.999955782608696">
We investigate the effects of vector based user and
product representations (uk, pj) as well as ma-
trix based user and product representations (Uk,
Pj) for sentiment classification. We remove vec-
tor based representations (uk, pj) and matrix based
representations (Uk, Pj) from UPNN separately,
and conduct experiments on three datasets. From
Table 3, we can find that vector based representa-
tions (uk, pj) are more effective than matrix based
representations (Uk, Pj). This is because uk and
pj encode user-sentiment and product-sentiment
consistencies, which are more directly associat-
ed with sentiment labels than user-text (Uk) and
product-text (Pj) consistencies. Another reason
might be that the parameters of vector represen-
tations are less than the matrix representations, so
that the vector representations are better estimat-
ed. We also see the contribution from each of user
and product by removing (Uk, uk) and (Pj, pj)
separately. Results are given in Table 3. It is in-
teresting to find that user representations are obvi-
ously more effective than product representations
for review rating prediction.
</bodyText>
<subsectionHeader confidence="0.999378">
4.5 Discussion: Out-Of-Vocabulary Users
and Products
</subsectionHeader>
<bodyText confidence="0.998922181818182">
Out-of-vocabulary (OOV) situation occurs if a us-
er or a product in testing/decoding process is n-
ever seen in training data. We give two natu-
ral solutions (avg UP and unk UP) to deal with
OOV users and products. One solution (avg UP)
is to regard the averaged representations of user-
s/products in training data as the representation of
OOV user/product. Another way (unk UP) is to
learn a shared “unknown” user/product represen-
tation for low-frequency users in training data, and
apply it to OOV user/product.
</bodyText>
<page confidence="0.95649">
1020
</page>
<table confidence="0.998523">
IMDB Yelp 2014 Yelp 2013
Acc MAE RMSE Acc MAE RMSE Acc MAE RMSE
UPNN (full) 0.435 0.979 1.602 0.608 0.447 0.764 0.596 0.464 0.784
UPNN − uk − pj 0.409 1.021 1.622 0.585 0.483 0.808 0.572 0.491 0.823
UPNN − Uk − Pj 0.426 0.993 1.607 0.597 0.465 0.789 0.585 0.482 0.802
UPNN − Uk − uk 0.324 1.209 1.743 0.577 0.475 0.778 0.566 0.505 0.828
UPNN − Pj − pj 0.397 1.075 1.712 0.595 0.462 0.776 0.590 0.476 0.802
</table>
<tableCaption confidence="0.974052">
Table 3: Influence of user and product representations. For user k and product j, uk and pj are their
continuous vector representations, Uk and Pj are their continuous matrix representations (see Figure 2).
</tableCaption>
<figureCaption confidence="0.9609105">
Figure 4: Accuracy of OOV user and product on
OOV test set.
</figureCaption>
<bodyText confidence="0.999983583333333">
In order to evaluate the two strategies for OOV
problem, we randomly select 10 percent users and
products from each development set, and mask
their user and product information. We run avg
UP, unk UP together with UPNN (no UP) which
only uses text information, and UPNN (full) which
learns tailored representation for each user and
product. We evaluate classification accuracy on
the extracted OOV test set. Experimental results
are given in Figure 5. We can find that these two
strategies perform slightly better than UPNN (no
UP), but still worse than the full model.
</bodyText>
<sectionHeader confidence="0.999966" genericHeader="method">
5 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999767">
5.1 Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.999982423076923">
Sentiment classification is a fundamental prob-
lem in sentiment analysis, which targets at infer-
ring the sentiment label of a document. Pang and
Lee (2002; 2005) cast this problem a classifica-
tion task, and use machine learning method in
a supervised learning framework. Goldberg and
Zhu (2006) use unlabelled reviews in a graph-
based semi-supervised learning method. Many s-
tudies design effective features, such as text top-
ic (Ganu et al., 2009), bag-of-opinion (Qu et al.,
2010) and sentiment lexicon features (Kiritchenko
et al., 2014). User information is also used for
sentiment classification. Gao et al. (2013) de-
sign user-specific features to capture user lenien-
cy. Li et al. (2014) incorporate textual topic and
user-word factors with supervised topic modeling.
Tan et al. (2011) and Hu et al. (2013) utilize user-
text and user-user relations for Twitter sentimen-
t analysis. Unlike most previous studies that use
hand-crafted features, we learn discriminative fea-
tures from data. We differ from Li et al. (2014) in
that we encode four kinds of consistencies and use
neural network approach. User representation is
also leveraged for recommendation (Weston et al.,
2013), web search (Song et al., 2014) and social
media analytics (Perozzi et al., 2014).
</bodyText>
<subsectionHeader confidence="0.9780695">
5.2 Neural Network for Sentiment
Classification
</subsectionHeader>
<bodyText confidence="0.999921086956522">
Neural networks have achieved promising results
for sentiment classification. Existing neural net-
work methods can be divided into two groups:
word embedding and semantic composition. For
learning word embeddings, (Mikolov et al., 2013;
Pennington et al., 2014) use local and global con-
texts, (Maas et al., 2011; Labutov and Lipson,
2013; Tang et al., 2014b; Tang et al., 2014a;
Zhou et al., 2015) further incorporate sentiment of
texts. For learning semantic composition, Glorot
et al. (2011) use stacked denoising autoencoder,
Socher et al. (2013) introduce a family of recursive
deep neural networks (RNN). RNN is extended
with adaptive composition functions (Dong et al.,
2014), global feedbackward (Paulus et al., 2014),
feature weight tuning (Li, 2014), and also used
for opinion relation detection (Xu et al., 2014).
Li et al. (2015) compare the effectiveness of re-
cursive neural network and recurrent neural net-
work on five NLP tasks including sentiment clas-
sification. (Kalchbrenner et al., 2014; Kim, 2014;
Johnson and Zhang, 2014) use convolutional neu-
ral networks. Le and Mikolov (2014) introduce
</bodyText>
<figure confidence="0.99817925">
0.65
0.6
0.55
0.5
0.45
0.4
0.35
IMDB Yelp 2014 Yelp 2013
no UP
avg UP
unk UP
full UP
</figure>
<page confidence="0.988214">
1021
</page>
<bodyText confidence="0.999247875">
Paragraph Vector. Unlike existing neural network
approaches that only use the semantics of texts,
we take consideration of user and product rep-
resentations and leverage their connections with
text semantics for sentiment classification. This
work is an extension of our previous work (Tang et
al., 2015), which only takes consideration of user-
word association.
</bodyText>
<sectionHeader confidence="0.998916" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999846076923077">
In this paper, we introduce User Product Neu-
ral Network (UPNN) for document level senti-
ment classification under a supervised learning
framework. We validate user-sentiment, product-
sentiment, user-text and product-text consistencies
on massive reviews, and effectively integrate them
in UPNN. We apply the model to three datasets
derived from IMDB and Yelp Dataset Challenge.
Empirical results show that: (1) UPNN outper-
forms state-of-the-art methods for document level
sentiment classification; (2) incorporating contin-
uous user and product representations significantly
boosts sentiment classification accuracy.
</bodyText>
<sectionHeader confidence="0.997238" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998297818181818">
The authors give great thanks to Furu Wei, Lei
Cui, Nan Yang, Jiwei Li, Yaming Sun, Mao Zheng
and anonymous reviewers for their valuable com-
ments. We would like to thank Qiming Diao for
providing the IMDB dataset as well as the codes of
JMARS. This work was supported by the Nation-
al High Technology Development 863 Program of
China (No. 2015AA015407), National Natural
Science Foundation of China (No. 61133012 and
No. 61273321). Duyu Tang is supported by Baidu
Fellowship and IBM Ph.D. Fellowship.
</bodyText>
<sectionHeader confidence="0.997861" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986176354838709">
Marco Baroni and Roberto Zamparelli. 2010. Noun-
s are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
EMNLP, pages 1183–1193.
Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and
Christian Janvin. 2003. A neural probabilistic lan-
guage model. Journal of Machine Learning Re-
search, 3:1137–1155.
Stephen Clark, Bob Coecke, and Mehrnoosh Sadrzade-
h. 2008. A compositional distributional model
of meaning. In Quantum Interaction Symposium,
pages 133–140.
Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexan-
der J Smola, Jing Jiang, and Chong Wang. 2014.
Jointly modeling aspects, ratings and sentiments for
movie recommendation (jmars). In SIGKDD, pages
193–202. ACM.
Pedro Domingos. 2012. A few useful things to know
about machine learning. Communications of the
ACM, 55(10):78–87.
Li Dong, Furu Wei, Ming Zhou, and Ke Xu. 2014.
Adaptive multi-compositionality for recursive neu-
ral models with applications to sentiment analysis.
In AAAI, pages 1537–1543.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. JMLR.
Gottlob Frege. 1892. On sense and reference. Ludlow
(1997), pages 563–584.
Gayatree Ganu, Noemie Elhadad, and Am´elie Marian.
2009. Beyond the stars: Improving rating predic-
tions using review text content. In WebDB.
Wenliang Gao, Naoki Yoshinaga, Nobuhiro Kaji, and
Masaru Kitsuregawa. 2013. Modeling user leniency
and product popularity for sentiment classification.
In ICJNLP, pages 1107–1111.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In ICML,
pages 513–520.
Andrew B Goldberg and Xiaojin Zhu. 2006. Seeing s-
tars when there aren’t many stars: graph-based semi-
supervised learning for sentiment categorization. In
GraphBased Method for NLP, pages 45–52.
Xia Hu, Lei Tang, Jiliang Tang, and Huan Liu. 2013.
Exploiting social relations for sentiment analysis in
microblogging. In WSDM, pages 537–546.
Rie Johnson and Tong Zhang. 2014. Effective use of
word order for text categorization with convolution-
al neural networks. arXiv preprint: 1412.1058.
Dan Jurafsky and James H Martin. 2000. Speech &amp;
language processing. Pearson Education India.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In ACL, pages 655–665.
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In EMNLP, pages 1746–
1751.
Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mo-
hammad. 2014. Sentiment analysis of short in-
formal texts. Journal of Artificial Intelligence Re-
search, pages 723–762.
</reference>
<page confidence="0.832227">
1022
</page>
<reference confidence="0.99975615625">
Igor Labutov and Hod Lipson. 2013. Re-embedding
words. In Annual Meeting of the Association for
Computational Linguistics.
Quoc V. Le and Tomas Mikolov. 2014. Distribut-
ed representations of sentences and documents. In
ICML, pages 1188–1196.
Fangtao Li, Sheng Wang, Shenghua Liu, and Ming
Zhang. 2014. Suit: A supervised user-item based
topic model for sentiment analysis. In AAAI, pages
1636–1642.
Jiwei Li, Dan Jurafsky, and Eudard Hovy. 2015. When
are tree structures necessary for deep learning of rep-
resentations? arXiv preprint:1503.00185.
Jiwei Li. 2014. Feature weight tuning for recursive
neural networks. Arxiv preprint, 1412.3714.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Andrew L Maas, Raymond E Daly, Peter T Pham, Dan
Huang, Andrew Y Ng, and Christopher Potts. 2011.
Learning word vectors for sentiment analysis. In A-
CL, pages 142–150.
Christopher D Manning and Hinrich Sch¨utze. 1999.
Foundations of statistical natural language process-
ing. MIT press.
Christopher Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven Bethard, and David McClosky.
2014. The stanford corenlp natural language pro-
cessing toolkit. In ACL, pages 55–60.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In NIPS, pages 3111–3119.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.
Bo Pang and Lillian Lee. 2005. Seeing stars: Exploit-
ing class relationships for sentiment categorization
with respect to rating scales. In ACL, pages 115–
124.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In EMNLP, pages 79–
86.
Romain Paulus, Richard Socher, and Christopher D
Manning. 2014. Global belief recursive neural net-
works. In NIPS, pages 2888–2896.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In EMNLP, pages 1532–1543.
Bryan Perozzi, Rami Al-Rfou, and Steven Skiena.
2014. Deepwalk: Online learning of social repre-
sentations. In SIGKDD, pages 701–710. ACM.
Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum.
2010. The bag-of-opinions method for review rating
prediction from sparse text patterns. In COLING,
pages 913–921.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic Composi-
tionality Through Recursive Matrix-Vector Spaces.
In EMNLP, pages 1201–1211.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In EMNLP, pages 1631–1642.
Yang Song, Hongning Wang, and Xiaodong He. 2014.
Adapting deep ranknet for personalized search. In
WSDM, pages 83–92. ACM.
Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming
Zhou, and Ping Li. 2011. User-level sentiment
analysis incorporating social networks. In SIGKDD,
pages 1397–1405. ACM.
Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and T-
ing Liu. 2014a. Building large-scale twitter-specific
sentiment lexicon: A representation learning ap-
proach. In COLING, pages 172–182.
Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014b. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In ACL, pages 1555–1565.
Duyu Tang, Bing Qin, Ting Liu, and Yuekui Yang.
2015. User modeling with neural network for re-
view rating prediction. In IJCAI.
Jason Weston, Ron J Weiss, and Hector Yee. 2013.
Nonlinear latent factorization by embedding multi-
ple user interests. In RecSys, pages 65–68. ACM.
Liheng Xu, Kang Liu, and Jun Zhao. 2014. Joint opin-
ion relation detection using one-class deep neural
network. In COLING, pages 677–687.
Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2015.
Representation learning for aspect category detec-
tion in online reviews. In AAAI.
</reference>
<page confidence="0.960145">
1023
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.605561">
<title confidence="0.999819">Learning Semantic Representations of Users and for Document Level Sentiment Classification</title>
<author confidence="0.987853">Bing Ting Tang</author>
<affiliation confidence="0.972551">Harbin Institute of Technology, Harbin, China</affiliation>
<email confidence="0.979432">qinb,</email>
<abstract confidence="0.98543408">Neural network methods have achieved promising results for sentiment classification of text. However, these models only use semantics of texts, while ignoring users who express the sentiment and products which are evaluated, both of which have great influences on interpreting the sentiment of text. In this paper, we address this issue by incorporating userand productlevel information into a neural network approach for document level sentiment classification. Users and products are modeled using vector space models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, productand documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp dataset-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>1183--1193</pages>
<contexts>
<context position="16124" citStr="Baroni and Zamparelli, 2010" startWordPosition="2579" endWordPosition="2582"> order to model user-text consistency, we represent each user as a continuous matrix Uk E RdU ×d, which acts as an operator to modify the semantic meaning of a word. This is on the basis of vector based semantic composition (Mitchell and Lapata, 2010). They regard compositional modifier as a matrix X1 to modify another component x2, and use matrix-vector multiplication y = X1 x x2 as the composition function. Multiplicative semantic composition is suitable for our need of user modifying word meaning, and it has been successfully utilized to model adjectivenoun composition (Clark et al., 2008; Baroni and Zamparelli, 2010) and adverb-adjective composition (Socher et al., 2012). Similarly, we model product-text consistency by encoding each product as a matrix Pj E RdP ×d, where d is the dimension of word vector, dP is the output length of product-word multiplicative composition. After conducting user-word multiplication and productword multiplication operations, we concatenate their outputs and feed them to CNN (detailed in Section 3.1) for producing user and product enhanced document representation. 3.3 Sentiment Classification We apply UPNN to document level sentiment classification under a supervised learning</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In EMNLP, pages 1183–1193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>R´ejean Ducharme</author>
<author>Pascal Vincent</author>
<author>Christian Janvin</author>
</authors>
<title>A neural probabilistic language model.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1137</pages>
<contexts>
<context position="11873" citStr="Bengio et al., 2003" startWordPosition="1876" endWordPosition="1879">ional, continu1016 uk vd pj Pooling Linear Softmax gold rating = 2 Convolution Lookup Tanh Uk w1 Pj h1 X X w1 Uk w2 Pj w2 h2 hn X X Uk wn Pj wn X X Figure 2: An illustration of the neural network approach for sentiment classification. wi means the i-th word of a review text. uk and pj are continuous vector representations of user k and product j for capturing user-sentiment and product-sentiment consistencies. Uk and Pj are continuous matrix representations of user k and product j for capturing user-text and product-text consistencies. ous and real-valued vector, also known as word embedding (Bengio et al., 2003). All the word vectors are stacked in a word embedding matrix Lw E Rdx�V �, where d is the dimension of word vector and |V |is the size of word vocabulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and</context>
</contexts>
<marker>Bengio, Ducharme, Vincent, Janvin, 2003</marker>
<rawString>Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and Christian Janvin. 2003. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137–1155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>Bob Coecke</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>A compositional distributional model of meaning.</title>
<date>2008</date>
<booktitle>In Quantum Interaction Symposium,</booktitle>
<pages>133--140</pages>
<contexts>
<context position="16094" citStr="Clark et al., 2008" startWordPosition="2575" endWordPosition="2578"> embedding space. In order to model user-text consistency, we represent each user as a continuous matrix Uk E RdU ×d, which acts as an operator to modify the semantic meaning of a word. This is on the basis of vector based semantic composition (Mitchell and Lapata, 2010). They regard compositional modifier as a matrix X1 to modify another component x2, and use matrix-vector multiplication y = X1 x x2 as the composition function. Multiplicative semantic composition is suitable for our need of user modifying word meaning, and it has been successfully utilized to model adjectivenoun composition (Clark et al., 2008; Baroni and Zamparelli, 2010) and adverb-adjective composition (Socher et al., 2012). Similarly, we model product-text consistency by encoding each product as a matrix Pj E RdP ×d, where d is the dimension of word vector, dP is the output length of product-word multiplicative composition. After conducting user-word multiplication and productword multiplication operations, we concatenate their outputs and feed them to CNN (detailed in Section 3.1) for producing user and product enhanced document representation. 3.3 Sentiment Classification We apply UPNN to document level sentiment classificati</context>
</contexts>
<marker>Clark, Coecke, Sadrzadeh, 2008</marker>
<rawString>Stephen Clark, Bob Coecke, and Mehrnoosh Sadrzadeh. 2008. A compositional distributional model of meaning. In Quantum Interaction Symposium, pages 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiming Diao</author>
<author>Minghui Qiu</author>
<author>Chao-Yuan Wu</author>
<author>Alexander J Smola</author>
<author>Jing Jiang</author>
<author>Chong Wang</author>
</authors>
<title>Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars).</title>
<date>2014</date>
<booktitle>In SIGKDD,</booktitle>
<pages>193--202</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4482" citStr="Diao et al., 2014" startWordPosition="681" endWordPosition="684"> Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge. We compare to several neural network models including recursive neural networks (Socher et al., 2013), paragraph vector (Le and Mikolov, 2014), sentimentspecific word embedding (Tang et al., 2014b), and a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014). Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy. The main contributions of this work are as follows: • We present a new neural network method (UPNN) by leveraging users and products for document-level sentiment classification. • We validate the influences of users and products in terms of sentiment and text on massive IMDB and Yelp reviews. • We report empirical results on three datasets, and show that UPNN outperforms state-o</context>
<context position="21722" citStr="Diao et al., 2014" startWordPosition="3443" endWordPosition="3446">embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) because its codes are not officially provided. The window size is tuned on development set. (9) We compare with a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014), which leverages user and aspects of a review with collaborative filtering and topic modeling. 4.3 Model Comparisons Experimental results are given in Table 2. The results are separated into two groups: the methods above only use texts of review, and the methods below also use user and product information. From the first group, we can see that majority performs very poor because it does not capture any text or user information. SVM classifiers with trigrams and hand-crafted text features are powerful for document level sentiment classification and hard to beat. We compare the word embedding l</context>
</contexts>
<marker>Diao, Qiu, Wu, Smola, Jiang, Wang, 2014</marker>
<rawString>Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexander J Smola, Jing Jiang, and Chong Wang. 2014. Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars). In SIGKDD, pages 193–202. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro Domingos</author>
</authors>
<title>A few useful things to know about machine learning.</title>
<date>2012</date>
<journal>Communications of the ACM,</journal>
<volume>55</volume>
<issue>10</issue>
<contexts>
<context position="1917" citStr="Domingos, 2012" startWordPosition="287" endWordPosition="288">opinion mining (Pang and Lee, 2008; Liu, 2012). The task is to infer the sentiment polarity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even i</context>
</contexts>
<marker>Domingos, 2012</marker>
<rawString>Pedro Domingos. 2012. A few useful things to know about machine learning. Communications of the ACM, 55(10):78–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Dong</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
<author>Ke Xu</author>
</authors>
<title>Adaptive multi-compositionality for recursive neural models with applications to sentiment analysis.</title>
<date>2014</date>
<booktitle>In AAAI,</booktitle>
<pages>1537--1543</pages>
<contexts>
<context position="30138" citStr="Dong et al., 2014" startWordPosition="4811" endWordPosition="4814">classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the sema</context>
</contexts>
<marker>Dong, Wei, Zhou, Xu, 2014</marker>
<rawString>Li Dong, Furu Wei, Ming Zhou, and Ke Xu. 2014. Adaptive multi-compositionality for recursive neural models with applications to sentiment analysis. In AAAI, pages 1537–1543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="20471" citStr="Fan et al., 2008" startWordPosition="3260" endWordPosition="3263">ntiment classification performance, and use MAE and RM5E to measure the divergences between predicted sentiment ratings (pr) and ground truth ratings (gd). MAE = Ei |gdi − pri |(3) N RM5E = l �i(gdi − pri)2 (4) V N 4.2 Baseline Methods We compare UPNN with the following baseline methods for document-level sentiment classification. (1) Majority is a heuristic baseline method, which assigns the majority sentiment category in training set to each review in the test dataset. (2) In Trigram, we use unigrams, bigrams and trigrams as features and train classifier with supported vector machine (SVM) (Fan et al., 2008). (3) In TextFeature, we implement hand-crafted text features including word/character ngrams, sentiment lexicon features, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. JMLR.</rawString>
</citation>
<citation valid="true">
<title>On sense and reference.</title>
<date>1997</date>
<pages>563--584</pages>
<location>Ludlow</location>
<marker>1997</marker>
<rawString>Gottlob Frege. 1892. On sense and reference. Ludlow (1997), pages 563–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>Noemie Elhadad</author>
<author>Am´elie Marian</author>
</authors>
<title>Beyond the stars: Improving rating predictions using review text content.</title>
<date>2009</date>
<booktitle>In WebDB.</booktitle>
<contexts>
<context position="28595" citStr="Ganu et al., 2009" startWordPosition="4573" endWordPosition="4576">n Figure 5. We can find that these two strategies perform slightly better than UPNN (no UP), but still worse than the full model. 5 Related Work 5.1 Sentiment Classification Sentiment classification is a fundamental problem in sentiment analysis, which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kin</context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, Noemie Elhadad, and Am´elie Marian. 2009. Beyond the stars: Improving rating predictions using review text content. In WebDB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Gao</author>
<author>Naoki Yoshinaga</author>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Modeling user leniency and product popularity for sentiment classification. In</title>
<date>2013</date>
<booktitle>ICJNLP,</booktitle>
<pages>1107--1111</pages>
<contexts>
<context position="3567" citStr="Gao et al., 2013" startWordPosition="549" endWordPosition="552"> classifier and achieve better performance2. In this paper, we propose a new model dubbed User Product Neural Network (UPNN) to capture user- and product-level information for sentiment classification of documents (e.g. reviews). UPNN takes as input a variable-sized document as well as the user who writes the review and the product which is evaluated. It outputs sentiment polarity label of a document. Users and products are encoded in continuous vector spaces, the representations of which capture important global clues such 2One can manually design a small number of user and product features (Gao et al., 2013). However, we argue that they are not effective enough to capture sophisticated semantics of users and products. 1014 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1014–1023, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets der</context>
<context position="20705" citStr="Gao et al., 2013" startWordPosition="3291" endWordPosition="3294">s We compare UPNN with the following baseline methods for document-level sentiment classification. (1) Majority is a heuristic baseline method, which assigns the majority sentiment category in training set to each review in the test dataset. (2) In Trigram, we use unigrams, bigrams and trigrams as features and train classifier with supported vector machine (SVM) (Fan et al., 2008). (3) In TextFeature, we implement hand-crafted text features including word/character ngrams, sentiment lexicon features, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013)</context>
<context position="28766" citStr="Gao et al. (2013)" startWordPosition="4598" endWordPosition="4601">n Sentiment classification is a fundamental problem in sentiment analysis, which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and soc</context>
</contexts>
<marker>Gao, Yoshinaga, Kaji, Kitsuregawa, 2013</marker>
<rawString>Wenliang Gao, Naoki Yoshinaga, Nobuhiro Kaji, and Masaru Kitsuregawa. 2013. Modeling user leniency and product popularity for sentiment classification. In ICJNLP, pages 1107–1111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Glorot</author>
<author>Antoine Bordes</author>
<author>Yoshua Bengio</author>
</authors>
<title>Domain adaptation for large-scale sentiment classification: A deep learning approach.</title>
<date>2011</date>
<booktitle>In ICML,</booktitle>
<pages>513--520</pages>
<contexts>
<context position="29950" citStr="Glorot et al. (2011)" startWordPosition="4783" endWordPosition="4786">b search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (</context>
</contexts>
<marker>Glorot, Bordes, Bengio, 2011</marker>
<rawString>Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML, pages 513–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Goldberg</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Seeing stars when there aren’t many stars: graph-based semisupervised learning for sentiment categorization. In GraphBased Method for NLP,</title>
<date>2006</date>
<pages>45--52</pages>
<contexts>
<context position="28444" citStr="Goldberg and Zhu (2006)" startWordPosition="4548" endWordPosition="4551">earns tailored representation for each user and product. We evaluate classification accuracy on the extracted OOV test set. Experimental results are given in Figure 5. We can find that these two strategies perform slightly better than UPNN (no UP), but still worse than the full model. 5 Related Work 5.1 Sentiment Classification Sentiment classification is a fundamental problem in sentiment analysis, which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most </context>
</contexts>
<marker>Goldberg, Zhu, 2006</marker>
<rawString>Andrew B Goldberg and Xiaojin Zhu. 2006. Seeing stars when there aren’t many stars: graph-based semisupervised learning for sentiment categorization. In GraphBased Method for NLP, pages 45–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xia Hu</author>
<author>Lei Tang</author>
<author>Jiliang Tang</author>
<author>Huan Liu</author>
</authors>
<title>Exploiting social relations for sentiment analysis in microblogging.</title>
<date>2013</date>
<booktitle>In WSDM,</booktitle>
<pages>537--546</pages>
<contexts>
<context position="28958" citStr="Hu et al. (2013)" startWordPosition="4630" endWordPosition="4633">tion task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural networ</context>
</contexts>
<marker>Hu, Tang, Tang, Liu, 2013</marker>
<rawString>Xia Hu, Lei Tang, Jiliang Tang, and Huan Liu. 2013. Exploiting social relations for sentiment analysis in microblogging. In WSDM, pages 537–546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rie Johnson</author>
<author>Tong Zhang</author>
</authors>
<title>Effective use of word order for text categorization with convolutional neural networks. arXiv preprint:</title>
<date>2014</date>
<pages>1412--1058</pages>
<contexts>
<context position="30498" citStr="Johnson and Zhang, 2014" startWordPosition="4868" endWordPosition="4871"> sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This work is an extension of our previous work (Tang et al., 2015), which only takes consideration of userword association. 6 Conclusion In this paper, we introduce User Product Neural Network (UPNN) for d</context>
</contexts>
<marker>Johnson, Zhang, 2014</marker>
<rawString>Rie Johnson and Tong Zhang. 2014. Effective use of word order for text categorization with convolutional neural networks. arXiv preprint: 1412.1058.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech &amp; language processing.</title>
<date>2000</date>
<publisher>Pearson Education</publisher>
<contexts>
<context position="19828" citStr="Jurafsky and Martin, 2000" startWordPosition="3153" endWordPosition="3156">s 1-10. The rating scale of Yelp 2014 and Yelp 2013 datasets is 1-5. |V |is the vocabulary size of words in each dataset. #users is the number of users, #docs/user means the average number of documents per user posts in the corpus. et al., 2014) and Yelp Dataset Challenge4 in 2013 and 2014. Statistical information of the generated datasets are given in Table 1. We split each corpus into training, development and testing sets with a 80/10/10 split, and conduct tokenization and sentence splitting with Stanford CoreNLP (Manning et al., 2014). We use standard accuracy (Manning and Sch¨utze, 1999; Jurafsky and Martin, 2000) to measure the overall sentiment classification performance, and use MAE and RM5E to measure the divergences between predicted sentiment ratings (pr) and ground truth ratings (gd). MAE = Ei |gdi − pri |(3) N RM5E = l �i(gdi − pri)2 (4) V N 4.2 Baseline Methods We compare UPNN with the following baseline methods for document-level sentiment classification. (1) Majority is a heuristic baseline method, which assigns the majority sentiment category in training set to each review in the test dataset. (2) In Trigram, we use unigrams, bigrams and trigrams as features and train classifier with suppor</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Dan Jurafsky and James H Martin. 2000. Speech &amp; language processing. Pearson Education India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural network for modelling sentences. In</title>
<date>2014</date>
<booktitle>ACL,</booktitle>
<pages>655--665</pages>
<contexts>
<context position="2145" citStr="Kalchbrenner et al., 2014" startWordPosition="321" endWordPosition="324">gard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review. In this case, user preference affects the sentiment rating of a review. Product quality also has an impact on review sentiment rating. Reviews towards high-quality products (e.g. Macbook)</context>
<context position="12726" citStr="Kalchbrenner et al., 2014" startWordPosition="2016" endWordPosition="2019">ion, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capable of capturing local semantics of n-grams of various granularities, which are proven powerful for sentiment classification. The convolutional filter with a width of 3 essentially captures the semantics of trigrams in a sentence. Accordingly, multiple convolutional filters with widths of 1, 2 and 3 encode the semantics of unigrams, bigrams and trigrams in a sentence. An illustration of CNN with t</context>
<context position="30461" citStr="Kalchbrenner et al., 2014" startWordPosition="4862" endWordPosition="4865">Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This work is an extension of our previous work (Tang et al., 2015), which only takes consideration of userword association. 6 Conclusion In this paper, we introduce Use</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. In ACL, pages 655–665.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification. In</title>
<date>2014</date>
<booktitle>EMNLP,</booktitle>
<pages>1746--1751</pages>
<contexts>
<context position="12698" citStr="Kim, 2014" startWordPosition="2014" endWordPosition="2015">m distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capable of capturing local semantics of n-grams of various granularities, which are proven powerful for sentiment classification. The convolutional filter with a width of 3 essentially captures the semantics of trigrams in a sentence. Accordingly, multiple convolutional filters with widths of 1, 2 and 3 encode the semantics of unigrams, bigrams and trigrams in a sentence. A</context>
<context position="30472" citStr="Kim, 2014" startWordPosition="4866" endWordPosition="4867">incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This work is an extension of our previous work (Tang et al., 2015), which only takes consideration of userword association. 6 Conclusion In this paper, we introduce User Product N</context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In EMNLP, pages 1746– 1751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
<author>Saif M Mohammad</author>
</authors>
<title>Sentiment analysis of short informal texts.</title>
<date>2014</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>723--762</pages>
<contexts>
<context position="2030" citStr="Kiritchenko et al., 2014" startWordPosition="304" endWordPosition="307">y (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review. In this case, user preference affects the sentiment rating of a review. </context>
<context position="20647" citStr="Kiritchenko et al., 2014" startWordPosition="3282" endWordPosition="3285">i − pri |(3) N RM5E = l �i(gdi − pri)2 (4) V N 4.2 Baseline Methods We compare UPNN with the following baseline methods for document-level sentiment classification. (1) Majority is a heuristic baseline method, which assigns the majority sentiment category in training set to each review in the test dataset. (2) In Trigram, we use unigrams, bigrams and trigrams as features and train classifier with supported vector machine (SVM) (Fan et al., 2008). (3) In TextFeature, we implement hand-crafted text features including word/character ngrams, sentiment lexicon features, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation.</context>
<context position="28687" citStr="Kiritchenko et al., 2014" startWordPosition="4586" endWordPosition="4589">no UP), but still worse than the full model. 5 Related Work 5.1 Sentiment Classification Sentiment classification is a fundamental problem in sentiment analysis, which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged f</context>
</contexts>
<marker>Kiritchenko, Zhu, Mohammad, 2014</marker>
<rawString>Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mohammad. 2014. Sentiment analysis of short informal texts. Journal of Artificial Intelligence Research, pages 723–762.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Labutov</author>
<author>Hod Lipson</author>
</authors>
<title>Re-embedding words.</title>
<date>2013</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29794" citStr="Labutov and Lipson, 2013" startWordPosition="4758" endWordPosition="4761">n that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP t</context>
</contexts>
<marker>Labutov, Lipson, 2013</marker>
<rawString>Igor Labutov and Hod Lipson. 2013. Re-embedding words. In Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quoc V Le and Tomas Mikolov</author>
</authors>
<title>Distributed representations of sentences and documents.</title>
<date>2014</date>
<booktitle>In ICML,</booktitle>
<pages>1188--1196</pages>
<contexts>
<context position="2168" citStr="Mikolov, 2014" startWordPosition="327" endWordPosition="328"> classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review. In this case, user preference affects the sentiment rating of a review. Product quality also has an impact on review sentiment rating. Reviews towards high-quality products (e.g. Macbook) tend to receive higher</context>
<context position="4352" citStr="Mikolov, 2014" startWordPosition="665" endWordPosition="666">tion for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1014–1023, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge. We compare to several neural network models including recursive neural networks (Socher et al., 2013), paragraph vector (Le and Mikolov, 2014), sentimentspecific word embedding (Tang et al., 2014b), and a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014). Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy. The main contributions of this work are as follows: • We present a new neural network method (UPNN) by leveraging users and products for document-level sentiment classification. • We validate the influences of users and products in terms of sentiment </context>
<context position="21540" citStr="Mikolov, 2014" startWordPosition="3416" endWordPosition="3417">ov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) because its codes are not officially provided. The window size is tuned on development set. (9) We compare with a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014), which leverages user and aspects of a review with collaborative filtering and topic modeling. 4.3 Model Comparisons Experimental results are given in Table 2. The results are separated into two groups: the methods above only use texts of review, and the methods below also use user and product information. From the first group, we can see that majority performs very poor because it does not capture any text or use</context>
<context position="30555" citStr="Mikolov (2014)" startWordPosition="4879" endWordPosition="4880">l. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This work is an extension of our previous work (Tang et al., 2015), which only takes consideration of userword association. 6 Conclusion In this paper, we introduce User Product Neural Network (UPNN) for document level sentiment classification under a supervised</context>
</contexts>
<marker>Mikolov, 2014</marker>
<rawString>Quoc V. Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In ICML, pages 1188–1196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Sheng Wang</author>
<author>Shenghua Liu</author>
<author>Ming Zhang</author>
</authors>
<title>Suit: A supervised user-item based topic model for sentiment analysis.</title>
<date>2014</date>
<booktitle>In AAAI,</booktitle>
<pages>1636--1642</pages>
<contexts>
<context position="28839" citStr="Li et al. (2014)" startWordPosition="4611" endWordPosition="4614"> which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentim</context>
</contexts>
<marker>Li, Wang, Liu, Zhang, 2014</marker>
<rawString>Fangtao Li, Sheng Wang, Shenghua Liu, and Ming Zhang. 2014. Suit: A supervised user-item based topic model for sentiment analysis. In AAAI, pages 1636–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Dan Jurafsky</author>
<author>Eudard Hovy</author>
</authors>
<title>When are tree structures necessary for deep learning of representations? arXiv preprint:1503.00185.</title>
<date>2015</date>
<contexts>
<context position="30297" citStr="Li et al. (2015)" startWordPosition="4837" endWordPosition="4840">t al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This</context>
</contexts>
<marker>Li, Jurafsky, Hovy, 2015</marker>
<rawString>Jiwei Li, Dan Jurafsky, and Eudard Hovy. 2015. When are tree structures necessary for deep learning of representations? arXiv preprint:1503.00185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
</authors>
<title>Feature weight tuning for recursive neural networks.</title>
<date>2014</date>
<tech>Arxiv preprint,</tech>
<pages>1412--3714</pages>
<contexts>
<context position="30215" citStr="Li, 2014" startWordPosition="4824" endWordPosition="4825">mbedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and</context>
</contexts>
<marker>Li, 2014</marker>
<rawString>Jiwei Li. 2014. Feature weight tuning for recursive neural networks. Arxiv preprint, 1412.3714.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1348" citStr="Liu, 2012" startWordPosition="201" endWordPosition="202">models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, product- and documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1. 1 Introduction Document-level sentiment classification is a fundamental problem in the field of sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2012). The task is to infer the sentiment polarity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Maas</author>
<author>Raymond E Daly</author>
<author>Peter T Pham</author>
<author>Dan Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Learning word vectors for sentiment analysis.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>142--150</pages>
<contexts>
<context position="29768" citStr="Maas et al., 2011" startWordPosition="4754" endWordPosition="4757"> Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent ne</context>
</contexts>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In ACL, pages 142–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of statistical natural language processing.</title>
<date>1999</date>
<publisher>MIT press.</publisher>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D Manning and Hinrich Sch¨utze. 1999. Foundations of statistical natural language processing. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven Bethard</author>
<author>David McClosky</author>
</authors>
<title>The stanford corenlp natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In ACL,</booktitle>
<pages>55--60</pages>
<contexts>
<context position="19746" citStr="Manning et al., 2014" startWordPosition="3141" endWordPosition="3144">atasets used for sentiment classification. The rating scale of IMDB dataset is 1-10. The rating scale of Yelp 2014 and Yelp 2013 datasets is 1-5. |V |is the vocabulary size of words in each dataset. #users is the number of users, #docs/user means the average number of documents per user posts in the corpus. et al., 2014) and Yelp Dataset Challenge4 in 2013 and 2014. Statistical information of the generated datasets are given in Table 1. We split each corpus into training, development and testing sets with a 80/10/10 split, and conduct tokenization and sentence splitting with Stanford CoreNLP (Manning et al., 2014). We use standard accuracy (Manning and Sch¨utze, 1999; Jurafsky and Martin, 2000) to measure the overall sentiment classification performance, and use MAE and RM5E to measure the divergences between predicted sentiment ratings (pr) and ground truth ratings (gd). MAE = Ei |gdi − pri |(3) N RM5E = l �i(gdi − pri)2 (4) V N 4.2 Baseline Methods We compare UPNN with the following baseline methods for document-level sentiment classification. (1) Majority is a heuristic baseline method, which assigns the majority sentiment category in training set to each review in the test dataset. (2) In Trigram, </context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit. In ACL, pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In NIPS,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="12302" citStr="Mikolov et al., 2013" startWordPosition="1949" endWordPosition="1952">ontinuous matrix representations of user k and product j for capturing user-text and product-text consistencies. ous and real-valued vector, also known as word embedding (Bengio et al., 2003). All the word vectors are stacked in a word embedding matrix Lw E Rdx�V �, where d is the dimension of word vector and |V |is the size of word vocabulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reas</context>
<context position="20942" citStr="Mikolov et al., 2013" startWordPosition="3329" endWordPosition="3332">dataset. (2) In Trigram, we use unigrams, bigrams and trigrams as features and train classifier with supported vector machine (SVM) (Fan et al., 2008). (3) In TextFeature, we implement hand-crafted text features including word/character ngrams, sentiment lexicon features, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) b</context>
<context position="29692" citStr="Mikolov et al., 2013" startWordPosition="4740" endWordPosition="4743">nd-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="15747" citStr="Mitchell and Lapata, 2010" startWordPosition="2518" endWordPosition="2522">ctor pj E Rdp, where du and dp are dimensions of user vector and product vector, respectively. The basic idea behind this is to map users with similar rating preferences (e.g. prefer assigning 4 stars) into close vectors in user embedding space. Similarly, the products which receive similar averaged ratings are mapped into neighboring vectors in product embedding space. In order to model user-text consistency, we represent each user as a continuous matrix Uk E RdU ×d, which acts as an operator to modify the semantic meaning of a word. This is on the basis of vector based semantic composition (Mitchell and Lapata, 2010). They regard compositional modifier as a matrix X1 to modify another component x2, and use matrix-vector multiplication y = X1 x x2 as the composition function. Multiplicative semantic composition is suitable for our need of user modifying word meaning, and it has been successfully utilized to model adjectivenoun composition (Clark et al., 2008; Baroni and Zamparelli, 2010) and adverb-adjective composition (Socher et al., 2012). Similarly, we model product-text consistency by encoding each product as a matrix Pj E RdP ×d, where d is the dimension of word vector, dP is the output length of pro</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="16755" citStr="Pang and Lee, 2005" startWordPosition="2674" endWordPosition="2677">adjective composition (Socher et al., 2012). Similarly, we model product-text consistency by encoding each product as a matrix Pj E RdP ×d, where d is the dimension of word vector, dP is the output length of product-word multiplicative composition. After conducting user-word multiplication and productword multiplication operations, we concatenate their outputs and feed them to CNN (detailed in Section 3.1) for producing user and product enhanced document representation. 3.3 Sentiment Classification We apply UPNN to document level sentiment classification under a supervised learning framework (Pang and Lee, 2005). Instead of using handcrafted features, we use continuous representation of documents, users and products as discriminative features. The sentiment classifier is built from documents with gold standard sentiment labels. As is shown in Figure 2, the feature representation for building rating predictor is the concatenation of three parts: continuous user representation uk, continuous product representation pj and continuous document representation vd, where vd encodes user-text consistency, product-text consistency and document level semantic composition. We use softmax to build the classifier </context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In ACL, pages 115– 124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1336" citStr="Pang and Lee, 2008" startWordPosition="197" endWordPosition="200"> using vector space models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, product- and documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1. 1 Introduction Document-level sentiment classification is a fundamental problem in the field of sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2012). The task is to infer the sentiment polarity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In EMNLP,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="1506" citStr="Pang et al. (2002" startWordPosition="228" endWordPosition="231">al evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, product- and documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1. 1 Introduction Document-level sentiment classification is a fundamental problem in the field of sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2012). The task is to infer the sentiment polarity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In EMNLP, pages 79– 86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Romain Paulus</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Global belief recursive neural networks.</title>
<date>2014</date>
<booktitle>In NIPS,</booktitle>
<pages>2888--2896</pages>
<contexts>
<context position="30181" citStr="Paulus et al., 2014" startWordPosition="4817" endWordPosition="4820">ethods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of us</context>
</contexts>
<marker>Paulus, Socher, Manning, 2014</marker>
<rawString>Romain Paulus, Richard Socher, and Christopher D Manning. 2014. Global belief recursive neural networks. In NIPS, pages 2888–2896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Glove: Global vectors for word representation. In</title>
<date>2014</date>
<booktitle>EMNLP,</booktitle>
<pages>1532--1543</pages>
<contexts>
<context position="12327" citStr="Pennington et al., 2014" startWordPosition="1953" endWordPosition="1956">sentations of user k and product j for capturing user-text and product-text consistencies. ous and real-valued vector, also known as word embedding (Bengio et al., 2003). All the word vectors are stacked in a word embedding matrix Lw E Rdx�V �, where d is the dimension of word vector and |V |is the size of word vocabulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capab</context>
<context position="29718" citStr="Pennington et al., 2014" startWordPosition="4744" endWordPosition="4747">e learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiv</context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In EMNLP, pages 1532–1543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Perozzi</author>
<author>Rami Al-Rfou</author>
<author>Steven Skiena</author>
</authors>
<title>Deepwalk: Online learning of social representations.</title>
<date>2014</date>
<booktitle>In SIGKDD,</booktitle>
<pages>701--710</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="29408" citStr="Perozzi et al., 2014" startWordPosition="4701" endWordPosition="4704"> features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) i</context>
</contexts>
<marker>Perozzi, Al-Rfou, Skiena, 2014</marker>
<rawString>Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In SIGKDD, pages 701–710. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lizhen Qu</author>
<author>Georgiana Ifrim</author>
<author>Gerhard Weikum</author>
</authors>
<title>The bag-of-opinions method for review rating prediction from sparse text patterns.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>913--921</pages>
<contexts>
<context position="2003" citStr="Qu et al., 2010" startWordPosition="300" endWordPosition="303">arity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document. Dominating studies follow Pang et al. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review. In this case, user preference affects the sen</context>
<context position="28629" citStr="Qu et al., 2010" startWordPosition="4578" endWordPosition="4581">wo strategies perform slightly better than UPNN (no UP), but still worse than the full model. 5 Related Work 5.1 Sentiment Classification Sentiment classification is a fundamental problem in sentiment analysis, which targets at inferring the sentiment label of a document. Pang and Lee (2002; 2005) cast this problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural</context>
</contexts>
<marker>Qu, Ifrim, Weikum, 2010</marker>
<rawString>Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum. 2010. The bag-of-opinions method for review rating prediction from sparse text patterns. In COLING, pages 913–921.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic Compositionality Through Recursive Matrix-Vector Spaces. In</title>
<date>2012</date>
<booktitle>EMNLP,</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="16179" citStr="Socher et al., 2012" startWordPosition="2587" endWordPosition="2590">s a continuous matrix Uk E RdU ×d, which acts as an operator to modify the semantic meaning of a word. This is on the basis of vector based semantic composition (Mitchell and Lapata, 2010). They regard compositional modifier as a matrix X1 to modify another component x2, and use matrix-vector multiplication y = X1 x x2 as the composition function. Multiplicative semantic composition is suitable for our need of user modifying word meaning, and it has been successfully utilized to model adjectivenoun composition (Clark et al., 2008; Baroni and Zamparelli, 2010) and adverb-adjective composition (Socher et al., 2012). Similarly, we model product-text consistency by encoding each product as a matrix Pj E RdP ×d, where d is the dimension of word vector, dP is the output length of product-word multiplicative composition. After conducting user-word multiplication and productword multiplication operations, we concatenate their outputs and feed them to CNN (detailed in Section 3.1) for producing user and product enhanced document representation. 3.3 Sentiment Classification We apply UPNN to document level sentiment classification under a supervised learning framework (Pang and Lee, 2005). Instead of using handc</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic Compositionality Through Recursive Matrix-Vector Spaces. In EMNLP, pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank. In</title>
<date>2013</date>
<booktitle>EMNLP,</booktitle>
<pages>1631--1642</pages>
<contexts>
<context position="2118" citStr="Socher et al., 2013" startWordPosition="317" endWordPosition="320">. (2002; 2005) and regard this problem as a multi-class classification task. They usually ∗Corresponding author. 1The codes and datasets are available at http://ir. hit.edu.cn/˜dytang/ use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels. Since the performance of a machine learner is heavily dependent on the choice of data representations (Domingos, 2012), many works focus on designing effective features (Pang et al., 2002; Qu et al., 2010; Kiritchenko et al., 2014) or learning discriminative features from data with neural networks (Socher et al., 2013; Kalchbrenner et al., 2014; Le and Mikolov, 2014). Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products. Let us take reviews with respect to 1-5 rating scales as an example. A critical user might write a review “it works great” and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review. In this case, user preference affects the sentiment rating of a review. Product quality also has an impact on review sentiment rating. Reviews towards high-qual</context>
<context position="4311" citStr="Socher et al., 2013" startWordPosition="656" endWordPosition="659">dings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1014–1023, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge. We compare to several neural network models including recursive neural networks (Socher et al., 2013), paragraph vector (Le and Mikolov, 2014), sentimentspecific word embedding (Tang et al., 2014b), and a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014). Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy. The main contributions of this work are as follows: • We present a new neural network method (UPNN) by leveraging users and products for document-level sentiment classification. • We validate the influences of </context>
<context position="12642" citStr="Socher et al., 2013" startWordPosition="2002" endWordPosition="2005">ulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capable of capturing local semantics of n-grams of various granularities, which are proven powerful for sentiment classification. The convolutional filter with a width of 3 essentially captures the semantics of trigrams in a sentence. Accordingly, multiple convolutional filters with widths of 1, 2 and 3 encode the sema</context>
<context position="18456" citStr="Socher et al., 2013" startWordPosition="2931" endWordPosition="2934">; Uk; Pj; Wsoftmax, bsoftmax], and update parameters with stochastic gradient descent. We set the widths of three convolutional filters as 1, 2 and 3. We learn 200-dimensional sentiment-specific word embeddings (Tang et al., 2014b) on each dataset separately, randomly initialize other parameters from a uniform distribution U(−0.01,0.01), and set learning rate as 0.03. 4 Experiment We conduct experiments to evaluate UPNN by applying it to sentiment classification of documents. 4.1 Experimental Setting Existing benchmark datasets for sentiment classification such as Stanford Sentiment Treebank (Socher et al., 2013) typically only have text information, but do not contain users who express the sentiment or products which are evaluated. Therefore, we build the datasets by ourselves. In order to obtain large scale corpora without manual annotation, we derive three datasets from IMDB (Diao Lookup Folding Pooling Tanh Convolution filter1 filter2 filter3 W1 W2 W3 W4 Wn−1 Wn 1018 Dataset #users #products #reviews #docs/user #docs/product #sents/doc #words/doc IMDB 1,310 1,635 84,919 64.82 51.94 16.08 394.6 Yelp 2014 4,818 4,194 231,163 47.97 55.11 11.41 196.9 Yelp 2013 1,631 1,633 78,966 48.42 48.36 10.89 189.</context>
<context position="21305" citStr="Socher et al., 2013" startWordPosition="3379" endWordPosition="3382">s (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) because its codes are not officially provided. The window size is tuned on development set. (9) We compare with a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014), which leverages user and aspects of a review with collaborative filtering and topic modeling. 4.3 Model Comparisons Experimental results are given in Table 2. The results are separa</context>
<context position="30006" citStr="Socher et al. (2013)" startWordPosition="4791" endWordPosition="4794">(Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yel</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP, pages 1631–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Song</author>
<author>Hongning Wang</author>
<author>Xiaodong He</author>
</authors>
<title>Adapting deep ranknet for personalized search. In</title>
<date>2014</date>
<booktitle>WSDM,</booktitle>
<pages>83--92</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="29358" citStr="Song et al., 2014" startWordPosition="4693" endWordPosition="4696">ication. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use sta</context>
</contexts>
<marker>Song, Wang, He, 2014</marker>
<rawString>Yang Song, Hongning Wang, and Xiaodong He. 2014. Adapting deep ranknet for personalized search. In WSDM, pages 83–92. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhao Tan</author>
<author>Lillian Lee</author>
<author>Jie Tang</author>
<author>Long Jiang</author>
<author>Ming Zhou</author>
<author>Ping Li</author>
</authors>
<title>User-level sentiment analysis incorporating social networks.</title>
<date>2011</date>
<booktitle>In SIGKDD,</booktitle>
<pages>1397--1405</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="28937" citStr="Tan et al. (2011)" startWordPosition="4625" endWordPosition="4628">s problem a classification task, and use machine learning method in a supervised learning framework. Goldberg and Zhu (2006) use unlabelled reviews in a graphbased semi-supervised learning method. Many studies design effective features, such as text topic (Ganu et al., 2009), bag-of-opinion (Qu et al., 2010) and sentiment lexicon features (Kiritchenko et al., 2014). User information is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. E</context>
</contexts>
<marker>Tan, Lee, Tang, Jiang, Zhou, Li, 2011</marker>
<rawString>Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming Zhou, and Ping Li. 2011. User-level sentiment analysis incorporating social networks. In SIGKDD, pages 1397–1405. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Bing Qin</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
</authors>
<title>Building large-scale twitter-specific sentiment lexicon: A representation learning approach.</title>
<date>2014</date>
<booktitle>In COLING,</booktitle>
<pages>172--182</pages>
<contexts>
<context position="4405" citStr="Tang et al., 2014" startWordPosition="671" endWordPosition="674">ernational Joint Conference on Natural Language Processing, pages 1014–1023, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge. We compare to several neural network models including recursive neural networks (Socher et al., 2013), paragraph vector (Le and Mikolov, 2014), sentimentspecific word embedding (Tang et al., 2014b), and a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014). Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy. The main contributions of this work are as follows: • We present a new neural network method (UPNN) by leveraging users and products for document-level sentiment classification. • We validate the influences of users and products in terms of sentiment and text on massive IMDB and Yelp reviews. • We repor</context>
<context position="12346" citStr="Tang et al., 2014" startWordPosition="1957" endWordPosition="1960">product j for capturing user-text and product-text consistencies. ous and real-valued vector, also known as word embedding (Bengio et al., 2003). All the word vectors are stacked in a word embedding matrix Lw E Rdx�V �, where d is the dimension of word vector and |V |is the size of word vocabulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capable of capturing loc</context>
<context position="18065" citStr="Tang et al., 2014" startWordPosition="2875" endWordPosition="2878"> given in Equation 2, where C is the category number (e.g. 5 or 10). sof tmaxi = exp(xi)C (2) �if=1 exp(xi�) We regard cross-entropy error between gold sentiment distribution and predicted sentiment distribution as the loss function of softmax. We take the derivative of loss function through back-propagation with respect to the whole set of parameters θ = [W 1,2,3 cf ; b1,2,3 cf ;uk;pj; Uk; Pj; Wsoftmax, bsoftmax], and update parameters with stochastic gradient descent. We set the widths of three convolutional filters as 1, 2 and 3. We learn 200-dimensional sentiment-specific word embeddings (Tang et al., 2014b) on each dataset separately, randomly initialize other parameters from a uniform distribution U(−0.01,0.01), and set learning rate as 0.03. 4 Experiment We conduct experiments to evaluate UPNN by applying it to sentiment classification of documents. 4.1 Experimental Setting Existing benchmark datasets for sentiment classification such as Stanford Sentiment Treebank (Socher et al., 2013) typically only have text information, but do not contain users who express the sentiment or products which are evaluated. Therefore, we build the datasets by ourselves. In order to obtain large scale corpora </context>
<context position="21208" citStr="Tang et al., 2014" startWordPosition="3365" endWordPosition="3368">s, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) because its codes are not officially provided. The window size is tuned on development set. (9) We compare with a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014), which leverages user and aspects of a review with collaborative filtering and topic </context>
<context position="29813" citStr="Tang et al., 2014" startWordPosition="4762" endWordPosition="4765">s of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sent</context>
</contexts>
<marker>Tang, Wei, Qin, Zhou, Liu, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting Liu. 2014a. Building large-scale twitter-specific sentiment lexicon: A representation learning approach. In COLING, pages 172–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Nan Yang</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
<author>Bing Qin</author>
</authors>
<title>Learning sentimentspecific word embedding for twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In ACL,</booktitle>
<pages>1555--1565</pages>
<contexts>
<context position="4405" citStr="Tang et al., 2014" startWordPosition="671" endWordPosition="674">ernational Joint Conference on Natural Language Processing, pages 1014–1023, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics as user preferences and product qualities. These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification. We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge. We compare to several neural network models including recursive neural networks (Socher et al., 2013), paragraph vector (Le and Mikolov, 2014), sentimentspecific word embedding (Tang et al., 2014b), and a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014). Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy. The main contributions of this work are as follows: • We present a new neural network method (UPNN) by leveraging users and products for document-level sentiment classification. • We validate the influences of users and products in terms of sentiment and text on massive IMDB and Yelp reviews. • We repor</context>
<context position="12346" citStr="Tang et al., 2014" startWordPosition="1957" endWordPosition="1960">product j for capturing user-text and product-text consistencies. ous and real-valued vector, also known as word embedding (Bengio et al., 2003). All the word vectors are stacked in a word embedding matrix Lw E Rdx�V �, where d is the dimension of word vector and |V |is the size of word vocabulary. These word vectors can be randomly initialized from a uniform distribution, regarded as a parameter and jointly trained with other parameters of neural networks. Alternatively, they can be pretrained from text corpus with embedding learning algorithms (Mikolov et al., 2013; Pennington et al., 2014; Tang et al., 2014b), and applied as initial values of word embedding matrix. We adopt the latter strategy which better exploits the semantic and grammatical associations of words. To model semantic representations of sentences, convolutional neural network (CNN) and recursive neural network (Socher et al., 2013) are two state-of-the-art methods. We use CNN (Kim, 2014; Kalchbrenner et al., 2014) in this work as it does not rely on external parse tree. Specifically, we use multiple convolutional filters with different widths to produce sentence representation. The reason is that they are capable of capturing loc</context>
<context position="18065" citStr="Tang et al., 2014" startWordPosition="2875" endWordPosition="2878"> given in Equation 2, where C is the category number (e.g. 5 or 10). sof tmaxi = exp(xi)C (2) �if=1 exp(xi�) We regard cross-entropy error between gold sentiment distribution and predicted sentiment distribution as the loss function of softmax. We take the derivative of loss function through back-propagation with respect to the whole set of parameters θ = [W 1,2,3 cf ; b1,2,3 cf ;uk;pj; Uk; Pj; Wsoftmax, bsoftmax], and update parameters with stochastic gradient descent. We set the widths of three convolutional filters as 1, 2 and 3. We learn 200-dimensional sentiment-specific word embeddings (Tang et al., 2014b) on each dataset separately, randomly initialize other parameters from a uniform distribution U(−0.01,0.01), and set learning rate as 0.03. 4 Experiment We conduct experiments to evaluate UPNN by applying it to sentiment classification of documents. 4.1 Experimental Setting Existing benchmark datasets for sentiment classification such as Stanford Sentiment Treebank (Socher et al., 2013) typically only have text information, but do not contain users who express the sentiment or products which are evaluated. Therefore, we build the datasets by ourselves. In order to obtain large scale corpora </context>
<context position="21208" citStr="Tang et al., 2014" startWordPosition="3365" endWordPosition="3368">s, negation features, etc al. (Kiritchenko et al., 2014). (4) We extract user-leniency features (Gao et al., 2013) and corresponding product features (denoted as UPF) from training data, and concatenate them with the features in baseline (2) and (3). (5) We learn word embeddings from training and development sets with word2vec (Mikolov et al., 2013), average word embeddings to get document representation, and train a SVM classifier. 4http://www.yelp.com/dataset_challenge (6) We learn sentiment-specific word embeddings (SSWE) from training and development sets, and use max/min/average pooling (Tang et al., 2014b) to generate document representation. (7) We represent sentence with RNTN (Socher et al., 2013) and compose document representation with recurrent neural network. We average hidden vectors of recurrent neural network as the features for sentiment classification. (8) We re-implement PVDM in Paragraph Vector (Le and Mikolov, 2014) because its codes are not officially provided. The window size is tuned on development set. (9) We compare with a state-of-the-art recommendation algorithm JMARS (Diao et al., 2014), which leverages user and aspects of a review with collaborative filtering and topic </context>
<context position="29813" citStr="Tang et al., 2014" startWordPosition="4762" endWordPosition="4765">s of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sent</context>
</contexts>
<marker>Tang, Wei, Yang, Zhou, Liu, Qin, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014b. Learning sentimentspecific word embedding for twitter sentiment classification. In ACL, pages 1555–1565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
<author>Yuekui Yang</author>
</authors>
<title>User modeling with neural network for review rating prediction.</title>
<date>2015</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="30959" citStr="Tang et al., 2015" startWordPosition="4945" endWordPosition="4948">al network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment classification. This work is an extension of our previous work (Tang et al., 2015), which only takes consideration of userword association. 6 Conclusion In this paper, we introduce User Product Neural Network (UPNN) for document level sentiment classification under a supervised learning framework. We validate user-sentiment, productsentiment, user-text and product-text consistencies on massive reviews, and effectively integrate them in UPNN. We apply the model to three datasets derived from IMDB and Yelp Dataset Challenge. Empirical results show that: (1) UPNN outperforms state-of-the-art methods for document level sentiment classification; (2) incorporating continuous user</context>
</contexts>
<marker>Tang, Qin, Liu, Yang, 2015</marker>
<rawString>Duyu Tang, Bing Qin, Ting Liu, and Yuekui Yang. 2015. User modeling with neural network for review rating prediction. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Ron J Weiss</author>
<author>Hector Yee</author>
</authors>
<title>Nonlinear latent factorization by embedding multiple user interests. In RecSys,</title>
<date>2013</date>
<pages>65--68</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="29326" citStr="Weston et al., 2013" startWordPosition="4687" endWordPosition="4690">is also used for sentiment classification. Gao et al. (2013) design user-specific features to capture user leniency. Li et al. (2014) incorporate textual topic and user-word factors with supervised topic modeling. Tan et al. (2011) and Hu et al. (2013) utilize usertext and user-user relations for Twitter sentiment analysis. Unlike most previous studies that use hand-crafted features, we learn discriminative features from data. We differ from Li et al. (2014) in that we encode four kinds of consistencies and use neural network approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic compositi</context>
</contexts>
<marker>Weston, Weiss, Yee, 2013</marker>
<rawString>Jason Weston, Ron J Weiss, and Hector Yee. 2013. Nonlinear latent factorization by embedding multiple user interests. In RecSys, pages 65–68. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liheng Xu</author>
<author>Kang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Joint opinion relation detection using one-class deep neural network. In</title>
<date>2014</date>
<booktitle>COLING,</booktitle>
<pages>677--687</pages>
<contexts>
<context position="30279" citStr="Xu et al., 2014" startWordPosition="4833" endWordPosition="4836">ddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al., 2014; Kim, 2014; Johnson and Zhang, 2014) use convolutional neural networks. Le and Mikolov (2014) introduce 0.65 0.6 0.55 0.5 0.45 0.4 0.35 IMDB Yelp 2014 Yelp 2013 no UP avg UP unk UP full UP 1021 Paragraph Vector. Unlike existing neural network approaches that only use the semantics of texts, we take consideration of user and product representations and leverage their connections with text semantics for sentiment cl</context>
</contexts>
<marker>Xu, Liu, Zhao, 2014</marker>
<rawString>Liheng Xu, Kang Liu, and Jun Zhao. 2014. Joint opinion relation detection using one-class deep neural network. In COLING, pages 677–687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinjie Zhou</author>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Representation learning for aspect category detection in online reviews.</title>
<date>2015</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="29854" citStr="Zhou et al., 2015" startWordPosition="4770" endWordPosition="4773">k approach. User representation is also leveraged for recommendation (Weston et al., 2013), web search (Song et al., 2014) and social media analytics (Perozzi et al., 2014). 5.2 Neural Network for Sentiment Classification Neural networks have achieved promising results for sentiment classification. Existing neural network methods can be divided into two groups: word embedding and semantic composition. For learning word embeddings, (Mikolov et al., 2013; Pennington et al., 2014) use local and global contexts, (Maas et al., 2011; Labutov and Lipson, 2013; Tang et al., 2014b; Tang et al., 2014a; Zhou et al., 2015) further incorporate sentiment of texts. For learning semantic composition, Glorot et al. (2011) use stacked denoising autoencoder, Socher et al. (2013) introduce a family of recursive deep neural networks (RNN). RNN is extended with adaptive composition functions (Dong et al., 2014), global feedbackward (Paulus et al., 2014), feature weight tuning (Li, 2014), and also used for opinion relation detection (Xu et al., 2014). Li et al. (2015) compare the effectiveness of recursive neural network and recurrent neural network on five NLP tasks including sentiment classification. (Kalchbrenner et al</context>
</contexts>
<marker>Zhou, Wan, Xiao, 2015</marker>
<rawString>Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2015. Representation learning for aspect category detection in online reviews. In AAAI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>