<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.991428">
Measuring the Productivity of Determinerless PPs
</title>
<author confidence="0.985319">
Florian D¨omges, Tibor Kiss, Antje M¨uller, Claudia Roch
</author>
<affiliation confidence="0.59043">
Sprachwissenschaftliches Institut
Ruhr-Universit¨at Bochum
</affiliation>
<email confidence="0.9531345">
florian.doemges@rub.de
tibor@linguistics.rub.de
antje.mueller@rub.de
claudia.roch@rub.de
</email>
<sectionHeader confidence="0.998458" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999975473684211">
We determine the productivity of determin-
erless PPs in German quantitatively, restrict-
ing ourselves to the preposition unter. The
study is based on two German newspa-
per corpora, comprising some 210 million
words. The problematic construction, i.e.
unter followed by a determinerless singular
noun occurs some 16.000 times in the cor-
pus. To clarify the empirical productivity
of the construction, we apply a productivity
measure developed by Baayen (2001) to the
syntactic domain by making use of statisti-
cal models suggested in Evert (2004). We
compare two different models and suggest a
gradient descent search for parameter esti-
mation. Our results show that the combina-
tion of unter+noun must in fact be character-
ized as productive, and hence that a syntactic
treatment is required.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999114604651163">
The combination of a preposition with a singular
count noun, illustrated in (1) with the preposition
unter, is a frequent construction in written and spo-
ken German. From a theoretical perspective, con-
structions like (1) are interesting since they seem
to violate the near universal rule that determiners
should accompany singular count nouns if the lan-
guage in question shows determiners at all (cf. Him-
melmann (1998)).
unter Vorbehalt (with reservation),
unter Androhung (on pain),
unter Lizenz (under licence),
unter Vorwand (pretending)
Baldwin et al. (2006) follow a tradition of En-
glish grammar and call constructions like (1) deter-
minerless PPs (D-PP), defined as PPs whose NP-
complement consists of a singular count noun with-
out an accompanying determiner (as e.g. English
by bus, in mind). It has been claimed that D-PPs
are mostly idiomatic and not productive. Hence,
computational grammars often include D-PPs only
as stock phrases or listed multiword expressions and
do not offer a grammatical treatment. However, both
claims have to be doubted seriously. Kiss (2006,
2007) shows that the class of D-PPs does not con-
tain more idiomatic phrases than a typical phrasal
category should and also argues against a ‘light P
hypothesis’ which allows a pseudo-compositional
treatment of D-PPs by ignoring the semantics of the
preposition altogether. Trawinski (2003), Baldwin
et al. (2006), as well as Trawinski et al. (2006) offer
grammatical treatments of D-PPs, or at least of some
subclasses of D-PPs. Interestingly, (Baldwin et al.
(2006), 175f.) take the productivity of a subclass
of D-PPs for granted and propose a lexical entry for
prepositions which select determinerless N’s as their
complement. While we are sympathetic to a syn-
tactic treatment of D-PPs in a computational gram-
mar, we think that the productivity of such construc-
tions must be considered more closely. The analysis
of Baldwin et al. (2006) allows the unlimited com-
bination of prepositions meeting their lexical spec-
ification with a determinerless N projection. This
</bodyText>
<equation confidence="0.930036">
(1)
</equation>
<page confidence="0.994734">
31
</page>
<note confidence="0.3136445">
Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, pages 31–37,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.997001052631579">
assumption is not in line with speaker’s intuitions
with regard to producing or judging such construc-
tions. As has been pointed out by Kiss (2006, 2007),
speakers of German can neither freely produce se-
quences consisting of unter and determinerless N
projections (typically a noun) nor can they judge
such constructions in isolation. In addition, not even
very similar nouns can be interchanged in a D-PP,
as can be witnessed by comparing near-synonyms
Voraussetzung and Pr¨amisse which both translate as
prerequisite, or as provided in the examples in (2). 100
The examples in (2) illustrate that Voraussetzung
cannot be replaced by Pr¨amisse in a D-PP (2a, b),
while it can be replaced as a head noun in a full
PP (2c, d). While the contrast in (2) casts doubt on
a productive analysis on the basis of the speakers
knowledge of language, the present paper will show
that unter+noun has to be classified as productive
from an empirical perspective. 10
</bodyText>
<listItem confidence="0.996941538461539">
a. Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter
Voraussetzung des Einverst¨andnisses
des Ensembles.
b. * Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter Pr¨amisse
des Einverst¨andnisses des Ensembles.
c. Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter der
Voraussetzung des Einverst¨andnisses (2)1
des Ensembles.
d. Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter der
</listItem>
<bodyText confidence="0.984358125">
Pr¨amisse des Einverst¨andnisses des
Ensembles.
“Philippe Egli insists on his individual way
of dealing with the issue, provided the
ensemble agrees.”
Our investigation is based of a corpus analysis of
D-PPs, consisting of the preposition unter and a fol-
lowing noun, and employs a quantitative measure
of productivity, first developed by Harald Baayen
to analyze morphological productivity. The pre-
liminary conclusion to be drawn from this result
will be that empirical and intuitive productivity of
unter+noun sequences do not match.
In applying Baayen’s productivity measure to
syntactic sequences, however, we are faced with
a serious problem. Baayen’s productivity measure
</bodyText>
<equation confidence="0.758716">
P(N) is based on the expectation of the hapax
legomena – E[V1] – occurring in a vocabulary of
size N, i.e. P(N) = E�V1]
N .
</equation>
<figureCaption confidence="0.910198">
Figure 1: Cardinalities of the frequency classes. The
</figureCaption>
<bodyText confidence="0.999686705882353">
frequency of each type was counted, then the types
were grouped into classes of equal frequency. The
number of types in each class was counted. The fre-
quency values m are assigned to the x-axis, the size
of the class Vm to the y-axis. Both are scaled loga-
rithmically.
Since we cannot derive the expectation of the ha-
pax legomena directly from the corpus, we have to
approximate it by use of regression models. To sim-
plify matters somewhat, Baayen’s models can only
be applied to unigrams, while we have to consider
bigrams – the preposition and the adjacent noun. To
circumvent this problem, Kiss (2006,2007) calcu-
lated P(N) on the basis of the empirical distribu-
tion of V1 as N gets larger. Evert (2004) offers re-
gression models to determine E[V1] for n-grams and
suggests two different models, the Zipf-Mandelbrot
</bodyText>
<figure confidence="0.547076">
1 10 100 1000
Cardinalities of the frequency classes
</figure>
<page confidence="0.984072">
32
</page>
<bodyText confidence="0.999986111111111">
model (ZM) and the finite Zipf-Mandelbrot model
(fZM). The difference between these two models
is that fZM assumes a finite vocabulary. In the
present paper, we apply Evert’s models to sequences
of unter+noun. We differ from Evert’s proposal in
estimating the free parameter α in both models on
the basis of the gradient descent algorithm. Contrary
to Evert’s assumptions, we will show that the results
of the ZM model are much closer to the empirical
observations than the results of the fZM model.
The paper is structured as follows. Section 2 de-
scribes the empirical basis of the experiment, a cor-
pus study of unter+textnounsy sequences. Section
3 introduces the models suggested by Evert (2004).
Section 3.1 introduces the models, section 3.2 shows
how the free parameter is estimated by making use
of the gradient descent algorithm. The results are
compared in section 3.3.
</bodyText>
<sectionHeader confidence="0.922033" genericHeader="method">
2 Corpus Study
</sectionHeader>
<bodyText confidence="0.993875583333333">
The present study is based on two German corpora,
with a total of 213 million words: the NZZ-corpus
1995-1998 (Neue Z¨urcher Zeitung) and the FRR-
corpus 1997-1999 (Frankfurter Rundschau). Mak-
ing use of the orthographic convention that nouns
are capitalized in German, we have automatically
extracted 12.993 types, amouting to some 71.000
tokens of unter and a following noun. From these
12.993 types, we have removed all candidates where
the noun is a proper noun, or realized as a plural,
or as member of a support verb construction. Also,
we have excluded typical stock phrases and all mass
nouns. The extraction process was done both man-
ually (proper nouns, mass nouns, support verb con-
structions) and automatically (plurals, mass nouns).
As a result of the extraction process, a total num-
ber of 1.103 types remained, amounting to 16.444
tokens. The frequency of every type was determined
and types with the same frequency were grouped
into classes. 65 equivalence classes were established
according to their frequency m (cf. Figure 1). The
number of elements in every class was counted and
the various count results were associated with the
variables Vm = V1, V2, . . . , V2134.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="method">
3 LNRE Model Regression
</sectionHeader>
<bodyText confidence="0.9991345">
Baayen (2001) uses the term LNRE models (large
number of rare events) to describe a class of mod-
els that allow the determination of the expectation
with a small set of parameters. Evert (2004) pro-
poses two LNRE models with are based on Zipf’s
Law (Zipf(1949), Li (1992)) to identify the expec-
tations E[V1], ... , E[Vmax]. Both models are based
on the Zipf-Mandelbrot law.
Zipf’s Law (Zipf(1949), Li (1992)) posits that the
frequency of the r-most frequent type is proportional
to 1r . The distribution of random texts displays a
strong similarity to the results expected according to
Zipf’s Law (cp. Li (1992)). Mandelbrot (1962) et
al. explain this phenomenon by Zipf’s Principle of
Least Effort.
Rouault (1978) shows that the probability of types
with a low frequency asymptotically behaves as
posited by the Zipf-Mandelbrot Law
</bodyText>
<equation confidence="0.958609666666667">
C
7rz = (i + b)a
with a &gt; 1 and b &gt; 0.
</equation>
<bodyText confidence="0.999983375">
The models are introduced in section 3.1. Both
require a parameter α, whose value was determined
by employing a gradient descent algorithm imple-
mented in Perl. The optimal value for the free pa-
rameter was found by constructing an error function
to minimise α. The calculation was carried out for
both models, but better results are produced if the
assumption is given up that the vocabulary is finite.
</bodyText>
<subsectionHeader confidence="0.995904">
3.1 Finite and general Zipf-Mandelbrot models
</subsectionHeader>
<bodyText confidence="0.999093058823529">
Evert (2004) proposes the finite Zipf-Mandelbrot
model (fZM) and the general Zipf-Mandelbrot
model (ZM) for modelling the expectations of the
frequency classes Vm, i.e. E[V1], ... , E[Vmax] and
the expected vocabulary size, i.e. the expectation
of the different types E[V ]. The two models make
different assumptions about the probability distribu-
tions of the frequency classes. The fZM assumes
that there is a minimal probability A – defined as
]A : Vi : A G 7rz. This amounts to the assumption
that the vocabulary size itself is finite. Hence, it can
be expected according to the fZM model that the set
of observed types does not increase once N Pz� A1 is
reached. In the general ZM model, there is no such
minimal probability.
Assuming a fZM model, Evert (2004) proposes
the following results to estimate the expectation of
</bodyText>
<page confidence="0.99804">
33
</page>
<bodyText confidence="0.961082666666667">
the frequency classes E[Vm] and the expected vo-
cabulary size E[V ]. In the following equations,
B stands for the maximum probability, defined as
</bodyText>
<equation confidence="0.992627875">
Vi : B &gt; πz.
1 − α
E[Vm] =
(B1−α − A1−α) · ml
Nα · F(m − α, N · A) (3)
OT = (V, V1, V2,..., V2134) E R66 (7)
ET (α) =
(E(V )(α), E(V1)(α), ... , E(V2134)(α)) E R66 (8)
</equation>
<figure confidence="0.6719089">
·
1 10 100 1000
100
10
1
Cardinalities of the frequency classes
1 − α α F(1 − α,N · A)
E[V ] = (B1−α − A1−α) · N · +
α
1 − α
</figure>
<equation confidence="0.8305525">
· (1 − e−N·4) (4)
(B1−α − A1−α) · α · Aα
</equation>
<bodyText confidence="0.996803285714286">
As can be witnessed from the formulae given, N,
A, and B are already known or directly derivable
from our observations, leaving us with the determi-
nation of the free parameter α.
Using the general Zipf-Mandelbrot model, we end
with the following estimations, again suggested by
Evert (2004):
</bodyText>
<equation confidence="0.9472954">
E[Vm] = 1 − . Nα · F(m − α) (5)
B1−α · ml
1 − α F(1 − α)
E[V ] = · Nα · (6)
B1−α α
</equation>
<bodyText confidence="0.999940666666667">
As there is no minimal probability, we are left
with the maximal probability B, the token size N,
and again a free parameter α.
</bodyText>
<subsectionHeader confidence="0.9517255">
3.2 Parameter estimation through gradient
descent
</subsectionHeader>
<bodyText confidence="0.999547333333333">
Since the expectation of the frequency classes in (3)
and (5) depend on the free parameter α, this pa-
rameter must be estimated in a way that minimises
the deviation of expected and observed values. We
measure the deviation with a function that takes into
account all observed frequencies and their expected
values. A function satisfying these criteria can be
found by treating observed frequency classes and ex-
pectations as real-valued vectors in a vector space.
</bodyText>
<figureCaption confidence="0.6914775">
Figure 2: The application of the fZM LNRE Model
combined with Rouault’s estimation method leads to
</figureCaption>
<bodyText confidence="0.976230222222222">
a strong deviation from the observed data. The ob-
served data is depicted as a solid line, the data from
the model as a dotted line. The frequency values m
are assigned to the x-axis, the size of the class Vm
respectively the expected size E(Vm) to the y-axis.
Both are scaled logarithmically.
A natural choice for a measure of error is the
quadratic norm of the difference vector between ob-
servation and expectation. As we have no infor-
</bodyText>
<page confidence="0.99763">
34
</page>
<bodyText confidence="0.9993006">
mation about the relationship between different fre-
quencies we assume that the covariance matrix is the
unit matrix.
These thoughts result in the following error func-
tion:
</bodyText>
<equation confidence="0.992038333333333">
g(α) = (E(V )(α) − V )2+
� (E(Vm)(α) − Vm)2 (9)
m=1,...,2134
</equation>
<bodyText confidence="0.999279">
The minimal α is equal to the root of the deriva-
tive of the error function with respect to α. The
derivative of the error function is:
</bodyText>
<equation confidence="0.992602666666667">
∂g = 2∂E(V ) (E(V ) (α) − V )+
∂α ∂α
2
m=1,...,2134
� ∂E(Vm) (E(Vm)(α) − Vm) (10)
∂α
</equation>
<bodyText confidence="0.999938">
One way to find the minimum α* =
argminα g(α) would be to derive the expected
values with respect to α and solve g′(α*) = 0 for
α. As there is no way known to the authors to
accomplish this in a symbolic way, the use of a
numeric method to calculate α* is advised.
We chose to find α* by employing a gradient de-
scent method and approximating ∂g
</bodyText>
<equation confidence="0.8007115">
∂α by evaluating
g(α) in small steps ǫα(i) and calculating Δg(k)
ǫα(k) =
g(α0+�kj=1 ǫα(j))−g(α0+�k�1
</equation>
<bodyText confidence="0.858811076923077">
j=1 ǫα(j))ǫα(k) , where k is num-
ber of the iteration.
In the vicinity of a minimum ∂g
∂α(α) decreases un-
til it vanishes at α*.
After every iteration the new ǫα(k) is chosen by
taking under consideration the change of Δg(k)
ǫα(k) and
the sign of ǫα(k − 1). If Δg(k)
ǫα(k) increased, the sign of
ǫα(k − 1) is inverted: ǫα(k) = −ǫα(k − 1).
To prevent the algorithm from oscillat-
ing around the minimum the last two values
</bodyText>
<equation confidence="0.892410375">
g(α0 + Ek−2
j=1 ǫα(j)) and g(α0 + Ek−1
j=1 ǫα(j)) are
saved.
When a step would result in returning to a previ-
ous value g(α0 + Ek−1
j=1 ǫα(j) + ǫα(k)) = g(α0 +
Ek−2
</equation>
<bodyText confidence="0.9975804">
j=1 ǫα(j)), the step size is multiplied by a con-
stant 0 &lt; γ &lt; 1: ǫα(k) = γǫα(k − 1). The al-
gorithm is stopped when the absolute value of the
step size drops under a predetermined threshold:
|ǫα(k) |&lt; ǫthreshold.
</bodyText>
<subsectionHeader confidence="0.653309">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.921007928571429">
Interestingly, α as determined by gradient descent
on the basis of a fZM leads to a value of 0.666,
which does not match well with our observations,
as can be witnessed in Figure 2.
Figure 3: The ZM LNRE Model leads to a far better
result with less deviation from the observation. The
observed data is depicted as a solid line, the data
from the model as a dotted line. The frequency val-
ues m are assigned to the x-axis, the size of the class
Vm respectively the expected size E(Vm) to the y-
axis. Both are scaled logarithmically.
A gradient descent search on the basis of the ZM
model delivered a value of α = 0.515, a much better
approximation (with a χ2-Value of 4.514), as can be
</bodyText>
<figure confidence="0.971264636363636">
1 10 100 1000
100
10
1
Cardinalities of the frequency classes
35
0.2
0.15
0.1
0.05
0
</figure>
<bodyText confidence="0.9968276">
witnessed from Figure 3. The value thus reached
also converges with the estimation procedure for α
suggested by Rouault (1978), and taken up by Evert
(2004), i.e. α = ul. Consequently, we assume a
ZM model for estimating of expected frequencies.
</bodyText>
<figure confidence="0.823404">
0 0.2 0.4 0.6 0.8 1
</figure>
<figureCaption confidence="0.763146">
Figure 4: The parts of the corpus were appended
to each other and after every step the productivity
</figureCaption>
<bodyText confidence="0.980918">
P(N) was calculated directly from the data as well
as from the fitted ZM model. The percentage of
the corpus is assigned to the x-axis, the productiv-
ity P(N) is assigned to the y-axis. The productivity
values that were deduced directly from data are plot-
ted as a dotted line, the productivity values from the
ZM model are plotted as a solid line.
To chart the productivity of sequences of the form
unter+noun, we have divided our corpus into six
smaller parts and sampled V , N, and V1 at these
parts. The distribution of the observations thus
gained can be found in Figure 4, together with the
expectations derived from the ZM model. We ob-
serve that both distributions are strikingly similar
and converge at th e values for the full corpus.
</bodyText>
<table confidence="0.960668375">
N V1 E[V1] P(N)
542 74 96.66 0.182
1068 104 123.47 0.118
2151 169 166.41 0.079
4262 282 249.93 0.059
6222 384 332.19 0.054
8365 469 400.43 0.048
16444 746 748.81 0.022
</table>
<tableCaption confidence="0.998771">
Table 1: Overview of the observed and expected
</tableCaption>
<bodyText confidence="0.950105875">
numbers of hapax legomena and the associated pro-
ductivity value at different corpus sizes.
In a broader perspective, Figure 4 shows that the
combination of unter+noun is a productive process,
when its empirical distribution is considered. As
was already pointed out in section 1, this finding
is at odds with speaker’s intuitions about combina-
tions of unter+noun. Assuming that this result can
be extended to other subclasses of D-PPs, we would
suggest restricting lexical specifications for preposi-
tions to subclasses of nouns, depending on the perti-
nent preposition. Future research will have to show
whether such clear-cut subclasses can be identified
by looking more closely at the empirical findings,
other whether we are confronted with a continuum,
which would require alternative rule types.
</bodyText>
<sectionHeader confidence="0.999547" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999739764705882">
Harald Baayen. 2001. Word Frequency Distributions.
Kluwer, Dordrecht.
Timothy Baldwin, John Beavers, Leonoor van der Beek,
Francis Bond, Dan Flickinger, and Ivan A. Sag. 2006.
In Search of a Systematic Treatment ofDeterminerless
PPs. In Patrick Saint-Dizier, editor, Syntax and Se-
mantics ofPrepositions, pages 163–179. Springer.
Stefan Evert. 2004. A Simple LNRE Model for Ran-
dom Character Sequences. In Proceedings of the
7mes Journees Internationales d’Analyse Statistique
des Donnees Textuelles, pages 411–422.
Nikolaus Himmelmann. 1998. Regularity in Irregular-
ity: Article Use in Adpositional Phrases. Linguistic
Typology, 2:315–353.
Tibor Kiss. 2006. Do we need a grammar of irregular
sequences? In Miriam Butt, editor, Proceedings of
KONVENS, pages 64–70, Konstanz.
</reference>
<figure confidence="0.9454865">
Estimated Productivity
Observed Productivity
</figure>
<page confidence="0.969775">
36
</page>
<reference confidence="0.999592761904762">
Tibor Kiss. 2007. Produktivit¨at und Idiomatizit¨at
von Pr¨aposition-Substantiv-Sequenzen. forthcoming
in Zeitschrift f¨ur Sprachwissenschaft.
W. Li. 1992. Random texts exhibit zipf’s-law-like word
frequency distribution. IEEE Transactions on Infor-
mation Theory.
B. Mandelbrot. 1962. On the theory of word frequencies
and on related Markovian models of discourse. Amer-
ican Mathematical Society.
A. Rouault. 1978. Lois de Zipf et sources markoviennes.
Annales de l’Institut H. Poincare.
Beata Trawinski, Manfred Sailer, and Jan-Philipp Soehn.
2006. Combinatorial Aspects of Collocational Prepo-
sitional Phrases. In Patrick Saint-Dizier, editor, Syn-
tax and Semantics of Prepositions, pages 181–196.
Springer.
Beata Trawinski. 2003. The Syntax of Complex Preposi-
tions in German: An HPSG Approach. In Proceedings
of GLIP, volume 5, pages 155–166.
G. K. Zipf. 1949. Human Behavior and the Principle of
Least Effort. Addison-Wesley, Campridge.
</reference>
<page confidence="0.999611">
37
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.342171">
<title confidence="0.999953">Measuring the Productivity of Determinerless PPs</title>
<author confidence="0.697283">Florian D¨omges</author>
<author confidence="0.697283">Tibor Kiss</author>
<author confidence="0.697283">Antje M¨uller</author>
<author confidence="0.697283">Claudia</author>
<title confidence="0.688045">Sprachwissenschaftliches</title>
<author confidence="0.715704">Ruhr-Universit¨at Bochum</author>
<email confidence="0.994616">claudia.roch@rub.de</email>
<abstract confidence="0.99818115">We determine the productivity of determinerless PPs in German quantitatively, restricting ourselves to the preposition unter. The study is based on two German newspaper corpora, comprising some 210 million words. The problematic construction, i.e. unter followed by a determinerless singular noun occurs some 16.000 times in the corpus. To clarify the empirical productivity of the construction, we apply a productivity measure developed by Baayen (2001) to the syntactic domain by making use of statistical models suggested in Evert (2004). We compare two different models and suggest a gradient descent search for parameter estimation. Our results show that the combination of unter+noun must in fact be characterized as productive, and hence that a syntactic treatment is required.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Harald Baayen</author>
</authors>
<title>Word Frequency Distributions.</title>
<date>2001</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="717" citStr="Baayen (2001)" startWordPosition="90" endWordPosition="91">h Sprachwissenschaftliches Institut Ruhr-Universit¨at Bochum florian.doemges@rub.de tibor@linguistics.rub.de antje.mueller@rub.de claudia.roch@rub.de Abstract We determine the productivity of determinerless PPs in German quantitatively, restricting ourselves to the preposition unter. The study is based on two German newspaper corpora, comprising some 210 million words. The problematic construction, i.e. unter followed by a determinerless singular noun occurs some 16.000 times in the corpus. To clarify the empirical productivity of the construction, we apply a productivity measure developed by Baayen (2001) to the syntactic domain by making use of statistical models suggested in Evert (2004). We compare two different models and suggest a gradient descent search for parameter estimation. Our results show that the combination of unter+noun must in fact be characterized as productive, and hence that a syntactic treatment is required. 1 Introduction The combination of a preposition with a singular count noun, illustrated in (1) with the preposition unter, is a frequent construction in written and spoken German. From a theoretical perspective, constructions like (1) are interesting since they seem to</context>
<context position="8505" citStr="Baayen (2001)" startWordPosition="1349" endWordPosition="1350">raction process was done both manually (proper nouns, mass nouns, support verb constructions) and automatically (plurals, mass nouns). As a result of the extraction process, a total number of 1.103 types remained, amounting to 16.444 tokens. The frequency of every type was determined and types with the same frequency were grouped into classes. 65 equivalence classes were established according to their frequency m (cf. Figure 1). The number of elements in every class was counted and the various count results were associated with the variables Vm = V1, V2, . . . , V2134. 3 LNRE Model Regression Baayen (2001) uses the term LNRE models (large number of rare events) to describe a class of models that allow the determination of the expectation with a small set of parameters. Evert (2004) proposes two LNRE models with are based on Zipf’s Law (Zipf(1949), Li (1992)) to identify the expectations E[V1], ... , E[Vmax]. Both models are based on the Zipf-Mandelbrot law. Zipf’s Law (Zipf(1949), Li (1992)) posits that the frequency of the r-most frequent type is proportional to 1r . The distribution of random texts displays a strong similarity to the results expected according to Zipf’s Law (cp. Li (1992)). M</context>
</contexts>
<marker>Baayen, 2001</marker>
<rawString>Harald Baayen. 2001. Word Frequency Distributions. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>John Beavers</author>
<author>Leonoor van der Beek</author>
<author>Francis Bond</author>
<author>Dan Flickinger</author>
<author>Ivan A Sag</author>
</authors>
<title>In Search of a Systematic Treatment ofDeterminerless PPs.</title>
<date>2006</date>
<booktitle>Syntax and Semantics ofPrepositions,</booktitle>
<pages>163--179</pages>
<editor>In Patrick Saint-Dizier, editor,</editor>
<publisher>Springer.</publisher>
<marker>Baldwin, Beavers, van der Beek, Bond, Flickinger, Sag, 2006</marker>
<rawString>Timothy Baldwin, John Beavers, Leonoor van der Beek, Francis Bond, Dan Flickinger, and Ivan A. Sag. 2006. In Search of a Systematic Treatment ofDeterminerless PPs. In Patrick Saint-Dizier, editor, Syntax and Semantics ofPrepositions, pages 163–179. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>A Simple LNRE Model for Random Character Sequences.</title>
<date>2004</date>
<booktitle>In Proceedings of the 7mes Journees Internationales d’Analyse Statistique des Donnees Textuelles,</booktitle>
<pages>411--422</pages>
<contexts>
<context position="803" citStr="Evert (2004)" startWordPosition="105" endWordPosition="106">or@linguistics.rub.de antje.mueller@rub.de claudia.roch@rub.de Abstract We determine the productivity of determinerless PPs in German quantitatively, restricting ourselves to the preposition unter. The study is based on two German newspaper corpora, comprising some 210 million words. The problematic construction, i.e. unter followed by a determinerless singular noun occurs some 16.000 times in the corpus. To clarify the empirical productivity of the construction, we apply a productivity measure developed by Baayen (2001) to the syntactic domain by making use of statistical models suggested in Evert (2004). We compare two different models and suggest a gradient descent search for parameter estimation. Our results show that the combination of unter+noun must in fact be characterized as productive, and hence that a syntactic treatment is required. 1 Introduction The combination of a preposition with a singular count noun, illustrated in (1) with the preposition unter, is a frequent construction in written and spoken German. From a theoretical perspective, constructions like (1) are interesting since they seem to violate the near universal rule that determiners should accompany singular count noun</context>
<context position="6224" citStr="Evert (2004)" startWordPosition="973" endWordPosition="974">ncy. The number of types in each class was counted. The frequency values m are assigned to the x-axis, the size of the class Vm to the y-axis. Both are scaled logarithmically. Since we cannot derive the expectation of the hapax legomena directly from the corpus, we have to approximate it by use of regression models. To simplify matters somewhat, Baayen’s models can only be applied to unigrams, while we have to consider bigrams – the preposition and the adjacent noun. To circumvent this problem, Kiss (2006,2007) calculated P(N) on the basis of the empirical distribution of V1 as N gets larger. Evert (2004) offers regression models to determine E[V1] for n-grams and suggests two different models, the Zipf-Mandelbrot 1 10 100 1000 Cardinalities of the frequency classes 32 model (ZM) and the finite Zipf-Mandelbrot model (fZM). The difference between these two models is that fZM assumes a finite vocabulary. In the present paper, we apply Evert’s models to sequences of unter+noun. We differ from Evert’s proposal in estimating the free parameter α in both models on the basis of the gradient descent algorithm. Contrary to Evert’s assumptions, we will show that the results of the ZM model are much clos</context>
<context position="8684" citStr="Evert (2004)" startWordPosition="1381" endWordPosition="1382">l number of 1.103 types remained, amounting to 16.444 tokens. The frequency of every type was determined and types with the same frequency were grouped into classes. 65 equivalence classes were established according to their frequency m (cf. Figure 1). The number of elements in every class was counted and the various count results were associated with the variables Vm = V1, V2, . . . , V2134. 3 LNRE Model Regression Baayen (2001) uses the term LNRE models (large number of rare events) to describe a class of models that allow the determination of the expectation with a small set of parameters. Evert (2004) proposes two LNRE models with are based on Zipf’s Law (Zipf(1949), Li (1992)) to identify the expectations E[V1], ... , E[Vmax]. Both models are based on the Zipf-Mandelbrot law. Zipf’s Law (Zipf(1949), Li (1992)) posits that the frequency of the r-most frequent type is proportional to 1r . The distribution of random texts displays a strong similarity to the results expected according to Zipf’s Law (cp. Li (1992)). Mandelbrot (1962) et al. explain this phenomenon by Zipf’s Principle of Least Effort. Rouault (1978) shows that the probability of types with a low frequency asymptotically behaves</context>
<context position="10574" citStr="Evert (2004)" startWordPosition="1703" endWordPosition="1704">classes Vm, i.e. E[V1], ... , E[Vmax] and the expected vocabulary size, i.e. the expectation of the different types E[V ]. The two models make different assumptions about the probability distributions of the frequency classes. The fZM assumes that there is a minimal probability A – defined as ]A : Vi : A G 7rz. This amounts to the assumption that the vocabulary size itself is finite. Hence, it can be expected according to the fZM model that the set of observed types does not increase once N Pz� A1 is reached. In the general ZM model, there is no such minimal probability. Assuming a fZM model, Evert (2004) proposes the following results to estimate the expectation of 33 the frequency classes E[Vm] and the expected vocabulary size E[V ]. In the following equations, B stands for the maximum probability, defined as Vi : B &gt; πz. 1 − α E[Vm] = (B1−α − A1−α) · ml Nα · F(m − α, N · A) (3) OT = (V, V1, V2,..., V2134) E R66 (7) ET (α) = (E(V )(α), E(V1)(α), ... , E(V2134)(α)) E R66 (8) · 1 10 100 1000 100 10 1 Cardinalities of the frequency classes 1 − α α F(1 − α,N · A) E[V ] = (B1−α − A1−α) · N · + α 1 − α · (1 − e−N·4) (4) (B1−α − A1−α) · α · Aα As can be witnessed from the formulae given, N, A, and </context>
<context position="15302" citStr="Evert (2004)" startWordPosition="2616" endWordPosition="2617">s a solid line, the data from the model as a dotted line. The frequency values m are assigned to the x-axis, the size of the class Vm respectively the expected size E(Vm) to the yaxis. Both are scaled logarithmically. A gradient descent search on the basis of the ZM model delivered a value of α = 0.515, a much better approximation (with a χ2-Value of 4.514), as can be 1 10 100 1000 100 10 1 Cardinalities of the frequency classes 35 0.2 0.15 0.1 0.05 0 witnessed from Figure 3. The value thus reached also converges with the estimation procedure for α suggested by Rouault (1978), and taken up by Evert (2004), i.e. α = ul. Consequently, we assume a ZM model for estimating of expected frequencies. 0 0.2 0.4 0.6 0.8 1 Figure 4: The parts of the corpus were appended to each other and after every step the productivity P(N) was calculated directly from the data as well as from the fitted ZM model. The percentage of the corpus is assigned to the x-axis, the productivity P(N) is assigned to the y-axis. The productivity values that were deduced directly from data are plotted as a dotted line, the productivity values from the ZM model are plotted as a solid line. To chart the productivity of sequences of t</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. A Simple LNRE Model for Random Character Sequences. In Proceedings of the 7mes Journees Internationales d’Analyse Statistique des Donnees Textuelles, pages 411–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikolaus Himmelmann</author>
</authors>
<title>Regularity in Irregularity: Article Use in Adpositional Phrases. Linguistic Typology,</title>
<date>1998</date>
<pages>2--315</pages>
<contexts>
<context position="1480" citStr="Himmelmann (1998)" startWordPosition="213" endWordPosition="215">cent search for parameter estimation. Our results show that the combination of unter+noun must in fact be characterized as productive, and hence that a syntactic treatment is required. 1 Introduction The combination of a preposition with a singular count noun, illustrated in (1) with the preposition unter, is a frequent construction in written and spoken German. From a theoretical perspective, constructions like (1) are interesting since they seem to violate the near universal rule that determiners should accompany singular count nouns if the language in question shows determiners at all (cf. Himmelmann (1998)). unter Vorbehalt (with reservation), unter Androhung (on pain), unter Lizenz (under licence), unter Vorwand (pretending) Baldwin et al. (2006) follow a tradition of English grammar and call constructions like (1) determinerless PPs (D-PP), defined as PPs whose NPcomplement consists of a singular count noun without an accompanying determiner (as e.g. English by bus, in mind). It has been claimed that D-PPs are mostly idiomatic and not productive. Hence, computational grammars often include D-PPs only as stock phrases or listed multiword expressions and do not offer a grammatical treatment. Ho</context>
</contexts>
<marker>Himmelmann, 1998</marker>
<rawString>Nikolaus Himmelmann. 1998. Regularity in Irregularity: Article Use in Adpositional Phrases. Linguistic Typology, 2:315–353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tibor Kiss</author>
</authors>
<title>Do we need a grammar of irregular sequences?</title>
<date>2006</date>
<booktitle>Proceedings of KONVENS,</booktitle>
<pages>64--70</pages>
<editor>In Miriam Butt, editor,</editor>
<location>Konstanz.</location>
<contexts>
<context position="2139" citStr="Kiss (2006" startWordPosition="316" endWordPosition="317">ohung (on pain), unter Lizenz (under licence), unter Vorwand (pretending) Baldwin et al. (2006) follow a tradition of English grammar and call constructions like (1) determinerless PPs (D-PP), defined as PPs whose NPcomplement consists of a singular count noun without an accompanying determiner (as e.g. English by bus, in mind). It has been claimed that D-PPs are mostly idiomatic and not productive. Hence, computational grammars often include D-PPs only as stock phrases or listed multiword expressions and do not offer a grammatical treatment. However, both claims have to be doubted seriously. Kiss (2006, 2007) shows that the class of D-PPs does not contain more idiomatic phrases than a typical phrasal category should and also argues against a ‘light P hypothesis’ which allows a pseudo-compositional treatment of D-PPs by ignoring the semantics of the preposition altogether. Trawinski (2003), Baldwin et al. (2006), as well as Trawinski et al. (2006) offer grammatical treatments of D-PPs, or at least of some subclasses of D-PPs. Interestingly, (Baldwin et al. (2006), 175f.) take the productivity of a subclass of D-PPs for granted and propose a lexical entry for prepositions which select determi</context>
<context position="3418" citStr="Kiss (2006" startWordPosition="517" endWordPosition="518">tic treatment of D-PPs in a computational grammar, we think that the productivity of such constructions must be considered more closely. The analysis of Baldwin et al. (2006) allows the unlimited combination of prepositions meeting their lexical specification with a determinerless N projection. This (1) 31 Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, pages 31–37, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics assumption is not in line with speaker’s intuitions with regard to producing or judging such constructions. As has been pointed out by Kiss (2006, 2007), speakers of German can neither freely produce sequences consisting of unter and determinerless N projections (typically a noun) nor can they judge such constructions in isolation. In addition, not even very similar nouns can be interchanged in a D-PP, as can be witnessed by comparing near-synonyms Voraussetzung and Pr¨amisse which both translate as prerequisite, or as provided in the examples in (2). 100 The examples in (2) illustrate that Voraussetzung cannot be replaced by Pr¨amisse in a D-PP (2a, b), while it can be replaced as a head noun in a full PP (2c, d). While the contrast i</context>
<context position="6122" citStr="Kiss (2006" startWordPosition="954" endWordPosition="955">es. The frequency of each type was counted, then the types were grouped into classes of equal frequency. The number of types in each class was counted. The frequency values m are assigned to the x-axis, the size of the class Vm to the y-axis. Both are scaled logarithmically. Since we cannot derive the expectation of the hapax legomena directly from the corpus, we have to approximate it by use of regression models. To simplify matters somewhat, Baayen’s models can only be applied to unigrams, while we have to consider bigrams – the preposition and the adjacent noun. To circumvent this problem, Kiss (2006,2007) calculated P(N) on the basis of the empirical distribution of V1 as N gets larger. Evert (2004) offers regression models to determine E[V1] for n-grams and suggests two different models, the Zipf-Mandelbrot 1 10 100 1000 Cardinalities of the frequency classes 32 model (ZM) and the finite Zipf-Mandelbrot model (fZM). The difference between these two models is that fZM assumes a finite vocabulary. In the present paper, we apply Evert’s models to sequences of unter+noun. We differ from Evert’s proposal in estimating the free parameter α in both models on the basis of the gradient descent a</context>
</contexts>
<marker>Kiss, 2006</marker>
<rawString>Tibor Kiss. 2006. Do we need a grammar of irregular sequences? In Miriam Butt, editor, Proceedings of KONVENS, pages 64–70, Konstanz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tibor Kiss</author>
</authors>
<date>2007</date>
<booktitle>Produktivit¨at und Idiomatizit¨at von Pr¨aposition-Substantiv-Sequenzen. forthcoming in Zeitschrift f¨ur Sprachwissenschaft.</booktitle>
<marker>Kiss, 2007</marker>
<rawString>Tibor Kiss. 2007. Produktivit¨at und Idiomatizit¨at von Pr¨aposition-Substantiv-Sequenzen. forthcoming in Zeitschrift f¨ur Sprachwissenschaft.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
</authors>
<title>Random texts exhibit zipf’s-law-like word frequency distribution.</title>
<date>1992</date>
<journal>IEEE Transactions on Information Theory.</journal>
<contexts>
<context position="8761" citStr="Li (1992)" startWordPosition="1395" endWordPosition="1396">very type was determined and types with the same frequency were grouped into classes. 65 equivalence classes were established according to their frequency m (cf. Figure 1). The number of elements in every class was counted and the various count results were associated with the variables Vm = V1, V2, . . . , V2134. 3 LNRE Model Regression Baayen (2001) uses the term LNRE models (large number of rare events) to describe a class of models that allow the determination of the expectation with a small set of parameters. Evert (2004) proposes two LNRE models with are based on Zipf’s Law (Zipf(1949), Li (1992)) to identify the expectations E[V1], ... , E[Vmax]. Both models are based on the Zipf-Mandelbrot law. Zipf’s Law (Zipf(1949), Li (1992)) posits that the frequency of the r-most frequent type is proportional to 1r . The distribution of random texts displays a strong similarity to the results expected according to Zipf’s Law (cp. Li (1992)). Mandelbrot (1962) et al. explain this phenomenon by Zipf’s Principle of Least Effort. Rouault (1978) shows that the probability of types with a low frequency asymptotically behaves as posited by the Zipf-Mandelbrot Law C 7rz = (i + b)a with a &gt; 1 and b &gt; 0.</context>
</contexts>
<marker>Li, 1992</marker>
<rawString>W. Li. 1992. Random texts exhibit zipf’s-law-like word frequency distribution. IEEE Transactions on Information Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mandelbrot</author>
</authors>
<title>On the theory of word frequencies and on related Markovian models of discourse.</title>
<date>1962</date>
<publisher>American Mathematical Society.</publisher>
<contexts>
<context position="9121" citStr="Mandelbrot (1962)" startWordPosition="1453" endWordPosition="1454">) uses the term LNRE models (large number of rare events) to describe a class of models that allow the determination of the expectation with a small set of parameters. Evert (2004) proposes two LNRE models with are based on Zipf’s Law (Zipf(1949), Li (1992)) to identify the expectations E[V1], ... , E[Vmax]. Both models are based on the Zipf-Mandelbrot law. Zipf’s Law (Zipf(1949), Li (1992)) posits that the frequency of the r-most frequent type is proportional to 1r . The distribution of random texts displays a strong similarity to the results expected according to Zipf’s Law (cp. Li (1992)). Mandelbrot (1962) et al. explain this phenomenon by Zipf’s Principle of Least Effort. Rouault (1978) shows that the probability of types with a low frequency asymptotically behaves as posited by the Zipf-Mandelbrot Law C 7rz = (i + b)a with a &gt; 1 and b &gt; 0. The models are introduced in section 3.1. Both require a parameter α, whose value was determined by employing a gradient descent algorithm implemented in Perl. The optimal value for the free parameter was found by constructing an error function to minimise α. The calculation was carried out for both models, but better results are produced if the assumption </context>
</contexts>
<marker>Mandelbrot, 1962</marker>
<rawString>B. Mandelbrot. 1962. On the theory of word frequencies and on related Markovian models of discourse. American Mathematical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rouault</author>
</authors>
<title>Lois de Zipf et sources markoviennes. Annales de l’Institut</title>
<date>1978</date>
<contexts>
<context position="9204" citStr="Rouault (1978)" startWordPosition="1466" endWordPosition="1467">s that allow the determination of the expectation with a small set of parameters. Evert (2004) proposes two LNRE models with are based on Zipf’s Law (Zipf(1949), Li (1992)) to identify the expectations E[V1], ... , E[Vmax]. Both models are based on the Zipf-Mandelbrot law. Zipf’s Law (Zipf(1949), Li (1992)) posits that the frequency of the r-most frequent type is proportional to 1r . The distribution of random texts displays a strong similarity to the results expected according to Zipf’s Law (cp. Li (1992)). Mandelbrot (1962) et al. explain this phenomenon by Zipf’s Principle of Least Effort. Rouault (1978) shows that the probability of types with a low frequency asymptotically behaves as posited by the Zipf-Mandelbrot Law C 7rz = (i + b)a with a &gt; 1 and b &gt; 0. The models are introduced in section 3.1. Both require a parameter α, whose value was determined by employing a gradient descent algorithm implemented in Perl. The optimal value for the free parameter was found by constructing an error function to minimise α. The calculation was carried out for both models, but better results are produced if the assumption is given up that the vocabulary is finite. 3.1 Finite and general Zipf-Mandelbrot m</context>
<context position="15272" citStr="Rouault (1978)" startWordPosition="2610" endWordPosition="2611"> The observed data is depicted as a solid line, the data from the model as a dotted line. The frequency values m are assigned to the x-axis, the size of the class Vm respectively the expected size E(Vm) to the yaxis. Both are scaled logarithmically. A gradient descent search on the basis of the ZM model delivered a value of α = 0.515, a much better approximation (with a χ2-Value of 4.514), as can be 1 10 100 1000 100 10 1 Cardinalities of the frequency classes 35 0.2 0.15 0.1 0.05 0 witnessed from Figure 3. The value thus reached also converges with the estimation procedure for α suggested by Rouault (1978), and taken up by Evert (2004), i.e. α = ul. Consequently, we assume a ZM model for estimating of expected frequencies. 0 0.2 0.4 0.6 0.8 1 Figure 4: The parts of the corpus were appended to each other and after every step the productivity P(N) was calculated directly from the data as well as from the fitted ZM model. The percentage of the corpus is assigned to the x-axis, the productivity P(N) is assigned to the y-axis. The productivity values that were deduced directly from data are plotted as a dotted line, the productivity values from the ZM model are plotted as a solid line. To chart the </context>
</contexts>
<marker>Rouault, 1978</marker>
<rawString>A. Rouault. 1978. Lois de Zipf et sources markoviennes. Annales de l’Institut H. Poincare.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Trawinski</author>
<author>Manfred Sailer</author>
<author>Jan-Philipp Soehn</author>
</authors>
<title>Combinatorial Aspects of Collocational Prepositional Phrases.</title>
<date>2006</date>
<booktitle>Syntax and Semantics of Prepositions,</booktitle>
<pages>181--196</pages>
<editor>In Patrick Saint-Dizier, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="2490" citStr="Trawinski et al. (2006)" startWordPosition="370" endWordPosition="373">been claimed that D-PPs are mostly idiomatic and not productive. Hence, computational grammars often include D-PPs only as stock phrases or listed multiword expressions and do not offer a grammatical treatment. However, both claims have to be doubted seriously. Kiss (2006, 2007) shows that the class of D-PPs does not contain more idiomatic phrases than a typical phrasal category should and also argues against a ‘light P hypothesis’ which allows a pseudo-compositional treatment of D-PPs by ignoring the semantics of the preposition altogether. Trawinski (2003), Baldwin et al. (2006), as well as Trawinski et al. (2006) offer grammatical treatments of D-PPs, or at least of some subclasses of D-PPs. Interestingly, (Baldwin et al. (2006), 175f.) take the productivity of a subclass of D-PPs for granted and propose a lexical entry for prepositions which select determinerless N’s as their complement. While we are sympathetic to a syntactic treatment of D-PPs in a computational grammar, we think that the productivity of such constructions must be considered more closely. The analysis of Baldwin et al. (2006) allows the unlimited combination of prepositions meeting their lexical specification with a determinerless </context>
</contexts>
<marker>Trawinski, Sailer, Soehn, 2006</marker>
<rawString>Beata Trawinski, Manfred Sailer, and Jan-Philipp Soehn. 2006. Combinatorial Aspects of Collocational Prepositional Phrases. In Patrick Saint-Dizier, editor, Syntax and Semantics of Prepositions, pages 181–196. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Trawinski</author>
</authors>
<title>The Syntax of Complex Prepositions in German: An HPSG Approach.</title>
<date>2003</date>
<booktitle>In Proceedings of GLIP,</booktitle>
<volume>5</volume>
<pages>155--166</pages>
<contexts>
<context position="2431" citStr="Trawinski (2003)" startWordPosition="361" endWordPosition="362">eterminer (as e.g. English by bus, in mind). It has been claimed that D-PPs are mostly idiomatic and not productive. Hence, computational grammars often include D-PPs only as stock phrases or listed multiword expressions and do not offer a grammatical treatment. However, both claims have to be doubted seriously. Kiss (2006, 2007) shows that the class of D-PPs does not contain more idiomatic phrases than a typical phrasal category should and also argues against a ‘light P hypothesis’ which allows a pseudo-compositional treatment of D-PPs by ignoring the semantics of the preposition altogether. Trawinski (2003), Baldwin et al. (2006), as well as Trawinski et al. (2006) offer grammatical treatments of D-PPs, or at least of some subclasses of D-PPs. Interestingly, (Baldwin et al. (2006), 175f.) take the productivity of a subclass of D-PPs for granted and propose a lexical entry for prepositions which select determinerless N’s as their complement. While we are sympathetic to a syntactic treatment of D-PPs in a computational grammar, we think that the productivity of such constructions must be considered more closely. The analysis of Baldwin et al. (2006) allows the unlimited combination of prepositions</context>
</contexts>
<marker>Trawinski, 2003</marker>
<rawString>Beata Trawinski. 2003. The Syntax of Complex Prepositions in German: An HPSG Approach. In Proceedings of GLIP, volume 5, pages 155–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>Human Behavior and the Principle of Least Effort.</title>
<date>1949</date>
<publisher>Addison-Wesley, Campridge.</publisher>
<marker>Zipf, 1949</marker>
<rawString>G. K. Zipf. 1949. Human Behavior and the Principle of Least Effort. Addison-Wesley, Campridge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>