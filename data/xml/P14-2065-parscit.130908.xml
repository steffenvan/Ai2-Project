<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010292">
<title confidence="0.9944105">
The VerbCorner Project: Findings from Phase 1 of Crowd-Sourcing a
Semantic Decomposition of Verbs
</title>
<author confidence="0.970355">
Joshua K. Hartshorne
</author>
<affiliation confidence="0.9828565">
Department of Brain and Cognitive Sciences
Massachusetts Institute of Technology
</affiliation>
<address confidence="0.904278">
77 Massachusetts Avenue
Cambridge, MA 02139, USA
</address>
<email confidence="0.995656">
jkhartshorne@gmail.com
</email>
<sectionHeader confidence="0.993776" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999950944444445">
Any given verb can appear in some syntac-
tic frames (Sally broke the vase, The vase
broke) but not others (*Sally broke at the
vase, *Sally broke the vase to John). There
is now considerable evidence that the syn-
tactic behaviors of some verbs can be pre-
dicted by their meanings, and many cur-
rent theories posit that this is true for most
if not all verbs. If true, this fact would
have striking implications for theories and
models of language acquisition, as well as
numerous applications in natural language
processing. However, empirical investiga-
tions to date have focused on a small num-
ber of verbs. We report on early results
from VerbCorner, a crowd-sourced project
extending this work to a large, representa-
tive sample of English verbs.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9994685">
Verbs vary in terms of which syntactic frames they
can appear in (Table 1). In principle, this could be
an unpredictable fact about the verb that must be
acquired, much like the phonological form of the
verb.
However, most theorists posit that there is a sys-
tematic relationship between the semantics of a
verb and the syntactic frames in which it can ap-
pear (Levin and Hovav, 2005). For instance, it
is argued that verbs like break, which describe a
</bodyText>
<table confidence="0.9184904">
Frame hit like break
NP V NP x x x
NP V - - x
NP that S - x -
NP V at NP x - -
</table>
<tableCaption confidence="0.9780215">
Table 1: Some of the syntactic frames available for
hit, like, and break.
</tableCaption>
<author confidence="0.977973">
Claire Bonial, Martha Palmer
</author>
<affiliation confidence="0.9783595">
Department of Linguistics
University of Colorado at Boulder
</affiliation>
<address confidence="0.8327165">
Hellems 290, 295 UCB
Boulder, CO 80309, USA
</address>
<email confidence="0.960916">
{CBonial, MPalmer}@colorado.edu
</email>
<bodyText confidence="0.996997375">
caused change of state, can appear in both the NP
V NP form (Sally broke the vase) and the NP
V form (The vase broke). Verbs such as hit and
like do not describe a change of state and so can-
not appear in both forms.1 Similarly, only verbs
that describe propositional attitudes, such as like,
can take a that complement (John liked that Sally
broke the vase).
</bodyText>
<subsectionHeader confidence="0.98855">
1.1 The Semantic Consistency Hypothesis
</subsectionHeader>
<bodyText confidence="0.999622333333333">
This account has a natural consequence, which we
dub the Semantic Consistency Hypothesis: There
is some set of semantic features such that verbs
that share the same syntactic behavior are identi-
cal along those semantic features.2 Note that on
certain accounts, this is a strong tendency rather
than a strict necessity (e.g., Goldberg, 1995).
It is widely recognized that a principled re-
lationship between syntax and semantics would
have broad implications. It is frequently invoked
in theories of language acquisition. For instance,
Pinker (1984, 1989) has described how this cor-
respondence could solve long-standing puzzles
about how children learn syntax in the first place.
Conversely, Gleitman (1990) has shown such a
syntax-semantics relationship could solve signif-
icant problems in vocabulary acquisition. In fact,
both researchers argue that a principled relation-
ship between syntax and semantics is necessary
for language to be learnable at all.
In computational linguistics and natural lan-
guage processing, some form of the Semantic
Consistency Hypothesis is often included in lin-
guistic resources and utilized in applications. We
</bodyText>
<footnote confidence="0.999676375">
1Note that this is a simplification in that there are non-
causal verbs that appear in both the NP V NP frame and the
NP V frame. For details, see (Levin, 1993).
2There is a long tradition of partitioning semantics into
those aspects of meaning which are “grammatically relevant”
and those which are not. We refer the interested reader to
Pinker (1989), Jackendoff (1990), and Levin &amp; Rappaport
Hovav (2005).
</footnote>
<page confidence="0.978536">
397
</page>
<bodyText confidence="0.90416">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 397–402,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
describe in detail one such resource, VerbNet,
which is highly relevant to our investigation.
</bodyText>
<subsectionHeader confidence="0.950521">
1.2 VerbNet
</subsectionHeader>
<bodyText confidence="0.986187461538461">
VerbNet (Kipper et al., 2008; based on Levin,
1993) lists over 6,000 verbs, categorized into 280
classes according to the syntactic frames they can
appear in. That is, all verbs in the same class ap-
pear in the same set of syntactic frames. Impor-
tantly, in addition to characterizing the syntactic
frames associated with each class, VerbNet also
characterizes the semantics of each class.
For instance, class 9.7, which comprises a
couple dozen verbs, allows 7 different syntactic
frames. The entry for one frame is shown below:
Syntactic Frame NP V NP PP.DESTINATION
Example Jessica sprayed the wall.
</bodyText>
<sectionHeader confidence="0.8622295" genericHeader="introduction">
Syntax AGENT V THEME {+LOC|+DEST CONF}
DESTINATION
</sectionHeader>
<bodyText confidence="0.898927142857143">
Semantics MOTION(DURING(E), THEME)
NOT(PREP(START(E), THEME, DESTINATION))
PREP(END(E), THEME, DESTINATION)
CAUSE(AGENT, E)
Importantly, the semantics listed here is not just
for the verb spray but applies to all verbs from the
Spray Class whenever they appear in that syntac-
tic frame – that is, VerbNet assumes the Semantic
Consistency Hypothesis.
VerbNet and its semantic features have been
used in a variety of NLP applications, such as se-
mantic role labeling (Swier and Stevenson, 2004),
inferencing (Zaenen et al., 2008), verb classifica-
tion (Joanis et al., 2008), and information extrac-
tion (Maynard et al., 2009). It has also been em-
ployed in models of language acquisition (Parisien
and Stevenson, 2011; Barak et al., 2012). In gen-
eral, there has been interest in the NLP literature
in using these syntactially-relevant semantic fea-
tures for shallow semantic parsing (e.g., Giuglea
and Moschitti, 2006).
</bodyText>
<sectionHeader confidence="0.8466985" genericHeader="method">
2 Empirical Status of the Semantic
Consistency Hypothesis
</sectionHeader>
<bodyText confidence="0.99998306122449">
Given the prominence of the Semantic Consis-
tency Hypothesis in both theory and practice, one
might expect that it was on firm empirical foot-
ing. That is, ideally there would be some database
of semantic judgments for a comprehensive set
of verbs from each syntactic class. In princi-
ple, these judgments would come from naive an-
notators, since researchers’ intuitions about sub-
tle judgments may be unconsciously clouded by
theoretical commitments (Gibson and Fedorenko,
2013). The Semantic Consistency Hypothesis
would be supported if, within that database, predi-
cates with the same syntactic properties were sys-
tematically related semantically.
No such database exists, whether consisting of
the judgments of linguists or naive annotators.
Most theoretical studies report researcher judg-
ments for only a handful of examples; how many
additional examples were considered by the re-
searcher goes unreported. In any case, to our
knowledge, of the 280 syntactic verb classes listed
by VerbNet, only a handful have been studied in
any detail.
The strongest evidence comes from experimen-
tal work on several so-called alternations (the pas-
sive, causative, locative, and dative alternations).
Here, there does appear to be a systematic seman-
tic distinction between the two syntactic frames in
each alternation, at least most of the time. This
has been tested with a reasonable sample of the
relevant verbs and also in both children and adults
(Ambridge et al., 2013; Pinker, 1989). However,
the relevant verbs make up a tiny fraction of all
English verbs, and even for these verbs, the syn-
tactic frames in question represent only a fraction
of the syntactic frames available to those verbs.
This is not an accidental oversight. The limit-
ing factor is scale: with many thousands of verbs
and over a hundred commonly-discussed seman-
tic features and syntactic frames, it is not feasi-
ble for a single researcher, or even team of re-
searchers, to check which verbs appear in which
syntactic frames and carry which semantic en-
tailments. Collecting data from naive subjects is
even more laborious, particularly since the aver-
age Man on the Street is not necessarily equipped
with metalinguistic concepts like caused change of
state and propositional attitude. The VerbCorner
Project is aimed at filling that empirical gap.
</bodyText>
<sectionHeader confidence="0.99867" genericHeader="method">
3 VerbCorner
</sectionHeader>
<bodyText confidence="0.99953">
The VerbCorner Project3 is devoted to collecting
semantic judgments for a comprehensive set of
verbs along a comprehensive set of theoretically-
relevant semantic dimension. These data can be
used to test the Semantic Consistency Hypothesis.
</bodyText>
<footnote confidence="0.953009">
3http://gameswithwords.org/VerbCorner/
</footnote>
<page confidence="0.996628">
398
</page>
<bodyText confidence="0.999572666666667">
Independent of the validity of that hypothesis, the
semantic judgments themselves should prove use-
ful for any study of linguistic meaning or related
application.
We address the issue of scale through crowd-
sourcing: Recruiting large numbers of volunteers,
each of whom may provide only a few annota-
tions. Several previous projects have success-
fully crowd-sourced linguistic annotations, such
as Phrase Detectives, where volunteers have con-
tributed 2.5 million judgments on anaphoric rela-
tions (Poesio et al., 2012).
</bodyText>
<subsectionHeader confidence="0.999333">
3.1 Integration with VerbNet
</subsectionHeader>
<bodyText confidence="0.999943307692308">
One significant challenge for any such project is
first classifying verbs according to the syntactic
frames they can appear in. Thus, at least initially,
we are focusing on the 6,000+ verbs already cata-
loged in VerbNet. As such, the VerbCorner Project
is also verifying and validating the semantics cur-
rently encoded in VerbNet. VerbNet will be edited
as necessary based on the empirical results.
Integration with VerbNet has additional bene-
fits, since VerbNet itself is integrated with a vari-
ety of linguistic resources, such as PropBank and
Penn TreeBank. This amplifies the impact of any
VerbCorner-inspired changes to VerbNet.
</bodyText>
<subsectionHeader confidence="0.999112">
3.2 The Tasks
</subsectionHeader>
<bodyText confidence="0.999987838709677">
We selected semantic features of interest based on
those most commonly cited in the linguistics lit-
erature, with a particular focus on those that – ac-
cording to VerbNet – apply to many predicates.
Previous research has shown that humans find
it easier to reason about real-world scenarios than
make abstract judgments (Cosmides and Tooby,
1992). Thus, for each feature (e.g., MOVEMENT),
we converted the metalinguistic judgment (“Does
this verb entail movement on the part of some en-
tity?”) into a real-world problem.
For example, in “Simon Says Freeze,” a task
designed to elicit judgments about movement, the
Galactic Overlord (Simon) decrees “Galactic Stay
Where You Are Day,” during which nobody is al-
lowed to move from their current location. Par-
ticipants read descriptions of events and decide
whether anyone violated the rule.
In “Explode on Contact,” designed to elicit
judgments about physical contact, objects and
people explode when they touch one another. The
participant reads descriptions of events and de-
cides whether anything has exploded.
Note that each task is designed to elicit judg-
ments about entailments – things that must be true
rather than are merely likely to be true. If John
greeted Bill, they might have come into contact
(e.g., by shaking hands), but perhaps they did not.
Previous work suggests that it is the semantic en-
tailments that matter, particularly for explaining
the syntactic behavior of verbs (Levin, 1993).
</bodyText>
<subsectionHeader confidence="0.998056">
3.3 The Items
</subsectionHeader>
<bodyText confidence="0.998794357142857">
The exact semantics associated with a verb may
depend on its syntactic frame. Thus Sally rolled
the ball entails that somebody applied force to the
ball (namely: Sally), whereas The ball rolled does
not. Thus, we investigate the semantics of each
verb in each syntactic frame available to it (as de-
scribed by VerbNet). Below, the term item is the
unit of annotation: a verb in a frame.
In order to minimize unwanted effects of world
knowledge, the verb’s arguments are replaced with
nonsense words or randomly chosen proper names
(Sally sprayed the dax onto the blicket). The use
of novel words is explained by the story for each
task.
</bodyText>
<subsectionHeader confidence="0.975341">
3.4 The Phases
</subsectionHeader>
<bodyText confidence="0.999973888888889">
Given the sheer scale of the project, data-
collection is expected to take several years at least.
Thus, data-collection has been broken up into a se-
ries of phases. Each phase focuses on a small num-
ber of classes and/or semantic entailments. This
ensures that there are meaningful intermediate re-
sults that can be disseminated prior to the comple-
tion of the entire project. This manuscript reports
the results of Phase 1.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999817">
The full data and annotations will be released in
the near future and may be available now by re-
quest. Below, we summarize the main findings
thus far.
</bodyText>
<subsectionHeader confidence="0.999638">
4.1 Description of Phase 1
</subsectionHeader>
<bodyText confidence="0.99995725">
In Phase 1 of the project, we focused on 11 verb
classes (Table 3) comprising 641 verbs and seven
different semantic entailments (Table 2). While
six of these entailments were chosen from among
those features widely believed to be relevant for
syntax, one was not: A Good World, which inves-
tigated evaluation (Is the event described by the
verb positive or negative?). Although evaluation
</bodyText>
<page confidence="0.997619">
399
</page>
<table confidence="0.999584">
Task Semantic Feature Anns. Anns./Item Mode Consistency
Entropy PHYSICAL CHANGE 23,875 7 86% 95%
Equilibrium APPLICATION OF FORCE 27,128 8 79% 95%
Explode on Contact PHYSICAL CONTACT 23,590 7 93% 95%
Fickle Folk CHANGE OF MENTAL STATE 16,466 5 81% 96%
Philosophical Zombie Hunter MENTAL STATE 24,592 7 80% 89%
Simon Says Freeze LOCATION CHANGE 24,245 7 83% 88%
A Good World EVALUATION 22,668 7 72% 74%
</table>
<tableCaption confidence="0.972431">
Table 2: Respectively: Task, semantic feature tested, number of annotations, mean number of annotations
per item, mean percentage of participants choosing the modal response, consistency within class.
</tableCaption>
<bodyText confidence="0.999099625">
of events is an important component of human
psychology, to our knowledge no researcher has
suggested that it is relevant for syntax. As such,
this task provides a lower bound for how much se-
mantic consistency one might expect within a syn-
tactic verb class.
In all, we collected 162,564 judgments from
1,983 volunteers (Table 2).
</bodyText>
<subsectionHeader confidence="0.610837">
4.2 Inter-annotator Agreement
</subsectionHeader>
<bodyText confidence="0.999951942857143">
Each task had been iteratively piloted and re-
designed until inter-annotator reliability was ac-
ceptable, as described in a previous publication.
However, these pilot studies involved a small num-
ber of items which were coded by all annota-
tors. How good was the reliability in the crowd-
sourcing context?
Because we recruited large numbers of an-
notators, most of whom annotated only a few
items, typical measures of inter-annotator agree-
ment such as Cohen’s kappa are not easily calcu-
lated. Instead, for each item, we calculated the
most common (modal) response. We then con-
sidered what proportion of all annotations were
accounted for by the modal response: a mean of
100% would indicate that there was no disagree-
ment among annotators for any item.
As can be seen in Table 2, for every task, the
modal response covered the bulk responses, rang-
ing from a low of 72% for EVALUATION to a high
of 93% for PHYSICAL CONTACT. Since there
were typically 4 or more possible answers per
item, inter-annotator agreement was well above
chance. This represents good performance given
that the annotators were entirely untrained.
In many cases, annotator disagreement seems
to be driven by syntactic constructions that are
only marginally grammatical. For instance, inter-
annotator agreement was typically low for class
63. VerbNet suggests two syntactic frames for
class 63, one of which (NP V THAT S) appears to
be marginal (?I control that Mary eats). In fact,
annotators frequently flagged these items as un-
grammatical, which is a valuable result in itself for
improving VerbNet.
</bodyText>
<footnote confidence="0.622466916666667">
Class Examples PChange Force Contact MChange Mental LChange
12 yank, press - x d - - d
18.1 hit, squash d x d - - d
29.5 believe, conjecture - - - - d -
31.1 amuse, frighten - - - x d -
31.2 like, fear - - - - x -
45.1 break, crack x d d - - d
51.3.1 bounce, roll - d d - - d
51.3.2 run, slink - d - - - d
51.6 chase, follow - - - - - d
61 attempt, try - - - - - -
63 control, enforce - - - - - -
</footnote>
<tableCaption confidence="0.97029">
Table 3: VerbNet classes investigated in Phase 1, with presence of semantic entailments as indicated by
data. x = feature present; - = feature absent; d = depends on syntactic frame.
</tableCaption>
<page confidence="0.993961">
400
</page>
<subsectionHeader confidence="0.998259666666667">
4.3 Testing the Semantic Consistency
Hypothesis
4.3.1 Calculating consistency
</subsectionHeader>
<bodyText confidence="0.9999892">
We next investigated whether our results support
the Semantic Consistency Hypothesis. As noted
above, the question is not whether all verbs in the
same syntactic class share the same semantic en-
tailments. Even a single verb may have different
semantic entailments when placed in different syn-
tactic frames. Thus, calculating consistency of a
class must take differing frames into account.
There are many sophisticated rubrics for calcu-
lating consistency. However, for expository pur-
poses here, we use one that is intuitive and easy
to interpret. First, we determined the annotation
for each item (i.e., each verb/frame combination)
by majority vote. We then considered how many
verbs in each class had the same annotation in any
given syntactic frame.
For example, suppose a class had 10 verbs and
2 frames. In the first frame, 8 verbs received the
same annotation and 2 received others. The con-
sistency for this class/frame combination is 80%.
In the second frame, 6 verbs received the same
annotation and 4 verbs received others. The con-
sistency for this class/frame combination is 60%.
The consistency for the class as a whole is the av-
erage across frames: 70%.
</bodyText>
<sectionHeader confidence="0.711045" genericHeader="evaluation">
4.3.2 Results
</sectionHeader>
<bodyText confidence="0.996122473684211">
Mean consistency averaged across classes is
shown for each task in Table 2. As expected,
consistency was lowest for EVALUATION, which
is not expected to necessarily correlate with syn-
tax. Interestingly, consistency for EVALUATION
was nonetheless well above floor. This is per-
haps not surprising: two sentences that have the
same values for PHYSICAL CHANGE, APPLICA-
TION OF FORCE, PHYSICAL CONTACT, CHANGE
OF MENTAL STATE, MENTAL STATE, and LO-
CATION CHANGE are, on average, also likely to
be both good or both bad.
Consistency was much higher for the other
tasks, and in fact was close to ceiling for most of
them. It remains to be seen whether the items that
deviate from the mode represent true differences in
semantics or reflect merely noise. One way of ad-
dressing this question is to collect additional anno-
tations for those items that deviate from the mode.
</bodyText>
<subsectionHeader confidence="0.995915">
4.4 Verb semantics
</subsectionHeader>
<bodyText confidence="0.9999648">
For each syntactic frame in each class, we deter-
mined the most common annotation. This is sum-
marized in Table 3. The semantic annotation de-
pended on syntactic frame nearly 1/4 of the time.4
These frequently matched VerbNet’s seman-
tics, though not always. For instance, annota-
tors judged that class 18.1 verbs in the NP V NP
PP.INSTRUMENT entailed movement on the part
of the instrument (Sally hit the ball with the stick)
– something not reflected in VerbNet.
</bodyText>
<sectionHeader confidence="0.992859" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999739818181818">
Results of Phase 1 provide support for the Seman-
tic Consistency Hypothesis, at least as a strong
bias. More work will be needed to determine the
strength of that bias. The findings are largely con-
sistent with VerbNet’s semantics, but changes are
indicated in some cases.
We find that inter-annotator agreement is suf-
ficiently high that annotation can be done effec-
tively using the modal response with an average
of 6-7 responses per item. We are currently in-
vestigating whether we can achieve better reliabil-
ity with fewer responses per item by taking into
account an individual annotator’s history across
items, as recent work suggests is possible (Passon-
neau and Carpenter, 2013; Rzhetsky et al., 2009;
Whitehill et al., 2009).
Thus, crowd-sourcing VerbNet semantic entail-
ments appears to be both feasible and productive.
Data-collection continues. Phase 2, which added
over 10 new verb classes, is complete. Phase 3,
which includes both new classes and new entail-
ments, has been launched.
</bodyText>
<sectionHeader confidence="0.997489" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.917197">
We gratefully acknowledge the support of the
National Science Foundation Grant NSF-IIS-
1116782, DARPA Machine Reading FA8750-09-
C-0179, and funding from the Ruth L. Kirschstein
National Research Service Award. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this material are those of the authors and
do not necessarily reflect the views of the National
Science Foundation.
4Note that this table was calculated based on whether the
semantic feature was present or not. In many cases, the data
was significantly richer. For instance, for APPLICATION OF
FORCE, annotators determined which participant in the event
was applying the force.
</bodyText>
<page confidence="0.998111">
401
</page>
<sectionHeader confidence="0.989643" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999756038461539">
Ben Ambridge, Julian Pine, Caroline Rowland,
Franklin Chang, and Amy Bidgood. 2013. The re-
treat from overgeneralization in child language ac-
quisition: word learning, morphology and verb ar-
gument structure. Wiley Interdisciplinary Reviews:
Cognitive Science, 4(1):47–62.
Libby Barak, Afsaneh Fazly, and Suzanne Steven-
son. 2012. Modeling the acquisition of mental
state verbs. In Proceedings of the 3rd Workshop on
Cognitive Modeling and Computational Linguistics,
pages 1–10. Association for Computational Linguis-
tics.
Leda Cosmides and John Tooby. 1992. Cognitive
adaptations for social exchange. The Adapted Mind,
pages 163–228.
Edward Gibson and Evelina Fedorenko. 2013. The
need for quantitative methods in syntax and seman-
tics research. Language and Cognitive Processes,
28(1-2):88–124.
Ana-Maria Giuglea and Alessandro Moschitti. 2006.
Shallow semantic parsing based on framenet, verb-
net and propbank. In Proceedings of the 217th
European Conference on Artificial Intelligence,
pages 563–567, Amsterdam, The Netherlands, The
Netherlands. IOS Press.
Lila Gleitman. 1990. The structural sources of verb
meanings. Language Acquisition, 1(1):3–55.
Adele E. Goldberg. 1995. Constructions: A Construc-
tion Grammar approach to argument structure. Uni-
versity of Chicago Press.
Eric Joanis, Suzanne Stevenson, and David James.
2008. A general feature space for automatic
verb classification. Natural Language Engineering,
14(3):337–367.
Beth Levin and Malka Rappaport Hovav. 2005. Argu-
ment Realization. Cambridge University Press.
Beth Levin. 1993. English Verb Classes and Alter-
nations: A preliminary Investigation. University of
Chicago press.
Diana Maynard, Adam Funk, and Wim Peters. 2009.
Using lexico-syntactic ontology design patterns for
ontology creation and population. In Proc. of the
Workshop on Ontology Patterns.
Christopher Parisien and Suzanne Stevenson. 2011.
Generalizing between form and meaning using
learned verb classes. In Proceedings of the 33rd An-
nual Meeting of the Cognitive Science Society. Cite-
seer.
Rebecca J Passonneau and Bob Carpenter. 2013. The
benefits of a model of annotation. In Proceedings of
the 7th Linguistic Annotation Workshop and Inter-
operability with Discourse, pages 187–195.
Steven Pinker. 1984. Language Learnability and Lan-
guage Development. Harvard University Press.
Steven Pinker. 1989. Learnability and Cognition: The
Acquisition of Argument Structure. MIT Press.
Massimo Poesio, Jon Chamberlain, Udo Kruschwitz,
Livio Robaldo, and Luca Ducceschi. 2012. The
phrase detective multilingual corpus, release 0.1. In
Collaborative Resource Development and Delivery
Workshop Programme, page 34.
Andrey Rzhetsky, Hagit Shatkay, and W John Wilbur.
2009. How to get the most out of your curation ef-
fort. PLoS Computational Biology, 5(5):1?13.
Robert S Swier and Suzanne Stevenson. 2004. Un-
supervised semantic role labeling. In Proceedings
of the Generative Lexicon Conference, volume 95,
page 102.
Jacob Whitehill, Paul Ruvolo, Tingfan Wu, Jacob
Bergsma, and Javier R Movellan. 2009. Whose vote
should count more: Optimal integration of labels
from labelers of unknown expertise. In Advances in
Neural Information Processing Systems, volume 22,
pages 2035–2043.
Annie Zaenen, Daniel G Bobrow, and Cleo Condo-
ravdi. 2008. The encoding of lexical implications in
verbnet: Predicates of change of locations. In Lan-
guage Resources Evaluation Conference.
</reference>
<page confidence="0.998604">
402
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.848593">
<title confidence="0.996554">The VerbCorner Project: Findings from Phase 1 of Crowd-Sourcing Semantic Decomposition of Verbs</title>
<author confidence="0.999946">K Joshua</author>
<affiliation confidence="0.998308">Department of Brain and Cognitive Massachusetts Institute of</affiliation>
<address confidence="0.947405">77 Massachusetts Cambridge, MA 02139,</address>
<email confidence="0.999913">jkhartshorne@gmail.com</email>
<abstract confidence="0.99776347368421">Any given verb can appear in some syntacframes broke the vase but not others broke at the broke the vase to There is now considerable evidence that the syntactic behaviors of some verbs can be predicted by their meanings, and many current theories posit that this is true for most if not all verbs. If true, this fact would have striking implications for theories and models of language acquisition, as well as numerous applications in natural language processing. However, empirical investigations to date have focused on a small number of verbs. We report on early results from VerbCorner, a crowd-sourced project extending this work to a large, representative sample of English verbs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ben Ambridge</author>
<author>Julian Pine</author>
<author>Caroline Rowland</author>
<author>Franklin Chang</author>
<author>Amy Bidgood</author>
</authors>
<title>The retreat from overgeneralization in child language acquisition: word learning, morphology and verb argument structure. Wiley Interdisciplinary Reviews:</title>
<date>2013</date>
<journal>Cognitive Science,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="7154" citStr="Ambridge et al., 2013" startWordPosition="1144" endWordPosition="1147">dditional examples were considered by the researcher goes unreported. In any case, to our knowledge, of the 280 syntactic verb classes listed by VerbNet, only a handful have been studied in any detail. The strongest evidence comes from experimental work on several so-called alternations (the passive, causative, locative, and dative alternations). Here, there does appear to be a systematic semantic distinction between the two syntactic frames in each alternation, at least most of the time. This has been tested with a reasonable sample of the relevant verbs and also in both children and adults (Ambridge et al., 2013; Pinker, 1989). However, the relevant verbs make up a tiny fraction of all English verbs, and even for these verbs, the syntactic frames in question represent only a fraction of the syntactic frames available to those verbs. This is not an accidental oversight. The limiting factor is scale: with many thousands of verbs and over a hundred commonly-discussed semantic features and syntactic frames, it is not feasible for a single researcher, or even team of researchers, to check which verbs appear in which syntactic frames and carry which semantic entailments. Collecting data from naive subjects</context>
</contexts>
<marker>Ambridge, Pine, Rowland, Chang, Bidgood, 2013</marker>
<rawString>Ben Ambridge, Julian Pine, Caroline Rowland, Franklin Chang, and Amy Bidgood. 2013. The retreat from overgeneralization in child language acquisition: word learning, morphology and verb argument structure. Wiley Interdisciplinary Reviews: Cognitive Science, 4(1):47–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libby Barak</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Modeling the acquisition of mental state verbs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 3rd Workshop on Cognitive Modeling and Computational Linguistics,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5459" citStr="Barak et al., 2012" startWordPosition="880" endWordPosition="883">E(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class. In principle, these judgments would come from naive annotators, since researchers’ intui</context>
</contexts>
<marker>Barak, Fazly, Stevenson, 2012</marker>
<rawString>Libby Barak, Afsaneh Fazly, and Suzanne Stevenson. 2012. Modeling the acquisition of mental state verbs. In Proceedings of the 3rd Workshop on Cognitive Modeling and Computational Linguistics, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leda Cosmides</author>
<author>John Tooby</author>
</authors>
<title>Cognitive adaptations for social exchange. The Adapted Mind,</title>
<date>1992</date>
<pages>163--228</pages>
<contexts>
<context position="9833" citStr="Cosmides and Tooby, 1992" startWordPosition="1561" endWordPosition="1564"> based on the empirical results. Integration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank. This amplifies the impact of any VerbCorner-inspired changes to VerbNet. 3.2 The Tasks We selected semantic features of interest based on those most commonly cited in the linguistics literature, with a particular focus on those that – according to VerbNet – apply to many predicates. Previous research has shown that humans find it easier to reason about real-world scenarios than make abstract judgments (Cosmides and Tooby, 1992). Thus, for each feature (e.g., MOVEMENT), we converted the metalinguistic judgment (“Does this verb entail movement on the part of some entity?”) into a real-world problem. For example, in “Simon Says Freeze,” a task designed to elicit judgments about movement, the Galactic Overlord (Simon) decrees “Galactic Stay Where You Are Day,” during which nobody is allowed to move from their current location. Participants read descriptions of events and decide whether anyone violated the rule. In “Explode on Contact,” designed to elicit judgments about physical contact, objects and people explode when </context>
</contexts>
<marker>Cosmides, Tooby, 1992</marker>
<rawString>Leda Cosmides and John Tooby. 1992. Cognitive adaptations for social exchange. The Adapted Mind, pages 163–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
<author>Evelina Fedorenko</author>
</authors>
<title>The need for quantitative methods in syntax and semantics research.</title>
<date>2013</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>28--1</pages>
<contexts>
<context position="6172" citStr="Gibson and Fedorenko, 2013" startWordPosition="990" endWordPosition="993">y-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class. In principle, these judgments would come from naive annotators, since researchers’ intuitions about subtle judgments may be unconsciously clouded by theoretical commitments (Gibson and Fedorenko, 2013). The Semantic Consistency Hypothesis would be supported if, within that database, predicates with the same syntactic properties were systematically related semantically. No such database exists, whether consisting of the judgments of linguists or naive annotators. Most theoretical studies report researcher judgments for only a handful of examples; how many additional examples were considered by the researcher goes unreported. In any case, to our knowledge, of the 280 syntactic verb classes listed by VerbNet, only a handful have been studied in any detail. The strongest evidence comes from exp</context>
</contexts>
<marker>Gibson, Fedorenko, 2013</marker>
<rawString>Edward Gibson and Evelina Fedorenko. 2013. The need for quantitative methods in syntax and semantics research. Language and Cognitive Processes, 28(1-2):88–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Giuglea</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Shallow semantic parsing based on framenet, verbnet and propbank.</title>
<date>2006</date>
<booktitle>In Proceedings of the 217th European Conference on Artificial Intelligence,</booktitle>
<pages>563--567</pages>
<publisher>IOS Press.</publisher>
<location>Amsterdam, The</location>
<contexts>
<context position="5638" citStr="Giuglea and Moschitti, 2006" startWordPosition="907" endWordPosition="910">me – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class. In principle, these judgments would come from naive annotators, since researchers’ intuitions about subtle judgments may be unconsciously clouded by theoretical commitments (Gibson and Fedorenko, 2013). The Semantic Consistency Hypothesis would be supported if, withi</context>
</contexts>
<marker>Giuglea, Moschitti, 2006</marker>
<rawString>Ana-Maria Giuglea and Alessandro Moschitti. 2006. Shallow semantic parsing based on framenet, verbnet and propbank. In Proceedings of the 217th European Conference on Artificial Intelligence, pages 563–567, Amsterdam, The Netherlands, The Netherlands. IOS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lila Gleitman</author>
</authors>
<title>The structural sources of verb meanings.</title>
<date>1990</date>
<journal>Language Acquisition,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="2912" citStr="Gleitman (1990)" startWordPosition="487" endWordPosition="488"> There is some set of semantic features such that verbs that share the same syntactic behavior are identical along those semantic features.2 Note that on certain accounts, this is a strong tendency rather than a strict necessity (e.g., Goldberg, 1995). It is widely recognized that a principled relationship between syntax and semantics would have broad implications. It is frequently invoked in theories of language acquisition. For instance, Pinker (1984, 1989) has described how this correspondence could solve long-standing puzzles about how children learn syntax in the first place. Conversely, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition. In fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be learnable at all. In computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications. We 1Note that this is a simplification in that there are noncausal verbs that appear in both the NP V NP frame and the NP V frame. For details, see (Levin, 1993). 2The</context>
</contexts>
<marker>Gleitman, 1990</marker>
<rawString>Lila Gleitman. 1990. The structural sources of verb meanings. Language Acquisition, 1(1):3–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adele E Goldberg</author>
</authors>
<title>Constructions: A Construction Grammar approach to argument structure.</title>
<date>1995</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2548" citStr="Goldberg, 1995" startWordPosition="434" endWordPosition="435"> such as hit and like do not describe a change of state and so cannot appear in both forms.1 Similarly, only verbs that describe propositional attitudes, such as like, can take a that complement (John liked that Sally broke the vase). 1.1 The Semantic Consistency Hypothesis This account has a natural consequence, which we dub the Semantic Consistency Hypothesis: There is some set of semantic features such that verbs that share the same syntactic behavior are identical along those semantic features.2 Note that on certain accounts, this is a strong tendency rather than a strict necessity (e.g., Goldberg, 1995). It is widely recognized that a principled relationship between syntax and semantics would have broad implications. It is frequently invoked in theories of language acquisition. For instance, Pinker (1984, 1989) has described how this correspondence could solve long-standing puzzles about how children learn syntax in the first place. Conversely, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition. In fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be lear</context>
</contexts>
<marker>Goldberg, 1995</marker>
<rawString>Adele E. Goldberg. 1995. Constructions: A Construction Grammar approach to argument structure. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
<author>David James</author>
</authors>
<title>A general feature space for automatic verb classification.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="5296" citStr="Joanis et al., 2008" startWordPosition="853" endWordPosition="856"> Syntax AGENT V THEME {+LOC|+DEST CONF} DESTINATION Semantics MOTION(DURING(E), THEME) NOT(PREP(START(E), THEME, DESTINATION)) PREP(END(E), THEME, DESTINATION) CAUSE(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of sema</context>
</contexts>
<marker>Joanis, Stevenson, James, 2008</marker>
<rawString>Eric Joanis, Suzanne Stevenson, and David James. 2008. A general feature space for automatic verb classification. Natural Language Engineering, 14(3):337–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
<author>Malka Rappaport Hovav</author>
</authors>
<title>Argument Realization.</title>
<date>2005</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1422" citStr="Levin and Hovav, 2005" startWordPosition="230" endWordPosition="233">. However, empirical investigations to date have focused on a small number of verbs. We report on early results from VerbCorner, a crowd-sourced project extending this work to a large, representative sample of English verbs. 1 Introduction Verbs vary in terms of which syntactic frames they can appear in (Table 1). In principle, this could be an unpredictable fact about the verb that must be acquired, much like the phonological form of the verb. However, most theorists posit that there is a systematic relationship between the semantics of a verb and the syntactic frames in which it can appear (Levin and Hovav, 2005). For instance, it is argued that verbs like break, which describe a Frame hit like break NP V NP x x x NP V - - x NP that S - x - NP V at NP x - - Table 1: Some of the syntactic frames available for hit, like, and break. Claire Bonial, Martha Palmer Department of Linguistics University of Colorado at Boulder Hellems 290, 295 UCB Boulder, CO 80309, USA {CBonial, MPalmer}@colorado.edu caused change of state, can appear in both the NP V NP form (Sally broke the vase) and the NP V form (The vase broke). Verbs such as hit and like do not describe a change of state and so cannot appear in both form</context>
</contexts>
<marker>Levin, Hovav, 2005</marker>
<rawString>Beth Levin and Malka Rappaport Hovav. 2005. Argument Realization. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: A preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago press.</publisher>
<contexts>
<context position="3506" citStr="Levin, 1993" startWordPosition="583" endWordPosition="584">y, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition. In fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be learnable at all. In computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications. We 1Note that this is a simplification in that there are noncausal verbs that appear in both the NP V NP frame and the NP V frame. For details, see (Levin, 1993). 2There is a long tradition of partitioning semantics into those aspects of meaning which are “grammatically relevant” and those which are not. We refer the interested reader to Pinker (1989), Jackendoff (1990), and Levin &amp; Rappaport Hovav (2005). 397 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 397–402, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics describe in detail one such resource, VerbNet, which is highly relevant to our investigation. 1.2 VerbNet VerbNet (Kipper et al., 2008; </context>
<context position="10937" citStr="Levin, 1993" startWordPosition="1740" endWordPosition="1741"> “Explode on Contact,” designed to elicit judgments about physical contact, objects and people explode when they touch one another. The participant reads descriptions of events and decides whether anything has exploded. Note that each task is designed to elicit judgments about entailments – things that must be true rather than are merely likely to be true. If John greeted Bill, they might have come into contact (e.g., by shaking hands), but perhaps they did not. Previous work suggests that it is the semantic entailments that matter, particularly for explaining the syntactic behavior of verbs (Levin, 1993). 3.3 The Items The exact semantics associated with a verb may depend on its syntactic frame. Thus Sally rolled the ball entails that somebody applied force to the ball (namely: Sally), whereas The ball rolled does not. Thus, we investigate the semantics of each verb in each syntactic frame available to it (as described by VerbNet). Below, the term item is the unit of annotation: a verb in a frame. In order to minimize unwanted effects of world knowledge, the verb’s arguments are replaced with nonsense words or randomly chosen proper names (Sally sprayed the dax onto the blicket). The use of n</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations: A preliminary Investigation. University of Chicago press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Maynard</author>
<author>Adam Funk</author>
<author>Wim Peters</author>
</authors>
<title>Using lexico-syntactic ontology design patterns for ontology creation and population.</title>
<date>2009</date>
<booktitle>In Proc. of the Workshop on Ontology Patterns.</booktitle>
<contexts>
<context position="5347" citStr="Maynard et al., 2009" startWordPosition="861" endWordPosition="864">N Semantics MOTION(DURING(E), THEME) NOT(PREP(START(E), THEME, DESTINATION)) PREP(END(E), THEME, DESTINATION) CAUSE(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of semantic judgments for a comprehensive set of verbs fro</context>
</contexts>
<marker>Maynard, Funk, Peters, 2009</marker>
<rawString>Diana Maynard, Adam Funk, and Wim Peters. 2009. Using lexico-syntactic ontology design patterns for ontology creation and population. In Proc. of the Workshop on Ontology Patterns.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Parisien</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Generalizing between form and meaning using learned verb classes.</title>
<date>2011</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Cognitive</booktitle>
<publisher>Science Society. Citeseer.</publisher>
<contexts>
<context position="5438" citStr="Parisien and Stevenson, 2011" startWordPosition="876" endWordPosition="879">D(E), THEME, DESTINATION) CAUSE(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, ideally there would be some database of semantic judgments for a comprehensive set of verbs from each syntactic class. In principle, these judgments would come from naive annotators, sin</context>
</contexts>
<marker>Parisien, Stevenson, 2011</marker>
<rawString>Christopher Parisien and Suzanne Stevenson. 2011. Generalizing between form and meaning using learned verb classes. In Proceedings of the 33rd Annual Meeting of the Cognitive Science Society. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passonneau</author>
<author>Bob Carpenter</author>
</authors>
<title>The benefits of a model of annotation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,</booktitle>
<pages>187--195</pages>
<contexts>
<context position="19026" citStr="Passonneau and Carpenter, 2013" startWordPosition="3121" endWordPosition="3125">c Consistency Hypothesis, at least as a strong bias. More work will be needed to determine the strength of that bias. The findings are largely consistent with VerbNet’s semantics, but changes are indicated in some cases. We find that inter-annotator agreement is sufficiently high that annotation can be done effectively using the modal response with an average of 6-7 responses per item. We are currently investigating whether we can achieve better reliability with fewer responses per item by taking into account an individual annotator’s history across items, as recent work suggests is possible (Passonneau and Carpenter, 2013; Rzhetsky et al., 2009; Whitehill et al., 2009). Thus, crowd-sourcing VerbNet semantic entailments appears to be both feasible and productive. Data-collection continues. Phase 2, which added over 10 new verb classes, is complete. Phase 3, which includes both new classes and new entailments, has been launched. Acknowledgments We gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS1116782, DARPA Machine Reading FA8750-09- C-0179, and funding from the Ruth L. Kirschstein National Research Service Award. Any opinions, findings, and conclusions or recommendations exp</context>
</contexts>
<marker>Passonneau, Carpenter, 2013</marker>
<rawString>Rebecca J Passonneau and Bob Carpenter. 2013. The benefits of a model of annotation. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 187–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Language Learnability and Language Development.</title>
<date>1984</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="2753" citStr="Pinker (1984" startWordPosition="464" endWordPosition="465">hat Sally broke the vase). 1.1 The Semantic Consistency Hypothesis This account has a natural consequence, which we dub the Semantic Consistency Hypothesis: There is some set of semantic features such that verbs that share the same syntactic behavior are identical along those semantic features.2 Note that on certain accounts, this is a strong tendency rather than a strict necessity (e.g., Goldberg, 1995). It is widely recognized that a principled relationship between syntax and semantics would have broad implications. It is frequently invoked in theories of language acquisition. For instance, Pinker (1984, 1989) has described how this correspondence could solve long-standing puzzles about how children learn syntax in the first place. Conversely, Gleitman (1990) has shown such a syntax-semantics relationship could solve significant problems in vocabulary acquisition. In fact, both researchers argue that a principled relationship between syntax and semantics is necessary for language to be learnable at all. In computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications. We 1Note</context>
</contexts>
<marker>Pinker, 1984</marker>
<rawString>Steven Pinker. 1984. Language Learnability and Language Development. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Learnability and Cognition: The Acquisition of Argument Structure.</title>
<date>1989</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3698" citStr="Pinker (1989)" startWordPosition="613" endWordPosition="614">tween syntax and semantics is necessary for language to be learnable at all. In computational linguistics and natural language processing, some form of the Semantic Consistency Hypothesis is often included in linguistic resources and utilized in applications. We 1Note that this is a simplification in that there are noncausal verbs that appear in both the NP V NP frame and the NP V frame. For details, see (Levin, 1993). 2There is a long tradition of partitioning semantics into those aspects of meaning which are “grammatically relevant” and those which are not. We refer the interested reader to Pinker (1989), Jackendoff (1990), and Levin &amp; Rappaport Hovav (2005). 397 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 397–402, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics describe in detail one such resource, VerbNet, which is highly relevant to our investigation. 1.2 VerbNet VerbNet (Kipper et al., 2008; based on Levin, 1993) lists over 6,000 verbs, categorized into 280 classes according to the syntactic frames they can appear in. That is, all verbs in the same class appear in the same set of </context>
<context position="7169" citStr="Pinker, 1989" startWordPosition="1148" endWordPosition="1149"> considered by the researcher goes unreported. In any case, to our knowledge, of the 280 syntactic verb classes listed by VerbNet, only a handful have been studied in any detail. The strongest evidence comes from experimental work on several so-called alternations (the passive, causative, locative, and dative alternations). Here, there does appear to be a systematic semantic distinction between the two syntactic frames in each alternation, at least most of the time. This has been tested with a reasonable sample of the relevant verbs and also in both children and adults (Ambridge et al., 2013; Pinker, 1989). However, the relevant verbs make up a tiny fraction of all English verbs, and even for these verbs, the syntactic frames in question represent only a fraction of the syntactic frames available to those verbs. This is not an accidental oversight. The limiting factor is scale: with many thousands of verbs and over a hundred commonly-discussed semantic features and syntactic frames, it is not feasible for a single researcher, or even team of researchers, to check which verbs appear in which syntactic frames and carry which semantic entailments. Collecting data from naive subjects is even more l</context>
</contexts>
<marker>Pinker, 1989</marker>
<rawString>Steven Pinker. 1989. Learnability and Cognition: The Acquisition of Argument Structure. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Jon Chamberlain</author>
<author>Udo Kruschwitz</author>
<author>Livio Robaldo</author>
<author>Luca Ducceschi</author>
</authors>
<title>The phrase detective multilingual corpus, release 0.1.</title>
<date>2012</date>
<booktitle>In Collaborative Resource Development and Delivery Workshop Programme,</booktitle>
<pages>34</pages>
<contexts>
<context position="8813" citStr="Poesio et al., 2012" startWordPosition="1399" endWordPosition="1402">e data can be used to test the Semantic Consistency Hypothesis. 3http://gameswithwords.org/VerbCorner/ 398 Independent of the validity of that hypothesis, the semantic judgments themselves should prove useful for any study of linguistic meaning or related application. We address the issue of scale through crowdsourcing: Recruiting large numbers of volunteers, each of whom may provide only a few annotations. Several previous projects have successfully crowd-sourced linguistic annotations, such as Phrase Detectives, where volunteers have contributed 2.5 million judgments on anaphoric relations (Poesio et al., 2012). 3.1 Integration with VerbNet One significant challenge for any such project is first classifying verbs according to the syntactic frames they can appear in. Thus, at least initially, we are focusing on the 6,000+ verbs already cataloged in VerbNet. As such, the VerbCorner Project is also verifying and validating the semantics currently encoded in VerbNet. VerbNet will be edited as necessary based on the empirical results. Integration with VerbNet has additional benefits, since VerbNet itself is integrated with a variety of linguistic resources, such as PropBank and Penn TreeBank. This amplif</context>
</contexts>
<marker>Poesio, Chamberlain, Kruschwitz, Robaldo, Ducceschi, 2012</marker>
<rawString>Massimo Poesio, Jon Chamberlain, Udo Kruschwitz, Livio Robaldo, and Luca Ducceschi. 2012. The phrase detective multilingual corpus, release 0.1. In Collaborative Resource Development and Delivery Workshop Programme, page 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrey Rzhetsky</author>
<author>Hagit Shatkay</author>
<author>W John Wilbur</author>
</authors>
<title>How to get the most out of your curation effort.</title>
<date>2009</date>
<journal>PLoS Computational Biology,</journal>
<volume>5</volume>
<issue>5</issue>
<contexts>
<context position="19049" citStr="Rzhetsky et al., 2009" startWordPosition="3126" endWordPosition="3129">st as a strong bias. More work will be needed to determine the strength of that bias. The findings are largely consistent with VerbNet’s semantics, but changes are indicated in some cases. We find that inter-annotator agreement is sufficiently high that annotation can be done effectively using the modal response with an average of 6-7 responses per item. We are currently investigating whether we can achieve better reliability with fewer responses per item by taking into account an individual annotator’s history across items, as recent work suggests is possible (Passonneau and Carpenter, 2013; Rzhetsky et al., 2009; Whitehill et al., 2009). Thus, crowd-sourcing VerbNet semantic entailments appears to be both feasible and productive. Data-collection continues. Phase 2, which added over 10 new verb classes, is complete. Phase 3, which includes both new classes and new entailments, has been launched. Acknowledgments We gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS1116782, DARPA Machine Reading FA8750-09- C-0179, and funding from the Ruth L. Kirschstein National Research Service Award. Any opinions, findings, and conclusions or recommendations expressed in this material</context>
</contexts>
<marker>Rzhetsky, Shatkay, Wilbur, 2009</marker>
<rawString>Andrey Rzhetsky, Hagit Shatkay, and W John Wilbur. 2009. How to get the most out of your curation effort. PLoS Computational Biology, 5(5):1?13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert S Swier</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Unsupervised semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the Generative Lexicon Conference,</booktitle>
<volume>95</volume>
<pages>102</pages>
<contexts>
<context position="5218" citStr="Swier and Stevenson, 2004" startWordPosition="841" endWordPosition="844">hown below: Syntactic Frame NP V NP PP.DESTINATION Example Jessica sprayed the wall. Syntax AGENT V THEME {+LOC|+DEST CONF} DESTINATION Semantics MOTION(DURING(E), THEME) NOT(PREP(START(E), THEME, DESTINATION)) PREP(END(E), THEME, DESTINATION) CAUSE(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on</context>
</contexts>
<marker>Swier, Stevenson, 2004</marker>
<rawString>Robert S Swier and Suzanne Stevenson. 2004. Unsupervised semantic role labeling. In Proceedings of the Generative Lexicon Conference, volume 95, page 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Whitehill</author>
<author>Paul Ruvolo</author>
<author>Tingfan Wu</author>
<author>Jacob Bergsma</author>
<author>Javier R Movellan</author>
</authors>
<title>Whose vote should count more: Optimal integration of labels from labelers of unknown expertise.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>22</volume>
<pages>2035--2043</pages>
<contexts>
<context position="19074" citStr="Whitehill et al., 2009" startWordPosition="3130" endWordPosition="3133">re work will be needed to determine the strength of that bias. The findings are largely consistent with VerbNet’s semantics, but changes are indicated in some cases. We find that inter-annotator agreement is sufficiently high that annotation can be done effectively using the modal response with an average of 6-7 responses per item. We are currently investigating whether we can achieve better reliability with fewer responses per item by taking into account an individual annotator’s history across items, as recent work suggests is possible (Passonneau and Carpenter, 2013; Rzhetsky et al., 2009; Whitehill et al., 2009). Thus, crowd-sourcing VerbNet semantic entailments appears to be both feasible and productive. Data-collection continues. Phase 2, which added over 10 new verb classes, is complete. Phase 3, which includes both new classes and new entailments, has been launched. Acknowledgments We gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS1116782, DARPA Machine Reading FA8750-09- C-0179, and funding from the Ruth L. Kirschstein National Research Service Award. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors</context>
</contexts>
<marker>Whitehill, Ruvolo, Wu, Bergsma, Movellan, 2009</marker>
<rawString>Jacob Whitehill, Paul Ruvolo, Tingfan Wu, Jacob Bergsma, and Javier R Movellan. 2009. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In Advances in Neural Information Processing Systems, volume 22, pages 2035–2043.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Zaenen</author>
<author>Daniel G Bobrow</author>
<author>Cleo Condoravdi</author>
</authors>
<title>The encoding of lexical implications in verbnet: Predicates of change of locations.</title>
<date>2008</date>
<booktitle>In Language Resources Evaluation Conference.</booktitle>
<contexts>
<context position="5253" citStr="Zaenen et al., 2008" startWordPosition="846" endWordPosition="849">STINATION Example Jessica sprayed the wall. Syntax AGENT V THEME {+LOC|+DEST CONF} DESTINATION Semantics MOTION(DURING(E), THEME) NOT(PREP(START(E), THEME, DESTINATION)) PREP(END(E), THEME, DESTINATION) CAUSE(AGENT, E) Importantly, the semantics listed here is not just for the verb spray but applies to all verbs from the Spray Class whenever they appear in that syntactic frame – that is, VerbNet assumes the Semantic Consistency Hypothesis. VerbNet and its semantic features have been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al., 2008), verb classification (Joanis et al., 2008), and information extraction (Maynard et al., 2009). It has also been employed in models of language acquisition (Parisien and Stevenson, 2011; Barak et al., 2012). In general, there has been interest in the NLP literature in using these syntactially-relevant semantic features for shallow semantic parsing (e.g., Giuglea and Moschitti, 2006). 2 Empirical Status of the Semantic Consistency Hypothesis Given the prominence of the Semantic Consistency Hypothesis in both theory and practice, one might expect that it was on firm empirical footing. That is, i</context>
</contexts>
<marker>Zaenen, Bobrow, Condoravdi, 2008</marker>
<rawString>Annie Zaenen, Daniel G Bobrow, and Cleo Condoravdi. 2008. The encoding of lexical implications in verbnet: Predicates of change of locations. In Language Resources Evaluation Conference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>