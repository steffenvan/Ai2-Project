<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.094376">
<title confidence="0.9994745">
Text Generation for Brazilian Portuguese:
the Surface Realization Task
</title>
<author confidence="0.997885">
Eder Miranda de Novais Thiago Dias Tadeu Ivandré Paraboni
</author>
<affiliation confidence="0.998281">
University of São Paulo - School of Arts, Sciences and Humanities (USP-EACH)
</affiliation>
<address confidence="0.867457">
Av. Arlindo Bettio, 1000, Ermelino Matarazzo
São Paulo, Brazil - 03828-000
</address>
<email confidence="0.998403">
eder.novais@usp.br tdtadeu@gmail.com ivandre@usp.br
</email>
<sectionHeader confidence="0.995641" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994648">
Despite the growing interest in NLP focused
on the Brazilian Portuguese language in recent
years, its obvious counterpart – Natural Lan-
guage Generation (NLG) – remains in that
case a little-explored research field. In this
paper we describe preliminary results of a first
project of this kind, addressing the issue of
surface realization for Brazilian Portuguese.
Our approach, which may be particularly suit-
able to simpler NLG applications in which a
domain corpus of the most likely output sen-
tences happens to be available, is in principle
adaptable to many closely-related languages,
and paves the way to further NLG research
focused on Romance languages in general.
</bodyText>
<sectionHeader confidence="0.999088" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999211444444445">
Data-to-Text Natural Language Generation (NLG)
systems produce text or speech from a given non-
linguistic input. Systems of this kind usually fol-
low a pipelined architecture (Reiter, 2007) com-
prising data interpretation, document planning,
sentence planning and surface realization tasks. In
this work we discuss the latter, that is, the task of
producing surface word strings from a non-
linguistic input specification.
Existing approaches to surface realization may
vary greatly in their input requirements and, con-
sequently, in the level of control over the output
text. On the one hand, more sophisticated, gram-
mar-based surface realization systems such as
KPML (Bateman, 1997) allow maximum flexibili-
ty and productive coverage. These advantages,
however, are only useful if the underlying applica-
tion is capable of providing a detailed semantic
specification as an input to the surface realization
module in the first place.
As an alternative to surface realization gram-
mars, NLG systems may also rely on template-
based surface realization, that is, the use of prede-
fined structures with a number of variable fields
(or slots) to be filled in with values provided by the
application. For a comparison between templates
and other approaches to NLG, see for instance van
Deemter et. al. (2005).
Adapting an existing application to a template-
based realization system is usually much simpler
than in a grammar-based approach. Yet, in order to
take full advantage of template definitions and to
obtain a degree of control over the output text that
is comparable to what a grammar-based system
would allow, it is still necessary to master the use
of templates and their rules to fill in each slot ade-
quately.
The problem of input specification to surface
realization has been discussed at length in the lite-
rature in the field - see for example Langkilde
(2000) – and we of course do not dispute that more
sophisticated NLG systems will require a detailed
input specification. However, given that the avail-
able semantics may not be provide in this level of
detail, in this paper we discuss an alternative that
</bodyText>
<page confidence="0.992751">
125
</page>
<note confidence="0.92672">
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 125–131, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999904826923077">
may be suitable to simpler applications, namely,
those cases in which it is known in advance what
the most likely output sentence structures are, for
example, because a corpus on that particular do-
main happens to be available. In these cases, we
will argue that it may be possible to take advantage
of the available knowledge to quickly deploy a
surface realization component based on existing
corpora.
The underlying assumption in our work is that
there are simpler NLG applications for which it
may be sufficient to select a sentence that resem-
bles the desired output, and then modify some or
all of its constituents as needed to achieve the de-
sired output. For instance, an application that is not
linguistically-oriented may produce its output re-
sults as natural language text by selecting a stan-
dard imperative sentence as in “Please reply to this
message” and, leaving all other sentence constitu-
ents unchanged, specify that the action to be rea-
lized in the output is “delete”, and that its patient
object is “file”. This will have the effect of produc-
ing the output sentence “Please delete this file”.
In this introductory work we intend to outline
our ongoing efforts to develop one such approach
to surface realization for the Brazilian Portuguese
language. In doing so, we shall focus on the gener-
al principles that guide our research, leaving much
of the theoretical details to be discussed elsewhere.
The present work has been developed within the
context of a query-and-answer application under
investigation, in which questions sent by undergra-
duate students enrolled in a particular course will
be matched to existing entries in a large database
of standard replies written by the professors in
charge to the most frequently asked questions
made by the students, and tailored to each particu-
lar context accordingly. Details of this particular
application will not be dealt with in this paper ei-
ther.
The reminder of this paper is structured as fol-
lows. Section 2 briefly discusses related work on
surface realization; Section 3 provides an overview
of our system’s architecture; Sections 4 describes
the extraction of syntactically-structured templates
from a target corpus and Section 5 presents the
current features of our template-based surface rea-
lization engine. Finally, Section 6 draws prelimi-
nary conclusions and describes ongoing work, and
Section 7 hints at possible collaboration with the
wider NLP research community in Latin America
and elsewhere.
</bodyText>
<sectionHeader confidence="0.998695" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999861043478261">
Mapping an application semantics to surface
strings usually involves the use of surface realiza-
tion grammars or similar resources, which can be
either built manually (e.g., Bateman, 1997) or ac-
quired automatically from a corpus (Ratnaparkhi,
2000; Zhong &amp; Stent, 2005; DeVault et. al., 2008).
The surface realization task proper can be di-
vided into two relatively independent procedures: a
domain-dependant mapping from the application
semantics onto linguistic structures (including,
e.g., lexical choice), and a language-oriented task
of linearization. As pointed out in Gatt &amp; Reiter
(2009), most of the existing systems tend to per-
form both tasks, but in some cases they focus on
the latter, assuming that all lexical choices and
other domain-dependent decisions have already
been made. This is the case for example of Sim-
pleNLG (Gatt &amp; Reiter, 2009), a surface realiza-
tion engine implemented as a Java library for
sentence linearization.
Central to the development and use of a surface
realization system is the kind of input specification
that will be expected from the application. In order
to take full advantage of grammar-based surface
realization, it is usually necessary to provided de-
tailed linguistic knowledge as an input. This is the
case, for example, of a number of corpus-based
approaches to grammar acquisition, which may
take logical forms as an input (e.g., Smets et. al.,
2003; Zhong &amp; Stent, 2005; Marciniak &amp; Strube,
2005). The Amalgam system, for instance (Smets
et. al., 2003), takes as an input a graph conveying
fixed content words (lemmas) and detailed linguis-
tic information such as verb tense and mode, gend-
er, number and definiteness of all its constituents,
and additional semantic features (e.g., ‘human’,
‘animated’ etc.)
Detailed input specification as required in
grammar-based surface realization is however of-
ten unavailable from the semantics of the applica-
tion. As an alternative, template-based surface
realization makes use of predefined structures
(e.g., syntactically-structured sentence templates)
with slots to be filled in with values provided by
the application. A prominent example of template-
based surface realization system is YAG (McRoy
</bodyText>
<page confidence="0.992927">
126
</page>
<bodyText confidence="0.999503444444444">
et. al., 2003), which may accept both feature struc-
tures and propositional semantics as an input. The
following is an example of input feature structure
in YAG, taken from McRoy et. al. (2003). In this
example, the structure represents the fact that a
discourse subject (George) performs an act (under-
stand) on a particular object (a book), in which
both subject and object happened to be realized as
pronouns as “He understands it”.
</bodyText>
<figure confidence="0.9900996">
((template clause
(process “understand”)
(agent ((template noun-phrase)
(np-type PROPER)
(head “George”)
(gender MASCULINE)
(pronominal YES)))
(object ((template noun-phrase)
(head “book”)
(pronominal YES))) )
</figure>
<subsectionHeader confidence="0.928609">
Input feature structure in YAG.
</subsectionHeader>
<bodyText confidence="0.999987571428572">
The input requirements of a template-based sur-
face realization system are obviously much simpler
– and more likely to be available from the applica-
tion – than a full set of linguistic instructions on
how to generate the desired output. Still, in this
work we would like to produce surface strings us-
ing even less knowledge, namely, by using sen-
tence-level templates extracted from a domain
corpus as a basis to generate original and modified
versions of the corpus sentences.
We will refer to this as an example-based ap-
proach to surface realization1, although this is not
to be mistaken for example-based learning tech-
niques to perform automatic grammar induction as
in DeVault et. al., (2008), or other forms of gram-
mar acquisition as in Zhong &amp; Stent (2005). Our
work is more related to Ratnaparkhi (2000) in the
sense that we also use a large collection of genera-
tion templates for surface realization, but still dis-
tinct in that we intend to generate text from
minimal input.
</bodyText>
<sectionHeader confidence="0.976796" genericHeader="method">
3 Project Overview
</sectionHeader>
<bodyText confidence="0.986450543859649">
Template-based surface realization systems such as
YAG (McRoy et. al., 2003) make use of a relative-
ly small number of template definitions and some
kind of descriptive language to provide fine-
grained input sentence specification with flexibility
1 Perhaps ‘select-and-modify’ would be closer to our current
purposes.
and wide coverage. However, if a corpus on the
application domain happens to be available, and
assuming that the corpus sentences resemble those
that we intend to generate, then it may be conve-
nient (at least for applications that are not linguisti-
cally-motivated in the first place) to simply use the
corpus sentences as examples, and allow an input
specification that makes explicit only the changes
that need to take place to convert the selected ex-
ample into the desired output.
For example, in order to produce the sentence
“He understands it” we may select an example
such as “People will understand it” from the cor-
pus, and then redefine its agent head type as a pro-
noun, and its action tense as present. The
difference may not seem so dramatic if compared
to, e.g., an input specification to YAG, but it will
obviously grow as more complex sentence struc-
tures are considered.
If the selected example differs greatly from the
target sentence, then a large number of modifica-
tions will have to take place, and in that case our
example-based approach may not seem very use-
ful. On the other hand, if the corpus is representa-
tive of the sentences that are likely to be generated,
then little or no additional modifications will be
required, in which case new sentences may be gen-
erated indeed from a minimally specified input. In
either case, we notice that since the examples are
represented directly in natural language in the cor-
pus, new instances can be easily added to expand
the system coverage.
In our present approach to the surface realization
task, syntactically-structured templates are selected
from a target corpus on the application domain and
used as a basis to produce original and modified
versions of the corpus sentences by a combination
of canned text and basic dependency-tree opera-
tions. Each sentence in the target corpus makes a
sentence template in which the agent, patient and
action constituents may be modified or replaced by
the application by combining lower-order tem-
plates (e.g., for NPs and VPs), and new sentences
may be supported by adding the corresponding
examples directly to the corpus.
Our current work can be divided into two main
tasks: the extraction of syntactically-structured
templates from corpora and the actual development
of the surface realization engine. The following
sections 4 and 5 discuss each of these tasks in turn.
</bodyText>
<page confidence="0.995144">
127
</page>
<sectionHeader confidence="0.99322" genericHeader="method">
4 Template Extraction
</sectionHeader>
<bodyText confidence="0.999838808988765">
Using a collection of emails sent to undergraduate
students by their professors in reply to their most
frequent questions regarding a particular project,
we developed a database conveying 597 instances
of surface realization templates for Brazilian Por-
tuguese NLG as follows.
After sentence segmentation, the corpus was
tagged and parsed using PALAVRAS (Bick,
2000). A number of critical parsing errors were
removed, and thus we arrived at a set of 578 sen-
tence-level templates represented in XML format.
In our example-based approach to surface reali-
zation we consider two kinds of structure: sentence
and constituent templates. Sentence templates are
high-level representations of the sample sentences
taken from our target corpus, and they contain a
number of variable fields (the constituents) to be
filled in with application data (in most cases hav-
ing an agent, action and patient fields.)
Everything else within the sentence is simply
canned text as seen in the corpus, and cannot be
modified by the application. In other words, if the
application needs to generate a sentence that dif-
fers from the template in any constituent other than
its NPs and VPs, it is necessary to define a new
template by adding a new example to the corpus.
Sentence templates are highly redundant in the
sense that many of them keep a similar syntactic
structure in which only the surrounding text might
change significantly. For example, many sentence
templates in our domain represent a simple piece
of advice in the form agent + action followed by
some canned text, as in “You should enroll by Fri-
day” and “All smokers are supposed to quit by the
end of the month”.
Although we could have defined a smaller (and
more flexible) set of templates by generalizing
over these structures, in practice this would in-
crease the complexity of the required input (e.g.,
with the addition of a ‘time’ field to a common
template to be shared by both examples above.) As
mentioned in the previous section, we intend to
keep input specification as simple as possible (i.e.,
in natural language format) by allowing the target
sentences to be specified directly in the corpus.
The contents of the variable fields in a sentence
template act as default values for the surface reali-
zation algorithm, and they may be changed indivi-
dually (e.g., by setting a different tense or gender
value for a particular field) or replaced by another
constituent template entirely. We notice that de-
fault values are acquired automatically from corpo-
ra, i.e., they do not need to be hard-coded as in
McRoy et. al., (2003).
Unlike sentence templates, constituent templates
are not extracted from corpora. Instead, constitu-
ents are dependency-trees generated by a small set
of grammar rules that covers the instances of VPs
and NPs found in our corpus, including support to
relative clauses and the most common forms of PP
attachment. The choice for a grammar representa-
tion for the more fine-grained constituents was
mainly motivated by the need to achieve wider
coverage and to support linguistic variation beyond
what the actual phrases found in the corpus would
allow. In doing so we are able to fill in sentence
templates with phrases of arbitrary complexity, as
in the NP “You should enroll by the end of the
month in which you are expected to complete your
current assignment”, and not simply using those
NPs found in the target corpus.
The set of mappings from domain concepts to
their dependency-trees (i.e., constituent templates)
makes a dictionary of realizations in the applica-
tion domain. As in related work in the field (e.g.,
Gatt &amp; Reiter, 2009), we presently assume that the
actual mappings are to be provided by the applica-
tion.
Concept-to-strings mappings are usually
handcrafted, but may also be acquired automatical-
ly from corpora, as in Bangalore &amp; Rambow
(2000). For testing purposes, we have extracted
1,548 instances of concept-to-string mappings
from the target corpus, being 1,298 mappings from
agent/patient entities to descriptions, pronouns and
proper names, and 250 mappings from actions to
VPs, even though many of them will not be of
practical use from the point of view of our in-
tended application.
</bodyText>
<sectionHeader confidence="0.984841" genericHeader="method">
5 Surface Realization
</sectionHeader>
<bodyText confidence="0.999937125">
Using the template definitions from the previous
section, we designed a simple corpus-based surface
realization component for our ongoing project.
Our surface realization module is currently able
to accept as an input a template id (to be taken as a
sample structure with inherited default values for
the output sentence) and, optionally, parameters
representing the alternative semantics of its agent,
</bodyText>
<page confidence="0.996406">
128
</page>
<bodyText confidence="0.999843909090909">
patient and action constituents. Alternatively, it is
also possible to specify a sentence from scratch
(that is, without using any existing template as a
basis) in a standard NP VP NP format. The latter
choice was added to the system as we noticed that
simpler sentence structures may be specified more
conveniently in this way, as opposed to looking up
an example in the corpus. In our project, this is the
case of short reply sentences as in “Yes, of
course”, “Thank you” and others, in which there is
hardly any point in selecting a template from the
corpus and then commanding the required changes.
The underlying application selects a target tem-
plate and provides a set of values to fill in the tem-
plate variable fields. These input values overwrite
the default values provided by the template (that is,
those values that were inherited from the corpus
data) and adjusted by basic agreement rules to
reestablish grammaticality if necessary, as we will
discuss later.
The currently supported variable fields for NPs
are determiner type, gender, number, person, de-
terminer lemma, pre and post modifiers, the NP
head, an attached pp-list and relative clause (which
may recursively convey NPs within themselves.)
As for VPs, the variable fields are VP type (finite
vs. infinite etc.), person, mode, verb type, verb
tense and adverbial modifiers. Verbal gender and
number are not specified directly but simply inhe-
rited from the subject’s own data to avoid a possi-
bly conflicting input specification.
The most obvious limitation to this kind of ap-
proach is the case in which there is a need to gen-
erate a sentence that does not resemble any
example in the corpus at all. Yet again, we notice
that this difficulty may be overcome by simply
adding a natural language example directly to the
corpus, a method that is arguably simpler than pro-
viding detailed instructions on how to select and
combine template structures in a traditional tem-
plate-based approach, and even simpler than pro-
viding a full sentence specification in grammar-
based surface realization.
The following is a complete example of how the
example-based approach is expected to work. In its
simplest form, the application may select the re-
quired template to produce the desired output ver-
batim as in (a); with some extra knowledge
available, the application may also change some of
the values of the variable template fields as in (b);
finally, with even more complete linguistic know-
ledge available, the original structure may be
changed even further as in (c), in which case only
the original sentence structure remained (besides
the canned text component “on Friday”).
</bodyText>
<figure confidence="0.841229375">
Input Expected output
(a) template #17 [You]agent
[should deliver]action
[your results]patient
on Friday.
(b) template #17, [You]agent
patient=essay, [did not complete]action
action=not_complete [your essay]patient
on Friday.
(c) template #17, [Our teacher]agent
agent=teacher, [will give]action
determiner=possess, [a talk]patient
action=give, on Friday.
tense=future,
patient=talk,
determiner=indefinite
</figure>
<tableCaption confidence="0.9175315">
Table 1. Examples of (semantic) input and expected
(surface text) output.
</tableCaption>
<bodyText confidence="0.999855545454546">
Depending on the changes in the constituent
values requested by the application, a number of
agreement rules may be invoked to re-establish
fluency and grammaticality. In our work this is
aided by a Brazilian Portuguese lexicon presented
in Muniz et. al. (2005) and a thesaurus. For exam-
ple, if a sentence template as (d) below is selected,
and then the value of the agent head field is
changed to represent a singular concept as in (e),
agreement rules are required to modify the verb
number as in (f).
</bodyText>
<listItem confidence="0.992996">
(d) [All students]agent [have submitted]action
[their papers]patient
(e) [Your teacher] agent [#have submitted]action
[their papers]patient
(f) [Your teacher] agent [has submitted]action
[their papers]patient
</listItem>
<tableCaption confidence="0.960671">
Table 2. An original example (d) reused with a new
agent head value (e) and agreement (f).
</tableCaption>
<bodyText confidence="0.9772445">
More complex or fine-grained dependencies
(e.g., the anaphoric reference ‘their’ in Table 2
</bodyText>
<page confidence="0.997147">
129
</page>
<bodyText confidence="0.999893272727273">
above) are not currently implemented. One possi-
ble approach to this is a standard generate-and-
select approach to NLG as in Langkilde (2000), Oh
&amp; Rudnicky (2000) and others. More specifically,
we may over-generate all possible realization al-
ternatives and then use a statistical language model
to select the most likely output. In our work we
intend to apply a similar approach also to handle
the lexical choice task, i.e., by selecting the most
likely wording for each concept based on a lan-
guage model.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999784425531915">
In this paper we have described a simple approach
to surface realization based on the reuse of syntac-
tically-structured templates acquired from corpora.
Although not nearly as flexible as a full NLG ap-
proach, our system may represent a straightforward
solution to the problem of input specification,
which in our case is simply based on natural lan-
guage. Our corpus-based approach is able to gen-
erate single sentences from an input conveying
various degrees of semantic knowledge, which
may be suitable to a wide range of NLG applica-
tions that are able to support only less detailed in-
put specification.
Much of the present work is however to be re-
garded as tentative. One major issue that is yet to
be discussed is how far we can go with an exam-
ple-based approach to surface realization without
compromising the quality of the output text. For
instance, it is not clear what it means for the NLG
system if the application selects a sentence tem-
plate that (in Portuguese) does not have a subject
field (e.g., “Please send it now”) and then attempts
to specify a subject. A similar conflict arises, for
example, if the application specifies an action that
is semantically incompatible with the selected
template, in which case the output sentence could
become ungrammatical. In both cases, we believe
that more research is still needed.
Being currently functional at a prototype level
only, our system is undergoing a number of im-
provements. First, we are expanding the possible
lexical choices by making use of a thesaurus, and
then we intend to use a language model to handle
synonymy.
Second, the mappings from semantic concepts
to surface strings still need to be revised and
adapted to the domain (questions and answers
about students’ undergraduate projects) in order to
deploy a fully functional application.
Finally, template selection needs improvement
to allow for a truly minimal input specification in
an application-friendly fashion.
With these tasks accomplished, we will be able
to attach a surface realization component to our
ongoing Q&amp;A project and generate context-
sensitive replies to students’ most frequent ques-
tions.
</bodyText>
<sectionHeader confidence="0.996538" genericHeader="method">
7 Final Remarks
</sectionHeader>
<bodyText confidence="0.9999724">
In the context of the NAACL-HLT Young Inves-
tigators Workshop on Computational Approaches
to Languages of the Americas, there are a number
of ways in which our work could benefit from co-
operation with researchers in Latin America, and
also help the development of NLP research in these
countries.
At the current stage, our work still relies heavily
on a Portuguese parsed corpus and grammar,
which may be seen being of limited interest outside
the Brazilian NLP research community. However,
given the close relation between Portuguese and
other languages spoken in the region (e.g., Spanish
and its variations), we believe that it would be a
rewarding experience to adapt similar language
resources (e.g., sentence templates, phrase gram-
mars etc.) that have been developed elsewhere, and
use these resources to deploy a multilingual NLG
application to validate our current approach.
Beyond the usefulness to the research communi-
ties involved, we would expect that this kind of co-
operation would be an effective means of sharing
costs and spreading the interest in NLG research
across the region, and a much-needed motivation
for young researchers to join the field.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999937142857143">
The authors acknowledge support by FAPESP and
CNPq. We are also thankful to the anonymous re-
viewers of the original submission, and to the or-
ganizers of the NAACL-HLT Young Investigators
Workshop on Computational Approaches to Lan-
guages of the Americas for the travel award given
for this presentation.
</bodyText>
<page confidence="0.995634">
130
</page>
<sectionHeader confidence="0.995881" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999821435483871">
Bangalore, S. and O. Rambow (2000) Corpus-based
lexical choice in natural language generation. Pro-
ceedings of the 38th Meeting of the ACL, Hong
Kong, pp. 464-471.
Bateman, J.A. (1997) Enabling technology for multilin-
gual natural language generation: the KPML devel-
opment environment. Natural Language Engineering,
3(1):15–55.
Bick, E. (2000) The parsing system PALAVRAS: au-
tomatic grammatical analysis of Portuguese in a con-
straint grammar framework. PhD Thesis, Aarhus
University.
DeVault, David, David Traum and Ron Arstein (2008)
Practical Grammar-Based NLG from Examples. Pro-
ceedings of the 5th International Natural Language
Generation Conference (INLG-2008) Columbus,
USA.
Gatt, Albert and Ehud Reiter (2009) SimpleNLG: A
realization engine for practical applications. Proceed-
ings of the European Natural Language Generation
workshop (ENLG-2009.)
Langkilde, Irene (2000) Forest-based statistical sentence
generation. Proceedings of the 6th Applied Natural
Language Processing Conference and 1st Meeting of
the North American Chapter of the Association of
Computational Linguistics (ANLP-NAACL’00), pp.
170–177.
Marciniak, T. and M. Strube (2005) Using an Annotated
Corpus As a Knowledge Source For Language Gen-
eration. Proceedings of the Corpus Linguistics’05
Workshop Using Corpora for NLG (UNNLG-2005),
pp. 19-24.
McRoy, Susan, Songsak Channarukul and Syed S. Ali
(2003) An augmented template-based approach to
text realization. Natural Language Engineering 9 (4)
pp. 381–420. Cambridge University Press.
Muniz, M. C., Laporte, E., Nunes, M.G.V (2005)
UNITEX-PB, a set of flexible language resources for
Brazilian Portuguese. Proceedings of the III Informa-
tion and Language Technology Workshop
(TIL-2005).
Oh, A. and A. Rudnicky (2000) Stochastic language
generation for spoken dialogue systems. Proceedings
of the ANLP-NAACL 2000 Workshop on Conversa-
tional Systems, pp. 27–32.
Ratnaparkhi, A. (2000) Trainable methods for surface
natural language generation. Proceedings of ANLP-
NAACL 2000, pp.194–201.
Reiter, E. (2007) An Architecture for Data-to-Text Sys-
tems. Proceedings of the European Natural Language
Generation workshop (ENLG-2007), pp. 97-104.
Smets, M., M.Gamon, S.Corston-Oliver and E. Ringger
(2003) French Amalgam: A machine-learned sen-
tence realization system. Proceedings of the TALN-
2003 Conference, Batz sur-Mer,
van Deemter, K., Emiel Krahmer and Mariët Theune
(2005) Real versus template-based NLG: a false op-
position? Computational Linguistics 31(1).
Zhong, Huayan and A. J. Stent (2005) Building Surface
Realizers Automatically from Corpora. Proceedings
of the Corpus Linguistics’05 Workshop Using Cor-
pora for NLG, pp. 49-54.
</reference>
<page confidence="0.998303">
131
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.487766">
<title confidence="0.983304">Text Generation for Brazilian the Surface Realization Task</title>
<author confidence="0.987568">Eder Miranda de_Novais Thiago Dias Tadeu Ivandré Paraboni</author>
<affiliation confidence="0.995543">University of São Paulo - School of Arts, Sciences and Humanities (USP-EACH)</affiliation>
<address confidence="0.7145065">Av. Arlindo Bettio, 1000, Ermelino Matarazzo São Paulo, Brazil - 03828-000</address>
<email confidence="0.896496">eder.novais@usp.brtdtadeu@gmail.comivandre@usp.br</email>
<abstract confidence="0.99966575">Despite the growing interest in NLP focused on the Brazilian Portuguese language in recent its obvious counterpart Lan- Generation (NLG) in that case a little-explored research field. In this paper we describe preliminary results of a first project of this kind, addressing the issue of surface realization for Brazilian Portuguese. Our approach, which may be particularly suitable to simpler NLG applications in which a domain corpus of the most likely output sentences happens to be available, is in principle adaptable to many closely-related languages, and paves the way to further NLG research focused on Romance languages in general.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Corpus-based lexical choice in natural language generation.</title>
<date>2000</date>
<booktitle>Proceedings of the 38th Meeting of the ACL, Hong Kong,</booktitle>
<pages>464--471</pages>
<contexts>
<context position="16276" citStr="Bangalore &amp; Rambow (2000)" startWordPosition="2616" endWordPosition="2619">ity, as in the NP “You should enroll by the end of the month in which you are expected to complete your current assignment”, and not simply using those NPs found in the target corpus. The set of mappings from domain concepts to their dependency-trees (i.e., constituent templates) makes a dictionary of realizations in the application domain. As in related work in the field (e.g., Gatt &amp; Reiter, 2009), we presently assume that the actual mappings are to be provided by the application. Concept-to-strings mappings are usually handcrafted, but may also be acquired automatically from corpora, as in Bangalore &amp; Rambow (2000). For testing purposes, we have extracted 1,548 instances of concept-to-string mappings from the target corpus, being 1,298 mappings from agent/patient entities to descriptions, pronouns and proper names, and 250 mappings from actions to VPs, even though many of them will not be of practical use from the point of view of our intended application. 5 Surface Realization Using the template definitions from the previous section, we designed a simple corpus-based surface realization component for our ongoing project. Our surface realization module is currently able to accept as an input a template </context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>Bangalore, S. and O. Rambow (2000) Corpus-based lexical choice in natural language generation. Proceedings of the 38th Meeting of the ACL, Hong Kong, pp. 464-471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
</authors>
<title>Enabling technology for multilingual natural language generation: the KPML development environment.</title>
<date>1997</date>
<journal>Natural Language Engineering,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1706" citStr="Bateman, 1997" startWordPosition="253" endWordPosition="254">ext or speech from a given nonlinguistic input. Systems of this kind usually follow a pipelined architecture (Reiter, 2007) comprising data interpretation, document planning, sentence planning and surface realization tasks. In this work we discuss the latter, that is, the task of producing surface word strings from a nonlinguistic input specification. Existing approaches to surface realization may vary greatly in their input requirements and, consequently, in the level of control over the output text. On the one hand, more sophisticated, grammar-based surface realization systems such as KPML (Bateman, 1997) allow maximum flexibility and productive coverage. These advantages, however, are only useful if the underlying application is capable of providing a detailed semantic specification as an input to the surface realization module in the first place. As an alternative to surface realization grammars, NLG systems may also rely on templatebased surface realization, that is, the use of predefined structures with a number of variable fields (or slots) to be filled in with values provided by the application. For a comparison between templates and other approaches to NLG, see for instance van Deemter </context>
<context position="6036" citStr="Bateman, 1997" startWordPosition="953" endWordPosition="954">of our system’s architecture; Sections 4 describes the extraction of syntactically-structured templates from a target corpus and Section 5 presents the current features of our template-based surface realization engine. Finally, Section 6 draws preliminary conclusions and describes ongoing work, and Section 7 hints at possible collaboration with the wider NLP research community in Latin America and elsewhere. 2 Related work Mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., Bateman, 1997) or acquired automatically from a corpus (Ratnaparkhi, 2000; Zhong &amp; Stent, 2005; DeVault et. al., 2008). The surface realization task proper can be divided into two relatively independent procedures: a domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and a language-oriented task of linearization. As pointed out in Gatt &amp; Reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been ma</context>
</contexts>
<marker>Bateman, 1997</marker>
<rawString>Bateman, J.A. (1997) Enabling technology for multilingual natural language generation: the KPML development environment. Natural Language Engineering, 3(1):15–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>The parsing system PALAVRAS: automatic grammatical analysis of Portuguese in a constraint grammar framework.</title>
<date>2000</date>
<tech>PhD Thesis,</tech>
<institution>Aarhus University.</institution>
<contexts>
<context position="12806" citStr="Bick, 2000" startWordPosition="2038" endWordPosition="2039">ed into two main tasks: the extraction of syntactically-structured templates from corpora and the actual development of the surface realization engine. The following sections 4 and 5 discuss each of these tasks in turn. 127 4 Template Extraction Using a collection of emails sent to undergraduate students by their professors in reply to their most frequent questions regarding a particular project, we developed a database conveying 597 instances of surface realization templates for Brazilian Portuguese NLG as follows. After sentence segmentation, the corpus was tagged and parsed using PALAVRAS (Bick, 2000). A number of critical parsing errors were removed, and thus we arrived at a set of 578 sentence-level templates represented in XML format. In our example-based approach to surface realization we consider two kinds of structure: sentence and constituent templates. Sentence templates are high-level representations of the sample sentences taken from our target corpus, and they contain a number of variable fields (the constituents) to be filled in with application data (in most cases having an agent, action and patient fields.) Everything else within the sentence is simply canned text as seen in </context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>Bick, E. (2000) The parsing system PALAVRAS: automatic grammatical analysis of Portuguese in a constraint grammar framework. PhD Thesis, Aarhus University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>David Traum</author>
<author>Ron Arstein</author>
</authors>
<title>Practical Grammar-Based NLG from Examples.</title>
<date>2008</date>
<booktitle>Proceedings of the 5th International Natural Language Generation Conference (INLG-2008)</booktitle>
<location>Columbus, USA.</location>
<marker>DeVault, Traum, Arstein, 2008</marker>
<rawString>DeVault, David, David Traum and Ron Arstein (2008) Practical Grammar-Based NLG from Examples. Proceedings of the 5th International Natural Language Generation Conference (INLG-2008) Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Gatt</author>
<author>Ehud Reiter</author>
</authors>
<title>SimpleNLG: A realization engine for practical applications.</title>
<date>2009</date>
<booktitle>Proceedings of the European Natural Language Generation workshop (ENLG-2009.)</booktitle>
<contexts>
<context position="6442" citStr="Gatt &amp; Reiter (2009)" startWordPosition="1010" endWordPosition="1013"> elsewhere. 2 Related work Mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., Bateman, 1997) or acquired automatically from a corpus (Ratnaparkhi, 2000; Zhong &amp; Stent, 2005; DeVault et. al., 2008). The surface realization task proper can be divided into two relatively independent procedures: a domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and a language-oriented task of linearization. As pointed out in Gatt &amp; Reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made. This is the case for example of SimpleNLG (Gatt &amp; Reiter, 2009), a surface realization engine implemented as a Java library for sentence linearization. Central to the development and use of a surface realization system is the kind of input specification that will be expected from the application. In order to take full advantage of grammar-based surface realization, it is usually necessary to provide</context>
<context position="16053" citStr="Gatt &amp; Reiter, 2009" startWordPosition="2581" endWordPosition="2584">need to achieve wider coverage and to support linguistic variation beyond what the actual phrases found in the corpus would allow. In doing so we are able to fill in sentence templates with phrases of arbitrary complexity, as in the NP “You should enroll by the end of the month in which you are expected to complete your current assignment”, and not simply using those NPs found in the target corpus. The set of mappings from domain concepts to their dependency-trees (i.e., constituent templates) makes a dictionary of realizations in the application domain. As in related work in the field (e.g., Gatt &amp; Reiter, 2009), we presently assume that the actual mappings are to be provided by the application. Concept-to-strings mappings are usually handcrafted, but may also be acquired automatically from corpora, as in Bangalore &amp; Rambow (2000). For testing purposes, we have extracted 1,548 instances of concept-to-string mappings from the target corpus, being 1,298 mappings from agent/patient entities to descriptions, pronouns and proper names, and 250 mappings from actions to VPs, even though many of them will not be of practical use from the point of view of our intended application. 5 Surface Realization Using </context>
</contexts>
<marker>Gatt, Reiter, 2009</marker>
<rawString>Gatt, Albert and Ehud Reiter (2009) SimpleNLG: A realization engine for practical applications. Proceedings of the European Natural Language Generation workshop (ENLG-2009.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
</authors>
<title>Forest-based statistical sentence generation.</title>
<date>2000</date>
<booktitle>Proceedings of the 6th Applied Natural Language Processing Conference and 1st Meeting of the North American Chapter of the Association of Computational Linguistics (ANLP-NAACL’00),</booktitle>
<pages>170--177</pages>
<contexts>
<context position="2884" citStr="Langkilde (2000)" startWordPosition="449" endWordPosition="450"> to NLG, see for instance van Deemter et. al. (2005). Adapting an existing application to a templatebased realization system is usually much simpler than in a grammar-based approach. Yet, in order to take full advantage of template definitions and to obtain a degree of control over the output text that is comparable to what a grammar-based system would allow, it is still necessary to master the use of templates and their rules to fill in each slot adequately. The problem of input specification to surface realization has been discussed at length in the literature in the field - see for example Langkilde (2000) – and we of course do not dispute that more sophisticated NLG systems will require a detailed input specification. However, given that the available semantics may not be provide in this level of detail, in this paper we discuss an alternative that 125 Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas, pages 125–131, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics may be suitable to simpler applications, namely, those cases in which it is known in advance what the most likely output sente</context>
<context position="21210" citStr="Langkilde (2000)" startWordPosition="3395" endWordPosition="3396">ept as in (e), agreement rules are required to modify the verb number as in (f). (d) [All students]agent [have submitted]action [their papers]patient (e) [Your teacher] agent [#have submitted]action [their papers]patient (f) [Your teacher] agent [has submitted]action [their papers]patient Table 2. An original example (d) reused with a new agent head value (e) and agreement (f). More complex or fine-grained dependencies (e.g., the anaphoric reference ‘their’ in Table 2 129 above) are not currently implemented. One possible approach to this is a standard generate-andselect approach to NLG as in Langkilde (2000), Oh &amp; Rudnicky (2000) and others. More specifically, we may over-generate all possible realization alternatives and then use a statistical language model to select the most likely output. In our work we intend to apply a similar approach also to handle the lexical choice task, i.e., by selecting the most likely wording for each concept based on a language model. 6 Discussion In this paper we have described a simple approach to surface realization based on the reuse of syntactically-structured templates acquired from corpora. Although not nearly as flexible as a full NLG approach, our system m</context>
</contexts>
<marker>Langkilde, 2000</marker>
<rawString>Langkilde, Irene (2000) Forest-based statistical sentence generation. Proceedings of the 6th Applied Natural Language Processing Conference and 1st Meeting of the North American Chapter of the Association of Computational Linguistics (ANLP-NAACL’00), pp. 170–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Marciniak</author>
<author>M Strube</author>
</authors>
<title>Using an Annotated Corpus As a Knowledge Source For Language Generation.</title>
<date>2005</date>
<booktitle>Proceedings of the Corpus Linguistics’05 Workshop Using Corpora for NLG (UNNLG-2005),</booktitle>
<pages>pp.</pages>
<contexts>
<context position="7296" citStr="Marciniak &amp; Strube, 2005" startWordPosition="1152" endWordPosition="1155"> SimpleNLG (Gatt &amp; Reiter, 2009), a surface realization engine implemented as a Java library for sentence linearization. Central to the development and use of a surface realization system is the kind of input specification that will be expected from the application. In order to take full advantage of grammar-based surface realization, it is usually necessary to provided detailed linguistic knowledge as an input. This is the case, for example, of a number of corpus-based approaches to grammar acquisition, which may take logical forms as an input (e.g., Smets et. al., 2003; Zhong &amp; Stent, 2005; Marciniak &amp; Strube, 2005). The Amalgam system, for instance (Smets et. al., 2003), takes as an input a graph conveying fixed content words (lemmas) and detailed linguistic information such as verb tense and mode, gender, number and definiteness of all its constituents, and additional semantic features (e.g., ‘human’, ‘animated’ etc.) Detailed input specification as required in grammar-based surface realization is however often unavailable from the semantics of the application. As an alternative, template-based surface realization makes use of predefined structures (e.g., syntactically-structured sentence templates) wi</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>Marciniak, T. and M. Strube (2005) Using an Annotated Corpus As a Knowledge Source For Language Generation. Proceedings of the Corpus Linguistics’05 Workshop Using Corpora for NLG (UNNLG-2005), pp. 19-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan McRoy</author>
<author>Songsak Channarukul</author>
<author>Syed S Ali</author>
</authors>
<title>An augmented template-based approach to text realization.</title>
<date>2003</date>
<journal>Natural Language Engineering</journal>
<volume>9</volume>
<issue>4</issue>
<pages>381--420</pages>
<publisher>Cambridge University Press.</publisher>
<marker>McRoy, Channarukul, Ali, 2003</marker>
<rawString>McRoy, Susan, Songsak Channarukul and Syed S. Ali (2003) An augmented template-based approach to text realization. Natural Language Engineering 9 (4) pp. 381–420. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Muniz</author>
<author>E Laporte</author>
<author>M G V Nunes</author>
</authors>
<title>UNITEX-PB, a set of flexible language resources for Brazilian Portuguese.</title>
<date>2005</date>
<booktitle>Proceedings of the III Information and Language Technology Workshop (TIL-2005).</booktitle>
<marker>Muniz, Laporte, Nunes, 2005</marker>
<rawString>Muniz, M. C., Laporte, E., Nunes, M.G.V (2005) UNITEX-PB, a set of flexible language resources for Brazilian Portuguese. Proceedings of the III Information and Language Technology Workshop (TIL-2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Oh</author>
<author>A Rudnicky</author>
</authors>
<title>Stochastic language generation for spoken dialogue systems.</title>
<date>2000</date>
<booktitle>Proceedings of the ANLP-NAACL 2000 Workshop on Conversational Systems,</booktitle>
<pages>27--32</pages>
<contexts>
<context position="21232" citStr="Oh &amp; Rudnicky (2000)" startWordPosition="3397" endWordPosition="3400">eement rules are required to modify the verb number as in (f). (d) [All students]agent [have submitted]action [their papers]patient (e) [Your teacher] agent [#have submitted]action [their papers]patient (f) [Your teacher] agent [has submitted]action [their papers]patient Table 2. An original example (d) reused with a new agent head value (e) and agreement (f). More complex or fine-grained dependencies (e.g., the anaphoric reference ‘their’ in Table 2 129 above) are not currently implemented. One possible approach to this is a standard generate-andselect approach to NLG as in Langkilde (2000), Oh &amp; Rudnicky (2000) and others. More specifically, we may over-generate all possible realization alternatives and then use a statistical language model to select the most likely output. In our work we intend to apply a similar approach also to handle the lexical choice task, i.e., by selecting the most likely wording for each concept based on a language model. 6 Discussion In this paper we have described a simple approach to surface realization based on the reuse of syntactically-structured templates acquired from corpora. Although not nearly as flexible as a full NLG approach, our system may represent a straigh</context>
</contexts>
<marker>Oh, Rudnicky, 2000</marker>
<rawString>Oh, A. and A. Rudnicky (2000) Stochastic language generation for spoken dialogue systems. Proceedings of the ANLP-NAACL 2000 Workshop on Conversational Systems, pp. 27–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Trainable methods for surface natural language generation.</title>
<date>2000</date>
<booktitle>Proceedings of ANLPNAACL 2000,</booktitle>
<pages>194--201</pages>
<contexts>
<context position="6095" citStr="Ratnaparkhi, 2000" startWordPosition="962" endWordPosition="963">xtraction of syntactically-structured templates from a target corpus and Section 5 presents the current features of our template-based surface realization engine. Finally, Section 6 draws preliminary conclusions and describes ongoing work, and Section 7 hints at possible collaboration with the wider NLP research community in Latin America and elsewhere. 2 Related work Mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., Bateman, 1997) or acquired automatically from a corpus (Ratnaparkhi, 2000; Zhong &amp; Stent, 2005; DeVault et. al., 2008). The surface realization task proper can be divided into two relatively independent procedures: a domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and a language-oriented task of linearization. As pointed out in Gatt &amp; Reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made. This is the case for example of SimpleNLG (Gatt &amp; Reite</context>
<context position="9528" citStr="Ratnaparkhi (2000)" startWordPosition="1501" endWordPosition="1502">ctions on how to generate the desired output. Still, in this work we would like to produce surface strings using even less knowledge, namely, by using sentence-level templates extracted from a domain corpus as a basis to generate original and modified versions of the corpus sentences. We will refer to this as an example-based approach to surface realization1, although this is not to be mistaken for example-based learning techniques to perform automatic grammar induction as in DeVault et. al., (2008), or other forms of grammar acquisition as in Zhong &amp; Stent (2005). Our work is more related to Ratnaparkhi (2000) in the sense that we also use a large collection of generation templates for surface realization, but still distinct in that we intend to generate text from minimal input. 3 Project Overview Template-based surface realization systems such as YAG (McRoy et. al., 2003) make use of a relatively small number of template definitions and some kind of descriptive language to provide finegrained input sentence specification with flexibility 1 Perhaps ‘select-and-modify’ would be closer to our current purposes. and wide coverage. However, if a corpus on the application domain happens to be available, </context>
</contexts>
<marker>Ratnaparkhi, 2000</marker>
<rawString>Ratnaparkhi, A. (2000) Trainable methods for surface natural language generation. Proceedings of ANLPNAACL 2000, pp.194–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>An Architecture for Data-to-Text Systems.</title>
<date>2007</date>
<booktitle>Proceedings of the European Natural Language Generation workshop (ENLG-2007),</booktitle>
<pages>97--104</pages>
<contexts>
<context position="1215" citStr="Reiter, 2007" startWordPosition="179" endWordPosition="180"> of a first project of this kind, addressing the issue of surface realization for Brazilian Portuguese. Our approach, which may be particularly suitable to simpler NLG applications in which a domain corpus of the most likely output sentences happens to be available, is in principle adaptable to many closely-related languages, and paves the way to further NLG research focused on Romance languages in general. 1 Introduction Data-to-Text Natural Language Generation (NLG) systems produce text or speech from a given nonlinguistic input. Systems of this kind usually follow a pipelined architecture (Reiter, 2007) comprising data interpretation, document planning, sentence planning and surface realization tasks. In this work we discuss the latter, that is, the task of producing surface word strings from a nonlinguistic input specification. Existing approaches to surface realization may vary greatly in their input requirements and, consequently, in the level of control over the output text. On the one hand, more sophisticated, grammar-based surface realization systems such as KPML (Bateman, 1997) allow maximum flexibility and productive coverage. These advantages, however, are only useful if the underly</context>
</contexts>
<marker>Reiter, 2007</marker>
<rawString>Reiter, E. (2007) An Architecture for Data-to-Text Systems. Proceedings of the European Natural Language Generation workshop (ENLG-2007), pp. 97-104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Smets</author>
<author>S Corston-Oliver M Gamon</author>
<author>E Ringger</author>
</authors>
<title>French Amalgam: A machine-learned sentence realization system.</title>
<date>2003</date>
<booktitle>Proceedings of the TALN2003 Conference, Batz sur-Mer,</booktitle>
<marker>Smets, Gamon, Ringger, 2003</marker>
<rawString>Smets, M., M.Gamon, S.Corston-Oliver and E. Ringger (2003) French Amalgam: A machine-learned sentence realization system. Proceedings of the TALN2003 Conference, Batz sur-Mer,</rawString>
</citation>
<citation valid="false">
<authors>
<author>K van Deemter</author>
</authors>
<title>Emiel Krahmer and Mariët Theune (2005) Real versus template-based NLG: a false opposition?</title>
<journal>Computational Linguistics</journal>
<volume>31</volume>
<issue>1</issue>
<marker>van Deemter, </marker>
<rawString>van Deemter, K., Emiel Krahmer and Mariët Theune (2005) Real versus template-based NLG: a false opposition? Computational Linguistics 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huayan Zhong</author>
<author>A J Stent</author>
</authors>
<title>Building Surface Realizers Automatically from Corpora.</title>
<date>2005</date>
<booktitle>Proceedings of the Corpus Linguistics’05 Workshop Using Corpora for NLG,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="6116" citStr="Zhong &amp; Stent, 2005" startWordPosition="964" endWordPosition="967">tically-structured templates from a target corpus and Section 5 presents the current features of our template-based surface realization engine. Finally, Section 6 draws preliminary conclusions and describes ongoing work, and Section 7 hints at possible collaboration with the wider NLP research community in Latin America and elsewhere. 2 Related work Mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., Bateman, 1997) or acquired automatically from a corpus (Ratnaparkhi, 2000; Zhong &amp; Stent, 2005; DeVault et. al., 2008). The surface realization task proper can be divided into two relatively independent procedures: a domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and a language-oriented task of linearization. As pointed out in Gatt &amp; Reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made. This is the case for example of SimpleNLG (Gatt &amp; Reiter, 2009), a surface r</context>
<context position="9480" citStr="Zhong &amp; Stent (2005)" startWordPosition="1491" endWordPosition="1494">application – than a full set of linguistic instructions on how to generate the desired output. Still, in this work we would like to produce surface strings using even less knowledge, namely, by using sentence-level templates extracted from a domain corpus as a basis to generate original and modified versions of the corpus sentences. We will refer to this as an example-based approach to surface realization1, although this is not to be mistaken for example-based learning techniques to perform automatic grammar induction as in DeVault et. al., (2008), or other forms of grammar acquisition as in Zhong &amp; Stent (2005). Our work is more related to Ratnaparkhi (2000) in the sense that we also use a large collection of generation templates for surface realization, but still distinct in that we intend to generate text from minimal input. 3 Project Overview Template-based surface realization systems such as YAG (McRoy et. al., 2003) make use of a relatively small number of template definitions and some kind of descriptive language to provide finegrained input sentence specification with flexibility 1 Perhaps ‘select-and-modify’ would be closer to our current purposes. and wide coverage. However, if a corpus on </context>
</contexts>
<marker>Zhong, Stent, 2005</marker>
<rawString>Zhong, Huayan and A. J. Stent (2005) Building Surface Realizers Automatically from Corpora. Proceedings of the Corpus Linguistics’05 Workshop Using Corpora for NLG, pp. 49-54.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>