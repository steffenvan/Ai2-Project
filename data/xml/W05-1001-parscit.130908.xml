<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001043">
<title confidence="0.939869">
Data Homogeneity and Semantic Role Tagging in Chinese
</title>
<author confidence="0.834105">
Oi Yee Kwong and Benjamin K. Tsou
</author>
<affiliation confidence="0.743953333333333">
Language Information Sciences Research Centre
City University of Hong Kong
Tat Chee Avenue, Kowloon, Hong Kong
</affiliation>
<email confidence="0.997423">
{rlolivia, rlbtsou}@cityu.edu.hk
</email>
<sectionHeader confidence="0.995614" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999981">
This paper reports on a study of semantic
role tagging in Chinese in the absence of a
parser. We tackle the task by identifying
the relevant headwords in a sentence as a
first step to partially locate the corre-
sponding constituents to be labelled. We
also explore the effect of data homogene-
ity by experimenting with a textbook cor-
pus and a news corpus, representing
simple data and complex data respectively.
Results suggest that while the headword
location method remains to be improved,
the homogeneity between the training and
testing data is important especially in
view of the characteristic syntax-
semantics interface in Chinese. We also
plan to explore some class-based tech-
niques for the task with reference to exist-
ing semantic lexicons, and to modify the
method and augment the feature set with
more linguistic input.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999807">
As the development of language resources pro-
gresses from POS-tagged corpora to syntactically
annotated treebanks, the inclusion of semantic in-
formation such as predicate-argument relations
becomes indispensable. The expansion of the Penn
Treebank into a Proposition Bank (Kingsbury and
Palmer, 2002) is a typical move in this direction.
Lexical resources also need to be enhanced with
semantic information (e.g. Fellbaum et al., 2001).
The ability to identify semantic role relations cor-
</bodyText>
<page confidence="0.845733">
1
</page>
<bodyText confidence="0.999946710526316">
rectly is essential to many applications such as in-
formation extraction and machine translation; and
making available resources with this kind of in-
formation would in turn facilitate the development
of such applications.
Large-scale production of annotated resources
is often labour intensive, and thus calls for auto-
matic labelling to streamline the process. The task
is essentially done in two phases, namely recognis-
ing the constituents bearing some semantic rela-
tionship to the target verb in a sentence, and then
labelling them with the corresponding semantic
roles.
In their seminal proposal, Gildea and Jurafsky
(2002) approached the task using various features
such as headword, phrase type, and parse tree path.
While such features have remained the basic and
essential features in subsequent research, parsed
sentences are nevertheless required, for extracting
the path features during training and providing the
argument boundaries during testing. The parse
information is deemed important for the perform-
ance of role labelling (Gildea and Palmer, 2002;
Gildea and Hockenmaier, 2003).
More precisely, parse information is rather
more critical for the identification of boundaries of
candidate constituents than for the extraction of
training data. Its limited function in training, for
instance, is reflected in the low coverage reported
(e.g. You and Chen, 2004). As full parses are not
always accessible, many thus resort to shallow syn-
tactic information from simple chunking, even
though results often turn out to be less satisfactory
than with full parses.
This limitation is even more pertinent for the
application of semantic role labelling to languages
which do not have sophisticated parsing resources.
In the case of Chinese, for example, there is con-
</bodyText>
<note confidence="0.988724">
Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 1–9,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.999593714285714">
siderable variability in its syntax-semantics inter-
face; and when one comes to more nested and
complex sentences such as those from news arti-
cles, it becomes more difficult to capture the sen-
tence structures by typical examples.
Thus in the current study, we approach the
problem in Chinese in the absence of parse infor-
mation, and attempt to identify the headwords in
the relevant constituents in a sentence to be tagged
as a first step. In addition, we will explore the ef-
fect of training on different datasets, simple or
complex, to shed light on the relative importance
of parse information for indicating constituent
boundaries in semantic role labelling.
In Section 2, related work will be reviewed. In
Section 3, the data used in the current study will be
introduced. Our proposed method will be ex-
plained in Section 4, and the experiment reported
in Section 5. Results and future work will be dis-
cussed in Section 6, followed by conclusions in
Section 7.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9996308">
The definition of semantic roles falls on a contin-
uum from abstract ones to very specific ones.
Gildea and Jurafsky (2002), for instance, used a set
of roles defined according to the FrameNet model
(Baker et al., 1998), thus corresponding to the
frame elements in individual frames under a par-
ticular domain to which a given verb belongs.
Lexical entries (in fact not limited to verbs, in the
case of FrameNet) falling under the same frame
will share the same set of roles. Gildea and Palmer
(2002) defined roles with respect to individual
predicates in the PropBank, without explicit nam-
ing. To date PropBank and FrameNet are the two
main resources in English for training semantic
role labelling systems, as in the CoNLL-2004
shared task (Carreras and Màrquez, 2004) and
SENSEVAL-3 (Litkowski, 2004).
The theoretical treatment of semantic roles is
also varied in Chinese. In practice, for example,
the semantic roles in the Sinica Treebank mark not
only verbal arguments but also modifier-head rela-
tions (You and Chen, 2004). In our present study,
we go for a set of more abstract semantic roles
similar to the thematic roles for English used in
VerbNet (Kipper et al., 2002). These roles are
generalisable to most Chinese verbs and are not
dependent on particular predicates. They will be
further introduced in Section 3.
Approaches in automatic semantic role label-
ling are mostly statistical, typically making use of
a number of features extracted from parsed training
sentences. In Gildea and Jurafsky (2002), the fea-
tures studied include phrase type (pt), governing
category (gov), parse tree path (path), position of
constituent with respect to the target predicate (po-
sition), voice (voice), and headword (h). The la-
belling of a constituent then depends on its
likelihood to fill each possible role r given the fea-
tures and the target predicate t, as in the following,
for example:
</bodyText>
<equation confidence="0.9782215">
P r h pt gov position voice t
(  |, , , , ,
</equation>
<bodyText confidence="0.97666294949495">
Subsequent studies exploited a variety of im-
plementation of the learning component. Trans-
formation-based approaches were also used (e.g.
see Carreras and Màrquez (2004) for an overview
of systems participating in the CoNLL shared task).
Swier and Stevenson (2004) innovated with an un-
supervised approach to the problem, using a boot-
strapping algorithm, and achieved 87% accuracy.
While the estimation of the probabilities could
be relatively straightforward, the trick often lies in
locating the candidate constituents to be labelled.
A parser of some kind is needed. Gildea and
Palmer (2002) compared the effects of full parsing
and shallow chunking; and found that when con-
stituent boundaries are known, both automatic
parses and gold standard parses resulted in about
80% accuracy for subsequent automatic role tag-
ging, but when boundaries are unknown, results
with automatic parses dropped to 57% precision
and 50% recall. With chunking only, performance
further degraded to below 30%. Problems mostly
arise from arguments which correspond to more
than one chunk, and the misplacement of core ar-
guments. Sun and Jurafsky (2004) also reported a
drop in F-score with automatic syntactic parses
compared to perfect parses for role labelling in
Chinese, despite the comparatively good results of
their parser (i.e. the Collins parser ported to Chi-
nese). The necessity of parse information is also
reflected from recent evaluation exercises. For
instance, most systems in SENSEVAL-3 used a
parser to obtain full syntactic parses for the sen-
tences, whereas systems participating in the
CoNLL task were restricted to use only shallow
)
2
syntactic information. Results reported in the for- 3.2 Training and Testing Data
mer tend to be higher. Although the dataset may For the current study, a set of 41 transitive verbs
be a factor affecting the labelling performance, it common to the two corpora (hereafter referred to
nevertheless reinforces the usefulness of full syn- as textbook corpus and news corpus), with fre-
tactic information. quency over 10 and over 50 respectively, was
According to Carreras and Màrquez (2004), for sampled.
English, the state-of-the-art results reach an F1 Sentences in the corpora containing the sam-
measure of slightly over 83 using gold standard pled verbs were extracted. Constituents corre-
parse trees and about 77 with real parsing results. sponding to semantic roles with respect to the
Those based on shallow syntactic information is target verbs were annotated by a trained human
about 60. annotator and the annotation was verified by an-
In this work, we study the problem in Chinese, other. In this study, we worked with a set of 11
treating it as a headword identification and label- predicate-independent abstract semantic roles.
ling task in the absence of parse information, and According to the Dictionary of Verbs in Contem-
examine how the nature of the dataset could affect porary Chinese (Xiandai Hanyu Dongci Dacidian,
the role tagging performance. fe pjpuJ�puJ – Lin et al., 1994), our se-
mantic roles include the necessary arguments for
most verbs such as agent and patient, or goal and
location in some cases; and some optional argu-
ments realised by adjuncts, such as quantity, in-
strument, and source. Some examples of semantic
roles with respect to a given predicate are shown in
Figure 1.
Altogether 980 sentences covering 41 verb
types in the textbook corpus were annotated, re-
sulting in 1,974 marked semantic roles (constitu-
ents); and 2,122 sentences covering 41 verb types
in the news corpus were annotated, resulting in
4,933 marked constituents2.
The role labelling system was trained on 90%
of the sample sentences from the textbook corpus
and the news corpus separately; and tested on the
remaining 10% of both corpora.
3 The Data
3.1 Materials
In this study, we used two datasets: sentences from
primary school textbooks were taken as examples
for simple data, while sentences from a large cor-
pus of newspaper texts were taken as complex ex-
amples.
Two sets of primary school Chinese textbooks
popularly used in Hong Kong were taken for refer-
ence. The two publishers were Keys Press and
Modern Education Research Society Ltd. Texts
for Primary One to Six were digitised, segmented
into words, and annotated with parts-of-speech
(POS). This results in a text collection of about
165K character tokens and upon segmentation
about 109K word tokens (about 15K word types).
There were about 2,500 transitive verb types, with
frequency ranging from 1 to 926.
The complex examples were taken from a sub-
set of the LIVAC synchronous corpus1 (Tsou et al.,
2000; Kwong and Tsou, 2003). The subcorpus
consists of newspaper texts from Hong Kong, in-
cluding local news, international news, financial
news, sports news, and entertainment news, col-
lected in 1997-98. The texts were segmented into
words and POS-tagged, resulting in about 1.8M
character tokens and upon segmentation about 1M
word tokens (about 47K word types). There were
about 7,400 transitive verb types, with frequency
ranging from 1 to just over 6,300.
</bodyText>
<table confidence="0.563254066666667">
4 Automatic Role Labelling
The automatic labelling was based on the statistical
approach in Gildea and Jurafsky (2002). In Sec-
tion 4.1, we will briefly mention the features used
in the training process. Then in Sections 4.2 and
4.3, we will explain our approach for locating
headwords in candidate constituents associated
with semantic roles, in the absence of parse infor-
mation.
2 These figures only refer to the samples used in the current
study. In fact over 35,000 sentences in the LIVAC corpus
have been semantically annotated, covering about 1,500 verb
types and about 80,000 constituents were marked.
1 http://www.livac.org
3
</table>
<subsectionHeader confidence="0.97742">
4.1 Training
</subsectionHeader>
<bodyText confidence="0.999200771428572">
In this study, our probability model was based
mostly on parse-independent features extracted
from the training sentences, namely:
Headword (head): The headword from each con-
stituent marked with a semantic role was identified.
For example, in the second sentence in Figure 1,
學校 (school) is the headword in the constituent
corresponding to the agent of the verb 舉行 (hold),
and tL賽 (contest) is the headword of the noun
phrase corresponding to the patient.
Position (posit): This feature shows whether the
constituent being labelled appears before or after
the target verb. In the first example in Figure 1,
the experiencer and time appear on the left of the
target, while the theme is on its right.
POS of headword (HPos): Without features pro-
vided by the parse, such as phrase type or parse
tree path, the POS of the headword of the labelled
constituent could provide limited syntactic infor-
mation.
Preposition (prep): Certain semantic roles like
time and location are often realised by preposi-
tional phrases, so the preposition introducing the
relevant constituents would be an informative fea-
ture.
Hence for automatic labelling, given the target
verb t, the candidate constituent, and the above
features, the role r which has the highest probabil-
ity for P(r  |head, posit, HPos, prep, t) will be as-
signed to that constituent. In this study, however,
we are also testing with the unknown boundary
condition where candidate constituents are not
available in advance. To start with, we attempt to
partially locate them by identifying their head-
words first, as explained in the following sections.
</bodyText>
<figure confidence="0.982783375">
Example: (Students always feel there is nothing to write about for their essays.)
同學 fl 作文 時 , 99 感到 沒 fflt TRT A
Student (-pl) write essay time always feel (neg) anything can write
Experiencer Time Target Theme
Example: (Next week, the school will hold a story-telling contest.)
下 星期 學校 舉行 講 故事 tL賽
Next week school hold tell story contest
Time Agent Target Patient
</figure>
<figureCaption confidence="0.998129">
Figure 1 Examples of semantic roles with respect to a given predicate
</figureCaption>
<subsectionHeader confidence="0.995295">
4.2 Locating Candidate Headwords
</subsectionHeader>
<bodyText confidence="0.9998824">
In the absence of parse information, and with con-
stituent boundaries unknown, we attempt to par-
tially locate the candidate constituents by
identifying their corresponding headwords first.
Sentences in our test data were segmented into
words and POS-tagged. We thus divide the recog-
nition process into two steps, locating the head-
word of a candidate constituent first, and then
expanding from the headword to determine its
boundaries.
</bodyText>
<page confidence="0.955045">
4
</page>
<bodyText confidence="0.984330759036145">
Basically, if we consider every word in the 5 The Experiment
same sentence with the target verb (both to its left 5.1 Testing
and to its right) a potential headword for a candi- The system was trained on the textbook corpus and
date constituent, what we need to do is to find out the news corpus separately, and tested on both cor-
the most probable words in the sentence to match pora (the data is homogeneous if the system is
against individual semantic roles. We start with a trained and tested on materials from the same
feature set with more specific distributions, and source). The testing was done under the “known
back off to feature sets with less specific distribu- constituent” condition and “unknown constituent”
tions3. Hence in each round we look for condition. The former essentially corresponds to
arg max P(r  |feature set) the known-boundary condition in related studies;
r whereas in the unknown-constituent condition,
for every candidate word. Ties are resolved by which we will call “headword location” condition
giving priority to the word nearest to the target hereafter, we tested our method of locating candi-
verb in the sentence. date headwords as explained above in Section 4.2.
Figure 2 shows an example illustrating the pro- In this study, every noun, verb, adjective, pronoun,
cedures for locating candidate headwords. The classifier, and number within the test sentence con-
target verb is RN (discover). In the first round, taining the target verb was considered a potential
using features head, posit, HPos, and t, Hirt (time) headword for a candidate constituent correspond-
and HI (problem) were identified as Time and ing to some semantic role. The performance was
Patient respectively. In the fourth subsequent measured in terms of the precision (defined as the
round, backing off with features posit and HPos, percentage of correct outputs among all outputs),
airg (we) was identified as a possible Agent. In recall (defined as the percentage of correct outputs
this round a few other words were identified as among expected outputs), and F1 score which is the
potential Patients. However, they would not be harmonic mean of precision and recall.
considered since Patient was already located in a 5.2 Results
previous round. So in the end the headwords iden- The results are shown in Tables 1 and 2, for train-
tified for the test sentence are airg for Agent, HI ing on homogeneous dataset and different dataset
� for Patient and Hirt for Time. respectively, and testing under the known constitu-
4.3 Constituent Boundary ent condition and the headword location condition.
Upon the identification of headwords for potential When trained on homogeneous data, the results
constituents, the next step is to expand from these were good on both datasets under the known con-
headwords for constituent boundaries. Although stituent condition, with an F1 score of about 90.
we are not doing this step in the current study, it This is comparable or even better to the results re-
can potentially be done via some finite state tech- ported in related studies for known boundary con-
niques, or better still, with shallow syntactic proc- dition. The difference is that we did not use any
essing like simple chunking if available. parse information in the training, not even phrase
type. When trained on a different dataset, however,
the accuracy was maintained for textbook data, but
it decreased for news data, for the known constitu-
ent condition.
For the headword location condition, the per-
formance in general was expectedly inferior to that
for the known constituent condition. Moreover,
this degradation seemed to be quite consistent in
most cases, regardless of the nature of the training
set. In fact, despite the effect of training set on
news data, as mentioned above, the degradation
3 In this experiment, we back off in the following order:
P(r|head, posit, HPos, prep t), P(r|head, posit, t), P(r  |head, t),
P(r  |HPos, posit, t), P(r  |HPos, t). However, the prep feature
becomes obsolete when constituent boundaries are unknown.
5
from known constituent to headword location is
nevertheless the least for news data when trained
on different materials.
Hence the effect of training data is only obvious
in the news corpus. In other words, both sets of
training data work similarly well with textbook test
data, but the performance on news test data is
worse when trained on textbook data. This is un-
derstandable as the textbook data contain fewer
examples and the sentence structures are usually
much simpler than those in newspapers. Hence the
system tends to miss many secondary roles like
location and time, which are not sufficiently repre-
sented in the textbook corpus. The conclusion that
training on news data gives better result might be
premature at this stage, given the considerable dif-
ference in the corpus size of the two datasets.
Nevertheless, the deterioration of results on text-
book sentences, even when trained on news data, is
simply reinforcing the importance of data homoge-
neity, if nothing else. More on data homogeneity
will be discussed in the next section.
In addition, the surprisingly low precision under
the headword location condition is attributable to a
technical inadequacy in the way we break ties. In
this study we only make an effort to eliminate mul-
tiple tagging of the same role to the same target
verb in a sentence on either side of the target verb,
but not if they appear on both sides of the target
verb. This should certainly be dealt with in future
experiments.
</bodyText>
<figureCaption confidence="0.968471">
Figure 2 Example illustrating the procedures for locating candidate headwords
</figureCaption>
<table confidence="0.997543">
Textbook Data News a
Dat
Precision Recall F1 Precision Recall F1
Known Constituent 93.85 87.50 90.56 90.49 87.70 89.07
Headword Location 46.12 61.98 52.89 38.52 52.25 44.35
</table>
<tableCaption confidence="0.976762">
Table 1 Results for Training on Homogeneous Datasets
</tableCaption>
<table confidence="0.630471588235294">
Sentence:
溫習的時候,我們發現了許多平時沒有想到,或是未能解決的問題,於是就去問爸爸 。
During revision, we discover a lot o f problems which we have not thought of or cannot be
solved, then we go and ask father.
Candidate Round 1 ... Round 4 Final Result
Headwords
溫習 (revisio n) Patient
時候 (time) Time ---- Time
我們 (we) Agent Agent
平時 (normally)
想到 (think) Patient
能 (can)
解決 (solve) Patient
問題 (problem) Patient ---- Patient
去 (go) Patient
問 (ask) Patient
爸爸 (father) Patient
</table>
<page confidence="0.955145">
6
</page>
<table confidence="0.9995188">
Textbook Data News a
Dat
Precision Recall F1 Precision Recall F1
Known Constituent 91.85 88.02 89.86 80.30 66.80 72.93
Headword Location 38.87 57.29 46.32 37.89 42.01 39.84
</table>
<tableCaption confidence="0.981711">
Table 2 Results for Training on Different Datasets
</tableCaption>
<sectionHeader confidence="0.998537" genericHeader="method">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999975">
6.1 Role of Parse Information
</subsectionHeader>
<bodyText confidence="0.999980608695652">
According to Carreras and Màrquez (2004), the
state-of-the-art results for semantic role labelling
systems based on shallow syntactic information is
about 15 lower than those with access to gold stan-
dard parse trees, i.e., around 60. With homogene-
ous training and testing data, our experimental
results for the headword location condition, with
no syntactic information available at all, give an F1
score of 52.89 and 44.35 respectively for textbook
data and news data. Such results are in line with
and comparable to those reported for the unknown
boundary condition with automatic parses in
Gildea and Palmer (2002), for instance. Moreover,
when they used simple chunks instead of full
parses, the performance resulted in a drop to below
50% precision and 35% recall with relaxed scoring,
hence their conclusion on the necessity of a parser.
The more degradation in performance observed
in the news data is nevertheless within expectation,
and it suggests that simple and complex data seem
to have varied dependence on parse information.
We will further discuss this below in relation to
data homogeneity.
</bodyText>
<subsectionHeader confidence="0.999826">
6.2 Data Homogeneity
</subsectionHeader>
<bodyText confidence="0.999938926829268">
The usefulness of parse information for semantic
role labelling is especially interesting in the case of
Chinese, given the flexibility in its syntax-
semantics interface (e.g. the object after 吃 ‘eat’
could refer to the patient as in 吃蘋果 ‘eat apple’,
location as in 吃食堂 ‘eat canteen’, duration as in
吃三
年 ‘eat three years’, etc.).
As reflected from the results, the nature of
training data is obviously more important for the
news data than the textbook data; and the main
reason might be the failure of the simple training
data to capture the many complex structures of the
news sentences, as we suggested earlier. The rela-
tive flexibility in the syntax-semantics interface of
Chinese is particularly salient; hence when a sen-
tence gets more complicated, there might be more
intervening constituents and the parse information
would be useful to help identify the relevant ones
in semantic role labelling.
With respect to the data used in the experiment,
we tried to explore the complexity in terms of the
average sentence length and number of semantic
role patterns exhibited. For the news data, the av-
erage sentence length is around 59.7 characters
(syllables), and the number of semantic role pat-
terns varies from 4 (e.g. 打算 ‘to plan’) to as many
as 25 (e.g. 進行 ‘to proceed with some action’),
with an average of 9.5 patterns per verb. On the
other hand, the textbook data give an average sen-
tence length of around 39.7 characters, and the
number of semantic role patterns only varies from
1 (e.g. 決定 ‘to decide’) to 11 (e.g. 舉行 ‘to hold
some event’), with an average of 5.1 patterns per
verb. Interestingly, the verb 進 行 , being very
polymorphous in news texts, only shows 5 differ-
ent patterns in textbooks.
Thus the nature of the dataset for semantic role
labelling is worth further investigation. T he design
of the method and the feature set should benefit
from more linguistic analysis and input.
</bodyText>
<subsectionHeader confidence="0.935974">
6.3 Future Work
</subsectionHeader>
<bodyText confidence="0.9996714">
In terms of future development, apart from improv-
ing the handling of ties in our method, as men-
tioned above, we plan to expand our work in
several respects. The major part would be on the
generalization to unseen headwords and unseen
predicates. As is with other related studies, the
examples available for training for each target verb
are very limited; and the availability of training
data is also insufficient in the sense that we cannot
expect them to cover all target verb types. Hence
</bodyText>
<page confidence="0.9977">
7
</page>
<bodyText confidence="0.999990923076923">
it is very important to be able to generalize the
process to unseen words and predicates. To this
end we will experiment with a semantic lexicon
like Tongyici Cilin (同義puJpuJ林, a Chinese the-
saurus) in both training and testing, which we ex-
pect to improve the overall performance.
Another area of interest is to look at the behav-
iour of near-synonymous predicates in the tagging
process. Many predicates may be unseen in the
training data, but while the probability estimation
could be generalized from near-synonyms as sug-
gested by a semantic lexicon, whether the similar-
ity and subtle differences between near-synonyms
with respect to the argument structure and the cor-
responding syntactic realisation could be distin-
guished would also be worth studying. Related to
this is the possibility of augmenting the feature set.
Xue and Palmer (2004), for instance, looked into
new features such as syntactic frame, lexicalized
constituent type, etc., and found that enriching the
feature set improved the labelling performance. In
particular, given the importance of data homogene-
ity as observed from the experimental results, and
the challenges posed by the characteristic nature of
Chinese, we intend to improve our method and
feature set with more linguistic consideration.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999975666666667">
The study reported in this paper has thus tackled
semantic role labelling in Chinese in the absence of
parse information, by attempting to locate the cor-
responding headwords first. We experimented
with both simple and complex data, and have ex-
plored the effect of training on different datasets.
Using only parse-independent features, our results
under the known boundary condition are compara-
ble to those reported in related studies. The head-
word location method can be further improved.
More importantly, we have observed the impor-
tance of data homogeneity, which is especially sa-
lient given the relative flexibility of Chinese in its
syntax-semantics interface. As a next step, we
plan to explore some class-based techniques for the
task with reference to existing semantic lexicons,
and to modify the method and augment the feature
set with more linguistic input.
</bodyText>
<sectionHeader confidence="0.989264" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9343825">
This work is supported by Competitive Earmarked
Research Grants (CERG) of the Research Grants
Council of Hong Kong under grant Nos.
CityU1233/01H and CityU1317/03H.
</bodyText>
<sectionHeader confidence="0.996902" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999328880952381">
Baker, C.F., Fillmore, C.J. and Lowe, J.B. (1998) The
Berkeley FrameNet Project. In Proceedings of the
36th Annual Meeting of the Association for Computa-
tional Linguistics and the 17th International Confer-
ence on Computational Linguistics (COLING-
ACL ’98), Montreal, Quebec, Canada, pp.86-90.
Carreras, X. and Màrquez, L. (2004) Introduction to the
CoNLL-2004 Shared Task: Semantic Role Labeling.
In Proceedings of the Eighth Conference on Compu-
tational Natural Language Learning (CoNLL-2004),
Boston, Massachusetts, pp.89-97.
Fe
llbaum, C., Palmer, M., Dang, H.T., Delfs, L. and
Wolf, S. (2001) Manual and Automatic Semantic
Annotation with WordNet. In Proceedings of the
NAACL-01 SIGLEX Workshop on WordNet and
Other Lexical Resources, Invited Talk, Pittsburg, PA.
Gildea, D. and Jurafsky, D. (2002) Automatic Labeling
of Semantic Roles. Computational Linguistics, 28(3):
245-288.
Gildea, D. and Palmer, M. (2002) The Necessity of
Parsing for Predicate Argument Recognition. In Pro-
ceedings of the 40th Meeting of the Association for
Computational Linguistics (ACL-02), Philadelphia,
PA.
Gildea, D. and Hockenmaier, J. (2003) Identifying Se-
mantic Roles Using Combinatory Categorial Gram-
mar. In Proceedings of the 2003 Conference on
Empirical Methods in Natural Language Processing,
Sapporo, Japan.
Kingsbury, P. and Palmer, M. (2002) From TreeBank
to PropBank. In Proceedings of the Third Confer-
ence on Language Resources and Evaluation (LREC-
02), Las Palmas, Canary Islands, Spain.
Kipper, K., Palmer, M. and Rambow, O. (2002) Ex-
tending PropBank with VerbNet Semantic Predicates.
In Proceedings of the AMTA-2002 Workshop on Ap-
plied Interlinguas, Tiburon, CA.
Kwong, O.Y. and Tsou, B.K. (2003) Categorial Fluidity
in Chinese and its Implications for Part-of-speech
Tagging. In Proceedings of the Research Note Ses-
sion of the 10th Conference of the European Chapter
</reference>
<page confidence="0.976612">
8
</page>
<reference confidence="0.982381846153846">
of the Association for Computational Linguistics,
Budapest, Hungary, pages 115-118.
Lin, X., Wang, L. and Sun, D. (1994) Dictionary of
Verbs in Contemporary Chinese. Beijing Language
and Culture University Press.
Litkowski, K.C. (2004) SENSEVAL-3 Task: Automatic
Labeling of Semantic Roles. In Proceedings of the
Third International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text
(SENSEVAL-3), Barcelona, Spain, pp.9-12.
Sun, H. and Jurafsky, D. (2004) Shallow Semantic
Parsing of Chinese. In Proceedings of the Human
Language Technology Conference of the North
American Ch apter of the Association for Computa-
tional Linguistics (HLT-NAACL 2004), Boston,
pp.249-256.
er, R.S. and Stevenson, S. (2004) Unsupervised
Semantic Role Labelling. In Proceedings of the
2004 Conference on Empirical Methods in Natural
Language Processing, Barcelona, Spain, pp.95-102.
Tsou, B.K., Tsoi, W.F., Lai, T.B.Y., Hu, J. and Chan,
S.W.K. (2000) LIVAC, A Chinese Synchronous
Corpus, and Some Applications. In Proceedings of
the ICCLC International Conference on Chinese
Language Computing, Chicago, pp. 233-238.
Xue, N. and Palmer, M. (2004) Calibrating Features for
Semantic Role Labeling. In Proceedings of the 2004
Conference on Empirical Methods in Natural Lan-
guage Processing, Barcelona, Spain, pp.88-94.
You, J-M. and Chen, K-J. (2004) Automatic Semantic
Role Assignment for a Tree Structure. In Proceed-
ings of the 3rd SigHAN Workshop on Chinese Lan-
guage Processing, ACL-04, Barcelona, pp .109-115.
啟思中國語文 Qisi Zhongguo Yuwen. Primary 1-6, 24
volumes, 2004. Hong Kong: Keys Press.
現 代中國語文 Xiandai Zhongguo Yuwen. Primary 1-6,
24 volumes, 2004. Hong Kong: Modern Education
Research Society Ltd.
Swi
</reference>
<page confidence="0.98431">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.726559">
<title confidence="0.999144">Data Homogeneity and Semantic Role Tagging in Chinese</title>
<author confidence="0.985026">Oi Yee Kwong</author>
<author confidence="0.985026">K Benjamin</author>
<affiliation confidence="0.985752">Language Information Sciences Research City University of Hong</affiliation>
<address confidence="0.755601">Tat Chee Avenue, Kowloon, Hong Kong</address>
<email confidence="0.985533">rlolivia@cityu.edu.hk</email>
<email confidence="0.985533">rlbtsou@cityu.edu.hk</email>
<abstract confidence="0.999403318181818">This paper reports on a study of semantic role tagging in Chinese in the absence of a parser. We tackle the task by identifying the relevant headwords in a sentence as a first step to partially locate the corresponding constituents to be labelled. We also explore the effect of data homogeneity by experimenting with a textbook corpus and a news corpus, representing simple data and complex data respectively. Results suggest that while the headword location method remains to be improved, the homogeneity between the training and testing data is important especially in view of the characteristic syntaxsemantics interface in Chinese. We also plan to explore some class-based techniques for the task with reference to existing semantic lexicons, and to modify the method and augment the feature set with more linguistic input.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C F Baker</author>
<author>C J Fillmore</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLINGACL ’98),</booktitle>
<pages>86--90</pages>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="4690" citStr="Baker et al., 1998" startWordPosition="735" endWordPosition="738">parse information for indicating constituent boundaries in semantic role labelling. In Section 2, related work will be reviewed. In Section 3, the data used in the current study will be introduced. Our proposed method will be explained in Section 4, and the experiment reported in Section 5. Results and future work will be discussed in Section 6, followed by conclusions in Section 7. 2 Related Work The definition of semantic roles falls on a continuum from abstract ones to very specific ones. Gildea and Jurafsky (2002), for instance, used a set of roles defined according to the FrameNet model (Baker et al., 1998), thus corresponding to the frame elements in individual frames under a particular domain to which a given verb belongs. Lexical entries (in fact not limited to verbs, in the case of FrameNet) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Baker, C.F., Fillmore, C.J. and Lowe, J.B. (1998) The Berkeley FrameNet Project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLINGACL ’98), Montreal, Quebec, Canada, pp.86-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L Màrquez</author>
</authors>
<title>Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004),</booktitle>
<pages>89--97</pages>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="5240" citStr="Carreras and Màrquez, 2004" startWordPosition="826" endWordPosition="829">d a set of roles defined according to the FrameNet model (Baker et al., 1998), thus corresponding to the frame elements in individual frames under a particular domain to which a given verb belongs. Lexical entries (in fact not limited to verbs, in the case of FrameNet) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical treatment of semantic roles is also varied in Chinese. In practice, for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles similar to the thematic roles for English used in VerbNet (Kipper et al., 2002). These roles are generalisable to most Chinese verbs and are not dependent on particular predicates. They will be further introduced in Section 3. Approaches in automatic semantic role label</context>
<context position="6573" citStr="Carreras and Màrquez (2004)" startWordPosition="1046" endWordPosition="1049">entences. In Gildea and Jurafsky (2002), the features studied include phrase type (pt), governing category (gov), parse tree path (path), position of constituent with respect to the target predicate (position), voice (voice), and headword (h). The labelling of a constituent then depends on its likelihood to fill each possible role r given the features and the target predicate t, as in the following, for example: P r h pt gov position voice t ( |, , , , , Subsequent studies exploited a variety of implementation of the learning component. Transformation-based approaches were also used (e.g. see Carreras and Màrquez (2004) for an overview of systems participating in the CoNLL shared task). Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a bootstrapping algorithm, and achieved 87% accuracy. While the estimation of the probabilities could be relatively straightforward, the trick often lies in locating the candidate constituents to be labelled. A parser of some kind is needed. Gildea and Palmer (2002) compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in abo</context>
<context position="8525" citStr="Carreras and Màrquez (2004)" startWordPosition="1354" endWordPosition="1357">er to obtain full syntactic parses for the sentences, whereas systems participating in the CoNLL task were restricted to use only shallow ) 2 syntactic information. Results reported in the for- 3.2 Training and Testing Data mer tend to be higher. Although the dataset may For the current study, a set of 41 transitive verbs be a factor affecting the labelling performance, it common to the two corpora (hereafter referred to nevertheless reinforces the usefulness of full syn- as textbook corpus and news corpus), with fretactic information. quency over 10 and over 50 respectively, was According to Carreras and Màrquez (2004), for sampled. English, the state-of-the-art results reach an F1 Sentences in the corpora containing the sammeasure of slightly over 83 using gold standard pled verbs were extracted. Constituents correparse trees and about 77 with real parsing results. sponding to semantic roles with respect to the Those based on shallow syntactic information is target verbs were annotated by a trained human about 60. annotator and the annotation was verified by anIn this work, we study the problem in Chinese, other. In this study, we worked with a set of 11 treating it as a headword identification and label- </context>
<context position="21192" citStr="Carreras and Màrquez (2004)" startWordPosition="3431" endWordPosition="3434"> of or cannot be solved, then we go and ask father. Candidate Round 1 ... Round 4 Final Result Headwords 溫習 (revisio n) Patient 時候 (time) Time ---- Time 我們 (we) Agent Agent 平時 (normally) 想到 (think) Patient 能 (can) 解決 (solve) Patient 問題 (problem) Patient ---- Patient 去 (go) Patient 問 (ask) Patient 爸爸 (father) Patient 6 Textbook Data News a Dat Precision Recall F1 Precision Recall F1 Known Constituent 91.85 88.02 89.86 80.30 66.80 72.93 Headword Location 38.87 57.29 46.32 37.89 42.01 39.84 Table 2 Results for Training on Different Datasets 6 Discussion 6.1 Role of Parse Information According to Carreras and Màrquez (2004), the state-of-the-art results for semantic role labelling systems based on shallow syntactic information is about 15 lower than those with access to gold standard parse trees, i.e., around 60. With homogeneous training and testing data, our experimental results for the headword location condition, with no syntactic information available at all, give an F1 score of 52.89 and 44.35 respectively for textbook data and news data. Such results are in line with and comparable to those reported for the unknown boundary condition with automatic parses in Gildea and Palmer (2002), for instance. Moreove</context>
</contexts>
<marker>Carreras, Màrquez, 2004</marker>
<rawString>Carreras, X. and Màrquez, L. (2004) Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling. In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004), Boston, Massachusetts, pp.89-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fe llbaum</author>
<author>C Palmer</author>
<author>M Dang</author>
<author>H T Delfs</author>
<author>L</author>
<author>S Wolf</author>
</authors>
<title>Manual and Automatic Semantic Annotation with WordNet.</title>
<date>2001</date>
<booktitle>In Proceedings of the NAACL-01 SIGLEX Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Invited Talk, Pittsburg, PA.</location>
<contexts>
<context position="1518" citStr="llbaum et al., 2001" startWordPosition="232" endWordPosition="235">re some class-based techniques for the task with reference to existing semantic lexicons, and to modify the method and augment the feature set with more linguistic input. 1 Introduction As the development of language resources progresses from POS-tagged corpora to syntactically annotated treebanks, the inclusion of semantic information such as predicate-argument relations becomes indispensable. The expansion of the Penn Treebank into a Proposition Bank (Kingsbury and Palmer, 2002) is a typical move in this direction. Lexical resources also need to be enhanced with semantic information (e.g. Fellbaum et al., 2001). The ability to identify semantic role relations cor1 rectly is essential to many applications such as information extraction and machine translation; and making available resources with this kind of information would in turn facilitate the development of such applications. Large-scale production of annotated resources is often labour intensive, and thus calls for automatic labelling to streamline the process. The task is essentially done in two phases, namely recognising the constituents bearing some semantic relationship to the target verb in a sentence, and then labelling them with the cor</context>
</contexts>
<marker>llbaum, Palmer, Dang, Delfs, L, Wolf, 2001</marker>
<rawString>Fe llbaum, C., Palmer, M., Dang, H.T., Delfs, L. and Wolf, S. (2001) Manual and Automatic Semantic Annotation with WordNet. In Proceedings of the NAACL-01 SIGLEX Workshop on WordNet and Other Lexical Resources, Invited Talk, Pittsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<contexts>
<context position="2198" citStr="Gildea and Jurafsky (2002)" startWordPosition="336" endWordPosition="339"> rectly is essential to many applications such as information extraction and machine translation; and making available resources with this kind of information would in turn facilitate the development of such applications. Large-scale production of annotated resources is often labour intensive, and thus calls for automatic labelling to streamline the process. The task is essentially done in two phases, namely recognising the constituents bearing some semantic relationship to the target verb in a sentence, and then labelling them with the corresponding semantic roles. In their seminal proposal, Gildea and Jurafsky (2002) approached the task using various features such as headword, phrase type, and parse tree path. While such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing. The parse information is deemed important for the performance of role labelling (Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003). More precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for</context>
<context position="4594" citStr="Gildea and Jurafsky (2002)" startWordPosition="718" endWordPosition="721">fect of training on different datasets, simple or complex, to shed light on the relative importance of parse information for indicating constituent boundaries in semantic role labelling. In Section 2, related work will be reviewed. In Section 3, the data used in the current study will be introduced. Our proposed method will be explained in Section 4, and the experiment reported in Section 5. Results and future work will be discussed in Section 6, followed by conclusions in Section 7. 2 Related Work The definition of semantic roles falls on a continuum from abstract ones to very specific ones. Gildea and Jurafsky (2002), for instance, used a set of roles defined according to the FrameNet model (Baker et al., 1998), thus corresponding to the frame elements in individual frames under a particular domain to which a given verb belongs. Lexical entries (in fact not limited to verbs, in the case of FrameNet) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL</context>
<context position="5985" citStr="Gildea and Jurafsky (2002)" startWordPosition="945" endWordPosition="948">for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles similar to the thematic roles for English used in VerbNet (Kipper et al., 2002). These roles are generalisable to most Chinese verbs and are not dependent on particular predicates. They will be further introduced in Section 3. Approaches in automatic semantic role labelling are mostly statistical, typically making use of a number of features extracted from parsed training sentences. In Gildea and Jurafsky (2002), the features studied include phrase type (pt), governing category (gov), parse tree path (path), position of constituent with respect to the target predicate (position), voice (voice), and headword (h). The labelling of a constituent then depends on its likelihood to fill each possible role r given the features and the target predicate t, as in the following, for example: P r h pt gov position voice t ( |, , , , , Subsequent studies exploited a variety of implementation of the learning component. Transformation-based approaches were also used (e.g. see Carreras and Màrquez (2004) for an over</context>
<context position="11583" citStr="Gildea and Jurafsky (2002)" startWordPosition="1853" endWordPosition="1856"> of the LIVAC synchronous corpus1 (Tsou et al., 2000; Kwong and Tsou, 2003). The subcorpus consists of newspaper texts from Hong Kong, including local news, international news, financial news, sports news, and entertainment news, collected in 1997-98. The texts were segmented into words and POS-tagged, resulting in about 1.8M character tokens and upon segmentation about 1M word tokens (about 47K word types). There were about 7,400 transitive verb types, with frequency ranging from 1 to just over 6,300. 4 Automatic Role Labelling The automatic labelling was based on the statistical approach in Gildea and Jurafsky (2002). In Section 4.1, we will briefly mention the features used in the training process. Then in Sections 4.2 and 4.3, we will explain our approach for locating headwords in candidate constituents associated with semantic roles, in the absence of parse information. 2 These figures only refer to the samples used in the current study. In fact over 35,000 sentences in the LIVAC corpus have been semantically annotated, covering about 1,500 verb types and about 80,000 constituents were marked. 1 http://www.livac.org 3 4.1 Training In this study, our probability model was based mostly on parse-independe</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, D. and Jurafsky, D. (2002) Automatic Labeling of Semantic Roles. Computational Linguistics, 28(3): 245-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>M Palmer</author>
</authors>
<title>The Necessity of Parsing for Predicate Argument Recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Meeting of the Association for Computational Linguistics (ACL-02),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2636" citStr="Gildea and Palmer, 2002" startWordPosition="400" endWordPosition="403">bearing some semantic relationship to the target verb in a sentence, and then labelling them with the corresponding semantic roles. In their seminal proposal, Gildea and Jurafsky (2002) approached the task using various features such as headword, phrase type, and parse tree path. While such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing. The parse information is deemed important for the performance of role labelling (Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003). More precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data. Its limited function in training, for instance, is reflected in the low coverage reported (e.g. You and Chen, 2004). As full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses. This limitation is even more pertinent for the application of semantic role labelling to la</context>
<context position="4970" citStr="Gildea and Palmer (2002)" startWordPosition="784" endWordPosition="787">ed in Section 5. Results and future work will be discussed in Section 6, followed by conclusions in Section 7. 2 Related Work The definition of semantic roles falls on a continuum from abstract ones to very specific ones. Gildea and Jurafsky (2002), for instance, used a set of roles defined according to the FrameNet model (Baker et al., 1998), thus corresponding to the frame elements in individual frames under a particular domain to which a given verb belongs. Lexical entries (in fact not limited to verbs, in the case of FrameNet) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical treatment of semantic roles is also varied in Chinese. In practice, for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles </context>
<context position="6997" citStr="Gildea and Palmer (2002)" startWordPosition="1112" endWordPosition="1115">v position voice t ( |, , , , , Subsequent studies exploited a variety of implementation of the learning component. Transformation-based approaches were also used (e.g. see Carreras and Màrquez (2004) for an overview of systems participating in the CoNLL shared task). Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a bootstrapping algorithm, and achieved 87% accuracy. While the estimation of the probabilities could be relatively straightforward, the trick often lies in locating the candidate constituents to be labelled. A parser of some kind is needed. Gildea and Palmer (2002) compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in about 80% accuracy for subsequent automatic role tagging, but when boundaries are unknown, results with automatic parses dropped to 57% precision and 50% recall. With chunking only, performance further degraded to below 30%. Problems mostly arise from arguments which correspond to more than one chunk, and the misplacement of core arguments. Sun and Jurafsky (2004) also reported a drop in F-score with automatic syntactic par</context>
<context position="21769" citStr="Gildea and Palmer (2002)" startWordPosition="3522" endWordPosition="3525">mation According to Carreras and Màrquez (2004), the state-of-the-art results for semantic role labelling systems based on shallow syntactic information is about 15 lower than those with access to gold standard parse trees, i.e., around 60. With homogeneous training and testing data, our experimental results for the headword location condition, with no syntactic information available at all, give an F1 score of 52.89 and 44.35 respectively for textbook data and news data. Such results are in line with and comparable to those reported for the unknown boundary condition with automatic parses in Gildea and Palmer (2002), for instance. Moreover, when they used simple chunks instead of full parses, the performance resulted in a drop to below 50% precision and 35% recall with relaxed scoring, hence their conclusion on the necessity of a parser. The more degradation in performance observed in the news data is nevertheless within expectation, and it suggests that simple and complex data seem to have varied dependence on parse information. We will further discuss this below in relation to data homogeneity. 6.2 Data Homogeneity The usefulness of parse information for semantic role labelling is especially interestin</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Gildea, D. and Palmer, M. (2002) The Necessity of Parsing for Predicate Argument Recognition. In Proceedings of the 40th Meeting of the Association for Computational Linguistics (ACL-02), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>J Hockenmaier</author>
</authors>
<title>Identifying Semantic Roles Using Combinatory Categorial Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2667" citStr="Gildea and Hockenmaier, 2003" startWordPosition="404" endWordPosition="407">ationship to the target verb in a sentence, and then labelling them with the corresponding semantic roles. In their seminal proposal, Gildea and Jurafsky (2002) approached the task using various features such as headword, phrase type, and parse tree path. While such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing. The parse information is deemed important for the performance of role labelling (Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003). More precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data. Its limited function in training, for instance, is reflected in the low coverage reported (e.g. You and Chen, 2004). As full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses. This limitation is even more pertinent for the application of semantic role labelling to languages which do not have sophi</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Gildea, D. and Hockenmaier, J. (2003) Identifying Semantic Roles Using Combinatory Categorial Grammar. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
</authors>
<title>From TreeBank to PropBank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third Conference on Language Resources and Evaluation (LREC02),</booktitle>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="1383" citStr="Kingsbury and Palmer, 2002" startWordPosition="210" endWordPosition="213">he training and testing data is important especially in view of the characteristic syntaxsemantics interface in Chinese. We also plan to explore some class-based techniques for the task with reference to existing semantic lexicons, and to modify the method and augment the feature set with more linguistic input. 1 Introduction As the development of language resources progresses from POS-tagged corpora to syntactically annotated treebanks, the inclusion of semantic information such as predicate-argument relations becomes indispensable. The expansion of the Penn Treebank into a Proposition Bank (Kingsbury and Palmer, 2002) is a typical move in this direction. Lexical resources also need to be enhanced with semantic information (e.g. Fellbaum et al., 2001). The ability to identify semantic role relations cor1 rectly is essential to many applications such as information extraction and machine translation; and making available resources with this kind of information would in turn facilitate the development of such applications. Large-scale production of annotated resources is often labour intensive, and thus calls for automatic labelling to streamline the process. The task is essentially done in two phases, namely</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Kingsbury, P. and Palmer, M. (2002) From TreeBank to PropBank. In Proceedings of the Third Conference on Language Resources and Evaluation (LREC02), Las Palmas, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kipper</author>
<author>M Palmer</author>
<author>O Rambow</author>
</authors>
<title>Extending PropBank with VerbNet Semantic Predicates.</title>
<date>2002</date>
<booktitle>In Proceedings of the AMTA-2002 Workshop on Applied Interlinguas,</booktitle>
<location>Tiburon, CA.</location>
<contexts>
<context position="5649" citStr="Kipper et al., 2002" startWordPosition="894" endWordPosition="897"> PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical treatment of semantic roles is also varied in Chinese. In practice, for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles similar to the thematic roles for English used in VerbNet (Kipper et al., 2002). These roles are generalisable to most Chinese verbs and are not dependent on particular predicates. They will be further introduced in Section 3. Approaches in automatic semantic role labelling are mostly statistical, typically making use of a number of features extracted from parsed training sentences. In Gildea and Jurafsky (2002), the features studied include phrase type (pt), governing category (gov), parse tree path (path), position of constituent with respect to the target predicate (position), voice (voice), and headword (h). The labelling of a constituent then depends on its likeliho</context>
</contexts>
<marker>Kipper, Palmer, Rambow, 2002</marker>
<rawString>Kipper, K., Palmer, M. and Rambow, O. (2002) Extending PropBank with VerbNet Semantic Predicates. In Proceedings of the AMTA-2002 Workshop on Applied Interlinguas, Tiburon, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Y Kwong</author>
<author>B K Tsou</author>
</authors>
<title>Categorial Fluidity in Chinese and its Implications for Part-of-speech Tagging.</title>
<date>2003</date>
<booktitle>In Proceedings of the Research Note Session of the 10th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>115--118</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="11032" citStr="Kwong and Tsou, 2003" startWordPosition="1768" endWordPosition="1771"> sets of primary school Chinese textbooks popularly used in Hong Kong were taken for reference. The two publishers were Keys Press and Modern Education Research Society Ltd. Texts for Primary One to Six were digitised, segmented into words, and annotated with parts-of-speech (POS). This results in a text collection of about 165K character tokens and upon segmentation about 109K word tokens (about 15K word types). There were about 2,500 transitive verb types, with frequency ranging from 1 to 926. The complex examples were taken from a subset of the LIVAC synchronous corpus1 (Tsou et al., 2000; Kwong and Tsou, 2003). The subcorpus consists of newspaper texts from Hong Kong, including local news, international news, financial news, sports news, and entertainment news, collected in 1997-98. The texts were segmented into words and POS-tagged, resulting in about 1.8M character tokens and upon segmentation about 1M word tokens (about 47K word types). There were about 7,400 transitive verb types, with frequency ranging from 1 to just over 6,300. 4 Automatic Role Labelling The automatic labelling was based on the statistical approach in Gildea and Jurafsky (2002). In Section 4.1, we will briefly mention the fea</context>
</contexts>
<marker>Kwong, Tsou, 2003</marker>
<rawString>Kwong, O.Y. and Tsou, B.K. (2003) Categorial Fluidity in Chinese and its Implications for Part-of-speech Tagging. In Proceedings of the Research Note Session of the 10th Conference of the European Chapter of the Association for Computational Linguistics, Budapest, Hungary, pages 115-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Lin</author>
<author>L Wang</author>
<author>D Sun</author>
</authors>
<title>Dictionary of Verbs in Contemporary Chinese. Beijing Language and Culture</title>
<date>1994</date>
<publisher>University Press.</publisher>
<contexts>
<context position="9429" citStr="Lin et al., 1994" startWordPosition="1501" endWordPosition="1504">spect to the Those based on shallow syntactic information is target verbs were annotated by a trained human about 60. annotator and the annotation was verified by anIn this work, we study the problem in Chinese, other. In this study, we worked with a set of 11 treating it as a headword identification and label- predicate-independent abstract semantic roles. ling task in the absence of parse information, and According to the Dictionary of Verbs in Contemexamine how the nature of the dataset could affect porary Chinese (Xiandai Hanyu Dongci Dacidian, the role tagging performance. fe pjpuJ�puJ – Lin et al., 1994), our semantic roles include the necessary arguments for most verbs such as agent and patient, or goal and location in some cases; and some optional arguments realised by adjuncts, such as quantity, instrument, and source. Some examples of semantic roles with respect to a given predicate are shown in Figure 1. Altogether 980 sentences covering 41 verb types in the textbook corpus were annotated, resulting in 1,974 marked semantic roles (constituents); and 2,122 sentences covering 41 verb types in the news corpus were annotated, resulting in 4,933 marked constituents2. The role labelling system</context>
</contexts>
<marker>Lin, Wang, Sun, 1994</marker>
<rawString>Lin, X., Wang, L. and Sun, D. (1994) Dictionary of Verbs in Contemporary Chinese. Beijing Language and Culture University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>SENSEVAL-3 Task: Automatic Labeling of Semantic Roles.</title>
<date>2004</date>
<booktitle>In Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),</booktitle>
<pages>9--12</pages>
<location>Barcelona,</location>
<contexts>
<context position="5273" citStr="Litkowski, 2004" startWordPosition="832" endWordPosition="833">ameNet model (Baker et al., 1998), thus corresponding to the frame elements in individual frames under a particular domain to which a given verb belongs. Lexical entries (in fact not limited to verbs, in the case of FrameNet) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical treatment of semantic roles is also varied in Chinese. In practice, for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles similar to the thematic roles for English used in VerbNet (Kipper et al., 2002). These roles are generalisable to most Chinese verbs and are not dependent on particular predicates. They will be further introduced in Section 3. Approaches in automatic semantic role labelling are mostly statistical, typi</context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>Litkowski, K.C. (2004) SENSEVAL-3 Task: Automatic Labeling of Semantic Roles. In Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), Barcelona, Spain, pp.9-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sun</author>
<author>D Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing of Chinese.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North</booktitle>
<contexts>
<context position="7536" citStr="Sun and Jurafsky (2004)" startWordPosition="1196" endWordPosition="1199">nstituents to be labelled. A parser of some kind is needed. Gildea and Palmer (2002) compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in about 80% accuracy for subsequent automatic role tagging, but when boundaries are unknown, results with automatic parses dropped to 57% precision and 50% recall. With chunking only, performance further degraded to below 30%. Problems mostly arise from arguments which correspond to more than one chunk, and the misplacement of core arguments. Sun and Jurafsky (2004) also reported a drop in F-score with automatic syntactic parses compared to perfect parses for role labelling in Chinese, despite the comparatively good results of their parser (i.e. the Collins parser ported to Chinese). The necessity of parse information is also reflected from recent evaluation exercises. For instance, most systems in SENSEVAL-3 used a parser to obtain full syntactic parses for the sentences, whereas systems participating in the CoNLL task were restricted to use only shallow ) 2 syntactic information. Results reported in the for- 3.2 Training and Testing Data mer tend to be</context>
</contexts>
<marker>Sun, Jurafsky, 2004</marker>
<rawString>Sun, H. and Jurafsky, D. (2004) Shallow Semantic Parsing of Chinese. In Proceedings of the Human Language Technology Conference of the North</rawString>
</citation>
<citation valid="false">
<booktitle>American Ch apter of the Association for Computational Linguistics (HLT-NAACL 2004),</booktitle>
<pages>249--256</pages>
<location>Boston,</location>
<marker></marker>
<rawString>American Ch apter of the Association for Computational Linguistics (HLT-NAACL 2004), Boston, pp.249-256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S er</author>
<author>S Stevenson</author>
</authors>
<title>Unsupervised Semantic Role Labelling.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>95--102</pages>
<location>Barcelona,</location>
<contexts>
<context position="6668" citStr="er and Stevenson (2004)" startWordPosition="1061" endWordPosition="1064">ategory (gov), parse tree path (path), position of constituent with respect to the target predicate (position), voice (voice), and headword (h). The labelling of a constituent then depends on its likelihood to fill each possible role r given the features and the target predicate t, as in the following, for example: P r h pt gov position voice t ( |, , , , , Subsequent studies exploited a variety of implementation of the learning component. Transformation-based approaches were also used (e.g. see Carreras and Màrquez (2004) for an overview of systems participating in the CoNLL shared task). Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a bootstrapping algorithm, and achieved 87% accuracy. While the estimation of the probabilities could be relatively straightforward, the trick often lies in locating the candidate constituents to be labelled. A parser of some kind is needed. Gildea and Palmer (2002) compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in about 80% accuracy for subsequent automatic role tagging, but when boundaries are unknown, results</context>
</contexts>
<marker>er, Stevenson, 2004</marker>
<rawString>er, R.S. and Stevenson, S. (2004) Unsupervised Semantic Role Labelling. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain, pp.95-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Tsou</author>
<author>W F Tsoi</author>
<author>T B Y Lai</author>
<author>J Hu</author>
<author>S W K Chan</author>
</authors>
<title>LIVAC, A Chinese Synchronous Corpus, and Some Applications.</title>
<date>2000</date>
<booktitle>In Proceedings of the ICCLC International Conference on Chinese Language Computing,</booktitle>
<pages>233--238</pages>
<location>Chicago,</location>
<contexts>
<context position="11009" citStr="Tsou et al., 2000" startWordPosition="1764" endWordPosition="1767">mplex examples. Two sets of primary school Chinese textbooks popularly used in Hong Kong were taken for reference. The two publishers were Keys Press and Modern Education Research Society Ltd. Texts for Primary One to Six were digitised, segmented into words, and annotated with parts-of-speech (POS). This results in a text collection of about 165K character tokens and upon segmentation about 109K word tokens (about 15K word types). There were about 2,500 transitive verb types, with frequency ranging from 1 to 926. The complex examples were taken from a subset of the LIVAC synchronous corpus1 (Tsou et al., 2000; Kwong and Tsou, 2003). The subcorpus consists of newspaper texts from Hong Kong, including local news, international news, financial news, sports news, and entertainment news, collected in 1997-98. The texts were segmented into words and POS-tagged, resulting in about 1.8M character tokens and upon segmentation about 1M word tokens (about 47K word types). There were about 7,400 transitive verb types, with frequency ranging from 1 to just over 6,300. 4 Automatic Role Labelling The automatic labelling was based on the statistical approach in Gildea and Jurafsky (2002). In Section 4.1, we will </context>
</contexts>
<marker>Tsou, Tsoi, Lai, Hu, Chan, 2000</marker>
<rawString>Tsou, B.K., Tsoi, W.F., Lai, T.B.Y., Hu, J. and Chan, S.W.K. (2000) LIVAC, A Chinese Synchronous Corpus, and Some Applications. In Proceedings of the ICCLC International Conference on Chinese Language Computing, Chicago, pp. 233-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>M Palmer</author>
</authors>
<title>Calibrating Features for Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>88--94</pages>
<location>Barcelona,</location>
<contexts>
<context position="25538" citStr="Xue and Palmer (2004)" startWordPosition="4156" endWordPosition="4159">ting, which we expect to improve the overall performance. Another area of interest is to look at the behaviour of near-synonymous predicates in the tagging process. Many predicates may be unseen in the training data, but while the probability estimation could be generalized from near-synonyms as suggested by a semantic lexicon, whether the similarity and subtle differences between near-synonyms with respect to the argument structure and the corresponding syntactic realisation could be distinguished would also be worth studying. Related to this is the possibility of augmenting the feature set. Xue and Palmer (2004), for instance, looked into new features such as syntactic frame, lexicalized constituent type, etc., and found that enriching the feature set improved the labelling performance. In particular, given the importance of data homogeneity as observed from the experimental results, and the challenges posed by the characteristic nature of Chinese, we intend to improve our method and feature set with more linguistic consideration. 7 Conclusion The study reported in this paper has thus tackled semantic role labelling in Chinese in the absence of parse information, by attempting to locate the correspon</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Xue, N. and Palmer, M. (2004) Calibrating Features for Semantic Role Labeling. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain, pp.88-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-M You</author>
<author>K-J Chen</author>
</authors>
<title>Automatic Semantic Role Assignment for a Tree Structure.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd SigHAN Workshop on Chinese Language Processing, ACL-04,</booktitle>
<pages>109--115</pages>
<location>Barcelona,</location>
<contexts>
<context position="2947" citStr="You and Chen, 2004" startWordPosition="446" endWordPosition="449">the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing. The parse information is deemed important for the performance of role labelling (Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003). More precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data. Its limited function in training, for instance, is reflected in the low coverage reported (e.g. You and Chen, 2004). As full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses. This limitation is even more pertinent for the application of semantic role labelling to languages which do not have sophisticated parsing resources. In the case of Chinese, for example, there is conProceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 1–9, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics siderable variability in its syntax-semantics interfa</context>
<context position="5498" citStr="You and Chen, 2004" startWordPosition="866" endWordPosition="869">et) falling under the same frame will share the same set of roles. Gildea and Palmer (2002) defined roles with respect to individual predicates in the PropBank, without explicit naming. To date PropBank and FrameNet are the two main resources in English for training semantic role labelling systems, as in the CoNLL-2004 shared task (Carreras and Màrquez, 2004) and SENSEVAL-3 (Litkowski, 2004). The theoretical treatment of semantic roles is also varied in Chinese. In practice, for example, the semantic roles in the Sinica Treebank mark not only verbal arguments but also modifier-head relations (You and Chen, 2004). In our present study, we go for a set of more abstract semantic roles similar to the thematic roles for English used in VerbNet (Kipper et al., 2002). These roles are generalisable to most Chinese verbs and are not dependent on particular predicates. They will be further introduced in Section 3. Approaches in automatic semantic role labelling are mostly statistical, typically making use of a number of features extracted from parsed training sentences. In Gildea and Jurafsky (2002), the features studied include phrase type (pt), governing category (gov), parse tree path (path), position of co</context>
</contexts>
<marker>You, Chen, 2004</marker>
<rawString>You, J-M. and Chen, K-J. (2004) Automatic Semantic Role Assignment for a Tree Structure. In Proceedings of the 3rd SigHAN Workshop on Chinese Language Processing, ACL-04, Barcelona, pp .109-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qisi</author>
</authors>
<title>Zhongguo Yuwen. Primary 1-6, 24 volumes,</title>
<date>2004</date>
<publisher>Keys Press.</publisher>
<marker>Qisi, 2004</marker>
<rawString>啟思中國語文 Qisi Zhongguo Yuwen. Primary 1-6, 24 volumes, 2004. Hong Kong: Keys Press.</rawString>
</citation>
<citation valid="true">
<title>Xiandai Zhongguo Yuwen. Primary 1-6, 24 volumes,</title>
<date>2004</date>
<institution>Hong Kong: Modern Education Research Society Ltd.</institution>
<contexts>
<context position="6573" citStr="(2004)" startWordPosition="1049" endWordPosition="1049">nd Jurafsky (2002), the features studied include phrase type (pt), governing category (gov), parse tree path (path), position of constituent with respect to the target predicate (position), voice (voice), and headword (h). The labelling of a constituent then depends on its likelihood to fill each possible role r given the features and the target predicate t, as in the following, for example: P r h pt gov position voice t ( |, , , , , Subsequent studies exploited a variety of implementation of the learning component. Transformation-based approaches were also used (e.g. see Carreras and Màrquez (2004) for an overview of systems participating in the CoNLL shared task). Swier and Stevenson (2004) innovated with an unsupervised approach to the problem, using a bootstrapping algorithm, and achieved 87% accuracy. While the estimation of the probabilities could be relatively straightforward, the trick often lies in locating the candidate constituents to be labelled. A parser of some kind is needed. Gildea and Palmer (2002) compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in abo</context>
<context position="8525" citStr="(2004)" startWordPosition="1357" endWordPosition="1357">tactic parses for the sentences, whereas systems participating in the CoNLL task were restricted to use only shallow ) 2 syntactic information. Results reported in the for- 3.2 Training and Testing Data mer tend to be higher. Although the dataset may For the current study, a set of 41 transitive verbs be a factor affecting the labelling performance, it common to the two corpora (hereafter referred to nevertheless reinforces the usefulness of full syn- as textbook corpus and news corpus), with fretactic information. quency over 10 and over 50 respectively, was According to Carreras and Màrquez (2004), for sampled. English, the state-of-the-art results reach an F1 Sentences in the corpora containing the sammeasure of slightly over 83 using gold standard pled verbs were extracted. Constituents correparse trees and about 77 with real parsing results. sponding to semantic roles with respect to the Those based on shallow syntactic information is target verbs were annotated by a trained human about 60. annotator and the annotation was verified by anIn this work, we study the problem in Chinese, other. In this study, we worked with a set of 11 treating it as a headword identification and label- </context>
<context position="21192" citStr="(2004)" startWordPosition="3434" endWordPosition="3434">ed, then we go and ask father. Candidate Round 1 ... Round 4 Final Result Headwords 溫習 (revisio n) Patient 時候 (time) Time ---- Time 我們 (we) Agent Agent 平時 (normally) 想到 (think) Patient 能 (can) 解決 (solve) Patient 問題 (problem) Patient ---- Patient 去 (go) Patient 問 (ask) Patient 爸爸 (father) Patient 6 Textbook Data News a Dat Precision Recall F1 Precision Recall F1 Known Constituent 91.85 88.02 89.86 80.30 66.80 72.93 Headword Location 38.87 57.29 46.32 37.89 42.01 39.84 Table 2 Results for Training on Different Datasets 6 Discussion 6.1 Role of Parse Information According to Carreras and Màrquez (2004), the state-of-the-art results for semantic role labelling systems based on shallow syntactic information is about 15 lower than those with access to gold standard parse trees, i.e., around 60. With homogeneous training and testing data, our experimental results for the headword location condition, with no syntactic information available at all, give an F1 score of 52.89 and 44.35 respectively for textbook data and news data. Such results are in line with and comparable to those reported for the unknown boundary condition with automatic parses in Gildea and Palmer (2002), for instance. Moreove</context>
<context position="25538" citStr="(2004)" startWordPosition="4159" endWordPosition="4159">expect to improve the overall performance. Another area of interest is to look at the behaviour of near-synonymous predicates in the tagging process. Many predicates may be unseen in the training data, but while the probability estimation could be generalized from near-synonyms as suggested by a semantic lexicon, whether the similarity and subtle differences between near-synonyms with respect to the argument structure and the corresponding syntactic realisation could be distinguished would also be worth studying. Related to this is the possibility of augmenting the feature set. Xue and Palmer (2004), for instance, looked into new features such as syntactic frame, lexicalized constituent type, etc., and found that enriching the feature set improved the labelling performance. In particular, given the importance of data homogeneity as observed from the experimental results, and the challenges posed by the characteristic nature of Chinese, we intend to improve our method and feature set with more linguistic consideration. 7 Conclusion The study reported in this paper has thus tackled semantic role labelling in Chinese in the absence of parse information, by attempting to locate the correspon</context>
</contexts>
<marker>2004</marker>
<rawString>現 代中國語文 Xiandai Zhongguo Yuwen. Primary 1-6, 24 volumes, 2004. Hong Kong: Modern Education Research Society Ltd.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>