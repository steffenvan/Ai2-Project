<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003342">
<title confidence="0.999081">
Hybrid Approaches to Improvement of Translation Quality
in Web-based English-Korean Machine Translation
</title>
<author confidence="0.817695">
Sung-Kwon Choi, Han-Min Jung,
Chul-Min Sim, Taewan Kim, Dong-In Park
</author>
<address confidence="0.794991666666667">
MT Lab. SERI
1 Eoun-dong, Yuseong-gu,
Taejon, 305-333, Korea
</address>
<email confidence="0.985479">
{skchoi, jhm, cmsim, twkim, dipark}@serise.kr
</email>
<author confidence="0.952875">
Jun-Sik Park, Key-Sun Choi
</author>
<affiliation confidence="0.998341">
Dept. of Computer Science, KAIST
</affiliation>
<address confidence="0.9059795">
373-1 Kusong-dong, Yuseong-gu,
Taejon, 305-701, Korea
</address>
<email confidence="0.969054">
jspark@world.kaist.ac.kr
kschoi@cs.kaist.ac.kr
</email>
<sectionHeader confidence="0.998412" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999781958333333">
The previous English-Korean MT system
that was the transfer-based MT system and
applied to only written text enumerated a
following brief list of the problems that had
not seemed to be easy to solve in the near
future : 1) processing of non-continuous
idiomatic expressions 2) reduction of too
many ambiguities in English syntactic
analysis 3) robust processing for failed or ill-
formed sentences 4) selecting correct word
correspondence between several alternatives
5) generation of Korean sentence style. The
problems can be considered as factors that
have influence on the translation quality of
machine translation system. This paper
describes the symbolic and statistical hybrid
approaches to solutions of problems of the
previous English-to-Korean machine
translation system in terms of the
improvement of translation quality. The
solutions are now successfully applied to the
web-based English-Korean machine
translation system &amp;quot;FromTo/EK&amp;quot; which has
been developed from 1997.
</bodyText>
<sectionHeader confidence="0.981959" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999349">
The transfer-based English-to-Korean machine
translation system &amp;quot;MATES/EK&amp;quot; that has been
developed from 1988 to 1992 in KAIST(Korean
Advanced Institute of Science and Technology)
and SERI(Systems Engineering Research
Institute) enumerated following list that doesn&apos;t
seem to be easy to solve in the near future in
terms of the problems for evolution of the
system (Choi et. al., 1994) :
</bodyText>
<listItem confidence="0.998246444444444">
• processing of non-continuous idiomatic
expressions
• generation of Korean sentence style
• reduction or ranking of too many
ambiguities in English syntactic analysis
• robust processing for failed or ill-formed
sentences
• selecting correct word correspondency
between several alternatives
</listItem>
<bodyText confidence="0.999818111111111">
The problems result in dropping a translation
assessment such as fidelity, intelligibility, and
style (Hutchins and Somers, 1992). They can be
the problems with which MATES/EK as well as
other MT systems have faced.
This paper describes the symbolic and statistical
hybird approaches to solve the problems and to
improve the translation quality of web-based
English-to-Korean machine translation.
</bodyText>
<sectionHeader confidence="0.929399" genericHeader="method">
1 System Overview
</sectionHeader>
<bodyText confidence="0.997430428571429">
English-to-Korean machine translation system
&amp;quot;FromTo/EK&amp;quot; has been developed from 1997,
solving the problems of its predecessor
&amp;quot;MATES/EK&amp;quot; and expanding its coverage to
WWW. FromTo/EK has basically the same
formalism as MATES/EK that does English
sentence analysis, transforms the result (parse
</bodyText>
<page confidence="0.998361">
251
</page>
<figureCaption confidence="0.999978">
Figure 1: The System Configuration of FromTo/EK
</figureCaption>
<figure confidence="0.993714444444444">
Tont
r ran .1•11.11
U1
Teat
r•nslalIen
UI
Domain
R eonioor
English
M orph.
An•lyter
English
Syn...R elation.
Barter
E ng-K.,
Transfer
Keratin
hsts.-M orp.
Generator
Learning
C rani ru
ss
Dependent,
C ram m
Glollon•ry
&amp;quot;••■
000s
English
An•Is-tit
Com pound
nil
Diction:4es
Dietionar,
Bilingu•1
(
ictionar,
U ser
In
User
In
Translation Engine
•oftener
Per-fail
•o (leiter
K now ledge and Dictionary
</figure>
<bodyText confidence="0.99932475">
tree) into an intermediate representation, and
then transforms it into a Korean syntactic
structure to construct a Korean sentence. Figure
1 shows the overall configuration of FromTo/EK.
FromTo/EK consists of user interface for
English and Korean, translation engine, and
knowledge and dictionaries. The black boxes in
the Figure 1 mean the modules that have existed
in MATES/EK, while the white ones are the new
modules that have been developed to improve
the translation quality. Next chapters describe
the new modules in detail.
</bodyText>
<subsectionHeader confidence="0.599216">
2 Domain Recognizer and Korean
sentence style
</subsectionHeader>
<bodyText confidence="0.999981894736842">
In order to identify the domain of text and
connect it to English terminology lexicon and
Korean sentence style in Korean generation, we
have developed a domain recognizer.
We adapted a semi-automated decision tree
induction using C4.5 (Quinlan, 1993) among
diverse approaches to text categorization such as
decision tree induction (Lewis et. al., 1994) and
neural networks (Ng et. al., 1997), because a
semi-automated approach showed perhaps the
best performance in domain identification
according to (Ng et. al., 1997). Twenty-five
domains were manually chosen from the
categories of awarded Web sites. We collected
0.4 million Web pages by using Web search
robot and counted the frequency of words to
extract features for domain recognition. The
words that appeared more than 200 times were
used as features. Besides we added some
manually chosen words to features because the
features extracted automatically were not able to
show the high accuracy.
Given an input text, our domain recognizer
assigns one or more domains to an input text.
The domains can raise the translation quality by
activating the corresponding domain-specific
terminology and selecting the correct Korean
sentence style. For example, given a &amp;quot;driver&amp;quot;, it
may be screw driver, taxi driver or device driver
program. After domain recognizer determines
each domain of input text, &amp;quot;driver&amp;quot; can be
translated into its appropriate Korean equivalent.
The domain selected by the domain recognizer is
able to have a contribution to generate a better
Korean sentence style because Korean sentence
style can be represented in various ways by the
verbal endings relevant to the domain. For
example, the formal domains such as technology
</bodyText>
<page confidence="0.98485">
252
</page>
<bodyText confidence="0.9998915">
and law etc. make use of the plain verbal ending
like `ta&apos; because they have carateristics of
formality, while the informal domains such as
weather, food and fashion etc. are related to the
polite verbal ending `supnita&apos; because they have
carateristics of politeness.
</bodyText>
<sectionHeader confidence="0.9971" genericHeader="method">
3 Compound Unit Recognition
</sectionHeader>
<bodyText confidence="0.999617733333333">
One of the problems of rule-based translation
has been the idiomatic expression which has
been dealt mainly with syntactic grammar rules
(Katoh and Aizawa, 1995) &amp;quot;Mary keeps up with
her brilliant classmates.&amp;quot; and &amp;quot;I prevent him
from going there.&amp;quot; are simple examples of
uninterupted and interupted idiomatic
expressions expectively.
In order to solve idiomatic expressions as well as
collocations and frozen compound nouns, we
have developed the compound unit(CU)
recognizer (Jung et. al., 1997). It is a plug-in
model locating between morphological and
syntactic analyzer. Figure 2 shows the structure
of CU recognizer.
</bodyText>
<figureCaption confidence="0.957707">
Figure 2 : System structure of CU recognizer
</figureCaption>
<bodyText confidence="0.999949916666667">
The recognizer searches all possible CUs in the
input sentence using co-occurrence constraint
string/POS and syntactic constraint and makes
the CU index. Syntactic verifier checks the
syntactic verification of variable constituents in
CU. For syntactic verifier we use a partial
parsing mechanism. Partial parser operates on
cyclic trie and simple CFG rules for the fast
syntactic constraint check. The experimental
result showed our syntactic verification
increased the precision of CU recognition to
99.69%.
</bodyText>
<sectionHeader confidence="0.998013" genericHeader="method">
4 Competitive Learning Grammar
</sectionHeader>
<bodyText confidence="0.999942083333333">
For the parse tree ranking of too many
ambiguities in English syntactic analysis, we use
the mechanism to insert the competitive
probabilistics into the rules. To decide the
correct parse tree ranking, we compare two
partial parse trees on the same node level with
competitive relation and add a (currently, 0.01)
to the better one, but subtract a from the worse
one on the base of the intuition of linguists. This
results now in raising the better parse tree higher
in the ranking list of the parse trees than the
worse one.
</bodyText>
<sectionHeader confidence="0.991784" genericHeader="method">
5 Robust Translation
</sectionHeader>
<bodyText confidence="0.99988">
In order to deal with long sentences, parsing-
failed or ill-formed sentences, we activate the
robust translation. It consists of two steps: first,
long sentence segmentation and then fail
softening.
</bodyText>
<subsectionHeader confidence="0.998998">
5.1 Long Sentence Segmentation
</subsectionHeader>
<bodyText confidence="0.999655285714286">
The grammar rules have generally a weak point
to cover long sentences. If there are no grammar
rules to process a long sentence, the whole parse
tree of a sentence can not be produced. Long
sentence segmentation produces simple
fragements from long sentences before parsing
fails.
We use the POS sequence of input sentence as a
clue of the segmentation. If the length of input
sentence exceeds pre-defined threshold,
currently 21 for segmentation level I and 25 for
level II, the sentence is divided into two or more
parts. Each POS trigram is separately applied to
the level I or II. After segmenting, each part of
</bodyText>
<figure confidence="0.998222571428571">
English —• McaPlrakSical
Analyzer ---
CURecognizr
CU DictionatD
CU Finder
Co-occummce Constraint String/POS
Syntactic Constraint
Syntactic Verifier
CFG Grammar
Partial Parser
Grammar Index 41
4&apos;
Korean I— Splenetic Analyzer
Search Index
</figure>
<page confidence="0.998106">
253
</page>
<bodyText confidence="0.99882845">
input sentence is analyzed and translated. The
following example shows an extremely long
sentence (45 words) and its long sentence
segmentation result.
[Input sentence]
&amp;quot;Were we to assemble a Valkyrie to challenge
IBM, we could play Deep Blue in as many
games as IBM wanted us to in a single match, in
fact, we could even play multiple games at the
same time. Now - - wouldn&apos;t that be
interesting?&amp;quot;
[Long Sentence Segmentation]
&amp;quot;Were we to assemble a Valkyrie to challenge
IBM, / (noun PUNCT pron) we could play Deep
Blue in as many games as IBM wanted us to in a
single match, / (noun PUNCT adv) in fact, /
(noun PUNCT pron) we could even play
multiple games at the same time, / (adv PUNCT
adv) Now - - / (PUNCT PUNCT aux) wouldn&apos;t
that be interesting?&amp;quot;
</bodyText>
<subsectionHeader confidence="0.999767">
5.2 Fail Softening
</subsectionHeader>
<bodyText confidence="0.999979238095238">
For robust translation we have a module &apos;fail
softening&apos; that processes the failed parse trees in
case of parsing failure. Fail softening finds set of
edges that covers a whole input sentence and
makes a parse tree using a virtual sentence tag.
We use left-to-right and right-to-left scanning
with &amp;quot;longer-edge-first&amp;quot; policy. In case that there
is no a set of edges for input sentence in a
scanning, the other scanning is preferred. If both
make a set of edges respectively, &amp;quot;smaller-set-
first&amp;quot; policy is applied to select a preferred set,
that is, the number of edges in one set should be
smaller than that of the other (e.g. if n(LR)=6
and n(RL)=5, then n(RL) is selected as the first
ranked parse tree, where n(LR) is the number of
left-to-right scanned edges, and n(RL) is the
number of right-to-left scanned edges). We use a
virtual sentence tag to connect the selected set of
edges. One of our future works is to have a
mechanism to give a weight into each edge by
syntactic preference.
</bodyText>
<sectionHeader confidence="0.96721" genericHeader="method">
6 Large Collocation Dictionary
</sectionHeader>
<bodyText confidence="0.999913545454545">
We select a correct word equivalent by using
lexical semantic marker as information
constraint and large collocation dictionary in the
transfer phase.
The lexical semantic marker is applied to the
terminal node for the relational representation,
while the collocation information is applied to
the non-terminal node.
The large collocation dictionary has been
collected from two resources; EDR dictionary
and Web documents.
</bodyText>
<sectionHeader confidence="0.819662" genericHeader="evaluation">
7 Test and Evaluation
</sectionHeader>
<bodyText confidence="0.999843379310345">
A semi-automated decision tree of our domain
recognizer uses as a feature twenty to sixty
keywords which are representative words
extracted from twenty-five domains. To raise the
accuracy of the domain identifier, manually
chosen words has been also added as features.
For learning of the domain identifier, each
thousand sentence from twenty-five domains is
used as training sets. We tested 250 sentences
that are the summation of each ten sentences
extracted from twenty-five domains. These test
sentences were not part of training sets. The
domain identifier outputs two top domains as its
result. The accuracy of first top domain shows
45% for 113 sentences. When second top
domains are applied, the accuracy rises up to
75%.
In FromTo/EK, the analysis dictionary consists
of about 70,000 English words, 15,000 English
compound units, 80,000 English-Korean
bilingual words, and 50,000 bilingual
collocations. The domain dictionary has 5,000
words for computer science that were extracted
from IEEE reports.
In order to make the evaluation as objective as
possible we compared FromTo/EK with
MATES/EK on 1,708 sentences in the IEEE
computer magazine September 1991 issue,
which MATES/EK had tested in 1994 and
</bodyText>
<page confidence="0.991457">
254
</page>
<bodyText confidence="0.5623175">
whose length had been less than 26 words. Table
1 shows the evaluation criteria.
</bodyText>
<tableCaption confidence="0.999141">
Table 1: The evaluation criteria
</tableCaption>
<table confidence="0.926310545454545">
Degree Meaning
4 The meaning of the sentence is
(Perfect) perfectly clear.
3 (Good) The meaning of the sentence is
almost clear.
2 (OK) The meaning of the sentence can be
understood after several readings.
1 (Poor) The meaning of the sentence can be
guessed only after a lot of readings.
0 (Fail) The meaning of the sentence
cannot be guessed at all.
</table>
<bodyText confidence="0.999458">
With the evaluation criteria three master degree
students whom we randomly selected compared
and evaluated the translation results of 1,708
sentences of MATES/EK and those of
FromTo/EK. We have considered the degrees 4,
3, and 2 in the table 1 as successful translation
results. Figure 3 shows the evaluation result.
</bodyText>
<table confidence="0.868698923076923">
(Number of oaccamfully
transimed minas)
. IN 42 64 76 62 m F iNv3 I 97 103 116 1o. 121 ., 10 35
, 42 74 68 .... 1 0 101 1 7,
9 il? ee 1 81
9
I&amp;quot;
112 142 112 ee ra
1 9 19 6
14
:. T I
57 53 42
MATESUCi
</table>
<figure confidence="0.8091785">
5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 23 21 23 24
(Length of lenience)
</figure>
<figureCaption confidence="0.96307">
Figure 3 : The evaluation of 1,708 sentences
</figureCaption>
<bodyText confidence="0.9601086">
Figure 3 shows a translation quality of both
FromTo/EK and MATES/EK according to the
length of a sentence. More than 84% of
sentences that FromTo/EK has translated is
understood by human being.
</bodyText>
<sectionHeader confidence="0.969613" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9996175">
In this paper we described the hybrid approaches
to resolution of various problems that
MATES/EK as the predecessor of FromTo/Ek
had to overcome. The approaches result in
improving the translation quality of web-based
documents.
FromTo/EK is still under growing, aiming at the
better Web-based machine translation, and
scaling up the dictionaries and the grammatical
coverage to get the better translation quality.
</bodyText>
<sectionHeader confidence="0.999417" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99971337037037">
Choi K.S., Lee S.M., Kim H.G., and Kim D.B.
(1994) An English-to-Korean Machine
Translator: MATES/EK COLING94, pp. 129-
133.
Hutchins W.J. and Somers H.L. (1992) An
Introduction to Machine Translation.
Academic Press.
Jung H.M., Yuh S.H., Kim T.W., and Park D.I.
(1997) Compound Unit Recognition for
Efficient English-Korean Translation.
Proceedings of ACH-ALLC.
Katoh N. and Aizawa T. (1995) Machine
Translation of Sentences with Fixed Expression.
Proceedings of the 4th Applied Natural
Language Processing.
Lewis D.D. and Ringuette M. (1994) A
comparison of two learning algorithms for text
categorization. Symposium on Document
Analysis and Information Retrieval, pp.81-93.
Ng H., Goh W., and Low K. (1997) Feature
Selection, Perceptron Learning, and a
Usability Case Study for Text Categorizatio.
Proceedings of the 20th Annual International
ACM SIGIR Conference on Research and
Development in Information Retrieval.
Quinlan J. (1993) C4.5: Programs for Machine
Learning. Morgan Kaufmann Publishers.
</reference>
<figure confidence="0.966292857142857">
140
120
1C0
83
40
0
4
</figure>
<page confidence="0.979316">
255
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.425843">
<title confidence="0.999398">Hybrid Approaches to Improvement of Translation Quality in Web-based English-Korean Machine Translation</title>
<author confidence="0.907210666666667">SERI</author>
<affiliation confidence="0.908409">Yuseong-gu,</affiliation>
<address confidence="0.997171">Taejon, 305-333, Korea</address>
<email confidence="0.989619">skchoi@serise.kr</email>
<email confidence="0.989619">jhm@serise.kr</email>
<email confidence="0.989619">cmsim@serise.kr</email>
<email confidence="0.989619">twkim@serise.kr</email>
<email confidence="0.989619">dipark@serise.kr</email>
<author confidence="0.991894">Jun-Sik Park</author>
<author confidence="0.991894">Key-Sun Choi</author>
<affiliation confidence="0.999871">Dept. of Computer Science, KAIST</affiliation>
<address confidence="0.9872925">373-1 Kusong-dong, Yuseong-gu, Taejon, 305-701, Korea</address>
<email confidence="0.910965">jspark@world.kaist.ac.krkschoi@cs.kaist.ac.kr</email>
<abstract confidence="0.99080252">The previous English-Korean MT system that was the transfer-based MT system and applied to only written text enumerated a following brief list of the problems that had not seemed to be easy to solve in the near future : 1) processing of non-continuous idiomatic expressions 2) reduction of too many ambiguities in English syntactic analysis 3) robust processing for failed or illformed sentences 4) selecting correct word correspondence between several alternatives 5) generation of Korean sentence style. The problems can be considered as factors that have influence on the translation quality of machine translation system. This paper describes the symbolic and statistical hybrid approaches to solutions of problems of the previous English-to-Korean machine translation system in terms of the improvement of translation quality. The solutions are now successfully applied to the web-based English-Korean machine translation system &amp;quot;FromTo/EK&amp;quot; which has been developed from 1997.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K S Choi</author>
<author>S M Lee</author>
<author>H G Kim</author>
<author>D B Kim</author>
</authors>
<title>An English-to-Korean</title>
<date>1994</date>
<booktitle>Machine Translator: MATES/EK COLING94,</booktitle>
<pages>129--133</pages>
<marker>Choi, Lee, Kim, Kim, 1994</marker>
<rawString>Choi K.S., Lee S.M., Kim H.G., and Kim D.B. (1994) An English-to-Korean Machine Translator: MATES/EK COLING94, pp. 129-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Hutchins</author>
<author>H L Somers</author>
</authors>
<title>An Introduction to Machine Translation.</title>
<date>1992</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2253" citStr="Hutchins and Somers, 1992" startWordPosition="311" endWordPosition="314"> SERI(Systems Engineering Research Institute) enumerated following list that doesn&apos;t seem to be easy to solve in the near future in terms of the problems for evolution of the system (Choi et. al., 1994) : • processing of non-continuous idiomatic expressions • generation of Korean sentence style • reduction or ranking of too many ambiguities in English syntactic analysis • robust processing for failed or ill-formed sentences • selecting correct word correspondency between several alternatives The problems result in dropping a translation assessment such as fidelity, intelligibility, and style (Hutchins and Somers, 1992). They can be the problems with which MATES/EK as well as other MT systems have faced. This paper describes the symbolic and statistical hybird approaches to solve the problems and to improve the translation quality of web-based English-to-Korean machine translation. 1 System Overview English-to-Korean machine translation system &amp;quot;FromTo/EK&amp;quot; has been developed from 1997, solving the problems of its predecessor &amp;quot;MATES/EK&amp;quot; and expanding its coverage to WWW. FromTo/EK has basically the same formalism as MATES/EK that does English sentence analysis, transforms the result (parse 251 Figure 1: The Sy</context>
</contexts>
<marker>Hutchins, Somers, 1992</marker>
<rawString>Hutchins W.J. and Somers H.L. (1992) An Introduction to Machine Translation. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Jung</author>
<author>S H Yuh</author>
<author>T W Kim</author>
<author>D I Park</author>
</authors>
<title>Compound Unit Recognition for Efficient English-Korean Translation.</title>
<date>1997</date>
<booktitle>Proceedings of ACH-ALLC.</booktitle>
<marker>Jung, Yuh, Kim, Park, 1997</marker>
<rawString>Jung H.M., Yuh S.H., Kim T.W., and Park D.I. (1997) Compound Unit Recognition for Efficient English-Korean Translation. Proceedings of ACH-ALLC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Katoh</author>
<author>T Aizawa</author>
</authors>
<title>Machine Translation of Sentences with Fixed Expression.</title>
<date>1995</date>
<booktitle>Proceedings of the 4th Applied Natural Language Processing.</booktitle>
<contexts>
<context position="6021" citStr="Katoh and Aizawa, 1995" startWordPosition="892" endWordPosition="895">because Korean sentence style can be represented in various ways by the verbal endings relevant to the domain. For example, the formal domains such as technology 252 and law etc. make use of the plain verbal ending like `ta&apos; because they have carateristics of formality, while the informal domains such as weather, food and fashion etc. are related to the polite verbal ending `supnita&apos; because they have carateristics of politeness. 3 Compound Unit Recognition One of the problems of rule-based translation has been the idiomatic expression which has been dealt mainly with syntactic grammar rules (Katoh and Aizawa, 1995) &amp;quot;Mary keeps up with her brilliant classmates.&amp;quot; and &amp;quot;I prevent him from going there.&amp;quot; are simple examples of uninterupted and interupted idiomatic expressions expectively. In order to solve idiomatic expressions as well as collocations and frozen compound nouns, we have developed the compound unit(CU) recognizer (Jung et. al., 1997). It is a plug-in model locating between morphological and syntactic analyzer. Figure 2 shows the structure of CU recognizer. Figure 2 : System structure of CU recognizer The recognizer searches all possible CUs in the input sentence using co-occurrence constraint s</context>
</contexts>
<marker>Katoh, Aizawa, 1995</marker>
<rawString>Katoh N. and Aizawa T. (1995) Machine Translation of Sentences with Fixed Expression. Proceedings of the 4th Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
<author>M Ringuette</author>
</authors>
<title>A comparison of two learning algorithms for text categorization.</title>
<date>1994</date>
<booktitle>Symposium on Document Analysis and Information Retrieval,</booktitle>
<pages>81--93</pages>
<marker>Lewis, Ringuette, 1994</marker>
<rawString>Lewis D.D. and Ringuette M. (1994) A comparison of two learning algorithms for text categorization. Symposium on Document Analysis and Information Retrieval, pp.81-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ng</author>
<author>W Goh</author>
<author>K Low</author>
</authors>
<title>Feature Selection, Perceptron Learning, and a Usability Case Study for Text Categorizatio.</title>
<date>1997</date>
<booktitle>Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<marker>Ng, Goh, Low, 1997</marker>
<rawString>Ng H., Goh W., and Low K. (1997) Feature Selection, Perceptron Learning, and a Usability Case Study for Text Categorizatio. Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="4110" citStr="Quinlan, 1993" startWordPosition="596" endWordPosition="597">nterface for English and Korean, translation engine, and knowledge and dictionaries. The black boxes in the Figure 1 mean the modules that have existed in MATES/EK, while the white ones are the new modules that have been developed to improve the translation quality. Next chapters describe the new modules in detail. 2 Domain Recognizer and Korean sentence style In order to identify the domain of text and connect it to English terminology lexicon and Korean sentence style in Korean generation, we have developed a domain recognizer. We adapted a semi-automated decision tree induction using C4.5 (Quinlan, 1993) among diverse approaches to text categorization such as decision tree induction (Lewis et. al., 1994) and neural networks (Ng et. al., 1997), because a semi-automated approach showed perhaps the best performance in domain identification according to (Ng et. al., 1997). Twenty-five domains were manually chosen from the categories of awarded Web sites. We collected 0.4 million Web pages by using Web search robot and counted the frequency of words to extract features for domain recognition. The words that appeared more than 200 times were used as features. Besides we added some manually chosen w</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan J. (1993) C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>