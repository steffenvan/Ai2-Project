<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000342">
<title confidence="0.997514">
Using Dependency Order Templates to Improve Generality in
Translation
</title>
<author confidence="0.661756">
Arul Menezes and Chris Quirk
</author>
<affiliation confidence="0.667002">
Microsoft Research
One Microsoft Way, Redmond, WA 98052, USA
</affiliation>
<email confidence="0.984722">
{arulm, chrisq}@microsoft.com
</email>
<sectionHeader confidence="0.997292" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999943269230769">
Today&apos;s statistical machine translation
systems generalize poorly to new
domains. Even small shifts can cause
precipitous drops in translation quality.
Phrasal systems rely heavily, for both
reordering and contextual translation, on
long phrases that simply fail to match out-
of-domain text. Hierarchical systems
attempt to generalize these phrases but
their learned rules are subject to severe
constraints. Syntactic systems can learn
lexicalized and unlexicalized rules, but the
joint modeling of lexical choice and
reordering can narrow the applicability of
learned rules. The treelet approach models
reordering separately from lexical choice,
using a discriminatively trained order
model, which allows treelets to apply
broadly, and has shown better
generalization to new domains, but suffers
a factorially large search space. We
introduce a new reordering model based
on dependency order templates, and show
that it outperforms both phrasal and treelet
systems on in-domain and out-of-domain
text, while limiting the search space.
</bodyText>
<sectionHeader confidence="0.999469" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999740228571429">
Modern phrasal SMT systems such as (Koehn et
al., 2003) derive much of their power from being
able to memorize and use long phrases. Phrases
allow for non-compositional translation, local
reordering and contextual lexical choice.
However the phrases are fully lexicalized, which
means they generalize poorly to even slightly out-
of-domain text. In an open competition (Koehn &amp;
Monz, 2006) systems trained on parliamentary
proceedings were tested on text from &apos;news
commentary&apos; web sites, a very slightly different
domain. The 9 phrasal systems in the English to
Spanish track suffered an absolute drop in BLEU
score of between 4.4% and 6.34% (14% to 27%
relative). The treelet system of Menezes et al.
(2006) fared somewhat better but still suffered an
absolute drop of 3.61%.
Clearly there is a need for approaches with
greater powers of generalization. There are
multiple facets to this issue, including handling of
unknown words, new senses of known words etc.
In this work, we will focus on the issue of
reordering, i.e. can we learn how to transform the
sentence structure of one language into the
sentence structure of another, in a way that is not
tied to a specific domain or sub-domains, or
indeed, sequences of individual words.
An early attempt at greater generality in a
purely phrasal setting was the alignment template
approach (Och &amp; Ney 2004); newer approaches
include formally syntactic (Chiang 2005), and
linguistically syntactic approaches (Quirk et al.
2005), (Huang et al. 2006). In the next section, we
examine these representative approaches to the
reordering problem.
</bodyText>
<sectionHeader confidence="0.999947" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999941">
Our discussion of related work will be grounded
in the following tiny English to Spanish example,
where the training set includes:
</bodyText>
<figure confidence="0.819175333333333">
a very old book
un libro más antiguo
a book very old1
the old man
el hombre viejo
the man old
</figure>
<footnote confidence="0.953256">
it is very important
es muy importante
is very important
1 English gloss of Spanish sentences in italics.
</footnote>
<page confidence="0.536903">
1
</page>
<note confidence="0.9746425">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 1–8,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<figure confidence="0.79066375">
and the test sentence and reference translation are
a very old man
un hombre muy viejo
a man very old
</figure>
<bodyText confidence="0.9997755">
Note that while the first training pair has the
correct structure for the test sentence, most of the
contextually correct lexical choices come from
the other two pairs.
</bodyText>
<subsectionHeader confidence="0.952188">
2.1 Phrasal translation, Alignment templates
</subsectionHeader>
<bodyText confidence="0.901885869565217">
The relevant phrases (i.e. those that match the test
sentence) extracted from these training pairs are
shown in Table 2.1. Only phrases up to size 3 are
shown. The ones in italics are &apos;correct&apos; in that they
can lead to the reference translation. Note that
none of the multi-word phrases lead to the
reference, so the local reordering often captured
in the phrasal model is no help at all in ordering
this sentence. The system is unable to learn the
correct structure from the first sentence because
the words are wrong, and from the second
sentence even though the phrase old man has the
right words in the right order, it does not lead to
the reference translation because the translation of
very cannot be inserted in the right place.
a un
very más
old antiguo
very old más antiguo
old viejo
man hombre
old man hombre viejo
very muy
</bodyText>
<tableCaption confidence="0.969698">
Table 2.1: Relevant extracted phrases
</tableCaption>
<bodyText confidence="0.9998236">
Looking at this as a sparse data issue we might
suspect that generalization could solve the
problem. The alignment template approach (Och
&amp; Ney, 2004) uses word classes rather than
lexical items to model phrase translation. Yet this
approach loses the advantage of context-sensitive
lexical selection: the word translation model
depends only on the word classes to subcategorize
for translations, which leads to less accurate
lexical choice in practice (Zens &amp; Ney, 2004).
</bodyText>
<subsectionHeader confidence="0.999086">
2.2 Hierarchical translation
</subsectionHeader>
<bodyText confidence="0.999193666666667">
Hierarchical systems (Chiang, 2005) induce a
context-free grammar with one non-terminal
directly from the parallel corpus, with the
advantage of not requiring any additional
knowledge source or tools, such as a treebank or a
parser. However this can lead to an explosion of
rules. In order to make the problem tractable and
avoid spurious ambiguity, Chiang restricts the
learned rules in several ways. The most
problematic of these is that every rule must have
at least one pair of aligned words, and that
adjacent non-terminals are not permitted on the
source side. In Table 2.2 we show the additional
hierarchical phrases that would be learned from
our training pairs under these restrictions. Again
only those applicable to the test sentence are
shown and the &apos;correct&apos; rules, i.e. those that lead to
the reference, are italicized.
</bodyText>
<table confidence="0.998726">
X1 old X1 antiguo
very X1 más X1
very old X1 X1 más antiguo
X1 old X2 X2 X1 antiguo
very X1 X2 X2 más X1
X1 man hombre X1
old X1 X1 viejo
X1 old man X1 hombre viejo
X1 very X1 muy
very X2 muy X2
X1 very X2 X1 muy X2
</table>
<tableCaption confidence="0.997991">
Table 2.2: Additional hierarchical phrases
</tableCaption>
<bodyText confidence="0.9999742">
Note that even though from the first pair, we learn
several rules with the perfect reordering for the
test sentence, they do not lead to the reference
because they drag along the contextually incorrect
lexical choices. From the second pair, we learn a
rule (X1 old man) that has the right contextual
word choice, but does not lead to the reference,
because the paucity of the grammar&apos;s single non-
terminal causes this rule to incorrectly imply that
the translation of very be placed before hombre.
</bodyText>
<subsectionHeader confidence="0.999372">
2.3 Constituency tree transduction
</subsectionHeader>
<bodyText confidence="0.9995191">
An alternate approach is to use linguistic
information from a parser. Transduction rules
between Spanish strings and English trees can be
learned from a word-aligned parallel corpus with
parse trees on one side (Graehl &amp; Knight, 2004).
Such rules can be used to translate from Spanish
to English by searching for the best English
language tree for a given Spanish language string
(Marcu et al., 2006). Alternately English trees
produced by a parser can be transduced to
</bodyText>
<page confidence="0.9735">
2
</page>
<figure confidence="0.8766895">
NP
ADJP
rules provide an elegant and powerful model of
reordering, they come with a potential cost in
NP context-sensitive translation.
PN VB RB JJ
it is very important
es muy importante
</figure>
<figureCaption confidence="0.996676">
Figure 2.1: Constituency parses
</figureCaption>
<bodyText confidence="0.999978666666667">
Spanish strings using the same rules (Huang et al.,
2006). Translation rules may reach beyond one
level in the syntax tree; this extended domain of
locality allows many phenomena including both
lexicalized and unlexicalized rules. However
reordering and translation are modeled jointly,
which may exacerbate data sparsity. Furthermore
it forces the system to pick between unlexicalized
rules that capture reordering and lexicalized rules
that model context-sensitive translation.
For instance, the following rules can be
extracted from the first sentence of the corpus:
</bodyText>
<equation confidence="0.842152">
r1: un x1 x2 ՜ NP(DT(a) ADJP:x2 NN:x1)
r2: x1 x2 ՜ ADJP(RB:x1 JJ:x2)
</equation>
<bodyText confidence="0.939527533333333">
Although together they capture the necessary
reordering for our test sentence pair, they do not
allow for context sensitive translations of the
ambiguous terms very and old; each must be
selected independently. Disappointingly, no
single constituency tree transduction rule derived
from this corpus translates old man as hombre
viejo in a single step on the test sentence: the
syntactic structures are slightly different, but the
difference is sufficient to prevent matching.2
Again we note that phrases provide utility by
capturing both reordering and context. While xRS
2 Marcu et al. (2006) and Zollmann et al. (2006) recognize
this problem and attempt to alleviate it by grafting surface
phrases into constituency trees by various methods.
</bodyText>
<subsectionHeader confidence="0.988101">
2.4 Dependency treelet translation
</subsectionHeader>
<bodyText confidence="0.999412045454546">
We previously described (Quirk et al, 2005) a
linguistically syntax-based system that parses the
source language, uses word-based alignments to
project a target dependency tree, and extracts
paired dependency tree fragments (treelets)
instead of surface phrases. In contrast to the xRS
approach, ordering is very loosely coupled with
translation via a separate discriminatively trained
dependency tree-based order model. The switch
to a dependency parse also changes the
conditioning information available for translation:
related lexical items are generally adjacent, rather
than separated by a path of unlexicalized non-
terminals. In effect, by using a looser matching
requirement, treelets retain the context-sensitive
lexical choice of phrases: treelets must only be a
connected subgraph of the input sentence to be
applicable; some children may remain uncovered.
Figure 2.2 shows source dependency parses
and projected target dependencies for our training
data; Figure 2.3 shows the treelet pairs that this
system would extract that match the input
</bodyText>
<figureCaption confidence="0.999614">
Figure 2.2: Dependency trees for training pairs
Figure 2.3: Relevant extracted treelets
</figureCaption>
<figure confidence="0.998488666666667">
DT RB JJ NN DT JJ NN
a very old book the old man
un libro más antiguo el hombre viejo
S
VP
ADJP
</figure>
<page confidence="0.981485">
3
</page>
<bodyText confidence="0.999775681818182">
sentence (treelets of size 1 are not shown). The
second treelet supplies the order of viejo with
respect to its head, and unlike the case with xRS
rules, we can use this to make the correct
contextual word choice. The difference is that
because xRS rules provide both reordering and
word choice, each rule must match all of the
children at any given tree node. On the other
hand, treelets are allowed to match more loosely.
The translations of the unmatched children (un
and muy in this case) are placed by exploring all
possible orderings and scoring them with both
order model and language model. Although this
effectively decouples lexical selection from
ordering, it comes at a huge cost in search space
and translation quality may suffer due to search
error. However, as mentioned in Section 1, this
approach is able to generalize better to out-of-
domain data than phrasal approaches. Koehn and
Monz (2006) also include a human evaluation, in
which this system ranked noticeably higher than
one might have predicted from its BLEU score.
</bodyText>
<sectionHeader confidence="0.993815" genericHeader="method">
3 Dependency Order Templates
</sectionHeader>
<bodyText confidence="0.99994272972973">
The Dependency Order Templates approach
leverages the power of the xR rule formalism,
while avoiding the problems mentioned in Section
2.3, by constructing the rules on the fly from two
separately matched components: (a) Dependency
treelet translation pairs described in Section 2.4
that capture contextual lexical translations but are
underspecified with respect to ordering, and (b)
Order templates, which are unlexicalized rules
(over dependency, rather than constituency trees)
that capture reordering phenomena.
Formally, an order template is an unlexicalized
transduction rule mapping dependency trees
containing only parts of speech to unlexicalized
target language trees (see Figure 4.1b).
Given an input sentence, we combine relevant
treelet translation pairs and order templates to
construct lexicalized transduction rules for that
sentence, and then decode using standard
transduction approaches. By keeping lexical and
ordering information orthogonal until runtime, we
can produce novel transduction rules not seen in
the training corpus. This allows greater
generalization capabilities than the constituency
tree transduction approaches of Section 2.3.
As compared to the treelet approach described
in Section 2.4, the generalization capability is
somewhat reduced. In the treelet system all
reorderings are exhaustively evaluated, but the
size of the search space necessitates tight pruning,
leading to significant search error. By contrast, in
the order template approach we consider only
reorderings that are captured in some order
template. The drastic reduction in search space
leads to an overall improvement, not only in
decoding speed, but also in translation quality due
to reduced search error.
</bodyText>
<subsectionHeader confidence="0.999912">
3.1 Extracting order templates
</subsectionHeader>
<bodyText confidence="0.999960208333333">
For each pair of parallel training sentences, we
parse the source sentence, obtain a source
dependency tree, and use GIZA++ word
alignments to project a target dependency tree as
described in Quirk et al. (2005).
Given this pair of aligned source and target
dependency trees, we recursively extract one
order template for each pair of aligned non-leaf
source and target nodes. In the case of multi-word
alignments, all contiguous 3 aligned nodes are
added to the template. Next we recursively add
child nodes as follows: For each node in the
template, add all its children. For each such child,
if it is aligned, stop recursing, if it is unaligned,
recursively add its children.
On each template node we remove the lexical
items; we retain the part of speech on the source
nodes (we do not use target linguistic features).
We also keep node alignment information4. The
resulting aligned source and target sub-graphs
comprise the order template. Figure 4.1b lists the
order templates extracted from the training pairs
in Figure 2.1 that capture all the patterns
necessary to correctly reorder the test sentence.
</bodyText>
<sectionHeader confidence="0.998062" genericHeader="method">
4 Decoding
</sectionHeader>
<bodyText confidence="0.98556675">
Decoding is treated as a problem of syntax-
directed transduction. Input sentences are
segmented into a token stream, annotated with
part-of-speech information, and parsed into
</bodyText>
<footnote confidence="0.912329333333333">
3 If a multi-word alignment is not contiguous in either source
or target dependency tree no order template is extracted.
4 If a source or target node aligns to a tree node outside the
template, the template breaks phrasal cohesion and is
currently discarded. We intend to address these &apos;structural
divergence&apos; patterns in future work.
</footnote>
<page confidence="0.993711">
4
</page>
<bodyText confidence="0.999959285714286">
unlabeled dependency trees. At each node in the
input dependency tree we first find the set of
matching treelet pairs: A pair matches if its source
side corresponds to a connected subgraph of the
input tree. Next we find matching order
templates: order templates must also match a
connected subgraph of the input tree, but in
addition, for each input node, the template must
match either all or none of its children 5 .
Compatible combinations of treelets and order
templates are merged to form xR rules. Finally,
we search for the best transduction according to
the constructed xR rules as scored by a log-linear
combination of models (see Section 5).
</bodyText>
<subsectionHeader confidence="0.961649">
4.1 Compatibility
</subsectionHeader>
<bodyText confidence="0.9999355">
A treelet and an order template are considered
compatible if the following conditions are met:
The treelet and the matching portions of the
template must be structurally isomorphic. Every
treelet node must match an order template node.
Matching nodes must have the same part of
speech. Unaligned treelet nodes must match an
unaligned template node. Aligned treelet nodes
must match aligned template nodes. Nodes that
are aligned to each other in the treelet pair must
match template nodes that are aligned to each
other.
</bodyText>
<subsectionHeader confidence="0.998091">
4.2 Creating transduction rules
</subsectionHeader>
<bodyText confidence="0.999931375">
Given a treelet, we can form a set of tree
transduction rules as follows. We iterate over
each source node n in the treelet pair; let s be the
corresponding node in the input tree (identified
during the matching). If, for all children of s there
is a corresponding child of n, then this treelet
specifies the placement of all children and no
changes are necessary. Otherwise we pick a
template that matched at s and is compatible with
the treelet. The treelet and template are unified to
produce an updated rule with variables on the
source and target sides for each uncovered child
of s. When all treelet nodes have been visited, we
are left with a transduction rule that specifies the
translation of all nodes in the treelet and contains
variables that specify the placement of all
</bodyText>
<footnote confidence="0.976626">
5 This is so the resulting rules fit within the xR formalism. At
each node, a rule either fully specifies its ordering, or
delegates the translation of the subtree to other rules.
</footnote>
<figureCaption confidence="0.996838">
Figure 4.1: Merging templates and treelets
</figureCaption>
<bodyText confidence="0.999747166666667">
uncovered nodes. Due to the independence of
ordering and lexical information, we may produce
novel transduction rules not seen in the training
corpus. Figure 4.1 shows this process as it applies
to the test sentence in Section 2.
If, at any node s, we cannot find a matching
template compatible with the current treelet, we
create an artificial source order template, which
simply preserves the source language order in the
target translation. We add a feature function that
counts the number of such templates and train its
weight during minimum error rate training.
</bodyText>
<subsectionHeader confidence="0.993301">
4.3 Transduction using xR rules
</subsectionHeader>
<bodyText confidence="0.999986631578947">
In the absence of a language model or other
contextually dependent features, finding the
highest scoring derivation would be a simple
dynamic program (Huang et al. 2006) 6.However
exact search using an n -gram language model
leads to split states for each n -gram context.
Instead we use an approximate beam search
moving bottom-up in the tree, much like a CKY
parser. Candidates in this search are derivations
with respect to the transducer.
Each transduction rule r has a vector of
variables v,.i, ... vr . Each variable is associated
with an input node S(v). For each input node s,
we keep a beam of derivations b[s]. Derivations
are represented as a pair (r, e) where r is a
transduction rule and e E N is a vector with one
integer for each of the k variables in r. The
interpretation is that the complete candidate can
be constructed by recursively substituting for each
</bodyText>
<footnote confidence="0.8266305">
6 Like Chiang (2005) we only search for the yield of the most
likely derivation, rather than the most likely yield.
</footnote>
<page confidence="0.90451">
5
</page>
<equation confidence="0.862728421052632">
GetTranslationBeam(s) // memoized
prioq F 0
beam F 0
for r E R(s)
Enqueue(prioq, (r, 1), EarlyScore((r, 1)))
while Size(prioq) &gt; 0
(r, e) F PopBest(prioq)
AddToBeam(beam, (r, e), TrueScore((r, e)))
for i in L.jej
Enqueue(prioq, (r, e + 1i),
EarlyScore((r, e + 1i)))
return beam
EarlyScore((r, e))
c F RuleScore(r)
for i in L.jej
s F InputNode(GetVariable (r, i))
beam F GetTranslationBeam(s)
c F c +TrueScore(GetNthEntry(beam, ei))
return c
</equation>
<figureCaption confidence="0.976075">
Figure 4.2: Beam tree transduction
</figureCaption>
<bodyText confidence="0.998333">
vri E vrl °• vrk the candidate constructed from
the eith entry in the beam b[S(vri)].
Figure 4.2 describes the transduction process.
Since we approach decoding as xR transduction,
the process is identical to that of constituency-
based algorithms (e.g. Huang and Chiang, 2007).
There are several free parameters to tune:
</bodyText>
<listItem confidence="0.994510444444444">
• Beam size – Maximum number of candidates
per input node (in this paper we use 100)
• Beam threshold – maximum range of scores
between top and bottom scoring candidate
(we use a logprob difference of 30)
• Maximum combinations considered – To
bound search time, we can stop after a
specified number of elements are popped off
the priority queue (we use 5000)
</listItem>
<sectionHeader confidence="0.978241" genericHeader="method">
5 Models
</sectionHeader>
<bodyText confidence="0.9965675">
We use all of the Treelet models we described in
Quirk et al. (2005) namely:
</bodyText>
<listItem confidence="0.999971666666667">
• Treelet table with translation probabilities
estimated using maximum likelihood, with
absolute discounting.
• Discriminative tree-based order model.
• Forward and backward lexical weighting,
using Model-1 translation probabilities.
• Trigram language model using modified
Kneser-Ney smoothing.
• Word and phrase count feature functions.
</listItem>
<bodyText confidence="0.732729">
In addition, we introduce the following:
</bodyText>
<listItem confidence="0.989324166666667">
• Order template table, with template
probabilities estimated using maximum
likelihood, with absolute discounting.
• A feature function that counts the number of
artificial source order templates (see below)
used in a candidate.
</listItem>
<bodyText confidence="0.999304666666667">
The models are combined in a log-linear
framework, with weights trained using minimum
error rate training to optimize the BLEU score.
</bodyText>
<sectionHeader confidence="0.998906" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9975495">
We evaluated the translation quality of the system
using the BLEU metric (Papineni et al., 2002).
We compared our system to Pharaoh, a leading
phrasal SMT decoder (Koehn et al., 2003), and
our treelet system. We report numbers for English
to Spanish.
</bodyText>
<subsectionHeader confidence="0.992089">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.997058071428572">
We used the Europarl corpus provided by the
NAACL 2006 Statistical Machine Translation
workshop. The target language model was trained
using only the target side of the parallel corpus.
The larger monolingual corpus was not utilized.
The corpus consists of European Parliament
proceedings, 730,740 parallel sentence pairs of
English-Spanish, amounting to about 15M words
in each language. The test data consists of 2000
sentences each of development (dev),
development-test (devtest) and test data (test)
from the same domain. There is also a separate set
of 1064 test sentences (NC-test) gathered from
&amp;quot;news commentary&amp;quot; web sites.
</bodyText>
<subsectionHeader confidence="0.999334">
6.2 Training
</subsectionHeader>
<bodyText confidence="0.999937153846154">
We parsed the source (English) side of the corpus
using NLPWIN, a broad-coverage rule-based
parser able to produce syntactic analyses at
varying levels of depth (Heidorn, 2002). For the
purposes of these experiments we used a
dependency tree output with part-of-speech tags
and unstemmed, case-normalized surface words.
For word alignment we used GIZA++, under a
training regimen of five iterations of Model 1,
five iterations of HMM, and five iterations of
Model 4, in both directions. The forward and
backward alignments were symmetrized using a
tree-based heuristic combination. The word
</bodyText>
<page confidence="0.99856">
6
</page>
<bodyText confidence="0.9999605">
alignments and English dependency tree were
used to project a target tree. From the aligned tree
pairs we extracted a treelet table and an order
template table.
The comparison treelet system was identical
except that no order template model was used.
The comparison phrasal system was
constructed using the same GIZA++ alignments
and the heuristic combination described in (Och
&amp; Ney, 2003). Except for the order models
(Pharaoh uses a penalty on the deviance from
monotone), the same models were used.
All systems used a treelet or phrase size of 7
and a trigram language model. Model weights
were trained separately for all 3 systems using
minimum error rate training to maximize BLEU
(Och, 2003) on the development set (dev). Some
decoder pruning parameters were tuned on the
development test (devtest). The test and NC-test
data sets were not used until final tests.
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.999888333333333">
We present the results of our system comparisons
in Table 7.1 and Figure 7.1 using three different
test sets: The in-domain development test data
(devtest), the in-domain blind test data (test) and
the out-of-domain news commentary test data
(NC-test). All differences (except phrasal vs.
template on devtest), are statistically significant at
the p&gt;=0.99 level under the bootstrap resampling
test. Note that while the systems are quite
comparable on the in-domain data, on the out-of-
domain data the phrasal system&apos;s performance
drops precipitously, whereas the performance of
the treelet and order template systems drops much
less, outperforming the phrasal system by 2.7%
and 3.46% absolute BLEU.
</bodyText>
<table confidence="0.97526675">
devtest test NC-test
Phrasal 0.2910 0.2935 0.2354
Treelet 0.2819 0.2981 0.2624
Template 0.2896 0.3045 0.2700
</table>
<tableCaption confidence="0.993815">
Table 7.1: System Comparisons across domains
</tableCaption>
<bodyText confidence="0.878661666666667">
Further insight may be had by comparing the
recall7 for different n-gram orders (Table 7.2).
The phrasal system suffers a greater decline in the
higher order n-grams than the treelet and template
7 n-gram precision cannot be directly compared across output
from different systems due to different levels of &apos;brevity&apos;
</bodyText>
<page confidence="0.939723">
31
</page>
<figure confidence="0.9601743">
30
29
28
27
26
25
24
23
development in-domain out-of-domain
Phrasal Treelet Order Template
</figure>
<figureCaption confidence="0.999295">
Figure 7.1: In-domain vs. Out-of-domain BLEU
</figureCaption>
<bodyText confidence="0.8692455">
systems, indicating that latter show improved
generality in reordering.
</bodyText>
<table confidence="0.999375571428571">
1gm 2gm 3gm 4gm
Test Phrasal 0.61 0.35 0.23 0.15
treelet 0.62 0.36 0.23 0.15
template 0.62 0.36 0.24 0.16
NC-test phrasal 0.58 0.30 0.17 0.10
treelet 0.60 0.33 0.20 0.12
template 0.61 0.34 0.20 0.13
</table>
<tableCaption confidence="0.99016">
Table 7.2: n-gram recall across domains
</tableCaption>
<subsectionHeader confidence="0.89005">
7.1 Treelet vs. Template systems
</subsectionHeader>
<bodyText confidence="0.9990428">
As described in Section 3.1, the order templates
restrict the broad reordering space of the treelet
system. Although in theory this might exclude
reorderings necessary for some translations, Table
7.3 shows that in practice, the drastic search space
reduction allows the decoder to explore a wider
beam and more rules, leading to reduced search
error and increased translation speed. (The topK
parameter is the number of phrases explored for
each span, or rules/treelets for each input node.)
</bodyText>
<table confidence="0.997694">
Devtest Sents.
BLEU per sec
Pharaoh, beam=100, topK=20 0.2910 0.94
Treelet, beam=12, topK=5 0.2819 0.21
Template, beam=100, topK=20 0.2896 0.56
</table>
<tableCaption confidence="0.999057">
Table 7.3: Performance comparisons
</tableCaption>
<bodyText confidence="0.986106">
Besides the search space restriction, the other
significant change in the template system is to
include MLE template probabilities as an
</bodyText>
<page confidence="0.997719">
7
</page>
<bodyText confidence="0.988823888888889">
additional feature function. Given that the
template system operates over rules where the
ordering is fully specified, and that most tree
transduction systems use MLE rule probabilities
to model both lexical selection and reordering,
one might ask if the treelet system&apos;s
discriminatively trained order model is now
redundant. In Table 7.4 we see that this is not the
case.8 (Differences are significant at p&gt;=0.99.)
</bodyText>
<table confidence="0.97087425">
devtest test NC-test
MLE model only 0.2769 0.2922 0.2512
Discriminative and 0.2896 0.3045 0.2700
MLE models
</table>
<tableCaption confidence="0.994153">
Table 7.4: Templates and discriminative order model
</tableCaption>
<bodyText confidence="0.9995405">
Finally we examine the role of frequency
thresholds in gathering templates. In Table 7.5 it
may be seen that discarding singletons reduces
the table size by a factor of 5 and improves
translation speed with negligible degradation in
quality.
</bodyText>
<table confidence="0.97985225">
devtest Number of Sentences
BLEU templates per sec.
No threshold 0.2898 752,165 0.40
Threshold=1 0.2896 137,584 0.56
</table>
<tableCaption confidence="0.99792">
Table 7.5: Effect of template count cutoffs
</tableCaption>
<sectionHeader confidence="0.996996" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99816175">
We introduced a new model of Dependency Order
Templates that provides for separation of lexical
choice and reordering knowledge, thus allowing
for greater generality than the phrasal and xRS
approaches, while drastically limiting the search
space as compared to the treelet approach. We
showed BLEU improvements over phrasal of over
1% in-domain and nearly 3.5% out-of-domain. As
compared to the treelet approach we showed an
improvement of about 0.5%, but a speedup of
nearly 3x, despite loosening pruning parameters.
Extraposition and long distance movement still
pose a serious challenge to syntax-based machine
translation systems. Most of the today&apos;s search
algorithms assume phrasal cohesion. Even if our
search algorithms could accommodate such
movement, we don&apos;t have appropriate models to
8 We speculate that other systems using transducers with
MLE probabilities may also benefit from additional
reordering models.
account for such phenomena. Our system already
extracts extraposition templates, which are a step
in the right direction, but may prove too sparse
and brittle to account for the range of phenomena.
</bodyText>
<sectionHeader confidence="0.998478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999841159090909">
Chiang, David. A hierarchical phrase-based model for
statistical machine translation. ACL 2005.
Galley, Michel, Mark Hopkins, Kevin Knight, and Daniel
Marcu. What’s in a translation rule? HLT-NAACL 2004.
Graehl, Jonathan and Kevin Knight. Training Tree
Transducers. NAACL 2004.
Heidorn, George. “Intelligent writing assistance”. In Dale et
al. Handbook of Natural Language Processing, Marcel
Dekker. (2000)
Huang, Liang, Kevin Knight, and Aravind Joshi. Statistical
Syntax-Directed Translation with Extended Domain of
Locality. AMTA 2006
Huang, Liang and David Chiang. Faster Algorithms for
Decoding with Integrated Language Models. ACL 2007
(to appear)
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
Statistical phrase based translation. NAACL 2003.
Koehn, Philipp and Christof Monz. Manual and automatic
evaluation of machine translation between european
languages. Workshop on Machine Translation, NAACL
2006.
Marcu, Daniel, Wei Wang, Abdessamad Echihabi, and Kevin
Knight. SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases. EMNLP-2006.
Menezes, Arul, Kristina Toutanova and Chris Quirk.
Microsoft Research Treelet translation system: NAACL
2006 Europarl evaluation. Workshop on Machine
Translation, NAACL 2006
Och, Franz Josef and Hermann Ney. A systematic
comparison of various statistical alignment models,
Computational Linguistics, 29(1):19-51 (2003).
Och, Franz Josef. Minimum error rate training in statistical
machine translation. ACL 2003.
Och, Franz Josef and Hermann Ney: The Alignment
Template Approach to Statistical Machine Translation.
Computational Linguistics 30 (4): 417-449 (2004)
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. BLEU: a method for automatic evaluation of
machine translation. ACL 2002.
Quirk, Chris, Arul Menezes, and Colin Cherry. Dependency
Tree Translation: Syntactically informed phrasal SMT.
ACL 2005
Zens, Richard and Hermann Ney. Improvements in phrase-
based statistical machine translation. HLT-NAACL 2004
</reference>
<page confidence="0.998485">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969474">
<title confidence="0.999202">Using Dependency Order Templates to Improve Generality in Translation</title>
<author confidence="0.991252">Menezes Quirk</author>
<affiliation confidence="0.999759">Microsoft Research</affiliation>
<address confidence="0.998724">One Microsoft Way, Redmond, WA 98052,</address>
<email confidence="0.997069">arulm@microsoft.com</email>
<email confidence="0.997069">chrisq@microsoft.com</email>
<abstract confidence="0.999393592592593">Today&apos;s statistical machine translation systems generalize poorly to new domains. Even small shifts can cause precipitous drops in translation quality. Phrasal systems rely heavily, for both reordering and contextual translation, on long phrases that simply fail to match outof-domain text. Hierarchical systems attempt to generalize these phrases but their learned rules are subject to severe constraints. Syntactic systems can learn lexicalized and unlexicalized rules, but the joint modeling of lexical choice and reordering can narrow the applicability of learned rules. The treelet approach models reordering separately from lexical choice, using a discriminatively trained order model, which allows treelets to apply broadly, and has shown better generalization to new domains, but suffers a factorially large search space. We introduce a new reordering model based order and show that it outperforms both phrasal and treelet systems on in-domain and out-of-domain text, while limiting the search space.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation. ACL</title>
<date>2005</date>
<contexts>
<context position="2665" citStr="Chiang 2005" startWordPosition="404" endWordPosition="405">approaches with greater powers of generalization. There are multiple facets to this issue, including handling of unknown words, new senses of known words etc. In this work, we will focus on the issue of reordering, i.e. can we learn how to transform the sentence structure of one language into the sentence structure of another, in a way that is not tied to a specific domain or sub-domains, or indeed, sequences of individual words. An early attempt at greater generality in a purely phrasal setting was the alignment template approach (Och &amp; Ney 2004); newer approaches include formally syntactic (Chiang 2005), and linguistically syntactic approaches (Quirk et al. 2005), (Huang et al. 2006). In the next section, we examine these representative approaches to the reordering problem. 2 Related Work Our discussion of related work will be grounded in the following tiny English to Spanish example, where the training set includes: a very old book un libro más antiguo a book very old1 the old man el hombre viejo the man old it is very important es muy importante is very important 1 English gloss of Spanish sentences in italics. 1 Proceedings of the Second Workshop on Statistical Machine Translation, pages </context>
<context position="5064" citStr="Chiang, 2005" startWordPosition="800" endWordPosition="801"> hombre old man hombre viejo very muy Table 2.1: Relevant extracted phrases Looking at this as a sparse data issue we might suspect that generalization could solve the problem. The alignment template approach (Och &amp; Ney, 2004) uses word classes rather than lexical items to model phrase translation. Yet this approach loses the advantage of context-sensitive lexical selection: the word translation model depends only on the word classes to subcategorize for translations, which leads to less accurate lexical choice in practice (Zens &amp; Ney, 2004). 2.2 Hierarchical translation Hierarchical systems (Chiang, 2005) induce a context-free grammar with one non-terminal directly from the parallel corpus, with the advantage of not requiring any additional knowledge source or tools, such as a treebank or a parser. However this can lead to an explosion of rules. In order to make the problem tractable and avoid spurious ambiguity, Chiang restricts the learned rules in several ways. The most problematic of these is that every rule must have at least one pair of aligned words, and that adjacent non-terminals are not permitted on the source side. In Table 2.2 we show the additional hierarchical phrases that would </context>
<context position="18183" citStr="Chiang (2005)" startWordPosition="2923" endWordPosition="2924"> use an approximate beam search moving bottom-up in the tree, much like a CKY parser. Candidates in this search are derivations with respect to the transducer. Each transduction rule r has a vector of variables v,.i, ... vr . Each variable is associated with an input node S(v). For each input node s, we keep a beam of derivations b[s]. Derivations are represented as a pair (r, e) where r is a transduction rule and e E N is a vector with one integer for each of the k variables in r. The interpretation is that the complete candidate can be constructed by recursively substituting for each 6 Like Chiang (2005) we only search for the yield of the most likely derivation, rather than the most likely yield. 5 GetTranslationBeam(s) // memoized prioq F 0 beam F 0 for r E R(s) Enqueue(prioq, (r, 1), EarlyScore((r, 1))) while Size(prioq) &gt; 0 (r, e) F PopBest(prioq) AddToBeam(beam, (r, e), TrueScore((r, e))) for i in L.jej Enqueue(prioq, (r, e + 1i), EarlyScore((r, e + 1i))) return beam EarlyScore((r, e)) c F RuleScore(r) for i in L.jej s F InputNode(GetVariable (r, i)) beam F GetTranslationBeam(s) c F c +TrueScore(GetNthEntry(beam, ei)) return c Figure 4.2: Beam tree transduction vri E vrl °• vrk the candi</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, David. A hierarchical phrase-based model for statistical machine translation. ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule? HLT-NAACL</title>
<date>2004</date>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Galley, Michel, Mark Hopkins, Kevin Knight, and Daniel Marcu. What’s in a translation rule? HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
</authors>
<title>Training Tree Transducers.</title>
<date>2004</date>
<location>NAACL</location>
<contexts>
<context position="6889" citStr="Graehl &amp; Knight, 2004" startWordPosition="1114" endWordPosition="1117">erence because they drag along the contextually incorrect lexical choices. From the second pair, we learn a rule (X1 old man) that has the right contextual word choice, but does not lead to the reference, because the paucity of the grammar&apos;s single nonterminal causes this rule to incorrectly imply that the translation of very be placed before hombre. 2.3 Constituency tree transduction An alternate approach is to use linguistic information from a parser. Transduction rules between Spanish strings and English trees can be learned from a word-aligned parallel corpus with parse trees on one side (Graehl &amp; Knight, 2004). Such rules can be used to translate from Spanish to English by searching for the best English language tree for a given Spanish language string (Marcu et al., 2006). Alternately English trees produced by a parser can be transduced to 2 NP ADJP rules provide an elegant and powerful model of reordering, they come with a potential cost in NP context-sensitive translation. PN VB RB JJ it is very important es muy importante Figure 2.1: Constituency parses Spanish strings using the same rules (Huang et al., 2006). Translation rules may reach beyond one level in the syntax tree; this extended domai</context>
</contexts>
<marker>Graehl, Knight, 2004</marker>
<rawString>Graehl, Jonathan and Kevin Knight. Training Tree Transducers. NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Heidorn</author>
</authors>
<title>Intelligent writing assistance”.</title>
<date>2000</date>
<booktitle>In Dale et al. Handbook of Natural Language Processing,</booktitle>
<publisher>Marcel Dekker.</publisher>
<marker>Heidorn, 2000</marker>
<rawString>Heidorn, George. “Intelligent writing assistance”. In Dale et al. Handbook of Natural Language Processing, Marcel Dekker. (2000)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical Syntax-Directed Translation with Extended Domain of Locality. AMTA</title>
<date>2006</date>
<contexts>
<context position="2747" citStr="Huang et al. 2006" startWordPosition="414" endWordPosition="417">to this issue, including handling of unknown words, new senses of known words etc. In this work, we will focus on the issue of reordering, i.e. can we learn how to transform the sentence structure of one language into the sentence structure of another, in a way that is not tied to a specific domain or sub-domains, or indeed, sequences of individual words. An early attempt at greater generality in a purely phrasal setting was the alignment template approach (Och &amp; Ney 2004); newer approaches include formally syntactic (Chiang 2005), and linguistically syntactic approaches (Quirk et al. 2005), (Huang et al. 2006). In the next section, we examine these representative approaches to the reordering problem. 2 Related Work Our discussion of related work will be grounded in the following tiny English to Spanish example, where the training set includes: a very old book un libro más antiguo a book very old1 the old man el hombre viejo the man old it is very important es muy importante is very important 1 English gloss of Spanish sentences in italics. 1 Proceedings of the Second Workshop on Statistical Machine Translation, pages 1–8, Prague, June 2007. c�2007 Association for Computational Linguistics and the t</context>
<context position="7403" citStr="Huang et al., 2006" startWordPosition="1201" endWordPosition="1204">s can be learned from a word-aligned parallel corpus with parse trees on one side (Graehl &amp; Knight, 2004). Such rules can be used to translate from Spanish to English by searching for the best English language tree for a given Spanish language string (Marcu et al., 2006). Alternately English trees produced by a parser can be transduced to 2 NP ADJP rules provide an elegant and powerful model of reordering, they come with a potential cost in NP context-sensitive translation. PN VB RB JJ it is very important es muy importante Figure 2.1: Constituency parses Spanish strings using the same rules (Huang et al., 2006). Translation rules may reach beyond one level in the syntax tree; this extended domain of locality allows many phenomena including both lexicalized and unlexicalized rules. However reordering and translation are modeled jointly, which may exacerbate data sparsity. Furthermore it forces the system to pick between unlexicalized rules that capture reordering and lexicalized rules that model context-sensitive translation. For instance, the following rules can be extracted from the first sentence of the corpus: r1: un x1 x2 ՜ NP(DT(a) ADJP:x2 NN:x1) r2: x1 x2 ՜ ADJP(RB:x1 JJ:x2) Although together </context>
<context position="17456" citStr="Huang et al. 2006" startWordPosition="2790" endWordPosition="2793">Figure 4.1 shows this process as it applies to the test sentence in Section 2. If, at any node s, we cannot find a matching template compatible with the current treelet, we create an artificial source order template, which simply preserves the source language order in the target translation. We add a feature function that counts the number of such templates and train its weight during minimum error rate training. 4.3 Transduction using xR rules In the absence of a language model or other contextually dependent features, finding the highest scoring derivation would be a simple dynamic program (Huang et al. 2006) 6.However exact search using an n -gram language model leads to split states for each n -gram context. Instead we use an approximate beam search moving bottom-up in the tree, much like a CKY parser. Candidates in this search are derivations with respect to the transducer. Each transduction rule r has a vector of variables v,.i, ... vr . Each variable is associated with an input node S(v). For each input node s, we keep a beam of derivations b[s]. Derivations are represented as a pair (r, e) where r is a transduction rule and e E N is a vector with one integer for each of the k variables in r.</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Huang, Liang, Kevin Knight, and Aravind Joshi. Statistical Syntax-Directed Translation with Extended Domain of Locality. AMTA 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Faster Algorithms for Decoding with Integrated Language Models. ACL</title>
<date>2007</date>
<note>(to appear)</note>
<contexts>
<context position="19031" citStr="Huang and Chiang, 2007" startWordPosition="3058" endWordPosition="3061">&gt; 0 (r, e) F PopBest(prioq) AddToBeam(beam, (r, e), TrueScore((r, e))) for i in L.jej Enqueue(prioq, (r, e + 1i), EarlyScore((r, e + 1i))) return beam EarlyScore((r, e)) c F RuleScore(r) for i in L.jej s F InputNode(GetVariable (r, i)) beam F GetTranslationBeam(s) c F c +TrueScore(GetNthEntry(beam, ei)) return c Figure 4.2: Beam tree transduction vri E vrl °• vrk the candidate constructed from the eith entry in the beam b[S(vri)]. Figure 4.2 describes the transduction process. Since we approach decoding as xR transduction, the process is identical to that of constituencybased algorithms (e.g. Huang and Chiang, 2007). There are several free parameters to tune: • Beam size – Maximum number of candidates per input node (in this paper we use 100) • Beam threshold – maximum range of scores between top and bottom scoring candidate (we use a logprob difference of 30) • Maximum combinations considered – To bound search time, we can stop after a specified number of elements are popped off the priority queue (we use 5000) 5 Models We use all of the Treelet models we described in Quirk et al. (2005) namely: • Treelet table with translation probabilities estimated using maximum likelihood, with absolute discounting.</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Huang, Liang and David Chiang. Faster Algorithms for Decoding with Integrated Language Models. ACL 2007 (to appear)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase based translation. NAACL</title>
<date>2003</date>
<contexts>
<context position="1304" citStr="Koehn et al., 2003" startWordPosition="182" endWordPosition="185">modeling of lexical choice and reordering can narrow the applicability of learned rules. The treelet approach models reordering separately from lexical choice, using a discriminatively trained order model, which allows treelets to apply broadly, and has shown better generalization to new domains, but suffers a factorially large search space. We introduce a new reordering model based on dependency order templates, and show that it outperforms both phrasal and treelet systems on in-domain and out-of-domain text, while limiting the search space. 1 Introduction Modern phrasal SMT systems such as (Koehn et al., 2003) derive much of their power from being able to memorize and use long phrases. Phrases allow for non-compositional translation, local reordering and contextual lexical choice. However the phrases are fully lexicalized, which means they generalize poorly to even slightly outof-domain text. In an open competition (Koehn &amp; Monz, 2006) systems trained on parliamentary proceedings were tested on text from &apos;news commentary&apos; web sites, a very slightly different domain. The 9 phrasal systems in the English to Spanish track suffered an absolute drop in BLEU score of between 4.4% and 6.34% (14% to 27% re</context>
<context position="20462" citStr="Koehn et al., 2003" startWordPosition="3283" endWordPosition="3286">eature functions. In addition, we introduce the following: • Order template table, with template probabilities estimated using maximum likelihood, with absolute discounting. • A feature function that counts the number of artificial source order templates (see below) used in a candidate. The models are combined in a log-linear framework, with weights trained using minimum error rate training to optimize the BLEU score. 6 Experiments We evaluated the translation quality of the system using the BLEU metric (Papineni et al., 2002). We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al., 2003), and our treelet system. We report numbers for English to Spanish. 6.1 Data We used the Europarl corpus provided by the NAACL 2006 Statistical Machine Translation workshop. The target language model was trained using only the target side of the parallel corpus. The larger monolingual corpus was not utilized. The corpus consists of European Parliament proceedings, 730,740 parallel sentence pairs of English-Spanish, amounting to about 15M words in each language. The test data consists of 2000 sentences each of development (dev), development-test (devtest) and test data (test) from the same doma</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och, and Daniel Marcu. Statistical phrase based translation. NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Manual and automatic evaluation of machine translation between european languages.</title>
<date>2006</date>
<booktitle>Workshop on Machine Translation, NAACL</booktitle>
<contexts>
<context position="10913" citStr="Koehn and Monz (2006)" startWordPosition="1749" endWordPosition="1752">hoice, each rule must match all of the children at any given tree node. On the other hand, treelets are allowed to match more loosely. The translations of the unmatched children (un and muy in this case) are placed by exploring all possible orderings and scoring them with both order model and language model. Although this effectively decouples lexical selection from ordering, it comes at a huge cost in search space and translation quality may suffer due to search error. However, as mentioned in Section 1, this approach is able to generalize better to out-ofdomain data than phrasal approaches. Koehn and Monz (2006) also include a human evaluation, in which this system ranked noticeably higher than one might have predicted from its BLEU score. 3 Dependency Order Templates The Dependency Order Templates approach leverages the power of the xR rule formalism, while avoiding the problems mentioned in Section 2.3, by constructing the rules on the fly from two separately matched components: (a) Dependency treelet translation pairs described in Section 2.4 that capture contextual lexical translations but are underspecified with respect to ordering, and (b) Order templates, which are unlexicalized rules (over de</context>
<context position="1636" citStr="Koehn &amp; Monz, 2006" startWordPosition="232" endWordPosition="235">arch space. We introduce a new reordering model based on dependency order templates, and show that it outperforms both phrasal and treelet systems on in-domain and out-of-domain text, while limiting the search space. 1 Introduction Modern phrasal SMT systems such as (Koehn et al., 2003) derive much of their power from being able to memorize and use long phrases. Phrases allow for non-compositional translation, local reordering and contextual lexical choice. However the phrases are fully lexicalized, which means they generalize poorly to even slightly outof-domain text. In an open competition (Koehn &amp; Monz, 2006) systems trained on parliamentary proceedings were tested on text from &apos;news commentary&apos; web sites, a very slightly different domain. The 9 phrasal systems in the English to Spanish track suffered an absolute drop in BLEU score of between 4.4% and 6.34% (14% to 27% relative). The treelet system of Menezes et al. (2006) fared somewhat better but still suffered an absolute drop of 3.61%. Clearly there is a need for approaches with greater powers of generalization. There are multiple facets to this issue, including handling of unknown words, new senses of known words etc. In this work, we will fo</context>
</contexts>
<marker>Koehn, Monz, 2006</marker>
<rawString>Koehn, Philipp and Christof Monz. Manual and automatic evaluation of machine translation between european languages. Workshop on Machine Translation, NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical Machine Translation with Syntactified Target Language Phrases.</title>
<date>2006</date>
<contexts>
<context position="7055" citStr="Marcu et al., 2006" startWordPosition="1143" endWordPosition="1146">but does not lead to the reference, because the paucity of the grammar&apos;s single nonterminal causes this rule to incorrectly imply that the translation of very be placed before hombre. 2.3 Constituency tree transduction An alternate approach is to use linguistic information from a parser. Transduction rules between Spanish strings and English trees can be learned from a word-aligned parallel corpus with parse trees on one side (Graehl &amp; Knight, 2004). Such rules can be used to translate from Spanish to English by searching for the best English language tree for a given Spanish language string (Marcu et al., 2006). Alternately English trees produced by a parser can be transduced to 2 NP ADJP rules provide an elegant and powerful model of reordering, they come with a potential cost in NP context-sensitive translation. PN VB RB JJ it is very important es muy importante Figure 2.1: Constituency parses Spanish strings using the same rules (Huang et al., 2006). Translation rules may reach beyond one level in the syntax tree; this extended domain of locality allows many phenomena including both lexicalized and unlexicalized rules. However reordering and translation are modeled jointly, which may exacerbate d</context>
<context position="8578" citStr="Marcu et al. (2006)" startWordPosition="1378" endWordPosition="1381">x1 x2 ՜ ADJP(RB:x1 JJ:x2) Although together they capture the necessary reordering for our test sentence pair, they do not allow for context sensitive translations of the ambiguous terms very and old; each must be selected independently. Disappointingly, no single constituency tree transduction rule derived from this corpus translates old man as hombre viejo in a single step on the test sentence: the syntactic structures are slightly different, but the difference is sufficient to prevent matching.2 Again we note that phrases provide utility by capturing both reordering and context. While xRS 2 Marcu et al. (2006) and Zollmann et al. (2006) recognize this problem and attempt to alleviate it by grafting surface phrases into constituency trees by various methods. 2.4 Dependency treelet translation We previously described (Quirk et al, 2005) a linguistically syntax-based system that parses the source language, uses word-based alignments to project a target dependency tree, and extracts paired dependency tree fragments (treelets) instead of surface phrases. In contrast to the xRS approach, ordering is very loosely coupled with translation via a separate discriminatively trained dependency tree-based order </context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Marcu, Daniel, Wei Wang, Abdessamad Echihabi, and Kevin Knight. SPMT: Statistical Machine Translation with Syntactified Target Language Phrases. EMNLP-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arul Menezes</author>
<author>Kristina Toutanova</author>
<author>Chris Quirk</author>
</authors>
<title>Microsoft Research Treelet translation system: NAACL</title>
<date>2006</date>
<booktitle>Europarl evaluation. Workshop on Machine Translation, NAACL</booktitle>
<contexts>
<context position="1956" citStr="Menezes et al. (2006)" startWordPosition="285" endWordPosition="288">m being able to memorize and use long phrases. Phrases allow for non-compositional translation, local reordering and contextual lexical choice. However the phrases are fully lexicalized, which means they generalize poorly to even slightly outof-domain text. In an open competition (Koehn &amp; Monz, 2006) systems trained on parliamentary proceedings were tested on text from &apos;news commentary&apos; web sites, a very slightly different domain. The 9 phrasal systems in the English to Spanish track suffered an absolute drop in BLEU score of between 4.4% and 6.34% (14% to 27% relative). The treelet system of Menezes et al. (2006) fared somewhat better but still suffered an absolute drop of 3.61%. Clearly there is a need for approaches with greater powers of generalization. There are multiple facets to this issue, including handling of unknown words, new senses of known words etc. In this work, we will focus on the issue of reordering, i.e. can we learn how to transform the sentence structure of one language into the sentence structure of another, in a way that is not tied to a specific domain or sub-domains, or indeed, sequences of individual words. An early attempt at greater generality in a purely phrasal setting wa</context>
</contexts>
<marker>Menezes, Toutanova, Quirk, 2006</marker>
<rawString>Menezes, Arul, Kristina Toutanova and Chris Quirk. Microsoft Research Treelet translation system: NAACL 2006 Europarl evaluation. Workshop on Machine Translation, NAACL 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models,</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="22167" citStr="Och &amp; Ney, 2003" startWordPosition="3546" endWordPosition="3549">ning regimen of five iterations of Model 1, five iterations of HMM, and five iterations of Model 4, in both directions. The forward and backward alignments were symmetrized using a tree-based heuristic combination. The word 6 alignments and English dependency tree were used to project a target tree. From the aligned tree pairs we extracted a treelet table and an order template table. The comparison treelet system was identical except that no order template model was used. The comparison phrasal system was constructed using the same GIZA++ alignments and the heuristic combination described in (Och &amp; Ney, 2003). Except for the order models (Pharaoh uses a penalty on the deviance from monotone), the same models were used. All systems used a treelet or phrase size of 7 and a trigram language model. Model weights were trained separately for all 3 systems using minimum error rate training to maximize BLEU (Och, 2003) on the development set (dev). Some decoder pruning parameters were tuned on the development test (devtest). The test and NC-test data sets were not used until final tests. 7 Results We present the results of our system comparisons in Table 7.1 and Figure 7.1 using three different test sets:</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. A systematic comparison of various statistical alignment models, Computational Linguistics, 29(1):19-51 (2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation. ACL</title>
<date>2003</date>
<contexts>
<context position="22475" citStr="Och, 2003" startWordPosition="3601" endWordPosition="3602">ned tree pairs we extracted a treelet table and an order template table. The comparison treelet system was identical except that no order template model was used. The comparison phrasal system was constructed using the same GIZA++ alignments and the heuristic combination described in (Och &amp; Ney, 2003). Except for the order models (Pharaoh uses a penalty on the deviance from monotone), the same models were used. All systems used a treelet or phrase size of 7 and a trigram language model. Model weights were trained separately for all 3 systems using minimum error rate training to maximize BLEU (Och, 2003) on the development set (dev). Some decoder pruning parameters were tuned on the development test (devtest). The test and NC-test data sets were not used until final tests. 7 Results We present the results of our system comparisons in Table 7.1 and Figure 7.1 using three different test sets: The in-domain development test data (devtest), the in-domain blind test data (test) and the out-of-domain news commentary test data (NC-test). All differences (except phrasal vs. template on devtest), are statistically significant at the p&gt;=0.99 level under the bootstrap resampling test. Note that while th</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, Franz Josef. Minimum error rate training in statistical machine translation. ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The Alignment Template Approach to Statistical Machine Translation.</title>
<date>2004</date>
<journal>Computational Linguistics</journal>
<volume>30</volume>
<issue>4</issue>
<pages>417--449</pages>
<contexts>
<context position="2606" citStr="Och &amp; Ney 2004" startWordPosition="395" endWordPosition="398">ffered an absolute drop of 3.61%. Clearly there is a need for approaches with greater powers of generalization. There are multiple facets to this issue, including handling of unknown words, new senses of known words etc. In this work, we will focus on the issue of reordering, i.e. can we learn how to transform the sentence structure of one language into the sentence structure of another, in a way that is not tied to a specific domain or sub-domains, or indeed, sequences of individual words. An early attempt at greater generality in a purely phrasal setting was the alignment template approach (Och &amp; Ney 2004); newer approaches include formally syntactic (Chiang 2005), and linguistically syntactic approaches (Quirk et al. 2005), (Huang et al. 2006). In the next section, we examine these representative approaches to the reordering problem. 2 Related Work Our discussion of related work will be grounded in the following tiny English to Spanish example, where the training set includes: a very old book un libro más antiguo a book very old1 the old man el hombre viejo the man old it is very important es muy importante is very important 1 English gloss of Spanish sentences in italics. 1 Proceedings of the</context>
<context position="4677" citStr="Och &amp; Ney, 2004" startWordPosition="743" endWordPosition="746">ntence. The system is unable to learn the correct structure from the first sentence because the words are wrong, and from the second sentence even though the phrase old man has the right words in the right order, it does not lead to the reference translation because the translation of very cannot be inserted in the right place. a un very más old antiguo very old más antiguo old viejo man hombre old man hombre viejo very muy Table 2.1: Relevant extracted phrases Looking at this as a sparse data issue we might suspect that generalization could solve the problem. The alignment template approach (Och &amp; Ney, 2004) uses word classes rather than lexical items to model phrase translation. Yet this approach loses the advantage of context-sensitive lexical selection: the word translation model depends only on the word classes to subcategorize for translations, which leads to less accurate lexical choice in practice (Zens &amp; Ney, 2004). 2.2 Hierarchical translation Hierarchical systems (Chiang, 2005) induce a context-free grammar with one non-terminal directly from the parallel corpus, with the advantage of not requiring any additional knowledge source or tools, such as a treebank or a parser. However this ca</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Och, Franz Josef and Hermann Ney: The Alignment Template Approach to Statistical Machine Translation. Computational Linguistics 30 (4): 417-449 (2004)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<publisher>ACL</publisher>
<contexts>
<context position="20375" citStr="Papineni et al., 2002" startWordPosition="3268" endWordPosition="3271">s. • Trigram language model using modified Kneser-Ney smoothing. • Word and phrase count feature functions. In addition, we introduce the following: • Order template table, with template probabilities estimated using maximum likelihood, with absolute discounting. • A feature function that counts the number of artificial source order templates (see below) used in a candidate. The models are combined in a log-linear framework, with weights trained using minimum error rate training to optimize the BLEU score. 6 Experiments We evaluated the translation quality of the system using the BLEU metric (Papineni et al., 2002). We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al., 2003), and our treelet system. We report numbers for English to Spanish. 6.1 Data We used the Europarl corpus provided by the NAACL 2006 Statistical Machine Translation workshop. The target language model was trained using only the target side of the parallel corpus. The larger monolingual corpus was not utilized. The corpus consists of European Parliament proceedings, 730,740 parallel sentence pairs of English-Spanish, amounting to about 15M words in each language. The test data consists of 2000 sentences each o</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. BLEU: a method for automatic evaluation of machine translation. ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency Tree Translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<publisher>ACL</publisher>
<contexts>
<context position="2726" citStr="Quirk et al. 2005" startWordPosition="410" endWordPosition="413"> are multiple facets to this issue, including handling of unknown words, new senses of known words etc. In this work, we will focus on the issue of reordering, i.e. can we learn how to transform the sentence structure of one language into the sentence structure of another, in a way that is not tied to a specific domain or sub-domains, or indeed, sequences of individual words. An early attempt at greater generality in a purely phrasal setting was the alignment template approach (Och &amp; Ney 2004); newer approaches include formally syntactic (Chiang 2005), and linguistically syntactic approaches (Quirk et al. 2005), (Huang et al. 2006). In the next section, we examine these representative approaches to the reordering problem. 2 Related Work Our discussion of related work will be grounded in the following tiny English to Spanish example, where the training set includes: a very old book un libro más antiguo a book very old1 the old man el hombre viejo the man old it is very important es muy importante is very important 1 English gloss of Spanish sentences in italics. 1 Proceedings of the Second Workshop on Statistical Machine Translation, pages 1–8, Prague, June 2007. c�2007 Association for Computational </context>
<context position="8807" citStr="Quirk et al, 2005" startWordPosition="1412" endWordPosition="1415">ently. Disappointingly, no single constituency tree transduction rule derived from this corpus translates old man as hombre viejo in a single step on the test sentence: the syntactic structures are slightly different, but the difference is sufficient to prevent matching.2 Again we note that phrases provide utility by capturing both reordering and context. While xRS 2 Marcu et al. (2006) and Zollmann et al. (2006) recognize this problem and attempt to alleviate it by grafting surface phrases into constituency trees by various methods. 2.4 Dependency treelet translation We previously described (Quirk et al, 2005) a linguistically syntax-based system that parses the source language, uses word-based alignments to project a target dependency tree, and extracts paired dependency tree fragments (treelets) instead of surface phrases. In contrast to the xRS approach, ordering is very loosely coupled with translation via a separate discriminatively trained dependency tree-based order model. The switch to a dependency parse also changes the conditioning information available for translation: related lexical items are generally adjacent, rather than separated by a path of unlexicalized nonterminals. In effect, </context>
<context position="13033" citStr="Quirk et al. (2005)" startWordPosition="2057" endWordPosition="2060">ed, but the size of the search space necessitates tight pruning, leading to significant search error. By contrast, in the order template approach we consider only reorderings that are captured in some order template. The drastic reduction in search space leads to an overall improvement, not only in decoding speed, but also in translation quality due to reduced search error. 3.1 Extracting order templates For each pair of parallel training sentences, we parse the source sentence, obtain a source dependency tree, and use GIZA++ word alignments to project a target dependency tree as described in Quirk et al. (2005). Given this pair of aligned source and target dependency trees, we recursively extract one order template for each pair of aligned non-leaf source and target nodes. In the case of multi-word alignments, all contiguous 3 aligned nodes are added to the template. Next we recursively add child nodes as follows: For each node in the template, add all its children. For each such child, if it is aligned, stop recursing, if it is unaligned, recursively add its children. On each template node we remove the lexical items; we retain the part of speech on the source nodes (we do not use target linguistic</context>
<context position="19513" citStr="Quirk et al. (2005)" startWordPosition="3146" endWordPosition="3149">e we approach decoding as xR transduction, the process is identical to that of constituencybased algorithms (e.g. Huang and Chiang, 2007). There are several free parameters to tune: • Beam size – Maximum number of candidates per input node (in this paper we use 100) • Beam threshold – maximum range of scores between top and bottom scoring candidate (we use a logprob difference of 30) • Maximum combinations considered – To bound search time, we can stop after a specified number of elements are popped off the priority queue (we use 5000) 5 Models We use all of the Treelet models we described in Quirk et al. (2005) namely: • Treelet table with translation probabilities estimated using maximum likelihood, with absolute discounting. • Discriminative tree-based order model. • Forward and backward lexical weighting, using Model-1 translation probabilities. • Trigram language model using modified Kneser-Ney smoothing. • Word and phrase count feature functions. In addition, we introduce the following: • Order template table, with template probabilities estimated using maximum likelihood, with absolute discounting. • A feature function that counts the number of artificial source order templates (see below) use</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Quirk, Chris, Arul Menezes, and Colin Cherry. Dependency Tree Translation: Syntactically informed phrasal SMT. ACL 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrasebased statistical machine translation. HLT-NAACL</title>
<date>2004</date>
<contexts>
<context position="4998" citStr="Zens &amp; Ney, 2004" startWordPosition="791" endWordPosition="794">ht place. a un very más old antiguo very old más antiguo old viejo man hombre old man hombre viejo very muy Table 2.1: Relevant extracted phrases Looking at this as a sparse data issue we might suspect that generalization could solve the problem. The alignment template approach (Och &amp; Ney, 2004) uses word classes rather than lexical items to model phrase translation. Yet this approach loses the advantage of context-sensitive lexical selection: the word translation model depends only on the word classes to subcategorize for translations, which leads to less accurate lexical choice in practice (Zens &amp; Ney, 2004). 2.2 Hierarchical translation Hierarchical systems (Chiang, 2005) induce a context-free grammar with one non-terminal directly from the parallel corpus, with the advantage of not requiring any additional knowledge source or tools, such as a treebank or a parser. However this can lead to an explosion of rules. In order to make the problem tractable and avoid spurious ambiguity, Chiang restricts the learned rules in several ways. The most problematic of these is that every rule must have at least one pair of aligned words, and that adjacent non-terminals are not permitted on the source side. In</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Zens, Richard and Hermann Ney. Improvements in phrasebased statistical machine translation. HLT-NAACL 2004</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>