<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000040">
<title confidence="0.451088">
GPSM: A GENERALIZED PROBABILISTIC
SEMANTIC MODEL FOR AMBIGUITY RESOLUTION
</title>
<author confidence="0.799211">
14ing-Shin Chang, tYih-Fen Luo and tKeh-Yih Su
</author>
<affiliation confidence="0.826048666666667">
tDepartment of Electrical Engineering
National Tsing Hua University
Hsinchu, TAIWAN 30043, R.O.C.
</affiliation>
<email confidence="0.877141">
shin@ee.nthu.edu.tw, kysu@ee.nthu.edu.tw
</email>
<sectionHeader confidence="0.457014" genericHeader="abstract">
*Behavior Design Corporation
</sectionHeader>
<bodyText confidence="0.5163675">
No. 28, 2F, R&amp;D Road II, Science-Based Industrial Park
Hsinchu, TAIWAN 30077, R.O.C.
</bodyText>
<sectionHeader confidence="0.931152" genericHeader="keywords">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999590785714286">
In natural language processing, ambiguity res-
olution is a central issue, and can be regarded
as a preference assignment problem. In this
paper, a Generalized Probabilistic Semantic
Model (GPSM) is proposed for preference
computation. An effective semantic tagging
procedure is proposed for tagging semantic
features. A semantic score function is de-
rived based on a score function, which inte-
grates lexical, syntactic and semantic prefer-
ence under a uniform formulation. The se-
mantic score measure shows substantial im-
provement in structural disambiguation over
a syntax-based approach.
</bodyText>
<sectionHeader confidence="0.997774" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999983914893617">
In a large natural language processing system,
such as a machine translation system (MTS), am-
biguity resolution is a critical problem. Various
rule-based and probabilistic approaches had been
proposed to resolve various kinds of ambiguity
problems on a case-by-case basis.
In rule-based systems, a large number of rules
are used to specify linguistic constraints for re-
solving ambiguity. Any parse that violates the se-
mantic constraints is regarded as ungrammatical
and rejected. Unfortunately, because every &amp;quot;rule&amp;quot;
tends to have exception and uncertainty, and ill-
formedness has significant contribution to the er-
ror rate of a large practical system, such &amp;quot;hard
rejection&amp;quot; approaches fail to deal with these situa-
tions. A better way is to find all possible interpre-
tations and place emphases on preference, rather
than well-formedness (e.g., [Wilks 83].) However,
most of the known approaches for giving prefer-
ence depend heavily on heuristics such as counting
the number of constraint satisfactions. Therefore,
most such preference measures can not be objec-
tively justified. Moreover, it is hard and costly
to acquire, verify and maintain the consistency of
the large fine-grained rule base by hand.
Probabilistic approaches greatly relieve the
knowledge acquisition problem because they are
usually trainable, consistent and easy to meet cer-
tain optimum criteria. They can also provide
more objective preference measures for &amp;quot;soft re-
jection.&amp;quot; Hence, they are attractive for a large sys-
tem. The current probabilistic approaches have a
wide coverage including lexical analysis [DeRose
88, Church 88], syntactic analysis [Garside 87,
Fujisalci 89, Su 88, 89, 91b], restricted semantic
analysis [Church 89, Liu 89, 90], and experimental
translation systems [Brown 90]. However, there
is still no integrated approach for modeling the
joint effects of lexical, syntactic and semantic in-
formation on preference evaluation.
A generalized probabilistic semantic model
(GPSM) will be proposed in this paper to over-
come the above problems. In particular, an in-
tegrated formulation for lexical, syntactic and se-
mantic knowledge will be used to derive the se-
mantic score for semantic preference evaluation.
Application of the model to structural disam-
</bodyText>
<page confidence="0.995569">
177
</page>
<bodyText confidence="0.99981625">
biguation is investigated. Preliminary experiments
show about 10%-14% improvement of the seman-
tic score measure over a model that uses syntactic
information only.
</bodyText>
<sectionHeader confidence="0.7115085" genericHeader="method">
2. Preference Assignment Using
Score Function
</sectionHeader>
<bodyText confidence="0.9998834">
In general, a particular semantic interpretation of
a sentence can be characterized by a set of lexical
categories (or parts of speech), a syntactic struc-
ture, and the semantic annotations associated with
it. Among the various interpretations of a sen-
tence, the best choice should be the most probable
semantic interpretation for the given input words.
In other words, the interpretation that maximizes
the following score function [Su 88, 89, 91b] or
analysis score [Chen 911 is preferred:
</bodyText>
<equation confidence="0.8031488">
Score (Semi, Syni , Lexk, Words)
P (Semi, Syn, LexkIWords)
= P (SemilSyni, Lerk,Words)
x P (SynilLerk,Words)
x P (LexklWords)
</equation>
<bodyText confidence="0.9999518125">
where (Lexk, Syn, Semi) refers to the kth set of
lexical categories, the jth syntactic structure and
the ith set of semantic annotations for the input
Words. The three component functions are re-
ferred to as semantic score (Ssem), syntactic score
(Ssy„) and lexical score (Stex), respectively. The
global preference measure will be referred to as
compositional score or simply as score. In partic-
ular, the semantic score accounts for the semantic
preference on a given set of lexical categories and
a particular syntactic structure for the sentence.
Various formulation for the lexical score and syn-
tactic score had been studied extensively in our
previous works [Su 88, 89, 91b, Chiang 92] and
other literatures. Hence, we will concentrate on
the formulation for semantic score.
</bodyText>
<sectionHeader confidence="0.967922" genericHeader="method">
3. Semantic Tagging
</sectionHeader>
<subsectionHeader confidence="0.9636545">
Canonical Form of Semantic
Representation
</subsectionHeader>
<bodyText confidence="0.999974055555556">
Given the formulation in Eqn. (1), first we will
show how to extract the abstract objects (Semi,
Syn, Lexk) from a semantic representation. In
general, a particular interpretation of a sentence
can be represented by an annotated syntax tree
(AST), which is a syntax tree annotated with fea-
ture structures in the tree nodes. Figure 1 shows
an example of AST. The annotated version of a
node A is denoted as A AU A] in the figure,
where fA is the feature structure associated with
node A. Because an AST preserves both syntactic
and semantic information, it can be converted to
other deep structure representations easily. There-
fore, without lose of generality, the AST represen-
tation will be used as the canonical form of seman-
tic representation for preference evaluation. The
techniques used here, of course, can be applied to
other deep structure representations as well.
</bodyText>
<equation confidence="0.998304888888889">
A[fA]
L8=(A }
L7=(13, C )
B[fg] C[fd L6=(3, F,G )
3 6 L5=(3, F,c4)
D[f0] E[fE] KfF] G[fc] L4=(B, C3, C4 )
I ti I t2 I CI I Is
Ci C2 C3 C4
(W 1) (w2) (w3) (w4)
</equation>
<figureCaption confidence="0.9956925">
Figure 1. Annotated Syntax Tree
(AST) and Phrase Levels (PL).
</figureCaption>
<bodyText confidence="0.980502111111111">
The hierarchical AST can be represented by
a set of phrase levels, such as Li through Lg in
Figure 1. Formally, a phrase level (PL) is a set
of symbols corresponding to a sentential form of
the sentence. The phrase levels in Figure 1 are
derived from a sequence of rightmost derivations,
which is commonly used in an LR parsing mech-
anism. For example, L5 and Li correspond to the
rightmost derivation B F c4 B c3 e4. Note
</bodyText>
<sectionHeader confidence="0.397167" genericHeader="method">
TM
</sectionHeader>
<bodyText confidence="0.992088428571429">
that the first phrase level L1 consists of all lexical
categories ci c„ of the terminal words (wi
w„). A phrase level with each symbol annotated
with its feature structure is called an annotated
phrase level (APL). The i-th APL is denoted as
F. For example, L5 in Figure 1 has an annotated
phrase level F5 = {B [fa] , F [IF] , C4 Lic.j} as its
</bodyText>
<equation confidence="0.961357428571428">
(1)
(semantic score)
(syntactic score)
(lexical score)
L3= (D, E , c3 , c4 )
L2=(D, C2, C3 , C4)
=(CI C/2, C3, C4 )
</equation>
<page confidence="0.963452">
178
</page>
<bodyText confidence="0.9999666">
counterpart, where fc, is the atomic feature of the
lexical category c4, which comes from the lexical
item of the 4th word w4. With the above nota-
tions, the score function can be re-formulated as
follows:
</bodyText>
<equation confidence="0.96276">
Score (Semi, Syn, Lexk , Words) (2)
P (Fr , LT,C11114)
P(rTILT,ci,wi) (semantic score)
x P (LT lel&apos;, 4) (syntactic score)
x P (c7114) (lexical score)
</equation>
<bodyText confidence="0.9964777">
where cin (a short form for {c/ c„)) is the
kth set of lexical categories (Lexk), Lim ({Li
L„,)) is the jth syntactic structure (Syn), and rim
((Pi rm)) is the ith set of semantic annotations
(Semi) for the input words win ({wi wn)). A
good encoding scheme for the PCs will allow us
to take semantic information into account with-
out using redundant information. Hence, we will
show how to annotate a syntax tree so that various
interpretations can be characterized differently.
</bodyText>
<subsectionHeader confidence="0.994139">
Semantic Tagging
</subsectionHeader>
<bodyText confidence="0.998617338235294">
A popular linguistic approach to annotate a tree
is to use a unification-based mechanism. How-
ever, many information irrelevant to disambigua-
tion might be included. An effective encod-
ing scheme should be simple yet can preserve
most discrimination information for disambigua-
tion. Such an encoding scheme can be ac-
complished by associating each phrase struc-
ture rule A X1X2 ... X m with a head list
(X2„Xi2...Xim). The head list is formed by
arranging the children nodes (X1, X2, , XM)
in descending order of importance to the compo-
sitional semantics of their mother node A. For this
reason, Xii, Xi2 and Xi, are called the primary,
secondary and the j-th heads of A, respectively.
The compositional semantic features of the mother
node A can be represented as an ordered list of the
feature structures of its children, where the order
is the same as in the head list. For example, for
S NP VP, we have a head list (VP, NP), be-
cause VP is the (primary) head of the sentence.
When composing the compositional semantics of
S. the features of VP and NP will be placed in
the first and second slots of the feature structure
of S, respectively.
Because not all children and all features in
a feature structure are equally significant for dis-
ambiguation, it is not really necessary to annotate
a node with the feature structures of all its chil-
dren. Instead, only the most important N chil-
dren of a node is needed in characterizing the
node, and only the most discriminative feature of
a child is needed to be passed to its mother node.
In other words, an N-dimensional feature vector,
called a semantic N-tuple, could be used to char-
acterize a node without losing much information
for disambiguation. The first feature in the se-
mantic N-tuple comes from the primary head, and
is thus called the head feature of the semantic N-
tuple. The other features come from the other
children in the order of the head list. (Compare
these notions with the linguistic sense of head and
head feature.) An annotated node can thus be
approximated as A A .f2, • • fiv), where
fi = HeadFeature () is the (primary) head
feature of its j-th head (i.e., Xi.) in the head list.
Non-head features of a child node xi, will not be
percolated up to its mother node. The head fea-
ture of A itself, in this case, is A. For a terminal
node, the head feature will be the semantic tag of
the corresponding lexical item; other features in
the N-tuple will be tagged as 66 (NULL).
Figure 2 shows two possible annotated syn-
tax trees for the sentence &amp;quot;... saw the boy in
the park.&amp;quot; For instance, the &amp;quot;loc(ation)&amp;quot; feature
of &amp;quot;park&amp;quot; is percolated to its mother NP node
as the head feature; it then serves as the sec-
ondary head feature of its grandmother node PP,
because the NP node is the secondary head of
PP. Similarly, the VP node in the left tree is an-
notated as VP(sta,anim) according to its primary
head saw(sta,cb) and secondary head NP(anim,in).
The VP(sta,in) node in the right tree is tagged dif-
ferently, which reflects different attachment pref-
erence of the prepositional phrase.
By this simple mechanism, the major charac-
teristics of the children, namely the head features,
can be percolated to higher syntactic levels, and
</bodyText>
<page confidence="0.923046">
179
</page>
<equation confidence="0.9651105">
saw(sta4) NP(anim,def)
••*&amp;quot;....°°#‘\.
the(def,4)) boy(anim4)
a(a-h1,a-h2) VP sta,anim)13(13-hi,13-h4 a(a-h1a-h2) VP
..‘c\
saw(sta4) NP anim,inL\
</equation>
<bodyText confidence="0.96782875">
sta: stative verb
def: definite article
loc: location
anim: animate
</bodyText>
<equation confidence="0.952108333333333">
i3(Pr-hi,ll- h4
7....(iin,loct)
in(in,0) NP(loc,def)
the(def4) park(loc,4))
NP(anim,def) PP (in,loc)
\)
the(def,4) boy(anim,0) in(in,4) NP(loc,def)
•/#°°. &apos;&apos;&apos;&apos;•.s\.
the(def,4)) park(loc,0)
</equation>
<figureCaption confidence="0.996827">
Figure 2. Ambiguous PP attachment patterns annotated with semantic 2-tuples.
</figureCaption>
<bodyText confidence="0.9999044">
their correlation and dependency can be taken into
account in preference evaluation even if they are
far apart. In this way, different interpretations will
be tagged differently. The preference on a partic-
ular interpretation can thus be evaluated from the
distribution of the annotated syntax trees. Based
on the above semantic tagging scheme, a seman-
tic score will be proposed to evaluate the seman-
tic preference on various interpretations for a sen-
tence. Its performance improvement over syntac-
tic score [Su 88, 89, 9113] will be investigated.
Consequently, a brief review of the syntactic score
evaluation method is given before going into de-
tails of the semantic score model. (See the cited
references for details.)
</bodyText>
<sectionHeader confidence="0.967172" genericHeader="method">
4. Syntactic Score
</sectionHeader>
<bodyText confidence="0.999492">
According to Eqn. (2), the syntactic score can be
formulated as follows [Su 88, 89, 91b]:
</bodyText>
<equation confidence="0.973295571428571">
S,,3 -.7. P (S yni}Lex k, wi) = P (LT Ic7 ,w7) (3)
In
. HP (LilLirl ,c7 , w)
1=2
pe. H P (41,11-1)
P.&apos;, II P (LilLi_i)
. II P ({eel, Al, )31} I {al, Xi, X2, • - • , X m , AD
</equation>
<bodyText confidence="0.9992405">
where al, 01 are the left context and right context
under which the derivation A1 4 x1x2...xm
occurs. (Assume that Li = {al, Ai, A} and
L1_1 = {cri, Xi,- - • ,Xm,i3i}.) If L left context
symbols in a/ and R right context symbols in 0/
are consulted to evaluate the syntactic score, it is
said to operate in LL,RR mode of operation. When
the context is ignored, such an L.4)R0 mode of oper-
ation reduces to a stochastic context-free grammar.
To avoid the normalization problem [Su 91b]
arisen from different number of transition prob-
abilities for different syntax trees, an alternative
formulation of the syntactic score is to evaluate
the transition probabilities between configuration
changes of the parser. For instance, the config-
uration of an LR parser is defined by its stack
contents and input buffer. For the AST in Figure
1, the parser configurations after the read of ci,
c2, c3, c4 and $ (end-of-sentence) are equivalent
to Li, L2, L4, L5 and L8, respectively. Therefore,
the syntactic score can be approximated as [Su
89, 91b]:
</bodyText>
<equation confidence="0.9989925">
S,y,, :-...- P (L8, L7 • • • 1,21Li) (4)
P(L8IL5) x P (L51L4) x P(L41L2) x P(L2IL1)
</equation>
<bodyText confidence="0.993381">
In this way, the number of transition probabilities
in the syntactic scores of all AST&apos;s will be kept
the same as the sentence length.
</bodyText>
<page confidence="0.997541">
180
</page>
<sectionHeader confidence="0.960663" genericHeader="method">
5. Semantic Score
</sectionHeader>
<bodyText confidence="0.999683666666667">
Semantic score evaluation is similar to syntactic
score evaluation. From Eqn. (2), we have the
following semantic model for semantic score:
</bodyText>
<equation confidence="0.999152166666667">
S sem (Semi, Syni , Lexk, Words) (5)
P (117141,4, w7)
= IIP (rilrii-1, LT , C7, WO
1=2
HP (r/Ir1-1)
P (I( 1.7 I tui,-5-(7:5-6,•••,xm,74,1)
</equation>
<bodyText confidence="0.912726285714286">
where Al E A/ (h,i, fo, • • • , fi,N) is the anno-
tated version of Ai, whose semantic N-tuple is
• • , ft,N), and rti, ,(3, are the annotated
context symbols. Only 4/ is assumed to be sig-
nificant for the transition to F/ in the last equa-
tion, because all required information is assumed
to have been percolated to F,.j through semantics
composition.
Each term in Eqn. (5) can be interpreted as
the probability that A1 is annotated with the partic-
ular set of head features (f,,i , 1.1,2, • • AN), given
that X./ XM are reduced to A/ in the context of
Ti/- and 0/. So it can be interpreted informally as
P(Al(h,i, • • • , ft.N) At +— Xi &amp;quot; • X m
in the context ofc7,131 ). It corresponds to the se-
mantic preference assigned to the annotated node
A,. Since (ft,i, • AN) are the head features
from various heads of the substructures of A, each
term reflects the feature co-occurrence preference
among these heads. Furthermore, the heads could
be very far apart. This is different from most
simple Markov models, which can deal with local
constraints only. Hence, such a formulation well
characterizes long distance dependency among the
heads, and provides a simple mechanism to incor-
porate the feature co-occurrence preference among
them. For the semantic N-tuple model, the seman-
tic score can thus be expressed as follows:
</bodyText>
<equation confidence="0.865938">
Ssem (6)
P (AI (Ai, .fi,2 • • • ft ,N) lab &lt;— X1 • • • X m 01)
</equation>
<page confidence="0.974965">
1=2
181
</page>
<bodyText confidence="0.999988357142857">
where fii are the semantic tags from the chil-
dren of Al. For example, we have terms
like P (VP (sta, anim) I a, VP 4—V NP,/3) and
P (VP (sta, in) I a, VP 4—V NP PP,O), respec-
tively, for the left and right trees in Figure 2. The
annotations of the context are ignored in evalu-
ating Eqn. (6) due to the assumption of seman-
tics compositionality. The operation mode will be
called LLRR+AN, where N is the dimension of the
N-tuple, and the subscript L (or R) refers to the
size of the context window. With an appropriate
N, the score will provide sufficient discrimination
power for general disambiguation problem with-
out resorting to full-blown semantic analysis.
</bodyText>
<sectionHeader confidence="0.9321695" genericHeader="method">
6. Major Categories and
Semantic Features
</sectionHeader>
<bodyText confidence="0.99122024137931">
As mentioned before, not all constituents are
equally important for disambiguation. For in-
stance, head words are usually more important
than modifiers in determining the compositional
semantic features of their mother node. There is
also lots of redundancy in a sentence. For in-
stance, &amp;quot;saw boy in park&amp;quot; is equally recogniz-
able as &amp;quot;saw the boy in the park.&amp;quot; Therefore,
only a few categories, including verbs, nouns, ad-
jectives, prepositions and adverbs and their pro-
jections (NP, VP, AP, PP, ADVP), are used to
carry semantic features for disambiguation. These
categories are roughly equivalent to the major cat-
egories in linguistic theory [Sells 851 with the in-
clusion of adverbs as the only difference.
The semantic feature of each major category
is encoded with a set of semantic tags that well
describes each category. A few rules of thumb
are used to select the semantic tags. In particular,
semantic features that can discriminate different
linguistic behavior from different possible seman-
tic N-tuples are preferred as the semantic tags.
With these heuristics in mind, the verbs, nouns,
adjectives, adverbs and prepositions are divided
into 22, 30, 14, 10 and 28 classes, respectively.
For example, the nouns are divided into &amp;quot;human,&amp;quot;
&amp;quot;plant,&amp;quot; &amp;quot;time,&amp;quot; &amp;quot;space,&amp;quot; and so on. These seman-
tic classes come from a number of sources and
the semantic attribute hierarchy of the ArchTran Table 1. Close Test of Semantic Score
</bodyText>
<note confidence="0.6162785">
MTS [Su 90, Chen 91].
7. Test and Analysis
</note>
<bodyText confidence="0.998868">
The semantic N-tuple model is used to test the
improvement of the semantic score over syntactic
score in structure disambiguation. Eqn. (3) is
adopted to evaluate the syntactic score in L2R1
mode of operation. The semantic score is derived
from Eqn. (6) in L2/2/ i-AN mode, for N 1, 2,
3, 4, where N is the dimension of the semantic
N-tuple.
A total of 1000 sentences (including 3 un-
ambiguous ones) are randomly selected from 14
computer manuals for training or testing. They
are divided into 10 parts; each part contains 100
sentences. In close tests, 9 parts are used both
as the training set and the testing set. In open
tests, the rotation estimation approach [Devijver
82] is adopted to estimate the open test perfor-
mance. This means to iteratively test one part of
the sentences while using the remaining parts as
the training set. The overall performance is then
estimated as the average performance of the 10
iterations.
The performance is evaluated in terms of Top-
N recognition rate (TNRR), which is defined as
the fraction of the test sentences whose preferred
interpretation is successfully ranked in the first
N candidates. Table 1 shows the simulation re-
sults of close tests. Table 2 shows partial results
for open tests (up to rank 5.) The recognition
rates achieved by considering syntactic score only
and semantic score only are shown in the tables.
(-.21Z1+A3 and L2R1+A4 performance are the same
as L2R1-1-A2 in the present test environment So
they are not shown in the tables.) Since each sen-
tence has about 70-75 ambiguous constructs on
the average, the task perplexity of the current dis-
ambiguation task is high.
</bodyText>
<table confidence="0.999411">
Score Syntax Semantics Semantics
(L2R1) (L2R1+A 1) (L2R1+A2)
Rank Count TNRR Count TNRR Count TNRR
(%) (%) (%)
1 781 87.07 872 97.21 866 96.54
2 101 98.33 20 99.44 24 99.22
3 9 99.33 5 100.00 4 99.67
4 5 99.89 - -
5 - - 2 99.89
13 - - 1 100.00
18 1 100.00
DataBase: 900 Sentences
Test Set: 897 Sentences
Total Number of Ambiguous Trees = 63233
(*) TNRR: Top-N Recognition Rate
</table>
<tableCaption confidence="0.999133">
Table 2. Open Test of Semantic Score
</tableCaption>
<table confidence="0.963004705882353">
Score Syntax Semantics Semantics
(L2R1) (L2R1+A1) (L2R1+A2)
Rank Count TNRR I Count TNRR
(T) Count TNRR (%)
(To) ,
1 430 43.13 569 57.07 578 57.97
2 232 66.40 163 73.42 167 74.72
3 94 75.83 90 82.45 75 82.25
4 80 83.85 50 87.46 49 87.16
5 35 87.36 22 89.67 28 89.97
DataBase: 900 Sentences (+)
Test Set: 997 Sentences (++)
Total Number of Ambiguous Trees = 75339
(+) DataBase: effective database size for rotation
estimation
(++) Test Set: all test sentences participating the
rotation estimation test
</table>
<page confidence="0.997085">
182
</page>
<bodyText confidence="0.999964911764706">
The close test Top-1 performance (Table 1)
for syntactic score (87%) is quite satisfactory.
When semantic score is taken into account, sub-
stantial improvement in recognition rate can be
observed further (97%). This shows that the se-
mantic model does provide an effective mecha-
nism for disambiguation. The recognition rates
in open tests, however, are less satisfactory under
the present test environment. The open test per-
formance can be attributed to the small database
size and the estimation error of the parameters
thus introduced. Because the training database is
small with respect to the complexity of the model,
a significant fraction of the probability entries in
the testing set can not be found in the training set.
As a result, the parameters are somewhat &amp;quot;over-
tuned&amp;quot; to the training database, and their values
are less favorable for open tests. Nevertheless,
in both close tests and open tests, the semantic
score model shows substantial improvement over
syntactic score (and hence stochastic context-free
grammar). The improvement is about 10% for
close tests and 14% for open tests.
In general, by using a larger database and bet-
ter robust estimation techniques [Su 91a, Chiang
92], the baseline model can be improved further.
As we had observed from other experiments for
spoken language processing [Su 91a], lexical tag-
ging, and structure disambiguation [Chiang 92],
the performance under sparse data condition can
be improved significantly if robust adaptive learn-
ing techniques are used to adjust the initial param-
eters. Interested readers are referred to [Su 91a,
Chiang 92] for more details.
</bodyText>
<sectionHeader confidence="0.684205" genericHeader="conclusions">
8. Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999785896551724">
In this paper, a generalized probabilistic seman-
tic model (GPSM) is proposed to assign semantic
preference to ambiguous interpretations. The se-
mantic model for measuring preference is based
on a score function, which takes lexical, syntactic
and semantic information into consideration and
optimizes the joint preference. A simple yet effec-
tive encoding scheme and semantic tagging proce-
dure is proposed to characterize various interpreta-
tions in an N dimensional feature space. With this
encoding scheme, one can encode the interpre-
tations with discriminative features, and take the
feature co-occurrence preference among various
constituents into account. Unlike simple Markov
models, long distance dependency can be man-
aged easily in the proposed model. Preliminary
tests show substantial improvement of the seman-
tic score measure over syntactic score measure.
Hence, it shows the possibility to overcome the
ambiguity resolution problem without resorting to
full-blown semantic analysis.
With such a simple, objective and trainable
formulation, it is possible to take high level se-
mantic knowledge into consideration in statistic
sense. It also provides a systematic way to con-
struct a disambiguation module for large practical
machine translation systems without much human
intervention; the heavy burden for the linguists to
write fine-grained &amp;quot;rules&amp;quot; can thus be relieved.
</bodyText>
<sectionHeader confidence="0.999126" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.983293454545454">
[Brown 90] Brown, P. et al., &amp;quot;A Statistical Ap-
proach to Machine Translation,&amp;quot; Computational
Linguistics, vol. 16, no. 2, pp. 79-85, June
1990.
[Chen 91] Chen, S.-C., J.-S. Chang, J.-N. Wang
and K.-Y. Su, &amp;quot;ArchTran: A Corpus-Based
Statistics-Oriented English-Chinese Machine
Translation System,&amp;quot; Proceedings of Machine
Translation Summit III, pp. 33-40, Washing-
ton, D.C., USA, July 1-4, 1991.
[Chiang 92] Chiang, T.-H., Y.-C. Lin and K.-Y.
Su, &amp;quot;Syntactic Ambiguity Resolution Using A
Discrimination and Robustness Oriented Adap-
tive Learning Algorithm&amp;quot;, to appear in Pro-
ceedings of COLING-92, 14th Int. Conference
on Computational Linguistics, Nantes, France,
20-28 July, 1992.
[Church 88] Church, K., &amp;quot;A Stochastic Parts Pro-
gram and Noun Phrase Parser for Unrestricted
Text,&amp;quot; ACL Proc. 2nd Conf on Applied Natu-
ral Language Processing, pp. 136-143, Austin,
Texas, USA, 9-12 Feb. 1988.
</reference>
<page confidence="0.990027">
183
</page>
<reference confidence="0.99976447826087">
[Church 89] Church, K. and P. Hanks, &amp;quot;Word As-
sociation Norms, Mutual Information, and Lex-
icography,&amp;quot; Proc. 27th Annual Meeting of the
ACL, pp. 76-83, University of British Colum-
bia, Vancouver, British Columbia, Canada, 26-
29 June 1989.
[DeRose 88] DeRose, Steven. J., &amp;quot;Grammatical
Category Disambiguation by Statistical Opti-
mization,&amp;quot; Computational Linguistics, vol. 14,
no. 1, pp. 31-39, 1988.
[Devijver 821 Devijver, P.A., and J. Kittler,
Pattern Recognition: A Statistical Approach,
Prentice-Hall, London, 1982.
[Fujisaki 89] Fujisalci, T., F. Jelinek, J. Cocke, E.
Black and T. Nishino, &amp;quot;A Probabilistic Parsing
Method for Sentence Disambiguation,&amp;quot; Proc. of
Int. Workshop on Parsing Technologies (IWPT-
89), pp. 85-94, CMU, Pittsburgh, PA, U.S.A.,
28-31 August 1989.
[Garside 87] Garside, Roger, Geoffrey Leech and
Geoffrey Sampson (eds.), The Computational
Analysis of English: A Corpus-Based Approach,
Longman Inc., New York, 1987.
[Liu 89] Liu, C.-L., On the Resolution of English
PP Attachment Problem with a Probabilistic Se-
mantic Model, Master Thesis, National Tsing
Hua University, Hsinchu, TAIWAN, R.O.C.,
1989.
[Liu 90] Liu, C.-L, J.-S. Chang and K.-Y. Su,
&amp;quot;The Semantic Score Approach to the Disam-
biguation of PP Attachment Problem,&amp;quot; Proc. of
ROCLING-III, pp. 253-270, Taipei, R.O.C.,
September 1990.
[Sells 85] Sells, Peter, Lectures On Con-
temporary Syntactic Theories: An Introduc-
lion to Government-Binding Theory, General-
ized Phrase Structure Grammar, and Lexical-
Functional Grammar, CSLI Lecture Notes
Number 3, Center for the Study of Language
and Information, Leland Stanford Junior Uni-
versity., 1985.
[Su 881 Su, K.-Y. and J.-S. Chang, &amp;quot;Semantic and
Syntactic Aspects of Score Function,&amp;quot; Proc. of
COLING-88, vol. 2, pp. 642-644, 12th Int.
Conf. on Computational Linguistics, Budapest,
Hungary, 22-27 August 1988.
[Su 89] Su, K.-Y., J.-N. Wang, M.-H. Su and J.-S.
Chang, &amp;quot;A Sequential Truncation Parsing Algo-
rithm Based on the Score Function,&amp;quot; Proc. of
Int Workshop on Parsing Technologies (IWPT-
89), pp. 95-104, CMU, Pittsburgh, PA, U.S.A.,
28-31 August 1989.
[Su 90] Su, K.-Y. and J.-S. Chang, &amp;quot;Some Key
Issues in Designing MT Systems,&amp;quot; Machine
Translation, vol. 5, no. 4, pp. 265-300, 1990.
[Su 91a1 Su, K.-Y., and C.-H. Lee, &amp;quot;Robustness
and Discrimination Oriented Speech Recog-
nition Using Weighted HMM and Subspace
Projection Approach,&amp;quot; Proceedings of IEEE
ICASSP-91, vol. 1, pp. 541-544, Toronto, On-
tario, Canada. May 14-17, 1991.
[Su 91b] Su, K.-Y., J.-N. Wang, M.-H. Su, and J.-
S. Chang, &amp;quot;GLR Parsing with Scoring&amp;quot;. In M.
Tomita (ed.), Generalized LR Parsing, Chapter
7, pp. 93-112, Kluwer Academic Publishers,
1991.
[Wilks 83] Wilks, Y. A., &amp;quot;Preference Semantics,
Ill-Fonnedness, and Metaphor,&amp;quot; AJCL, vol. 9,
no. 3-4, pp. 178 - 187, July - Dec. 1983.
</reference>
<page confidence="0.998702">
184
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.710872">
<title confidence="0.964">GPSM: A GENERALIZED PROBABILISTIC SEMANTIC MODEL FOR AMBIGUITY RESOLUTION</title>
<author confidence="0.98602">tYih-Fen Luo Chang</author>
<author confidence="0.98602">tKeh-Yih Su</author>
<affiliation confidence="0.998352">tDepartment of Electrical Engineering National Tsing Hua University</affiliation>
<address confidence="0.998616">Hsinchu, TAIWAN 30043, R.O.C.</address>
<email confidence="0.967964">shin@ee.nthu.edu.tw,kysu@ee.nthu.edu.tw</email>
<affiliation confidence="0.880292">Behavior Design Corporation</affiliation>
<address confidence="0.9088545">No. 28, 2F, R&amp;D Road II, Science-Based Industrial Park Hsinchu, TAIWAN 30077, R.O.C.</address>
<abstract confidence="0.997671666666667">natural language ambiguity resolution is a central issue, and can be regarded a problem. In this paper, a Generalized Probabilistic Semantic Model (GPSM) is proposed for preference An effective tagging procedure is proposed for tagging semantic A score is debased on a function, integrates lexical, syntactic and semantic preferunder a uniform formulation. The sescore shows substantial improvement in structural disambiguation over a syntax-based approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Brown</author>
</authors>
<title>A Statistical Approach to Machine Translation,&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>79--85</pages>
<marker>[Brown 90]</marker>
<rawString>Brown, P. et al., &amp;quot;A Statistical Approach to Machine Translation,&amp;quot; Computational Linguistics, vol. 16, no. 2, pp. 79-85, June 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-C Chen</author>
<author>J-S Chang</author>
<author>J-N Wang</author>
<author>K-Y Su</author>
</authors>
<title>ArchTran: A Corpus-Based Statistics-Oriented English-Chinese Machine Translation System,&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of Machine Translation Summit III,</booktitle>
<pages>33--40</pages>
<location>Washington, D.C., USA,</location>
<marker>[Chen 91]</marker>
<rawString>Chen, S.-C., J.-S. Chang, J.-N. Wang and K.-Y. Su, &amp;quot;ArchTran: A Corpus-Based Statistics-Oriented English-Chinese Machine Translation System,&amp;quot; Proceedings of Machine Translation Summit III, pp. 33-40, Washington, D.C., USA, July 1-4, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T-H Chiang</author>
<author>Y-C Lin</author>
<author>K-Y Su</author>
</authors>
<title>Syntactic Ambiguity Resolution Using A Discrimination and Robustness Oriented Adaptive Learning Algorithm&amp;quot;, to appear in</title>
<date>1992</date>
<booktitle>Proceedings of COLING-92, 14th Int. Conference on Computational Linguistics,</booktitle>
<location>Nantes,</location>
<marker>[Chiang 92]</marker>
<rawString>Chiang, T.-H., Y.-C. Lin and K.-Y. Su, &amp;quot;Syntactic Ambiguity Resolution Using A Discrimination and Robustness Oriented Adaptive Learning Algorithm&amp;quot;, to appear in Proceedings of COLING-92, 14th Int. Conference on Computational Linguistics, Nantes, France, 20-28 July, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text,&amp;quot; ACL</title>
<date>1988</date>
<booktitle>Proc. 2nd Conf on Applied Natural Language Processing,</booktitle>
<pages>136--143</pages>
<location>Austin, Texas, USA,</location>
<marker>[Church 88]</marker>
<rawString>Church, K., &amp;quot;A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text,&amp;quot; ACL Proc. 2nd Conf on Applied Natural Language Processing, pp. 136-143, Austin, Texas, USA, 9-12 Feb. 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word Association Norms, Mutual Information, and Lexicography,&amp;quot;</title>
<date>1989</date>
<booktitle>Proc. 27th Annual Meeting of the ACL,</booktitle>
<pages>76--83</pages>
<institution>University of British Columbia,</institution>
<location>Vancouver, British Columbia, Canada,</location>
<marker>[Church 89]</marker>
<rawString>Church, K. and P. Hanks, &amp;quot;Word Association Norms, Mutual Information, and Lexicography,&amp;quot; Proc. 27th Annual Meeting of the ACL, pp. 76-83, University of British Columbia, Vancouver, British Columbia, Canada, 26-29 June 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J</author>
</authors>
<title>Grammatical Category Disambiguation by Statistical Optimization,&amp;quot;</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<pages>31--39</pages>
<location>Prentice-Hall, London,</location>
<marker>[DeRose 88]</marker>
<rawString>DeRose, Steven. J., &amp;quot;Grammatical Category Disambiguation by Statistical Optimization,&amp;quot; Computational Linguistics, vol. 14, no. 1, pp. 31-39, 1988. [Devijver 821 Devijver, P.A., and J. Kittler, Pattern Recognition: A Statistical Approach, Prentice-Hall, London, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Fujisalci</author>
<author>F Jelinek</author>
<author>J Cocke</author>
<author>E Black</author>
<author>T Nishino</author>
</authors>
<title>A Probabilistic Parsing Method for Sentence Disambiguation,&amp;quot;</title>
<date>1989</date>
<booktitle>Proc. of Int. Workshop on Parsing Technologies (IWPT89),</booktitle>
<pages>85--94</pages>
<location>CMU, Pittsburgh, PA, U.S.A.,</location>
<marker>[Fujisaki 89]</marker>
<rawString>Fujisalci, T., F. Jelinek, J. Cocke, E. Black and T. Nishino, &amp;quot;A Probabilistic Parsing Method for Sentence Disambiguation,&amp;quot; Proc. of Int. Workshop on Parsing Technologies (IWPT89), pp. 85-94, CMU, Pittsburgh, PA, U.S.A., 28-31 August 1989.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>The Computational Analysis of English: A Corpus-Based Approach,</booktitle>
<editor>Garside, Roger, Geoffrey Leech and Geoffrey Sampson (eds.),</editor>
<publisher>Longman Inc.,</publisher>
<location>New York,</location>
<marker>[Garside 87]</marker>
<rawString>Garside, Roger, Geoffrey Leech and Geoffrey Sampson (eds.), The Computational Analysis of English: A Corpus-Based Approach, Longman Inc., New York, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-L Liu</author>
</authors>
<title>On the Resolution of English PP Attachment Problem with a Probabilistic Semantic Model, Master Thesis,</title>
<date>1989</date>
<institution>National Tsing Hua University,</institution>
<location>Hsinchu, TAIWAN, R.O.C.,</location>
<marker>[Liu 89]</marker>
<rawString>Liu, C.-L., On the Resolution of English PP Attachment Problem with a Probabilistic Semantic Model, Master Thesis, National Tsing Hua University, Hsinchu, TAIWAN, R.O.C., 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-L Liu</author>
<author>J-S Chang</author>
<author>K-Y Su</author>
</authors>
<title>The Semantic Score Approach to the Disambiguation of PP Attachment Problem,&amp;quot;</title>
<date>1990</date>
<booktitle>Proc. of ROCLING-III,</booktitle>
<pages>253--270</pages>
<location>Taipei, R.O.C.,</location>
<marker>[Liu 90]</marker>
<rawString>Liu, C.-L, J.-S. Chang and K.-Y. Su, &amp;quot;The Semantic Score Approach to the Disambiguation of PP Attachment Problem,&amp;quot; Proc. of ROCLING-III, pp. 253-270, Taipei, R.O.C., September 1990.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Peter Sells</author>
</authors>
<title>Lectures On Contemporary Syntactic Theories: An Introduclion to Government-Binding Theory, Generalized Phrase Structure Grammar, and LexicalFunctional Grammar, CSLI Lecture Notes Number 3, Center for the Study of Language and Information,</title>
<date>1985</date>
<journal>Su</journal>
<booktitle>Proc. of COLING-88,</booktitle>
<volume>881</volume>
<pages>642--644</pages>
<institution>Leland Stanford Junior University.,</institution>
<location>Budapest,</location>
<marker>[Sells 85]</marker>
<rawString>Sells, Peter, Lectures On Contemporary Syntactic Theories: An Introduclion to Government-Binding Theory, Generalized Phrase Structure Grammar, and LexicalFunctional Grammar, CSLI Lecture Notes Number 3, Center for the Study of Language and Information, Leland Stanford Junior University., 1985. [Su 881 Su, K.-Y. and J.-S. Chang, &amp;quot;Semantic and Syntactic Aspects of Score Function,&amp;quot; Proc. of COLING-88, vol. 2, pp. 642-644, 12th Int. Conf. on Computational Linguistics, Budapest, Hungary, 22-27 August 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-Y Su</author>
<author>J-N Wang</author>
<author>M-H Su</author>
<author>J-S Chang</author>
</authors>
<title>A Sequential Truncation Parsing Algorithm Based on the Score Function,&amp;quot;</title>
<date>1989</date>
<booktitle>Proc. of Int Workshop on Parsing Technologies (IWPT89),</booktitle>
<pages>95--104</pages>
<location>CMU, Pittsburgh, PA, U.S.A.,</location>
<marker>[Su 89]</marker>
<rawString>Su, K.-Y., J.-N. Wang, M.-H. Su and J.-S. Chang, &amp;quot;A Sequential Truncation Parsing Algorithm Based on the Score Function,&amp;quot; Proc. of Int Workshop on Parsing Technologies (IWPT89), pp. 95-104, CMU, Pittsburgh, PA, U.S.A., 28-31 August 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-Y Su</author>
<author>J-S Chang</author>
</authors>
<title>Some Key Issues in Designing MT Systems,&amp;quot;</title>
<date>1990</date>
<journal>Machine Translation,</journal>
<booktitle>Proceedings of IEEE ICASSP-91,</booktitle>
<volume>5</volume>
<pages>265--300</pages>
<location>Toronto, Ontario, Canada.</location>
<marker>[Su 90]</marker>
<rawString>Su, K.-Y. and J.-S. Chang, &amp;quot;Some Key Issues in Designing MT Systems,&amp;quot; Machine Translation, vol. 5, no. 4, pp. 265-300, 1990. [Su 91a1 Su, K.-Y., and C.-H. Lee, &amp;quot;Robustness and Discrimination Oriented Speech Recognition Using Weighted HMM and Subspace Projection Approach,&amp;quot; Proceedings of IEEE ICASSP-91, vol. 1, pp. 541-544, Toronto, Ontario, Canada. May 14-17, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-Y Su</author>
<author>J-N Wang</author>
<author>M-H Su</author>
<author>J-S Chang</author>
</authors>
<title>GLR Parsing with Scoring&amp;quot;.</title>
<date>1991</date>
<booktitle>Generalized LR Parsing, Chapter 7,</booktitle>
<pages>93--112</pages>
<editor>In M. Tomita (ed.),</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<marker>[Su 91b]</marker>
<rawString>Su, K.-Y., J.-N. Wang, M.-H. Su, and J.-S. Chang, &amp;quot;GLR Parsing with Scoring&amp;quot;. In M. Tomita (ed.), Generalized LR Parsing, Chapter 7, pp. 93-112, Kluwer Academic Publishers, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
</authors>
<title>Preference Semantics, Ill-Fonnedness, and Metaphor,&amp;quot;</title>
<date>1983</date>
<journal>AJCL,</journal>
<volume>9</volume>
<pages>3--4</pages>
<marker>[Wilks 83]</marker>
<rawString>Wilks, Y. A., &amp;quot;Preference Semantics, Ill-Fonnedness, and Metaphor,&amp;quot; AJCL, vol. 9, no. 3-4, pp. 178 - 187, July - Dec. 1983.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>