<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007969">
<title confidence="0.9950245">
The Importance of Lexicalized Syntax Models
for Natural Language Generation Tasks
</title>
<author confidence="0.99834">
Hal Daum´e III, Kevin Knight, Irene Langkilde-Geary, Daniel Marcu and Kenji Yamada
</author>
<affiliation confidence="0.924355">
Information Sciences Institute
Computer Science Department
University of Southern California
4676 Admiralty Way, Suite 1001
</affiliation>
<address confidence="0.623106">
Marina del Rey, CA 90292
</address>
<email confidence="0.998147">
hdaume,knight,ilangkil,marcu,kyamada @isi.edu
</email>
<sectionHeader confidence="0.995628" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99959075">
The parsing community has long recog-
nized the importance of lexicalized mod-
els of syntax. By contrast, these models
do not appear to have had an impact on
the statistical NLG community. To prove
their importance in NLG, we show that a
lexicalized model of syntax improves the
performance of a statistical text compres-
sion system, and show results that suggest
it would also improve the performances of
an MT application and a pure natural lan-
guage generation system.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999892357142858">
We distinguish between three types of language
models:
-gram language models look only at word se-
quences to gauge the quality of a sentence.
Non-lexicalized syntax models consider only
syntactic structure down to the level of word
tags in assessing the grammaticality of a sen-
tence. A PCFG is an example of such a model.
Lexicalized syntax models take into account
both sentence syntax and lexical values when
determining the quality of a sentence.
The parsing community has long recognized
the importance of lexicalized models of syntax
for building robust natural language applications.
For example, Charniak (1997) showed that by us-
ing a lexicalized syntax model instead of a non-
lexicalized PCFG syntax model trained on Penn
Treebank data, one can increase the performance of
a syntactic parser from labeled recall and
precision to . More sophisticated lexicalized
models of syntax (Collins, 1997; Charniak, 2000)
have increased the performance of syntactic parsers
to labeled recall and precision. Lexicalized
models of syntax have been also proven useful in
speech recognition (Chelba and Jelinek, 1998) and
language modeling (Charniak, 2001; Roark, 2001).
By contrast, lexicalized models of syntax do not
appear to have had an impact on the statistical NLG
community. Langkilde and Knight (1998), for ex-
ample, use an -gram model to select between dif-
ferent lexical renderings of a meaning representa-
tion. Knight and Marcu (2000) use a combination
of bigram and context free probabilities to select be-
tween sentence compressions. To our knowledge,
the only NLG work that resonates with the work in
parsing, speech recognition, and language modeling
is that of Bangalore and Rambow (2000), who show
that a statistical generation system that uses a lexi-
calized hierarchical model of syntax outperforms a
system that uses a random model.
Given the small interest in exploiting lexicalized
models of syntax in NLG, we may conclude that
such models have no role to play in this area. In
this paper, we show that this is not the case. To
prove the importance of lexicalized models of syn-
tax in NLG, we focus on three distinct tasks, each
involving a generation component. First, we show
that a lexicalized model of syntax can improve the
performance of a statistics-based text compression
system. Second, we show that a lexicalized model
of syntax may improve the outputs of a Chinese-to-
English machine translation system. Finally, we an-
alyze the results of a pure natural language genera-
tion system.1
In each experiment, we assess the impact that a
lexicalized model of syntax may have on improving
the quality of existing systems using an off-the-shelf
component: the parser built by Charniak (2000).
Our use of Charniak’s parser provides for a loose
coupling of a lexicalized model of syntax with a gen-
eration system, which is far from ideal. Neverthe-
less, these experiments provide evidence that lex-
icalized models of syntax can improve the quality
of the outputs of statistics-based generators. Our
results motivate work aimed at building generation
systems that choose between possible renderings of
the same meaning using not only n-gram proba-
bilistic models, but lexicalized models of syntax,
such as those proposed by Collins (1997) and Char-
niak (2000).
</bodyText>
<sectionHeader confidence="0.935076" genericHeader="method">
2 Statistical Summarization
</sectionHeader>
<subsectionHeader confidence="0.976137">
2.1 Document Compression
</subsectionHeader>
<bodyText confidence="0.999948041666667">
To assess the impact that lexicalized models of syn-
tax may have on the task of summary generation, we
used a noisy-channel document compression system
(Daum´e III and Marcu, 2002), which generalizes the
sentence compression system developed by Knight
and Marcu (2000) to the document level.
In Daum´e and Marcu’s system, possible docu-
ment compressions are packed into a shared-forest
structure which contains explicit channel-model
probability scores. These channel probabilities are
based on discourse PCFG probabilities and syntac-
tic PCFG probabilities, as well as compression prob-
abilities. None of these probabilities are lexicalized.
We then use a generic forest ranker which com-
bines these channel probabilities with bigram-based
source model probabilities (Langkilde, 2000) to ex-
tract the top scoring compression. The only point
at which lexicalization enters the model is in the
bigram-based source model. This leads to the gen-
eration of many poor syntactic structures. For in-
stance, the model does not know the difference be-
tween transitive and intransitive verbs, and therefore
will often “compress off” the objects of transitive
verbs.
</bodyText>
<footnote confidence="0.593458">
1We are grateful to Eugene Charniak for suggesting these
experiments to us.
</footnote>
<bodyText confidence="0.9999784">
After the system was constructed, we evaluated its
performance on documents chosen from the Wall
Street Journal portion of the Penn Treebank, each
containing between and words2. We also eval-
uated it on documents selected from the Mitre cor-
pus (Hirschman et al., 1999), each document con-
taining between and words. We used two cor-
pora to see whether the system’s performance varied
with text genre. In the evaluations, the system out-
performed a baseline system presented by Knight &amp;
Marcu (2000), applied iteratively. However, it still
made many errors which would not have been made,
had it had a good grasp of English grammar. We per-
formed an exhaustive error analysis on the system to
see where it could be improved.
</bodyText>
<subsectionHeader confidence="0.977653">
2.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999656352941176">
After analyzing the errors the system made, we clas-
sified them into ten classes, each listed in Table 1
with an example of the error and an example of this
error fixed.
We then tabulated the frequency with which these
error occurred in the summaries produced by the
system. They are shown in Table 2.
Three of these error classes can be consid-
ered grammaticality errors: DET, MOD, COMP,
NOVERB and NUM. These three alone account for
errors out of a total of errors. It seemed
that the integration of a lexicalized model of syn-
tax into the source model would easily remove all
of these problems. Since the document compression
system was able to output an -best list of possible
compressions, we were able to rerank this list using
Charniak’s parser.
</bodyText>
<subsectionHeader confidence="0.998108">
2.3 Syntax-Based Reranking
</subsectionHeader>
<bodyText confidence="0.996374166666667">
To do this reranking, we modified Charniak’s (2000)
parser so that instead of outputting the optimal
parse tree for a given sentence, it outputs its non-
normalized maximum entropy score. We then ran
the modified parser on the 1000 best compressions
according to the bigram model, normalized the prob-
abilities by length and chose the single best com-
pression.
2Because there are an exponential number of summaries that
can be generated for any text, the decoder runs out of memory
for longer documents; therefore, we selected shorter subtexts
from the original documents.
</bodyText>
<figure confidence="0.903888757575758">
Grammatical Errors
DET - A noun or noun phrase is missing a determiner.
Erroneous “El Paso owns and operates refinery.”
Fixed “El Paso owns and operates a refinery.”
COMP - The complement of a verb or noun is missing, rendering the output ungrammatical.
Erroneous “Banco Exterior was run by politicians who lacked the skills or the will.”
Fixed “Banco Exterior was run by politicians who lacked the skills or the will to do .”
NUM - Often if the original document contains a percentage (for instance “5%”), the number will be dropped without the percent-
age sign.
Erroneous “The rate is %.”.
Fixed “The rate is 5%.”.
NOVERB - Sentence lacking a verb.
Erroneous “Stewart, the builder.”
Fixed “It is namedfor Stewart, the builder.”
Discourse/Coherence-specific Errors
ANTE - The antecedent of an anaphor has been dropped, resulting in incoherence.
Erroneous “Terms are subject to change, the company said.”
Fixed “Terms are subject to change, Banko Exterior said.”
CUE+ - Uninterpretable cue-word. For instance, if and form a discourse constituent and is contrasting and
begins with “But”, but is dropped, so should be “But.”
Erroneous “But the proposed transaction calls for an exchange of the debt ”
Fixed “The proposed transaction calls for an exchange of the debt ”
CUE- - A cue word or phrase is missing, rendering the output incoherent.
Erroneous “The President of the United States urged the armed forces to advance. His commanders did not have
the initiative.”
Fixed “President of the United States urged the armed forces to advance. When he did, his commanders did
not have the initiative.”
Summarization-specific Errors
MOD - A nominal modifier which should not have been dropped has been and significant meaning is lost.
Erroneous “Tons will fill damp barns across the land.”
Fixed “Tons of vegetables will fill damp barns across the land.”
MISS - The compression misses important information.
EXTRA - The compression contains unimportant information.
</figure>
<tableCaption confidence="0.980964">
Table 1: Types of errors in the texts generated by the model.
</tableCaption>
<bodyText confidence="0.999916142857143">
This is far from an ideal language model. For in-
stance, there is no guarantee that the structure the
parser will derive for the sentence will be the same
structure the compression model generated. Further-
more, since the parser assumes only one input sen-
tence, the scores produced by the best parse for two
different sentences may not be comparable.
</bodyText>
<subsectionHeader confidence="0.863793">
2.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.998663">
After reranking, we performed the same error anal-
ysis as before. The results for the new error analysis
are summarized in Table 3.
We can see from the delta row in Table 3 (negative
numbers are good), that we removed most grammat-
icality errors. We saw modest improvement with re-
spect to the dropping of important modifiers; this is
to be expected, though, since the syntax model has
no idea of “importance.” The same argument ex-
plains the minimal change in the missing antecedent
problems. We removed all instances of extra infor-
mation but added seven additional counts of missing
information.
Any summarization system must balance length
of summary against informational and grammati-
cal quality. In order to have more documents of
higher grammaticality, more words are often nec-
</bodyText>
<table confidence="0.999882041666667">
DET MOD Grammaticality NUM NOVERB ANTE Discourse CUE- MISS Summarization
COMP CUE+ EXTRA
wsj 0607
wsj 0616
wsj 0632
wsj 0654
wsj 0655
wsj 0667
wsj 0689
wsj 1126
wsj 1146
wsj 1189
wsj 1307
wsj 1331
wsj 1346
wsj 1376
wsj 1380
wsj 2386
rm5-10
rm5-22
rm5-27
rm5-6
rm5-9
Count
</table>
<tableCaption confidence="0.974511">
Table 2: Tabulation of the errors in the texts generated by the model.
</tableCaption>
<table confidence="0.99995332">
DET MOD Grammaticality NUM NOVERB ANTE Discourse CUE- MISS Summarization
COMP CUE+ EXTRA
wsj 0607
wsj 0616
wsj 0632
wsj 0654
wsj 0655
wsj 0667
wsj 0689
wsj 1126
wsj 1146
wsj 1189
wsj 1307
wsj 1331
wsj 1346
wsj 1376
wsj 1380
wsj 2386
rm5-10
rm5-22
rm5-27
rm5-6
rm5-9
Count
Delta
</table>
<tableCaption confidence="0.999923">
Table 3: Tabulation of the errors in the texts generated by the model with syntax-based rescoring.
</tableCaption>
<bodyText confidence="0.999707916666667">
essary, which reduces the amount of information
which can be packed into a summary of comparable
length. Here, by removing most of the grammatical-
ity errors, we caused the system to drop some of the
important information.
To determine whether the changes in the system
are noticeable to a user, we carried out a subjec-
tive evaluation. We presented human judges with
the outputs generated by the original text compres-
sion system, the results after rescoring, and human-
generated compressions. These judges were asked
to rank outputs on a scale from to ( being the
</bodyText>
<table confidence="0.9992536">
WSJ Texts Mitre Texts
Cmp Grm Coh Qual Cmp Grm Coh Qual
Old 0.47 3.11 2.98 2.55 0.47 3.57 2.90 2.80
Rescored 0.42 3.41 3.11 2.64 0.30 3.00 3.05 2.23
Hand 0.59 4.38 4.33 3.97 0.46 4.70 4.45 4.10
</table>
<tableCaption confidence="0.99942">
Table 4: Evaluation Results
</tableCaption>
<bodyText confidence="0.8860346">
best) on metrics of compression rate (Cmp), Gram-
maticality (Grm), Coherence (Coh) and Compres-
sion Quality (Qual). The results of this evaluation
are summarized in Table 4.
In the Wall Street Journal data, there was a mod-
erate improvement in grammaticality, coherence and
quality, as error analysis suggested. In the Mitre
data, grammaticality and quality went down signif-
icantly, while coherence remained steady. This can
be attributed to two factors. First, there were few
errors in the Mitre data to start with and thus less
room for improvement; Second, the Mitre data is out
of domain for both the document compression sys-
tem and for the parser, which leads to less reliable
statistics.
</bodyText>
<sectionHeader confidence="0.996998" genericHeader="method">
3 Machine Translation
</sectionHeader>
<bodyText confidence="0.99751431147541">
For our machine translation experiments, we use the
statistical MT system of Yamada and Knight (2001).
This system produces English translations of foreign
language sentences by exploiting three components:
A Translation model (TM). For any given pair
English parse tree , foreign language string
, this model returns a probability .
A Search algorithm. Given a foreign language
sentence , this algorithm searches for the En-
glish tree e that maximizes
.
Yamada and Knight (2001; 2002) describe the
TM and the search algorithm, respectively. The
search algorithm takes a foreign language sentence
and produces a vast number of candidate English
trees, packed into a forest structure, as in sum-
marization (see Section 2), then searches for the
highest-scoring tree. The current algorithm uses a
trigram LM, ignoring the internal structure of the
candidate trees. Therefore, the system does not nec-
essarily produce syntactically correct translations.
To see the effect of a lexicalized syntax language
model, we performed what automatic speech recog-
nition (ASR) researchers call “a cheating experi-
ment”. For a given acoustic signal, ASR researchers
know both the correct target transcription, A, (which
was done by hand) and the current automatic system
transcription, B. The probabilistic score for B will be
greater than that for A. However, a new knowledge
source may provide additional scores that cause A to
be reranked higher. This is cheating for two reasons:
(1) it does not include a search algorithm that inte-
grates the new knowledge source, and (2) there may
be an incorrect string C that scores higher than both
A and B under reranking.
This kind of experiment is not regularly done in
machine translation because there is no single cor-
rect translation A. Using a human translation as a
target A does not work, because human translations
are often non-literal and current statistical models do
not recognize them as good translations. To rem-
edy this, we manually created a set of target trans-
lations, which we called “hope” translations. These
are good translations that we believe to be within
reach of the system: we can reasonably hope that
the system would prefer them.
In our experiment, we score both hope sentences,
A, and current system translations, B, over a num-
ber of examples, using combinations of these knowl-
edge sources:
T: translation model
R: word-trigram language model
C: score from Charniak’s parser
Table 5 shows the results. A sentence marked
“dec1” is a decoder output (Sentence B) and “hope”
is a hope sentence (Sentence A); lower scores are
better. The last row shows the average difference of
the score (a positive difference means that the sys-
tem prefers “hope” sentences over current system
outputs). Just above the last row is the number of
sentences which ranked better.3
</bodyText>
<footnote confidence="0.997470666666667">
3The score from Charniak’s parser (C) is a
un-normalized prob , thus it may yield negative
value. The TM scores are calculated from parse trees, not from
</footnote>
<table confidence="0.9549932">
A Language model (LM). For any English tree
, this model returns a probability .
T R C T+R T+2R T+C T+R+C T+2C T+R+2C
-1.048 -0.776 0.956 -1.825 -2.601 -0.092 -0.868 0.864 0.088
ave. diff
</table>
<tableCaption confidence="0.868099">
Table 5: Results of the experiment on the MT system
</tableCaption>
<table confidence="0.992994166666667">
36.36 39.63 17.44 75.99 115.62 53.80 93.43 71.24 110.87 45.47 52.62 16.53 98.09 150.72 62.00 114.62 78.53 131.15 50.84 74.34 25.62 125.17 199.51 76.45 150.79 102.07 176.41 16.99 43.38 36.31 60.37 103.75 53.30 96.68 89.61 132.99 27.32 57.36 25.96 84.68 142.04 53.29 110.65 79.25 136.61 23.65 49.54 28.26 73.19 122.73 51.91 101.45 80.17 129.71 39.80 42.88 16.20 82.69 125.57 56.01 98.89 72.21 115.09 45.15 30.03 7.01 75.18 105.21 52.16 82.19 59.17 89.21 17.69 32.87 34.18 50.56 83.43 51.87 84.74 86.05 118.92 51.95 53.75 38.74 105.70 159.45 90.69 144.44 129.43 183.18 21.93 18.81 2.01 40.74 59.54 23.94 42.74 25.95 44.75 40.96 32.37 -3.53 73.33 105.69 37.44 69.80 33.91 66.27 39.88 39.22 16.68 79.10 118.32 56.55 95.77 73.23 112.45 13.93 23.39 12.34 37.32 60.71 26.27 49.66 38.61 61.99 31.68 32.81 27.96 64.49 97.31 59.64 92.45 87.59 120.41 5.52 14.57 39.17 20.09 34.66 44.69 59.26 83.86 98.43 22.03 17.21 -3.10 39.24 56.44 18.93 36.14 15.83 33.04 18.67 25.89 10.68 44.56 70.46 29.35 55.24 40.03 65.92 24.15 32.48 13.53 56.63 89.11 37.68 70.16 51.21 83.69 42.07 40.63 15.04 82.69 123.32 57.11 97.73 72.15 112.78 10.10 17.77 23.17 27.87 45.63 33.27 51.03 56.44 74.20 18 19 6 20 20 12 14 9 9
66.74 54.17 -5.14 120.91 175.08 61.60 115.77 56.46 110.63 64.81 56.69 0.72 121.50 178.20 65.52 122.22 66.24 122.93 81.84 83.53 15.01 165.37 248.90 96.85 180.38 111.86 195.39 27.34 45.43 18.27 72.77 118.20 45.62 91.05 63.89 109.32 47.61 62.06 17.79 109.67 171.73 65.40 127.46 83.19 145.25 39.73 47.08 13.31 86.81 133.88 53.03 100.11 66.34 113.42 44.26 73.31 39.15 117.56 190.87 83.41 156.71 122.55 195.86 39.78 29.43 -10.12 69.20 98.63 29.66 59.09 19.54 48.97 26.52 34.07 11.30 60.58 94.65 37.82 71.89 49.12 83.19 52.35 70.89 27.98 123.24 194.13 80.33 151.22 108.31 179.19 24.15 18.81 2.01 42.96 61.76 26.16 44.96 28.16 46.97 35.73 52.06 12.32 87.79 139.84 48.05 100.10 60.37 112.42 57.78 45.56 -4.22 103.33 148.89 53.56 99.11 49.34 94.89 16.78 23.39 12.34 40.17 63.55 29.12 52.50 41.45 64.84 47.46 54.21 8.63 101.67 155.88 56.09 110.30 64.72 118.93 7.90 14.57 39.17 22.47 37.04 47.07 61.64 86.24 100.81 21.26 19.97 4.00 41.23 61.20 25.26 45.23 29.27 49.24 22.08 25.90 -0.59 47.98 73.88 21.49 47.39 20.90 46.80 28.77 35.91 -4.54 64.68 100.59 24.23 60.14 19.70 55.61 52.66 49.59 14.71 102.24 151.83 67.37 116.95 82.08 131.66 18.72 21.66 7.40 40.39 62.05 26.12 47.78 33.52 55.18 3 5 18 1 1 9 7 12 12
great attention his first visit to china he briefed reporters declaring the major contents industrial production and marketing join basic level restored to normal state renminbi exchange rate stability this reputation order form is really “ agricultural ” the rapid development talks have topic hot spot reminding one person alone can not treat bad now like this ? stratify bimonthly the masses undercompensation conditions for accept the us side to this aspect this is extremely absurd rights and obligations are associated with each other mass various channels to reflect the views hong kong is our home he said china evermore taste hujintao said this is not possible this globalization of production many successes possible ? clinton meeting was held this idea reiterative he explained
his first visit is highly important to the chinese side he declared the main contents to the press agency the basic link between supply and marketing in industry resumed normal status the renminbi exchange rate continued to maintain stability third, “ agriculture to order ” has developed rapidly talks will have many hot topics to remind chen that one-man rule is unacceptable now it is not good ? the masses are stratified the us side did not accept the dprk side ’s proposed compensation terms this is extremely absurd but rights and obligations are mutually linked there are many such channels to reflect the views of the masses hong kong is our home he said he often eats chinese food hujintao said “ this is not possible this is the globalization of production how much success is possible ? holding this meeting was clinton ’s decision he has repeatedly explained
dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1 dec1
hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope hope
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 T
(H37 :ADJUNCT &amp;quot;earlier&amp;quot;
:LOGICAL-SUBJECT (H5 / &amp;quot;company&amp;quot;)
/ &amp;quot;announce&amp;quot;
:ADJUNCT (H34 :ADJUNCT &amp;quot;its&amp;quot;
/ &amp;quot;plan&amp;quot;))
</table>
<figureCaption confidence="0.9256755">
Figure 1: An underspecified input for the sentence,
”Earlier the company announced its plans.”
</figureCaption>
<bodyText confidence="0.999993">
As expected, our current system (T+R) almost
never ranks the hope sentence higher than the system
sentence. If we replace the trigram model with Char-
niak’s parser (T+C), the hope sentence is ranked
higher than the originally preferred sentences in 9
cases. These results are slightly better than rerank-
ing with the parser (T+R+C). Best results are ob-
tained by assigning a higher weight to the parser
score relative to the translation model (T+2C): here,
the hope sentence comes out on top in 12 cases.
</bodyText>
<sectionHeader confidence="0.98168" genericHeader="method">
4 Natural Language Generation
</sectionHeader>
<bodyText confidence="0.999931431818182">
From the sentences in section 23 of the Penn
Treebank, inputs to the HALogen generator sys-
tem were automatically derived and then re-
generated(Langkilde-Geary, 2002). The inputs
derived were feature-value dependency structures,
where the features represent syntactic relationships
between values, and the values were either words in
root form or a nested feature-value structure. The
inputs were underspecified with respect to proper-
ties such as part-of-speech category, tense, voice,
and number, as well as constituent order and some
closed-class words like auxiliary verbs and deter-
miners. Underspecification tests the ability of a lan-
guage model to pick the best solution from among a
set of choices.
HALogen overgenerates possible expressions for
an input, in part because of enumerating possible
choices for underspecified details. It then ranks po-
tential outputs using an -gram model. Both bigram
and trigram models were available, but because the
trigram model takes two orders of magnitude more
time to use (roughly 40 minutes per sentence, ver-
sus 1 minute per sentence for the bigram model), the
sentences were generated using the bigram model.
sentences. For “dec1” sentences, we use the parse tree returned
from the decoder to calculate it. For “hope” sentences, we use
a parse tree generated from Collins parser (1997) to calculate
it. Thus, there may be different T scores for the same sentence.
One hundred sentences were randomly chosen from
among the successfully generated outputs. Each was
paired with its original Treebank sentence, and then
trigram and Charniak-parser scores were calculated
for all the sentences. About 3% of the sentence pairs
were exact matches. Sentences within pairs had very
similar lengths in all cases. The average sentence
length was 24 tokens. The original Treebank sen-
tence serves as a gold standard for the generator.
Trigram scores for original Treebank sentences
scored better than the output of the generator sys-
tem 71% of the time. In comparison, Charniak-
parse scores preferred the original Treebank sen-
tences 83% of the time. This indicates that the gen-
erator system would benefit even more from a statis-
tical model of syntax than from trigrams.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999976714285714">
In statistical summarization, we have shown that
having a lexicalized syntax model reduces the fre-
quency of grammatical errors through both a care-
ful error analysis and a human evaluation. We
furthermore show that a lexicalized syntax model
might assist in the selection of good translations in a
syntax-based machine translation system. Finally,
we present results that indicate the importance of
lexicalized models of syntax in the HALogen nat-
ural language generation system (Langkilde-Geary,
2002).
It seems from these results that the integration
of such a language model in these tasks and in
statistical natural language generation systems will
prove to be fruitful. Most importantly, all three
of these systems use the same forest ranking algo-
rithm/component. Thus, if this one component were
extended to use a lexicalized model of syntax in
place of the current -gram scoring method, the per-
formance of all three system would undoubtedly im-
prove significantly.
</bodyText>
<sectionHeader confidence="0.997037" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999443333333333">
This work was partially supported by DARPA-ITO
grant N66001-00-1-9814 and a USC Dean Fellow-
ship to Hal Daume III.
</bodyText>
<sectionHeader confidence="0.989448" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999099154929577">
S. Bangalore and O. Rambow. 2000. Exploiting a proba-
bilistic hierarchical model for generation. In Proceed-
ings ofthe International Conference on Computational
Linguistics (COLING 2000), Hong Kong, China.
Eugene Charniak. 1997. Statistical parsing with a
context-free grammar and word statistics. In Proceed-
ings of the Fourteenth National Conference on Arti-
ficial Intelligence (AAAI’97), pages 598–603, Provi-
dence, Rhode Island, July 27–31.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the First Annual Meeting
of the North American Chapter of the Association for
Computational Linguistics NAACL–2000, pages 132–
139, Seattle, Washington, April 29 – May 3.
Eugene Charniak. 2001. Immediate-head parsing for
language models. In Proceedings of the 39th Annual
Meeting of the Association for Computational Linguis-
tics.
Ciprian Chelba and Frederick Jelinek. 1998. Exploiting
syntactic structure for language modeling. In Chris-
tian Boitet and Pete Whitelock, editors, Proceedings
of the Thirty-Sixth Annual Meeting of the Associa-
tion for Computational Linguistics and Seventeenth
International Conference on Computational Linguis-
tics, pages 225–231, San Francisco, California. Mor-
gan Kaufmann Publishers.
Michael Collins. 1997. Three generative, lexicalized
models for statistical parsing. In Proceedings of the
35th Annual Meeting of the Association for Compu-
tational Linguistics (ACL–97), pages 16–23, Madrid,
Spain, July 7-12.
Hal Daum´e III and Daniel Marcu. 2002. A noisy-channel
model for document compression. In Proceedings of
the Conference of the Association of Computational
Linguistics (ACL 2002).
L. Hirschman, M. Light, E. Breck, and J. Burger. 1999.
Deep read: A reading comprehension system. In Pro-
ceedings ofthe 37th Annual Meeting ofthe Association
for Computational Linguistics.
Kevin Knight and Daniel Marcu. 2000. Statistics-based
summarization — step one: Sentence compression.
In The 17th National Conference on Artificial Intelli-
gence (AAAI–2000), pages 703–710, Austin, TX, July
30th – August 3rd.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In
Proceedings of the 36th Annual Meeting of the Asso-
ciation for Computational Linguistics and of the 17th
International Conference on Computational Linguis-
tics (COLING/ACL’98), Montreal, Canada, August.
Irene Langkilde-Geary. 2002. An empirical verifica-
tion of coverage and correctness for a general-purpose
sentence generator. In Proceedings of the 2nd Inter-
national Conference on Natural Language Generation
(INLG 2002)., Arden House, NJ, July.
Irene Langkilde. 2000. Forest-based statistical sentence
generation. In Proceedings of the 1st Annual Meeting
of the North American Chapter of the Association for
Computational Linguistics, Seattle, Washington, April
30–May 3.
Brian Roark. 2001. Probabilistic top-down parsing and
language modelling. In Computational Linguistics
27(2), pages 249–276.
K. Yamada and K. Knight. 2001. A syntax-based statis-
tical translation model. In Proceedings of the Confer-
ence of the Association of Computational Linguistics
(ACL 2001).
K. Yamada and K. Knight. 2002. A decoder for syntax-
based statistical MT. In Proceedings of the Confer-
ence of the Association of Computational Linguistics
(ACL 2002).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.510821">
<title confidence="0.999472">The Importance of Lexicalized Syntax for Natural Language Generation Tasks</title>
<author confidence="0.983772">Hal Daum´e Kevin Knight</author>
<author confidence="0.983772">Irene Langkilde-Geary</author>
<author confidence="0.983772">Daniel Marcu</author>
<author confidence="0.983772">Kenji</author>
<affiliation confidence="0.998264666666667">Information Sciences Computer Science University of Southern</affiliation>
<address confidence="0.996457">4676 Admiralty Way, Suite</address>
<author confidence="0.542849">Marina del Rey</author>
<author confidence="0.542849">CA</author>
<email confidence="0.987079">hdaume,knight,ilangkil,marcu,kyamada@isi.edu</email>
<abstract confidence="0.998476384615385">The parsing community has long recognized the importance of lexicalized models of syntax. By contrast, these models do not appear to have had an impact on the statistical NLG community. To prove their importance in NLG, we show that a lexicalized model of syntax improves the performance of a statistical text compression system, and show results that suggest it would also improve the performances of an MT application and a pure natural language generation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<booktitle>In Proceedings ofthe International Conference on Computational Linguistics (COLING</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="2543" citStr="Bangalore and Rambow (2000)" startWordPosition="390" endWordPosition="393">eech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that a statistical generation system that uses a lexicalized hierarchical model of syntax outperforms a system that uses a random model. Given the small interest in exploiting lexicalized models of syntax in NLG, we may conclude that such models have no role to play in this area. In this paper, we show that this is not the case. To prove the importance of lexicalized models of syntax in NLG, we focus on three distinct tasks, each involving a generation component. First, we show that a lexicalized model of syntax can improve the performance of a statistics-based text compression syst</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>S. Bangalore and O. Rambow. 2000. Exploiting a probabilistic hierarchical model for generation. In Proceedings ofthe International Conference on Computational Linguistics (COLING 2000), Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical parsing with a context-free grammar and word statistics.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI’97),</booktitle>
<pages>598--603</pages>
<location>Providence, Rhode Island,</location>
<contexts>
<context position="1468" citStr="Charniak (1997)" startWordPosition="222" endWordPosition="223"> distinguish between three types of language models: -gram language models look only at word sequences to gauge the quality of a sentence. Non-lexicalized syntax models consider only syntactic structure down to the level of word tags in assessing the grammaticality of a sentence. A PCFG is an example of such a model. Lexicalized syntax models take into account both sentence syntax and lexical values when determining the quality of a sentence. The parsing community has long recognized the importance of lexicalized models of syntax for building robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear</context>
</contexts>
<marker>Charniak, 1997</marker>
<rawString>Eugene Charniak. 1997. Statistical parsing with a context-free grammar and word statistics. In Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI’97), pages 598–603, Providence, Rhode Island, July 27–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics NAACL–2000,</booktitle>
<volume>29</volume>
<pages>132--139</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="1767" citStr="Charniak, 2000" startWordPosition="270" endWordPosition="271">le of such a model. Lexicalized syntax models take into account both sentence syntax and lexical values when determining the quality of a sentence. The parsing community has long recognized the importance of lexicalized models of syntax for building robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sent</context>
<context position="3551" citStr="Charniak (2000)" startWordPosition="561" endWordPosition="562">ntax in NLG, we focus on three distinct tasks, each involving a generation component. First, we show that a lexicalized model of syntax can improve the performance of a statistics-based text compression system. Second, we show that a lexicalized model of syntax may improve the outputs of a Chinese-toEnglish machine translation system. Finally, we analyze the results of a pure natural language generation system.1 In each experiment, we assess the impact that a lexicalized model of syntax may have on improving the quality of existing systems using an off-the-shelf component: the parser built by Charniak (2000). Our use of Charniak’s parser provides for a loose coupling of a lexicalized model of syntax with a generation system, which is far from ideal. Nevertheless, these experiments provide evidence that lexicalized models of syntax can improve the quality of the outputs of statistics-based generators. Our results motivate work aimed at building generation systems that choose between possible renderings of the same meaning using not only n-gram probabilistic models, but lexicalized models of syntax, such as those proposed by Collins (1997) and Charniak (2000). 2 Statistical Summarization 2.1 Docume</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics NAACL–2000, pages 132– 139, Seattle, Washington, April 29 – May 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Immediate-head parsing for language models.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1997" citStr="Charniak, 2001" startWordPosition="303" endWordPosition="304">yntax for building robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that a statistical generation system that u</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>Eugene Charniak. 2001. Immediate-head parsing for language models. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
<author>Frederick Jelinek</author>
</authors>
<title>Exploiting syntactic structure for language modeling.</title>
<date>1998</date>
<booktitle>Proceedings of the Thirty-Sixth Annual Meeting of the Association for Computational Linguistics and Seventeenth International Conference on Computational Linguistics,</booktitle>
<pages>225--231</pages>
<editor>In Christian Boitet and Pete Whitelock, editors,</editor>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Francisco, California.</location>
<contexts>
<context position="1959" citStr="Chelba and Jelinek, 1998" startWordPosition="296" endWordPosition="299">ognized the importance of lexicalized models of syntax for building robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that </context>
</contexts>
<marker>Chelba, Jelinek, 1998</marker>
<rawString>Ciprian Chelba and Frederick Jelinek. 1998. Exploiting syntactic structure for language modeling. In Christian Boitet and Pete Whitelock, editors, Proceedings of the Thirty-Sixth Annual Meeting of the Association for Computational Linguistics and Seventeenth International Conference on Computational Linguistics, pages 225–231, San Francisco, California. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalized models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL–97),</booktitle>
<pages>16--23</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="1750" citStr="Collins, 1997" startWordPosition="268" endWordPosition="269">CFG is an example of such a model. Lexicalized syntax models take into account both sentence syntax and lexical values when determining the quality of a sentence. The parsing community has long recognized the importance of lexicalized models of syntax for building robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to se</context>
<context position="4091" citStr="Collins (1997)" startWordPosition="646" endWordPosition="647">tems using an off-the-shelf component: the parser built by Charniak (2000). Our use of Charniak’s parser provides for a loose coupling of a lexicalized model of syntax with a generation system, which is far from ideal. Nevertheless, these experiments provide evidence that lexicalized models of syntax can improve the quality of the outputs of statistics-based generators. Our results motivate work aimed at building generation systems that choose between possible renderings of the same meaning using not only n-gram probabilistic models, but lexicalized models of syntax, such as those proposed by Collins (1997) and Charniak (2000). 2 Statistical Summarization 2.1 Document Compression To assess the impact that lexicalized models of syntax may have on the task of summary generation, we used a noisy-channel document compression system (Daum´e III and Marcu, 2002), which generalizes the sentence compression system developed by Knight and Marcu (2000) to the document level. In Daum´e and Marcu’s system, possible document compressions are packed into a shared-forest structure which contains explicit channel-model probability scores. These channel probabilities are based on discourse PCFG probabilities and</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalized models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL–97), pages 16–23, Madrid, Spain, July 7-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A noisy-channel model for document compression.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics (ACL</booktitle>
<marker>Daum´e, Marcu, 2002</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2002. A noisy-channel model for document compression. In Proceedings of the Conference of the Association of Computational Linguistics (ACL 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschman</author>
<author>M Light</author>
<author>E Breck</author>
<author>J Burger</author>
</authors>
<title>Deep read: A reading comprehension system.</title>
<date>1999</date>
<booktitle>In Proceedings ofthe 37th Annual Meeting ofthe Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5656" citStr="Hirschman et al., 1999" startWordPosition="883" endWordPosition="886">the model is in the bigram-based source model. This leads to the generation of many poor syntactic structures. For instance, the model does not know the difference between transitive and intransitive verbs, and therefore will often “compress off” the objects of transitive verbs. 1We are grateful to Eugene Charniak for suggesting these experiments to us. After the system was constructed, we evaluated its performance on documents chosen from the Wall Street Journal portion of the Penn Treebank, each containing between and words2. We also evaluated it on documents selected from the Mitre corpus (Hirschman et al., 1999), each document containing between and words. We used two corpora to see whether the system’s performance varied with text genre. In the evaluations, the system outperformed a baseline system presented by Knight &amp; Marcu (2000), applied iteratively. However, it still made many errors which would not have been made, had it had a good grasp of English grammar. We performed an exhaustive error analysis on the system to see where it could be improved. 2.2 Error Analysis After analyzing the errors the system made, we classified them into ten classes, each listed in Table 1 with an example of the err</context>
</contexts>
<marker>Hirschman, Light, Breck, Burger, 1999</marker>
<rawString>L. Hirschman, M. Light, E. Breck, and J. Burger. 1999. Deep read: A reading comprehension system. In Proceedings ofthe 37th Annual Meeting ofthe Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistics-based summarization — step one: Sentence compression.</title>
<date>2000</date>
<booktitle>In The 17th National Conference on Artificial Intelligence (AAAI–2000),</booktitle>
<pages>703--710</pages>
<location>Austin, TX,</location>
<contexts>
<context position="2285" citStr="Knight and Marcu (2000)" startWordPosition="349" endWordPosition="352">recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that a statistical generation system that uses a lexicalized hierarchical model of syntax outperforms a system that uses a random model. Given the small interest in exploiting lexicalized models of syntax in NLG, we may conclude that such models have no role to play in this area. In this paper, we show that this is not the case. </context>
<context position="4433" citStr="Knight and Marcu (2000)" startWordPosition="696" endWordPosition="699">outputs of statistics-based generators. Our results motivate work aimed at building generation systems that choose between possible renderings of the same meaning using not only n-gram probabilistic models, but lexicalized models of syntax, such as those proposed by Collins (1997) and Charniak (2000). 2 Statistical Summarization 2.1 Document Compression To assess the impact that lexicalized models of syntax may have on the task of summary generation, we used a noisy-channel document compression system (Daum´e III and Marcu, 2002), which generalizes the sentence compression system developed by Knight and Marcu (2000) to the document level. In Daum´e and Marcu’s system, possible document compressions are packed into a shared-forest structure which contains explicit channel-model probability scores. These channel probabilities are based on discourse PCFG probabilities and syntactic PCFG probabilities, as well as compression probabilities. None of these probabilities are lexicalized. We then use a generic forest ranker which combines these channel probabilities with bigram-based source model probabilities (Langkilde, 2000) to extract the top scoring compression. The only point at which lexicalization enters </context>
<context position="5882" citStr="Knight &amp; Marcu (2000)" startWordPosition="921" endWordPosition="924">ten “compress off” the objects of transitive verbs. 1We are grateful to Eugene Charniak for suggesting these experiments to us. After the system was constructed, we evaluated its performance on documents chosen from the Wall Street Journal portion of the Penn Treebank, each containing between and words2. We also evaluated it on documents selected from the Mitre corpus (Hirschman et al., 1999), each document containing between and words. We used two corpora to see whether the system’s performance varied with text genre. In the evaluations, the system outperformed a baseline system presented by Knight &amp; Marcu (2000), applied iteratively. However, it still made many errors which would not have been made, had it had a good grasp of English grammar. We performed an exhaustive error analysis on the system to see where it could be improved. 2.2 Error Analysis After analyzing the errors the system made, we classified them into ten classes, each listed in Table 1 with an example of the error and an example of this error fixed. We then tabulated the frequency with which these error occurred in the summaries produced by the system. They are shown in Table 2. Three of these error classes can be considered grammati</context>
</contexts>
<marker>Knight, Marcu, 2000</marker>
<rawString>Kevin Knight and Daniel Marcu. 2000. Statistics-based summarization — step one: Sentence compression. In The 17th National Conference on Artificial Intelligence (AAAI–2000), pages 703–710, Austin, TX, July 30th – August 3rd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and of the 17th International Conference on Computational Linguistics (COLING/ACL’98),</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="2152" citStr="Langkilde and Knight (1998)" startWordPosition="326" endWordPosition="329">of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that a statistical generation system that uses a lexicalized hierarchical model of syntax outperforms a system that uses a random model. Given the small interest in exploiting lexicalized models of </context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and of the 17th International Conference on Computational Linguistics (COLING/ACL’98), Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd International Conference on Natural Language Generation (INLG 2002).,</booktitle>
<location>Arden House, NJ,</location>
<contexts>
<context position="21282" citStr="Langkilde-Geary, 2002" startWordPosition="3507" endWordPosition="3509"> higher than the system sentence. If we replace the trigram model with Charniak’s parser (T+C), the hope sentence is ranked higher than the originally preferred sentences in 9 cases. These results are slightly better than reranking with the parser (T+R+C). Best results are obtained by assigning a higher weight to the parser score relative to the translation model (T+2C): here, the hope sentence comes out on top in 12 cases. 4 Natural Language Generation From the sentences in section 23 of the Penn Treebank, inputs to the HALogen generator system were automatically derived and then regenerated(Langkilde-Geary, 2002). The inputs derived were feature-value dependency structures, where the features represent syntactic relationships between values, and the values were either words in root form or a nested feature-value structure. The inputs were underspecified with respect to properties such as part-of-speech category, tense, voice, and number, as well as constituent order and some closed-class words like auxiliary verbs and determiners. Underspecification tests the ability of a language model to pick the best solution from among a set of choices. HALogen overgenerates possible expressions for an input, in p</context>
<context position="23830" citStr="Langkilde-Geary, 2002" startWordPosition="3907" endWordPosition="3908">tes that the generator system would benefit even more from a statistical model of syntax than from trigrams. 5 Conclusion In statistical summarization, we have shown that having a lexicalized syntax model reduces the frequency of grammatical errors through both a careful error analysis and a human evaluation. We furthermore show that a lexicalized syntax model might assist in the selection of good translations in a syntax-based machine translation system. Finally, we present results that indicate the importance of lexicalized models of syntax in the HALogen natural language generation system (Langkilde-Geary, 2002). It seems from these results that the integration of such a language model in these tasks and in statistical natural language generation systems will prove to be fruitful. Most importantly, all three of these systems use the same forest ranking algorithm/component. Thus, if this one component were extended to use a lexicalized model of syntax in place of the current -gram scoring method, the performance of all three system would undoubtedly improve significantly. Acknowledgements This work was partially supported by DARPA-ITO grant N66001-00-1-9814 and a USC Dean Fellowship to Hal Daume III. </context>
</contexts>
<marker>Langkilde-Geary, 2002</marker>
<rawString>Irene Langkilde-Geary. 2002. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proceedings of the 2nd International Conference on Natural Language Generation (INLG 2002)., Arden House, NJ, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
</authors>
<title>Forest-based statistical sentence generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Annual Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<volume>30</volume>
<location>Seattle, Washington,</location>
<contexts>
<context position="4946" citStr="Langkilde, 2000" startWordPosition="769" endWordPosition="770">nd Marcu, 2002), which generalizes the sentence compression system developed by Knight and Marcu (2000) to the document level. In Daum´e and Marcu’s system, possible document compressions are packed into a shared-forest structure which contains explicit channel-model probability scores. These channel probabilities are based on discourse PCFG probabilities and syntactic PCFG probabilities, as well as compression probabilities. None of these probabilities are lexicalized. We then use a generic forest ranker which combines these channel probabilities with bigram-based source model probabilities (Langkilde, 2000) to extract the top scoring compression. The only point at which lexicalization enters the model is in the bigram-based source model. This leads to the generation of many poor syntactic structures. For instance, the model does not know the difference between transitive and intransitive verbs, and therefore will often “compress off” the objects of transitive verbs. 1We are grateful to Eugene Charniak for suggesting these experiments to us. After the system was constructed, we evaluated its performance on documents chosen from the Wall Street Journal portion of the Penn Treebank, each containing</context>
</contexts>
<marker>Langkilde, 2000</marker>
<rawString>Irene Langkilde. 2000. Forest-based statistical sentence generation. In Proceedings of the 1st Annual Meeting of the North American Chapter of the Association for Computational Linguistics, Seattle, Washington, April 30–May 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
</authors>
<title>Probabilistic top-down parsing and language modelling.</title>
<date>2001</date>
<journal>In Computational Linguistics</journal>
<volume>27</volume>
<issue>2</issue>
<pages>249--276</pages>
<contexts>
<context position="2011" citStr="Roark, 2001" startWordPosition="305" endWordPosition="306">ng robust natural language applications. For example, Charniak (1997) showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn Treebank data, one can increase the performance of a syntactic parser from labeled recall and precision to . More sophisticated lexicalized models of syntax (Collins, 1997; Charniak, 2000) have increased the performance of syntactic parsers to labeled recall and precision. Lexicalized models of syntax have been also proven useful in speech recognition (Chelba and Jelinek, 1998) and language modeling (Charniak, 2001; Roark, 2001). By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community. Langkilde and Knight (1998), for example, use an -gram model to select between different lexical renderings of a meaning representation. Knight and Marcu (2000) use a combination of bigram and context free probabilities to select between sentence compressions. To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of Bangalore and Rambow (2000), who show that a statistical generation system that uses a lexicali</context>
</contexts>
<marker>Roark, 2001</marker>
<rawString>Brian Roark. 2001. Probabilistic top-down parsing and language modelling. In Computational Linguistics 27(2), pages 249–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics (ACL</booktitle>
<contexts>
<context position="12955" citStr="Yamada and Knight (2001)" startWordPosition="2113" endWordPosition="2116"> Journal data, there was a moderate improvement in grammaticality, coherence and quality, as error analysis suggested. In the Mitre data, grammaticality and quality went down significantly, while coherence remained steady. This can be attributed to two factors. First, there were few errors in the Mitre data to start with and thus less room for improvement; Second, the Mitre data is out of domain for both the document compression system and for the parser, which leads to less reliable statistics. 3 Machine Translation For our machine translation experiments, we use the statistical MT system of Yamada and Knight (2001). This system produces English translations of foreign language sentences by exploiting three components: A Translation model (TM). For any given pair English parse tree , foreign language string , this model returns a probability . A Search algorithm. Given a foreign language sentence , this algorithm searches for the English tree e that maximizes . Yamada and Knight (2001; 2002) describe the TM and the search algorithm, respectively. The search algorithm takes a foreign language sentence and produces a vast number of candidate English trees, packed into a forest structure, as in summarizatio</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>K. Yamada and K. Knight. 2001. A syntax-based statistical translation model. In Proceedings of the Conference of the Association of Computational Linguistics (ACL 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A decoder for syntaxbased statistical MT.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics (ACL</booktitle>
<marker>Yamada, Knight, 2002</marker>
<rawString>K. Yamada and K. Knight. 2002. A decoder for syntaxbased statistical MT. In Proceedings of the Conference of the Association of Computational Linguistics (ACL 2002).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>