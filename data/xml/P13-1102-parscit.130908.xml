<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.571528">
The effect of non-tightness on Bayesian estimation of PCFGs
</title>
<author confidence="0.950032">
Shay B. Cohen
</author>
<affiliation confidence="0.996392">
Department of Computer Science
Columbia University
</affiliation>
<email confidence="0.994025">
scohen@cs.columbia.edu
</email>
<sectionHeader confidence="0.994691" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999740833333333">
Probabilistic context-free grammars have
the unusual property of not always defin-
ing tight distributions (i.e., the sum of the
“probabilities” of the trees the grammar
generates can be less than one). This paper
reviews how this non-tightness can arise
and discusses its impact on Bayesian es-
timation of PCFGs. We begin by present-
ing the notion of “almost everywhere tight
grammars” and show that linear CFGs fol-
low it. We then propose three different
ways of reinterpreting non-tight PCFGs to
make them tight, show that the Bayesian
estimators in Johnson et al. (2007) are
correct under one of them, and provide
MCMC samplers for the other two. We
conclude with a discussion of the impact
of tightness empirically.
</bodyText>
<sectionHeader confidence="0.998669" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996845904761905">
Probabilistic Context-Free Grammars (PCFGs)
play a special role in computational linguistics be-
cause they are perhaps the simplest probabilistic
models of hierarchical structures. Their simplicity
enables us to mathematically analyze their prop-
erties to a detail that would be difficult with lin-
guistically more accurate models. Such analysis
is useful because it is reasonable to expect more
complex models to exhibit similar properties as
well.
The problem of inferring PCFG rule probabil-
ities from training data consisting of yields or
strings alone is interesting from both cognitive and
engineering perspectives. Cognitively it is implau-
sible that children can perceive the parse trees of
the language they are learning, but it is more rea-
sonable to assume that they can obtain the terminal
strings or yield of these trees. Unsupervised meth-
ods for learning a grammar from terminal strings
alone is also interesting from an engineering per-
spective because such training data is cheap and
</bodyText>
<author confidence="0.66213">
Mark Johnson
</author>
<affiliation confidence="0.869976">
Department of Computing
Macquarie University
</affiliation>
<email confidence="0.900079">
mark.johnson@mq.edu.au
</email>
<bodyText confidence="0.999811558139535">
plentiful, while the manually parsed data required
by supervised methods are expensive to produce
and relatively rare.
Cohen and Smith (2012) show that inferring
PCFG rule probabilities from strings alone is com-
putationally intractable, so we should not expect
to find an efficient, general-purpose algorithm for
the unsupervised problem. Instead, approxima-
tion algorithms are standardly used. For exam-
ple, the Inside-Outside (IO) algorithm efficiently
implements the Expectation-Maximization (EM)
procedure for approximating a Maximum Likeli-
hood estimator (Lari and Young, 1990). Bayesian
estimators for PCFG rule probabilities have also
been attracting attention because they provide a
theoretically-principled way of incorporating prior
information. Kurihara and Sato (2006) proposed
a Variational Bayes estimator based on a mean-
field approximation, and Johnson et al. (2007) pro-
posed MCMC samplers for the posterior distribu-
tion over rule probabilities and the parse trees of
the training data strings.
PCFGs have the interesting property (which we
expect most linguistically more realistic models to
also possess) that the distributions they define are
not always properly normalized or “tight”. In a
non-tight PCFG the partition function (i.e., sum
of the “probabilities” of all the trees generated by
the PCFG) is less than one. (Booth and Thomp-
son, 1973, called such non-tight PCFGs “incon-
sistent”, but we follow Chi and Geman (1998)
in calling them “non-tight” to avoid confusion
with the consistency of statistical estimators). Chi
(1999) showed that renormalized non-tight PCFGs
(which he called “Gibbs CFGs”) define the same
class of distributions over trees as do tight PCFGs
with the same rules, and provided an algorithm for
mapping any PCFG to a tight PCFG with the same
rules that defines the same distribution over trees.
An obvious question is then: how does tightness
affect the inference of PCFGs? Chi and Geman
(1998) studied the question for Maximum Likeli-
hood (ML) estimation, and showed that ML es-
</bodyText>
<page confidence="0.905345">
1033
</page>
<note confidence="0.913677">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1033–1041,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999593631578947">
timates are always tight for both the supervised
case (where the input consists of parse trees) and
the unsupervised case (where the input consists of
yields or terminal strings). This means that ML
estimators can simply ignore issues of tightness,
and rest assured that the PCFGs they estimate are
in fact tight.
The situation is more subtle with Bayesian es-
timators. We show that for the special case of
linear PCFGs (which include HMMs) with non-
degenerate priors the posterior puts zero mass on
non-tight PCFGs, so tightness is not an issue with
Bayesian estimation of such grammars. However,
because all of the commonly used priors (such as
the Dirichlet or the logistic normal) assign non-
zero probability across the whole probability sim-
plex, in general the posterior may assign non-zero
probability to non-tight PCFGs. We discuss three
different possible approaches to this in this paper:
</bodyText>
<listItem confidence="0.988546181818182">
1. the only-tight approach, where we modify the
prior so it only assigns non-zero probability
to tight PCFGs,
2. the renormalization approach, where we
renormalize non-tight PCFGs so they define
a probability distribution over trees, and
3. the sink-element approach, where we reinter-
pret non-tight PCFGs as assigning non-zero
probability to a “sink element”, so both tight
and non-tight PCFGs are properly normal-
ized.
</listItem>
<bodyText confidence="0.999788133333333">
We show how to modify the Gibbs sampler de-
scribed by Johnson et al. (2007) so it produces
samples from the posterior distributions defined
by the only-tight and renormalization approaches.
Perhaps surprisingly, we show that Gibbs sampler
as defined by Johnson et al. actually produces
samples from the posterior distributions defined by
the sink-element approach.
We conclude by studying the effect of requir-
ing tightness on the estimation of some simple
PCFGs. Because the Bayesian posterior converges
around the (tight) ML estimate as the size of
the data grows, requiring tightness only seems to
make a difference with highly biased priors or with
very small training corpora.
</bodyText>
<sectionHeader confidence="0.763976" genericHeader="introduction">
2 PCFGs and tightness
</sectionHeader>
<bodyText confidence="0.9880923">
Let G = (T, N, 5, R) be a Context-Free Grammar
in Chomsky normal form with no useless produc-
tions, where T is a finite set of terminal symbols,
N is a finite set of nonterminal symbols (disjoint
from T), 5 E N is a distinguished nonterminal
called the start symbol, and R is a finite set of pro-
ductions of the form A -+ B C or A -+ w, where
A, B, C E N and w E T. In what follows we use
0 as a variable ranging over (N x N) U T.
A Probabilistic Context-Free Grammar (G, Θ)
is a pair consisting of a context-free grammar G
and a real-valued vector Θ of length |R |indexed
by productions, where θA-+β is the production
probability associated with the production A -+
0 E R. We require that θA-+β &gt; 0 and that for
all nonterminals A E N, EA-+βERA θA-+β = 1,
where RA is the subset of rules R expanding the
nonterminal A.
A PCFG (G, Θ) defines a measure Pe over
trees t as follows:
</bodyText>
<equation confidence="0.995878333333333">
H
Pe(t) =
rER
</equation>
<bodyText confidence="0.95693">
where fr(t) is the number of times the production
r = A -+ 0 E R is used in the derivation of t.
The partition function Z or measure of all pos-
sible trees is:
</bodyText>
<equation confidence="0.947106666666667">
�
Z(Θ) =
t&apos;ET
</equation>
<bodyText confidence="0.9993935">
where T is the set of all (finite) trees generated
by G. A PCFG is tight iff the partition function
Z(Θ) = 1. In this paper we use Θ1 to denote the
set of rule probability vectors Θ for which G is
non-tight. Nederhof and Satta (2008) survey sev-
eral algorithms for computing Z(Θ), and hence
for determining whether a PCFG is tight.1
Non-tightness can arise in very simple PCFGs,
such as the “Catalan” PCFG 5 -+ 5 5 |a. This
grammar produces binary trees where all internal
nodes are labeled as 5 and the yield of these trees
is a sequence of as. If the probability of the rule
5 -+ 5 5 is greater than 0.5 then this PCFG is
non-tight.
Perhaps the most straight-forward way to under-
stand this non-tightness is to view this grammar as
defining a branching process where an 5 can either
“reproduce” with probability θS-+S S or “die out”
</bodyText>
<footnote confidence="0.989451">
1We found out that finding whether a PCFG is tight by
directly inspecting the partition function value is less stable
than using the method in Wetherell (1980). For this reason,
we used Wetherell’s approach, which is based on finding the
principal eigenvalue of the matrix M.
</footnote>
<equation confidence="0.996892">
θfr(t)
r
H
rER
θfr(t&apos;)
r
</equation>
<page confidence="0.966288">
1034
</page>
<bodyText confidence="0.96791675">
with probability θS-+a. When θS-+S S &gt; θS-+a the
S nodes reproduce at a faster rate than they die
out, so the derivation has a non-zero probability of
endlessly rewriting (Atherya and Ney, 1972).
</bodyText>
<sectionHeader confidence="0.911897" genericHeader="method">
3 Bayesian inference for PCFGs
</sectionHeader>
<bodyText confidence="0.998285727272727">
The goal of Bayesian inference for PCFGs is to in-
fer a posterior distribution over the rule probabil-
ity vectors Θ given observed data D. This poste-
rior distribution is obtained by combining the like-
lihood P(D  |Θ) with a prior distribution P(Θ)
over Θ using Bayes Rule.
With this in hand, we can now define the likeli-
hood term. We consider two types of data D here.
In the supervised setting the data D consists of a
corpus of parse trees D = (t1, ... , tn) where each
tree ti is generated by the PCFG G, so
</bodyText>
<equation confidence="0.996643">
n
P(D  |Θ) = P(ti  |Θ)
i=1
</equation>
<bodyText confidence="0.99886375">
In the unsupervised setting the data D consists
of a corpus of strings D = (w1, ... , wn) where
each string wi is the yield of one or more trees
generated by G. In this setting
</bodyText>
<equation confidence="0.992665666666667">
n
P(Θ  |D) a P(D  |Θ) P(Θ) P(D  |Θ) = P(wi  |Θ), where:
i=1
</equation>
<bodyText confidence="0.9981525">
We now formally define the three approaches to E P(t  |Θ)
handling non-tightness mentioned earlier: P(w  |Θ) =
tET:yield(t)=w
the only-tight approach: we only permit priors
where P(01) = 0, i.e., we insist that the
prior assign zero mass to non-tight rule prob-
ability vectors, so Z = 1. This means we can
define:
</bodyText>
<equation confidence="0.994328">
P(t  |Θ) = µO(t)
</equation>
<bodyText confidence="0.991058666666667">
the renormalization approach: we renormalize
non-tight PCFGs by dividing by the partition
function:
</bodyText>
<equation confidence="0.9968945">
1
P(t  |Θ) = Z(Θ) µO(t) (1)
</equation>
<bodyText confidence="0.998587714285714">
the sink-element approach: we redefine our
probability distribution so its domain is a set
T&apos; = T U {1}, where T is the set of (finite)
trees generated by G and 1 E� T is a new
element that serves as a “sink state” to which
the “missing mass” 1 − Z(Θ) is assigned.
Then we define:2
</bodyText>
<equation confidence="0.9508545">
( µO (t) if t E T
t 1 − Z(Θ) if t = 1
</equation>
<bodyText confidence="0.9995488">
2This definition of a distribution over trees can be induced
by a tight PCFG with a special L symbol in its vocabulary.
Given G, the first step is to create a tight grammar G0 using
the renormalization approach. Then, a new start symbol is
added to G0, S0, and also rules S0 → S (where S is the
old start symbol in G0) and S0 → L. The first rule is given
probability Z(0) and the second rule is given probability 1−
Z(0). It can be then readily shown that the new tight PCFG
G0 induces a distribution over trees just like in Eq. 3, only
with additional S0 on top of all trees.
</bodyText>
<sectionHeader confidence="0.81607" genericHeader="method">
4 The special case of linear PCFGs
</sectionHeader>
<bodyText confidence="0.98014445">
One way to handle the issue of tightness is to iden-
tify a family of CFGs for which practically any pa-
rameter setting will yield a tight PCFG. This is the
focus of this section, in which we identify a sub-
set of CFGs, which are “almost everywhere” tight.
This family of CFGs includes many of the CFGs
used in NLP applications.
We cannot expect that a CFG will yield a tight
PCFG for any assignment to the rule probabilities
(i.e. that 01 = 0). Even in simple cases, such as
the grammar S -+ S|a, the assignment of proba-
bility 1 to S -+ S and 0 to the other rule renders
the S nonterminal useless, and places all of the
probability mass on infinite structures of the form
S - +S - +S - +....
However, we can weaken our requirement so
that the cases in which parameter assignment
yields a non-tight PCFG are rare, or have measure
zero. To put it more formally, we say that a prior
P(Θ) is “tight almost everywhere for G” if
</bodyText>
<equation confidence="0.992323">
�P(01) = OEΘ⊥ P(Θ) dΘ = 0.
</equation>
<bodyText confidence="0.99993175">
We now provide a sufficient condition (linear-
ity) for CFGs under which they are tight almost
everywhere with any continuous prior.
For a nonterminal A E N and β E (N U T)*,
we use A ==�,k β to denote that A can be re-written
using a sequence of rules from R to the sentential
form β in k derivation steps. We use A ==�,+ β to
denote that there exists a k &gt; 0 such that A ==�,k β.
</bodyText>
<equation confidence="0.435796333333333">
P(t  |Θ) =
1035
Definition 1 A context-free grammar G is linear if
there are no A ∈ N such that �pA = P(A ⇒|N |β|Θ).
A ⇒+ .. . A ... A.... 0=...A...
Definition 2 A nonterminal A ∈ N in a proba-
bilistic context-free grammar G with parameters
Θ is nonterminating if
PG(A ⇒+ ...A... |Θ) = 1.
Here P(A ⇒+ ... A... |Θ) is defined as:
� PG(A ⇒+ β|Θ).
0:0=...A...
</equation>
<construct confidence="0.4868368">
Lemma 1 A linear PCFG G with parameters Θ
which does not have any nonterminating nonter-
minals is tight.
Proof: Our proof relies on the properties of a cer-
tain |N |× |N |matrix M where:
</construct>
<equation confidence="0.978418">
�MAB = n(β, B) θA-+0
A-+0ERA
</equation>
<bodyText confidence="0.891359222222222">
where n(β, B) is the number of appearances of the
nonterminal B in the sequence β. MAB is the ex-
pected number of B nonterminals generated from
an A nonterminal in one single derivational step,
so [Mk]AB is the expected number of B nontermi-
nals generated from an A nonterminal in a k-step
derivation (Wetherell, 1980).
Since M is a non-negative matrix, under some
regularity conditions, the Frobenius-Perron theo-
rem states that the largest eigenvalue of this ma-
trix (in absolute value) is a real number. Let this
eigenvalue be denoted by λ.
A PCFG is called “subcritical” if λ &lt; 1 and
supercritical if λ &gt; 1. Then, in turn, a PCFG is
tight if it is subcritical. It is not tight if it is su-
percritical. The case of λ = 1 is a borderline case
that does not give sufficient information to know
whether the PCFG is tight or not. In the Bayesian
case, for a continuous prior such as the Dirichlet
prior, this borderline case will have measure zero
under the prior.
Now let A ∈ N. Since the grammar is lin-
ear, there is no derivation A ⇒+ ... A ... A....
Therefore, any derivation of the form A ⇒+
... A ... includes A on the right hand-side exactly
once. Because the grammar has no useless non-
terminals, the probability of such a derivation is
strictly smaller than 1.
For each A ∈ N, define:
Since A is not useless, then pA &lt; 1. Therefore
q = maxA pA &lt; 1. Since any derivation of length
k of the form A ⇒ ... A ... can be decomposed to
k
at least 2|N |cycles that start at a terminal B ∈ N
and end in the same nonterminal B ∈ N, it holds
that:
</bodyText>
<equation confidence="0.8537635">
[Mk]AA ≤ qk
2|N |k-+�→ 0.
</equation>
<bodyText confidence="0.999004473684211">
This means that trace(Mk) k-+�→ 0. This means
that the eigenvalue of M is strictly smaller than 1
(linear algebra), and therefore the PCFG is tight.■
Proposition 1 Any continuous prior P(Θ) on a
linear grammar G is tight almost everywhere for
G.
Proof: Let G be a linear grammar. With a contin-
uous prior, the probability of G getting parameters
from the prior which yield a useless non-terminal
is 0 – it would require setting at least one rule in
the grammar with rule probability which is exactly
1. Therefore, with probability 1, the parameters
taken from the prior yield a PCFG which is linear
and does not have nonterminating nonterminals.
According to Lemma 1, this means the PCFG is
tight. ■
Deciding whether a grammar G is linear can
be done in polynomial time using the construction
from Bar-Hillel et al. (1964). We can first elimi-
nate the differences between nonterminals and ter-
minal symbols by adding a rule A → cA for each
nonterminal A ∈ N, after extending the set of
terminal symbols A with {cA|A ∈ N}. Let GA
be the grammar G with the start symbol being re-
placed with A. We can then intersect the grammar
GA with the regular language T*cAT*cAT* (for
each nonterminal A ∈ N). If for any nontermi-
nal A the intersection is not the empty set (with
respect to the language that the intersection gen-
erates), then the grammar is not linear. Checking
whether the intersection is the empty set or not can
be done in polynomial time.
We conclude this section by remarking that
many of the models used in computational lin-
guistics are in fact equivalent to linear PCFGs, so
continuous Bayesian priors are almost everywhere
tight. For example, HMMs and many kinds of
“stacked” finite-state machines are equivalent to
</bodyText>
<page confidence="0.975766">
1036
</page>
<bodyText confidence="0.969835333333333">
linear PCFGs, as are the example PCFGs given in
Johnson et al. (2007) to motivate the MCMC esti-
mation procedures.
</bodyText>
<sectionHeader confidence="0.980484" genericHeader="method">
5 Dirichlet priors
</sectionHeader>
<bodyText confidence="0.999973153846154">
The first step in Bayesian inference is to specify a
prior on Θ. In the rest of this paper we take P(Θ)
to be a product of Dirichlet distributions, with one
distribution for each non-terminal A ∈ N, as this
turns out to simplify the computations consider-
ably. The prior is parameterized by a positive real
valued vector α indexed by productions R, so each
production probability θA→β has a corresponding
Dirichlet parameter αA→β. As before, let RA be
the set of productions in R with left-hand side A,
and let θA and αA refer to the component subvec-
tors of θ and α respectively indexed by produc-
tions in RA. The Dirichlet prior P(Θ  |α) is:
</bodyText>
<equation confidence="0.989326">
P(Θ  |α) = Y PD(ΘA  |αA),
A∈N
</equation>
<bodyText confidence="0.669612">
where
</bodyText>
<equation confidence="0.9995448">
PD(ΘA  |αA) =
C(αA) r∈RA
1
C(αA) = Qr∈RA Γ(αr)
Γ(Pr∈RA αr)
</equation>
<bodyText confidence="0.999907272727273">
where Γ is the generalized factorial function and
C(α) is a normalization constant that does not de-
pend on ΘA.
Dirichlet priors are useful because they are con-
jugate to the multinomial distribution, which is
the building block of PCFGs. Ignoring issues of
tightness for the moment and setting P(t  |Θ) =
µe(t), this means that in the supervised setting the
posterior distribution P(Θ  |t, α) given a set of
parse trees t = (t1, ... , tn) is also a product of
Dirichlets distribution.
</bodyText>
<equation confidence="0.995265142857143">
P(Θ  |t, α) ∝ P(t  |Θ) P(Θ  |α)
Y∝
r∈R θfr(t) Yθ αr−1
r ! r∈R
Y= θfr(t)+αr−1
r
r∈R
</equation>
<bodyText confidence="0.74517275">
which is a product of Dirichlet distributions with
parameters f(t) + α, where f(t) is the vector of
rule counts in t indexed by r ∈ R. We can thus
write:
</bodyText>
<equation confidence="0.774387">
P(Θ  |t, α) = P(Θ  |f(t) + α)
</equation>
<bodyText confidence="0.45885825">
Input: Grammar G, vector of trees t, vector of
hyperparameters α, previous parameters O0.
Result: A vector of parameters O
repeat
</bodyText>
<figure confidence="0.662109">
draw θ from products of Dirichlet with
hyperparameters α + f(t)
until O is tight for G;
return O
Algorithm 1: An algorithm for generating sam-
ples from P(Θ  |t, α) for the only-tight ap-
proach.
Input: Grammar G, vector of trees t, vector of
hyperparameters α, previous rule parameters
O0.
Result: A vector of parameters O
draw a proposal O* from a product of Dirichlets with
parameters α + f(t).
draw a uniform number u from [0, 1].
( )n
if u &lt; min{1, Z(O(i−1))/Z(O*) I return O*.
return O0.
Algorithm 2: One step of Metropolis-Hastings
</figure>
<bodyText confidence="0.9393826">
algorithm for generating samples from P(Θ |
t, α) for the renormalization approach.
which makes it clear that the rule counts are di-
rectly added to the parameters of the prior to pro-
duce the parameters of the posterior.
</bodyText>
<sectionHeader confidence="0.965709" genericHeader="method">
6 Inference in the supervised setting
</sectionHeader>
<bodyText confidence="0.9999629">
We first discuss Bayesian inference in the super-
vised setting, as inference in the unsupervised set-
ting is based on inference for the supervised set-
ting. For each of the three approaches to non-
tightness we provide an algorithm that character-
izes the posterior P(Θ  |t), where t = (t1, ... , tn)
is a sequence of trees, by generating samples from
that posterior. Our MCMC algorithms for the un-
supervised setting build on these samplers for the
supervised setting.
</bodyText>
<subsectionHeader confidence="0.99914">
6.1 The only-tight approach
</subsectionHeader>
<bodyText confidence="0.99991">
The “only-tight” approach requires that the prior
assign zero mass to non-tight rule probability vec-
tors 0⊥. One way to define such a distribution is
to restrict the domain of an existing prior distribu-
tion with the set of tight Θ and renormalize. In
more detail, if P(Θ) is a prior over rule probabili-
ties, then its renormalization is the prior P0 defined
as:
</bodyText>
<equation confidence="0.9384554">
P(Θ)I(Θ ∈/ 0⊥)
P0(Θ) = Z(0⊥) .(2)
where Z(0⊥) = Re P(Θ)I(Θ ∈/ 0⊥)dΘ.
θαr−1 and
r
</equation>
<page confidence="0.961406">
1037
</page>
<bodyText confidence="0.440542">
Input: Grammar G, vector of trees t, vector of
hyperparameters α, previous parameters Oo.
Result: A vector of parameters O
</bodyText>
<equation confidence="0.379129666666667">
draw O from products of Dirichlet with
hyperparameters α + f(t)
return O
</equation>
<bodyText confidence="0.904997928571429">
Algorithm 3: An algorithm for generating sam-
ples from P(Θ  |t, α) for the sink-state approach.
Perhaps surprisingly, it turns out that if P(Θ)
belongs to a family of conjugate priors, then P0(Θ)
also belongs to a (different) family of conjugate
priors as well.
Proposition 2 Let P(Θ|α) be a prior with hyper-
parameters α over the parameters of G such that
P is conjugate to the grammar likelihood. Then
P0, defined in Eq. 2, is conjugate to the grammar
likelihood as well.
Proof: Assume that trees t are observed, and the
prior over the grammar parameters is the prior de-
fined in Eq. 2. Therefore, the posterior is:
</bodyText>
<equation confidence="0.747041">
P(Θ|t, α) ∝ P0(Θ|α)p(t|Θ)
P(Θ|α)p(t|Θ)I(Θ ∈/ Θ⊥)
Since P(Θ|α) is a conjugate prior to the PCFG
likelihood, then there exists α0 = α0(t) such that
P(Θ|t, α) = P0(Θ|α0). Therefore:
</equation>
<bodyText confidence="0.9951665625">
which exactly equals P0(Θ|α0). ■
Sampling from the posterior over the parame-
ters given a set of trees t is therefore quite sim-
ple when assuming the base prior being renormal-
ized is a product of Dirichlets. Algorithm 1 sam-
ples from a product of Dirichlets distribution with
hyperparameters α + f(t) repeatedly, each time
checking and rejecting the sample until we obtain
a tight PCFG.
The more mass the Dirichlet distribution with
hyperparameters α + f(t) puts on non-tight
PCFGs, the more rejections will happen. In gen-
eral, if the probability mass on non-tight PCFGs is
q⊥, then it would require, on average 1/(1 − q⊥)
samples from this distribution in order to obtain a
tight PCFG.
</bodyText>
<subsectionHeader confidence="0.998138">
6.2 The renormalization approach
</subsectionHeader>
<bodyText confidence="0.999986833333333">
The renormalization approach modifies the likeli-
hood function instead of the prior. Here we use a
product of Dirichlets prior P(Θ  |α) on rule prob-
ability vectors Θ, but the presence of the partition
function Z(Θ) in Eq. 1 means that the likelihood is
no longer conjugate to the prior. Instead we have:
</bodyText>
<equation confidence="0.9960002">
µΘ(ti)
Z(Θ) P(Θ  |α)
1
∝ P(Θ  |α + f(t)). (3)
Z(Θ)n
</equation>
<bodyText confidence="0.999992">
Note that the factor Z(Θ) depends on Θ, and
therefore cannot be absorbed into the constant. Al-
gorithm 2 describes a Metropolis-Hastings sam-
pler for sampling from the posterior in Eq. 3
that uses a product of Dirichlets with parameters
α + f(t) as a proposal distribution.
In our experiments, we use the algorithm from
Nederhof and Satta (2008) to compute the parti-
tion function which is needed in Algorithm 2.
</bodyText>
<subsectionHeader confidence="0.992375">
6.3 The “sink element” approach
</subsectionHeader>
<bodyText confidence="0.999958833333333">
The “sink element” approach does not affect the
likelihood (since the probability of a tree t is just
the product of the probabilities of the rules used
to generate it), nor does it require a change to the
prior. (The sink element ⊥ is not a member of the
set of trees T, so it cannot appear in the data t).
This means that the conjugacy argument given
at the bottom of section 5 holds in this approach,
so the posterior P(Θ  |t, α) is a product of Dirich-
lets with parameters f(t) + α. Algorithm 3 gives
a sampler for P(Θ  |t, α) for the sink element ap-
proach.
</bodyText>
<sectionHeader confidence="0.899251" genericHeader="method">
7 Inference in the unsupervised setting
</sectionHeader>
<bodyText confidence="0.962177153846154">
Johnson et al. (2007) provide two Markov chain
Monte Carlo algorithms for Bayesian inference for
PCFG rule probabilities in the unsupervised set-
ting (i.e., where the data consists of a corpus of
strings w = (w1, ... , wn) alone). The algorithms
we give here are based on their Gibbs sampler,
which in each iteration first samples parse trees
t = (t1, ... , tn), where each ti is a parse for
wi, from P(t  |w, Θ), and then samples Θ from
P(Θ  |t, α).
Notice that the conditional distribution P(t |
w, Θ) is unaffected in each of our three ap-
proaches (the partition functions cancel in the
</bodyText>
<equation confidence="0.997184454545455">
= Z(Θ⊥)
P(Θ|t,α)I(Θ ∈/ Θ⊥)
∝
Z(Θ⊥) .
P(Θ|α0)I(Θ ∈/ Θ⊥)
P(Θ|t, α) ∝
.
Z(Θ⊥)
n
P(Θ  |t) =
i=1
</equation>
<page confidence="0.980441">
1038
</page>
<table confidence="0.618463555555555">
Input: Grammar G, vector of hyperparameters α,
vector of strings w = (w1,... , wn), previous
rule parameters O0.
Result: A vector of parameters O
for i ← 1 to n do
draw ti from P(ti|wi, O0)
end
use Algorithm 2 to sample O given G, t, α and O0
return O
</table>
<bodyText confidence="0.968269370967742">
Algorithm 4: One step of the Metropolis-within-
Gibbs sampler for the renormalization approach.
renormalization approach), so the algorithm for
sampling from P(t  |w, 0) given by Johnson et
al. applies in each of our three approaches as well.
Johnson et al. ignored tightness and assumed
that P(0  |t, α) is a product of Dirichlets with
parameters f(t) + α. As we noted in section 6.3,
this assumption holds for the sink-state approach
to non-tightness, so their sampler is in fact correct
for the sink-state approach.
In fact, we obtain samplers for the unsupervised
setting for each of our approaches by “plugging
in” the corresponding sampling algorithm (Eq. 1–
3) for P(0  |t, α) into the generic Gibbs sampler
framework of Johnson et al.
The one complication is that because we use a
Metropolis-Hastings procedure to generate sam-
ples from P(0  |t, α) in the renormalization ap-
proach, we use the Metropolis-within-Gibbs pro-
cedure given in Algorithm 4 (Robert and Casella,
2004).
8 The expressive power of the three
approaches
Probably the most important question to ask with
respect to the three different approaches to non-
tightness is whether they differ in terms of expres-
sive power. Clearly the three approaches differ in
terms of the grammars they admit (the only-tight
approach requires the prior to only assign non-zero
probability to tight PCFGs, while the other two ap-
proaches permit the prior to assign non-zero prob-
ability to non-tight PCFGs as well). However, if
we regard a grammar as merely a device for defin-
ing a distribution over trees and a prior as defining
a distribution over distributions over trees, it is rea-
sonable to ask whether the class of distributions
over distributions of trees that each of these ap-
proaches define are the same or differ. We believe,
but have not proved, that all three approaches de-
fine the same class of distributions over distribu-
tions of trees in the following sense: any prior used
with one of the approaches can be transformed
into a different prior that can be used with one of
the other approaches, and yield the same posterior
over trees conditioned on a string, marginalizing
out the parameters.
This does not mean that the three approaches
are equivalent, however. In this section we pro-
vide a grammar such that with a uniform prior over
rule probabilities, the conditional distribution over
trees given a fixed string varies under each of the
three different approaches.
The grammar we consider has three rules S →
S S S|S S|a with probabilities θ1, θ2 and 1− θ1 −
θ2, respectively. The 0 parameters are required to
satisfy θ1 + θ2 ≤ 1 and θi ≥ 0 for i = 1, 2.
We compute the posterior distribution over
parse trees for the string w = a a a. The gram-
mar generates three parse trees for w1, namely:
The partition function Z for this grammar is the
smallest positive root of the cubic equation:
</bodyText>
<equation confidence="0.999123">
Z = θ1Z3 + θ2Z2 + (1 − θ1 − θ2)
</equation>
<bodyText confidence="0.999966166666667">
We used Mathematica to find an analytic solution
for Z in this equation, obtaining not only an ex-
pression for the partition function Z(0) but also
identifying the non-tight region 01.
In order to compute P(t1|w), we used Mathe-
matica to first compute the following quantities:
</bodyText>
<equation confidence="0.999916666666667">
qsinkElement(ti) = le µΘ(ti) d0
IreqtightOnly(ti) = µΘ(ti) I(0 ∈/ 01) d0
qrenormalization(ti) = Ire µΘ(ti)/Z(0) d0
</equation>
<bodyText confidence="0.997669333333333">
where i ∈ {1, 2, 3}. We used Mathematica to ana-
lytically compute q(ti) for each approach and each
i ∈ {1, 2, 3}. Then it’s easy to show that:
</bodyText>
<equation confidence="0.97824">
(ti I w) q(ti)
P —_�z _1 q(ti,)
</equation>
<bodyText confidence="0.9996485">
where the q used is based on the approach to
tightness desired. For the sink-element approach,
</bodyText>
<figure confidence="0.994591515151515">
S
S
S
S
a
a
a
a
a
a
a
a
a
t1 = S
S
t2 = S
S
t3 = S
S S
S
S
S
1039
Inference
only−tight
sink−state
renormalise
30
20
10
0
0.35 0.40 0.45 0.50 0.55
Average f−score
</figure>
<figureCaption confidence="0.999735">
Figure 1: The density of the F1-scores with the
three approaches. The prior used is a symmetric
</figureCaption>
<equation confidence="0.9664138">
Dirichlet with α = 0.1.
P(t1|w) = 7≈ 0.636364. For the only-tight
11
approach P(t1|w) = 11179 ≈ 0.649149. For
17221
</equation>
<bodyText confidence="0.999942266666667">
the renormalization approach the analytic ex-
pression is too complex to include in this paper,
but it approximately equals 0.619893. A log
of our Mathematica calculations is available
at http://www.cs.columbia.edu/˜scohen/
acl13tightness-mathematica.pdf, and we
confirmed these results to three decimal places us-
ing the samplers described above (which required
107 samples per approach).
While the differences between these conditional
probabilities are not great, the conditional prob-
abilities are clearly different, so the three ap-
proaches do in fact define different distributions
over trees under a uniform prior on rule probabili-
ties.
</bodyText>
<sectionHeader confidence="0.949929" genericHeader="method">
9 Empirical effects of the three
approaches in unsupervised grammar
induction
</sectionHeader>
<bodyText confidence="0.999897483870968">
In this section we present experiments using the
three samplers just described in an unsupervised
grammar induction problem. Our goal here is
not to improve the state-of-the-art in unsupervised
grammar induction, but to try to measure empir-
ical differences in the estimates produced by the
three different approaches to tightness just de-
scribed. The bottom line of our experiments is that
we could not detect any significant difference in
the estimates produced by samplers for these three
different approaches.
In our experiments we used the English Penn
treebank (Marcus et al., 1993). We use the part-
of-speech tag sequences of sentences shorter than
11 words in sections 2–21. The grammar we use is
the PCFG version of the dependency model with
valence (Klein and Manning, 2004), as it appears
in Smith (2006).
We used a symmetric Dirichlet prior with hy-
perparameter α = 0.1. For each of the three ap-
proaches for handling tightness, we ran 100 times
the samplers in §7, each for 1,000 iterations. We
discarded the first 900 sweeps of each run, and cal-
culated the F1-scores of the sampled trees every
10th sweep from the last 100 sweeps. For each
run we calculated the average F1-score over the
10 sweeps we evaluated. We thus have 100 aver-
age F1-scores for each of the samplers.
Figure 1 plots the density of F1 scores (com-
pared to the gold standard) resulting from the
Gibbs sampler, using all three approaches. The
mean value for each of the approaches is 0.41
with standard deviation 0.06 (only-tight), 0.41
with standard deviation 0.05 (renormalization)
and 0.42 with standard deviation 0.06 (sink ele-
ment). In addition, the only-tight approach results
in an average of 437 (s.d., 142) rejected propos-
als in 1,000 samples, while the renormalization
approach results in an average of 232 (s.d., 114)
rejected proposals in 1,000 samples. (It’s not sur-
prising that the only-tight approach results in more
rejections as it keeps proposing new O until a tight
proposal is found, while the renormalization ap-
proach simply uses the old O).
We performed two-sample Kolmogorov-
Smirnov tests (which are non-parametric tests
designed to determine if two distributions are
different; see DeGroot, 1991) on each of the three
pairs of 100 F1-scores. None of the tests were
close to significant; the p-values were all above
0.5. Thus our experiments provided no evidence
that the samplers produced different distributions
over trees, although it’s reasonable to expect that
these distributions do indeed differ.
In terms of running time, our implementation
of the renormalization approach was several times
slower than our implementations of the other two
approaches because we used the naive fixed-point
algorithm to compute the partition function: per-
haps this could be improved using one of the
more sophisticated partition function algorithms
described in Nederhof and Satta (2008).
</bodyText>
<figure confidence="0.352498">
Density
</figure>
<page confidence="0.946401">
1040
</page>
<sectionHeader confidence="0.987962" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.999926552631579">
In this paper we characterized the notion of an al-
most everywhere tight grammar in the Bayesian
setting and showed it holds for linear CFGs. For
non-linear CFGs, we described three different ap-
proaches to handle non-tightness. The “only-
tight” approach restricts attention to tight PCFGs,
and perhaps surprisingly, we showed that conju-
gacy still obtains when the domain of a product
of Dirichlets prior is restricted to the subset of
tight grammars. The renormalization approach in-
volves renormalizing the PCFG measure µ over
trees when the grammar is non-tight, which de-
stroys conjugacy with a product of Dirichlets prior.
Perhaps most surprisingly of all, the sink-element
approach, which assigns the missing mass in non-
tight PCFG to a sink element ⊥, turns out to be
equivalent to existing practice where tightness is
ignored.
We studied the posterior distributions over trees
induced by the three approaches under a uniform
prior for a simple grammar and showed that they
differ. We leave for future work the important
question of whether the classes of distributions
over distributions over trees that the three ap-
proaches define are the same or different.
We described samplers for the supervised
and unsupervised settings for each of these ap-
proaches, and applied them to an unsupervised
grammar induction problem. (The code for the
unsupervised samplers is available from http://
web.science.mq.edu.au/˜mjohnson).
We could not detect any difference in the pos-
terior distributions over trees produced by these
samplers, despite devoting considerable computa-
tional resources to the problem. This suggests that
for these kinds of problems at least, tightness is
not of practical concern for Bayesian inference of
PCFGs.
</bodyText>
<sectionHeader confidence="0.996521" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997153666666667">
We thank the anonymous reviewers and Gior-
gio Satta for their valuable comments. Shay
Cohen was supported by the National Science
Foundation under Grant #1136996 to the Com-
puting Research Association for the CIFellows
Project, and Mark Johnson was supported by the
Australian Research Council’s Discovery Projects
funding scheme (project numbers DP110102506
and DP110102593).
</bodyText>
<sectionHeader confidence="0.993683" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998642">
K. B. Atherya and P. E. Ney. 1972. Branching Pro-
cesses. Dover Publications.
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On
formal properties of simple phrase structure gram-
mars. Language and Information: Selected Essays
on Their Theory and Application, pages 116–150.
T. L. Booth and R. A. Thompson. 1973. Applying
probability measures to abstract languages. IEEE
Transactions on Computers, C-22:442–450.
Z. Chi and S. Geman. 1998. Estimation of probabilis-
tic context-free grammars. Computational Linguis-
tics, 24(2):299–305.
Z. Chi. 1999. Statistical properties of probabilistic
context-free grammars. Computational Linguistics,
25(1):131–160.
S. B. Cohen and N. A. Smith. 2012. Empirical risk
minimization for probabilistic grammars: Sample
complexity and hardness of learning. Computa-
tional Linguistics, 38(3):479–526.
M. H. DeGroot. 1991. Probability and Statistics (3rd
edition). Addison-Wesley.
M. Johnson, T. L. Griffiths, and S. Goldwater. 2007.
Bayesian inference for PCFGs via Markov chain
Monte Carlo. In Proceedings of NAACL.
D. Klein and C. D. Manning. 2004. Corpus-based
induction of syntactic structure: Models of depen-
dency and constituency. In Proceedings ofACL.
K. Kurihara and T. Sato. 2006. Variational Bayesian
grammar induction for natural language. In 8th In-
ternational Colloquium on Grammatical Inference.
K. Lari and S.J. Young. 1990. The estimation of
Stochastic Context-Free Grammars using the Inside-
Outside algorithm. Computer Speech and Lan-
guage, 4(35-56).
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: The Penn treebank. Computational Linguis-
tics, 19:313–330.
M.-J. Nederhof and G. Satta. 2008. Computing par-
tition functions of PCFGs. Research on Language
and Computation, 6(2):139–162.
C. P. Robert and G. Casella. 2004. Monte Carlo Sta-
tistical Methods. Springer-Verlag New York.
N. A. Smith. 2006. Novel Estimation Methods for Un-
supervised Discovery of Latent Structure in Natural
Language Text. Ph.D. thesis, Johns Hopkins Univer-
sity.
C. S. Wetherell. 1980. Probabilistic languages: A re-
view and some open questions. Computing Surveys,
12:361–379.
</reference>
<page confidence="0.990856">
1041
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.777091">
<title confidence="0.996776">The effect of non-tightness on Bayesian estimation of PCFGs</title>
<author confidence="0.999967">B Shay</author>
<affiliation confidence="0.895988">Department of Computer Columbia</affiliation>
<email confidence="0.999828">scohen@cs.columbia.edu</email>
<abstract confidence="0.999173631578947">Probabilistic context-free grammars have the unusual property of not always defining tight distributions (i.e., the sum of the “probabilities” of the trees the grammar generates can be less than one). This paper reviews how this non-tightness can arise and discusses its impact on Bayesian estimation of PCFGs. We begin by presenting the notion of “almost everywhere tight grammars” and show that linear CFGs follow it. We then propose three different ways of reinterpreting non-tight PCFGs to make them tight, show that the Bayesian estimators in Johnson et al. (2007) are correct under one of them, and provide MCMC samplers for the other two. We conclude with a discussion of the impact of tightness empirically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K B Atherya</author>
<author>P E Ney</author>
</authors>
<title>Branching Processes.</title>
<date>1972</date>
<publisher>Dover Publications.</publisher>
<contexts>
<context position="8592" citStr="Atherya and Ney, 1972" startWordPosition="1418" endWordPosition="1421">view this grammar as defining a branching process where an 5 can either “reproduce” with probability θS-+S S or “die out” 1We found out that finding whether a PCFG is tight by directly inspecting the partition function value is less stable than using the method in Wetherell (1980). For this reason, we used Wetherell’s approach, which is based on finding the principal eigenvalue of the matrix M. θfr(t) r H rER θfr(t&apos;) r 1034 with probability θS-+a. When θS-+S S &gt; θS-+a the S nodes reproduce at a faster rate than they die out, so the derivation has a non-zero probability of endlessly rewriting (Atherya and Ney, 1972). 3 Bayesian inference for PCFGs The goal of Bayesian inference for PCFGs is to infer a posterior distribution over the rule probability vectors Θ given observed data D. This posterior distribution is obtained by combining the likelihood P(D |Θ) with a prior distribution P(Θ) over Θ using Bayes Rule. With this in hand, we can now define the likelihood term. We consider two types of data D here. In the supervised setting the data D consists of a corpus of parse trees D = (t1, ... , tn) where each tree ti is generated by the PCFG G, so n P(D |Θ) = P(ti |Θ) i=1 In the unsupervised setting the dat</context>
</contexts>
<marker>Atherya, Ney, 1972</marker>
<rawString>K. B. Atherya and P. E. Ney. 1972. Branching Processes. Dover Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>M Perles</author>
<author>E Shamir</author>
</authors>
<title>On formal properties of simple phrase structure grammars. Language and Information: Selected Essays on Their Theory and Application,</title>
<date>1964</date>
<pages>116--150</pages>
<contexts>
<context position="15057" citStr="Bar-Hillel et al. (1964)" startWordPosition="2683" endWordPosition="2686">near grammar G is tight almost everywhere for G. Proof: Let G be a linear grammar. With a continuous prior, the probability of G getting parameters from the prior which yield a useless non-terminal is 0 – it would require setting at least one rule in the grammar with rule probability which is exactly 1. Therefore, with probability 1, the parameters taken from the prior yield a PCFG which is linear and does not have nonterminating nonterminals. According to Lemma 1, this means the PCFG is tight. ■ Deciding whether a grammar G is linear can be done in polynomial time using the construction from Bar-Hillel et al. (1964). We can first eliminate the differences between nonterminals and terminal symbols by adding a rule A → cA for each nonterminal A ∈ N, after extending the set of terminal symbols A with {cA|A ∈ N}. Let GA be the grammar G with the start symbol being replaced with A. We can then intersect the grammar GA with the regular language T*cAT*cAT* (for each nonterminal A ∈ N). If for any nonterminal A the intersection is not the empty set (with respect to the language that the intersection generates), then the grammar is not linear. Checking whether the intersection is the empty set or not can be done </context>
</contexts>
<marker>Bar-Hillel, Perles, Shamir, 1964</marker>
<rawString>Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal properties of simple phrase structure grammars. Language and Information: Selected Essays on Their Theory and Application, pages 116–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Booth</author>
<author>R A Thompson</author>
</authors>
<title>Applying probability measures to abstract languages.</title>
<date>1973</date>
<journal>IEEE Transactions on Computers,</journal>
<pages>22--442</pages>
<contexts>
<context position="3323" citStr="Booth and Thompson, 1973" startWordPosition="496" endWordPosition="500">or information. Kurihara and Sato (2006) proposed a Variational Bayes estimator based on a meanfield approximation, and Johnson et al. (2007) proposed MCMC samplers for the posterior distribution over rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly normalized or “tight”. In a non-tight PCFG the partition function (i.e., sum of the “probabilities” of all the trees generated by the PCFG) is less than one. (Booth and Thompson, 1973, called such non-tight PCFGs “inconsistent”, but we follow Chi and Geman (1998) in calling them “non-tight” to avoid confusion with the consistency of statistical estimators). Chi (1999) showed that renormalized non-tight PCFGs (which he called “Gibbs CFGs”) define the same class of distributions over trees as do tight PCFGs with the same rules, and provided an algorithm for mapping any PCFG to a tight PCFG with the same rules that defines the same distribution over trees. An obvious question is then: how does tightness affect the inference of PCFGs? Chi and Geman (1998) studied the question </context>
</contexts>
<marker>Booth, Thompson, 1973</marker>
<rawString>T. L. Booth and R. A. Thompson. 1973. Applying probability measures to abstract languages. IEEE Transactions on Computers, C-22:442–450.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Chi</author>
<author>S Geman</author>
</authors>
<title>Estimation of probabilistic context-free grammars.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="3403" citStr="Chi and Geman (1998)" startWordPosition="510" endWordPosition="513">d on a meanfield approximation, and Johnson et al. (2007) proposed MCMC samplers for the posterior distribution over rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly normalized or “tight”. In a non-tight PCFG the partition function (i.e., sum of the “probabilities” of all the trees generated by the PCFG) is less than one. (Booth and Thompson, 1973, called such non-tight PCFGs “inconsistent”, but we follow Chi and Geman (1998) in calling them “non-tight” to avoid confusion with the consistency of statistical estimators). Chi (1999) showed that renormalized non-tight PCFGs (which he called “Gibbs CFGs”) define the same class of distributions over trees as do tight PCFGs with the same rules, and provided an algorithm for mapping any PCFG to a tight PCFG with the same rules that defines the same distribution over trees. An obvious question is then: how does tightness affect the inference of PCFGs? Chi and Geman (1998) studied the question for Maximum Likelihood (ML) estimation, and showed that ML es1033 Proceedings of</context>
</contexts>
<marker>Chi, Geman, 1998</marker>
<rawString>Z. Chi and S. Geman. 1998. Estimation of probabilistic context-free grammars. Computational Linguistics, 24(2):299–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Chi</author>
</authors>
<title>Statistical properties of probabilistic context-free grammars.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="3510" citStr="Chi (1999)" startWordPosition="527" endWordPosition="528">rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly normalized or “tight”. In a non-tight PCFG the partition function (i.e., sum of the “probabilities” of all the trees generated by the PCFG) is less than one. (Booth and Thompson, 1973, called such non-tight PCFGs “inconsistent”, but we follow Chi and Geman (1998) in calling them “non-tight” to avoid confusion with the consistency of statistical estimators). Chi (1999) showed that renormalized non-tight PCFGs (which he called “Gibbs CFGs”) define the same class of distributions over trees as do tight PCFGs with the same rules, and provided an algorithm for mapping any PCFG to a tight PCFG with the same rules that defines the same distribution over trees. An obvious question is then: how does tightness affect the inference of PCFGs? Chi and Geman (1998) studied the question for Maximum Likelihood (ML) estimation, and showed that ML es1033 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1033–1041, Sofia, Bulgaria</context>
</contexts>
<marker>Chi, 1999</marker>
<rawString>Z. Chi. 1999. Statistical properties of probabilistic context-free grammars. Computational Linguistics, 25(1):131–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S B Cohen</author>
<author>N A Smith</author>
</authors>
<title>Empirical risk minimization for probabilistic grammars: Sample complexity and hardness of learning.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>3</issue>
<contexts>
<context position="2103" citStr="Cohen and Smith (2012)" startWordPosition="319" endWordPosition="322">ngineering perspectives. Cognitively it is implausible that children can perceive the parse trees of the language they are learning, but it is more reasonable to assume that they can obtain the terminal strings or yield of these trees. Unsupervised methods for learning a grammar from terminal strings alone is also interesting from an engineering perspective because such training data is cheap and Mark Johnson Department of Computing Macquarie University mark.johnson@mq.edu.au plentiful, while the manually parsed data required by supervised methods are expensive to produce and relatively rare. Cohen and Smith (2012) show that inferring PCFG rule probabilities from strings alone is computationally intractable, so we should not expect to find an efficient, general-purpose algorithm for the unsupervised problem. Instead, approximation algorithms are standardly used. For example, the Inside-Outside (IO) algorithm efficiently implements the Expectation-Maximization (EM) procedure for approximating a Maximum Likelihood estimator (Lari and Young, 1990). Bayesian estimators for PCFG rule probabilities have also been attracting attention because they provide a theoretically-principled way of incorporating prior i</context>
</contexts>
<marker>Cohen, Smith, 2012</marker>
<rawString>S. B. Cohen and N. A. Smith. 2012. Empirical risk minimization for probabilistic grammars: Sample complexity and hardness of learning. Computational Linguistics, 38(3):479–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H DeGroot</author>
</authors>
<title>Probability and Statistics (3rd edition).</title>
<date>1991</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="30294" citStr="DeGroot, 1991" startWordPosition="5380" endWordPosition="5381">d deviation 0.06 (sink element). In addition, the only-tight approach results in an average of 437 (s.d., 142) rejected proposals in 1,000 samples, while the renormalization approach results in an average of 232 (s.d., 114) rejected proposals in 1,000 samples. (It’s not surprising that the only-tight approach results in more rejections as it keeps proposing new O until a tight proposal is found, while the renormalization approach simply uses the old O). We performed two-sample KolmogorovSmirnov tests (which are non-parametric tests designed to determine if two distributions are different; see DeGroot, 1991) on each of the three pairs of 100 F1-scores. None of the tests were close to significant; the p-values were all above 0.5. Thus our experiments provided no evidence that the samplers produced different distributions over trees, although it’s reasonable to expect that these distributions do indeed differ. In terms of running time, our implementation of the renormalization approach was several times slower than our implementations of the other two approaches because we used the naive fixed-point algorithm to compute the partition function: perhaps this could be improved using one of the more so</context>
</contexts>
<marker>DeGroot, 1991</marker>
<rawString>M. H. DeGroot. 1991. Probability and Statistics (3rd edition). Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
<author>T L Griffiths</author>
<author>S Goldwater</author>
</authors>
<title>Bayesian inference for PCFGs via Markov chain Monte Carlo.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="726" citStr="Johnson et al. (2007)" startWordPosition="109" endWordPosition="112">Columbia University scohen@cs.columbia.edu Abstract Probabilistic context-free grammars have the unusual property of not always defining tight distributions (i.e., the sum of the “probabilities” of the trees the grammar generates can be less than one). This paper reviews how this non-tightness can arise and discusses its impact on Bayesian estimation of PCFGs. We begin by presenting the notion of “almost everywhere tight grammars” and show that linear CFGs follow it. We then propose three different ways of reinterpreting non-tight PCFGs to make them tight, show that the Bayesian estimators in Johnson et al. (2007) are correct under one of them, and provide MCMC samplers for the other two. We conclude with a discussion of the impact of tightness empirically. 1 Introduction Probabilistic Context-Free Grammars (PCFGs) play a special role in computational linguistics because they are perhaps the simplest probabilistic models of hierarchical structures. Their simplicity enables us to mathematically analyze their properties to a detail that would be difficult with linguistically more accurate models. Such analysis is useful because it is reasonable to expect more complex models to exhibit similar properties </context>
<context position="2840" citStr="Johnson et al. (2007)" startWordPosition="419" endWordPosition="422">ect to find an efficient, general-purpose algorithm for the unsupervised problem. Instead, approximation algorithms are standardly used. For example, the Inside-Outside (IO) algorithm efficiently implements the Expectation-Maximization (EM) procedure for approximating a Maximum Likelihood estimator (Lari and Young, 1990). Bayesian estimators for PCFG rule probabilities have also been attracting attention because they provide a theoretically-principled way of incorporating prior information. Kurihara and Sato (2006) proposed a Variational Bayes estimator based on a meanfield approximation, and Johnson et al. (2007) proposed MCMC samplers for the posterior distribution over rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly normalized or “tight”. In a non-tight PCFG the partition function (i.e., sum of the “probabilities” of all the trees generated by the PCFG) is less than one. (Booth and Thompson, 1973, called such non-tight PCFGs “inconsistent”, but we follow Chi and Geman (1998) in calling them “non-tight” to avoid</context>
<context position="5566" citStr="Johnson et al. (2007)" startWordPosition="855" endWordPosition="858">erior may assign non-zero probability to non-tight PCFGs. We discuss three different possible approaches to this in this paper: 1. the only-tight approach, where we modify the prior so it only assigns non-zero probability to tight PCFGs, 2. the renormalization approach, where we renormalize non-tight PCFGs so they define a probability distribution over trees, and 3. the sink-element approach, where we reinterpret non-tight PCFGs as assigning non-zero probability to a “sink element”, so both tight and non-tight PCFGs are properly normalized. We show how to modify the Gibbs sampler described by Johnson et al. (2007) so it produces samples from the posterior distributions defined by the only-tight and renormalization approaches. Perhaps surprisingly, we show that Gibbs sampler as defined by Johnson et al. actually produces samples from the posterior distributions defined by the sink-element approach. We conclude by studying the effect of requiring tightness on the estimation of some simple PCFGs. Because the Bayesian posterior converges around the (tight) ML estimate as the size of the data grows, requiring tightness only seems to make a difference with highly biased priors or with very small training cor</context>
<context position="16032" citStr="Johnson et al. (2007)" startWordPosition="2857" endWordPosition="2860">terminal A ∈ N). If for any nonterminal A the intersection is not the empty set (with respect to the language that the intersection generates), then the grammar is not linear. Checking whether the intersection is the empty set or not can be done in polynomial time. We conclude this section by remarking that many of the models used in computational linguistics are in fact equivalent to linear PCFGs, so continuous Bayesian priors are almost everywhere tight. For example, HMMs and many kinds of “stacked” finite-state machines are equivalent to 1036 linear PCFGs, as are the example PCFGs given in Johnson et al. (2007) to motivate the MCMC estimation procedures. 5 Dirichlet priors The first step in Bayesian inference is to specify a prior on Θ. In the rest of this paper we take P(Θ) to be a product of Dirichlet distributions, with one distribution for each non-terminal A ∈ N, as this turns out to simplify the computations considerably. The prior is parameterized by a positive real valued vector α indexed by productions R, so each production probability θA→β has a corresponding Dirichlet parameter αA→β. As before, let RA be the set of productions in R with left-hand side A, and let θA and αA refer to the com</context>
<context position="22551" citStr="Johnson et al. (2007)" startWordPosition="4032" endWordPosition="4035"> The “sink element” approach does not affect the likelihood (since the probability of a tree t is just the product of the probabilities of the rules used to generate it), nor does it require a change to the prior. (The sink element ⊥ is not a member of the set of trees T, so it cannot appear in the data t). This means that the conjugacy argument given at the bottom of section 5 holds in this approach, so the posterior P(Θ |t, α) is a product of Dirichlets with parameters f(t) + α. Algorithm 3 gives a sampler for P(Θ |t, α) for the sink element approach. 7 Inference in the unsupervised setting Johnson et al. (2007) provide two Markov chain Monte Carlo algorithms for Bayesian inference for PCFG rule probabilities in the unsupervised setting (i.e., where the data consists of a corpus of strings w = (w1, ... , wn) alone). The algorithms we give here are based on their Gibbs sampler, which in each iteration first samples parse trees t = (t1, ... , tn), where each ti is a parse for wi, from P(t |w, Θ), and then samples Θ from P(Θ |t, α). Notice that the conditional distribution P(t | w, Θ) is unaffected in each of our three approaches (the partition functions cancel in the = Z(Θ⊥) P(Θ|t,α)I(Θ ∈/ Θ⊥) ∝ Z(Θ⊥) </context>
</contexts>
<marker>Johnson, Griffiths, Goldwater, 2007</marker>
<rawString>M. Johnson, T. L. Griffiths, and S. Goldwater. 2007. Bayesian inference for PCFGs via Markov chain Monte Carlo. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="28879" citStr="Klein and Manning, 2004" startWordPosition="5142" endWordPosition="5145">the state-of-the-art in unsupervised grammar induction, but to try to measure empirical differences in the estimates produced by the three different approaches to tightness just described. The bottom line of our experiments is that we could not detect any significant difference in the estimates produced by samplers for these three different approaches. In our experiments we used the English Penn treebank (Marcus et al., 1993). We use the partof-speech tag sequences of sentences shorter than 11 words in sections 2–21. The grammar we use is the PCFG version of the dependency model with valence (Klein and Manning, 2004), as it appears in Smith (2006). We used a symmetric Dirichlet prior with hyperparameter α = 0.1. For each of the three approaches for handling tightness, we ran 100 times the samplers in §7, each for 1,000 iterations. We discarded the first 900 sweeps of each run, and calculated the F1-scores of the sampled trees every 10th sweep from the last 100 sweeps. For each run we calculated the average F1-score over the 10 sweeps we evaluated. We thus have 100 average F1-scores for each of the samplers. Figure 1 plots the density of F1 scores (compared to the gold standard) resulting from the Gibbs sa</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>D. Klein and C. D. Manning. 2004. Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kurihara</author>
<author>T Sato</author>
</authors>
<title>Variational Bayesian grammar induction for natural language.</title>
<date>2006</date>
<booktitle>In 8th International Colloquium on Grammatical Inference.</booktitle>
<contexts>
<context position="2739" citStr="Kurihara and Sato (2006)" startWordPosition="403" endWordPosition="406">nferring PCFG rule probabilities from strings alone is computationally intractable, so we should not expect to find an efficient, general-purpose algorithm for the unsupervised problem. Instead, approximation algorithms are standardly used. For example, the Inside-Outside (IO) algorithm efficiently implements the Expectation-Maximization (EM) procedure for approximating a Maximum Likelihood estimator (Lari and Young, 1990). Bayesian estimators for PCFG rule probabilities have also been attracting attention because they provide a theoretically-principled way of incorporating prior information. Kurihara and Sato (2006) proposed a Variational Bayes estimator based on a meanfield approximation, and Johnson et al. (2007) proposed MCMC samplers for the posterior distribution over rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly normalized or “tight”. In a non-tight PCFG the partition function (i.e., sum of the “probabilities” of all the trees generated by the PCFG) is less than one. (Booth and Thompson, 1973, called such no</context>
</contexts>
<marker>Kurihara, Sato, 2006</marker>
<rawString>K. Kurihara and T. Sato. 2006. Variational Bayesian grammar induction for natural language. In 8th International Colloquium on Grammatical Inference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lari</author>
<author>S J Young</author>
</authors>
<title>The estimation of Stochastic Context-Free Grammars using the InsideOutside algorithm.</title>
<date>1990</date>
<journal>Computer Speech and Language,</journal>
<pages>4--35</pages>
<contexts>
<context position="2541" citStr="Lari and Young, 1990" startWordPosition="378" endWordPosition="381">cquarie University mark.johnson@mq.edu.au plentiful, while the manually parsed data required by supervised methods are expensive to produce and relatively rare. Cohen and Smith (2012) show that inferring PCFG rule probabilities from strings alone is computationally intractable, so we should not expect to find an efficient, general-purpose algorithm for the unsupervised problem. Instead, approximation algorithms are standardly used. For example, the Inside-Outside (IO) algorithm efficiently implements the Expectation-Maximization (EM) procedure for approximating a Maximum Likelihood estimator (Lari and Young, 1990). Bayesian estimators for PCFG rule probabilities have also been attracting attention because they provide a theoretically-principled way of incorporating prior information. Kurihara and Sato (2006) proposed a Variational Bayes estimator based on a meanfield approximation, and Johnson et al. (2007) proposed MCMC samplers for the posterior distribution over rule probabilities and the parse trees of the training data strings. PCFGs have the interesting property (which we expect most linguistically more realistic models to also possess) that the distributions they define are not always properly n</context>
</contexts>
<marker>Lari, Young, 1990</marker>
<rawString>K. Lari and S.J. Young. 1990. The estimation of Stochastic Context-Free Grammars using the InsideOutside algorithm. Computer Speech and Language, 4(35-56).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="28684" citStr="Marcus et al., 1993" startWordPosition="5108" endWordPosition="5111">in unsupervised grammar induction In this section we present experiments using the three samplers just described in an unsupervised grammar induction problem. Our goal here is not to improve the state-of-the-art in unsupervised grammar induction, but to try to measure empirical differences in the estimates produced by the three different approaches to tightness just described. The bottom line of our experiments is that we could not detect any significant difference in the estimates produced by samplers for these three different approaches. In our experiments we used the English Penn treebank (Marcus et al., 1993). We use the partof-speech tag sequences of sentences shorter than 11 words in sections 2–21. The grammar we use is the PCFG version of the dependency model with valence (Klein and Manning, 2004), as it appears in Smith (2006). We used a symmetric Dirichlet prior with hyperparameter α = 0.1. For each of the three approaches for handling tightness, we ran 100 times the samplers in §7, each for 1,000 iterations. We discarded the first 900 sweeps of each run, and calculated the F1-scores of the sampled trees every 10th sweep from the last 100 sweeps. For each run we calculated the average F1-scor</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-J Nederhof</author>
<author>G Satta</author>
</authors>
<title>Computing partition functions of PCFGs.</title>
<date>2008</date>
<journal>Research on Language and Computation,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="7492" citStr="Nederhof and Satta (2008)" startWordPosition="1222" endWordPosition="1225">e require that θA-+β &gt; 0 and that for all nonterminals A E N, EA-+βERA θA-+β = 1, where RA is the subset of rules R expanding the nonterminal A. A PCFG (G, Θ) defines a measure Pe over trees t as follows: H Pe(t) = rER where fr(t) is the number of times the production r = A -+ 0 E R is used in the derivation of t. The partition function Z or measure of all possible trees is: � Z(Θ) = t&apos;ET where T is the set of all (finite) trees generated by G. A PCFG is tight iff the partition function Z(Θ) = 1. In this paper we use Θ1 to denote the set of rule probability vectors Θ for which G is non-tight. Nederhof and Satta (2008) survey several algorithms for computing Z(Θ), and hence for determining whether a PCFG is tight.1 Non-tightness can arise in very simple PCFGs, such as the “Catalan” PCFG 5 -+ 5 5 |a. This grammar produces binary trees where all internal nodes are labeled as 5 and the yield of these trees is a sequence of as. If the probability of the rule 5 -+ 5 5 is greater than 0.5 then this PCFG is non-tight. Perhaps the most straight-forward way to understand this non-tightness is to view this grammar as defining a branching process where an 5 can either “reproduce” with probability θS-+S S or “die out” </context>
<context position="21832" citStr="Nederhof and Satta (2008)" startWordPosition="3895" endWordPosition="3898">of the prior. Here we use a product of Dirichlets prior P(Θ |α) on rule probability vectors Θ, but the presence of the partition function Z(Θ) in Eq. 1 means that the likelihood is no longer conjugate to the prior. Instead we have: µΘ(ti) Z(Θ) P(Θ |α) 1 ∝ P(Θ |α + f(t)). (3) Z(Θ)n Note that the factor Z(Θ) depends on Θ, and therefore cannot be absorbed into the constant. Algorithm 2 describes a Metropolis-Hastings sampler for sampling from the posterior in Eq. 3 that uses a product of Dirichlets with parameters α + f(t) as a proposal distribution. In our experiments, we use the algorithm from Nederhof and Satta (2008) to compute the partition function which is needed in Algorithm 2. 6.3 The “sink element” approach The “sink element” approach does not affect the likelihood (since the probability of a tree t is just the product of the probabilities of the rules used to generate it), nor does it require a change to the prior. (The sink element ⊥ is not a member of the set of trees T, so it cannot appear in the data t). This means that the conjugacy argument given at the bottom of section 5 holds in this approach, so the posterior P(Θ |t, α) is a product of Dirichlets with parameters f(t) + α. Algorithm 3 give</context>
<context position="30974" citStr="Nederhof and Satta (2008)" startWordPosition="5482" endWordPosition="5485">he tests were close to significant; the p-values were all above 0.5. Thus our experiments provided no evidence that the samplers produced different distributions over trees, although it’s reasonable to expect that these distributions do indeed differ. In terms of running time, our implementation of the renormalization approach was several times slower than our implementations of the other two approaches because we used the naive fixed-point algorithm to compute the partition function: perhaps this could be improved using one of the more sophisticated partition function algorithms described in Nederhof and Satta (2008). Density 1040 10 Conclusion In this paper we characterized the notion of an almost everywhere tight grammar in the Bayesian setting and showed it holds for linear CFGs. For non-linear CFGs, we described three different approaches to handle non-tightness. The “onlytight” approach restricts attention to tight PCFGs, and perhaps surprisingly, we showed that conjugacy still obtains when the domain of a product of Dirichlets prior is restricted to the subset of tight grammars. The renormalization approach involves renormalizing the PCFG measure µ over trees when the grammar is non-tight, which des</context>
</contexts>
<marker>Nederhof, Satta, 2008</marker>
<rawString>M.-J. Nederhof and G. Satta. 2008. Computing partition functions of PCFGs. Research on Language and Computation, 6(2):139–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C P Robert</author>
<author>G Casella</author>
</authors>
<title>Monte Carlo Statistical Methods.</title>
<date>2004</date>
<publisher>Springer-Verlag</publisher>
<location>New York.</location>
<contexts>
<context position="24439" citStr="Robert and Casella, 2004" startWordPosition="4372" endWordPosition="4375"> α. As we noted in section 6.3, this assumption holds for the sink-state approach to non-tightness, so their sampler is in fact correct for the sink-state approach. In fact, we obtain samplers for the unsupervised setting for each of our approaches by “plugging in” the corresponding sampling algorithm (Eq. 1– 3) for P(0 |t, α) into the generic Gibbs sampler framework of Johnson et al. The one complication is that because we use a Metropolis-Hastings procedure to generate samples from P(0 |t, α) in the renormalization approach, we use the Metropolis-within-Gibbs procedure given in Algorithm 4 (Robert and Casella, 2004). 8 The expressive power of the three approaches Probably the most important question to ask with respect to the three different approaches to nontightness is whether they differ in terms of expressive power. Clearly the three approaches differ in terms of the grammars they admit (the only-tight approach requires the prior to only assign non-zero probability to tight PCFGs, while the other two approaches permit the prior to assign non-zero probability to non-tight PCFGs as well). However, if we regard a grammar as merely a device for defining a distribution over trees and a prior as defining a</context>
</contexts>
<marker>Robert, Casella, 2004</marker>
<rawString>C. P. Robert and G. Casella. 2004. Monte Carlo Statistical Methods. Springer-Verlag New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
</authors>
<title>Novel Estimation Methods for Unsupervised Discovery of Latent Structure in Natural Language Text.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Johns Hopkins University.</institution>
<contexts>
<context position="28910" citStr="Smith (2006)" startWordPosition="5150" endWordPosition="5151">r induction, but to try to measure empirical differences in the estimates produced by the three different approaches to tightness just described. The bottom line of our experiments is that we could not detect any significant difference in the estimates produced by samplers for these three different approaches. In our experiments we used the English Penn treebank (Marcus et al., 1993). We use the partof-speech tag sequences of sentences shorter than 11 words in sections 2–21. The grammar we use is the PCFG version of the dependency model with valence (Klein and Manning, 2004), as it appears in Smith (2006). We used a symmetric Dirichlet prior with hyperparameter α = 0.1. For each of the three approaches for handling tightness, we ran 100 times the samplers in §7, each for 1,000 iterations. We discarded the first 900 sweeps of each run, and calculated the F1-scores of the sampled trees every 10th sweep from the last 100 sweeps. For each run we calculated the average F1-score over the 10 sweeps we evaluated. We thus have 100 average F1-scores for each of the samplers. Figure 1 plots the density of F1 scores (compared to the gold standard) resulting from the Gibbs sampler, using all three approach</context>
</contexts>
<marker>Smith, 2006</marker>
<rawString>N. A. Smith. 2006. Novel Estimation Methods for Unsupervised Discovery of Latent Structure in Natural Language Text. Ph.D. thesis, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C S Wetherell</author>
</authors>
<title>Probabilistic languages: A review and some open questions. Computing Surveys,</title>
<date>1980</date>
<pages>12--361</pages>
<contexts>
<context position="8251" citStr="Wetherell (1980)" startWordPosition="1360" endWordPosition="1361">, such as the “Catalan” PCFG 5 -+ 5 5 |a. This grammar produces binary trees where all internal nodes are labeled as 5 and the yield of these trees is a sequence of as. If the probability of the rule 5 -+ 5 5 is greater than 0.5 then this PCFG is non-tight. Perhaps the most straight-forward way to understand this non-tightness is to view this grammar as defining a branching process where an 5 can either “reproduce” with probability θS-+S S or “die out” 1We found out that finding whether a PCFG is tight by directly inspecting the partition function value is less stable than using the method in Wetherell (1980). For this reason, we used Wetherell’s approach, which is based on finding the principal eigenvalue of the matrix M. θfr(t) r H rER θfr(t&apos;) r 1034 with probability θS-+a. When θS-+S S &gt; θS-+a the S nodes reproduce at a faster rate than they die out, so the derivation has a non-zero probability of endlessly rewriting (Atherya and Ney, 1972). 3 Bayesian inference for PCFGs The goal of Bayesian inference for PCFGs is to infer a posterior distribution over the rule probability vectors Θ given observed data D. This posterior distribution is obtained by combining the likelihood P(D |Θ) with a prior </context>
<context position="12988" citStr="Wetherell, 1980" startWordPosition="2291" endWordPosition="2292"> ...A... |Θ) = 1. Here P(A ⇒+ ... A... |Θ) is defined as: � PG(A ⇒+ β|Θ). 0:0=...A... Lemma 1 A linear PCFG G with parameters Θ which does not have any nonterminating nonterminals is tight. Proof: Our proof relies on the properties of a certain |N |× |N |matrix M where: �MAB = n(β, B) θA-+0 A-+0ERA where n(β, B) is the number of appearances of the nonterminal B in the sequence β. MAB is the expected number of B nonterminals generated from an A nonterminal in one single derivational step, so [Mk]AB is the expected number of B nonterminals generated from an A nonterminal in a k-step derivation (Wetherell, 1980). Since M is a non-negative matrix, under some regularity conditions, the Frobenius-Perron theorem states that the largest eigenvalue of this matrix (in absolute value) is a real number. Let this eigenvalue be denoted by λ. A PCFG is called “subcritical” if λ &lt; 1 and supercritical if λ &gt; 1. Then, in turn, a PCFG is tight if it is subcritical. It is not tight if it is supercritical. The case of λ = 1 is a borderline case that does not give sufficient information to know whether the PCFG is tight or not. In the Bayesian case, for a continuous prior such as the Dirichlet prior, this borderline ca</context>
</contexts>
<marker>Wetherell, 1980</marker>
<rawString>C. S. Wetherell. 1980. Probabilistic languages: A review and some open questions. Computing Surveys, 12:361–379.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>