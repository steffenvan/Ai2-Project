<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000455">
<note confidence="0.571174">
WHAT NOT TO SAY
</note>
<author confidence="0.830423">
Jan Fornell
</author>
<affiliation confidence="0.9728815">
Department of Linguistics &amp; Phonetics
Lund University
</affiliation>
<address confidence="0.453226">
Helgonabacken 12. Lund, Sweden
</address>
<email confidence="0.721331">
ABSTRACT
</email>
<bodyText confidence="0.99608">
A problem with most text production and
language generation systems is that they tend to
become rather verbose. This may be due to
neglection of the pragmatic factors involved in
communication. In this paper, a text production
system, COMMENTATOR, is described and taken as a
starting point for a more general discussion of
some problems in Computational Pragmatics. A new
line of research is suggested, based on the
concept of unification.
</bodyText>
<figure confidence="0.858204333333333">
I COMMENTATOR
A. The original model
1. General purpose
</figure>
<bodyText confidence="0.999525833333333">
The original version of Commentator was
written in BASIC on a small micro computer. It was
intended as a generator of text (rather than just
sentences), but has in fact proved quite useful,
in a somewhat more general sense, as a generator
of linguistic problems, and is often thought of as
a &amp;quot;linguistic research tool&amp;quot;.
The idea was to create a model that
worked at all levels, from &amp;quot;raw data&amp;quot; like
perceptions and knowledge, via syntactic, semantic
and pragmatic components to coherent text or
speech, in order to be able to study the various
levels and the interaction between them at the
same time. This means that the model is very
narrow and &amp;quot;vertical&amp;quot;, rather than like most other
computational models, which are usually
characterized by huge databases at a single level
of representation.
</bodyText>
<sectionHeader confidence="0.970345" genericHeader="method">
2. The model
</sectionHeader>
<bodyText confidence="0.988327586206897">
The system dynamically describes the
movements and locations of a few objects on the
computer screen. (In one version: two persons,
called Adam and Eve, moving around in a yard with
a gate and a tree. In another version, some ships
outside a harbour). The comments are presented in
Swedish or English in a written and a spoken
version simultaneously (using a VOTRAX speech
synthesis device). No real perceptive mechanism
(such as a video camera) is included in the
system, (instead it is fed the successive
coordinates of the moving objects) but otherwise
all the other abovementioned components are
present, to some extent.
For both practical and intuitive reasons
the system is &amp;quot;pragmatically deterministic&amp;quot; in
some sense. By this I mean that a certain state of
affairs is investigated only if it might lead to
an expressible comment. For every change of the
scene, potentially relevant and commentable topics
are selected from a question menu. If something
actually has happened (i e a change of state [1]
has occurred), a syntactic rule is selected and
appropriate words and phrases are put in. A choice
Is made between pronouns and other nounphrases,
depending on the previous sentences. If a change
of focus has occurred, contrastive stress is added
to the new. focus. Some &amp;quot;discourse connectives&amp;quot;
like ocksa (also/too) and heller (neither) are
also added. There are apparently some more or less
obligatory contexts for this, namely when all
parts (predicates and arguments) of two sentences
are equal except for one. For example
&amp;quot;Adam is approaching the gate.&amp;quot;
&amp;quot;Eve is also approaching it.&amp;quot;
(predicates equal, but subjects different)
&amp;quot;John hit Mary.&amp;quot;
&amp;quot;He kicked her too.&amp;quot;
(subjects and objects equal, but different
predicates), etc. Stating the respective second
sentences of the examples above without the
also/too sounds highly unnatural. This is however
only part of the truth (see below).
Note that all selections of relevant
topics and syntactic forms are made at an abstract
level. Once words have begun being inserted, the
sentence will be expressed, and it is never the
case that a sentence is constructed, but not
expressed. Neither are words first put in, and
then deleted. This is in contrast with many other
text production systems, where a range of
sentences are constructed, and then compared to
find the &amp;quot;best&amp;quot; way of expressing the proposition.
That might be a possible approach when writing a
(single) text, such as an instruction manual, or a
paper like this, but it seems unsuitable for
dynamic text production in a changing environment
like Commentator&apos;s.
</bodyText>
<page confidence="0.990892">
348
</page>
<bodyText confidence="0.98630047826087">
B. A new model
A new version is currently being
inplemented in Prolog on a VAX11/730, avoiding
many of the drawbacks and limitations of the BASIC
model. It is highly modular, and can easily be
expanded in any given direction. It does not yet
include any speech synthesis mechanism, but plans
are being made to connect the system to the quite
sophisticated ILS program package available at the
department of linguistics. On the other hand, it
does include some interactive components, and some
facilities for (simple) machine translation within
the specified domains, using Prolog as an
intermediary level of representation.
The major aim, however, is not to
re—implement a slightly more sophisticated version
of the original Commentator, which is basically a
monologue generator, but instead to develop a new,
highly interactive model, nick—named CONVERSATOR,
in order to study the properties of human
discourse. What will be described in the
following, is mostly the original Commentator,
though.
</bodyText>
<sectionHeader confidence="0.967283" genericHeader="method">
II COMPUTATIONAL PRAGMATICS
</sectionHeader>
<bodyText confidence="0.962490181818182">
A. Relevance Strategies in Commentator
The previous presentation of Commentator
of course raises some questions, such as &amp;quot;What is
a relevant topic?&amp;quot; It is a well known fact, that
for most text production systems it is a major
problem to restrict the computer output — to get
the computer to shut up, as it were, and avoid
stating the obvious. In many cases this problem is
not solved at all, and the system goes on to
become quite verbose. On the other hand,
Commentator was developed with this in mind.
</bodyText>
<sectionHeader confidence="0.499475" genericHeader="method">
1. Changes
</sectionHeader>
<bodyText confidence="0.999718222222222">
A major strategy has been to only
comment on changes [27. Thus, for example, if
Commentator notes that the object called Adam is
approaching the object called the gate (where
approach is defined as something like &amp;quot;moving in
the direction of the goal, with diminishing
distance&amp;quot; — this is not obvious, but perhaps a
problem of pattern recognition rather than
semantics), the system will say something like
</bodyText>
<listItem confidence="0.806261">
(1) &amp;quot;Adam is approaching the gate&amp;quot;.
</listItem>
<bodyText confidence="0.992093">
Then, if in the next few scenes he&apos;s still
approaching the gate, nothing more need to be said
about it. Only when something new happens, a
comment will be generated, such as if Adam reaches
the gate, which is what one might expect him to do
sooner or later, if (1) is to be at all
appropriate. Or if Adam suddenly reverses his
direction, a slightly more drastic comment might
</bodyText>
<listItem confidence="0.795483">
be generated, such as
(2) &amp;quot;Now he&apos;s moving away from it&amp;quot;.
</listItem>
<bodyText confidence="0.987869083333334">
Note however, that the Commentator can
only observe Adam&apos;s behaviour and make guesses
about his intentions. Since he is not Adam
himself, he can never know what Adam&apos;s real
intentions are. He can never say what Adam is in
fact doing, only what he thinks Adam is doing, and
any presuppositions or implicatures conveyed are
only those of his beliefs. Thus, uttering (1)
somehow implicates that the Commentator believes
that Adam is approaching the gate in order to
reach it, but not that Adam is in fact doing so.
This might be quite important.
</bodyText>
<sectionHeader confidence="0.944132" genericHeader="method">
2. Nearness
</sectionHeader>
<bodyText confidence="0.999846875">
Another criterion for relevance is
nearness. It seems reasonable to talk about
objects in relation to other objects close by [3],
rather than to objects further away. For instance,
if Adam is close to the gate, but the tree is on
the other side of the yard, it would probably make
more sense to say (3) than (4), even though they
may be equally true.
</bodyText>
<listItem confidence="0.9996315">
(3) Adam is approaching the gate.
(4) Adam is moving away from the tree.
</listItem>
<bodyText confidence="0.987724387096774">
All of this, of course, presupposes that
it is sensible to talk about these things at all,
and this is not obvious. What is a text generation
system supposed to do, really?
B. Why talk?
Expert systems require some kind of text
generation module to be able to present output in
a comprehensible way. This means that the input to
the system (some set of data) is fairly
well—known, as well as the desired format of the
output. But this means that the quality of the
output can only be measured against how well it
meets the pre—determined standards. There is
obviously much more to human communication than
that. I believe that the serious limitations and
unnaturalness of existing text generation systems
(whether they are included in an expert system or
not. There aren&apos;t really many of the latter type.)
cannot be overcome, unless a certain important
question is asked, namely &amp;quot;Why ever say anything
at all?&amp;quot;
Two different dimensions can be
recognized. One is prompted vs spontaneous speech,
and the other is the informative content.
At one end of the information scale is
talk that contains almost no information at all,
such as most talk about the weather. This is
usually a very ritualized behaviour [4], and is
quite different from the exchange of data, which
characterizes most interactions with computers and
would be the other end of the scale.
</bodyText>
<page confidence="0.998309">
349
</page>
<bodyText confidence="0.989698136363636">
Aside from the abovementioned kind of
social interaction, it seems that one talks when
one is in possession of some information, and
believes that the listener—to—be is interested in
this information. The most obvious case is when a
question has been asked, or the speaker otherwise
has been prompted. In fact, this is the only case
that text generation systems ever seem to take
care of. Expert systems speak only when spoken to.
The Commentator is made to talk about what&apos;s
happening, assuming that someone is listening, and
interested in what it says. But for a conversating
system this is not enough. The properties of
spontaneous speech has to be investigated, in
order to address questions like &amp;quot;When does one
volunteer information?&amp;quot;, &amp;quot;When does one initiate a
conversation?&amp;quot; and &amp;quot;When does one change topic?&amp;quot;
It will involve quite a lot of knowledge about the
potential listener and the world in general, which
might be extremely hard to implement, but which I
believe is necessary anyway, for other reasons as
well (see below).
</bodyText>
<subsectionHeader confidence="0.614925">
C. Natural Language—Understanding
</subsectionHeader>
<bodyText confidence="0.980748976190476">
It has been pointed out (Green (1983),
and references cited therein) that &amp;quot;communication
is not usefully thought of as a matter of decoding
someone&apos;s encryption of their thoughts, but is
better considered as a matter of guessing at what
someone has in mind, on the basis of clues
afforded by the way that person says what s/he
says&amp;quot;. Still, much work in linguistics relies on
the assumption that the meaning of a sentence can
be identified with its truth—conditions, and that
it can somehow be calculated from the meaning of
its parts [5], where the meanings of the words
themselves usually is left entirely untreated. But
again, this is a far cry from what a speaker can
be said to mean by uttering a sentence [6].
While some interesting work has been
done trying to recognize Gricean conventional
implicatures and presuppositions in a
computational, model—theoretical framework (Gunji,
1981), the particularized conversational
implicatures were left aside, and for a good
reason too. With the kind of approaches used
hitherto, they seem entirely untreatable.
Instead, I would say that understanding
language is very much a creative ability. To
understand what someone means by uttering some
sentence, is to construct a context where the
utterance fits in. This involves not only the
linguistic context (what has been said before) and
the extra—linguistic context (the speech
situation), but also the listener&apos;s knowledge
about the speaker and the world in general. It
also involves recognizing that every utterance is
made for a purpose. The speaker says what s/he
does rather than something else. The used mode of
expression (e g syntactic construction) was
selected, rather than some other. In this sense,
what is not said is as important as what is
actually said. Note that I said &amp;quot;a context&amp;quot; rather
than &amp;quot;the context&amp;quot;: one can do no more than guess
what the speaker had in mind, since it strictly is
impossible to know.
</bodyText>
<subsectionHeader confidence="0.441969">
D. Text Generation Revisited
</subsectionHeader>
<bodyText confidence="0.997977956521739">
A text generation system would also need
the same kind of creative ability, in order to
have some conception of how the listener will
interpret the message. This will of course affect
how the message is put forward. One does not say
what one believes the listener already knows, or
is uninterested in, and on the other hand, one
does not use words or syntactic constructions that
one believes the listener is unfamiliar with.
Since speakers generally will tend to avoid
stating the obvious, and at the same time say as
much as possible with as few words as possible,
conversational implicatures will be the rule,
rather than the exception.
For example, using words like &amp;quot;too&amp;quot; and
&amp;quot;also&amp;quot; means that the current sentence is to be
connected to something previous. Only in a few,
very obvious cases (such as the Commentator
examples above) will the &amp;quot;previous&amp;quot; sentence
actually have been stated. In most cases, the
speaker will rely on the listener&apos;s ability to
construct that sentence (or rather context) for
himself.
</bodyText>
<sectionHeader confidence="0.993839" genericHeader="method">
III CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999436043478261">
Does this paint too grim a picture of
the future for text generation and natural
language understanding systems? I don&apos;t think so.
I have just wanted to point out that unless quite
a lot of information about the world is included,
and a suitable Context Creating Mechanism is
constructed, these systems will never rise above
the phrase—book level, and any questions of
&amp;quot;naturalness&amp;quot; will be more or less irrelevant,
since what is discussed is something highly
artificial, namely a &amp;quot;speaker&amp;quot; with the grammar
and dictionary of an adult, but no knowledge of
the world whatsoever.
How is this Creative Mechanism supposed
to work? Well, that is the question that I intend
to explore. The concept of unification seems very
promising [7]. Unification is currently used in
several syntactic theories for the handling of
features, but I can see no reason why it shouldn&apos;t
be useful in handling semantics, discourse
structure and the connections with world—knowledge
as well. Any suggestions would be greatly
appreciated.
</bodyText>
<page confidence="0.994406">
350
</page>
<sectionHeader confidence="0.76079" genericHeader="conclusions">
NOTES
</sectionHeader>
<reference confidence="0.971659357142857">
[1] In this sense, something like &amp;quot;X is
approaching Y&amp;quot; is as much a state as &amp;quot;X is in
front of Y&amp;quot;.
[2] This is apart from an initial description of
the scene for a listener who can&apos;t see it for
himself, or is otherwise unfamiliar with it. Cf a
radio sports commentator, who would hardly descibe
what a tennis court looks like, or the general
rules of the game, but will probably say something
about who is playing, the weather and other
conditions, etc.
[3] Though closeness is of course not just a
physical property. Two people in love might be
said to be very close, even though they are
physically far apart. This is something, however,
that the Commentator would have to know, since
it&apos;s usually not immediately observable.
[4] For instance, if someone says &amp;quot;Nice weather
today, isn&apos;t it?&amp;quot;, you&apos;re supposed to answer &amp;quot;Yes&amp;quot;
no matter what you really think about the weather.
Not much information can be said to be exchanged.
[5] This is of course valuable in the sense that
it says that &amp;quot;John hit Bill&amp;quot; means that somebody
called John did something called hitting to
somebody called Bill, rather than vice versa.
[6] And, importantly, it is the speaker who means
something, and not the words used.
[7] Unification is an operation a bit like putting
</reference>
<bodyText confidence="0.9231235">
together two pieces of a jigsaw puzzle. They can
be fitted together (unified) if they have
something in common (some edge), and are then, for
all practical purposes, moved around as a single,
slightly larger piece. For an excellent
introduction to unification and its linguistic
applications see Karttunen (1984). Unification is
also very much at the heart of Prolog.
</bodyText>
<sectionHeader confidence="0.977502" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.9994282">
Fornell,Jan (1983): &amp;quot;Commentator — ett
mikrodatorbaserat forskningsredskap for
lingvister&amp;quot;, Praktisk lingvistik 8, Dept of
Linguistics, Lund University.
Green, Georgia M. (1983): Some Remarks on How
Words Mean, Indiana University Linguistics
Club, Bloomington, Indiana.
Gunji, Takao (1981): Toward a Computational
Theory of Pragmatics, Indiana University
Linguistics Club, Bloomington, Indiana.
Karttunen, Lauri (1984): &amp;quot;Features and Values&amp;quot;, in
this volume?
Sigurd, Bengt (1983): &amp;quot;Commentator: A Computer
Model of Verbal Production&amp;quot;, Linguistics
20-9/10.
</reference>
<page confidence="0.998674">
351
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.326915">
<title confidence="0.992039">WHAT NOT TO SAY</title>
<author confidence="0.999999">Jan Fornell</author>
<affiliation confidence="0.99995">Department of Linguistics &amp; Phonetics Lund University</affiliation>
<address confidence="0.987122">Helgonabacken 12. Lund, Sweden</address>
<abstract confidence="0.99538453008596">A problem with most text production and language generation systems is that they tend to become rather verbose. This may be due to neglection of the pragmatic factors involved in communication. In this paper, a text production system, COMMENTATOR, is described and taken as a starting point for a more general discussion of some problems in Computational Pragmatics. A new line of research is suggested, based on the concept of unification. I COMMENTATOR A. The original model General purpose The original version of Commentator was written in BASIC on a small micro computer. It was intended as a generator of text (rather than just sentences), but has in fact proved quite useful, in a somewhat more general sense, as a generator of linguistic problems, and is often thought of as a &amp;quot;linguistic research tool&amp;quot;. The idea was to create a model that worked at all levels, from &amp;quot;raw data&amp;quot; like perceptions and knowledge, via syntactic, semantic and pragmatic components to coherent text or in order to to study the various levels and the interaction between them at the same time. This means that the model is very narrow and &amp;quot;vertical&amp;quot;, rather than like most other computational models, which are usually characterized by huge databases at a single level of representation. 2. The model The system dynamically describes the movements and locations of a few objects on the computer screen. (In one version: two persons, called Adam and Eve, moving around in a yard with a gate and a tree. In another version, some ships outside a harbour). The comments are presented in Swedish or English in a written and a spoken version simultaneously (using a VOTRAX speech synthesis device). No real perceptive mechanism (such as a video camera) is included in the (instead it is successive coordinates of the moving objects) but otherwise all the other abovementioned components are present, to some extent. For both practical and intuitive reasons the system is &amp;quot;pragmatically deterministic&amp;quot; in some sense. By this I mean that a certain state of affairs is investigated only if it might lead to an expressible comment. For every change of the scene, potentially relevant and commentable topics are selected from a question menu. If something actually has happened (i e a change of state [1] has occurred), a syntactic rule is selected and words and phrases are put choice Is made between pronouns and other nounphrases, depending on the previous sentences. If a change of focus has occurred, contrastive stress is added the focus. Some &amp;quot;discourse connectives&amp;quot; ocksa(also/too) and heller(neither) are also added. There are apparently some more or less obligatory contexts for this, namely when all parts (predicates and arguments) of two sentences are equal except for one. For example &amp;quot;Adam is approaching the gate.&amp;quot; &amp;quot;Eve is also approaching it.&amp;quot; (predicates equal, but subjects different) &amp;quot;John hit Mary.&amp;quot; &amp;quot;He kicked her too.&amp;quot; (subjects and objects equal, but different predicates), etc. Stating the respective second sentences of the examples above without the also/too sounds highly unnatural. This is however only part of the truth (see below). Note that all selections of relevant topics and syntactic forms are made at an abstract level. Once words have begun being inserted, the sentence will be expressed, and it is never the case that a sentence is constructed, but not expressed. Neither are words first put in, and then deleted. This is in contrast with many other text production systems, where a range of sentences are constructed, and then compared to find the &amp;quot;best&amp;quot; way of expressing the proposition. That might be a possible approach when writing a (single) text, such as an instruction manual, or a like this, but it for dynamic text production in a changing environment like Commentator&apos;s. 348 A new A new version is currently being inplemented in Prolog on a VAX11/730, avoiding many of the drawbacks and limitations of the BASIC model. It is highly modular, and can easily be expanded in any given direction. It does not yet include any speech synthesis mechanism, but plans are being made to connect the system to the quite sophisticated ILS program package available at the department of linguistics. On the other hand, it does include some interactive components, and some facilities for (simple) machine translation within the specified domains, using Prolog as an intermediary level of representation. The major aim, however, is not to re—implement a slightly more sophisticated version of the original Commentator, which is basically a monologue generator, but instead to develop a new, highly interactive model, nick—named CONVERSATOR, in order to study the properties of human discourse. What will be described in the following, is mostly the original Commentator, though. II COMPUTATIONAL PRAGMATICS Strategiesin The previous presentation of Commentator of course raises some questions, such as &amp;quot;What is a relevant topic?&amp;quot; It is a well known fact, that for most text production systems it is a major problem to restrict the computer output — to get the computer to shut up, as it were, and avoid stating the obvious. In many cases this problem is not solved at all, and the system goes on to become quite verbose. On the other hand, Commentator was developed with this in mind. A major strategy has been to only comment on changes [27. Thus, for example, if Commentator notes that the object called Adam is approaching the object called the gate (where approach is defined as something like &amp;quot;moving in the direction of the goal, with diminishing distance&amp;quot; — this is not obvious, but perhaps a problem of pattern recognition rather than semantics), the system will say something like (1) &amp;quot;Adam is approaching the gate&amp;quot;. Then, if in the next few scenes he&apos;s still approaching the gate, nothing more need to be said about it. Only when something new happens, a comment will be generated, such as if Adam reaches the gate, which is what one might expect him to do sooner or later, if (1) is to be at all appropriate. Or if Adam suddenly reverses his direction, a slightly more drastic comment might be generated, such as (2) &amp;quot;Now he&apos;s moving away from it&amp;quot;. Note however, that the Commentator can only observe Adam&apos;s behaviour and make guesses about his intentions. Since he is not Adam himself, he can never know what Adam&apos;s real intentions are. He can never say what Adam is in fact doing, only what he thinks Adam is doing, and any presuppositions or implicatures conveyed are only those of his beliefs. Thus, uttering (1) somehow implicates that the Commentator believes that Adam is approaching the gate in order to reach it, but not that Adam is in fact doing so. This might be quite important. Another criterion for relevance is nearness. It seems reasonable to talk about objects in relation to other objects close by [3], rather than to objects further away. For instance, if Adam is close to the gate, but the tree is on the other side of the yard, it would probably make more sense to say (3) than (4), even though they may be equally true. (3) Adam is approaching the gate. (4) Adam is moving away from the tree. All of this, of course, presupposes that it is sensible to talk about these things at all, and this is not obvious. What is a text generation system supposed to do, really? talk? Expert systems require some kind of text generation module to be able to present output in a comprehensible way. This means that the input to the system (some set of data) is fairly well—known, as well as the desired format of the output. But this means that the quality of the output can only be measured against how well it meets the pre—determined standards. There is obviously much more to human communication than that. I believe that the serious limitations and unnaturalness of existing text generation systems (whether they are included in an expert system or not. There aren&apos;t really many of the latter type.) cannot be overcome, unless a certain important question is asked, namely &amp;quot;Why ever say anything at all?&amp;quot; Two different dimensions can be recognized. One is prompted vs spontaneous speech, and the other is the informative content. At one end of the information scale is talk that contains almost no information at all, as most talk about the weather. This usually a very ritualized behaviour [4], and is quite different from the exchange of data, which characterizes most interactions with computers and would be the other end of the scale. 349 Aside from the abovementioned kind of social interaction, it seems that one talks when one is in possession of some information, and believes that the listener—to—be is interested in this information. The most obvious case is when a question has been asked, or the speaker otherwise has been prompted. In fact, this is the only case that text generation systems ever seem to take care of. Expert systems speak only when spoken to. The Commentator is made to talk about what&apos;s happening, assuming that someone is listening, and interested in what it says. But for a conversating system this is not enough. The properties of spontaneous speech has to be investigated, in order to address questions like &amp;quot;When does one volunteer information?&amp;quot;, &amp;quot;When does one initiate a conversation?&amp;quot; and &amp;quot;When does one change topic?&amp;quot; It will involve quite a lot of knowledge about the potential listener and the world in general, which might be extremely hard to implement, but which I believe is necessary anyway, for other reasons as well (see below). NaturalLanguage—Understanding It has been pointed out (Green (1983), and references cited therein) that &amp;quot;communication is not usefully thought of as a matter of decoding someone&apos;s encryption of their thoughts, but is better considered as a matter of guessing at what someone has in mind, on the basis of clues afforded by the way that person says what s/he says&amp;quot;. Still, much work in linguistics relies on the assumption that the meaning of a sentence can be identified with its truth—conditions, and that it can somehow be calculated from the meaning of its parts [5], where the meanings of the words themselves usually is left entirely untreated. But again, this is a far cry from what a speaker can be said to mean by uttering a sentence [6]. While some interesting work has been done trying to recognize Gricean conventional implicatures and presuppositions in a computational, model—theoretical framework (Gunji, 1981), the particularized conversational implicatures were left aside, and for a good reason too. With the kind of approaches used hitherto, they seem entirely untreatable. Instead, I would say that understanding language is very much a creative ability. To understand what someone means by uttering some sentence, is to construct a context where the utterance fits in. This involves not only the linguistic context (what has been said before) and the extra—linguistic context (the speech but also listener&apos;s knowledge about the speaker and the world in general. It also involves recognizing that every utterance is made for a purpose. The speaker says what s/he does rather than something else. The used mode of expression (e g syntactic construction) was selected, rather than some other. In this sense, what is not said is as important as what is actually said. Note that I said &amp;quot;a context&amp;quot; rather than &amp;quot;the context&amp;quot;: one can do no more than guess what the speaker had in mind, since it strictly is impossible to know. Generation Revisited A text generation system would also need the same kind of creative ability, in order to have some conception of how the listener will interpret the message. This will of course affect how the message is put forward. One does not say what one believes the listener already knows, or is uninterested in, and on the other hand, one does not use words or syntactic constructions that one believes the listener is unfamiliar with. Since speakers generally will tend to avoid stating the obvious, and at the same time say as much as possible with as few words as possible, conversational implicatures will be the rule, rather than the exception. For example, using words like &amp;quot;too&amp;quot; and &amp;quot;also&amp;quot; means that the current sentence is to be connected to something previous. Only in a few, very obvious cases (such as the Commentator examples above) will the &amp;quot;previous&amp;quot; sentence actually have been stated. In most cases, the speaker will rely on the listener&apos;s ability to construct that sentence (or rather context) for himself. III CONCLUSIONS Does this paint too grim a picture of the future for text generation and natural language understanding systems? I don&apos;t think so. I have just wanted to point out that unless quite a lot of information about the world is included, and a suitable Context Creating Mechanism is constructed, these systems will never rise above the phrase—book level, and any questions of &amp;quot;naturalness&amp;quot; will be more or less irrelevant, since what is discussed is something highly artificial, namely a &amp;quot;speaker&amp;quot; with the grammar and dictionary of an adult, but no knowledge of the world whatsoever. How is this Creative Mechanism supposed to work? Well, that is the question that I intend to explore. The concept of unification seems very promising [7]. Unification is currently used in several syntactic theories for the handling of features, but I can see no reason why it shouldn&apos;t be useful in handling semantics, discourse structure and the connections with world—knowledge as well. Any suggestions would be greatly appreciated. 350 NOTES [1] In this sense, something like &amp;quot;X is approaching Y&amp;quot; is as much a state as &amp;quot;X is in front of Y&amp;quot;. [2] This is apart from an initial description of the scene for a listener who can&apos;t see it for himself, or is otherwise unfamiliar with it. Cf a radio sports commentator, who would hardly descibe what a tennis court looks like, or the general rules of the game, but will probably say something about who is playing, the weather and other conditions, etc. [3] Though closeness is of course not just a physical property. Two people in love might be said to be very close, even though they are physically far apart. This is something, however, that the Commentator would have to know, since it&apos;s usually not immediately observable. [4] For instance, if someone says &amp;quot;Nice weather today, isn&apos;t it?&amp;quot;, you&apos;re supposed to answer &amp;quot;Yes&amp;quot; no matter what you really think about the weather. Not much information can be said to be exchanged. [5] This is of course valuable in the sense that it says that &amp;quot;John hit Bill&amp;quot; means that somebody called John did something called hitting to somebody called Bill, rather than vice versa. [6] And, importantly, it is the speaker who means something, and not the words used. [7] Unification is an operation a bit like putting together two pieces of a jigsaw puzzle. They can be fitted together (unified) if they have something in common (some edge), and are then, for all practical purposes, moved around as a single, slightly larger piece. For an excellent</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>In this sense, something like &amp;quot;X is approaching Y&amp;quot; is as much a state as &amp;quot;X is in front of Y&amp;quot;.</title>
<contexts>
<context position="2435" citStr="[1]" startWordPosition="401" endWordPosition="401">ptive mechanism (such as a video camera) is included in the system, (instead it is fed the successive coordinates of the moving objects) but otherwise all the other abovementioned components are present, to some extent. For both practical and intuitive reasons the system is &amp;quot;pragmatically deterministic&amp;quot; in some sense. By this I mean that a certain state of affairs is investigated only if it might lead to an expressible comment. For every change of the scene, potentially relevant and commentable topics are selected from a question menu. If something actually has happened (i e a change of state [1] has occurred), a syntactic rule is selected and appropriate words and phrases are put in. A choice Is made between pronouns and other nounphrases, depending on the previous sentences. If a change of focus has occurred, contrastive stress is added to the new. focus. Some &amp;quot;discourse connectives&amp;quot; like ocksa (also/too) and heller (neither) are also added. There are apparently some more or less obligatory contexts for this, namely when all parts (predicates and arguments) of two sentences are equal except for one. For example &amp;quot;Adam is approaching the gate.&amp;quot; &amp;quot;Eve is also approaching it.&amp;quot; (predicate</context>
</contexts>
<marker>[1]</marker>
<rawString>In this sense, something like &amp;quot;X is approaching Y&amp;quot; is as much a state as &amp;quot;X is in front of Y&amp;quot;.</rawString>
</citation>
<citation valid="false">
<title>This is apart from an initial description of the scene for a listener who can&apos;t see it for himself, or is otherwise unfamiliar with it. Cf a radio sports commentator, who would hardly descibe what a tennis court looks like, or the general rules of the game, but will probably say something about who is playing, the weather and other conditions,</title>
<pages>etc.</pages>
<marker>[2]</marker>
<rawString>This is apart from an initial description of the scene for a listener who can&apos;t see it for himself, or is otherwise unfamiliar with it. Cf a radio sports commentator, who would hardly descibe what a tennis court looks like, or the general rules of the game, but will probably say something about who is playing, the weather and other conditions, etc.</rawString>
</citation>
<citation valid="false">
<title>Though closeness is of course not just a physical property. Two people in love might be said to be very close, even though they are physically far apart. This is something, however, that the Commentator would have to know, since it&apos;s usually not immediately observable.</title>
<contexts>
<context position="7113" citStr="[3]" startWordPosition="1177" endWordPosition="1177">esses about his intentions. Since he is not Adam himself, he can never know what Adam&apos;s real intentions are. He can never say what Adam is in fact doing, only what he thinks Adam is doing, and any presuppositions or implicatures conveyed are only those of his beliefs. Thus, uttering (1) somehow implicates that the Commentator believes that Adam is approaching the gate in order to reach it, but not that Adam is in fact doing so. This might be quite important. 2. Nearness Another criterion for relevance is nearness. It seems reasonable to talk about objects in relation to other objects close by [3], rather than to objects further away. For instance, if Adam is close to the gate, but the tree is on the other side of the yard, it would probably make more sense to say (3) than (4), even though they may be equally true. (3) Adam is approaching the gate. (4) Adam is moving away from the tree. All of this, of course, presupposes that it is sensible to talk about these things at all, and this is not obvious. What is a text generation system supposed to do, really? B. Why talk? Expert systems require some kind of text generation module to be able to present output in a comprehensible way. This </context>
</contexts>
<marker>[3]</marker>
<rawString>Though closeness is of course not just a physical property. Two people in love might be said to be very close, even though they are physically far apart. This is something, however, that the Commentator would have to know, since it&apos;s usually not immediately observable.</rawString>
</citation>
<citation valid="false">
<title>For instance, if someone says &amp;quot;Nice weather today, isn&apos;t it?&amp;quot;, you&apos;re supposed to answer &amp;quot;Yes&amp;quot; no matter what you really think about the weather. Not much information can be said to be exchanged.</title>
<contexts>
<context position="8616" citStr="[4]" startWordPosition="1442" endWordPosition="1442"> that. I believe that the serious limitations and unnaturalness of existing text generation systems (whether they are included in an expert system or not. There aren&apos;t really many of the latter type.) cannot be overcome, unless a certain important question is asked, namely &amp;quot;Why ever say anything at all?&amp;quot; Two different dimensions can be recognized. One is prompted vs spontaneous speech, and the other is the informative content. At one end of the information scale is talk that contains almost no information at all, such as most talk about the weather. This is usually a very ritualized behaviour [4], and is quite different from the exchange of data, which characterizes most interactions with computers and would be the other end of the scale. 349 Aside from the abovementioned kind of social interaction, it seems that one talks when one is in possession of some information, and believes that the listener—to—be is interested in this information. The most obvious case is when a question has been asked, or the speaker otherwise has been prompted. In fact, this is the only case that text generation systems ever seem to take care of. Expert systems speak only when spoken to. The Commentator is </context>
</contexts>
<marker>[4]</marker>
<rawString>For instance, if someone says &amp;quot;Nice weather today, isn&apos;t it?&amp;quot;, you&apos;re supposed to answer &amp;quot;Yes&amp;quot; no matter what you really think about the weather. Not much information can be said to be exchanged.</rawString>
</citation>
<citation valid="false">
<title>This is of course valuable in the sense that it says that &amp;quot;John hit Bill&amp;quot; means that somebody called John did something called hitting to somebody called Bill, rather than vice versa.</title>
<contexts>
<context position="10374" citStr="[5]" startWordPosition="1735" endWordPosition="1735">r reasons as well (see below). C. Natural Language—Understanding It has been pointed out (Green (1983), and references cited therein) that &amp;quot;communication is not usefully thought of as a matter of decoding someone&apos;s encryption of their thoughts, but is better considered as a matter of guessing at what someone has in mind, on the basis of clues afforded by the way that person says what s/he says&amp;quot;. Still, much work in linguistics relies on the assumption that the meaning of a sentence can be identified with its truth—conditions, and that it can somehow be calculated from the meaning of its parts [5], where the meanings of the words themselves usually is left entirely untreated. But again, this is a far cry from what a speaker can be said to mean by uttering a sentence [6]. While some interesting work has been done trying to recognize Gricean conventional implicatures and presuppositions in a computational, model—theoretical framework (Gunji, 1981), the particularized conversational implicatures were left aside, and for a good reason too. With the kind of approaches used hitherto, they seem entirely untreatable. Instead, I would say that understanding language is very much a creative abil</context>
</contexts>
<marker>[5]</marker>
<rawString>This is of course valuable in the sense that it says that &amp;quot;John hit Bill&amp;quot; means that somebody called John did something called hitting to somebody called Bill, rather than vice versa.</rawString>
</citation>
<citation valid="false">
<authors>
<author>importantly And</author>
</authors>
<title>it is the speaker who means something, and not the words used.</title>
<contexts>
<context position="10550" citStr="[6]" startWordPosition="1768" endWordPosition="1768">t of as a matter of decoding someone&apos;s encryption of their thoughts, but is better considered as a matter of guessing at what someone has in mind, on the basis of clues afforded by the way that person says what s/he says&amp;quot;. Still, much work in linguistics relies on the assumption that the meaning of a sentence can be identified with its truth—conditions, and that it can somehow be calculated from the meaning of its parts [5], where the meanings of the words themselves usually is left entirely untreated. But again, this is a far cry from what a speaker can be said to mean by uttering a sentence [6]. While some interesting work has been done trying to recognize Gricean conventional implicatures and presuppositions in a computational, model—theoretical framework (Gunji, 1981), the particularized conversational implicatures were left aside, and for a good reason too. With the kind of approaches used hitherto, they seem entirely untreatable. Instead, I would say that understanding language is very much a creative ability. To understand what someone means by uttering some sentence, is to construct a context where the utterance fits in. This involves not only the linguistic context (what has </context>
</contexts>
<marker>[6]</marker>
<rawString>And, importantly, it is the speaker who means something, and not the words used.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M</author>
</authors>
<title>Unification is an operation a bit like putting Fornell,Jan</title>
<date>1983</date>
<journal>Linguistics</journal>
<pages>20--9</pages>
<institution>Indiana University Linguistics Club,</institution>
<location>Lund University. Green, Georgia</location>
<marker>[7]</marker>
<rawString>Unification is an operation a bit like putting Fornell,Jan (1983): &amp;quot;Commentator — ett mikrodatorbaserat forskningsredskap for lingvister&amp;quot;, Praktisk lingvistik 8, Dept of Linguistics, Lund University. Green, Georgia M. (1983): Some Remarks on How Words Mean, Indiana University Linguistics Club, Bloomington, Indiana. Gunji, Takao (1981): Toward a Computational Theory of Pragmatics, Indiana University Linguistics Club, Bloomington, Indiana. Karttunen, Lauri (1984): &amp;quot;Features and Values&amp;quot;, in this volume? Sigurd, Bengt (1983): &amp;quot;Commentator: A Computer Model of Verbal Production&amp;quot;, Linguistics 20-9/10.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>