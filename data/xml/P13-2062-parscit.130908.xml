<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002178">
<title confidence="0.988354">
Automatically Predicting Sentence Translation Difficulty
</title>
<author confidence="0.992212">
Abhijit Mishra*, Pushpak Bhattacharyya*, Michael Carl†
</author>
<affiliation confidence="0.982863">
* Department of Computer Science and Engineering, IIT Bombay, India
</affiliation>
<email confidence="0.974555">
{abhijitmishra,pb}@cse.iitb.ac.in
</email>
<note confidence="0.706972">
† CRITT, IBC, Copenhagen Business School, Denmark,
</note>
<email confidence="0.99302">
mc.ibc@cbs.dk
</email>
<sectionHeader confidence="0.997335" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999591818181818">
In this paper we introduce Translation Dif-
ficulty Index (TDI), a measure of diffi-
culty in text translation. We first de-
fine and quantify translation difficulty in
terms of TDI. We realize that any mea-
sure of TDI based on direct input by trans-
lators is fraught with subjectivity and ad-
hocism. We, rather, rely on cognitive ev-
idences from eye tracking. TDI is mea-
sured as the sum of fixation (gaze) and
saccade (rapid eye movement) times of
the eye. We then establish that TDI is
correlated with three properties of the in-
put sentence, viz. length (L), degree of
polysemy (DP) and structural complexity
(SC). We train a Support Vector Regres-
sion (SVR) system to predict TDIs for
new sentences using these features as in-
put. The prediction done by our frame-
work is well correlated with the empiri-
cal gold standard data, which is a repos-
itory of &lt; L, DP, SC &gt; and TDI pairs
for a set of sentences. The primary use of
our work is a way of “binning” sentences
(to be translated) in “easy”, “medium” and
“hard” categories as per their predicted
TDI. This can decide pricing of any trans-
lation task, especially useful in a scenario
where parallel corpora for Machine Trans-
lation are built through translation crowd-
sourcing/outsourcing. This can also pro-
vide a way of monitoring progress of sec-
ond language learners.
</bodyText>
<sectionHeader confidence="0.999628" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999239142857143">
Difficulty in translation stems from the fact that
most words are polysemous and sentences can be
long and have complex structure. While length of
sentence is commonly used as a translation diffi-
culty indicator, lexical and structural properties of
a sentence also contribute to translation difficulty.
Consider the following example sentences.
</bodyText>
<listItem confidence="0.9930855">
1. The camera-man shot the policeman
with a gun. (length-8)
2. I was returning from my old office
yesterday. (length-8)
</listItem>
<bodyText confidence="0.999774735294118">
Clearly, sentence 1 is more difficult to process
and translate than sentence 2, since it has lexical
ambiguity (“Shoot” as an act of firing a shot or
taking a photograph?) and structural ambiguity
(Shot with a gun or policeman with a gun?). To
produce fluent and adequate translations, efforts
have to be put to analyze both the lexical and syn-
tactic properties of the sentences.
The most recent work on studying translation
difficulty is by Campbell and Hale (1999) who
identified several areas of difficulty in lexis and
grammar. “Reading” researchers have focused on
developing readability formulae, since 1970. The
Flesch-Kincaid Readability test (Kincaid et al.,
1975), the Fry Readability Formula (Fry, 1977)
and the Dale-Chall readability formula (Chall and
Dale, 1999) are popular and influential. These for-
mulae use factors such as vocabulary difficulty (or
semantic factors) and sentence length (or syntac-
tic factors). In a different setting, Malsburg et
al. (2012) correlate eye fixations and scanpaths
of readers with sentence processing. While these
approaches are successful in quantifying readabil-
ity, they may not be applicable to translation sce-
narios. The reason is that, translation is not
merely a reading activity. Translation requires
co-ordination between source text comprehension
and target text production (Dragsted, 2010). To
the best of our knowledge, our work on predicting
TDI is the first of its kind.
The motivation of the work is as follows. Cur-
rently, for domain specific Machine Translation
systems, parallel corpora are gathered through
translation crowdsourcing/outsourcing. In such
</bodyText>
<page confidence="0.989003">
346
</page>
<note confidence="0.626893">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 346–351,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.98317">
Figure 1: Inherent sentence complexity and per-
ceived difficulty during translation
</figureCaption>
<bodyText confidence="0.997096">
a scenario, translators are paid on the basis of
sentence length, which ignores other factors con-
tributing to translation difficulty, as stated above.
Our proposed Translation Difficulty Index (TDI)
quantifies the translation difficulty of a sentence
considering both lexical and structural proper-
ties. This measure can, in turn, be used to clus-
ter sentences according to their difficulty levels
(viz. easy, medium, hard). Different payment and
schemes can be adopted for different such clusters.
TDI can also be useful for training and evalu-
ating second language learners. For example, ap-
propriate examples at particular levels of difficulty
can be chosen for giving assignments and monitor-
ing progress.
The rest of the paper is organized in the fol-
lowing way. Section 2 describes TDI as func-
tion of translation processing time. Section 3 is
on measuring translation processing time through
eye tracking. Section 4 gives the correlation of
linguistic complexity with observed TDI. In sec-
tion 5, we describe a technique for predicting TDIs
and ranking unseen sentences using Support Vec-
tor Machines. Section 6 concludes the paper with
pointers to future work.
</bodyText>
<sectionHeader confidence="0.916626" genericHeader="method">
2 Quantifying Translation Difficulty
</sectionHeader>
<bodyText confidence="0.999922315789474">
As a first approximation, TDI of a sentence can
be the time taken to translate the sentence, which
can be measured through simple translation exper-
iments. This is based on the assumption that more
difficult sentences will require more time to trans-
late. However, “time taken to translate” may not
be strongly related to the translation difficulty for
two reasons. First, it is difficult to know what
fraction of the total translation time is actually
spent on the translation-related-thinking. For ex-
ample, translators may spend considerable amount
of time typing/writing translations, which is ir-
relevant to the translation difficulty. Second, the
translation time is sensitive to distractions from
the environment. So, instead of the “time taken
to translate”, we are more interested in the “time
for which translation related processing is carried
out by the brain”. This can be termed as the Trans-
lation Processing Time (Tp). Mathematically,
</bodyText>
<equation confidence="0.589302">
Tp = Tp comp + Tp gen (1)
</equation>
<bodyText confidence="0.9959305">
Where Tp comp and Tp gen are the processing times
for source text comprehension and target text gen-
eration respectively. The empirical TDI, is com-
puted by normalizing Tp with sentence length.
</bodyText>
<equation confidence="0.989373666666667">
TDI =
Tp (2)
sentencelength
</equation>
<bodyText confidence="0.968159666666667">
Measuring Tp is a difficult task as translators of-
ten switch between thinking and writing activities.
Here comes the role of eye tracking.
</bodyText>
<sectionHeader confidence="0.878641" genericHeader="method">
3 Measuring Tp by eye-tracking
</sectionHeader>
<bodyText confidence="0.9936625">
We measure Tp by analyzing the gaze behavior
of translators through eye-tracking. The rationale
behind using eye-tracking is that, humans spend
time on what they see, and this “time” is corre-
lated with the complexity of the information being
processed, as shown in Figure 1. Two fundamental
components of eye behavior are (a) Gaze-fixation
or simply, Fixation and (b) Saccade. The former
is a long stay of the visual gaze on a single loca-
tion. The latter is a very rapid movement of the
eyes between positions of rest. An intuitive feel
for these two concepts can be had by consider-
ing the example of translating the sentence The
camera-man shot the policeman with a gun men-
tioned in the introduction. It is conceivable that
the eye will linger long on the word “shot” which
is ambiguous and will rapidly move across “shot”,
“camera-man” and “gun” to ascertain the clue for
disambiguation.
The terms Tp comp and Tp gen in (1) can now be
looked upon as the sum of fixation and saccadic
durations for both source and target sentences re-
spectively.
Modifying 1
</bodyText>
<equation confidence="0.985070666666667">
�Tp = dur(f) + � dur(s)
fEF3 sES3
+ � dur(f) + �
fEFt sESt
(3)
dur(s)
</equation>
<page confidence="0.993742">
347
</page>
<figureCaption confidence="0.9384">
Figure 2: Screenshot of Translog. The circles rep-
</figureCaption>
<bodyText confidence="0.939332166666667">
resent fixations and arrow represent saccades.
Here, Fs and Ss correspond to sets of fixations and
saccades for source sentence and Ft and St corre-
spond to those for the target sentence respectively.
dur is a function returning the duration of fixations
and saccades.
</bodyText>
<subsectionHeader confidence="0.942627">
3.1 Computing TDI using eye-tracking
</subsectionHeader>
<bodyText confidence="0.996714258064516">
database
We obtained TDIs for a set of sentences from
the Translation Process Research Database (TPR
1.0)(Carl, 2012). The database contains trans-
lation studies for which gaze data is recorded
through the Translog software1(Carl, 2012). Fig-
ure 2 presents a screendump of Translog. Out of
the 57 available sessions, we selected 40 transla-
tion sessions comprising 80 sentence translations2.
Each of these 80 sentences was translated from
English to three different languages, viz. Span-
ish, Danish and Hindi by at least 2 translators.
The translators were young professional linguists
or students pursuing PhD in linguistics.
The eye-tracking data is noisy and often ex-
hibits systematic errors (Hornof and Halverson,
2002). To correct this, we applied automatic er-
ror correction technique (Mishra et al., 2012) fol-
lowed by manually correcting incorrect gaze-to-
word mapping using Translog. Note that, gaze and
saccadic durations may also depend on the transla-
tor’s reading speed. We tried to rule out this effect
by sampling out translations for which the vari-
ance in participant’s reading speed is minimum.
Variance in reading speed was calculated after tak-
ing a samples of source text for each participant
and measuring the time taken to read the text.
After preprocessing the data, TDI was com-
puted for each sentence by using (2) and (3).The
observed unnormalized TDI score3 ranges from
0.12 to 0.86. We normalize this to a [0,1] scale
</bodyText>
<footnote confidence="0.9965278">
1http://www.translog.dk
220% of the translation sessions were discarded as it was
difficult to rectify the gaze logs for these sessions.
3Anything beyond the upper bound is hard to translate and
can be assigned with the maximum score.
</footnote>
<figureCaption confidence="0.955967">
Figure 3: Dependency graph used for computing
SC
</figureCaption>
<bodyText confidence="0.982058416666667">
using MinMax normalization.
If the “time taken to translate” and Tp were
strongly correlated, we would have rather opted
“time taken to translate” for the measurement of
TDI. The reason is that “time taken to translate”
is relatively easy to compute and does not require
expensive setup for conducting “eye-tracking” ex-
periments. But our experiments show that there
is a weak correlation (coefficient = 0.12) between
“time taken to translate” and Tp. This makes us
believe that Tp is still the best option for TDI mea-
surement.
</bodyText>
<sectionHeader confidence="0.994534" genericHeader="method">
4 Relating TDI to sentence features
</sectionHeader>
<bodyText confidence="0.999075666666667">
Our claim is that translation difficulty is mainly
caused by three features: Length, Degree of Poly-
semy and Structural Complexity.
</bodyText>
<subsectionHeader confidence="0.977525">
4.1 Length
</subsectionHeader>
<bodyText confidence="0.9997995">
It is the total number of words occurring in a sen-
tence.
</bodyText>
<subsectionHeader confidence="0.997938">
4.2 Degree of Polysemy (DP)
</subsectionHeader>
<bodyText confidence="0.999489">
The degree of polysemy of a sentence is the sum of
senses possessed by each word in the Wordnet nor-
malized by the sentence length. Mathematically,
</bodyText>
<equation confidence="0.894593666666667">
DP EwEW Senses(w) 4
sentence — length (sentence)
( )
</equation>
<bodyText confidence="0.999627">
Here, Senses(w) retrieves the total number senses
of a word P from the Wordnet. W is the set of
words appearing in the sentence.
</bodyText>
<subsectionHeader confidence="0.997192">
4.3 Structural Complexity (SC)
</subsectionHeader>
<bodyText confidence="0.998220166666667">
Syntactically, words, phrases and clauses are at-
tached to each other in a sentence. If the attach-
ment units lie far from each other, the sentence
has higher structural complexity. Lin (1996) de-
fines it as the total length of dependency links in
the dependency structure of the sentence.
</bodyText>
<page confidence="0.997577">
348
</page>
<figureCaption confidence="0.698234454545454">
Figure 4: Prediction of TDI using linguistic prop-
erties such as Length(L), Degree of Polysemy
(DP) and Structural Complexity (SC)
Example: The man who the boy attacked
escaped.
Figure 3 shows the dependency graph for the
example sentence. The weights of the edges cor-
respond how far the two connected words lie from
each other in the sentence. Using Lin’s formula,
the SC score for the example sentence turns out to
be 15.
</figureCaption>
<bodyText confidence="0.9708722">
Lin’s way of computing SC is affected by sen-
tence length since the number of dependency links
for a sentence depends on its length. So we nor-
malize SC by the length of the sentence. After
normalization, the SC score for the example given
becomes 15/7 = 2.14
4.4 How are TDI and linguistic features
related
To validate that translation difficulty depends on
the above mentioned linguistic features, we tried
to find out the correlation coefficients between
each feature and empirical TDI. We extracted
three sets of sample sentences. For each sample,
sentence selection was done with a view to vary-
ing one feature, keeping the other two constant.
The Correlation Coefficients between L, DP and
SC and the empirical TDI turned out to be 0.72,
0.41 and 0.63 respectively. These positive correla-
tion coefficients indicate that all the features con-
tribute to the translation difficulty.
</bodyText>
<sectionHeader confidence="0.962122" genericHeader="method">
5 Predicting TDI
</sectionHeader>
<bodyText confidence="0.990036857142857">
Our system predicts TDI from the linguistic prop-
erties of a sentence as shown in Figure 4.
The prediction happens in a supervised setting
through regression. Training such a system re-
quires a set sentences annotated with TDIs. In
our case, direct annotation of TDI is a difficult and
unintuitive task. So, we annotate TDI by observ-
</bodyText>
<table confidence="0.960386">
Kernel(C=3.0) MSE (%) Correlation
Linear 20.64 0.69
Poly (Deg 2) 12.88 0.81
Poly (Deg 3) 13.35 0.78
Rbf (default) 13.32 0.73
</table>
<tableCaption confidence="0.992814">
Table 1: Relative MSE and Correlation with ob-
served data for different kernels used for SVR.
</tableCaption>
<bodyText confidence="0.9772186">
ing translator’s behavior (using equations (1) and
(2))instead of asking people to rate sentences with
TDI.
We are now prepared to give the regression sce-
nario for predicting TDI.
</bodyText>
<subsectionHeader confidence="0.998735">
5.1 Preparing the dataset
</subsectionHeader>
<bodyText confidence="0.999905333333333">
Our dataset contains 80 sentences for which TDI
have been measured (Section 3.1). We divided this
data into 10 sets of training and testing datasets in
order to carry out a 10-fold evaluation. DP and SC
features were computed using Princeton Wordnet4
and Stanford Dependence Parser5.
</bodyText>
<subsectionHeader confidence="0.999734">
5.2 Applying Support Vector Regression
</subsectionHeader>
<bodyText confidence="0.999880083333333">
To predict TDI, Support Vector Regression (SVR)
technique (Joachims et al., 1999) was preferred
since it facilitates multiple kernel-based methods
for regression. We tried using different kernels us-
ing default parameters. Error analysis was done
by means of Mean Squared Error estimate (MSE).
We also measured the Pearson correlation coeffi-
cient between the empirical and predicted TDI for
our test-sets.
Table 1 indicates Mean Square Error percent-
ages for different kernel methods used for SVR.
MSE (%) indicates by what percentage the pre-
dicted TDIs differ from the observed TDIs. In our
setting, quadratic polynomial kernel with c=3.0
outperforms other kernels. The predicted TDIs are
well correlated with the empirical TDIs. This tells
us that even if the predicted scores are not as ac-
curate as desired, the system is capable of ranking
sentences in correct order. Table 2 presents exam-
ples from the test dataset for which the observed
TDI (TDIO) and the TDI predicted by polynomial
kernel based SVR (TDIP) are shown.
Our larger goal is to group unknown sentences
into different categories by the level of transla-
</bodyText>
<footnote confidence="0.992811666666667">
4http://www.wordnet.princeton.edu
5http://www.nlp.stanford.edu/software/
lex-parser.html
</footnote>
<page confidence="0.995976">
349
</page>
<reference confidence="0.5095045">
Example L DP SC TDIp TDIp Error
1. American Express recently
announced a second round
of job cuts.
2. Sociology is a relatively
new academic discipline.
</reference>
<table confidence="0.8731365">
10 10 1.8 0.24 0.23 4%
7 6 3.7 0.49 0.53 8%
</table>
<tableCaption confidence="0.998117">
Table 2: Example sentences from the test dataset.
</tableCaption>
<bodyText confidence="0.999966166666666">
tion difficulty. For that, we tried to manually as-
sign three different class labels to sentences viz.
easy, medium and hard based on the empirical
TDI scores. The ranges of scores chosen for easy,
medium and hard categories were [0-0.3], [0.3-
0.75] and [0.75-1.0] respectively (by trial and er-
ror). Then we trained a Support Vector Rank
(Joachims, 2006) with default parameters using
different kernel methods. The ranking framework
achieves a maximum 67.5% accuracy on the test
data. The accuracy should increase by adding
more data to the training dataset.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999973611111111">
This paper introduces an approach to quantify-
ing translation difficulty and automatically assign-
ing difficulty levels to unseen sentences. It estab-
lishes a relationship between the intrinsic senten-
tial properties, viz., length (L), degree ofpolysemy
(DP) and structural complexity (SC), on one hand
and the Translation Difficulty Index (TDI), on the
other. Future work includes deeper investigation
into other linguistic factors such as presence of do-
main specific terms, target language properties etc.
and applying more sophisticated cognitive analy-
sis techniques for more reliable TDI score. We
would like to make use of inter-annotator agree-
ment to decide the boundaries for the translation
difficulty categories. Extending the study to differ-
ent language pairs and studying the applicability
of this technique for Machine Translation Quality
Estimation are also on the agenda.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999156">
We would like to thank the CRITT, CBS group for
their help in manual correction of TPR data. In
particular, thanks to Barto Mesa and Khristina for
helping with Spanish and Danish dataset correc-
tions.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99973465">
Campbell, S., and Hale, S. 1999. What makes a text
difficult to translate? Refereed Proceedings of the
23rd Annual ALAA Congress.
Carl, M. 2012. Translog-II: A Program for Record-
ing User Activity Data for Empirical Reading and
Writing Research In Proceedings of the Eight In-
ternational Conference on Language Resources and
Evaluation, European Language Resources Associ-
ation (ELRA)
Carl, M. 2012 The CRITT TPR-DB 1.0: A Database
for Empirical Human Translation Process Research.
AMTA 2012 Workshop on Post-Editing Technology
and Practice (WPTP-2012).
Chall, J. S., and Dale, E. 1995. Readability revisited:
the new Dale-Chall readability formula Cambridge,
Mass.: Brookline Books.
Dragsted, B. 2010. Co-ordination of reading andwrit-
ing processes in translation. Contribution to Trans-
lation and Cognition, Shreve, G. and Angelone,
E.(eds.)Cognitive Science Society.
Fry, E. 1977 Fry’s readability graph: Clarification,
validity, and extension to level 17 Journal of Read-
ing, 21(3), 242-252.
Hornof, A. J. and Halverson, T. 2002 Cleaning up sys-
tematic error in eye-tracking data by using required
fixation locations. Behavior Research Methods, In-
struments, and Computers, 34, 592604.
Joachims, T., Schlkopf, B. ,Burges, C and A. Smola
(ed.). 1999. Making large-Scale SVM Learning
Practical. Advances in Kernel Methods - Support
Vector Learning. MIT-Press, 1999,
Joachims, T. 2006 Training Linear SVMs in Lin-
ear Time Proceedings of the ACM Conference on
Knowledge Discovery and Data Mining (KDD).
Kincaid, J. P., Fishburne, R. P., Jr., Rogers, R. L., and
Chissom, B. S. 1975. Derivation of New Read-
ability Formulas (Automated Readability Index, Fog
Count and Flesch Reading Ease Formula) for Navy
Enlisted Personnel Millington, Tennessee: Naval
Air Station Memphis,pp. 8-75.
</reference>
<page confidence="0.964854">
350
</page>
<reference confidence="0.999335444444444">
Lin, D. 1996 On the structural complexity of natural
language sentences. Proceeding of the 16th Inter-
national Conference on Computational Linguistics
(COLING), pp. 729733.
Mishra, A., Carl, M, Bhattacharyya, P. 2012 A
heuristic-based approach for systematic error cor-
rection of gaze datafor reading. In MichaelCarl, P.B.
and Choudhary, K.K., editors, Proceedings of the
First Workshop on Eye-tracking and Natural Lan-
guage Processing, Mumbai, India. The COLING
2012 Organizing Committee
von der Malsburg, T., Vasishth, S., and Kliegl, R. 2012
Scanpaths in reading are informative about sen-
tence processing. In MichaelCarl, P.B. and Choud-
hary, K.K., editors, Proceedings of the First Work-
shop on Eye-tracking and Natural Language Pro-
cessing, Mumbai, India. The COLING 2012 Orga-
nizing Committee
</reference>
<page confidence="0.998658">
351
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.881365">
<title confidence="0.999045">Automatically Predicting Sentence Translation Difficulty</title>
<author confidence="0.998769">Pushpak Michael</author>
<affiliation confidence="0.95156">of Computer Science and Engineering, IIT Bombay, India IBC, Copenhagen Business School,</affiliation>
<email confidence="0.989045">mc.ibc@cbs.dk</email>
<abstract confidence="0.999398588235294">this paper we introduce Dif- Index a measure of difficulty in text translation. We first define and quantify translation difficulty in terms of TDI. We realize that any meaof TDI based on by translators is fraught with subjectivity and ad- We, rather, rely on eveye tracking. TDI is meaas the sum of (gaze) (rapid eye movement) of the eye. We then establish that TDI is correlated with three properties of the insentence, length (L), degree of (DP) complexity We train a Vector Regressystem to predict TDIs for new sentences using these features as input. The prediction done by our framework is well correlated with the empirical gold standard data, which is a reposof L, DP, SC &gt; for a set of sentences. The primary use of our work is a way of “binning” sentences (to be translated) in “easy”, “medium” and “hard” categories as per their predicted TDI. This can decide pricing of any translation task, especially useful in a scenario parallel corpora for Transbuilt through translation crowdsourcing/outsourcing. This can also provide a way of monitoring progress of second language learners.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>L Example</author>
</authors>
<title>DP SC TDIp TDIp Error 1. American Express recently announced a second round of job cuts.</title>
<marker>Example, </marker>
<rawString>Example L DP SC TDIp TDIp Error 1. American Express recently announced a second round of job cuts.</rawString>
</citation>
<citation valid="false">
<title>Sociology is a relatively new academic discipline.</title>
<marker></marker>
<rawString>2. Sociology is a relatively new academic discipline.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Campbell</author>
<author>S Hale</author>
</authors>
<title>What makes a text difficult to translate?</title>
<date>1999</date>
<booktitle>Refereed Proceedings of the 23rd Annual ALAA Congress.</booktitle>
<contexts>
<context position="2542" citStr="Campbell and Hale (1999)" startWordPosition="411" endWordPosition="414">ider the following example sentences. 1. The camera-man shot the policeman with a gun. (length-8) 2. I was returning from my old office yesterday. (length-8) Clearly, sentence 1 is more difficult to process and translate than sentence 2, since it has lexical ambiguity (“Shoot” as an act of firing a shot or taking a photograph?) and structural ambiguity (Shot with a gun or policeman with a gun?). To produce fluent and adequate translations, efforts have to be put to analyze both the lexical and syntactic properties of the sentences. The most recent work on studying translation difficulty is by Campbell and Hale (1999) who identified several areas of difficulty in lexis and grammar. “Reading” researchers have focused on developing readability formulae, since 1970. The Flesch-Kincaid Readability test (Kincaid et al., 1975), the Fry Readability Formula (Fry, 1977) and the Dale-Chall readability formula (Chall and Dale, 1999) are popular and influential. These formulae use factors such as vocabulary difficulty (or semantic factors) and sentence length (or syntactic factors). In a different setting, Malsburg et al. (2012) correlate eye fixations and scanpaths of readers with sentence processing. While these app</context>
</contexts>
<marker>Campbell, Hale, 1999</marker>
<rawString>Campbell, S., and Hale, S. 1999. What makes a text difficult to translate? Refereed Proceedings of the 23rd Annual ALAA Congress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carl</author>
</authors>
<title>Translog-II: A Program for Recording User Activity Data for Empirical Reading and Writing Research</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation, European Language Resources Association (ELRA)</booktitle>
<contexts>
<context position="8132" citStr="Carl, 2012" startWordPosition="1301" endWordPosition="1302">ns for both source and target sentences respectively. Modifying 1 �Tp = dur(f) + � dur(s) fEF3 sES3 + � dur(f) + � fEFt sESt (3) dur(s) 347 Figure 2: Screenshot of Translog. The circles represent fixations and arrow represent saccades. Here, Fs and Ss correspond to sets of fixations and saccades for source sentence and Ft and St correspond to those for the target sentence respectively. dur is a function returning the duration of fixations and saccades. 3.1 Computing TDI using eye-tracking database We obtained TDIs for a set of sentences from the Translation Process Research Database (TPR 1.0)(Carl, 2012). The database contains translation studies for which gaze data is recorded through the Translog software1(Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2. Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 200</context>
</contexts>
<marker>Carl, 2012</marker>
<rawString>Carl, M. 2012. Translog-II: A Program for Recording User Activity Data for Empirical Reading and Writing Research In Proceedings of the Eight International Conference on Language Resources and Evaluation, European Language Resources Association (ELRA)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carl</author>
</authors>
<title>The CRITT TPR-DB 1.0: A Database for Empirical Human Translation</title>
<date>2012</date>
<booktitle>Process Research. AMTA 2012 Workshop on Post-Editing Technology and Practice (WPTP-2012).</booktitle>
<contexts>
<context position="8132" citStr="Carl, 2012" startWordPosition="1301" endWordPosition="1302">ns for both source and target sentences respectively. Modifying 1 �Tp = dur(f) + � dur(s) fEF3 sES3 + � dur(f) + � fEFt sESt (3) dur(s) 347 Figure 2: Screenshot of Translog. The circles represent fixations and arrow represent saccades. Here, Fs and Ss correspond to sets of fixations and saccades for source sentence and Ft and St correspond to those for the target sentence respectively. dur is a function returning the duration of fixations and saccades. 3.1 Computing TDI using eye-tracking database We obtained TDIs for a set of sentences from the Translation Process Research Database (TPR 1.0)(Carl, 2012). The database contains translation studies for which gaze data is recorded through the Translog software1(Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2. Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 200</context>
</contexts>
<marker>Carl, 2012</marker>
<rawString>Carl, M. 2012 The CRITT TPR-DB 1.0: A Database for Empirical Human Translation Process Research. AMTA 2012 Workshop on Post-Editing Technology and Practice (WPTP-2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Chall</author>
<author>E Dale</author>
</authors>
<title>Readability revisited: the new Dale-Chall readability formula</title>
<date>1995</date>
<location>Cambridge, Mass.: Brookline Books.</location>
<marker>Chall, Dale, 1995</marker>
<rawString>Chall, J. S., and Dale, E. 1995. Readability revisited: the new Dale-Chall readability formula Cambridge, Mass.: Brookline Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dragsted</author>
</authors>
<title>Co-ordination of reading andwriting processes in translation. Contribution to Translation</title>
<date>2010</date>
<editor>and Cognition, Shreve, G. and Angelone,</editor>
<publisher>E.(eds.)Cognitive Science Society.</publisher>
<contexts>
<context position="3424" citStr="Dragsted, 2010" startWordPosition="539" endWordPosition="540"> readability formula (Chall and Dale, 1999) are popular and influential. These formulae use factors such as vocabulary difficulty (or semantic factors) and sentence length (or syntactic factors). In a different setting, Malsburg et al. (2012) correlate eye fixations and scanpaths of readers with sentence processing. While these approaches are successful in quantifying readability, they may not be applicable to translation scenarios. The reason is that, translation is not merely a reading activity. Translation requires co-ordination between source text comprehension and target text production (Dragsted, 2010). To the best of our knowledge, our work on predicting TDI is the first of its kind. The motivation of the work is as follows. Currently, for domain specific Machine Translation systems, parallel corpora are gathered through translation crowdsourcing/outsourcing. In such 346 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 346–351, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 1: Inherent sentence complexity and perceived difficulty during translation a scenario, translators are paid on the basis of sente</context>
</contexts>
<marker>Dragsted, 2010</marker>
<rawString>Dragsted, B. 2010. Co-ordination of reading andwriting processes in translation. Contribution to Translation and Cognition, Shreve, G. and Angelone, E.(eds.)Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Fry</author>
</authors>
<title>Fry’s readability graph: Clarification, validity, and extension to level 17</title>
<date>1977</date>
<journal>Journal of Reading,</journal>
<volume>21</volume>
<issue>3</issue>
<pages>242--252</pages>
<contexts>
<context position="2790" citStr="Fry, 1977" startWordPosition="447" endWordPosition="448">iguity (“Shoot” as an act of firing a shot or taking a photograph?) and structural ambiguity (Shot with a gun or policeman with a gun?). To produce fluent and adequate translations, efforts have to be put to analyze both the lexical and syntactic properties of the sentences. The most recent work on studying translation difficulty is by Campbell and Hale (1999) who identified several areas of difficulty in lexis and grammar. “Reading” researchers have focused on developing readability formulae, since 1970. The Flesch-Kincaid Readability test (Kincaid et al., 1975), the Fry Readability Formula (Fry, 1977) and the Dale-Chall readability formula (Chall and Dale, 1999) are popular and influential. These formulae use factors such as vocabulary difficulty (or semantic factors) and sentence length (or syntactic factors). In a different setting, Malsburg et al. (2012) correlate eye fixations and scanpaths of readers with sentence processing. While these approaches are successful in quantifying readability, they may not be applicable to translation scenarios. The reason is that, translation is not merely a reading activity. Translation requires co-ordination between source text comprehension and targe</context>
</contexts>
<marker>Fry, 1977</marker>
<rawString>Fry, E. 1977 Fry’s readability graph: Clarification, validity, and extension to level 17 Journal of Reading, 21(3), 242-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Hornof</author>
<author>T Halverson</author>
</authors>
<title>Cleaning up systematic error in eye-tracking data by using required fixation locations.</title>
<date>2002</date>
<journal>Behavior Research Methods, Instruments, and Computers,</journal>
<volume>34</volume>
<pages>592604</pages>
<contexts>
<context position="8734" citStr="Hornof and Halverson, 2002" startWordPosition="1391" endWordPosition="1394">ase (TPR 1.0)(Carl, 2012). The database contains translation studies for which gaze data is recorded through the Translog software1(Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2. Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 2002). To correct this, we applied automatic error correction technique (Mishra et al., 2012) followed by manually correcting incorrect gaze-toword mapping using Translog. Note that, gaze and saccadic durations may also depend on the translator’s reading speed. We tried to rule out this effect by sampling out translations for which the variance in participant’s reading speed is minimum. Variance in reading speed was calculated after taking a samples of source text for each participant and measuring the time taken to read the text. After preprocessing the data, TDI was computed for each sentence by </context>
</contexts>
<marker>Hornof, Halverson, 2002</marker>
<rawString>Hornof, A. J. and Halverson, T. 2002 Cleaning up systematic error in eye-tracking data by using required fixation locations. Behavior Research Methods, Instruments, and Computers, 34, 592604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Burges</author>
<author>A Smola</author>
</authors>
<date>1999</date>
<booktitle>Making large-Scale SVM Learning Practical. Advances in Kernel Methods - Support Vector Learning. MIT-Press,</booktitle>
<marker>Burges, Smola, 1999</marker>
<rawString>Joachims, T., Schlkopf, B. ,Burges, C and A. Smola (ed.). 1999. Making large-Scale SVM Learning Practical. Advances in Kernel Methods - Support Vector Learning. MIT-Press, 1999,</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Training Linear SVMs in Linear Time</title>
<date>2006</date>
<booktitle>Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<marker>Joachims, 2006</marker>
<rawString>Joachims, T. 2006 Training Linear SVMs in Linear Time Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Kincaid</author>
<author>R P Fishburne</author>
<author>R L Rogers</author>
<author>B S Chissom</author>
</authors>
<title>Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel Millington, Tennessee: Naval Air Station Memphis,pp.</title>
<date>1975</date>
<pages>8--75</pages>
<contexts>
<context position="2749" citStr="Kincaid et al., 1975" startWordPosition="439" endWordPosition="442"> translate than sentence 2, since it has lexical ambiguity (“Shoot” as an act of firing a shot or taking a photograph?) and structural ambiguity (Shot with a gun or policeman with a gun?). To produce fluent and adequate translations, efforts have to be put to analyze both the lexical and syntactic properties of the sentences. The most recent work on studying translation difficulty is by Campbell and Hale (1999) who identified several areas of difficulty in lexis and grammar. “Reading” researchers have focused on developing readability formulae, since 1970. The Flesch-Kincaid Readability test (Kincaid et al., 1975), the Fry Readability Formula (Fry, 1977) and the Dale-Chall readability formula (Chall and Dale, 1999) are popular and influential. These formulae use factors such as vocabulary difficulty (or semantic factors) and sentence length (or syntactic factors). In a different setting, Malsburg et al. (2012) correlate eye fixations and scanpaths of readers with sentence processing. While these approaches are successful in quantifying readability, they may not be applicable to translation scenarios. The reason is that, translation is not merely a reading activity. Translation requires co-ordination be</context>
</contexts>
<marker>Kincaid, Fishburne, Rogers, Chissom, 1975</marker>
<rawString>Kincaid, J. P., Fishburne, R. P., Jr., Rogers, R. L., and Chissom, B. S. 1975. Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel Millington, Tennessee: Naval Air Station Memphis,pp. 8-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>On the structural complexity of natural language sentences.</title>
<date>1996</date>
<booktitle>Proceeding of the 16th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>729733</pages>
<contexts>
<context position="11074" citStr="Lin (1996)" startWordPosition="1786" endWordPosition="1787"> words occurring in a sentence. 4.2 Degree of Polysemy (DP) The degree of polysemy of a sentence is the sum of senses possessed by each word in the Wordnet normalized by the sentence length. Mathematically, DP EwEW Senses(w) 4 sentence — length (sentence) ( ) Here, Senses(w) retrieves the total number senses of a word P from the Wordnet. W is the set of words appearing in the sentence. 4.3 Structural Complexity (SC) Syntactically, words, phrases and clauses are attached to each other in a sentence. If the attachment units lie far from each other, the sentence has higher structural complexity. Lin (1996) defines it as the total length of dependency links in the dependency structure of the sentence. 348 Figure 4: Prediction of TDI using linguistic properties such as Length(L), Degree of Polysemy (DP) and Structural Complexity (SC) Example: The man who the boy attacked escaped. Figure 3 shows the dependency graph for the example sentence. The weights of the edges correspond how far the two connected words lie from each other in the sentence. Using Lin’s formula, the SC score for the example sentence turns out to be 15. Lin’s way of computing SC is affected by sentence length since the number of</context>
</contexts>
<marker>Lin, 1996</marker>
<rawString>Lin, D. 1996 On the structural complexity of natural language sentences. Proceeding of the 16th International Conference on Computational Linguistics (COLING), pp. 729733.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mishra</author>
<author>M Carl</author>
<author>P Bhattacharyya</author>
</authors>
<title>A heuristic-based approach for systematic error correction of gaze datafor reading.</title>
<date>2012</date>
<booktitle>Proceedings of the First Workshop on Eye-tracking and Natural Language Processing, Mumbai, India. The COLING 2012 Organizing Committee</booktitle>
<editor>In MichaelCarl, P.B. and Choudhary, K.K., editors,</editor>
<contexts>
<context position="8822" citStr="Mishra et al., 2012" startWordPosition="1405" endWordPosition="1408">orded through the Translog software1(Carl, 2012). Figure 2 presents a screendump of Translog. Out of the 57 available sessions, we selected 40 translation sessions comprising 80 sentence translations2. Each of these 80 sentences was translated from English to three different languages, viz. Spanish, Danish and Hindi by at least 2 translators. The translators were young professional linguists or students pursuing PhD in linguistics. The eye-tracking data is noisy and often exhibits systematic errors (Hornof and Halverson, 2002). To correct this, we applied automatic error correction technique (Mishra et al., 2012) followed by manually correcting incorrect gaze-toword mapping using Translog. Note that, gaze and saccadic durations may also depend on the translator’s reading speed. We tried to rule out this effect by sampling out translations for which the variance in participant’s reading speed is minimum. Variance in reading speed was calculated after taking a samples of source text for each participant and measuring the time taken to read the text. After preprocessing the data, TDI was computed for each sentence by using (2) and (3).The observed unnormalized TDI score3 ranges from 0.12 to 0.86. We norm</context>
</contexts>
<marker>Mishra, Carl, Bhattacharyya, 2012</marker>
<rawString>Mishra, A., Carl, M, Bhattacharyya, P. 2012 A heuristic-based approach for systematic error correction of gaze datafor reading. In MichaelCarl, P.B. and Choudhary, K.K., editors, Proceedings of the First Workshop on Eye-tracking and Natural Language Processing, Mumbai, India. The COLING 2012 Organizing Committee</rawString>
</citation>
<citation valid="true">
<authors>
<author>T von der Malsburg</author>
<author>S Vasishth</author>
<author>R Kliegl</author>
</authors>
<title>Scanpaths in reading are informative about sentence processing.</title>
<date>2012</date>
<booktitle>Proceedings of the First Workshop on Eye-tracking and Natural Language Processing, Mumbai, India. The COLING 2012 Organizing Committee</booktitle>
<editor>In MichaelCarl, P.B. and Choudhary, K.K., editors,</editor>
<marker>von der Malsburg, Vasishth, Kliegl, 2012</marker>
<rawString>von der Malsburg, T., Vasishth, S., and Kliegl, R. 2012 Scanpaths in reading are informative about sentence processing. In MichaelCarl, P.B. and Choudhary, K.K., editors, Proceedings of the First Workshop on Eye-tracking and Natural Language Processing, Mumbai, India. The COLING 2012 Organizing Committee</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>