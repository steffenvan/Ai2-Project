<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.239207">
<title confidence="0.997059">
Annotating Wall Street Journal Texts Using a Hand-Crafted Deep
Linguistic Grammar
</title>
<author confidence="0.990232">
Valia Kordoni &amp; Yi Zhang
</author>
<affiliation confidence="0.919052">
DFKI GmbH and Dept. of Computational Linguistics, Saarland University
</affiliation>
<address confidence="0.878568">
66041 Saarbr¨ucken, GERMANY
</address>
<email confidence="0.994219">
{kordoni,yzhang}@coli.uni-sb.de
</email>
<sectionHeader confidence="0.997326" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999824428571429">
This paper presents an on-going effort
which aims to annotate the Wall Street
Journal sections of the Penn Treebank with
the help of a hand-written large-scale and
wide-coverage grammar of English. In do-
ing so, we are not only focusing on the
various stages of the semi-automated an-
notation process we have adopted, but we
are also showing that rich linguistic anno-
tations, which can apart from syntax also
incorporate semantics, ensure that the tree-
bank is guaranteed to be a truly sharable,
re-usable and multi-functional linguistic
resource†.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998502545454546">
The linguistic annotation of a corpus is the prac-
tice of adding interpretative linguistic information
in order to give “added value” to the corpus. Lin-
guistically annotated corpora have been shown to
help in many kinds of automatic language pro-
cessing or analysis. For example, corpora which
have been POS-tagged can automatically yield fre-
quency lists or frequency dictionaries with gram-
matical classification. Another important use for
linguistically annotated corpora is in the area of
automatic parsing. In terms of re-usability of lin-
guistic annotations, what is to be advocated here is
that – as long as the annotation provided is a kind
useful to many users - an annotated corpus gives
“value added” because it can be readily shared by
others, apart from those who originally added the
annotation. In short, a linguistically annotated cor-
pus is a sharable resource, an example of the elec-
tronic resources increasingly relied on for research
and study in the humanities and social sciences.
In this paper, we present an on-going project
whose aim is to produce rich syntactic and se-
</bodyText>
<footnote confidence="0.78163075">
†We thank Dan Flickinger and Stephan Oepen for their
support with the grammar and treebanking software used in
this project. The second author is supported by the German
Excellence Cluster: Multimodal Computing &amp; Interaction.
</footnote>
<bodyText confidence="0.998596777777778">
mantic annotations for the Wall Street Journal
(henceforward WSJ) sections of the Penn Tree-
bank (henceforward PTB; Marcus et al. (1993)).
The task is being carried out with the help of the
English Resource Grammar (henceforward ERG;
Flickinger (2002)), which is a hand-written gram-
mar for English in the spirit of the framework of
Head-driven Phrase Structure Grammar (hence-
forward HPSG; Pollard and Sag (1994)).
</bodyText>
<sectionHeader confidence="0.940344" genericHeader="introduction">
2 Background &amp; Motivation
</sectionHeader>
<bodyText confidence="0.9996118">
The past two decades have seen the development
of many syntactically annotated corpora. There is
no need to defend the importance of treebanks in
the study of corpus linguistics or computational
linguistics here. Evidently, the successful devel-
opment of many statistical parsers is attributed
to the development of large treebanks. But for
parsing systems based on hand-written grammars,
treebanks are also important resources on the base
of which statistical parse disambiguation models
have been developed.
The early treebanking efforts started with man-
ual annotations which are time-consuming and
error-prone procedures. For instance, the WSJ
sections of the PTB has taken many person years
to get annotated. Similar efforts have been car-
ried out in many more languages, as can be seen
in the cases of the German Negra/Tiger Treebank
(Brants et al., 2002), the Prague Dependency Tree-
bank (Hajiˇc et al., 2000), T¨uBa-D/Z1, etc. Al-
though many of these projects have stimulated re-
search in various sub-fields of computational lin-
guistics where corpus-based empirical methods
are used, there are many known shortcomings of
the manual corpus annotation approach.
Many of the limitations in the manual treebank-
ing approach have led to the development of sev-
eral alternative approaches. While annotating lin-
guistically rich structures from scratch is clearly
inpractical, it has been shown that the different
</bodyText>
<footnote confidence="0.998469">
1http://www.sfs.nphil.uni-tuebingen.de/en tuebadz.shtml
</footnote>
<page confidence="0.858299">
170
</page>
<note confidence="0.95891">
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 170–173,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99954672972973">
structures in various linguistic frameworks can be
converted from annotated treebanks to a differ-
ent format. And the missing rich annotations can
be filled in incrementally and semi-automatically.
This process usually involves careful design of
the conversion program, which is a non-trivial
task. In very recent years, based on the treebank
conversion approach and existing manually anno-
tated treebanks, various “new” annotations in dif-
ferent grammar frameworks have been produced
for the same set of texts. For example, for the
WSJ sections of the PTB, annotations in the style
of dependency grammar, CCG, LFG and HPSG
have become available. Such double annotations
have helped the cross-framework development and
evaluation of parsing systems. However, it must
be noted that the influence of the original PTB an-
notations and the assumptions implicit in the con-
version programs have made the independence of
such new treebanks at least questionable. To our
knowledge, there is no completely independent
annotation of the WSJ texts built without conver-
sion from the original PTB trees.
Another popular alternative way to aid treebank
development is to use automatic parsing outputs
as guidance. Many state-of-the-art parsers are
able to efficiently produce large amount of anno-
tated syntactic structures with relatively high ac-
curacy. This approach has changed the role of
human annotation from a labour-intensive task of
drawing trees from scratch to a more intelligence-
demanding task of correcting parsing errors, or
eliminating unwanted ambiguities (cf., the Red-
woods Treebank (Oepen et al., 2002)). It is our
aim in this on-going project to build a HPSG tree-
bank for the WSJ sections of the PTB based on the
hand-written ERG for English.
</bodyText>
<sectionHeader confidence="0.983191" genericHeader="method">
3 The Annotation Scheme
</sectionHeader>
<subsectionHeader confidence="0.999332">
3.1 Grammars &amp; Tools
</subsectionHeader>
<bodyText confidence="0.9998794">
The treebank under construction in this project
is in line with the so-called dynamic treebanks
(Oepen et al., 2002). We rely on the HPSG anal-
yses produced by the ERG, and manually dis-
ambiguate the parsing outputs with multiple an-
notators. The development is heavily based on
the DELPH-IN2 software repository and makes
use of the English Resource Grammar (ERG;
Flickinger (2002), PET (Callmeier, 2001), an ef-
ficient unification-based parser which is used in
</bodyText>
<footnote confidence="0.766408">
2http://www.delph-in.net/
</footnote>
<bodyText confidence="0.999756166666667">
our project for parsing the WSJ sections of the
PTB, and [incr tsdb()] (Oepen, 2001), the gram-
mar performance profiling system we are using,
which comes with a complete set of GUI-based
tools for treebanking. Version control system also
plays an important role in this project.
</bodyText>
<subsectionHeader confidence="0.99956">
3.2 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999973">
The sentences from the Wall Street Journal Sec-
tions of the Penn Treebank are extracted with their
original tokenization, with each word paired with
a part-of-speech tag. Each sentence is given a
unique ID which can be used to easily look up its
origin in the PTB.
</bodyText>
<subsectionHeader confidence="0.999178">
3.3 Annotation Cycles
</subsectionHeader>
<bodyText confidence="0.999967448275862">
The annotation is organised into iterations of
parsing, treebanking, error analysis and gram-
mar/treebank update cycles.
Parsing Sentences from the WSJ are first parsed
with the PET parser using the ERG. Up to
500 top readings are recorded for each sentence.
The exact best-first parsing mode guarantees that
these recorded readings are the ones that have
“achieved” highest disambiguation scores accord-
ing to the current parse selection model, without
enumerating through all possible analyses.
Treebanking The parsing results are then man-
ually disambiguated by the annotators. However,
instead of looking at individual trees, the annota-
tors spend most of their effort making binary de-
cisions on either accepting or rejecting construc-
tions. Each of these decisions, called discrim-
inants, reduces the number of the trees satisfy-
ing the constraints (see Figure 1). Every time a
decision is made, the remaining set of trees and
discriminants are updated simultaneously. This
continues until one of the following conditions is
met: i) if there is only one remaining tree and it
represents a correct analysis of the sentence, the
tree is marked as gold; ii) if none of the remain-
ing trees represents a valid analysis, the sentence
will be marked as “rejected”, indicating an error
in the grammar3; iii) if the annotator is not sure
about any further decision, a “low confidence”
</bodyText>
<footnote confidence="0.9978475">
3In some cases, the grammar does produce a valid read-
ing, but the disambiguation model fails to rank it among the
top 500 recorded candidates. In practice, we find such er-
rors occuring frequently during the first annotation circle, but
they diminish quickly when the disambiguation model gets
updated.
</footnote>
<page confidence="0.990456">
171
</page>
<figureCaption confidence="0.9860238">
Figure 1: Treebanking Interface with an example sentence, candidate readings, discriminants and the MRS. The top row of
the interface is occupied by a list of functional buttons, followed by a line indicating the sentence ID, number of remaining
readings, number of eliminated readings, annotator confidence level, and the original PTB bracket annotation. The left part
displays the candidate readings, and their corresponding IDs (ranked by the disambiguation model). The right part lists all the
discriminants among the remaining readings. The lower part shows the MRS of one candicate reading.
</figureCaption>
<bodyText confidence="0.999973060606061">
state will be marked on the sentence, saved to-
gether with the partial disambiguation decisions.
Generally speaking, given n candidate trees, on
average 1092 n decisions are needed in order to
fully disambiguate. Given that we set a limit of
500 candidate readings per sentence, the whole
process should require no more than 9 decisions.
If both the syntactic and the MRS analyses look
valid, the tree will be recorded as the gold read-
ing for the sentence. It should be noted here that
the tree displayed in the treebanking window is
an abbreviated representation of the actual HPSG
analysis, which is much more informative than the
phrase-structure tree shown here.
Grammar &amp; Treebank Update While the
grammar development is independent to the tree-
banking progress, we periodically incorporate the
recent changes of the grammar into the treebank
annotation cycle. When a grammar update is in-
corporated, the treebank will be updated accord-
ingly by i) parsing all the sentences with the new
grammar; ii) re-applying the recorded annotation
decisions; iii) re-annotating those sentences which
are not fully disambiguated after step ii. The ex-
tra manual annotation effort in treebank update is
usually small when compared to the first round an-
notation.
Another type of update happens more fre-
quently without extra annotation cost. When a
new portion of the corpus is annotated, this is used
to retrain the parse disambiguation model. This
improves the parse selection accuracy and reduces
the annotation workload.
</bodyText>
<subsectionHeader confidence="0.96106">
3.4 Grammar coverage &amp; robust parsing
</subsectionHeader>
<bodyText confidence="0.9999305">
Not having been specifically tuned for the newspa-
per texts, the ERG achieved out-of-box coverage
of over 80% on the WSJ dataset. While this is a re-
spectably high coverage for a hand-written preci-
sion grammar, the remaining 20% of the data is not
covered by the first round of annotation. We plan
to parse the remaining data using a less-restrictive
probabilistic context-free grammar extracted from
the annotated part of the treebank. The PCFG
parser will produce a pseudo-derivation tree, with
which robust unifications can be applied to con-
struct the semantic structures (Zhang and Kordoni,
</bodyText>
<page confidence="0.985672">
172
</page>
<figure confidence="0.999630701030928">
5
NP
VP
N
VP
PP
DET
NP
DET
ADJ
N
V
P
VP
N
N
5
to
VP
N
NP
V
NP
DET
the
’s
largest
N
5/NP
V
plans
PP
P
N
N
nation
NP
N
DET
N
DET
V
N
N
VP/NP
to
pension
N
N
N
AP
PP
VP/NP
ADJ
its
ADJ
offer
which
NP
P
NP
N
N
ADJ
ADJ
N
fund,
V/NP
two
new
N
investment
N
million
V/NP
1.2
N
for
N
N
ADJ
ADJ
N
college
oversees
NP
options
participants.
N
N
N
N
ADJ
N
N
$ 80 billion N
employees,
</figure>
<figureCaption confidence="0.992507">
Figure 2: An example tree including a ”heavy” NP-subject, a relative clause, and noun-noun compounds
</figureCaption>
<bodyText confidence="0.911878">
2008).
</bodyText>
<subsectionHeader confidence="0.91438">
3.5 Multiple annotations
</subsectionHeader>
<bodyText confidence="0.9999882">
To speed up the annotation, the project employs
three annotators. They are assigned with slightly
overlapping sections of the WSJ dataset. The
overlapping part allows us to measure the inter-
annotator agreement for the purpose of quality
control. To estimate the agreement level, the WSJ
Section 02 has been completely annotated by all
three annotators. Analysis shows that the annota-
tors reach exact match agreement for around 50%
of the sentences. Many disagreements are re-
lated to subtle variations in the linguistic analy-
ses. The agreement level shows improvement af-
ter several treebanker meetings. For future devel-
opment, a more fine-grained disagreement assess-
ment is planned.
</bodyText>
<sectionHeader confidence="0.99988" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999991333333333">
The WSJ section of the PTB is not only a chal-
lenging corpus to parse with a hand-written gram-
mar. It also contains various interesting and chal-
lenging linguistic phenomena. Figure 2, for in-
stance, shows the syntactic analysis that the ERG
produces for a sentence which includes a “heavy”
NP (noun phrase) containing a relative clause in-
troduced by which in the subject position, as well
as many interesting compound nouns whose inter-
pretations are missing from the PTB annotation.
The newly annotated data will be also very im-
portant for the cross-framework parser develop-
ment and evaluation. While almost all of the state-
of-the-art statistical parsers for English use PTB
annotations for training and testing, it would be
interesting to see whether a comparable level of
parsing accuracy can be reproduced on the same
texts when re-annotated independently.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708972972973">
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang
Lezius, and George Smith. 2002. The tiger treebank. In
Proceedings of the workshop on treebanks and linguistic
theories, pages 24–41.
Ulrich Callmeier. 2001. Efficient parsing with large-scale
unification grammars. Master’s thesis, Universit¨at des
Saarlandes, Saarbr¨ucken, Germany.
Dan Flickinger. 2002. On building a more efficient grammar
by exploiting types. In Stephan Oepen, Dan Flickinger,
Jun’ichi Tsujii, and Hans Uszkoreit, editors, Collaborative
Language Engineering, pages 1–17. CSLI Publications.
Jan Hajiˇc, Alena B¨ohmov´a, Eva Hajiˇcov´a, and Barbora Vi-
dov´a-Hladk´a. 2000. The Prague Dependency Treebank:
A Three-Level Annotation Scenario. In A. Abeill´e, editor,
Treebanks: Building and Using Parsed Corpora, pages
103–127. Amsterdam:Kluwer.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated corpus
of english: The penn treebank. Computational Linguis-
tics, 19(2):313–330.
Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christo-
pher Manning, Dan Flickinger, and Thorsten Brants.
2002. The LinGO Redwoods treebank: motivation and
preliminary applications. In Proceedings of COLING
2002: The 17th International Conference on Computa-
tional Linguistics: Project Notes, Taipei, Taiwan.
Stephan Oepen. 2001. [incr tsdb()] — competence
and performance laboratory. User manual. Technical
report, Computational Linguistics, Saarland University,
Saarbr¨ucken, Germany.
Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. University of Chicago Press,
Chicago, USA.
Yi Zhang and Valia Kordoni. 2008. Robust Parsing with a
Large HPSG Grammar. In Proceedings of the Sixth Inter-
national Language Resources and Evaluation (LREC’08),
Marrakech, Morocco.
</reference>
<page confidence="0.999101">
173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.447541">
<title confidence="0.9842445">Annotating Wall Street Journal Texts Using a Hand-Crafted Linguistic Grammar</title>
<author confidence="0.90001">Kordoni</author>
<affiliation confidence="0.935537">DFKI GmbH and Dept. of Computational Linguistics, Saarland</affiliation>
<address confidence="0.912263">66041 Saarbr¨ucken,</address>
<abstract confidence="0.999729769230769">This paper presents an on-going effort which aims to annotate the Wall Street Journal sections of the Penn Treebank with the help of a hand-written large-scale and wide-coverage grammar of English. In doing so, we are not only focusing on the various stages of the semi-automated annotation process we have adopted, but we are also showing that rich linguistic annotations, which can apart from syntax also incorporate semantics, ensure that the treebank is guaranteed to be a truly sharable,</abstract>
<intro confidence="0.573439">re-usable and multi-functional linguistic</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The tiger treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the workshop on treebanks and linguistic theories,</booktitle>
<pages>24--41</pages>
<contexts>
<context position="3418" citStr="Brants et al., 2002" startWordPosition="530" endWordPosition="533"> development of many statistical parsers is attributed to the development of large treebanks. But for parsing systems based on hand-written grammars, treebanks are also important resources on the base of which statistical parse disambiguation models have been developed. The early treebanking efforts started with manual annotations which are time-consuming and error-prone procedures. For instance, the WSJ sections of the PTB has taken many person years to get annotated. Similar efforts have been carried out in many more languages, as can be seen in the cases of the German Negra/Tiger Treebank (Brants et al., 2002), the Prague Dependency Treebank (Hajiˇc et al., 2000), T¨uBa-D/Z1, etc. Although many of these projects have stimulated research in various sub-fields of computational linguistics where corpus-based empirical methods are used, there are many known shortcomings of the manual corpus annotation approach. Many of the limitations in the manual treebanking approach have led to the development of several alternative approaches. While annotating linguistically rich structures from scratch is clearly inpractical, it has been shown that the different 1http://www.sfs.nphil.uni-tuebingen.de/en tuebadz.sh</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The tiger treebank. In Proceedings of the workshop on treebanks and linguistic theories, pages 24–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>Efficient parsing with large-scale unification grammars.</title>
<date>2001</date>
<booktitle>Master’s thesis, Universit¨at des Saarlandes,</booktitle>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="6362" citStr="Callmeier, 2001" startWordPosition="984" endWordPosition="985">eebank (Oepen et al., 2002)). It is our aim in this on-going project to build a HPSG treebank for the WSJ sections of the PTB based on the hand-written ERG for English. 3 The Annotation Scheme 3.1 Grammars &amp; Tools The treebank under construction in this project is in line with the so-called dynamic treebanks (Oepen et al., 2002). We rely on the HPSG analyses produced by the ERG, and manually disambiguate the parsing outputs with multiple annotators. The development is heavily based on the DELPH-IN2 software repository and makes use of the English Resource Grammar (ERG; Flickinger (2002), PET (Callmeier, 2001), an efficient unification-based parser which is used in 2http://www.delph-in.net/ our project for parsing the WSJ sections of the PTB, and [incr tsdb()] (Oepen, 2001), the grammar performance profiling system we are using, which comes with a complete set of GUI-based tools for treebanking. Version control system also plays an important role in this project. 3.2 Preprocessing The sentences from the Wall Street Journal Sections of the Penn Treebank are extracted with their original tokenization, with each word paired with a part-of-speech tag. Each sentence is given a unique ID which can be use</context>
</contexts>
<marker>Callmeier, 2001</marker>
<rawString>Ulrich Callmeier. 2001. Efficient parsing with large-scale unification grammars. Master’s thesis, Universit¨at des Saarlandes, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2002</date>
<booktitle>Collaborative Language Engineering,</booktitle>
<pages>1--17</pages>
<editor>In Stephan Oepen, Dan Flickinger, Jun’ichi Tsujii, and Hans Uszkoreit, editors,</editor>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="2371" citStr="Flickinger (2002)" startWordPosition="369" endWordPosition="370"> and study in the humanities and social sciences. In this paper, we present an on-going project whose aim is to produce rich syntactic and se†We thank Dan Flickinger and Stephan Oepen for their support with the grammar and treebanking software used in this project. The second author is supported by the German Excellence Cluster: Multimodal Computing &amp; Interaction. mantic annotations for the Wall Street Journal (henceforward WSJ) sections of the Penn Treebank (henceforward PTB; Marcus et al. (1993)). The task is being carried out with the help of the English Resource Grammar (henceforward ERG; Flickinger (2002)), which is a hand-written grammar for English in the spirit of the framework of Head-driven Phrase Structure Grammar (henceforward HPSG; Pollard and Sag (1994)). 2 Background &amp; Motivation The past two decades have seen the development of many syntactically annotated corpora. There is no need to defend the importance of treebanks in the study of corpus linguistics or computational linguistics here. Evidently, the successful development of many statistical parsers is attributed to the development of large treebanks. But for parsing systems based on hand-written grammars, treebanks are also impo</context>
<context position="6339" citStr="Flickinger (2002)" startWordPosition="981" endWordPosition="982">es (cf., the Redwoods Treebank (Oepen et al., 2002)). It is our aim in this on-going project to build a HPSG treebank for the WSJ sections of the PTB based on the hand-written ERG for English. 3 The Annotation Scheme 3.1 Grammars &amp; Tools The treebank under construction in this project is in line with the so-called dynamic treebanks (Oepen et al., 2002). We rely on the HPSG analyses produced by the ERG, and manually disambiguate the parsing outputs with multiple annotators. The development is heavily based on the DELPH-IN2 software repository and makes use of the English Resource Grammar (ERG; Flickinger (2002), PET (Callmeier, 2001), an efficient unification-based parser which is used in 2http://www.delph-in.net/ our project for parsing the WSJ sections of the PTB, and [incr tsdb()] (Oepen, 2001), the grammar performance profiling system we are using, which comes with a complete set of GUI-based tools for treebanking. Version control system also plays an important role in this project. 3.2 Preprocessing The sentences from the Wall Street Journal Sections of the Penn Treebank are extracted with their original tokenization, with each word paired with a part-of-speech tag. Each sentence is given a uni</context>
</contexts>
<marker>Flickinger, 2002</marker>
<rawString>Dan Flickinger. 2002. On building a more efficient grammar by exploiting types. In Stephan Oepen, Dan Flickinger, Jun’ichi Tsujii, and Hans Uszkoreit, editors, Collaborative Language Engineering, pages 1–17. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Alena B¨ohmov´a, Eva Hajiˇcov´a, and Barbora Vidov´a-Hladk´a.</title>
<date>2000</date>
<pages>103--127</pages>
<editor>In A. Abeill´e, editor,</editor>
<publisher>Amsterdam:Kluwer.</publisher>
<marker>Hajiˇc, 2000</marker>
<rawString>Jan Hajiˇc, Alena B¨ohmov´a, Eva Hajiˇcov´a, and Barbora Vidov´a-Hladk´a. 2000. The Prague Dependency Treebank: A Three-Level Annotation Scenario. In A. Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, pages 103–127. Amsterdam:Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2256" citStr="Marcus et al. (1993)" startWordPosition="349" endWordPosition="352">ly annotated corpus is a sharable resource, an example of the electronic resources increasingly relied on for research and study in the humanities and social sciences. In this paper, we present an on-going project whose aim is to produce rich syntactic and se†We thank Dan Flickinger and Stephan Oepen for their support with the grammar and treebanking software used in this project. The second author is supported by the German Excellence Cluster: Multimodal Computing &amp; Interaction. mantic annotations for the Wall Street Journal (henceforward WSJ) sections of the Penn Treebank (henceforward PTB; Marcus et al. (1993)). The task is being carried out with the help of the English Resource Grammar (henceforward ERG; Flickinger (2002)), which is a hand-written grammar for English in the spirit of the framework of Head-driven Phrase Structure Grammar (henceforward HPSG; Pollard and Sag (1994)). 2 Background &amp; Motivation The past two decades have seen the development of many syntactically annotated corpora. There is no need to defend the importance of treebanks in the study of corpus linguistics or computational linguistics here. Evidently, the successful development of many statistical parsers is attributed to </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Kristina Toutanova</author>
<author>Stuart Shieber</author>
<author>Christopher Manning</author>
<author>Dan Flickinger</author>
<author>Thorsten Brants</author>
</authors>
<title>The LinGO Redwoods treebank: motivation and preliminary applications.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="5773" citStr="Oepen et al., 2002" startWordPosition="881" endWordPosition="884">completely independent annotation of the WSJ texts built without conversion from the original PTB trees. Another popular alternative way to aid treebank development is to use automatic parsing outputs as guidance. Many state-of-the-art parsers are able to efficiently produce large amount of annotated syntactic structures with relatively high accuracy. This approach has changed the role of human annotation from a labour-intensive task of drawing trees from scratch to a more intelligencedemanding task of correcting parsing errors, or eliminating unwanted ambiguities (cf., the Redwoods Treebank (Oepen et al., 2002)). It is our aim in this on-going project to build a HPSG treebank for the WSJ sections of the PTB based on the hand-written ERG for English. 3 The Annotation Scheme 3.1 Grammars &amp; Tools The treebank under construction in this project is in line with the so-called dynamic treebanks (Oepen et al., 2002). We rely on the HPSG analyses produced by the ERG, and manually disambiguate the parsing outputs with multiple annotators. The development is heavily based on the DELPH-IN2 software repository and makes use of the English Resource Grammar (ERG; Flickinger (2002), PET (Callmeier, 2001), an effici</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christopher Manning, Dan Flickinger, and Thorsten Brants. 2002. The LinGO Redwoods treebank: motivation and preliminary applications. In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
</authors>
<title>incr tsdb()] — competence and performance laboratory. User manual.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>Computational Linguistics, Saarland University,</institution>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="6529" citStr="Oepen, 2001" startWordPosition="1009" endWordPosition="1010">The Annotation Scheme 3.1 Grammars &amp; Tools The treebank under construction in this project is in line with the so-called dynamic treebanks (Oepen et al., 2002). We rely on the HPSG analyses produced by the ERG, and manually disambiguate the parsing outputs with multiple annotators. The development is heavily based on the DELPH-IN2 software repository and makes use of the English Resource Grammar (ERG; Flickinger (2002), PET (Callmeier, 2001), an efficient unification-based parser which is used in 2http://www.delph-in.net/ our project for parsing the WSJ sections of the PTB, and [incr tsdb()] (Oepen, 2001), the grammar performance profiling system we are using, which comes with a complete set of GUI-based tools for treebanking. Version control system also plays an important role in this project. 3.2 Preprocessing The sentences from the Wall Street Journal Sections of the Penn Treebank are extracted with their original tokenization, with each word paired with a part-of-speech tag. Each sentence is given a unique ID which can be used to easily look up its origin in the PTB. 3.3 Annotation Cycles The annotation is organised into iterations of parsing, treebanking, error analysis and grammar/treeba</context>
</contexts>
<marker>Oepen, 2001</marker>
<rawString>Stephan Oepen. 2001. [incr tsdb()] — competence and performance laboratory. User manual. Technical report, Computational Linguistics, Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl J Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, USA.</location>
<contexts>
<context position="2531" citStr="Pollard and Sag (1994)" startWordPosition="393" endWordPosition="396">Flickinger and Stephan Oepen for their support with the grammar and treebanking software used in this project. The second author is supported by the German Excellence Cluster: Multimodal Computing &amp; Interaction. mantic annotations for the Wall Street Journal (henceforward WSJ) sections of the Penn Treebank (henceforward PTB; Marcus et al. (1993)). The task is being carried out with the help of the English Resource Grammar (henceforward ERG; Flickinger (2002)), which is a hand-written grammar for English in the spirit of the framework of Head-driven Phrase Structure Grammar (henceforward HPSG; Pollard and Sag (1994)). 2 Background &amp; Motivation The past two decades have seen the development of many syntactically annotated corpora. There is no need to defend the importance of treebanks in the study of corpus linguistics or computational linguistics here. Evidently, the successful development of many statistical parsers is attributed to the development of large treebanks. But for parsing systems based on hand-written grammars, treebanks are also important resources on the base of which statistical parse disambiguation models have been developed. The early treebanking efforts started with manual annotations </context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
</authors>
<title>Robust Parsing with a Large HPSG Grammar.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco.</location>
<marker>Zhang, Kordoni, 2008</marker>
<rawString>Yi Zhang and Valia Kordoni. 2008. Robust Parsing with a Large HPSG Grammar. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>