<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000968">
<title confidence="0.973351">
Context-Dependent Multilingual Lexical Lookup for Under-Resourced
Languages
</title>
<author confidence="0.958421">
Lian Tze Lim*†
</author>
<affiliation confidence="0.7486765">
*SEST, KDU College Penang
Georgetown, Penang, Malaysia
</affiliation>
<email confidence="0.945163">
liantze@gmail.com
</email>
<author confidence="0.995086">
Enya Kong Tang
</author>
<affiliation confidence="0.873649">
Linton University College
Seremban, Negeri Sembilan, Malaysia
</affiliation>
<email confidence="0.993054">
enyakong1@gmail.com
</email>
<sectionHeader confidence="0.997317" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935086956522">
Current approaches for word sense dis-
ambiguation and translation selection typ-
ically require lexical resources or large
bilingual corpora with rich information
fields and annotations, which are often
infeasible for under-resourced languages.
We extract translation context knowledge
from a bilingual comparable corpora of a
richer-resourced language pair, and inject
it into a multilingual lexicon. The multilin-
gual lexicon can then be used to perform
context-dependent lexical lookup on texts
of any language, including under-resourced
ones. Evaluations on a prototype lookup
tool, trained on a English–Malay bilingual
Wikipedia corpus, show a precision score
of 0.65 (baseline 0.55) and mean recip-
rocal rank score of 0.81 (baseline 0.771).
Based on the early encouraging results,
the context-dependent lexical lookup tool
may be developed further into an intelligent
reading aid, to help users grasp the gist of
a second or foreign language text.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99914475">
Word sense disambiguation (WSD) is the task of
assigning sense tags to ambiguous lexical items
(LIs) in a text. Translation selection chooses target
language items for translating ambiguous LIs in a
text, and can therefore be viewed as a kind of WSD
task, with translations as the sense tags. The trans-
lation selection task may also be modified slightly
to output a ranked list of translations. This then re-
sembles a dictionary lookup process as performed
by a human reader when reading or browsing a text
written in a second or foreign language. For conve-
nience’s sake, we will call this task (as performed
</bodyText>
<note confidence="0.980347">
Lay-Ki Soon and Tek Yong Lim
†FCI, Multimedia University
Cyberjaya, Selangor, Malaysia
</note>
<email confidence="0.675082">
{lksoon,tylim}@mmu.edu.my
</email>
<author confidence="0.796776">
Bali Ranaivo-Malançon
</author>
<affiliation confidence="0.9650575">
FCSIT, Universiti Malaysia Sarawak,
Kota Samarahan, Sarawak, Malaysia
</affiliation>
<email confidence="0.956664">
mbranaivo@fit.unimas.my
</email>
<bodyText confidence="0.999391264705882">
via computational means) context-dependent lexi-
cal lookup. It can also be viewed as a simplified
version of the Cross-Lingual Lexical Substitution
(Mihalcea et al., 2010) and Cross-Lingual Word
Sense Disambiguation (Lefever and Hoste, 2010)
tasks, as defined in SemEval-2010.
There is a large body of work around WSD and
translation selection. However, many of these ap-
proaches require lexical resources or large bilin-
gual corpora with rich information fields and an-
notations, as reviewed in section 2. Unfortunately,
not all languages have equal amounts of digital re-
sources for developing language technologies, and
such requirements are often infeasible for under-
resourced languages.
We are interested in leveraging richer-resourced
language pairs to enable context-dependent lexical
lookup for under-resourced languages. For this pur-
pose, we model translation context knowledge as a
second-order co-occurrence bag-of-words model.
We propose a rapid approach for acquiring them
from an untagged, comparable bilingual corpus
of a (richer-resourced) language pair in section 3.
This information is then transferred into a multilin-
gual lexicon to perform context-dependent lexical
lookup on input texts, including those in an under-
resourced language (section 4). Section 5 describes
a prototype implementation, where translation con-
text knowledge is extracted from a English–Malay
bilingual corpus to enrich a multilingual lexicon
with six languages. Results from a small experi-
ment are presented in 6 and discussed in section 7.
The approach is briefly compared with some related
work in section 8, before concluding in section 9.
</bodyText>
<sectionHeader confidence="0.928344" genericHeader="introduction">
2 Typical Resource Requirements for
</sectionHeader>
<subsectionHeader confidence="0.598102">
Translation Selection
</subsectionHeader>
<bodyText confidence="0.837063">
WSD and translation selection approaches may be
broadly classified into two categories depending
</bodyText>
<page confidence="0.970743">
294
</page>
<bodyText confidence="0.951776827586207">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 294–299,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
on the type of learning resources used: knowledge-
and corpus-based. Knowledge-based approaches
make use of various types of information from
existing dictionaries, thesauri, or other lexical re-
sources. Possible knowledge sources include defi-
nition or gloss text (Banerjee and Pedersen, 2003),
subject codes (Magnini et al., 2001), semantic net-
works (Shirai and Yagi, 2004; Mahapatra et al.,
2010) and others.
Nevertheless, lexical resources of such rich con-
tent types are usually available for medium- to rich-
resourced languages only, and are costly to build
and verify by hand. Some approaches therefore
turn to corpus-based approaches, use bilingual cor-
pora as learning resources for translation selection.
(Ide et al., 2002; Ng et al., 2003) used aligned cor-
pora in their work. As it is not always possible to
acquire parallel corpora, comparable corpora, or
even independent second-language corpora have
also been shown to be suitable for training pur-
poses, either by purely numerical means (Li and Li,
2004) or with the aid of syntactic relations (Zhou
et al., 2001). Vector-based models, which capture
the context of a translation or meaning, have also
been used (SchUtze, 1998; Papp, 2009). For under-
resourced languages, however, bilingual corpora of
sufficient size may still be unavailable.
</bodyText>
<sectionHeader confidence="0.9151385" genericHeader="method">
3 Enriching Multilingual Lexicon with
Translation Context Knowledge
</sectionHeader>
<bodyText confidence="0.999881">
Corpus-driven translation selection approaches typ-
ically derive supporting semantic information from
an aligned corpus, where a text and its translation
are aligned at the sentence, phrase and word level.
However, aligned corpora can be difficult to ob-
tain for under-resourced language pairs, and are
expensive to construct.
On the other hand, documents in a comparable
corpus comprise bilingual or multilingual text of
a similar nature, and need not even be exact trans-
lations of each other. The texts are therefore un-
aligned except at the document level. Comparable
corpora are relatively easier to obtain, especially
for richer-resourced languages.
</bodyText>
<subsectionHeader confidence="0.999833">
3.1 Overview of Multilingual Lexicon
</subsectionHeader>
<bodyText confidence="0.999986916666667">
Entries in our multilingual lexicon are organised as
multilingual translation sets, each corresponding to
a coarse-grained concept, and whose members are
LIs from different languages {L1, ... , LN} con-
veying the same concept. We denote an LI as
«item», sometimes with the 3-letter ISO language
code in underscript when necessary: «item»eng. A
list of 3-letter ISO language codes used in this pa-
per is given in Appendix A.
For example, following are two translation sets
containing different senses of English «bank» (‘fi-
nancial institution’ and ‘riverside land’):
</bodyText>
<equation confidence="0.9984685">
TS1 = {«bank»eng, «bank»msa, «银行»zho, . . .}
TS2 = {«bank»eng, «tebing»msa, «岸»zho, . . .}.
</equation>
<bodyText confidence="0.999325166666667">
Multilingual lexicons with under-resourced lan-
guages can be rapidly bootstrapped from simple
bilingual translation lists (Lim et al., 2011). Our
multilingual lexicon currently contains 24371 En-
glish, 13226 Chinese, 35640 Malay, 17063 French,
14687 Thai and 5629 Iban LIs.
</bodyText>
<subsectionHeader confidence="0.9936275">
3.2 Extracting Translation Context
Knowledge from Comparable Corpus
</subsectionHeader>
<bodyText confidence="0.99669764">
We model translation knowledge as a bag-of-words
consisting of the context of a translation equiva-
lence in the corpus. We then run latent seman-
tic indexing (LSI) (Deerwester et al., 1990) on a
comparable bilingual corpora. A vector is then ob-
tained for each LI in both languages, which may
be regarded as encoding some translation context
knowledge.
While LSI is more frequently used in informa-
tion retrieval, the translation knowledge acquisi-
tion task can be recast as a cross-lingual indexing
task, following (Dumais et al., 1997). The underly-
ing intuition is that in a comparable bilingual cor-
pus, a document pair about finance would be more
likely to contain English «bank»eng and Malay
«bank»msa (‘financial institution’), as opposed to
Malay «tebing»msa (‘riverside’). The words ap-
pearing in this document pair would then be an
indicative context for the translation equivalence
between «bank»eng and «bank»msa. In other words,
the translation equivalents present serve as a kind
of implicit sense tag.
Briefly, a translation knowledge vector is ob-
tained for each multilingual translation set from a
bilingual comparable corpus as follows:
</bodyText>
<listItem confidence="0.893898142857143">
1. Each bilingual pair of documents is merged
as one single document, with each LI tagged
with its respective language code.
2. Pre-process the corpus, e.g. remove closed-
class words, perform stemming or lemmati-
sation, and word segmentation for languages
without word boundaries (Chinese, Thai).
</listItem>
<page confidence="0.878293">
295
</page>
<listItem confidence="0.9983722">
3. Construct a term-document matrix (TDM), us-
ing the frequency of terms (each made up by
a LI and its language tag) in each document.
Apply further weighting, e.g. TF-IDF, if nec-
essary.
4. Perform LSI on the TDM. A vector is then
obtained for every LI in both languages.
5. Set the vector associated with each translation
set to be the sum of all available vectors of its
member LIs.
</listItem>
<sectionHeader confidence="0.829992" genericHeader="method">
4 Context-Dependent Lexical Lookup
</sectionHeader>
<bodyText confidence="0.997574615384615">
Given an input text in language Li (1 G i G N),
the lookup module should return a list of multilin-
gual translation set entries, which would contain
L1, L2, ... , LN translation equivalents of LIs in
the input text, wherever available. For polysemous
LIs, the lookup module should return translation
sets that convey the appropriate meaning in context.
For each input text segment Q (typically a sen-
tence), a ‘query vector’, VQ is computed by taking
the vectorial sum of all open class LIs in the in-
put Q. For each LI l in the input, the list of all
translation sets containing l, is retrieved into TSl.
TSl is then sorted in descending order of
</bodyText>
<equation confidence="0.999223">
Vt - VQ
CSim(Vt, VQ) =
|Vt |X |VQ|
</equation>
<bodyText confidence="0.996166272727273">
(i.e. the cosine similarity between the query vector
VQ and the translation set candidate t’s vector) for
all t E TSl.
If the language of input Q is not present in
the bilingual training corpus (e.g. Iban, an under-
resourced language spoken in Borneo), VQ is then
computed as the sum of all vectors associated with
all translation sets in TSl. For example, given the
Iban sentence ‘Lelaki nya tikah enggau emperaja
iya, siko dayang ke ligung’ (‘he married his sweet-
heart, a pretty girl’), VQ would be computed as
</bodyText>
<equation confidence="0.9780088">
VQ = V (lookup(«lelaki»iba))
+ V (lookup(«tikah»iba))
+ V (lookup(«emperaja»iba))
+ V (lookup(«dayang»iba))
+ V (lookup(«ligung»iba))
</equation>
<bodyText confidence="0.99942">
where the function lookup(w) returns the transla-
tion sets containing LI w.
</bodyText>
<sectionHeader confidence="0.993962" genericHeader="method">
5 Prototype Implementation
</sectionHeader>
<bodyText confidence="0.999952447368421">
We have implemented LEXICALSELECTOR, a pro-
totype context-dependent lexical lookup tool in
Java, trained on a English–Malay bilingual cor-
pus built from Wikipedia articles. Wikipedia ar-
ticles are freely available under a Creative Com-
mons license, thus providing a convenient source
of bilingual comparable corpus. Note that while
the training corpus is English–Malay, the trained
lookup tool can be applied to texts of any language
included in the multilingual dictionary.
Malay Wikipedia articles1 and their correspond-
ing English articles of the same topics2 were first
downloaded. To form the bilingual corpus, each
Malay article is concatenated with its correspond-
ing English article as one document.
The TDM constructed from this corpus con-
tains 62 993 documents and 67 499 terms, includ-
ing both English and Malay items. The TDM is
weighted by TF-IDF, then processed by LSI using
the Gensim Python library3. The indexing process,
using 1000 factors, took about 45 minutes on a
MacBook Pro with a 2.3 GHz processor and 4 GB
RAM. The vectors obtained for each English and
Malay LIs were then used to populate the transla-
tion context knowledge vectors of translation set
in a multilingual lexicon, which comprise six lan-
guages: English, Malay, Chinese, French, Thai and
Iban.
As mentioned earlier, LEXICALSELECTOR can
process texts in any member languages of the mul-
tilingual lexicon, instead of only the languages of
the training corpus (English and Malay). Figure 1
shows the context-depended lexical lookup out-
puts for the Iban input ‘Lelaki nya tikah enggau
emperaja iya, siko dayang ke ligung’. Note that
«emperaja» is polysemous (‘rainbow’ or ‘lover’),
but is successfully identified as meaning ‘lover’ in
this sentence.
</bodyText>
<sectionHeader confidence="0.987545" genericHeader="method">
6 Early Experimental Results
</sectionHeader>
<bodyText confidence="0.880664">
80 input sentences containing LIs with translation
ambiguities were randomly selected from the Inter-
net (English, Malay and Chinese) and contributed
by a native speaker (Iban). The test words are:
</bodyText>
<listItem confidence="0.990212">
• English «plant» (vegetation or factory),
</listItem>
<footnote confidence="0.99975825">
1http://dumps.wikimedia.org/mswiki/
2http://en.wikipedia.org/wiki/Special:
Export
3http://radimrehurek.com/gensim/
</footnote>
<page confidence="0.996709">
296
</page>
<figureCaption confidence="0.9724715">
Figure 1: LEXICALSELECTOR output for Iban input ‘Lelaki nya tikah enggau emperaja iya, siko dayang
ke ligung’. Only top ranked translation sets are shown.
</figureCaption>
<listItem confidence="0.999128714285714">
• English «bank» (financial institution or river-
side land),
• Malay «kabinet» (governmental Cabinet or
household furniture),
• Malay «mangga» (mango or padlock),
• Chinese «谷» (gù, valley or grain) and
• Iban «emperaja» (rainbow or lover).
</listItem>
<bodyText confidence="0.999883615384615">
Each test sentence was first POS-tagged auto-
matically based on the Penn Treebank tagset. The
English test sentences were lemmatised and POS-
tagged with the Stanford Parser.4 The Chinese test
sentences segmented with the Stanford Chinese
Word Segmenter tool.5 For Malay POS-tagging,
we trained the QTag tagger6 on a hand-tagged
Malay corpus, and applied the trained tagger on our
test sentences. As we lacked a Iban POS-tagger,
the Iban test sentences were tagged by hand. LIs
of each language and their associated vectors can
then be retrieved from the multilingual lexicon.
The prototype tool LEXICALSELECTOR then
computes the CSim score and ranks potential trans-
lation sets for each LI in the input sentences
(ranking strategy wiki-lsi). The baseline strat-
egy (base-freq) selects the translation set whose
members occur most frequently in the bilingual
Wikipedia corpus.
As a comparison, the English, Chinese and
Malay test sentences were fed to Google Trans-
late7 and translated into Chinese, Malay and En-
glish. (Google Translate does not support Iban
currently.) The Google Translate interface makes
available the ranked list of translation candidates
for each word in an input sentence, one language
</bodyText>
<footnote confidence="0.994204833333333">
4http://www-nlp.stanford.edu/software/
lex-parser.shtml
5http://nlp.stanford.edu/software/segmenter.
shtml
6http://phrasys.net/uob/om/software
7http://translate.google.com on 3 October 2012
</footnote>
<bodyText confidence="0.998923588235294">
at a time.The translated word for each of the input
test word can therefore be noted. The highest rank
of the correct translation for the test words in En-
glish/Chinese/Malay are used to evaluate goog-tr.
Two metrics were used in this quick evaluation.
The first metric is by taking the precision of the first
translation set returned by each ranking strategy,
i.e. whether the top ranked translation set contains
the correct translation of the ambiguous item. The
precision metric is important for applications like
machine translation, where only the top-ranked
meaning or translation is considered.
The results may also be evaluated similar to a
document retrieval task, i.e. as a ranked lexical
lookup for human consumption. This is measured
by the mean reciprocal rank (MRR), the average
of the reciprocal ranks of the correct translation set
for each input sentence in the test set T:
The results for the three ranking strategies are
summarised in Table 1. For the precision metric,
wiki-lsi scored 0.650 when all 80 input sen-
tences are tested, while the base-freq baseline
scored 0.550. goog-tr has the highest precision
at 0.797. However, if only the Chinese and Malay
inputs — which has less presence on the Inter-
net and ‘less resource-rich’ than English — were
tested (since goog-tr cannot accept Iban inputs),
wiki-lsi and goog-tr actually performs equally
well at 0.690 precision.
In our evaluation, the MRR score of wiki-lsi
is 0.810, while base-freq scored 0.771.
wiki-lsi even outperforms goog-tr when
only the Chinese and Malay test sentences are
considered for the MRR metric, as goog-tr
</bodyText>
<figure confidence="0.624311714285714">
1
1
ITI
MRR =
ranki
� �Tj
i=1
</figure>
<page confidence="0.994015">
297
</page>
<tableCaption confidence="0.9036745">
Table 1: Precision and MRR scores of context-
dependent lexical lookup
</tableCaption>
<table confidence="0.9760436">
Strategy Incl. Eng. &amp; Iban W/o Eng. &amp; Iban
Precision MRR Precision MRR
wiki-lsi 0.650 0.810 0.690 0.845
base-freq 0.550 0.771 0.524 0.762
goog-tr 0.797 0.812 0.690 0.708
</table>
<bodyText confidence="0.9994506">
did not present the correct translation in its list
of alternative translation candidates for some
test sentences. This suggests that the LSI-based
translation context knowledge vectors would be
helpful in building an intelligent reading aid.
</bodyText>
<sectionHeader confidence="0.99893" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999977185185185">
wiki-lsi performed better than base-freq for
both the precision and the MRR metrics, although
further tests is warranted, given the small size of
the current test set. While wiki-lsi is not yet
sufficiently accurate to be used directly in an MT
system, it is helpful in producing a list of ranked
multilingual translation sets depending on the input
context, as part of an intelligent reading aid. Specif-
ically, the lookup module would have benefited if
syntactic information (e.g. syntactic relations and
parse trees) was incorporated during the training
and testing phase. This would require more time
in parsing the training corpus, as well as assuming
that syntactic analysis tools are available to pro-
cess test sentences of all languages, including the
under-resourced ones.
Note that even though the translation context
knowledge vectors were extracted from an English–
Malay corpus, the same vectors can be applied on
Chinese and Iban input sentences as well. This
is especially significant for Iban, which otherwise
lacks resources from which a lookup or disambigua-
tion tool can be trained. Translation context knowl-
edge vectors mined via LSI from a bilingual com-
parable corpus, therefore offers a fast, low cost and
efficient fallback strategy for acquiring multilin-
gual translation equivalence context information.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999963115384615">
Basile and Semeraro (2010) also used Wikipedia
articles as a parallel corpus for their participation
in the SemEval 2010 Cross-Lingual Lexical Sub-
stitution task. Both training and test data were for
English–Spanish. The idea behind their system
is to count, for each potential Spanish candidate,
the number of documents in which the target En-
glish word and the Spanish candidate occurs in
an English–Spanish document pair. In the task’s
‘best’ evaluation (which is comparable to our ‘Preci-
sion’ metric), Basile and Semeraro’s system scored
26.39 precision on the trial data and 19.68 preci-
sion on the SemEval test data. This strategy of
selecting the most frequent translation is similar to
our base-freq baseline strategy.
Sarrafzadeh et al. (2011) also tackled the prob-
lem of cross-lingual disambiguation for under-
resourced language pairs (English–Persian) using
Wikipedia articles, by applying the one sense per
collocation and one sense per discourse heuristics
on a comparable corpus. The authors incorporated
English and Persian wordnets in their system, thus
achieving 0.68 for the ‘best sense’ (‘Precision’)
evaluation. However, developing wordnets for new
languages is no trivial effort, as acknowledged by
the authors.
</bodyText>
<sectionHeader confidence="0.997119" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999978071428571">
We extracted translation context knowledge from a
bilingual comparable corpus by running LSI on the
corpus. A context-dependent multilingual lexical
lookup module was implemented, using the cosine
similarity score between the vector of the input
sentence and those of candidate translation sets to
rank the latter in order of relevance. The precision
and MRR scores outperformed Google Translate’s
lexical selection for medium- and under-resourced
language test inputs. The LSI-backed translation
context knowledge vectors, mined from bilingual
comparable corpora, thus provide an fast and af-
fordable data source for building intelligent reading
aids, especially for under-resourced languages.
</bodyText>
<sectionHeader confidence="0.998136" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9993012">
The authors thank Multimedia University and Uni-
versiti Malaysia Sarawak for providing support and
resources during the conduct of this study. We also
thank Panceras Talita for helping to prepare the
Iban test sentences for context-dependent lookup.
</bodyText>
<table confidence="0.8103824">
A 3-Letter ISO Language Codes
Code Language Code Language
eng English msa Malay
zho Chinese fra French
tha Thai iba Iban
</table>
<page confidence="0.992367">
298
</page>
<sectionHeader confidence="0.993729" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997927892857143">
Satanjeev Banerjee and Ted Pedersen. 2003. Extended
gloss overlaps as a measure of semantic relatedness.
In Proceedings of the 18th International Joint Con-
ference on Artificial Intelligence, pages 805–810.
Pierpaolo Basile and Giovanni Semeraro. 2010. UBA:
Using automatic translation and Wikipedia for cross-
lingual lexical substitution. In Proceedings of the
5th International Workshop on Semantic Evaluation
(SemEval 2010), pages 242–247, Uppsala, Sweden.
Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society for Information Science,
41(6):391–407.
Susan T. Dumais, Michael L. Littman, and Thomas K.
Landauer. 1997. Automatic cross-language re-
trieval using latent semantic indexing. In AAAI97
Spring Symposium Series: Cross Language Text and
Speech Retrieval, pages 18–24, Stanford University.
Nancy Ide, Tomaz Erjavec, and Dan Tufi¸s. 2002.
Sense discrimination with parallel corpora. In Pro-
ceedings of the SIGLEX/SENSEVAL Workshop on
Word Sense Disambiguation: Recent Successes and
Future Directions, pages 54–60, Philadelphia, USA.
Els Lefever and Véronique Hoste. 2010. SemEval-
2010 Task 3: Cross-lingual word sense disambigua-
tion. In Proceedings of the 5th International Work-
shop on Semantic Evaluation (SemEval 2010), Upp-
sala, Sweden.
Hang Li and Cong Li. 2004. Word translation disam-
biguation using bilingual bootstrapping. Computa-
tional Linguistics, 30(1):1–22.
Lian Tze Lim, Bali Ranaivo-Malançon, and Enya Kong
Tang. 2011. Low cost construction of a multilingual
lexicon from bilingual lists. Polibits, 43:45–51.
Bernardo Magnini, Carlo Strapparava, Giovanni Pez-
zulo, and Alfio Gliozzo. 2001. Using domain
information for word sense disambiguation. In
Proceedings of the 2nd International Workshop on
Evaluating Word Sense Disambiguation Systems
(SENSEVAL-2), pages 111–114, Toulouse, France.
Lipta Mahapatra, Meera Mohan, Mitesh M. Khapra,
and Pushpak Bhattacharyya. 2010. OWNS: Cross-
lingual word sense disambiguation using weighted
overlap counts and Wordnet based similarity mea-
sures. In Proceedings of the 5th International Work-
shop on Semantic Evaluation (SemEval 2010), Upp-
sala, Sweden.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy.
2010. SemEval-2010 Task 2: Cross-lingual lexical
substitution. In Proceedings of the 5th International
Workshop on Semantic Evaluation (SemEval 2010),
Uppsala, Sweden.
Hwee Tou Ng, Bin Wang, and Yee Seng Chan. 2003.
Exploiting parallel texts for word sense disambigua-
tion: An empirical study. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 455–462, Sapporo, Japan.
Gyula Papp. 2009. Vector-based unsupervised word
sense disambiguation for large number of contexts.
In Václav Matoušek and Pavel Mautner, editors,
Text, Speech and Dialogue, volume 5729 of Lec-
ture Notes in Computer Science, pages 109–115.
Springer Berlin Heidelberg.
Bahareh Sarrafzadeh, Nikolay Yakovets, Nick Cercone,
and Aijun An. 2011. Cross-lingual word sense dis-
ambiguation for languages with scarce resources. In
Proceedings of the 24th Canadian Conference on
Advances in Artificial Intelligence, pages 347–358,
St. John’s, Canada.
Hinrich Schütze. 1998. Automatic word sense discrim-
ination. Computational Linguistics, 24(1):97–123.
Kiyoaki Shirai and Tsunekazu Yagi. 2004. Learn-
ing a robust word sense disambiguation model us-
ing hypernyms in definition sentences. In Proceed-
ings of the 20th International Conference on Com-
putational Linguistics (COLING 2004), pages 917–
923, Geneva, Switzerland. Association for Compu-
tational Linguistics.
Ming Zhou, Yuan Ding, and Changning Huang. 2001.
Improviging translation selection with a new transla-
tion model trained by independent monolingual cor-
pora. Computational Linguistics and Chinese lan-
guage Processing, 6(1):1–26.
</reference>
<page confidence="0.998655">
299
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.281950">
<title confidence="0.9974855">Context-Dependent Multilingual Lexical Lookup for Under-Resourced Languages</title>
<author confidence="0.947463">Tze</author>
<affiliation confidence="0.999405">KDU College</affiliation>
<address confidence="0.515895">Georgetown, Penang,</address>
<email confidence="0.999457">liantze@gmail.com</email>
<author confidence="0.987179">Enya Kong</author>
<affiliation confidence="0.7976945">Linton University Seremban, Negeri Sembilan,</affiliation>
<email confidence="0.998689">enyakong1@gmail.com</email>
<abstract confidence="0.999430416666666">Current approaches for word sense disambiguation and translation selection typically require lexical resources or large bilingual corpora with rich information fields and annotations, which are often infeasible for under-resourced languages. We extract translation context knowledge from a bilingual comparable corpora of a richer-resourced language pair, and inject it into a multilingual lexicon. The multilingual lexicon can then be used to perform context-dependent lexical lookup on texts of any language, including under-resourced ones. Evaluations on a prototype lookup tool, trained on a English–Malay bilingual Wikipedia corpus, show a precision score of 0.65 (baseline 0.55) and mean reciprocal rank score of 0.81 (baseline 0.771). Based on the early encouraging results, the context-dependent lexical lookup tool may be developed further into an intelligent reading aid, to help users grasp the gist of a second or foreign language text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Extended gloss overlaps as a measure of semantic relatedness.</title>
<date>2003</date>
<booktitle>In Proceedings of the 18th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>805--810</pages>
<contexts>
<context position="4339" citStr="Banerjee and Pedersen, 2003" startWordPosition="621" endWordPosition="624">l Resource Requirements for Translation Selection WSD and translation selection approaches may be broadly classified into two categories depending 294 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 294–299, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics on the type of learning resources used: knowledgeand corpus-based. Knowledge-based approaches make use of various types of information from existing dictionaries, thesauri, or other lexical resources. Possible knowledge sources include definition or gloss text (Banerjee and Pedersen, 2003), subject codes (Magnini et al., 2001), semantic networks (Shirai and Yagi, 2004; Mahapatra et al., 2010) and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-langu</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 805–810.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierpaolo Basile</author>
<author>Giovanni Semeraro</author>
</authors>
<title>UBA: Using automatic translation and Wikipedia for crosslingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>242--247</pages>
<location>Uppsala,</location>
<contexts>
<context position="17794" citStr="Basile and Semeraro (2010)" startWordPosition="2727" endWordPosition="2730">es, including the under-resourced ones. Note that even though the translation context knowledge vectors were extracted from an English– Malay corpus, the same vectors can be applied on Chinese and Iban input sentences as well. This is especially significant for Iban, which otherwise lacks resources from which a lookup or disambiguation tool can be trained. Translation context knowledge vectors mined via LSI from a bilingual comparable corpus, therefore offers a fast, low cost and efficient fallback strategy for acquiring multilingual translation equivalence context information. 8 Related Work Basile and Semeraro (2010) also used Wikipedia articles as a parallel corpus for their participation in the SemEval 2010 Cross-Lingual Lexical Substitution task. Both training and test data were for English–Spanish. The idea behind their system is to count, for each potential Spanish candidate, the number of documents in which the target English word and the Spanish candidate occurs in an English–Spanish document pair. In the task’s ‘best’ evaluation (which is comparable to our ‘Precision’ metric), Basile and Semeraro’s system scored 26.39 precision on the trial data and 19.68 precision on the SemEval test data. This s</context>
</contexts>
<marker>Basile, Semeraro, 2010</marker>
<rawString>Pierpaolo Basile and Giovanni Semeraro. 2010. UBA: Using automatic translation and Wikipedia for crosslingual lexical substitution. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval 2010), pages 242–247, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="7288" citStr="Deerwester et al., 1990" startWordPosition="1074" endWordPosition="1077">d’): TS1 = {«bank»eng, «bank»msa, «银行»zho, . . .} TS2 = {«bank»eng, «tebing»msa, «岸»zho, . . .}. Multilingual lexicons with under-resourced languages can be rapidly bootstrapped from simple bilingual translation lists (Lim et al., 2011). Our multilingual lexicon currently contains 24371 English, 13226 Chinese, 35640 Malay, 17063 French, 14687 Thai and 5629 Iban LIs. 3.2 Extracting Translation Context Knowledge from Comparable Corpus We model translation knowledge as a bag-of-words consisting of the context of a translation equivalence in the corpus. We then run latent semantic indexing (LSI) (Deerwester et al., 1990) on a comparable bilingual corpora. A vector is then obtained for each LI in both languages, which may be regarded as encoding some translation context knowledge. While LSI is more frequently used in information retrieval, the translation knowledge acquisition task can be recast as a cross-lingual indexing task, following (Dumais et al., 1997). The underlying intuition is that in a comparable bilingual corpus, a document pair about finance would be more likely to contain English «bank»eng and Malay «bank»msa (‘financial institution’), as opposed to Malay «tebing»msa (‘riverside’). The words ap</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan T Dumais</author>
<author>Michael L Littman</author>
<author>Thomas K Landauer</author>
</authors>
<title>Automatic cross-language retrieval using latent semantic indexing.</title>
<date>1997</date>
<booktitle>In AAAI97 Spring Symposium Series: Cross Language Text and Speech Retrieval,</booktitle>
<pages>18--24</pages>
<institution>Stanford University.</institution>
<contexts>
<context position="7633" citStr="Dumais et al., 1997" startWordPosition="1130" endWordPosition="1133"> and 5629 Iban LIs. 3.2 Extracting Translation Context Knowledge from Comparable Corpus We model translation knowledge as a bag-of-words consisting of the context of a translation equivalence in the corpus. We then run latent semantic indexing (LSI) (Deerwester et al., 1990) on a comparable bilingual corpora. A vector is then obtained for each LI in both languages, which may be regarded as encoding some translation context knowledge. While LSI is more frequently used in information retrieval, the translation knowledge acquisition task can be recast as a cross-lingual indexing task, following (Dumais et al., 1997). The underlying intuition is that in a comparable bilingual corpus, a document pair about finance would be more likely to contain English «bank»eng and Malay «bank»msa (‘financial institution’), as opposed to Malay «tebing»msa (‘riverside’). The words appearing in this document pair would then be an indicative context for the translation equivalence between «bank»eng and «bank»msa. In other words, the translation equivalents present serve as a kind of implicit sense tag. Briefly, a translation knowledge vector is obtained for each multilingual translation set from a bilingual comparable corpu</context>
</contexts>
<marker>Dumais, Littman, Landauer, 1997</marker>
<rawString>Susan T. Dumais, Michael L. Littman, and Thomas K. Landauer. 1997. Automatic cross-language retrieval using latent semantic indexing. In AAAI97 Spring Symposium Series: Cross Language Text and Speech Retrieval, pages 18–24, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Tomaz Erjavec</author>
<author>Dan Tufi¸s</author>
</authors>
<title>Sense discrimination with parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,</booktitle>
<pages>54--60</pages>
<location>Philadelphia, USA.</location>
<marker>Ide, Erjavec, Tufi¸s, 2002</marker>
<rawString>Nancy Ide, Tomaz Erjavec, and Dan Tufi¸s. 2002. Sense discrimination with parallel corpora. In Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions, pages 54–60, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Véronique Hoste</author>
</authors>
<title>SemEval2010 Task 3: Cross-lingual word sense disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="2311" citStr="Lefever and Hoste, 2010" startWordPosition="329" endWordPosition="332">ed by a human reader when reading or browsing a text written in a second or foreign language. For convenience’s sake, we will call this task (as performed Lay-Ki Soon and Tek Yong Lim †FCI, Multimedia University Cyberjaya, Selangor, Malaysia {lksoon,tylim}@mmu.edu.my Bali Ranaivo-Malançon FCSIT, Universiti Malaysia Sarawak, Kota Samarahan, Sarawak, Malaysia mbranaivo@fit.unimas.my via computational means) context-dependent lexical lookup. It can also be viewed as a simplified version of the Cross-Lingual Lexical Substitution (Mihalcea et al., 2010) and Cross-Lingual Word Sense Disambiguation (Lefever and Hoste, 2010) tasks, as defined in SemEval-2010. There is a large body of work around WSD and translation selection. However, many of these approaches require lexical resources or large bilingual corpora with rich information fields and annotations, as reviewed in section 2. Unfortunately, not all languages have equal amounts of digital resources for developing language technologies, and such requirements are often infeasible for underresourced languages. We are interested in leveraging richer-resourced language pairs to enable context-dependent lexical lookup for under-resourced languages. For this purpos</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Véronique Hoste. 2010. SemEval2010 Task 3: Cross-lingual word sense disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval 2010), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Cong Li</author>
</authors>
<title>Word translation disambiguation using bilingual bootstrapping.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="5060" citStr="Li and Li, 2004" startWordPosition="737" endWordPosition="740"> and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by purely numerical means (Li and Li, 2004) or with the aid of syntactic relations (Zhou et al., 2001). Vector-based models, which capture the context of a translation or meaning, have also been used (SchUtze, 1998; Papp, 2009). For underresourced languages, however, bilingual corpora of sufficient size may still be unavailable. 3 Enriching Multilingual Lexicon with Translation Context Knowledge Corpus-driven translation selection approaches typically derive supporting semantic information from an aligned corpus, where a text and its translation are aligned at the sentence, phrase and word level. However, aligned corpora can be difficu</context>
</contexts>
<marker>Li, Li, 2004</marker>
<rawString>Hang Li and Cong Li. 2004. Word translation disambiguation using bilingual bootstrapping. Computational Linguistics, 30(1):1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lian Tze Lim</author>
<author>Bali Ranaivo-Malançon</author>
<author>Enya Kong Tang</author>
</authors>
<title>Low cost construction of a multilingual lexicon from bilingual lists.</title>
<date>2011</date>
<tech>Polibits, 43:45–51.</tech>
<contexts>
<context position="6900" citStr="Lim et al., 2011" startWordPosition="1015" endWordPosition="1018">ages {L1, ... , LN} conveying the same concept. We denote an LI as «item», sometimes with the 3-letter ISO language code in underscript when necessary: «item»eng. A list of 3-letter ISO language codes used in this paper is given in Appendix A. For example, following are two translation sets containing different senses of English «bank» (‘financial institution’ and ‘riverside land’): TS1 = {«bank»eng, «bank»msa, «银行»zho, . . .} TS2 = {«bank»eng, «tebing»msa, «岸»zho, . . .}. Multilingual lexicons with under-resourced languages can be rapidly bootstrapped from simple bilingual translation lists (Lim et al., 2011). Our multilingual lexicon currently contains 24371 English, 13226 Chinese, 35640 Malay, 17063 French, 14687 Thai and 5629 Iban LIs. 3.2 Extracting Translation Context Knowledge from Comparable Corpus We model translation knowledge as a bag-of-words consisting of the context of a translation equivalence in the corpus. We then run latent semantic indexing (LSI) (Deerwester et al., 1990) on a comparable bilingual corpora. A vector is then obtained for each LI in both languages, which may be regarded as encoding some translation context knowledge. While LSI is more frequently used in information </context>
</contexts>
<marker>Lim, Ranaivo-Malançon, Tang, 2011</marker>
<rawString>Lian Tze Lim, Bali Ranaivo-Malançon, and Enya Kong Tang. 2011. Low cost construction of a multilingual lexicon from bilingual lists. Polibits, 43:45–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Carlo Strapparava</author>
<author>Giovanni Pezzulo</author>
<author>Alfio Gliozzo</author>
</authors>
<title>Using domain information for word sense disambiguation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2),</booktitle>
<pages>111--114</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="4377" citStr="Magnini et al., 2001" startWordPosition="627" endWordPosition="630">tion WSD and translation selection approaches may be broadly classified into two categories depending 294 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 294–299, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics on the type of learning resources used: knowledgeand corpus-based. Knowledge-based approaches make use of various types of information from existing dictionaries, thesauri, or other lexical resources. Possible knowledge sources include definition or gloss text (Banerjee and Pedersen, 2003), subject codes (Magnini et al., 2001), semantic networks (Shirai and Yagi, 2004; Mahapatra et al., 2010) and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be</context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2001</marker>
<rawString>Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo, and Alfio Gliozzo. 2001. Using domain information for word sense disambiguation. In Proceedings of the 2nd International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2), pages 111–114, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lipta Mahapatra</author>
<author>Meera Mohan</author>
<author>Mitesh M Khapra</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>OWNS: Crosslingual word sense disambiguation using weighted overlap counts and Wordnet based similarity measures.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="4444" citStr="Mahapatra et al., 2010" startWordPosition="638" endWordPosition="641">sified into two categories depending 294 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 294–299, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics on the type of learning resources used: knowledgeand corpus-based. Knowledge-based approaches make use of various types of information from existing dictionaries, thesauri, or other lexical resources. Possible knowledge sources include definition or gloss text (Banerjee and Pedersen, 2003), subject codes (Magnini et al., 2001), semantic networks (Shirai and Yagi, 2004; Mahapatra et al., 2010) and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by purely numerical means (</context>
</contexts>
<marker>Mahapatra, Mohan, Khapra, Bhattacharyya, 2010</marker>
<rawString>Lipta Mahapatra, Meera Mohan, Mitesh M. Khapra, and Pushpak Bhattacharyya. 2010. OWNS: Crosslingual word sense disambiguation using weighted overlap counts and Wordnet based similarity measures. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval 2010), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Ravi Sinha</author>
<author>Diana McCarthy</author>
</authors>
<title>SemEval-2010 Task 2: Cross-lingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="2241" citStr="Mihalcea et al., 2010" startWordPosition="320" endWordPosition="323">slations. This then resembles a dictionary lookup process as performed by a human reader when reading or browsing a text written in a second or foreign language. For convenience’s sake, we will call this task (as performed Lay-Ki Soon and Tek Yong Lim †FCI, Multimedia University Cyberjaya, Selangor, Malaysia {lksoon,tylim}@mmu.edu.my Bali Ranaivo-Malançon FCSIT, Universiti Malaysia Sarawak, Kota Samarahan, Sarawak, Malaysia mbranaivo@fit.unimas.my via computational means) context-dependent lexical lookup. It can also be viewed as a simplified version of the Cross-Lingual Lexical Substitution (Mihalcea et al., 2010) and Cross-Lingual Word Sense Disambiguation (Lefever and Hoste, 2010) tasks, as defined in SemEval-2010. There is a large body of work around WSD and translation selection. However, many of these approaches require lexical resources or large bilingual corpora with rich information fields and annotations, as reviewed in section 2. Unfortunately, not all languages have equal amounts of digital resources for developing language technologies, and such requirements are often infeasible for underresourced languages. We are interested in leveraging richer-resourced language pairs to enable context-d</context>
</contexts>
<marker>Mihalcea, Sinha, McCarthy, 2010</marker>
<rawString>Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. SemEval-2010 Task 2: Cross-lingual lexical substitution. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval 2010), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Bin Wang</author>
<author>Yee Seng Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>455--462</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="4792" citStr="Ng et al., 2003" startWordPosition="693" endWordPosition="696">rmation from existing dictionaries, thesauri, or other lexical resources. Possible knowledge sources include definition or gloss text (Banerjee and Pedersen, 2003), subject codes (Magnini et al., 2001), semantic networks (Shirai and Yagi, 2004; Mahapatra et al., 2010) and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by purely numerical means (Li and Li, 2004) or with the aid of syntactic relations (Zhou et al., 2001). Vector-based models, which capture the context of a translation or meaning, have also been used (SchUtze, 1998; Papp, 2009). For underresourced languages, however, bilingual corpora of sufficient size may still be unavailable. 3 Enriching Multilingual Lexicon with Transl</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>Hwee Tou Ng, Bin Wang, and Yee Seng Chan. 2003. Exploiting parallel texts for word sense disambiguation: An empirical study. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 455–462, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gyula Papp</author>
</authors>
<title>Vector-based unsupervised word sense disambiguation for large number of contexts.</title>
<date>2009</date>
<booktitle>In Václav Matoušek and Pavel Mautner, editors, Text, Speech and Dialogue,</booktitle>
<volume>5729</volume>
<pages>109--115</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="5244" citStr="Papp, 2009" startWordPosition="769" endWordPosition="770">pproaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by purely numerical means (Li and Li, 2004) or with the aid of syntactic relations (Zhou et al., 2001). Vector-based models, which capture the context of a translation or meaning, have also been used (SchUtze, 1998; Papp, 2009). For underresourced languages, however, bilingual corpora of sufficient size may still be unavailable. 3 Enriching Multilingual Lexicon with Translation Context Knowledge Corpus-driven translation selection approaches typically derive supporting semantic information from an aligned corpus, where a text and its translation are aligned at the sentence, phrase and word level. However, aligned corpora can be difficult to obtain for under-resourced language pairs, and are expensive to construct. On the other hand, documents in a comparable corpus comprise bilingual or multilingual text of a simila</context>
</contexts>
<marker>Papp, 2009</marker>
<rawString>Gyula Papp. 2009. Vector-based unsupervised word sense disambiguation for large number of contexts. In Václav Matoušek and Pavel Mautner, editors, Text, Speech and Dialogue, volume 5729 of Lecture Notes in Computer Science, pages 109–115. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bahareh Sarrafzadeh</author>
<author>Nikolay Yakovets</author>
<author>Nick Cercone</author>
<author>Aijun An</author>
</authors>
<title>Cross-lingual word sense disambiguation for languages with scarce resources.</title>
<date>2011</date>
<booktitle>In Proceedings of the 24th Canadian Conference on Advances in Artificial Intelligence,</booktitle>
<pages>347--358</pages>
<publisher>St. John’s, Canada.</publisher>
<contexts>
<context position="18517" citStr="Sarrafzadeh et al. (2011)" startWordPosition="2841" endWordPosition="2844">ss-Lingual Lexical Substitution task. Both training and test data were for English–Spanish. The idea behind their system is to count, for each potential Spanish candidate, the number of documents in which the target English word and the Spanish candidate occurs in an English–Spanish document pair. In the task’s ‘best’ evaluation (which is comparable to our ‘Precision’ metric), Basile and Semeraro’s system scored 26.39 precision on the trial data and 19.68 precision on the SemEval test data. This strategy of selecting the most frequent translation is similar to our base-freq baseline strategy. Sarrafzadeh et al. (2011) also tackled the problem of cross-lingual disambiguation for underresourced language pairs (English–Persian) using Wikipedia articles, by applying the one sense per collocation and one sense per discourse heuristics on a comparable corpus. The authors incorporated English and Persian wordnets in their system, thus achieving 0.68 for the ‘best sense’ (‘Precision’) evaluation. However, developing wordnets for new languages is no trivial effort, as acknowledged by the authors. 9 Conclusion We extracted translation context knowledge from a bilingual comparable corpus by running LSI on the corpus.</context>
</contexts>
<marker>Sarrafzadeh, Yakovets, Cercone, An, 2011</marker>
<rawString>Bahareh Sarrafzadeh, Nikolay Yakovets, Nick Cercone, and Aijun An. 2011. Cross-lingual word sense disambiguation for languages with scarce resources. In Proceedings of the 24th Canadian Conference on Advances in Artificial Intelligence, pages 347–358, St. John’s, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Schütze, 1998</marker>
<rawString>Hinrich Schütze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoaki Shirai</author>
<author>Tsunekazu Yagi</author>
</authors>
<title>Learning a robust word sense disambiguation model using hypernyms in definition sentences.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>917--923</pages>
<institution>Geneva, Switzerland. Association for Computational Linguistics.</institution>
<contexts>
<context position="4419" citStr="Shirai and Yagi, 2004" startWordPosition="634" endWordPosition="637">hes may be broadly classified into two categories depending 294 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 294–299, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics on the type of learning resources used: knowledgeand corpus-based. Knowledge-based approaches make use of various types of information from existing dictionaries, thesauri, or other lexical resources. Possible knowledge sources include definition or gloss text (Banerjee and Pedersen, 2003), subject codes (Magnini et al., 2001), semantic networks (Shirai and Yagi, 2004; Mahapatra et al., 2010) and others. Nevertheless, lexical resources of such rich content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by</context>
</contexts>
<marker>Shirai, Yagi, 2004</marker>
<rawString>Kiyoaki Shirai and Tsunekazu Yagi. 2004. Learning a robust word sense disambiguation model using hypernyms in definition sentences. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), pages 917– 923, Geneva, Switzerland. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Zhou</author>
<author>Yuan Ding</author>
<author>Changning Huang</author>
</authors>
<title>Improviging translation selection with a new translation model trained by independent monolingual corpora.</title>
<date>2001</date>
<booktitle>Computational Linguistics and Chinese language Processing,</booktitle>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="5119" citStr="Zhou et al., 2001" startWordPosition="748" endWordPosition="751"> content types are usually available for medium- to richresourced languages only, and are costly to build and verify by hand. Some approaches therefore turn to corpus-based approaches, use bilingual corpora as learning resources for translation selection. (Ide et al., 2002; Ng et al., 2003) used aligned corpora in their work. As it is not always possible to acquire parallel corpora, comparable corpora, or even independent second-language corpora have also been shown to be suitable for training purposes, either by purely numerical means (Li and Li, 2004) or with the aid of syntactic relations (Zhou et al., 2001). Vector-based models, which capture the context of a translation or meaning, have also been used (SchUtze, 1998; Papp, 2009). For underresourced languages, however, bilingual corpora of sufficient size may still be unavailable. 3 Enriching Multilingual Lexicon with Translation Context Knowledge Corpus-driven translation selection approaches typically derive supporting semantic information from an aligned corpus, where a text and its translation are aligned at the sentence, phrase and word level. However, aligned corpora can be difficult to obtain for under-resourced language pairs, and are ex</context>
</contexts>
<marker>Zhou, Ding, Huang, 2001</marker>
<rawString>Ming Zhou, Yuan Ding, and Changning Huang. 2001. Improviging translation selection with a new translation model trained by independent monolingual corpora. Computational Linguistics and Chinese language Processing, 6(1):1–26.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>