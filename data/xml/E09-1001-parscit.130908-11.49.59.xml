<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002940">
<title confidence="0.985659">
Slacker semantics: why superficiality, dependency and avoidance of
commitment can be the right way to go
</title>
<author confidence="0.991865">
Ann Copestake
</author>
<affiliation confidence="0.994302">
Computer Laboratory, University of Cambridge
</affiliation>
<address confidence="0.856288">
15 JJ Thomson Avenue, Cambridge, UK
</address>
<email confidence="0.998986">
aac@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993899" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999511">
This paper discusses computational com-
positional semantics from the perspective
of grammar engineering, in the light of ex-
perience with the use of Minimal Recur-
sion Semantics in DELPH-IN grammars.
The relationship between argument index-
ation and semantic role labelling is ex-
plored and a semantic dependency nota-
tion (DMRS) is introduced.
</bodyText>
<sectionHeader confidence="0.998792" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999898985507247">
The aim of this paper is to discuss work on com-
positional semantics from the perspective of gram-
mar engineering, which I will take here as the de-
velopment of (explicitly) linguistically-motivated
computational grammars. The paper was written
to accompany an invited talk: it is intended to pro-
vide background and further details for those parts
of the talk which are not covered in previous pub-
lications. It consists of an brief introduction to our
approach to computational compositional seman-
tics, followed by details of two contrasting topics
which illustrate the grammar engineering perspec-
tive. The first of these is argument indexing and its
relationship to semantic role labelling, the second
is semantic dependency structure.
Standard linguistic approaches to compositional
semantics require adaptation for use in broad-
coverage computational processing. Although
some of the adaptations are relatively trivial, oth-
ers have involved considerable experimentation by
various groups of computational linguists. Per-
haps the most important principle is that semantic
representations should be a good match for syn-
tax, in the sense of capturing all and only the in-
formation available from syntax and productive
morphology, while nevertheless abstracting over
semantically-irrelevant idiosyncratic detail. Com-
pared to much of the linguistics literature, our
analyses are relatively superficial, but this is essen-
tially because the broad-coverage computational
approach prevents us from over-committing on the
basis of the information available from the syntax.
One reflection of this are the formal techniques
for scope underspecification which have been de-
veloped in computational linguistics. The im-
plementational perspective, especially when com-
bined with a requirement that grammars can be
used for generation as well as parsing, also forces
attention to details which are routinely ignored in
theoretical linguistic studies. This is particularly
true when there are interactions between phenom-
ena which are generally studied separately. Fi-
nally, our need to produce usable systems disal-
lows some appeals to pragmatics, especially those
where analyses are radically underspecified to al-
low for syntactic and morphological effects found
only in highly marked contexts.1
In a less high-minded vein, sometimes it is right
to be a slacker: life (or at least, project funding) is
too short to implement all ideas within a grammar
in their full theoretical glory. Often there is an easy
alternative which conveys the necessary informa-
tion to a consumer of the semantic representations.
Without this, grammars would never stabilise.
Here I will concentrate on discussing work
which has used Minimal Recursion Semantics
(MRS: Copestake et al. (2005)) or Robust Min-
imal Recursion Semantics (RMRS: Copestake
(2003)). The (R)MRS approach has been adopted
as a common framework for the DELPH-IN ini-
tiative (Deep Linguistic Processing with HPSG:
http://www.delph-in.net) and the work dis-
cussed here has been done by and in collaboration
with researchers involved in DELPH-IN.
The programme of developing computational
compositional semantics has a large number of
aspects. It is important that the semantics
has a logically-sound interpretation (e.g., Koller
and Lascarides (2009), Thater (2007)), is cross-
</bodyText>
<footnote confidence="0.997313333333333">
1For instance, we cannot afford to underspecify number
on nouns because of examples such as The hash browns is
getting angry (from Pollard and Sag (1994) p.85).
</footnote>
<note confidence="0.96231">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.981402">
1
</page>
<bodyText confidence="0.99424207">
linguistically adequate (e.g., Bender (2008)) and
is compatible with generation (e.g., Carroll et al.
(1999), Carroll and Oepen (2005)). Ideally, we
want support for shallow as well as deep syn-
tactic analysis (which was the reason for devel-
oping RMRS), enrichment by deeper analysis (in-
cluding lexical semantics and anaphora resolution,
both the subject of ongoing work), and (robust) in-
ference. The motivation for the development of
dependency-style representations (including De-
pendency MRS (DMRS) discussed in §4) has been
to improve ease of use for consumers of the repre-
sentation and human annotators, as well as use in
statistical ranking of analyses/realisations (Fujita
et al. (2007), Oepen and L¢nning (2006)). Inte-
gration with distributional semantic techniques is
also of interest.
The belated ‘introduction’ to MRS in Copestake
et al. (2005) primarily covered formal represen-
tation of complete utterances. Copestake (2007a)
described uses of (R)MRS in applications. Copes-
take et al. (2001) and Copestake (2007b) concern
the algebra for composition. What I want to do
here is to concentrate on less abstract issues in
the syntax-semantics interface. I will discuss two
cases where the grammar engineering perspective
is important and where there are some conclusions
about compositional semantics which are relevant
beyond DELPH-IN. The first, argument indexing
(§3), is a relatively clear case in which the con-
straints imposed by grammar engineering have a
significant effect on choice between plausible al-
ternatives. I have chosen to talk about this both
because of its relationship with the currently pop-
ular task of semantic role labelling and because
the DELPH-IN approach is now fairly stable af-
ter a quite considerable degree of experimentation.
What I am reporting is thus a perspective on work
done primarily by Flickinger within the English
Resource Grammar (ERG: Flickinger (2000)) and
by Bender in the context of the Grammar Matrix
(Bender et al., 2002), though I’ve been involved in
many of the discussions. The second main topic
(§4) is new work on a semantic dependency rep-
resentation which can be derived from MRS, ex-
tending the previous work by Oepen (Oepen and
L¢nning, 2006). Here, the motivation came from
an engineering perspective, but the nature of the
representation, and indeed the fact that it is possi-
ble at all, reveals some interesting aspects of se-
mantic composition in the grammars.
2 The MRS and RMRS languages
This paper concerns only representations which
are output by deep grammars, which use MRS, but
it will be convenient to talk in terms of RMRS and
to describe the RMRSs that are constructed under
those assumptions. Such RMRSs are interconvert-
ible with MRSs.2 The description is necessarily
terse and contains the minimal detail necessary to
follow the remainder of the paper.
An RMRS is a description of a set of trees cor-
responding to scoped logical forms. Fig 1 shows
an example of an RMRS and its corresponding
scoped form (only one for this example). RMRS
is a ‘flat’ representation, consisting of a bag of el-
ementary predications (EP), a set of argument
relations, and a set of constraints on the possi-
ble linkages of the EPs when the RMRS is resolved
to scoped form. Each EP has a predicate, a la-
bel and a unique anchor and may have a distin-
guished (ARG0) argument (EPs are written here as
label:anchor:pred(arg0)). Label sharing between
EPs indicates conjunction (e.g., in Fig 1, big, an-
gry and dog share the label l2). Argument relations
relate non-arg0 arguments to the corresponding EP
via the anchor. Argument names are taken from a
fixed set (discussed in §3). Argument values may
be variables (e.g., e8, x4: variables are the only
possibility for values of ARG0), constants (strings
such as “London”), or holes (e.g. h5), which in-
dicate scopal relationships. Variables have sortal
properties, indicating tense, number and so on, but
these are not relevant for this paper. Variables cor-
responding to unfilled (syntactically optional) ar-
guments are unique in the RMRS, but otherwise
variables must correspond to the ARG0 of an EP
(since I am only considering RMRSs from deep
grammars here).
Constraints on possible scopal relationships be-
tween EPs may be explicitly specified in the gram-
mar via relationships between holes and labels. In
particular qeq constraints (the only type consid-
ered here) indicate that, in the scoped forms, a
label must either plug a hole directly or be con-
nected to it via a chain of quantifiers. Hole argu-
ments (other than the BODY of a quantifier) are al-
ways linked to a label via a qeq or other constraint
(in a deep grammar RMRS). Variables survive in
the models of RMRSs (i.e., the fully scoped trees)
whereas holes and labels do not.
</bodyText>
<footnote confidence="0.9931715">
2See Flickinger and Bender (2003) and Flickinger et al.
(2003) for the use of MRS in DELPH-IN grammars.
</footnote>
<page confidence="0.991542">
2
</page>
<bodyText confidence="0.49693525">
l1:a1: some q, BV(a1,x4), RSTR(a1,h5), BODY(a1,h6), h5 qeq l2,
l2:a2: big a 1(e8), ARG1(a2,x4), l2:a3: angry a 1(e9), ARG1(a3,x4), l2:a4: dog n 1(x4),
l4:a5: bark v 1(e2), ARG1(a5,x4), l4:a6: loud a 1(e10), ARG1(a6,e2)
some q(x4, big a 1(e8,x4) n angry a 1(e9, x4) n dog n 1(x4), bark v 1(e2,x4) n loud a 1(e10,e2))
</bodyText>
<figureCaption confidence="0.937266">
Figure 1: RMRS and scoped form for ‘Some big angry dogs bark loudly’. Tense and number are omitted.
</figureCaption>
<bodyText confidence="0.99876280882353">
The naming convention for predicates corre-
sponding to lexemes is: stem major sense tag,
optionally followed by and minor sense tag (e.g.,
loud a 1). Major sense tags correspond roughly
to traditional parts of speech. There are also non-
lexical predicates such as ‘poss’ (though none oc-
cur in Fig 1).3 MRS varies from RMRS in that the
arguments are all directly associated with the EP
and thus no anchors are necessary.
I have modified the definition of RMRS given
in Copestake (2007b) to make the ARG0 argument
optional. Here I want to add the additional con-
straint that the ARG0 of an EP is unique to it (i.e.,
not the ARG0 of any other EP). I will term this
the characteristic variable property. This means
that, for every variable, there is a unique EP which
has that variable as its ARG0. I will assume for this
paper that all EPs, apart from quantifier EPs, have
such an ARG0.4 The characteristic variable prop-
erty is one that has emerged from working with
large-scale constraint-based grammars.
A few concepts from the MRS algebra are also
necessary to the discussion. Composition can
be formalised as functor-argument combination
where the argument phrase’s hook fills a slot in
the functor phrase, thus instantiating an RMRS ar-
gument relation. The hook consists of an index
(a variable), an external argument (also a vari-
able) and an ltop (local top: the label correspond-
ing to the topmost node in the current partial tree,
ignoring quantifiers). The syntax-semantics inter-
face requires that the appropriate hook and slots be
set up (mostly lexically in a DELPH-IN grammar)
and that each application of a rule specifies the slot
to be used (e.g., MOD for modification). In a lex-
ical entry, the ARG0 of the EP provides the hook
3In fact, most of the choices about semantics made by
grammar writers concern the behaviour of constructions and
thus these non-lexical predicates, but this would require an-
other paper to discuss.
4I am simplifying for expository convenience. In current
DELPH-IN grammars, quantifiers have an ARG0 which corre-
sponds to the bound variable. This should not be the charac-
teristic variable of the quantifier (it is the characteristic vari-
able of a nominal EP), since its role in the scoped forms is as
a notational convenience to avoid lambda expressions. I will
call it the BV argument here.
index, and, apart from quantifiers, the hook ltop
is the EP’s label. In intersective combination, the
ltops of the hooks will be equated. In scopal com-
bination, a hole argument in a slot is specified to
be qeq to the ltop of the argument phrase and the
ltop of the functor phrase supplies the new hook’s
ltop.
By thinking of qeqs as links in an RMRS graph
(rather than in terms of their logical behaviour
as constraints on the possible scoped forms), an
RMRS can be treated as consisting of a set of trees
with nodes consisting of EPs grouped via intersec-
tive relationships: there will be a backbone tree
(headed by the overall ltop and including the main
verb if there is one), plus a separate tree for each
quantified NP. For instance, in Fig 1, the third
line contains the EPs corresponding to the (single
node) backbone tree and the first two lines show
the EPs comprising the tree for the quantified NP
(one node for the quantifier and one for the N&apos;
which it connects to via the RSTR and its qeq).
</bodyText>
<sectionHeader confidence="0.958159" genericHeader="introduction">
3 Arguments and roles
</sectionHeader>
<bodyText confidence="0.999989045454546">
I will now turn to the representation of arguments
in MRS and their relationship to semantic roles. I
want to discuss the approach to argument labelling
in some detail, because it is a reasonably clear
case where the desiderata for broad-coverage se-
mantics which were discussed in §1 led us to a
syntactically-driven approach, as opposed to using
semantically richer roles such as AGENT, GOAL
and INSTRUMENT.
An MRS can, in fact, be written using a conven-
tional predicate-argument representation. A repre-
sentation which uses ordered argument labels can
be recovered from this in the obvious way. E.g.,
l:like v 1(e,x,y) is equivalent to l:a:like v 1(e),
ARG1(a,x), ARG2(a,y). A fairly large inventory of
argument labels is actually used in the DELPH-IN
grammars (e.g., RSTR, BODY). To recover these
from the conventional predicate-argument nota-
tion requires a look up in a semantic interface
component (the SEM-I, Flickinger et al. (2005)).
But open-class predicates use the ARGn conven-
tion, where n is 0,1,2,3 or 4 and the discussion here
</bodyText>
<page confidence="0.994837">
3
</page>
<bodyText confidence="0.992400745098039">
only concerns these.5
Arguably, the DELPH-IN approach is Davidso-
nian rather than neo-Davidsonian in that, even in
the RMRS form, the arguments are related to the
predicate via the anchor which plays no other role
in the semantics. Unlike the neo-Davidsonian use
of the event variable to attach arguments, this al-
lows the same style of representation to be used
uniformly, including quantifiers, for instance. Ar-
guments can omitted completely without syntactic
ill-formedness of the RMRS, but this is primarily
relevant to shallower grammars. A semantic pred-
icate, such as like v 1, is a logical predicate and as
such is expected to have the same arity wherever it
occurs in the DELPH-IN grammars. Thus models
for an MRS may be defined in a language with or
without argument labels.
The ordering of arguments for open class lex-
emes is lexically specified on the basis of the
syntactic obliqueness hierarchy (Pollard and Sag,
1994). ARG1 corresponds to the subject in the
base (non-passivised) form (‘deep subject’). Ar-
gument numbering is consecutive in the base form,
so no predicate with an ARG3 is lexically missing
an ARG2, for instance. An ARG3 may occur with-
out an instantiated ARG2 when a syntactically op-
tional argument is missing (e.g., Kim gave to the
library), but this is explicit in the linearised form
(e.g., give v(e,x,u,y)).
The full statement of how the obliqueness hi-
erarchy (and thus the labelling) is determined for
lexemes has to be made carefully and takes us too
far into discussion of syntax to explain in detail
here. While the majority of cases are straightfor-
ward, a few are not (e.g., because they depend
on decisions about which form is taken as the
base in an alternation). However, all decisions are
made at the level of lexical types: adding an en-
try for a lexeme for a DELPH-IN grammar only
requires working out its lexical type(s) (from syn-
tactic behaviour and very constrained semantic no-
tions, e.g., control). The actual assignment of ar-
guments to an utterance is just a consequence of
parsing. Argument labelling is thus quite different
from PropBank (Palmer et al., 2005) role labelling
despite the unfortunate similarity of the PropBank
naming scheme.
It follows from the fixed arity of predicates
that lexemes with different numbers of argu-
5ARG4 occurs very rarely, at least in English (the verb bet
being perhaps the clearest case).
ments should be given different predicate symbols.
There is usually a clear sense distinction when this
occurs. For instance, we should distinguish be-
tween the ‘depart’ and ‘bequeath’ senses of leave
because the first takes an ARG1 and an ARG2 (op-
tional) and the second ARG1, ARG2 (optional),
ARG3. We do not draw sense distinctions where
there is no usage which the grammar could disam-
biguate.
Of course, there are obvious engineering rea-
sons for preferring a scheme that requires mini-
mal additional information in order to assign argu-
ment labels. Not only does this simplify the job of
the grammar writer, but it makes it easier to con-
struct lexical entries automatically and to integrate
RMRSs derived from shallower systems. However,
grammar engineers respond to consumers: if more
detailed role labelling had a clear utility and re-
quired an analysis at the syntax level, we would
want to do it in the grammar. The question is
whether it is practically possible.
Detailed discussion of the linguistics literature
would be out of place here. I will assume that
Dowty (1991) is right in the assertion that there
is no small (say, less than 10) set of role labels
which can also be used to link the predicate to its
arguments in compositionally constructed seman-
tics (i.e., argument-indexing in Dowty’s terminol-
ogy) such that each role label can be given a con-
sistent individual semantic interpretation. For our
purposes, a consistent semantic interpretation in-
volves entailment of one or more useful real world
propositions (allowing for exceptions to the entail-
ment for unusual individual sentences).
This is not a general argument against rich role
labels in semantics, just their use as the means
of argument-indexation. It leaves open uses for
grammar-internal purposes, e.g., for defining and
controlling alternations. The earliest versions of
the ERG experimented with a version of Davis’s
(2001) approach to roles for such reasons: this
was not continued, but for reasons irrelevant here.
Roles are still routinely used for argument index-
ation in linguistics papers (without semantic inter-
pretation). The case is sometimes made that more
mnemonic argument labelling helps human inter-
pretation of the notation. This may be true of se-
mantics papers in linguistics, which tend to con-
cern groups of similar lexemes. It is not true of a
collaborative computational linguistics project in
which broad coverage is being attempted: names
</bodyText>
<page confidence="0.987946">
4
</page>
<bodyText confidence="0.999962333333333">
can only be mnemonic if they carry some meaning
and if the meaning cannot be consistently applied
this leads to endless trouble.
What I want to show here is how problems
arise even when very limited semantic generalisa-
tions are attempted about the nature of just one or
two argument labels, when used in broad-coverage
grammars. Take the quite reasonable idea that a
semantically consistent labelling for intransitives
and related causatives is possible (cf PropBank).
For instance, water might be associated with the
same argument label in the following examples:
</bodyText>
<listItem confidence="0.963316833333333">
(1) Kim boiled the water.
(2) The water boiled.
Using (simplified) RMRS representations, this
might amount to:
(3) l:a:boil v(e), a:ARG1(k), a:ARG2(x), water(x)
(4) l:a:boil v(e), a:ARG2(x), water(x)
</listItem>
<bodyText confidence="0.9719392">
Such an approach was used for a time in the ERG
with unaccusatives. However, it turns out to be im-
possible to carry through consistently for causative
alternations.
Consider the following examples of gallop: 6
</bodyText>
<listItem confidence="0.979356571428571">
(5) Michaela galloped the horse to the far end of
the meadow,...
(6) With that Michaela nudged the horse with her
heels and off the horse galloped.
(7) Michaela declared, “I shall call him Lightning
because he runs as fast as lightning.” And with
that, off she galloped.
</listItem>
<bodyText confidence="0.999856285714286">
If only a single predicate is involved, e.g., gal-
lop v, and the causative has an ARG1 and an
ARG2, then what about the two intransitive cases?
If the causative is treated as obligatorily transi-
tive syntactically, then (6) and (7) presumably both
have an ARG2 subject. This leads to Michaela
having a different role label in (5) and (7), de-
spite the evident similarity of the real world situ-
ation. Furthermore, the role labels for intransitive
movement verbs could only be predicted by a con-
sumer of the semantics who knew whether or not
a causative form existed. The causative may be
rare, as with gallop, where the intransitive use is
clearly the base case. Alternatively, if (7) is treated
</bodyText>
<footnote confidence="0.825432">
6http://www.thewestcoast.net/bobsnook/kid/horses.htm.
</footnote>
<bodyText confidence="0.9991238125">
as a causative intransitive, and thus has a subject
labelled ARG1, there is a systematic unresolvable
ambiguity and the generalisation that the subjects
in both intransitive sentences are moving is lost.
Gallop is an not isolated case in having a vo-
litional intransitive use: it applies to most (if not
all) motion verbs which undergo the causative al-
ternation. To rescue this account, we would need
to apply it only to true lexical anti-causatives. It is
not clear whether this is doable (even the standard
example sink can be used intransitively of deliber-
ate movement) but from a slacker perspective, at
this point we should decide to look for an easier
approach.
The current ERG captures the causative relation-
ship by using systematic sense labelling:
</bodyText>
<listItem confidence="0.4710085">
(8) Kim boiled the water.
l:a:boil v cause(e), a:ARG1(k), a:ARG2(x),
water(x)
(9) The water boiled.
</listItem>
<bodyText confidence="0.990523933333333">
l:a:boil v 1(e), a:ARG1(x), water(x)
This is not perfect, but it has clear advantages.
It allows inferences to be made about ARG1 and
ARG2 of cause verbs. In general, inferences about
arguments may be made with respect to particular
verb classes. This lends itself to successive refine-
ment in the grammars: the decision to add a stan-
dardised sense label, such as cause, does not re-
quire changes to the type system, for instance. If
we decide that we can identify true anti-causatives,
we can easily make them a distinguished class via
this convention. Conversely, in the situation where
causation has not been recognised, and the verb
has been treated as a single lexeme having an op-
tional ARG2, the semantics is imperfect but at least
the imperfection is local.
In fact, determining argument labelling by the
obliqueness hierarchy still allows generalisations
to be made for all verbs. Dowty (1991) argues
for the notion of proto-agent (p-agt) and proto-
patient (p-pat) as cluster concepts. Proto-agent
properties include volitionality, sentience, causa-
tion of an event and movement relative to another
participant. Proto-patient properties include be-
ing causally affected and being stationary relative
to another participant. Dowty claims that gener-
alisations about which arguments are lexicalised
as subject, object and indirect object/oblique can
be expressed in terms of relative numbers of p-agt
and p-pat properties. If this is correct, then we can,
</bodyText>
<page confidence="0.984995">
5
</page>
<bodyText confidence="0.99998692">
for example, predict that the ARG1 of any predi-
cate in a DELPH-IN grammar will not have fewer
p-agt properties than the ARG2 of that predicate.7
As an extreme alternative, we could use la-
bels which were individual to each predicate,
such as LIKER and LIKED (e.g., Pollard and Sag
(1994)). For such role labels to have a consistent
meaning, they would have to be lexeme-specific:
e.g., LEAVER1 (‘departer’) versus LEAVER2 (‘be-
queather’). However this does nothing for seman-
tic generalisation, blocks the use of argument la-
bels in syntactic generalisations and leads to an
extreme proliferation of lexical types when us-
ing typed feature structure formalisms (one type
would be required per lexeme). The labels add
no additional information and could trivially be
added automatically to an RMRS if this were use-
ful for human readers. Much more interesting is
the use of richer lexical semantic generalisations,
such as those employed in FrameNet (Baker et al.,
1998). In principle, at least, we could (and should)
systematically link the ERG to FrameNet, but this
would be a form of semantic enrichment mediated
via the SEM-I (cf Roa et al. (2008)), and not an
alternative technique for argument indexation.
</bodyText>
<sectionHeader confidence="0.998759" genericHeader="method">
4 Dependency MRS
</sectionHeader>
<bodyText confidence="0.981778558139535">
The second main topic I want to address is a
form of semantic dependency structure (DMRS:
see wiki.delph-in.net for the evolving details).
There are good engineering reasons for producing
a dependency style representation with links be-
tween predicates and no variables: ease of read-
ability for consumers of the representation and for
human annotators, parser comparison and integra-
tion with distributional lexical semantics being the
immediate goals. Oepen has previously produced
elementary dependencies from MRSs but the pro-
cedure (partially sketched in Oepen and Lønning
(2006)) was not intended to produce complete rep-
resentations. It turns out that a DMRS can be con-
structed which can be demonstrated to be inter-
convertible with RMRS, has a simple graph struc-
ture and minimises redundancy in the representa-
tion. What is surprising is that this can be done
for a particular class of grammars without mak-
7Sanfilippo (1990) originally introduced Dowty’s ideas
into computational linguistics, but this relative behaviour
cannot be correctly expressed simply by using p-agt and p-
pat directly for argument indexation as he suggested. It is
incorrect for examples like (2) to be labelled as p-agt, since
they have no agentive properties.
ing use of the evident clues to syntax in the pred-
icate names. The characteristic variable property
discussed in §2 is crucial: its availability allows
a partial replication of composition, with DMRS
links being relatable to functor-argument combi-
nations in the MRS algebra. I should emphasize
that, unlike MRS and RMRS, DMRS is not intended
to have a direct logical interpretation.
An example of a DMRS is given in Fig 2. Links
relate nodes corresponding to RMRS predicates.
Nodes have unique identifiers, not shown here. Di-
rected link labels are of the form ARG/H, ARG/EQ
or ARG/NEQ, where ARG corresponds to an RMRS
argument label. H indicates a qeq relationship,
EQ label equality and NEQ label inequality, as ex-
plained more fully below. Undirected /EQ arcs
also sometimes occur (see §4.3). The ltop is in-
dicated with a *.
</bodyText>
<subsectionHeader confidence="0.982356">
4.1 RMRS-to-DMRS
</subsectionHeader>
<bodyText confidence="0.997977548387097">
In order to transform an RMRS into a DMRS, we
will treat the RMRS as made up of three subgraphs:
Label equality graph. Each EP in an RMRS
has a label, which may be shared with any number
of other EPs. This can be captured in DMRS via
a graph linking EPs: if this is done exhaustively,
there would be n(n − 1)/2 binary non-directional
links. E.g., for the RMRS in Fig 1, we need to link
big a 1, angry a 1 and dog n 1 and this takes
3 links. Obviously the effect of equality could be
captured by a smaller number of links, assuming
transitivity: but to make the RMRS-to-DMRS con-
version deterministic, we need a method for se-
lecting canonical links.
Hole-to-label qeq graph. A qeq in RMRS links
a hole to a label which labels a set of EPs. There
is thus a 1 : 1 mapping between holes and la-
bels which can be converted to a 1 : n mapping
between holes and the EPs which share the la-
bel. By taking the EP with the hole as the origin,
we can construct an EP-to-EP graph, using the ar-
gument name as a label for the link: of course,
such links are asymmetric and thus the graph is
directed. e.g., some q has RSTR links to each of
big a 1, angry a 1 and dog n 1. Reducing this
to a 1 : 1 mapping between EPs, which we would
ideally like for DMRS, requires a canonical method
of selecting a head EP from the set of target EPs (as
does the selection of the ltop).
Variable graph. For the conversion to DMRS,
we will rely on the characteristic variable prop-
</bodyText>
<page confidence="0.990332">
6
</page>
<figure confidence="0.522850428571428">
some q big a 1 angry a at dog n 1 bark v 1* loud a 1
� � �
� ARG1/NEQ ARG1/EQ
�
ARG1/EQ
ARG1/EQ
RSTR/H
</figure>
<figureCaption confidence="0.966317">
Figure 2: DMRS for ‘Some big angry dogs bark loudly.’
</figureCaption>
<bodyText confidence="0.999959948717949">
erty, that every variable has a unique EP associated
with it via its ARG0. Any non-hole argument of an
EP will have a value which is the ARG0 of some
other EP, or which is unbound (i.e., not found else-
where in the RMRS) in which case we ignore it.
Thus we can derive a graph between EPs, such
that each link is labelled with an argument posi-
tion and points to a unique EP. I will talk about an
EP’s ‘argument EPs’, to refer to the set of EPs its
arguments point to in this graph.
The three EP graphs can be combined to form
a dependency structure. But this has an excessive
number of links due to the label equality and qeq
components. We need deterministic techniques for
removing the redundancy. These can utilise the
variable graph, since this is already minimal.
The first strategy is to combine the label equal-
ity and variable links when they connect the same
two EPs. For instance, we combine the ARG1
link between big a 1, and dog n 1 with the la-
bel equality link to give a link labelled ARG1/EQ.
We then test the connectivity of the ARG/EQ links
on the assumption of transitivity and remove any
redundant links from the label graph. This usually
removes all label equality links: one case where
it does not is discussed in §4.3. Variable graph
links with no corresponding label equality are an-
notated ARG/NEQ, while links arising from the
qeq graph are labelled ARG/H. This retains suf-
ficient information to allow the reconstruction of
the three graphs in DMRS-to-RMRS conversion.
In order to reduce the number of links arising
from the qeq graph, we make use of the variable
graph to select a head from a set of EPs sharing
a label. It is not essential that there should be a
unique head, but it is desirable. The next section
outlines how head selection works: despite not us-
ing any directly syntactic properties, it generally
recovers the syntactic head.
</bodyText>
<subsectionHeader confidence="0.997903">
4.2 Head selection in the qeq graph
</subsectionHeader>
<bodyText confidence="0.999855090909091">
Head selection uses one principle and one heuris-
tic, both of which are motivated by the composi-
tional properties of the grammar. The principle is
that qeq links from an EP should parallel any com-
parable variable links. If an EP has two arguments,
one of which is a variable argument which links
to EP&apos; and the other a hole argument which has a
value corresponding to a set of EPs including EP&apos;,
EP&apos; is chosen as the head of that set.
This essentially follows from the composition
rules: in an algebra operation giving rise to a qeq,
the argument phrase supplies a hook consisting
of an index (normally, the ARG0 of the head EP)
and an ltop (normally, the label of the head EP).
Thus if a variable argument corresponds to EP&apos;,
EP&apos; will have been the head of the corresponding
phrase and is thus the choice of head in the DMRS.
This most frequently arises with quantifiers, which
have both a BV and a RSTR argument: the RSTR
argument can be taken as linking to the EP which
has an ARG0 equal to the BV (i.e., the head of the
N&apos;). If this principle applies, it will select a unique
head. In fact, in this special case, we drop the BV
link from the final DMRS because it is entirely pre-
dictable from the RSTR link.
In the case where there is no variable argu-
ment, we use the heuristic which generally holds
in DELPH-IN grammars that the EPs which we
wish to distinguish as heads in the DMRS do not
share labels with their DMRS argument EPs (in
contrast to intersective modifiers, which always
share labels with their argument EPs). Heads may
share labels with PPs which are syntactically ar-
guments, but these have a semantics like PP mod-
ifiers, where the head is the preposition’s EP ar-
gument. NP arguments are generally quantified
and quantifiers scope freely. AP, VP and S syn-
tactic arguments are always scopal. PPs which are
not modifier-like are either scopal (small clauses)
or NP-like (case marking Ps) and free-scoping.
Thus, somewhat counter-intuitively, we can select
the head EP from the set of EPs which share a label
by looking for an EP which has no argument EPs
in that set.
</bodyText>
<subsectionHeader confidence="0.998414">
4.3 Some properties of DMRS
</subsectionHeader>
<bodyText confidence="0.997251333333333">
The MRS-to-DMRS procedure deterministically
creates a unique DMRS. A converse DMRS-to-MRS
procedure recreates the MRS (up to label, anchor
</bodyText>
<page confidence="0.995631">
7
</page>
<figure confidence="0.995305454545454">
the q dog n 1 def explicit q poss toy n 1 the q cat n 1 bite v 1 bark v 1*
�
RSTR/H
� � � �
ARG2/EQ ARG1/NEQ RSTR/H ARG1/NEQ
� �
ARG2/NEQ
RSTR/H
/EQ
�
ARG1/NEQ
</figure>
<figureCaption confidence="0.999825">
Figure 3: DMRS for ‘The dog whose toy the cat bit barked.’
</figureCaption>
<bodyText confidence="0.991225142857143">
and variable renaming), though requiring the SEM-
I to add the uninstantiated optional arguments.
I claimed above that DMRSs are an idealisa-
tion of semantic composition. A pure functor-
argument application scheme would produce a tree
which could be transformed into a structure where
no dependent had more than one head. But in
DMRS the notion of functor/head is more complex
as determiners and modifiers provide slots in the
RMRS algebra but not the index of the result. Com-
position of a verb (or any other functor) with an
NP argument gives rise to a dependency between
the verb and the head noun in the N&apos;. The head
noun provides the index of the NP’s hook in com-
position, though it does not provide the ltop, which
comes from the quantifier. However, because this
ltop is not equated with any label, there is no direct
link between the verb and the determiner. Thus the
noun will have a link from the determiner and from
the verb.
Similarly, if the constituents in composition
were continuous, the adjacency condition would
hold, but this does not apply because of the mech-
anisms for long-distance dependencies and the
availability of the external argument in the hook.8
DMRS indirectly preserves the information
about constituent structure which is essential for
semantic interpretation, unlike some syntactic de-
pendency schemes. In particular, it retains infor-
mation about a quantifier’s N&apos;, since this forms the
restrictor of the generalised quantifier (for instance
Most white cats are deaf has different truth condi-
tions from Most deaf cats are white). An inter-
esting example of nominal modification is shown
in Fig 3. Notice that whose has a decomposed
semantics combining two non-lexeme predicates
def explicit q and poss. Unusually, the relative
clause has a gap which is not an argument of its
semantic head (it’s an argument of poss rather than
bite v 1). This means that when the relative clause
8Given that non-local effects are relatively circumscribed,
it is possible to require adjacency in some parts of the DMRS.
This leads to a technique for recording underspecification of
noun compound bracketing, for instance.
is combined with the gap filler, the label equality
and the argument instantiation correspond to dif-
ferent EPs. Thus there is a label equality which
cannot be combined with an argument link and has
to be represented by an undirected /EQ arc.
</bodyText>
<sectionHeader confidence="0.99971" genericHeader="method">
5 Related work and conclusion
</sectionHeader>
<bodyText confidence="0.999990692307692">
Hobbs (1985) described a philosophy of computa-
tional compositional semantics that is in some re-
spects similar to that presented here. But, as far as
I am aware, the Core Language Engine book (Al-
shawi, 1992) provided the first detailed descrip-
tion of a truly computational approach to com-
positional semantics: in any case, Steve Pulman
provided my own introduction to the idea. Cur-
rently, the ParGram project also undertakes large-
scale multilingual grammar engineering work: see
Crouch and King (2006) and Crouch (2006) for an
account of the semantic composition techniques
now being used. I am not aware of any other
current grammar engineering activities on the Par-
Gram or DELPH-IN scale which build bidirectional
grammars for multiple languages.
Overall, what I have tried to do here is to give a
flavour of how compositional semantics and syn-
tax interact in computational grammars. Analy-
ses which look simple have often taken consider-
able experimentation to arrive at when working on
a large-scale, especially when attempting cross-
linguistic generalisations. The toy examples that
can be given in papers like this one do no justice to
this, and I would urge readers to try out the gram-
mars and software and, perhaps, to join in.
</bodyText>
<sectionHeader confidence="0.996517" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999231">
Particular thanks to Emily Bender, Dan Flickinger
and Alex Lascarides for detailed comments at
very short notice! I am also grateful to many
other colleagues, especially from DELPH-IN and
in the Cambridge NLIP research group. This
work was supported by the Engineering and Phys-
ical Sciences Research Council [grant numbers
EP/C010035/1, EP/F012950/1].
</bodyText>
<page confidence="0.996979">
8
</page>
<sectionHeader confidence="0.99589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99991612264151">
Hiyan Alshawi, editor. 1992. The Core Language En-
gine. MIT Press.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proc.
ACL-98, pages 86–90, Montreal, Quebec, Canada.
Association for Computational Linguistics.
Emily Bender, Dan Flickinger, and Stephan Oepen.
2002. The Grammar Matrix: An open-source
starter-kit for the rapid development of cross-
linguistically consistent broad-coverage precision
grammars. In Proc. Workshop on Grammar Engi-
neering and Evaluation, Coling 2002, pages 8–14,
Taipei, Taiwan.
Emily Bender. 2008. Evaluating a crosslinguistic
grammar resource: A case study of Wambaya. In
Proc. ACL-08, pages 977–985, Columbus, Ohio,
USA.
John Carroll and Stephan Oepen. 2005. High ef-
ficiency realization for a wide-coverage unification
grammar. In Proc. IJCNLP05, Springer Lecture
Notes in Artificial Intelligence, Volume 3651, pages
165–176, Jeju Island, Korea.
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Poznanski. 1999. An efficient chart generator
for (semi-)lexicalist grammars. In Proc. 7th Eu-
ropean Workshop on Natural Language Generation
(EWNLG’99), pages 86–95, Toulouse.
Ann Copestake, Alex Lascarides, and Dan Flickinger.
2001. An algebra for semantic construction in
constraint-based grammars. In Proc. ACL-01,
Toulouse.
Ann Copestake, Dan Flickinger, Ivan A. Sag, and Carl
Pollard. 2005. Minimal Recursion Semantics: an
introduction. Research on Language and Computa-
tion, 3(2-3):281–332.
Ann Copestake. 2003. Report on the design of RMRS.
DeepThought project deliverable.
Ann Copestake. 2007a. Applying robust semantics.
In Proc. PACLING 2007 — 10th Conference of the
Pacific Association for Computational Linguistics,
pages 1–12, Melbourne.
Ann Copestake. 2007b. Semantic composition with
(Robust) Minimal Recursion Semantics. In Proc.
Workshop on Deep Linguistic Processing, ACL
2007, Prague.
Dick Crouch and Tracy Holloway King. 2006. Seman-
tics via F-structure rewriting. In Miriam Butt and
Tracy Holloway King, editors, Proc. LFG06 Con-
ference, Universitat Konstanz. CSLI Publications.
Dick Crouch. 2006. Packed rewriting for mapping se-
mantics and KR. In Intelligent Linguistic Architec-
tures Variations on Themes by Ronald M. Kaplan,
pages 389–416. CSLI Publications.
Anthony Davis. 2001. Linking by Types in the Hierar-
chical Lexicon. CSLI Publications.
David Dowty. 1991. Thematic proto-roles and argu-
ment selection. Language, 67(3):547–619.
Dan Flickinger and Emily Bender. 2003. Compo-
sitional semantics in a multilingual grammar re-
source. In Proc. Workshop on Ideas and Strate-
gies for Multilingual Grammar Development, ESS-
LLI2003, pages 33–42, Vienna.
Dan Flickinger, Emily Bender, and Stephan Oepen.
2003. MRS in the LinGO Grammar Matrix: A prac-
tical user’s guide. http://tinyurl.com/crf5z7.
Dan Flickinger, Jan Tore Lønning, Helge Dyvik,
Stephan Oepen, and Francis Bond. 2005. SEM-I
rational MT — enriching deep grammars with a se-
mantic interface for scalable machine translation. In
Proc. MT Summit X, Phuket, Thailand.
Dan Flickinger. 2000. On building a more efficient
grammar by exploiting types. Natural Language
Engineering, 6(1):15–28.
Sanae Fujita, Francis Bond, Stephan Oepen, and
Takaaki Tanaka. 2007. Exploiting semantic infor-
mation for HPSG parse selection. In Proc. Work-
shop on Deep Linguistic Processing, ACL 2007,
Prague.
Jerry Hobbs. 1985. Ontological promiscuity. In Proc.
ACL-85, pages 61–69, Chicago, IL.
Alexander Koller and Alex Lascarides. 2009. A logic
of semantic representations for shallow parsing. In
Proc. EACL-2009, Athens.
Stephan Oepen and Jan Tore Lønning. 2006.
Discriminant-based MRS banking. In Proc. LREC-
2006, Genoa, Italy.
Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005.
The Proposition Bank: A corpus annotated with se-
mantic roles. Computational Linguistics, 31(1).
Carl Pollard and Ivan Sag. 1994. Head-driven Phrase
Structure Grammar. University of Chicago Press,
Chicago.
Sergio Roa, Valia Kordoni, and Yi Zhang. 2008. Map-
ping between compositional semantic representa-
tions and lexical semantic resources: Towards accu-
rate deep semantic parsing. In Proc. ACL-08, pages
189–192, Columbus, Ohio. Association for Compu-
tational Linguistics.
Antonio Sanfilippo. 1990. Grammatical Relations,
Thematic Roles and Verb Semantics. Ph.D. thesis,
Centre for Cognitive Science, University of Edin-
burgh.
Stefan Thater. 2007. Minimal Recursion Semantics
as Dominance Constraints: Graph-Theoretic Foun-
dation and Application to Grammar Engineering.
Ph.D. thesis, Universit¨at des Saarlandes.
</reference>
<page confidence="0.997096">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.295205">
<title confidence="0.5407355">Slacker semantics: why superficiality, dependency and avoidance of commitment can be the right way to go</title>
<author confidence="0.958179">Ann Copestake</author>
<affiliation confidence="0.998841">Computer Laboratory, University of Cambridge</affiliation>
<address confidence="0.998565">15 JJ Thomson Avenue, Cambridge, UK</address>
<email confidence="0.996793">aac@cl.cam.ac.uk</email>
<abstract confidence="0.9767479">This paper discusses computational compositional semantics from the perspective of grammar engineering, in the light of experience with the use of Minimal Recur- Semantics in The relationship between argument indexation and semantic role labelling is explored and a semantic dependency notais introduced.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>The Core Language Engine.</title>
<date>1992</date>
<editor>Hiyan Alshawi, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1992</marker>
<rawString>Hiyan Alshawi, editor. 1992. The Core Language Engine. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proc. ACL-98,</booktitle>
<pages>86--90</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="23938" citStr="Baker et al., 1998" startWordPosition="3895" endWordPosition="3898"> would have to be lexeme-specific: e.g., LEAVER1 (‘departer’) versus LEAVER2 (‘bequeather’). However this does nothing for semantic generalisation, blocks the use of argument labels in syntactic generalisations and leads to an extreme proliferation of lexical types when using typed feature structure formalisms (one type would be required per lexeme). The labels add no additional information and could trivially be added automatically to an RMRS if this were useful for human readers. Much more interesting is the use of richer lexical semantic generalisations, such as those employed in FrameNet (Baker et al., 1998). In principle, at least, we could (and should) systematically link the ERG to FrameNet, but this would be a form of semantic enrichment mediated via the SEM-I (cf Roa et al. (2008)), and not an alternative technique for argument indexation. 4 Dependency MRS The second main topic I want to address is a form of semantic dependency structure (DMRS: see wiki.delph-in.net for the evolving details). There are good engineering reasons for producing a dependency style representation with links between predicates and no variables: ease of readability for consumers of the representation and for human a</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proc. ACL-98, pages 86–90, Montreal, Quebec, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Bender</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>The Grammar Matrix: An open-source starter-kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars.</title>
<date>2002</date>
<booktitle>In Proc. Workshop on Grammar Engineering and Evaluation, Coling</booktitle>
<pages>8--14</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="6188" citStr="Bender et al., 2002" startWordPosition="933" endWordPosition="936">rgument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I have chosen to talk about this both because of its relationship with the currently popular task of semantic role labelling and because the DELPH-IN approach is now fairly stable after a quite considerable degree of experimentation. What I am reporting is thus a perspective on work done primarily by Flickinger within the English Resource Grammar (ERG: Flickinger (2000)) and by Bender in the context of the Grammar Matrix (Bender et al., 2002), though I’ve been involved in many of the discussions. The second main topic (§4) is new work on a semantic dependency representation which can be derived from MRS, extending the previous work by Oepen (Oepen and L¢nning, 2006). Here, the motivation came from an engineering perspective, but the nature of the representation, and indeed the fact that it is possible at all, reveals some interesting aspects of semantic composition in the grammars. 2 The MRS and RMRS languages This paper concerns only representations which are output by deep grammars, which use MRS, but it will be convenient to ta</context>
</contexts>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>Emily Bender, Dan Flickinger, and Stephan Oepen. 2002. The Grammar Matrix: An open-source starter-kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars. In Proc. Workshop on Grammar Engineering and Evaluation, Coling 2002, pages 8–14, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Bender</author>
</authors>
<title>Evaluating a crosslinguistic grammar resource: A case study of Wambaya. In</title>
<date>2008</date>
<booktitle>Proc. ACL-08,</booktitle>
<pages>977--985</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="4256" citStr="Bender (2008)" startWordPosition="634" endWordPosition="635">IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking</context>
</contexts>
<marker>Bender, 2008</marker>
<rawString>Emily Bender. 2008. Evaluating a crosslinguistic grammar resource: A case study of Wambaya. In Proc. ACL-08, pages 977–985, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Stephan Oepen</author>
</authors>
<title>High efficiency realization for a wide-coverage unification grammar.</title>
<date>2005</date>
<booktitle>In Proc. IJCNLP05, Springer Lecture Notes in Artificial Intelligence,</booktitle>
<volume>3651</volume>
<pages>165--176</pages>
<location>Jeju Island,</location>
<contexts>
<context position="4346" citStr="Carroll and Oepen (2005)" startWordPosition="646" endWordPosition="649">ge number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration wi</context>
</contexts>
<marker>Carroll, Oepen, 2005</marker>
<rawString>John Carroll and Stephan Oepen. 2005. High efficiency realization for a wide-coverage unification grammar. In Proc. IJCNLP05, Springer Lecture Notes in Artificial Intelligence, Volume 3651, pages 165–176, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Victor Poznanski</author>
</authors>
<title>An efficient chart generator for (semi-)lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proc. 7th European Workshop on Natural Language Generation (EWNLG’99),</booktitle>
<pages>86--95</pages>
<location>Toulouse.</location>
<contexts>
<context position="4320" citStr="Carroll et al. (1999)" startWordPosition="642" endWordPosition="645">nal semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nni</context>
</contexts>
<marker>Carroll, Copestake, Flickinger, Poznanski, 1999</marker>
<rawString>John Carroll, Ann Copestake, Dan Flickinger, and Victor Poznanski. 1999. An efficient chart generator for (semi-)lexicalist grammars. In Proc. 7th European Workshop on Natural Language Generation (EWNLG’99), pages 86–95, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Alex Lascarides</author>
<author>Dan Flickinger</author>
</authors>
<title>An algebra for semantic construction in constraint-based grammars.</title>
<date>2001</date>
<booktitle>In Proc. ACL-01,</booktitle>
<location>Toulouse.</location>
<contexts>
<context position="5213" citStr="Copestake et al. (2001)" startWordPosition="777" endWordPosition="781">obust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration with distributional semantic techniques is also of interest. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of (R)MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH-IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I have chosen to talk about this both because of its relationship with </context>
</contexts>
<marker>Copestake, Lascarides, Flickinger, 2001</marker>
<rawString>Ann Copestake, Alex Lascarides, and Dan Flickinger. 2001. An algebra for semantic construction in constraint-based grammars. In Proc. ACL-01, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Ivan A Sag</author>
<author>Carl Pollard</author>
</authors>
<title>Minimal Recursion Semantics: an introduction.</title>
<date>2005</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>3--2</pages>
<contexts>
<context position="3325" citStr="Copestake et al. (2005)" startWordPosition="492" endWordPosition="495">, especially those where analyses are radically underspecified to allow for syntactic and morphological effects found only in highly marked contexts.1 In a less high-minded vein, sometimes it is right to be a slacker: life (or at least, project funding) is too short to implement all ideas within a grammar in their full theoretical glory. Often there is an easy alternative which conveys the necessary information to a consumer of the semantic representations. Without this, grammars would never stabilise. Here I will concentrate on discussing work which has used Minimal Recursion Semantics (MRS: Copestake et al. (2005)) or Robust Minimal Recursion Semantics (RMRS: Copestake (2003)). The (R)MRS approach has been adopted as a common framework for the DELPH-IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH-IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify </context>
<context position="5065" citStr="Copestake et al. (2005)" startWordPosition="757" endWordPosition="760"> for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration with distributional semantic techniques is also of interest. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of (R)MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH-IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar eng</context>
</contexts>
<marker>Copestake, Flickinger, Sag, Pollard, 2005</marker>
<rawString>Ann Copestake, Dan Flickinger, Ivan A. Sag, and Carl Pollard. 2005. Minimal Recursion Semantics: an introduction. Research on Language and Computation, 3(2-3):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Report on the design of RMRS. DeepThought project deliverable.</title>
<date>2003</date>
<contexts>
<context position="3388" citStr="Copestake (2003)" startWordPosition="503" endWordPosition="504">w for syntactic and morphological effects found only in highly marked contexts.1 In a less high-minded vein, sometimes it is right to be a slacker: life (or at least, project funding) is too short to implement all ideas within a grammar in their full theoretical glory. Often there is an easy alternative which conveys the necessary information to a consumer of the semantic representations. Without this, grammars would never stabilise. Here I will concentrate on discussing work which has used Minimal Recursion Semantics (MRS: Copestake et al. (2005)) or Robust Minimal Recursion Semantics (RMRS: Copestake (2003)). The (R)MRS approach has been adopted as a common framework for the DELPH-IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH-IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is </context>
</contexts>
<marker>Copestake, 2003</marker>
<rawString>Ann Copestake. 2003. Report on the design of RMRS. DeepThought project deliverable.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Applying robust semantics.</title>
<date>2007</date>
<booktitle>In Proc. PACLING 2007 — 10th Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>1--12</pages>
<location>Melbourne.</location>
<contexts>
<context position="5145" citStr="Copestake (2007" startWordPosition="769" endWordPosition="770">aphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration with distributional semantic techniques is also of interest. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of (R)MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH-IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I h</context>
<context position="9946" citStr="Copestake (2007" startWordPosition="1581" endWordPosition="1582">rk v 1(e2,x4) n loud a 1(e10,e2)) Figure 1: RMRS and scoped form for ‘Some big angry dogs bark loudly’. Tense and number are omitted. The naming convention for predicates corresponding to lexemes is: stem major sense tag, optionally followed by and minor sense tag (e.g., loud a 1). Major sense tags correspond roughly to traditional parts of speech. There are also nonlexical predicates such as ‘poss’ (though none occur in Fig 1).3 MRS varies from RMRS in that the arguments are all directly associated with the EP and thus no anchors are necessary. I have modified the definition of RMRS given in Copestake (2007b) to make the ARG0 argument optional. Here I want to add the additional constraint that the ARG0 of an EP is unique to it (i.e., not the ARG0 of any other EP). I will term this the characteristic variable property. This means that, for every variable, there is a unique EP which has that variable as its ARG0. I will assume for this paper that all EPs, apart from quantifier EPs, have such an ARG0.4 The characteristic variable property is one that has emerged from working with large-scale constraint-based grammars. A few concepts from the MRS algebra are also necessary to the discussion. Composi</context>
</contexts>
<marker>Copestake, 2007</marker>
<rawString>Ann Copestake. 2007a. Applying robust semantics. In Proc. PACLING 2007 — 10th Conference of the Pacific Association for Computational Linguistics, pages 1–12, Melbourne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Semantic composition with (Robust) Minimal Recursion Semantics.</title>
<date>2007</date>
<booktitle>In Proc. Workshop on Deep Linguistic Processing, ACL 2007,</booktitle>
<location>Prague.</location>
<contexts>
<context position="5145" citStr="Copestake (2007" startWordPosition="769" endWordPosition="770">aphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration with distributional semantic techniques is also of interest. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of (R)MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about compositional semantics which are relevant beyond DELPH-IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I h</context>
<context position="9946" citStr="Copestake (2007" startWordPosition="1581" endWordPosition="1582">rk v 1(e2,x4) n loud a 1(e10,e2)) Figure 1: RMRS and scoped form for ‘Some big angry dogs bark loudly’. Tense and number are omitted. The naming convention for predicates corresponding to lexemes is: stem major sense tag, optionally followed by and minor sense tag (e.g., loud a 1). Major sense tags correspond roughly to traditional parts of speech. There are also nonlexical predicates such as ‘poss’ (though none occur in Fig 1).3 MRS varies from RMRS in that the arguments are all directly associated with the EP and thus no anchors are necessary. I have modified the definition of RMRS given in Copestake (2007b) to make the ARG0 argument optional. Here I want to add the additional constraint that the ARG0 of an EP is unique to it (i.e., not the ARG0 of any other EP). I will term this the characteristic variable property. This means that, for every variable, there is a unique EP which has that variable as its ARG0. I will assume for this paper that all EPs, apart from quantifier EPs, have such an ARG0.4 The characteristic variable property is one that has emerged from working with large-scale constraint-based grammars. A few concepts from the MRS algebra are also necessary to the discussion. Composi</context>
</contexts>
<marker>Copestake, 2007</marker>
<rawString>Ann Copestake. 2007b. Semantic composition with (Robust) Minimal Recursion Semantics. In Proc. Workshop on Deep Linguistic Processing, ACL 2007, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dick Crouch</author>
<author>Tracy Holloway King</author>
</authors>
<title>Semantics via F-structure rewriting.</title>
<date>2006</date>
<booktitle>Proc. LFG06 Conference,</booktitle>
<editor>In Miriam Butt and Tracy Holloway King, editors,</editor>
<publisher>CSLI Publications.</publisher>
<location>Universitat Konstanz.</location>
<contexts>
<context position="35162" citStr="Crouch and King (2006)" startWordPosition="5881" endWordPosition="5884">annot be combined with an argument link and has to be represented by an undirected /EQ arc. 5 Related work and conclusion Hobbs (1985) described a philosophy of computational compositional semantics that is in some respects similar to that presented here. But, as far as I am aware, the Core Language Engine book (Alshawi, 1992) provided the first detailed description of a truly computational approach to compositional semantics: in any case, Steve Pulman provided my own introduction to the idea. Currently, the ParGram project also undertakes largescale multilingual grammar engineering work: see Crouch and King (2006) and Crouch (2006) for an account of the semantic composition techniques now being used. I am not aware of any other current grammar engineering activities on the ParGram or DELPH-IN scale which build bidirectional grammars for multiple languages. Overall, what I have tried to do here is to give a flavour of how compositional semantics and syntax interact in computational grammars. Analyses which look simple have often taken considerable experimentation to arrive at when working on a large-scale, especially when attempting crosslinguistic generalisations. The toy examples that can be given in </context>
</contexts>
<marker>Crouch, King, 2006</marker>
<rawString>Dick Crouch and Tracy Holloway King. 2006. Semantics via F-structure rewriting. In Miriam Butt and Tracy Holloway King, editors, Proc. LFG06 Conference, Universitat Konstanz. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dick Crouch</author>
</authors>
<title>Packed rewriting for mapping semantics and KR.</title>
<date>2006</date>
<booktitle>In Intelligent Linguistic Architectures Variations on Themes by</booktitle>
<pages>389--416</pages>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="35180" citStr="Crouch (2006)" startWordPosition="5886" endWordPosition="5887">rgument link and has to be represented by an undirected /EQ arc. 5 Related work and conclusion Hobbs (1985) described a philosophy of computational compositional semantics that is in some respects similar to that presented here. But, as far as I am aware, the Core Language Engine book (Alshawi, 1992) provided the first detailed description of a truly computational approach to compositional semantics: in any case, Steve Pulman provided my own introduction to the idea. Currently, the ParGram project also undertakes largescale multilingual grammar engineering work: see Crouch and King (2006) and Crouch (2006) for an account of the semantic composition techniques now being used. I am not aware of any other current grammar engineering activities on the ParGram or DELPH-IN scale which build bidirectional grammars for multiple languages. Overall, what I have tried to do here is to give a flavour of how compositional semantics and syntax interact in computational grammars. Analyses which look simple have often taken considerable experimentation to arrive at when working on a large-scale, especially when attempting crosslinguistic generalisations. The toy examples that can be given in papers like this o</context>
</contexts>
<marker>Crouch, 2006</marker>
<rawString>Dick Crouch. 2006. Packed rewriting for mapping semantics and KR. In Intelligent Linguistic Architectures Variations on Themes by Ronald M. Kaplan, pages 389–416. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Davis</author>
</authors>
<title>Linking by Types in the Hierarchical Lexicon.</title>
<date>2001</date>
<publisher>CSLI Publications.</publisher>
<marker>Davis, 2001</marker>
<rawString>Anthony Davis. 2001. Linking by Types in the Hierarchical Lexicon. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Thematic proto-roles and argument selection.</title>
<date>1991</date>
<journal>Language,</journal>
<volume>67</volume>
<issue>3</issue>
<contexts>
<context position="17304" citStr="Dowty (1991)" startWordPosition="2829" endWordPosition="2830">eme that requires minimal additional information in order to assign argument labels. Not only does this simplify the job of the grammar writer, but it makes it easier to construct lexical entries automatically and to integrate RMRSs derived from shallower systems. However, grammar engineers respond to consumers: if more detailed role labelling had a clear utility and required an analysis at the syntax level, we would want to do it in the grammar. The question is whether it is practically possible. Detailed discussion of the linguistics literature would be out of place here. I will assume that Dowty (1991) is right in the assertion that there is no small (say, less than 10) set of role labels which can also be used to link the predicate to its arguments in compositionally constructed semantics (i.e., argument-indexing in Dowty’s terminology) such that each role label can be given a consistent individual semantic interpretation. For our purposes, a consistent semantic interpretation involves entailment of one or more useful real world propositions (allowing for exceptions to the entailment for unusual individual sentences). This is not a general argument against rich role labels in semantics, ju</context>
<context position="22416" citStr="Dowty (1991)" startWordPosition="3658" endWordPosition="3659">nt in the grammars: the decision to add a standardised sense label, such as cause, does not require changes to the type system, for instance. If we decide that we can identify true anti-causatives, we can easily make them a distinguished class via this convention. Conversely, in the situation where causation has not been recognised, and the verb has been treated as a single lexeme having an optional ARG2, the semantics is imperfect but at least the imperfection is local. In fact, determining argument labelling by the obliqueness hierarchy still allows generalisations to be made for all verbs. Dowty (1991) argues for the notion of proto-agent (p-agt) and protopatient (p-pat) as cluster concepts. Proto-agent properties include volitionality, sentience, causation of an event and movement relative to another participant. Proto-patient properties include being causally affected and being stationary relative to another participant. Dowty claims that generalisations about which arguments are lexicalised as subject, object and indirect object/oblique can be expressed in terms of relative numbers of p-agt and p-pat properties. If this is correct, then we can, 5 for example, predict that the ARG1 of any</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>David Dowty. 1991. Thematic proto-roles and argument selection. Language, 67(3):547–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
<author>Emily Bender</author>
</authors>
<title>Compositional semantics in a multilingual grammar resource.</title>
<date>2003</date>
<booktitle>In Proc. Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI2003,</booktitle>
<pages>33--42</pages>
<location>Vienna.</location>
<contexts>
<context position="8976" citStr="Flickinger and Bender (2003)" startWordPosition="1410" endWordPosition="1413">ep grammars here). Constraints on possible scopal relationships between EPs may be explicitly specified in the grammar via relationships between holes and labels. In particular qeq constraints (the only type considered here) indicate that, in the scoped forms, a label must either plug a hole directly or be connected to it via a chain of quantifiers. Hole arguments (other than the BODY of a quantifier) are always linked to a label via a qeq or other constraint (in a deep grammar RMRS). Variables survive in the models of RMRSs (i.e., the fully scoped trees) whereas holes and labels do not. 2See Flickinger and Bender (2003) and Flickinger et al. (2003) for the use of MRS in DELPH-IN grammars. 2 l1:a1: some q, BV(a1,x4), RSTR(a1,h5), BODY(a1,h6), h5 qeq l2, l2:a2: big a 1(e8), ARG1(a2,x4), l2:a3: angry a 1(e9), ARG1(a3,x4), l2:a4: dog n 1(x4), l4:a5: bark v 1(e2), ARG1(a5,x4), l4:a6: loud a 1(e10), ARG1(a6,e2) some q(x4, big a 1(e8,x4) n angry a 1(e9, x4) n dog n 1(x4), bark v 1(e2,x4) n loud a 1(e10,e2)) Figure 1: RMRS and scoped form for ‘Some big angry dogs bark loudly’. Tense and number are omitted. The naming convention for predicates corresponding to lexemes is: stem major sense tag, optionally followed by </context>
</contexts>
<marker>Flickinger, Bender, 2003</marker>
<rawString>Dan Flickinger and Emily Bender. 2003. Compositional semantics in a multilingual grammar resource. In Proc. Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI2003, pages 33–42, Vienna.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
<author>Emily Bender</author>
<author>Stephan Oepen</author>
</authors>
<title>MRS in the LinGO Grammar Matrix: A practical user’s guide.</title>
<date>2003</date>
<note>http://tinyurl.com/crf5z7.</note>
<contexts>
<context position="9005" citStr="Flickinger et al. (2003)" startWordPosition="1415" endWordPosition="1418"> possible scopal relationships between EPs may be explicitly specified in the grammar via relationships between holes and labels. In particular qeq constraints (the only type considered here) indicate that, in the scoped forms, a label must either plug a hole directly or be connected to it via a chain of quantifiers. Hole arguments (other than the BODY of a quantifier) are always linked to a label via a qeq or other constraint (in a deep grammar RMRS). Variables survive in the models of RMRSs (i.e., the fully scoped trees) whereas holes and labels do not. 2See Flickinger and Bender (2003) and Flickinger et al. (2003) for the use of MRS in DELPH-IN grammars. 2 l1:a1: some q, BV(a1,x4), RSTR(a1,h5), BODY(a1,h6), h5 qeq l2, l2:a2: big a 1(e8), ARG1(a2,x4), l2:a3: angry a 1(e9), ARG1(a3,x4), l2:a4: dog n 1(x4), l4:a5: bark v 1(e2), ARG1(a5,x4), l4:a6: loud a 1(e10), ARG1(a6,e2) some q(x4, big a 1(e8,x4) n angry a 1(e9, x4) n dog n 1(x4), bark v 1(e2,x4) n loud a 1(e10,e2)) Figure 1: RMRS and scoped form for ‘Some big angry dogs bark loudly’. Tense and number are omitted. The naming convention for predicates corresponding to lexemes is: stem major sense tag, optionally followed by and minor sense tag (e.g., lo</context>
</contexts>
<marker>Flickinger, Bender, Oepen, 2003</marker>
<rawString>Dan Flickinger, Emily Bender, and Stephan Oepen. 2003. MRS in the LinGO Grammar Matrix: A practical user’s guide. http://tinyurl.com/crf5z7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
<author>Jan Tore Lønning</author>
<author>Helge Dyvik</author>
<author>Stephan Oepen</author>
<author>Francis Bond</author>
</authors>
<title>SEM-I rational MT — enriching deep grammars with a semantic interface for scalable machine translation.</title>
<date>2005</date>
<booktitle>In Proc. MT Summit X,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="13752" citStr="Flickinger et al. (2005)" startWordPosition="2231" endWordPosition="2234">en approach, as opposed to using semantically richer roles such as AGENT, GOAL and INSTRUMENT. An MRS can, in fact, be written using a conventional predicate-argument representation. A representation which uses ordered argument labels can be recovered from this in the obvious way. E.g., l:like v 1(e,x,y) is equivalent to l:a:like v 1(e), ARG1(a,x), ARG2(a,y). A fairly large inventory of argument labels is actually used in the DELPH-IN grammars (e.g., RSTR, BODY). To recover these from the conventional predicate-argument notation requires a look up in a semantic interface component (the SEM-I, Flickinger et al. (2005)). But open-class predicates use the ARGn convention, where n is 0,1,2,3 or 4 and the discussion here 3 only concerns these.5 Arguably, the DELPH-IN approach is Davidsonian rather than neo-Davidsonian in that, even in the RMRS form, the arguments are related to the predicate via the anchor which plays no other role in the semantics. Unlike the neo-Davidsonian use of the event variable to attach arguments, this allows the same style of representation to be used uniformly, including quantifiers, for instance. Arguments can omitted completely without syntactic ill-formedness of the RMRS, but this</context>
</contexts>
<marker>Flickinger, Lønning, Dyvik, Oepen, Bond, 2005</marker>
<rawString>Dan Flickinger, Jan Tore Lønning, Helge Dyvik, Stephan Oepen, and Francis Bond. 2005. SEM-I rational MT — enriching deep grammars with a semantic interface for scalable machine translation. In Proc. MT Summit X, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="6114" citStr="Flickinger (2000)" startWordPosition="921" endWordPosition="922">ompositional semantics which are relevant beyond DELPH-IN. The first, argument indexing (§3), is a relatively clear case in which the constraints imposed by grammar engineering have a significant effect on choice between plausible alternatives. I have chosen to talk about this both because of its relationship with the currently popular task of semantic role labelling and because the DELPH-IN approach is now fairly stable after a quite considerable degree of experimentation. What I am reporting is thus a perspective on work done primarily by Flickinger within the English Resource Grammar (ERG: Flickinger (2000)) and by Bender in the context of the Grammar Matrix (Bender et al., 2002), though I’ve been involved in many of the discussions. The second main topic (§4) is new work on a semantic dependency representation which can be derived from MRS, extending the previous work by Oepen (Oepen and L¢nning, 2006). Here, the motivation came from an engineering perspective, but the nature of the representation, and indeed the fact that it is possible at all, reveals some interesting aspects of semantic composition in the grammars. 2 The MRS and RMRS languages This paper concerns only representations which a</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanae Fujita</author>
<author>Francis Bond</author>
<author>Stephan Oepen</author>
<author>Takaaki Tanaka</author>
</authors>
<title>Exploiting semantic information for HPSG parse selection.</title>
<date>2007</date>
<booktitle>In Proc. Workshop on Deep Linguistic Processing, ACL 2007,</booktitle>
<location>Prague.</location>
<contexts>
<context position="4903" citStr="Fujita et al. (2007)" startWordPosition="733" endWordPosition="736">neration (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the development of dependency-style representations (including Dependency MRS (DMRS) discussed in §4) has been to improve ease of use for consumers of the representation and human annotators, as well as use in statistical ranking of analyses/realisations (Fujita et al. (2007), Oepen and L¢nning (2006)). Integration with distributional semantic techniques is also of interest. The belated ‘introduction’ to MRS in Copestake et al. (2005) primarily covered formal representation of complete utterances. Copestake (2007a) described uses of (R)MRS in applications. Copestake et al. (2001) and Copestake (2007b) concern the algebra for composition. What I want to do here is to concentrate on less abstract issues in the syntax-semantics interface. I will discuss two cases where the grammar engineering perspective is important and where there are some conclusions about composi</context>
</contexts>
<marker>Fujita, Bond, Oepen, Tanaka, 2007</marker>
<rawString>Sanae Fujita, Francis Bond, Stephan Oepen, and Takaaki Tanaka. 2007. Exploiting semantic information for HPSG parse selection. In Proc. Workshop on Deep Linguistic Processing, ACL 2007, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Ontological promiscuity.</title>
<date>1985</date>
<booktitle>In Proc. ACL-85,</booktitle>
<pages>61--69</pages>
<location>Chicago, IL.</location>
<contexts>
<context position="34674" citStr="Hobbs (1985)" startWordPosition="5804" endWordPosition="5805">emantic head (it’s an argument of poss rather than bite v 1). This means that when the relative clause 8Given that non-local effects are relatively circumscribed, it is possible to require adjacency in some parts of the DMRS. This leads to a technique for recording underspecification of noun compound bracketing, for instance. is combined with the gap filler, the label equality and the argument instantiation correspond to different EPs. Thus there is a label equality which cannot be combined with an argument link and has to be represented by an undirected /EQ arc. 5 Related work and conclusion Hobbs (1985) described a philosophy of computational compositional semantics that is in some respects similar to that presented here. But, as far as I am aware, the Core Language Engine book (Alshawi, 1992) provided the first detailed description of a truly computational approach to compositional semantics: in any case, Steve Pulman provided my own introduction to the idea. Currently, the ParGram project also undertakes largescale multilingual grammar engineering work: see Crouch and King (2006) and Crouch (2006) for an account of the semantic composition techniques now being used. I am not aware of any o</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry Hobbs. 1985. Ontological promiscuity. In Proc. ACL-85, pages 61–69, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Alex Lascarides</author>
</authors>
<title>A logic of semantic representations for shallow parsing.</title>
<date>2009</date>
<booktitle>In Proc. EACL-2009,</booktitle>
<location>Athens.</location>
<contexts>
<context position="3851" citStr="Koller and Lascarides (2009)" startWordPosition="568" endWordPosition="571">oncentrate on discussing work which has used Minimal Recursion Semantics (MRS: Copestake et al. (2005)) or Robust Minimal Recursion Semantics (RMRS: Copestake (2003)). The (R)MRS approach has been adopted as a common framework for the DELPH-IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH-IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for deve</context>
</contexts>
<marker>Koller, Lascarides, 2009</marker>
<rawString>Alexander Koller and Alex Lascarides. 2009. A logic of semantic representations for shallow parsing. In Proc. EACL-2009, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Jan Tore Lønning</author>
</authors>
<title>Discriminant-based MRS banking.</title>
<date>2006</date>
<booktitle>In Proc. LREC2006,</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="24777" citStr="Oepen and Lønning (2006)" startWordPosition="4024" endWordPosition="4027">e for argument indexation. 4 Dependency MRS The second main topic I want to address is a form of semantic dependency structure (DMRS: see wiki.delph-in.net for the evolving details). There are good engineering reasons for producing a dependency style representation with links between predicates and no variables: ease of readability for consumers of the representation and for human annotators, parser comparison and integration with distributional lexical semantics being the immediate goals. Oepen has previously produced elementary dependencies from MRSs but the procedure (partially sketched in Oepen and Lønning (2006)) was not intended to produce complete representations. It turns out that a DMRS can be constructed which can be demonstrated to be interconvertible with RMRS, has a simple graph structure and minimises redundancy in the representation. What is surprising is that this can be done for a particular class of grammars without mak7Sanfilippo (1990) originally introduced Dowty’s ideas into computational linguistics, but this relative behaviour cannot be correctly expressed simply by using p-agt and ppat directly for argument indexation as he suggested. It is incorrect for examples like (2) to be lab</context>
</contexts>
<marker>Oepen, Lønning, 2006</marker>
<rawString>Stephan Oepen and Jan Tore Lønning. 2006. Discriminant-based MRS banking. In Proc. LREC2006, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Dan Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: A corpus annotated with semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="15963" citStr="Palmer et al., 2005" startWordPosition="2605" endWordPosition="2608"> into discussion of syntax to explain in detail here. While the majority of cases are straightforward, a few are not (e.g., because they depend on decisions about which form is taken as the base in an alternation). However, all decisions are made at the level of lexical types: adding an entry for a lexeme for a DELPH-IN grammar only requires working out its lexical type(s) (from syntactic behaviour and very constrained semantic notions, e.g., control). The actual assignment of arguments to an utterance is just a consequence of parsing. Argument labelling is thus quite different from PropBank (Palmer et al., 2005) role labelling despite the unfortunate similarity of the PropBank naming scheme. It follows from the fixed arity of predicates that lexemes with different numbers of argu5ARG4 occurs very rarely, at least in English (the verb bet being perhaps the clearest case). ments should be given different predicate symbols. There is usually a clear sense distinction when this occurs. For instance, we should distinguish between the ‘depart’ and ‘bequeath’ senses of leave because the first takes an ARG1 and an ARG2 (optional) and the second ARG1, ARG2 (optional), ARG3. We do not draw sense distinctions wh</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005. The Proposition Bank: A corpus annotated with semantic roles. Computational Linguistics, 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="4030" citStr="Pollard and Sag (1994)" startWordPosition="598" endWordPosition="601">ch has been adopted as a common framework for the DELPH-IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH-IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), enrichment by deeper analysis (including lexical semantics and anaphora resolution, both the subject of ongoing work), and (robust) inference. The motivation for the</context>
<context position="14785" citStr="Pollard and Sag, 1994" startWordPosition="2404" endWordPosition="2407">is allows the same style of representation to be used uniformly, including quantifiers, for instance. Arguments can omitted completely without syntactic ill-formedness of the RMRS, but this is primarily relevant to shallower grammars. A semantic predicate, such as like v 1, is a logical predicate and as such is expected to have the same arity wherever it occurs in the DELPH-IN grammars. Thus models for an MRS may be defined in a language with or without argument labels. The ordering of arguments for open class lexemes is lexically specified on the basis of the syntactic obliqueness hierarchy (Pollard and Sag, 1994). ARG1 corresponds to the subject in the base (non-passivised) form (‘deep subject’). Argument numbering is consecutive in the base form, so no predicate with an ARG3 is lexically missing an ARG2, for instance. An ARG3 may occur without an instantiated ARG2 when a syntactically optional argument is missing (e.g., Kim gave to the library), but this is explicit in the linearised form (e.g., give v(e,x,u,y)). The full statement of how the obliqueness hierarchy (and thus the labelling) is determined for lexemes has to be made carefully and takes us too far into discussion of syntax to explain in d</context>
<context position="23261" citStr="Pollard and Sag (1994)" startWordPosition="3788" endWordPosition="3791">patient properties include being causally affected and being stationary relative to another participant. Dowty claims that generalisations about which arguments are lexicalised as subject, object and indirect object/oblique can be expressed in terms of relative numbers of p-agt and p-pat properties. If this is correct, then we can, 5 for example, predict that the ARG1 of any predicate in a DELPH-IN grammar will not have fewer p-agt properties than the ARG2 of that predicate.7 As an extreme alternative, we could use labels which were individual to each predicate, such as LIKER and LIKED (e.g., Pollard and Sag (1994)). For such role labels to have a consistent meaning, they would have to be lexeme-specific: e.g., LEAVER1 (‘departer’) versus LEAVER2 (‘bequeather’). However this does nothing for semantic generalisation, blocks the use of argument labels in syntactic generalisations and leads to an extreme proliferation of lexical types when using typed feature structure formalisms (one type would be required per lexeme). The labels add no additional information and could trivially be added automatically to an RMRS if this were useful for human readers. Much more interesting is the use of richer lexical sema</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head-driven Phrase Structure Grammar. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Roa</author>
<author>Valia Kordoni</author>
<author>Yi Zhang</author>
</authors>
<title>Mapping between compositional semantic representations and lexical semantic resources: Towards accurate deep semantic parsing.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08,</booktitle>
<pages>189--192</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<contexts>
<context position="24119" citStr="Roa et al. (2008)" startWordPosition="3927" endWordPosition="3930">n syntactic generalisations and leads to an extreme proliferation of lexical types when using typed feature structure formalisms (one type would be required per lexeme). The labels add no additional information and could trivially be added automatically to an RMRS if this were useful for human readers. Much more interesting is the use of richer lexical semantic generalisations, such as those employed in FrameNet (Baker et al., 1998). In principle, at least, we could (and should) systematically link the ERG to FrameNet, but this would be a form of semantic enrichment mediated via the SEM-I (cf Roa et al. (2008)), and not an alternative technique for argument indexation. 4 Dependency MRS The second main topic I want to address is a form of semantic dependency structure (DMRS: see wiki.delph-in.net for the evolving details). There are good engineering reasons for producing a dependency style representation with links between predicates and no variables: ease of readability for consumers of the representation and for human annotators, parser comparison and integration with distributional lexical semantics being the immediate goals. Oepen has previously produced elementary dependencies from MRSs but the</context>
</contexts>
<marker>Roa, Kordoni, Zhang, 2008</marker>
<rawString>Sergio Roa, Valia Kordoni, and Yi Zhang. 2008. Mapping between compositional semantic representations and lexical semantic resources: Towards accurate deep semantic parsing. In Proc. ACL-08, pages 189–192, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Sanfilippo</author>
</authors>
<title>Grammatical Relations, Thematic Roles and Verb Semantics.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<contexts>
<context position="25122" citStr="Sanfilippo (1990)" startWordPosition="4085" endWordPosition="4087">he representation and for human annotators, parser comparison and integration with distributional lexical semantics being the immediate goals. Oepen has previously produced elementary dependencies from MRSs but the procedure (partially sketched in Oepen and Lønning (2006)) was not intended to produce complete representations. It turns out that a DMRS can be constructed which can be demonstrated to be interconvertible with RMRS, has a simple graph structure and minimises redundancy in the representation. What is surprising is that this can be done for a particular class of grammars without mak7Sanfilippo (1990) originally introduced Dowty’s ideas into computational linguistics, but this relative behaviour cannot be correctly expressed simply by using p-agt and ppat directly for argument indexation as he suggested. It is incorrect for examples like (2) to be labelled as p-agt, since they have no agentive properties. ing use of the evident clues to syntax in the predicate names. The characteristic variable property discussed in §2 is crucial: its availability allows a partial replication of composition, with DMRS links being relatable to functor-argument combinations in the MRS algebra. I should empha</context>
</contexts>
<marker>Sanfilippo, 1990</marker>
<rawString>Antonio Sanfilippo. 1990. Grammatical Relations, Thematic Roles and Verb Semantics. Ph.D. thesis, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Thater</author>
</authors>
<title>Minimal Recursion Semantics as Dominance Constraints: Graph-Theoretic Foundation and Application to Grammar Engineering.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit¨at des Saarlandes.</institution>
<contexts>
<context position="3866" citStr="Thater (2007)" startWordPosition="572" endWordPosition="573">which has used Minimal Recursion Semantics (MRS: Copestake et al. (2005)) or Robust Minimal Recursion Semantics (RMRS: Copestake (2003)). The (R)MRS approach has been adopted as a common framework for the DELPH-IN initiative (Deep Linguistic Processing with HPSG: http://www.delph-in.net) and the work discussed here has been done by and in collaboration with researchers involved in DELPH-IN. The programme of developing computational compositional semantics has a large number of aspects. It is important that the semantics has a logically-sound interpretation (e.g., Koller and Lascarides (2009), Thater (2007)), is cross1For instance, we cannot afford to underspecify number on nouns because of examples such as The hash browns is getting angry (from Pollard and Sag (1994) p.85). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 1–9, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 1 linguistically adequate (e.g., Bender (2008)) and is compatible with generation (e.g., Carroll et al. (1999), Carroll and Oepen (2005)). Ideally, we want support for shallow as well as deep syntactic analysis (which was the reason for developing RMRS), e</context>
</contexts>
<marker>Thater, 2007</marker>
<rawString>Stefan Thater. 2007. Minimal Recursion Semantics as Dominance Constraints: Graph-Theoretic Foundation and Application to Grammar Engineering. Ph.D. thesis, Universit¨at des Saarlandes.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>