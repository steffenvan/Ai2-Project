<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002850">
<title confidence="0.998644">
Scaling Construction Grammar up to Production Systems:
the Situated Constructional Interpretation Model
</title>
<author confidence="0.865234">
Guillaume Pitel
</author>
<affiliation confidence="0.534982">
Langue et Dialogue
</affiliation>
<address confidence="0.735808">
LORIA
BP239 54000 Nancy, France
</address>
<email confidence="0.997757">
Guillaume.Pitel@gmail.com
</email>
<sectionHeader confidence="0.995597" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871666666667">
While a great effort has concerned the de-
velopment of fully integrated modular un-
derstanding systems, few researches have
focused on the problem of unifying exist-
ing linguistic formalisms with cognitive
processing models. The Situated Construc-
tional Interpretation Model is one of these
attempts. In this model, the notion of “con-
struction” has been adapted in order to be
able to mimic the behavior of Production
Systems. The Construction Grammar ap-
proach establishes a model of the relations
between linguistic forms and meaning, by
the mean of constructions. The latter can be
considered as pairings from a topologically
structured space to an unstructured space,
in some way a special kind of production
rules.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998999">
Accounting for pragmatical and cognitive phe-
nomena in a linguistic formalism is a challenging
task whose resolution would be of great benefit for
many fields of linguistics, especially those dealing
with interpretation in a context. In domains such as
practical dialogue or embodied understanding,
there would be a real gain in dealing with envi-
ronment data the same way one deals with linguis-
tic data. These kinds of systems currently need ad
hoc heuristics or representations. These heuristics
</bodyText>
<page confidence="0.991498">
49
</page>
<bodyText confidence="0.999954285714286">
are implemented in modules that are often impos-
sible to reuse for another task than the one they
were developed for. This point particularly con-
cerns phenomena that lay at the interface of lin-
guistics and general cognition, such as vagueness
(Ballweg, 1983), reference resolution (Brown-
Schmidt, 2003; Reboul, 1999), or modeling of
cognitive representations (Langacker, 1983;
Talmy, 1988).
Similarly, accounting for linguistic phenomena
in a psychologically motivated model is far from
simple. The attempts in that direction are often
limited to simple phenomena, because all linguistic
formalisms rely on principles slightly or totally
different from those of cognitive architectures.
The definitive solution to this problem is proba-
bly still far from reach, but nevertheless, I think
that the maturity of cognitive linguistics and the
consequent emergence of language analyzers con-
nected to cognitive architectures is an excellent
direction toward a unified theory mixing linguistic
and psychological models. The Embodied Con-
struction Grammar or ECG (Bergen, 2003) and its
analyzer (Bryant, 2003) are a good example of
such an effort, even though it does not go beyond
the linguistic layer since mental simulation is left
to a mental simulation module based on the notion
of x-schema (Narayanan, 2001).
Consequently, I try to propose a model that con-
ciliates a linguistic theory with a cognitive archi-
tecture. The choice of the linguistic theory
naturally goes to Construction Grammar (Fillmore,
1988; Kay 2002) and Frame Semantics (Fillmore,
1982), due to the parallel one can draw between a
production rule and a construction, and the cogni-
</bodyText>
<note confidence="0.845036">
Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999754428571428">
tive architecture is, obviously, the family of Pro-
duction Systems (Newell, 1990; Anderson, 1993).
Moreover, since many pragmatical models rely on
topologically structured representation, I introduce
the notion of context, a notion that has never been
adapted to these theories in order to organize data
in “storages” structured in dissimilar ways.
</bodyText>
<subsectionHeader confidence="0.998325">
1.1 Typical Problem
</subsectionHeader>
<bodyText confidence="0.9735338">
Consider a situation where a user can command a
software to manipulate some very simple objects
(colored geometrical objects of various sizes). The
user may say (a) “Put the small red square on the
left”, (b) “Remove the small red square on the left”
or (c) “Move the small red square on the left”.
First, these three utterances may involve differ-
ent parsing depending on the actual environment of
the utterance, at least for those with “put” and
“move”. Second, the “square” targeted by the user
may be a rectangle in the actual software represen-
tation, with slightly different width and height. It
may also be relatively small compared to other red
squares, but bigger than other objects, and rela-
tively red compared to other non-square objects.
</bodyText>
<figureCaption confidence="0.9885755">
Figure 1: Some situations involving different
understandings (without color).
</figureCaption>
<bodyText confidence="0.999962255813953">
Imagine what happens in the different situations
illustrated in Figure 1. In situation 1, for instance,
(a) would not be understandable, since the small
square is already on the left, while (c) could lead to
the one argument sense of “move”, i.e. “move
something somewhere else”, not to the two argu-
ments version “move something somewhere” (ac-
tually, the one-argument sense is an implicit
understanding of the destination allowed by
“move”, so the difference should not be lexical-
ized). In situation 2, (b) and (c) would lead to two
different interpretations of the referring expression
“the small red square on the left”: in (b), it refers to
the square in the center (with a possible wavering),
while it preferably refers to the square on the right
in (c). In situation 3, (c) may be interpreted with
the one argument sense of “move”, and will target
the square on the left since it is the smallest, but
there should be a strong hesitation, since the other
square is not that bigger, and the two arguments
sense of “move” is intuitively preferred. At the
same time (a) will target the square on the right,
which is relatively small compared to the neigh-
boring circles, but would raise incomprehension if
the circles were missing.
In general, in order to take those facts into ac-
count, it is necessary either to produce all possible
analyzes at each layer of the interpretation (which
is quite problematic if it is desirable to allow for
imperfect analyzes), or to allow two-ways interac-
tions between the layers of interpretation (for in-
stance, the pragmatic layer talking back to the
semantic layer about the fact that the original posi-
tion of an object is the same as the requested desti-
nation, which may indicate a wrong analysis).
My proposal is to allow for a generic capacity of
interaction between the states of the interpretation
(speaking about states is better than about layers
since the latter presupposes something about the
organizing of the interpretation), based on a unified
operation between all the possible states. More
specifically, the idea is to merge the notions from
construction grammar and productions systems.
</bodyText>
<subsectionHeader confidence="0.997941">
1.2 Merging Construction Grammar and
Production Systems
</subsectionHeader>
<bodyText confidence="0.999835">
Merging a linguistic analyzer with a cognitive
processing model may seem a bit useless since
they do not share the same objective. Linguistic
analyzer’s goal is to provide a formal model for the
representation of linguistic knowledge, accordingly
to linguistic observations. Cognitive models, on the
other hand, aim at helping the modeling of real
cognitive processing, in order to compare theoreti-
cal model of perception processing with real data
from experiments. Cognitive models like produc-
tion systems being Turing-equivalent, they typi-
cally do not lack of any expressiveness, meaning
that anything one can describe with any linguistic
representation could be implemented within a cog-
nitive model (hopefully, since linguistic compe-
tence is part of the cognitive competence).
</bodyText>
<page confidence="0.974783">
50
</page>
<bodyText confidence="0.999895142857143">
However, to my knowledge, no attempt to try
describing a linguistic competence within a cogni-
tive model has gone a long way. Existing re-
searches on that topic have focused on very narrow
problems, and what is more important, have been
tightened to very small lexicons (Emond, 1997;
Ball, 2003; Fowles-Winkler and Michaelis, 2005).
My analysis of this problem is that production
systems are too permissive to allow a human to
describe a grammar with a reasonable effort. More
specifically, all generalization links that exist be-
tween grammar rules should be encoded in some
explicit way in a production system.
Furthermore, linguistic formalisms are designed
in such way to only express all possible human
languages. In other words, a linguistic formalism is
successful when it is flexible enough to describe all
linguistic phenomena, while being human-readable
enough to allow for a large-scale grammar devel-
opment. As a consequence, linguistic formalisms
are too restrictive to allow dealing with cognitive
processes like the ones described using production
systems.
Putting together a linguistic formalism and a
model of pragmatical and cognitive processing
implies to make a choice among all the current
theories. Given the large predominance of produc-
tion systems in cognitive modeling, it seems quit-
</bodyText>
<figureCaption confidence="0.9186795">
Figure 3: First step of analysis, the global
construction (Imperative) is not active yet.
</figureCaption>
<bodyText confidence="0.999845769230769">
natural to choose them as the cognitive model. The
choice for the linguistic formalism is more open.
Previous attempts of linguistic modeling in cogni-
tive models have used X theory, categorical gram-
mar or construction grammar. My pick has been
the construction grammar because it shares some
interesting features with production systems, and
and because it deals directly with semantic, con-
trary to other grammatical theories. Particularly,
constructions are pairing between too poles: form
and meaning, this is very similar to the notion of a
production taking one input from a chunk, and
producing its output into another one.
</bodyText>
<subsectionHeader confidence="0.997904">
1.3 Example of processing
</subsectionHeader>
<bodyText confidence="0.999946863636364">
In such an approach, what should happen when
interpreting “move the small square on the left” in
situation 3 on the Figure 1? The first step of the
analysis (simplified for sake of clarity), illustrated
in Figure 3, shows how “move” produces a predi-
cate that encompasses a Cause-Motion schema,
itself evoking a Source-Path-Goal (SPG) and a
Force-Action (FA) schema. The CxMove construc-
tion adds a constraint about the fact that source and
goal should differ.
After this, two constructions CxImperative can
connect, through their theme role, the referents
evoked by the RefExp shemas (each construction
being one possible interpretation) with the source
of the Source-Path-Goal. The CxImperative encap-
sulates the predicate in a Request schema. Another
construction can connect the goal of the Source-
Path-Goal with the Spatial-PP produced from “on
the left”, with the predicate modified by the con-
struction that took its RefExp from “the small
square”.
At this point, the “mental simulation” required
</bodyText>
<figureCaption confidence="0.8514375">
Figure 2: Mental simulation of the reference
resolution
</figureCaption>
<bodyText confidence="0.993863">
to resolve the referents can start. This step is illus-
trated in a very simplified way in Figure 2. The
complete process is described in (Pitel, 2004; Pitel
</bodyText>
<figure confidence="0.936929142857143">
CxMove
Move the small square on the left
Cause-
Motion
FA
SPG
Ref-Exp
CxRefExpSp
Ref-Exp
CxSpatialPP
Spatial-PP
Resolution Context 2
Visual Context
Resolution Context 1
</figure>
<page confidence="0.990699">
51
</page>
<bodyText confidence="0.99947525">
&amp; Sansonnet, 2003) and processes potential refer-
ents through several sorting steps, one for each
referential predicate (here: square and small in
Resolution Context 1 from the two-arguments
move interpretation; square, small and on the left
in Resolution Context 2 from the other one). The
process is described with the kind of constructions
defined by the SCIM.
</bodyText>
<sectionHeader confidence="0.899847" genericHeader="method">
2 Basic Notions of the SCIM
</sectionHeader>
<bodyText confidence="0.999823166666667">
The Situated Constructional Interpretation model
(SCIM) describes how information can be proc-
essed in a way that is both linguistically and psy-
chologically plausible. It relies on three notions:
schemas are for low-level data description, con-
texts are for describing the organization of in-
stances of schemas, and s-constructions represent
the mean to process data. Eventually, a SCIM-
based interpretation system will run instances of s-
constructions that take and produce instances of
schemas situated in instances of contexts. These
three notions are partly inherited from the ECG.
</bodyText>
<subsectionHeader confidence="0.949995">
2.1 Schemas
</subsectionHeader>
<bodyText confidence="0.989648363636363">
Schemas are constrained, typed features struc-
tures, with an inheritance mechanism and no type
disjunction. Schemas are a kind of data type. They
describe complex structures of information used to
represent the state of the running interpretation. As
shown in Figure 4, schemas are defined with three
blocks:
■ inherits schema-name1, É which specifies
from which schema(s) this one inherits from. a
specific case of the schema x, it inherits all of
its properties (roles and constraints).
</bodyText>
<listItem confidence="0.84871025">
■ roles, which specifies a list of roles, con-
strained to a given schema type or atomic type
(Integer, Boolean, String, or user-defined
enumerations of symbols).
</listItem>
<bodyText confidence="0.945531722222222">
■ constraints, which specify the constraints that
must be verified in order for an instance of the
schema to be a valid one. A constraint can be a
predicate if the role has an atomic type, or an
identification constraint (asserting that two
roles must share the same value), or a filler
constraint with a constant value.
An instance of schema is moreover described
by values attached to its roles (some or all of them
may be left underspecified), a unique identifier, a
positive value representing its informative capac-
ity, a percentage of trust level, and the list of its
parents’ identifiers. A parent of an instance of
schema is an instance of schema “used” in the
process that led to its production. It is thus possi-
ble, in a s-construction, to know whether two given
instances of schema are somehow related to each
other in the interpretation process.
</bodyText>
<figure confidence="0.98585195">
schema &lt;schema-id&gt;
inherits &lt;schema-id0, ..., schema-idn&gt;
Roles
[?]&lt;local-type-id&gt;:&lt;atomic-type-id&gt;
[?]&lt;local-context-id&gt;:&lt;context-id&gt;[@&lt;local-context-id&gt;]
[?]&lt;local-schema-id&gt;:&lt;schema-id&gt;[@&lt;local-context-id&gt;]
Constraints
&lt;boolean-operation&gt;(&lt;constraint0&gt;, ..., &lt;constraintn&gt;)
&lt;role-id&gt; +— &lt;atomic-value&gt;|&lt;function&gt;(&lt;atomic-
value&gt;,É)
&lt;role-id&gt; H &lt;role-id&gt;|&lt;C-function&gt;(&lt;role-id&gt;)
&lt;role-id&gt; = &lt;role-id&gt;
&lt;boolean-predicate&gt;(&lt;role-id0&gt;, ..., &lt;role-idn&gt;)
a &lt;role-id&gt; is one of:
self (optional if not used alone)
&lt;local-type-id&gt;
&lt;local-context-id&gt;
&lt;local-schema-id&gt;
&lt;inherited-schema&gt;*&lt;inherited-role-id&gt;
&lt;role-id&gt;.&lt;sub-role-id&gt;
</figure>
<figureCaption confidence="0.999987">
Figure 4: Schema definition formalism.
</figureCaption>
<bodyText confidence="0.99958125">
From the production systems perspective, sche-
mas define the type of features that can be attached
to a category. Basically, in that point of view, an
instance of schema is a chunk and roles are slots.
</bodyText>
<subsectionHeader confidence="0.877262">
Schemas hierarchy
</subsectionHeader>
<bodyText confidence="0.9998753">
Schemas can inherit roles and constraints from
other schemas. That means that schemas are orga-
nized in a multiple inheritance hierarchy. In order
to avoid ambiguity in role access, inherited roles
must be accessed through an inheritance path. For
instance, accessing the role color in a schema
Square, if the hierarchy is Fig-
ure4Rectangle4Square, and where the color role
is declared in the Figure schema, would be realized
through this kind of path: Rectangle*Figure*color.
</bodyText>
<page confidence="0.995177">
52
</page>
<bodyText confidence="0.965432769230769">
Inheritance also means that an instance of
schema S can be unified with a role whose type is
R if S == R or if R is one of the parents of S.
One problem with this approach of inheritance is
that, in order to fulfill the Liskov substitution prin-
ciple (Liskov, 1988), it is sometimes necessary to
use unnatural type hierarchies (stating that Square
doesn’t inherit from Rectangle, for instance). I am
very mindful about this problem, since such a dis-
crepancy is quite tedious for a model that aims to
approximate the human way of processing infor-
mation, but this problem is out of the scope of this
paper1.
</bodyText>
<sectionHeader confidence="0.514688" genericHeader="method">
Constraints
</sectionHeader>
<bodyText confidence="0.999557">
A schema declaration contains a set of constraints
that must be satisfied in order for an instance of
this schema to be considered valid. Constraints are
specified with six basic forms:
</bodyText>
<listItem confidence="0.981138933333333">
■ Type constraints on roles.
■ Boolean operation (OR, NOT, NAND,É)
connecting several constraints.
■ Filler constraint symbolized by a single arrow
(&lt;--) specifies that a constant, atomic value
must fill the role in an instance.
■ Identification constraint, symbolized by a
double-headed arrow (H), specifies that both
sides of the constraint must unify, that is, all
roles’ values must be compatible with each
other.
■ An equality constraint (=) that constrains two
roles to refer to the same instance.
■ A boolean predicate constraint can be as-
serted between any number of roles.
</listItem>
<bodyText confidence="0.990528785714286">
Another kind of constraint, on the places occu-
pied by instances of schema in context, will be ex-
plained in the section about s-constructions, as will
1 We consider that this problem could be solved by the ap-
proach called “Points of View Theory” (which is not related to
inter-person points of view), proposed by Pitel (2004). In this
theory, there is no type hierarchy, and the ability to substitute
a representation by another is described by rules that can take
the dynamic context into account. In this approach, types do
not represent concepts, but points of view on perceptions (in
the wide meaning), and transition from one point of view to
the other is context-dependent.
the role of interrogation marks in the schema dec-
laration formalism.
</bodyText>
<subsectionHeader confidence="0.994947">
2.2 Contexts
</subsectionHeader>
<bodyText confidence="0.992377619047619">
A context declaration is a description of a container
that can hold instances of schemas. In other words,
it describes a space (including the topology part
that can be specified by a set of relations and op-
erations) that can contain pointers to instances of
schemas at given places.
The notion of context inherits all of the proper-
ties of the notion of schema. Actually, a context is
really a kind of schema and, as a consequence, a
schema’s role can be restricted to be a context. A
declaration of context adds three more blocks to
the declaration of a schema, as shown in Figure 5:
■ places declare a list of opaque types (the inter-
nal structure of the type is hidden in the im-
plementation) that describe an acceptable
position in the context. Instances of schema (or
context) that will be contained in an instance
of this context will be linked with a position
whose type is one (and only one) of the de-
clared places. Examples of places are: point,
segment, multi-segment, line, box, disc, É
</bodyText>
<figure confidence="0.950529214285714">
context &lt;context-id&gt;
inherits &lt;context-id0, ..., context-idn&gt;
Roles
// idem schemas roles
Constraints
// idem schemas constraints
Places
&lt;place-id&gt;
Relations
&lt;relation-id(&lt;place-id&gt;, &lt;place-id&gt;,...)&gt; y &lt;type-id&gt;
// for instance: before(point, point) y Boolean
Operations
&lt;operation-id&gt;(&lt;place-id&gt;, &lt;place-id&gt;,...) y &lt;place-id&gt;
// for instance: intersection(segment, segment) y segment
</figure>
<figureCaption confidence="0.999816">
Figure 5: Context definition formalism
</figureCaption>
<bodyText confidence="0.998216333333333">
■ relations are functions that associate a value in
an atomic domain from one or more places.
Relations define constraints on the positions of
a set of instances of schema. For instance, one
can define a precedence relation in a linear
context.
</bodyText>
<page confidence="0.997075">
53
</page>
<bodyText confidence="0.998326875">
■ operations are functions that associate a posi-
tion from one or more positions. For instance,
a union of segments is an operation.
Terminologically, an instance of schema (or
context) located in a context, that is, an instance
with a place, will be called a situated instance,
whereas an instance of schema (or context) simply
connected to another instance by a role will just be
called a role instance.
The only explicit equivalent to contexts in ECG
is the notion of space, which describes Fau-
connier&apos;s mental spaces (Fauconnier, 1985). Im-
plicit contexts are however used in Construction
Grammar: the form pole, which stores instances of
schemas representing linguistic data in a linear
space, and the unstructured meaning pole.
</bodyText>
<figure confidence="0.969108647058823">
s-construction &lt;s-construction-id&gt;
inherits &lt;s-construction-id0, É, s-construction-idn&gt;
roles // idem schema&apos;s roles
constructional
&lt;local-s-constr-id&gt;: &lt;s-construction-id&gt;
constituents
&lt;local-ctx-id&gt;: &lt;context-id&gt;[@&lt;local-ctx-id&gt;]/I/O1IO
&lt;local-constit-id&gt;: &lt;schema-id&gt;[@&lt;local-ctx-id&gt;]/I|O|IO
constraints
// idem schemas constraints, plus :
// a role-id can be marked as muted: ?&lt;role-id&gt;
// a place-id is either a &lt;local-constit-id&gt; or the result of a
context operation like:
// &lt;local-ctx-id&gt;.&lt;context-operation-id&gt;(&lt;place-id&gt;, ...)
&lt;role-id&gt; ⊂ &lt;role-id&gt; // right hand side must be parent
&lt;local-ctx-id&gt;.&lt;context-relation-id&gt;(&lt;place-id&gt;, ...)
OUT(&lt;local-constit-id&gt;) // remove the situated instance
</figure>
<figureCaption confidence="0.999926">
Figure 6: S-construction definition formalism
</figureCaption>
<subsectionHeader confidence="0.999723">
2.3 S-constructions
</subsectionHeader>
<bodyText confidence="0.997975444444445">
S-constructions are situated constructions, that is,
constructions that describe the relations between
several instances of schemas located in structured
contexts. As for the notion of context, the notion of
s-construction is derived from the schemas, be-
cause the s-construction itself can hold informa-
tion. Besides that, the declaration of a s-
construction contains:
■ A constructional block that describes the
other instances of s-constructions this s-
construction relies on. The block contains a
list of label: s-construction-name declara-
tions. Any restriction on the constituents of
those instances of s-construction is de-
scribed as a constraint on label.constituent
in the constraints block.
■ A constituents block that describes the in-
stances of contexts and schemas constrained
by the s-construction (note that the meaning
of constituents is different than in ECG).
The declaration of those constituents speci-
fies whether the instance must preexist
and/or whether it may be created or speci-
fied by the s-construction’s constraints.
From a production system point of view, it
means that we describe which instances are
in the input, and which one are produced.
</bodyText>
<subsectionHeader confidence="0.49433">
S-constructions hierarchy
</subsectionHeader>
<bodyText confidence="0.999952083333333">
Like schemas, s-constructions are organized in a
multiple inheritance hierarchy. Moreover, s-
constructions benefit from a mechanism of con-
structional dependence, held by the constructional
block. Those two notions are, to some extent, re-
dundant. Indeed, inheriting from a s-construction is
equivalent to having an instance of this s-
construction in the constructional block. However,
one can have two different instances of the same s-
construction in the constructional block, whereas it
is impossible to inherit twice from the same s-
construction. Moreover, it is possible to add a
negative semantics in the constructional block, in
order to assert that some instance of s-construction
must not have occurred to satisfy the s-
construction’s conditions.
The constructional block is thus more powerful
than the classical inheritance relation, but as for the
schemas hierarchy, it is not within the scope of this
paper to discuss about the inheritance relations be-
tween s-constructions. A declaration of s-
construction is thus, from that point of view, in
conformance with the standard view shared in con-
struction grammars.
</bodyText>
<subsectionHeader confidence="0.865092">
Situated aspects of s-constructions
</subsectionHeader>
<bodyText confidence="0.9996385">
A s-construction can “choose” instances of sche-
mas, given positional constraints in the context
where the instances of schemas are stored. Then,
the s-construction will “create” new instances of
context or schemas, or will specify some previ-
ously underspecified role’s value. S-constructions
</bodyText>
<page confidence="0.99394">
54
</page>
<bodyText confidence="0.999972307692308">
and s-constructions. Applications for such a model
are wide, from more integrated dialogue systems to
a unified theory of cognition and language.
A longer description of the processing architec-
ture would be necessary in order to really confront
the hypotheses I made in the section “Computa-
tional aspects”, but nevertheless, one can already
draw a parallel between this model with a spatial
structuring of information, and the structure that
neuromimetic models can handle. Also, incomplete
exploration of the search space, guided by a
cost/gain approach, has previously been proposed
as a plausible model of processing for human cog-
nition. More than computational efficiency, the
goal of this model is to propose a formalism that
would be easier to use both for linguistic and cog-
nitive modeling, in order to observe and act on the
simulated processing of language and other cogni-
tive functions.
Many of the claims in this paper have yet to be
proved through the implementation of the SCIM,
and cognitive modeling using the system. Since
many processing models have been made both on
construction grammar and production systems,
important researches should be easy enough to re-
use in the SCIM.
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999890691176471">
John R. Anderson (1993). Rules of the Mind. Erlbaum,
Hillsdale, NJ.
Jerry T. Ball (2003). Beginnings of a language compre-
hension module in ACT-R 5.0. In F. Detje, D. Do-
erner, &amp; H. Schaub (Eds.), In Proceedings of the
Fifth International Conference on Cognitive Model-
ing (pp. 231-232). Bamberg, Germany: Universitats-
Verlag Bamberg.
Joachim Ballweg (1983). Vagueness or context-
dependence? supervaluation revisited in a semantics
based on scales. In T. T. Ballmer and M. Pinkal, edi-
tors, Approaching Vagueness, pages 59--78. North
Holland, Amsterdam.
Benjamin K. Bergen &amp; Nancy Chang (2003). Embodied
construction grammar in simulation-based language
understanding. In J.-O. Ostman and M. Fried, editors,
Construction Grammar(s): Cognitive and Cross-
Language Dimensions. John Benjamins,
Sarah Brown-Schmidt &amp; Michael K. Tanenhaus (2003).
Referential domains and the interpretation of refer-
ring expressions in interactive conversation. In Proc.
of Diabruck 2003, Seventh Workshop on the Seman-
tics and Pragmatics of Dialogue (SEMDIAL).
Johno Bryant (2003). Constructional analysis. Master&apos;s
thesis, University of California at Berkeley,
Bruno Emond (1997). Modeling natural language com-
prehension and anaphora resolution with ACT-R. In
Proceedings of the Fourth Annual ACT-R Workshop
(pp. 1-8). Pittsburgh, PA: Department of Psychology,
Carnegie Mellon University.
Fauconnier, G. (1985). Mental Spaces: Aspects of
Meaning Construction in Natural Language. MIT
Press/Bradford, Cambridge, Mass. and London.
Fillmore, C. J. (1982). Frame Semantics. In L. S.
of Korea, editor, Linguistic in the Morning Calm,
pages 111--38. Hanshin, Seoul.
Fillmore, C. J. (1988). The Mechanisms of Construction
Grammar. Berkeley Linguistics Society, 14:0 35—55.
Anna M. Fowles-Winkler &amp; Laura Michaelis (2005) An
ACT-R model of sentence sorting with argument
structure constuctions. In the Proceedings of the Lin-
guistic Society of America Annual Meeting, January
7, 2005, Oakland, CA.
Kay, P. (2002). An informal sketch of a formal architec-
ture for construction grammar. Grammars, 5:0 1—
19.
Langacker, R. W. (1987). Foundations of Cognitive
Grammar, volume 1. Stanford University Press.
Liskov, B. (1988). Data abstraction and hierarchy.
SIGPLAN Notices, 230 (5), 1988.
Newell, A. (1990). Unified Theories of Cognition. Har-
vard University Press, Cambridge, MA.
Pitel, G. and Sansonnet, J.-P. (2003) Unified Represen-
tation of Typological, Absolute and Relational Predi-
cates. In Proceedings of PACLING’03. Avail. on first
author web page.
Pitel, G. (2004). MICO: la notion de construction situ&amp;e
pour un modele d’interpr6tation et de resolution de la
r6erence pour le dialogue finalis&amp;. PhD Thesis, Uni-
versit&amp; Paris XI.
Reboul, A. (1999). Reference, agreement, evolving ref-
erence and the theory of mental representation. In
M. Coene, W. D. Mulder, P. Dendale, and
Y. D&apos;Hulst, Eds. Studia Linguisticae in honorem Lil-
ianae Tasmowski, pages 601—616. Unipress, Pa-
dova.
Talmy, L. (1988). Force dynamics in language and
cognition. Cognitive Science, 12:0 49—100.
</reference>
<page confidence="0.998422">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.362287">
<title confidence="0.997722">Scaling Construction Grammar up to Production Systems: the Situated Constructional Interpretation Model</title>
<author confidence="0.985356">Guillaume Pitel</author>
<affiliation confidence="0.507656">Langue et</affiliation>
<address confidence="0.479576">BP239 54000 Nancy,</address>
<email confidence="0.993204">Guillaume.Pitel@gmail.com</email>
<abstract confidence="0.997180315789474">While a great effort has concerned the development of fully integrated modular understanding systems, few researches have focused on the problem of unifying existing linguistic formalisms with cognitive processing models. The Situated Constructional Interpretation Model is one of these attempts. In this model, the notion of “construction” has been adapted in order to be able to mimic the behavior of Production Systems. The Construction Grammar approach establishes a model of the relations between linguistic forms and meaning, by the mean of constructions. The latter can be considered as pairings from a topologically structured space to an unstructured space, in some way a special kind of production rules.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John R Anderson</author>
</authors>
<title>Rules of the Mind. Erlbaum,</title>
<date>1993</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="3338" citStr="Anderson, 1993" startWordPosition="505" endWordPosition="506">rayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics tive architecture is, obviously, the family of Production Systems (Newell, 1990; Anderson, 1993). Moreover, since many pragmatical models rely on topologically structured representation, I introduce the notion of context, a notion that has never been adapted to these theories in order to organize data in “storages” structured in dissimilar ways. 1.1 Typical Problem Consider a situation where a user can command a software to manipulate some very simple objects (colored geometrical objects of various sizes). The user may say (a) “Put the small red square on the left”, (b) “Remove the small red square on the left” or (c) “Move the small red square on the left”. First, these three utterances</context>
</contexts>
<marker>Anderson, 1993</marker>
<rawString>John R. Anderson (1993). Rules of the Mind. Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry T Ball</author>
</authors>
<title>Beginnings of a language comprehension module in ACT-R 5.0. In</title>
<date>2003</date>
<booktitle>In Proceedings of the Fifth International Conference on Cognitive Modeling</booktitle>
<pages>231--232</pages>
<location>Bamberg, Germany: UniversitatsVerlag Bamberg.</location>
<contexts>
<context position="7706" citStr="Ball, 2003" startWordPosition="1215" endWordPosition="1216"> Cognitive models like production systems being Turing-equivalent, they typically do not lack of any expressiveness, meaning that anything one can describe with any linguistic representation could be implemented within a cognitive model (hopefully, since linguistic competence is part of the cognitive competence). 50 However, to my knowledge, no attempt to try describing a linguistic competence within a cognitive model has gone a long way. Existing researches on that topic have focused on very narrow problems, and what is more important, have been tightened to very small lexicons (Emond, 1997; Ball, 2003; Fowles-Winkler and Michaelis, 2005). My analysis of this problem is that production systems are too permissive to allow a human to describe a grammar with a reasonable effort. More specifically, all generalization links that exist between grammar rules should be encoded in some explicit way in a production system. Furthermore, linguistic formalisms are designed in such way to only express all possible human languages. In other words, a linguistic formalism is successful when it is flexible enough to describe all linguistic phenomena, while being human-readable enough to allow for a large-sca</context>
</contexts>
<marker>Ball, 2003</marker>
<rawString>Jerry T. Ball (2003). Beginnings of a language comprehension module in ACT-R 5.0. In F. Detje, D. Doerner, &amp; H. Schaub (Eds.), In Proceedings of the Fifth International Conference on Cognitive Modeling (pp. 231-232). Bamberg, Germany: UniversitatsVerlag Bamberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Ballweg</author>
</authors>
<title>Vagueness or contextdependence? supervaluation revisited in a semantics based on scales. In</title>
<date>1983</date>
<booktitle>Approaching Vagueness,</booktitle>
<pages>59--78</pages>
<editor>T. T. Ballmer and M. Pinkal, editors,</editor>
<publisher>North</publisher>
<location>Holland, Amsterdam.</location>
<contexts>
<context position="1692" citStr="Ballweg, 1983" startWordPosition="259" endWordPosition="260">for many fields of linguistics, especially those dealing with interpretation in a context. In domains such as practical dialogue or embodied understanding, there would be a real gain in dealing with environment data the same way one deals with linguistic data. These kinds of systems currently need ad hoc heuristics or representations. These heuristics 49 are implemented in modules that are often impossible to reuse for another task than the one they were developed for. This point particularly concerns phenomena that lay at the interface of linguistics and general cognition, such as vagueness (Ballweg, 1983), reference resolution (BrownSchmidt, 2003; Reboul, 1999), or modeling of cognitive representations (Langacker, 1983; Talmy, 1988). Similarly, accounting for linguistic phenomena in a psychologically motivated model is far from simple. The attempts in that direction are often limited to simple phenomena, because all linguistic formalisms rely on principles slightly or totally different from those of cognitive architectures. The definitive solution to this problem is probably still far from reach, but nevertheless, I think that the maturity of cognitive linguistics and the consequent emergence </context>
</contexts>
<marker>Ballweg, 1983</marker>
<rawString>Joachim Ballweg (1983). Vagueness or contextdependence? supervaluation revisited in a semantics based on scales. In T. T. Ballmer and M. Pinkal, editors, Approaching Vagueness, pages 59--78. North Holland, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin K Bergen</author>
<author>Nancy Chang</author>
</authors>
<title>Embodied construction grammar in simulation-based language understanding.</title>
<date>2003</date>
<editor>In J.-O. Ostman and M. Fried, editors,</editor>
<publisher>John Benjamins,</publisher>
<marker>Bergen, Chang, 2003</marker>
<rawString>Benjamin K. Bergen &amp; Nancy Chang (2003). Embodied construction grammar in simulation-based language understanding. In J.-O. Ostman and M. Fried, editors, Construction Grammar(s): Cognitive and CrossLanguage Dimensions. John Benjamins,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah Brown-Schmidt</author>
<author>Michael K Tanenhaus</author>
</authors>
<title>Referential domains and the interpretation of referring expressions in interactive conversation.</title>
<date>2003</date>
<booktitle>In Proc. of Diabruck 2003, Seventh Workshop on the Semantics and Pragmatics of Dialogue (SEMDIAL).</booktitle>
<marker>Brown-Schmidt, Tanenhaus, 2003</marker>
<rawString>Sarah Brown-Schmidt &amp; Michael K. Tanenhaus (2003). Referential domains and the interpretation of referring expressions in interactive conversation. In Proc. of Diabruck 2003, Seventh Workshop on the Semantics and Pragmatics of Dialogue (SEMDIAL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johno Bryant</author>
</authors>
<title>Constructional analysis. Master&apos;s thesis,</title>
<date>2003</date>
<institution>University of California at Berkeley,</institution>
<contexts>
<context position="2532" citStr="Bryant, 2003" startWordPosition="378" endWordPosition="379"> simple. The attempts in that direction are often limited to simple phenomena, because all linguistic formalisms rely on principles slightly or totally different from those of cognitive architectures. The definitive solution to this problem is probably still far from reach, but nevertheless, I think that the maturity of cognitive linguistics and the consequent emergence of language analyzers connected to cognitive architectures is an excellent direction toward a unified theory mixing linguistic and psychological models. The Embodied Construction Grammar or ECG (Bergen, 2003) and its analyzer (Bryant, 2003) are a good example of such an effort, even though it does not go beyond the linguistic layer since mental simulation is left to a mental simulation module based on the notion of x-schema (Narayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural La</context>
</contexts>
<marker>Bryant, 2003</marker>
<rawString>Johno Bryant (2003). Constructional analysis. Master&apos;s thesis, University of California at Berkeley,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Emond</author>
</authors>
<title>Modeling natural language comprehension and anaphora resolution with ACT-R.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourth Annual ACT-R Workshop</booktitle>
<pages>1--8</pages>
<institution>Department of Psychology, Carnegie Mellon University.</institution>
<location>Pittsburgh, PA:</location>
<contexts>
<context position="7694" citStr="Emond, 1997" startWordPosition="1213" endWordPosition="1214"> experiments. Cognitive models like production systems being Turing-equivalent, they typically do not lack of any expressiveness, meaning that anything one can describe with any linguistic representation could be implemented within a cognitive model (hopefully, since linguistic competence is part of the cognitive competence). 50 However, to my knowledge, no attempt to try describing a linguistic competence within a cognitive model has gone a long way. Existing researches on that topic have focused on very narrow problems, and what is more important, have been tightened to very small lexicons (Emond, 1997; Ball, 2003; Fowles-Winkler and Michaelis, 2005). My analysis of this problem is that production systems are too permissive to allow a human to describe a grammar with a reasonable effort. More specifically, all generalization links that exist between grammar rules should be encoded in some explicit way in a production system. Furthermore, linguistic formalisms are designed in such way to only express all possible human languages. In other words, a linguistic formalism is successful when it is flexible enough to describe all linguistic phenomena, while being human-readable enough to allow for</context>
</contexts>
<marker>Emond, 1997</marker>
<rawString>Bruno Emond (1997). Modeling natural language comprehension and anaphora resolution with ACT-R. In Proceedings of the Fourth Annual ACT-R Workshop (pp. 1-8). Pittsburgh, PA: Department of Psychology, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fauconnier</author>
</authors>
<title>Mental Spaces: Aspects of Meaning Construction in Natural Language.</title>
<date>1985</date>
<publisher>MIT Press/Bradford,</publisher>
<location>Cambridge, Mass. and London.</location>
<contexts>
<context position="19044" citStr="Fauconnier, 1985" startWordPosition="2995" endWordPosition="2996">ma. For instance, one can define a precedence relation in a linear context. 53 ■ operations are functions that associate a position from one or more positions. For instance, a union of segments is an operation. Terminologically, an instance of schema (or context) located in a context, that is, an instance with a place, will be called a situated instance, whereas an instance of schema (or context) simply connected to another instance by a role will just be called a role instance. The only explicit equivalent to contexts in ECG is the notion of space, which describes Fauconnier&apos;s mental spaces (Fauconnier, 1985). Implicit contexts are however used in Construction Grammar: the form pole, which stores instances of schemas representing linguistic data in a linear space, and the unstructured meaning pole. s-construction &lt;s-construction-id&gt; inherits &lt;s-construction-id0, É, s-construction-idn&gt; roles // idem schema&apos;s roles constructional &lt;local-s-constr-id&gt;: &lt;s-construction-id&gt; constituents &lt;local-ctx-id&gt;: &lt;context-id&gt;[@&lt;local-ctx-id&gt;]/I/O1IO &lt;local-constit-id&gt;: &lt;schema-id&gt;[@&lt;local-ctx-id&gt;]/I|O|IO constraints // idem schemas constraints, plus : // a role-id can be marked as muted: ?&lt;role-id&gt; // a place-id i</context>
</contexts>
<marker>Fauconnier, 1985</marker>
<rawString>Fauconnier, G. (1985). Mental Spaces: Aspects of Meaning Construction in Natural Language. MIT Press/Bradford, Cambridge, Mass. and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>Frame Semantics.</title>
<date>1982</date>
<booktitle>Linguistic in the Morning Calm,</booktitle>
<pages>111--38</pages>
<editor>In L. S. of Korea, editor,</editor>
<publisher>Hanshin, Seoul.</publisher>
<contexts>
<context position="2984" citStr="Fillmore, 1982" startWordPosition="452" endWordPosition="453">rection toward a unified theory mixing linguistic and psychological models. The Embodied Construction Grammar or ECG (Bergen, 2003) and its analyzer (Bryant, 2003) are a good example of such an effort, even though it does not go beyond the linguistic layer since mental simulation is left to a mental simulation module based on the notion of x-schema (Narayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics tive architecture is, obviously, the family of Production Systems (Newell, 1990; Anderson, 1993). Moreover, since many pragmatical models rely on topologically structured representation, I introduce the notion of context, a notion that has never been adapted to these theories in order to organize data in “storages” structured in dissimilar </context>
</contexts>
<marker>Fillmore, 1982</marker>
<rawString>Fillmore, C. J. (1982). Frame Semantics. In L. S. of Korea, editor, Linguistic in the Morning Calm, pages 111--38. Hanshin, Seoul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>The Mechanisms of Construction Grammar.</title>
<date>1988</date>
<journal>Berkeley Linguistics Society,</journal>
<volume>14</volume>
<pages>35--55</pages>
<contexts>
<context position="2936" citStr="Fillmore, 1988" startWordPosition="445" endWordPosition="446">d to cognitive architectures is an excellent direction toward a unified theory mixing linguistic and psychological models. The Embodied Construction Grammar or ECG (Bergen, 2003) and its analyzer (Bryant, 2003) are a good example of such an effort, even though it does not go beyond the linguistic layer since mental simulation is left to a mental simulation module based on the notion of x-schema (Narayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics tive architecture is, obviously, the family of Production Systems (Newell, 1990; Anderson, 1993). Moreover, since many pragmatical models rely on topologically structured representation, I introduce the notion of context, a notion that has never been adapted to these theories in order to organ</context>
</contexts>
<marker>Fillmore, 1988</marker>
<rawString>Fillmore, C. J. (1988). The Mechanisms of Construction Grammar. Berkeley Linguistics Society, 14:0 35—55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna M Fowles-Winkler</author>
<author>Laura Michaelis</author>
</authors>
<title>An ACT-R model of sentence sorting with argument structure constuctions.</title>
<date>2005</date>
<booktitle>In the Proceedings of the Linguistic Society of America Annual Meeting,</booktitle>
<location>Oakland, CA.</location>
<contexts>
<context position="7743" citStr="Fowles-Winkler and Michaelis, 2005" startWordPosition="1217" endWordPosition="1220">odels like production systems being Turing-equivalent, they typically do not lack of any expressiveness, meaning that anything one can describe with any linguistic representation could be implemented within a cognitive model (hopefully, since linguistic competence is part of the cognitive competence). 50 However, to my knowledge, no attempt to try describing a linguistic competence within a cognitive model has gone a long way. Existing researches on that topic have focused on very narrow problems, and what is more important, have been tightened to very small lexicons (Emond, 1997; Ball, 2003; Fowles-Winkler and Michaelis, 2005). My analysis of this problem is that production systems are too permissive to allow a human to describe a grammar with a reasonable effort. More specifically, all generalization links that exist between grammar rules should be encoded in some explicit way in a production system. Furthermore, linguistic formalisms are designed in such way to only express all possible human languages. In other words, a linguistic formalism is successful when it is flexible enough to describe all linguistic phenomena, while being human-readable enough to allow for a large-scale grammar development. As a conseque</context>
</contexts>
<marker>Fowles-Winkler, Michaelis, 2005</marker>
<rawString>Anna M. Fowles-Winkler &amp; Laura Michaelis (2005) An ACT-R model of sentence sorting with argument structure constuctions. In the Proceedings of the Linguistic Society of America Annual Meeting, January 7, 2005, Oakland, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kay</author>
</authors>
<title>An informal sketch of a formal architecture for construction grammar.</title>
<date>2002</date>
<journal>Grammars,</journal>
<volume>5</volume>
<pages>19</pages>
<contexts>
<context position="2947" citStr="Kay 2002" startWordPosition="447" endWordPosition="448">rchitectures is an excellent direction toward a unified theory mixing linguistic and psychological models. The Embodied Construction Grammar or ECG (Bergen, 2003) and its analyzer (Bryant, 2003) are a good example of such an effort, even though it does not go beyond the linguistic layer since mental simulation is left to a mental simulation module based on the notion of x-schema (Narayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics tive architecture is, obviously, the family of Production Systems (Newell, 1990; Anderson, 1993). Moreover, since many pragmatical models rely on topologically structured representation, I introduce the notion of context, a notion that has never been adapted to these theories in order to organize data in</context>
</contexts>
<marker>Kay, 2002</marker>
<rawString>Kay, P. (2002). An informal sketch of a formal architecture for construction grammar. Grammars, 5:0 1— 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Langacker</author>
</authors>
<date>1987</date>
<journal>Foundations of Cognitive Grammar,</journal>
<volume>1</volume>
<publisher>Stanford University Press.</publisher>
<marker>Langacker, 1987</marker>
<rawString>Langacker, R. W. (1987). Foundations of Cognitive Grammar, volume 1. Stanford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liskov</author>
</authors>
<title>Data abstraction and hierarchy.</title>
<date>1988</date>
<journal>SIGPLAN Notices,</journal>
<volume>230</volume>
<issue>5</issue>
<contexts>
<context position="14957" citStr="Liskov, 1988" startWordPosition="2323" endWordPosition="2324">rarchy. In order to avoid ambiguity in role access, inherited roles must be accessed through an inheritance path. For instance, accessing the role color in a schema Square, if the hierarchy is Figure4Rectangle4Square, and where the color role is declared in the Figure schema, would be realized through this kind of path: Rectangle*Figure*color. 52 Inheritance also means that an instance of schema S can be unified with a role whose type is R if S == R or if R is one of the parents of S. One problem with this approach of inheritance is that, in order to fulfill the Liskov substitution principle (Liskov, 1988), it is sometimes necessary to use unnatural type hierarchies (stating that Square doesn’t inherit from Rectangle, for instance). I am very mindful about this problem, since such a discrepancy is quite tedious for a model that aims to approximate the human way of processing information, but this problem is out of the scope of this paper1. Constraints A schema declaration contains a set of constraints that must be satisfied in order for an instance of this schema to be considered valid. Constraints are specified with six basic forms: ■ Type constraints on roles. ■ Boolean operation (OR, NOT, NA</context>
</contexts>
<marker>Liskov, 1988</marker>
<rawString>Liskov, B. (1988). Data abstraction and hierarchy. SIGPLAN Notices, 230 (5), 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
</authors>
<title>Unified Theories of Cognition.</title>
<date>1990</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3321" citStr="Newell, 1990" startWordPosition="503" endWordPosition="504">f x-schema (Narayanan, 2001). Consequently, I try to propose a model that conciliates a linguistic theory with a cognitive architecture. The choice of the linguistic theory naturally goes to Construction Grammar (Fillmore, 1988; Kay 2002) and Frame Semantics (Fillmore, 1982), due to the parallel one can draw between a production rule and a construction, and the cogniProceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 49–56, New York City, June 2006. c�2006 Association for Computational Linguistics tive architecture is, obviously, the family of Production Systems (Newell, 1990; Anderson, 1993). Moreover, since many pragmatical models rely on topologically structured representation, I introduce the notion of context, a notion that has never been adapted to these theories in order to organize data in “storages” structured in dissimilar ways. 1.1 Typical Problem Consider a situation where a user can command a software to manipulate some very simple objects (colored geometrical objects of various sizes). The user may say (a) “Put the small red square on the left”, (b) “Remove the small red square on the left” or (c) “Move the small red square on the left”. First, these</context>
</contexts>
<marker>Newell, 1990</marker>
<rawString>Newell, A. (1990). Unified Theories of Cognition. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pitel</author>
<author>J-P Sansonnet</author>
</authors>
<title>Unified Representation of Typological, Absolute and Relational Predicates.</title>
<date>2003</date>
<booktitle>In Proceedings of PACLING’03. Avail. on first author web</booktitle>
<pages>page.</pages>
<marker>Pitel, Sansonnet, 2003</marker>
<rawString>Pitel, G. and Sansonnet, J.-P. (2003) Unified Representation of Typological, Absolute and Relational Predicates. In Proceedings of PACLING’03. Avail. on first author web page.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pitel</author>
</authors>
<title>MICO: la notion de construction situ&amp;e pour un modele d’interpr6tation et de resolution de la r6erence pour le dialogue finalis&amp;.</title>
<date>2004</date>
<tech>PhD Thesis,</tech>
<institution>Universit&amp; Paris XI.</institution>
<contexts>
<context position="10666" citStr="Pitel, 2004" startWordPosition="1677" endWordPosition="1678">struction being one possible interpretation) with the source of the Source-Path-Goal. The CxImperative encapsulates the predicate in a Request schema. Another construction can connect the goal of the SourcePath-Goal with the Spatial-PP produced from “on the left”, with the predicate modified by the construction that took its RefExp from “the small square”. At this point, the “mental simulation” required Figure 2: Mental simulation of the reference resolution to resolve the referents can start. This step is illustrated in a very simplified way in Figure 2. The complete process is described in (Pitel, 2004; Pitel CxMove Move the small square on the left CauseMotion FA SPG Ref-Exp CxRefExpSp Ref-Exp CxSpatialPP Spatial-PP Resolution Context 2 Visual Context Resolution Context 1 51 &amp; Sansonnet, 2003) and processes potential referents through several sorting steps, one for each referential predicate (here: square and small in Resolution Context 1 from the two-arguments move interpretation; square, small and on the left in Resolution Context 2 from the other one). The process is described with the kind of constructions defined by the SCIM. 2 Basic Notions of the SCIM The Situated Constructional Int</context>
<context position="16402" citStr="Pitel (2004)" startWordPosition="2564" endWordPosition="2565">(H), specifies that both sides of the constraint must unify, that is, all roles’ values must be compatible with each other. ■ An equality constraint (=) that constrains two roles to refer to the same instance. ■ A boolean predicate constraint can be asserted between any number of roles. Another kind of constraint, on the places occupied by instances of schema in context, will be explained in the section about s-constructions, as will 1 We consider that this problem could be solved by the approach called “Points of View Theory” (which is not related to inter-person points of view), proposed by Pitel (2004). In this theory, there is no type hierarchy, and the ability to substitute a representation by another is described by rules that can take the dynamic context into account. In this approach, types do not represent concepts, but points of view on perceptions (in the wide meaning), and transition from one point of view to the other is context-dependent. the role of interrogation marks in the schema declaration formalism. 2.2 Contexts A context declaration is a description of a container that can hold instances of schemas. In other words, it describes a space (including the topology part that ca</context>
</contexts>
<marker>Pitel, 2004</marker>
<rawString>Pitel, G. (2004). MICO: la notion de construction situ&amp;e pour un modele d’interpr6tation et de resolution de la r6erence pour le dialogue finalis&amp;. PhD Thesis, Universit&amp; Paris XI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reboul</author>
</authors>
<title>Reference, agreement, evolving reference and the theory of mental representation.</title>
<date>1999</date>
<journal>In</journal>
<pages>601--616</pages>
<publisher>Unipress,</publisher>
<location>Padova.</location>
<contexts>
<context position="1749" citStr="Reboul, 1999" startWordPosition="266" endWordPosition="267">ith interpretation in a context. In domains such as practical dialogue or embodied understanding, there would be a real gain in dealing with environment data the same way one deals with linguistic data. These kinds of systems currently need ad hoc heuristics or representations. These heuristics 49 are implemented in modules that are often impossible to reuse for another task than the one they were developed for. This point particularly concerns phenomena that lay at the interface of linguistics and general cognition, such as vagueness (Ballweg, 1983), reference resolution (BrownSchmidt, 2003; Reboul, 1999), or modeling of cognitive representations (Langacker, 1983; Talmy, 1988). Similarly, accounting for linguistic phenomena in a psychologically motivated model is far from simple. The attempts in that direction are often limited to simple phenomena, because all linguistic formalisms rely on principles slightly or totally different from those of cognitive architectures. The definitive solution to this problem is probably still far from reach, but nevertheless, I think that the maturity of cognitive linguistics and the consequent emergence of language analyzers connected to cognitive architecture</context>
</contexts>
<marker>Reboul, 1999</marker>
<rawString>Reboul, A. (1999). Reference, agreement, evolving reference and the theory of mental representation. In M. Coene, W. D. Mulder, P. Dendale, and Y. D&apos;Hulst, Eds. Studia Linguisticae in honorem Lilianae Tasmowski, pages 601—616. Unipress, Padova.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Talmy</author>
</authors>
<title>Force dynamics in language and cognition.</title>
<date>1988</date>
<journal>Cognitive Science,</journal>
<volume>12</volume>
<pages>49--100</pages>
<contexts>
<context position="1822" citStr="Talmy, 1988" startWordPosition="275" endWordPosition="276">embodied understanding, there would be a real gain in dealing with environment data the same way one deals with linguistic data. These kinds of systems currently need ad hoc heuristics or representations. These heuristics 49 are implemented in modules that are often impossible to reuse for another task than the one they were developed for. This point particularly concerns phenomena that lay at the interface of linguistics and general cognition, such as vagueness (Ballweg, 1983), reference resolution (BrownSchmidt, 2003; Reboul, 1999), or modeling of cognitive representations (Langacker, 1983; Talmy, 1988). Similarly, accounting for linguistic phenomena in a psychologically motivated model is far from simple. The attempts in that direction are often limited to simple phenomena, because all linguistic formalisms rely on principles slightly or totally different from those of cognitive architectures. The definitive solution to this problem is probably still far from reach, but nevertheless, I think that the maturity of cognitive linguistics and the consequent emergence of language analyzers connected to cognitive architectures is an excellent direction toward a unified theory mixing linguistic and</context>
</contexts>
<marker>Talmy, 1988</marker>
<rawString>Talmy, L. (1988). Force dynamics in language and cognition. Cognitive Science, 12:0 49—100.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>