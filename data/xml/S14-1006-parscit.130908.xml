<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014986">
<title confidence="0.98017">
Exploring ESA to Improve Word Relatedness
</title>
<author confidence="0.959897">
Nitish Aggarwal Kartik Asooja Paul Buitelaar
</author>
<affiliation confidence="0.984906">
Insight Centre for Data Analytics
National University of Ireland
</affiliation>
<address confidence="0.559392">
Galway, Ireland
</address>
<email confidence="0.995673">
firstname.lastname@deri.org
</email>
<sectionHeader confidence="0.995685" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992281904761905">
Explicit Semantic Analysis (ESA) is an ap-
proach to calculate the semantic relatedness
between two words or natural language texts
with the help of concepts grounded in human
cognition. ESA usage has received much at-
tention in the field of natural language pro-
cessing, information retrieval and text analy-
sis, however, performance of the approach de-
pends on several parameters that are included
in the model, and also on the text data type
used for evaluation. In this paper, we investi-
gate the behavior of using different number of
Wikipedia articles in building ESA model, for
calculating the semantic relatedness for differ-
ent types of text pairs: word-word, phrase-
phrase and document-document. With our
findings, we further propose an approach to
improve the ESA semantic relatedness scores
for words by enriching the words with their
explicit context such as synonyms, glosses and
Wikipedia definitions.
</bodyText>
<sectionHeader confidence="0.999113" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9953389">
Explicit Semantic Analysis (ESA) is a distributional
semantic model (Harris, 1954) that computes the
relatedness scores between natural language texts
by using high dimensional vectors. ESA builds
the high dimensional vectors by using the explicit
concepts defined in human cognition. Gabrilovich
and Markovitch (2007) introduced the ESA model
in which Wikipedia and Open Directory Project1
was used to obtain the explicit concepts. ESA con-
siders every Wikipedia article as a unique explicit
</bodyText>
<footnote confidence="0.979135">
1http://www.dmoz.org
</footnote>
<bodyText confidence="0.99363146875">
topic. It also assumes that the articles are topically
orthogonal. However, recent work (Gottron et
al., 2011) has shown that by using the documents
from Reuters corpus instead of Wikipedia articles
can also achieve comparable results. ESA model
includes various parameters (Sorg and Cimiano,
2010) that play important roles on its performance.
Therefore, the model requires further investigation
in order to better tune the parameters.
ESA model has been adapted very quickly in
different fields related to text analysis, due to the
simplicity of its implementation and the availability
of Wikipedia corpus. Gabrilovich and Markovitch
(2007) evaluated the ESA against word relatedness
dataset WN353 (Finkelstein et al., 2001) and doc-
ument relatedness dataset Lee50 (Lee et al., 2005)
by using all the articles from Wikipedia snapshot of
11 Nov, 2005. However, the results reported using
different implementations (Polajnar et al., 2013)
(Hassan and Mihalcea, 2011) of ESA on same
datasets (WN353 and Lee50) vary a lot, due the
specificity of ESA implementation. For instance,
Hassan and Mihalcea (2011) found a significant
difference between the scores obtained from their
own implementation and the scores reported in the
original article (Gabrilovich and Markovitch, 2007).
In this paper, first, we investigate the behavior
of ESA model in calculating the semantic related-
ness for different types of text pairs: word-word,
phrase-phrase and document-document by using
different number of Wikipedia articles for building
the model. Second, we propose an approach
</bodyText>
<page confidence="0.98813">
51
</page>
<note confidence="0.760861">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 51–56,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999135333333333">
for context enrichment of words to improve the
performance of ESA on word relatedness task.
al. (2011) investigated the ESA performance for
document relatedness and showed that ESA scores
are not tightly dependent on the explicit concept
spaces.
</bodyText>
<sectionHeader confidence="0.470589" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.998892547619048">
The ESA model can be described as a method of
obtaining the relatedness score between two texts by
quantifying the distance between two high dimen-
sional vectors. Every explicit concept represents a
dimension of the ESA vector, and the associativity
weight of a given word with the explicit concept
can be taken as magnitude of the corresponding
dimension. For instance, there is a word t, ESA
builds a vector v, where v = EZ_&apos;0 az * cz and cz is
ith concept from the explicit concept space, and az
is the associativity weight of word t with the concept
cz. Here, N represents the total number of concepts.
In our implementation, we build ESA model by
using Wikipedia articles as explicit concepts, and
take the TFIDF weights as associativity strength.
Similarly, ESA builds the vector for natural lan-
guage text by considering it as a bag of words. Let
T = {t1, t2, t3...t�}, where T is a natural language
text that has n words. ESA generates the vector
V, where V = Etk&apos;T vk and v = EZ_&apos;0 az * cz. vk
represents the ESA vector of a individual words as
explained above. The relatedness score between two
natural language texts is calculated by computing
cosine product of their corresponding ESA vectors.
In recent years, some extensions (Polajnar et
al., 2013) (Hassan and Mihalcea, 2011) (Scholl et
al., 2010) have been proposed to improve the ESA
performance, however, they have not discussed the
consistency in the performance of ESA. Polajnar
et al. (2013) used only 10,000 Wikipedia articles
as the concept space, and got significantly different
results on the previously evaluated datasets. Hassan
and Mihalcea (2011) have not discussed the ESA
implementation in detail but obtained significantly
different scores. Although, these proposed exten-
sions got different baseline ESA scores but they
improve the relatedness scores with their additions.
Polajnar et al. (2013) used the concept-concept
correlation to improve the ESA model. Hassan and
Mihalcea (2011) proposed a model similar to ESA,
which builds the high dimensional vector of salient
concepts rather than explicit concepts. Gortton et
</bodyText>
<figure confidence="0.757304416666667">
Minimum unique Total number of
words (K) articles (N)
100 438379
300 110900
500 46035
700 23608
900 13718
1100 8322
1300 5241
1500 3329
1700 2126
1900 1368
</figure>
<tableCaption confidence="0.9976105">
Table 1: The total number of retrieved articles for differ-
ent values of K
</tableCaption>
<sectionHeader confidence="0.909884" genericHeader="method">
3 Investigation of ESA model
</sectionHeader>
<bodyText confidence="0.999970518518519">
Although Gortton et al. (2011) has shown that ESA
performance on document pairs does not get af-
fected by using different number of Wikipedia ar-
ticles, we further examine it for word-word and
phrase-phrase pairs. We use three different datasets
WN353, SemEvalOnWN (Agirre et al., 2012) and
Lee50. WN353 contains 353 word pairs, SemEval-
OnWN consists of 750 short phrase/sentence pairs,
and Lee50 is a collection of 50 document pairs.
All these datasets contain relatedness scores given
by human annotators. We evaluate ESA model
on these three datasets against different number of
Wikipedia articles. In order to select different num-
ber of Wikipedia articles, we sort them according to
the total number of unique words appearing in each
article. We select N articles, where N is total num-
ber of articles which have at least K unique words.
Table 1 shows the total number of retrieved articles
for different values of K. We build 20 different ESA
models with the different values of N retrieved by
varying K from 100 to 2000 with an interval of 100.
Figure 1 illustrates Spearman’s rank correlation of
all the three types of text pairs on Y-axis while X-
axis shows the different values of N which are taken
to build the model. It shows that ESA model gener-
ates very consistent results for phrase pairs similar
to the one reported in (Aggarwal et al., 2012), how-
</bodyText>
<page confidence="0.997188">
52
</page>
<sectionHeader confidence="0.993673" genericHeader="method">
4 Context Enrichment
</sectionHeader>
<bodyText confidence="0.999887285714286">
Context enrichment is performed by concatenating
the context defining text to the given word before
building the ESA vector. Therefore, instead of build-
ing the ESA vector of a word, the vector is built for
the short text that is obtained after concatenating the
related context. This is similar to classical query ex-
pansion task (Aggarwal and Buitelaar, 2012; Pan-
tel and Fuxman, 2011), where related concepts are
concatenated with a query to improve the informa-
tion retrieval performance. We propose three differ-
ent methods to obtain related context: 1) WordNet-
based Context Enrichment 2) Wikipedia-based Con-
text Enrichment, and 3) WikiDefinition-based Con-
text Enrichment.
</bodyText>
<subsectionHeader confidence="0.594174">
4.1 WordNet-based Context Enrichment
</subsectionHeader>
<figureCaption confidence="0.999136">
Figure 1: ESA performance on different types of text
pairs by varying the total number of articles
</figureCaption>
<bodyText confidence="0.999934452380952">
ever, the correlation scores decreases monotonously
in the case of word pairs as the number of articles
goes down. In the case of document pairs, ESA pro-
duces similar results until the value of N is chosen
according to K = 1000, but after that, it decreases
quickly because the number of articles becomes too
low for making a good enough ESA model. All this
indicates that word-word relatedness scores have a
strong impact of changing the N in comparison of
document-document or phrase-phrase text pairs. An
explanation to this is that the size of the ESA vec-
tor for a word solely depends upon the popularity
of the given word, however, in the case of text, the
vector size depends on the popularity summation of
all the words appearing in the given text. It suggests
that the word relatedness problem can be reduced to
short text relatedness by adding some related con-
text with the given word. Therefore, to improve
the ESA performance for word relatedness, we pro-
pose an approach for context enrichment of words.
We perform context enrichment by concatenating re-
lated context with the given word and use this con-
text to build the ESA vector, which transforms the
word relatedness problem to phrase relatedness.
WordNet-based context enrichment uses the Word-
Net synonyms to obtain the context, and concate-
nates them into the given word to build the ESA vec-
tor. However, WordNet may contain more than one
synset for a word, where each synset represents a
different semantic sense. Therefore, we obtain more
than one contexts for a given word, by concatenat-
ing the different synsets. Further, we calculate ESA
score of every context of a given word against all the
contexts of the other word which is being compared,
and consider the highest score as the final related-
ness score. For instance, there is a given word pair
“train and car”, car has 8 different synsets that build
8 different contexts, and train has 6 different synsets
that build 6 different contexts. We calculate the ESA
score of these 8 contexts of car to the 6 contexts of
train, and finally select the highest obtained score
from all of the 24 calculated scores.
</bodyText>
<subsectionHeader confidence="0.949778">
4.2 Wikipedia-based Context Enrichment
</subsectionHeader>
<bodyText confidence="0.9996941">
In this method, the context is defined by the word
usage in Wikipedia articles. We retrieve top 5
Wikipedia articles by querying the articles’ content,
and concatenate the short abstracts of the retrieved
articles to the given word to build the ESA vector.
Short abstract is the first two sentences of Wikipedia
article and has a maximum limit of 500 characters.
In order to retrieve the top 5 articles from Wikipedia
for a given word, we build an index of all Wikipedia
articles and use TF-IDF scores. We further explain
</bodyText>
<page confidence="0.996325">
53
</page>
<bodyText confidence="0.632396">
our implementation in Section 5.1.
</bodyText>
<subsectionHeader confidence="0.989829">
4.3 WikiDefinition-based Context Enrichment
</subsectionHeader>
<bodyText confidence="0.999901444444445">
This method uses the definition of a given word from
Wikipedia. To obtain a definition from Wikipedia,
we first try to find a Wikipedia article on the given
word by matching the Wikipedia title. As definition,
we take the short abstract of the Wikipedia article.
For instance, for a given word “train”, we take the
Wikipedia article with the title “Train”2. If there is
no such Wikipedia article, then we use the previous
method “Wikipedia-based Context Enrichment” to
get the context defining text for the given word. In
contrary to the previous method for defining context,
here we first try to get a more precise context as it
comes from the Wikipedia article on that word only.
After obtaining the definition, we concatenate it to
the given word to build the ESA vector. At the time
of experimentation, we were able to find 339 words
appearing as Wikipedia articles out of 437 unique
words in the WN353 dataset.
</bodyText>
<figureCaption confidence="0.98269">
Figure 2: Effect of different types of context enrichments
on WN353 gold standard
</figureCaption>
<footnote confidence="0.702681">
2http://en.wikipedia.org/wiki/Train
</footnote>
<sectionHeader confidence="0.996791" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<subsectionHeader confidence="0.997715">
5.1 ESA implementation
</subsectionHeader>
<bodyText confidence="0.999887888888889">
In this section, we describe the implementation of
ESA and the parameters used to build the model.
We build an index over all Wikipedia articles from
the pre-processed Wikipedia dump from November
11, 2005 (Gabrilovich, 2006). We use Lucene3 to
build the index and retrieve the articles using TF-
IDF scores. As described in section 3, we build 20
different indices with different values of total num-
ber of articles (N).
</bodyText>
<subsectionHeader confidence="0.987309">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999953612903226">
To evaluate the effect of the aforementioned
approaches for context enrichment, we compare
the results obtained by them against the results
generated by ESA model as a baseline. We cal-
culated the scores on WN353 word pairs dataset
by using ESA, WordNet-based Context Enrich-
ment (ESA CEWN), Wikipedia-based Context
Enrichment (ESA CEWiki) and WikiDefition-based
Context Enrichment (ESA CEWikiDef). Further,
we examine the performance of context enrichment
approaches by reducing the total number of articles
taken to build the model. Figure 2 shows that the
proposed methods of context enrichment signifi-
cantly improve over the ESA scores for different
values of N.
Table 2 reports the results obtained by using
different context enrichments and ESA model.
It shows Spearman’s rank correlation on four
different values of N. All the proposed con-
text enrichment methods improve over the ESA
baseline scores. Context enrichments based on
Wikipedia outperforms the other methods, and
ESA CEWikiDef significantly improves over the
ESA baseline. Moreover, given a very less number
of Wikipedia articles used for building the model,
ESA CEWikiDef obtains a correlation score which
is considerably higher than the one obtained by
ESA baseline. ESA CEWN and ESA CEWiki can
include some unrelated context as they do not care
about the semantic sense of the given word, for
instance, for a given word “car”, ESA CEWiki
</bodyText>
<footnote confidence="0.96781">
3https://lucene.apache.org/
</footnote>
<page confidence="0.994556">
54
</page>
<table confidence="0.9998798">
K Total articles (N) ESA ESA CEWN ESA CEWiki ESA CEWikiDef
100 438,379 0.711 0.692 0.724 0.741
200 221,572 0.721 0.707 0.726 0.743
500 46,035 0.673 0.670 0.679 0.698
1000 10,647 0.563 0.593 0.598 0.614
</table>
<tableCaption confidence="0.999545">
Table 2: Spearman rank correlation scores on WN353 gold standard
</tableCaption>
<bodyText confidence="0.999887">
includes the context about the word ”car” at surface
level rather than at the semantic level. However,
ESA CEWikiDef only includes the definition if it
does not refer to more than one semantic sense,
therefore, ESA CEWikiDef outperforms all other
types of context enrichment.
We achieved best results in all the cases by tak-
ing all the articles which has a minimum of 200
unique words (K=200). This indicates that further
increasing the value of K considerably decreases
the value of N, consequently, it harms the overall
distributional knowledge of the language, which is
the core of ESA model. However, decreasing the
value of K introduces very small Wikipedia articles
or stubs, which do not provide enough content on a
subject.
</bodyText>
<sectionHeader confidence="0.999232" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999386">
In this paper, we investigated the ESA performance
for three different types of text pairs: word-word,
phrase-phrase and document-document. We showed
that ESA scores varies significantly for word re-
latedness measure with the change in the number
(N) and length (≈K which is the number of unique
words) of the Wikipedia articles used for building
the model. Further, we proposed context enrichment
approaches for improving word relatedness compu-
tation by ESA. To this end, we presented three dif-
ferent approaches: 1) WordNet-based, 2) Wikipedia-
based, and 3) WikiDefinition-based, and we real-
ized that concatenating the context defining text im-
proves the ESA performance for word relatedness
task.
</bodyText>
<sectionHeader confidence="0.998294" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99881">
This work has been funded in part by a research
grant from Science Foundation Ireland (SFI) under
Grant Number SFI/12/RC/2289 (INSIGHT) and by
the EU FP7 program in the context of the project
LIDER (610782).
</bodyText>
<sectionHeader confidence="0.997526" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99683623255814">
Nitish Aggarwal and Paul Buitelaar. 2012. Query expan-
sion using wikipedia and dbpedia. In CLEF.
Nitish Aggarwal, Kartik Asooja, and Paul Buitelaar.
2012. DERI&amp;UPM: Pushing corpus based relatedness
to similarity: Shared task system description. In Pro-
ceedings of the First Joint Conference on Lexical and
Computational Semantics - Volume 1: Proceedings of
the Main Conference and the Shared Task, and Volume
2: Proceedings of the Sixth International Workshop on
Semantic Evaluation, SemEval ’12, pages 643–647,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Eneko Agirre, Mona Diab, Daniel Cer, and Aitor
Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot
on semantic textual similarity. In Proceedings of the
First Joint Conference on Lexical and Computational
Semantics-Volume 1: Proceedings of the main confer-
ence and the shared task, and Volume 2: Proceedings
of the Sixth International Workshop on Semantic Eval-
uation, pages 385–393. Association for Computational
Linguistics.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan
Ruppin. 2001. Placing search in context: The con-
cept revisited. In Proceedings of the 10th international
conference on World Wide Web, pages 406–414. ACM.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using wikipedia-based
explicit semantic analysis. In Proceedings of the
20th international joint conference on Artifical intel-
ligence, IJCAI’07, pages 1606–1611, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Evgeniy Gabrilovich. 2006. Feature generation for
textual information retrieval using world knowledge.
Ph.D. thesis, Technion - Israel Institute of Technology,
Haifa, Israel, December.
Thomas Gottron, Maik Anderka, and Benno Stein. 2011.
Insights into explicit semantic analysis. In Proceed-
ings of the 20th ACM international conference on In-
formation and knowledge management, pages 1961–
1964. ACM.
Zellig Harris. 1954. Distributional structure. In Word 10
(23), pages 146–162.
</reference>
<page confidence="0.978135">
55
</page>
<reference confidence="0.999486043478261">
Samer Hassan and Rada Mihalcea. 2011. Semantic re-
latedness using salient semantic analysis. In AAAI.
Michael David Lee, BM Pincombe, and Matthew Brian
Welsh. 2005. An empirical evaluation of models of
text document similarity. Cognitive Science.
Patrick Pantel and Ariel Fuxman. 2011. Jigs and lures:
Associating web queries with structured entities. In
ACL, pages 83–92.
Tamara Polajnar, Nitish Aggarwal, Kartik Asooja, and
Paul Buitelaar. 2013. Improving esa with docu-
ment similarity. In Advances in Information Retrieval,
pages 582–593. Springer.
Philipp Scholl, Doreen B¨ohnstedt, Renato Domfnguez
Garcfa, Christoph Rensing, and Ralf Steinmetz. 2010.
Extended explicit semantic analysis for calculating
semantic relatedness of web resources. In Sustain-
ing TEL: From Innovation to Learning and Practice,
pages 324–339. Springer.
Philipp Sorg and Philipp Cimiano. 2010. An experi-
mental comparison of explicit semantic analysis im-
plementations for cross-language retrieval. In Natural
Language Processing and Information Systems, pages
36–48. Springer.
</reference>
<page confidence="0.99842">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.575120">
<title confidence="0.99983">Exploring ESA to Improve Word Relatedness</title>
<author confidence="0.988066">Nitish Aggarwal Kartik Asooja Paul Buitelaar</author>
<affiliation confidence="0.9837665">Insight Centre for Data National University of</affiliation>
<address confidence="0.723628">Galway,</address>
<email confidence="0.999322">firstname.lastname@deri.org</email>
<abstract confidence="0.991868909090909">Explicit Semantic Analysis (ESA) is an approach to calculate the semantic relatedness between two words or natural language texts with the help of concepts grounded in human cognition. ESA usage has received much attention in the field of natural language processing, information retrieval and text analysis, however, performance of the approach depends on several parameters that are included in the model, and also on the text data type used for evaluation. In this paper, we investigate the behavior of using different number of Wikipedia articles in building ESA model, for calculating the semantic relatedness for different types of text pairs: word-word, phrasephrase and document-document. With our findings, we further propose an approach to improve the ESA semantic relatedness scores for words by enriching the words with their explicit context such as synonyms, glosses and Wikipedia definitions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nitish Aggarwal</author>
<author>Paul Buitelaar</author>
</authors>
<title>Query expansion using wikipedia and dbpedia.</title>
<date>2012</date>
<booktitle>In CLEF.</booktitle>
<contexts>
<context position="7711" citStr="Aggarwal and Buitelaar, 2012" startWordPosition="1227" endWordPosition="1230">e types of text pairs on Y-axis while Xaxis shows the different values of N which are taken to build the model. It shows that ESA model generates very consistent results for phrase pairs similar to the one reported in (Aggarwal et al., 2012), how52 4 Context Enrichment Context enrichment is performed by concatenating the context defining text to the given word before building the ESA vector. Therefore, instead of building the ESA vector of a word, the vector is built for the short text that is obtained after concatenating the related context. This is similar to classical query expansion task (Aggarwal and Buitelaar, 2012; Pantel and Fuxman, 2011), where related concepts are concatenated with a query to improve the information retrieval performance. We propose three different methods to obtain related context: 1) WordNetbased Context Enrichment 2) Wikipedia-based Context Enrichment, and 3) WikiDefinition-based Context Enrichment. 4.1 WordNet-based Context Enrichment Figure 1: ESA performance on different types of text pairs by varying the total number of articles ever, the correlation scores decreases monotonously in the case of word pairs as the number of articles goes down. In the case of document pairs, ESA</context>
</contexts>
<marker>Aggarwal, Buitelaar, 2012</marker>
<rawString>Nitish Aggarwal and Paul Buitelaar. 2012. Query expansion using wikipedia and dbpedia. In CLEF.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nitish Aggarwal</author>
<author>Kartik Asooja</author>
<author>Paul Buitelaar</author>
</authors>
<title>DERI&amp;UPM: Pushing corpus based relatedness to similarity: Shared task system description.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, SemEval ’12,</booktitle>
<pages>643--647</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7324" citStr="Aggarwal et al., 2012" startWordPosition="1163" endWordPosition="1166">each article. We select N articles, where N is total number of articles which have at least K unique words. Table 1 shows the total number of retrieved articles for different values of K. We build 20 different ESA models with the different values of N retrieved by varying K from 100 to 2000 with an interval of 100. Figure 1 illustrates Spearman’s rank correlation of all the three types of text pairs on Y-axis while Xaxis shows the different values of N which are taken to build the model. It shows that ESA model generates very consistent results for phrase pairs similar to the one reported in (Aggarwal et al., 2012), how52 4 Context Enrichment Context enrichment is performed by concatenating the context defining text to the given word before building the ESA vector. Therefore, instead of building the ESA vector of a word, the vector is built for the short text that is obtained after concatenating the related context. This is similar to classical query expansion task (Aggarwal and Buitelaar, 2012; Pantel and Fuxman, 2011), where related concepts are concatenated with a query to improve the information retrieval performance. We propose three different methods to obtain related context: 1) WordNetbased Cont</context>
</contexts>
<marker>Aggarwal, Asooja, Buitelaar, 2012</marker>
<rawString>Nitish Aggarwal, Kartik Asooja, and Paul Buitelaar. 2012. DERI&amp;UPM: Pushing corpus based relatedness to similarity: Shared task system description. In Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, SemEval ’12, pages 643–647, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eneko Agirre</author>
<author>Mona Diab</author>
<author>Daniel Cer</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>Semeval-2012 task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation,</booktitle>
<pages>385--393</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6256" citStr="Agirre et al., 2012" startWordPosition="977" endWordPosition="980">nsional vector of salient concepts rather than explicit concepts. Gortton et Minimum unique Total number of words (K) articles (N) 100 438379 300 110900 500 46035 700 23608 900 13718 1100 8322 1300 5241 1500 3329 1700 2126 1900 1368 Table 1: The total number of retrieved articles for different values of K 3 Investigation of ESA model Although Gortton et al. (2011) has shown that ESA performance on document pairs does not get affected by using different number of Wikipedia articles, we further examine it for word-word and phrase-phrase pairs. We use three different datasets WN353, SemEvalOnWN (Agirre et al., 2012) and Lee50. WN353 contains 353 word pairs, SemEvalOnWN consists of 750 short phrase/sentence pairs, and Lee50 is a collection of 50 document pairs. All these datasets contain relatedness scores given by human annotators. We evaluate ESA model on these three datasets against different number of Wikipedia articles. In order to select different number of Wikipedia articles, we sort them according to the total number of unique words appearing in each article. We select N articles, where N is total number of articles which have at least K unique words. Table 1 shows the total number of retrieved ar</context>
</contexts>
<marker>Agirre, Diab, Cer, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Mona Diab, Daniel Cer, and Aitor Gonzalez-Agirre. 2012. Semeval-2012 task 6: A pilot on semantic textual similarity. In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, pages 385–393. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eytan Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th international conference on World Wide Web,</booktitle>
<pages>406--414</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2367" citStr="Finkelstein et al., 2001" startWordPosition="348" endWordPosition="351">l., 2011) has shown that by using the documents from Reuters corpus instead of Wikipedia articles can also achieve comparable results. ESA model includes various parameters (Sorg and Cimiano, 2010) that play important roles on its performance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different implementations (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) of ESA on same datasets (WN353 and Lee50) vary a lot, due the specificity of ESA implementation. For instance, Hassan and Mihalcea (2011) found a significant difference between the scores obtained from their own implementation and the scores reported in the original article (Gabrilovich and Markovitch, 2007). In this paper, first, we investigate the behavior</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2001. Placing search in context: The concept revisited. In Proceedings of the 10th international conference on World Wide Web, pages 406–414. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th international joint conference on Artifical intelligence, IJCAI’07,</booktitle>
<pages>1606--1611</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="1446" citStr="Gabrilovich and Markovitch (2007)" startWordPosition="211" endWordPosition="214">edness for different types of text pairs: word-word, phrasephrase and document-document. With our findings, we further propose an approach to improve the ESA semantic relatedness scores for words by enriching the words with their explicit context such as synonyms, glosses and Wikipedia definitions. 1 Introduction Explicit Semantic Analysis (ESA) is a distributional semantic model (Harris, 1954) that computes the relatedness scores between natural language texts by using high dimensional vectors. ESA builds the high dimensional vectors by using the explicit concepts defined in human cognition. Gabrilovich and Markovitch (2007) introduced the ESA model in which Wikipedia and Open Directory Project1 was used to obtain the explicit concepts. ESA considers every Wikipedia article as a unique explicit 1http://www.dmoz.org topic. It also assumes that the articles are topically orthogonal. However, recent work (Gottron et al., 2011) has shown that by using the documents from Reuters corpus instead of Wikipedia articles can also achieve comparable results. ESA model includes various parameters (Sorg and Cimiano, 2010) that play important roles on its performance. Therefore, the model requires further investigation in order</context>
<context position="2916" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="432" endWordPosition="435"> evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different implementations (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) of ESA on same datasets (WN353 and Lee50) vary a lot, due the specificity of ESA implementation. For instance, Hassan and Mihalcea (2011) found a significant difference between the scores obtained from their own implementation and the scores reported in the original article (Gabrilovich and Markovitch, 2007). In this paper, first, we investigate the behavior of ESA model in calculating the semantic relatedness for different types of text pairs: word-word, phrase-phrase and document-document by using different number of Wikipedia articles for building the model. Second, we propose an approach 51 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 51–56, Dublin, Ireland, August 23-24 2014. for context enrichment of words to improve the performance of ESA on word relatedness task. al. (2011) investigated the ESA performance for document relatedness and</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In Proceedings of the 20th international joint conference on Artifical intelligence, IJCAI’07, pages 1606–1611, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
</authors>
<title>Feature generation for textual information retrieval using world knowledge.</title>
<date>2006</date>
<booktitle>Ph.D. thesis, Technion - Israel Institute of Technology,</booktitle>
<location>Haifa, Israel,</location>
<contexts>
<context position="12231" citStr="Gabrilovich, 2006" startWordPosition="1982" endWordPosition="1983">nly. After obtaining the definition, we concatenate it to the given word to build the ESA vector. At the time of experimentation, we were able to find 339 words appearing as Wikipedia articles out of 437 unique words in the WN353 dataset. Figure 2: Effect of different types of context enrichments on WN353 gold standard 2http://en.wikipedia.org/wiki/Train 5 Experiment 5.1 ESA implementation In this section, we describe the implementation of ESA and the parameters used to build the model. We build an index over all Wikipedia articles from the pre-processed Wikipedia dump from November 11, 2005 (Gabrilovich, 2006). We use Lucene3 to build the index and retrieve the articles using TFIDF scores. As described in section 3, we build 20 different indices with different values of total number of articles (N). 5.2 Results and Discussion To evaluate the effect of the aforementioned approaches for context enrichment, we compare the results obtained by them against the results generated by ESA model as a baseline. We calculated the scores on WN353 word pairs dataset by using ESA, WordNet-based Context Enrichment (ESA CEWN), Wikipedia-based Context Enrichment (ESA CEWiki) and WikiDefition-based Context Enrichment</context>
</contexts>
<marker>Gabrilovich, 2006</marker>
<rawString>Evgeniy Gabrilovich. 2006. Feature generation for textual information retrieval using world knowledge. Ph.D. thesis, Technion - Israel Institute of Technology, Haifa, Israel, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Gottron</author>
<author>Maik Anderka</author>
<author>Benno Stein</author>
</authors>
<title>Insights into explicit semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>pages</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1751" citStr="Gottron et al., 2011" startWordPosition="257" endWordPosition="260">plicit Semantic Analysis (ESA) is a distributional semantic model (Harris, 1954) that computes the relatedness scores between natural language texts by using high dimensional vectors. ESA builds the high dimensional vectors by using the explicit concepts defined in human cognition. Gabrilovich and Markovitch (2007) introduced the ESA model in which Wikipedia and Open Directory Project1 was used to obtain the explicit concepts. ESA considers every Wikipedia article as a unique explicit 1http://www.dmoz.org topic. It also assumes that the articles are topically orthogonal. However, recent work (Gottron et al., 2011) has shown that by using the documents from Reuters corpus instead of Wikipedia articles can also achieve comparable results. ESA model includes various parameters (Sorg and Cimiano, 2010) that play important roles on its performance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelste</context>
</contexts>
<marker>Gottron, Anderka, Stein, 2011</marker>
<rawString>Thomas Gottron, Maik Anderka, and Benno Stein. 2011. Insights into explicit semantic analysis. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1961– 1964. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1954</date>
<journal>In Word</journal>
<volume>10</volume>
<issue>23</issue>
<pages>146--162</pages>
<contexts>
<context position="1210" citStr="Harris, 1954" startWordPosition="180" endWordPosition="181">d in the model, and also on the text data type used for evaluation. In this paper, we investigate the behavior of using different number of Wikipedia articles in building ESA model, for calculating the semantic relatedness for different types of text pairs: word-word, phrasephrase and document-document. With our findings, we further propose an approach to improve the ESA semantic relatedness scores for words by enriching the words with their explicit context such as synonyms, glosses and Wikipedia definitions. 1 Introduction Explicit Semantic Analysis (ESA) is a distributional semantic model (Harris, 1954) that computes the relatedness scores between natural language texts by using high dimensional vectors. ESA builds the high dimensional vectors by using the explicit concepts defined in human cognition. Gabrilovich and Markovitch (2007) introduced the ESA model in which Wikipedia and Open Directory Project1 was used to obtain the explicit concepts. ESA considers every Wikipedia article as a unique explicit 1http://www.dmoz.org topic. It also assumes that the articles are topically orthogonal. However, recent work (Gottron et al., 2011) has shown that by using the documents from Reuters corpus </context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. In Word 10 (23), pages 146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semantic relatedness using salient semantic analysis.</title>
<date>2011</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="2606" citStr="Hassan and Mihalcea, 2011" startWordPosition="385" endWordPosition="388">ance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different implementations (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) of ESA on same datasets (WN353 and Lee50) vary a lot, due the specificity of ESA implementation. For instance, Hassan and Mihalcea (2011) found a significant difference between the scores obtained from their own implementation and the scores reported in the original article (Gabrilovich and Markovitch, 2007). In this paper, first, we investigate the behavior of ESA model in calculating the semantic relatedness for different types of text pairs: word-word, phrase-phrase and document-document by using different number of Wikipedia articles for building the model. Second, we propose an approach </context>
<context position="4899" citStr="Hassan and Mihalcea, 2011" startWordPosition="762" endWordPosition="765">edia articles as explicit concepts, and take the TFIDF weights as associativity strength. Similarly, ESA builds the vector for natural language text by considering it as a bag of words. Let T = {t1, t2, t3...t�}, where T is a natural language text that has n words. ESA generates the vector V, where V = Etk&apos;T vk and v = EZ_&apos;0 az * cz. vk represents the ESA vector of a individual words as explained above. The relatedness score between two natural language texts is calculated by computing cosine product of their corresponding ESA vectors. In recent years, some extensions (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) (Scholl et al., 2010) have been proposed to improve the ESA performance, however, they have not discussed the consistency in the performance of ESA. Polajnar et al. (2013) used only 10,000 Wikipedia articles as the concept space, and got significantly different results on the previously evaluated datasets. Hassan and Mihalcea (2011) have not discussed the ESA implementation in detail but obtained significantly different scores. Although, these proposed extensions got different baseline ESA scores but they improve the relatedness scores with their additions. Polajnar et al. (2013) used the con</context>
</contexts>
<marker>Hassan, Mihalcea, 2011</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2011. Semantic relatedness using salient semantic analysis. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael David Lee</author>
<author>BM Pincombe</author>
<author>Matthew Brian Welsh</author>
</authors>
<title>An empirical evaluation of models of text document similarity.</title>
<date>2005</date>
<journal>Cognitive Science.</journal>
<contexts>
<context position="2425" citStr="Lee et al., 2005" startWordPosition="358" endWordPosition="361">s instead of Wikipedia articles can also achieve comparable results. ESA model includes various parameters (Sorg and Cimiano, 2010) that play important roles on its performance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different implementations (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) of ESA on same datasets (WN353 and Lee50) vary a lot, due the specificity of ESA implementation. For instance, Hassan and Mihalcea (2011) found a significant difference between the scores obtained from their own implementation and the scores reported in the original article (Gabrilovich and Markovitch, 2007). In this paper, first, we investigate the behavior of ESA model in calculating the semantic relatedness for </context>
</contexts>
<marker>Lee, Pincombe, Welsh, 2005</marker>
<rawString>Michael David Lee, BM Pincombe, and Matthew Brian Welsh. 2005. An empirical evaluation of models of text document similarity. Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Ariel Fuxman</author>
</authors>
<title>Jigs and lures: Associating web queries with structured entities.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>83--92</pages>
<contexts>
<context position="7737" citStr="Pantel and Fuxman, 2011" startWordPosition="1231" endWordPosition="1235">s while Xaxis shows the different values of N which are taken to build the model. It shows that ESA model generates very consistent results for phrase pairs similar to the one reported in (Aggarwal et al., 2012), how52 4 Context Enrichment Context enrichment is performed by concatenating the context defining text to the given word before building the ESA vector. Therefore, instead of building the ESA vector of a word, the vector is built for the short text that is obtained after concatenating the related context. This is similar to classical query expansion task (Aggarwal and Buitelaar, 2012; Pantel and Fuxman, 2011), where related concepts are concatenated with a query to improve the information retrieval performance. We propose three different methods to obtain related context: 1) WordNetbased Context Enrichment 2) Wikipedia-based Context Enrichment, and 3) WikiDefinition-based Context Enrichment. 4.1 WordNet-based Context Enrichment Figure 1: ESA performance on different types of text pairs by varying the total number of articles ever, the correlation scores decreases monotonously in the case of word pairs as the number of articles goes down. In the case of document pairs, ESA produces similar results </context>
</contexts>
<marker>Pantel, Fuxman, 2011</marker>
<rawString>Patrick Pantel and Ariel Fuxman. 2011. Jigs and lures: Associating web queries with structured entities. In ACL, pages 83–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara Polajnar</author>
<author>Nitish Aggarwal</author>
<author>Kartik Asooja</author>
<author>Paul Buitelaar</author>
</authors>
<title>Improving esa with document similarity.</title>
<date>2013</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>582--593</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2578" citStr="Polajnar et al., 2013" startWordPosition="381" endWordPosition="384">ant roles on its performance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different implementations (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) of ESA on same datasets (WN353 and Lee50) vary a lot, due the specificity of ESA implementation. For instance, Hassan and Mihalcea (2011) found a significant difference between the scores obtained from their own implementation and the scores reported in the original article (Gabrilovich and Markovitch, 2007). In this paper, first, we investigate the behavior of ESA model in calculating the semantic relatedness for different types of text pairs: word-word, phrase-phrase and document-document by using different number of Wikipedia articles for building the model. Sec</context>
<context position="4871" citStr="Polajnar et al., 2013" startWordPosition="758" endWordPosition="761">ESA model by using Wikipedia articles as explicit concepts, and take the TFIDF weights as associativity strength. Similarly, ESA builds the vector for natural language text by considering it as a bag of words. Let T = {t1, t2, t3...t�}, where T is a natural language text that has n words. ESA generates the vector V, where V = Etk&apos;T vk and v = EZ_&apos;0 az * cz. vk represents the ESA vector of a individual words as explained above. The relatedness score between two natural language texts is calculated by computing cosine product of their corresponding ESA vectors. In recent years, some extensions (Polajnar et al., 2013) (Hassan and Mihalcea, 2011) (Scholl et al., 2010) have been proposed to improve the ESA performance, however, they have not discussed the consistency in the performance of ESA. Polajnar et al. (2013) used only 10,000 Wikipedia articles as the concept space, and got significantly different results on the previously evaluated datasets. Hassan and Mihalcea (2011) have not discussed the ESA implementation in detail but obtained significantly different scores. Although, these proposed extensions got different baseline ESA scores but they improve the relatedness scores with their additions. Polajna</context>
</contexts>
<marker>Polajnar, Aggarwal, Asooja, Buitelaar, 2013</marker>
<rawString>Tamara Polajnar, Nitish Aggarwal, Kartik Asooja, and Paul Buitelaar. 2013. Improving esa with document similarity. In Advances in Information Retrieval, pages 582–593. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Scholl</author>
<author>Doreen B¨ohnstedt</author>
<author>Renato Domfnguez Garcfa</author>
<author>Christoph Rensing</author>
<author>Ralf Steinmetz</author>
</authors>
<title>Extended explicit semantic analysis for calculating semantic relatedness of web resources. In Sustaining TEL: From Innovation to Learning and Practice,</title>
<date>2010</date>
<pages>324--339</pages>
<publisher>Springer.</publisher>
<marker>Scholl, B¨ohnstedt, Garcfa, Rensing, Steinmetz, 2010</marker>
<rawString>Philipp Scholl, Doreen B¨ohnstedt, Renato Domfnguez Garcfa, Christoph Rensing, and Ralf Steinmetz. 2010. Extended explicit semantic analysis for calculating semantic relatedness of web resources. In Sustaining TEL: From Innovation to Learning and Practice, pages 324–339. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Sorg</author>
<author>Philipp Cimiano</author>
</authors>
<title>An experimental comparison of explicit semantic analysis implementations for cross-language retrieval.</title>
<date>2010</date>
<booktitle>In Natural Language Processing and Information Systems,</booktitle>
<pages>36--48</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1939" citStr="Sorg and Cimiano, 2010" startWordPosition="285" endWordPosition="288">A builds the high dimensional vectors by using the explicit concepts defined in human cognition. Gabrilovich and Markovitch (2007) introduced the ESA model in which Wikipedia and Open Directory Project1 was used to obtain the explicit concepts. ESA considers every Wikipedia article as a unique explicit 1http://www.dmoz.org topic. It also assumes that the articles are topically orthogonal. However, recent work (Gottron et al., 2011) has shown that by using the documents from Reuters corpus instead of Wikipedia articles can also achieve comparable results. ESA model includes various parameters (Sorg and Cimiano, 2010) that play important roles on its performance. Therefore, the model requires further investigation in order to better tune the parameters. ESA model has been adapted very quickly in different fields related to text analysis, due to the simplicity of its implementation and the availability of Wikipedia corpus. Gabrilovich and Markovitch (2007) evaluated the ESA against word relatedness dataset WN353 (Finkelstein et al., 2001) and document relatedness dataset Lee50 (Lee et al., 2005) by using all the articles from Wikipedia snapshot of 11 Nov, 2005. However, the results reported using different </context>
</contexts>
<marker>Sorg, Cimiano, 2010</marker>
<rawString>Philipp Sorg and Philipp Cimiano. 2010. An experimental comparison of explicit semantic analysis implementations for cross-language retrieval. In Natural Language Processing and Information Systems, pages 36–48. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>