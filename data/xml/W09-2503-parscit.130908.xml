<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000089">
<title confidence="0.922405">
Sub-sentential Paraphrasing by Contextual Pivot Translation
</title>
<author confidence="0.647481">
Aur´elien Max
</author>
<affiliation confidence="0.28659">
LIMSI-CNRS
</affiliation>
<address confidence="0.374695">
Universit´e Paris-Sud 11
Orsay, France
</address>
<email confidence="0.990186">
aurelien.max@limsi.fr
</email>
<sectionHeader confidence="0.99727" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874464285714">
The ability to generate or to recognize
paraphrases is key to the vast majority of
NLP applications. As correctly exploit-
ing context during translation has been
shown to be successful, using context in-
formation for paraphrasing could also lead
to improved performance. In this arti-
cle, we adopt the pivot approach based
on parallel multilingual corpora proposed
by (Bannard and Callison-Burch, 2005),
which finds short paraphrases by finding
appropriate pivot phrases in one or several
auxiliary languages and back-translating
these pivot phrases into the original lan-
guage. We show how context can be ex-
ploited both when attempting to find pivot
phrases, and when looking for the most
appropriate paraphrase in the original sub-
sentential “envelope”. This framework al-
lows the use of paraphrasing units ranging
from words to large sub-sentential frag-
ments for which context information from
the sentence can be successfully exploited.
We report experiments on a text revision
task, and show that in these experiments
our contextual sub-sentential paraphrasing
system outperforms a strong baseline sys-
tem.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955395348837">
The ability to generate or to recognize paraphrases
is key to the vast majority of NLP applications.
Most current research efforts on paraphrase gener-
ation attempt to push the limits of their respective
methods and resources without recourse to deep
meaning interpretation, an admitedly long-term
research objective. A step towards meaning-aware
paraphrasing can be done by appropriate use of the
context in which a paraphrasing occurrence oc-
curs. At the lowest level, deciding automatically
when a word can be substituted with a synonym is
a complex issue (Connor and Roth, 2007). When
attempting paraphrasing on a higher level, such as
arbitrary phrases or full sentences (Barzilay and
Lee, 2003; Pang et al., 2003; Quirk et al., 2004;
Bannard and Callison-Burch, 2005; Zhao et al.,
2008a), a first issue concerns the acquisition of el-
ementary units, which in the general case do not
exist in predefined dictionaries. Some paraphras-
ing strategy must then follow, which may consider
the context of a substitution to guide the selection
of appropriate units (Callison-Burch, 2008; Max,
2008). An important limitation to this family of
works is the scarcity of corpora that can be used as
reliable supervised training data. Indeed, strictly
parallel sentence pairs, for instance, are not nat-
urally produced in human activities.1 As a con-
sequence, works on paraphrasing have recourse to
costly human evaluation procedures, and an objec-
tive of automatic evaluation metrics is to rely on
as little gold standard data as possible (Callison-
Burch et al., 2008).
A text revision task is an application of para-
phrase generation where context may be used in
an effective way. When a local change is made to
a text, it occurs within a textual “envelope” within
which a paraphrase should fit. In particular, if the
original sentence was grammatical, the substituted
sentence should remain grammatical and convey
essentially the same meaning.2 The manner in
which such a context can be exploited depends
of course on the type of automatic paraphrasing
technique used. In this article, we adopt the pivot
</bodyText>
<footnote confidence="0.927595888888889">
1Recent works such as (Nelken and Yamangil, 2008)
have proposed mining the revision histories of collabora-
tive authoring resources like Wikipedia, offering interesting
prospects in paraphrasing and rewriting studies.
2We posit here that the revision activity does not involve
important semantic changes, as opposed to the rewriting ac-
tivity. In future work, we will attempt to consider cases of
paraphrasing involving meaning changes corresponding to
textual entailment phenomena.
</footnote>
<page confidence="0.976593">
18
</page>
<note confidence="0.998995">
Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 18–26,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.998927869565217">
approach based on parallel multilingual corpora
proposed by (Bannard and Callison-Burch, 2005),
which finds short paraphrases by finding appropri-
ate pivot phrases in one or several auxiliary lan-
guages and back-translating these pivot phrases
into the original language. We show how con-
text can be exploited both when attempting to find
pivot phrases, and when looking for the most ap-
propriate paraphrase in the original sub-sentential
envelope. This framework allows the use of para-
phrasing units ranging from words to large sub-
sentential fragments for which context informa-
tion from the sentence can be successfully ex-
ploited.
This article is organized as follows. In section 2,
we briefly review related work in paraphrasing and
context-aware Machine Translation. We describe
the main characteristics of our approach to sub-
sentential paraphrasing in section 3. We then de-
scribe an evaluation protocol for evaluating our
proposal and report the results of a human evalua-
tion in section 4. We finally conclude and present
our future work in section 5.
</bodyText>
<sectionHeader confidence="0.999854" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.995093217948719">
Different sources have been considered for para-
phrase acquisition techniques. (Pang et al., 2003),
for example, apply syntactic fusion to multiple
translations of individual sentences. (Barzilay and
Lee, 2003; Dolan et al., 2004) acquire short para-
phrases from comparable corpora, while (Bha-
gat and Ravichandran, 2008) considered the is-
sue of acquiring short paraphrase patterns from
huge amounts of comparable corpora. (Bannard
and Callison-Burch, 2005) introduced a pivot ap-
proach to acquire short paraphrases from multi-
lingual parallel corpora, a resource much more
readily available than their monolingual counter-
part. (Zhao et al., 2008b) acquire paraphrase pat-
terns from bilingual corpora and report the vari-
ous types obtained.3 (Callison-Burch, 2008) im-
proves the pivot paraphrase acquisition technique
by using syntactic constraints at the level of con-
stituents during phrase extraction. This works also
uses syntactic constraints during phrase substitu-
tion, resulting in improvements in both grammat-
3The types of their paraphrase patterns are the follow-
ing (numbers in parentheses indicate frequency in their
database): phrase replacements (267); trivial changes (79);
structural paraphrases (71); phrase reorderings (56); and ad-
dition of deletion of information that are claimed to not alter
meaning (27).
icality and meaning preservation in a large-scale
experiment on English. (Max, 2008) explored the
use of syntactic dependency preservation during
phrase substitution on French.
This family of works considered the acquisi-
tion of short paraphrases and their use in local
paraphrasing of known units. Several works have
tackled full sentence paraphrasing as a monolin-
gual translation task relying on Statistical Ma-
chine Translation (SMT). For instance, (Quirk et
al., 2004) used a phrase-based SMT decoder that
uses local paraphrases acquired from compara-
ble corpora to produce monotone sentential para-
phrases. (Zhao et al., 2008a) acquired monolin-
gual biphrases from various sources and used them
with a phrase-based SMT decoder, and (Madnani
et al., 2007) combined rules of their hierarchical
decoders by pivot to obtain a monolingual gram-
mar. These works were not motivated by the gen-
eration of high-quality paraphrases that could, for
example, be reused in documents. The lack of
structural information, the local nature of the para-
phrasing performed and the fact that the context of
the original sentences was not taken into account
in the phrase-based approaches make it difficult to
control meaning preservation during paraphrasing.
Context has been shown to play a crucial role
in Machine Translation, where in particular proper
Word Sense Disambiguation (WSD) is required in
many cases. A variety of works have integrated
context with some success into phrase-based and
hierarchical decoders. For example, (Carpuat and
Wu, 2007) disambiguate phrases using a state-of-
the-art WSD classifier, and (Stroppa et al., 2007)
use a global memory-based classifier to find ap-
propriate phrase translations in context. Context
is often defined as local linguistic features such
as surrounding words and their part-of-speech, but
some works have experimented with more syntac-
tic features (e.g. (Gimpel and Smith, 2008; Max
et al., 2008; Haque et al., 2009)).
Using an intermediate pivot language with
bilingual translation in which a given language
pair is low-resourced has led to improvements
in translation performance (Wu and Wang, 2007;
Bertoldi et al., 2008), but to our knowledge this ap-
proach has not been applied to full sentence para-
phrasing. Several reasons may explain this, in par-
ticular the relative low quality of current MT ap-
proaches on full sentence translation, and the diffi-
culties in controlling what is paraphrased and how.
</bodyText>
<page confidence="0.999495">
19
</page>
<sectionHeader confidence="0.836155" genericHeader="method">
3 Contextual pivot SMT for
sub-sentential paraphrasing
</sectionHeader>
<bodyText confidence="0.999973333333333">
Although many works have addressed the issue of
local paraphrase acquisition, effective use of such
paraphrases for paraphrase generation has only be
achieved at the level of text units corresponding
to short contiguous phrases. Recent works have
proposed approaches to exploit context in order
to correctly replace a text fragment with a para-
phrase, but they are limited to known text units
and therefore suffer from a scarcity of data.4
In this work, we address the case of sub-
sentential paraphrase generation, an intermediate
case between local paraphrasing using text units
for which paraphrases are available and full sen-
tence paraphrasing. Data sparcity is addressed by
using a pivot translation mechanism, which can
produce back-translations for text fragments for
which paraphrases cannot be acquired beforehand
by some paraphrase acquisition technique. Sub-
sentential paraphrasing by pivot allows the ex-
ploitation of context during both source-to-pivot
translation, where the source context is avail-
able, and during pivot-to-source back-translation,
where the target context is known. The success
of this approach is then directly dependent on the
availability of high quality MT engines and on
their ability to exploit these source and target con-
texts.
</bodyText>
<subsectionHeader confidence="0.99969">
3.1 Paraphrasing by pivot translation
</subsectionHeader>
<bodyText confidence="0.965436492753624">
Whereas attempts at using two translation sys-
tems in pivot have met with some success for low-
resourced language pairs, it is unlikely that cur-
rent SMT systems can be successfully called in
succession to obtain high-quality sentential para-
phrases.5 Several works have shown that mono-
lingual biphrases obtained by multilingual pivots
can be used by decoders, but although gains can
for example be obtained by using sentential para-
phrases as alternative reference corpora for opti-
mizing SMT systems (Madnani et al., 2007), re-
sulting paraphrases seem to be of too low quality
4Current approaches based on paraphrase patterns are
only a partial solution to this issue, as the variables used are
limited to simple types.
5In particular, back-translation can introduce lexical er-
rors due to incorrect word sense disambiguation and there-
fore severely hamper understanding, as illustrated by the in-
famous MT textbook example of the sentence The spirit is
willing but theflesh is weak being translated into Russian and
back-translated into English as The vodka is good, but the
meat is rotten.
for most other possible application contexts. In
this work, we propose to use a pivot approach from
a source language to a pivot language and back to
the source language, but for sub-sentential frag-
ments. In this way, the source context in which
they occur can be exploited for both translating
into the pivot language and for back-translating
into the original language. This is illustrated on
Figure 1.
Step (1) performs a N-best decoding (a single
example is shown here) in which a segmentation
of the source sentence is forced to ensure that
a given fragment (mettre en danger la richesse
´ecologique in the example) is translated indepen-
dently of its surrounding context.6 Only trans-
lations which respect this segmentation are kept,
yielding a variety of pivot sentences. We are
mostly interested in the pivot translation of our
paraphrased fragment, but its prefix and suffix
pivot context can be exploited by contextual SMT
to guide pivot-to-source translation, although the
lower quality of automatically generated sentences
might not help as much as before.
Step (2) produces from each obtained N-best
hypothesis a new N-best list of hypotheses, this
time in the source language. The decoder is once
more asked to use a given segmentation, and is fur-
ther given imposed translations for the pivot pre-
fix and suffix, as shown by the arrows going di-
rectly from the sentence at the top to the sentence
at the bottom of Figure 1. Step (2) can be fol-
lowed by a reranking procedure on the obtained
N-best list of hypotheses, whose individual score
can be obtained by combining the scores of the
two translation hypotheses that led to it. As op-
posed to the pivot approach for phrases of (Ban-
nard and Callison-Burch, 2005), it is not possi-
ble to sum over all possible pivots for a given
pair (original sentence, paraphrased sentence), as
the search space would make this computation im-
practical. We can instead look for the paraphrase
that maximizes the product of the probabilities of
the two translation steps according to the scores
produced by the decoders used.
A further step can eliminate paraphrases by ap-
plying heuristics designed to define sought or un-
desirable properties for paraphrases, although this
</bodyText>
<footnote confidence="0.8280824">
6It is in fact incorrect to say that translation of the vari-
ous fragments would take place independently of each other,
as various models such as a source context models or target
language models will use information from surrounding frag-
ments.
</footnote>
<page confidence="0.982685">
20
</page>
<figureCaption confidence="0.999943">
Figure 1: Example of sub-sentential paraphrasing by contextual pivot translation
</figureCaption>
<bodyText confidence="0.999883833333333">
could be directly integrated in the reranking step.
For example, we may not be interested by identity
paraphrases, or by paraphrases including or being
included in the original fragment, or we may pre-
fer paraphrases in which a given word has been
replaced, etc.
</bodyText>
<subsectionHeader confidence="0.998754">
3.2 Source context for pivot SMT
</subsectionHeader>
<bodyText confidence="0.999727714285714">
Using the context of a phrase is necessary to trans-
late it correctly, most notably when several word
senses corresponding to distinct translations are
involved. The following examples show a case of
a polysemous English word, which can be trans-
lated into three distinct French words and back-
translated into various English fragments:
</bodyText>
<listItem confidence="0.999550444444445">
• Follow the instructions outlined below to
save that file. → sauvegarder ce fichier →
write the file on disk
• Quitting smoking is a sure-fire way to save
some money. → ´economiser de l’argent →
have some money on your bank account
• Brown’s gamble may save the banks but the
economy cannot wait. → sauver les banques
→ salvage the banks
</listItem>
<bodyText confidence="0.999905833333333">
Our approach for source context aware SMT,
based on that of (Stroppa et al., 2007), is illus-
trated by the system architecture on Figure 2. A
memory-based classification approach was cho-
sen as it allows for efficient training with large
example sets, can handle any number of output
classes and produces results that can be directly
used to estimate the required conditional probabil-
ities. We add context-informed features to the log-
linear framework of our SMT system based on the
conditional probability of a target phrase ei given
a source phrase fi and its context, C(fi):
</bodyText>
<equation confidence="0.454935">
hm(fi, C(fi), ei) = log P(ei|fi, C(fi))
</equation>
<figureCaption confidence="0.984425">
Figure 2: Architecture of our contextual phrase-
based SMT system
</figureCaption>
<page confidence="0.994624">
21
</page>
<bodyText confidence="0.996625914285714">
Memory-based classification performs implicit
smoothing, which addresses in part the problem
of data sparcity, which worsen with the inclu-
sion of context features and makes direct estima-
tion of those probabilities problematic. Given a
fixed-length vector, (fi, C(fi)), a set of weighted
class labels corresponding to target phrases is
returned by the classifier, which give access to
P(ei|fi, C(fi)) after normalization.
Because each source phrase potentially occurs
in a unique context, they must be given a unique
entry in the phrase table. To this end, we added
a preprocessor component whose role is to dy-
namically build a modified source file containing
unique tokens and to produce a modified trans-
lation table containing those tokens. Phrase ex-
traction uses both phrase alignment results and
linguistic analysis of the source corpus to pro-
duce standard biphrases and biphrases with con-
textual information. The latter are used to train the
memory-based classifier. The source file under-
goes the same linguistic analysis whose output is
then aligned to unique tokens (e.g. president@45),
and each possible phrase which is also present in
the standard translation table is classified using its
context information. The output is used to create a
set of entries in the contextual translation tables, in
which a new score corresponding to our context-
based feature are added.
Most existing context-aware SMT approaches
rely on context features from the immediate con-
text of a source phrase. In this work, we initially
restricted ourselves to a limited set of features: up
to two lemmas to the left and to the right of a seg-
ment and their part-of-speech.7
</bodyText>
<subsectionHeader confidence="0.995488">
3.3 Target context for pivot SMT
</subsectionHeader>
<bodyText confidence="0.999973727272727">
When decoding from the pivot hypothesis, we
force our decoder to use provided sentence pre-
fix and suffix corresponding to the “envelope” of
the original fragment. Target context will thus be
taken into account by the decoder.
Furthermore, based on the hypothesis that a
paraphrase for an unmodified envelope should pre-
serve the syntactic dependencies between the para-
phrased fragment and its envelope (inter-fragment
dependencies), we optionaly add a “hard” rerank-
ing step where we filter the N-best list of hypothe-
</bodyText>
<footnote confidence="0.86607225">
7We will integrate richer syntactic context as in (Gimpel
and Smith, 2008; Max et al., 2008) in our short-term future
work, as we expect it to be particularly useful for our para-
phrasing task.
</footnote>
<bodyText confidence="0.996350461538461">
ses to keep only those which preserve these depen-
dencies. Note however that for a dependency to be
marked as preserved, we only need to find its label
and its target word in the envelope (governor or de-
pendent), as the word in the paraphrased fragment
might have changed. This of course has practical
implications on the nature of the paraphrases that
can be produced.
In part due to various deficiencies of phrase
alignments discussed in (Callison-Burch, 2008),
we further apply heuristics to filter out some un-
desirable paraphrase candidates. Our current set
of heuristics includes:
</bodyText>
<listItem confidence="0.986492625">
• no reordering should have taken place be-
tween the original source phrase and its con-
text8;
• considering the set of full word lemmas for
the original fragment and the paraphrased
fragment, at least one lemma should not be-
long to both sets9;
• neither the original fragment nor its para-
</listItem>
<bodyText confidence="0.6180765">
phrase must be included into the other (only
taking full words into account).
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99998">
We have conducted experiments motivated by a
text revision task that we report in this section
by describing our baseline and context-aware sub-
sentential paraphrasing systems and the results of
a small-scale manual evaluation.
</bodyText>
<subsectionHeader confidence="0.99131">
4.1 Data and systems
</subsectionHeader>
<bodyText confidence="0.999928333333333">
We built two-way French-English SMT sys-
tems using 188,115 lines of the Europarl cor-
pus (Koehn, 2005) of parliamentary debates with
moses (Koehn et al., 2007) 10. Our corpus was
analyzed by the XIP robust parser (A¨ıt-Mokhtar
et al., 2002) and its output tokenization was used.
We built standard systems, as well as a contextual
system for French→English as described in sec-
tion 3.2 using an additional contextual score ob-
</bodyText>
<footnote confidence="0.9839754">
8Reordering is allowed in the paraphrased fragment.
9As a consequence, minimal paraphrases may differ by
only one full word. This can however be used advantageously
when the sought type of paraphrasing aims at “normalizing”
a text fragment and when the most appropriate rewording is
very similar to an original text fragment.
10We used revision 2234 available on the moses SVN web-
site: http://mosesdecoder.sourceforge.net/
svn.php. In particular, it allows the use of XML annota-
tions to guide the translation of particular fragments.
</footnote>
<page confidence="0.997127">
22
</page>
<table confidence="0.882306333333333">
Baseline fr→en 30.56
Contextual fr→en 31.17
Baseline en→fr 32.10
</table>
<tableCaption confidence="0.9185475">
Table 1: BLEU scores for the translation systems
used by our paraphrasing system
</tableCaption>
<bodyText confidence="0.947612590909091">
tained through memory-based classification per-
formed with the TiMBL package (Daelemans et
al., 2007). Standard MERT was used to optimize
model weights. BLEU scores for the three systems
are reported on Table 1. The contextual system
obtains a slightly higher score than the baseline
system, which can participate to some extent to a
better exploitation of context for paraphrasing.11
Two paraphrasing systems we built: Sbas is a
baseline system which uses standard phrase tables
and post-filtering heuritics, but does not include
reranking based on syntactic dependencies. Scont
is a contextual system which uses the contex-
tual French→English translation system, rerank-
ing based on syntactic dependencies and post-
filtering heuristics.
We used 1000-best lists of hypotheses for the
source-to-pivot translation, and restricted our-
selves to much smaller 10-best lists for pivot-
to-source translation (integrating early more con-
straints directly into decoding could help in ob-
taining better and smaller N-best lists).12
</bodyText>
<subsectionHeader confidence="0.991003">
4.2 Evaluation protocol
</subsectionHeader>
<bodyText confidence="0.999984625">
A native speaker was asked to study a held-out test
file of Europarl data in French and to identify at
most one fragment per sentence that would be a
good candidate for revision and for which the an-
notator could think of reasonable paraphrases that
did not involve changes to the envelope. Candidate
fragments were accepted if they were not found in
the French→English translation table. This step
resulted in a corpus of 151 sentences with as many
test fragments, with sizes ranging from 2 to 12
words, an average size of 5.38 words and a me-
dian size of 4 words.
Two native speakers, including the previous an-
notator, were asked to evaluate all paraphrased
sentences on grammaticality and meaning. Con-
trary to previous works, we decided to use a
</bodyText>
<footnote confidence="0.918389">
11The unexpected worse performance of the fr→en system
may be explained by issues related to tokenization after anal-
ysis by the parser.
12In our future work, we intend to investigate the possible
use of lattices rather than N-best lists.
</footnote>
<bodyText confidence="0.864841333333333">
smaller evaluation scale with only 3 values, as
using more values tend to result in low inter-
annotator agreement:
</bodyText>
<listItem confidence="0.97153775">
• 2: indicates that the paraphrase is perfect or
almost perfect;
• 1: indicates that the paraphrase could become
grammatical with one minor change, or that
its meaning is almost clear;
• 0: indicates that more than one minor change
is required to make the paraphrase grammat-
ical or understandable.
</listItem>
<subsectionHeader confidence="0.956">
4.3 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999978891891892">
We ran both systems and took their one-best hy-
pothesis for evaluation. Table 2 shows the results
of a contrastive evaluation of the results obtained.
For the 143 sentences for which paraphrases could
be produced, we obtained 72 results common to
both systems, and 71 which were specific to each
system. The fact that for half of the cases the two
systems produced the same paraphrases reveals
that either context did not play an important role
in these cases, and/or that the search space was
rather limited due to the presence of rare words in
the original fragment. Systems Scont and Sbas are
compared based on the number of cases were one
was found to be better or worse than the other for
the 71 cases where they proposed different para-
phrases, either by the two judges (denoted by the
&lt; and &gt; signs) or by one of the two judges while
the other found the two systems to be of compara-
ble performance (denoted by the ≤ and ≥ signs).
As can be seen from the table, there is a clear pref-
erence for our Scont system, with a 31:37 ratio of
cases where it is preferred for grammar, and 33:49
for meaning.
Table 3 shows absolute results for the same run
of evaluation. First, it can be noted that both sys-
tems perform at a reasonable level, both for short
and long text fragments. Several reasons may ex-
plain this: first, sentences to paraphrase are from
the same domain as the training corpora for our
SMT systems, which is a positive bias towards
the paraphrasing systems. Also, the post-filtering
heuristics and the fact that both systems could
benefit from the knowledge of the target enve-
lope during pivot-to-source back-translation cer-
tainly helped in filtering out incorrect paraphrases.
These results confirm the trend observed on con-
trastive results that our Scont system is the best
</bodyText>
<page confidence="0.996831">
23
</page>
<table confidence="0.995709666666667">
Scont &lt; Sbas Scont ≤ Sbas Scont ≥ Sbas Scont &gt; Sbas ? Total
Grammar 3 3 10 21 34 71
Meaning 3 13 13 20 22 71
</table>
<tableCaption confidence="0.96162525">
Table 2: Contrastive results. The notation Scont &lt; Sbas stands for cases in which Scont is found to be
worse than Sbas by both judges; Scont ≤ Sbas for cases where Scont was found to be worse by one judge
while the other found the two systems equivalent; similarly for other cases. ’?’ stands for cases where
judges disagreed.
</tableCaption>
<table confidence="0.999886888888889">
count Grammar Meaning System
- + ? - + ? - + ?
Sbas and Scont 72 0 69 3 1 67 4 0 66 6
Sbas only 71 13 46 12 18 41 12 9 39 23
Scont only 71 5 63 3 8 56 7 4 55 12
Sbas: 2 ≤ size ≤ 5 81 6 69 6 10 63 8 4 61 16
Scont: 2 ≤ size ≤ 5 81 2 78 1 6 72 3 2 71 8
Sbas: 6 ≤ size ≤ 12 62 7 46 9 9 45 8 5 44 13
Scont: 6 ≤ size ≤ 12 62 4 54 4 3 51 8 2 50 10
</table>
<tableCaption confidence="0.680861333333333">
Table 3: Absolute results for manual evaluation. ’+’ indicates that both judges agree on a positive
judgement (score 1 or 2), ’-’ that both judges agree on a negative judgment (score 0), and ’?’ that judges
disagreed. ’System’ judgments include judgments for both Grammar and Meaning.
</tableCaption>
<bodyText confidence="0.999690096153846">
performer for that task and that test set. It is
however noteworthy that results were significantly
better when they were produced by both systems,
which may correspond to the easiest cases with re-
spect to the training data and/or the task but also
suggests the application of consensus techniques
as done in MT system output combination.
Table 4 shows paraphrasing examples produced
by Scont. As can be noted from positive exam-
ples (a-c), the obtained paraphrases are mostly of
the same syntactic types as the original phrases,
which may be due to the proximity between the
main language and the pivot language, as well as
to the constraint on syntactic dependency preser-
vation. Example (a) shows a case of what may
be seen as some sort of normalization, as the con-
cept of “confidence ofpeople” (w.r.t. the English
pivot language) may be more frequently expressed
as la confiance des citoyens (citizens) than as la
confiance des gens (people) in the reference cor-
pus. Example (b), although showing a correct
paraphrasing, contains an agreement error which
is a result of the use of the gender neutral English
pivot and the fact that the language model used by
the pivot-to-source SMT system was not able to
choose the correct agreement. Example (c) illus-
trates a case of correct paraphrasing involving re-
ordering strongly influenced by the reordering re-
quired by the pivot language. The incorrect para-
phrase of example (d) mainly results from the in-
ability of the source-to-pivot SMT system to cor-
rectly translate the selected fragment; in particular,
the syntactic structure was not correctly translated,
and the noun palier (stage) was incorrectly trans-
lated as the verb heal and back-translated as the
verb traiter (heal, cure). Lastly, example (e) con-
tains an error in word sense disambiguation be-
tween the pivot noun act and the noun loi (law)13,
as well as the incorrect deletion of the adverb tr`es
fermement (firmly) during source-to-pivot transla-
tion.
Several conclusions can be drawn from these
results and observations. First, it is not surpris-
ing that the performance of the SMT systems used
has an important impact on the results. This can
be mitigated in several ways: by attempting para-
phrasing on in-domain sentences; by using an ap-
propriate pivot language with respect to the nature
of the text fragment to paraphrase; by using one or
several pivot languages (as proposed by (Bannard
and Callison-Burch, 2005) for phrase paraphras-
ing) and consensus on the obtained paraphrases.
</bodyText>
<footnote confidence="0.9373425">
13This example might call for better lexical checking be-
tween original and paraphrased sentences, as well as exploit-
ing context-aware SMT on the lower quality input of pivot-
to-source translation.
</footnote>
<page confidence="0.998758">
24
</page>
<bodyText confidence="0.992555833333333">
(a) En tant que parti de gauche, nous avons dˆu, avec beaucoup de peine, nous rendre compte que les institutions ne sont
pas des jeux de construction montables, transformables et d´emontables a` souhait, mais qu’elles ont leur propre histoire
et doivent b´en´eficier de la confiance des gens qui les soutiennent.
As the left, we have had, with a great deal of trouble, we see that the institutions are not games montables construction,
transformables d´emontables and to wish, but they have their own history and must enjoy the confidence of people
who support them.
</bodyText>
<figure confidence="0.616885388888889">
→ doivent avoir la confiance des citoyens
(b) Monsieur le pr´esident, je suis inqui`ete au sujet de l’attitude qui risque de se d´evelopper au sein de l’UE concernant la
libert´e des ´echanges.
Mr President, I am concerned about the attitude which might develop within the EU on free trade.
→ je suis pr´eoccup´e par
(c) Ces accords constituent un cadre contractuel entiirement nouveau pour les pays de la r´egion.
These agreements constitute an entirely new contractual framework for the countries of the region.
→ un tout nouveau cadre contractuel
(d) Aujourd’hui, le durcissement parall`ele des ind´ependantistes albanais et des autorit´es serbes fait franchir a` la crise un
nouveau palier tris inqui´etant dans la mont´ee des tensions.
Today, the inflexibility parallel with the Albanian independent and the Serbian authorities to overcome the crisis is a
new heal very worrying in the rise of tension.
→ (*) de surmonter la crise est une nouvelle traiter tris pr´eoccupant
(e) La commission condamne tris fermement cet acte et prend note de la d´ecision de constituer un comit´e sp´ecial au sein
de la fiscalia general de la naci´on afin d’enquˆeter sur cet assassinat.
The Commission condemn this act and takes note of the decision to set up a special committee fiscalia within the
general de la nacin in order to investigate this murder.
→ (*) condamne cette loi
</figure>
<tableCaption confidence="0.982652">
Table 4: Examples of sub-sentential paraphrasings produced by our Scont system.
</tableCaption>
<bodyText confidence="0.996513333333333">
Another remark is that our systems could be im-
proved as regards their ability to exploit source
context.14
</bodyText>
<sectionHeader confidence="0.991197" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.994439272727273">
In this article, we have presented an approach to
obtain sub-sentential paraphrases by using pivot
SMT systems. Although our results showed that
we were able to build a strong baseline on our test
set, they also showed that integrating context both
when translating from source-to-pivot and when
back-translating from pivot-to-source can lead to
improved performance. Our approach has the dis-
tinctive feature that it targets text fragments that
can be larger than phrases traditionally captured
by statistical techniques, while not targeting full
sentences for which it would be harder to exploit
context successfully. More generally, it addresses
the case of the paraphrasing of text units for which
no paraphrases are directly available.
We have identified several issues in our exper-
iments that will constitute our future work. We
intend to experiment with several pivot languages
and to make them compete to obtain the N-best
lists, as done in some approaches to multisource
translation (Och and Ney, 2001) and/or to use a
consensus technique to select the best paraphrase.
14It should be noted, however, that the reported experi-
ments used relatively small amounts of training data as in
most comparable works on context-aware Machine Transla-
tion.
As regards our context-aware SMT systems, we
plan to exploit more complex syntactic knowledge
and to learn correspondances for inter-fragment
dependencies so as to make our rescoring based
on syntactic dependencies more flexible. We are
currently working on extracting revision instances
from Wikipedia’s revision history, which will pro-
vide us with a corpus of genuine revision occur-
rences as well as with an out-domain test corpus
with reference paraphrases. Lastly, we want to in-
vestigate the use of our approach for two types of
applications: text normalization, in which a text
is revised to select approved phraseology and ter-
minology, through the use of a carefully chosen
training corpus for our pivot-to-source SMT sys-
tem ; and interactive translation output revision for
cases with or without a source text for professional
translators or monolingual users.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.967357">
This work was funded by a grant from LIMSI.
</bodyText>
<sectionHeader confidence="0.999303" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993652571428571">
Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond shallowness: in-
cremental deep parsing. Natural Language Engi-
neering, 8(3):121–144.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Pro-
ceedings ofACL, Ann Arbor, USA.
</reference>
<page confidence="0.98599">
25
</page>
<reference confidence="0.999504578431372">
Regina Barzilay and Lillian Lee. 2003. Learn-
ing to paraphrase: an unsupervised approach us-
ing multiple-sequence alignment. In Proceedings of
NAACL/HLT, Edmonton, Canada.
Nicola Bertoldi, Madalina Barbaiani, Marcello Fed-
erico, and Roldano Cattoni. 2008. Phrase-based
statistical machine translation with pivot languages.
In Proceeding of IWSLT, pages 143–149, Hawaii,
USA.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of ACL: HLT, Columbus,
USA.
Chris Callison-Burch, Trevor Cohn, and Mirella Lap-
ata. 2008. Parametric: An automatic evaluation
metric for paraphrasing. In Proceedings of COL-
ING, Manchester, UK.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. In Pro-
ceedings ofEMNLP, Hawai, USA.
Marine Carpuat and Dekai Wu. 2007. Context-
dependent phrasal translation lexicons for statisti-
cal machine translation. In Proceedings of Machine
Translation Summit XI, Copenhagen, Denmark.
Michael Connor and Dan Roth. 2007. Context sensi-
tive paraphrasing with a single unsupervised classi-
fier. In Proceedings ofECML, Warsaw, Poland.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot,
and Antal van den Bosch. 2007. TiMBL: Tilburg
Memory Based Learner, version 6.1, Reference
Guide. Technical report, ILK 07-xx. Available from
http://ilk.uvt.nl/downloads/pub/pap
ers/ilk0703.pdf.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
Unsupervised construction of large paraphrase cor-
pora: Exploiting massively parallel news sources.
In Proceedings of Coling 2004, pages 350–356,
Geneva, Switzerland.
Kevin Gimpel and Noah A. Smith. 2008. Rich source-
side context for statistical machine translation. In
Proceedings of WMT at ACL, Columbus, USA.
Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma,
and Andy Way. 2009. Using supertags as source
language context in smt. In Proceedings of EAMT,
Barcelona, Spain.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of ACL, demo session, Prague, Czech
Republic.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
ofMT Summit, Phuket, Thailand.
Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and
Bonnie J. Dorr. 2007. Paraphrases for parameter
tuning in statistical machine translation. In Proceed-
ings of Workshop on Machine Translation at ACL,
Prague, Czech Republic.
Aur´elien Max, Rafik Makhloufi, and Philippe Langlais.
2008. Explorations in using grammatical dependen-
cies for contextual phrase translation disambigua-
tion. In Proceedings of EAMT, Hamburg, Germany.
Aur´elien Max. 2008. Local rephrasing suggestions for
supporting the work of writers. In Proceedings of
GoTAL, Gothenburg, Sweden.
Rani Nelken and Elif Yamangil. 2008. Mining
wikipedia’s article revision history for training com-
putational linguistics algorithms. In Proceedings of
the AAAI Workshop on Wikipedia and Artificial In-
telligence: An Evolving Synergy, Chicago, USA.
Franz Josef Och and Hermann Ney. 2001. Statisti-
cal multi-source translation. In Proceedings of MT
Summit, Santiago de Compostela, Spain.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations:
Extracting paraphrases and generating new sen-
tences. In Proceedings of NAACL/HLT, Edmonton,
Canada.
Chris Quirk, Chris Brockett, and William B. Dolan.
2004. Monolingual machine translation for para-
phrase generation. In Proceedings of EMNLP,
Barcelona, Spain.
Nicolas Stroppa, Antal van den Bosch, and Andy Way.
2007. Exploiting source similarity for smt using
context-informed features. In Proceedings of TMI,
Skvde, Sweden.
Hua Wu and Haifeng Wang. 2007. Pivot language
approach for phrase-based statistical machine trans-
lation. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
Prague, Czech Republic.
Shiqi Zhao, Cheng Niu, Ming Zhou, and Sheng Li.
2008a. Combining multiple resources to improve
smt-based paraphrasing model. In Proceedings of
ACL-HLT, Columbus, USA.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008b. Pivot approach for extracting paraphrase
patterns from bilingual corpora. In Proceedings of
ACL-HLT, Columbus, USA.
</reference>
<page confidence="0.998058">
26
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.554889">
<title confidence="0.992099">Sub-sentential Paraphrasing by Contextual Pivot Translation</title>
<author confidence="0.783756">Aur´elien</author>
<affiliation confidence="0.928216">Universit´e Paris-Sud</affiliation>
<address confidence="0.903471">Orsay,</address>
<email confidence="0.997633">aurelien.max@limsi.fr</email>
<abstract confidence="0.992634448275862">The ability to generate or to recognize paraphrases is key to the vast majority of NLP applications. As correctly exploiting context during translation has been shown to be successful, using context information for paraphrasing could also lead to improved performance. In this article, we adopt the pivot approach based on parallel multilingual corpora proposed by (Bannard and Callison-Burch, 2005), which finds short paraphrases by finding appropriate pivot phrases in one or several auxiliary languages and back-translating these pivot phrases into the original language. We show how context can be exploited both when attempting to find pivot phrases, and when looking for the most appropriate paraphrase in the original subsentential “envelope”. This framework allows the use of paraphrasing units ranging from words to large sub-sentential fragments for which context information from the sentence can be successfully exploited. We report experiments on a text revision task, and show that in these experiments our contextual sub-sentential paraphrasing system outperforms a strong baseline system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah A¨ıt-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>Robustness beyond shallowness: incremental deep parsing.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>3</issue>
<marker>A¨ıt-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude Roux. 2002. Robustness beyond shallowness: incremental deep parsing. Natural Language Engineering, 8(3):121–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="2045" citStr="Bannard and Callison-Burch, 2005" startWordPosition="304" endWordPosition="307">phrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a consequence, works on paraphrasing ha</context>
<context position="4092" citStr="Bannard and Callison-Burch, 2005" startWordPosition="622" endWordPosition="625"> of collaborative authoring resources like Wikipedia, offering interesting prospects in paraphrasing and rewriting studies. 2We posit here that the revision activity does not involve important semantic changes, as opposed to the rewriting activity. In future work, we will attempt to consider cases of paraphrasing involving meaning changes corresponding to textual entailment phenomena. 18 Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 18–26, Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP approach based on parallel multilingual corpora proposed by (Bannard and Callison-Burch, 2005), which finds short paraphrases by finding appropriate pivot phrases in one or several auxiliary languages and back-translating these pivot phrases into the original language. We show how context can be exploited both when attempting to find pivot phrases, and when looking for the most appropriate paraphrase in the original sub-sentential envelope. This framework allows the use of paraphrasing units ranging from words to large subsentential fragments for which context information from the sentence can be successfully exploited. This article is organized as follows. In section 2, we briefly rev</context>
<context position="5519" citStr="Bannard and Callison-Burch, 2005" startWordPosition="844" endWordPosition="847">ation protocol for evaluating our proposal and report the results of a human evaluation in section 4. We finally conclude and present our future work in section 5. 2 Related work Different sources have been considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses syntactic constraints during phrase substitution, resulting in improvements in both grammat3The types of their paraphrase patterns are th</context>
<context position="12983" citStr="Bannard and Callison-Burch, 2005" startWordPosition="2016" endWordPosition="2020"> each obtained N-best hypothesis a new N-best list of hypotheses, this time in the source language. The decoder is once more asked to use a given segmentation, and is further given imposed translations for the pivot prefix and suffix, as shown by the arrows going directly from the sentence at the top to the sentence at the bottom of Figure 1. Step (2) can be followed by a reranking procedure on the obtained N-best list of hypotheses, whose individual score can be obtained by combining the scores of the two translation hypotheses that led to it. As opposed to the pivot approach for phrases of (Bannard and Callison-Burch, 2005), it is not possible to sum over all possible pivots for a given pair (original sentence, paraphrased sentence), as the search space would make this computation impractical. We can instead look for the paraphrase that maximizes the product of the probabilities of the two translation steps according to the scores produced by the decoders used. A further step can eliminate paraphrases by applying heuristics designed to define sought or undesirable properties for paraphrases, although this 6It is in fact incorrect to say that translation of the various fragments would take place independently of </context>
<context position="27911" citStr="Bannard and Callison-Burch, 2005" startWordPosition="4550" endWordPosition="4553">ation between the pivot noun act and the noun loi (law)13, as well as the incorrect deletion of the adverb tr`es fermement (firmly) during source-to-pivot translation. Several conclusions can be drawn from these results and observations. First, it is not surprising that the performance of the SMT systems used has an important impact on the results. This can be mitigated in several ways: by attempting paraphrasing on in-domain sentences; by using an appropriate pivot language with respect to the nature of the text fragment to paraphrase; by using one or several pivot languages (as proposed by (Bannard and Callison-Burch, 2005) for phrase paraphrasing) and consensus on the obtained paraphrases. 13This example might call for better lexical checking between original and paraphrased sentences, as well as exploiting context-aware SMT on the lower quality input of pivotto-source translation. 24 (a) En tant que parti de gauche, nous avons dˆu, avec beaucoup de peine, nous rendre compte que les institutions ne sont pas des jeux de construction montables, transformables et d´emontables a` souhait, mais qu’elles ont leur propre histoire et doivent b´en´eficier de la confiance des gens qui les soutiennent. As the left, we hav</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings ofACL, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: an unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1972" citStr="Barzilay and Lee, 2003" startWordPosition="292" endWordPosition="295">rity of NLP applications. Most current research efforts on paraphrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally </context>
<context position="5273" citStr="Barzilay and Lee, 2003" startWordPosition="808" endWordPosition="811"> as follows. In section 2, we briefly review related work in paraphrasing and context-aware Machine Translation. We describe the main characteristics of our approach to subsentential paraphrasing in section 3. We then describe an evaluation protocol for evaluating our proposal and report the results of a human evaluation in section 4. We finally conclude and present our future work in section 5. 2 Related work Different sources have been considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition techniqu</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: an unsupervised approach using multiple-sequence alignment. In Proceedings of NAACL/HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Madalina Barbaiani</author>
<author>Marcello Federico</author>
<author>Roldano Cattoni</author>
</authors>
<title>Phrase-based statistical machine translation with pivot languages.</title>
<date>2008</date>
<booktitle>In Proceeding of IWSLT,</booktitle>
<pages>143--149</pages>
<location>Hawaii, USA.</location>
<contexts>
<context position="8537" citStr="Bertoldi et al., 2008" startWordPosition="1300" endWordPosition="1303"> disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; Bertoldi et al., 2008), but to our knowledge this approach has not been applied to full sentence paraphrasing. Several reasons may explain this, in particular the relative low quality of current MT approaches on full sentence translation, and the difficulties in controlling what is paraphrased and how. 19 3 Contextual pivot SMT for sub-sentential paraphrasing Although many works have addressed the issue of local paraphrase acquisition, effective use of such paraphrases for paraphrase generation has only be achieved at the level of text units corresponding to short contiguous phrases. Recent works have proposed appr</context>
</contexts>
<marker>Bertoldi, Barbaiani, Federico, Cattoni, 2008</marker>
<rawString>Nicola Bertoldi, Madalina Barbaiani, Marcello Federico, and Roldano Cattoni. 2008. Phrase-based statistical machine translation with pivot languages. In Proceeding of IWSLT, pages 143–149, Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL: HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="5383" citStr="Bhagat and Ravichandran, 2008" startWordPosition="824" endWordPosition="828">anslation. We describe the main characteristics of our approach to subsentential paraphrasing in section 3. We then describe an evaluation protocol for evaluating our proposal and report the results of a human evaluation in section 4. We finally conclude and present our future work in section 5. 2 Related work Different sources have been considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses s</context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of ACL: HLT, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Parametric: An automatic evaluation metric for paraphrasing.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Manchester, UK.</location>
<marker>Callison-Burch, Cohn, Lapata, 2008</marker>
<rawString>Chris Callison-Burch, Trevor Cohn, and Mirella Lapata. 2008. Parametric: An automatic evaluation metric for paraphrasing. In Proceedings of COLING, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings ofEMNLP,</booktitle>
<location>Hawai, USA.</location>
<contexts>
<context position="2354" citStr="Callison-Burch, 2008" startWordPosition="355" endWordPosition="356">st level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a consequence, works on paraphrasing have recourse to costly human evaluation procedures, and an objective of automatic evaluation metrics is to rely on as little gold standard data as possible (CallisonBurch et al., 2008). A text revision task is an application of paraphrase generation where context may be used in an effective way. When a local </context>
<context position="5822" citStr="Callison-Burch, 2008" startWordPosition="891" endWordPosition="892">o multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses syntactic constraints during phrase substitution, resulting in improvements in both grammat3The types of their paraphrase patterns are the following (numbers in parentheses indicate frequency in their database): phrase replacements (267); trivial changes (79); structural paraphrases (71); phrase reorderings (56); and addition of deletion of information that are claimed to not alter meaning (27). icality and meaning preservation in a lar</context>
<context position="18312" citStr="Callison-Burch, 2008" startWordPosition="2894" endWordPosition="2895">ic context as in (Gimpel and Smith, 2008; Max et al., 2008) in our short-term future work, as we expect it to be particularly useful for our paraphrasing task. ses to keep only those which preserve these dependencies. Note however that for a dependency to be marked as preserved, we only need to find its label and its target word in the envelope (governor or dependent), as the word in the paraphrased fragment might have changed. This of course has practical implications on the nature of the paraphrases that can be produced. In part due to various deficiencies of phrase alignments discussed in (Callison-Burch, 2008), we further apply heuristics to filter out some undesirable paraphrase candidates. Our current set of heuristics includes: • no reordering should have taken place between the original source phrase and its context8; • considering the set of full word lemmas for the original fragment and the paraphrased fragment, at least one lemma should not belong to both sets9; • neither the original fragment nor its paraphrase must be included into the other (only taking full words into account). 4 Experiments We have conducted experiments motivated by a text revision task that we report in this section by</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings ofEMNLP, Hawai, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Contextdependent phrasal translation lexicons for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of Machine Translation</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="7915" citStr="Carpuat and Wu, 2007" startWordPosition="1205" endWordPosition="1208">hrases that could, for example, be reused in documents. The lack of structural information, the local nature of the paraphrasing performed and the fact that the context of the original sentences was not taken into account in the phrase-based approaches make it difficult to control meaning preservation during paraphrasing. Context has been shown to play a crucial role in Machine Translation, where in particular proper Word Sense Disambiguation (WSD) is required in many cases. A variety of works have integrated context with some success into phrase-based and hierarchical decoders. For example, (Carpuat and Wu, 2007) disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; </context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Contextdependent phrasal translation lexicons for statistical machine translation. In Proceedings of Machine Translation Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Connor</author>
<author>Dan Roth</author>
</authors>
<title>Context sensitive paraphrasing with a single unsupervised classifier.</title>
<date>2007</date>
<booktitle>In Proceedings ofECML,</booktitle>
<location>Warsaw, Poland.</location>
<contexts>
<context position="1855" citStr="Connor and Roth, 2007" startWordPosition="274" endWordPosition="277"> a strong baseline system. 1 Introduction The ability to generate or to recognize paraphrases is key to the vast majority of NLP applications. Most current research efforts on paraphrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be </context>
</contexts>
<marker>Connor, Roth, 2007</marker>
<rawString>Michael Connor and Dan Roth. 2007. Context sensitive paraphrasing with a single unsupervised classifier. In Proceedings ofECML, Warsaw, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Ko van der Sloot</author>
<author>Antal van den Bosch</author>
</authors>
<title>TiMBL: Tilburg Memory Based Learner, version 6.1, Reference Guide.</title>
<date>2007</date>
<tech>Technical report, ILK 07-xx.</tech>
<note>Available from http://ilk.uvt.nl/downloads/pub/pap ers/ilk0703.pdf.</note>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2007</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and Antal van den Bosch. 2007. TiMBL: Tilburg Memory Based Learner, version 6.1, Reference Guide. Technical report, ILK 07-xx. Available from http://ilk.uvt.nl/downloads/pub/pap ers/ilk0703.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>350--356</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="5294" citStr="Dolan et al., 2004" startWordPosition="812" endWordPosition="815">2, we briefly review related work in paraphrasing and context-aware Machine Translation. We describe the main characteristics of our approach to subsentential paraphrasing in section 3. We then describe an evaluation protocol for evaluating our proposal and report the results of a human evaluation in section 4. We finally conclude and present our future work in section 5. 2 Related work Different sources have been considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic </context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of Coling 2004, pages 350–356, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Rich sourceside context for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of WMT at ACL,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="8290" citStr="Gimpel and Smith, 2008" startWordPosition="1261" endWordPosition="1264">achine Translation, where in particular proper Word Sense Disambiguation (WSD) is required in many cases. A variety of works have integrated context with some success into phrase-based and hierarchical decoders. For example, (Carpuat and Wu, 2007) disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; Bertoldi et al., 2008), but to our knowledge this approach has not been applied to full sentence paraphrasing. Several reasons may explain this, in particular the relative low quality of current MT approaches on full sentence translation, and the difficulties in controlling what is paraphrased and how. 19 3 Contextual pivot SMT for sub-sentential paraphrasing Although many</context>
<context position="17731" citStr="Gimpel and Smith, 2008" startWordPosition="2792" endWordPosition="2795"> 3.3 Target context for pivot SMT When decoding from the pivot hypothesis, we force our decoder to use provided sentence prefix and suffix corresponding to the “envelope” of the original fragment. Target context will thus be taken into account by the decoder. Furthermore, based on the hypothesis that a paraphrase for an unmodified envelope should preserve the syntactic dependencies between the paraphrased fragment and its envelope (inter-fragment dependencies), we optionaly add a “hard” reranking step where we filter the N-best list of hypothe7We will integrate richer syntactic context as in (Gimpel and Smith, 2008; Max et al., 2008) in our short-term future work, as we expect it to be particularly useful for our paraphrasing task. ses to keep only those which preserve these dependencies. Note however that for a dependency to be marked as preserved, we only need to find its label and its target word in the envelope (governor or dependent), as the word in the paraphrased fragment might have changed. This of course has practical implications on the nature of the paraphrases that can be produced. In part due to various deficiencies of phrase alignments discussed in (Callison-Burch, 2008), we further apply </context>
</contexts>
<marker>Gimpel, Smith, 2008</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2008. Rich sourceside context for statistical machine translation. In Proceedings of WMT at ACL, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rejwanul Haque</author>
<author>Sudip Kumar Naskar</author>
<author>Yanjun Ma</author>
<author>Andy Way</author>
</authors>
<title>Using supertags as source language context in smt.</title>
<date>2009</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="8329" citStr="Haque et al., 2009" startWordPosition="1269" endWordPosition="1272">oper Word Sense Disambiguation (WSD) is required in many cases. A variety of works have integrated context with some success into phrase-based and hierarchical decoders. For example, (Carpuat and Wu, 2007) disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; Bertoldi et al., 2008), but to our knowledge this approach has not been applied to full sentence paraphrasing. Several reasons may explain this, in particular the relative low quality of current MT approaches on full sentence translation, and the difficulties in controlling what is paraphrased and how. 19 3 Contextual pivot SMT for sub-sentential paraphrasing Although many works have addressed the issue of loca</context>
</contexts>
<marker>Haque, Naskar, Ma, Way, 2009</marker>
<rawString>Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma, and Andy Way. 2009. Using supertags as source language context in smt. In Proceedings of EAMT, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL, demo session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="19220" citStr="Koehn et al., 2007" startWordPosition="3041" endWordPosition="3044">the paraphrased fragment, at least one lemma should not belong to both sets9; • neither the original fragment nor its paraphrase must be included into the other (only taking full words into account). 4 Experiments We have conducted experiments motivated by a text revision task that we report in this section by describing our baseline and context-aware subsentential paraphrasing systems and the results of a small-scale manual evaluation. 4.1 Data and systems We built two-way French-English SMT systems using 188,115 lines of the Europarl corpus (Koehn, 2005) of parliamentary debates with moses (Koehn et al., 2007) 10. Our corpus was analyzed by the XIP robust parser (A¨ıt-Mokhtar et al., 2002) and its output tokenization was used. We built standard systems, as well as a contextual system for French→English as described in section 3.2 using an additional contextual score ob8Reordering is allowed in the paraphrased fragment. 9As a consequence, minimal paraphrases may differ by only one full word. This can however be used advantageously when the sought type of paraphrasing aims at “normalizing” a text fragment and when the most appropriate rewording is very similar to an original text fragment. 10We used </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL, demo session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings ofMT Summit,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="19163" citStr="Koehn, 2005" startWordPosition="3034" endWordPosition="3035">of full word lemmas for the original fragment and the paraphrased fragment, at least one lemma should not belong to both sets9; • neither the original fragment nor its paraphrase must be included into the other (only taking full words into account). 4 Experiments We have conducted experiments motivated by a text revision task that we report in this section by describing our baseline and context-aware subsentential paraphrasing systems and the results of a small-scale manual evaluation. 4.1 Data and systems We built two-way French-English SMT systems using 188,115 lines of the Europarl corpus (Koehn, 2005) of parliamentary debates with moses (Koehn et al., 2007) 10. Our corpus was analyzed by the XIP robust parser (A¨ıt-Mokhtar et al., 2002) and its output tokenization was used. We built standard systems, as well as a contextual system for French→English as described in section 3.2 using an additional contextual score ob8Reordering is allowed in the paraphrased fragment. 9As a consequence, minimal paraphrases may differ by only one full word. This can however be used advantageously when the sought type of paraphrasing aims at “normalizing” a text fragment and when the most appropriate rewording</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings ofMT Summit, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Necip Fazil Ayan</author>
<author>Philip Resnik</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Paraphrases for parameter tuning in statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of Workshop on Machine Translation at ACL,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7135" citStr="Madnani et al., 2007" startWordPosition="1084" endWordPosition="1087">ation during phrase substitution on French. This family of works considered the acquisition of short paraphrases and their use in local paraphrasing of known units. Several works have tackled full sentence paraphrasing as a monolingual translation task relying on Statistical Machine Translation (SMT). For instance, (Quirk et al., 2004) used a phrase-based SMT decoder that uses local paraphrases acquired from comparable corpora to produce monotone sentential paraphrases. (Zhao et al., 2008a) acquired monolingual biphrases from various sources and used them with a phrase-based SMT decoder, and (Madnani et al., 2007) combined rules of their hierarchical decoders by pivot to obtain a monolingual grammar. These works were not motivated by the generation of high-quality paraphrases that could, for example, be reused in documents. The lack of structural information, the local nature of the paraphrasing performed and the fact that the context of the original sentences was not taken into account in the phrase-based approaches make it difficult to control meaning preservation during paraphrasing. Context has been shown to play a crucial role in Machine Translation, where in particular proper Word Sense Disambigu</context>
<context position="10695" citStr="Madnani et al., 2007" startWordPosition="1635" endWordPosition="1638">nd on their ability to exploit these source and target contexts. 3.1 Paraphrasing by pivot translation Whereas attempts at using two translation systems in pivot have met with some success for lowresourced language pairs, it is unlikely that current SMT systems can be successfully called in succession to obtain high-quality sentential paraphrases.5 Several works have shown that monolingual biphrases obtained by multilingual pivots can be used by decoders, but although gains can for example be obtained by using sentential paraphrases as alternative reference corpora for optimizing SMT systems (Madnani et al., 2007), resulting paraphrases seem to be of too low quality 4Current approaches based on paraphrase patterns are only a partial solution to this issue, as the variables used are limited to simple types. 5In particular, back-translation can introduce lexical errors due to incorrect word sense disambiguation and therefore severely hamper understanding, as illustrated by the infamous MT textbook example of the sentence The spirit is willing but theflesh is weak being translated into Russian and back-translated into English as The vodka is good, but the meat is rotten. for most other possible applicatio</context>
</contexts>
<marker>Madnani, Ayan, Resnik, Dorr, 2007</marker>
<rawString>Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie J. Dorr. 2007. Paraphrases for parameter tuning in statistical machine translation. In Proceedings of Workshop on Machine Translation at ACL, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
<author>Rafik Makhloufi</author>
<author>Philippe Langlais</author>
</authors>
<title>Explorations in using grammatical dependencies for contextual phrase translation disambiguation.</title>
<date>2008</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Hamburg, Germany.</location>
<contexts>
<context position="8308" citStr="Max et al., 2008" startWordPosition="1265" endWordPosition="1268">e in particular proper Word Sense Disambiguation (WSD) is required in many cases. A variety of works have integrated context with some success into phrase-based and hierarchical decoders. For example, (Carpuat and Wu, 2007) disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; Bertoldi et al., 2008), but to our knowledge this approach has not been applied to full sentence paraphrasing. Several reasons may explain this, in particular the relative low quality of current MT approaches on full sentence translation, and the difficulties in controlling what is paraphrased and how. 19 3 Contextual pivot SMT for sub-sentential paraphrasing Although many works have addres</context>
<context position="17750" citStr="Max et al., 2008" startWordPosition="2796" endWordPosition="2799">pivot SMT When decoding from the pivot hypothesis, we force our decoder to use provided sentence prefix and suffix corresponding to the “envelope” of the original fragment. Target context will thus be taken into account by the decoder. Furthermore, based on the hypothesis that a paraphrase for an unmodified envelope should preserve the syntactic dependencies between the paraphrased fragment and its envelope (inter-fragment dependencies), we optionaly add a “hard” reranking step where we filter the N-best list of hypothe7We will integrate richer syntactic context as in (Gimpel and Smith, 2008; Max et al., 2008) in our short-term future work, as we expect it to be particularly useful for our paraphrasing task. ses to keep only those which preserve these dependencies. Note however that for a dependency to be marked as preserved, we only need to find its label and its target word in the envelope (governor or dependent), as the word in the paraphrased fragment might have changed. This of course has practical implications on the nature of the paraphrases that can be produced. In part due to various deficiencies of phrase alignments discussed in (Callison-Burch, 2008), we further apply heuristics to filte</context>
</contexts>
<marker>Max, Makhloufi, Langlais, 2008</marker>
<rawString>Aur´elien Max, Rafik Makhloufi, and Philippe Langlais. 2008. Explorations in using grammatical dependencies for contextual phrase translation disambiguation. In Proceedings of EAMT, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
</authors>
<title>Local rephrasing suggestions for supporting the work of writers.</title>
<date>2008</date>
<booktitle>In Proceedings of GoTAL,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="2366" citStr="Max, 2008" startWordPosition="357" endWordPosition="358">omatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a consequence, works on paraphrasing have recourse to costly human evaluation procedures, and an objective of automatic evaluation metrics is to rely on as little gold standard data as possible (CallisonBurch et al., 2008). A text revision task is an application of paraphrase generation where context may be used in an effective way. When a local change is ma</context>
<context position="6465" citStr="Max, 2008" startWordPosition="984" endWordPosition="985">quisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses syntactic constraints during phrase substitution, resulting in improvements in both grammat3The types of their paraphrase patterns are the following (numbers in parentheses indicate frequency in their database): phrase replacements (267); trivial changes (79); structural paraphrases (71); phrase reorderings (56); and addition of deletion of information that are claimed to not alter meaning (27). icality and meaning preservation in a large-scale experiment on English. (Max, 2008) explored the use of syntactic dependency preservation during phrase substitution on French. This family of works considered the acquisition of short paraphrases and their use in local paraphrasing of known units. Several works have tackled full sentence paraphrasing as a monolingual translation task relying on Statistical Machine Translation (SMT). For instance, (Quirk et al., 2004) used a phrase-based SMT decoder that uses local paraphrases acquired from comparable corpora to produce monotone sentential paraphrases. (Zhao et al., 2008a) acquired monolingual biphrases from various sources and</context>
</contexts>
<marker>Max, 2008</marker>
<rawString>Aur´elien Max. 2008. Local rephrasing suggestions for supporting the work of writers. In Proceedings of GoTAL, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Elif Yamangil</author>
</authors>
<title>Mining wikipedia’s article revision history for training computational linguistics algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI Workshop on Wikipedia and Artificial Intelligence: An Evolving Synergy,</booktitle>
<location>Chicago, USA.</location>
<contexts>
<context position="3415" citStr="Nelken and Yamangil, 2008" startWordPosition="527" endWordPosition="530">s possible (CallisonBurch et al., 2008). A text revision task is an application of paraphrase generation where context may be used in an effective way. When a local change is made to a text, it occurs within a textual “envelope” within which a paraphrase should fit. In particular, if the original sentence was grammatical, the substituted sentence should remain grammatical and convey essentially the same meaning.2 The manner in which such a context can be exploited depends of course on the type of automatic paraphrasing technique used. In this article, we adopt the pivot 1Recent works such as (Nelken and Yamangil, 2008) have proposed mining the revision histories of collaborative authoring resources like Wikipedia, offering interesting prospects in paraphrasing and rewriting studies. 2We posit here that the revision activity does not involve important semantic changes, as opposed to the rewriting activity. In future work, we will attempt to consider cases of paraphrasing involving meaning changes corresponding to textual entailment phenomena. 18 Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 18–26, Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP approach based on</context>
</contexts>
<marker>Nelken, Yamangil, 2008</marker>
<rawString>Rani Nelken and Elif Yamangil. 2008. Mining wikipedia’s article revision history for training computational linguistics algorithms. In Proceedings of the AAAI Workshop on Wikipedia and Artificial Intelligence: An Evolving Synergy, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Statistical multi-source translation.</title>
<date>2001</date>
<booktitle>In Proceedings of MT Summit,</booktitle>
<location>Santiago de Compostela,</location>
<contexts>
<context position="31343" citStr="Och and Ney, 2001" startWordPosition="5098" endWordPosition="5101">tinctive feature that it targets text fragments that can be larger than phrases traditionally captured by statistical techniques, while not targeting full sentences for which it would be harder to exploit context successfully. More generally, it addresses the case of the paraphrasing of text units for which no paraphrases are directly available. We have identified several issues in our experiments that will constitute our future work. We intend to experiment with several pivot languages and to make them compete to obtain the N-best lists, as done in some approaches to multisource translation (Och and Ney, 2001) and/or to use a consensus technique to select the best paraphrase. 14It should be noted, however, that the reported experiments used relatively small amounts of training data as in most comparable works on context-aware Machine Translation. As regards our context-aware SMT systems, we plan to exploit more complex syntactic knowledge and to learn correspondances for inter-fragment dependencies so as to make our rescoring based on syntactic dependencies more flexible. We are currently working on extracting revision instances from Wikipedia’s revision history, which will provide us with a corpus</context>
</contexts>
<marker>Och, Ney, 2001</marker>
<rawString>Franz Josef Och and Hermann Ney. 2001. Statistical multi-source translation. In Proceedings of MT Summit, Santiago de Compostela, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1991" citStr="Pang et al., 2003" startWordPosition="296" endWordPosition="299">. Most current research efforts on paraphrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human a</context>
<context position="5162" citStr="Pang et al., 2003" startWordPosition="793" endWordPosition="796">ts for which context information from the sentence can be successfully exploited. This article is organized as follows. In section 2, we briefly review related work in paraphrasing and context-aware Machine Translation. We describe the main characteristics of our approach to subsentential paraphrasing in section 3. We then describe an evaluation protocol for evaluating our proposal and report the results of a human evaluation in section 4. We finally conclude and present our future work in section 5. 2 Related work Different sources have been considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora an</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of NAACL/HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
<author>William B Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2011" citStr="Quirk et al., 2004" startWordPosition="300" endWordPosition="303">arch efforts on paraphrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a con</context>
<context position="6851" citStr="Quirk et al., 2004" startWordPosition="1040" endWordPosition="1043">nges (79); structural paraphrases (71); phrase reorderings (56); and addition of deletion of information that are claimed to not alter meaning (27). icality and meaning preservation in a large-scale experiment on English. (Max, 2008) explored the use of syntactic dependency preservation during phrase substitution on French. This family of works considered the acquisition of short paraphrases and their use in local paraphrasing of known units. Several works have tackled full sentence paraphrasing as a monolingual translation task relying on Statistical Machine Translation (SMT). For instance, (Quirk et al., 2004) used a phrase-based SMT decoder that uses local paraphrases acquired from comparable corpora to produce monotone sentential paraphrases. (Zhao et al., 2008a) acquired monolingual biphrases from various sources and used them with a phrase-based SMT decoder, and (Madnani et al., 2007) combined rules of their hierarchical decoders by pivot to obtain a monolingual grammar. These works were not motivated by the generation of high-quality paraphrases that could, for example, be reused in documents. The lack of structural information, the local nature of the paraphrasing performed and the fact that </context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>Chris Quirk, Chris Brockett, and William B. Dolan. 2004. Monolingual machine translation for paraphrase generation. In Proceedings of EMNLP, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Stroppa</author>
<author>Antal van den Bosch</author>
<author>Andy Way</author>
</authors>
<title>Exploiting source similarity for smt using context-informed features.</title>
<date>2007</date>
<booktitle>In Proceedings of TMI, Skvde,</booktitle>
<marker>Stroppa, van den Bosch, Way, 2007</marker>
<rawString>Nicolas Stroppa, Antal van den Bosch, and Andy Way. 2007. Exploiting source similarity for smt using context-informed features. In Proceedings of TMI, Skvde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
</authors>
<title>Pivot language approach for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8513" citStr="Wu and Wang, 2007" startWordPosition="1296" endWordPosition="1299">rpuat and Wu, 2007) disambiguate phrases using a state-ofthe-art WSD classifier, and (Stroppa et al., 2007) use a global memory-based classifier to find appropriate phrase translations in context. Context is often defined as local linguistic features such as surrounding words and their part-of-speech, but some works have experimented with more syntactic features (e.g. (Gimpel and Smith, 2008; Max et al., 2008; Haque et al., 2009)). Using an intermediate pivot language with bilingual translation in which a given language pair is low-resourced has led to improvements in translation performance (Wu and Wang, 2007; Bertoldi et al., 2008), but to our knowledge this approach has not been applied to full sentence paraphrasing. Several reasons may explain this, in particular the relative low quality of current MT approaches on full sentence translation, and the difficulties in controlling what is paraphrased and how. 19 3 Contextual pivot SMT for sub-sentential paraphrasing Although many works have addressed the issue of local paraphrase acquisition, effective use of such paraphrases for paraphrase generation has only be achieved at the level of text units corresponding to short contiguous phrases. Recent </context>
</contexts>
<marker>Wu, Wang, 2007</marker>
<rawString>Hua Wu and Haifeng Wang. 2007. Pivot language approach for phrase-based statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Cheng Niu</author>
<author>Ming Zhou</author>
<author>Sheng Li</author>
</authors>
<title>Combining multiple resources to improve smt-based paraphrasing model.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="2064" citStr="Zhao et al., 2008" startWordPosition="308" endWordPosition="311">the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a consequence, works on paraphrasing have recourse to cost</context>
<context position="5706" citStr="Zhao et al., 2008" startWordPosition="873" endWordPosition="876">een considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses syntactic constraints during phrase substitution, resulting in improvements in both grammat3The types of their paraphrase patterns are the following (numbers in parentheses indicate frequency in their database): phrase replacements (267); trivial changes (79); structural paraphrases (71); phrase reorderings (56); and addit</context>
<context position="7007" citStr="Zhao et al., 2008" startWordPosition="1064" endWordPosition="1067">nd meaning preservation in a large-scale experiment on English. (Max, 2008) explored the use of syntactic dependency preservation during phrase substitution on French. This family of works considered the acquisition of short paraphrases and their use in local paraphrasing of known units. Several works have tackled full sentence paraphrasing as a monolingual translation task relying on Statistical Machine Translation (SMT). For instance, (Quirk et al., 2004) used a phrase-based SMT decoder that uses local paraphrases acquired from comparable corpora to produce monotone sentential paraphrases. (Zhao et al., 2008a) acquired monolingual biphrases from various sources and used them with a phrase-based SMT decoder, and (Madnani et al., 2007) combined rules of their hierarchical decoders by pivot to obtain a monolingual grammar. These works were not motivated by the generation of high-quality paraphrases that could, for example, be reused in documents. The lack of structural information, the local nature of the paraphrasing performed and the fact that the context of the original sentences was not taken into account in the phrase-based approaches make it difficult to control meaning preservation during par</context>
</contexts>
<marker>Zhao, Niu, Zhou, Li, 2008</marker>
<rawString>Shiqi Zhao, Cheng Niu, Ming Zhou, and Sheng Li. 2008a. Combining multiple resources to improve smt-based paraphrasing model. In Proceedings of ACL-HLT, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot approach for extracting paraphrase patterns from bilingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="2064" citStr="Zhao et al., 2008" startWordPosition="308" endWordPosition="311">the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective. A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs. At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue (Connor and Roth, 2007). When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Bannard and Callison-Burch, 2005; Zhao et al., 2008a), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries. Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units (Callison-Burch, 2008; Max, 2008). An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data. Indeed, strictly parallel sentence pairs, for instance, are not naturally produced in human activities.1 As a consequence, works on paraphrasing have recourse to cost</context>
<context position="5706" citStr="Zhao et al., 2008" startWordPosition="873" endWordPosition="876">een considered for paraphrase acquisition techniques. (Pang et al., 2003), for example, apply syntactic fusion to multiple translations of individual sentences. (Barzilay and Lee, 2003; Dolan et al., 2004) acquire short paraphrases from comparable corpora, while (Bhagat and Ravichandran, 2008) considered the issue of acquiring short paraphrase patterns from huge amounts of comparable corpora. (Bannard and Callison-Burch, 2005) introduced a pivot approach to acquire short paraphrases from multilingual parallel corpora, a resource much more readily available than their monolingual counterpart. (Zhao et al., 2008b) acquire paraphrase patterns from bilingual corpora and report the various types obtained.3 (Callison-Burch, 2008) improves the pivot paraphrase acquisition technique by using syntactic constraints at the level of constituents during phrase extraction. This works also uses syntactic constraints during phrase substitution, resulting in improvements in both grammat3The types of their paraphrase patterns are the following (numbers in parentheses indicate frequency in their database): phrase replacements (267); trivial changes (79); structural paraphrases (71); phrase reorderings (56); and addit</context>
<context position="7007" citStr="Zhao et al., 2008" startWordPosition="1064" endWordPosition="1067">nd meaning preservation in a large-scale experiment on English. (Max, 2008) explored the use of syntactic dependency preservation during phrase substitution on French. This family of works considered the acquisition of short paraphrases and their use in local paraphrasing of known units. Several works have tackled full sentence paraphrasing as a monolingual translation task relying on Statistical Machine Translation (SMT). For instance, (Quirk et al., 2004) used a phrase-based SMT decoder that uses local paraphrases acquired from comparable corpora to produce monotone sentential paraphrases. (Zhao et al., 2008a) acquired monolingual biphrases from various sources and used them with a phrase-based SMT decoder, and (Madnani et al., 2007) combined rules of their hierarchical decoders by pivot to obtain a monolingual grammar. These works were not motivated by the generation of high-quality paraphrases that could, for example, be reused in documents. The lack of structural information, the local nature of the paraphrasing performed and the fact that the context of the original sentences was not taken into account in the phrase-based approaches make it difficult to control meaning preservation during par</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008b. Pivot approach for extracting paraphrase patterns from bilingual corpora. In Proceedings of ACL-HLT, Columbus, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>