<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.091456">
<title confidence="0.995612">
Adaptive Information Extraction for Complex Biomedical Tasks
</title>
<author confidence="0.988431">
Donghui Feng Gully Burns Eduard Hovy
</author>
<affiliation confidence="0.880490333333333">
Information Sciences Insitute
University of Southern California
Marina del Rey, CA, 90292
</affiliation>
<email confidence="0.916699">
{donghui, burns, hovy}@isi.edu
</email>
<sectionHeader confidence="0.993538" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998950333333333">
Biomedical information extraction tasks are of-
ten more complex and contain uncertainty at
each step during problem solving processes. We
present an adaptive information extraction
framework and demonstrate how to explore un-
certainty using feedback integration.
</bodyText>
<sectionHeader confidence="0.990417" genericHeader="method">
1 Adaptive Information Extraction
</sectionHeader>
<bodyText confidence="0.999859611111111">
Biomedical information extraction (IE) tasks are
often more complex and contain uncertainty at each
step during problem solving processes.
When in the first place the desired information is
not easy to define and to annotate (even by humans),
iterative IE cycles are to be expected. There might
be gaps between the domain knowledge representa-
tion and computer processing ability. Domain
knowledge might be hard to represent in a clear
format easy for computers to process. Computer sci-
entists may need time to understand the inherent
characteristics of domain problems so as to find ef-
fective approaches to solve them. All these issues
mandate a more expressive IE process.
In these situations, the traditional, straightfor-
ward, and one-pass problem-solving procedure, con-
sisting of definition-learning-testing, is no longer
adequate for the solution.
</bodyText>
<figureCaption confidence="0.99404">
Figure 1. Adaptive information extraction.
</figureCaption>
<bodyText confidence="0.999953458333333">
For more complex tasks requiring iterative cycles,
an adaptive and extended IE framework has not yet
been fully defined although variants have been ex-
plored. We describe an adaptive IE framework to
characterize the activities involved in complex IE
tasks. Figure 1 depicts the adaptive information ex-
traction framework.
This procedure emphasizes one important adap-
tive step between the learning and application
phases. If the IE result is not adequate, some adapta-
tions are required:
Our study focuses on extracting tract-tracing ex-
periments (Swanson, 2004) from neuroscience arti-
cles. The goal of tract-tracing experiment is to chart
the interconnectivity of the brain by injecting tracer
chemicals into a region of the brain and then identi-
fying corresponding labeled regions where the tracer
is transported to (Burns et al., 2007). Our work is
performed in the context of NeuroScholar1, a project
that aims to develop a Knowledge Base Manage-
ment System to benefit neuroscience research.
We show how this new framework evolves to
meet the demands of the more complex scenario of
biomedical text mining.
</bodyText>
<sectionHeader confidence="0.968876" genericHeader="method">
2 Feedback Integration
</sectionHeader>
<bodyText confidence="0.999824571428572">
This task requires finding the knowledge describing
one or more experiments within an article as well as
identifying desired fields within individual sen-
tences. Significant complexity arises from the pres-
ence of a variable number of records (experiments)
in a single research article --- anywhere from one to
many.
</bodyText>
<tableCaption confidence="0.99347">
Table 1. An example tract-tracing experiment.
</tableCaption>
<bodyText confidence="0.917831">
Table 1 provides an example of a tract-tracing ex-
periment. In this experiment, when the tracer was
injected into the injection location “the contralateral
AVCN”, “no labeled cells” was found in the label-
ing location “the DCN”.
For sentence level fields labeling, the perform-
ance of F1 score is around 0.79 (Feng et al., 2008).
</bodyText>
<footnote confidence="0.976053">
1 http://www.neuroscholar.org/
</footnote>
<page confidence="0.7291">
120
</page>
<note confidence="0.610192">
BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120–121,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.99999125">
We here show how the adaptive information extrac-
tion framework is applied to labeling individual sen-
tences. Please see Feng et al. (2007) for the details
of segmenting data records.
</bodyText>
<subsectionHeader confidence="0.997504">
2.1 Choosing Learning Approach via F1
</subsectionHeader>
<bodyText confidence="0.999994">
A natural way to label sentences is to obtain (by
hand or learning) patterns characterizing each field
(Feng et al., 2006; Ravichandran and Hovy, 2002).
We tried to annotate field values for the biomedical
data, but we found few intuitive clues that rich sur-
face text patterns could be learned with this corpus.
This insight, Feedback F1, caused us to give up
the idea of learning surface text patterns as usual,
and switch to the Conditional Random Fields (CRF)
(Lafferty et al., 2001) for labeling sentences instead.
In contrast to fixed-order patterns, the CRF model
provides a compact way to integrate different types
of features for sequential labeling problems and can
reach state-of-the-art level performance.
</bodyText>
<subsectionHeader confidence="0.999261">
2.2 Determining Knowledge Schema via F2
</subsectionHeader>
<bodyText confidence="0.999926875">
In the first place, it is not clear what granularity of
knowledge/information can be extracted from text
and whether the knowledge representation is suitable
for computer processing. We tried a series of ap-
proaches, using different levels of granularity and
description, in order to obtain formulation suitable
for IE. Figure 2 represents the evolution of the
knowledge schema in our repeated activities.
</bodyText>
<figureCaption confidence="0.9999055">
Figure 2. Knowledge schema evolution.
Figure 3. System performance at stage 1 and 2.
</figureCaption>
<bodyText confidence="0.99998875">
We initially started with the schema in the left-
most column but our pilot study showed that some
fields, for example, “label_type”, had too many
variations in text description, making it very hard for
CRF to learn clues about it. We then switched to the
second schema but ended up seeing that the field
“injectionSpread” needed more domain knowledge
and was therefore not able to be learned by the sys-
tems. The last column is the final schema after those
pilot studies. Figure 3 shows system performance
(overall and the worst field) corresponding to the
first and the second representation schemas.
</bodyText>
<subsectionHeader confidence="0.999579">
2.3 Exploring Features via F3
</subsectionHeader>
<bodyText confidence="0.999788142857143">
To train CRF sentence labeling systems, it is vital to
decide what features to use and how to prepare those
features. Through the cycle of Feedback F3, we ex-
plored five categories of features and their combina-
tions to determine the best features for optimal
system performance. Table 2 shows system per-
formance with different feature combinations.
</bodyText>
<table confidence="0.999583352941177">
System Features Prec. Recall F_Score
Baseline 0.4067 0.1761 0.2458
Lexicon 0.5998 0.3734 0.4602
Lexicon 0.7663 0.7302 0.7478
+ Surface Words
Lexicon 0.7717 0.7279 0.7491
+ Surface Words
+ Context Window
Lexicon + Surface 0.8076 0.7451 0.7751
Words + Context
Window + Window
Words
Lexicon + Surface 0.7991 0.7828 0.7909
Words + Context
Window + Window
Words + Depend-
ency Features
</table>
<tableCaption confidence="0.999377">
Table 2. Precision, Recall, and F_Score for labeling.
</tableCaption>
<bodyText confidence="0.8694625">
Please see Feng et al. (2008) for the details of the
sentence level extraction and feature preparation,
</bodyText>
<sectionHeader confidence="0.999642" genericHeader="conclusions">
3 Conclusions
</sectionHeader>
<bodyText confidence="0.9999452">
In this paper, we have shown an adaptive informa-
tion extraction framework for complex biomedical
tasks. Using the iterative development cycle, we
have been able to explore uncertainty at different
levels using feedback integration.
</bodyText>
<sectionHeader confidence="0.999284" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999466526315789">
Burns, G., Feng, D., and Hovy, E.H. 2007. Intelligent Approaches to
Mining the Primary Research Literature: Techniques, Systems, and
Examples. Book Chapter in Computational Intelligence in Bioinfor-
matics, Springer-Verlag, Germany.
Feng, D., Burns, G., and Hovy, E.H. 2007. Extracting Data Records
from Unstructured Biomedical Full Text. In Proc. of EMNLP 2007.
Feng, D., Burns, G., Zhu, J., and Hovy, E.H. 2008. Towards Automated
Semantic Analysis on Biomedical Research Articles. In Proc. of
IJCNLP-2008. Poster Paper.
Feng, D., Ravichandran, D., and Hovy, E.H. 2006. Mining and re-
ranking for answering biographical queries on the web. In Proc. of
AAAI-2006. pp. 1283-1288.
Lafferty, J., McCallum, A. and Pereira, F. 2001. Conditional random
fields: probabilistic models for segmenting and labeling sequence
data. In Proc. of ICML-2001.
Ravichandran, D. and Hovy, E.H. 2002. Learning surface text patterns
for a question answering system. In Proceedings of ACL-2002.
Swanson, L.W. 2004. Brain maps: structure of the rat brain. 3rd edition,
Elsevier Academic Press.
</reference>
<page confidence="0.997869">
121
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001745">
<title confidence="0.99988">Adaptive Information Extraction for Complex Biomedical Tasks</title>
<author confidence="0.999237">Donghui Feng Gully Burns Eduard Hovy</author>
<affiliation confidence="0.9987625">Information Sciences University of Southern</affiliation>
<author confidence="0.738858">Marina del Rey</author>
<author confidence="0.738858">CA</author>
<email confidence="0.997258">donghui@isi.edu</email>
<email confidence="0.997258">burns@isi.edu</email>
<email confidence="0.997258">hovy@isi.edu</email>
<abstract confidence="0.997784353846153">Biomedical information extraction tasks are often more complex and contain uncertainty at each step during problem solving processes. We present an adaptive information extraction framework and demonstrate how to explore uncertainty using feedback integration. 1 Adaptive Information Extraction Biomedical information extraction (IE) tasks are often more complex and contain uncertainty at each step during problem solving processes. When in the first place the desired information is not easy to define and to annotate (even by humans), are to be expected. There might be gaps between the domain knowledge representation and computer processing ability. Domain knowledge might be hard to represent in a clear format easy for computers to process. Computer scientists may need time to understand the inherent characteristics of domain problems so as to find effective approaches to solve them. All these issues mandate a more expressive IE process. In these situations, the traditional, straightforward, and one-pass problem-solving procedure, consisting of definition-learning-testing, is no longer adequate for the solution. Figure 1. Adaptive information extraction. For more complex tasks requiring iterative cycles, an adaptive and extended IE framework has not yet been fully defined although variants have been explored. We describe an adaptive IE framework to characterize the activities involved in complex IE tasks. Figure 1 depicts the adaptive information extraction framework. This procedure emphasizes one important adaptive step between the learning and application phases. If the IE result is not adequate, some adaptations are required: Our study focuses on extracting tract-tracing experiments (Swanson, 2004) from neuroscience articles. The goal of tract-tracing experiment is to chart the interconnectivity of the brain by injecting tracer chemicals into a region of the brain and then identifying corresponding labeled regions where the tracer transported to (Burns 2007). Our work is in the context of a project that aims to develop a Knowledge Base Management System to benefit neuroscience research. We show how this new framework evolves to meet the demands of the more complex scenario of biomedical text mining. 2 Feedback Integration This task requires finding the knowledge describing one or more experiments within an article as well as identifying desired fields within individual sentences. Significant complexity arises from the presence of a variable number of records (experiments) in a single research article --anywhere from one to many. Table 1. An example tract-tracing experiment. Table 1 provides an example of a tract-tracing experiment. In this experiment, when the tracer was injected into the injection location “the contralateral AVCN”, “no labeled cells” was found in the labeling location “the DCN”.</abstract>
<note confidence="0.4602042">For sentence level fields labeling, the performof F1 score is around 0.79 (Feng 2008). 120 2008: Current Trends in Biomedical Natural Language pages 120–121, Ohio, USA, June 2008. Association for Computational Linguistics</note>
<abstract confidence="0.897808971014493">We here show how the adaptive information extraction framework is applied to labeling individual sen- Please see Feng (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field 2006; Ravichandran and Hovy, 2002). We tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus. This insight, Feedback F1, caused us to give up the idea of learning surface text patterns as usual, and switch to the Conditional Random Fields (CRF) 2001) for labeling sentences instead. In contrast to fixed-order patterns, the CRF model provides a compact way to integrate different types of features for sequential labeling problems and can reach state-of-the-art level performance. 2.2 Determining Knowledge Schema via F2 In the first place, it is not clear what granularity of knowledge/information can be extracted from text and whether the knowledge representation is suitable for computer processing. We tried a series of approaches, using different levels of granularity and description, in order to obtain formulation suitable for IE. Figure 2 represents the evolution of the knowledge schema in our repeated activities. Figure 2. Knowledge schema evolution. Figure 3. System performance at stage 1 and 2. We initially started with the schema in the leftmost column but our pilot study showed that some fields, for example, “label_type”, had too many variations in text description, making it very hard for CRF to learn clues about it. We then switched to the second schema but ended up seeing that the field “injectionSpread” needed more domain knowledge and was therefore not able to be learned by the systems. The last column is the final schema after those pilot studies. Figure 3 shows system performance (overall and the worst field) corresponding to the first and the second representation schemas. 2.3 Exploring Features via F3 To train CRF sentence labeling systems, it is vital to decide what features to use and how to prepare those features. Through the cycle of Feedback F3, we explored five categories of features and their combinations to determine the best features for optimal system performance. Table 2 shows system performance with different feature combinations. System Features Prec. Recall F_Score Baseline 0.4067 0.1761 0.2458 Lexicon 0.5998 0.3734 0.4602 Lexicon 0.7663 0.7302 0.7478 + Surface Words Lexicon 0.7717 0.7279 0.7491 + Surface Words + Context Window Lexicon + Surface Words + Context Window + Window Words 0.8076 0.7451 0.7751 Lexicon + Surface Words + Context Window + Window Words + Depend-ency Features 0.7991 0.7828 0.7909 Table 2. Precision, Recall, and F_Score for labeling. see Feng (2008) for the details of the sentence level extraction and feature preparation, 3 Conclusions In this paper, we have shown an adaptive information extraction framework for complex biomedical tasks. Using the iterative development cycle, we have been able to explore uncertainty at different levels using feedback integration.</abstract>
<note confidence="0.907503857142857">References Burns, G., Feng, D., and Hovy, E.H. 2007. Intelligent Approaches to Mining the Primary Research Literature: Techniques, Systems, and Book Chapter in Intelligence in Bioinfor- Springer-Verlag, Germany. Feng, D., Burns, G., and Hovy, E.H. 2007. Extracting Data Records Unstructured Biomedical Full Text. In of EMNLP Feng, D., Burns, G., Zhu, J., and Hovy, E.H. 2008. Towards Automated Analysis on Biomedical Research Articles. In of Poster Paper. Feng, D., Ravichandran, D., and Hovy, E.H. 2006. Mining and refor answering biographical queries on the web. In of pp. 1283-1288. Lafferty, J., McCallum, A. and Pereira, F. 2001. Conditional random</note>
<abstract confidence="0.901674166666667">fields: probabilistic models for segmenting and labeling sequence In of Ravichandran, D. and Hovy, E.H. 2002. Learning surface text patterns a question answering system. In of L.W. 2004. maps: structure of the rat edition, Elsevier Academic Press.</abstract>
<intro confidence="0.572538">121</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Burns</author>
<author>D Feng</author>
<author>E H Hovy</author>
</authors>
<date>2007</date>
<booktitle>Intelligent Approaches to Mining the Primary Research Literature: Techniques, Systems, and Examples. Book Chapter in Computational Intelligence in Bioinformatics,</booktitle>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="2251" citStr="Burns et al., 2007" startWordPosition="329" endWordPosition="332"> activities involved in complex IE tasks. Figure 1 depicts the adaptive information extraction framework. This procedure emphasizes one important adaptive step between the learning and application phases. If the IE result is not adequate, some adaptations are required: Our study focuses on extracting tract-tracing experiments (Swanson, 2004) from neuroscience articles. The goal of tract-tracing experiment is to chart the interconnectivity of the brain by injecting tracer chemicals into a region of the brain and then identifying corresponding labeled regions where the tracer is transported to (Burns et al., 2007). Our work is performed in the context of NeuroScholar1, a project that aims to develop a Knowledge Base Management System to benefit neuroscience research. We show how this new framework evolves to meet the demands of the more complex scenario of biomedical text mining. 2 Feedback Integration This task requires finding the knowledge describing one or more experiments within an article as well as identifying desired fields within individual sentences. Significant complexity arises from the presence of a variable number of records (experiments) in a single research article --- anywhere from one</context>
</contexts>
<marker>Burns, Feng, Hovy, 2007</marker>
<rawString>Burns, G., Feng, D., and Hovy, E.H. 2007. Intelligent Approaches to Mining the Primary Research Literature: Techniques, Systems, and Examples. Book Chapter in Computational Intelligence in Bioinformatics, Springer-Verlag, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Feng</author>
<author>G Burns</author>
<author>E H Hovy</author>
</authors>
<title>Extracting Data Records from Unstructured Biomedical Full Text.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP</booktitle>
<contexts>
<context position="3573" citStr="Feng et al. (2007)" startWordPosition="534" endWordPosition="537">xperiment. In this experiment, when the tracer was injected into the injection location “the contralateral AVCN”, “no labeled cells” was found in the labeling location “the DCN”. For sentence level fields labeling, the performance of F1 score is around 0.79 (Feng et al., 2008). 1 http://www.neuroscholar.org/ 120 BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120–121, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics We here show how the adaptive information extraction framework is applied to labeling individual sentences. Please see Feng et al. (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (Feng et al., 2006; Ravichandran and Hovy, 2002). We tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus. This insight, Feedback F1, caused us to give up the idea of learning surface text patterns as usual, and switch to the Conditional Random Fields (CRF) (Lafferty et al., 2001) for labeling sentences instead</context>
</contexts>
<marker>Feng, Burns, Hovy, 2007</marker>
<rawString>Feng, D., Burns, G., and Hovy, E.H. 2007. Extracting Data Records from Unstructured Biomedical Full Text. In Proc. of EMNLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Feng</author>
<author>G Burns</author>
<author>J Zhu</author>
<author>E H Hovy</author>
</authors>
<title>Towards Automated Semantic Analysis on Biomedical Research Articles.</title>
<date>2008</date>
<booktitle>In Proc. of IJCNLP-2008. Poster Paper.</booktitle>
<contexts>
<context position="3232" citStr="Feng et al., 2008" startWordPosition="487" endWordPosition="490">riments within an article as well as identifying desired fields within individual sentences. Significant complexity arises from the presence of a variable number of records (experiments) in a single research article --- anywhere from one to many. Table 1. An example tract-tracing experiment. Table 1 provides an example of a tract-tracing experiment. In this experiment, when the tracer was injected into the injection location “the contralateral AVCN”, “no labeled cells” was found in the labeling location “the DCN”. For sentence level fields labeling, the performance of F1 score is around 0.79 (Feng et al., 2008). 1 http://www.neuroscholar.org/ 120 BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120–121, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics We here show how the adaptive information extraction framework is applied to labeling individual sentences. Please see Feng et al. (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (Feng et al., 2006; Ravichandran and Hovy, 2002). We tried to annotate fi</context>
</contexts>
<marker>Feng, Burns, Zhu, Hovy, 2008</marker>
<rawString>Feng, D., Burns, G., Zhu, J., and Hovy, E.H. 2008. Towards Automated Semantic Analysis on Biomedical Research Articles. In Proc. of IJCNLP-2008. Poster Paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Feng</author>
<author>D Ravichandran</author>
<author>E H Hovy</author>
</authors>
<title>Mining and reranking for answering biographical queries on the web.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI-2006.</booktitle>
<pages>1283--1288</pages>
<contexts>
<context position="3777" citStr="Feng et al., 2006" startWordPosition="568" endWordPosition="571">labeling, the performance of F1 score is around 0.79 (Feng et al., 2008). 1 http://www.neuroscholar.org/ 120 BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120–121, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics We here show how the adaptive information extraction framework is applied to labeling individual sentences. Please see Feng et al. (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (Feng et al., 2006; Ravichandran and Hovy, 2002). We tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus. This insight, Feedback F1, caused us to give up the idea of learning surface text patterns as usual, and switch to the Conditional Random Fields (CRF) (Lafferty et al., 2001) for labeling sentences instead. In contrast to fixed-order patterns, the CRF model provides a compact way to integrate different types of features for sequential labeling problems and can reach state-of-the-art level performance. 2.2 </context>
</contexts>
<marker>Feng, Ravichandran, Hovy, 2006</marker>
<rawString>Feng, D., Ravichandran, D., and Hovy, E.H. 2006. Mining and reranking for answering biographical queries on the web. In Proc. of AAAI-2006. pp. 1283-1288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of ICML-2001.</booktitle>
<contexts>
<context position="4142" citStr="Lafferty et al., 2001" startWordPosition="630" endWordPosition="633">g individual sentences. Please see Feng et al. (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (Feng et al., 2006; Ravichandran and Hovy, 2002). We tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus. This insight, Feedback F1, caused us to give up the idea of learning surface text patterns as usual, and switch to the Conditional Random Fields (CRF) (Lafferty et al., 2001) for labeling sentences instead. In contrast to fixed-order patterns, the CRF model provides a compact way to integrate different types of features for sequential labeling problems and can reach state-of-the-art level performance. 2.2 Determining Knowledge Schema via F2 In the first place, it is not clear what granularity of knowledge/information can be extracted from text and whether the knowledge representation is suitable for computer processing. We tried a series of approaches, using different levels of granularity and description, in order to obtain formulation suitable for IE. Figure 2 r</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A. and Pereira, F. 2001. Conditional random fields: probabilistic models for segmenting and labeling sequence data. In Proc. of ICML-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ravichandran</author>
<author>E H Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-2002.</booktitle>
<contexts>
<context position="3807" citStr="Ravichandran and Hovy, 2002" startWordPosition="572" endWordPosition="575">rmance of F1 score is around 0.79 (Feng et al., 2008). 1 http://www.neuroscholar.org/ 120 BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 120–121, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics We here show how the adaptive information extraction framework is applied to labeling individual sentences. Please see Feng et al. (2007) for the details of segmenting data records. 2.1 Choosing Learning Approach via F1 A natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (Feng et al., 2006; Ravichandran and Hovy, 2002). We tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus. This insight, Feedback F1, caused us to give up the idea of learning surface text patterns as usual, and switch to the Conditional Random Fields (CRF) (Lafferty et al., 2001) for labeling sentences instead. In contrast to fixed-order patterns, the CRF model provides a compact way to integrate different types of features for sequential labeling problems and can reach state-of-the-art level performance. 2.2 Determining Knowledge Schema v</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Ravichandran, D. and Hovy, E.H. 2002. Learning surface text patterns for a question answering system. In Proceedings of ACL-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L W Swanson</author>
</authors>
<title>Brain maps: structure of the rat brain.</title>
<date>2004</date>
<note>3rd edition,</note>
<contexts>
<context position="1975" citStr="Swanson, 2004" startWordPosition="287" endWordPosition="288">the solution. Figure 1. Adaptive information extraction. For more complex tasks requiring iterative cycles, an adaptive and extended IE framework has not yet been fully defined although variants have been explored. We describe an adaptive IE framework to characterize the activities involved in complex IE tasks. Figure 1 depicts the adaptive information extraction framework. This procedure emphasizes one important adaptive step between the learning and application phases. If the IE result is not adequate, some adaptations are required: Our study focuses on extracting tract-tracing experiments (Swanson, 2004) from neuroscience articles. The goal of tract-tracing experiment is to chart the interconnectivity of the brain by injecting tracer chemicals into a region of the brain and then identifying corresponding labeled regions where the tracer is transported to (Burns et al., 2007). Our work is performed in the context of NeuroScholar1, a project that aims to develop a Knowledge Base Management System to benefit neuroscience research. We show how this new framework evolves to meet the demands of the more complex scenario of biomedical text mining. 2 Feedback Integration This task requires finding th</context>
</contexts>
<marker>Swanson, 2004</marker>
<rawString>Swanson, L.W. 2004. Brain maps: structure of the rat brain. 3rd edition,</rawString>
</citation>
<citation valid="false">
<publisher>Elsevier Academic Press.</publisher>
<marker></marker>
<rawString>Elsevier Academic Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>