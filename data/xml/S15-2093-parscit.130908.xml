<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004461">
<title confidence="0.986254">
UDLAP: Sentiment Analysis Using a Graph Based Representation
</title>
<author confidence="0.989085">
Esteban Castillo&apos;, Ofelia Cervantes&apos;, Darnes Vilari˜no2, David B´aez&apos; and Alfredo S´anchez&apos;
</author>
<affiliation confidence="0.9652755">
&apos;Universidad de las Am´ericas Puebla
Department of Computer Science, Electronics and Mechatronics, Mexico
</affiliation>
<email confidence="0.9600405">
{esteban.castillojz, ofelia.cervantes}@udlap.mx
{david.baez, alfredo.sanchez}@udlap.mx
</email>
<affiliation confidence="0.8902725">
2Benem´erita Universidad Aut´onoma de Puebla
Faculty of Computer Science, Mexico
</affiliation>
<email confidence="0.995146">
darnes@cs.buap.mx
</email>
<sectionHeader confidence="0.995576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998189375">
We present an approach for tackling the Sen-
timent Analysis problem in SemEval 2015.
The approach is based on the use of a co-
occurrence graph to represent existing rela-
tionships among terms in a document with
the aim of using centrality measures to extract
the most representative words that express the
sentiment. These words are then used in a su-
pervised learning algorithm as features to ob-
tain the polarity of unknown documents. The
best results obtained for the different datasets
are: 77.76% for positive, 100% for negative
and 68.04% for neutral, showing that the pro-
posed graph-based representation could be a
way of extracting terms that are relevant to de-
tect a sentiment.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99786606122449">
In the past decade, new forms of communication,
such as microblogging and text messaging have
emerged and become ubiquitous. While there is no
limit to the range of information conveyed by tweets
and texts, often these short messages are used to
share opinions and sentiments that people have
about what is going on in the world around them.
Working with these informal text genres presents
challenges for natural language processing (NLP)
beyond those encountered when working with more
traditional text genres. Typically this kind of texts
are short and the language used is very informal.
We can find creative spelling and punctuation, slang,
new words, URLs, and genre-specific terminology
and abbreviations that make their manipulation more
challenging.
Representing that kind of text for automatically
mining and understanding the opinions and senti-
ments that people communicate inside them has very
recently become an attractive research topic (Pang,
2008). In this sense, the experiments reported in
this paper were carried out in the framework of the
SemEval 20151 (Semantic Evaluation) which has
created a series of tasks for Sentiment Analysis on
Twitter (Rosenthal, 2015). Among the proposed
tasks we find Task 10, subtask B which was named
Message Polarity Classification and was defined
as follows: ”Given a message, classify whether the
message is of positive, negative, or neutral senti-
ment. For messages conveying both a positive and
a negative sentiment, whichever is the stronger sen-
timent should be chosen”. In order to solve this task
we create an approach that uses a graph based rep-
resentation to extract relevant words that are used
in a supervised learning method to classify a set of
unknown documents in different topics and genres
provided by the SemEval team. The methodology
for our approach is discussed in detail in the next
sections.
The rest of the paper is structured as follows. In
Section 2 we present some related work found in the
literature with respect to the identification of senti-
ments in text documents. In Section 3 a graph based
representation is proposed. In Section 4 the method-
ology and the tools used to detect the sentiments of
a set of unknown documents are explained. In Sec-
tion 5, the experimental results are presented and
discussed. Finally, in Section 6 the conclusions as
well as further work are described.
</bodyText>
<footnote confidence="0.993158">
1http://alt.qcri.org/semeval2015/
</footnote>
<page confidence="0.977744">
556
</page>
<note confidence="0.6124685">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 556–560,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.999023" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999859375">
There exist a number of works in literature associ-
ated to the automatic identification of sentiments in
documents. Some of these works have focused on
the contribution of particular features, such as the
use of the vocabulary to extract lexical elements as-
sociated to the documents (Kim, 2006), the use of
bigrams and trigrams (Dave, 2008) to capture syn-
tactic features of texts associated with a sentiment,
the use of dictionaries and emoticons of positive and
negative words (Agarwal, 2011) as well as lexical-
syntactic features or the use of Part of Speech tags
(PoS) (Wilks, 1999; Whitelaw, 2005) as syntactic
features that can help to disambiguate the polarity
of the words in a context.
In the other hand, many contributions focused on
the use of structures to represent the features asso-
ciated to a document like the frequency of occur-
rence vector (Wrobel, 2002; Aizawa, 2003; Serrano,
2006). Finally, linear representation of documents
features combined with the use of a Support Vector
Machine (SVM) has shown great performance in the
tasks associated with the classification of texts (Vap-
nik, 1995; Joachims, 1998).
Research works that use graph representations for
texts in the context of Sentiment Analysis barely ap-
pear in the literature (Pinto, 2014; Poria, 2014). It
usually has been proposed the concept of n-grams
with a frequency of occurrence vector to solved it
(Pang, 2008). However, there is still an enormous
gap between this approach and the use of more de-
tailed graph structures that represent in a natural way
the lexical, semantic and stylistic features.
</bodyText>
<sectionHeader confidence="0.997193" genericHeader="method">
3 Graph-Based Representation
</sectionHeader>
<bodyText confidence="0.97884175">
Among different proposals for mapping texts to
graphs, the co-occurrence of words (Sonawane,
2014) has become a simple but effective way to rep-
resent the relationship of one term over another one
in texts where there is no syntactic order (usually
social media texts like Twitter or SMS). Formally
the proposed co-ocurrence graph is represented by
G = (V, E, L, α), where:
</bodyText>
<listItem confidence="0.9991065">
• V = {vi|i = 1, ..., n} is a finite set of vertices
that consists of the words contained in one or
several texts.
• E ⊆ V x V is the finite set of edges which
</listItem>
<bodyText confidence="0.655963">
represents that two vertices are connected by
means of the co- occurrence, where:
– Two vertices are connected if their cor-
responding lexical units co-occur within
a window of maximum N words, where
N can be set to any value (typically be-
tween two and ten words).
</bodyText>
<listItem confidence="0.9757204">
• L is the edges tag set which consists of the
number of times that two vertices co-occur in
a text window.
• α : E → L is a function that assigns a tag to a
pair of associated vertices.
</listItem>
<bodyText confidence="0.997431636363636">
As an example, consider the following sentence C
extracted from a text T in the dataset: “They may
have a SuperBowl in Dallas, but Dallas ain’t win-
ning a SuperBowl. Not with that quarterback and
owner, they are really bad.”, which after the prepro-
cessing stage (see Section 4) would be as follows:
“may have SuperBowl Dallas Dallas ain’t winning
SuperBowl quarterback owner are bad”. Based on
the proposed representation, preprocessed sentence
C can be mapped to the proposed co-ocurrence graph
shown in Figure 1.
</bodyText>
<figureCaption confidence="0.999811">
Figure 1: co-ocurrence graph example
</figureCaption>
<figure confidence="0.998947352112676">
1
may
V2
Super
bowl
V9
V3
are
VB
1
1
Vs
quarter
back
V1
V10
bad
1
have
1
1
2
1
1
Dallas
V4
1
1
owner
1
1
ain´t
V7
1
winning
V6
557
SemEval 2015 Dataset
...
Positive
texts
Preprocess documents
Graph representation
...
Training phase
Neutral
texts
...
Negative
texts
2
Graph for
all documents
Centrality
measures
1
3
SVM
polynomial kernel
Training file Test file
Test vectors
... ...
Feature extraction
Test phase
Training vectors
5
Model
frequency vectors of
extracted features
Result
4
</figure>
<figureCaption confidence="0.999637">
Figure 2: Sentiment Analysis Process
</figureCaption>
<bodyText confidence="0.9991945">
The co-occurrence graph shown in figure 1 has the
following features:
</bodyText>
<listItem confidence="0.999170222222222">
• Terms co-occur within a window of 3 words.
• The set of vertices consists of the preprocessed
words in sentence ζ.
• An edge between two vertices represent that
both words appear in the same co-occurrence
window (at least once).
• The label edge between two vertices represents
the number of times that two words appear in a
co-occurrence window in sentence ζ.
</listItem>
<sectionHeader confidence="0.7735785" genericHeader="method">
4 Sentiment Analysis Process Using A
Graph Representation
</sectionHeader>
<bodyText confidence="0.917984833333333">
Figure 2 shows the methodology used to detect the
sentiments associated to a set of unknown docu-
ments, considering the use of graphs to extract the
most relevant words associated to the documents.
The methodology consists of five steps:
1. Preprocess all documents associated with the
SemEval 2015 dataset. This task includes elim-
ination of punctuation symbols and all the ele-
ments that are not part of the ASCII encoding.
Then, each preprocessed sentence in a text is
tagged with its corresponding PoS tags, for this
step, the TreeTagger tool2 was used.
</bodyText>
<listItem confidence="0.967398894736842">
2. Map only the nouns, verbs and adjectives of all
documents in the training set to a graph repre-
sentation (see section 3).
3. Apply the Degree and Closeness centrality
measures (Freeman, 1979) which are indicators
that identify the most important vertices within
a graph, where:
• The Degree centrality is defined as the
number of links incident upon a vertex in
the graph and is used to find the topologi-
cally representative words.
• The Closeness centrality is defined as the
average sum of the shortest paths from one
vertex to the others in the graph and is
used to find the most accessible words in
the graph which consequently are syntac-
tically relevant.
4. For each document in the training and test col-
lection extract the top 100 ranked vertices (the
</listItem>
<footnote confidence="0.969858">
2www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
</footnote>
<page confidence="0.997456">
558
</page>
<tableCaption confidence="0.999479">
Table 2: Evaluation of the graph model approach using the test dataset
</tableCaption>
<table confidence="0.99954675">
Test Dataset Methodology % Correct % Correct % Correct % Overall Baseline
Runtime Positive Negative Neutral score
Official 2015 Test 00:04:56 70.90 43.23 52.06 42.10 30.28
LiveJournal 2014 00:05:14 63.95 59.57 48.82 50.11 29.2
SMS 2013 00:05:14 52.16 42.56 68.04 39.35 19.0
Twitter 2013 00:05:14 70.44 44.49 54.69 41.93 34.6
Twitter 2014 00:05:14 77.76 45.00 49.50 45.93 27.7
Twitter Sarcasm 00:05:14 50.00 100.00 26.32 41.04 27.2
</table>
<bodyText confidence="0.9171623">
most important words in the graph) from both
centrality measures in the graph without repe-
tition and use them to build a frequency of oc-
currence vector (Manning, 2008).
5. Apply a SVM classifier (Harrington, 2012)
with a polynomial kernel implemented in the
scikit-learn3 platform (Pedregosa, 2011), in or-
der to construct a classification model which is
used for determining the sentiment of a given
anonymous document.
</bodyText>
<sectionHeader confidence="0.988446" genericHeader="evaluation">
5 Experimental results
</sectionHeader>
<bodyText confidence="0.99985375">
The results obtained with the proposed approach are
discussed in this section. First, we describe the
dataset used in the experiments and, thereafter, the
results obtained.
</bodyText>
<subsectionHeader confidence="0.984608">
5.1 Dataset
</subsectionHeader>
<bodyText confidence="0.998197">
The description of the three text collections used in
the experiments for the SemEval 2015 is shown in
the next table:
</bodyText>
<tableCaption confidence="0.9404365">
Table 1: Datasets used in the Sentiment Analysis
problems
</tableCaption>
<table confidence="0.96733875">
Dataset Name # Documents
Training Development 7493
Test Official 2015 Test 2390
Test Progress Test 8987
</table>
<bodyText confidence="0.9969354">
The test corpus was made up of short texts (mes-
sages) categorized as: ”Progress Test” and Offi-
cial 2015 Test. The Progress Test includes the fol-
lowing datasets: LiveJournal2014, SMS2013, Twit-
ter2013, Twitter2014 and Twitter2014Sarcasm. A
</bodyText>
<footnote confidence="0.798241">
3http://scikit-learn.org/stable/
</footnote>
<bodyText confidence="0.98105">
complete description of the training and test datasets
can be found at the task description paper (Rosen-
thal, 2015).
</bodyText>
<subsectionHeader confidence="0.999217">
5.2 Obtained results
</subsectionHeader>
<bodyText confidence="0.999911941176471">
In Table 2 we present results obtained with each
dataset considered in the SemEval 2015 competi-
tion. The results were evaluated according to the
(F1pos + F1neg)/2 measure (Rosenthal, 2014) for
the overall score and the precision measure (Man-
ning, 2008) for each one of the sentiments. Our
approach performed in all cases above the base-
line. We consider that these results were obtained
even though the training corpus was very unbal-
anced (there were more positive texts than others)
and there was a high difference between the vocabu-
lary of the training and test datasets. Further anal-
ysis on the use of centrality measures and on the
methodology for constructing the graph will allow
us to find more accurate features that can be used
in a supervised learning method for the Sentiment
Analysis problem.
</bodyText>
<sectionHeader confidence="0.999498" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999909166666667">
We have presented an approach that uses a super-
vised learning method with a graph based repre-
sentation. The results obtained show a competitive
performance that is above the baseline score. The
model presents a good performance on the Twitter
dataset. However, there is still a great deal to im-
prove on the LiveJournal and SMS datasets where
the text could be smaller and the use of slang and
genre-specific terminology is usual. One of the con-
tributions of this paper is that we use a graph based
representation (with an excellent runtime) with cen-
trality measures to discover words related to each
</bodyText>
<page confidence="0.994435">
559
</page>
<bodyText confidence="0.869111142857143">
sentiment instead of using traditional features like n-
grams and vocabulary. As further work we propose
the following:
• Experiment with other graph representations
for texts that include alternative levels of lan-
guage descriptions such as the use of sentence
chunks, pragmatic sentences, etc.
</bodyText>
<listItem confidence="0.887448142857143">
• Apply the graph representation described in
this paper to the Authorship Attribution prob-
lem (Holmes, 1994), where training and test
data sets are balanced and belong to the same
linguistic domain.
• Explore different supervised/unsupervised
classification algorithms.
</listItem>
<sectionHeader confidence="0.998253" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.8318205">
This work was partially supported by the REAU-
MOBILE Proyect: CONACYT-OSEO no. 192321
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99973627027027">
Agarwal A., Xie B., Vovsha I., Rambow O., Passonneau
R. 2011. Sentiment Analysis of Twitter Data. Pro-
ceedings of the Workshop on Languages in Social Me-
dia. Stroudsburg, PA, USA, 30-38.
Aizawa, A. 2003. An information-theoretic perspective
of tf-idf measures. Journal of Information Processing
and Management, 39, 45–65.
Dave, S. L. K. and Pennock, D. M. 2003. Mining
the Peanut Gallery: Opinion Extraction and Seman-
tic Classification of Product Reviews, Proceedings of
the 12th International Conference on World Wide Web.
New York, NY, USA, 519-528.
Freeman, L.C. 1979. Centrality in Social Networks:
Conceptual Clarification. Journal of Social Networks,
1, 215–239.
Harrington, P. 2012. Machine Learning in Action. Man-
ning Publications Co., Greenwich, CT, USA.
Holmes, D. 1999. Authorship Attribution. Journal of
Computers and the Humanities, 28, 87–106.
Joachims, T. 1998. Text Categorization with Suport Vec-
tor Machines: Learning with Many Relevant Features,
Proceedings of the 10th European Conference on Ma-
chine Learning, London, UK, 137–142.
Kim, S.-M. and Hovy, E. 2006. Automatic Identification
of Pro and Con Reasons in Online Reviews. Proceed-
ings of the COLING/ACL Main Conference Poster
Sessions, Stroudsburg, PA, USA, 483–490.
Manning, C. D., Raghavan, P. and Sch¨utze, H. 2008. In-
troduction to Information Retrieval. Cambridge Uni-
versity Press, New York, NY, USA.
Pang, Bo and Lee, Lillian. 2008. Analysis mining opin-
ion sentiment. Journal of Foundations and Trends in
Information Retrieval, 2, 1–135.
Pedregosa, F. 2011. Scikit-learn: Machine Learning in
Python, Journal of Machine Learning Research, 12,
2825–2830.
Pinto, D., Vilari˜no D., Leon S., Jasso M., and Lucero C.
2014. BUAP: Polarity Classification of Short Texts,
Proceedings of the 8th International Workshop on Se-
mantic Evaluation (SemEval 2014), Dublin, Ireland,
154–159.
Poria S., Cambria E., Winterstein G., Huang H. 2014.
Sentic patterns: Dependency-based rules for concept-
level sentiment analysis, Journal of Knowledge-Based
Systems USA.
Rosenthal S., Nakov P., Kiritchenko S., Mohammad S.,
Ritter A., Stoyanov V. 2014. SemEval-2014 Task
9: Sentiment Analysis in Twitter, Proceedings of the
8th International Workshop on Semantic Evaluation,
Dublin, Ireland, 73–80.
Rosenthal S., Nakov P., Kiritchenko S., Mohammad S.,
Ritter A., Stoyanov V. 2015. SemEval-2015 Task 10:
Sentiment Analysis in Twitter, Proceedings of the 9th
International Workshop on Semantic Evaluation, Den-
ver, Colorado, USA.
Serrano, J. and del Castillo, M. 2006. Text Representa-
tion by a Computational Model of Reading. Journal of
Neural Information Processing, 237–246.
Sonawane S and Kulkarni P. 2014. Graph based Rep-
resentation and Analysis of Text Document: A Sur-
vey of Techniques. Journal of Computer Applications,
96(19):1-8.
Vapnik, V. N. 1995. The Nature of Statistical Learning
Theory. Springer. New York, NY, USA.
Whitelaw, C., Garg, N. and Argamon, S. 2005. Using
appraisal groups for sentiment analysis. Proceedings
of the ACM SIGIR Conference on Information and
Knowledge, New York, NY, USA, 625–631.
Wilks, Y. and Stevenson, M. 1999. The Grammar of
Sense: Using part-of-speech tags as a first step in se-
mantic disambiguation. Journal of Natural Language
Engineering, 4(3), 4.
Wrobel, S. and Scheffer, T. 2002. Text Classication Be-
yond the Bag-of-Words Representation.
</reference>
<page confidence="0.996991">
560
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.571673">
<title confidence="0.998944">UDLAP: Sentiment Analysis Using a Graph Based Representation</title>
<author confidence="0.984617">Ofelia Darnes David</author>
<affiliation confidence="0.9021635">de las Am´ericas Department of Computer Science, Electronics and Mechatronics, Universidad Aut´onoma de Faculty of Computer Science,</affiliation>
<email confidence="0.963269">darnes@cs.buap.mx</email>
<abstract confidence="0.998495352941176">We present an approach for tackling the Sentiment Analysis problem in SemEval 2015. The approach is based on the use of a cooccurrence graph to represent existing relationships among terms in a document with the aim of using centrality measures to extract the most representative words that express the sentiment. These words are then used in a supervised learning algorithm as features to obtain the polarity of unknown documents. The best results obtained for the different datasets are: 77.76% for positive, 100% for negative and 68.04% for neutral, showing that the proposed graph-based representation could be a way of extracting terms that are relevant to detect a sentiment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Agarwal</author>
<author>B Xie</author>
<author>I Vovsha</author>
<author>O Rambow</author>
<author>R Passonneau</author>
</authors>
<title>Sentiment Analysis of Twitter Data.</title>
<date>2011</date>
<booktitle>Proceedings of the Workshop on Languages in Social Media.</booktitle>
<pages>30--38</pages>
<location>Stroudsburg, PA, USA,</location>
<marker>Agarwal, Xie, Vovsha, Rambow, Passonneau, 2011</marker>
<rawString>Agarwal A., Xie B., Vovsha I., Rambow O., Passonneau R. 2011. Sentiment Analysis of Twitter Data. Proceedings of the Workshop on Languages in Social Media. Stroudsburg, PA, USA, 30-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aizawa</author>
</authors>
<title>An information-theoretic perspective of tf-idf measures.</title>
<date>2003</date>
<journal>Journal of Information Processing and Management,</journal>
<volume>39</volume>
<pages>45--65</pages>
<contexts>
<context position="4635" citStr="Aizawa, 2003" startWordPosition="721" endWordPosition="722">he documents (Kim, 2006), the use of bigrams and trigrams (Dave, 2008) to capture syntactic features of texts associated with a sentiment, the use of dictionaries and emoticons of positive and negative words (Agarwal, 2011) as well as lexicalsyntactic features or the use of Part of Speech tags (PoS) (Wilks, 1999; Whitelaw, 2005) as syntactic features that can help to disambiguate the polarity of the words in a context. In the other hand, many contributions focused on the use of structures to represent the features associated to a document like the frequency of occurrence vector (Wrobel, 2002; Aizawa, 2003; Serrano, 2006). Finally, linear representation of documents features combined with the use of a Support Vector Machine (SVM) has shown great performance in the tasks associated with the classification of texts (Vapnik, 1995; Joachims, 1998). Research works that use graph representations for texts in the context of Sentiment Analysis barely appear in the literature (Pinto, 2014; Poria, 2014). It usually has been proposed the concept of n-grams with a frequency of occurrence vector to solved it (Pang, 2008). However, there is still an enormous gap between this approach and the use of more deta</context>
</contexts>
<marker>Aizawa, 2003</marker>
<rawString>Aizawa, A. 2003. An information-theoretic perspective of tf-idf measures. Journal of Information Processing and Management, 39, 45–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L K Dave</author>
<author>D M Pennock</author>
</authors>
<title>Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews,</title>
<date>2003</date>
<booktitle>Proceedings of the 12th International Conference on World Wide Web.</booktitle>
<pages>519--528</pages>
<location>New York, NY, USA,</location>
<marker>Dave, Pennock, 2003</marker>
<rawString>Dave, S. L. K. and Pennock, D. M. 2003. Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews, Proceedings of the 12th International Conference on World Wide Web. New York, NY, USA, 519-528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L C Freeman</author>
</authors>
<title>Centrality in Social Networks: Conceptual Clarification.</title>
<date>1979</date>
<journal>Journal of Social Networks,</journal>
<volume>1</volume>
<pages>215--239</pages>
<contexts>
<context position="8661" citStr="Freeman, 1979" startWordPosition="1417" endWordPosition="1418">o extract the most relevant words associated to the documents. The methodology consists of five steps: 1. Preprocess all documents associated with the SemEval 2015 dataset. This task includes elimination of punctuation symbols and all the elements that are not part of the ASCII encoding. Then, each preprocessed sentence in a text is tagged with its corresponding PoS tags, for this step, the TreeTagger tool2 was used. 2. Map only the nouns, verbs and adjectives of all documents in the training set to a graph representation (see section 3). 3. Apply the Degree and Closeness centrality measures (Freeman, 1979) which are indicators that identify the most important vertices within a graph, where: • The Degree centrality is defined as the number of links incident upon a vertex in the graph and is used to find the topologically representative words. • The Closeness centrality is defined as the average sum of the shortest paths from one vertex to the others in the graph and is used to find the most accessible words in the graph which consequently are syntactically relevant. 4. For each document in the training and test collection extract the top 100 ranked vertices (the 2www.ims.uni-stuttgart.de/projekt</context>
</contexts>
<marker>Freeman, 1979</marker>
<rawString>Freeman, L.C. 1979. Centrality in Social Networks: Conceptual Clarification. Journal of Social Networks, 1, 215–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Harrington</author>
</authors>
<title>Machine Learning in Action.</title>
<date>2012</date>
<publisher>Manning Publications Co.,</publisher>
<location>Greenwich, CT, USA.</location>
<contexts>
<context position="10002" citStr="Harrington, 2012" startWordPosition="1633" endWordPosition="1634">Correct % Correct % Correct % Overall Baseline Runtime Positive Negative Neutral score Official 2015 Test 00:04:56 70.90 43.23 52.06 42.10 30.28 LiveJournal 2014 00:05:14 63.95 59.57 48.82 50.11 29.2 SMS 2013 00:05:14 52.16 42.56 68.04 39.35 19.0 Twitter 2013 00:05:14 70.44 44.49 54.69 41.93 34.6 Twitter 2014 00:05:14 77.76 45.00 49.50 45.93 27.7 Twitter Sarcasm 00:05:14 50.00 100.00 26.32 41.04 27.2 most important words in the graph) from both centrality measures in the graph without repetition and use them to build a frequency of occurrence vector (Manning, 2008). 5. Apply a SVM classifier (Harrington, 2012) with a polynomial kernel implemented in the scikit-learn3 platform (Pedregosa, 2011), in order to construct a classification model which is used for determining the sentiment of a given anonymous document. 5 Experimental results The results obtained with the proposed approach are discussed in this section. First, we describe the dataset used in the experiments and, thereafter, the results obtained. 5.1 Dataset The description of the three text collections used in the experiments for the SemEval 2015 is shown in the next table: Table 1: Datasets used in the Sentiment Analysis problems Dataset </context>
</contexts>
<marker>Harrington, 2012</marker>
<rawString>Harrington, P. 2012. Machine Learning in Action. Manning Publications Co., Greenwich, CT, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Holmes</author>
</authors>
<title>Authorship Attribution.</title>
<date>1999</date>
<journal>Journal of Computers and the Humanities,</journal>
<volume>28</volume>
<pages>87--106</pages>
<marker>Holmes, 1999</marker>
<rawString>Holmes, D. 1999. Authorship Attribution. Journal of Computers and the Humanities, 28, 87–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text Categorization with Suport Vector Machines: Learning with Many Relevant Features,</title>
<date>1998</date>
<booktitle>Proceedings of the 10th European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<location>London, UK,</location>
<contexts>
<context position="4877" citStr="Joachims, 1998" startWordPosition="757" endWordPosition="758">calsyntactic features or the use of Part of Speech tags (PoS) (Wilks, 1999; Whitelaw, 2005) as syntactic features that can help to disambiguate the polarity of the words in a context. In the other hand, many contributions focused on the use of structures to represent the features associated to a document like the frequency of occurrence vector (Wrobel, 2002; Aizawa, 2003; Serrano, 2006). Finally, linear representation of documents features combined with the use of a Support Vector Machine (SVM) has shown great performance in the tasks associated with the classification of texts (Vapnik, 1995; Joachims, 1998). Research works that use graph representations for texts in the context of Sentiment Analysis barely appear in the literature (Pinto, 2014; Poria, 2014). It usually has been proposed the concept of n-grams with a frequency of occurrence vector to solved it (Pang, 2008). However, there is still an enormous gap between this approach and the use of more detailed graph structures that represent in a natural way the lexical, semantic and stylistic features. 3 Graph-Based Representation Among different proposals for mapping texts to graphs, the co-occurrence of words (Sonawane, 2014) has become a s</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Joachims, T. 1998. Text Categorization with Suport Vector Machines: Learning with Many Relevant Features, Proceedings of the 10th European Conference on Machine Learning, London, UK, 137–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Automatic Identification of Pro and Con Reasons in Online Reviews.</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL Main Conference Poster Sessions,</booktitle>
<pages>483--490</pages>
<location>Stroudsburg, PA, USA,</location>
<marker>Kim, Hovy, 2006</marker>
<rawString>Kim, S.-M. and Hovy, E. 2006. Automatic Identification of Pro and Con Reasons in Online Reviews. Proceedings of the COLING/ACL Main Conference Poster Sessions, Stroudsburg, PA, USA, 483–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Manning, C. D., Raghavan, P. and Sch¨utze, H. 2008. Introduction to Information Retrieval. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Analysis mining opinion sentiment.</title>
<date>2008</date>
<journal>Journal of Foundations and Trends in Information Retrieval,</journal>
<volume>2</volume>
<pages>1--135</pages>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, Bo and Lee, Lillian. 2008. Analysis mining opinion sentiment. Journal of Foundations and Trends in Information Retrieval, 2, 1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pedregosa</author>
</authors>
<title>Scikit-learn: Machine Learning in Python,</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>12</volume>
<pages>2825--2830</pages>
<contexts>
<context position="10087" citStr="Pedregosa, 2011" startWordPosition="1644" endWordPosition="1645"> Official 2015 Test 00:04:56 70.90 43.23 52.06 42.10 30.28 LiveJournal 2014 00:05:14 63.95 59.57 48.82 50.11 29.2 SMS 2013 00:05:14 52.16 42.56 68.04 39.35 19.0 Twitter 2013 00:05:14 70.44 44.49 54.69 41.93 34.6 Twitter 2014 00:05:14 77.76 45.00 49.50 45.93 27.7 Twitter Sarcasm 00:05:14 50.00 100.00 26.32 41.04 27.2 most important words in the graph) from both centrality measures in the graph without repetition and use them to build a frequency of occurrence vector (Manning, 2008). 5. Apply a SVM classifier (Harrington, 2012) with a polynomial kernel implemented in the scikit-learn3 platform (Pedregosa, 2011), in order to construct a classification model which is used for determining the sentiment of a given anonymous document. 5 Experimental results The results obtained with the proposed approach are discussed in this section. First, we describe the dataset used in the experiments and, thereafter, the results obtained. 5.1 Dataset The description of the three text collections used in the experiments for the SemEval 2015 is shown in the next table: Table 1: Datasets used in the Sentiment Analysis problems Dataset Name # Documents Training Development 7493 Test Official 2015 Test 2390 Test Progress</context>
</contexts>
<marker>Pedregosa, 2011</marker>
<rawString>Pedregosa, F. 2011. Scikit-learn: Machine Learning in Python, Journal of Machine Learning Research, 12, 2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pinto</author>
<author>D Vilari˜no</author>
<author>S Leon</author>
<author>M Jasso</author>
<author>C Lucero</author>
</authors>
<title>BUAP: Polarity Classification of Short Texts,</title>
<date>2014</date>
<booktitle>Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<pages>154--159</pages>
<location>Dublin, Ireland,</location>
<marker>Pinto, Vilari˜no, Leon, Jasso, Lucero, 2014</marker>
<rawString>Pinto, D., Vilari˜no D., Leon S., Jasso M., and Lucero C. 2014. BUAP: Polarity Classification of Short Texts, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Ireland, 154–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Poria</author>
<author>E Cambria</author>
<author>G Winterstein</author>
<author>H Huang</author>
</authors>
<title>Sentic patterns: Dependency-based rules for conceptlevel sentiment analysis,</title>
<date>2014</date>
<journal>Journal of Knowledge-Based Systems USA.</journal>
<marker>Poria, Cambria, Winterstein, Huang, 2014</marker>
<rawString>Poria S., Cambria E., Winterstein G., Huang H. 2014. Sentic patterns: Dependency-based rules for conceptlevel sentiment analysis, Journal of Knowledge-Based Systems USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rosenthal</author>
<author>P Nakov</author>
<author>S Kiritchenko</author>
<author>S Mohammad</author>
<author>A Ritter</author>
<author>V Stoyanov</author>
</authors>
<date>2014</date>
<booktitle>SemEval-2014 Task 9: Sentiment Analysis in Twitter, Proceedings of the 8th International Workshop on Semantic Evaluation,</booktitle>
<pages>73--80</pages>
<location>Dublin, Ireland,</location>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2014</marker>
<rawString>Rosenthal S., Nakov P., Kiritchenko S., Mohammad S., Ritter A., Stoyanov V. 2014. SemEval-2014 Task 9: Sentiment Analysis in Twitter, Proceedings of the 8th International Workshop on Semantic Evaluation, Dublin, Ireland, 73–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rosenthal</author>
<author>P Nakov</author>
<author>S Kiritchenko</author>
<author>S Mohammad</author>
<author>A Ritter</author>
<author>V Stoyanov</author>
</authors>
<date>2015</date>
<booktitle>SemEval-2015 Task 10: Sentiment Analysis in Twitter, Proceedings of the 9th International Workshop on Semantic Evaluation,</booktitle>
<location>Denver, Colorado, USA.</location>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2015</marker>
<rawString>Rosenthal S., Nakov P., Kiritchenko S., Mohammad S., Ritter A., Stoyanov V. 2015. SemEval-2015 Task 10: Sentiment Analysis in Twitter, Proceedings of the 9th International Workshop on Semantic Evaluation, Denver, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Serrano</author>
<author>del Castillo</author>
<author>M</author>
</authors>
<title>Text Representation by a Computational Model of Reading.</title>
<date>2006</date>
<journal>Journal of Neural Information Processing,</journal>
<pages>237--246</pages>
<marker>Serrano, Castillo, M, 2006</marker>
<rawString>Serrano, J. and del Castillo, M. 2006. Text Representation by a Computational Model of Reading. Journal of Neural Information Processing, 237–246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sonawane</author>
<author>P Kulkarni</author>
</authors>
<title>Graph based Representation and Analysis of Text Document: A Survey of Techniques.</title>
<date>2014</date>
<journal>Journal of Computer Applications,</journal>
<pages>96--19</pages>
<marker>Sonawane, Kulkarni, 2014</marker>
<rawString>Sonawane S and Kulkarni P. 2014. Graph based Representation and Analysis of Text Document: A Survey of Techniques. Journal of Computer Applications, 96(19):1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4860" citStr="Vapnik, 1995" startWordPosition="754" endWordPosition="756">s well as lexicalsyntactic features or the use of Part of Speech tags (PoS) (Wilks, 1999; Whitelaw, 2005) as syntactic features that can help to disambiguate the polarity of the words in a context. In the other hand, many contributions focused on the use of structures to represent the features associated to a document like the frequency of occurrence vector (Wrobel, 2002; Aizawa, 2003; Serrano, 2006). Finally, linear representation of documents features combined with the use of a Support Vector Machine (SVM) has shown great performance in the tasks associated with the classification of texts (Vapnik, 1995; Joachims, 1998). Research works that use graph representations for texts in the context of Sentiment Analysis barely appear in the literature (Pinto, 2014; Poria, 2014). It usually has been proposed the concept of n-grams with a frequency of occurrence vector to solved it (Pang, 2008). However, there is still an enormous gap between this approach and the use of more detailed graph structures that represent in a natural way the lexical, semantic and stylistic features. 3 Graph-Based Representation Among different proposals for mapping texts to graphs, the co-occurrence of words (Sonawane, 201</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vapnik, V. N. 1995. The Nature of Statistical Learning Theory. Springer. New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Whitelaw</author>
<author>N Garg</author>
<author>S Argamon</author>
</authors>
<title>Using appraisal groups for sentiment analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the ACM SIGIR Conference on Information and Knowledge,</booktitle>
<pages>625--631</pages>
<location>New York, NY, USA,</location>
<marker>Whitelaw, Garg, Argamon, 2005</marker>
<rawString>Whitelaw, C., Garg, N. and Argamon, S. 2005. Using appraisal groups for sentiment analysis. Proceedings of the ACM SIGIR Conference on Information and Knowledge, New York, NY, USA, 625–631.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>M Stevenson</author>
</authors>
<title>The Grammar of Sense: Using part-of-speech tags as a first step in semantic disambiguation.</title>
<date>1999</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>4</volume>
<issue>3</issue>
<pages>4</pages>
<marker>Wilks, Stevenson, 1999</marker>
<rawString>Wilks, Y. and Stevenson, M. 1999. The Grammar of Sense: Using part-of-speech tags as a first step in semantic disambiguation. Journal of Natural Language Engineering, 4(3), 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wrobel</author>
<author>T Scheffer</author>
</authors>
<title>Text Classication Beyond the Bag-of-Words Representation.</title>
<date>2002</date>
<marker>Wrobel, Scheffer, 2002</marker>
<rawString>Wrobel, S. and Scheffer, T. 2002. Text Classication Beyond the Bag-of-Words Representation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>