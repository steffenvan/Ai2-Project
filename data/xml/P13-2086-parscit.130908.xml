<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002544">
<title confidence="0.997505">
A Novel Text Classifier Based on Quantum Computation
</title>
<author confidence="0.999752">
Ding Liu, Xiaofang Yang, Minghu Jiang
</author>
<affiliation confidence="0.957574">
Laboratory of Computational Linguistics, School of Humanities,
Tsinghua University, Beijing , China
</affiliation>
<email confidence="0.8602245">
Dingliu_thu@126.com xfyang.thu@gmail.com
jiang.mh@mail.tsinghua.edu.cn
</email>
<sectionHeader confidence="0.997283" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999665333333334">
In this article, we propose a novel classifier
based on quantum computation theory. Differ-
ent from existing methods, we consider the
classification as an evolutionary process of a
physical system and build the classifier by us-
ing the basic quantum mechanics equation.
The performance of the experiments on two
datasets indicates feasibility and potentiality of
the quantum classifier.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999743166666667">
Taking modern natural science into account, the
quantum mechanics theory (QM) is one of the
most famous and profound theory which brings a
world-shaking revolution for physics. Since QM
was born, it has been considered as a significant
part of theoretic physics and has shown its power
in explaining experimental results. Furthermore,
some scientists believe that QM is the final prin-
ciple of physics even the whole natural science.
Thus, more and more researchers have expanded
the study of QM in other fields of science, and it
has affected almost every aspect of natural sci-
ence and technology deeply, such as quantum
computation.
The principle of quantum computation has al-
so affected a lot of scientific researches in com-
puter science, specifically in computational mod-
eling, cryptography theory as well as information
theory. Some researchers have employed the
principle and technology of quantum computa-
tion to improve the studies on Machine Learning
(ML) (Aїmeur et al., 2006; Aїmeur et al., 2007;
Chen et al., 2008; Gambs, 2008; Horn and
Gottlieb, 2001; Nasios and Bors, 2007), a field
which studies theories and constructions of sys-
tems that can learn from data, among which clas-
sification is a typical task. Thus, we attempted to
build a computational model based on quantum
computation theory to handle classification tasks
in order to prove the feasibility of applying the
QM model to machine learning.
In this article, we present a method that con-
siders the classifier as a physical system amena-
ble to QM and treat the entire process of classifi-
cation as the evolutionary process of a closed
quantum system. According to QM, the evolu-
tion of quantum system can be described by a
unitary operator. Therefore, the primary problem
of building a quantum classifier (QC) is to find
the correct or optimal unitary operator. We ap-
plied classical optimization algorithms to deal
with the problem, and the experimental results
have confirmed our theory.
The outline of this paper is as follows. First,
the basic principle and structure of QC is intro-
duced in section 2. Then, two different experi-
ments are described in section 3. Finally, section
4 concludes with a discussion.
</bodyText>
<sectionHeader confidence="0.647188" genericHeader="method">
2 Basic principle of quantum classifier
</sectionHeader>
<bodyText confidence="0.999875222222222">
As we mentioned in the introduction, the major
principle of quantum classifier (QC) is to consid-
er the classifier as a physical system and the
whole process of classification as the evolution-
ary process of a closed quantum system. Thus,
the evolution of the quantum system can be de-
scribed by a unitary operator (unitary matrix),
and the remaining job is to find the correct or
optimal unitary operator.
</bodyText>
<subsectionHeader confidence="0.999879">
2.1 Architecture of quantum classifier
</subsectionHeader>
<bodyText confidence="0.9998534">
The architecture and the whole procedure of data
processing of QC are illustrated in Figure 1. As
is shown, the key aspect of QC is the optimiza-
tion part where we employ the optimization algo-
rithm to find an optimal unitary operator ܷᇱ.
</bodyText>
<page confidence="0.985234">
484
</page>
<note confidence="0.627166">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 484–488,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999855">
Figure 1. Architecture of quantum classifier
</figureCaption>
<bodyText confidence="0.999729">
The detailed information about each phase of the
process will be explained thoroughly in the fol-
lowing sections.
</bodyText>
<subsectionHeader confidence="0.973713">
2.2 Encode input state and target state
</subsectionHeader>
<bodyText confidence="0.980821833333333">
In quantum mechanics theory, the state of a
physical system can be described as a superposi-
tion of the so called eigenstates which are or-
thogonal. Any state, including the eigenstate, can
be represented by a complex number vector. We
use Dirac’s braket notation to formalize the data
as equation 1:
For different applications, we employ different
approaches to determine the value of rn and On.
Specifically, in our experiment, we assigned the
term frequency, a feature frequently used in text
classification to rn , and treated the phase On as
a constant, since we found the phase makes little
contribution to the classification.
For each data sample samplek, we calculate
the corresponding input complex number vector
by equation 3, which is illustrated in detail in
Figure 2.
</bodyText>
<equation confidence="0.973417666666667">
|0) = I Cn|En) (1) In (3)
|0k) = I rjk • eiO|Ej)
j=1
</equation>
<bodyText confidence="0.909692133333333">
where |0) denotes a state and Cn E C is a com-
plex number with Cn = (En|0) being the projec-
tion of |0) on the eigenstate |En). According to
quantum theory, Cn denotes the probability am-
plitude. Furthermore, the probability of |0) col-
lapsing on |En) is P(En) = |Cn|2
� |Cn|�
n .
Based on the hypothesis that QC can be con-
sidered as a quantum system, the input data
should be transformed to an available format in
quantum theory — the complex number vector.
According to Euler’s formula, a complex number
z can be denoted as z = reiO with r&gt;_ 0, O E R.
Equation 1, thus, can be written as:
</bodyText>
<equation confidence="0.9078735">
|0) =I rneiOn|En) (2)
n
</equation>
<bodyText confidence="0.995223">
where rn and On denote the module and the
phase of the complex coefficient respectively.
</bodyText>
<figureCaption confidence="0.967184">
Figure 2. Process of calculating the input state
</figureCaption>
<bodyText confidence="0.932431571428571">
Each eigenstate |Ej) denotes the correspond-
ing featurej, resulting in m eigenstates for all
the samples.
As is mentioned above, the evolutionary pro-
cess of a closed physical system can be described
by a unitary operator, depicted by a matrix as in
equation 4:
</bodyText>
<equation confidence="0.989306">
|0&apos;) = U|0) (4)
</equation>
<bodyText confidence="0.997700333333333">
where |0&apos;) and |0) denote the final state and the
initial state respectively. The approach to deter-
mine the unitary operator will be discussed in
</bodyText>
<page confidence="0.998145">
485
</page>
<figureCaption confidence="0.9859146">
section 2.3. We encode the target state in the
similar way. Like the Vector Space Model(VSM),
we use a label matrix to represent each class as in
Figure 3.
Figure 3. Label matrix
</figureCaption>
<bodyText confidence="0.957797">
For each input sample samplek, we generate
the corresponding target complex number vector
according to equation 5:
</bodyText>
<equation confidence="0.988353">
n
Vk) = I Ljk • eieIEj) (5)
j=1
</equation>
<bodyText confidence="0.99974225">
where each eigenstate IEj) represents the corre-
sponding Labelj, resulting in w eigenstates for
all the labels. Totally, we need m + w eigen-
states, including features and labels.
</bodyText>
<subsectionHeader confidence="0.9607455">
2.3 Finding the Hamiltonian matrix and the
Unitary operator
</subsectionHeader>
<bodyText confidence="0.999985142857143">
As is mentioned in the first section, finding a
unitary operator to describe the evolutionary pro-
cess is the vital step in building a QC. As a basic
quantum mechanics theory, a unitary operator
can be represented by a unitary matrix with the
property Ut = U-1, and a unitary operator can
also be written as equation 6:
</bodyText>
<equation confidence="0.997848333333333">
U = eh t
-iH
(6)
</equation>
<bodyText confidence="0.880526333333333">
where H is the Hamiltonian matrix and h is the
reduced Planck constant. Moreover, the Hamil-
tonian H is a Hermitian matrix with the property
</bodyText>
<equation confidence="0.932231">
Ut = (Ut)* = U. The remaining job, therefore,
</equation>
<bodyText confidence="0.989069888888889">
is to find an optimal Hamiltonian matrix.
Since H is a Hermitian matrix, we only need
to determine (m + w)2 free real parameters,
provided that the dimension of H is (m+w). Thus,
the problem of determining H can be regarded as
a classical optimization problem, which can be
resolved by various optimization algorithms
(Chen and Kudlek, 2001). An error function is
defined as equation 7:
</bodyText>
<equation confidence="0.951338">
1
err(H) = E(0z,0�)E 1(0 �l0o)l (7)
</equation>
<bodyText confidence="0.928271666666667">
where T is a set of training pairs with q5t,
q5i, and q5o denoting the target, input, and output
state respectively, and q5o is determined by q5i as
</bodyText>
<equation confidence="0.962472333333333">
equation 8:
��H
I0o) = e h t10i) (8)
</equation>
<bodyText confidence="0.999869">
In the optimization phase, we employed sever-
al optimization algorithm, including BFGS, Ge-
neric Algorithm, and a multi-objective optimiza-
tion algorithm SQP (sequential quadratic pro-
gramming) to optimize the error function. In our
experiment, the SQP method performed best out-
performed the others.
</bodyText>
<sectionHeader confidence="0.999553" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.999987111111111">
We tested the performance of QC on two differ-
ent datasets. In section 3.1, the Reuters-21578
dataset was used to train a binary QC. We com-
pared the performance of QC with several classi-
cal classification methods, including Support
Vector Machine (SVM) and K-nearest neighbor
(KNN). In section 3.2, we evaluated the perfor-
mance on multi-class classification using an oral
conversation datasets and analyzed the results.
</bodyText>
<subsectionHeader confidence="0.998048">
3.1 Reuters-21578
</subsectionHeader>
<bodyText confidence="0.999662461538462">
The Reuters dataset we tested contains 3,964
texts belonging to “earnings” category and 8,938
texts belonging to “others” categories. In this
classification task, we selected the features by
calculating the X2 score of each term from the
“earnings” category (Manning and Schütze,
2002).
For the convenience of counting, we adopted
3,900 “earnings” documents and 8,900 “others”
documents and divided them into two groups: the
training pool and the testing sets. Since we fo-
cused on the performance of QC trained by
small-scale training sets in our experiment, we
each selected 1,000 samples from the “earnings”
and the “others” category as our training pool
and took the rest of the samples (2,900 “earnings”
and 7,900 “others” documents) as our testing sets.
We randomly selected training samples from the
training pool ten times to train QC, SVM, and
KNN classifier respectively and then verified the
three trained classifiers on the testing sets, the
results of which are illustrated in Figure 4. We
noted that the QC performed better than both
KNN and SVM on small-scale training sets,
when the number of training samples is less than
50.
</bodyText>
<page confidence="0.999062">
486
</page>
<figureCaption confidence="0.999076">
Figure 4. Classification accuracy for Reuters-
</figureCaption>
<bodyText confidence="0.974902416666667">
21578 datasets
Generally speaking, the QC trained by a large
training set may not always has an ideal perfor-
mance. Whereas some single training sample
pair led to a favorable result when we used only
one sample from each category to train the QC.
Actually, some single samples could lead to an
accuracy of more than 90%, while some others
may produce an accuracy lower than 30%.
Therefore, the most significant factor for QC is
the quality of the training samples rather than the
quantity.
</bodyText>
<subsectionHeader confidence="0.999724">
3.2 Oral conversation datasets
</subsectionHeader>
<bodyText confidence="0.99992156">
Besides the binary QC, we also built a multi-
class version and tested its performance on an
oral conversation dataset which was collected by
the Laboratory of Computational Linguistics of
Tsinghua university. The dataset consisted of
1,000 texts and were categorized into 5 classes,
each containing 200 texts. We still took the term
frequency as the feature, the dimension of which
exceeded 1,000. We, therefore, utilized the pri-
mary component analysis (PCA) to reduce the
high dimension of the features in order to de-
crease the computational complexity. In this ex-
periment, we chose the top 10 primary compo-
nents of the outcome of PCA, which contained
nearly 60% information of the original data.
Again, we focused on the performance of QC
trained by small-scale training sets. We selected
100 samples from each class to construct the
training pool and took the rest of the data as the
testing sets. Same to the experiment in section
3.1, we randomly selected the training samples
from the training pool ten times to train QC,
SVM, and KNN classifier respectively and veri
fied the models on the testing sets, the results of
which are shown in Figure 5.
</bodyText>
<figureCaption confidence="0.980327">
Figure 5. Classification accuracy for oral
</figureCaption>
<bodyText confidence="0.594709">
conversation datasets
</bodyText>
<sectionHeader confidence="0.99904" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999973676470588">
We present here our model of text classification
and compare it with SVM and KNN on two da-
tasets. We find that it is feasible to build a super-
vised learning model based on quantum mechan-
ics theory. Previous studies focus on combining
quantum method with existing classification
models such as neural network (Chen et al., 2008)
and kernel function (Nasios and Bors, 2007) aim-
ing to improve existing models to work faster
and more efficiently. Our work, however, focus-
es on developing a novel method which explores
the relationship between machine learning model
with physical world, in order to investigate these
models by physical rule which describe our uni-
verse. Moreover, the QC performs well in text
classification compared with SVM and KNN and
outperforms them on small-scale training sets.
Additionally, the time complexity of QC depends
on the optimization algorithm and the amounts of
features we adopt. Generally speaking, simulat-
ing quantum computing on classical computer
always requires more computation resources, and
we believe that quantum computer will tackle the
difficulty in the forthcoming future. Actually,
Google and NASA have launched a quantum
computing AI lab this year, and we regard the
project as an exciting beginning.
Future studies include: We hope to find a
more suitable optimization algorithm for QC and
a more reasonable physical explanation towards
the “quantum nature” of the QC. We hope our
attempt will shed some light upon the application
of quantum theory into the field of machine
learning.
</bodyText>
<page confidence="0.997737">
487
</page>
<sectionHeader confidence="0.998028" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997426571428572">
This work was supported by the National Natural
Science Foundation in China (61171114), State
Key Lab of Pattern Recognition open foundation,
CAS. Tsinghua University Self-determination
Research Project (20111081023 &amp; 20111081010)
and Human &amp; liberal arts development founda-
tion (2010WKHQ009)
</bodyText>
<sectionHeader confidence="0.998908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999620452830189">
Esma A&apos;imeur, Gilles Brassard, and Sébastien Gambs.
2006. Machine Learning in a Quantum World. Ca-
nadian AI 2006
Esma A&apos;imeur, Gilles Brassard and Sébastien Gambs.
2007. Quantum Clustering Algorithms. Proceed-
ings of the 24 th International Conference on Ma-
chine Learning
Joseph C.H. Chen and Manfred Kudlek. 2001. Duality
of Syntex and Semantics – From the View Point of
Brain as a Quantum Computer. Proceedings of Re-
cent Advances in NLP
Joseph C.H. Chen. 2001. Quantum Computation and
Natural Language Processing. University of Ham-
burg, Germany. Ph.D. thesis
Joseph C.H. Chen. 2001. A Quantum Mechanical
Approach to Cognition and Representation. Con-
sciousness and its Place in Nature,Toward a Sci-
ence of Consciousness.
Cheng-Hung Chen, Cheng-Jian Lin and Chin-Teng
Lin. 2008. An efficient quantum neuro-fuzzy clas-
sifier based on fuzzy entropy and compensatory
operation. Soft Comput, 12:567–583.
Fumiyo Fukumoto and Yoshimi Suzuki. 2002. Ma-
nipulating Large Corpora for Text Classification.
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing
Sébastien Gambs. 2008. Quantum classification,
arXiv:0809.0444
Lov K. Grover. 1997. Quantum Mechanics Helps in
Searching for a Needle in a Haystack. Physical Re
view Letters, 79,325–328
David Horn and Assaf Gottlieb. 2001. The Method of
Quantum Clustering. Proceedings of Advances in
Neural Information Processing Systems .
Christopher D. Manning and Hinrich Schütze. 2002.
Foundations of Statistical Natural Language Pro-
cessing. MIT Press. Cambridge, Massachu-
setts,USA.
Nikolaos Nasios and Adrian G. Bors. 2007. Kernel-
based classification using quantum mechanics. Pat-
tern Recognition, 40:875–889
Hartmut Neven and Vasil S. Denchev. 2009. Training
a Large Scale Classifier with the Quantum Adia-
batic Algorithm. arXiv:0912.0779v1
Michael A. Nielsen and Isasc L. Chuang. 2000. Quan-
tum Computation and Quantum Information, Cam-
bridge University Press, Cambridge, UK.
Masahide Sasaki and and Alberto Carlini. 2002.
Quantum learning and universal quantum matching
machine. Physical Review, A 66, 022303
Dan Ventura. 2002. Pattern classification using a
quantum system. Proceedings of the Joint Confer-
ence on Information Sciences.
</reference>
<page confidence="0.997985">
488
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.774590">
<title confidence="0.999859">A Novel Text Classifier Based on Quantum Computation</title>
<author confidence="0.997721">Ding Liu</author>
<author confidence="0.997721">Xiaofang Yang</author>
<author confidence="0.997721">Minghu</author>
<affiliation confidence="0.992283">Laboratory of Computational Linguistics, School of Tsinghua University, Beijing , China</affiliation>
<email confidence="0.898285">Dingliu_thu@126.comjiang.mh@mail.tsinghua.edu.cn</email>
<abstract confidence="0.9978397">In this article, we propose a novel classifier based on quantum computation theory. Different from existing methods, we consider the classification as an evolutionary process of a physical system and build the classifier by using the basic quantum mechanics equation. The performance of the experiments on two datasets indicates feasibility and potentiality of the quantum classifier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Esma A&apos;imeur</author>
<author>Gilles Brassard</author>
<author>Sébastien Gambs</author>
</authors>
<title>Machine Learning in a Quantum World. Canadian AI</title>
<date>2006</date>
<marker>A&apos;imeur, Brassard, Gambs, 2006</marker>
<rawString>Esma A&apos;imeur, Gilles Brassard, and Sébastien Gambs. 2006. Machine Learning in a Quantum World. Canadian AI 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esma A&apos;imeur</author>
<author>Gilles Brassard</author>
<author>Sébastien Gambs</author>
</authors>
<title>Quantum Clustering Algorithms.</title>
<date>2007</date>
<booktitle>Proceedings of the 24 th International Conference on Machine Learning</booktitle>
<marker>A&apos;imeur, Brassard, Gambs, 2007</marker>
<rawString>Esma A&apos;imeur, Gilles Brassard and Sébastien Gambs. 2007. Quantum Clustering Algorithms. Proceedings of the 24 th International Conference on Machine Learning</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph C H Chen</author>
<author>Manfred Kudlek</author>
</authors>
<date>2001</date>
<booktitle>Duality of Syntex and Semantics – From the View Point of Brain as a Quantum Computer. Proceedings of Recent Advances in NLP</booktitle>
<contexts>
<context position="7397" citStr="Chen and Kudlek, 2001" startWordPosition="1236" endWordPosition="1239"> property Ut = U-1, and a unitary operator can also be written as equation 6: U = eh t -iH (6) where H is the Hamiltonian matrix and h is the reduced Planck constant. Moreover, the Hamiltonian H is a Hermitian matrix with the property Ut = (Ut)* = U. The remaining job, therefore, is to find an optimal Hamiltonian matrix. Since H is a Hermitian matrix, we only need to determine (m + w)2 free real parameters, provided that the dimension of H is (m+w). Thus, the problem of determining H can be regarded as a classical optimization problem, which can be resolved by various optimization algorithms (Chen and Kudlek, 2001). An error function is defined as equation 7: 1 err(H) = E(0z,0�)E 1(0 �l0o)l (7) where T is a set of training pairs with q5t, q5i, and q5o denoting the target, input, and output state respectively, and q5o is determined by q5i as equation 8: ��H I0o) = e h t10i) (8) In the optimization phase, we employed several optimization algorithm, including BFGS, Generic Algorithm, and a multi-objective optimization algorithm SQP (sequential quadratic programming) to optimize the error function. In our experiment, the SQP method performed best outperformed the others. 3 Experiment We tested the performan</context>
</contexts>
<marker>Chen, Kudlek, 2001</marker>
<rawString>Joseph C.H. Chen and Manfred Kudlek. 2001. Duality of Syntex and Semantics – From the View Point of Brain as a Quantum Computer. Proceedings of Recent Advances in NLP</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph C H Chen</author>
</authors>
<title>Quantum Computation and Natural Language Processing.</title>
<date>2001</date>
<tech>Ph.D. thesis</tech>
<institution>University of Hamburg, Germany.</institution>
<marker>Chen, 2001</marker>
<rawString>Joseph C.H. Chen. 2001. Quantum Computation and Natural Language Processing. University of Hamburg, Germany. Ph.D. thesis</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph C H Chen</author>
</authors>
<title>A Quantum Mechanical Approach to Cognition and Representation. Consciousness and its Place in Nature,Toward a Science of Consciousness.</title>
<date>2001</date>
<marker>Chen, 2001</marker>
<rawString>Joseph C.H. Chen. 2001. A Quantum Mechanical Approach to Cognition and Representation. Consciousness and its Place in Nature,Toward a Science of Consciousness.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cheng-Hung Chen</author>
<author>Cheng-Jian Lin</author>
<author>Chin-Teng Lin</author>
</authors>
<title>An efficient quantum neuro-fuzzy classifier based on fuzzy entropy and compensatory operation. Soft Comput,</title>
<date>2008</date>
<pages>12--567</pages>
<contexts>
<context position="1694" citStr="Chen et al., 2008" startWordPosition="251" endWordPosition="254">the whole natural science. Thus, more and more researchers have expanded the study of QM in other fields of science, and it has affected almost every aspect of natural science and technology deeply, such as quantum computation. The principle of quantum computation has also affected a lot of scientific researches in computer science, specifically in computational modeling, cryptography theory as well as information theory. Some researchers have employed the principle and technology of quantum computation to improve the studies on Machine Learning (ML) (Aїmeur et al., 2006; Aїmeur et al., 2007; Chen et al., 2008; Gambs, 2008; Horn and Gottlieb, 2001; Nasios and Bors, 2007), a field which studies theories and constructions of systems that can learn from data, among which classification is a typical task. Thus, we attempted to build a computational model based on quantum computation theory to handle classification tasks in order to prove the feasibility of applying the QM model to machine learning. In this article, we present a method that considers the classifier as a physical system amenable to QM and treat the entire process of classification as the evolutionary process of a closed quantum system. A</context>
<context position="11682" citStr="Chen et al., 2008" startWordPosition="1944" endWordPosition="1947"> randomly selected the training samples from the training pool ten times to train QC, SVM, and KNN classifier respectively and veri fied the models on the testing sets, the results of which are shown in Figure 5. Figure 5. Classification accuracy for oral conversation datasets 4 Discussion We present here our model of text classification and compare it with SVM and KNN on two datasets. We find that it is feasible to build a supervised learning model based on quantum mechanics theory. Previous studies focus on combining quantum method with existing classification models such as neural network (Chen et al., 2008) and kernel function (Nasios and Bors, 2007) aiming to improve existing models to work faster and more efficiently. Our work, however, focuses on developing a novel method which explores the relationship between machine learning model with physical world, in order to investigate these models by physical rule which describe our universe. Moreover, the QC performs well in text classification compared with SVM and KNN and outperforms them on small-scale training sets. Additionally, the time complexity of QC depends on the optimization algorithm and the amounts of features we adopt. Generally spea</context>
</contexts>
<marker>Chen, Lin, Lin, 2008</marker>
<rawString>Cheng-Hung Chen, Cheng-Jian Lin and Chin-Teng Lin. 2008. An efficient quantum neuro-fuzzy classifier based on fuzzy entropy and compensatory operation. Soft Comput, 12:567–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fumiyo Fukumoto</author>
<author>Yoshimi Suzuki</author>
</authors>
<title>Manipulating Large Corpora for Text Classification.</title>
<date>2002</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing</booktitle>
<marker>Fukumoto, Suzuki, 2002</marker>
<rawString>Fumiyo Fukumoto and Yoshimi Suzuki. 2002. Manipulating Large Corpora for Text Classification. Proceedings of the Conference on Empirical Methods in Natural Language Processing</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sébastien Gambs</author>
</authors>
<date>2008</date>
<note>Quantum classification, arXiv:0809.0444</note>
<contexts>
<context position="1707" citStr="Gambs, 2008" startWordPosition="255" endWordPosition="256">cience. Thus, more and more researchers have expanded the study of QM in other fields of science, and it has affected almost every aspect of natural science and technology deeply, such as quantum computation. The principle of quantum computation has also affected a lot of scientific researches in computer science, specifically in computational modeling, cryptography theory as well as information theory. Some researchers have employed the principle and technology of quantum computation to improve the studies on Machine Learning (ML) (Aїmeur et al., 2006; Aїmeur et al., 2007; Chen et al., 2008; Gambs, 2008; Horn and Gottlieb, 2001; Nasios and Bors, 2007), a field which studies theories and constructions of systems that can learn from data, among which classification is a typical task. Thus, we attempted to build a computational model based on quantum computation theory to handle classification tasks in order to prove the feasibility of applying the QM model to machine learning. In this article, we present a method that considers the classifier as a physical system amenable to QM and treat the entire process of classification as the evolutionary process of a closed quantum system. According to Q</context>
</contexts>
<marker>Gambs, 2008</marker>
<rawString>Sébastien Gambs. 2008. Quantum classification, arXiv:0809.0444</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lov K Grover</author>
</authors>
<title>Quantum Mechanics Helps in Searching for a Needle in a Haystack. Physical Re view Letters,</title>
<date>1997</date>
<pages>79--325</pages>
<marker>Grover, 1997</marker>
<rawString>Lov K. Grover. 1997. Quantum Mechanics Helps in Searching for a Needle in a Haystack. Physical Re view Letters, 79,325–328</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Horn</author>
<author>Assaf Gottlieb</author>
</authors>
<title>The Method of Quantum Clustering.</title>
<date>2001</date>
<booktitle>Proceedings of Advances in Neural Information Processing Systems .</booktitle>
<contexts>
<context position="1732" citStr="Horn and Gottlieb, 2001" startWordPosition="257" endWordPosition="260"> more and more researchers have expanded the study of QM in other fields of science, and it has affected almost every aspect of natural science and technology deeply, such as quantum computation. The principle of quantum computation has also affected a lot of scientific researches in computer science, specifically in computational modeling, cryptography theory as well as information theory. Some researchers have employed the principle and technology of quantum computation to improve the studies on Machine Learning (ML) (Aїmeur et al., 2006; Aїmeur et al., 2007; Chen et al., 2008; Gambs, 2008; Horn and Gottlieb, 2001; Nasios and Bors, 2007), a field which studies theories and constructions of systems that can learn from data, among which classification is a typical task. Thus, we attempted to build a computational model based on quantum computation theory to handle classification tasks in order to prove the feasibility of applying the QM model to machine learning. In this article, we present a method that considers the classifier as a physical system amenable to QM and treat the entire process of classification as the evolutionary process of a closed quantum system. According to QM, the evolution of quant</context>
</contexts>
<marker>Horn, Gottlieb, 2001</marker>
<rawString>David Horn and Assaf Gottlieb. 2001. The Method of Quantum Clustering. Proceedings of Advances in Neural Information Processing Systems .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<date>2002</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press.</publisher>
<location>Cambridge, Massachusetts,USA.</location>
<contexts>
<context position="8696" citStr="Manning and Schütze, 2002" startWordPosition="1444" endWordPosition="1447">aset was used to train a binary QC. We compared the performance of QC with several classical classification methods, including Support Vector Machine (SVM) and K-nearest neighbor (KNN). In section 3.2, we evaluated the performance on multi-class classification using an oral conversation datasets and analyzed the results. 3.1 Reuters-21578 The Reuters dataset we tested contains 3,964 texts belonging to “earnings” category and 8,938 texts belonging to “others” categories. In this classification task, we selected the features by calculating the X2 score of each term from the “earnings” category (Manning and Schütze, 2002). For the convenience of counting, we adopted 3,900 “earnings” documents and 8,900 “others” documents and divided them into two groups: the training pool and the testing sets. Since we focused on the performance of QC trained by small-scale training sets in our experiment, we each selected 1,000 samples from the “earnings” and the “others” category as our training pool and took the rest of the samples (2,900 “earnings” and 7,900 “others” documents) as our testing sets. We randomly selected training samples from the training pool ten times to train QC, SVM, and KNN classifier respectively and t</context>
</contexts>
<marker>Manning, Schütze, 2002</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 2002. Foundations of Statistical Natural Language Processing. MIT Press. Cambridge, Massachusetts,USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikolaos Nasios</author>
<author>Adrian G Bors</author>
</authors>
<title>Kernelbased classification using quantum mechanics. Pattern Recognition,</title>
<date>2007</date>
<pages>40--875</pages>
<contexts>
<context position="1756" citStr="Nasios and Bors, 2007" startWordPosition="261" endWordPosition="264">s have expanded the study of QM in other fields of science, and it has affected almost every aspect of natural science and technology deeply, such as quantum computation. The principle of quantum computation has also affected a lot of scientific researches in computer science, specifically in computational modeling, cryptography theory as well as information theory. Some researchers have employed the principle and technology of quantum computation to improve the studies on Machine Learning (ML) (Aїmeur et al., 2006; Aїmeur et al., 2007; Chen et al., 2008; Gambs, 2008; Horn and Gottlieb, 2001; Nasios and Bors, 2007), a field which studies theories and constructions of systems that can learn from data, among which classification is a typical task. Thus, we attempted to build a computational model based on quantum computation theory to handle classification tasks in order to prove the feasibility of applying the QM model to machine learning. In this article, we present a method that considers the classifier as a physical system amenable to QM and treat the entire process of classification as the evolutionary process of a closed quantum system. According to QM, the evolution of quantum system can be describ</context>
<context position="11726" citStr="Nasios and Bors, 2007" startWordPosition="1951" endWordPosition="1954">from the training pool ten times to train QC, SVM, and KNN classifier respectively and veri fied the models on the testing sets, the results of which are shown in Figure 5. Figure 5. Classification accuracy for oral conversation datasets 4 Discussion We present here our model of text classification and compare it with SVM and KNN on two datasets. We find that it is feasible to build a supervised learning model based on quantum mechanics theory. Previous studies focus on combining quantum method with existing classification models such as neural network (Chen et al., 2008) and kernel function (Nasios and Bors, 2007) aiming to improve existing models to work faster and more efficiently. Our work, however, focuses on developing a novel method which explores the relationship between machine learning model with physical world, in order to investigate these models by physical rule which describe our universe. Moreover, the QC performs well in text classification compared with SVM and KNN and outperforms them on small-scale training sets. Additionally, the time complexity of QC depends on the optimization algorithm and the amounts of features we adopt. Generally speaking, simulating quantum computing on classi</context>
</contexts>
<marker>Nasios, Bors, 2007</marker>
<rawString>Nikolaos Nasios and Adrian G. Bors. 2007. Kernelbased classification using quantum mechanics. Pattern Recognition, 40:875–889</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hartmut Neven</author>
<author>Vasil S Denchev</author>
</authors>
<title>Training a Large Scale Classifier with the Quantum Adiabatic Algorithm.</title>
<date>2009</date>
<pages>0912--0779</pages>
<marker>Neven, Denchev, 2009</marker>
<rawString>Hartmut Neven and Vasil S. Denchev. 2009. Training a Large Scale Classifier with the Quantum Adiabatic Algorithm. arXiv:0912.0779v1</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Nielsen</author>
<author>Isasc L Chuang</author>
</authors>
<title>Quantum Computation and Quantum Information,</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Nielsen, Chuang, 2000</marker>
<rawString>Michael A. Nielsen and Isasc L. Chuang. 2000. Quantum Computation and Quantum Information, Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahide Sasaki</author>
<author>Alberto Carlini</author>
</authors>
<title>Quantum learning and universal quantum matching machine.</title>
<date>2002</date>
<journal>Physical Review, A</journal>
<volume>66</volume>
<pages>022303</pages>
<marker>Sasaki, Carlini, 2002</marker>
<rawString>Masahide Sasaki and and Alberto Carlini. 2002. Quantum learning and universal quantum matching machine. Physical Review, A 66, 022303</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Ventura</author>
</authors>
<title>Pattern classification using a quantum system.</title>
<date>2002</date>
<booktitle>Proceedings of the Joint Conference on Information Sciences.</booktitle>
<marker>Ventura, 2002</marker>
<rawString>Dan Ventura. 2002. Pattern classification using a quantum system. Proceedings of the Joint Conference on Information Sciences.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>