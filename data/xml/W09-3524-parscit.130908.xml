<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015329">
<title confidence="0.998865">
A Hybrid Approach to English-Korean Name Transliteration
</title>
<author confidence="0.999678">
Gumwon Hong*, Min-Jeong Kim*, Do-Gil Lee+ and Hae-Chang Rim*
</author>
<affiliation confidence="0.999599">
*Department of Computer Science &amp; Engineering, Korea University, Seoul 136-713, Korea
</affiliation>
<email confidence="0.961491">
{gwhong,mjkim,rim}@nlp.korea.ac.kr
</email>
<note confidence="0.578537">
+Institute of Korean Culture, Korea University, Seoul 136-701, Korea
</note>
<email confidence="0.995003">
motdg@korea.ac.kr
</email>
<sectionHeader confidence="0.993771" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999727941176471">
This paper presents a hybrid approach to
English-Korean name transliteration. The
base system is built on MOSES with en-
abled factored translation features. We
expand the base system by combining
with various transliteration methods in-
cluding a Web-based n-best re-ranking, a
dictionary-based method, and a rule-based
method. Our standard run and best non-
standard run achieve 45.1 and 78.5, re-
spectively, in top-1 accuracy. Experimen-
tal results show that expanding training
data size significantly contributes to the
performance. Also we discover that the
Web-based re-ranking method can be suc-
cessfully applied to the English-Korean
transliteration.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999850690476191">
Often, named entities such as person names or
place names from foreign origin do not appear in
the dictionary, and such out of vocabulary words
are a common source of errors in processing nat-
ural languages. For example, in statistical ma-
chine translation (SMT), if a new word occurs
in the input source sentence, the decoder will at
best drop the unknown word or directly copy the
source word to the target sentence. Transliteration,
a method of mapping phonemes or graphemes of
source language into those of target language, can
be used in this case in order to identify a possible
translation of the word.
The approaches to automatic transliteration be-
tween English and Korean can be performed
through the following ways: First, in learning how
to write the names of foreign origin, we can re-
fer to a transliteration standard which is estab-
lished by the government or some official linguis-
tic organizations. No matter where the standard
comes from, the basic principle of the standard
is based on the correct pronunciation of foreign
words. Second, since constructing such rules are
very costly in terms of time and money, we can
rely on a statistical method such as SMT. We be-
lieve that the rule-based method can guarantee to
increase accuracy for known cases, and the statis-
tical method can be robust to handle various ex-
ceptions.
In this paper, we present a variety of tech-
niques for English-Korean name transliteration.
First, we use a phrase-base SMT model with some
factored translation features for the transliteration
task. Second, we expand the base system by ap-
plying Web-based n-best re-ranking of the results.
Third, we apply a pronouncing dictionary-based
method to the base system which utilizes the pro-
nunciation symbols which is motivated by linguis-
tic knowledge. Finally, we introduce a phonics-
based method which is originally designed for
teaching speakers of English to read and write that
language.
</bodyText>
<sectionHeader confidence="0.9317" genericHeader="method">
2 Proposed Approach
</sectionHeader>
<bodyText confidence="0.999960470588236">
In order to build our base system, we use MOSES
(Koehn et al., 2007), a well-known phrase-based
system designed for SMT. MOSES offers a con-
venient framework which can be directly applied
to machine transliteration experiments. In this
framework, the transliteration can be performed
in a very similar process of SMT task except the
following changes. First, the unit of translation
is changed from words to characters. Second, a
phrase in transliteration refers to any contiguous
block of character sequence which can be directly
matched from a source word to a target word.
Also, we do not have to worry about any distortion
parameters because decoding can be performed in
a totally monotonic way.
The process of the general transliteration ap-
proach begins by matching the unit of a source
</bodyText>
<page confidence="0.977122">
108
</page>
<note confidence="0.9903595">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 108–111,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<table confidence="0.9894026">
Bilingual Corpus Input Word
Eumjeol
Decomposition
Eumjeol
Decomposition
</table>
<bodyText confidence="0.979064657142857">
word to the unit of a target word. The unit can be
based on graphemes or phonemes, depending on
language pairs or approaches. In English-Korean
transliteration, both grapheme-to-grapheme and
grapheme-to-phoneme approaches are possible. In
our method, we select grapheme-to-grapheme ap-
proach as a base system, and we apply grapheme-
to-phoneme functions in pronouncing dictionary-
based approach.
The transliteration between Korean and other
languages requires some special preprocessing
techniques. First of all, Korean alphabet is or-
ganized into syllabic blocks called Eumjeol. Ko-
rean transliteration standard allows each Eumjeol
to consist of either two or three of the 24 Korean
letters, with (1) leading 14 consonants, (2) inter-
mediate 10 vowels, and (3) optionally, trailing 7
consonants (out of the possible 14). Therefore,
Korean Eumjeol should be decomposed into letters
before performing training or decoding any input.
Consequently, after the letter-unit transliteration is
finished, all the letters should be re-composed to
form a correct sequence of Eumjeols.
Figure 1 shows the overall architecture of our
system. The alignment between English letter and
Korean letter is performed using GIZA++ (Och
and Ney, 2003). We use MOSES decoder in or-
der to search the best sequence of transliteration.
In this paper we focus on describing factored
phrase-based training and n-best re-ranking tech-
niques including a Web-based method, a pro-
nouncing dictionary-based method, and a phonics-
based method.
Figure 2: Alignment example between ‘Knight’
and ‘�+��� [naiteu]’
</bodyText>
<subsectionHeader confidence="0.99136">
2.1 Factored Phrase-based Training
</subsectionHeader>
<bodyText confidence="0.999980882352941">
Koehn and Hoang (2007) introduces an integration
of different information for phrase-based SMT
model. We report on experiments with three fac-
tors: surface form, positional information, and
the type of a letter. Surface form indicates a
letter itself. For positional information, we add
a BIO label to each input character in both the
source words and the target words. The intuition is
that certain character is differently pronounced de-
pending on its position in a word. For example, ‘k’
in ‘Knight’ or ‘h’ in ‘Sarah’ are not pronounced.
The type of a letter is used to classify whether a
given letter is a vowel or a consonant. We assume
that a consonant in source word would more likely
be linked to a consonant in a target word. Figure 2
shows an example of alignment with factored fea-
tures.
</bodyText>
<subsectionHeader confidence="0.998386">
2.2 Web-based Re-ranking
</subsectionHeader>
<bodyText confidence="0.99991505882353">
We re-ranked the top n results of the decoder by
referring to how many times both source word and
target word co-occur on the Web. In news articles
on the Web, a translation of a foreign name is of-
ten provided near the foreign name to describe its
pronunciation or description. To reflect this obser-
vation, we use Google’s proximity search by re-
stricting two terms should occur within four-word
distance. The frequency is adjusted as relative fre-
quency form by dividing each frequency by total
frequency of all n-best results.
Also, we linearly interpolate the n-best score
with the relative frequency of candidate output. To
make fair interpolation, we adjust both scores to be
between 0 and 1. Also, in this method, we decide
to remove all the candidates whose frequencies are
zero.
</bodyText>
<subsectionHeader confidence="0.999588">
2.3 Pronouncing Dictionary-based Method
</subsectionHeader>
<bodyText confidence="0.9945815">
According to “Oeraeeo pyogibeop1” (Korean or-
thography and writing method of borrowed for-
</bodyText>
<footnote confidence="0.627543">
1http://www.korean.go.kr/08 new/data/rule03.jsp
</footnote>
<figure confidence="0.9922475">
Factored Phrase-
based Training
Trained Model
Eumjeol
Re-composition
N-best
Re-ranking
Target Word
</figure>
<figureCaption confidence="0.996201">
Figure 1: System Architecture
</figureCaption>
<figure confidence="0.98549175">
Letter
Alignment
MOSES
Decoder
</figure>
<page confidence="0.984428">
109
</page>
<table confidence="0.985304166666667">
Methods Acc.1 Mean Fi Mean Fde, MRR MAPTef MAPio MAPsys
BS 0.451 0.720 0.852 0.576 0.451 0.181 0.181
ER 0.740 0.868 0.930 0.806 0.740 0.243 0.243
WR 0.784 0.889 0.944 0.840 0.784 0.252 0.484
PD 0.781 0.885 0.941 0.839 0.781 0.252 0.460
PB 0.785 0.887 0.943 0.840 0.785 0.252 0.441
</table>
<tableCaption confidence="0.999874">
Table 1: Experimental Results (EnKo)
</tableCaption>
<bodyText confidence="0.99991432">
eign words), the primary principle of English-to-
Korean transliteration is to spell according to the
mapping table between the international phonetic
alphabets and the Korean alphabets. Therefore,
we can say that a pronouncing dictionary-based
method is very suitable for this principle.
We use the following two resources for build-
ing a pronouncing dictionary: one is an English-
Korean dictionary that contains 130,000 words.
The other is the CMU pronouncing dictionary2
created by Carnegie Mellon University that con-
tains over 125,000 words and their transcriptions.
Phonetic symbols for English words in the
dictionaries are transformed to their pronuncia-
tion information by using an internal code table.
The internal code table represents mappings from
each phonetic symbol to a single character within
ASCII code table. Our pronouncing dictionary in-
cludes a list of words and their pronunciation in-
formation.
For a given English word, if the word exists
in the pronouncing dictionary, then its pronunci-
ations are translated to Korean graphemes by a
mapping table and transformation rules, which are
defined by “Oeraeeo pyogibeop”.
</bodyText>
<subsectionHeader confidence="0.947304">
2.4 Phonics-based Method
</subsectionHeader>
<bodyText confidence="0.999948928571429">
Phonics is a pronunciation-based linguistic teach-
ing method, especially for children (Strickland,
1998). Originally, it was designed to connect the
sounds of spoken English with group of English
letters. In this research, we modify the phonics
in order to connect English sounds to Korean let-
ter because in Korean there is nearly a one-to-one
correspondence between sounds and the letter pat-
terns that represent them. For example, alpha-
bet ‘b’ can be pronounced to ‘ii’(bieup) in Ko-
rean. Consequently, we construct about 150 rules
which map English alphabet into one or more sev-
eral Korean graphemes, by referring to the phon-
ics. Though phonics cannot reveal all of the pro-
</bodyText>
<footnote confidence="0.740804">
2http://www.speech.cs.cmu.edu/cgi-bin/cmudict
</footnote>
<bodyText confidence="0.995901166666667">
nunciation of English words, the conversion from
English alphabet into Korean letter is performed
simply and efficiently. We apply the phonics in
serial order from left to right of each input word.
If multiple rules are applicable, the most specific
rules are fist applied.
</bodyText>
<sectionHeader confidence="0.99984" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999357">
3.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.997841666666667">
We participate in both standard and non-standard
tracks for English-Korean name transliteration in
NEWS 2009 Machine Transliteration Shared Task
(Li et al., 2009). Experimenting on the develop-
ment data, we determine the best performing pa-
rameters for MOSES as follows.
</bodyText>
<listItem confidence="0.9999535">
• Maximum Phrase Length: 3
• Language Model N-gram Order: 3
• Language Model Smoothing: Kneser-Ney
• Phrase Alignment Heuristic: grow-diag-final
• Reordering: Monotone
• Maximum Distortion Length: 0
</listItem>
<bodyText confidence="0.975701">
With above parameter setup, the results are pro-
duced from the following five different systems.
</bodyText>
<listItem confidence="0.901049076923077">
• Baseline System (BS): For the standard task,
we use only given official training data 3 to con-
struct translation model and language model for
our base system.
• Expanded Resource (ER): For all four non-
standard tasks, we use the examples of writing for-
eign names as additional training data. The ex-
amples are provided from the National Institute of
the Korean Language4. The data originally con-
sists of around 27,000 person names and around
7,000 place names including non-Ascii characters
for English side words as well as duplicate entries.
We preprocess the data in order to use 13,194 dis-
</listItem>
<footnote confidence="0.99939075">
3Refer to Website http://www.cjk.org for more informa-
tion
4The resource is open to public. See
http://www.korean.go.kr/eng for more information.
</footnote>
<page confidence="0.99613">
110
</page>
<bodyText confidence="0.7594445">
tinct pairs of English names and Korean transliter-
ation.
</bodyText>
<listItem confidence="0.993363428571429">
• Web-based Re-ranking (WR): We re-rank the
result of ER by applying the method described in
section 2.2.
• Pronouncing Dictionary-based Method (PD):
The re-ranking of WR by combining with the
method described in section 2.3.
• Phonics-based Method (PB): The re-ranking
</listItem>
<bodyText confidence="0.945889833333333">
of WR by combining with the method described in
section 2.4.
The last two methods re-rank the WR method
by applying pronouncing dictionary-based method
and Phonics-based method. We restrict that
the pronouncing dictionary-based method and
Phonics-based method can produce only one out-
put, and use the outputs of the two methods to re-
rank (again) the result of Web-based re-ranking.
When re-ranking the results, we heuristically com-
bined the outputs of PD or PB with the n-best re-
sult of WR. If the outputs of the two methods exist
in the result of WR, we add some positive scores to
the original scores of WR. Otherwise, we inserted
the result into fixed position of the rank. The fixed
position of rank is empirically decided using de-
velopment set. We inserted the output of PD and
PB at second rank and at sixth rank, respectively.
</bodyText>
<subsectionHeader confidence="0.995096">
3.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999982411764706">
Table 1 shows our experimental results of the five
systems on the test data. We found that the use
of additional training data (ER) and web-based re-
ranking (WR) have a strong effect on translitera-
tion performance. However, the integration of the
PD or PB with WB proves not to significantly con-
tribute the performance. To find more elaborate
integration of those results will be one of our fu-
ture work.
The MAPsys value of the three re-ranking
methods WR, PD, and PB are relatively higher
than other methods because we filter out some
candidates in n-best by their Web frequencies. In
addition to the standard evaluation measures, we
include the Mean Fd,, to measure the Levenshtein
distance between reference and the output of the
decoder (decomposed result).
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999646052631579">
In this paper, we proposed a hybrid approach to
English-Korean name transliteration. The system
is built on MOSES with factored translation fea-
tures. When evaluating the proposed methods,
we found that the use of additional training data
can significantly outperforms the baseline system.
Also, the experimental result of using three n-best
re-ranking techniques shows that the Web-based
re-ranking is proved to be a useful method. How-
ever, our two integration methods with dictionary-
based or rule-based method does not show the sig-
nificant gain over the Web-based re-ranking.
For future work, we plan to devise more elab-
orate way to integrate statistical method and dic-
tionary or rule-based method to further improve
the transliteration performance. Also, we will ap-
ply the proposed techniques to possible applica-
tions such as SMT or Cross Lingual Information
Retrieval.
</bodyText>
<sectionHeader confidence="0.99941" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997952">
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868–876,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In ACL 2007, Demo and Poster Sessions, June.
Haizhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009. Whitepaper of news 2009
machine transliteration shared task. In Proceed-
ings of ACL-IJCNLP 2009 Named Entities Work-
shop (NEWS 2009), Singapore.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29.
D.S. Strickland. 1998. Teaching phonics today: A
primer for educators. International Reading Asso-
ciation.
</reference>
<page confidence="0.998793">
111
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.105246">
<title confidence="0.999711">A Hybrid Approach to English-Korean Name Transliteration</title>
<author confidence="0.588395">Min-Jeong Do-Gil</author>
<author confidence="0.588395">Hae-Chang</author>
<affiliation confidence="0.262831">of Computer Science &amp; Engineering, Korea University, Seoul 136-713,</affiliation>
<address confidence="0.231231">of Korean Culture, Korea University, Seoul 136-701,</address>
<email confidence="0.923072">motdg@korea.ac.kr</email>
<abstract confidence="0.990674888888889">This paper presents a hybrid approach to English-Korean name transliteration. The base system is built on MOSES with enabled factored translation features. We expand the base system by combining with various transliteration methods ina Web-based re-ranking, a dictionary-based method, and a rule-based method. Our standard run and best nonstandard run achieve 45.1 and 78.5, respectively, in top-1 accuracy. Experimental results show that expanding training data size significantly contributes to the performance. Also we discover that the Web-based re-ranking method can be successfully applied to the English-Korean transliteration.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5567" citStr="Koehn and Hoang (2007)" startWordPosition="854" endWordPosition="857">ters should be re-composed to form a correct sequence of Eumjeols. Figure 1 shows the overall architecture of our system. The alignment between English letter and Korean letter is performed using GIZA++ (Och and Ney, 2003). We use MOSES decoder in order to search the best sequence of transliteration. In this paper we focus on describing factored phrase-based training and n-best re-ranking techniques including a Web-based method, a pronouncing dictionary-based method, and a phonicsbased method. Figure 2: Alignment example between ‘Knight’ and ‘�+��� [naiteu]’ 2.1 Factored Phrase-based Training Koehn and Hoang (2007) introduces an integration of different information for phrase-based SMT model. We report on experiments with three factors: surface form, positional information, and the type of a letter. Surface form indicates a letter itself. For positional information, we add a BIO label to each input character in both the source words and the target words. The intuition is that certain character is differently pronounced depending on its position in a word. For example, ‘k’ in ‘Knight’ or ‘h’ in ‘Sarah’ are not pronounced. The type of a letter is used to classify whether a given letter is a vowel or a con</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In ACL 2007, Demo and Poster Sessions,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="3009" citStr="Koehn et al., 2007" startWordPosition="468" endWordPosition="471">nglish-Korean name transliteration. First, we use a phrase-base SMT model with some factored translation features for the transliteration task. Second, we expand the base system by applying Web-based n-best re-ranking of the results. Third, we apply a pronouncing dictionary-based method to the base system which utilizes the pronunciation symbols which is motivated by linguistic knowledge. Finally, we introduce a phonicsbased method which is originally designed for teaching speakers of English to read and write that language. 2 Proposed Approach In order to build our base system, we use MOSES (Koehn et al., 2007), a well-known phrase-based system designed for SMT. MOSES offers a convenient framework which can be directly applied to machine transliteration experiments. In this framework, the transliteration can be performed in a very similar process of SMT task except the following changes. First, the unit of translation is changed from words to characters. Second, a phrase in transliteration refers to any contiguous block of character sequence which can be directly matched from a source word to a target word. Also, we do not have to worry about any distortion parameters because decoding can be perform</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL 2007, Demo and Poster Sessions, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Min Zhang</author>
<author>Vladimir Pervouchine</author>
</authors>
<title>Whitepaper of news 2009 machine transliteration shared task.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009 Named Entities Workshop (NEWS</booktitle>
<contexts>
<context position="10158" citStr="Li et al., 2009" startWordPosition="1578" endWordPosition="1581">everal Korean graphemes, by referring to the phonics. Though phonics cannot reveal all of the pro2http://www.speech.cs.cmu.edu/cgi-bin/cmudict nunciation of English words, the conversion from English alphabet into Korean letter is performed simply and efficiently. We apply the phonics in serial order from left to right of each input word. If multiple rules are applicable, the most specific rules are fist applied. 3 Experiments 3.1 Experimental Setup We participate in both standard and non-standard tracks for English-Korean name transliteration in NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009). Experimenting on the development data, we determine the best performing parameters for MOSES as follows. • Maximum Phrase Length: 3 • Language Model N-gram Order: 3 • Language Model Smoothing: Kneser-Ney • Phrase Alignment Heuristic: grow-diag-final • Reordering: Monotone • Maximum Distortion Length: 0 With above parameter setup, the results are produced from the following five different systems. • Baseline System (BS): For the standard task, we use only given official training data 3 to construct translation model and language model for our base system. • Expanded Resource (ER): For all fou</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2009</marker>
<rawString>Haizhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2009. Whitepaper of news 2009 machine transliteration shared task. In Proceedings of ACL-IJCNLP 2009 Named Entities Workshop (NEWS 2009), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<contexts>
<context position="5167" citStr="Och and Ney, 2003" startWordPosition="794" endWordPosition="797">d allows each Eumjeol to consist of either two or three of the 24 Korean letters, with (1) leading 14 consonants, (2) intermediate 10 vowels, and (3) optionally, trailing 7 consonants (out of the possible 14). Therefore, Korean Eumjeol should be decomposed into letters before performing training or decoding any input. Consequently, after the letter-unit transliteration is finished, all the letters should be re-composed to form a correct sequence of Eumjeols. Figure 1 shows the overall architecture of our system. The alignment between English letter and Korean letter is performed using GIZA++ (Och and Ney, 2003). We use MOSES decoder in order to search the best sequence of transliteration. In this paper we focus on describing factored phrase-based training and n-best re-ranking techniques including a Web-based method, a pronouncing dictionary-based method, and a phonicsbased method. Figure 2: Alignment example between ‘Knight’ and ‘�+��� [naiteu]’ 2.1 Factored Phrase-based Training Koehn and Hoang (2007) introduces an integration of different information for phrase-based SMT model. We report on experiments with three factors: surface form, positional information, and the type of a letter. Surface for</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Strickland</author>
</authors>
<title>Teaching phonics today: A primer for educators. International Reading Association.</title>
<date>1998</date>
<contexts>
<context position="9069" citStr="Strickland, 1998" startWordPosition="1410" endWordPosition="1411">r pronunciation information by using an internal code table. The internal code table represents mappings from each phonetic symbol to a single character within ASCII code table. Our pronouncing dictionary includes a list of words and their pronunciation information. For a given English word, if the word exists in the pronouncing dictionary, then its pronunciations are translated to Korean graphemes by a mapping table and transformation rules, which are defined by “Oeraeeo pyogibeop”. 2.4 Phonics-based Method Phonics is a pronunciation-based linguistic teaching method, especially for children (Strickland, 1998). Originally, it was designed to connect the sounds of spoken English with group of English letters. In this research, we modify the phonics in order to connect English sounds to Korean letter because in Korean there is nearly a one-to-one correspondence between sounds and the letter patterns that represent them. For example, alphabet ‘b’ can be pronounced to ‘ii’(bieup) in Korean. Consequently, we construct about 150 rules which map English alphabet into one or more several Korean graphemes, by referring to the phonics. Though phonics cannot reveal all of the pro2http://www.speech.cs.cmu.edu/</context>
</contexts>
<marker>Strickland, 1998</marker>
<rawString>D.S. Strickland. 1998. Teaching phonics today: A primer for educators. International Reading Association.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>