Multilingual Coreference Resolution
Sanda M. Harabagiu Steven J. Maiorano
Southern Methodist University IPO
Dallas, TX 75275-0122 Washington, D.C. 20505
sandaseas.smu.edu mai orano@c ai s . corn
Abstract
In this paper we present a new, multilingual data-driven method for coreference
resolution as implemented in the SWIZZLE
system. The results obtained after training
this system on a bilingual corpus of English
and Romanian tagged texts, outperformed
coreference resolution in each of the individual languages.
1 Introduction
The recent availability of large bilingual corpora has
spawned interest in several areas of multilingual text
processing. Most of the research has focused on
bilingual terminology identification, either as parallel multiwords forms (e.g. the Champolhon system (Smadja et al.1996)), technical terminology (e.g.
the Termight system (Dagan and Church, 1994) or
broad-coverage translation lexicons (e.g. the SABLE
system (Resnik and Melamed, 1997)). In addition,
the Multilingual Entity Task (MET) from the TIPSTER program' (http://www-nipir.nist.gov/relatedprojects/tipster/met.htm) challenged the participants in the Message Understanding Conference
(MUC) to extract named entities across several foreign language corpora, such as Chinese, Japanese
and Spanish.
In this paper we present a new application of
aligned multilingual texts. Since coreference resolution is a pervasive discourse phenomenon causing
performance impediments in current IE systems, we
considered a corpus of aligned English and Romanian texts to identify coreferring expressions. Our
task focused on the same kind of coreference as
considered in the past MUC competitions, namely
'The TIPSTER Text Program was a DARPA-led
government effort to advance the state of the art in text
processing technologies.
the identity coreference. Identity coreference links
nouns, pronouns and noun phrases (including proper
names) to their corresponding antecedents.
We created our bilingual collection by translating
the MUC-6 and MUC-7 coreference training texts
into Romanian using native speakers. The training data set for Romanian coreference used, wherever possible, the same coreference identifiers as the
English data and incorporated additional tags as
needed. Our claim is that by adding the wealth
of coreferential features provided by multilingual
data, new powerful heuristics for coreference resolution can be developed that outperform monolingual
coreference resolution systems.
For both languages, we resolved coreference by
using SWIZZLE, our implementation of a bilingual
coreference resolver. SWIZZLE is a multilingual enhancement of COCKTAIL (Harabagiu and Maiorano,
1999), a coreference resolution system that operates
on a mixture of heuristics that combine semantic
and textual cohesive information'. When COCKTAIL
was applied separately on the English and the Romanian texts, coreferring links were identified for
each English and Romanian document respectively.
When aligned referential expressions corefer with
non-aligned anaphors, SWIZZLE derived new heuristics for coreference. Our experiments show that
SWIZZLE outperformed COCKTAIL on both English
and Romanian test documents.
The rest of the paper is organized as follows. Section 2 presents COCKTAIL, a monolingual coreference
resolution system used separately on both the English and Romanian texts. Section 3 details the
data-driven approach used in SWIZZLE and presents
some of its resources. Section 4 reports and discusses
the experimental results. Section 5 summarizes the
'The name of COCKTAIL is a pun on CogNIAC because COCKTAIL combines a larger number of heuristics
than those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual
aligned corpus.
142
conclusions.
2 COCKTAIL
Currently, some of the best-performing and
most robust coreference resolution systems employ
knowledge-based techniques. Traditionally, these
techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition
of such knowledge is time-consuming, difficult, and
error-prone. Nevertheless, recent results show that
knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev,
1996) (Kameyama, 1997)). For example, CogNIAC
(Baldwin, 1997), a system based on seven ordered
heuristics, generates high-precision resolution (over
90%) for some cases of pronominal reference. For
this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to
various forms of coreference. This system, called
COCKTAIL, resolves coreference by exploiting several
textual cohesion constraints (e.g. term repetition)
combined with lexical and textual coherence cues
(e.g. subjects of communication verbs are more
likely to refer to the last person mentioned in the
text). These constraints are implemented as a set of
heuristics ordered by their priority. Moreover, the
COCKTAIL framework uniformly addresses the problem of interaction between different forms of coreference, thus making the extension to multilingual
coreference very natural.
2.1 Data-Driven Coreference Resolution
In general, we define a data-driven methodology as
a sequence of actions that captures the data patterns capable of resolving a problem with both a
high degree of precision and recall. Our data-driven
methodology reported here generated sets of heuristics for the coreference resolution problem. Precision
is the number of correct references out of the total
number of coreferences resolved, whereas the recall
measures the number of resolved references out of
the total number of keys, i.e., the annotated coreference data.
The data-driven methodology used in COCKTAIL is
centered around the notion of a coreference chain.
Due to the transitivity of coreference relations, k
coreference relations having at least one common argument generate k + 1 coreferring expressions. The
text position induces an order among coreferring expressions. A coreference structure is created when
a set of coreferring expressions are connected in an
oriented graph such that each node is related only
to one of its preceding nodes. In turn, a coreference chain is the coreference structure in which every node is connected to its immediately preceding
node. Clearly, multiple coreference structures for the
same set of coreferring expressions can be mapped
to a single coreference chain. As an example, both
coreference structures illustrated in Figure 1(a) and
(c) are cast into the coreference chain illustrated in
Figure 1(b).
TEXT TEXT TEXT
(a) (b) (c)
Figure 1: Three coreference structures.
Given a corpus annotated with coreference data,
the data-driven methodology first generates all
coreference chains in the data set and then considers all possible combinations of coreference relations that would generate the same coreference
chains. For a coreference chain of length 1 with
nodes n1, n2, ... ni±i , each node nk (1<k<l) can
be connected to any of the 1 — k nodes preceding
it. From this observation, we find that a number
of 1 x 2 x x (/ — k)... x = 1! coreference structures can generate the same coreference chain. This
result is very important, since it allows for the automatic generation of coreference data. For each coreference relation R. from an annotated corpus we created a median of (1 — 1)! new coreference relations,
where 1 is the length of the coreference chain containing relation 7Z. This observation gave us the possibility of expanding the test data provided by the
coreference keys available in the MUC-6 and MUC7 competitions (MUC-6 1996), (MUC-7 1998). The
MUC-6 coreference annotated corpus contains 1626
coreference relations, while the MUC-7 corpus has
2245 relations. The average length of a coreference
chain is 7.21 for the MUC-6 data, and 8.57 for the
MUC-7 data. We were able to expand the number
of annotated coreference relations to 6,095,142 for
the MUC-6 corpus and to 8,269,403 relations for the
MUC-7 corpus; this represents an expansion factor
of 3,710. We are not aware of any other automated
way of creating coreference annotated data, and we
believe that much of the COCKTAIL's impressive performance is due to the plethora of data provided by
this method.
143
Heuristics for 3rd person pronouns Heuristics for nominal reference
oHeuristic 1-Pronoun(H1Pron) oHeuristic 1-Nominal(H1Nom)
Search in the same sentence for the same if (Noun is the head of an appositive)
3rd person pronoun Pron' then Pick the preceding NP.
if (Pron' belongs to coreference chain CC) oHeuristic 2-Nomina/(H2Nom)
and there is an element from CC which is if (Noun belongs to an NP, Search for NP'
closest to Pron in Text, Pick that element, such that Noun'=same_name(head(NP),head(NP9)
else Pick Pron'. Or
oHeuristic 2-Pronoun(H2Pron) Noun'=same_name(adjunct(NP),adjunct(NP')))
Search for PN, the closest proper name from Pron then if (Noun' belongs to coreference chain CC)
if (PN agrees in number and gender with Pron) then Pick the element from CC which is
if (PN belongs to coreference chain CC) closest to Noun in Text.
then Pick the element from CC which is else Pick Noun'.
closest to Pron in Text. oHeuristic 3-Nominal(H3Nom)
else Pick PN. if Noun is the head of an NP
oHeuristic 3-Pronoun(H3Pron) then Search for proper name PN
Search for Noun, the closest noun from Pron such that head(PN)=Noun
if (Noun agrees in number and gender with Pron) if (PN belongs to coreference chain CC)
if (Noun belongs to coreference chain CC) and there is an element from CC which is
and there is an element from CC which is closest to Noun in Text, Pick that element.
closest to Pron in Text, Pick that element. else Pick PN.
else Pick Noun
Table 1: Best performing heuristics implemented in COCKTAIL
2.2 Knowledge-Poor Coreference
Resolution
The result of our data-driven methodology is the
set of heuristics implemented in COCKTAIL which
cover both nominal and pronoun coreference. Each
heuristic represents a pattern of coreference that
was mined from the large set of coreference data.
COCKTAIL uses knowledge-poor methods because (a)
it is based only on a limited number of heuristics
and (b) text processing is limited to part-of-speech
tagging, named-entity recognition, and approximate
phrasal parsing. The heuristics from COCKTAIL can
be classified along two directions. First of all, they
can be grouped according to the type of coreference they resolve, e.g., heuristics that resolve the
anaphors of reflexive pronouns operate differently
than those resolving bare nominals. Currently, in
COCKTAIL there are heuristics that resolve five types
of pronouns (personal, possessive, reflexive, demonstrative and relative) and three forms of nominals
(definite, bare and indefinite).
Secondly, for each type of coreference, there are
three classes of heuristics categorized according to
their suitability to resolve coreference. The first
class is comprised of strong indicators of coreference.
This class resulted from the analysis of the distribution of the antecedents in the MUC annotated data.
For example, repetitions of named entities and appositives account for the majority of the nominal
coreferences, and, therefore, represent anchors for
the first class of heuristics.
The second class of coreference covers cases in
which the arguments are recognized to be semantically consistent. COCKTAIL's test of semantic consistency blends together information available from
WordNet and statistics gathered from Treebank.
Different consistency checks are modeled for each of
the heuristics.
Example of the application of heuristic H2Pron
Mr. Adamsi, 69 years old, is the retired chairman
of Canadian-based Emco Ltd., a maker of plumbing
and petroleum equipment; hei has served on the
Woolworth board since 1981.
Example of the application of heuristic H3Pron
&quot;We have got to stop pointing our fingers at these
kids2 who have no future,&quot; he said, &quot;and reach our
hands out to them2.
Example of the application of heuristic H2Nom
The chairman and the chief executive of ficers
of Woolworth Corp. have temporarily relinquished
their posts while the retailer conducts its investigation into alleged accounting irregularities4.
Woolworth's board named John W. Adams, an
outsider, to serve as interim chairman and executive
officers, while a special committee, appointed by
the board last week and led by Mr. Adams,
investigates the alleged irregularities4.
Table 2: Examples of coreference resolution. The
same annotated index indicates coreference.
The third class of heuristics resolves coreference
by coercing nominals. Sometimes coercions involve
only derivational morphology - linking verbs with
their nominalizations. On other occasions, coercions
are obtained as paths of meronyms (e.g. is-part relations) and hypernyms (e.g. is-a relations). Con
144
sistency checks implemented for this class of coreference are conservative: either the adjuncts must be
identical or the adjunct of the referent must be less
specific than the antecedent. Table 1 lists the top
performing heuristics of COCKTAIL for pronominal
and nominal coreference. Examples of the heuristics
operation on the MUC data are presented presented
in Table 2. Details of the top performing heuristics of COCKTAIL were reported in (Harabagiu and
Maiorano, 1999).
2.3 Bootstrapping for Coreference
Resolution
One of the major drawbacks of existing coreference resolution systems is their inability to recognize many forms of coreference displayed by many
real-world texts. Recall measures of current systems
range between 36% and 59% for both knowledgebased and statistical techniques. Knowledge basedsystems would perform better if more coreference
constraints were available whereas statistical methods would be improved if more annotated data were
available. Since knowledge-based techniques outperform inductive methods, we used high-precision
coreference heuristics as knowledge seeds for machine learning techniques that operate on large
amounts of unlabeled data. One such technique
is bootstrapping, which was recently presented in
(Riloff and Jones 1999), (Jones et al.1999) as an
ideal framework for text learning tasks that have
knowledge seeds. The method does not require large
training sets. We extended COCKTAIL by using metabootstrapping of both new heuristics and clusters of
nouns that display semantic consistency for coreference.
The coreference heuristics are the seeds of our
bootstrapping framework for coreference resolution.
When applied to large collections of texts, the
heuristics determine classes of coreferring expressions. By generating coreference chains out of all
these coreferring expressions, often new heuristics
are uncovered. For example, Figure 2 illustrates the
application of three heuristics and the generation of
data for a new heuristic rule. In COCKTAIL, after a
heuristic is applied, a new coreference chain is calculated. For the example illustrated in Figure 2, if
the reference of expression A is sought, heuristic R1
indicates expression B to be the antecedent. When
the coreference chain is built, expression A is directly linked to expression D, thus uncovering a new
heuristic HO.
As a rule of thumb, we do not consider a new
heuristic unless there is massive evidence of its coverage in the data. To measure the coverage we use
the FOIL_Gain measure, as introduced by the FOIL
inductive algorithm (Cameron-Jones and Quinlan
1993). Let Ho be the new heuristic and Hi a heuristic that is already in the seed set. Let po be the number of positive coreference examples of Hne. (i.e.
the number of coreference relations produced by the
heuristic that can be found in the test data) and no
the number of negative examples of Hneu, (i.e. the
number of relations generated by the heuristic which
cannot be found in the test data). Similarly, pi and
ni are the positive and negative examples of Hi.
The new heuristics are scored by their FOIL_Gain
distance to the existing set of heuristics, and the best
scoring one is added to the COCKTAIL system. The
FOIL_Gain formula is:
FOIL_Gain(Hi, Ho) = k(log2 Po log2 )
+ ni po+no
where k is the number of positive examples covered by both Hi and Ho. Heuristic Ho is added to
the seed set if there is no other heuristic providing
larger FOIL_Gain to any of the seed heuristics.
Figure 2: Bootstrapping new heuristics.
Since in COCKTAIL, semantic consistency of coreferring expressions is checked by comparing the similarity of noun classes, each new heuristic determines the adjustment of the similarity threshold of
all known coreferring noun classes. The steps of
the bootstrapping algorithm that learns both new
heuristics and adjusts the similarity threshold of
coreferential expressions is:
MUTUAL BOOTSTRAPPING LOOP
I. Score all candidate heuristics with FOIL_Gain
2. Best_h=closest candidate to heuristics(COCKTAIL)
3. Add Best_h to heuristics(COCKTAIL)
4. Adjust semantic similarity threshold for semantic
consistency of coreferring nouns
5. Goto step 1 if the precision and recall did not
degrade under minimal performance.
(Riloff and Jones 1999) note that the bootstrapping algorithm works well but its performance can
deteriorate rapidly when non-coreferring data enter
as candidate heuristics. To make the algorithm more
robust, a second level of bootstrapping can be introduced. The outer bootstrapping mechanism, called
145
meta-bootstrapping compiles the results of the inner
(mutual) bootstrapping process and identifies the k
most reliable heuristics, where k is a number determined experimentally. These k heuristics are retained and the rest of them are discarded.
3 SWIZZLE
3.1 Multilingual Coreference Data
To study the performance of a data-driven multilingual coreference resolution system, we prepared a
corpus of Romanian texts by translating the MUC-6
and MUC-7 coreference training texts. The translations were performed by a group of four Romanian
native speakers, and were checked for style by a certified translator from Romania. In addition, the Romanian texts were annotated with coreference keys.
Two rules were followed when the annotations were
done:
01: Whenever an expression ER represents a translation of an expression ER from the corresponding
English text, if ER is tagged as a coreference key
with identification number ID, then the Romanian
expression ER is also tagged with the same ID number. This rule allows for translations in which the
textual position of the referent and the antecedent
have been swapped.
.32: Since the translations often introduce new
coreferring expressions in the same chain, the new
expressions are given new, unused ID numbers.
For example, Table 3 lists corresponding English
and Romanian fragments of coreference chains from
the original MUC-6 Wall Street Journal document
DOCNO: 930729-0143.
Table 3 also shows the original MUC coreference
SGML annotations. Whenever present, the REF tag
indicates the ID of the antecedent, whereas the MIN
tag indicates the minimal reference expression.
3.2 Lexical Resources
The multilingual coreference resolution method implemented in SWIZZLE incorporates the heuristics derived from COKCTAIL's monolingual coreference resolution processing in both languages. To this end,
COCKTAIL required both sets of texts to be tagged
for part-of-speech and to recognize the noun phrases.
The English texts were parsed with Brill's part-ofspeech tagger (Brill 1992) and the noun phrases were
identified by the grammar rules implemented in the
phrasal parser of FASTUS (Appelt et al., 1993). Corresponding resources are not available in Romanian.
To minimize COCKTAIL's configuration for processing Romanian texts, we implemented a Romanian
part-of-speech rule-based tagger that used the same
Economic adviser Gene Sperling described
<COREF ID=&quot; 29&quot; TYPE=&quot;IDENT&quot; REF=&quot; 30&quot;>
it< /COREF> as &quot;a true full-court press&quot; to pass
<COREF ID=&quot;31&quot; TYPE=&quot;IDENT&quot; REF=&quot;26&quot;
MIN=&quot;bill&quot; >the <COREF ID=&quot; 32&quot;
TYPE=&quot;IDENT&quot; REF=&quot;10&quot; MIN=&quot;reduction&quot;>
<COREF ID=&quot; 33&quot; TYPE=&quot;IDENT&quot; REF=&quot;12&quot;>
deficit< /COREF>-reduction< /COREF>
bill, the final version of which is now being
hammered out by <COREF ID=&quot; 43&quot; >House
< /COREF> and <COREF ID=&quot; 41&quot; >Senate
< /COREF>negotiators< /COREF>.
<COREF ID=&quot; 34&quot; TYPE=&quot;IDENT&quot; REF=&quot; 2&quot;>
The executives< /COREF>' backing - however tepid
- gives the administration a way to counter
<COREF ID=&quot; 35&quot; TYPE.&quot; IDENT&quot; REF=&quot; 36&quot;>
business< /COREF> critics of <COREF ID=&quot; 500&quot;
TYPE=&quot;IDENT&quot; REF=&quot; 31&quot; MIN=&quot; package&quot;
STATUS=&quot;OPT&quot;>the overall package
< /COREF>,...
Consilierul cu probleme economice Gene Sperling a
descris-&lt;COREF ID=&quot; 29&quot; TYPE=&quot;IDENT&quot;
REF=&quot;30&quot;>o< /COREF> ca pe un efort de
avengurg menit sà promoveze <COREF ID=&quot;1125&quot;
TYPE=&quot; IDENT&quot; REF=&quot; 26&quot; MIN=&quot; legea&quot; >legea
< /COREF> pentru <COREF TYPE=&quot;IDENT&quot;
REF=&quot;10&quot; MIN=&quot;reducerea&quot;> reducerea
< /COREF> <COREF ID=&quot; 33&quot; TYPE=&quot; IDENT&quot;
REF=&quot;12&quot;> deficitului in bugetul SUA< /COREF>.
Versiunea finala a acestei <COREF ID=&quot;1126&quot;
TYPE=&quot;IDENT&quot; REF=&quot;1125&quot; MIN=&quot;legi&quot;>legi
< /COREF> este desfiintatA chiax in aceste
zile in cadrul dezbaterilor cc an loc in
<COREF ID=&quot;43&quot; >Camera Reprezentativilor
< /COREF> §i in <COREF ID=&quot;41&quot;>
Senat< /COREF>< /COREF>.
Sprijinirea <COREF ID=&quot;127&quot; TYPE=&quot;IDENT&quot;
REF=&quot;1126&quot; MIN=&quot;legii&quot; >legii> /COREF>
de care speciali§ti in economie - dei
in maniera,' moderata - ofer5, administratiei o
modalitate de a contrabalansa criticile aduse
<COREF ID=&quot; 500&quot; TYPE=&quot;IDENT&quot; REF=&quot; 31&quot;
MIN=&quot; legii&quot; STATUS=&quot; OPT&quot; >legii< /COREF>
de care companiile americane,...
Table 3: Example of parallel English and Romanian
text annotated for coreference. The elements from a
coreference chain in the respective texts are underlined. The English text has only two elements in the
coreference chain, whereas the Romanian text contains four different elements. The two additional elements of the Romanian coreference chain are derived
due to (1) the need to translate the relative clause
from the English fragment into a separate sentence
in Romanian; and (2) the reordering of words in the
second sentence.
146
tags as generated by the Brill tagger. In addition,
we implemented rules that identify noun phrases in
Romanian.
To take advantage of the aligned corpus, SWIZZLE
also relied on bilingual lexical resources that help
translate the referential expressions. For this
purpose, we used a core Romanian WordNet
(Harabagiu, 1999) which encoded, wherever possible, links between the English synsets and their Romanian counterparts. This resource also incorporated knowledge derived from several bilingual dictionaries (e.g. (Banta, 1969)).
Having the parallel coreference annotations, we
can easily identify their translations because they
have the same identification coreference key. Looking at the example given in Table 3, the expression &quot;legii&quot;, with ID=500 is the translation of the
expression &quot;package&quot;, having the same ID in the
English text. However, in the test set, the REF
fields are intentionally voided, entrusting COCKTAIL
to identify the antecedents. The bilingual coreference resolution performed in SWIZZLE, however, requires the translations of the English and Romanian
antecedents. The principles guiding the translations
of the English and Romanian antecedents (AE—R
and AR—E, respectively) are:
• Circularity: Given an English antecedent, due to
semantic ambiguity, it can belong to several English
WordNet sysnsets. For each such sysnset ST we consider the Romanian corresponding sysnet(s) SJ. We
filter out all Sr that do not contain AE—R. If only
one Romanian sysnset is left, then we identified a
translation. Otherwise, we start from the Romanian antecedent, find all synsets Sf to which it belongs, and obtain the corresponding English sysnets
sr. Similarly, all English synsets not containing
the English antecedent are filtered out. If only one
synset remains, we have again identified a translation. Finally, in the last case, the intersection of
the multiple synsets in either language generates a
legal translation. For example, the English synset
SE .{bill, measure} translates into the Romanian
synset SR =flegel. First, none of the dictionary
translations of bill into Romanian (e.g. politd, bacnotd, aM translate back into any of the elements
of SE. However the translation of measure into the
Romanian lege translates back into bill, its synonym.
• Semantic density: Given an English and a Roma
nian antecedent, to establish whether they are translations of one another, we disambiguate them by first
collapsing all sysnsets that have common elements.
Then we apply the circularity principle, relying on
the semantic alignment encoded in the Romanian
WordNet. When this core lexical database was first
implemented, several other principles were applied.
In our experiment, we were satisfied with the quality of the translations recognized by following only
these two principles.
3.3 Multilingual Coreference Resolution
The SWIZZLE system was run on a corpus of 2335
referential expressions in English (927 from MUC6 and 1408 from MUC-7) and 2851 Romanian expressions (1219 from MUC-6 and 1632 from MUC7). Initially, the heuristics implemented in COCKTAIL
were applied separately to the two textual collections. Several special cases arose.
English Text
Translation
Translation
Figure 3: Case 1 of multilingual coreference
Case I, which is the ideal case, is shown in Figure 3. It occurs when two referential expressions
have antecedents that are translations of one another. This situation occurred in 63.3% of the referential expressions from MUC-6 and in 58.7% of the
MUC-7 references. Over 50% of these are pronouns
or named entities. However, all the non-ideal cases
are more interesting for SWIZZLE, since they port
knowledge that enhances system performance.
English Text
ER: English reference RR: Romanian reference
EA: English antecedent RA: Romanian antecedent
ET: English translation RT: Romanian translation
of Romanian antecedent of English antecedent
Figure 4: Case 2 of multilingual coreference
Case 2 occurs when the antecedents are not translations, but belong to or corefer with elements of
some coreference chains that were already established. Moreover, one of the antecedents is textually
Romanian Text
Coref.
chains Romanian Text
147
closer to its referent. Figure 4 illustrates the case
when the English antecedent is closer to the referent
than the Romanian one.
SWIZZLE Solutions: (1) If the heuristic H(E) used
to resolve the reference in the English text has higher
priority than H(R), which was used to resolve the
reference from the Romanian text, then we first
search for RT, the Romanian translation of EA, the
English antecedent. In the next step, we add heuristic H1 that resolves RR into RT, and give it a higher
priority than H(R). Finally, we also add heuristic H2
that links RT to RA when there is at least one translation between the elements of the coreference chains
containing EA and ET respectively.
(2) If H(R) has higher priority than H(E), heuristic H3 is added while H(E) is removed. We also add
H4 that relates ER to ET, the English translation of
RA.
Case 3 occurs when at least one of the antecedents
starts a new coreference chain (i.e., no coreferring
antecedent can be found in the current chains).
SWIZZLE Solution: If one of the antecedents
corefers with an element from a coreference chain,
then the antecedent in the opposite language is its
translation. Otherwise, SWIZZLE chooses the antecedent returned by the heuristic with highest priority.
4 Results
The foremost contribution of SWIZZLE was that it
improved coreference resolution over both English
and Romanian texts when compared to monolingual
coreference resolution performance in terms of precision and recall. Also relevant was the contribution of
SWIZZLE to the process of understanding the cultural
differences expressed in language and the way these
differences influence coreference resolution. Because
we do not have sufficient space to discuss this issue
in detail here, let us state, in short, that English is
more economical than Romanian in terms of referential expressions. However the referential expressions
in Romanian contribute to the resolution of some of
the most difficult forms of coreference in English.
4.1 Precision and Recall
Table 4 summarizes the precision results for both
English and Romanian coreference. The results indicate that the English coreference is more precise than the Romanian coreference, but SWIZZLE
improves coreference resolution in both languages.
There were 64% cases when the English coreference
was resolved by a heuristic with higher priority than
the corresponding heuristic for the Romanian counterpart. This result explains why there is better precision enhancement for the English coreference.
Nominal Pronominal Total
English 73% 89% 84%
Romanian 66% 78% 72%
SWIZZLE on 76% 93% 87%
English
SWIZZLE on 71% 82% 76%
Romanian
Table 4: Coreference precision
Nominal Pronominal Total
English 69% 89% 78%
Romanian 63% 83% 72%
SWIZZLE on 66% 87% 77%
English
SWIZZLE on 61% 80% 70%
Romanian
Table 5: Coreference recall
Table 5 also illustrates the recall results. The
advantage of the data-driven coreference resolution
over other methods is based on its better recall performance. This is explained by the fact that this
method captures a larger variety of coreference patterns. Even though other coreference resolution systems perform better for some specific forms of reference, their recall results are surpassed by the datadriven approach. Multilingual coreference in turn
improves more the precision than the recall of the
monolingual data-driven coreference systems.
In addition, Table 5 shows that the English coreference results in better recall than Romanian coreference. However, the recall shows a decrease for both
languages for SWIZZLE because imprecise coreference
links are deleted. As is usually the case, deleting
data lowers the recall. All results were obtained by
using the automatic scorer program developed for
the MUC evaluations.
5 Conclusions
We have introduced a new data-driven method for
multilingual coreference resolution, implemented in
the SWIZZLE system. The results of this method
are encouraging since they show clear improvements
over monolingual coreference resolution. Currently,
we are also considering the effects of a bootstrapping algorithm for multilingual coreference resolution. Through this procedure we would learn concurrently semantic consistency knowledge and better performing heuristic rules. To be able to develop such a learning approach, we must first develop
a method for automatic recognition of multilingual
referential expressions.
148
We also believe that a better performance evaluation of SWIZZLE can be achieved by measuring its
impact on several complex applications. We intend
to analyze the performance of SWIZZLE when it is
used as a module in an IE system, and separately in
a Question/Answering system.
Acknowledgements This paper is dedicated to the
memory of our friend Megumi Kameyama, who inspired this work.
References
Douglas E. Appelt, Jerry R. Hobbs, John Bear, David
Israel, Megumi Kameyama and Mabry Tyson. 1993.
The SRI MUC-5 JV-FASTUS Information Extraction
System. In Proceedings of the Fifth Message Understanding Conference (MUC-5).
Brack Baldwin. 1997. CogNIAC: high precision coreference with limited knowledge and linguistic resources.
In Proceedings of the ACL'97/EACL '97 Workshop on
Operational factors in practical, robust anaphora resolution, pages 38-45, Madrid, Spain.
Andrei Banta. 1969. Diction& Roman-Englez, EnlgezRoman. Editura Wintifica, Bucuresti.
David Bean and Ellen Riloff. 1999. Corpus-Based Identification of Non-Anaphoric Noun Phrases. In Proceedings of the 37th Conference of the Assosiation for
Computatioanl Linguistics (ACL-99), pages 373-380.
Eric Brill. A simple rule-based part of speech tagger. In
Proceedings of the Third Conference on Applied Natural Language Processing, pages 152-155,1992.
Joseph F. Cameron-Jones and Ross Quinlan. 1993.
Avoiding Pitfalls When Learning Recursive Theories.
In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93), pages 10501055.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the Joint
Conference on Empirical Methods in NLP and Very
Large Corpora, pages 82-89.
Niyu Ge, John Gale and Eugene Charniak. 1998.
Anaphora Resolution: A Multi-Strategy Approach. In
Proceedings of the 6th Workshop on Very Large Corpora, ( COLING /A CL '98).
Ido Dagan and Ken W. Church. 1994. TERMIGHT:
Identifying and translating technical terminology. In
Proceedings of the 4th ACL Conference on Applied
Natural Language Processing (ANLP-94).
Sanda M. Harabagiu. 1999. Lexical Acquisition for a
Romanian WordNet. Proceeding of the 3rd European
Summer School on Computational Linguistics.
Sanda M. Harabagiu and Steve J. Maiorano. 1999.
Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence. In Proceedings of the Workshop on the Relation of Discourse/Dialogue Structure and Reference, ACL '98,
pages 29-38.
Jerry R. Hobbs. Resolving pronoun references. Lingua,
44:311-338.
Andrew Kehler. 1997. Probabilistic Coreference in Information Extraction. In Proceedings of the Second
Conference on Empirical Methods in Natural Language Processing (SIGDAT), pages 163-173.
Shalom Lappin and Herbert Leass. 1994. An algorithm
for pronominal anaphora resolution. Computational
Linguistics, 20(4):535-562.
Rosie Jones, Andrew McCallum, Kevin Nigam and Ellen
Riloff. 1999. Bootstrapping for Text Learning Tasks.
In Proceedings of the IJCAI-99 Workshop on Text
Mining: Foundations, Techniques, and Applications.
Megumi Kameyama. 1997. Recognizing Referential
Links: An Information Extraction Perspective. In
Proceedings of the Workshop on Operational Factors
in Practical, Robust Anaphora Resolution for Unrestricted Texts, (ACL-97/EACL-97), pages 46-53,
Madrid, Spain.
Christopher Kennedy and Branimir Bogureav. 1996.
Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th
International Conference on Computational Linguistics (COLING-96).
George A. Miller. 1995. WordNet: A Lexical Database.
Communication of the ACM, 38 (11) :39-41.
Ruslan Mitkov. 1998. Robust pronoun resolution
with limited knowledge. In Proceedings of COLINGACL '98, pages 869-875.
1996. Proceedings of the Sixth Message Understanding
Conference (MUC-6),Morgan Kaufmann, San Mateo,
CA.
1998. Proceedings of the Seventh Message Understanding Conference (MUC-7) ,Morgan Kaufmann, San
Mateo, CA.
Philip Resnik and I. Dan Melamed. 1997. SemiAutomatic Acquisition of Domain-Specific Translation
Lexicons. In Proceedings of the 5th ACL Conference
on Applied Natural Language Processing (ANLP-97).
Ellen Riloff and Rosie Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National
Conference on Artificial Intelligence (AAAI-99).
Frank Smadja, Katheleen R. McKeown and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: A statistical approach. Computational Linguistics , 21(1):1-38.
149
Multilingual Coreference Resolution
Sanda M Harabagiu Steven J Maiorano
Southern Methodist University IPO
Dallas, TX 75275-0122 Washington, D.C. 20505
oranoc ai s
In this paper we present a new, multilingual data-driven method for coreference resolution as implemented in the SWIZZLE system. The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages.
Douglas E Appelt
Jerry R Hobbs
John Bear
David Israel
Megumi Kameyama
Mabry Tyson
1993
The SRI MUC-5 JV-FASTUS Information Extraction System. In Proceedings of the Fifth Message Understanding Conference (MUC-5).
tes the ID of the antecedent, whereas the MIN tag indicates the minimal reference expression. 3.2 Lexical Resources The multilingual coreference resolution method implemented in SWIZZLE incorporates the heuristics derived from COKCTAIL's monolingual coreference resolution processing in both languages. To this end, COCKTAIL required both sets of texts to be tagged for part-of-speech and to recognize the noun phrases. The English texts were parsed with Brill's part-ofspeech tagger (Brill 1992) and the noun phrases were identified by the grammar rules implemented in the phrasal parser of FASTUS (Appelt et al., 1993). Corresponding resources are not available in Romanian. To minimize COCKTAIL's configuration for processing Romanian texts, we implemented a Romanian part-of-speech rule-based tagger that used the same Economic adviser Gene Sperling described <COREF ID=&quot; 29&quot; TYPE=&quot;IDENT&quot; REF=&quot; 30&quot;> it< /COREF> as &quot;a true full-court press&quot; to pass <COREF ID=&quot;31&quot; TYPE=&quot;IDENT&quot; REF=&quot;26&quot; MIN=&quot;bill&quot; >the <COREF ID=&quot; 32&quot; TYPE=&quot;IDENT&quot; REF=&quot;10&quot; MIN=&quot;reduction&quot;> <COREF ID=&quot; 33&quot; TYPE=&quot;IDENT&quot; REF=&quot;12&quot;> deficit< /COREF>-reduction< /COREF> bill, the final version of which is now being hammered out by <COREF ID=&quot; 43&quot; >House
Appelt, Hobbs, Bear, Israel, Kameyama, Tyson, 1993
Douglas E. Appelt, Jerry R. Hobbs, John Bear, David Israel, Megumi Kameyama and Mabry Tyson. 1993. The SRI MUC-5 JV-FASTUS Information Extraction System. In Proceedings of the Fifth Message Understanding Conference (MUC-5).
Brack Baldwin
CogNIAC: high precision coreference with limited knowledge and linguistic resources.
1997
In Proceedings of the ACL'97/EACL '97 Workshop on Operational factors in practical, robust anaphora resolution,
38--45
Madrid,
stics for coreference. Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents. The rest of the paper is organized as follows. Section 2 presents COCKTAIL, a monolingual coreference resolution system used separately on both the English and Romanian texts. Section 3 details the data-driven approach used in SWIZZLE and presents some of its resources. Section 4 reports and discusses the experimental results. Section 5 summarizes the 'The name of COCKTAIL is a pun on CogNIAC because COCKTAIL combines a larger number of heuristics than those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIA
Baldwin, 1997
Brack Baldwin. 1997. CogNIAC: high precision coreference with limited knowledge and linguistic resources. In Proceedings of the ACL'97/EACL '97 Workshop on Operational factors in practical, robust anaphora resolution, pages 38-45, Madrid, Spain.
Andrei Banta
1969
Diction& Roman-Englez, EnlgezRoman. Editura Wintifica,
Bucuresti.
e sentence in Romanian; and (2) the reordering of words in the second sentence. 146 tags as generated by the Brill tagger. In addition, we implemented rules that identify noun phrases in Romanian. To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions. For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possible, links between the English synsets and their Romanian counterparts. This resource also incorporated knowledge derived from several bilingual dictionaries (e.g. (Banta, 1969)). Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key. Looking at the example given in Table 3, the expression &quot;legii&quot;, with ID=500 is the translation of the expression &quot;package&quot;, having the same ID in the English text. However, in the test set, the REF fields are intentionally voided, entrusting COCKTAIL to identify the antecedents. The bilingual coreference resolution performed in SWIZZLE, however, requires the translations of the English and Romanian antecedents. The principles guiding the translat
Banta, 1969
Andrei Banta. 1969. Diction& Roman-Englez, EnlgezRoman. Editura Wintifica, Bucuresti.
David Bean
Ellen Riloff
Corpus-Based Identification of Non-Anaphoric Noun Phrases.
1999
In Proceedings of the 37th Conference of the Assosiation for Computatioanl Linguistics (ACL-99),
373--380
Bean, Riloff, 1999
David Bean and Ellen Riloff. 1999. Corpus-Based Identification of Non-Anaphoric Noun Phrases. In Proceedings of the 37th Conference of the Assosiation for Computatioanl Linguistics (ACL-99), pages 373-380.
Eric Brill
A simple rule-based part of speech tagger.
In Proceedings of the Third Conference on Applied Natural Language Processing,
152--155
Brill, 
Eric Brill. A simple rule-based part of speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, pages 152-155,1992.
Joseph F Cameron-Jones
Ross Quinlan
Avoiding Pitfalls When Learning Recursive Theories.
1993
In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93),
1050--1055
 of data for a new heuristic rule. In COCKTAIL, after a heuristic is applied, a new coreference chain is calculated. For the example illustrated in Figure 2, if the reference of expression A is sought, heuristic R1 indicates expression B to be the antecedent. When the coreference chain is built, expression A is directly linked to expression D, thus uncovering a new heuristic HO. As a rule of thumb, we do not consider a new heuristic unless there is massive evidence of its coverage in the data. To measure the coverage we use the FOIL_Gain measure, as introduced by the FOIL inductive algorithm (Cameron-Jones and Quinlan 1993). Let Ho be the new heuristic and Hi a heuristic that is already in the seed set. Let po be the number of positive coreference examples of Hne. (i.e. the number of coreference relations produced by the heuristic that can be found in the test data) and no the number of negative examples of Hneu, (i.e. the number of relations generated by the heuristic which cannot be found in the test data). Similarly, pi and ni are the positive and negative examples of Hi. The new heuristics are scored by their FOIL_Gain distance to the existing set of heuristics, and the best scoring one is added to the COCKT
Cameron-Jones, Quinlan, 1993
Joseph F. Cameron-Jones and Ross Quinlan. 1993. Avoiding Pitfalls When Learning Recursive Theories. In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93), pages 1050-1055.
Claire Cardie
Kiri Wagstaff
Noun phrase coreference as clustering.
1999
In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora,
82--89
Cardie, Wagstaff, 1999
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora, pages 82-89.
Niyu Ge
John Gale
Eugene Charniak
Anaphora Resolution: A Multi-Strategy Approach.
1998
In Proceedings of the 6th Workshop on Very Large Corpora, ( COLING /A CL '98).
Ge, Gale, Charniak, 1998
Niyu Ge, John Gale and Eugene Charniak. 1998. Anaphora Resolution: A Multi-Strategy Approach. In Proceedings of the 6th Workshop on Very Large Corpora, ( COLING /A CL '98).
Ido Dagan
Ken W Church
TERMIGHT: Identifying and translating technical terminology.
1994
In Proceedings of the 4th ACL Conference on Applied Natural Language Processing (ANLP-94).
 method for coreference resolution as implemented in the SWIZZLE system. The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages. 1 Introduction The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing. Most of the research has focused on bilingual terminology identification, either as parallel multiwords forms (e.g. the Champolhon system (Smadja et al.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)). In addition, the Multilingual Entity Task (MET) from the TIPSTER program' (http://www-nipir.nist.gov/relatedprojects/tipster/met.htm) challenged the participants in the Message Understanding Conference (MUC) to extract named entities across several foreign language corpora, such as Chinese, Japanese and Spanish. In this paper we present a new application of aligned multilingual texts. Since coreference resolution is a pervasive discourse phenomenon causing performance impediments in current IE systems, 
Dagan, Church, 1994
Ido Dagan and Ken W. Church. 1994. TERMIGHT: Identifying and translating technical terminology. In Proceedings of the 4th ACL Conference on Applied Natural Language Processing (ANLP-94).
Sanda M Harabagiu
Lexical Acquisition for a Romanian WordNet.
1999
Proceeding of the 3rd European Summer School on Computational Linguistics.
nian text contains four different elements. The two additional elements of the Romanian coreference chain are derived due to (1) the need to translate the relative clause from the English fragment into a separate sentence in Romanian; and (2) the reordering of words in the second sentence. 146 tags as generated by the Brill tagger. In addition, we implemented rules that identify noun phrases in Romanian. To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions. For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possible, links between the English synsets and their Romanian counterparts. This resource also incorporated knowledge derived from several bilingual dictionaries (e.g. (Banta, 1969)). Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key. Looking at the example given in Table 3, the expression &quot;legii&quot;, with ID=500 is the translation of the expression &quot;package&quot;, having the same ID in the English text. However, in the test set, the REF fields are intentionally voided, entrusting C
Harabagiu, 1999
Sanda M. Harabagiu. 1999. Lexical Acquisition for a Romanian WordNet. Proceeding of the 3rd European Summer School on Computational Linguistics.
Sanda M Harabagiu
Steve J Maiorano
Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence.
1999
In Proceedings of the Workshop on the Relation of Discourse/Dialogue Structure and Reference, ACL '98,
29--38
 into Romanian using native speakers. The training data set for Romanian coreference used, wherever possible, the same coreference identifiers as the English data and incorporated additional tags as needed. Our claim is that by adding the wealth of coreferential features provided by multilingual data, new powerful heuristics for coreference resolution can be developed that outperform monolingual coreference resolution systems. For both languages, we resolved coreference by using SWIZZLE, our implementation of a bilingual coreference resolver. SWIZZLE is a multilingual enhancement of COCKTAIL (Harabagiu and Maiorano, 1999), a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information'. When COCKTAIL was applied separately on the English and the Romanian texts, coreferring links were identified for each English and Romanian document respectively. When aligned referential expressions corefer with non-aligned anaphors, SWIZZLE derived new heuristics for coreference. Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents. The rest of the paper is organized as follows. Section 2 presents COCKTAIL, a monoli
owledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of communication verbs are more likely to refer to the last person mentioned in the text). These constraints are implemented as a set of heuristics ordered by their priority. Moreover, the COCKTAIL framework uniformly addresses the problem of interaction between different forms of coreference, thus making the extens
their nominalizations. On other occasions, coercions are obtained as paths of meronyms (e.g. is-part relations) and hypernyms (e.g. is-a relations). Con144 sistency checks implemented for this class of coreference are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent. Table 1 lists the top performing heuristics of COCKTAIL for pronominal and nominal coreference. Examples of the heuristics operation on the MUC data are presented presented in Table 2. Details of the top performing heuristics of COCKTAIL were reported in (Harabagiu and Maiorano, 1999). 2.3 Bootstrapping for Coreference Resolution One of the major drawbacks of existing coreference resolution systems is their inability to recognize many forms of coreference displayed by many real-world texts. Recall measures of current systems range between 36% and 59% for both knowledgebased and statistical techniques. Knowledge basedsystems would perform better if more coreference constraints were available whereas statistical methods would be improved if more annotated data were available. Since knowledge-based techniques outperform inductive methods, we used high-precision coreference he
Harabagiu, Maiorano, 1999
Sanda M. Harabagiu and Steve J. Maiorano. 1999. Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence. In Proceedings of the Workshop on the Relation of Discourse/Dialogue Structure and Reference, ACL '98, pages 29-38.
Jerry R Hobbs
Resolving pronoun references.
Lingua,
44--311
Hobbs, 
Jerry R. Hobbs. Resolving pronoun references. Lingua, 44:311-338.
Andrew Kehler
Probabilistic Coreference in Information Extraction.
1997
In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (SIGDAT),
163--173
Kehler, 1997
Andrew Kehler. 1997. Probabilistic Coreference in Information Extraction. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (SIGDAT), pages 163-173.
Shalom Lappin
Herbert Leass
An algorithm for pronominal anaphora resolution.
1994
Computational Linguistics,
20--4
Lappin, Leass, 1994
Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-562.
Rosie Jones
Andrew McCallum
Kevin Nigam
Ellen Riloff
Bootstrapping for Text Learning Tasks.
1999
In Proceedings of the IJCAI-99 Workshop on Text Mining: Foundations, Techniques, and Applications.
Jones, McCallum, Nigam, Riloff, 1999
Rosie Jones, Andrew McCallum, Kevin Nigam and Ellen Riloff. 1999. Bootstrapping for Text Learning Tasks. In Proceedings of the IJCAI-99 Workshop on Text Mining: Foundations, Techniques, and Applications.
Megumi Kameyama
Recognizing Referential Links: An Information Extraction Perspective.
1997
In Proceedings of the Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts, (ACL-97/EACL-97),
46--53
Madrid,
han those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of communication verbs are more likely to refer to the 
Kameyama, 1997
Megumi Kameyama. 1997. Recognizing Referential Links: An Information Extraction Perspective. In Proceedings of the Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts, (ACL-97/EACL-97), pages 46-53, Madrid, Spain.
Christopher Kennedy
Branimir Bogureav
Anaphora for everyone: Pronominal anaphora resolution without a parser.
1996
In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).
Kennedy, Bogureav, 1996
Christopher Kennedy and Branimir Bogureav. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).
George A Miller
WordNet: A Lexical Database.
1995
Communication of the ACM,
38
11
39--41
Miller, 1995
George A. Miller. 1995. WordNet: A Lexical Database. Communication of the ACM, 38 (11) :39-41.
Ruslan Mitkov
Robust pronoun resolution with limited knowledge.
1998
In Proceedings of COLINGACL '98,
869--875
TAIL combines a larger number of heuristics than those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of commu
Mitkov, 1998
Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of COLINGACL '98, pages 869-875.
1996
Proceedings of the Sixth Message Understanding Conference (MUC-6),Morgan Kaufmann,
San Mateo, CA.
1996
1996. Proceedings of the Sixth Message Understanding Conference (MUC-6),Morgan Kaufmann, San Mateo, CA.
1998
Proceedings of the Seventh Message Understanding Conference (MUC-7)
Morgan Kaufmann,
San Mateo, CA.
1998
1998. Proceedings of the Seventh Message Understanding Conference (MUC-7) ,Morgan Kaufmann, San Mateo, CA.
Philip Resnik
I Dan Melamed
SemiAutomatic Acquisition of Domain-Specific Translation Lexicons.
1997
In Proceedings of the 5th ACL Conference on Applied Natural Language Processing (ANLP-97).
tained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages. 1 Introduction The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing. Most of the research has focused on bilingual terminology identification, either as parallel multiwords forms (e.g. the Champolhon system (Smadja et al.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)). In addition, the Multilingual Entity Task (MET) from the TIPSTER program' (http://www-nipir.nist.gov/relatedprojects/tipster/met.htm) challenged the participants in the Message Understanding Conference (MUC) to extract named entities across several foreign language corpora, such as Chinese, Japanese and Spanish. In this paper we present a new application of aligned multilingual texts. Since coreference resolution is a pervasive discourse phenomenon causing performance impediments in current IE systems, we considered a corpus of aligned English and Romanian texts to identify coreferring expr
Resnik, Melamed, 1997
Philip Resnik and I. Dan Melamed. 1997. SemiAutomatic Acquisition of Domain-Specific Translation Lexicons. In Proceedings of the 5th ACL Conference on Applied Natural Language Processing (ANLP-97).
Ellen Riloff
Rosie Jones
Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.
1999
In Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99).
layed by many real-world texts. Recall measures of current systems range between 36% and 59% for both knowledgebased and statistical techniques. Knowledge basedsystems would perform better if more coreference constraints were available whereas statistical methods would be improved if more annotated data were available. Since knowledge-based techniques outperform inductive methods, we used high-precision coreference heuristics as knowledge seeds for machine learning techniques that operate on large amounts of unlabeled data. One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et al.1999) as an ideal framework for text learning tasks that have knowledge seeds. The method does not require large training sets. We extended COCKTAIL by using metabootstrapping of both new heuristics and clusters of nouns that display semantic consistency for coreference. The coreference heuristics are the seeds of our bootstrapping framework for coreference resolution. When applied to large collections of texts, the heuristics determine classes of coreferring expressions. By generating coreference chains out of all these coreferring expressions, often new heuristics are uncovere
asses, each new heuristic determines the adjustment of the similarity threshold of all known coreferring noun classes. The steps of the bootstrapping algorithm that learns both new heuristics and adjusts the similarity threshold of coreferential expressions is: MUTUAL BOOTSTRAPPING LOOP I. Score all candidate heuristics with FOIL_Gain 2. Best_h=closest candidate to heuristics(COCKTAIL) 3. Add Best_h to heuristics(COCKTAIL) 4. Adjust semantic similarity threshold for semantic consistency of coreferring nouns 5. Goto step 1 if the precision and recall did not degrade under minimal performance. (Riloff and Jones 1999) note that the bootstrapping algorithm works well but its performance can deteriorate rapidly when non-coreferring data enter as candidate heuristics. To make the algorithm more robust, a second level of bootstrapping can be introduced. The outer bootstrapping mechanism, called 145 meta-bootstrapping compiles the results of the inner (mutual) bootstrapping process and identifies the k most reliable heuristics, where k is a number determined experimentally. These k heuristics are retained and the rest of them are discarded. 3 SWIZZLE 3.1 Multilingual Coreference Data To study the performance of
Riloff, Jones, 1999
Ellen Riloff and Rosie Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99).
Frank Smadja
Katheleen R McKeown
Vasileios Hatzivassiloglou
Translating collocations for bilingual lexicons: A statistical approach.
1996
Computational Linguistics ,
21--1
Smadja, McKeown, Hatzivassiloglou, 1996
Frank Smadja, Katheleen R. McKeown and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational Linguistics , 21(1):1-38.
