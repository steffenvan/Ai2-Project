Word Sense Disambiguation for Cross-Language Information
Retrieval
Mary Xiaoyong Liu, Ted Diamond, and Anne R. Diekema
School of Information Studies
Syracuse University
Syracuse, NY 13244
xliu03a,mailbox.syr.edu
tdiamonl@twcny.rr.com
diekemar@,mailbox.syr.edu
Abstract
We have developed a word sense
disambiguation algorithm, following Cheng and
Wilensky (1997), to disambiguate among
WordNet synsets. This algorithm is to be used in
a cross-language information retrieval system,
CINDOR, which indexes queries and documents
in a language-neutral concept representation
based on WordNet synsets. Our goal is to
improve retrieval precision through word sense
disambiguation. An evaluation against human
disambiguation judgements suggests promise for
our approach.
1 Introduction
The C1NDOR cross-language information
retrieval system (Diekema et al., 1998) uses an
information structure known as &quot;conceptual
interlingua&quot; for query and document
representation. This conceptual interlingua is a
hierarchically organized multilingual concept
lexicon, which is structured following WordNet
(Miller, 1990). By representing query and
document terms by their WordNet synset
numbers we arrive at essentially a language
neutral representation consisting of synset
numbers representing concepts. This
representation facilitates cross-language retrieval
by matching term synonyms in English as well as
across languages. However, many terms are
polysemous and belong to multiple synsets,
resulting in spurious matches in retrieval. The
noun figure for example appears in 13 synsets in
WordNet 1.6. This research paper describes the
early stages1 of our efforts to develop a word
sense disambiguation (WSD) algorithm aimed at
improving the precision of our cross-language
retrieval system.
2 Related Work
To determine the sense of a word, a WSD
algorithm typically uses the context of the
ambiguous word, external resources such as
machine-readable dictionaries, or a combination
of both. Although dictionaries provide useful
word sense information and thesauri provide
additional information about relationships
between words, they lack pragmatic information
as can be found in corpora. Corpora contain
examples of words that enable the development of
statistical models of word senses and their
contexts Ode and Veronis, 1998; Leacock and
Chodorow, 1998).
There are two general problems with using
corpora however; 1) corpora typically do not
come pre-tagged with manually disambiguated
senses, and 2) corpora are often not large nor
diverse enough for all senses of a word to appear
often enough for reliable statistical models (data
sparseness). Although researchers have tried
sense-tagging corpora automatically by using
either supervised or unsupervised training
methods, we have adopted a WSD algorithm
which avoids the necessity for a sense-tagged
training corpus.
'Please note that the disambiguation research
described in this paper has not yet been extended to
multiple language areas.
35
P(context(w) I synset) P(synset)
P(synseticontext(w)) —
P(context(w))
(1)
The problem of data sparseness is usually
solved by using either smoothing methods, classbased methods, or by relying on similarity-based
methods between words and co-occurrence data.
Since we are using a WordNet-based resource for
retrieval, using class-based methods seems a
natural choice. Appropriate word classes can be
formed by synsets or groups of synsets. The
evidence of a certain sense (synset) is then no
longer dependent on one word but on all the
members of a particular synset.
Yarowsky (1992) used Rogets Thesaurus
categories as classes for WSD. His approach was
based on selecting the most likely Roget category
for nouns given their context of 50 words on
either side. When any of the category indicator
words appeared in the context of an ambiguous
word, the indicator weights for each category
were summed to determine the most likely
category. The category with the largest sum was
then selected.
A similar approach to that of Yarowslcy was
followed by Cheng and Willensky (1997) who
used a training matrix of associations of words
with a certain category. Their algorithm was
appealing to us because it requires no human
intervention, and more importantly, it avoids the
use of sense-tagged data. Our methodology
described in the next section is therefore based on
Cheng and Wilensky's approach.
Methods to reduce (translation) ambiguity in
cross-language information retrieval have
included using part-of-speech taggers to restrict
the translation options (Davis 1997), applying
pseudo-relevance feedback loops to expand the
query with better terms aiding translation
(Ballesteros and Croft 1997), using corpora for
term translation disambiguation (Ballesteros and
Croft, 1998), and weighted Boolean models
which tend to have a self-disambiguating quality
(Hull, 1997; Diekema et al., 1999; Hiemstra and
Kraaij, 1999).
3 Methodology
To disambiguate a given word, we would like
to know the probability that a sense occurs in a
given context, i.e., P(sensecontext). In this study,
WordNet synsets are used to represent word
senses, so P(sensecontext) can be rewritten as
P(synseticontext), for each synset of which that
word is a member For nouns, we defme the
context of word w to be the occurrence of words
in a moving window of 100 words (50 words on
each side) around w2.
By Bayes Theorem, we can obtain the desired
probability by inversion (see equation (1)). Since
we are not specifically concerned with getting
accurate probabilities but rather relative rank
order for sense selection, we ignore P(context(w))
and focus on estimating
P(context(w)Isynset)P(synset). The event space
from which &quot;context(w)&quot; is drawn is the set of
sets of words that ever appear with each other in
the window around w. In other words, w induces
a partition on the set of words. We define
&quot;context(w)&quot; to be true whenever any of the
words in the set appears in the window around w,
and conversely to be false whenever none of the
words in the set appears around w. If we assume
independence of appearance of any two words in
a given context, then we get:
P(synset) x (1- P(w I synset))) (2)
wiecontext
Due to the lack of sense-tagged corpora, we
are not able to directly estimate P(synset) and
P(wiIsynset). Instead, we introduce &quot;noisy
estimators&quot; (Pe(synset) and Pe(wilsynset)) to
approximate these probabilities. In doing so, we
make two assumptions: 1) The presence of any
word wk that belongs to synset Si signals the
presence of si; 2) Any word wk belongs to all its
synsets simultaneously, and with equal
probability. Although the assumptions underlying
the &quot;noisy estimators&quot; are not strictly true, it is
our belief that the &quot;noisy estimators&quot; should work
reasonably well if:
• The words that belong to synset si tend to
appear in similar contexts when sf, is their
intended sense;
• These words do not completely overlap
with the words belonging to some synset
sj ( i j ) that partially overlaps with si;
2 For other parts of speech, the window size should
be much smaller as suggested by previous research.
36
• The common words between si and si
appear in different contexts when si and
s. are their intended senses.
4 The WSD Algorithm
We chose as a basis the algorithms described
by YarrowsIcy (1992) and by Cheng and
Wilensky (1997). In our variation, we use the
synset numbers in WordNet to represent the
senses of a word. Our algorithm learns
associations of WordNet synsets with words in a
surrounding context to determine a word sense. It
consists of two phases.
During the training phase, the algorithm
reads in all training documents in collection and
computes the distance-adjusted weight of cooccurrence of each word with each corresponding
synset. This is done by establishing a 100-word
window around a target word (50 words on each
side), and correlating each synset to which the
target word belongs with each word in the
surrounding window. The result of the training
phase is a matrix of associations of words with
synsets.
In the sense prediction phase, the algorithm
takes as input randomly selected testing
documents or sentences that contain the
polysemous words we want to disambiguate and
exploits the context vectors built in the training
phase by adding up the weighted &quot;votes&quot;. It then
returns a ranked list of probability values
associated with each synset, and chooses the
synset with the highest probability as the sense of
the ambiguous word.
Figure 1 and Figure 2 show an outline of the
algorithm.
In this algorithm, &quot;noisy estimators&quot; are
employed in the sense prediction phase. They are
calculated using following formulas:
M[wi IX]
Pe(Wi)X)
IslcV m[wix]
e (3)
where wi is a stem, x is a given synset,
M[w][x] is a cell in the correlation matrix that
corresponds to word w and synset x, and
1,, M
Pe(x) — [wix]
M[wIY} (4)
where w is any stem in the collection, x
is a given synset, y is any synset ever occurred in
collection.
lineW,yeY
For each document d in collection
read in a noun stem w from d
for each synset s in which w occurs
get the column b in the association matrix M that corresponds to s if the column already
exists; create a new column for s otherwise
for each word stem j appearing in the 100-word window around w
get the row a in M that corresponds to j if the row already exists; create a new
row for j otherwise
add a distance-adjusted weight to M[a][b]
Figure 1: WSD Algorithm: the training phase
Set value = 1
For each word w to be disambiguated
get synsets of w
for each synset x of w
for each w, in the context of w (within the 100-window around w)
calculate Pe(wilx)
value *= ( - Pe(wilx))
P(context(w)lx) = 1 - value
Calculate pe(x)
P(xlcontext(w)) = pc(x)* P(context(w)k)
display a ranked list of the synsets arranged according to their P(xlcontext(w)) in decreasing
order
Figure 2: WSD Algorithm: the sense prediction phase
37
5 Evaluation
As suggested by the WSD literature,
evaluation of word sense disambiguation systems
is not yet standardized (Resnik and Yarowsky,
1997). Some WSD evaluations have been done
using the Brown Corpus as training and testing
resources and comparing the results against
SemCor3, the sense-tagged version of the Brown
Corpus (Agirre and Rigau, 1996; Gonzalo et al.,
1998). Others have used common test suites such
as the 2094-word line data of Leacock et al.
(1993). Still others have tended to use their own
metrics. We chose an evaluation with a userbased component that allowed a ranked list of
sense selection for each target word and enabled
a comprehensive comparison between automatic
and manual WSD results. In addition we wanted
to base the disambiguation matrix on a corpus
that we use for retrieval. This approach allows
for a much richer evaluation than a simple hit-ormiss test. For validation purpose, we will conduct
a fully automatic evaluation against SemCor in
our future efforts.
We use in vitro evaluation in this study, i.e.
the WSD algorithm is tested independent of the
retrieval system. The population consists of all
the nouns in WordNet, after removal of
monosemous nouns, and after removal of a
problematic class of polysemous nouns.4 We
drew a random sample of 87 polysemous nouns5
from this population.
In preparation, for each noun in our sample
we identified all the documents containing that
noun from the Associated Press (AP) newspaper
corpus. The testing document set was then
formed by randomly selecting 10 documents from
the set of identified documents for each of the 87
nouns. In total, there are 867 documents in the
3 SemCor is a semantically sense-tagged corpus
comprising approximately 250, 000 words. The
reported error rate is around 10% for polysemous
words.
4
This class of nouns refers to nouns that are in
synsets in which they are the sole word, or in synsets
whose words were subsets of other synsets for that
noun. This situation makes disambiguation
extremely problematic. This class of noun will be
dealt with in a future version of our algorithm but for
now it is beyond the scope of this evaluation.
5A polysemous noun is defined as a noun that
belongs to two or more synsets.
testing set. The training document set consists of
all the documents in the AP corpus excluding the
above-mentioned 867 documents. For each noun
in our sample, we selected all its corresponding
WordNet noun synsets and randomly selected 10
sentence occurrences with each from one of the
10 random documents.
After collecting 87 polysemous nouns with
10 noun sentences each, we had 870 sentences for
disambiguation. Four human judges were
randomly assigned to two groups with two judges
each, and each judge was asked to disambiguate
275 word occurrences out of which 160 were
unique and 115 were shared with the other judge
in the same group. For each word occurrence, the
judge put the target word's possible senses in
rank order according to their appropriateness
given the context (ties are allowed).
Our WSD algorithm was also fed with the
identical set of 870 word occurrences in the sense
prediction phase and produced a ranked list of
senses for each word occurrence.
Since our study has a matched-group design
in which the subjects (word occurrences) receive
both the treatments and control, the measurement
of variables is on an ordinal scale, and there is no
apparently applicable parametric statistical
procedure available, two nonparametric
procedures -the Friedman two-way analysis of
variance and the Spearman rank correlation
coefficient -were originally chosen as candidates
for the statistical analysis of our results.
However, the number of ties in our results
renders the Spearman coefficient unreliable. We
have therefore concentrated on the Friedman
analysis of our experimental results. We use the
two-alternative test with a=0.05.
The first tests of interest were aimed at
establishing inter-judge reliability across the 115
shared sentences by each pair of judges. The null
hypothesis can be generalized as &quot;There is no
difference in judgments on the same word
occurrences between two judges in the same
group&quot;. Following general steps of conducting a
Friedman test as described by Siegel (1956), we
cast raw ranks in a two-way table having 2
conditions/columns (K = 2) with each of the
human judges in the pair serving as one condition
and 365 subjects/rows (N = 365) which are all
the senses of the 115 word occurrences that were
judged by both human judges. We then ranked
38
N K Xr2 df Rejection region Reject Ho?
First pair of judges 365 2 .003 1 3.84 No
Second pair of judges 380 2 2.5289 1 3.84 No
Figure 3: Statistics for significance tests of inter-judge reliability (a=.05, 2-alt. Test)
N K Xr2 df Rejection region Reject Ho?
Auto WSD vs man. WSD 2840 3 73.217 2 5.99 Yes
vs sense pooling
Auto WSD vs man. WSD 2840 2 3.7356 1 3.84 No
Auto WSD vs sense pooling 2840 2 5.9507 1 3.84 Yes
Man. WSD vs sense pooling 2840 2 126.338 1 3.84 Yes
Figure 4: Statistics for significance tests among automatic WSD, manual WSD,
and sense pooling (a----.05, 2-alt. Test)
the scores in each row from 1 to K (in this case K
is 2), summed the derived ranks in each column,
and calculated Xr2 which is .003. For a=0.05,
degrees of freedom df = 1 (df = K —1), the
rejection region starts at 3.84. Since .003 is
smaller than 3.84, the null hypothesis is not
rejected. Similar steps were used for analyzing
reliability between the second pair of judges. In
both cases, we did not find significant difference
between judges (see Figure 3).
Our second area of interest was the
comparison of automatic WSD, manual WSD,
and &quot;sense pooling&quot;. Sense pooling equates to no
disambiguation, where each sense of a word is
considered equally likely (a tie). The null
hypothesis (Ho) is &quot;There is no difference among
manual WSD, automatic WSD, and sense
pooling (all the conditions come from the same
population)&quot;. The steps for Friedman analysis
were similar to what we did for the inter-judge
reliability test while the conditions and subjects
were changed in each test according to what we
would like to compare. Test results are
summarized in Figure 4. In the three-way
comparison shown in the first row of the table,
we rejected Ho so there was at least one condition
that was from a different population. By further
conducting tests which examined each two of the
above three conditions at a time we found that it
was sense pooling that came from a different
population while manual and automatic WSD
were not significantly different. We can therefore
conclude that our WSD algorithm is better than
no disambiguation.
6 Concluding Remarks
The ambiguity of words may negatively
impact the retrieval performance of a conceptbased information retrieval system like CINDOR.
We have developed a WSD algorithm that uses
all the words in a WordNet synset as evidence of
a given sense and builds an association matrix to
learn the co-occurrence between words and
senses. An evaluation of our algorithm against
human judgements of a small sample of nouns
demonstrated no significant difference between
our automatic ranking of senses and the human
judgements. There was, however, a significant
difference between human judgement and
rankings produced with no disambiguation where
all senses were tied.
These early results are such as to encourage
us to continue our research in this area. In our
future work we must tackle issues associated
with the fine granularity of some WordNet sense
distinctions, synsets which are proper subsets of
other synsets and are therefore impossible to
distinguish, and also extend our evaluation to
multiple languages and to other parts of speech.
The next step in our work will be to evaluate our
WSD algorithm against the manually sensetagged SemCor Corpus for validation, and then
integrate our WSD algorithm into C1NDOR's
processing and evaluate directly the impact on
retrieval performance. We hope to verify that
word sense disambiguation leads to improved
precision in cross-language retrieval.
Acknowledgements
This work was completed under a research
practicum at MNIS-TextWise Labs, Syracuse,
NY. We thank Paraic Sheridan for many useful
discussions and the anonymous reviewers for
constructive comments on the manuscript.
39
References
Agirre, E., and Rigau, G. (1996). Word sense
disambiguation using conceptual density. In:
Proceedings of the 16th International
Conference on Computational Linguistics,
Copenhagen,1996.
Ballesteros, L., and Croft, B. (1997). Phrasal
Translation and Query Expansion Techniques
for Cross-Language Information Retrieval. In:
Proceedings of the Association for Computing
Machinery Special Interest Group on
Information Retrieval (ACM/SIGIR) 20th
International Conference on Research and
Development in Information Retrieval; 1997
July 25-31; Philadelphia, PA. New York, NY:
ACM, 1997. 84-91.
Ballesteros, L., and Croft, B. (1998). Resolving
Ambiguity for Cross-language Retrieval. In:
Proceedings of the Association for Computing
Machinery Special Interest Group on
Information Retrieval (ACM/SIGIR) 21st
International Conference on Research and
Development in Information Retrieval; 1998
August 24-28; Melbourne, Australia. New York,
NY: ACM, 1998. 64-71.
Cheng, I., and Wilensky, R. (1997). An Experiment
in Enhancing Information Access by Natural
Language Processing. UC Berkeley Computer
Science Technical Report UCB/CSD
UCB//CSD-97-963.
Davis, M. (1997). New Experiments in CrossLanguage Text Retrieval at NMSU's Computing
Research Lab. In: D.K. Harman, Ed. The Fifth
Text Retrieval Conference (7'REC-5). 1996,
November. National Institute of Standards and
Technology (NIST), Gaithersburg, MD.
Diekema, A., Oroumchian, F., Sheridan, P., and
Liddy, E. D. (1999). TREC-7 Evaluation of
Conceptual Interlingua Document Retrieval
(CINDOR) in English and French. In: E.M.
Voorhees and D.K. Harman (Eds.) The Seventh
Text REtrieval Conference (7REC-7). 1998,
November 9-11; National Institute of Standards
and Technology (NIST), Gaithersburg, MD.
169-180.
Gonzalo, J., Verdejo, F., Chugur, I., and Cigarran, J.
(1998). Indexing with WordNet synsets can
improve text retrieval. In: Proceedings of the
COLING/ACL Workshop on Usage of WordNet
in Natural Language Processing Systems,
Montreal, 1998.
Hiemstra, D., and Kraaij, W. (1999). Twenty-One at
TREC-7: Ad-hoc and Cross-language Track. In:
E.M. Voorhees and D.K. Harman (Eds.) The
Seventh Text REtrieval Conference (TREC-7).
1998, November 9-11; National Institute of
Standards and Technology (NIST),
Gaithersburg, MD. 227-238.
Hull, D. A. (1997). Using Structured Queries for
Disambiguation in Cross-Language Information
Retrieval. In: American Association for
Artificial Intelligence (AAA° Symposium on
Cross-Language Text and Speech Retrieval;
1997 March 24-26; Palo Alto, CA 1997. 84-98.
Ide, N., and Veronis, J. (1998). Introduction to the
Special Issue on Word Sense Disambiguation:
The State of the Art. Computational Linguistics,
Vol. 24, No. 1, 1-40.
Leacock, C., and Chodorow, M. (1998). Combining
Local Context and WordNet Similarity for Word
Sense Identification. In: Christiane Fellbaum
(Eds.) WordNet: An Electronic Lexical
Database. Cambridge, MA: MIT Press.
Leacock, C., Towell, G., and Voorhees, E. (1993).
Corpus-based Statistical Sense Resolution. In:
Proceedings, ARPA Human Language
Technology Workshop, Plainsboro, NJ. 260-265.
Miller, G. (1990). WordNet: An On-line Lexical
Database. International Journal of
Lexicography, Vol. 3, No. 4, Special Issue.
Resnik, P., and Yarowslcy, D. (1997). A Perspective
on Word Sense Disambiguation Methods and
Their Evaluation, position paper presented at the
ACL SIGLEX Workshop on Tagging Text with
Lexical Semantics: Why, What, and How?, held
April 4-5, 1997 in Washington, D.C., USA in
conjunction with ANLP-97.
Siegel, S. (1956). Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw-Hill,
1956.
Yarowslcy, D. (1992). Word-Sense Disambiguation
Using Statistical Models of Roget's Categories
Trained on Large Corpora. In: Proceedings of
the Fourteenth International Conference on
Computational Linguistics. Nantes, France. 454460.
40
Word Sense Disambiguation for Cross-Language Information Retrieval
Xiaoyong Liu
Ted Diamond
R Diekema
School of Information Studies Syracuse University
Syracuse, NY 13244
xliu03a,mailbox.syr.edutdiamonl@twcny.rr.comdiekemar@,mailbox.syr.edu
We have developed a word sense disambiguation algorithm, following Cheng and Wilensky (1997), to disambiguate among WordNet synsets. This algorithm is to be used in a cross-language information retrieval system, CINDOR, which indexes queries and documents in a language-neutral concept representation based on WordNet synsets. Our goal is to improve retrieval precision through word sense disambiguation. An evaluation against human disambiguation judgements suggests promise for our approach.
E Agirre
G Rigau
Word sense disambiguation using conceptual density. In:
1996
Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen,1996.
ilx) value *= ( - Pe(wilx)) P(context(w)lx) = 1 - value Calculate pe(x) P(xlcontext(w)) = pc(x)* P(context(w)k) display a ranked list of the synsets arranged according to their P(xlcontext(w)) in decreasing order Figure 2: WSD Algorithm: the sense prediction phase 37 5 Evaluation As suggested by the WSD literature, evaluation of word sense disambiguation systems is not yet standardized (Resnik and Yarowsky, 1997). Some WSD evaluations have been done using the Brown Corpus as training and testing resources and comparing the results against SemCor3, the sense-tagged version of the Brown Corpus (Agirre and Rigau, 1996; Gonzalo et al., 1998). Others have used common test suites such as the 2094-word line data of Leacock et al. (1993). Still others have tended to use their own metrics. We chose an evaluation with a userbased component that allowed a ranked list of sense selection for each target word and enabled a comprehensive comparison between automatic and manual WSD results. In addition we wanted to base the disambiguation matrix on a corpus that we use for retrieval. This approach allows for a much richer evaluation than a simple hit-ormiss test. For validation purpose, we will conduct a fully automati
Agirre, Rigau, 1996
Agirre, E., and Rigau, G. (1996). Word sense disambiguation using conceptual density. In: Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen,1996.
L Ballesteros
B Croft
Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval. In:
1997
Proceedings of the Association for Computing Machinery Special Interest Group on Information Retrieval (ACM/SIGIR) 20th International Conference on Research and Development in Information Retrieval;
84--91
ACM,
Philadelphia, PA. New York, NY:
y (1997) who used a training matrix of associations of words with a certain category. Their algorithm was appealing to us because it requires no human intervention, and more importantly, it avoids the use of sense-tagged data. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as P(synseticontext), for each synset of which that word is a member For nouns, we defme the context of word w to be the occurrenc
Ballesteros, Croft, 1997
Ballesteros, L., and Croft, B. (1997). Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval. In: Proceedings of the Association for Computing Machinery Special Interest Group on Information Retrieval (ACM/SIGIR) 20th International Conference on Research and Development in Information Retrieval; 1997 July 25-31; Philadelphia, PA. New York, NY: ACM, 1997. 84-91.
L Ballesteros
B Croft
Resolving Ambiguity for Cross-language Retrieval. In:
1998
Proceedings of the Association for Computing Machinery Special Interest Group on Information Retrieval (ACM/SIGIR) 21st International Conference on Research and Development in Information Retrieval;
64--71
ACM,
Melbourne, Australia. New York, NY:
gory. Their algorithm was appealing to us because it requires no human intervention, and more importantly, it avoids the use of sense-tagged data. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as P(synseticontext), for each synset of which that word is a member For nouns, we defme the context of word w to be the occurrence of words in a moving window of 100 words (50 words on each side) around w2. By 
Ballesteros, Croft, 1998
Ballesteros, L., and Croft, B. (1998). Resolving Ambiguity for Cross-language Retrieval. In: Proceedings of the Association for Computing Machinery Special Interest Group on Information Retrieval (ACM/SIGIR) 21st International Conference on Research and Development in Information Retrieval; 1998 August 24-28; Melbourne, Australia. New York, NY: ACM, 1998. 64-71.
I Cheng
R Wilensky
An Experiment in Enhancing Information Access by Natural Language Processing.
1997
Technical Report UCB/CSD
97--963
UC Berkeley Computer Science
ef that the &quot;noisy estimators&quot; should work reasonably well if: • The words that belong to synset si tend to appear in similar contexts when sf, is their intended sense; • These words do not completely overlap with the words belonging to some synset sj ( i j ) that partially overlaps with si; 2 For other parts of speech, the window size should be much smaller as suggested by previous research. 36 • The common words between si and si appear in different contexts when si and s. are their intended senses. 4 The WSD Algorithm We chose as a basis the algorithms described by YarrowsIcy (1992) and by Cheng and Wilensky (1997). In our variation, we use the synset numbers in WordNet to represent the senses of a word. Our algorithm learns associations of WordNet synsets with words in a surrounding context to determine a word sense. It consists of two phases. During the training phase, the algorithm reads in all training documents in collection and computes the distance-adjusted weight of cooccurrence of each word with each corresponding synset. This is done by establishing a 100-word window around a target word (50 words on each side), and correlating each synset to which the target word belongs with each word in the
Cheng, Wilensky, 1997
Cheng, I., and Wilensky, R. (1997). An Experiment in Enhancing Information Access by Natural Language Processing. UC Berkeley Computer Science Technical Report UCB/CSD UCB//CSD-97-963.
M Davis
New Experiments in CrossLanguage Text Retrieval at NMSU's Computing Research Lab. In:
1997
The Fifth Text Retrieval Conference (7'REC-5). 1996, November. National Institute of Standards and Technology (NIST),
D.K. Harman, Ed.
Gaithersburg, MD.
th the largest sum was then selected. A similar approach to that of Yarowslcy was followed by Cheng and Willensky (1997) who used a training matrix of associations of words with a certain category. Their algorithm was appealing to us because it requires no human intervention, and more importantly, it avoids the use of sense-tagged data. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as
Davis, 1997
Davis, M. (1997). New Experiments in CrossLanguage Text Retrieval at NMSU's Computing Research Lab. In: D.K. Harman, Ed. The Fifth Text Retrieval Conference (7'REC-5). 1996, November. National Institute of Standards and Technology (NIST), Gaithersburg, MD.
A Diekema
F Oroumchian
P Sheridan
E D Liddy
1999
TREC-7 Evaluation of Conceptual Interlingua Document Retrieval (CINDOR) in English
169--180
Gaithersburg, MD.
 use of sense-tagged data. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as P(synseticontext), for each synset of which that word is a member For nouns, we defme the context of word w to be the occurrence of words in a moving window of 100 words (50 words on each side) around w2. By Bayes Theorem, we can obtain the desired probability by inversion (see equation (1)). Since we are not specifica
Diekema, Oroumchian, Sheridan, Liddy, 1999
Diekema, A., Oroumchian, F., Sheridan, P., and Liddy, E. D. (1999). TREC-7 Evaluation of Conceptual Interlingua Document Retrieval (CINDOR) in English and French. In: E.M. Voorhees and D.K. Harman (Eds.) The Seventh Text REtrieval Conference (7REC-7). 1998, November 9-11; National Institute of Standards and Technology (NIST), Gaithersburg, MD. 169-180.
J Gonzalo
F Verdejo
I Chugur
J Cigarran
Indexing with WordNet synsets can improve text retrieval. In:
1998
Proceedings of the COLING/ACL Workshop on Usage of WordNet in Natural Language Processing Systems,
Montreal,
x)) P(context(w)lx) = 1 - value Calculate pe(x) P(xlcontext(w)) = pc(x)* P(context(w)k) display a ranked list of the synsets arranged according to their P(xlcontext(w)) in decreasing order Figure 2: WSD Algorithm: the sense prediction phase 37 5 Evaluation As suggested by the WSD literature, evaluation of word sense disambiguation systems is not yet standardized (Resnik and Yarowsky, 1997). Some WSD evaluations have been done using the Brown Corpus as training and testing resources and comparing the results against SemCor3, the sense-tagged version of the Brown Corpus (Agirre and Rigau, 1996; Gonzalo et al., 1998). Others have used common test suites such as the 2094-word line data of Leacock et al. (1993). Still others have tended to use their own metrics. We chose an evaluation with a userbased component that allowed a ranked list of sense selection for each target word and enabled a comprehensive comparison between automatic and manual WSD results. In addition we wanted to base the disambiguation matrix on a corpus that we use for retrieval. This approach allows for a much richer evaluation than a simple hit-ormiss test. For validation purpose, we will conduct a fully automatic evaluation against Se
Gonzalo, Verdejo, Chugur, Cigarran, 1998
Gonzalo, J., Verdejo, F., Chugur, I., and Cigarran, J. (1998). Indexing with WordNet synsets can improve text retrieval. In: Proceedings of the COLING/ACL Workshop on Usage of WordNet in Natural Language Processing Systems, Montreal, 1998.
D Hiemstra
W Kraaij
Twenty-One at TREC-7: Ad-hoc and Cross-language Track.
1999
The Seventh Text REtrieval Conference (TREC-7). 1998, November 9-11; National Institute of Standards and Technology (NIST),
227--238
In: E.M. Voorhees and D.K. Harman (Eds.)
Gaithersburg, MD.
ata. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as P(synseticontext), for each synset of which that word is a member For nouns, we defme the context of word w to be the occurrence of words in a moving window of 100 words (50 words on each side) around w2. By Bayes Theorem, we can obtain the desired probability by inversion (see equation (1)). Since we are not specifically concerned with getting a
Hiemstra, Kraaij, 1999
Hiemstra, D., and Kraaij, W. (1999). Twenty-One at TREC-7: Ad-hoc and Cross-language Track. In: E.M. Voorhees and D.K. Harman (Eds.) The Seventh Text REtrieval Conference (TREC-7). 1998, November 9-11; National Institute of Standards and Technology (NIST), Gaithersburg, MD. 227-238.
D A Hull
Using Structured Queries for Disambiguation in Cross-Language Information Retrieval. In:
1997
American Association for Artificial Intelligence (AAA° Symposium on Cross-Language Text and Speech Retrieval;
84--98
Palo Alto, CA
t avoids the use of sense-tagged data. Our methodology described in the next section is therefore based on Cheng and Wilensky's approach. Methods to reduce (translation) ambiguity in cross-language information retrieval have included using part-of-speech taggers to restrict the translation options (Davis 1997), applying pseudo-relevance feedback loops to expand the query with better terms aiding translation (Ballesteros and Croft 1997), using corpora for term translation disambiguation (Ballesteros and Croft, 1998), and weighted Boolean models which tend to have a self-disambiguating quality (Hull, 1997; Diekema et al., 1999; Hiemstra and Kraaij, 1999). 3 Methodology To disambiguate a given word, we would like to know the probability that a sense occurs in a given context, i.e., P(sensecontext). In this study, WordNet synsets are used to represent word senses, so P(sensecontext) can be rewritten as P(synseticontext), for each synset of which that word is a member For nouns, we defme the context of word w to be the occurrence of words in a moving window of 100 words (50 words on each side) around w2. By Bayes Theorem, we can obtain the desired probability by inversion (see equation (1)). Sinc
Hull, 1997
Hull, D. A. (1997). Using Structured Queries for Disambiguation in Cross-Language Information Retrieval. In: American Association for Artificial Intelligence (AAA° Symposium on Cross-Language Text and Speech Retrieval; 1997 March 24-26; Palo Alto, CA 1997. 84-98.
N Ide
J Veronis
Introduction to the Special Issue on Word Sense Disambiguation: The State of the Art.
1998
Computational Linguistics,
24
1--40
Ide, Veronis, 1998
Ide, N., and Veronis, J. (1998). Introduction to the Special Issue on Word Sense Disambiguation: The State of the Art. Computational Linguistics, Vol. 24, No. 1, 1-40.
C Leacock
M Chodorow
Combining Local Context and WordNet Similarity for Word Sense Identification. In: Christiane Fellbaum (Eds.) WordNet: An Electronic Lexical Database.
1998
MIT Press.
Cambridge, MA:
roving the precision of our cross-language retrieval system. 2 Related Work To determine the sense of a word, a WSD algorithm typically uses the context of the ambiguous word, external resources such as machine-readable dictionaries, or a combination of both. Although dictionaries provide useful word sense information and thesauri provide additional information about relationships between words, they lack pragmatic information as can be found in corpora. Corpora contain examples of words that enable the development of statistical models of word senses and their contexts Ode and Veronis, 1998; Leacock and Chodorow, 1998). There are two general problems with using corpora however; 1) corpora typically do not come pre-tagged with manually disambiguated senses, and 2) corpora are often not large nor diverse enough for all senses of a word to appear often enough for reliable statistical models (data sparseness). Although researchers have tried sense-tagging corpora automatically by using either supervised or unsupervised training methods, we have adopted a WSD algorithm which avoids the necessity for a sense-tagged training corpus. 'Please note that the disambiguation research described in this paper has not yet 
Leacock, Chodorow, 1998
Leacock, C., and Chodorow, M. (1998). Combining Local Context and WordNet Similarity for Word Sense Identification. In: Christiane Fellbaum (Eds.) WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press.
C Leacock
G Towell
E Voorhees
Corpus-based Statistical Sense Resolution. In:
1993
Proceedings, ARPA Human Language Technology Workshop,
260--265
Plainsboro, NJ.
y a ranked list of the synsets arranged according to their P(xlcontext(w)) in decreasing order Figure 2: WSD Algorithm: the sense prediction phase 37 5 Evaluation As suggested by the WSD literature, evaluation of word sense disambiguation systems is not yet standardized (Resnik and Yarowsky, 1997). Some WSD evaluations have been done using the Brown Corpus as training and testing resources and comparing the results against SemCor3, the sense-tagged version of the Brown Corpus (Agirre and Rigau, 1996; Gonzalo et al., 1998). Others have used common test suites such as the 2094-word line data of Leacock et al. (1993). Still others have tended to use their own metrics. We chose an evaluation with a userbased component that allowed a ranked list of sense selection for each target word and enabled a comprehensive comparison between automatic and manual WSD results. In addition we wanted to base the disambiguation matrix on a corpus that we use for retrieval. This approach allows for a much richer evaluation than a simple hit-ormiss test. For validation purpose, we will conduct a fully automatic evaluation against SemCor in our future efforts. We use in vitro evaluation in this study, i.e. the WSD algorithm i
Leacock, Towell, Voorhees, 1993
Leacock, C., Towell, G., and Voorhees, E. (1993). Corpus-based Statistical Sense Resolution. In: Proceedings, ARPA Human Language Technology Workshop, Plainsboro, NJ. 260-265.
G Miller
WordNet: An On-line Lexical Database.
1990
International Journal of Lexicography,
3
Special Issue.
R, which indexes queries and documents in a language-neutral concept representation based on WordNet synsets. Our goal is to improve retrieval precision through word sense disambiguation. An evaluation against human disambiguation judgements suggests promise for our approach. 1 Introduction The C1NDOR cross-language information retrieval system (Diekema et al., 1998) uses an information structure known as &quot;conceptual interlingua&quot; for query and document representation. This conceptual interlingua is a hierarchically organized multilingual concept lexicon, which is structured following WordNet (Miller, 1990). By representing query and document terms by their WordNet synset numbers we arrive at essentially a language neutral representation consisting of synset numbers representing concepts. This representation facilitates cross-language retrieval by matching term synonyms in English as well as across languages. However, many terms are polysemous and belong to multiple synsets, resulting in spurious matches in retrieval. The noun figure for example appears in 13 synsets in WordNet 1.6. This research paper describes the early stages1 of our efforts to develop a word sense disambiguation (WSD) algori
Miller, 1990
Miller, G. (1990). WordNet: An On-line Lexical Database. International Journal of Lexicography, Vol. 3, No. 4, Special Issue.
P Resnik
D Yarowslcy
A Perspective on Word Sense Disambiguation Methods and Their Evaluation, position paper presented at the ACL
1997
SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How?, held
Resnik, Yarowslcy, 1997
Resnik, P., and Yarowslcy, D. (1997). A Perspective on Word Sense Disambiguation Methods and Their Evaluation, position paper presented at the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How?, held April 4-5, 1997 in Washington, D.C., USA in conjunction with ANLP-97.
S Siegel
Nonparametric Statistics for the Behavioral Sciences.
1956
New York: McGraw-Hill,
ical analysis of our results. However, the number of ties in our results renders the Spearman coefficient unreliable. We have therefore concentrated on the Friedman analysis of our experimental results. We use the two-alternative test with a=0.05. The first tests of interest were aimed at establishing inter-judge reliability across the 115 shared sentences by each pair of judges. The null hypothesis can be generalized as &quot;There is no difference in judgments on the same word occurrences between two judges in the same group&quot;. Following general steps of conducting a Friedman test as described by Siegel (1956), we cast raw ranks in a two-way table having 2 conditions/columns (K = 2) with each of the human judges in the pair serving as one condition and 365 subjects/rows (N = 365) which are all the senses of the 115 word occurrences that were judged by both human judges. We then ranked 38 N K Xr2 df Rejection region Reject Ho? First pair of judges 365 2 .003 1 3.84 No Second pair of judges 380 2 2.5289 1 3.84 No Figure 3: Statistics for significance tests of inter-judge reliability (a=.05, 2-alt. Test) N K Xr2 df Rejection region Reject Ho? Auto WSD vs man. WSD 2840 3 73.217 2 5.99 Yes vs sense pool
Siegel, 1956
Siegel, S. (1956). Nonparametric Statistics for the Behavioral Sciences. New York: McGraw-Hill, 1956.
D Yarowslcy
Word-Sense Disambiguation Using Statistical Models of Roget's Categories Trained on Large Corpora. In:
1992
Proceedings of the Fourteenth International Conference on Computational Linguistics.
454--460
Nantes,
Yarowslcy, 1992
Yarowslcy, D. (1992). Word-Sense Disambiguation Using Statistical Models of Roget's Categories Trained on Large Corpora. In: Proceedings of the Fourteenth International Conference on Computational Linguistics. Nantes, France. 454-460.
