[{"frames":[{"target":{"name":"Topic","spans":[{"start":5,"end":6,"text":"Topic"}]},"annotationSets":[{"rank":0,"score":25.201834103994614,"frameElements":[{"name":"Topic","spans":[{"start":6,"end":7,"text":"Model"}]}]}]},{"target":{"name":"Vehicle","spans":[{"start":6,"end":7,"text":"Model"}]},"annotationSets":[{"rank":0,"score":23.315704872494447,"frameElements":[{"name":"Vehicle","spans":[{"start":6,"end":7,"text":"Model"}]}]}]},{"target":{"name":"Coming_up_with","spans":[{"start":11,"end":12,"text":"designed"}]},"annotationSets":[{"rank":0,"score":51.08667337773009,"frameElements":[{"name":"Idea","spans":[{"start":3,"end":7,"text":"Abstract Biterm Topic Model"}]},{"name":"Purpose","spans":[{"start":12,"end":28,"text":"to model the generative process of the word co-occurrence patterns in short texts such as tweets"}]}]}]},{"target":{"name":"Means","spans":[{"start":16,"end":17,"text":"process"}]},"annotationSets":[{"rank":0,"score":17.293234207617633,"frameElements":[{"name":"Means","spans":[{"start":16,"end":17,"text":"process"}]},{"name":"Descriptor","spans":[{"start":15,"end":16,"text":"generative"}]}]}]},{"target":{"name":"Simple_name","spans":[{"start":19,"end":20,"text":"word"}]},"annotationSets":[{"rank":0,"score":9.767346061564528,"frameElements":[]}]},{"target":{"name":"Locale_by_use","spans":[{"start":20,"end":21,"text":"co-occurrence"}]},"annotationSets":[{"rank":0,"score":35.7663053081559,"frameElements":[{"name":"Locale","spans":[{"start":20,"end":21,"text":"co-occurrence"}]}]}]},{"target":{"name":"Pattern","spans":[{"start":21,"end":22,"text":"patterns"}]},"annotationSets":[{"rank":0,"score":6.258174611309843,"frameElements":[]}]},{"target":{"name":"Dimension","spans":[{"start":23,"end":24,"text":"short"}]},"annotationSets":[{"rank":0,"score":19.83488288137162,"frameElements":[{"name":"Object","spans":[{"start":24,"end":25,"text":"texts"}]}]}]},{"target":{"name":"Make_noise","spans":[{"start":27,"end":28,"text":"tweets"}]},"annotationSets":[{"rank":0,"score":78.50555144031804,"frameElements":[]}]}],"tokens":["<","newSection",">","Abstract","Biterm","Topic","Model","-LRB-","BTM","-RRB-","is","designed","to","model","the","generative","process","of","the","word","co-occurrence","patterns","in","short","texts","such","as","tweets","."]},{"frames":[{"target":{"name":"Concessive","spans":[{"start":0,"end":1,"text":"However"}]},"annotationSets":[{"rank":0,"score":5.875789320013224,"frameElements":[]}]},{"target":{"name":"Cardinal_numbers","spans":[{"start":2,"end":3,"text":"two"}]},"annotationSets":[{"rank":0,"score":30.481539439492416,"frameElements":[{"name":"Number","spans":[{"start":2,"end":3,"text":"two"}]},{"name":"Entity","spans":[{"start":3,"end":4,"text":"aspects"}]}]}]},{"target":{"name":"Distinctiveness","spans":[{"start":3,"end":4,"text":"aspects"}]},"annotationSets":[{"rank":0,"score":18.693706157119642,"frameElements":[{"name":"Entity","spans":[{"start":4,"end":6,"text":"of BTM"}]}]}]},{"target":{"name":"Likelihood","spans":[{"start":6,"end":7,"text":"may"}]},"annotationSets":[{"rank":0,"score":30.24589452011285,"frameElements":[{"name":"Hypothetical_event","spans":[{"start":3,"end":6,"text":"aspects of BTM"}]}]}]},{"target":{"name":"Grant_permission","spans":[{"start":7,"end":8,"text":"restrict"}]},"annotationSets":[{"rank":0,"score":61.30759303495332,"frameElements":[{"name":"Grantor","spans":[{"start":3,"end":6,"text":"aspects of BTM"}]},{"name":"Action","spans":[{"start":8,"end":10,"text":"its performance"}]}]}]},{"target":{"name":"Performing_arts","spans":[{"start":9,"end":10,"text":"performance"}]},"annotationSets":[{"rank":0,"score":5.701600185106868,"frameElements":[]}]},{"target":{"name":"Getting","spans":[{"start":18,"end":19,"text":"obtain"}]},"annotationSets":[{"rank":0,"score":60.650373730707166,"frameElements":[{"name":"Theme","spans":[{"start":19,"end":25,"text":"the corpus level words co-occurrence patterns"}]}]}]},{"target":{"name":"Rank","spans":[{"start":21,"end":22,"text":"level"}]},"annotationSets":[{"rank":0,"score":3.931362799707194,"frameElements":[{"name":"Rank","spans":[{"start":20,"end":21,"text":"corpus"}]}]}]},{"target":{"name":"Simple_name","spans":[{"start":22,"end":23,"text":"words"}]},"annotationSets":[{"rank":0,"score":10.504075436953919,"frameElements":[]}]},{"target":{"name":"Locale_by_use","spans":[{"start":23,"end":24,"text":"co-occurrence"}]},"annotationSets":[{"rank":0,"score":35.72296035627833,"frameElements":[{"name":"Locale","spans":[{"start":23,"end":24,"text":"co-occurrence"}]}]}]},{"target":{"name":"Pattern","spans":[{"start":24,"end":25,"text":"patterns"}]},"annotationSets":[{"rank":0,"score":5.045189585077299,"frameElements":[]}]},{"target":{"name":"Being_strong","spans":[{"start":30,"end":31,"text":"strong"}]},"annotationSets":[{"rank":0,"score":41.86197990966048,"frameElements":[{"name":"Entity","spans":[{"start":31,"end":32,"text":"assumptions"}]}]}]},{"target":{"name":"Cardinal_numbers","spans":[{"start":33,"end":34,"text":"two"}]},"annotationSets":[{"rank":0,"score":28.347454789764214,"frameElements":[{"name":"Number","spans":[{"start":33,"end":34,"text":"two"}]},{"name":"Entity","spans":[{"start":35,"end":36,"text":"words"}]}]}]},{"target":{"name":"Simple_name","spans":[{"start":35,"end":36,"text":"words"}]},"annotationSets":[{"rank":0,"score":10.61014534888967,"frameElements":[]}]},{"target":{"name":"Identicality","spans":[{"start":40,"end":41,"text":"same"}]},"annotationSets":[{"rank":0,"score":19.78259217200013,"frameElements":[{"name":"Type","spans":[{"start":41,"end":42,"text":"topic"}]}]}]},{"target":{"name":"Topic","spans":[{"start":41,"end":42,"text":"topic"}]},"annotationSets":[{"rank":0,"score":23.738692599784947,"frameElements":[]}]},{"target":{"name":"Labeling","spans":[{"start":42,"end":43,"text":"label"}]},"annotationSets":[{"rank":0,"score":29.140479973857843,"frameElements":[]}]},{"target":{"name":"Capability","spans":[{"start":43,"end":44,"text":"could"}]},"annotationSets":[{"rank":0,"score":39.91893277571029,"frameElements":[{"name":"Event","spans":[{"start":46,"end":48,"text":"background words"}]},{"name":"Entity","spans":[{"start":39,"end":43,"text":"the same topic label"}]}]}]},{"target":{"name":"Differentiation","spans":[{"start":45,"end":46,"text":"distinguish"}]},"annotationSets":[{"rank":0,"score":25.36618800400393,"frameElements":[]}]},{"target":{"name":"Simple_name","spans":[{"start":47,"end":48,"text":"words"}]},"annotationSets":[{"rank":0,"score":10.161843410762062,"frameElements":[]}]},{"target":{"name":"Simple_name","spans":[{"start":50,"end":51,"text":"words"}]},"annotationSets":[{"rank":0,"score":10.882790915570792,"frameElements":[]}]}],"tokens":["However",",","two","aspects","of","BTM","may","restrict","its","performance",":","1","-RRB-","user","individualities","are","ignored","to","obtain","the","corpus","level","words","co-occurrence","patterns",";","and","2","-RRB-","the","strong","assumptions","that","two","co-occurring","words","will","be","assigned","the","same","topic","label","could","not","distinguish","background","words","from","topical","words","."]},{"frames":[{"target":{"name":"Statement","spans":[{"start":5,"end":6,"text":"propose"}]},"annotationSets":[{"rank":0,"score":108.24743288097422,"frameElements":[{"name":"Message","spans":[{"start":6,"end":19,"text":"Twitter-BTM model to address those issues by considering user level personalization in BTM"}]},{"name":"Speaker","spans":[{"start":4,"end":5,"text":"we"}]},{"name":"Time","spans":[{"start":0,"end":3,"text":"In this paper"}]}]}]},{"target":{"name":"Gizmo","spans":[{"start":7,"end":8,"text":"model"}]},"annotationSets":[{"rank":0,"score":19.455354007444658,"frameElements":[]}]},{"target":{"name":"Topic","spans":[{"start":9,"end":10,"text":"address"}]},"annotationSets":[{"rank":0,"score":21.964586116052402,"frameElements":[{"name":"Topic","spans":[{"start":10,"end":12,"text":"those issues"}]}]}]},{"target":{"name":"Text","spans":[{"start":11,"end":12,"text":"issues"}]},"annotationSets":[{"rank":0,"score":55.61716485279155,"frameElements":[{"name":"Text","spans":[{"start":11,"end":12,"text":"issues"}]}]}]},{"target":{"name":"Categorization","spans":[{"start":13,"end":14,"text":"considering"}]},"annotationSets":[{"rank":0,"score":34.58537371465269,"frameElements":[{"name":"Cognizer","spans":[{"start":4,"end":5,"text":"we"}]},{"name":"Item","spans":[{"start":10,"end":12,"text":"those issues"}]},{"name":"Category","spans":[{"start":14,"end":19,"text":"user level personalization in BTM"}]}]}]},{"target":{"name":"Rank","spans":[{"start":15,"end":16,"text":"level"}]},"annotationSets":[{"rank":0,"score":4.8636201700043,"frameElements":[{"name":"Rank","spans":[{"start":14,"end":15,"text":"user"}]}]}]}],"tokens":["In","this","paper",",","we","propose","Twitter-BTM","model","to","address","those","issues","by","considering","user","level","personalization","in","BTM","."]},{"frames":[{"target":{"name":"Using","spans":[{"start":3,"end":4,"text":"use"}]},"annotationSets":[{"rank":0,"score":94.9526448589244,"frameElements":[{"name":"Instrument","spans":[{"start":4,"end":14,"text":"user based biterms aggregation to learn user specific topic distribution"}]},{"name":"Agent","spans":[{"start":2,"end":3,"text":"we"}]}]}]},{"target":{"name":"Education_teaching","spans":[{"start":9,"end":10,"text":"learn"}]},"annotationSets":[{"rank":0,"score":95.47452660462663,"frameElements":[{"name":"Student","spans":[{"start":10,"end":14,"text":"user specific topic distribution"}]}]}]},{"target":{"name":"Topic","spans":[{"start":12,"end":13,"text":"topic"}]},"annotationSets":[{"rank":0,"score":23.738692599784947,"frameElements":[]}]},{"target":{"name":"Dispersal","spans":[{"start":13,"end":14,"text":"distribution"}]},"annotationSets":[{"rank":0,"score":51.91290597400867,"frameElements":[]}]}],"tokens":["Firstly",",","we","use","user","based","biterms","aggregation","to","learn","user","specific","topic","distribution","."]},{"frames":[{"target":{"name":"Simple_name","spans":[{"start":8,"end":9,"text":"words"}]},"annotationSets":[{"rank":0,"score":9.816965749669018,"frameElements":[]}]},{"target":{"name":"Simple_name","spans":[{"start":11,"end":12,"text":"words"}]},"annotationSets":[{"rank":0,"score":10.882790915570792,"frameElements":[]}]},{"target":{"name":"Estimating","spans":[{"start":13,"end":14,"text":"estimated"}]},"annotationSets":[{"rank":0,"score":73.01822636611486,"frameElements":[{"name":"Estimation","spans":[{"start":14,"end":19,"text":"by incorporating a background topic"}]}]}]},{"target":{"name":"Inclusion","spans":[{"start":15,"end":16,"text":"incorporating"}]},"annotationSets":[{"rank":0,"score":30.441516423250263,"frameElements":[{"name":"Part","spans":[{"start":16,"end":19,"text":"a background topic"}]},{"name":"Total","spans":[{"start":2,"end":12,"text":"each user 's preference between background words and topical words"}]}]}]},{"target":{"name":"Topic","spans":[{"start":18,"end":19,"text":"topic"}]},"annotationSets":[{"rank":0,"score":22.78588355118424,"frameElements":[{"name":"Topic","spans":[{"start":17,"end":18,"text":"background"}]}]}]}],"tokens":["Secondly",",","each","user","'s","preference","between","background","words","and","topical","words","is","estimated","by","incorporating","a","background","topic","."]},{"frames":[{"target":{"name":"Sounds","spans":[{"start":5,"end":6,"text":"Twitter"}]},"annotationSets":[{"rank":0,"score":48.2617401745562,"frameElements":[]}]},{"target":{"name":"Reasoning","spans":[{"start":7,"end":8,"text":"show"}]},"annotationSets":[{"rank":0,"score":47.681223756335726,"frameElements":[{"name":"Content","spans":[{"start":8,"end":14,"text":"that Twitter-BTM outperforms several state-of-the-art baselines"}]},{"name":"Arguer","spans":[{"start":6,"end":7,"text":"dataset"}]}]}]},{"target":{"name":"Quantity","spans":[{"start":11,"end":12,"text":"several"}]},"annotationSets":[{"rank":0,"score":25.907488214710998,"frameElements":[{"name":"Quantity","spans":[{"start":11,"end":12,"text":"several"}]},{"name":"Individuals","spans":[{"start":13,"end":14,"text":"baselines"}]}]}]},{"target":{"name":"Temporal_collocation","spans":[{"start":12,"end":13,"text":"state-of-the-art"}]},"annotationSets":[{"rank":0,"score":30.658426737723918,"frameElements":[{"name":"Trajector_entity","spans":[{"start":13,"end":14,"text":"baselines"}]}]}]}],"tokens":["Experiments","on","a","large-scale","real-world","Twitter","dataset","show","that","Twitter-BTM","outperforms","several","state-of-the-art","baselines","."]}]