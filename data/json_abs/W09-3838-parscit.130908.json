[{"frames":[{"target":{"name":"Becoming_aware","spans":[{"start":3,"end":4,"text":"Abstract"}]},"annotationSets":[{"rank":0,"score":82.20587381118023,"frameElements":[{"name":"Cognizer","spans":[{"start":0,"end":2,"text":"< newSection"}]}]}]},{"target":{"name":"Presence","spans":[{"start":5,"end":6,"text":"present"}]},"annotationSets":[{"rank":0,"score":8.180111576330907,"frameElements":[{"name":"Entity","spans":[{"start":4,"end":5,"text":"We"}]}]}]},{"target":{"name":"Gizmo","spans":[{"start":7,"end":8,"text":"model"}]},"annotationSets":[{"rank":0,"score":20.175810759838644,"frameElements":[]}]},{"target":{"name":"Reliance","spans":[{"start":10,"end":11,"text":"dependency"}]},"annotationSets":[{"rank":0,"score":31.193734883077646,"frameElements":[]}]},{"target":{"name":"Education_teaching","spans":[{"start":14,"end":15,"text":"learning"}]},"annotationSets":[{"rank":0,"score":96.3639835794255,"frameElements":[]}]},{"target":{"name":"Deciding","spans":[{"start":18,"end":19,"text":"decision"}]},"annotationSets":[{"rank":0,"score":18.338394440460917,"frameElements":[{"name":"Cognizer","spans":[{"start":17,"end":18,"text":"Markov"}]}]}]},{"target":{"name":"Means","spans":[{"start":19,"end":20,"text":"process"}]},"annotationSets":[{"rank":0,"score":17.59479686574845,"frameElements":[{"name":"Means","spans":[{"start":19,"end":20,"text":"process"}]}]}]}],"tokens":["<","newSection",">","Abstract","We","present","a","model","which","integrates","dependency","parsing","with","reinforcement","learning","based","on","Markov","decision","process","."]},{"frames":[{"target":{"name":"Being_up_to_it","spans":[{"start":9,"end":11,"text":"up to"}]},"annotationSets":[{"rank":0,"score":9.442956191561555,"frameElements":[{"name":"Entity","spans":[{"start":11,"end":21,"text":"construct the dependency tree in terms of the long-run reward"}]}]}]},{"target":{"name":"Measure_duration","spans":[{"start":2,"end":3,"text":"time"}]},"annotationSets":[{"rank":0,"score":17.83394585833954,"frameElements":[{"name":"Unit","spans":[{"start":2,"end":3,"text":"time"}]}]}]},{"target":{"name":"Intentionally_act","spans":[{"start":3,"end":4,"text":"step"}]},"annotationSets":[{"rank":0,"score":56.95482096047413,"frameElements":[{"name":"Act","spans":[{"start":3,"end":4,"text":"step"}]},{"name":"Agent","spans":[{"start":1,"end":3,"text":"each time"}]}]}]},{"target":{"name":"Undergo_change","spans":[{"start":6,"end":7,"text":"transition"}]},"annotationSets":[{"rank":0,"score":51.70970197629141,"frameElements":[]}]},{"target":{"name":"Choosing","spans":[{"start":8,"end":9,"text":"picked"}]},"annotationSets":[{"rank":0,"score":33.36158406836676,"frameElements":[{"name":"Time","spans":[{"start":0,"end":4,"text":"At each time step"}]},{"name":"Chosen","spans":[{"start":5,"end":7,"text":"a transition"}]}]}]},{"target":{"name":"Building","spans":[{"start":11,"end":12,"text":"construct"}]},"annotationSets":[{"rank":0,"score":72.27044720220434,"frameElements":[{"name":"Created_entity","spans":[{"start":12,"end":15,"text":"the dependency tree"}]},{"name":"Agent","spans":[{"start":6,"end":7,"text":"transition"}]},{"name":"Place","spans":[{"start":15,"end":21,"text":"in terms of the long-run reward"}]}]}]},{"target":{"name":"Reliance","spans":[{"start":13,"end":14,"text":"dependency"}]},"annotationSets":[{"rank":0,"score":31.193734883077646,"frameElements":[]}]},{"target":{"name":"Simple_name","spans":[{"start":16,"end":17,"text":"terms"}]},"annotationSets":[{"rank":0,"score":11.357774931729505,"frameElements":[{"name":"Entity","spans":[{"start":17,"end":21,"text":"of the long-run reward"}]}]}]},{"target":{"name":"Rewards_and_punishments","spans":[{"start":20,"end":21,"text":"reward"}]},"annotationSets":[{"rank":0,"score":42.496462811519514,"frameElements":[]}]}],"tokens":["At","each","time","step",",","a","transition","is","picked","up","to","construct","the","dependency","tree","in","terms","of","the","long-run","reward","."]},{"frames":[{"target":{"name":"Law","spans":[{"start":2,"end":3,"text":"policy"}]},"annotationSets":[{"rank":0,"score":39.338115550358744,"frameElements":[{"name":"Law","spans":[{"start":2,"end":3,"text":"policy"}]}]}]},{"target":{"name":"Choosing","spans":[{"start":4,"end":5,"text":"choosing"}]},"annotationSets":[{"rank":0,"score":35.992432208368605,"frameElements":[{"name":"Chosen","spans":[{"start":5,"end":6,"text":"transitions"}]}]}]},{"target":{"name":"Undergo_change","spans":[{"start":5,"end":6,"text":"transitions"}]},"annotationSets":[{"rank":0,"score":50.51511351399867,"frameElements":[]}]},{"target":{"name":"Likelihood","spans":[{"start":6,"end":7,"text":"can"}]},"annotationSets":[{"rank":0,"score":31.593628756717788,"frameElements":[{"name":"Hypothetical_event","spans":[{"start":0,"end":6,"text":"The optimal policy for choosing transitions"}]}]}]},{"target":{"name":"Locating","spans":[{"start":8,"end":9,"text":"found"}]},"annotationSets":[{"rank":0,"score":12.690534964505083,"frameElements":[{"name":"Sought_entity","spans":[{"start":0,"end":6,"text":"The optimal policy for choosing transitions"}]},{"name":"Location","spans":[{"start":9,"end":13,"text":"with the SARSA algorithm"}]}]}]}],"tokens":["The","optimal","policy","for","choosing","transitions","can","be","found","with","the","SARSA","algorithm","."]},{"frames":[{"target":{"name":"Contingency","spans":[{"start":8,"end":9,"text":"function"}]},"annotationSets":[{"rank":0,"score":14.771558008048789,"frameElements":[{"name":"Determinant","spans":[{"start":7,"end":8,"text":"state-action"}]}]}]},{"target":{"name":"Likelihood","spans":[{"start":9,"end":10,"text":"can"}]},"annotationSets":[{"rank":0,"score":31.43624297008049,"frameElements":[{"name":"Hypothetical_event","spans":[{"start":3,"end":9,"text":"an approximation of the state-action function"}]}]}]},{"target":{"name":"Getting","spans":[{"start":11,"end":12,"text":"obtained"}]},"annotationSets":[{"rank":0,"score":58.97185940800972,"frameElements":[{"name":"Theme","spans":[{"start":3,"end":9,"text":"an approximation of the state-action function"}]}]}]},{"target":{"name":"Expensiveness","spans":[{"start":16,"end":17,"text":"free"}]},"annotationSets":[{"rank":0,"score":30.111336675187378,"frameElements":[{"name":"Goods","spans":[{"start":17,"end":18,"text":"energies"}]}]}]},{"target":{"name":"Electricity","spans":[{"start":17,"end":18,"text":"energies"}]},"annotationSets":[{"rank":0,"score":16.530290904329163,"frameElements":[{"name":"Electricity","spans":[{"start":17,"end":18,"text":"energies"}]},{"name":"Use","spans":[{"start":18,"end":23,"text":"for the Restricted Boltzmann Machine"}]}]}]},{"target":{"name":"Grant_permission","spans":[{"start":20,"end":21,"text":"Restricted"}]},"annotationSets":[{"rank":0,"score":53.35659532682713,"frameElements":[{"name":"Action","spans":[{"start":21,"end":22,"text":"Boltzmann"}]}]}]},{"target":{"name":"Gizmo","spans":[{"start":22,"end":23,"text":"Machine"}]},"annotationSets":[{"rank":0,"score":18.40783395150051,"frameElements":[{"name":"Use","spans":[{"start":21,"end":22,"text":"Boltzmann"}]}]}]}],"tokens":["In","SARSA",",","an","approximation","of","the","state-action","function","can","be","obtained","by","calculating","the","negative","free","energies","for","the","Restricted","Boltzmann","Machine","."]},{"frames":[{"target":{"name":"Causation","spans":[{"start":2,"end":3,"text":"results"}]},"annotationSets":[{"rank":0,"score":71.47388546642911,"frameElements":[{"name":"Cause","spans":[{"start":1,"end":2,"text":"experimental"}]}]}]},{"target":{"name":"Reasoning","spans":[{"start":7,"end":8,"text":"show"}]},"annotationSets":[{"rank":0,"score":51.65169945381884,"frameElements":[{"name":"Content","spans":[{"start":8,"end":20,"text":"that the proposed model achieves comparable results with the current state-of-the-art methods"}]},{"name":"Arguer","spans":[{"start":4,"end":7,"text":"CoNLL-X multilingual data"}]}]}]},{"target":{"name":"Statement","spans":[{"start":10,"end":11,"text":"proposed"}]},"annotationSets":[{"rank":0,"score":105.60694696980093,"frameElements":[{"name":"Message","spans":[{"start":11,"end":12,"text":"model"}]}]}]},{"target":{"name":"Vehicle","spans":[{"start":11,"end":12,"text":"model"}]},"annotationSets":[{"rank":0,"score":22.80760031873906,"frameElements":[{"name":"Vehicle","spans":[{"start":11,"end":12,"text":"model"}]}]}]},{"target":{"name":"Accomplishment","spans":[{"start":12,"end":13,"text":"achieves"}]},"annotationSets":[{"rank":0,"score":62.801843628321095,"frameElements":[{"name":"Goal","spans":[{"start":13,"end":15,"text":"comparable results"}]},{"name":"Agent","spans":[{"start":9,"end":12,"text":"the proposed model"}]}]}]},{"target":{"name":"Evaluative_comparison","spans":[{"start":13,"end":14,"text":"comparable"}]},"annotationSets":[{"rank":0,"score":32.36333116309974,"frameElements":[]}]},{"target":{"name":"Causation","spans":[{"start":14,"end":15,"text":"results"}]},"annotationSets":[{"rank":0,"score":69.31303888793853,"frameElements":[{"name":"Cause","spans":[{"start":13,"end":14,"text":"comparable"}]}]}]},{"target":{"name":"Temporal_collocation","spans":[{"start":17,"end":18,"text":"current"}]},"annotationSets":[{"rank":0,"score":29.20501177219598,"frameElements":[{"name":"Trajector_entity","spans":[{"start":19,"end":20,"text":"methods"}]}]}]},{"target":{"name":"Temporal_collocation","spans":[{"start":18,"end":19,"text":"state-of-the-art"}]},"annotationSets":[{"rank":0,"score":31.868126974813926,"frameElements":[{"name":"Trajector_entity","spans":[{"start":19,"end":20,"text":"methods"}]}]}]},{"target":{"name":"Means","spans":[{"start":19,"end":20,"text":"methods"}]},"annotationSets":[{"rank":0,"score":20.94268108508758,"frameElements":[{"name":"Means","spans":[{"start":19,"end":20,"text":"methods"}]},{"name":"Purpose","spans":[{"start":18,"end":19,"text":"state-of-the-art"}]}]}]}],"tokens":["The","experimental","results","on","CoNLL-X","multilingual","data","show","that","the","proposed","model","achieves","comparable","results","with","the","current","state-of-the-art","methods","."]}]