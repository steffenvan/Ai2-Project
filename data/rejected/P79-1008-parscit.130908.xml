<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.205448">
<note confidence="0.666921">
KNOWLEDGE ORGANIZATION AND APPLICATION: BRIEF COMMENTS ON PAPERS IN THE SESSION
Aravind K. Joshi
</note>
<affiliation confidence="0.905853">
Department of Computer and Information Science
The Moore School
University of Pennsylvania, Philadelphia, PA 19104
</affiliation>
<bodyText confidence="0.995021512605042">
Comments:
My brief comments on the papers in this session are based
on the abstracts available to me and not on the complete
papers. Hence, it is quite possible that some of the
comments may turn out to be inappropriate or else they
have already been taken care of in the full texts. In a
couple of cases. I had the benefit of reading some
earlier longer related reports, which were very helpful.
All the papers (except by Sangster) deal with either
knowledge representation, particular types of knowledge
to be represented, or how certain types of knowledge are
to be used.
Brackman describes a lattice-like structured inheritance
network (KLONE) as a language for explicit representation
of natural language conceptual information. Multiple
descriptions can be represented. How does the facility
differ from a similar one in KRL? Belief representations
appear to be only implicit. Quantification is handled
through a set of &amp;quot;structural descriptions.&amp;quot; It is not
clear how negation is handled. The main application is
for the command and control of advanced graphics
manipulators through natural language. Is there an
implicit claim here that the KLONE representations are
suitable for both natural language concepts as well as
for those in the visual domain?
Sowa also presents a network like representation (con-
ceptual graphs). It is a representation that is
apparently based on some ideas of Hintikka on incomplete
but extensible models called surface models. Sowa also
uses some ideas of graph grammars. It is not clear how
multiple descriptions and beliefs can be represented in
this framework. Perhaps the detailed paper will clarify
some of these issues. This paper does not describe any
application.
Sangster&apos;s paper is not concerned-directly with knowledge
representation. It is concerned with complete and
partial matching procedures, especially for determining
whether a particular instance satisfies the criteria for
membership in a particular class. Matching procedures,
especially partial matching procedures, are highly rele-
vant to the use of any knowledge representation. Partial
matching procedures have received considerable attention
in the rule-based systems. This does not appear to be
the case for other representations.
Moore and Mann do not deal with knowledge representation
per se, but rather with the generation of natural lang-
uage texts from a given knowledge representation. They
are more concerned with the problem of generating a text
(which includes questions of ordering among sentences,
their scopes, etc.) which satisfies a goal held by the
system, describing a (cognitive) state of the reader.
The need for resorting to multi-sentence structures
arises from the fact that for achieving a desired state
of the reader, a single sentence may not be adequate.
McDonald&apos;s work on generation appears to be relevant, but
it is not mentioned by the authors.
Burnstein is primarily concerned with knowledge about
(physical) objects and its role in the comprehension
process. The interest here is the need for a particular
type of knowledge rather than the representation scheme
itself, which he takes to be that of Schank. Knowledge
about objects, their normal uses, and the kinds of
actions they are normally involved in is necessary for
interoretation of sentences dealing with objects. In
sentence (1) John opened the bottle and poured the wine,
Burnstein&apos;s analysis indicates that the inference is dri-
ven largely by our knowledge about open bottles. In this
instance, this need not be the case. We have the same
situation in John took the bottle out of the refrigerator
and poured the wine. The inference here is dependent on
knowing something about wine bottles and their normal
uses; knowledge of the fact that the bottle was open is
not necessary.
Given the normal reading of (1), (1&apos;) John opened the
bottle and Poured the wine out of it will be judged as
Fealindint. 6eiTtion ofâ€”redundant material in (1&apos;) gives
(1). Deletion of redundant and recoverable material is a
device that language exploits. The recoverability here,
however, is dependent on the knowledge about the objects
and their normal uses.If a non-normal reading of (1) is
intended (e.g., the wine being poured into the bottle)
then (1&amp;quot;) John opened the bottle and poured the wine into
it is not felt redundant. This suggests that a prediction
that a normal reading is intended can be made (not, of
course, with complete certainty) by recognizing that we
are dealing with reduced forms. (Of course, context can
always override such a prediction.)
Some further questions are: Knowledge about objects is
essential for comprehension. The paper does not discuss,
however, how this knowledge and its particular represen-
tation helps in controlling the inferences in a uniform
manner. Is there any relationship of this work to the
common sense algorithms of Rieger?
Lebowitz is also concerned with a particular type of
knowledge rather than a representation scheme. Knowledge
about the reader&apos;s purpose is essential for comprehension.
The role played by the &amp;quot;interest&amp;quot; of the reader is also
explored. The application is for the comprehension of
newspaper stories. There is considerable work beyond the
indicated references in the analysis of goal-directed
discourse, but this has not been mentioned.
Finally, there are other issues which are important for
knowledge representation but which have been either left
out or only peripherally mentioned by some of the authors.
Some of these are as follows.
(i) A representation has to be adequate to support the
desired inference. But this is not enough. It is also
important to know how inferences are made (e.g., with
what ease or difficulty). The interaction of the nature
of a representation and the structure of the sentence or
discourse will make certain inferences go through more
easily than others,
(ii) Knowledge has to be updated. Again the nature of
the representation would make certain kinds of updates or
modifications easy and others difficult.
(iii) The previous issue also has a bearing on the
relationship between knowledge representation and know-
ledge acquisition. At some level, these two aspects
have to be viewed together.
</bodyText>
<page confidence="0.999853">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.085200">
<title confidence="0.9967">KNOWLEDGE ORGANIZATION AND APPLICATION: BRIEF COMMENTS ON PAPERS IN THE SESSION</title>
<author confidence="0.999985">Aravind K Joshi</author>
<affiliation confidence="0.85046">Department of Computer and Information Science The Moore School</affiliation>
<address confidence="0.609738">University of Pennsylvania, Philadelphia, PA 19104</address>
<note confidence="0.254901">Comments:</note>
<abstract confidence="0.998360516949152">My brief comments on the papers in this session are based on the abstracts available to me and not on the complete papers. Hence, it is quite possible that some of the comments may turn out to be inappropriate or else they have already been taken care of in the full texts. In a couple of cases. I had the benefit of reading some earlier longer related reports, which were very helpful. All the papers (except by Sangster) deal with either knowledge representation, particular types of knowledge to be represented, or how certain types of knowledge are to be used. Brackman describes a lattice-like structured inheritance network (KLONE) as a language for explicit representation of natural language conceptual information. Multiple descriptions can be represented. How does the facility differ from a similar one in KRL? Belief representations appear to be only implicit. Quantification is handled through a set of &amp;quot;structural descriptions.&amp;quot; It is not clear how negation is handled. The main application is for the command and control of advanced graphics manipulators through natural language. Is there an implicit claim here that the KLONE representations are suitable for both natural language concepts as well as for those in the visual domain? Sowa also presents a network like representation (conceptual graphs). It is a representation that is apparently based on some ideas of Hintikka on incomplete but extensible models called surface models. Sowa also uses some ideas of graph grammars. It is not clear how multiple descriptions and beliefs can be represented in this framework. Perhaps the detailed paper will clarify some of these issues. This paper does not describe any application. Sangster&apos;s paper is not concerned-directly with knowledge representation. It is concerned with complete and partial matching procedures, especially for determining whether a particular instance satisfies the criteria for membership in a particular class. Matching procedures, especially partial matching procedures, are highly relevant to the use of any knowledge representation. Partial matching procedures have received considerable attention in the rule-based systems. This does not appear to be the case for other representations. Moore and Mann do not deal with knowledge representation per se, but rather with the generation of natural language texts from a given knowledge representation. They are more concerned with the problem of generating a text (which includes questions of ordering among sentences, their scopes, etc.) which satisfies a goal held by the system, describing a (cognitive) state of the reader. The need for resorting to multi-sentence structures arises from the fact that for achieving a desired state of the reader, a single sentence may not be adequate. McDonald&apos;s work on generation appears to be relevant, but it is not mentioned by the authors. Burnstein is primarily concerned with knowledge about (physical) objects and its role in the comprehension process. The interest here is the need for a particular type of knowledge rather than the representation scheme itself, which he takes to be that of Schank. Knowledge about objects, their normal uses, and the kinds of actions they are normally involved in is necessary for interoretation of sentences dealing with objects. In (1) opened the bottle and poured the wine, Burnstein&apos;s analysis indicates that the inference is driven largely by our knowledge about open bottles. In this instance, this need not be the case. We have the same in John the bottle out of the refrigerator poured thewine. The inference here is dependent on knowing something about wine bottles and their normal uses; knowledge of the fact that the bottle was open is not necessary. the normal reading of (1), (1&apos;) opened the and Poured the wine out of itwill be judged as 6eiTtion material in (1&apos;) gives (1). Deletion of redundant and recoverable material is a device that language exploits. The recoverability here, however, is dependent on the knowledge about the objects and their normal uses.If a non-normal reading of (1) is intended (e.g., the wine being poured into the bottle) (1&amp;quot;) opened the bottle and poured the wine into it is not felt redundant. This suggests that a prediction that a normal reading is intended can be made (not, of course, with complete certainty) by recognizing that we are dealing with reduced forms. (Of course, context can always override such a prediction.) Some further questions are: Knowledge about objects is essential for comprehension. The paper does not discuss, however, how this knowledge and its particular representation helps in controlling the inferences in a uniform manner. Is there any relationship of this work to the common sense algorithms of Rieger? Lebowitz is also concerned with a particular type of knowledge rather than a representation scheme. Knowledge about the reader&apos;s purpose is essential for comprehension. The role played by the &amp;quot;interest&amp;quot; of the reader is also explored. The application is for the comprehension of newspaper stories. There is considerable work beyond the indicated references in the analysis of goal-directed discourse, but this has not been mentioned. Finally, there are other issues which are important for knowledge representation but which have been either left out or only peripherally mentioned by some of the authors. Some of these are as follows. (i) A representation has to be adequate to support the desired inference. But this is not enough. It is also important to know how inferences are made (e.g., with what ease or difficulty). The interaction of the nature of a representation and the structure of the sentence or discourse will make certain inferences go through more easily than others, (ii) Knowledge has to be updated. Again the nature of the representation would make certain kinds of updates or modifications easy and others difficult. (iii) The previous issue also has a bearing on the relationship between knowledge representation and knowledge acquisition. At some level, these two aspects have to be viewed together.</abstract>
<intro confidence="0.898909">31</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>