<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.849744">
Understanding
</title>
<author confidence="0.90483">
Claire Gardent
</author>
<affiliation confidence="0.8669445">
Computational Linguistics
University of the Saarland
</affiliation>
<address confidence="0.61415">
Saarbriicken, Germany
</address>
<email confidence="0.990446">
claire@coli.uni-sb.de
</email>
<title confidence="0.566375">
&amp;quot;Each Other&amp;quot;
</title>
<author confidence="0.686527">
Karsten Konrad
</author>
<affiliation confidence="0.9836505">
Computer Science
University of the Saarland
</affiliation>
<address confidence="0.562468">
Saarbriicken, Germany
</address>
<email confidence="0.78683">
konrad@ags .uni-sb.de
</email>
<sectionHeader confidence="0.970717" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999863666666667">
Although natural language is ambiguous, vari-
ous linguistic and extra-linguistic factors often
help determine a preferred reading. In this pa-
per, we show that model generation can be used
to model this process in the case of reciprocal
statements. The proposed analysis builds on in-
sights from Dalrymple et al. 98 and is shown to
provide an integrated, computational account
of the interplay between model theoretic inter-
pretation, knowledge-based reasoning and pref-
erences that characterises the interpretation of
reciprocals.
</bodyText>
<sectionHeader confidence="0.995594" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997119047619">
Although there is widespread agreement that
inference is an essential component of natural
language processing, little work has been done
so far on whether existing automated reason-
ing systems such as theorem provers and model
builders could be fruitfully put to work in the
area of natural language interpretation.
In this paper, we focus on the inference prob-
lems raised by the reciprocal expression each
other and show that model generation provides
an adequate tool for modeling them.
The paper is structured as follows. Section 3
discusses the meaning of reciprocal statements
and proposes a formal semantics for each other.
Section 2 shows how model generation can be
used to provide this semantics with a compu-
tational interpretation. Section 4 compares our
approach with the account of reciprocals which
inspired it in the first place namely, (Dalrymple
et al., 1998). Section 5 concludes with pointers
for further research.
</bodyText>
<sectionHeader confidence="0.703625" genericHeader="method">
2 The meaning of reciprocal
statements
</sectionHeader>
<bodyText confidence="0.998387">
In the linguistic literature, the reciprocal ex-
pression each other is often taken to denote a
dyadic quantifier over a first-order set, which we
will call the antecedent set, and a binary first-
order relation, which we will call the scope re-
lation. In what follows, we assume an approach
of this type and will use the symbol RCP for
such reciprocal quantifiers so that the seman-
tic representation of e.g. Jon and Bill saw each
other will be:
</bodyText>
<listItem confidence="0.679946">
(1) RcP({j on, bill})(AyAx saw(x , y))
</listItem>
<bodyText confidence="0.995042571428572">
When antecedent sets of just two members
are considered, each set member is required to
stand in the scope relation to each other mem-
ber. For larger sets however, research on recip-
rocal statements has uncovered a variety of log-
ical contributions that the reciprocal can pro-
vide. Here are some examples.
</bodyText>
<listItem confidence="0.7664222">
(2) The students like each other.
Vx (std(x) Vy (x y A std(y)
ke (x , y))
(3) The students stare at each other in sur-
prise.
</listItem>
<equation confidence="0.6871756">
Vx (std(x) 3y (x y A std(y) A
stare_at(x , y))
(4) The students gave each other measles.
Vx (std(x) -4 3y (x y A std(y) A
(gave_measles(x, y) V gave_measle(y, x))))
</equation>
<bodyText confidence="0.999586428571429">
We can accept (2) to be true only if for each
pair x and y of two students it holds that x
likes y. But an analogous interpretation would
be invalid in the case of (3) and (4) where not
all pairs in the antecedent set the students can
consistently stand in the scope relation (one can
only stare at most at one person at a time, and
</bodyText>
<page confidence="0.998544">
319
</page>
<bodyText confidence="0.999042454545454">
one can only get measles from at most one per-
son). More generally, (Langendoen, 1978; Dal-
rymple et al., 1998) convincingly argues that
different reciprocal statements can have very
different truth conditions. The challenge to be
addressed is thus the following: How can we
determine a (computational) semantics for the
reciprocal expressions each other that accounts
for these multiplicity of meanings while predict-
ing the specific meaning of a particular recipro-
cal statement?
Clearly knowledge based reasoning plays an
important role: only those readings are possible
that are consistent with our knowledge about
the situation and the world. Specifically, knowl-
edge based reasoning constrains the strength of
the truth conditions of a reciprocal statement.
Thus if we abstract away from the specific scope
relations, the truth conditions of examples such
as (2),(3) and (4) are ordered through entail-
ment as follows (with A the antecedent set and
R the scope relation):
</bodyText>
<equation confidence="0.996464333333333">
Vx (A(x) Vy (A(y) -+ R(xy))
Vx (A(x) -43y (A(y) A R(xy))
Vx (A(x) -4 3y (A(y) A (R(xy)V (R(yx)))
</equation>
<bodyText confidence="0.991872555555556">
Specifically, example (2), which does not in-
volve any strong knowledge based constraint,
has the strongest truth-conditions of the three
examples. By contrast in (3), the knowledge
that one can stare at most at one person, forces
a V3 reading while in (4), a weaker meaning still
is imposed by knowledge based constraints: the
x gave y measles relation is asymmetric hence
the W reading is ruled out; moreover, since one
cannot be infected twice, some students in the
group will be infected but not pass on the dis-
ease to anyone. Hence the strongest truth con-
ditions that can be assigned the sentence are the
V] disjunctive reading indicated in (4).
But are there any other constraints on the
interpretation process than these knowledge
based constraints? And which meaning shall
we assign a reciprocal expression? The compu-
tational semantics we will propose is inspired
from (Dalrymple et al., 1998) and relies on the
following observations.
First, we note that (Dalrymple et al., 1998)
identifies a lower bound for the truth conditions
of reciprocal sentences which they dub Inclusive
Alternative Ordering (IAO). It is exemplified by
sentence (4) above and corresponds to the fol-
lowing definition of RCP.
</bodyText>
<listItem confidence="0.929017">
(5) RcPrAo APAR VI &gt; 2 A Vx (P(x)
P(y) AxyA (R(x, y) V R(y, , x))))
</listItem>
<bodyText confidence="0.999968633333334">
This definition only adequately characterises ex-
amples such as (4). It does not cover the
stronger meanings of the reciprocal in sentences
such as (2) and (3). However, each known form
of reciprocity entails RCP/AO&apos;s truth conditions,
and RCP/A0 therefore provides us with a mini-
mal semantics for reciprocals.
Further, we observe that given a particular
reciprocal statement, there seems to be a pref-
erence for consistent interpretations where the
number of pairs that are in the scope relation
is as large as possible. For instance in (3), not
every student can stare at every other student
(one can stare at at most one person), but intu-
itively, the sentence requires that every student
stares at some other student. While such an
interpretation is much weaker than that of (2),
this maximisation of the scope relation yields a
reading that is also much stronger than the min-
imal IAO interpretation of (4). More generally,
while IAO provides us with a lower bound for
the interpretation of reciprocal statements, we
will see in section 3 that the maximisation of the
scope relation that is consistent with contextual
knowledge yields the upper bound for the inter-
pretation of a particular reciprocal statement
i.e., its meaning.
Based on these observations, the principle de-
termining the actual logical contribution of a
reciprocal statement can be stated as follows:
</bodyText>
<subsectionHeader confidence="0.967493">
Maximise Meaning Hypothesis
</subsectionHeader>
<bodyText confidence="0.9990255">
(MMH): The valid interpretations of
a reciprocal sentence S in a context r
(where r includes knowledge about the
previous discourse, the discourse situ-
ation and the world) are those which
(a) are consistent both with the IA0
form of reciprocity and the informa-
tion provided by r, and (b) whose con-
tributions to the scope relation are the
strongest.
The MMH selects from the set of interpreta-
tions that are consistent with TAO and contex-
tual knowledge, those that maximise the scope
relation. Crucially, this view of reciprocals leads
</bodyText>
<page confidence="0.995098">
320
</page>
<bodyText confidence="0.999833">
to an inference method that can actually com-
pute the preferred interpretations of reciprocal
sentences. We now turn to this.
</bodyText>
<sectionHeader confidence="0.973275" genericHeader="method">
3 Interpretation as Model
Generation
</sectionHeader>
<bodyText confidence="0.999738727272727">
In Discourse Representation Theory (DRT,
(Kamp, 1981; Kamp and Reyle, 1993)), a sen-
tence with semantic representation 4) is true
with respect to a model M if there is an embed-
ding of 4) onto M. Intuitively, this requirement
says that a sub-model M&apos; of M must be found
which satisfies (D. So for instance, sentence (6a)
is true in M if there are two individuals bugs
and bunny in M such that bugs and bunny stand
in the love relation; or in other words, if the
partial model sketched in (6b) is part of M.
</bodyText>
<listItem confidence="0.9631785">
(6) a. Bugs likes Bunny.
b. {love(bugs, bunny)}
</listItem>
<bodyText confidence="0.999811690476191">
As shown in (Gardent and Konrad, To ap-
pear), model generators (i.e., programs that
compute some of the models satisfying a finite
set of logical formulas) can be used to provide
DRT, and more generally model-theoretic ap-
proaches to natural language semantics, with a
procedural interpretation: Given the semantic
representation of a discourse and the relevant
world knowledge 4) (i.e., a finite set of logical
formulas), a model generator proves that 4. is
satisfiable by generating some of its models.
Intuitively, satisfying models explain how dis-
courses can be made true. They give an
abstract representation of how (part of) the
world should be for a discourse to be true.
Concretely, satisfying models can be seen as
capturing the meaning of discourses: data-
bases that can be queried e.g. as part of
a query/answer system or to interpret subse-
quent discourse. Satisfying models are also
remininiscent of Johnson-Laird&apos;s mental mod-
els (Johnson-Laird and Byrne, 1991) and in
essence, mental models are very much like the
Herbrand models we are making use of here.
Formally, a model is a mathematical struc-
ture that describes how the symbols of a logi-
cal theory are interpreted. Given a first-order
language .C, a model is a pair (I, D) with D a
non-empty set of entities (the domain of indi-
viduals) and I an interpretation function which
maps relation symbols in G to relations of ap-
propriate arity in D and constant symbols in G
to elements of D. Here we identify these mod-
els with sets of positive assumptions that unam-
biguously define the interpretation of the rela-
tion symbols and fix the interpretation of terms
to first-order entities that carry a unique name.
These are known in the literature as Herbrand
models.
The set (7c) is such a model for the logical
form (7b) which is a semantic representation of
the sentence (7a).
</bodyText>
<listItem confidence="0.96611675">
(7) a. Jon likes his cousin.
b. 3x cousin_of (x, jon) A like(jon,x)
c. A41 = {cousin_of(cjjon),
like(jon, ci)}
</listItem>
<bodyText confidence="0.999894">
The model M1 defines an interpretation of
the predicates cousin and like over the universe
of discourse D = fjon,c11 . It can also be taken
as a valid interpretation of (7a).There are, how-
ever, infinitely many models for (7b) that do
not correspond to such interpretations e.g.
</bodyText>
<equation confidence="0.939163666666667">
(8) M2 = {cousin_of (jon, jon), like(jon, j on)}
(9) M3 = {cousin_of (ci, jon), (jon, ci),
like(ci, jon)}
</equation>
<bodyText confidence="0.999630333333333">
The model M2 explains the truth of (7a) by
declaring Jon as his own cousin. This is a re-
sult of the inappropriate semantic representa-
tion (7b) which fails to specify that the relation
expressed by the noun cousin is irreflexive. In
the case of M3, the model contains superfluous
information. While it is consistent to assume
j on) it is not necessary for explaining
the truth of the input.
</bodyText>
<subsectionHeader confidence="0.999053">
3.1 Minimality
</subsectionHeader>
<bodyText confidence="0.999865625">
For applications to natural-language, we are in-
terested in exactly those models that capture
the meaning of a discourse, or at least capture
the preferred interpretations that a hearer asso-
ciates with it. As discussed in (Gardent and
Webber, January 2000), obtaining only these
models requires eliminating both models that
are &amp;quot;too small&amp;quot; (e.g. M2) and models that are
&amp;quot;too big&amp;quot; (e.g. M3).
Models such as M2 can be eliminated simply
by using more appropriate truth conditions for
NL expressions (e.g. 3x cousin(x) A of (x, jon) A
x jon A like(j on, x) for (7a)). In general how-
ever, eliminating models that are &amp;quot;too small&amp;quot;
is a non-trivial task which involves the interac-
tion of model-theoretic interpretation not only
</bodyText>
<page confidence="0.993222">
321
</page>
<bodyText confidence="0.999900090909091">
with world knowledge reasoning but also with
syntax, prosody and pragmatics. The issue is
discussed at some length (though not solved) in
(Gardent and Webber, January 2000).
To eliminate models that are &amp;quot;too big&amp;quot;, some
notion of minimality must be resorted to. For
instance, (Gardent and Konrad, 1999; Gardent
and Konrad, To appear) argues that local min-
imality is an adequate form of minimality for
interpreting definite descriptions. Local mini-
mality is defined as follows.
</bodyText>
<construct confidence="0.458216666666667">
Local Minimality: Let 4) be a set of first-
order formulas and D be the set of Herbrand
models of 4) that use some finite domain D
whose size is minimal. Then a model (I, D) E
D is locally minimal if there is no other
model (I&apos; , D&apos;) E D such that I&apos; C I.
</construct>
<bodyText confidence="0.997222166666667">
Locally minimal models are models that sat-
isfy some input (I, within a minimal domain /31 of
individuals and are subset-minimal with respect
to all other domain minimal models. These
models are the simplest in the sense of Occam&apos;s
Razor and often the best explanation for the
truth of an observation. In particular, if we as-
sume that M2 is ruled out by a more appro-
priate semantics for the word cousin, local min-
imality rules out M3 as non locally minimal and
therefore M1 is correctly identified as giving the
preferred interpretation for example (7).
</bodyText>
<subsectionHeader confidence="0.9853655">
3.2 The MMH as a Minimality
Constraint
</subsectionHeader>
<bodyText confidence="0.999458363636364">
In the case of reciprocals, local minimality
is clearly not a characterisation of preferred
interpretations. Our semantic representation
RCP/A0 will only capture a reciprocal&apos;s mean-
ing if the reciprocal group has exactly two mem-
bers or if the input meets IAO, the weakest form
of reciprocity. For instance, the locally minimal
model (10c) of formula (10b) is too weak to con-
stitute an acceptable interpretation of (10a). In-
stead, the model capturing the meaning of (10a)
is the model given in (10d).
</bodyText>
<listItem confidence="0.9863268">
(10) a. Jon, Bill and Dan like each other.
b. Rcprito Won, bill, danD(AyAx like (x , y))
c. Ilike(j on, bill), like (bill , dan)}
d. flike(jon, bill), like (jon, dan), like (bill , dan),
like(bill, j on), like (dan, bill), like(dan, jon)}
</listItem>
<bodyText confidence="0.999325625">
Since the MMH maximises rather than min-
imises the logical contribution of formulas, it
seems at first sight incompatible with local min-
imality. However, a simple method to combine
the MMH and model minimality is to consider
the maximisation of reciprocal relations as a
minimisation of their complement sets. After
all, the difference in acceptability between (10c)
and (10d) as models for (10a) is due to exactly
those pairs (x, y) (with x y) that are not in
the like relation. To capture this intuition, we
introduce a special predicate $R that indicates
assumptions whose truth is considered &amp;quot;costly&amp;quot;.
In our case, these assumptions correspond to the
pairs of individuals that are not in the scope re-
lation. The semantic representation of recipro-
</bodyText>
<equation confidence="0.70661025">
cal each other is then as follows.
(11) RCP APAR (RcP/Ao(P)(R) A
VxVy (P(x) A P(y) A x y A y) &lt;#.
$R(x,y)))
</equation>
<bodyText confidence="0.999371666666667">
The first conjunct says that a reciprocal sen-
tence has as weakest possible meaning an IA0
reading. Since TAO is entailed by other identi-
fied meaning for reciprocal statements, this is
compatible with the fact that reciprocal sen-
tences can have other, stronger meanings. The
second conjunct says that each pair (x, y) (with
x y) that is not in the like relation is in
the $R relation. This encoding leads to mod-
els like (12b) and (12c) for (12a). We say that
model (12b) has a $R-cost of 4 ($R4), while
model (12c) has a cost of 0.
</bodyText>
<listItem confidence="0.946915285714286">
(12) a. RcP({jon, bill, dan})(AyAx like(x, y))
b. {like (jon, bill), like (jon, dan), $R (bill, dan),
SR(bill, j on), SR (dan, bill), SR (dan, jon)}
$R4
c. Ilike(j on, bill), li ke (j on, dan), like(bill, dan),
like (bill , jon), like (dan, bill), like (dan, jon)}
$R0
</listItem>
<bodyText confidence="0.972139916666667">
We now introduce a new form of minimality
whose definition is as follows.
Conservative Minimality: Let 4. be a set
of first-order formulas and D be the set of Her-
brand models of 43 with a minimal domain D.
Then D has a subset C of models that carry
a minimal cost. A model (I, D) E C is con-
servative minimal if there is no other model
(I&apos; , D&apos;) E C such that
Conservative minimality is a conservative ex-
tension of local minimality: if there are no
costs at all, then all local minimal models are
</bodyText>
<page confidence="0.992705">
322
</page>
<bodyText confidence="0.999704533333333">
also conservative models. Conservative mini-
mality is a combination of local minimality and
cost minimisation that correctly identifies the
preferred interpretation of reciprocal sentences.
For instance since (12c) carries a minimal cost,
it is a conservative minimal model for (12a)
whereas (12b) isn&apos;t. Intuitively the approach
works as follows: the more pairs there are that
do not stand in the scope relation of the re-
ciprocal, the bigger the $R predicate and the
more costly (i.e. the least preferred) the model.
That is, the combined use of a $R-predicate and
of conservative minimality allows us to enforce
a preference for interpretations (i.e. models)
maximising R.
</bodyText>
<subsectionHeader confidence="0.999302">
3.3 The System
</subsectionHeader>
<bodyText confidence="0.9852425">
KIMBA (Konrad and Wolfram, 1999) is a finite
model generator for first-order and higher-order
logical theories that is based on a translation
of logics into constraint problems over finite-
domain integer variables. KIMBA uses an effi-
cient constraint solver to produce solutions that
can be translated back into Herbrand models of
the input.
We have tailored KIMBA such that it enumer-
ates the conservative models of its input. In-
tuitively, this works as follows. First, KIMBA
searches for some arbitrary model of the input
that mentions a minimum number of individu-
als. Then, it takes the $R-cost of this model
as an upper bound for the cost of all successor
models and further minimises the cost as far
as possible by branch-and-bound search. After
KIMBA has determined the lowest cost possi-
ble, it restarts the model search and eliminates
those models from the search space that have
a non-minimal cost. For each model M that
it identifies as a cost-minimal one, it proves by
refutation that there is no other cost-minimal
model M&apos; that uses only a subset of the pos-
itive assumptions in M. Each succesful proof
yields a conservative minimal model.
All the examples discussed in this paper have
been tested on Kimba and can be tried out at:
http://www.coli.uni-sb.de/c1/
projects /lisa/kimba.html
</bodyText>
<subsectionHeader confidence="0.985577">
3.4 A spectrum of possible meanings
</subsectionHeader>
<bodyText confidence="0.982581285714286">
Let us see in more detail what the predictions of
our analysis are. As we saw in section 2, recip-
rocal statements can have very different truth
conditions. Intuitively, these truth-conditions
lie on a spectrum from the weakest IAO inter-
pretation (A is the antecedent set and R the
scope relation):
</bodyText>
<equation confidence="0.9241205">
1,41 &gt; 2 A Vx E A(x) y (A(y) A x y
A(R(x, y) V R(y, x))
</equation>
<bodyText confidence="0.917292">
to the strongest so-called Strong Reciprocity
(SR) interpretation namely:
fAI 2 A Vx A(x)Vy A(y)(x y z= R(x,y))
We now see how the MMH allows us to cap-
ture this spectrum.
Let us start with example (2) whose truth-
conditions are the strongest Strong Reciprocity
conditions: every distinct x and y in the an-
tecedent set are related to each other by the
scope relation. In this case, there is no con-
straining world knowledge hence the content of
the like relation can be fully maximised. For
instance if there are five students, the cheapest
model is one in which the cardinality of like is
twenty (and consequently the cardinatity of $R
is zero).
</bodyText>
<equation confidence="0.995854375">
(13) flike(sl, s2), like(sl, 83), like(sl, s4),
like(sl, 85), like(s2, 31), like(s2, 83),
like(s2, s4), like(s2, s5), like (s3, sl),
like(s3, s2), like(s3, s4), like(s3, s5),
like(s4, sl), like(s4, s3), like(s4, s2),
like(s4, s5), like (s5, 81), like (85, s3),
like(s5, 82), like(s5, s4)
$R0
</equation>
<bodyText confidence="0.999823133333333">
By contrast, example (3) has a much weaker
meaning. In this case there is a strong world
knowledge constraint at work, namely that one
can stare at only one other person at some
time. The cheapest models compatible with this
knowledge are models in which every student
stare at exactly one other student. Thus in a
universe with five students, the preferred inter-
pretations are models in which the cardinality
of the scope relation x stares at y in surprise
is five. The following are example models. For
simplicity we ommit the SR propositions and
give the cost of the model instead (i.e. the car-
dinality of the complement set of the scope re-
lation).
</bodyText>
<equation confidence="0.625766714285714">
(14) {stare_at(sl, s2), stare_at(82, s3),
stare_at(s3, s4), stare_at(s4, .85),
stare_at(s5, s3)} $R15
323
(15) Istare_at(sl, 82), stare_at(s2, s3),
stare_at(s3, s4), stare_at(s4, s5),
stare_at(s5, sl)} $R15
</equation>
<bodyText confidence="0.999793555555555">
Sentence (4) illustrates an intermediate case
with respect to strength of truth conditions.
World knowledge implies that the scope rela-
tion x give y measles is assymetric and further
that every individual is given measles by at most
one other individual. Given a set of five stu-
dents, model (16) and (17) are both acceptable
interpretations of (4), (16) being the preferred
interpretation.
</bodyText>
<equation confidence="0.9731496">
(16) Igave_measles(81, s2), gave_measles(sl, s3),
gave_measles(s2, s4), gave_measles(s3, 85)1
$R16
(17) Igave_measles(sl, 82), gave_measles(s2, s4),
gave_measles(s3, s5)} $R17
</equation>
<bodyText confidence="0.999977764705882">
In short, these examples show the MMH at
work. They show how given a single seman-
tic representation for reciprocals, a variety of
meanings can be derived as required by each
specific reciprocal statement. Two elements are
crucial to the account: the use of model build-
ing, and that of minimality as an implemen-
tation of preferences. Model building allows
us to compute all the finite interpretations of
a sentence that are consistent with contextual
knowledge and with an IA0 interpretation of
the reciprocal expression. Preferences on the
other hand (i.e. the use of the cost predicate
$R and the search for conservative mininal mod-
els), permits choosing among these interpreta-
tions the most likely one(s) namely, the inter-
pretation(s) maximising the scope relation.
</bodyText>
<sectionHeader confidence="0.999909" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.99952025">
(Dalrymple et al., 1998) (henceforth DKKMP)
proposes the following taxonomy of mean-
ings for reciprocal statements (A stands for
the antecedent set and R for the scope relation):
</bodyText>
<construct confidence="0.434457">
Strong Reciprocity (SR)
Vs, y E A(x y xRy).
Intermediate reciprocity (IR)
Vx, y E A 3.zi, 3,4„, E A(x
xRzi A ... A zrnRY)
</construct>
<figure confidence="0.833386">
One-way Weak Reciprocity ( OWR)
Vx E A 3y E A (xRy)
Intermediate Alternative Reciprocity (JAR)
x, y E A3zi, 3z7, E A(x y
(xRzi V zdix) A... A (zmRy V yRzni))
Inclusive Alternative Ordering (IAO)
Vx E A 3y E A(xRy V yRx)
</figure>
<bodyText confidence="0.998477948717949">
To predict the meaning of a specific recip-
rocal sentence, DKKMP then postulate the
Strongest Meaning Hypothesis which says that
the meaning of a reciprocal sentence is the log-
ically strongest meaning consistent with world
and contextual knowledge.
The main difference between the DKKMP ap-
proach and the present approach lies in how
the best reading is determined: it is the logi-
cally strongest of the five postulated meanings
in DKKMP, whereas in our approach, it is that
reading which maximises the scope relation of
the reciprocal. This difference has both empiri-
cal and computational consequences.
Empirically, the predictions are the same in
most cases because maximising the scope rela-
tion often results in yielding a logically stronger
meaning. In particular, as is illustrated by the
examples in section 2, the present approach cap-
tures the five meanings postulated by DKKMP.
Thus model (13) exemplifies an SR reading,
model (15) an IR reading and model (14) an
OWR reading. Further, model (16) is an JAR
interpretation while model (17) shows an TAO
reading.
But as the examples also show there are
cases where the predictions differ. In particu-
lar, in the DKKMP approach, sentence (3) is
assigned the IR reading represented by model
(15). However as they themselves observe, the
sentence also has a natural OWR interpretation
namely, one as depicted in model (14), in which
some pairs of students reciprocally stare at each
other. This is predicted by the present approach
which says that models (14) and (15) are equally
plausible since they both maximise the stare at
relation to cardinality five.
On the other hand, the DKKMP account is
more appropriate for examples such as:
</bodyText>
<listItem confidence="0.893178">
(18) The students sat next to each other
a. forming a nice cercle.
</listItem>
<page confidence="0.974575">
324
</page>
<listItem confidence="0.541236666666667">
b. filling the bench.
c. some to the front and others to the back
of the church.
</listItem>
<bodyText confidence="0.996177068181818">
An IR interpretation is predicted for (18)
which is compatible with both continuation
(18a) and continuation (18b). By contrast, the
model generation approach predicts that the
preferred interpretation is a model in which the
students form a circle, an interpretation com-
patible with continuation (18a) but not with
continuations (18b-c)
However, both approaches fail to predict the
reading made explicit by continuation (18c)
since this corresponds to the weaker OWR in-
terpretation under the DKKMP account and to
a model which fails to maximise the scope re-
lation under the present approach. More gen-
erally, both approaches fail to capture the se-
mantic vagueness of reciprocal statements illus-
trated by the following examples&apos;:
(19) a. The students often help each other with
their homework.
b. In the closing minutes of the game, the
members of the losing team tried to encour-
age each other.
In both cases, the sentences can be true with-
out maximising either the strength of its truth
conditions (Strong Reciprocity) or the scope re-
lation. This suggests that an empirically more
correct analysis of reciprocals should involve
prototypical and probabilistic knowledge - as
it is essentially a computational approximation
of the DKKMP approach, the present account
does not integrate such information though it is
compatible with it: just as we restrict the set
of generated models to the set of conservative
minimal models, we could restrict it to the set
of models having some minimal probability.
Computationally, the difference between the
DKKMP and the present approach is as fol-
lows. In essence, the DKKMP approach re-
quires that each of the five possible readings
(together with the relevant world knoweldge)
be checked for consistency: some will be con-
sistent, others will not. Since the first order
consistency and validity problems are not de-
cidable, we know that there can be no method
</bodyText>
<footnote confidence="0.980736">
1I am thankful to an anonymous NAACL referree for
these examples.
</footnote>
<bodyText confidence="0.999837625">
guaranteed to always return a result. In order
to implement the DKKMP approach, one must
therefore resort to the technique advocated in
(Blackburn et al., 1999) and use both a theo-
rem prover and a model builder: for each possi-
ble meaning M, the theorem is asked to prove
and the model builder to satisfy M. Mi is
inconsistent if the theorem prover succeeds, and
consistent if the model builder does. Theoreti-
cally however, cases may remain where neither
theorem proving nor model building will return
an answer. If these cases occur in practice, the
approach simply is not an option. Further, the
approach is linguistically unappealing as it in
essence requires the reciprocal each other to be
five-way ambiguous.
By contrast, the model generation approach
assigns a single semantic representation to each
other. The approach strengthens the logical
contribution of the weak semantic representa-
tion as a process based on computational con-
straints on a set of effectively enumerable mod-
els. As a result, we will never encounter un-
decidable logical problems as long as the repre-
sented discourse is consistent. The model gener-
ator is the only computational tool that we need
for determining preferable readings, and our ex-
periment shows that for the examples discussed
in this paper, it returns preferred readings in
a few seconds on standard PCs as long as the
background theory and the size of the domain
remain managably small.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999983176470588">
We have argued that Model building can be used
to provide a computational approximation of
DKKMP&apos;s analysis of reciprocals.
One crucial feature of the account is that
it permits building, comparing and ranking of
natural-language interpretations against each
other. In the case of reciprocals, the ranking is
given by the size of the scope relation, but other
ranking criteria have already been identified in
the literature as well. For instance, (Gardent
and Konrad, To appear) shows that in the case
of definite descriptions, the ranking defined by
local minimality permits capturing the prefer-
ence of binding over bridging, over accomoda-
tion. Similarly (Baumgartner and Kuhn, 1999)
shows that a predicate minimisation together
with a preference for logically consequent reso-
</bodyText>
<page confidence="0.996918">
325
</page>
<bodyText confidence="0.999708815789474">
lutions can be used to model the interpretation
of pronominal anaphora.
This suggests that one of the most promising
application of model generators is as a device for
developing and testing preference systems for
the interpretation of natural language. Infer-
ence and knowledge based reasoning are needed
in NLP not only to check for consistency and
informativity (as illustrated in e.g. (Blackburn
et al., 1999)), but also to express preferences
between, or constraints on, possible interpreta-
tions. For this, finite model builders are natural
tools.
Another area that deserves further investi-
gation concerns the use of minimality for dis-
ambiguation. In this paper, conservative min-
imality is used to choose among the possible
interpretations of a particular reciprocal state-
ment. On the other hand, (Gardent and Web-
ber, January 2000) shows that minimality is
also an important tool for disambiguating noun-
compounds, logical metonymy and definite de-
scriptions. As the paper shows though, many
questions remains open about this use of mini-
mality for disambiguation which are well worth
investigating.
In further work, we intend to look at other
ambiguous natural language constructs and to
identify and model the ranking criteria deter-
mining their preferred interpretation. Plurals
are a first obvious choice. But more generally,
we hope that looking at a wider range of data
will unveil a broader picture of what the gen-
eral biases are which help determine a preferred
reading — either in isolation, as here, or in con-
text, as in (Gardent and Webber, January 2000)
— and of how these biases can be modelled us-
ing automated reasoning systems.
</bodyText>
<sectionHeader confidence="0.991331" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999850363636364">
We are grateful to audiences from ITRI-
Brighton, the Edinburgh School of Cognitive
Science, the Paris VI TALANA seminar and the
Amsterdam DIP colloquium for helpful com-
ments and discussion on the material presented
here as well as to the three NAACL anony-
mous referrees for constructive feedback. This
work was partially supported by the Project
C2 (LISA) in SFB-378, grant by the Deutsche
Forschungsgemeinschaft to the University of
Saarbriicken.
</bodyText>
<sectionHeader confidence="0.987004" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.983051791666667">
Peter Baumgartner and Michael Kiihn. 1999.
Abductive coreference by model construction.
In ICoS-1 Inference in Computational Se-
mantics, Institute for Logic, Language and
Computation, University of Amsterdam, Au-
gust.
P. Blackburn, J. Bos, M. Kohlhase, and
H. de Neville. 1999. Inference and Com-
putational Semantics. In Third Interna-
tional Workshop on Computational Seman-
tics (IWCS-3), Tilburg, The Netherlands.
Mary Dalrymple, Makoto Kanasawa, Yookyung
Kim, Sam Mchombo, and Stanley Peters.
1998. Reciprocal expressions and the con-
cept of reciprocity. Linguistics and Philoso-
phy, 21(2):159-210, April.
Claire Gardent and Karsten Konrad. 1999.
Definites and the proper treatment of rabbits.
In Proceedings of ICOS. Also CLAUS Report
111, http://www.coli.uni-sb.de/claus/.
Claire Gardent and Karsten Konrad. To ap-
pear. Interpreting Definites using Model
Generation. Journal of Language and Com-
putation.
Claire Gardent and Bonnie Webber. Jan-
uary 2000. Automated deduction and
discourse disambiguation. Submitted for
Publication. Also CLAUS Report 113,
http: / /www.coli.uni-sb.de/claus/.
P.N. Johnson-Laird and Ruth M.J. Byrne.
1991. Deduction. Lawrence Erlbaum Asso-
ciates Publishers.
Hans Kamp and Uwe Reyle. 1993. From Dis-
course to Logic. Kluwer, Dordrecht.
Hans Kamp. 1981. A theory of truth and
semantic representation. In J. Groenendijk,
Th. Janssen, and M. Stokhof, editors, Formal
Methods in the Study of Language, pages 277
- 322. Mathematisch Centrum Tracts, Ams-
terdam.
Karsten Konrad and D. A. Wolfram. 1999.
Kimba, a model generator for many-valued
first-order logics. In Proc., 16th Interna-
tional Conference on Automated Deduction,
CADE 99, LNCS, forthcoming, Trento, Italy.
Springer.
D. Terence Langendoen. 1978. The logic of reci-
procity. Linguistic Inquiry, 9(2):177-197.
</reference>
<page confidence="0.999117">
326
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.602442">
<title confidence="0.998706">Understanding</title>
<author confidence="0.999072">Claire Gardent</author>
<affiliation confidence="0.9949135">Computational Linguistics University of the Saarland</affiliation>
<address confidence="0.900834">Saarbriicken, Germany</address>
<author confidence="0.849934">Each Other Karsten Konrad</author>
<affiliation confidence="0.997622">Computer Science University of the Saarland</affiliation>
<address confidence="0.970643">Saarbriicken, Germany</address>
<abstract confidence="0.997550769230769">Although natural language is ambiguous, various linguistic and extra-linguistic factors often help determine a preferred reading. In this paper, we show that model generation can be used to model this process in the case of reciprocal statements. The proposed analysis builds on insights from Dalrymple et al. 98 and is shown to provide an integrated, computational account of the interplay between model theoretic interpretation, knowledge-based reasoning and preferences that characterises the interpretation of reciprocals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter Baumgartner</author>
<author>Michael Kiihn</author>
</authors>
<title>Abductive coreference by model construction.</title>
<date>1999</date>
<booktitle>In ICoS-1 Inference in Computational Semantics, Institute for Logic, Language</booktitle>
<institution>and Computation, University of Amsterdam,</institution>
<marker>Baumgartner, Kiihn, 1999</marker>
<rawString>Peter Baumgartner and Michael Kiihn. 1999. Abductive coreference by model construction. In ICoS-1 Inference in Computational Semantics, Institute for Logic, Language and Computation, University of Amsterdam, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blackburn</author>
<author>J Bos</author>
<author>M Kohlhase</author>
<author>H de Neville</author>
</authors>
<title>Inference and Computational Semantics.</title>
<date>1999</date>
<booktitle>In Third International Workshop on Computational Semantics (IWCS-3),</booktitle>
<location>Tilburg, The Netherlands.</location>
<marker>Blackburn, Bos, Kohlhase, de Neville, 1999</marker>
<rawString>P. Blackburn, J. Bos, M. Kohlhase, and H. de Neville. 1999. Inference and Computational Semantics. In Third International Workshop on Computational Semantics (IWCS-3), Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>Makoto Kanasawa</author>
<author>Yookyung Kim</author>
<author>Sam Mchombo</author>
<author>Stanley Peters</author>
</authors>
<title>Reciprocal expressions and the concept of reciprocity.</title>
<date>1998</date>
<journal>Linguistics and Philosophy,</journal>
<pages>21--2</pages>
<contexts>
<context position="1668" citStr="Dalrymple et al., 1998" startWordPosition="244" endWordPosition="247">lly put to work in the area of natural language interpretation. In this paper, we focus on the inference problems raised by the reciprocal expression each other and show that model generation provides an adequate tool for modeling them. The paper is structured as follows. Section 3 discusses the meaning of reciprocal statements and proposes a formal semantics for each other. Section 2 shows how model generation can be used to provide this semantics with a computational interpretation. Section 4 compares our approach with the account of reciprocals which inspired it in the first place namely, (Dalrymple et al., 1998). Section 5 concludes with pointers for further research. 2 The meaning of reciprocal statements In the linguistic literature, the reciprocal expression each other is often taken to denote a dyadic quantifier over a first-order set, which we will call the antecedent set, and a binary firstorder relation, which we will call the scope relation. In what follows, we assume an approach of this type and will use the symbol RCP for such reciprocal quantifiers so that the semantic representation of e.g. Jon and Bill saw each other will be: (1) RcP({j on, bill})(AyAx saw(x , y)) When antecedent sets of</context>
<context position="3283" citStr="Dalrymple et al., 1998" startWordPosition="543" endWordPosition="547">n surprise. Vx (std(x) 3y (x y A std(y) A stare_at(x , y)) (4) The students gave each other measles. Vx (std(x) -4 3y (x y A std(y) A (gave_measles(x, y) V gave_measle(y, x)))) We can accept (2) to be true only if for each pair x and y of two students it holds that x likes y. But an analogous interpretation would be invalid in the case of (3) and (4) where not all pairs in the antecedent set the students can consistently stand in the scope relation (one can only stare at most at one person at a time, and 319 one can only get measles from at most one person). More generally, (Langendoen, 1978; Dalrymple et al., 1998) convincingly argues that different reciprocal statements can have very different truth conditions. The challenge to be addressed is thus the following: How can we determine a (computational) semantics for the reciprocal expressions each other that accounts for these multiplicity of meanings while predicting the specific meaning of a particular reciprocal statement? Clearly knowledge based reasoning plays an important role: only those readings are possible that are consistent with our knowledge about the situation and the world. Specifically, knowledge based reasoning constrains the strength o</context>
<context position="5143" citStr="Dalrymple et al., 1998" startWordPosition="845" endWordPosition="848">ll is imposed by knowledge based constraints: the x gave y measles relation is asymmetric hence the W reading is ruled out; moreover, since one cannot be infected twice, some students in the group will be infected but not pass on the disease to anyone. Hence the strongest truth conditions that can be assigned the sentence are the V] disjunctive reading indicated in (4). But are there any other constraints on the interpretation process than these knowledge based constraints? And which meaning shall we assign a reciprocal expression? The computational semantics we will propose is inspired from (Dalrymple et al., 1998) and relies on the following observations. First, we note that (Dalrymple et al., 1998) identifies a lower bound for the truth conditions of reciprocal sentences which they dub Inclusive Alternative Ordering (IAO). It is exemplified by sentence (4) above and corresponds to the following definition of RCP. (5) RcPrAo APAR VI &gt; 2 A Vx (P(x) P(y) AxyA (R(x, y) V R(y, , x)))) This definition only adequately characterises examples such as (4). It does not cover the stronger meanings of the reciprocal in sentences such as (2) and (3). However, each known form of reciprocity entails RCP/AO&apos;s truth co</context>
<context position="21389" citStr="Dalrymple et al., 1998" startWordPosition="3608" endWordPosition="3611">eciprocal statement. Two elements are crucial to the account: the use of model building, and that of minimality as an implementation of preferences. Model building allows us to compute all the finite interpretations of a sentence that are consistent with contextual knowledge and with an IA0 interpretation of the reciprocal expression. Preferences on the other hand (i.e. the use of the cost predicate $R and the search for conservative mininal models), permits choosing among these interpretations the most likely one(s) namely, the interpretation(s) maximising the scope relation. 4 Related Work (Dalrymple et al., 1998) (henceforth DKKMP) proposes the following taxonomy of meanings for reciprocal statements (A stands for the antecedent set and R for the scope relation): Strong Reciprocity (SR) Vs, y E A(x y xRy). Intermediate reciprocity (IR) Vx, y E A 3.zi, 3,4„, E A(x xRzi A ... A zrnRY) One-way Weak Reciprocity ( OWR) Vx E A 3y E A (xRy) Intermediate Alternative Reciprocity (JAR) x, y E A3zi, 3z7, E A(x y (xRzi V zdix) A... A (zmRy V yRzni)) Inclusive Alternative Ordering (IAO) Vx E A 3y E A(xRy V yRx) To predict the meaning of a specific reciprocal sentence, DKKMP then postulate the Strongest Meaning Hyp</context>
</contexts>
<marker>Dalrymple, Kanasawa, Kim, Mchombo, Peters, 1998</marker>
<rawString>Mary Dalrymple, Makoto Kanasawa, Yookyung Kim, Sam Mchombo, and Stanley Peters. 1998. Reciprocal expressions and the concept of reciprocity. Linguistics and Philosophy, 21(2):159-210, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Karsten Konrad</author>
</authors>
<title>Definites and the proper treatment of rabbits.</title>
<date>1999</date>
<booktitle>In Proceedings of ICOS. Also</booktitle>
<tech>CLAUS Report 111, http://www.coli.uni-sb.de/claus/.</tech>
<contexts>
<context position="11928" citStr="Gardent and Konrad, 1999" startWordPosition="1995" endWordPosition="1998">ch as M2 can be eliminated simply by using more appropriate truth conditions for NL expressions (e.g. 3x cousin(x) A of (x, jon) A x jon A like(j on, x) for (7a)). In general however, eliminating models that are &amp;quot;too small&amp;quot; is a non-trivial task which involves the interaction of model-theoretic interpretation not only 321 with world knowledge reasoning but also with syntax, prosody and pragmatics. The issue is discussed at some length (though not solved) in (Gardent and Webber, January 2000). To eliminate models that are &amp;quot;too big&amp;quot;, some notion of minimality must be resorted to. For instance, (Gardent and Konrad, 1999; Gardent and Konrad, To appear) argues that local minimality is an adequate form of minimality for interpreting definite descriptions. Local minimality is defined as follows. Local Minimality: Let 4) be a set of firstorder formulas and D be the set of Herbrand models of 4) that use some finite domain D whose size is minimal. Then a model (I, D) E D is locally minimal if there is no other model (I&apos; , D&apos;) E D such that I&apos; C I. Locally minimal models are models that satisfy some input (I, within a minimal domain /31 of individuals and are subset-minimal with respect to all other domain minimal m</context>
</contexts>
<marker>Gardent, Konrad, 1999</marker>
<rawString>Claire Gardent and Karsten Konrad. 1999. Definites and the proper treatment of rabbits. In Proceedings of ICOS. Also CLAUS Report 111, http://www.coli.uni-sb.de/claus/.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Claire Gardent</author>
<author>Karsten Konrad</author>
</authors>
<title>To appear. Interpreting Definites using Model Generation.</title>
<journal>Journal of Language and Computation.</journal>
<marker>Gardent, Konrad, </marker>
<rawString>Claire Gardent and Karsten Konrad. To appear. Interpreting Definites using Model Generation. Journal of Language and Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Bonnie Webber</author>
</authors>
<title>Automated deduction and discourse disambiguation.</title>
<date>2000</date>
<note>Submitted for Publication. Also CLAUS Report 113, http: / /www.coli.uni-sb.de/claus/.</note>
<marker>Gardent, Webber, 2000</marker>
<rawString>Claire Gardent and Bonnie Webber. January 2000. Automated deduction and discourse disambiguation. Submitted for Publication. Also CLAUS Report 113, http: / /www.coli.uni-sb.de/claus/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P N Johnson-Laird</author>
<author>Ruth M J Byrne</author>
</authors>
<title>Deduction. Lawrence Erlbaum Associates Publishers.</title>
<date>1991</date>
<contexts>
<context position="9139" citStr="Johnson-Laird and Byrne, 1991" startWordPosition="1512" endWordPosition="1515">se and the relevant world knowledge 4) (i.e., a finite set of logical formulas), a model generator proves that 4. is satisfiable by generating some of its models. Intuitively, satisfying models explain how discourses can be made true. They give an abstract representation of how (part of) the world should be for a discourse to be true. Concretely, satisfying models can be seen as capturing the meaning of discourses: databases that can be queried e.g. as part of a query/answer system or to interpret subsequent discourse. Satisfying models are also remininiscent of Johnson-Laird&apos;s mental models (Johnson-Laird and Byrne, 1991) and in essence, mental models are very much like the Herbrand models we are making use of here. Formally, a model is a mathematical structure that describes how the symbols of a logical theory are interpreted. Given a first-order language .C, a model is a pair (I, D) with D a non-empty set of entities (the domain of individuals) and I an interpretation function which maps relation symbols in G to relations of appropriate arity in D and constant symbols in G to elements of D. Here we identify these models with sets of positive assumptions that unambiguously define the interpretation of the rel</context>
</contexts>
<marker>Johnson-Laird, Byrne, 1991</marker>
<rawString>P.N. Johnson-Laird and Ruth M.J. Byrne. 1991. Deduction. Lawrence Erlbaum Associates Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="7691" citStr="Kamp and Reyle, 1993" startWordPosition="1264" endWordPosition="1267">on and the world) are those which (a) are consistent both with the IA0 form of reciprocity and the information provided by r, and (b) whose contributions to the scope relation are the strongest. The MMH selects from the set of interpretations that are consistent with TAO and contextual knowledge, those that maximise the scope relation. Crucially, this view of reciprocals leads 320 to an inference method that can actually compute the preferred interpretations of reciprocal sentences. We now turn to this. 3 Interpretation as Model Generation In Discourse Representation Theory (DRT, (Kamp, 1981; Kamp and Reyle, 1993)), a sentence with semantic representation 4) is true with respect to a model M if there is an embedding of 4) onto M. Intuitively, this requirement says that a sub-model M&apos; of M must be found which satisfies (D. So for instance, sentence (6a) is true in M if there are two individuals bugs and bunny in M such that bugs and bunny stand in the love relation; or in other words, if the partial model sketched in (6b) is part of M. (6) a. Bugs likes Bunny. b. {love(bugs, bunny)} As shown in (Gardent and Konrad, To appear), model generators (i.e., programs that compute some of the models satisfying a</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From Discourse to Logic. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
</authors>
<title>A theory of truth and semantic representation.</title>
<date>1981</date>
<booktitle>Formal Methods in the Study of Language,</booktitle>
<pages>277--322</pages>
<editor>In J. Groenendijk, Th. Janssen, and M. Stokhof, editors,</editor>
<location>Amsterdam.</location>
<contexts>
<context position="7668" citStr="Kamp, 1981" startWordPosition="1262" endWordPosition="1263">urse situation and the world) are those which (a) are consistent both with the IA0 form of reciprocity and the information provided by r, and (b) whose contributions to the scope relation are the strongest. The MMH selects from the set of interpretations that are consistent with TAO and contextual knowledge, those that maximise the scope relation. Crucially, this view of reciprocals leads 320 to an inference method that can actually compute the preferred interpretations of reciprocal sentences. We now turn to this. 3 Interpretation as Model Generation In Discourse Representation Theory (DRT, (Kamp, 1981; Kamp and Reyle, 1993)), a sentence with semantic representation 4) is true with respect to a model M if there is an embedding of 4) onto M. Intuitively, this requirement says that a sub-model M&apos; of M must be found which satisfies (D. So for instance, sentence (6a) is true in M if there are two individuals bugs and bunny in M such that bugs and bunny stand in the love relation; or in other words, if the partial model sketched in (6b) is part of M. (6) a. Bugs likes Bunny. b. {love(bugs, bunny)} As shown in (Gardent and Konrad, To appear), model generators (i.e., programs that compute some of </context>
</contexts>
<marker>Kamp, 1981</marker>
<rawString>Hans Kamp. 1981. A theory of truth and semantic representation. In J. Groenendijk, Th. Janssen, and M. Stokhof, editors, Formal Methods in the Study of Language, pages 277 - 322. Mathematisch Centrum Tracts, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karsten Konrad</author>
<author>D A Wolfram</author>
</authors>
<title>Kimba, a model generator for many-valued first-order logics.</title>
<date>1999</date>
<booktitle>In Proc., 16th International Conference on Automated Deduction, CADE 99, LNCS, forthcoming,</booktitle>
<publisher>Springer.</publisher>
<location>Trento, Italy.</location>
<contexts>
<context position="16567" citStr="Konrad and Wolfram, 1999" startWordPosition="2814" endWordPosition="2817">minimisation that correctly identifies the preferred interpretation of reciprocal sentences. For instance since (12c) carries a minimal cost, it is a conservative minimal model for (12a) whereas (12b) isn&apos;t. Intuitively the approach works as follows: the more pairs there are that do not stand in the scope relation of the reciprocal, the bigger the $R predicate and the more costly (i.e. the least preferred) the model. That is, the combined use of a $R-predicate and of conservative minimality allows us to enforce a preference for interpretations (i.e. models) maximising R. 3.3 The System KIMBA (Konrad and Wolfram, 1999) is a finite model generator for first-order and higher-order logical theories that is based on a translation of logics into constraint problems over finitedomain integer variables. KIMBA uses an efficient constraint solver to produce solutions that can be translated back into Herbrand models of the input. We have tailored KIMBA such that it enumerates the conservative models of its input. Intuitively, this works as follows. First, KIMBA searches for some arbitrary model of the input that mentions a minimum number of individuals. Then, it takes the $R-cost of this model as an upper bound for t</context>
</contexts>
<marker>Konrad, Wolfram, 1999</marker>
<rawString>Karsten Konrad and D. A. Wolfram. 1999. Kimba, a model generator for many-valued first-order logics. In Proc., 16th International Conference on Automated Deduction, CADE 99, LNCS, forthcoming, Trento, Italy. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Terence Langendoen</author>
</authors>
<title>The logic of reciprocity.</title>
<date>1978</date>
<journal>Linguistic Inquiry,</journal>
<pages>9--2</pages>
<contexts>
<context position="3258" citStr="Langendoen, 1978" startWordPosition="541" endWordPosition="542">re at each other in surprise. Vx (std(x) 3y (x y A std(y) A stare_at(x , y)) (4) The students gave each other measles. Vx (std(x) -4 3y (x y A std(y) A (gave_measles(x, y) V gave_measle(y, x)))) We can accept (2) to be true only if for each pair x and y of two students it holds that x likes y. But an analogous interpretation would be invalid in the case of (3) and (4) where not all pairs in the antecedent set the students can consistently stand in the scope relation (one can only stare at most at one person at a time, and 319 one can only get measles from at most one person). More generally, (Langendoen, 1978; Dalrymple et al., 1998) convincingly argues that different reciprocal statements can have very different truth conditions. The challenge to be addressed is thus the following: How can we determine a (computational) semantics for the reciprocal expressions each other that accounts for these multiplicity of meanings while predicting the specific meaning of a particular reciprocal statement? Clearly knowledge based reasoning plays an important role: only those readings are possible that are consistent with our knowledge about the situation and the world. Specifically, knowledge based reasoning </context>
</contexts>
<marker>Langendoen, 1978</marker>
<rawString>D. Terence Langendoen. 1978. The logic of reciprocity. Linguistic Inquiry, 9(2):177-197.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>