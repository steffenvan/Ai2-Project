<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.966145">
Modelling Grounding and Discourse Obligations Using Update
Rules
</title>
<author confidence="0.998461">
Colin Matheson
</author>
<affiliation confidence="0.782357">
University of Edinburgh
Edinburgh, Scotland
colin.mathesonOed.ac.uk
</affiliation>
<author confidence="0.986197">
Massimo Poesio
</author>
<affiliation confidence="0.9351785">
University of Edinburgh
Edinburgh, Scotland
</affiliation>
<email confidence="0.581498">
massimo.poesio©ed.ac.uk
</email>
<author confidence="0.99223">
David Traum
</author>
<affiliation confidence="0.7950325">
University of Maryland
Maryland, USA
</affiliation>
<email confidence="0.852859">
traurn©cs.umd.edu
</email>
<sectionHeader confidence="0.995769" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998027">
This paper describes an implementation of some key
aspects of a theory of dialogue processing whose
main concerns are to provide models of GROUND-
ING and of the role of DISCOURSE OBLIGATIONS in
an agent&apos;s deliberation processes. Our system uses
the TrindiKit dialogue move engine toolkit, which
assumes a model of dialogue in which a participan-
t&apos;s knowledge is characterised in terms of INFORMA-
TION STATES which are subject to various kinds of
updating mechanisms.
</bodyText>
<sectionHeader confidence="0.999396" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99988180952381">
In this paper we describe a preliminary implemen-
tation of a &apos;middle-level&apos; dialogue management sys-
tem. The key tasks of a dialogue manager are to
update the representation of dialogue on the basis of
processed input (generally, but not exclusively, lan-
guage utterances), and to decide what (if anything)
the system should do next. There is a wide range of
opinions concerning how these tasks should be per-
formed, and in particular, how the ongoing dialogue
state should be represented: e.g., as something very
specific to a particular domain, or according to some
more general theory of (human or human inspired)
dialogue processing. At one extreme, some systems
represent only the (typically very rigid) transitions
possible in a perceived dialogue for the given task,
often using finite states in a transition network to
represent the dialogue: examples of this are sys-
tems built using Nuance&apos;s DialogueBuilder or the
CSLU&apos;s Rapid Application Prototyper. The other
extreme is to build the dialogue processing theory on
top of a full model of rational agency (e.g., (Bretier
and Sadek, 1996)). The approach we take here lies
in between these two extremes: we use rich repre-
sentations of information states, but simpler, more
dialogue-specific deliberation methods, rather than
a deductive reasoner working on the basis of an ax-
iomatic theory of rational agency. We show in this
paper that the theory of information states we pro-
pose can, nevertheless, be used to give a character-
isation of dialogue acts such as those proposed by
the Discourse Resource Initiative precise enough to
formalise the deliberation process of a dialogue man-
ager in a completely declarative fashion.
Our implementation is based on the approach to
dialogue developed in (Traum, 1994; Poesio and
Traum, 1997; Poesio and Traum, 1998; Traum et al.,
1999). This theory, like other action-based theories
of dialogue, views dialogue participation in terms of
agents performing dialogue acts, the effects of which
are to update the information state of the partici-
pants in a dialogue. However, our view of dialogue
act effects is closer in some respects to that of (All-
wood, 1976; Allwood, 1994) and (Singh, 1998) than
to the belief and intention model of (Sadek, 1991;
Grosz and Sidner, 1990; Cohen and Levesque, 1990).
Particular emphasis is placed on the social commit-
ments of the dialogue participants (obligations to
act and commitments to propositions) without mak-
ing explicit claims about the actual beliefs and in-
tentions of the participants. Also, heavy empha-
sis is placed on how dialogue participants socially
GROUND (Clark and Wilkes-Gibbs, 1986) the infor-
mation expressed in dialogue: the information state
assumed in this theory specifies which information is
assumed to be already part of the common ground at
a given point, and which part has been introduced,
but not yet been established.
The rest of this paper is structured as follows. The
theory of dialogue underlying the implementation is
described in more detail in Section 2. Section 3 de-
scribes the implementation itself. Section 4 shows
how the system updates its information state while
participating in a fairly simple dialogue.
</bodyText>
<sectionHeader confidence="0.992719" genericHeader="method">
2 Theoretical Background
</sectionHeader>
<bodyText confidence="0.961058425925926">
One basic assumption underlying this work is that
it is useful to analyse dialogues by describing the
relevant &apos;information&apos; that is available to each par-
ticipant. The notion of INFORMATION STATE (IS) is
therefore employed in deciding what the next action
should be, and the effects of utterances are described
in terms of the changes they bring about in ISs. A
particular instantiation of a dialogue manager, from
this point of view, consists of a definition of the con-
tents of ISs plus a description of the update processes
which map from IS to IS. Updates are typically trig-
gered by &apos;full&apos; dialogue acts such as assertions or
directives,&apos; of course, but the theory allows parts of
utterances, including individual words and even sub-
parts of words, to be the trigger. The update rules
for dialogue acts that we assume here are a simpli-
fied version of the formalisations proposed in (Poesio
and Traum, 1998; Traum et al., 1999) (henceforth,
PTT).
The main aspects of PTT which have been im-
plemented concern the way discourse obligations are
handled and the manner in which dialogue partic-
ipants interact to add information to the common
ground. Obligations are essentially social in nature,
and directly characterise spoken dialogue; a typical
example of a discourse obligation concerns the rela-
tionship between questions and answers. Poesio and
Traum follow (Traum and Allen, 1994) in suggesting
that the utterance of a question imposes an obliga-
tion on the hearer to address the question (e.g., by
providing an answer), irrespective of intentions.
As for the process by which common ground is es-
tablished, or GROUNDING (Clark and Schaefer, 1989;
Traum, 1994), the assumption in PTT is that classi-
cal speech act theory is inherently too simplistic in
that it ignores the fact that co-operative interaction
is essential in discourse; thus, for instance, simply as-
serting something does not make it become mutually
&apos;known&apos; (part of the common ground). It is actually
necessary for the hearer to provide some kind of ac-
knowledgement that the assertion has been received,
understood or not understood, accepted or rejected,
and so on. Poesio and Traum view the public in-
formation state as including both material that has
already been grounded, indicated by CND here, and
material that hasn&apos;t been grounded yet. These com-
ponents of the information state are updated when
GROUNDING ACTS such as acknowledgement are per-
formed. Each new contribution results in a new DIS-
COURSE UNIT (DU) being added to the information
state (Traum, 1994) and recorded in a list of &apos;un-
grounded discourse units&apos; (UDUS); these DUs can
then be subsequently grounded as the result, e.g., of
(implicit or explicit) acknowledgements.
</bodyText>
<sectionHeader confidence="0.987919" genericHeader="method">
3 Implementing PTT
</sectionHeader>
<bodyText confidence="0.950740777777778">
In this section, we describe the details of the im-
plementation. First, in Section 3.1, we describe the
TrindiKit tool for building dialogue managers that
we used to build our system. In Section 3.2, we de-
scribe the information states used in the implemen-
tation, an extension and simplification of the ideas
from PTT discussed in the previous section. Then,
in Section 3.3, we discuss how the information state
is updated when dialogue acts are observed. Finally,
</bodyText>
<footnote confidence="0.863182">
&apos;We assume here the DRI classification of dialogue acts
(Discourse Resource Initiative, 1997).
</footnote>
<figureCaption confidence="0.999729">
Figure 1: TrindiKit Architecture
</figureCaption>
<bodyText confidence="0.9973974">
in Section 3.4, we describe the rules used by the sys-
tem to adopt intentions and perform its own actions.
An extended example of how these mechanisms are
used to track and participate in a dialogue is pre-
sented in Section 4.
</bodyText>
<subsectionHeader confidence="0.997436">
3.1 TrindiKit
</subsectionHeader>
<bodyText confidence="0.993896">
The basis for our implementation is the TrindiKit
dialogue move engine toolkit implemented as part
of the TRINDI project (Larsson et al., 1999). The
toolkit provides support for developing dialogue sys-
tems, focusing on the central dialogue management
components.
The system architecture assumed by the TrindiKit
is shown in Figure 1. A prominent feature of this ar-
chitecture is the information state, which serves as a
central &apos;blackboard&apos; that processing modules can ex-
amine (by means of defined CONDITIONS) or change
(by means of defined OPERATIONS). The structure
of the IS for a particular dialogue system is defined
by the developer who uses the TrindiKit to build
that system, on the basis of his/her own theory of
dialogue processing; no predefined notion of infor-
mation state is provided.2. The toolkit provides a
number of abstract data-types such as lists, stacks,
and records, along with associated conditions and
operations, that can be used to implement the user&apos;s
theory of information states; other abstract types
can also be defined. In addition to this customis-
able notion of information state, TrindiKit provides
a few system variables that can also used for inter-
module communication. These include input for the
raw observed (language) input, latest_moves which
</bodyText>
<footnote confidence="0.857939333333333">
2In TRINDI we are experimenting with multiple instanti-
ations of three different theories of information state (Traum
et al., 1999).
</footnote>
<page confidence="0.995061">
2
</page>
<bodyText confidence="0.999984454545455">
contains the dialogue moves observed in the most
recent turn, 1st est _speaker, and next _moves, con-
taining the dialogue moves to be performed by the
system in the next turn.
A complete system is assumed to consist of sev-
eral modules interacting via the IS. (See Figure 1
again.) The central component is called the DIA-
LOGUE MOVE ENGINE (DME). The DME performs
the processing needed to integrate the observed di-
alogue moves with the IS, and to select new moves
for the system to perform. These two functions are
encapsulated in the UPDATE and SELECTION sub-
modules of the DME. The update and select mod-
ules are specified by means of typed rules, as well as
sequencing procedures to determine when to apply
the rules. We are here mainly concerned with UP-
DATE RULES (urules), which consist of four parts: a
name, a type, a list of conditions to check in the in-
formation state, and a list of operations to perform
on the information state. urules are described in
more detail below, in Section 3.3. There are also
two modules outside the DME proper, but still cru-
cial to a complete system: INTERPRETATION, which
consumes the input and produces a list of dialogue
acts in the latest_moves variable (potentially mak-
ing reference to the current information state), and
GENERATION, which produces NL output from the
dialogue acts in the next_moves variable. Finally,
there is a CONTROL module, that governs the se-
quencing (or parallel invocation) of the other mod-
ules. In this paper we focus on the IS and the DME;
our current implementation only uses very simple
interpretation and generation components.
</bodyText>
<subsectionHeader confidence="0.999578">
3.2 Information States in PTT
</subsectionHeader>
<bodyText confidence="0.933941">
In this section we discuss the information state used
in the current implementation. The main difference
between the implemented IS and the theoretical pro-
posal in (Poesio and Traum, 1998) is that in the im-
plementation the information state is partitioned in
fields, each containing information of different types,
whereas in the theoretical version the information
state is a single repository of facts (a DISCOURSE
REPRESENTATION STRUCTURE). Other differences
are discussed below. An example IS with some fields
filled is shown in Figure 2; this is the IS which results
from the second utterance in the example dialogue
discussed in Section 4, A route please.3
The IS in Figure 2 is a record with two main
parts, W and C. The first of these represents the
system&apos;s (Wizard) view of his own mental state and
of the (semi-)public information discussed in the di-
alogue; the second, his view of the user&apos;s (Caller)
information state. This second part is needed to
3A11 diagrams in this paper are automatically generated
from TrindiKit system internal representations and displayed
using the Thistle dialogue editor (Calder, 1998). Some have
been subsequently edited for brevity and clarity.
</bodyText>
<equation confidence="0.8974104">
(
understandingAct( W,0U3 )
address(C,CA2 )
(
CA3: C2, acknowledge( C.DU2 ) )
CA2: C2, info_request( W,?helpform
&lt; &gt;
&lt;address( C,CA2 ) &gt;
&lt;CA2: C2, info_request( W,?helpform )
&lt; &gt;
</equation>
<figure confidence="0.595610666666667">
W:
TOGND:
INT:
</figure>
<figureCaption confidence="0.999672">
Figure 2: Structure of Information States
</figureCaption>
<bodyText confidence="0.99996540625">
model misunderstandings arising from the dialogue
participants having differing views on what has been
grounded; as we are not concerned with this problem
here, we will ignore C in what follows.
w contains information on the grounded mate-
rial (GND), on the ungrounded information (uDDS,
PDU and CDU), and on W&apos;s intentions (INT). GND
contains the information that has already been
grounded; the other fields contain information about
the contributions still to be grounded. As noticed
above, in PTT it is assumed that for each new ut-
terance, a new DU is created and added to the IS.
The current implementation differs from the full the-
ory in that only two DUs are retained at each point;
the current DU (GDu) and the previous DU (PDD).
The CDU contains the information in the latest con-
tribution, while the PDU contains information from
the penultimate contribution. Information is moved
from PDU to GND as a result of an ack (acknowl-
edgement) dialogue act (see below.)
The DUs and the GND field contain four fields,
representing obligations (OBL), the dialogue history
(DH), propositions to which agents are socially com-
mitted (SCP) , and conditional updates (GoND). The
value of OBL is a list of action types: actions that
agents are obliged to perform. An action type is
specified by a PREDICATE, a DIALOGUE PARTICI-
PANT, and a list of ARGUMENTS. The value of SCP
is a list of a particular type of mental states, so-
cial commitments of agents to propositions.4 These
are specified by a DIALOGUE PARTICIPANT, and a
PROPOSITION. Finally, the elements in DH are dia-
</bodyText>
<footnote confidence="0.850122">
4SCPs play much the same role in PTT as do beliefs in
many BDI accounts of speech acts.
</footnote>
<figure confidence="0.9817826">
GND: OBL:
OH:
SCP:
COND: &lt;&gt;
UDUS: &lt;DU3 &gt;
OBL:
DH:
PDU: TOON D: {
SCP:
COND: &lt; &gt;
ID DU2
OBL: &lt;address( W,CA6 )&gt;
DH: CAS: C2, answer( C,CA2,CA4 )
(CAS: C2, direct ( Cgiveroute(W) ) )
CA4: C2, assert( C,want(C,route) )
SCP: &lt;scp(C,want(C.route ) ) &gt;
COND: &lt;accept( W,CA6 ) -&gt; obi( Wgiveroute(W) ) &gt;..,
ID: DU3
(
info_request(W,?start 1
glveroute(W )
accept( Vi.CA6 )
acknowledge( W,DU3 )
C: (INT: &lt;getroute(C )&gt; I
CDU:
</figure>
<page confidence="0.983546">
3
</page>
<bodyText confidence="0.999355367346939">
logue actions, which are instances of dialogue action
types. A dialogue action is specified by an action
type, a dialogue act id, and a confidence level CONF
(the confidence that an agent has that that dialogue
act has been observed).
The situation in Figure 2 is the result of updates to
the IS caused by utterance [2] in the dialogue in (6),
which is assumed to generate a direct act as well as
an assert act and an answer act.5 That utterance
is also assumed to contain an implicit acknowledge-
ment of the original question; this understanding act
has resulted in the contents of DU2 being grounded
(and subsequently merged with GND), as discussed
below.
GND.OBL in Figure 2 includes two obligations.
The first is an obligation on W to perform an under-
standing act (the predicate is understandingAct,
the participant is W, and there is just one argument,
DU3, which identifies the DU in CDU by referring to
its ID). The second obligation is an obligation on C
to address conversational act CA2; this ID points
to the appropriate info_request in the DH list by
means of the ID number. Obligations are specified
in CDU and PDU, as well. Those in PDU are simply
a subset of those in OND, since at point in the up-
date process shown in Figure 2 this field contains
information that has already been grounded (note
that DU2 is not in UDUS anymore); but CDU con-
tains obligations that have not been grounded yet —
in particular, the obligation on W to address CA6.
GND.DH in this IS contains a list of dialogue ac-
tions whose occurrence has already been grounded:
the info_request performed by utterance 1, with ar-
gument a question,6 and the implicit acknowledge
performed by utterance 2.7 The DH field in CDU con-
tains dialogue acts performed by utterance 2 that do
need to be grounded: a directive by C to W to per-
form an action of type giveroute, and an assert
by C of the proposition want(C, route), by which C
provides an answer to the previous info .request
CA2.
The COND field in CDU contains a conditional up-
date resulting from the directive performed by that
utterance. The idea is that directives do not imme-
diately lead to obligations to perform the mentioned
action: instead (in addition to an obligation to ad-
dress the action with some sort of response), their ef-
fect is to add to the common ground the information
that if the directive is accepted by the addressee,
</bodyText>
<footnote confidence="0.995895111111111">
6The fact that the utterance of a route please constitutes
an answer is explicitly assumed; however, it should be possible
to derive this information automatically (perhaps along the
lines suggested by Kreutel (Kreutel, 1998)).
6We use the notation ?p to indicate a question of the form
?([4P(x)) •
7We assume here, as in (Traum, 1994) and (Poesio and
Traum, 1998), that understanding acts do not have to be
grounded themselves, which would result in a infinite regress.
</footnote>
<bodyText confidence="0.997469">
then he or she has the obligation to perform the ac-
tion type requested. (In this case, to give a route to
C.)
</bodyText>
<subsectionHeader confidence="0.999672">
3.3 Update Rules in PTT
</subsectionHeader>
<bodyText confidence="0.999914">
We are now in a position to examine the update
mechanisms which are performed when new dia-
logue acts are recognised. When a dialogue par-
ticipant takes a turn and produces an utterance,
the interpretation module sets the system variable
latest_moves to contain a representation of the di-
alogue acts performed with the utterance. The up-
dating procedure then uses update rules to modify
the IS on the basis of the contents of latestmoves
and of the previous IS. The basic procedure is de-
scribed in (1) below.8
</bodyText>
<listItem confidence="0.975306222222222">
(1) 1. Create a new DU and push it on top of
UDUs.
2. Perform updates on the basis of backwards
grounding acts.
3. If any other type of act is observed, record
it in the dialogue history in CDU and apply
the update rules for this kind of act
4. Apply update rules to all parts of the IS
which contain newly added acts.
</listItem>
<bodyText confidence="0.998613333333333">
The first step involves moving the contents of CDU
to PDU (losing direct access to the former PDU con-
tents) and putting in CDU a new empty DU with
a new identifier. The second and third steps deal
explicitly with the contents of latest_moves, ap-
plying one urule (of possibly a larger set) for each
act in latest moves. The relevant effects for each
act are summarised in (2), where the variables have
the following types:
</bodyText>
<table confidence="0.983575">
IDx Dialogue Act Identification Number
DUx DU Identification Number
DP Dialogue Participant (i.e., the speaker)
A Question
PROP A Proposition
Act An Action
o(DP) The other dialogue participant
P (ID) The content of the ID, a proposition
Q (ID) The content of the ID, a question
</table>
<footnote confidence="0.481722666666667">
8See (Poesio et al., 1999; Traum et al., 1999) for different
versions of this update procedure used for slightly different
versions of the theory.
</footnote>
<page confidence="0.864136">
4
</page>
<table confidence="0.998864615384615">
act ID:2, accept(DP,ID2)
effect accomplished via rule resolution
act ID:2, ack(DP,DU1)
effect peRec(w.Gnd,w.pdu.tognd)
effect remove(DU1,UDUS)
act ID:2, agree(DP,ID2)
effect push(scP,scp(DP,P(ID2)))
act ID:2, answer(DP,ID2,ID3)
effect push(scP,ans(DP,Q(ID2),P(ID2)))
act ID:2, assert(DP,PROP)
effect push(scP,scp(DP,PROP))
effect push(coND,accept(o(DP),ID)-+
scp(o(DP),PROP))
act ID:1, assert(DP,PROP)
effect push(coND,accept(o(DP),ID)-+
scp(o(DP),PROP))
act ID:2, check(DP,PROP)
effect push(ost,address(o(DP),ID))
effect push(coND,agree(o(DP),ID) -+
scp(DP,PROP))
act ID:2, direct(DP,Act)
effect push(osL,address(o(DP),ID))
effect push(coND,accept(o(DP),ID) -4
obl(o(DP),Act))
act ID:2, info_request(DP,Q)
effect push(orm,address(o(DP),ID))
</table>
<bodyText confidence="0.999928102564103">
The ack act is the only backward grounding act
implemented at the moment. The main effect of an
ack is to merge the information in the acknowledged
DU (assumed to be Pm) into GND, also removing
this DU from UDUS. Unlike the other acts described
below, ack acts are recorded directly into GND.DH,
rather than into CDU.TOGND.DH.
All of the other updates are performed in the third
step of the procedure in (1). The only effect of ac-
cept acts is to enable the conditional rules which
are part of the effect of assert and direct, leading
to social commitments and obligations, respectively.
agree acts also trigger conditional rules introduced
by check; in addition, they result in the agent be-
ing socially committed to the proposition introduced
by the act with which the agent agrees. Perform-
ing an answer to question ID2 by asserting propo-
sition P(ID3) commits the dialogue participant to
the proposition that P(1D3) is indeed an answer to
Q (ID2).
The two rules for assert are where the confidence
levels are actually used, to implement a simple ver-
ification strategy. The idea is that the system only
assumes that the user is committed to the asserted
proposition when a confidence level of 2 is observed,
while some asserts are assumed not to have been
sufficiently well understood, and are only assigned a
confidence level 1. This leads the system to perform
a check, as we will see shortly.
The next three update rules, for check, direct,
and info_req, all impose an obligation on the other
dialogue participant to address the dialogue act. In
addition, the direct rule introduces a conditional
act: acceptance of the directive will impose an obli-
gation on the hearer to act on its contents.
In addition, all FORWARD ACTS9 in the DRI
scheme (Discourse Resource Initiative, 1997) impose
an obligation to perform an understanding act (e.g.,
an acknowledgement):
</bodyText>
<equation confidence="0.374739">
act ID:c, forward-looking-act(DP)
effect push(on,u-act(o(DP),CDU.id))
</equation>
<bodyText confidence="0.691274">
The internal urules implementing the updates in
(2) have the format shown in (4), which is the urule
for info_request.
</bodyText>
<figure confidence="0.973135470588235">
(4) urule( doInfoReq, ruletype3,
hearer(U),
latent_moves: in(Move),
Move:valRec(pred,inforeq) ],
incr_set(update_cycles,_),
incr_set(next_dh_id,RID),
next_du_name(ID),
pushRec(w-cdetognd-dh,
record([atypevMove,clevel=2,idvIIID ])),
pushRec(v-cdetogneobl,
recordapredvaddrees,dpvDP,
argsvstackset(
Erecord((itenmRID))])])),
pushRec(v-gnd&amp;quot;obl,
recordapredmuact,dp=P,
argsvstackset(
[record((item=ID])])])) ]).
</figure>
<bodyText confidence="0.999989954545455">
As noted above, these rules have four parts; a
name, a type, a list of conditions, and a list of ef-
fects. The conditions in (4) state that there must be
a move in latest _moves whose predicate is inf oreq.
The effects&amp;quot;) state that the move should be recorded
in the dialogue history in CDU, that an obligation to
address the request should be pushed into OBL in
CDU, and that the requirement for an understand-
ing act by W should be pushed directly into the list
in W.GND.
The fourth and final step of the algorithm cycles
through the updating process in case recently added
facts have further implications. For instance, when
an action has been performed that matches the an-
tecedent of a rule in COND, the consequent is es-
tablished. Likewise, when an action is performed
it releases any obligations to perform that action.
Thus, accept, answer, and agree are all ways of
releasing an obligation to address, since these are
all appropriate backward looking actions. Similarly,
an agent will drop intentions to perform actions it
has already (successfully) performed.
</bodyText>
<subsectionHeader confidence="0.942275">
3.4 Deliberation
</subsectionHeader>
<bodyText confidence="0.996735">
We assume, in common with BDI-approaches to
agency (e.g., (Bratman et al., 1988)) that intentions
</bodyText>
<footnote confidence="0.97166375">
9Forward acts include assert, check, direct, and
info_request.
19The ID and HID values simply contain numbers identifying
the discourse units and conversational acts.
</footnote>
<figure confidence="0.343162">
(2)
</figure>
<page confidence="0.970624">
5
</page>
<bodyText confidence="0.998847">
are the primary mental attitude leading to an agen-
t&apos;s actions. The main issues to explain then become
how such intentions are adopted given the rest of
the information state, and how an agent gets from
intentions to actual performance.
For the latter question, we take a fairly simplistic
approach here: all the intentions to perform dia-
logue acts are simply transferred to the next_moves
system variable, with the assumption that the gen-
eration module can realise all of them as a single ut-
terance. A more sophisticated approach would be to
weight the importance of (immediate) realisation of
sets of intentions and compare this to the likelihood
that particular utterances will achieve these effects
at minimal cost, and choose accordingly. We leave
this for future work (see (Traum and Dillenbourg,
1998) for some preliminary ideas along these lines),
concentrating here on the first issue — how the sys-
tem adopts intentions to perform dialogue acts from
other aspects of the mental state.
The current system takes the following factors into
account:
</bodyText>
<listItem confidence="0.999074222222222">
• obligations (to perform understanding acts, to
address previous dialogue acts, to perform other
actions)
• potential obligations (that would result if an-
other act were performed, as represented in the
COND field)
• insufficiently understood dialogue acts (with a
1 confidence level in CDU.DH)
• intentions to perform complex acts
</listItem>
<bodyText confidence="0.997414785714286">
The current deliberation process assumes maxi-
mal cooperativity, in that the system always chooses
to meet its obligations whenever possible, and also
chooses to provide a maximally helpful response
when possible. Thus, when obliged to address a
previous dialogue act such as a question or direc-
tive, it will choose to actually return the answer or
perform the action, if possible, rather than reject or
negotiate such a performance, which would also be
acting in accordance with the obligations (see (Kreu-
tel, 1998) on how acts might be rejected).
In the current implementation, the following rules
are used to adopt new intentions (i.e., to update the
INT field):
</bodyText>
<listItem confidence="0.9379845">
(5) I. add an intention to acknowl-
edge(W,CDU), given an obligation to
perform a u-act, if everything in CDU is
sufficiently understood (i.e., to level 2);
2. add an intention to accept a directive or an-
swer a question as the result of an obligation
to address a dialogue act;
3. add an intention to perform an action if
COND contains a conditional that will estab-
lish an obligation to perform the action, and
</listItem>
<bodyText confidence="0.995951363636364">
the antecedent of this conditional is another
action that is already intended. (This an-
ticipatory planning allows the obligation to
be discharged at the same time it is invoked,
e.g., without giving an intermediate accep-
tance of an directive.)
4. add an intention to perform a (dialogue) ac-
tion motivated by the intention to perform
the current task. In the case of the Au-
toroute domain, we have two cases: the sys-
tem may decide
</bodyText>
<listItem confidence="0.8369163">
(a) to check any dialogue acts in CDU at
confidence level 1, which contain infor-
mation needed to discharge the intention
to give a route; or
(b) to perform a question asking about a new
piece of information that has not been es-
tablished (this is decided by inspecting
GND.SCP and CDU .SCP). For example,
it may decide to ask about the starting
point, the time of departure, etc.
</listItem>
<sectionHeader confidence="0.918146" genericHeader="method">
4 Extended Example
</sectionHeader>
<bodyText confidence="0.9977237">
In this section, we discuss more examples of how the
information state changes as a result of processing
and performing dialogue acts. It is useful to do this
by looking briefly at a typical Autoroute dialogue,
shown in (6).h1 Our implementation can process this
sort of dialogue using very simple interpretation and
generation routines that provide the dialogue acts
in latestmoves from the text strings, and produce
W&apos;s output text from the dialogue acts which the
system places in next_moves.
</bodyText>
<table confidence="0.933845421052632">
How can I help?
A route please
Where would you like to start?
Malvern
Great Malvern?
Yes
Where do you want to go?
Edwinstowe
Edwinstowe in Nottingham?
Yes
When do you want to leave?
Six pm
Leaving at 6 p.m.?
Yes
Do you want the quickest or the
shortest route?
Quickest
Please wait while your route is cal-
culated.
</table>
<bodyText confidence="0.78395375">
We assume that before the dialogue starts, W has
the intention to ask C what kind of help is required,
11The interchanges have been cleaned up to some extent
here, mainly by removing pauses and hesitations.
</bodyText>
<figure confidence="0.697548">
(6)
C)C)C)C)C)C)
</figure>
<page confidence="0.977254">
6
</page>
<table confidence="0.962166266666667">
( giveroute( W
OBL: understandingAct( W,DU5
address( C,CA8
( E
CA 10: C2, acknowledge( C,DU4
CA9: C2, accept( WA6 )
CAR: C2, info_request( W?stan
SCP: &lt;&gt;
COND: &lt; &gt;
UDUS: &lt;DU5 &gt;
OBL: &lt;address( C.CA8 )&gt;
DH: (CM: C2, accept( W,CA6 )
TOGND:
CA8: C2, info_request( W,?start ))
SCP: &lt;&gt;
</table>
<figure confidence="0.946011468085106">
COND: &lt; &gt;
ID: DU4
OBL:
DH:
SCP:
&lt;&gt;
(
CA12: C2, answer( C,CA8,CA I I ) )
CA I 1; CI, assert( C.starnmalvern) )
C&gt;
GND:
DI-1,
PDU;
CDU:
TOGND:
COND: &lt;&gt;
ID: DU5
(check( W.slarnmalvern ))
INT: (acknowledge( W.DU5 )
giveroute( W )
C: f INT: &lt;getroute(C ) &gt;
OBL:
(understandingAct(C,DU6
giveroute( W
/CAI 3: C2, acknowledge( WOW)
GND OH: CA12: C2, answer( C,CA8 )
CA I I: CI, assert( Cstart(malvern) )
SCR &lt;&gt;
COND: &lt;&gt;
UDUS: &lt;DU6 &gt;
OBL: &lt;&gt;
TOGND: Dli: (CA12: C2, answer( C.CA8.CA I I) )
CA11: CI, assert( C.start(malvem) )
SCP: &lt;&gt;
COND: &lt; &gt;
ID: DU5
{ OBL: &lt;address( C,CA14 )&gt;
DH: &lt;CA14: C2, check( W,starUmalvern) 1&gt;
TOGND:
INT:
C [INT: &lt;getroute(C )&gt; I
W:
PDU:
CDU:
SCP: &lt;&gt;
COND &lt;agree( C,CA 14 ) -&gt; scp( Wstart(malvem) )
ID: &lt;giveroute(DWU6)&gt;
</figure>
<figureCaption confidence="0.999842">
Figure 4: Information State Following Check in [5]
Figure 3: Information State Prompting Check in [5]
</figureCaption>
<bodyText confidence="0.999932862068966">
and that C has the intention to find a route. We also
assume that W has the turn, and that the presence
of the how can I help intention triggers an utterance
directly. Figure 2, presented above, shows the in-
formation state after utterance [2]. The intentions
in that figure lead directly to the system producing
utterance [3].
Looking a little further ahead in the dialogue, Fig-
ure 3 shows the information state after utterance
[4].12 Here we can see in CD U . TOGND . DH (along with
the ack act CA10, in GND.DH) the dialogue moves
that this utterance has generated. Note that the as-
sert, CA11, is only at confidence level 1, indicating
lack of sufficient certainty in this interpretation as
the town &apos;Great Malvern&apos;. This lack of certainty and
the resulting lack of a relevant SCP in CDU.TOGND
lead the deliberation routines to produce an inten-
tion to check this proposition rather than to move
directly on to another information request. This
intention leads to utterance [5], which, after inter-
pretation and updating on the new dialogue acts,
leads to the information state in Figure 4. The in-
teresting thing here is the condition which appears
in CDU.TOGND.COND as a result of the check; the
interpretation of this is that, if C agrees with the
check, then W will be committed to the proposition
that the starting place is Malvern (C would also be
committed to this by way of the direct effects of an
agree act).
</bodyText>
<footnote confidence="0.675144">
12The actual information state contains all the previously
established dialogue acts, SCPs and Obligations in CND, from
Figure 2 and intermediate utterances. Here we have deleted
these aspects from the figures for brevity and clarity.
</footnote>
<table confidence="0.997177578947369">
OND: OBL: understandingAct(C,DU8 )&gt;
UDUS ( giveroute(W )
PDU: DH: CA17: C2, adcnowledge( W,DU7
( CA16: C2, agree( C,CA 14 )
SCP: scP(C.start( malvem ) ) )
( scp( W,start( malvem ))
COND: &lt;&gt; OBL: &lt;&gt;
&lt;DU8 &gt; DH: &lt;CA16: C2. agree(C,CA 14
TOGND: SCP: &lt;scp(C.start( malvem ))&gt;
COND: &lt; &gt;
ID: DU7
OBL: &lt;address( C.CA 18 )&gt;
DH: C2, info_request( W.?clest )&gt;
TOGND: I&lt;CA18:
CDU: SCP: C&gt;
COND: &lt; &gt;
DUR
INT: &lt;giveroute( W )&gt;
C; I &lt;getroute(C ) &gt; I
</table>
<figureCaption confidence="0.997677">
Figure 5: Information state following [7]
</figureCaption>
<bodyText confidence="0.9999448">
After C&apos;s agreement in [6], the deliberation rou-
tine is able to move past discussion of the start-
ing point, and add an intention to ask about the
next piece of information, the destination. This
leads to producing utterance [7], which also implic-
itly acknowledges [6], after which C&apos;s agreement is
grounded, leading to the IS shown in Figure 5. Note
that the list in W.GND.SCP in Figure 5 indicates that
both C and W are committed to the proposition that
the starting place is Malvern.
</bodyText>
<sectionHeader confidence="0.999822" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999698">
It has only been possible here to introduce the basic
concerns of the PTT account of dialogue modelling
and to pick out one or two illustrative examples to
highlight the implementational approach which has
</bodyText>
<page confidence="0.997201">
7
</page>
<bodyText confidence="0.999923666666667">
been assumed. Current and future work is directed
towards measuring the theory against more challeng-
ing data to test its validity; cases where ground-
ing is less automatic are an obvious source of such
tests, and we have identified a few relevant problem
cases in the Autoroute dialogues. We do claim, how-
ever, that the implementation as it stands validates
a number of key aspects of the theory and provides
a good basis for future work in dialogue modelling.
</bodyText>
<sectionHeader confidence="0.999402" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.5119942">
The TRINDI (Task Oriented Instructional Dia-
logue) project is supported by the Telematics Appli-
cations Programme, Language Engineering Project
LE4-8314. Massimo Poesio is supported by an EP-
SRC Advanced Research Fellowship.
</bodyText>
<sectionHeader confidence="0.930282" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999028117647059">
J. Allwood. 1976. Linguistic Communication as
Action and Cooperation. Ph.D. thesis, Goteborg
University, Department of Linguistics.
J. Allwood. 1994. Obligations and options in dia-
logue. Think Quarterly, 3:9-18.
M. E. Bratman, D. J. Israel and M. E. Pollack. 1988.
Plans and Resource-Bounded Practical Reason-
ing. Computational Intelligence, 4(4).
P. Bretier and M. D. Sadek. 1996. A rational agent
as the kernel of a cooperative spoken dialogue
system: Implementing a logical theory of inter-
action. In J. P. Muller, M. J. Wooldridge, and
N. R. Jennings, editors, Intelligent Agents III -
Proceedings of the Third International Workshop
on Agent Theories, Architectures, and Languages
(ATAL-96), Lecture Notes in Artificial Intelli-
gence. Springer-Verlag, Heidelberg.
J. Calder. 1998. Thistle: diagram display en-
gines and editors. Technical Report HCRC/TR-
97, HCRC, University of Edinburgh, Edinburgh.
H. H. Clark and E. F. Schaefer. 1989. Contributing
to discourse. Cognitive Science, 13:259-294.
H. H. Clark and D. Wilkes-Gibbs. 1986. Referring
as a collaborative process. Cognition, 22:1-39.
Also appears as Chapter 4 in (Clark, 1992).
H. H. Clark. 1992. Arenas of Language Use. Uni-
versity of Chicago Press.
P. R. Cohen and H. J. Levesque. 1990. Rational in-
teraction as the basis for communication. In P. R.
Cohen, J. Morgan, and M. E. Pollack, editors, In-
tentions in Communication. MIT Press.
Discourse Resource Initiative. 1997. Standards for
dialogue coding in natural language processing.
Report no. 167, Dagstuhl-Seminar.
B. J. Grosz and C. L. Sidner. 1990. Plans for dis-
course. In P. R. Cohen, J. Morgan, and M. E. Pol-
lack, editors, Intentions in Communication. MIT
Press.
J. Kreutel. 1998. An obligation-driven computa-
tional model for questions and assertions in dia-
logue. Master&apos;s thesis, Department of Linguistics,
University of Edinburgh, Edinburgh.
S. Larsson, P. Bohlin, J. Bos, and D. Traum. 1999.
Trindikit manual. Technical Report Deliverable
D2.2 - Manual, Trindi.
M. Poesio, R. Cooper, S. Larsson, D. Traum, and
C. Matheson. 1999. Annotating conversations for
information state update. In Proceedings of Am-
stelogue 99, 3rd Workshop on the Semantics and
Pragmatics of Dialogues.
M. Poesio and D. R. Traum. 1997. Conversational
actions and discourse situations. Computational
Intelligence, 13(3).
M. Poesio and D. R. Traum. 1998. Towards an ax-
iomatization of dialogue acts. In Proceedings of
Twendial&apos;98, 13th Twente Workshop on Language
Technology, pages 207-222.
M. D. Sadek. 1991. Dialogue acts are rational plans.
In Proceedings of the ESCA/ETR workshop on
multi-modal dialogue.
M. P. Singh. 1998. Agent communication lan-
guages: Rethinking the principles. IEEE Com-
puter, 31(12):40-47.
D. R. Traum and J. F. Allen. 1992. A speech acts
approach to grounding in conversation. In Pro-
ceedings 2nd International Conference on Spoken
Language Processing (ICSLP-92), pages 137-40,
October.
D. R. Traum and J. F. Allen. 1994. Discourse obli-
gations in dialogue processing. In Proceedings of
the 32nd Annual meeting of the Association for
Computational Linguistics, pages 1-8, June.
D. R. Traum, J. Bos, R. Cooper, S. Larsson, I.
Lewin, C. Matheson, and M. Poesio. 1999. A
model of dialogue moves and information state re-
vision. Technical Report Deliverable D2.1, Trindi.
D. R. Traum and P. Dillenbourg. 1998. Towards a
Normative Model of Grounding in Collaboration.
In Proceedings of the ESSLLI98 workshop on Mu-
tual Knowledge, Common Ground and Public In-
formation.
D. R. Traum. 1994. A computational theory
of grounding in natural language conversation.
Ph.D. thesis, Computer Science, University of
Rochester, New York, December.
</reference>
<page confidence="0.998496">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932283">
<title confidence="0.998785">Modelling Grounding and Discourse Obligations Using Update Rules</title>
<author confidence="0.999754">Colin Matheson</author>
<affiliation confidence="0.999987">University of Edinburgh</affiliation>
<address confidence="0.992725">Edinburgh, Scotland</address>
<email confidence="0.998431">colin.mathesonOed.ac.uk</email>
<author confidence="0.999538">Massimo Poesio</author>
<affiliation confidence="0.999979">University of Edinburgh</affiliation>
<address confidence="0.97139">Edinburgh, Scotland</address>
<email confidence="0.99762">massimo.poesio©ed.ac.uk</email>
<author confidence="0.999465">David Traum</author>
<affiliation confidence="0.99999">University of Maryland</affiliation>
<address confidence="0.979729">Maryland, USA</address>
<email confidence="0.999825">traurn©cs.umd.edu</email>
<abstract confidence="0.999445909090909">This paper describes an implementation of some key aspects of a theory of dialogue processing whose concerns are to provide models of GROUNDof the role of OBLIGATIONS an agent&apos;s deliberation processes. Our system uses the TrindiKit dialogue move engine toolkit, which assumes a model of dialogue in which a participanknowledge is characterised in terms of INFORMA- STATES are subject to various kinds of updating mechanisms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allwood</author>
</authors>
<title>Linguistic Communication as Action and Cooperation.</title>
<date>1976</date>
<tech>Ph.D. thesis,</tech>
<institution>Goteborg University, Department of Linguistics.</institution>
<contexts>
<context position="2934" citStr="Allwood, 1976" startWordPosition="455" endWordPosition="457">Discourse Resource Initiative precise enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assume</context>
</contexts>
<marker>Allwood, 1976</marker>
<rawString>J. Allwood. 1976. Linguistic Communication as Action and Cooperation. Ph.D. thesis, Goteborg University, Department of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allwood</author>
</authors>
<title>Obligations and options in dialogue. Think Quarterly,</title>
<date>1994</date>
<pages>3--9</pages>
<contexts>
<context position="2950" citStr="Allwood, 1994" startWordPosition="458" endWordPosition="459">rce Initiative precise enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already </context>
</contexts>
<marker>Allwood, 1994</marker>
<rawString>J. Allwood. 1994. Obligations and options in dialogue. Think Quarterly, 3:9-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Bratman</author>
<author>D J Israel</author>
<author>M E Pollack</author>
</authors>
<title>Plans and Resource-Bounded Practical Reasoning.</title>
<date>1988</date>
<journal>Computational Intelligence,</journal>
<volume>4</volume>
<issue>4</issue>
<contexts>
<context position="23096" citStr="Bratman et al., 1988" startWordPosition="3753" endWordPosition="3756"> process in case recently added facts have further implications. For instance, when an action has been performed that matches the antecedent of a rule in COND, the consequent is established. Likewise, when an action is performed it releases any obligations to perform that action. Thus, accept, answer, and agree are all ways of releasing an obligation to address, since these are all appropriate backward looking actions. Similarly, an agent will drop intentions to perform actions it has already (successfully) performed. 3.4 Deliberation We assume, in common with BDI-approaches to agency (e.g., (Bratman et al., 1988)) that intentions 9Forward acts include assert, check, direct, and info_request. 19The ID and HID values simply contain numbers identifying the discourse units and conversational acts. (2) 5 are the primary mental attitude leading to an agent&apos;s actions. The main issues to explain then become how such intentions are adopted given the rest of the information state, and how an agent gets from intentions to actual performance. For the latter question, we take a fairly simplistic approach here: all the intentions to perform dialogue acts are simply transferred to the next_moves system variable, wit</context>
</contexts>
<marker>Bratman, Israel, Pollack, 1988</marker>
<rawString>M. E. Bratman, D. J. Israel and M. E. Pollack. 1988. Plans and Resource-Bounded Practical Reasoning. Computational Intelligence, 4(4).</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Bretier</author>
<author>M D Sadek</author>
</authors>
<title>A rational agent as the kernel of a cooperative spoken dialogue system: Implementing a logical theory of interaction.</title>
<date>1996</date>
<booktitle>Intelligent Agents III -Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence.</booktitle>
<editor>In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Heidelberg.</location>
<contexts>
<context position="1878" citStr="Bretier and Sadek, 1996" startWordPosition="282" endWordPosition="285">d be represented: e.g., as something very specific to a particular domain, or according to some more general theory of (human or human inspired) dialogue processing. At one extreme, some systems represent only the (typically very rigid) transitions possible in a perceived dialogue for the given task, often using finite states in a transition network to represent the dialogue: examples of this are systems built using Nuance&apos;s DialogueBuilder or the CSLU&apos;s Rapid Application Prototyper. The other extreme is to build the dialogue processing theory on top of a full model of rational agency (e.g., (Bretier and Sadek, 1996)). The approach we take here lies in between these two extremes: we use rich representations of information states, but simpler, more dialogue-specific deliberation methods, rather than a deductive reasoner working on the basis of an axiomatic theory of rational agency. We show in this paper that the theory of information states we propose can, nevertheless, be used to give a characterisation of dialogue acts such as those proposed by the Discourse Resource Initiative precise enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementat</context>
</contexts>
<marker>Bretier, Sadek, 1996</marker>
<rawString>P. Bretier and M. D. Sadek. 1996. A rational agent as the kernel of a cooperative spoken dialogue system: Implementing a logical theory of interaction. In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, Intelligent Agents III -Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. Springer-Verlag, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Calder</author>
</authors>
<title>Thistle: diagram display engines and editors.</title>
<date>1998</date>
<tech>Technical Report HCRC/TR97,</tech>
<institution>HCRC, University of Edinburgh,</institution>
<location>Edinburgh.</location>
<contexts>
<context position="11711" citStr="Calder, 1998" startWordPosition="1892" endWordPosition="1893">filled is shown in Figure 2; this is the IS which results from the second utterance in the example dialogue discussed in Section 4, A route please.3 The IS in Figure 2 is a record with two main parts, W and C. The first of these represents the system&apos;s (Wizard) view of his own mental state and of the (semi-)public information discussed in the dialogue; the second, his view of the user&apos;s (Caller) information state. This second part is needed to 3A11 diagrams in this paper are automatically generated from TrindiKit system internal representations and displayed using the Thistle dialogue editor (Calder, 1998). Some have been subsequently edited for brevity and clarity. ( understandingAct( W,0U3 ) address(C,CA2 ) ( CA3: C2, acknowledge( C.DU2 ) ) CA2: C2, info_request( W,?helpform &lt; &gt; &lt;address( C,CA2 ) &gt; &lt;CA2: C2, info_request( W,?helpform ) &lt; &gt; W: TOGND: INT: Figure 2: Structure of Information States model misunderstandings arising from the dialogue participants having differing views on what has been grounded; as we are not concerned with this problem here, we will ignore C in what follows. w contains information on the grounded material (GND), on the ungrounded information (uDDS, PDU and CDU), a</context>
</contexts>
<marker>Calder, 1998</marker>
<rawString>J. Calder. 1998. Thistle: diagram display engines and editors. Technical Report HCRC/TR97, HCRC, University of Edinburgh, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>E F Schaefer</author>
</authors>
<title>Contributing to discourse.</title>
<date>1989</date>
<journal>Cognitive Science,</journal>
<pages>13--259</pages>
<contexts>
<context position="5633" citStr="Clark and Schaefer, 1989" startWordPosition="892" endWordPosition="895">se obligations are handled and the manner in which dialogue participants interact to add information to the common ground. Obligations are essentially social in nature, and directly characterise spoken dialogue; a typical example of a discourse obligation concerns the relationship between questions and answers. Poesio and Traum follow (Traum and Allen, 1994) in suggesting that the utterance of a question imposes an obligation on the hearer to address the question (e.g., by providing an answer), irrespective of intentions. As for the process by which common ground is established, or GROUNDING (Clark and Schaefer, 1989; Traum, 1994), the assumption in PTT is that classical speech act theory is inherently too simplistic in that it ignores the fact that co-operative interaction is essential in discourse; thus, for instance, simply asserting something does not make it become mutually &apos;known&apos; (part of the common ground). It is actually necessary for the hearer to provide some kind of acknowledgement that the assertion has been received, understood or not understood, accepted or rejected, and so on. Poesio and Traum view the public information state as including both material that has already been grounded, indi</context>
</contexts>
<marker>Clark, Schaefer, 1989</marker>
<rawString>H. H. Clark and E. F. Schaefer. 1989. Contributing to discourse. Cognitive Science, 13:259-294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>D Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<pages>22--1</pages>
<note>Also appears as Chapter 4 in (Clark,</note>
<contexts>
<context position="3412" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="528" endWordPosition="531">the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already part of the common ground at a given point, and which part has been introduced, but not yet been established. The rest of this paper is structured as follows. The theory of dialogue underlying the implementation is described in more detail in Section 2. Section 3 describes the implementation itself. Section 4 shows how the system updates its information state while participating in a fairly simple dialogue. 2 Theoretical Background One basic assumption under</context>
</contexts>
<marker>Clark, Wilkes-Gibbs, 1986</marker>
<rawString>H. H. Clark and D. Wilkes-Gibbs. 1986. Referring as a collaborative process. Cognition, 22:1-39. Also appears as Chapter 4 in (Clark, 1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
</authors>
<title>Arenas of Language Use.</title>
<date>1992</date>
<publisher>University of Chicago Press.</publisher>
<marker>Clark, 1992</marker>
<rawString>H. H. Clark. 1992. Arenas of Language Use. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
<author>H J Levesque</author>
</authors>
<title>Rational interaction as the basis for communication.</title>
<date>1990</date>
<booktitle>Intentions in Communication.</booktitle>
<editor>In P. R. Cohen, J. Morgan, and M. E. Pollack, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3074" citStr="Cohen and Levesque, 1990" startWordPosition="477" endWordPosition="480">tive fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already part of the common ground at a given point, and which part has been introduced, but not yet been established. The rest of th</context>
</contexts>
<marker>Cohen, Levesque, 1990</marker>
<rawString>P. R. Cohen and H. J. Levesque. 1990. Rational interaction as the basis for communication. In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, Intentions in Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Discourse Resource Initiative</author>
</authors>
<title>Standards for dialogue coding in natural language processing.</title>
<date>1997</date>
<tech>Report no. 167, Dagstuhl-Seminar.</tech>
<contexts>
<context position="7266" citStr="Initiative, 1997" startWordPosition="1159" endWordPosition="1160"> (implicit or explicit) acknowledgements. 3 Implementing PTT In this section, we describe the details of the implementation. First, in Section 3.1, we describe the TrindiKit tool for building dialogue managers that we used to build our system. In Section 3.2, we describe the information states used in the implementation, an extension and simplification of the ideas from PTT discussed in the previous section. Then, in Section 3.3, we discuss how the information state is updated when dialogue acts are observed. Finally, &apos;We assume here the DRI classification of dialogue acts (Discourse Resource Initiative, 1997). Figure 1: TrindiKit Architecture in Section 3.4, we describe the rules used by the system to adopt intentions and perform its own actions. An extended example of how these mechanisms are used to track and participate in a dialogue is presented in Section 4. 3.1 TrindiKit The basis for our implementation is the TrindiKit dialogue move engine toolkit implemented as part of the TRINDI project (Larsson et al., 1999). The toolkit provides support for developing dialogue systems, focusing on the central dialogue management components. The system architecture assumed by the TrindiKit is shown in Fi</context>
<context position="21254" citStr="Initiative, 1997" startWordPosition="3496" endWordPosition="3497">when a confidence level of 2 is observed, while some asserts are assumed not to have been sufficiently well understood, and are only assigned a confidence level 1. This leads the system to perform a check, as we will see shortly. The next three update rules, for check, direct, and info_req, all impose an obligation on the other dialogue participant to address the dialogue act. In addition, the direct rule introduces a conditional act: acceptance of the directive will impose an obligation on the hearer to act on its contents. In addition, all FORWARD ACTS9 in the DRI scheme (Discourse Resource Initiative, 1997) impose an obligation to perform an understanding act (e.g., an acknowledgement): act ID:c, forward-looking-act(DP) effect push(on,u-act(o(DP),CDU.id)) The internal urules implementing the updates in (2) have the format shown in (4), which is the urule for info_request. (4) urule( doInfoReq, ruletype3, hearer(U), latent_moves: in(Move), Move:valRec(pred,inforeq) ], incr_set(update_cycles,_), incr_set(next_dh_id,RID), next_du_name(ID), pushRec(w-cdetognd-dh, record([atypevMove,clevel=2,idvIIID ])), pushRec(v-cdetogneobl, recordapredvaddrees,dpvDP, argsvstackset( Erecord((itenmRID))])])), pushRe</context>
</contexts>
<marker>Initiative, 1997</marker>
<rawString>Discourse Resource Initiative. 1997. Standards for dialogue coding in natural language processing. Report no. 167, Dagstuhl-Seminar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Plans for discourse.</title>
<date>1990</date>
<booktitle>Intentions in Communication.</booktitle>
<editor>In P. R. Cohen, J. Morgan, and M. E. Pollack, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3047" citStr="Grosz and Sidner, 1990" startWordPosition="473" endWordPosition="476"> in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already part of the common ground at a given point, and which part has been introduced, but not yet been </context>
</contexts>
<marker>Grosz, Sidner, 1990</marker>
<rawString>B. J. Grosz and C. L. Sidner. 1990. Plans for discourse. In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, Intentions in Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kreutel</author>
</authors>
<title>An obligation-driven computational model for questions and assertions in dialogue.</title>
<date>1998</date>
<tech>Master&apos;s thesis,</tech>
<institution>Department of Linguistics, University of Edinburgh,</institution>
<location>Edinburgh.</location>
<contexts>
<context position="16675" citStr="Kreutel, 1998" startWordPosition="2759" endWordPosition="2760">contains a conditional update resulting from the directive performed by that utterance. The idea is that directives do not immediately lead to obligations to perform the mentioned action: instead (in addition to an obligation to address the action with some sort of response), their effect is to add to the common ground the information that if the directive is accepted by the addressee, 6The fact that the utterance of a route please constitutes an answer is explicitly assumed; however, it should be possible to derive this information automatically (perhaps along the lines suggested by Kreutel (Kreutel, 1998)). 6We use the notation ?p to indicate a question of the form ?([4P(x)) • 7We assume here, as in (Traum, 1994) and (Poesio and Traum, 1998), that understanding acts do not have to be grounded themselves, which would result in a infinite regress. then he or she has the obligation to perform the action type requested. (In this case, to give a route to C.) 3.3 Update Rules in PTT We are now in a position to examine the update mechanisms which are performed when new dialogue acts are recognised. When a dialogue participant takes a turn and produces an utterance, the interpretation module sets the </context>
<context position="25188" citStr="Kreutel, 1998" startWordPosition="4087" endWordPosition="4089">nderstood dialogue acts (with a 1 confidence level in CDU.DH) • intentions to perform complex acts The current deliberation process assumes maximal cooperativity, in that the system always chooses to meet its obligations whenever possible, and also chooses to provide a maximally helpful response when possible. Thus, when obliged to address a previous dialogue act such as a question or directive, it will choose to actually return the answer or perform the action, if possible, rather than reject or negotiate such a performance, which would also be acting in accordance with the obligations (see (Kreutel, 1998) on how acts might be rejected). In the current implementation, the following rules are used to adopt new intentions (i.e., to update the INT field): (5) I. add an intention to acknowledge(W,CDU), given an obligation to perform a u-act, if everything in CDU is sufficiently understood (i.e., to level 2); 2. add an intention to accept a directive or answer a question as the result of an obligation to address a dialogue act; 3. add an intention to perform an action if COND contains a conditional that will establish an obligation to perform the action, and the antecedent of this conditional is ano</context>
</contexts>
<marker>Kreutel, 1998</marker>
<rawString>J. Kreutel. 1998. An obligation-driven computational model for questions and assertions in dialogue. Master&apos;s thesis, Department of Linguistics, University of Edinburgh, Edinburgh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Larsson</author>
<author>P Bohlin</author>
<author>J Bos</author>
<author>D Traum</author>
</authors>
<title>Trindikit manual.</title>
<date>1999</date>
<journal>Computational Intelligence,</journal>
<booktitle>In Proceedings of Amstelogue 99, 3rd Workshop on the Semantics and Pragmatics</booktitle>
<tech>Technical Report Deliverable D2.2</tech>
<volume>13</volume>
<issue>3</issue>
<contexts>
<context position="7683" citStr="Larsson et al., 1999" startWordPosition="1228" endWordPosition="1231">hen, in Section 3.3, we discuss how the information state is updated when dialogue acts are observed. Finally, &apos;We assume here the DRI classification of dialogue acts (Discourse Resource Initiative, 1997). Figure 1: TrindiKit Architecture in Section 3.4, we describe the rules used by the system to adopt intentions and perform its own actions. An extended example of how these mechanisms are used to track and participate in a dialogue is presented in Section 4. 3.1 TrindiKit The basis for our implementation is the TrindiKit dialogue move engine toolkit implemented as part of the TRINDI project (Larsson et al., 1999). The toolkit provides support for developing dialogue systems, focusing on the central dialogue management components. The system architecture assumed by the TrindiKit is shown in Figure 1. A prominent feature of this architecture is the information state, which serves as a central &apos;blackboard&apos; that processing modules can examine (by means of defined CONDITIONS) or change (by means of defined OPERATIONS). The structure of the IS for a particular dialogue system is defined by the developer who uses the TrindiKit to build that system, on the basis of his/her own theory of dialogue processing; n</context>
</contexts>
<marker>Larsson, Bohlin, Bos, Traum, 1999</marker>
<rawString>S. Larsson, P. Bohlin, J. Bos, and D. Traum. 1999. Trindikit manual. Technical Report Deliverable D2.2 - Manual, Trindi. M. Poesio, R. Cooper, S. Larsson, D. Traum, and C. Matheson. 1999. Annotating conversations for information state update. In Proceedings of Amstelogue 99, 3rd Workshop on the Semantics and Pragmatics of Dialogues. M. Poesio and D. R. Traum. 1997. Conversational actions and discourse situations. Computational Intelligence, 13(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>D R Traum</author>
</authors>
<title>Towards an axiomatization of dialogue acts.</title>
<date>1998</date>
<booktitle>In Proceedings of Twendial&apos;98, 13th Twente Workshop on Language Technology,</booktitle>
<pages>207--222</pages>
<contexts>
<context position="2592" citStr="Poesio and Traum, 1998" startWordPosition="397" endWordPosition="400"> of information states, but simpler, more dialogue-specific deliberation methods, rather than a deductive reasoner working on the basis of an axiomatic theory of rational agency. We show in this paper that the theory of information states we propose can, nevertheless, be used to give a characterisation of dialogue acts such as those proposed by the Discourse Resource Initiative precise enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitm</context>
<context position="4893" citStr="Poesio and Traum, 1998" startWordPosition="775" endWordPosition="778"> utterances are described in terms of the changes they bring about in ISs. A particular instantiation of a dialogue manager, from this point of view, consists of a definition of the contents of ISs plus a description of the update processes which map from IS to IS. Updates are typically triggered by &apos;full&apos; dialogue acts such as assertions or directives,&apos; of course, but the theory allows parts of utterances, including individual words and even subparts of words, to be the trigger. The update rules for dialogue acts that we assume here are a simplified version of the formalisations proposed in (Poesio and Traum, 1998; Traum et al., 1999) (henceforth, PTT). The main aspects of PTT which have been implemented concern the way discourse obligations are handled and the manner in which dialogue participants interact to add information to the common ground. Obligations are essentially social in nature, and directly characterise spoken dialogue; a typical example of a discourse obligation concerns the relationship between questions and answers. Poesio and Traum follow (Traum and Allen, 1994) in suggesting that the utterance of a question imposes an obligation on the hearer to address the question (e.g., by provid</context>
<context position="10772" citStr="Poesio and Traum, 1998" startWordPosition="1738" endWordPosition="1741">(potentially making reference to the current information state), and GENERATION, which produces NL output from the dialogue acts in the next_moves variable. Finally, there is a CONTROL module, that governs the sequencing (or parallel invocation) of the other modules. In this paper we focus on the IS and the DME; our current implementation only uses very simple interpretation and generation components. 3.2 Information States in PTT In this section we discuss the information state used in the current implementation. The main difference between the implemented IS and the theoretical proposal in (Poesio and Traum, 1998) is that in the implementation the information state is partitioned in fields, each containing information of different types, whereas in the theoretical version the information state is a single repository of facts (a DISCOURSE REPRESENTATION STRUCTURE). Other differences are discussed below. An example IS with some fields filled is shown in Figure 2; this is the IS which results from the second utterance in the example dialogue discussed in Section 4, A route please.3 The IS in Figure 2 is a record with two main parts, W and C. The first of these represents the system&apos;s (Wizard) view of his </context>
<context position="16814" citStr="Poesio and Traum, 1998" startWordPosition="2783" endWordPosition="2786">tely lead to obligations to perform the mentioned action: instead (in addition to an obligation to address the action with some sort of response), their effect is to add to the common ground the information that if the directive is accepted by the addressee, 6The fact that the utterance of a route please constitutes an answer is explicitly assumed; however, it should be possible to derive this information automatically (perhaps along the lines suggested by Kreutel (Kreutel, 1998)). 6We use the notation ?p to indicate a question of the form ?([4P(x)) • 7We assume here, as in (Traum, 1994) and (Poesio and Traum, 1998), that understanding acts do not have to be grounded themselves, which would result in a infinite regress. then he or she has the obligation to perform the action type requested. (In this case, to give a route to C.) 3.3 Update Rules in PTT We are now in a position to examine the update mechanisms which are performed when new dialogue acts are recognised. When a dialogue participant takes a turn and produces an utterance, the interpretation module sets the system variable latest_moves to contain a representation of the dialogue acts performed with the utterance. The updating procedure then use</context>
</contexts>
<marker>Poesio, Traum, 1998</marker>
<rawString>M. Poesio and D. R. Traum. 1998. Towards an axiomatization of dialogue acts. In Proceedings of Twendial&apos;98, 13th Twente Workshop on Language Technology, pages 207-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Sadek</author>
</authors>
<title>Dialogue acts are rational plans.</title>
<date>1991</date>
<booktitle>In Proceedings of the ESCA/ETR workshop on multi-modal dialogue.</booktitle>
<contexts>
<context position="3023" citStr="Sadek, 1991" startWordPosition="471" endWordPosition="472">logue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already part of the common ground at a given point, and which part has been intro</context>
</contexts>
<marker>Sadek, 1991</marker>
<rawString>M. D. Sadek. 1991. Dialogue acts are rational plans. In Proceedings of the ESCA/ETR workshop on multi-modal dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Singh</author>
</authors>
<title>Agent communication languages: Rethinking the principles.</title>
<date>1998</date>
<journal>IEEE Computer,</journal>
<pages>31--12</pages>
<contexts>
<context position="2968" citStr="Singh, 1998" startWordPosition="461" endWordPosition="462">se enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialogue participants (obligations to act and commitments to propositions) without making explicit claims about the actual beliefs and intentions of the participants. Also, heavy emphasis is placed on how dialogue participants socially GROUND (Clark and Wilkes-Gibbs, 1986) the information expressed in dialogue: the information state assumed in this theory specifies which information is assumed to be already part of the common</context>
</contexts>
<marker>Singh, 1998</marker>
<rawString>M. P. Singh. 1998. Agent communication languages: Rethinking the principles. IEEE Computer, 31(12):40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
<author>J F Allen</author>
</authors>
<title>A speech acts approach to grounding in conversation.</title>
<date>1992</date>
<booktitle>In Proceedings 2nd International Conference on Spoken Language Processing (ICSLP-92),</booktitle>
<pages>137--40</pages>
<marker>Traum, Allen, 1992</marker>
<rawString>D. R. Traum and J. F. Allen. 1992. A speech acts approach to grounding in conversation. In Proceedings 2nd International Conference on Spoken Language Processing (ICSLP-92), pages 137-40, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
<author>J F Allen</author>
</authors>
<title>Discourse obligations in dialogue processing.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="5369" citStr="Traum and Allen, 1994" startWordPosition="848" endWordPosition="851">trigger. The update rules for dialogue acts that we assume here are a simplified version of the formalisations proposed in (Poesio and Traum, 1998; Traum et al., 1999) (henceforth, PTT). The main aspects of PTT which have been implemented concern the way discourse obligations are handled and the manner in which dialogue participants interact to add information to the common ground. Obligations are essentially social in nature, and directly characterise spoken dialogue; a typical example of a discourse obligation concerns the relationship between questions and answers. Poesio and Traum follow (Traum and Allen, 1994) in suggesting that the utterance of a question imposes an obligation on the hearer to address the question (e.g., by providing an answer), irrespective of intentions. As for the process by which common ground is established, or GROUNDING (Clark and Schaefer, 1989; Traum, 1994), the assumption in PTT is that classical speech act theory is inherently too simplistic in that it ignores the fact that co-operative interaction is essential in discourse; thus, for instance, simply asserting something does not make it become mutually &apos;known&apos; (part of the common ground). It is actually necessary for th</context>
</contexts>
<marker>Traum, Allen, 1994</marker>
<rawString>D. R. Traum and J. F. Allen. 1994. Discourse obligations in dialogue processing. In Proceedings of the 32nd Annual meeting of the Association for Computational Linguistics, pages 1-8, June. D. R. Traum, J. Bos, R. Cooper, S. Larsson, I.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Matheson Lewin</author>
<author>M Poesio</author>
</authors>
<title>A model of dialogue moves and information state revision.</title>
<date>1999</date>
<tech>Technical Report Deliverable D2.1,</tech>
<marker>Lewin, Poesio, 1999</marker>
<rawString>Lewin, C. Matheson, and M. Poesio. 1999. A model of dialogue moves and information state revision. Technical Report Deliverable D2.1, Trindi. D. R. Traum and P. Dillenbourg. 1998. Towards a Normative Model of Grounding in Collaboration.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the ESSLLI98 workshop on Mutual Knowledge, Common Ground and Public Information.</booktitle>
<marker></marker>
<rawString>In Proceedings of the ESSLLI98 workshop on Mutual Knowledge, Common Ground and Public Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
</authors>
<title>A computational theory of grounding in natural language conversation.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science, University of Rochester,</institution>
<location>New York,</location>
<contexts>
<context position="2544" citStr="Traum, 1994" startWordPosition="391" endWordPosition="392">extremes: we use rich representations of information states, but simpler, more dialogue-specific deliberation methods, rather than a deductive reasoner working on the basis of an axiomatic theory of rational agency. We show in this paper that the theory of information states we propose can, nevertheless, be used to give a characterisation of dialogue acts such as those proposed by the Discourse Resource Initiative precise enough to formalise the deliberation process of a dialogue manager in a completely declarative fashion. Our implementation is based on the approach to dialogue developed in (Traum, 1994; Poesio and Traum, 1997; Poesio and Traum, 1998; Traum et al., 1999). This theory, like other action-based theories of dialogue, views dialogue participation in terms of agents performing dialogue acts, the effects of which are to update the information state of the participants in a dialogue. However, our view of dialogue act effects is closer in some respects to that of (Allwood, 1976; Allwood, 1994) and (Singh, 1998) than to the belief and intention model of (Sadek, 1991; Grosz and Sidner, 1990; Cohen and Levesque, 1990). Particular emphasis is placed on the social commitments of the dialo</context>
<context position="5647" citStr="Traum, 1994" startWordPosition="896" endWordPosition="897"> and the manner in which dialogue participants interact to add information to the common ground. Obligations are essentially social in nature, and directly characterise spoken dialogue; a typical example of a discourse obligation concerns the relationship between questions and answers. Poesio and Traum follow (Traum and Allen, 1994) in suggesting that the utterance of a question imposes an obligation on the hearer to address the question (e.g., by providing an answer), irrespective of intentions. As for the process by which common ground is established, or GROUNDING (Clark and Schaefer, 1989; Traum, 1994), the assumption in PTT is that classical speech act theory is inherently too simplistic in that it ignores the fact that co-operative interaction is essential in discourse; thus, for instance, simply asserting something does not make it become mutually &apos;known&apos; (part of the common ground). It is actually necessary for the hearer to provide some kind of acknowledgement that the assertion has been received, understood or not understood, accepted or rejected, and so on. Poesio and Traum view the public information state as including both material that has already been grounded, indicated by CND h</context>
<context position="16785" citStr="Traum, 1994" startWordPosition="2780" endWordPosition="2781">ves do not immediately lead to obligations to perform the mentioned action: instead (in addition to an obligation to address the action with some sort of response), their effect is to add to the common ground the information that if the directive is accepted by the addressee, 6The fact that the utterance of a route please constitutes an answer is explicitly assumed; however, it should be possible to derive this information automatically (perhaps along the lines suggested by Kreutel (Kreutel, 1998)). 6We use the notation ?p to indicate a question of the form ?([4P(x)) • 7We assume here, as in (Traum, 1994) and (Poesio and Traum, 1998), that understanding acts do not have to be grounded themselves, which would result in a infinite regress. then he or she has the obligation to perform the action type requested. (In this case, to give a route to C.) 3.3 Update Rules in PTT We are now in a position to examine the update mechanisms which are performed when new dialogue acts are recognised. When a dialogue participant takes a turn and produces an utterance, the interpretation module sets the system variable latest_moves to contain a representation of the dialogue acts performed with the utterance. Th</context>
</contexts>
<marker>Traum, 1994</marker>
<rawString>D. R. Traum. 1994. A computational theory of grounding in natural language conversation. Ph.D. thesis, Computer Science, University of Rochester, New York, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>