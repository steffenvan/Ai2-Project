<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.983575">
Multilingual Coreference Resolution
</title>
<author confidence="0.98365">
Sanda M. Harabagiu Steven J. Maiorano
</author>
<affiliation confidence="0.913856">
Southern Methodist University IPO
</affiliation>
<address confidence="0.600741">
Dallas, TX 75275-0122 Washington, D.C. 20505
</address>
<email confidence="0.470368">
sandaseas.smu.edu mai orano@c ai s . corn
</email>
<sectionHeader confidence="0.974258" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999182">
In this paper we present a new, multi-
lingual data-driven method for coreference
resolution as implemented in the SWIZZLE
system. The results obtained after training
this system on a bilingual corpus of English
and Romanian tagged texts, outperformed
coreference resolution in each of the indi-
vidual languages.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.960865602941177">
The recent availability of large bilingual corpora has
spawned interest in several areas of multilingual text
processing. Most of the research has focused on
bilingual terminology identification, either as par-
allel multiwords forms (e.g. the Champolhon sys-
tem (Smadja et al.1996)), technical terminology (e.g.
the Termight system (Dagan and Church, 1994) or
broad-coverage translation lexicons (e.g. the SABLE
system (Resnik and Melamed, 1997)). In addition,
the Multilingual Entity Task (MET) from the TIP-
STER program&apos; (http://www-nipir.nist.gov/related-
projects/tipster/met.htm) challenged the partici-
pants in the Message Understanding Conference
(MUC) to extract named entities across several for-
eign language corpora, such as Chinese, Japanese
and Spanish.
In this paper we present a new application of
aligned multilingual texts. Since coreference reso-
lution is a pervasive discourse phenomenon causing
performance impediments in current IE systems, we
considered a corpus of aligned English and Roma-
nian texts to identify coreferring expressions. Our
task focused on the same kind of coreference as
considered in the past MUC competitions, namely
&apos;The TIPSTER Text Program was a DARPA-led
government effort to advance the state of the art in text
processing technologies.
the identity coreference. Identity coreference links
nouns, pronouns and noun phrases (including proper
names) to their corresponding antecedents.
We created our bilingual collection by translating
the MUC-6 and MUC-7 coreference training texts
into Romanian using native speakers. The train-
ing data set for Romanian coreference used, wher-
ever possible, the same coreference identifiers as the
English data and incorporated additional tags as
needed. Our claim is that by adding the wealth
of coreferential features provided by multilingual
data, new powerful heuristics for coreference resolu-
tion can be developed that outperform monolingual
coreference resolution systems.
For both languages, we resolved coreference by
using SWIZZLE, our implementation of a bilingual
coreference resolver. SWIZZLE is a multilingual en-
hancement of COCKTAIL (Harabagiu and Maiorano,
1999), a coreference resolution system that operates
on a mixture of heuristics that combine semantic
and textual cohesive information&apos;. When COCKTAIL
was applied separately on the English and the Ro-
manian texts, coreferring links were identified for
each English and Romanian document respectively.
When aligned referential expressions corefer with
non-aligned anaphors, SWIZZLE derived new heuris-
tics for coreference. Our experiments show that
SWIZZLE outperformed COCKTAIL on both English
and Romanian test documents.
The rest of the paper is organized as follows. Sec-
tion 2 presents COCKTAIL, a monolingual coreference
resolution system used separately on both the En-
glish and Romanian texts. Section 3 details the
data-driven approach used in SWIZZLE and presents
some of its resources. Section 4 reports and discusses
the experimental results. Section 5 summarizes the
&apos;The name of COCKTAIL is a pun on CogNIAC be-
cause COCKTAIL combines a larger number of heuristics
than those reported in (Baldwin, 1997). SWIZZLE, more-
over, adds new heuristics, discovered from the bilingual
aligned corpus.
</bodyText>
<page confidence="0.99246">
142
</page>
<bodyText confidence="0.663729">
conclusions.
</bodyText>
<sectionHeader confidence="0.993928" genericHeader="introduction">
2 COCKTAIL
</sectionHeader>
<bodyText confidence="0.999929214285715">
Currently, some of the best-performing and
most robust coreference resolution systems employ
knowledge-based techniques. Traditionally, these
techniques have combined extensive syntactic, se-
mantic, and discourse knowledge. The acquisition
of such knowledge is time-consuming, difficult, and
error-prone. Nevertheless, recent results show that
knowledge-poor methods perform with amazing ac-
curacy (cf. (Mitkov, 1998), (Kennedy and Boguraev,
1996) (Kameyama, 1997)). For example, CogNIAC
(Baldwin, 1997), a system based on seven ordered
heuristics, generates high-precision resolution (over
90%) for some cases of pronominal reference. For
this research, we used a coreference resolution sys-
tem ((Harabagiu and Maiorano, 1999)) that imple-
ments different sets of heuristics corresponding to
various forms of coreference. This system, called
COCKTAIL, resolves coreference by exploiting several
textual cohesion constraints (e.g. term repetition)
combined with lexical and textual coherence cues
(e.g. subjects of communication verbs are more
likely to refer to the last person mentioned in the
text). These constraints are implemented as a set of
heuristics ordered by their priority. Moreover, the
COCKTAIL framework uniformly addresses the prob-
lem of interaction between different forms of coref-
erence, thus making the extension to multilingual
coreference very natural.
</bodyText>
<subsectionHeader confidence="0.999309">
2.1 Data-Driven Coreference Resolution
</subsectionHeader>
<bodyText confidence="0.976651137931035">
In general, we define a data-driven methodology as
a sequence of actions that captures the data pat-
terns capable of resolving a problem with both a
high degree of precision and recall. Our data-driven
methodology reported here generated sets of heuris-
tics for the coreference resolution problem. Precision
is the number of correct references out of the total
number of coreferences resolved, whereas the recall
measures the number of resolved references out of
the total number of keys, i.e., the annotated coref-
erence data.
The data-driven methodology used in COCKTAIL is
centered around the notion of a coreference chain.
Due to the transitivity of coreference relations, k
coreference relations having at least one common ar-
gument generate k + 1 coreferring expressions. The
text position induces an order among coreferring ex-
pressions. A coreference structure is created when
a set of coreferring expressions are connected in an
oriented graph such that each node is related only
to one of its preceding nodes. In turn, a corefer-
ence chain is the coreference structure in which ev-
ery node is connected to its immediately preceding
node. Clearly, multiple coreference structures for the
same set of coreferring expressions can be mapped
to a single coreference chain. As an example, both
coreference structures illustrated in Figure 1(a) and
(c) are cast into the coreference chain illustrated in
Figure 1(b).
</bodyText>
<figure confidence="0.871605">
TEXT TEXT TEXT
(a) (b) (c)
</figure>
<figureCaption confidence="0.999977">
Figure 1: Three coreference structures.
</figureCaption>
<bodyText confidence="0.999895484848485">
Given a corpus annotated with coreference data,
the data-driven methodology first generates all
coreference chains in the data set and then con-
siders all possible combinations of coreference re-
lations that would generate the same coreference
chains. For a coreference chain of length 1 with
nodes n1, n2, ... ni±i , each node nk (1&lt;k&lt;l) can
be connected to any of the 1 — k nodes preceding
it. From this observation, we find that a number
of 1 x 2 x x (/ — k)... x = 1! coreference struc-
tures can generate the same coreference chain. This
result is very important, since it allows for the auto-
matic generation of coreference data. For each coref-
erence relation R. from an annotated corpus we cre-
ated a median of (1 — 1)! new coreference relations,
where 1 is the length of the coreference chain contain-
ing relation 7Z. This observation gave us the possi-
bility of expanding the test data provided by the
coreference keys available in the MUC-6 and MUC-
7 competitions (MUC-6 1996), (MUC-7 1998). The
MUC-6 coreference annotated corpus contains 1626
coreference relations, while the MUC-7 corpus has
2245 relations. The average length of a coreference
chain is 7.21 for the MUC-6 data, and 8.57 for the
MUC-7 data. We were able to expand the number
of annotated coreference relations to 6,095,142 for
the MUC-6 corpus and to 8,269,403 relations for the
MUC-7 corpus; this represents an expansion factor
of 3,710. We are not aware of any other automated
way of creating coreference annotated data, and we
believe that much of the COCKTAIL&apos;s impressive per-
formance is due to the plethora of data provided by
this method.
</bodyText>
<page confidence="0.990615">
143
</page>
<bodyText confidence="0.664637227272727">
Heuristics for 3rd person pronouns Heuristics for nominal reference
oHeuristic 1-Pronoun(H1Pron) oHeuristic 1-Nominal(H1Nom)
Search in the same sentence for the same if (Noun is the head of an appositive)
3rd person pronoun Pron&apos; then Pick the preceding NP.
if (Pron&apos; belongs to coreference chain CC) oHeuristic 2-Nomina/(H2Nom)
and there is an element from CC which is if (Noun belongs to an NP, Search for NP&apos;
closest to Pron in Text, Pick that element, such that Noun&apos;=same_name(head(NP),head(NP9)
else Pick Pron&apos;. Or
oHeuristic 2-Pronoun(H2Pron) Noun&apos;=same_name(adjunct(NP),adjunct(NP&apos;)))
Search for PN, the closest proper name from Pron then if (Noun&apos; belongs to coreference chain CC)
if (PN agrees in number and gender with Pron) then Pick the element from CC which is
if (PN belongs to coreference chain CC) closest to Noun in Text.
then Pick the element from CC which is else Pick Noun&apos;.
closest to Pron in Text. oHeuristic 3-Nominal(H3Nom)
else Pick PN. if Noun is the head of an NP
oHeuristic 3-Pronoun(H3Pron) then Search for proper name PN
Search for Noun, the closest noun from Pron such that head(PN)=Noun
if (Noun agrees in number and gender with Pron) if (PN belongs to coreference chain CC)
if (Noun belongs to coreference chain CC) and there is an element from CC which is
and there is an element from CC which is closest to Noun in Text, Pick that element.
closest to Pron in Text, Pick that element. else Pick PN.
else Pick Noun
</bodyText>
<tableCaption confidence="0.991657">
Table 1: Best performing heuristics implemented in COCKTAIL
</tableCaption>
<subsectionHeader confidence="0.8875005">
2.2 Knowledge-Poor Coreference
Resolution
</subsectionHeader>
<bodyText confidence="0.993011809523809">
The result of our data-driven methodology is the
set of heuristics implemented in COCKTAIL which
cover both nominal and pronoun coreference. Each
heuristic represents a pattern of coreference that
was mined from the large set of coreference data.
COCKTAIL uses knowledge-poor methods because (a)
it is based only on a limited number of heuristics
and (b) text processing is limited to part-of-speech
tagging, named-entity recognition, and approximate
phrasal parsing. The heuristics from COCKTAIL can
be classified along two directions. First of all, they
can be grouped according to the type of corefer-
ence they resolve, e.g., heuristics that resolve the
anaphors of reflexive pronouns operate differently
than those resolving bare nominals. Currently, in
COCKTAIL there are heuristics that resolve five types
of pronouns (personal, possessive, reflexive, demon-
strative and relative) and three forms of nominals
(definite, bare and indefinite).
Secondly, for each type of coreference, there are
three classes of heuristics categorized according to
their suitability to resolve coreference. The first
class is comprised of strong indicators of coreference.
This class resulted from the analysis of the distribu-
tion of the antecedents in the MUC annotated data.
For example, repetitions of named entities and ap-
positives account for the majority of the nominal
coreferences, and, therefore, represent anchors for
the first class of heuristics.
The second class of coreference covers cases in
which the arguments are recognized to be seman-
tically consistent. COCKTAIL&apos;s test of semantic con-
sistency blends together information available from
WordNet and statistics gathered from Treebank.
Different consistency checks are modeled for each of
the heuristics.
Example of the application of heuristic H2Pron
Mr. Adamsi, 69 years old, is the retired chairman
of Canadian-based Emco Ltd., a maker of plumbing
and petroleum equipment; hei has served on the
Woolworth board since 1981.
Example of the application of heuristic H3Pron
&amp;quot;We have got to stop pointing our fingers at these
kids2 who have no future,&amp;quot; he said, &amp;quot;and reach our
hands out to them2.
Example of the application of heuristic H2Nom
The chairman and the chief executive of ficers
of Woolworth Corp. have temporarily relinquished
their posts while the retailer conducts its investi-
gation into alleged accounting irregularities4.
Woolworth&apos;s board named John W. Adams, an
outsider, to serve as interim chairman and executive
officers, while a special committee, appointed by
the board last week and led by Mr. Adams,
investigates the alleged irregularities4.
Table 2: Examples of coreference resolution. The
same annotated index indicates coreference.
The third class of heuristics resolves coreference
by coercing nominals. Sometimes coercions involve
only derivational morphology - linking verbs with
their nominalizations. On other occasions, coercions
are obtained as paths of meronyms (e.g. is-part re-
lations) and hypernyms (e.g. is-a relations). Con-
</bodyText>
<page confidence="0.993348">
144
</page>
<bodyText confidence="0.9993863">
sistency checks implemented for this class of coref-
erence are conservative: either the adjuncts must be
identical or the adjunct of the referent must be less
specific than the antecedent. Table 1 lists the top
performing heuristics of COCKTAIL for pronominal
and nominal coreference. Examples of the heuristics
operation on the MUC data are presented presented
in Table 2. Details of the top performing heuris-
tics of COCKTAIL were reported in (Harabagiu and
Maiorano, 1999).
</bodyText>
<subsectionHeader confidence="0.9918495">
2.3 Bootstrapping for Coreference
Resolution
</subsectionHeader>
<bodyText confidence="0.999420785714285">
One of the major drawbacks of existing corefer-
ence resolution systems is their inability to recog-
nize many forms of coreference displayed by many
real-world texts. Recall measures of current systems
range between 36% and 59% for both knowledge-
based and statistical techniques. Knowledge based-
systems would perform better if more coreference
constraints were available whereas statistical meth-
ods would be improved if more annotated data were
available. Since knowledge-based techniques out-
perform inductive methods, we used high-precision
coreference heuristics as knowledge seeds for ma-
chine learning techniques that operate on large
amounts of unlabeled data. One such technique
is bootstrapping, which was recently presented in
(Riloff and Jones 1999), (Jones et al.1999) as an
ideal framework for text learning tasks that have
knowledge seeds. The method does not require large
training sets. We extended COCKTAIL by using meta-
bootstrapping of both new heuristics and clusters of
nouns that display semantic consistency for corefer-
ence.
The coreference heuristics are the seeds of our
bootstrapping framework for coreference resolution.
When applied to large collections of texts, the
heuristics determine classes of coreferring expres-
sions. By generating coreference chains out of all
these coreferring expressions, often new heuristics
are uncovered. For example, Figure 2 illustrates the
application of three heuristics and the generation of
data for a new heuristic rule. In COCKTAIL, after a
heuristic is applied, a new coreference chain is cal-
culated. For the example illustrated in Figure 2, if
the reference of expression A is sought, heuristic R1
indicates expression B to be the antecedent. When
the coreference chain is built, expression A is di-
rectly linked to expression D, thus uncovering a new
heuristic HO.
As a rule of thumb, we do not consider a new
heuristic unless there is massive evidence of its cov-
erage in the data. To measure the coverage we use
the FOIL_Gain measure, as introduced by the FOIL
inductive algorithm (Cameron-Jones and Quinlan
1993). Let Ho be the new heuristic and Hi a heuris-
tic that is already in the seed set. Let po be the num-
ber of positive coreference examples of Hne. (i.e.
the number of coreference relations produced by the
heuristic that can be found in the test data) and no
the number of negative examples of Hneu, (i.e. the
number of relations generated by the heuristic which
cannot be found in the test data). Similarly, pi and
ni are the positive and negative examples of Hi.
The new heuristics are scored by their FOIL_Gain
distance to the existing set of heuristics, and the best
scoring one is added to the COCKTAIL system. The
FOIL_Gain formula is:
</bodyText>
<equation confidence="0.877781">
FOIL_Gain(Hi, Ho) = k(log2 Po log2 )
+ ni po+no
</equation>
<bodyText confidence="0.951096">
where k is the number of positive examples cov-
ered by both Hi and Ho. Heuristic Ho is added to
the seed set if there is no other heuristic providing
larger FOIL_Gain to any of the seed heuristics.
</bodyText>
<figureCaption confidence="0.60176">
Figure 2: Bootstrapping new heuristics.
Since in COCKTAIL, semantic consistency of core-
ferring expressions is checked by comparing the sim-
ilarity of noun classes, each new heuristic deter-
mines the adjustment of the similarity threshold of
all known coreferring noun classes. The steps of
the bootstrapping algorithm that learns both new
heuristics and adjusts the similarity threshold of
coreferential expressions is:
</figureCaption>
<table confidence="0.561849">
MUTUAL BOOTSTRAPPING LOOP
I. Score all candidate heuristics with FOIL_Gain
</table>
<listItem confidence="0.979034">
2. Best_h=closest candidate to heuristics(COCKTAIL)
3. Add Best_h to heuristics(COCKTAIL)
4. Adjust semantic similarity threshold for semantic
consistency of coreferring nouns
5. Goto step 1 if the precision and recall did not
degrade under minimal performance.
</listItem>
<bodyText confidence="0.992394333333333">
(Riloff and Jones 1999) note that the bootstrap-
ping algorithm works well but its performance can
deteriorate rapidly when non-coreferring data enter
as candidate heuristics. To make the algorithm more
robust, a second level of bootstrapping can be intro-
duced. The outer bootstrapping mechanism, called
</bodyText>
<page confidence="0.995503">
145
</page>
<bodyText confidence="0.999513">
meta-bootstrapping compiles the results of the inner
(mutual) bootstrapping process and identifies the k
most reliable heuristics, where k is a number de-
termined experimentally. These k heuristics are re-
tained and the rest of them are discarded.
</bodyText>
<sectionHeader confidence="0.999751" genericHeader="method">
3 SWIZZLE
</sectionHeader>
<subsectionHeader confidence="0.999979">
3.1 Multilingual Coreference Data
</subsectionHeader>
<bodyText confidence="0.999947310344828">
To study the performance of a data-driven multi-
lingual coreference resolution system, we prepared a
corpus of Romanian texts by translating the MUC-6
and MUC-7 coreference training texts. The transla-
tions were performed by a group of four Romanian
native speakers, and were checked for style by a cer-
tified translator from Romania. In addition, the Ro-
manian texts were annotated with coreference keys.
Two rules were followed when the annotations were
done:
01: Whenever an expression ER represents a trans-
lation of an expression ER from the corresponding
English text, if ER is tagged as a coreference key
with identification number ID, then the Romanian
expression ER is also tagged with the same ID num-
ber. This rule allows for translations in which the
textual position of the referent and the antecedent
have been swapped.
.32: Since the translations often introduce new
coreferring expressions in the same chain, the new
expressions are given new, unused ID numbers.
For example, Table 3 lists corresponding English
and Romanian fragments of coreference chains from
the original MUC-6 Wall Street Journal document
DOCNO: 930729-0143.
Table 3 also shows the original MUC coreference
SGML annotations. Whenever present, the REF tag
indicates the ID of the antecedent, whereas the MIN
tag indicates the minimal reference expression.
</bodyText>
<subsectionHeader confidence="0.999957">
3.2 Lexical Resources
</subsectionHeader>
<bodyText confidence="0.862273043478261">
The multilingual coreference resolution method im-
plemented in SWIZZLE incorporates the heuristics de-
rived from COKCTAIL&apos;s monolingual coreference res-
olution processing in both languages. To this end,
COCKTAIL required both sets of texts to be tagged
for part-of-speech and to recognize the noun phrases.
The English texts were parsed with Brill&apos;s part-of-
speech tagger (Brill 1992) and the noun phrases were
identified by the grammar rules implemented in the
phrasal parser of FASTUS (Appelt et al., 1993). Cor-
responding resources are not available in Romanian.
To minimize COCKTAIL&apos;s configuration for process-
ing Romanian texts, we implemented a Romanian
part-of-speech rule-based tagger that used the same
Economic adviser Gene Sperling described
&lt;COREF ID=&amp;quot; 29&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot; 30&amp;quot;&gt;
it&lt; /COREF&gt; as &amp;quot;a true full-court press&amp;quot; to pass
&lt;COREF ID=&amp;quot;31&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;26&amp;quot;
MIN=&amp;quot;bill&amp;quot; &gt;the &lt;COREF ID=&amp;quot; 32&amp;quot;
TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;10&amp;quot; MIN=&amp;quot;reduction&amp;quot;&gt;
&lt;COREF ID=&amp;quot; 33&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;12&amp;quot;&gt;
deficit&lt; /COREF&gt;-reduction&lt; /COREF&gt;
bill, the final version of which is now being
hammered out by &lt;COREF ID=&amp;quot; 43&amp;quot; &gt;House
&lt; /COREF&gt; and &lt;COREF ID=&amp;quot; 41&amp;quot; &gt;Senate
&lt; /COREF&gt;negotiators&lt; /COREF&gt;.
&lt;COREF ID=&amp;quot; 34&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot; 2&amp;quot;&gt;
The executives&lt; /COREF&gt;&apos; backing - however tepid
- gives the administration a way to counter
&lt;COREF ID=&amp;quot; 35&amp;quot; TYPE.&amp;quot; IDENT&amp;quot; REF=&amp;quot; 36&amp;quot;&gt;
business&lt; /COREF&gt; critics of &lt;COREF ID=&amp;quot; 500&amp;quot;
TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot; 31&amp;quot; MIN=&amp;quot; package&amp;quot;
STATUS=&amp;quot;OPT&amp;quot;&gt;the overall package
&lt; /COREF&gt;,...
Consilierul cu probleme economice Gene Sperling a
descris-&lt;COREF ID=&amp;quot; 29&amp;quot; TYPE=&amp;quot;IDENT&amp;quot;
REF=&amp;quot;30&amp;quot;&gt;o&lt; /COREF&gt; ca pe un efort de
avengurg menit sà promoveze &lt;COREF ID=&amp;quot;1125&amp;quot;
TYPE=&amp;quot; IDENT&amp;quot; REF=&amp;quot; 26&amp;quot; MIN=&amp;quot; legea&amp;quot; &gt;legea
&lt; /COREF&gt; pentru &lt;COREF TYPE=&amp;quot;IDENT&amp;quot;
REF=&amp;quot;10&amp;quot; MIN=&amp;quot;reducerea&amp;quot;&gt; reducerea
&lt; /COREF&gt; &lt;COREF ID=&amp;quot; 33&amp;quot; TYPE=&amp;quot; IDENT&amp;quot;
REF=&amp;quot;12&amp;quot;&gt; deficitului in bugetul SUA&lt; /COREF&gt;.
Versiunea finala a acestei &lt;COREF ID=&amp;quot;1126&amp;quot;
TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;1125&amp;quot; MIN=&amp;quot;legi&amp;quot;&gt;legi
&lt; /COREF&gt; este desfiintatA chiax in aceste
zile in cadrul dezbaterilor cc an loc in
&lt;COREF ID=&amp;quot;43&amp;quot; &gt;Camera Reprezentativilor
&lt; /COREF&gt; §i in &lt;COREF ID=&amp;quot;41&amp;quot;&gt;
Senat&lt; /COREF&gt;&lt; /COREF&gt;.
Sprijinirea &lt;COREF ID=&amp;quot;127&amp;quot; TYPE=&amp;quot;IDENT&amp;quot;
REF=&amp;quot;1126&amp;quot; MIN=&amp;quot;legii&amp;quot; &gt;legii&gt; /COREF&gt;
de care speciali§ti in economie - dei
in maniera,&apos; moderata - ofer5, administratiei o
modalitate de a contrabalansa criticile aduse
&lt;COREF ID=&amp;quot; 500&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot; 31&amp;quot;
MIN=&amp;quot; legii&amp;quot; STATUS=&amp;quot; OPT&amp;quot; &gt;legii&lt; /COREF&gt;
de care companiile americane,...
Table 3: Example of parallel English and Romanian
text annotated for coreference. The elements from a
coreference chain in the respective texts are under-
lined. The English text has only two elements in the
coreference chain, whereas the Romanian text con-
tains four different elements. The two additional ele-
ments of the Romanian coreference chain are derived
due to (1) the need to translate the relative clause
from the English fragment into a separate sentence
in Romanian; and (2) the reordering of words in the
second sentence.
</bodyText>
<page confidence="0.997818">
146
</page>
<bodyText confidence="0.999409692307692">
tags as generated by the Brill tagger. In addition,
we implemented rules that identify noun phrases in
Romanian.
To take advantage of the aligned corpus, SWIZZLE
also relied on bilingual lexical resources that help
translate the referential expressions. For this
purpose, we used a core Romanian WordNet
(Harabagiu, 1999) which encoded, wherever possi-
ble, links between the English synsets and their Ro-
manian counterparts. This resource also incorpo-
rated knowledge derived from several bilingual dic-
tionaries (e.g. (Banta, 1969)).
Having the parallel coreference annotations, we
can easily identify their translations because they
have the same identification coreference key. Look-
ing at the example given in Table 3, the expres-
sion &amp;quot;legii&amp;quot;, with ID=500 is the translation of the
expression &amp;quot;package&amp;quot;, having the same ID in the
English text. However, in the test set, the REF
fields are intentionally voided, entrusting COCKTAIL
to identify the antecedents. The bilingual corefer-
ence resolution performed in SWIZZLE, however, re-
quires the translations of the English and Romanian
antecedents. The principles guiding the translations
of the English and Romanian antecedents (AE—R
and AR—E, respectively) are:
</bodyText>
<listItem confidence="0.965377181818182">
• Circularity: Given an English antecedent, due to
semantic ambiguity, it can belong to several English
WordNet sysnsets. For each such sysnset ST we con-
sider the Romanian corresponding sysnet(s) SJ. We
filter out all Sr that do not contain AE—R. If only
one Romanian sysnset is left, then we identified a
translation. Otherwise, we start from the Roma-
nian antecedent, find all synsets Sf to which it be-
longs, and obtain the corresponding English sysnets
sr. Similarly, all English synsets not containing
the English antecedent are filtered out. If only one
synset remains, we have again identified a transla-
tion. Finally, in the last case, the intersection of
the multiple synsets in either language generates a
legal translation. For example, the English synset
SE .{bill, measure} translates into the Romanian
synset SR =flegel. First, none of the dictionary
translations of bill into Romanian (e.g. politd, bac-
notd, aM translate back into any of the elements
of SE. However the translation of measure into the
Romanian lege translates back into bill, its synonym.
• Semantic density: Given an English and a Roma-
</listItem>
<bodyText confidence="0.9214338">
nian antecedent, to establish whether they are trans-
lations of one another, we disambiguate them by first
collapsing all sysnsets that have common elements.
Then we apply the circularity principle, relying on
the semantic alignment encoded in the Romanian
WordNet. When this core lexical database was first
implemented, several other principles were applied.
In our experiment, we were satisfied with the qual-
ity of the translations recognized by following only
these two principles.
</bodyText>
<subsectionHeader confidence="0.999005">
3.3 Multilingual Coreference Resolution
</subsectionHeader>
<bodyText confidence="0.962955">
The SWIZZLE system was run on a corpus of 2335
referential expressions in English (927 from MUC-
6 and 1408 from MUC-7) and 2851 Romanian ex-
pressions (1219 from MUC-6 and 1632 from MUC-
7). Initially, the heuristics implemented in COCKTAIL
were applied separately to the two textual collec-
tions. Several special cases arose.
</bodyText>
<figure confidence="0.880457666666667">
English Text
Translation
Translation
</figure>
<figureCaption confidence="0.8818359">
Figure 3: Case 1 of multilingual coreference
Case I, which is the ideal case, is shown in Fig-
ure 3. It occurs when two referential expressions
have antecedents that are translations of one an-
other. This situation occurred in 63.3% of the refer-
ential expressions from MUC-6 and in 58.7% of the
MUC-7 references. Over 50% of these are pronouns
or named entities. However, all the non-ideal cases
are more interesting for SWIZZLE, since they port
knowledge that enhances system performance.
</figureCaption>
<figure confidence="0.340901">
English Text
ER: English reference RR: Romanian reference
EA: English antecedent RA: Romanian antecedent
ET: English translation RT: Romanian translation
of Romanian antecedent of English antecedent
</figure>
<figureCaption confidence="0.7923686">
Figure 4: Case 2 of multilingual coreference
Case 2 occurs when the antecedents are not trans-
lations, but belong to or corefer with elements of
some coreference chains that were already estab-
lished. Moreover, one of the antecedents is textually
</figureCaption>
<figure confidence="0.787296">
Romanian Text
Coref.
chains Romanian Text
</figure>
<page confidence="0.991663">
147
</page>
<bodyText confidence="0.996266185185185">
closer to its referent. Figure 4 illustrates the case
when the English antecedent is closer to the referent
than the Romanian one.
SWIZZLE Solutions: (1) If the heuristic H(E) used
to resolve the reference in the English text has higher
priority than H(R), which was used to resolve the
reference from the Romanian text, then we first
search for RT, the Romanian translation of EA, the
English antecedent. In the next step, we add heuris-
tic H1 that resolves RR into RT, and give it a higher
priority than H(R). Finally, we also add heuristic H2
that links RT to RA when there is at least one trans-
lation between the elements of the coreference chains
containing EA and ET respectively.
(2) If H(R) has higher priority than H(E), heuris-
tic H3 is added while H(E) is removed. We also add
H4 that relates ER to ET, the English translation of
RA.
Case 3 occurs when at least one of the antecedents
starts a new coreference chain (i.e., no coreferring
antecedent can be found in the current chains).
SWIZZLE Solution: If one of the antecedents
corefers with an element from a coreference chain,
then the antecedent in the opposite language is its
translation. Otherwise, SWIZZLE chooses the an-
tecedent returned by the heuristic with highest pri-
ority.
</bodyText>
<sectionHeader confidence="0.999978" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999809285714286">
The foremost contribution of SWIZZLE was that it
improved coreference resolution over both English
and Romanian texts when compared to monolingual
coreference resolution performance in terms of preci-
sion and recall. Also relevant was the contribution of
SWIZZLE to the process of understanding the cultural
differences expressed in language and the way these
differences influence coreference resolution. Because
we do not have sufficient space to discuss this issue
in detail here, let us state, in short, that English is
more economical than Romanian in terms of referen-
tial expressions. However the referential expressions
in Romanian contribute to the resolution of some of
the most difficult forms of coreference in English.
</bodyText>
<subsectionHeader confidence="0.982347">
4.1 Precision and Recall
</subsectionHeader>
<bodyText confidence="0.9949323">
Table 4 summarizes the precision results for both
English and Romanian coreference. The results in-
dicate that the English coreference is more pre-
cise than the Romanian coreference, but SWIZZLE
improves coreference resolution in both languages.
There were 64% cases when the English coreference
was resolved by a heuristic with higher priority than
the corresponding heuristic for the Romanian coun-
terpart. This result explains why there is better pre-
cision enhancement for the English coreference.
</bodyText>
<table confidence="0.999624285714286">
Nominal Pronominal Total
English 73% 89% 84%
Romanian 66% 78% 72%
SWIZZLE on 76% 93% 87%
English
SWIZZLE on 71% 82% 76%
Romanian
</table>
<tableCaption confidence="0.929765">
Table 4: Coreference precision
</tableCaption>
<table confidence="0.999873857142857">
Nominal Pronominal Total
English 69% 89% 78%
Romanian 63% 83% 72%
SWIZZLE on 66% 87% 77%
English
SWIZZLE on 61% 80% 70%
Romanian
</table>
<tableCaption confidence="0.998066">
Table 5: Coreference recall
</tableCaption>
<bodyText confidence="0.981222">
Table 5 also illustrates the recall results. The
advantage of the data-driven coreference resolution
over other methods is based on its better recall per-
formance. This is explained by the fact that this
method captures a larger variety of coreference pat-
terns. Even though other coreference resolution sys-
tems perform better for some specific forms of refer-
ence, their recall results are surpassed by the data-
driven approach. Multilingual coreference in turn
improves more the precision than the recall of the
monolingual data-driven coreference systems.
In addition, Table 5 shows that the English coref-
erence results in better recall than Romanian coref-
erence. However, the recall shows a decrease for both
languages for SWIZZLE because imprecise coreference
links are deleted. As is usually the case, deleting
data lowers the recall. All results were obtained by
using the automatic scorer program developed for
the MUC evaluations.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999779076923077">
We have introduced a new data-driven method for
multilingual coreference resolution, implemented in
the SWIZZLE system. The results of this method
are encouraging since they show clear improvements
over monolingual coreference resolution. Currently,
we are also considering the effects of a bootstrap-
ping algorithm for multilingual coreference resolu-
tion. Through this procedure we would learn con-
currently semantic consistency knowledge and bet-
ter performing heuristic rules. To be able to de-
velop such a learning approach, we must first develop
a method for automatic recognition of multilingual
referential expressions.
</bodyText>
<page confidence="0.994738">
148
</page>
<bodyText confidence="0.999371333333333">
We also believe that a better performance evalu-
ation of SWIZZLE can be achieved by measuring its
impact on several complex applications. We intend
to analyze the performance of SWIZZLE when it is
used as a module in an IE system, and separately in
a Question/Answering system.
Acknowledgements This paper is dedicated to the
memory of our friend Megumi Kameyama, who in-
spired this work.
</bodyText>
<sectionHeader confidence="0.998382" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999849086956522">
Douglas E. Appelt, Jerry R. Hobbs, John Bear, David
Israel, Megumi Kameyama and Mabry Tyson. 1993.
The SRI MUC-5 JV-FASTUS Information Extraction
System. In Proceedings of the Fifth Message Under-
standing Conference (MUC-5).
Brack Baldwin. 1997. CogNIAC: high precision corefer-
ence with limited knowledge and linguistic resources.
In Proceedings of the ACL&apos;97/EACL &apos;97 Workshop on
Operational factors in practical, robust anaphora res-
olution, pages 38-45, Madrid, Spain.
Andrei Banta. 1969. Diction&amp; Roman-Englez, Enlgez-
Roman. Editura Wintifica, Bucuresti.
David Bean and Ellen Riloff. 1999. Corpus-Based Iden-
tification of Non-Anaphoric Noun Phrases. In Pro-
ceedings of the 37th Conference of the Assosiation for
Computatioanl Linguistics (ACL-99), pages 373-380.
Eric Brill. A simple rule-based part of speech tagger. In
Proceedings of the Third Conference on Applied Nat-
ural Language Processing, pages 152-155,1992.
Joseph F. Cameron-Jones and Ross Quinlan. 1993.
Avoiding Pitfalls When Learning Recursive Theories.
In Proceedings of the 13th International Joint Confer-
ence on Artificial Intelligence (IJCAI-93), pages 1050-
1055.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the Joint
Conference on Empirical Methods in NLP and Very
Large Corpora, pages 82-89.
Niyu Ge, John Gale and Eugene Charniak. 1998.
Anaphora Resolution: A Multi-Strategy Approach. In
Proceedings of the 6th Workshop on Very Large Cor-
pora, ( COLING /A CL &apos;98).
Ido Dagan and Ken W. Church. 1994. TERMIGHT:
Identifying and translating technical terminology. In
Proceedings of the 4th ACL Conference on Applied
Natural Language Processing (ANLP-94).
Sanda M. Harabagiu. 1999. Lexical Acquisition for a
Romanian WordNet. Proceeding of the 3rd European
Summer School on Computational Linguistics.
Sanda M. Harabagiu and Steve J. Maiorano. 1999.
Knowledge-Lean Coreference Resolution and its Re-
lation to Textual Cohesion and Coherence. In Pro-
ceedings of the Workshop on the Relation of Dis-
course/Dialogue Structure and Reference, ACL &apos;98,
pages 29-38.
Jerry R. Hobbs. Resolving pronoun references. Lingua,
44:311-338.
Andrew Kehler. 1997. Probabilistic Coreference in In-
formation Extraction. In Proceedings of the Second
Conference on Empirical Methods in Natural Lan-
guage Processing (SIGDAT), pages 163-173.
Shalom Lappin and Herbert Leass. 1994. An algorithm
for pronominal anaphora resolution. Computational
Linguistics, 20(4):535-562.
Rosie Jones, Andrew McCallum, Kevin Nigam and Ellen
Riloff. 1999. Bootstrapping for Text Learning Tasks.
In Proceedings of the IJCAI-99 Workshop on Text
Mining: Foundations, Techniques, and Applications.
Megumi Kameyama. 1997. Recognizing Referential
Links: An Information Extraction Perspective. In
Proceedings of the Workshop on Operational Factors
in Practical, Robust Anaphora Resolution for Un-
restricted Texts, (ACL-97/EACL-97), pages 46-53,
Madrid, Spain.
Christopher Kennedy and Branimir Bogureav. 1996.
Anaphora for everyone: Pronominal anaphora reso-
lution without a parser. In Proceedings of the 16th
International Conference on Computational Linguis-
tics (COLING-96).
George A. Miller. 1995. WordNet: A Lexical Database.
Communication of the ACM, 38 (11) :39-41.
Ruslan Mitkov. 1998. Robust pronoun resolution
with limited knowledge. In Proceedings of COLING-
ACL &apos;98, pages 869-875.
1996. Proceedings of the Sixth Message Understanding
Conference (MUC-6),Morgan Kaufmann, San Mateo,
CA.
1998. Proceedings of the Seventh Message Understand-
ing Conference (MUC-7) ,Morgan Kaufmann, San
Mateo, CA.
Philip Resnik and I. Dan Melamed. 1997. Semi-
Automatic Acquisition of Domain-Specific Translation
Lexicons. In Proceedings of the 5th ACL Conference
on Applied Natural Language Processing (ANLP-97).
Ellen Riloff and Rosie Jones. 1999. Learning Dictionar-
ies for Information Extraction by Multi-Level Boot-
strapping. In Proceedings of the Sixteenth National
Conference on Artificial Intelligence (AAAI-99).
Frank Smadja, Katheleen R. McKeown and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: A statistical approach. Computa-
tional Linguistics , 21(1):1-38.
</reference>
<page confidence="0.998961">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.507373">
<title confidence="0.999279">Multilingual Coreference Resolution</title>
<author confidence="0.999988">Sanda M Harabagiu Steven J Maiorano</author>
<affiliation confidence="0.993934">Southern Methodist University IPO</affiliation>
<address confidence="0.92391">Dallas, TX 75275-0122 Washington, D.C. 20505</address>
<author confidence="0.59526">oranoc ai s</author>
<abstract confidence="0.991131333333333">In this paper we present a new, multilingual data-driven method for coreference resolution as implemented in the SWIZZLE system. The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
<author>Jerry R Hobbs</author>
<author>John Bear</author>
<author>David Israel</author>
<author>Megumi Kameyama</author>
<author>Mabry Tyson</author>
</authors>
<date>1993</date>
<booktitle>The SRI MUC-5 JV-FASTUS Information Extraction System. In Proceedings of the Fifth Message Understanding Conference (MUC-5).</booktitle>
<contexts>
<context position="19568" citStr="Appelt et al., 1993" startWordPosition="3006" endWordPosition="3009">tes the ID of the antecedent, whereas the MIN tag indicates the minimal reference expression. 3.2 Lexical Resources The multilingual coreference resolution method implemented in SWIZZLE incorporates the heuristics derived from COKCTAIL&apos;s monolingual coreference resolution processing in both languages. To this end, COCKTAIL required both sets of texts to be tagged for part-of-speech and to recognize the noun phrases. The English texts were parsed with Brill&apos;s part-ofspeech tagger (Brill 1992) and the noun phrases were identified by the grammar rules implemented in the phrasal parser of FASTUS (Appelt et al., 1993). Corresponding resources are not available in Romanian. To minimize COCKTAIL&apos;s configuration for processing Romanian texts, we implemented a Romanian part-of-speech rule-based tagger that used the same Economic adviser Gene Sperling described &lt;COREF ID=&amp;quot; 29&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot; 30&amp;quot;&gt; it&lt; /COREF&gt; as &amp;quot;a true full-court press&amp;quot; to pass &lt;COREF ID=&amp;quot;31&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;26&amp;quot; MIN=&amp;quot;bill&amp;quot; &gt;the &lt;COREF ID=&amp;quot; 32&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;10&amp;quot; MIN=&amp;quot;reduction&amp;quot;&gt; &lt;COREF ID=&amp;quot; 33&amp;quot; TYPE=&amp;quot;IDENT&amp;quot; REF=&amp;quot;12&amp;quot;&gt; deficit&lt; /COREF&gt;-reduction&lt; /COREF&gt; bill, the final version of which is now being hammered out by &lt;COREF ID=&amp;quot; 43&amp;quot; &gt;House</context>
</contexts>
<marker>Appelt, Hobbs, Bear, Israel, Kameyama, Tyson, 1993</marker>
<rawString>Douglas E. Appelt, Jerry R. Hobbs, John Bear, David Israel, Megumi Kameyama and Mabry Tyson. 1993. The SRI MUC-5 JV-FASTUS Information Extraction System. In Proceedings of the Fifth Message Understanding Conference (MUC-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brack Baldwin</author>
</authors>
<title>CogNIAC: high precision coreference with limited knowledge and linguistic resources.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL&apos;97/EACL &apos;97 Workshop on Operational factors in practical, robust anaphora resolution,</booktitle>
<pages>38--45</pages>
<location>Madrid,</location>
<contexts>
<context position="3685" citStr="Baldwin, 1997" startWordPosition="530" endWordPosition="531">stics for coreference. Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents. The rest of the paper is organized as follows. Section 2 presents COCKTAIL, a monolingual coreference resolution system used separately on both the English and Romanian texts. Section 3 details the data-driven approach used in SWIZZLE and presents some of its resources. Section 4 reports and discusses the experimental results. Section 5 summarizes the &apos;The name of COCKTAIL is a pun on CogNIAC because COCKTAIL combines a larger number of heuristics than those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIA</context>
</contexts>
<marker>Baldwin, 1997</marker>
<rawString>Brack Baldwin. 1997. CogNIAC: high precision coreference with limited knowledge and linguistic resources. In Proceedings of the ACL&apos;97/EACL &apos;97 Workshop on Operational factors in practical, robust anaphora resolution, pages 38-45, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Banta</author>
</authors>
<date>1969</date>
<booktitle>Diction&amp; Roman-Englez, EnlgezRoman. Editura Wintifica,</booktitle>
<location>Bucuresti.</location>
<contexts>
<context position="22574" citStr="Banta, 1969" startWordPosition="3447" endWordPosition="3448">e sentence in Romanian; and (2) the reordering of words in the second sentence. 146 tags as generated by the Brill tagger. In addition, we implemented rules that identify noun phrases in Romanian. To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions. For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possible, links between the English synsets and their Romanian counterparts. This resource also incorporated knowledge derived from several bilingual dictionaries (e.g. (Banta, 1969)). Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key. Looking at the example given in Table 3, the expression &amp;quot;legii&amp;quot;, with ID=500 is the translation of the expression &amp;quot;package&amp;quot;, having the same ID in the English text. However, in the test set, the REF fields are intentionally voided, entrusting COCKTAIL to identify the antecedents. The bilingual coreference resolution performed in SWIZZLE, however, requires the translations of the English and Romanian antecedents. The principles guiding the translat</context>
</contexts>
<marker>Banta, 1969</marker>
<rawString>Andrei Banta. 1969. Diction&amp; Roman-Englez, EnlgezRoman. Editura Wintifica, Bucuresti.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bean</author>
<author>Ellen Riloff</author>
</authors>
<title>Corpus-Based Identification of Non-Anaphoric Noun Phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Conference of the Assosiation for Computatioanl Linguistics (ACL-99),</booktitle>
<pages>373--380</pages>
<marker>Bean, Riloff, 1999</marker>
<rawString>David Bean and Ellen Riloff. 1999. Corpus-Based Identification of Non-Anaphoric Noun Phrases. In Proceedings of the 37th Conference of the Assosiation for Computatioanl Linguistics (ACL-99), pages 373-380.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing,</booktitle>
<pages>152--155</pages>
<marker>Brill, </marker>
<rawString>Eric Brill. A simple rule-based part of speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, pages 152-155,1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph F Cameron-Jones</author>
<author>Ross Quinlan</author>
</authors>
<title>Avoiding Pitfalls When Learning Recursive Theories.</title>
<date>1993</date>
<booktitle>In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93),</booktitle>
<pages>1050--1055</pages>
<contexts>
<context position="15472" citStr="Cameron-Jones and Quinlan 1993" startWordPosition="2354" endWordPosition="2357"> of data for a new heuristic rule. In COCKTAIL, after a heuristic is applied, a new coreference chain is calculated. For the example illustrated in Figure 2, if the reference of expression A is sought, heuristic R1 indicates expression B to be the antecedent. When the coreference chain is built, expression A is directly linked to expression D, thus uncovering a new heuristic HO. As a rule of thumb, we do not consider a new heuristic unless there is massive evidence of its coverage in the data. To measure the coverage we use the FOIL_Gain measure, as introduced by the FOIL inductive algorithm (Cameron-Jones and Quinlan 1993). Let Ho be the new heuristic and Hi a heuristic that is already in the seed set. Let po be the number of positive coreference examples of Hne. (i.e. the number of coreference relations produced by the heuristic that can be found in the test data) and no the number of negative examples of Hneu, (i.e. the number of relations generated by the heuristic which cannot be found in the test data). Similarly, pi and ni are the positive and negative examples of Hi. The new heuristics are scored by their FOIL_Gain distance to the existing set of heuristics, and the best scoring one is added to the COCKT</context>
</contexts>
<marker>Cameron-Jones, Quinlan, 1993</marker>
<rawString>Joseph F. Cameron-Jones and Ross Quinlan. 1993. Avoiding Pitfalls When Learning Recursive Theories. In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93), pages 1050-1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Kiri Wagstaff</author>
</authors>
<title>Noun phrase coreference as clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora,</booktitle>
<pages>82--89</pages>
<marker>Cardie, Wagstaff, 1999</marker>
<rawString>Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora, pages 82-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niyu Ge</author>
<author>John Gale</author>
<author>Eugene Charniak</author>
</authors>
<title>Anaphora Resolution: A Multi-Strategy Approach.</title>
<date>1998</date>
<booktitle>In Proceedings of the 6th Workshop on Very Large Corpora, ( COLING /A CL &apos;98).</booktitle>
<marker>Ge, Gale, Charniak, 1998</marker>
<rawString>Niyu Ge, John Gale and Eugene Charniak. 1998. Anaphora Resolution: A Multi-Strategy Approach. In Proceedings of the 6th Workshop on Very Large Corpora, ( COLING /A CL &apos;98).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Ken W Church</author>
</authors>
<title>TERMIGHT: Identifying and translating technical terminology.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th ACL Conference on Applied Natural Language Processing (ANLP-94).</booktitle>
<contexts>
<context position="883" citStr="Dagan and Church, 1994" startWordPosition="123" endWordPosition="126"> method for coreference resolution as implemented in the SWIZZLE system. The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages. 1 Introduction The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing. Most of the research has focused on bilingual terminology identification, either as parallel multiwords forms (e.g. the Champolhon system (Smadja et al.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)). In addition, the Multilingual Entity Task (MET) from the TIPSTER program&apos; (http://www-nipir.nist.gov/relatedprojects/tipster/met.htm) challenged the participants in the Message Understanding Conference (MUC) to extract named entities across several foreign language corpora, such as Chinese, Japanese and Spanish. In this paper we present a new application of aligned multilingual texts. Since coreference resolution is a pervasive discourse phenomenon causing performance impediments in current IE systems, </context>
</contexts>
<marker>Dagan, Church, 1994</marker>
<rawString>Ido Dagan and Ken W. Church. 1994. TERMIGHT: Identifying and translating technical terminology. In Proceedings of the 4th ACL Conference on Applied Natural Language Processing (ANLP-94).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
</authors>
<title>Lexical Acquisition for a Romanian WordNet.</title>
<date>1999</date>
<booktitle>Proceeding of the 3rd European Summer School on Computational Linguistics.</booktitle>
<contexts>
<context position="22367" citStr="Harabagiu, 1999" startWordPosition="3417" endWordPosition="3418">nian text contains four different elements. The two additional elements of the Romanian coreference chain are derived due to (1) the need to translate the relative clause from the English fragment into a separate sentence in Romanian; and (2) the reordering of words in the second sentence. 146 tags as generated by the Brill tagger. In addition, we implemented rules that identify noun phrases in Romanian. To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions. For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possible, links between the English synsets and their Romanian counterparts. This resource also incorporated knowledge derived from several bilingual dictionaries (e.g. (Banta, 1969)). Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key. Looking at the example given in Table 3, the expression &amp;quot;legii&amp;quot;, with ID=500 is the translation of the expression &amp;quot;package&amp;quot;, having the same ID in the English text. However, in the test set, the REF fields are intentionally voided, entrusting C</context>
</contexts>
<marker>Harabagiu, 1999</marker>
<rawString>Sanda M. Harabagiu. 1999. Lexical Acquisition for a Romanian WordNet. Proceeding of the 3rd European Summer School on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Steve J Maiorano</author>
</authors>
<title>Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence.</title>
<date>1999</date>
<booktitle>In Proceedings of the Workshop on the Relation of Discourse/Dialogue Structure and Reference, ACL &apos;98,</booktitle>
<pages>29--38</pages>
<contexts>
<context position="2679" citStr="Harabagiu and Maiorano, 1999" startWordPosition="377" endWordPosition="380"> into Romanian using native speakers. The training data set for Romanian coreference used, wherever possible, the same coreference identifiers as the English data and incorporated additional tags as needed. Our claim is that by adding the wealth of coreferential features provided by multilingual data, new powerful heuristics for coreference resolution can be developed that outperform monolingual coreference resolution systems. For both languages, we resolved coreference by using SWIZZLE, our implementation of a bilingual coreference resolver. SWIZZLE is a multilingual enhancement of COCKTAIL (Harabagiu and Maiorano, 1999), a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information&apos;. When COCKTAIL was applied separately on the English and the Romanian texts, coreferring links were identified for each English and Romanian document respectively. When aligned referential expressions corefer with non-aligned anaphors, SWIZZLE derived new heuristics for coreference. Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents. The rest of the paper is organized as follows. Section 2 presents COCKTAIL, a monoli</context>
<context position="4525" citStr="Harabagiu and Maiorano, 1999" startWordPosition="638" endWordPosition="641">owledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of communication verbs are more likely to refer to the last person mentioned in the text). These constraints are implemented as a set of heuristics ordered by their priority. Moreover, the COCKTAIL framework uniformly addresses the problem of interaction between different forms of coreference, thus making the extens</context>
<context position="13349" citStr="Harabagiu and Maiorano, 1999" startWordPosition="2028" endWordPosition="2031">their nominalizations. On other occasions, coercions are obtained as paths of meronyms (e.g. is-part relations) and hypernyms (e.g. is-a relations). Con144 sistency checks implemented for this class of coreference are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent. Table 1 lists the top performing heuristics of COCKTAIL for pronominal and nominal coreference. Examples of the heuristics operation on the MUC data are presented presented in Table 2. Details of the top performing heuristics of COCKTAIL were reported in (Harabagiu and Maiorano, 1999). 2.3 Bootstrapping for Coreference Resolution One of the major drawbacks of existing coreference resolution systems is their inability to recognize many forms of coreference displayed by many real-world texts. Recall measures of current systems range between 36% and 59% for both knowledgebased and statistical techniques. Knowledge basedsystems would perform better if more coreference constraints were available whereas statistical methods would be improved if more annotated data were available. Since knowledge-based techniques outperform inductive methods, we used high-precision coreference he</context>
</contexts>
<marker>Harabagiu, Maiorano, 1999</marker>
<rawString>Sanda M. Harabagiu and Steve J. Maiorano. 1999. Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence. In Proceedings of the Workshop on the Relation of Discourse/Dialogue Structure and Reference, ACL &apos;98, pages 29-38.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<journal>Lingua,</journal>
<pages>44--311</pages>
<marker>Hobbs, </marker>
<rawString>Jerry R. Hobbs. Resolving pronoun references. Lingua, 44:311-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
</authors>
<title>Probabilistic Coreference in Information Extraction.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (SIGDAT),</booktitle>
<pages>163--173</pages>
<marker>Kehler, 1997</marker>
<rawString>Andrew Kehler. 1997. Probabilistic Coreference in Information Extraction. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (SIGDAT), pages 163-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosie Jones</author>
<author>Andrew McCallum</author>
<author>Kevin Nigam</author>
<author>Ellen Riloff</author>
</authors>
<title>Bootstrapping for Text Learning Tasks.</title>
<date>1999</date>
<booktitle>In Proceedings of the IJCAI-99 Workshop on Text Mining: Foundations, Techniques, and Applications.</booktitle>
<marker>Jones, McCallum, Nigam, Riloff, 1999</marker>
<rawString>Rosie Jones, Andrew McCallum, Kevin Nigam and Ellen Riloff. 1999. Bootstrapping for Text Learning Tasks. In Proceedings of the IJCAI-99 Workshop on Text Mining: Foundations, Techniques, and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>Recognizing Referential Links: An Information Extraction Perspective.</title>
<date>1997</date>
<booktitle>In Proceedings of the Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts, (ACL-97/EACL-97),</booktitle>
<pages>46--53</pages>
<location>Madrid,</location>
<contexts>
<context position="4263" citStr="Kameyama, 1997" startWordPosition="603" endWordPosition="604">han those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of communication verbs are more likely to refer to the </context>
</contexts>
<marker>Kameyama, 1997</marker>
<rawString>Megumi Kameyama. 1997. Recognizing Referential Links: An Information Extraction Perspective. In Proceedings of the Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts, (ACL-97/EACL-97), pages 46-53, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Bogureav</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</booktitle>
<marker>Kennedy, Bogureav, 1996</marker>
<rawString>Christopher Kennedy and Branimir Bogureav. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A Lexical Database.</title>
<date>1995</date>
<journal>Communication of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<pages>39--41</pages>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A Lexical Database. Communication of the ACM, 38 (11) :39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of COLINGACL &apos;98,</booktitle>
<pages>869--875</pages>
<contexts>
<context position="4216" citStr="Mitkov, 1998" startWordPosition="597" endWordPosition="598">TAIL combines a larger number of heuristics than those reported in (Baldwin, 1997). SWIZZLE, moreover, adds new heuristics, discovered from the bilingual aligned corpus. 142 conclusions. 2 COCKTAIL Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques. Traditionally, these techniques have combined extensive syntactic, semantic, and discourse knowledge. The acquisition of such knowledge is time-consuming, difficult, and error-prone. Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf. (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)). For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. For this research, we used a coreference resolution system ((Harabagiu and Maiorano, 1999)) that implements different sets of heuristics corresponding to various forms of coreference. This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of commu</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of COLINGACL &apos;98, pages 869-875.</rawString>
</citation>
<citation valid="true">
<date>1996</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference (MUC-6),Morgan Kaufmann,</booktitle>
<location>San Mateo, CA.</location>
<marker>1996</marker>
<rawString>1996. Proceedings of the Sixth Message Understanding Conference (MUC-6),Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference (MUC-7)</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<marker>1998</marker>
<rawString>1998. Proceedings of the Seventh Message Understanding Conference (MUC-7) ,Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>I Dan Melamed</author>
</authors>
<title>SemiAutomatic Acquisition of Domain-Specific Translation Lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th ACL Conference on Applied Natural Language Processing (ANLP-97).</booktitle>
<contexts>
<context position="972" citStr="Resnik and Melamed, 1997" startWordPosition="135" endWordPosition="138">tained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the individual languages. 1 Introduction The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing. Most of the research has focused on bilingual terminology identification, either as parallel multiwords forms (e.g. the Champolhon system (Smadja et al.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)). In addition, the Multilingual Entity Task (MET) from the TIPSTER program&apos; (http://www-nipir.nist.gov/relatedprojects/tipster/met.htm) challenged the participants in the Message Understanding Conference (MUC) to extract named entities across several foreign language corpora, such as Chinese, Japanese and Spanish. In this paper we present a new application of aligned multilingual texts. Since coreference resolution is a pervasive discourse phenomenon causing performance impediments in current IE systems, we considered a corpus of aligned English and Romanian texts to identify coreferring expr</context>
</contexts>
<marker>Resnik, Melamed, 1997</marker>
<rawString>Philip Resnik and I. Dan Melamed. 1997. SemiAutomatic Acquisition of Domain-Specific Translation Lexicons. In Proceedings of the 5th ACL Conference on Applied Natural Language Processing (ANLP-97).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99).</booktitle>
<contexts>
<context position="14150" citStr="Riloff and Jones 1999" startWordPosition="2143" endWordPosition="2146">layed by many real-world texts. Recall measures of current systems range between 36% and 59% for both knowledgebased and statistical techniques. Knowledge basedsystems would perform better if more coreference constraints were available whereas statistical methods would be improved if more annotated data were available. Since knowledge-based techniques outperform inductive methods, we used high-precision coreference heuristics as knowledge seeds for machine learning techniques that operate on large amounts of unlabeled data. One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et al.1999) as an ideal framework for text learning tasks that have knowledge seeds. The method does not require large training sets. We extended COCKTAIL by using metabootstrapping of both new heuristics and clusters of nouns that display semantic consistency for coreference. The coreference heuristics are the seeds of our bootstrapping framework for coreference resolution. When applied to large collections of texts, the heuristics determine classes of coreferring expressions. By generating coreference chains out of all these coreferring expressions, often new heuristics are uncovere</context>
<context position="17133" citStr="Riloff and Jones 1999" startWordPosition="2629" endWordPosition="2632">asses, each new heuristic determines the adjustment of the similarity threshold of all known coreferring noun classes. The steps of the bootstrapping algorithm that learns both new heuristics and adjusts the similarity threshold of coreferential expressions is: MUTUAL BOOTSTRAPPING LOOP I. Score all candidate heuristics with FOIL_Gain 2. Best_h=closest candidate to heuristics(COCKTAIL) 3. Add Best_h to heuristics(COCKTAIL) 4. Adjust semantic similarity threshold for semantic consistency of coreferring nouns 5. Goto step 1 if the precision and recall did not degrade under minimal performance. (Riloff and Jones 1999) note that the bootstrapping algorithm works well but its performance can deteriorate rapidly when non-coreferring data enter as candidate heuristics. To make the algorithm more robust, a second level of bootstrapping can be introduced. The outer bootstrapping mechanism, called 145 meta-bootstrapping compiles the results of the inner (mutual) bootstrapping process and identifies the k most reliable heuristics, where k is a number determined experimentally. These k heuristics are retained and the rest of them are discarded. 3 SWIZZLE 3.1 Multilingual Coreference Data To study the performance of</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Katheleen R McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<booktitle>Computational Linguistics ,</booktitle>
<pages>21--1</pages>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Smadja, Katheleen R. McKeown and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational Linguistics , 21(1):1-38.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>