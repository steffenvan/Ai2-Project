<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000801">
<title confidence="0.994974">
Automatic construction of parallel English-Chinese corpus for
cross-language information retrieval
</title>
<author confidence="0.836042">
Jiang Chen and Jian-Yun Nie
</author>
<affiliation confidence="0.6739135">
Departement d&apos;Informatique et Recherche Operationnelle
Universite de Montréal
</affiliation>
<address confidence="0.584514">
C.P. 6128, succursale CENTRE-VILLE
Montreal (Quebec), Canada H3C 3J7
</address>
<email confidence="0.996004">
{chen, nie}@iro.umontreal.ca
</email>
<sectionHeader confidence="0.993804" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999817">
A major obstacle to the construction of a probabilis-
tic translation model is the lack of large parallel cor-
pora. In this paper we first describe a parallel text
mining system that finds parallel texts automatically
on the Web. The generated Chinese-English paral-
lel corpus is used to train a probabilistic translation
model which translates queries for Chinese-English
cross-language information retrieval (CLIR). We will
discuss some problems in translation model training
and show the preliminary CUR results.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953774193548">
Parallel texts have been used in a number of studies
in computational linguistics. Brown et al. (1993)
defined a series of probabilistic translation models
for MT purposes. While people may question the
effectiveness of using these models for a full-blown
MT system, the models are certainly valuable for de-
veloping translation assistance tools. For example,
we can use such a translation model to help com-
plete target text being drafted by a human transla-
tor (Langlais et al., 2000).
Another utilization is in cross-language informa-
tion retrieval (CUR) where queries have to be trans-
lated from one language to another language in
which the documents are written. In CUR, the qual-
ity requirement for translation is relatively low. For
example, the syntactic aspect is irrelevant. Even if
the translated word is not a true translation but is
strongly related to the original query, it is still help-
ful. Therefore, CUR is a suitable application for
such a translation model.
However, a major obstacle to this approach is the
lack of parallel corpora for model training. Only
a few such corpora exist, including the Hansard
English-French corpus and the HKUST English-
Chinese corpus (Wu, 1994). In this paper, we will
describe a method which automatically searches for
parallel texts on the Web. We will discuss the text
mining algorithm we adopted, some issues in trans-
lation model training using the generated parallel
corpus, and finally the translation model&apos;s perfor-
mance in CUR.
</bodyText>
<sectionHeader confidence="0.973491" genericHeader="method">
2 Parallel Text Mining Algorithm
</sectionHeader>
<bodyText confidence="0.997741347826087">
The PTMiner system is an intelligent Web agent
that is designed to search for large amounts of paral-
lel text on the Web. The mining algorithm is largely
language independent. It can thus be adapted to
other language pairs with only minor modifications.
Taking advantage of Web search engines as much
as possible, PTMiner implements the following steps
(illustrated in Fig. 1):
1 Search for candidate sites — Using existing Web
search engines, search for the candidate sites
that may contain parallel pages;
2 File name fetching — For each candidate site,
fetch the URLs of Web pages that are indexed
by the search engines;
3 Host crawling — Starting from the URLs col-
lected in the previous step, search through each
candidate site separately for more URLs;
4 Pair scan — From the obtained URLs of each
site, scan for possible parallel pairs;
5 Download and verifying — Download the parallel
pages, determine file size, language, and charac-
ter set of each page, and filter out non-parallel
pairs.
</bodyText>
<subsectionHeader confidence="0.970121">
2.1 Search for candidate Sites
</subsectionHeader>
<bodyText confidence="0.999949916666667">
We take advantage of the huge number of Web sites
indexed by existing search engines in determining
candidate sites. This is done by submitting some
particular requests to the search engines. The re-
quests are determined according to the following ob-
servations. In the sites where parallel text exists,
there are normally some pages in one language con-
taining links to the parallel version in the other lan-
guage. These are usually indicated by those links&apos;
anchor texts 1. For example, on some English page
there may be a link to its Chinese version with
the anchor text &amp;quot;Chinese Version&amp;quot; or &amp;quot;in Chinese&amp;quot;.
</bodyText>
<footnote confidence="0.99926975">
1 An anchor text is a piece of text on a Web page which,
when clicked on, will take you to another linked page. To
be helpful, it usually contains the key information about the
linked page.
</footnote>
<page confidence="0.999476">
21
</page>
<figureCaption confidence="0.999871">
Figure 1: The workflow of the mining process.
</figureCaption>
<figure confidence="0.996552523809524">
Candidate
Sites Search
File Nome
Fetching
File Name
Logs ((or each
site)
Candidate
Sites
4..
PfhBaer DB
World Wide Web
Host
Craning
••■
World Wide Web
Web Search
Engines
Extended Rio
Name Logs
Pair Scan
</figure>
<bodyText confidence="0.985211117647059">
The same phenomenon can be observed on Chinese
pages. Chances are that a site with parallel texts
will contain such links in some of its documents.
This fact is used as the criterion in searching for
candidate sites.
Therefore, to determine possible sites for English-
Chinese parallel texts, we can request an English
document containing the following anchor:
anchor: &amp;quot;english version&amp;quot; [&amp;quot;in english&amp;quot;, ...].
Similar requests are sent for Chinese documents.
From the two sets of pages obtained by the above
queries we extract two sets of Web sites. The union
of these two sets constitutes then the candidate sites.
That is to say, a site is a candidate site when it
is found to have either an English page linking to
its Chinese version or a Chinese page linking to its
English version.
</bodyText>
<subsectionHeader confidence="0.999677">
2.2 File Name Fetching
</subsectionHeader>
<bodyText confidence="0.9857545">
We now assume that a pair of parallel texts exists on
the same site. To search for parallel pairs on a site,
PTMiner first has to obtain all (or at least part of)
the HTML file names on the site. From these names
pairs are scanned. It is possible to use a Web crawler
to explore the candidate sites completely. However,
we can take advantage of the search engines again to
accelerate the process. As the first step, we submit
the following query to the search engines:
host: hostname
to fetch the Web pages that they indexed from this
site. If we only require a small amount of parallel
texts, this result may be sufficient. For our purpose,
however, we need to explore the sites more thor-
oughly using a host crawler. Therefore, we continue
our search for files with a host crawler which uses
the documents found by the search engines as the
starting point.
</bodyText>
<subsectionHeader confidence="0.999641">
2.3 Host Crawling
</subsectionHeader>
<bodyText confidence="0.9999904">
A host crawler is slightly different from a Web
crawler. Web crawlers go through innumerable
pages and hosts on the Web. A host crawler is a
Web crawler that crawls through documents on a
given host only. A breadth-first crawling algorithm
is applied in PTMiner as host crawler. The principle
is that when a link to an unexplored document on
the same site is found in a document, it is added to
a list that will be explored later. In this way, most
file names from the candidate sites are obtained.
</bodyText>
<subsectionHeader confidence="0.998513">
2.4 Pair Scan
</subsectionHeader>
<bodyText confidence="0.99998396">
After collecting file names for each candidate site,
the next task is to determine the parallel pairs.
Again, we try to use some heuristic rules to guess
which files may be parallel texts before downloading
them. The rules are based on external features of
the documents. By external feature, we mean those
features which may be known without analyzing the
contents of the file, such as its URL, size, and date.
This is in contrast with the internal features, such as
language, character set, and HTML structure, which
cannot be known until we have downloaded the page
and analyzed its contents.
The heuristic criterion comes from the following
observation: We observe that parallel text pairs usu-
ally have similar name patterns. The difference be-
tween the names of two parallel pages usually lies
in a segment which indicates the language. For ex-
ample, &amp;quot;file-ch.html&amp;quot; (in Chinese) vs. &amp;quot;file-en.html&amp;quot;
(in English). The difference may also appear in the
path, such as &amp;quot;.../chinese/.../file.html&amp;quot; vs.
glish/.../file.html&amp;quot; . The name patterns described
above are commonly used by webmasters to help or-
ganize their sites. Hence, we can suppose that a
pair of pages with this kind of pattern are probably
parallel texts.
</bodyText>
<page confidence="0.976879">
22
</page>
<bodyText confidence="0.999940909090909">
First, we establish four lists for English pre-
fixes, English suffixes, Chinese prefixes and Chi-
nese suffixes. For example: English Prefix =
{e, en, e_, en_, e—, en—, ...}. For each file in one lan-
guage, if a segment in its name corresponds to one
of the language affixes, several new names are gener-
ated by changing the segment to the possible corre-
sponding affixes of the other language. If a generated
name corresponds to an existing file, then the file is
considered as a candidate parallel document of the
original file.
</bodyText>
<subsectionHeader confidence="0.995537">
2.5 Filtering
</subsectionHeader>
<bodyText confidence="0.9999878">
Next, we further examine the contents of the paired
files to determine if they are really parallel according
to various external and internal features. This may
further improve the pairing precision. The following
methods have been implemented in our system.
</bodyText>
<subsectionHeader confidence="0.635857">
2.5.1 Text Length
</subsectionHeader>
<bodyText confidence="0.999984583333333">
Parallel files often have similar file lengths. One sim-
ple way to filter out incorrect pairs is to compare
the lengths of the two files. The only problem is to
set a reasonable threshold that will not discard too
many good pairs, i.e. balance recall and precision.
The usual difference ratio depends on the language
pairs we are dealing with. For example, Chinese-
English parallel texts usually have a larger differ-
ence ratio than English-French parallel texts. The
filtering threshold had to be determined empirically,
from the actual observations. For Chinese-English,
a difference up to 50% is tolerated.
</bodyText>
<subsectionHeader confidence="0.659477">
2.5.2 Language and Character Set
</subsectionHeader>
<bodyText confidence="0.999982933333333">
It is also obvious that the two files of a pair have
to be in the two languages of interest. By auto-
matically identifying language and character set, we
can filter out the pairs that do not satisfy this basic
criterion. Some Web pages explicitly indicate the
language and the character set. More often such
information is omitted by authors. We need some
language identification tool for this task.
SILC is a language and encoding identification
system developed by the RALI laboratory at the
University of Montreal. It employs a probabilistic
model estimated on tri-grams. Using these mod-
els, the system is able to determine the most proba-
ble language and encoding of a text (Isabelle et al.,
1997).
</bodyText>
<subsectionHeader confidence="0.960513">
2.5.3 HTML Structure and Alignment
</subsectionHeader>
<bodyText confidence="0.999871384615384">
In the STRAND system (Resnik, 1998), the candi-
date pairs are evaluated by aligning them according
to their HTML structures and computing confidence
values. Pairs are assumed to be wrong if they have
too many mismatching markups or low confidence
values.
Comparing HTML structures seems to be a sound
way to evaluate candidate pairs since parallel pairs
usually have similar HTML structures. However, we
also noticed that parallel texts may have quite dif-
ferent HTML structures. One of the reasons is that
the two files may be created using two HTML ed-
itors. For example, one may be used for English
and another for Chinese, depending on the language
handling capability of the editors. Therefore, cau-
tion is required when measuring structure difference
numerically.
Parallel text alignment is still an experimental
area. Measuring the confidence values of an align-
ment is even more complicated. For example, the
alignment algorithm we used in the training of the
statistical translation model produces acceptable
alignment results but it does not provide a confi-
dence value that we can &amp;quot;confidently&amp;quot; use as an eval-
uation criterion. So, for the moment this criterion is
not used in candidate pair evaluation.
</bodyText>
<sectionHeader confidence="0.9083725" genericHeader="method">
3 Generated Corpus and Translation
Model Training
</sectionHeader>
<bodyText confidence="0.999497">
In this section, we describe the results of our parallel
text mining and translation model training.
</bodyText>
<subsectionHeader confidence="0.996611">
3.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.999952785714286">
Using the above approach for Chinese-English, 185
candidate sites were searched from the domain hk.
We limited the mining domain to hk because Hong
Kong is a bilingual English-Chinese city where high
quality parallel Web sites exist. Because of the small
number of candidate sites, the host crawler was used
to thoroughly explore each site. The resulting cor-
pus contains 14820 pairs of texts including 117.2Mb
Chinese texts and 136.5Mb English texts. The entire
mining process lasted about a week. Using length
comparison and language identification, we refined
the precision of the corpus to about 90%. The preci-
sion is estimated by examining 367 randomly picked
pairs.
</bodyText>
<subsectionHeader confidence="0.998553">
3.2 Statistical Translation Model
</subsectionHeader>
<bodyText confidence="0.999689941176471">
Many approaches in computational linguistics try to
extract translation knowledge from previous trans-
lation examples. Most work of this kind establishes
probabilistic models from parallel corpora. Based
on one of the statistical models proposed by Brown
et al. (1993), the basic principle of our translation
model is the following: given a corpus of aligned sen-
tences, if two words often co-occur in the source and
target sentences, there is a good likelihood that they
are translations of each other. In the simplest case
(model 1), the model learns the probability, p(tis), of
having a word t in the translation of a sentence con-
taining a word s. For an input sentence, the model
then calculates a sequence of words that are most
probable to appear in its translation. Using a sim-
ilar statistical model, Wu (1995) extracted a large-
scale English-Chinese lexicon from the HKUST cor-
</bodyText>
<page confidence="0.991902">
23
</page>
<table confidence="0.99509196969697">
&lt;s id=&amp;quot;0000&amp;quot;&gt; &lt;s id=&amp;quot;0000&amp;quot;&gt;
&lt;HTML&gt; &lt;HEAD&gt; &lt;HTML&gt; &lt;HEAD&gt;
&lt;META HTTP-EQUP/=&amp;quot;Content-type&amp;quot; &lt;META HTTP-EQUP/=&amp;quot;Content-type&amp;quot;
CONTENT=&amp;quot;text/html; charset=iso-8859-1&amp;quot;&gt; CONTENT=&amp;quot;text/html; charset=big5&amp;quot;&gt;
&lt;META HITP-EQUIV=&amp;quot;Content-language&amp;quot; &lt;META HTrP-EQUIV=&amp;quot;Content-language&amp;quot;
CONTENT=&amp;quot;Western&amp;quot;&gt; CONTENT=&amp;quot;zh&amp;quot;&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0001&amp;quot;&gt; &lt;s id=&amp;quot;0001&amp;quot;&gt;
&lt;TITLE&gt;Journal of Primary Education 1996, &lt;TITLE&gt; Journal of Primary Education 1996,
Vol., No. 1&amp;2, pp. 19-27 &lt;/TITLE&gt; Vol., No. 1&amp;2, Page 19-27 &lt;/TITLE&gt;
&lt;/HEAD&gt; &lt;/HEAD&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0002&amp;quot;&gt; &lt;s id=&amp;quot;0002&amp;quot;&gt;
&lt;BODY BACKGROUND=&amp;quot;../gif/pejbg.jpg&amp;quot; &lt;BODY BACKGROUNI&amp;quot;.Jgif/pejbg.jpg&amp;quot;
TEXT=&amp;quot;#000000&amp;quot; BGCOLOR=&amp;quot;rtffffff&apos;&gt; TEXT=&amp;quot;#000000&amp;quot; BGCOLOR=&amp;quot;Kfffff&amp;quot;&gt; &lt;A
&lt;CENTER&gt; HREF=&amp;quot;/en/pej/b2g_pej.phunl?URL=%2fen%2fp
&lt;/s&gt; ej%2f0601%2f0601019c.htm&amp;quot;&gt;
&lt;s id=&amp;quot;0003&amp;quot;&gt; &lt;IMG SRC=&amp;quot;/en/gif/Ican.gir ALT=&amp;quot;i44.&amp;quot;
&lt;H1&gt;Journal of Primary Education &lt;/HI&gt; BORDER=O ALIGN=R IGHT&gt; &lt;/A&gt; &lt;CENTER&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0004&amp;quot;&gt;
&lt;HR&gt; &lt;B&gt;Volume 6, No 1&amp;2, pp. 19-27 (May,
1996) &lt;/B&gt; &lt;HR&gt;
&lt;/s&gt;
&lt;s id=&amp;quot;0005&amp;quot;&gt; &lt;s id=&amp;quot;0003&amp;quot;&gt;
&lt;H3&gt;Principles for Redesigning Teacher &lt;H2&gt;in**. 1$ 0,&lt;/H2&gt;
Education &lt;/113&gt; Alan TOM &lt;/CENTER&gt; &lt;/s&gt;
&lt;/s&gt; &lt;s id=&amp;quot;0004&amp;quot;&gt;
&lt;HR&gt; (-4A 9) If irt.
&lt;/s&gt;
&lt;s id=&amp;quot;0006&amp;quot;&gt; &lt;s id=&amp;quot;0005&amp;quot;&gt;
&lt;P&gt; &lt;B&gt; &lt;I&gt; Abstract &lt;/I&gt; &lt;/B&gt; 19-27k*--1...=.11 &lt;HR&gt;
&lt;/s&gt; &lt;/s&gt;
</table>
<figureCaption confidence="0.990216">
Figure 2: An alignment example using pure length-based method.
</figureCaption>
<bodyText confidence="0.99983825">
pus which is built manually. In our case, the prob-
abilistic translation model will be used for CUR.
The requirement on our translation model may be
less demanding: it is not absolutely necessary that
a word t with high p(t1s) always be a true trans-
lation of s. It is still useful if t is strongly related
to s. For example, although &amp;quot;railway&amp;quot; is not a true
translation of &amp;quot;train&amp;quot; (in French), it is highly useful
to include &amp;quot;railway&amp;quot; in the translation of a query on
&amp;quot;train&amp;quot;. This is one of the reasons why we think a
less controlled parallel corpus can be used to train a
translation model for CLIR.
</bodyText>
<subsectionHeader confidence="0.998692">
3.3 Parallel Text Alignment
</subsectionHeader>
<bodyText confidence="0.999986447368421">
Before the mined documents can be aligned into par-
allel sentences, the raw texts have to undergo a se-
ries of some preprocessing, which, to some extent, is
language dependent. For example, the major opera-
tions on the Chinese-English corpus include encod-
ing scheme transformation (for Chinese), sentence
level segmentation, parallel text alignment, Chinese
word segmentation (Nie et al., 1999) and English
expression extraction.
The parallel Web pages we collected from vari-
ous sites are not all of the same quality. Some are
highly parallel and easy to align while others can be
very noisy. Aligning English-Chinese parallel texts
is already very difficult because of the great differ-
ences in the syntactic structures and writing sys-
tems of the two languages. A number of alignment
techniques have been proposed, varying from statis-
tical methods (Brown et al., 1991; Gale and Church,
1991) to lexical methods (Kay and Roscheisen, 1993;
Chen, 1993). The method we adopted is that of
Simard et al. (1992). Because it considers both
length similarity and cognateness as alignment cri-
teria, the method is more robust and better able
to deal with noise than pure length-based methods.
Cognates are identical sequences of characters in cor-
responding words in two languages. They are com-
monly found in English and French. In the case of
English-Chinese alignment, where there are no cog-
nates shared by the two languages, only the HTML
markup in both texts are taken as cognates. Be-
cause the HTML structures of parallel pages are nor-
mally similar, the markup was found to be helpful
for alignment.
To illustrate how markup can help with the align-
ment, we align the same pair with both the pure
length-based method of Gale &amp; Church (Fig. 2),
and the method of Simard et al. (Fig. 3). First of
all, we observe from the figures that the two texts are
</bodyText>
<page confidence="0.997641">
24
</page>
<table confidence="0.974849027777778">
&lt;s id=&amp;quot;0000&amp;quot;&gt; &lt;s id=&amp;quot;0000&amp;quot;&gt;
&lt;HTML&gt; &lt;HEAD&gt; &lt;HTML&gt; &lt;HEAD&gt;
&lt;META HTTP-EQUIV=&amp;quot;Content-type&amp;quot; &lt;META HTTP-EQUIV=&amp;quot;Content-type&amp;quot;
CONTENT=&amp;quot;text/htrn1; charset=iso-8859-1&amp;quot;&gt; CONTENT=&amp;quot;text/html; charset=big5&amp;quot;&gt;
&lt;META HTTP-EQUIV=&amp;quot;Content-language&amp;quot; &lt;META HTTP-EQUIV=&amp;quot;Content-language&amp;quot;
CONTENT=&amp;quot;Westem&amp;quot;&gt; CONTENT=&amp;quot;th&amp;quot;&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0001&amp;quot;&gt; &lt;s id=&amp;quot;0001&amp;quot;&gt;
&lt;TITLE&gt;Journal of Primary Education 1996, &lt;TITLE&gt; Journal of Primary Education 1996,
Vol., No. 1&amp;2, pp. 19-27 &lt;11TILE&gt; Vol., No. 1&amp;2, Page 19-27 &lt;/TITLE&gt;
&lt;/HEAD&gt; &lt;/HEAD&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0002&amp;quot;&gt; &lt;s id=&amp;quot;0002&amp;quot;&gt;
&lt;BODY BACKGROUND=&amp;quot;../gif/pejbg.jpg&amp;quot; &lt;BODY BACKGROUND=&amp;quot;../gif/pejbg.jpg&amp;quot;
TEXT=&amp;quot;#000000&amp;quot; BGCOLOR=&amp;quot;itffffff&apos;&gt; TEXT=&amp;quot;#000000&amp;quot; BGCOLOR=&amp;quot;#ffffff&apos;&gt; &lt;A
&lt;CENTER&gt; HREF=&amp;quot;/en/pej/b2g_pej.phtml?URL=%2Ten%2fp
&lt;/s&gt; ej%2f0601%2f0601019c.htm&amp;quot;&gt;
&lt;IMG SRC=Ven/gif/Ican.gif&apos; ALT=&amp;quot;144.&amp;quot;
BORDER=O ALIGN=R IGHT&gt; &lt;/A&gt; &lt;CENTER&gt;
&lt;/s&gt;
&lt;s id=&amp;quot;0003&amp;quot;&gt; &lt;s id=&amp;quot;0003&amp;quot;&gt;
&lt;H1&gt;Journal of Primary Education &lt;/H1&gt; &lt;H2&gt;4n*&lt;/H2&gt;
&lt;/s&gt; &lt;A&gt;
&lt;s id=&amp;quot;0004&amp;quot;&gt; &lt;s id=&amp;quot;0004&amp;quot;&gt;
&lt;HR&gt; &lt;B&gt;Volume 6, No 1&amp;2, pp. 19-27 (May, &lt;FIR&gt; (--Adtei,74-31./1) iit #4.
1996) &lt;/B&gt; &lt;HR&gt; &lt;/s&gt;
&lt;/s&gt; &lt;s id=&amp;quot;0005&amp;quot;&gt;
Ai —21..19-27 if &lt;HR&gt;
&lt;/s&gt;
&lt;s id=&amp;quot;0005&amp;quot;&gt; &lt;s id=&amp;quot;0006&amp;quot;&gt;
&lt;H3&gt;Principles for Redesigning Teacher &lt;H3&gt;..4. k 401 *F. it 0 s Rj &lt;/H3&gt; Alan TOM
Education &lt;/113&gt; Alan TOM &lt;/CENTER&gt; &lt;/CENTER&gt;
&lt;/s&gt; &lt;/s&gt;
&lt;s id=&amp;quot;0006&amp;quot;&gt; &lt;s id=&amp;quot;0007&amp;quot;&gt;
&lt;P&gt; &lt;B&gt; &lt;I&gt; Abstract &lt;/I&gt; 411&gt; &lt;P&gt; &lt;I&gt; &lt;B&gt; 4*. &lt;nil&gt; &lt;/I&gt; &lt;P&gt;
&lt;A&gt; &lt;A&gt;
</table>
<figureCaption confidence="0.996124">
Figure 3: An alignment example considering cognates.
</figureCaption>
<bodyText confidence="0.99745737037037">
divided into sentences. The sentences are marked by
&lt;s id= &amp;quot;xxxx&amp;quot; &gt; and &lt;/s&gt;. Note that we determine
sentences not only by periods, but also by means of
HTML markup.
We further notice that it is difficult to align sen-
tences 0002. The sentence in the Chinese page is
much longer than its counterpart in the English page
because some additional information (font) is added.
The length-based method thus tends to take sen-
tence 0002, 0003, and 0004 in the English page as
the translation of sentence 0002 in the Chinese page
(Fig. 2), which is wrong. This in turn provocated
the three following incorrect alignments. As we can
see in Fig. 3, the cognate method did not make the
same mistake because of the noise in sentence 0002.
Despite their large length difference, the two 0002
sentences are still aligned as a 1-1 pair, because the
sentences in the following 4 alignments (0003 - 0003;
0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) have
rather similar HTML markups and are taken by the
program to be the most likely alignments.
Beside HTML markups, other criteria may also
be incorporated. For example, it would be helpful
to consider strong correspondence between certain
English and Chinese words, as in (Wu, 1994). We
hope to implement such correspondences in our fu-
ture research.
</bodyText>
<subsectionHeader confidence="0.997777">
3.4 Lexicon Evaluation
</subsectionHeader>
<bodyText confidence="0.9998842">
To evaluate the precision of the English-Chinese
translation model trained on the Web corpus, we
examined two sample lexicons of 200 words, one in
each direction. The 200 words for each lexicon were
randomly selected from the training source. We ex-
amined the most probable translation for each word.
The Chinese-English lexicon was found to have a
precision of 77%. The English-Chinese lexicon has
a higher precision of 81.5%. Part of the lexicons
are shown in Fig. 4, where t/f indicates whether a
translation is true or false.
These precisions seem to be reasonably high.
They are quite comparable to that obtained by Wu
(1994) using a manual Chinese-English parallel cor-
pus.
</bodyText>
<subsectionHeader confidence="0.997595">
3.5 Effect of Stopwords
</subsectionHeader>
<bodyText confidence="0.999553">
We also found that stop-lists have significant effect
on the translation model. Stop-list is a set of the
most frequent words that we remove from the train-
</bodyText>
<page confidence="0.9860535">
25
26
</page>
<table confidence="0.9995236">
C-E CLIR E-C CLIR
Mono-Lingual IR 0.3861 0.3976
Translation Model 0.1504 (39.0%mono) 0.1841 (46.3%mono)
Dictionary 0.1530 (39.6%mono) 0.1427 (35.9%mono)
TM + DICT 0.2583 (66.9%mono) 0.2232 (56.1%mono)
</table>
<tableCaption confidence="0.999675">
Table 1: CUR results.
</tableCaption>
<bodyText confidence="0.8579395">
trained without considering the English stopwords
gives higher probabilities.
</bodyText>
<sectionHeader confidence="0.993996" genericHeader="method">
4 English-Chinese CUR Results
</sectionHeader>
<bodyText confidence="0.999394">
Our final goal was to test the performance of the
translation models trained on the Web parallel cor-
pora in CUR. We conducted CLIR experiments us-
ing the Smart IR system.
</bodyText>
<sectionHeader confidence="0.598827" genericHeader="evaluation">
4.1 Results
</sectionHeader>
<bodyText confidence="0.999985368421053">
The English test corpus (for C-E CLIR) was the
AP corpus used in TREC6 and TREC7. The short
English queries were translated manually into Chi-
nese and then translated back to English by the
translation model. The Chinese test corpus was the
one used in the TREC5 and TREC6 Chinese track.
It contains both Chinese queries and their English
translations.
Our experiments on these two corpora produced
the results shown in Tab. 1. The precision of mono-
lingual IR is given as benchmark. In both E-C and
C-E CLIR, the translation model achieved around
40% of monolingual precision. To compare with the
dictionary-based approach, we employed a Chinese-
English dictionary, CEDICT (Denisowski, 1999),
and an English-Chinese online dictionary (Anony-
mous, 1999a) to translate queries. For each word
of the source query, all the possible translations
given by the dictionary are included in the translated
query. The Chinese-English dictionary has about
the same performace as the translation model, while
the English-Chinese dictionary has lower precision
than that of the translation model.
We also tried to combine the translations given by
the translation model and the dictionary. In both
C-E and E-C CUR, significant improvements were
achieved (as shown in Tab. 1). The improvements
show that the translations given by the translation
model and the dictionary complement each other
well for IR purposes. The translation model may
give either exact translations or incorrect but related
words. Even though these words are not correct in
the sense of translation, they are very possibly re-
lated to the subject of the query and thus helpful
for IR purposes. The dictionary-based approach ex-
pands a query along another dimension. It gives
all the possible translations for each word including
those that are missed by the translation model.
</bodyText>
<subsectionHeader confidence="0.998887">
4.2 Comparison With MT Systems
</subsectionHeader>
<bodyText confidence="0.999892833333333">
One advantage of a parallel text-based translation
model is that it is easier to build than an MT system.
Now that we have examined the CLIR performance
of the translation model, we will compare it with
two existing MT systems. Both systems were tested
in E-C CUR.
</bodyText>
<subsectionHeader confidence="0.602459">
4.2.1 Sunshine WebTran Server
</subsectionHeader>
<bodyText confidence="0.999848875">
Using the Sunshine WebTran server (Anonymous,
1999b), an online English-Chinese MT system, to
translate the 54 English queries, we obtained an
average precision of 0.2001, which is 50.3% of the
mono-lingual precision. The precision is higher than
that obtained using the translation model (0.1804)
or the dictionary (0.1427) alone, but lower than the
precison obtained using them together (0.2232).
</bodyText>
<subsubsectionHeader confidence="0.473424">
4.2.2 Transperfect
</subsubsectionHeader>
<bodyText confidence="0.999991461538462">
Kwok (1999) investigated the CLIR performance of
an English-Chinese MT software called Transper-
fect, using the same TREC Chinese collection as we
used in this study. Using the MT software alone,
Kwok achieved 56% of monolingual precision. The
precision is improved to 62% by refining the trans-
lation with a dictionary. Kwok also adopted pre-
translation query expansion, which further improved
the precison to 70% of the monolingual results.
In our case, the best E-C CLIR precison using the
translation model (and dictionary) is 56.1%. It is
lower than what Kwok achieved using Transperfect,
however, the difference is not large.
</bodyText>
<subsectionHeader confidence="0.993506">
4.3 Further Problems
</subsectionHeader>
<bodyText confidence="0.996484066666667">
The Chinese-English translation model has a far
lower CLIR performance than that of the English-
French model established using the same method
(Nie et al., 1999). The principal reason for this is the
fact that English and Chinese are much more differ-
ent than English and French. This problem surfaced
in many phases of this work, from text alignment to
query translation. Below, we list some further fac-
tors affecting CLIR precision.
• The Web-collected corpus is noisy and it is dif-
ficult to align English-Chinese texts. The align-
ment method we employed has performed more
poorly than on English-French alignment. This
in turn leads to poorer performance of the trans-
lation model. In general, we observe a higher
</bodyText>
<page confidence="0.9918">
27
</page>
<bodyText confidence="0.514230947368421">
variability in Chinese-English translations than
in English-French translations.
• For E-C CLIR, although queries in both lan-
guages were provided, the English queries were
not strictly translated from the original Chi-
nese ones. For example, if■AttA, (human right
situation) was translated into human right is-
sue. We cannot expect the translation model
to translate issue back to :KA, (situation).
• The training source and the CLIR collections
were from different domains. The Web cor-
pus are retrieved from the parallel sites in Hong
Kong while the Chinese collection is from Peo-
ple&apos;s Daily and Xinhua News Agency, which are
published in mainland China. As the result,
some important terms such as ft* tiq (most-
favored-nation) and -- al A 4J (one-nation-two-
systems) in the collection are not known by the
model.
</bodyText>
<sectionHeader confidence="0.995469" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.99996412">
The goal of this work was to investigate the feasibil-
ity of using a statistical translation model trained on
a Web-collected corpus to do English-Chinese CLIR.
In this paper, we have described the algorithm and
implementation we used for parallel text mining,
translation model training, and some results we ob-
tained in CLIR experiments. Although further work
remains to be done, we can conclude that it is pos-
sible to automatically construct a Chinese-English
parallel corpus from the Web. The current system
can be easily adapted to other language pairs. De-
spite the noisy nature of the corpus and the great
difference in the languages, the evaluation lexicons
generated by the translation model produced accept-
able precision. While the current CLIR results are
not as encouraging as those of English-French CLIR,
they could be improved in various ways, such as im-
proving the alignment method by adapting cognate
definitions to HTML markup, incorporating a lexi-
con and/or removing some common function words
in translated queries.
We hope to be able to demonstrate in the near
future that a fine-tuned English-Chinese translation
model can provide query translations for CLIR with
the same quality produced by MT systems.
</bodyText>
<sectionHeader confidence="0.999641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999821048387097">
Anonymous. 1999a. Sunrain.net - English-Chinese
dictionary. http://sunrain.net/r_ecdict_e.htm.
Anonymous. 1999b. Sunshine WebTran server.
http://www.readworld.com/translate.htm.
P. F. Brown, J. C. Lai, and R. L. Mercer. 1991.
Aligning sentences in parallel corpora. In 29th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 89-94, Berkeley, Calif.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra,
and R. L. Mercer. 1993. The mathematics of ma-
chine translation: Parameter estimation. Compu-
tational Linguistics, 19:263-311.
S. F. Chen. 1993. Aligning sentences in bilingual
corpora using lexical information. In Proceedings
of the 31th Annual Meeting of the Association for
Computational Linguistics, pages 9-16, Colum-
bus, Ohio.
Paul Denisowski. 1999. Cedict (chinese-english dic-
tionary) project. http://www.mindspring.com/
paul_denisowski/cedict.html.
William A. Gale and Kenneth W. Church. 1991. A
program for aligning sentences in bilingual cor-
pora. In Proceedings of the 29th Annual Meeting
of the Association for Computational Linguistics,
pages 177-184, Berkeley, Calif.
P. Isabelle, G. Foster, and P. Plamondon.
1997. SILC: un systeme d&apos;identification
de la langue et du codage. http://www-
rali.iro.umontreal.ca/ProjetSILC.en.html.
M. Kay and M. Roscheisen. 1993. Text-translation
alignment. Computational Linguistics, 19:121-
142.
K. L. Kwok. 1999. English-chinese cross-language
retrieval based on a translation package. In Work-
shop of Machine Translation for Cross Language
Information Retrieval, Machine Translation Sum-
mit VII, Singapore.
P. Langlais, G. Foster, and G. Lapalme. 2000. Unit
completion for a computer-aided translation typ-
ing system. In Applied Natural Language Pro-
cessing Conference (ANLP), Seattle, Washington,
May.
Jianyun Nie, Michel Simard, Pierre Isabelle, and
Richard Durand. 1999. Cross-language informa-
tion retrieval based on parallel texts and auto-
matic mining parallel texts from the Web. In
ACM SIGIR&apos;99, pages 74-81, August.
Philip Resnik. 1998. Parallel stands: A preliminary
investigation into mining the Web for bilingual
text. In A MTA &apos;98, October.
Michel Simard, George F. Foster, and Pierre Is-
abelle. 1992. Using cognates to align sentences
in bilingual corpora. In Proceedings of TMI-92,
Montreal, Quebec.
Dekai Wu. 1994. Aligning a parallel English-
Chinese corpus statistically with lexical criteria.
In ACL-94: 32nd Annual Meeting of the Assoc.
for Computational Linguistics, pages 80-87, Las
Cruces, NM, June.
Dekai Wu. 1995. Large-scale automatic extraction
of an English-Chinese lexicon. Machine Transla-
tion, 9(3-4):285-313.
</reference>
<page confidence="0.999068">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.709351">
<title confidence="0.9826105">Automatic construction of parallel English-Chinese corpus for cross-language information retrieval</title>
<author confidence="0.999628">Jiang Chen</author>
<author confidence="0.999628">Jian-Yun Nie</author>
<affiliation confidence="0.9954265">Departement d&apos;Informatique et Recherche Operationnelle Universite de Montréal</affiliation>
<address confidence="0.8751885">C.P. 6128, succursale CENTRE-VILLE Montreal (Quebec), Canada H3C 3J7</address>
<email confidence="0.958038">chen@iro.umontreal.ca</email>
<email confidence="0.958038">nie@iro.umontreal.ca</email>
<abstract confidence="0.999098545454546">A major obstacle to the construction of a probabilistic translation model is the lack of large parallel corpora. In this paper we first describe a parallel text mining system that finds parallel texts automatically on the Web. The generated Chinese-English parallel corpus is used to train a probabilistic translation model which translates queries for Chinese-English cross-language information retrieval (CLIR). We will discuss some problems in translation model training and show the preliminary CUR results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anonymous</author>
</authors>
<title>Sunrain.net - English-Chinese dictionary.</title>
<date>1999</date>
<note>http://sunrain.net/r_ecdict_e.htm.</note>
<contexts>
<context position="21645" citStr="Anonymous, 1999" startWordPosition="3468" endWordPosition="3470">into Chinese and then translated back to English by the translation model. The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track. It contains both Chinese queries and their English translations. Our experiments on these two corpora produced the results shown in Tab. 1. The precision of monolingual IR is given as benchmark. In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision. To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries. For each word of the source query, all the possible translations given by the dictionary are included in the translated query. The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model. We also tried to combine the translations given by the translation model and the dictionary. In both C-E and E-C CUR, significant improvements were achieved (as shown in Tab. 1). The improvements show that the translations given by the translation model and the dictio</context>
<context position="23103" citStr="Anonymous, 1999" startWordPosition="3703" endWordPosition="3704">e subject of the query and thus helpful for IR purposes. The dictionary-based approach expands a query along another dimension. It gives all the possible translations for each word including those that are missed by the translation model. 4.2 Comparison With MT Systems One advantage of a parallel text-based translation model is that it is easier to build than an MT system. Now that we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems. Both systems were tested in E-C CUR. 4.2.1 Sunshine WebTran Server Using the Sunshine WebTran server (Anonymous, 1999b), an online English-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision. The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232). 4.2.2 Transperfect Kwok (1999) investigated the CLIR performance of an English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study. Using the MT software alone, Kwok achieved 56% of monolingual prec</context>
</contexts>
<marker>Anonymous, 1999</marker>
<rawString>Anonymous. 1999a. Sunrain.net - English-Chinese dictionary. http://sunrain.net/r_ecdict_e.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anonymous</author>
</authors>
<date>1999</date>
<note>Sunshine WebTran server. http://www.readworld.com/translate.htm.</note>
<contexts>
<context position="21645" citStr="Anonymous, 1999" startWordPosition="3468" endWordPosition="3470">into Chinese and then translated back to English by the translation model. The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track. It contains both Chinese queries and their English translations. Our experiments on these two corpora produced the results shown in Tab. 1. The precision of monolingual IR is given as benchmark. In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision. To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries. For each word of the source query, all the possible translations given by the dictionary are included in the translated query. The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model. We also tried to combine the translations given by the translation model and the dictionary. In both C-E and E-C CUR, significant improvements were achieved (as shown in Tab. 1). The improvements show that the translations given by the translation model and the dictio</context>
<context position="23103" citStr="Anonymous, 1999" startWordPosition="3703" endWordPosition="3704">e subject of the query and thus helpful for IR purposes. The dictionary-based approach expands a query along another dimension. It gives all the possible translations for each word including those that are missed by the translation model. 4.2 Comparison With MT Systems One advantage of a parallel text-based translation model is that it is easier to build than an MT system. Now that we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems. Both systems were tested in E-C CUR. 4.2.1 Sunshine WebTran Server Using the Sunshine WebTran server (Anonymous, 1999b), an online English-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision. The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232). 4.2.2 Transperfect Kwok (1999) investigated the CLIR performance of an English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study. Using the MT software alone, Kwok achieved 56% of monolingual prec</context>
</contexts>
<marker>Anonymous, 1999</marker>
<rawString>Anonymous. 1999b. Sunshine WebTran server. http://www.readworld.com/translate.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Aligning sentences in parallel corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>89--94</pages>
<location>Berkeley, Calif.</location>
<contexts>
<context position="15805" citStr="Brown et al., 1991" startWordPosition="2552" endWordPosition="2555"> encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cog</context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>P. F. Brown, J. C. Lai, and R. L. Mercer. 1991. Aligning sentences in parallel corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 89-94, Berkeley, Calif.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--263</pages>
<contexts>
<context position="941" citStr="Brown et al. (1993)" startWordPosition="127" endWordPosition="130">stacle to the construction of a probabilistic translation model is the lack of large parallel corpora. In this paper we first describe a parallel text mining system that finds parallel texts automatically on the Web. The generated Chinese-English parallel corpus is used to train a probabilistic translation model which translates queries for Chinese-English cross-language information retrieval (CLIR). We will discuss some problems in translation model training and show the preliminary CUR results. 1 Introduction Parallel texts have been used in a number of studies in computational linguistics. Brown et al. (1993) defined a series of probabilistic translation models for MT purposes. While people may question the effectiveness of using these models for a full-blown MT system, the models are certainly valuable for developing translation assistance tools. For example, we can use such a translation model to help complete target text being drafted by a human translator (Langlais et al., 2000). Another utilization is in cross-language information retrieval (CUR) where queries have to be translated from one language to another language in which the documents are written. In CUR, the quality requirement for tr</context>
<context position="12380" citStr="Brown et al. (1993)" startWordPosition="2039" endWordPosition="2042">g corpus contains 14820 pairs of texts including 117.2Mb Chinese texts and 136.5Mb English texts. The entire mining process lasted about a week. Using length comparison and language identification, we refined the precision of the corpus to about 90%. The precision is estimated by examining 367 randomly picked pairs. 3.2 Statistical Translation Model Many approaches in computational linguistics try to extract translation knowledge from previous translation examples. Most work of this kind establishes probabilistic models from parallel corpora. Based on one of the statistical models proposed by Brown et al. (1993), the basic principle of our translation model is the following: given a corpus of aligned sentences, if two words often co-occur in the source and target sentences, there is a good likelihood that they are translations of each other. In the simplest case (model 1), the model learns the probability, p(tis), of having a word t in the translation of a sentence containing a word s. For an input sentence, the model then calculates a sequence of words that are most probable to appear in its translation. Using a similar statistical model, Wu (1995) extracted a largescale English-Chinese lexicon from</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19:263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
</authors>
<title>Aligning sentences in bilingual corpora using lexical information.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>9--16</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="15887" citStr="Chen, 1993" startWordPosition="2567" endWordPosition="2568"> alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML structures of parallel pages are normally similar, the mar</context>
</contexts>
<marker>Chen, 1993</marker>
<rawString>S. F. Chen. 1993. Aligning sentences in bilingual corpora using lexical information. In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, pages 9-16, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Denisowski</author>
</authors>
<date>1999</date>
<note>Cedict (chinese-english dictionary) project. http://www.mindspring.com/ paul_denisowski/cedict.html.</note>
<contexts>
<context position="21586" citStr="Denisowski, 1999" startWordPosition="3461" endWordPosition="3462">nd TREC7. The short English queries were translated manually into Chinese and then translated back to English by the translation model. The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track. It contains both Chinese queries and their English translations. Our experiments on these two corpora produced the results shown in Tab. 1. The precision of monolingual IR is given as benchmark. In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision. To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries. For each word of the source query, all the possible translations given by the dictionary are included in the translated query. The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model. We also tried to combine the translations given by the translation model and the dictionary. In both C-E and E-C CUR, significant improvements were achieved (as shown in Tab. 1). The improvements show that the</context>
</contexts>
<marker>Denisowski, 1999</marker>
<rawString>Paul Denisowski. 1999. Cedict (chinese-english dictionary) project. http://www.mindspring.com/ paul_denisowski/cedict.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>177--184</pages>
<location>Berkeley, Calif.</location>
<contexts>
<context position="15829" citStr="Gale and Church, 1991" startWordPosition="2556" endWordPosition="2559">nsformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML </context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>William A. Gale and Kenneth W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 177-184, Berkeley, Calif.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Isabelle</author>
<author>G Foster</author>
<author>P Plamondon</author>
</authors>
<title>SILC: un systeme d&apos;identification de la langue et du codage.</title>
<date>1997</date>
<note>http://wwwrali.iro.umontreal.ca/ProjetSILC.en.html.</note>
<contexts>
<context position="9997" citStr="Isabelle et al., 1997" startWordPosition="1663" endWordPosition="1666">es of interest. By automatically identifying language and character set, we can filter out the pairs that do not satisfy this basic criterion. Some Web pages explicitly indicate the language and the character set. More often such information is omitted by authors. We need some language identification tool for this task. SILC is a language and encoding identification system developed by the RALI laboratory at the University of Montreal. It employs a probabilistic model estimated on tri-grams. Using these models, the system is able to determine the most probable language and encoding of a text (Isabelle et al., 1997). 2.5.3 HTML Structure and Alignment In the STRAND system (Resnik, 1998), the candidate pairs are evaluated by aligning them according to their HTML structures and computing confidence values. Pairs are assumed to be wrong if they have too many mismatching markups or low confidence values. Comparing HTML structures seems to be a sound way to evaluate candidate pairs since parallel pairs usually have similar HTML structures. However, we also noticed that parallel texts may have quite different HTML structures. One of the reasons is that the two files may be created using two HTML editors. For e</context>
</contexts>
<marker>Isabelle, Foster, Plamondon, 1997</marker>
<rawString>P. Isabelle, G. Foster, and P. Plamondon. 1997. SILC: un systeme d&apos;identification de la langue et du codage. http://wwwrali.iro.umontreal.ca/ProjetSILC.en.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M Roscheisen</author>
</authors>
<date>1993</date>
<booktitle>Text-translation alignment. Computational Linguistics,</booktitle>
<pages>19--121</pages>
<contexts>
<context position="15874" citStr="Kay and Roscheisen, 1993" startWordPosition="2563" endWordPosition="2566">egmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML structures of parallel pages are normally sim</context>
</contexts>
<marker>Kay, Roscheisen, 1993</marker>
<rawString>M. Kay and M. Roscheisen. 1993. Text-translation alignment. Computational Linguistics, 19:121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K L Kwok</author>
</authors>
<title>English-chinese cross-language retrieval based on a translation package.</title>
<date>1999</date>
<booktitle>In Workshop of Machine Translation for Cross Language Information Retrieval, Machine Translation Summit VII,</booktitle>
<contexts>
<context position="23482" citStr="Kwok (1999)" startWordPosition="3759" endWordPosition="3760">t we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems. Both systems were tested in E-C CUR. 4.2.1 Sunshine WebTran Server Using the Sunshine WebTran server (Anonymous, 1999b), an online English-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision. The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232). 4.2.2 Transperfect Kwok (1999) investigated the CLIR performance of an English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study. Using the MT software alone, Kwok achieved 56% of monolingual precision. The precision is improved to 62% by refining the translation with a dictionary. Kwok also adopted pretranslation query expansion, which further improved the precison to 70% of the monolingual results. In our case, the best E-C CLIR precison using the translation model (and dictionary) is 56.1%. It is lower than what Kwok achieved using Transperfect, however, the differe</context>
</contexts>
<marker>Kwok, 1999</marker>
<rawString>K. L. Kwok. 1999. English-chinese cross-language retrieval based on a translation package. In Workshop of Machine Translation for Cross Language Information Retrieval, Machine Translation Summit VII, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Langlais</author>
<author>G Foster</author>
<author>G Lapalme</author>
</authors>
<title>Unit completion for a computer-aided translation typing system.</title>
<date>2000</date>
<booktitle>In Applied Natural Language Processing Conference (ANLP),</booktitle>
<location>Seattle, Washington,</location>
<contexts>
<context position="1322" citStr="Langlais et al., 2000" startWordPosition="189" endWordPosition="192">rmation retrieval (CLIR). We will discuss some problems in translation model training and show the preliminary CUR results. 1 Introduction Parallel texts have been used in a number of studies in computational linguistics. Brown et al. (1993) defined a series of probabilistic translation models for MT purposes. While people may question the effectiveness of using these models for a full-blown MT system, the models are certainly valuable for developing translation assistance tools. For example, we can use such a translation model to help complete target text being drafted by a human translator (Langlais et al., 2000). Another utilization is in cross-language information retrieval (CUR) where queries have to be translated from one language to another language in which the documents are written. In CUR, the quality requirement for translation is relatively low. For example, the syntactic aspect is irrelevant. Even if the translated word is not a true translation but is strongly related to the original query, it is still helpful. Therefore, CUR is a suitable application for such a translation model. However, a major obstacle to this approach is the lack of parallel corpora for model training. Only a few such</context>
</contexts>
<marker>Langlais, Foster, Lapalme, 2000</marker>
<rawString>P. Langlais, G. Foster, and G. Lapalme. 2000. Unit completion for a computer-aided translation typing system. In Applied Natural Language Processing Conference (ANLP), Seattle, Washington, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianyun Nie</author>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
<author>Richard Durand</author>
</authors>
<title>Cross-language information retrieval based on parallel texts and automatic mining parallel texts from the Web. In</title>
<date>1999</date>
<booktitle>ACM SIGIR&apos;99,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="15332" citStr="Nie et al., 1999" startWordPosition="2474" endWordPosition="2477">ly useful to include &amp;quot;railway&amp;quot; in the translation of a query on &amp;quot;train&amp;quot;. This is one of the reasons why we think a less controlled parallel corpus can be used to train a translation model for CLIR. 3.3 Parallel Text Alignment Before the mined documents can be aligned into parallel sentences, the raw texts have to undergo a series of some preprocessing, which, to some extent, is language dependent. For example, the major operations on the Chinese-English corpus include encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et </context>
<context position="24281" citStr="Nie et al., 1999" startWordPosition="3884" endWordPosition="3887">, Kwok achieved 56% of monolingual precision. The precision is improved to 62% by refining the translation with a dictionary. Kwok also adopted pretranslation query expansion, which further improved the precison to 70% of the monolingual results. In our case, the best E-C CLIR precison using the translation model (and dictionary) is 56.1%. It is lower than what Kwok achieved using Transperfect, however, the difference is not large. 4.3 Further Problems The Chinese-English translation model has a far lower CLIR performance than that of the EnglishFrench model established using the same method (Nie et al., 1999). The principal reason for this is the fact that English and Chinese are much more different than English and French. This problem surfaced in many phases of this work, from text alignment to query translation. Below, we list some further factors affecting CLIR precision. • The Web-collected corpus is noisy and it is difficult to align English-Chinese texts. The alignment method we employed has performed more poorly than on English-French alignment. This in turn leads to poorer performance of the translation model. In general, we observe a higher 27 variability in Chinese-English translations </context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>Jianyun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining parallel texts from the Web. In ACM SIGIR&apos;99, pages 74-81, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Parallel stands: A preliminary investigation into mining the Web for bilingual text.</title>
<date>1998</date>
<booktitle>In A MTA &apos;98,</booktitle>
<contexts>
<context position="10069" citStr="Resnik, 1998" startWordPosition="1676" endWordPosition="1677">ilter out the pairs that do not satisfy this basic criterion. Some Web pages explicitly indicate the language and the character set. More often such information is omitted by authors. We need some language identification tool for this task. SILC is a language and encoding identification system developed by the RALI laboratory at the University of Montreal. It employs a probabilistic model estimated on tri-grams. Using these models, the system is able to determine the most probable language and encoding of a text (Isabelle et al., 1997). 2.5.3 HTML Structure and Alignment In the STRAND system (Resnik, 1998), the candidate pairs are evaluated by aligning them according to their HTML structures and computing confidence values. Pairs are assumed to be wrong if they have too many mismatching markups or low confidence values. Comparing HTML structures seems to be a sound way to evaluate candidate pairs since parallel pairs usually have similar HTML structures. However, we also noticed that parallel texts may have quite different HTML structures. One of the reasons is that the two files may be created using two HTML editors. For example, one may be used for English and another for Chinese, depending o</context>
</contexts>
<marker>Resnik, 1998</marker>
<rawString>Philip Resnik. 1998. Parallel stands: A preliminary investigation into mining the Web for bilingual text. In A MTA &apos;98, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>George F Foster</author>
<author>Pierre Isabelle</author>
</authors>
<title>Using cognates to align sentences in bilingual corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of TMI-92,</booktitle>
<location>Montreal, Quebec.</location>
<contexts>
<context position="15942" citStr="Simard et al. (1992)" startWordPosition="2576" endWordPosition="2579">al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML structures of parallel pages are normally similar, the markup was found to be helpful for alignment. To illustrat</context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>Michel Simard, George F. Foster, and Pierre Isabelle. 1992. Using cognates to align sentences in bilingual corpora. In Proceedings of TMI-92, Montreal, Quebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Aligning a parallel EnglishChinese corpus statistically with lexical criteria.</title>
<date>1994</date>
<booktitle>In ACL-94: 32nd Annual Meeting of the Assoc. for Computational Linguistics,</booktitle>
<pages>80--87</pages>
<location>Las Cruces, NM,</location>
<contexts>
<context position="2028" citStr="Wu, 1994" startWordPosition="306" endWordPosition="307">ranslated from one language to another language in which the documents are written. In CUR, the quality requirement for translation is relatively low. For example, the syntactic aspect is irrelevant. Even if the translated word is not a true translation but is strongly related to the original query, it is still helpful. Therefore, CUR is a suitable application for such a translation model. However, a major obstacle to this approach is the lack of parallel corpora for model training. Only a few such corpora exist, including the Hansard English-French corpus and the HKUST EnglishChinese corpus (Wu, 1994). In this paper, we will describe a method which automatically searches for parallel texts on the Web. We will discuss the text mining algorithm we adopted, some issues in translation model training using the generated parallel corpus, and finally the translation model&apos;s performance in CUR. 2 Parallel Text Mining Algorithm The PTMiner system is an intelligent Web agent that is designed to search for large amounts of parallel text on the Web. The mining algorithm is largely language independent. It can thus be adapted to other language pairs with only minor modifications. Taking advantage of We</context>
<context position="19430" citStr="Wu, 1994" startWordPosition="3113" endWordPosition="3114">ents. As we can see in Fig. 3, the cognate method did not make the same mistake because of the noise in sentence 0002. Despite their large length difference, the two 0002 sentences are still aligned as a 1-1 pair, because the sentences in the following 4 alignments (0003 - 0003; 0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) have rather similar HTML markups and are taken by the program to be the most likely alignments. Beside HTML markups, other criteria may also be incorporated. For example, it would be helpful to consider strong correspondence between certain English and Chinese words, as in (Wu, 1994). We hope to implement such correspondences in our future research. 3.4 Lexicon Evaluation To evaluate the precision of the English-Chinese translation model trained on the Web corpus, we examined two sample lexicons of 200 words, one in each direction. The 200 words for each lexicon were randomly selected from the training source. We examined the most probable translation for each word. The Chinese-English lexicon was found to have a precision of 77%. The English-Chinese lexicon has a higher precision of 81.5%. Part of the lexicons are shown in Fig. 4, where t/f indicates whether a translatio</context>
</contexts>
<marker>Wu, 1994</marker>
<rawString>Dekai Wu. 1994. Aligning a parallel EnglishChinese corpus statistically with lexical criteria. In ACL-94: 32nd Annual Meeting of the Assoc. for Computational Linguistics, pages 80-87, Las Cruces, NM, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Large-scale automatic extraction of an English-Chinese lexicon.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>9--3</pages>
<contexts>
<context position="12928" citStr="Wu (1995)" startWordPosition="2138" endWordPosition="2139">one of the statistical models proposed by Brown et al. (1993), the basic principle of our translation model is the following: given a corpus of aligned sentences, if two words often co-occur in the source and target sentences, there is a good likelihood that they are translations of each other. In the simplest case (model 1), the model learns the probability, p(tis), of having a word t in the translation of a sentence containing a word s. For an input sentence, the model then calculates a sequence of words that are most probable to appear in its translation. Using a similar statistical model, Wu (1995) extracted a largescale English-Chinese lexicon from the HKUST cor23 &lt;s id=&amp;quot;0000&amp;quot;&gt; &lt;s id=&amp;quot;0000&amp;quot;&gt; &lt;HTML&gt; &lt;HEAD&gt; &lt;HTML&gt; &lt;HEAD&gt; &lt;META HTTP-EQUP/=&amp;quot;Content-type&amp;quot; &lt;META HTTP-EQUP/=&amp;quot;Content-type&amp;quot; CONTENT=&amp;quot;text/html; charset=iso-8859-1&amp;quot;&gt; CONTENT=&amp;quot;text/html; charset=big5&amp;quot;&gt; &lt;META HITP-EQUIV=&amp;quot;Content-language&amp;quot; &lt;META HTrP-EQUIV=&amp;quot;Content-language&amp;quot; CONTENT=&amp;quot;Western&amp;quot;&gt; CONTENT=&amp;quot;zh&amp;quot;&gt; &lt;/s&gt; &lt;/s&gt; &lt;s id=&amp;quot;0001&amp;quot;&gt; &lt;s id=&amp;quot;0001&amp;quot;&gt; &lt;TITLE&gt;Journal of Primary Education 1996, &lt;TITLE&gt; Journal of Primary Education 1996, Vol., No. 1&amp;2, pp. 19-27 &lt;/TITLE&gt; Vol., No. 1&amp;2, Page 19-27 &lt;/TITLE&gt; &lt;/HEAD&gt; &lt;/HEAD&gt; &lt;/s&gt; &lt;/s&gt; &lt;s id=&amp;quot;0002&amp;quot;</context>
</contexts>
<marker>Wu, 1995</marker>
<rawString>Dekai Wu. 1995. Large-scale automatic extraction of an English-Chinese lexicon. Machine Translation, 9(3-4):285-313.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>