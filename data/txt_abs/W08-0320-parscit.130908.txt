<newSection> Abstract We describe the experiments of the UC Berkeley team on improving English-Spanish machine translation of news text, as part of the WMT’08 Shared Translation Task.
We experiment with domain adaptation, combining a small in-domain news bi-text and a large out-of-domain one from the Europarl corpus, building two separate phrase translation models and two separate language models.
We further add a third phrase translation model trained on a version of the news bi-text augmented with monolingual sentencelevel syntactic paraphrases on the source-language side, and we combine all models in a log-linear model using minimum error rate training.
Finally, we experiment with different tokenization and recasing rules, achieving 35.09% Bleu score on the WMT’07 news test data when translating from English to Spanish, which is a sizable improvement over the highest Bleu score achieved on that dataset at WMT’07: 33.10% (in fact, by our system).
On the WMT’08 English to Spanish news translation, we achieve 21.92%, which makes our team the second best on Bleu score.