<newSection> Abstract Various semantic relatedness, similarity, and distance measures have been proposed in the past decade and many NLP-applications strongly rely on these semantic measures.
Researchers compete for better algorithms and normally only few percentage points seem to suffice in order to prove a new measure outperforms an older one.
In this paper we present a meta-study comparing various semantic measures and their correlation with human judgments.
We show that the results are rather inconsistent and ask for detailed analyses as well as clarification.
We argue that the definition of a shared task might bring us considerably closer to understanding the concept of semantic relatedness.