<newSection> Abstract This paper presents a discriminative parser that does not use a generative model in any way, yet whose accuracy still surpasses a generative baseline.
The parser performs feature selection incrementally during training, as opposed to a priori, which enables it to work well with minimal linguistic cleverness.
The main challenge in building this parser was fitting the training data into memory.
We introduce gradient sampling, which increased training speed 100-fold.
Our implementation is freely available at http://nlp.cs.nyu.edu/parser/.