<newSection> Abstract This article describes the construction of a morphological, syntactic and semantic analyzer to operate a high-grade search engine for Hebrew texts.
A good search engine must be complete and accurate.
In Hebrew or Arabic script most of the vowels are not written, many particles are attached to the word without space, a double consonant is written with one letter, and some letters signify both vowels and consonants.
Thus, almost every string of characters may designate many words (the average in Hebrew is almost three words).
As a consequence, deciphering a word necessitates reading the whole sentence.
Our model is Fillmore’s framework of an expression with a verb as its center.
The engine eliminates readings of words unsuited to the syntax or the semantic structure of the sentence.
In every verbal entry of our conceptual dictionary the features of the noun phrases (NP’s) required by the verb are included.
When all the correct readings of all the strings of characters in the sentence have been identified, the program chooses the proper occurrences of the searched word in the text.
Approximately 95% of the results by our search engine match those in the query.
1.Introduction It is easy to construct a search engine that, in a given text, will find all the occurrences of the string of characters specified in the query.
In Hebrew script, however, the string of characters that makes up a word may also be interpreted as designating other words.
Almost every word in Hebrew script can be read as one of an average of three words.
This is because Hebrew script is fundamentally defective: (1) Most vowels in a given word have no sign in the script.
(2) Particles are attached with no intervening space to the string of characters that makes up the following word.
(3) A geminated consonant is written as one letter, like a not-geminated consonant.
(4) Several letters serve as both vowels and consonants.
Threfore, it is impossible to identify the word stated in the query by its form: if we try to do so, we would obtain all the occurrences which are written in the same way but are, in fact, different words.
Since only 20-30% of the words so obtained are actually occurrences of the required word, the users have to check every word in the result obtained in order to decide whether it is actually the one they want.1 In order to solve this problem, some systems recommend that every query should contain some other words that are often found close to the stipulated word.2 But such a search may lead to a loss of important occurrences of the required word.
Neither a frequency list of words nor another statistical device can be an ultimate answer in our search of accurate and full device.
A statistical approach ensures that some mistakes or omissions will always exist.
Also, eliminating certain readings by an examination of the words in the short context will not ensure completeness, nor will it ensure accuracy, since a large number of the strings that appear in the result will not be relevant to the question.
(Choueka and Lusignan, 1985; Choueka, 1990).
We can obtain a correct reading of a word only if we can make a correct reading of the whole sentence.
In order to do this, we must eliminate all the unsuitable readings of every string of characters in the sentence, and leave only one reading.
To this end, we had to go through the following stages: 1.
First, we adopted a phonemic script, a method of writing Hebrew in Latin characters, in which each vowel has its character, the particles are separated from the following word, geminated consonants are represented by two identical letters, and vowels and consonants are given completely distinct letters .3 impossible in Hebrew script.
We constructed a complete, exact morphological analyzer for Hebrew words, which also identifies inflections and attached particles.
provides a complete set of details for the analysis of any possible reading of a string of characters, we could write a program which checks every suggested reading of a word, and eliminates readings unsuitable to the syntax of the possibly required sentence.
4. Even a syntactic reading does not ensure that each of the strings in the sentence is indeed a proper reading of the relevant word.
Syntactic elimination may leave many words that do not suit a meaningful sentence.
Further semantic eliminating is required.
5. For this purpose we compiled a complete conceptual dictionary of the Hebrew language.
It is based on Fillmore’s ideas about case grammar (Fillmore, 1968), according to which the verb is the center of the expression: it is a function whose arguments are the noun phrases.
In every conceptual entry in our dictionary of verbs there appear the semantic, syntactic and morphological features demanded by the verb to exist in the NP’s of the sentence, -- including the prepositions, which precede them.
Since the dictionary includes also the features of the arguments (NP’s) in the sentence, it eliminates readings of words that are suitable syntactically but not semantically.
Semantic check enables us to discriminate both between different readings of same string of Hebrew characters as well as between the different meanings of each of the readings.
In this way we completed the necessary basis for the production of an excellent search engine: it will respond to any question only with the occurrences which bear the stipulated meaning, even though the same reading of the characters may have several meanings.
The contents of the article are as follows: In section 2 we shall explain how we establish all possible readings of a string of characters.
Section 3 shows how we use syntactic features to eliminate readings that do not fit the syntactic context; then we describe our conceptual dictionary.
Section 4 shows how we can eliminate readings that are possible syntactically but not semantically.
Finally, in section 5 we shall explain how we choose the appropriate meaning of the word by using the dictionary.
Section 6 concludes the article.