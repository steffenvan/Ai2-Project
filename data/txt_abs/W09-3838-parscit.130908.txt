<newSection> Abstract We present a model which integrates dependency parsing with reinforcement learning based on Markov decision process.
At each time step, a transition is picked up to construct the dependency tree in terms of the long-run reward.
The optimal policy for choosing transitions can be found with the SARSA algorithm.
In SARSA, an approximation of the state-action function can be obtained by calculating the negative free energies for the Restricted Boltzmann Machine.
The experimental results on CoNLL-X multilingual data show that the proposed model achieves comparable results with the current state-of-the-art methods.