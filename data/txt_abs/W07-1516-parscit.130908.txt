<newSection> Abstract In the construction of a part-of-speech annotated corpus, we are constrained by a fixed budget.
A fully annotated corpus is required, but we can afford to label only a subset.
We train a Maximum Entropy Markov Model tagger from a labeled subset and automatically tag the remainder.
This paper addresses the question of where to focus our manual tagging efforts in order to deliver an annotation of highest quality.
In this context, we find that active learning is always helpful.
We focus on Query by Uncertainty (QBU) and Query by Committee (QBC) and report on experiments with several baselines and new variations of QBC and QBU, inspired by weaknesses particular to their use in this application.
Experiments on English prose and poetry test these approaches and evaluate their robustness.
The results allow us to make recommendations for both types of text and raise questions that will lead to further inquiry.