<newSection> Abstract When interacting with humans, intelligent agents must be able not only to understand natural language inputs but also to remember them and link their content with the contents of their memory of event and object instances.
As inputs can come in a variety of forms, linking to memory can be successful only when paraphrasing relations are established between the meaning of new input and the content of the agent’s memory.
This paper discusses a variety of types of paraphrases relevant to this task and describes the way we implement this capability in a virtual patient application.
Paraphrase, under any of its many definitions, is ubiquitous in language use.
It could be likened to reference, both in function and in the complexity of its detection and resolution.
Indeed, there are many ways to express a given idea in language: one can use a canonical word/phrase (dog), a synonymous terse locution (mutt, pooch, canine, man’s best friend), or an explanatory description that can be of any length and include one or more specific salient features (a pet that barks; one of the two most common four-legged domesticated mammals in the USA that is not a cat).
Although these locutions are not semantically identical, they are functionally equivalent in many contexts, meaning that they can permit a person or intelligent agent to carry out the same types of reasoning.
No matter which of the above locutions is used to express the idea of dog, a person or an artificial intelligent agent should be able resolve it to the concept DOG in his/its world model.
Such resolution, or “anchoring”, permits other knowledge about the entity to be leveraged for reasoning: for example, the sentence Our pooch has a long tail should be construed as perfectly normal, whereas Our pooch wrote a grocery list should be understood as impossible in its direct sense since dogs cannot be agents of writing.
Such incongruence should, in turn, suggest either a non-real world or the use of pooch as a nickname for some person or intelligent agent, like an automatic grocery list writing system.
Paraphrase is a difficult problem: at its deepest, it centrally involves semantics, which, due to its inherent complexity, can be addressed only in limited ways in current NLP work.
As a result, most contributions devoted to paraphrase can be described as syntactic or “light semantic.”
In some contributions, processing semantics is constrained to finding synonyms, hyponyms, etc., in a manually constructed word net, like WordNet or any of its progeny.
Some others do not rely on a manually constructed knowledge resource but, rather, aim to determine distributional clustering of similar words in corpora (see, e.g. Pereira et al. (1993) or Lin (2001)).
A few approaches to dealing with paraphrase actually go beyond the detection and use of synonyms.
For example, Lapata (2001) seeks to interpret the meanings of contextually elastic adjectives (such as fast, which means different things in fast highway and fast eater) by semiautomatically constructing paraphrases for phrases that include such adjectives.
These paraphrases use the original noun and the adjective (or any of its synonyms, taken from a hand-constructed list) in its adverbial form and add a corpus-derived candidate verb intended to explain the meaning of the adjective.
Results are evaluated by human judgments of whether a paraphrase (e.g., highway travel quickly) is appropriate as an explanation of the meaning offast in fast highway.
Ibrahim et al.
(2003) pursue the more immediate goal of supporting a question-answering system.
Creating paraphrases for questions helps to expand the queries to the textual resources that are mined for answers.
In an early version of this system, such paraphrase rules — which included a combination of lexical and syntactic transformations — were created by hand (Katz and Levin, 1988).
The new approach follows the methodology of Lin and Pantel (2001) for dynamically determining paraphrases in a corpus by measuring the similarity of paths between nodes in syntactic dependency trees.
This method was applied to pairs of sentences from different English translations of the same text.
(The idea of using a monolingual “sentence-aligned” corpus is due to Barzilay and McKeown (2001).)
Ibrahim et al.
(2003) then suggest a set of heuristics for the subsentential-level matching of nouns and pronouns which leads to the specification of paraphrases in terms of rules such as X became a state in Y H X was admitted to the Union in Y.
The reported precision of the process is about 41%, while the upper bound is given at about 65%.1 Ibrahim et al. state that “question answering should be performed at the level of ‘key relations’ in addition to keywords.”
We believe that it is even better to use key word senses rather than key words, and to include key relations of a semantic and pragmatic nature — though syntactic information should be retained as a valuable source of heuristics for specifying semantic relations.
We believe that we have developed enabling technologies and resources that allow us, at this time, to process paraphrase by relying on meaning representations rather than just syntactic dependencies and text-level relations.
One system that has an application area similar to ours is the one developed by Boonthum (2004).
Boonthum is developing an automatic tutoring application that will be enhanced by paraphrase recognition.
To process paraphrase, she automatically converts natural language sentences into Conceptual Graphs (Sowa, 1983) and compares the graphs of two candidate paraphrases using various metrics.
This system, unlike ours, works at the level of strings (not concepts), does not automatically carry out disambiguation, and cannot handle complex sentences or long spans of text.
Since paraphrase recognition, when viewed broadly, is a very challenging task, some developers choose to focus on a narrow application area.
One such system, reported in Brun and Hagège (2003), detects paraphrases in texts about toxic products.
Developers hand create rules using lexical and structural information, and system output is logical structures like PHYS_FORM(acetone,liquid), which means that the physical form of acetone is liquid.
The approach taken in this work seems very appropriate for this narrow domain of interest.
The research methodology we adopt has the following features, which will serve to orient it in the landscape of work by others.
This methodology: • has provisions for including conceptual paraphrases, which are different ways of describing the same object or event that must be interpreted using the ontological knowledge available to specific agents.
The initial experimentation that we are reporting covers a relatively narrow domain but we hypothesize that the same methodology can be used in other domains, with certain modifications related to ontological and lexical coverage.
The application that drives our current research is Maryland Virtual Patient (MVP), which is an agent-oriented simulation and tutoring system.
In MVP, a human user plays the role of a physician in training who must diagnose and treat open-ended simulations of patients, with or without the help of a virtual mentor agent (e.g. McShane et al., 2007).
The virtual patient is, itself, a “double” agent, comprised of: (a) a physiological agent that lives over time and responds in realistic ways to disease progression and interventions, and (b) a cognitive agent that experiences symptoms, decides when to consult a physician, makes decisions about its lifestyle, treatment options, etc., and communicates with a human user using natural language.
The system currently covers six diseases of the esophagus, so many of our examples will come from this subdomain of medicine.
As should be clear even from this brief overview, MVP is a reasoning-intensive application.
Both physiological simulation and NLP are supported by hand-crafted, ontologically grounded knowledge that includes: All knowledge in the MVP environment is recorded using the metalanguage of description of Ontological Semantics (Nirenburg and Raskin, 2004).
The MVP application will serve as a concrete example for the discussion of paraphrase processing in applications that include intelligent agents.
However, the analysis is readily generalizable and could be applied to any system that would benefit from paraphrase understanding.
This paper will not discuss all types of paraphrase and how OntoSem (the implementation of the theory of Ontological Semantics) handles them, even though one of the core contributions of OntoSem is the robust handling of lexical and syntactic paraphrase by automatically deriving identical meaning representations for inputs that contain such paraphrases (for discussion see Nirenburg and Raskin, 2004, Chapter 8).
Here we focus on just a few of the more “compositional-semantic” types of paraphrase and our theoretical and implementation-oriented solutions to treating them.
Resolving Paraphrases to Support Modeling Language Perception 183