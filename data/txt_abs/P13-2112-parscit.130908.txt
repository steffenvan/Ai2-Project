<newSection> Abstract We present an unsupervised approach to part-of-speech tagging based on projections of tags in a word-aligned bilingual parallel corpus.
In contrast to the existing state-of-the-art approach of Das and Petrov, we have developed a substantially simpler method by automatically identifying “good” training sentences from the parallel corpus and applying self-training.
In experimental results on eight languages, our method achieves state-of-the-art results.
1 Unsupervised part-of-speech tagging Currently, part-of-speech (POS) taggers are available for many highly spoken and well-resourced languages such as English, French, German, Italian, and Arabic.
For example, Petrov et al.
(2012) build supervised POS taggers for 22 languages using the TNT tagger (Brants, 2000), with an average accuracy of 95.2%.
However, many widely-spoken languages — including Bengali, Javanese, and Lahnda — have little data manually labelled for POS, limiting supervised approaches to POS tagging for these languages.
However, with the growing quantity of text available online, and in particular, multilingual parallel texts from sources such as multilingual websites, government documents and large archives of human translations of books, news, and so forth, unannotated parallel data is becoming more widely available.
This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers.
In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011).
In this approach, a parallel corpus for a more-resourced language having a POS tagger, and a lesser-resourced language, is word-aligned.
These alignments are exploited to infer an unsupervised tagger for the target language (i.e., a tagger not requiring manually-labelled data in the target language).
Our approach is substantially simpler than that of Das and Petrov, the current state-of-the art, yet performs comparably well.