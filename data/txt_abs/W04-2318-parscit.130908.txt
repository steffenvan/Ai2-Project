<newSection> Abstract Theories of discourse structure hypothesize a hierarchical structure of discourse segments, typically tree-structured.
While substantial work has been done on identifying and automatically recognizing the textual and prosodic correlates of discourse structure in monologue, comparable cues for dialogue or multiparty conversation, and in particular human-computer dialogue remain relatively less studied.
In this paper, we explore prosodic cues to discourse segmentation in human-computer dialogue.
Using data drawn from 60 hours of interactions with a voice-only conversational spoken language system, we identify pitch and intensity features that signal segment boundaries.
Specifically, based on 473 pairs of segment-final and segment-initiating utterances, we find significant increases for segment-initial utterances in maximum pitch, average pitch, and average intensity, while segment-final utterances show significantly lower minimum pitch.
These results suggest that even in the artificial environment of human-computer dialogue, prosodic cues robustly signal discourse segment structure, comparably to the contrastive uses of pitch and amplitude identified in natural monologues.
Keywords Dialogue Systems, Discourse structure, Prosody in understanding