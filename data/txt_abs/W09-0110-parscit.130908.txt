<newSection> 1 Introduction Typically, current research in psycholinguistics does not rely heavily on results from theoretical linguistics.
In particular, most experimental work studying human sentence processing makes very straightforward assumptions about sentence structure; essentially only a simple context-free grammar is assumed.
The main text book in psycholinguistics, for instance, mentions Minimalism in its chapter on linguistic description (Harley, 2001, ch.
2), but does not provide any details, and all the examples in this chapter, as well as in the chapters on sentence processing and language production (Harley, 2001, chs.
9, 12), only use context-free syntactic structures with uncontroversial phrase markers (S, VP, NP, etc.).
The one exception is traces, which the textbook discusses in the context of syntactic ambiguity resolution.
Harley’s (2001) textbook is typical of experimental psycholinguistics, a field in which most of the work is representationally agnostic, i.e., assumptions about syntactic structure left implicit, or limited to uncontroversial ones.
However, the situation is different in computational psycholinguistics, where researchers built computationally implemented models of human language processing.
This typically involves making one’s theoretical assumptions explicit, a prerequisite for being able to implement them.
For example, Crocker’s (1996) model explicitly implements assumptions from the Principles and Parameters framework, while Hale (2006) uses probabilistic Minimalist grammars, or Mazzei et al.
(2007) tree-adjoining grammars.
Here, we will investigate how evidence regarding human sentence processing can inform our assumptions about syntactic structure, at least in so far as this structure is used in computational models of human parsing.