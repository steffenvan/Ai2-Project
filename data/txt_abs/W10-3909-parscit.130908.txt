<newSection> Abstract Semantic information is a very important factor in coreference resolution.
The combination of large corpora and ‘deep’ analysis procedures has made it possible to acquire a range of semantic information and apply it to this task.
In this paper, we generate two statistically-based semantic features from a large corpus and measure their influence on pronoun coreference.
One is contextual compatibility, which decides if the antecedent can be used in the anaphor’s context; the other is role pair, which decides if the actions asserted of the antecedent and the anaphor are likely to apply to the same entity.
We apply a semantic labeling system and a baseline coreference system to a large corpus to generate semantic patterns and convert them into features in a MaxEnt model.
These features produce an absolute gain of 1.5% to 1.7% in resolution accuracy (a 6% reduction in errors).
To understand the limitations of these features, we also extract patterns from the test corpus, use these patterns to train a coreference model, and examine some of the cases where coreference still fails.
We also compare the performance of patterns extracted from semantic role labeling and syntax.