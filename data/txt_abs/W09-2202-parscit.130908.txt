<newSection> Abstract We consider the task of learning a classifier from the feature space X to the set of classes Y = {0, 1}, when the features can be partitioned into class-conditionally independent feature sets X1 and X2.
We show that the class-conditional independence can be used to represent the original learning task in terms of 1) learning a classifier from X2 to X1 (in the sense of estimating the probability P(x1|x2))and 2) learning the class-conditional distribution of the feature set X1.
This fact can be exploited for semi-supervised learning because the former task can be accomplished purely from unlabeled samples.
We present experimental evaluation of the idea in two real world applications.