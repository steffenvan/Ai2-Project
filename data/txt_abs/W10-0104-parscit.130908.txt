<newSection> Abstract In this work, we show how active learning in some (target) domain can leverage information from a different but related (source) domain.
We present an algorithm that harnesses the source domain data to learn the best possible initializer hypothesis for doing active learning in the target domain, resulting in improved label complexity.
We also present a variant of this algorithm which additionally uses the domain divergence information to selectively query the most informative points in the target domain, leading to further reductions in label complexity.
Experimental results on a variety of datasets establish the efficacy of the proposed methods.